{"title": "Test-Time Scaling with Reflective Generative Model", "abstract": "We introduce our first reflective generative model MetaStone-S1, which\nobtains OpenAI o3's performance via the self-supervised process reward model\n(SPRM). Through sharing the backbone network and using task-specific heads for\nnext token prediction and process scoring respectively, SPRM successfully\nintegrates the policy model and process reward model(PRM) into a unified\ninterface without extra process annotation, reducing over 99% PRM parameters\nfor efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable\nfor test time scaling (TTS), and we provide three reasoning effort modes (low,\nmedium, and high), based on the controllable thinking length. Moreover, we\nempirically establish a scaling law that reveals the relationship between total\nthinking computation and TTS performance. Experiments demonstrate that our\nMetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with\nonly 32B parameter size. To support the research community, we have\nopen-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.", "published": "2025-07-02 17:58:01", "link": "http://arxiv.org/abs/2507.01951v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Thin Line Between Comprehension and Persuasion in LLMs", "abstract": "Large language models (LLMs) are excellent at maintaining high-level,\nconvincing dialogues. They are being fast deployed as chatbots and evaluators\nin sensitive areas, such as peer review and mental health applications. This,\nalong with the disparate accounts on their reasoning capabilities, calls for a\ncloser examination of LLMs and their comprehension of dialogue. In this work we\nbegin by evaluating LLMs' ability to maintain a debate--one of the purest yet\nmost complex forms of human communication. Then we measure how this capability\nrelates to their understanding of what is being talked about, namely, their\ncomprehension of dialogical structures and the pragmatic context. We find that\nLLMs are capable of maintaining coherent, persuasive debates, often swaying the\nbeliefs of participants and audiences alike. We also note that awareness or\nsuspicion of AI involvement encourage people to be more critical of the\narguments made. When polling LLMs on their comprehension of deeper structures\nof dialogue, however, they cannot demonstrate said understanding. Our findings\ntie the shortcomings of LLMs-as-evaluators to their (in)ability to understand\nthe context. More broadly, for the field of argumentation theory we posit that,\nif an agent can convincingly maintain a dialogue, it is not necessary for it to\nknow what it is talking about. Hence, the modelling of pragmatic context and\ncoherence are secondary to effectiveness.", "published": "2025-07-02 17:46:56", "link": "http://arxiv.org/abs/2507.01936v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla", "abstract": "In recent years, neural models trained on large multilingual text and speech\ndatasets have shown great potential for supporting low-resource languages. This\nstudy investigates the performances of two state-of-the-art Automatic Speech\nRecognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's\nWav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments\nusing two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to\nevaluate model performances. Through systematic fine-tuning and hyperparameter\noptimization, including learning rate, epochs, and model checkpoint selection,\nwe have compared the models based on Word Error Rate (WER), Character Error\nRate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model\noutperformed Whisper across all key evaluation metrics, demonstrated superior\nperformance while requiring fewer computational resources, and offered valuable\ninsights to develop robust speech recognition systems in low-resource\nlinguistic settings.", "published": "2025-07-02 17:44:54", "link": "http://arxiv.org/abs/2507.01931v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Decision-oriented Text Evaluation", "abstract": "Natural language generation (NLG) is increasingly deployed in high-stakes\ndomains, yet common intrinsic evaluation methods, such as n-gram overlap or\nsentence plausibility, weakly correlate with actual decision-making efficacy.\nWe propose a decision-oriented framework for evaluating generated text by\ndirectly measuring its influence on human and large language model (LLM)\ndecision outcomes. Using market digest texts--including objective morning\nsummaries and subjective closing-bell analyses--as test cases, we assess\ndecision quality based on the financial performance of trades executed by human\ninvestors and autonomous LLM agents informed exclusively by these texts. Our\nfindings reveal that neither humans nor LLM agents consistently surpass random\nperformance when relying solely on summaries. However, richer analytical\ncommentaries enable collaborative human-LLM teams to outperform individual\nhuman or agent baselines significantly. Our approach underscores the importance\nof evaluating generated text by its ability to facilitate synergistic\ndecision-making between humans and LLMs, highlighting critical limitations of\ntraditional intrinsic metrics.", "published": "2025-07-02 17:32:35", "link": "http://arxiv.org/abs/2507.01923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks", "abstract": "Recent work has shown that distilling reasoning traces from a larger teacher\nmodel via supervised finetuning outperforms reinforcement learning with the\nsmaller student model alone (Guo et al. 2025). However, there has not been a\nsystematic study of what kind of reasoning demonstrations from the teacher are\nmost effective in improving the student model's reasoning capabilities. In this\nwork we curate high-quality \"NaturalThoughts\" by selecting reasoning traces\nfrom a strong teacher model based on a large pool of questions from\nNaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of\nfactors that affect distilling reasoning capabilities, in terms of sample\nefficiency and scalability for general reasoning tasks. We observe that simply\nscaling up data size with random sampling is a strong baseline with steady\nperformance gains. Further, we find that selecting difficult examples that\nrequire more diverse reasoning strategies is more sample-efficient to transfer\nthe teacher model's reasoning skills. Evaluated on both Llama and Qwen models,\ntraining with NaturalThoughts outperforms existing reasoning datasets such as\nOpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including\nGPQA-Diamond, MMLU-Pro and SuperGPQA.", "published": "2025-07-02 17:30:24", "link": "http://arxiv.org/abs/2507.01921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful\ntechnique for aligning large language models (LLMs) with human preferences.\nHowever, effectively aligning LLMs with diverse human preferences remains a\nsignificant challenge, particularly when they are conflict. To address this\nissue, we frame human value alignment as a multi-objective optimization\nproblem, aiming to maximize a set of potentially conflicting objectives. We\nintroduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning\nparadigm that employs multiple-gradient descent to align LLMs with diverse\npreference distributions. GAPO adaptively rescales the gradients for each\nobjective to determine an update direction that optimally balances the\ntrade-offs between objectives. Additionally, we introduce P-GAPO, which\nincorporates user preferences across different objectives and achieves Pareto\nsolutions that better align with the user's specific needs. Our theoretical\nanalysis demonstrates that GAPO converges towards a Pareto optimal solution for\nmultiple objectives. Empirical results on Mistral-7B show that GAPO outperforms\ncurrent state-of-the-art methods, achieving superior performance in both\nhelpfulness and harmlessness.", "published": "2025-07-02 17:25:26", "link": "http://arxiv.org/abs/2507.01915v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AI4Research: A Survey of Artificial Intelligence for Scientific Research", "abstract": "Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated\nremarkable capabilities in complex domains such as logical reasoning and\nexperimental coding. Motivated by these advancements, numerous studies have\nexplored the application of AI in the innovation process, particularly in the\ncontext of scientific research. These AI technologies primarily aim to develop\nsystems that can autonomously conduct research processes across a wide range of\nscientific disciplines. Despite these significant strides, a comprehensive\nsurvey on AI for Research (AI4Research) remains absent, which hampers our\nunderstanding and impedes further development in this field. To address this\ngap, we present a comprehensive survey and offer a unified perspective on\nAI4Research. Specifically, the main contributions of our work are as follows:\n(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify\nfive mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key\nresearch gaps and highlight promising future directions, focusing on the rigor\nand scalability of automated experiments, as well as the societal impact. (3)\nAbundant applications and resources: Finally, we compile a wealth of resources,\nincluding relevant multidisciplinary applications, data corpora, and tools. We\nhope our work will provide the research community with quick access to these\nresources and stimulate innovative breakthroughs in AI4Research.", "published": "2025-07-02 17:19:20", "link": "http://arxiv.org/abs/2507.01903v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "High-Layer Attention Pruning with Rescaling", "abstract": "Pruning is a highly effective approach for compressing large language models\n(LLMs), significantly reducing inference latency. However, conventional\ntraining-free structured pruning methods often employ a heuristic metric that\nindiscriminately removes some attention heads across all pruning layers,\nwithout considering their positions within the network architecture. In this\nwork, we propose a novel pruning algorithm that strategically prunes attention\nheads in the model's higher layers. Since the removal of attention heads can\nalter the magnitude of token representations, we introduce an adaptive\nrescaling parameter that calibrates the representation scale post-pruning to\ncounteract this effect. We conduct comprehensive experiments on a wide range of\nLLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our\nevaluation includes both generation and discriminative tasks across 27\ndatasets. The results consistently demonstrate that our method outperforms\nexisting structured pruning methods. This improvement is particularly notable\nin generation tasks, where our approach significantly outperforms existing\nbaselines.", "published": "2025-07-02 17:15:05", "link": "http://arxiv.org/abs/2507.01900v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants", "abstract": "Large language models (LLMs) excel at reasoning tasks requiring long thought\nsequences for planning, reflection, and refinement. However, their substantial\nmodel size and high computational demands are impractical for widespread\ndeployment. Yet, small language models (SLMs) often struggle to learn long-form\nCoT reasoning due to their limited capacity, a phenomenon we refer to as the\n\"SLMs Learnability Gap\". To address this, we introduce\n\\textbf{Mi}d-\\textbf{Co}T \\textbf{T}eacher \\textbf{A}ssistant Distillation\n(MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA\nemploys intermediate-sized models as teacher assistants and utilizes\nintermediate-length CoT sequences to bridge both the capacity and reasoning\nlength gaps. Our experiments on downstream tasks demonstrate that although SLMs\ndistilled from large teachers can perform poorly, by applying MiCoTA, they\nachieve significant improvements in reasoning performance. Specifically,\nQwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and\n3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and\nGSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform\na quantitative experiment demonstrating that our method produces data more\nclosely aligned with base SLM distributions. Our insights pave the way for\nfuture research into long-CoT data distillation for SLMs.", "published": "2025-07-02 16:57:01", "link": "http://arxiv.org/abs/2507.01887v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DIY-MKG: An LLM-Based Polyglot Language Learning System", "abstract": "Existing language learning tools, even those powered by Large Language Models\n(LLMs), often lack support for polyglot learners to build linguistic\nconnections across vocabularies in multiple languages, provide limited\ncustomization for individual learning paces or needs, and suffer from\ndetrimental cognitive offloading. To address these limitations, we design\nDo-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system\nthat supports polyglot language learning. DIY-MKG allows the user to build\npersonalized vocabulary knowledge graphs, which are constructed by selective\nexpansion with related words suggested by an LLM. The system further enhances\nlearning through rich annotation capabilities and an adaptive review module\nthat leverages LLMs for dynamic, personalized quiz generation. In addition,\nDIY-MKG allows users to flag incorrect quiz questions, simultaneously\nincreasing user engagement and providing a feedback loop for prompt refinement.\nOur evaluation of LLM-based components in DIY-MKG shows that vocabulary\nexpansion is reliable and fair across multiple languages, and that the\ngenerated quizzes are highly accurate, validating the robustness of DIY-MKG.", "published": "2025-07-02 16:38:51", "link": "http://arxiv.org/abs/2507.01872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages", "abstract": "The rapid advancement of Large Language Models (LLMs) has intensified the\nneed for evaluation frameworks that go beyond English centric benchmarks and\naddress the requirements of linguistically diverse regions such as India. We\npresent EKA-EVAL, a unified and production-ready evaluation framework that\nintegrates over 35 benchmarks, including 10 Indic-specific datasets, spanning\ncategories like reasoning, mathematics, tool use, long-context understanding,\nand reading comprehension. Compared to existing Indian language evaluation\ntools, EKA-EVAL offers broader benchmark coverage, with built-in support for\ndistributed inference, quantization, and multi-GPU usage. Our systematic\ncomparison positions EKA-EVAL as the first end-to-end, extensible evaluation\nsuite tailored for both global and Indic LLMs, significantly lowering the\nbarrier to multilingual benchmarking. The framework is open-source and publicly\navailable at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA\ninitiative (https://eka.soket.ai), which aims to scale up to over 100\nbenchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.", "published": "2025-07-02 16:07:54", "link": "http://arxiv.org/abs/2507.01853v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-Perplexity LLM-Generated Sequences and Where To Find Them", "abstract": "As Large Language Models (LLMs) become increasingly widespread, understanding\nhow specific training data shapes their outputs is crucial for transparency,\naccountability, privacy, and fairness. To explore how LLMs leverage and\nreplicate their training data, we introduce a systematic approach centered on\nanalyzing low-perplexity sequences - high-probability text spans generated by\nthe model. Our pipeline reliably extracts such long sequences across diverse\ntopics while avoiding degeneration, then traces them back to their sources in\nthe training data. Surprisingly, we find that a substantial portion of these\nlow-perplexity spans cannot be mapped to the corpus. For those that do match,\nwe quantify the distribution of occurrences across source documents,\nhighlighting the scope and nature of verbatim recall and paving a way toward\nbetter understanding of how LLMs training data impacts their behavior.", "published": "2025-07-02 15:58:51", "link": "http://arxiv.org/abs/2507.01844v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes", "abstract": "We present a comparative analysis of the parseability of structured outputs\ngenerated by small language models for open attribute-value extraction from\nclinical notes. We evaluate three widely used serialization formats: JSON,\nYAML, and XML, and find that JSON consistently yields the highest parseability.\nStructural robustness improves with targeted prompting and larger models, but\ndeclines for longer documents and certain note types. Our error analysis\nidentifies recurring format-specific failure patterns. These findings offer\npractical guidance for selecting serialization formats and designing prompts\nwhen deploying language models in privacy-sensitive clinical settings.", "published": "2025-07-02 15:27:41", "link": "http://arxiv.org/abs/2507.01810v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs", "abstract": "Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language\nModels (LLMs) by enabling parameter-efficient updates. However, their\nwidespread adoption remains limited by the reliance on GPU-based training. In\nthis work, we propose a theoretically grounded approach to LoRA fine-tuning\ndesigned specifically for users with limited computational resources,\nparticularly those restricted to standard laptop CPUs. Our method learns a\nmeta-operator that maps any input dataset, represented as a probability\ndistribution, to a set of LoRA weights by leveraging a large bank of\npre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of\nperforming new gradient-based updates, our pipeline constructs adapters via\nlightweight combinations of existing LoRAs directly on CPU. While the resulting\nadapters do not match the performance of GPU-trained counterparts, they\nconsistently outperform the base Mistral model on downstream tasks, offering a\npractical and accessible alternative to traditional GPU-based fine-tuning.", "published": "2025-07-02 15:24:47", "link": "http://arxiv.org/abs/2507.01806v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Anatomy of Evidence: An Investigation Into Explainable ICD Coding", "abstract": "Automatic medical coding has the potential to ease documentation and billing\nprocesses. For this task, transparency plays an important role for medical\ncoders and regulatory bodies, which can be achieved using explainability\nmethods. However, the evaluation of these approaches has been mostly limited to\nshort text and binary settings due to a scarcity of annotated data. Recent\nefforts by Cheng et al. (2023) have introduced the MDACE dataset, which\nprovides a valuable resource containing code evidence in clinical records. In\nthis work, we conduct an in-depth analysis of the MDACE dataset and perform\nplausibility evaluation of current explainable medical coding systems from an\napplied perspective. With this, we contribute to a deeper understanding of\nautomatic medical coding and evidence extraction. Our findings reveal that\nground truth evidence aligns with code descriptions to a certain degree. An\ninvestigation into state-of-the-art approaches shows a high overlap with ground\ntruth evidence. We propose match measures and highlight success and failure\ncases. Based on our findings, we provide recommendations for developing and\nevaluating explainable medical coding systems.", "published": "2025-07-02 15:21:29", "link": "http://arxiv.org/abs/2507.01802v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?", "abstract": "AI models are increasingly required to be multimodal, integrating disparate\ninput streams into a coherent state representation on which subsequent\nbehaviors and actions can be based. This paper seeks to understand how such\nmodels behave when input streams present conflicting information. Focusing\nspecifically on vision-language models, we provide inconsistent inputs (e.g.,\nan image of a dog paired with the caption \"A photo of a cat\") and ask the model\nto report the information present in one of the specific modalities (e.g.,\n\"What does the caption say / What is in the image?\"). We find that models often\nfavor one modality over the other, e.g., reporting the image regardless of what\nthe caption says, but that different models differ in which modality they\nfavor. We find evidence that the behaviorally preferred modality is evident in\nthe internal representational structure of the model, and that specific\nattention heads can restructure the representations to favor one modality over\nthe other. Moreover, we find modality-agnostic \"router heads\" which appear to\npromote answers about the modality requested in the instruction, and which can\nbe manipulated or transferred in order to improve performance across datasets\nand modalities. Together, the work provides essential steps towards identifying\nand controlling if and how models detect and resolve conflicting signals within\ncomplex multimodal environments.", "published": "2025-07-02 15:15:14", "link": "http://arxiv.org/abs/2507.01790v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing Evaluation Awareness of Language Models", "abstract": "Language models can distinguish between testing and deployment phases -- a\ncapability known as evaluation awareness. This has significant safety and\npolicy implications, potentially undermining the reliability of evaluations\nthat are central to AI governance frameworks and voluntary industry\ncommitments. In this paper, we study evaluation awareness in\nLlama-3.3-70B-Instruct. We show that linear probes can separate real-world\nevaluation and deployment prompts, suggesting that current models internally\nrepresent this distinction. We also find that current safety evaluations are\ncorrectly classified by the probes, suggesting that they already appear\nartificial or inauthentic to models. Our findings underscore the importance of\nensuring trustworthy evaluations and understanding deceptive capabilities. More\nbroadly, our work showcases how model internals may be leveraged to support\nblackbox methods in safety audits, especially for future models more competent\nat evaluation awareness and deception.", "published": "2025-07-02 15:12:43", "link": "http://arxiv.org/abs/2507.01786v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining", "abstract": "Data quality is a critical driver of large language model performance, yet\nexisting model-based selection methods focus almost exclusively on English. We\nintroduce MuRating, a scalable framework that transfers high-quality English\ndata-quality signals into a single rater for 17 target languages. MuRating\naggregates multiple English \"raters\" via pairwise comparisons to learn unified\ndocument-quality scores,then projects these judgments through translation to\ntrain a multilingual evaluator on monolingual, cross-lingual, and parallel text\npairs. Applied to web data, MuRating selects balanced subsets of English and\nmultilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to\nstrong baselines, including QuRater, AskLLM, DCLM and so on, our approach\nboosts average accuracy on both English benchmarks and multilingual\nevaluations, with especially large gains on knowledge-intensive tasks. We\nfurther analyze translation fidelity, selection biases, and underrepresentation\nof narrative material, outlining directions for future work.", "published": "2025-07-02 15:11:12", "link": "http://arxiv.org/abs/2507.01785v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results", "abstract": "Tokenisation - \"the process of splitting text into atomic parts\" (Brezina &\nTimperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides\nthe basis for any applicable quantitative method (e.g. collocations) while\nensuring the reliability of qualitative approaches. This paper examines how\ndiscrepancies in tokenisation affect the representation of language data and\nthe validity of analytical findings: investigating the challenges posed by\nemojis and homoglyphs, the study highlights the necessity of preprocessing\nthese elements to maintain corpus fidelity to the source data. The research\npresents methods for ensuring that digital texts are accurately represented in\ncorpora, thereby supporting reliable linguistic analysis and guaranteeing the\nrepeatability of linguistic interpretations. The findings emphasise the\nnecessity of a detailed understanding of both linguistic and technical aspects\ninvolved in digital textual data to enhance the accuracy of corpus analysis,\nand have significant implications for both quantitative and qualitative\napproaches in corpus-based research.", "published": "2025-07-02 14:46:26", "link": "http://arxiv.org/abs/2507.01764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "abstract": "Gradient-based optimization is the workhorse of deep learning, offering\nefficient and scalable training via backpropagation. However, its reliance on\nlarge volumes of labeled data raises privacy and security concerns such as\nsusceptibility to data poisoning attacks and the risk of overfitting. In\ncontrast, black box optimization methods, which treat the model as an opaque\nfunction, relying solely on function evaluations to guide optimization, offer a\npromising alternative in scenarios where data access is restricted, adversarial\nrisks are high, or overfitting is a concern. However, black box methods also\npose significant challenges, including poor scalability to high-dimensional\nparameter spaces, as prevalent in large language models (LLMs), and high\ncomputational costs due to reliance on numerous model evaluations. This paper\nintroduces BBoxER, an evolutionary black-box method for LLM post-training that\ninduces an information bottleneck via implicit compression of the training\ndata. Leveraging the tractability of information flow, we provide strong\ntheoretical bounds on generalization, differential privacy, susceptibility to\ndata poisoning attacks, and robustness to extraction attacks. BBoxER operates\non top of pre-trained LLMs, offering a lightweight and modular enhancement\nsuitable for deployment in restricted or privacy-sensitive environments, in\naddition to non-vacuous generalization guarantees. In experiments with LLMs, we\ndemonstrate empirically that Retrofitting methods are able to learn, showing\nhow a few iterations of BBoxER improve performance and generalize well on a\nbenchmark of reasoning datasets. This positions BBoxER as an attractive add-on\non top of gradient-based optimization.", "published": "2025-07-02 14:29:30", "link": "http://arxiv.org/abs/2507.01752v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving", "abstract": "In this paper, we present details of the 1st W-CODA workshop, held in\nconjunction with the ECCV 2024. W-CODA aims to explore next-generation\nsolutions for autonomous driving corner cases, empowered by state-of-the-art\nmultimodal perception and comprehension techniques. 5 Speakers from both\nacademia and industry are invited to share their latest progress and opinions.\nWe collect research papers and hold a dual-track challenge, including both\ncorner case scene understanding and generation. As the pioneering effort, we\nwill continuously bridge the gap between frontier autonomous driving techniques\nand fully intelligent, reliable self-driving agents robust towards corner\ncases.", "published": "2025-07-02 14:10:25", "link": "http://arxiv.org/abs/2507.01735v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LLMs for Legal Subsumption in German Employment Contracts", "abstract": "Legal work, characterized by its text-heavy and resource-intensive nature,\npresents unique challenges and opportunities for NLP research. While\ndata-driven approaches have advanced the field, their lack of interpretability\nand trustworthiness limits their applicability in dynamic legal environments.\nTo address these issues, we collaborated with legal experts to extend an\nexisting dataset and explored the use of Large Language Models (LLMs) and\nin-context learning to evaluate the legality of clauses in German employment\ncontracts. Our work evaluates the ability of different LLMs to classify clauses\nas \"valid,\" \"unfair,\" or \"void\" under three legal context variants: no legal\ncontext, full-text sources of laws and court rulings, and distilled versions of\nthese (referred to as examination guidelines). Results show that full-text\nsources moderately improve performance, while examination guidelines\nsignificantly enhance recall for void clauses and weighted F1-Score, reaching\n80\\%. Despite these advancements, LLMs' performance when using full-text\nsources remains substantially below that of human lawyers. We contribute an\nextended dataset, including examination guidelines, referenced legal sources,\nand corresponding annotations, alongside our code and all log files. Our\nfindings highlight the potential of LLMs to assist lawyers in contract legality\nreview while also underscoring the limitations of the methods presented.", "published": "2025-07-02 14:07:54", "link": "http://arxiv.org/abs/2507.01734v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach", "abstract": "Bias and stereotypes in language models can cause harm, especially in\nsensitive areas like content moderation and decision-making. This paper\naddresses bias and stereotype detection by exploring how jointly learning these\ntasks enhances model performance. We introduce StereoBias, a unique dataset\nlabeled for bias and stereotype detection across five categories: religion,\ngender, socio-economic status, race, profession, and others, enabling a deeper\nstudy of their relationship. Our experiments compare encoder-only models and\nfine-tuned decoder-only models using QLoRA. While encoder-only models perform\nwell, decoder-only models also show competitive results. Crucially, joint\ntraining on bias and stereotype detection significantly improves bias detection\ncompared to training them separately. Additional experiments with sentiment\nanalysis confirm that the improvements stem from the connection between bias\nand stereotypes, not multi-task learning alone. These findings highlight the\nvalue of leveraging stereotype information to build fairer and more effective\nAI systems.", "published": "2025-07-02 13:46:00", "link": "http://arxiv.org/abs/2507.01715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness", "abstract": "The proliferation of multimodal memes in the social media era demands that\nmultimodal Large Language Models (mLLMs) effectively understand meme\nharmfulness. Existing benchmarks for assessing mLLMs on harmful meme\nunderstanding rely on accuracy-based, model-agnostic evaluations using static\ndatasets. These benchmarks are limited in their ability to provide up-to-date\nand thorough assessments, as online memes evolve dynamically. To address this,\nwe propose AdamMeme, a flexible, agent-based evaluation framework that\nadaptively probes the reasoning capabilities of mLLMs in deciphering meme\nharmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive\nevaluations by iteratively updating the meme data with challenging samples,\nthereby exposing specific limitations in how mLLMs interpret harmfulness.\nExtensive experiments show that our framework systematically reveals the\nvarying performance of different target mLLMs, offering in-depth, fine-grained\nanalyses of model-specific weaknesses. Our code is available at\nhttps://github.com/Lbotirx/AdamMeme.", "published": "2025-07-02 13:32:30", "link": "http://arxiv.org/abs/2507.01702v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling", "abstract": "Existing post-training techniques for large language models are broadly\ncategorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning\n(RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking\ndemonstration data but can lead to problematic generalization as a form of\nbehavior cloning. Conversely, RFT can significantly enhance a model's\nperformance but is prone to learn unexpected behaviors, and its performance is\nhighly sensitive to the initial policy. In this paper, we propose a unified\nview of these methods and introduce Prefix-RFT, a hybrid approach that\nsynergizes learning from both demonstration and exploration. Using mathematical\nreasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is\nboth simple and effective. It not only surpasses the performance of standalone\nSFT and RFT but also outperforms parallel mixed-policy RFT methods. A key\nadvantage is its seamless integration into existing open-source frameworks,\nrequiring only minimal modifications to the standard RFT pipeline. Our analysis\nhighlights the complementary nature of SFT and RFT, and validates that\nPrefix-RFT effectively harmonizes these two learning paradigms. Furthermore,\nablation studies confirm the method's robustness to variations in the quality\nand quantity of demonstration data. We hope this work offers a new perspective\non LLM post-training, suggesting that a unified paradigm that judiciously\nintegrates demonstration and exploration could be a promising direction for\nfuture research.", "published": "2025-07-02 13:04:09", "link": "http://arxiv.org/abs/2507.01679v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings", "abstract": "In this paper, we investigate the transferability of pre-trained language\nmodels to low-resource Indonesian local languages through the task of sentiment\nanalysis. We evaluate both zero-shot performance and adapter-based transfer on\nten local languages using models of different types: a monolingual Indonesian\nBERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based\napproach called MAD-X. To better understand model behavior, we group the target\nlanguages into three categories: seen (included during pre-training), partially\nseen (not included but linguistically related to seen languages), and unseen\n(absent and unrelated in pre-training data). Our results reveal clear\nperformance disparities across these groups: multilingual models perform best\non seen languages, moderately on partially seen ones, and poorly on unseen\nlanguages. We find that MAD-X significantly improves performance, especially\nfor seen and partially seen languages, without requiring labeled data in the\ntarget language. Additionally, we conduct a further analysis on tokenization\nand show that while subword fragmentation and vocabulary overlap with\nIndonesian correlate weakly with prediction quality, they do not fully explain\nthe observed performance. Instead, the most consistent predictor of transfer\nsuccess is the model's prior exposure to the language, either directly or\nthrough a related language.", "published": "2025-07-02 12:17:55", "link": "http://arxiv.org/abs/2507.01645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Confidence and Stability of Global and Pairwise Scores in NLP Evaluation", "abstract": "With the advent of highly capable instruction-tuned neural language models,\nbenchmarking in natural language processing (NLP) is increasingly shifting\ntowards pairwise comparison leaderboards, such as LMSYS Arena, from traditional\nglobal pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper\nempirically investigates the strengths and weaknesses of both global scores and\npairwise comparisons to aid decision-making in selecting appropriate model\nevaluation strategies. Through computational experiments on synthetic and\nreal-world datasets using standard global metrics and the popular Bradley-Terry\nmodel for pairwise comparisons, we found that while global scores provide more\nreliable overall rankings, they can underestimate strong models with rare,\nsignificant errors or low confidence. Conversely, pairwise comparisons are\nparticularly effective for identifying strong contenders among models with\nlower global scores, especially where quality metrics are hard to define (e.g.,\ntext generation), though they require more comparisons to converge if ties are\nfrequent. Our code and data are available at\nhttps://github.com/HSPyroblast/srw-ranking under a permissive license.", "published": "2025-07-02 12:05:22", "link": "http://arxiv.org/abs/2507.01633v1", "categories": ["cs.CL", "cs.IR", "62-04", "D.2.3"], "primary_category": "cs.CL"}
{"title": "Chart Question Answering from Real-World Analytical Narratives", "abstract": "We present a new dataset for chart question answering (CQA) constructed from\nvisualization notebooks. The dataset features real-world, multi-view charts\npaired with natural language questions grounded in analytical narratives.\nUnlike prior benchmarks, our data reflects ecologically valid reasoning\nworkflows. Benchmarking state-of-the-art multimodal large language models\nreveals a significant performance gap, with GPT-4.1 achieving an accuracy of\n69.3%, underscoring the challenges posed by this more authentic CQA setting.", "published": "2025-07-02 11:58:04", "link": "http://arxiv.org/abs/2507.01627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems", "abstract": "Traditional Data+AI systems utilize data-driven techniques to optimize\nperformance, but they rely heavily on human experts to orchestrate system\npipelines, enabling them to adapt to changes in data, queries, tasks, and\nenvironments. For instance, while there are numerous data science tools\navailable, developing a pipeline planning system to coordinate these tools\nremains challenging. This difficulty arises because existing Data+AI systems\nhave limited capabilities in semantic understanding, reasoning, and planning.\nFortunately, we have witnessed the success of large language models (LLMs) in\nenhancing semantic understanding, reasoning, and planning abilities. It is\ncrucial to incorporate LLM techniques to revolutionize data systems for\norchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive\narchitecture designed to orchestrate Data+AI ecosystems, which focuses on\ntackling data-related tasks by integrating knowledge comprehension, reasoning,\nand planning capabilities. We delve into the challenges involved in designing\ndata agents, such as understanding data/queries/environments/tools,\norchestrating pipelines/workflows, optimizing and executing pipelines, and\nfostering pipeline self-reflection. Furthermore, we present examples of data\nagent systems, including a data science agent, data analytics agents (such as\nunstructured data analytics agent, semantic structured data analytics agent,\ndata lake analytics agent, and multi-modal data analytics agent), and a\ndatabase administrator (DBA) agent. We also outline several open challenges\nassociated with designing data agent systems.", "published": "2025-07-02 11:04:49", "link": "http://arxiv.org/abs/2507.01599v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning", "abstract": "Temporal Knowledge Graph (TKG) is an efficient method for describing the\ndynamic development of facts along a timeline. Most research on TKG reasoning\n(TKGR) focuses on modelling the repetition of global facts and designing\npatterns of local historical facts. However, they face two significant\nchallenges: inadequate modeling of the event distribution shift between\ntraining and test samples, and reliance on random entity substitution for\ngenerating negative samples, which often results in low-quality sampling. To\nthis end, we propose a novel distributional feature modeling approach for\ntraining TKGR models, Test-Time Training-guided Distribution shift Modelling\n(T3DM), to adjust the model based on distribution shift and ensure the global\nconsistency of model reasoning. In addition, we design a negative-sampling\nstrategy to generate higher-quality negative quadruples based on adversarial\ntraining. Extensive experiments show that T3DM provides better and more robust\nresults than the state-of-the-art baselines in most cases.", "published": "2025-07-02 11:02:37", "link": "http://arxiv.org/abs/2507.01597v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation", "abstract": "Task-oriented dialogue (ToD) systems are designed to help users achieve\nspecific goals through natural language interaction. While recent advances in\nlarge language models (LLMs) have significantly improved linguistic fluency and\ncontextual understanding, building effective and emotionally intelligent ToD\nsystems remains a complex challenge. Effective ToD systems must optimise for\ntask success, emotional understanding and responsiveness, and precise\ninformation conveyance, all within inherently noisy and ambiguous\nconversational environments. In this work, we investigate architectural,\nrepresentational, optimisational as well as emotional considerations of ToD\nsystems. We set up systems covering these design considerations with a\nchallenging evaluation environment composed of a natural-language user\nsimulator coupled with an imperfect natural language understanding module. We\npropose \\textbf{LUSTER}, an \\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem\nfor \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end\n\\textbf{R}einforcement learning with both short-term (user sentiment) and\nlong-term (task success) rewards. Our findings demonstrate that combining LLM\ncapability with structured reward modelling leads to more resilient and\nemotionally responsive ToD systems, offering a practical path forward for\nnext-generation conversational agents.", "published": "2025-07-02 11:00:33", "link": "http://arxiv.org/abs/2507.01594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning", "abstract": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential\nin enhancing the reasoning capabilities of Large Language Models~(LLMs).\nHowever, introducing additional process reward models incurs substantial\ncomputational overhead, and there is no unified theoretical framework for\nprocess-level advantage estimation. To bridge this gap, we propose\n\\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward\n\\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables\nprocess-aware RL through two key innovations: (1) we first theoretically\ndemonstrate that process rewards can be derived intrinsically from the policy\nmodel itself, and (2) we introduce well-defined cumulative process rewards and\n\\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which\nfacilitates rigorous step-wise action advantage estimation within shared-prompt\nsampling groups. Our experimental results demonstrate that SPRO outperforms\nvaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy\nimprovement. Furthermore, SPRO maintains a stable and elevated policy entropy\nthroughout training while reducing the average response length by approximately\n$1/3$, evidencing sufficient exploration and prevention of reward hacking.\nNotably, SPRO incurs no additional computational overhead compared to\noutcome-supervised RL methods such as GRPO, which benefit industrial\nimplementation.", "published": "2025-07-02 10:05:14", "link": "http://arxiv.org/abs/2507.01551v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "abstract": "This paper explores how older adults, particularly aging migrants in urban\nChina, can engage AI-assisted co-creation to express personal narratives that\nare often fragmented, underrepresented, or difficult to verbalize. Through a\npilot workshop combining oral storytelling and the symbolic reconstruction of\nHanzi, participants shared memories of migration and recreated new character\nforms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),\ntogether with physical materials. Supported by human facilitation and a soft AI\npresence, participants transformed lived experience into visual and tactile\nexpressions without requiring digital literacy. This approach offers new\nperspectives on human-AI collaboration and aging by repositioning AI not as a\ncontent producer but as a supportive mechanism, and by supporting narrative\nagency within sociotechnical systems.", "published": "2025-07-02 10:00:12", "link": "http://arxiv.org/abs/2507.01548v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Is External Information Useful for Stance Detection with LLMs?", "abstract": "In the stance detection task, a text is classified as either favorable,\nopposing, or neutral towards a target. Prior work suggests that the use of\nexternal information, e.g., excerpts from Wikipedia, improves stance detection\nperformance. However, whether or not such information can benefit large\nlanguage models (LLMs) remains an unanswered question, despite their wide\nadoption in many reasoning tasks. In this study, we conduct a systematic\nevaluation on how Wikipedia and web search external information can affect\nstance detection across eight LLMs and in three datasets with 12 targets.\nSurprisingly, we find that such information degrades performance in most cases,\nwith macro F1 scores dropping by up to 27.9\\%. We explain this through\nexperiments showing LLMs' tendency to align their predictions with the stance\nand sentiment of the provided information rather than the ground truth stance\nof the given text. We also find that performance degradation persists with\nchain-of-thought prompting, while fine-tuning mitigates but does not fully\neliminate it. Our findings, in contrast to previous literature on BERT-based\nsystems which suggests that external information enhances performance,\nhighlight the risks of information biases in LLM-based stance classifiers. Code\nis available at https://github.com/ngqm/acl2025-stance-detection.", "published": "2025-07-02 09:53:41", "link": "http://arxiv.org/abs/2507.01543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing", "abstract": "Out-of-scope (OOS) intent detection is a critical challenge in task-oriented\ndialogue systems (TODS), as it ensures robustness to unseen and ambiguous\nqueries. In this work, we propose a novel but simple modular framework that\ncombines uncertainty modeling with fine-tuned large language models (LLMs) for\nefficient and accurate OOS detection. The first step applies uncertainty\nestimation to the output of an in-scope intent detection classifier, which is\ncurrently deployed in a real-world TODS handling tens of thousands of user\ninteractions daily. The second step then leverages an emerging LLM-based\napproach, where a fine-tuned LLM is triggered to make a final decision on\ninstances with high uncertainty. Unlike prior approaches, our method\neffectively balances computational efficiency and performance, combining\ntraditional approaches with LLMs and yielding state-of-the-art results on key\nOOS detection benchmarks, including real-world OOS data acquired from a\ndeployed TODS.", "published": "2025-07-02 09:51:41", "link": "http://arxiv.org/abs/2507.01541v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence", "abstract": "The collection and release of street-level recordings as Open Data play a\nvital role in advancing autonomous driving systems and AI research. However,\nthese datasets pose significant privacy risks, particularly for pedestrians,\ndue to the presence of Personally Identifiable Information (PII) that extends\nbeyond biometric traits such as faces. In this paper, we present cRID, a novel\ncross-modal framework combining Large Vision-Language Models, Graph Attention\nNetworks, and representation learning to detect textual describable clues of\nPII and enhance person re-identification (Re-ID). Our approach focuses on\nidentifying and leveraging interpretable features, enabling the detection of\nsemantically meaningful PII beyond low-level appearance cues. We conduct a\nsystematic evaluation of PII presence in person image datasets. Our experiments\nshow improved performance in practical cross-dataset Re-ID scenarios, notably\nfrom Market-1501 to CUHK03-np (detected), highlighting the framework's\npractical utility. Code is available at https://github.com/RAufschlaeger/cRID.", "published": "2025-07-02 09:10:33", "link": "http://arxiv.org/abs/2507.01504v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities", "abstract": "Automatic text simplification (ATS) aims to enhance language accessibility\nfor various target groups, particularly persons with intellectual disabilities.\nRecent advancements in generative AI, especially large language models (LLMs),\nhave substantially improved the quality of machine-generated text\nsimplifications, thereby mitigating information barriers for the target group.\nHowever, existing LLM-based ATS systems do not incorporate preference feedback\non text simplifications during training, resulting in a lack of personalization\ntailored to the specific needs of target group representatives.\n  In this work, we extend the standard supervised fine-tuning (SFT) approach\nfor adapting LLM-based ATS models by leveraging a computationally efficient LLM\nalignment technique -- direct preference optimization (DPO). Specifically, we\npost-train LLM-based ATS models using human feedback collected from persons\nwith intellectual disabilities, reflecting their preferences on paired text\nsimplifications generated by mainstream LLMs. Furthermore, we propose a\npipeline for developing personalized LLM-based ATS systems, encompassing data\ncollection, model selection, SFT and DPO post-training, and evaluation. Our\nfindings underscore the necessity of active participation of target group\npersons in designing personalized AI accessibility solutions aligned with human\nexpectations. This work represents a step towards personalizing inclusive AI\nsystems at the target-group level, incorporating insights not only from text\nsimplification experts but also from target group persons themselves.", "published": "2025-07-02 08:43:06", "link": "http://arxiv.org/abs/2507.01479v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation", "abstract": "Speculative decoding (SD), where a small draft model is employed to propose\ndraft tokens in advance and then the target model validates them in parallel,\nhas emerged as a promising technique for LLM inference acceleration. Many\nendeavors to improve SD are to eliminate the need for a draft model and\ngenerate draft tokens in a retrieval-based manner in order to further alleviate\nthe drafting overhead and significantly reduce the difficulty in deployment and\napplications. However, retrieval-based SD relies on a matching paradigm to\nretrieval the most relevant reference as the draft tokens, where these methods\noften fail to find matched and accurate draft tokens. To address this\nchallenge, we propose LogitSpec to effectively expand the retrieval range and\nfind the most relevant reference as drafts. Our LogitSpec is motivated by the\nobservation that the logit of the last token can not only predict the next\ntoken, but also speculate the next next token. Specifically, LogitSpec\ngenerates draft tokens in two steps: (1) utilizing the last logit to speculate\nthe next next token; (2) retrieving relevant reference for both the next token\nand the next next token. LogitSpec is training-free and plug-and-play, which\ncan be easily integrated into existing LLM inference frameworks. Extensive\nexperiments on a wide range of text generation benchmarks demonstrate that\nLogitSpec can achieve up to 2.61 $\\times$ speedup and 3.28 mean accepted tokens\nper decoding step. Our code is available at\nhttps://github.com/smart-lty/LogitSpec.", "published": "2025-07-02 08:08:30", "link": "http://arxiv.org/abs/2507.01449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction", "abstract": "This paper addresses the challenges posed by the unstructured nature and\nhigh-dimensional semantic complexity of electronic health record texts. A deep\nlearning method based on attention mechanisms is proposed to achieve unified\nmodeling for information extraction and multi-label disease prediction. The\nstudy is conducted on the MIMIC-IV dataset. A Transformer-based architecture is\nused to perform representation learning over clinical text. Multi-layer\nself-attention mechanisms are employed to capture key medical entities and\ntheir contextual relationships. A Sigmoid-based multi-label classifier is then\napplied to predict multiple disease labels. The model incorporates a\ncontext-aware semantic alignment mechanism, enhancing its representational\ncapacity in typical medical scenarios such as label co-occurrence and sparse\ninformation. To comprehensively evaluate model performance, a series of\nexperiments were conducted, including baseline comparisons, hyperparameter\nsensitivity analysis, data perturbation studies, and noise injection tests.\nResults demonstrate that the proposed method consistently outperforms\nrepresentative existing approaches across multiple performance metrics. The\nmodel maintains strong generalization under varying data scales, interference\nlevels, and model depth configurations. The framework developed in this study\noffers an efficient algorithmic foundation for processing real-world clinical\ntexts and presents practical significance for multi-label medical text modeling\ntasks.", "published": "2025-07-02 07:45:22", "link": "http://arxiv.org/abs/2507.01437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading", "abstract": "Grading handwritten, open-ended responses remains a major bottleneck in large\nuniversity STEM courses. We introduce Pensieve (https://www.pensieve.co), an\nAI-assisted grading platform that leverages large language models (LLMs) to\ntranscribe and evaluate student work, providing instructors with rubric-aligned\nscores, transcriptions, and confidence ratings. Unlike prior tools that focus\nnarrowly on specific tasks like transcription or rubric generation, Pensieve\nsupports the entire grading pipeline-from scanned student submissions to final\nfeedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and\nhas graded more than 300,000 student responses. We present system details and\nempirical results across four core STEM disciplines: Computer Science,\nMathematics, Physics, and Chemistry. Our findings show that Pensieve reduces\ngrading time by an average of 65%, while maintaining a 95.4% agreement rate\nwith instructor-assigned grades for high-confidence predictions.", "published": "2025-07-02 07:33:19", "link": "http://arxiv.org/abs/2507.01431v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "abstract": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.", "published": "2025-07-02 04:40:29", "link": "http://arxiv.org/abs/2507.01352v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LEDOM: An Open and Fundamental Reverse Language Model", "abstract": "We introduce LEDOM, the first purely reverse language model, trained\nautoregressively on 435B tokens with 2B and 7B parameter variants, which\nprocesses sequences in reverse temporal order through previous token\nprediction. For the first time, we present the reverse language model as a\npotential foundational model across general tasks, accompanied by a set of\nintriguing examples and insights. Based on LEDOM, we further introduce a novel\napplication: Reverse Reward, where LEDOM-guided reranking of forward language\nmodel outputs leads to substantial performance improvements on mathematical\nreasoning tasks. This approach leverages LEDOM's unique backward reasoning\ncapability to refine generation quality through posterior evaluation. Our\nfindings suggest that LEDOM exhibits unique characteristics with broad\napplication potential. We will release all models, training code, and\npre-training data to facilitate future research.", "published": "2025-07-02 03:52:00", "link": "http://arxiv.org/abs/2507.01335v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "abstract": "Navigating the complexities of physics reasoning has long been a difficult\ntask for Large Language Models (LLMs), requiring a synthesis of profound\nconceptual understanding and adept problem-solving techniques. In this study,\nwe investigate the application of advanced instruction-tuned reasoning models,\nsuch as Deepseek-R1, to address a diverse spectrum of physics problems curated\nfrom the challenging SciBench benchmark. Our comprehensive experimental\nevaluation reveals the remarkable capabilities of reasoning models. Not only do\nthey achieve state-of-the-art accuracy in answering intricate physics\nquestions, but they also generate distinctive reasoning patterns that emphasize\non symbolic derivation. Furthermore, our findings indicate that even for these\nhighly sophisticated reasoning models, the strategic incorporation of few-shot\nprompting can still yield measurable improvements in overall accuracy,\nhighlighting the potential for continued performance gains.", "published": "2025-07-02 03:51:16", "link": "http://arxiv.org/abs/2507.01334v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation", "abstract": "Activation sparsity can reduce the computational overhead and memory\ntransfers during the forward pass of Large Language Model (LLM) inference.\nExisting methods face limitations, either demanding time-consuming recovery\ntraining that hinders real-world adoption, or relying on empirical\nmagnitude-based pruning, which causes fluctuating sparsity and unstable\ninference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse\nActivation), a novel method for activation sparsification designed to improve\nLLM efficiency without requiring additional training or magnitude-based\npruning. We leverage layerwise orthogonal rotations to transform input\nactivations into rotated forms that are more suitable for sparsification. By\nemploying a Top-K selection approach within the rotated activations, we achieve\nconsistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA\nis effective across various sizes and types of LLMs, demonstrating minimal\nperformance degradation and robust inference acceleration. Specifically, for\nLLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a\nconsistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in\nzero-shot tasks compared to the dense model to just 0.54%, while surpassing\nTEAL by 1.77% and CATS by 17.14%.", "published": "2025-07-02 02:36:03", "link": "http://arxiv.org/abs/2507.01299v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks", "abstract": "Retrieval-augmented Generation (RAG) has primarily been studied in limited\nsettings, such as factoid question answering; more challenging,\nreasoning-intensive benchmarks have seen limited success from minimal RAG. In\nthis work, we challenge this prevailing view on established,\nreasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We\nidentify a key missing component in prior work: a usable, web-scale datastore\naligned with the breadth of pretraining data. To this end, we introduce\nCompactDS: a diverse, high-quality, web-scale datastore that achieves high\nretrieval accuracy and subsecond latency on a single-node. The key insights are\n(1) most web content can be filtered out without sacrificing coverage, and a\ncompact, high-quality subset is sufficient; and (2) combining in-memory\napproximate nearest neighbor (ANN) retrieval and on-disk exact search balances\nspeed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves\nconsistent accuracy improvements across all benchmarks and model sizes\n(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,\nand 19% on MATH. No single data source suffices alone, highlighting the\nimportance of diversity of sources (web crawls, curated math, academic papers,\ntextbooks). Finally, we show that our carefully designed in-house datastore\nmatches or outperforms web search engines such as Google Search, as well as\nrecently proposed, complex agent-based RAG systems--all while maintaining\nsimplicity, reproducibility, and self-containment. We release CompactDS and our\nretrieval pipeline, supporting future research exploring retrieval-based AI\nsystems.", "published": "2025-07-02 02:35:47", "link": "http://arxiv.org/abs/2507.01297v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization", "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating their parametric knowledge with external retrieved content.\nHowever, knowledge conflicts caused by internal inconsistencies or noisy\nretrieved content can severely undermine the generation reliability of RAG\nsystems.In this work, we argue that LLMs should rethink all evidence, including\nboth retrieved content and internal knowledge, before generating responses.We\npropose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel\nframework that improves trustworthiness through Conflict-Driven Summarization\nof all available evidence.CARE-RAG first derives parameter-aware evidence by\ncomparing parameter records to identify diverse internal perspectives. It then\nrefines retrieved evidences to produce context-aware evidence, removing\nirrelevant or misleading content. To detect and summarize conflicts, we distill\na 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable\nsynthesis across multiple sources.To further ensure evaluation integrity, we\nintroduce a QA Repair step to correct outdated or ambiguous benchmark\nanswers.Experiments on revised QA datasets with retrieval data show that\nCARE-RAG consistently outperforms strong RAG baselines, especially in scenarios\nwith noisy or conflicting evidence.", "published": "2025-07-02 01:39:49", "link": "http://arxiv.org/abs/2507.01281v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening", "abstract": "Large language models (LLMs) can simulate clinical reasoning based on natural\nlanguage prompts, but their utility in ophthalmology is largely unexplored.\nThis study evaluated GPT-4's ability to interpret structured textual\ndescriptions of retinal fundus photographs and simulate clinical decisions for\ndiabetic retinopathy (DR) and glaucoma screening, including the impact of\nadding real or synthetic clinical metadata. We conducted a retrospective\ndiagnostic validation study using 300 annotated fundus images. GPT-4 received\nstructured prompts describing each image, with or without patient metadata. The\nmodel was tasked with assigning an ICDR severity score, recommending DR\nreferral, and estimating the cup-to-disc ratio for glaucoma referral.\nPerformance was evaluated using accuracy, macro and weighted F1 scores, and\nCohen's kappa. McNemar's test and change rate analysis were used to assess the\ninfluence of metadata. GPT-4 showed moderate performance for ICDR\nclassification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),\ndriven mainly by correct identification of normal cases. Performance improved\nin the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For\nglaucoma referral, performance was poor across all settings (accuracy ~78%, F1\n<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes\n(McNemar p > 0.05), and predictions remained consistent across conditions.\nGPT-4 can simulate basic ophthalmic decision-making from structured prompts but\nlacks precision for complex tasks. While not suitable for clinical use, LLMs\nmay assist in education, documentation, or image annotation workflows in\nophthalmology.", "published": "2025-07-02 01:35:59", "link": "http://arxiv.org/abs/2507.01278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant", "abstract": "In this paper we discuss the capability of large language models to base\ntheir answer and provide proper references when dealing with legal matters of\nnon-english and non-chinese speaking country. We discuss the history of legal\ninformation retrieval, the difference between case law and statute law, its\nimpact on the legal tasks and analyze the latest research in this field. Basing\non that background we introduce gAIus, the architecture of the cognitive\nLLM-based agent, whose responses are based on the knowledge retrieved from\ncertain legal act, which is Polish Civil Code. We propose a retrieval mechanism\nwhich is more explainable, human-friendly and achieves better results than\nembedding-based approaches. To evaluate our method we create special dataset\nbased on single-choice questions from entrance exams for law apprenticeships\nconducted in Poland. The proposed architecture critically leveraged the\nabilities of used large language models, improving the gpt-3.5-turbo-0125 by\n419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.\nAt the end of our paper we show the possible future path of research and\npotential applications of our findings.", "published": "2025-07-02 00:36:27", "link": "http://arxiv.org/abs/2507.01259v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation", "abstract": "Recently, mobile manipulation has attracted increasing attention for enabling\nlanguage-conditioned robotic control in household tasks. However, existing\nmethods still face challenges in coordinating mobile base and manipulator,\nprimarily due to two limitations. On the one hand, they fail to explicitly\nmodel the influence of the mobile base on manipulator control, which easily\nleads to error accumulation under high degrees of freedom. On the other hand,\nthey treat the entire mobile manipulation process with the same visual\nobservation modality (e.g., either all 2D or all 3D), overlooking the distinct\nmultimodal perception requirements at different stages during mobile\nmanipulation. To address this, we propose the Adaptive Coordination Diffusion\nTransformer (AC-DiT), which enhances mobile base and manipulator coordination\nfor end-to-end mobile manipulation. First, since the motion of the mobile base\ndirectly influences the manipulator's actions, we introduce a mobility-to-body\nconditioning mechanism that guides the model to first extract base motion\nrepresentations, which are then used as context prior for predicting whole-body\nactions. This enables whole-body control that accounts for the potential impact\nof the mobile base's motion. Second, to meet the perception requirements at\ndifferent stages of mobile manipulation, we design a perception-aware\nmultimodal conditioning strategy that dynamically adjusts the fusion weights\nbetween various 2D visual images and 3D point clouds, yielding visual features\ntailored to the current perceptual needs. This allows the model to, for\nexample, adaptively rely more on 2D inputs when semantic information is crucial\nfor action prediction, while placing greater emphasis on 3D geometric\ninformation when precise spatial understanding is required. We validate AC-DiT\nthrough extensive experiments on both simulated and real-world mobile\nmanipulation tasks.", "published": "2025-07-02 17:59:54", "link": "http://arxiv.org/abs/2507.01961v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation", "abstract": "We present Locality-aware Parallel Decoding (LPD) to accelerate\nautoregressive image generation. Traditional autoregressive image generation\nrelies on next-patch prediction, a memory-bound process that leads to high\nlatency. Existing works have tried to parallelize next-patch prediction by\nshifting to multi-patch prediction to accelerate the process, but only achieved\nlimited parallelization. To achieve high parallelization while maintaining\ngeneration quality, we introduce two key techniques: (1) Flexible Parallelized\nAutoregressive Modeling, a novel architecture that enables arbitrary generation\nordering and degrees of parallelization. It uses learnable position query\ntokens to guide generation at target positions while ensuring mutual visibility\namong concurrently generated tokens for consistent parallel decoding. (2)\nLocality-aware Generation Ordering, a novel schedule that forms groups to\nminimize intra-group dependencies and maximize contextual support, enhancing\ngeneration quality. With these designs, we reduce the generation steps from 256\nto 20 (256$\\times$256 res.) and 1024 to 48 (512$\\times$512 res.) without\ncompromising quality on the ImageNet class-conditional generation, and\nachieving at least 3.4$\\times$ lower latency than previous parallelized\nautoregressive models.", "published": "2025-07-02 17:59:23", "link": "http://arxiv.org/abs/2507.01957v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks", "abstract": "Multimodal foundation models, such as GPT-4o, have recently made remarkable\nprogress, but it is not clear where exactly these models stand in terms of\nunderstanding vision. In this paper, we benchmark the performance of popular\nmultimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0\nFlash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision\ntasks (semantic segmentation, object detection, image classification, depth and\nsurface normal prediction) using established datasets (e.g., COCO, ImageNet and\nits variants, etc).\n  The main challenges to performing this are: 1) most models are trained to\noutput text and cannot natively express versatile domains, such as segments or\n3D geometry, and 2) many leading models are proprietary and accessible only at\nan API level, i.e., there is no weight access to adapt them. We address these\nchallenges by translating standard vision tasks into equivalent text-promptable\nand API-compatible tasks via prompt chaining to create a standardized\nbenchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art\nspecialist models at any task. However, 2) they are respectable generalists;\nthis is remarkable as they are presumably trained on primarily image-text-based\ntasks. 3) They perform semantic tasks notably better than geometric ones. 4)\nWhile the prompt-chaining techniques affect performance, better models exhibit\nless sensitivity to prompt variations. 5) GPT-4o performs the best among\nnon-reasoning models, securing the top position in 4 out of 6 tasks, 6)\nreasoning models, e.g. o3, show improvements in geometric tasks, and 7) a\npreliminary analysis of models with native image generation, like the latest\nGPT-4o, shows they exhibit quirks like hallucinations and spatial\nmisalignments.", "published": "2025-07-02 17:59:07", "link": "http://arxiv.org/abs/2507.01955v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars", "abstract": "In recent years, large language models (LLMs) have transformed natural\nlanguage understanding through vast datasets and large-scale parameterization.\nInspired by this success, we present SpecCLIP, a foundation model framework\nthat extends LLM-inspired methodologies to stellar spectral analysis. Stellar\nspectra, akin to structured language, encode rich physical and chemical\ninformation about stars. By training foundation models on large-scale spectral\ndatasets, our goal is to learn robust and informative embeddings that support\ndiverse downstream applications. As a proof of concept, SpecCLIP involves\npre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed\nby contrastive alignment using the CLIP (Contrastive Language-Image\nPre-training) framework, adapted to associate spectra from different\ninstruments. This alignment is complemented by auxiliary decoders that preserve\nspectrum-specific information and enable translation (prediction) between\nspectral types, with the former achieved by maximizing mutual information\nbetween embeddings and input spectra. The result is a cross-spectrum framework\nenabling intrinsic calibration and flexible applications across instruments. We\ndemonstrate that fine-tuning these models on moderate-sized labeled datasets\nimproves adaptability to tasks such as stellar-parameter estimation and\nchemical-abundance determination. SpecCLIP also enhances the accuracy and\nprecision of parameter estimates benchmarked against external survey data.\nAdditionally, its similarity search and cross-spectrum prediction capabilities\noffer potential for anomaly detection. Our results suggest that contrastively\ntrained foundation models enriched with spectrum-aware decoders can advance\nprecision stellar spectroscopy.", "published": "2025-07-02 17:49:52", "link": "http://arxiv.org/abs/2507.01939v1", "categories": ["astro-ph.IM", "astro-ph.SR", "cs.AI", "cs.LG"], "primary_category": "astro-ph.IM"}
{"title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection", "abstract": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings.", "published": "2025-07-02 17:33:47", "link": "http://arxiv.org/abs/2507.01924v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning", "abstract": "We develop a rotation-invariant neural network that provides the global\nminimum-variance portfolio by jointly learning how to lag-transform historical\nreturns and how to regularise both the eigenvalues and the marginal\nvolatilities of large equity covariance matrices. This explicit mathematical\nmapping offers clear interpretability of each module's role, so the model\ncannot be regarded as a pure black-box. The architecture mirrors the analytical\nform of the global minimum-variance solution yet remains agnostic to dimension,\nso a single model can be calibrated on panels of a few hundred stocks and\napplied, without retraining, to one thousand US equities-a cross-sectional jump\nthat demonstrates robust out-of-sample generalisation. The loss function is the\nfuture realized minimum portfolio variance and is optimized end-to-end on real\ndaily returns. In out-of-sample tests from January 2000 to December 2024 the\nestimator delivers systematically lower realised volatility, smaller maximum\ndrawdowns, and higher Sharpe ratios than the best analytical competitors,\nincluding state-of-the-art non-linear shrinkage. Furthermore, although the\nmodel is trained end-to-end to produce an unconstrained (long-short)\nminimum-variance portfolio, we show that its learned covariance representation\ncan be used in general optimizers under long-only constraints with virtually no\nloss in its performance advantage over competing estimators. These gains\npersist when the strategy is executed under a highly realistic implementation\nframework that models market orders at the auctions, empirical slippage,\nexchange fees, and financing charges for leverage, and they remain stable\nduring episodes of acute market stress.", "published": "2025-07-02 17:27:29", "link": "http://arxiv.org/abs/2507.01918v1", "categories": ["q-fin.PM", "cs.AI", "math.OC", "physics.data-an", "stat.ML", "91G10 (Primary) 68T07, 91G60, 62P05 (Secondary)", "I.2.6; I.5.1; G.3; J.4"], "primary_category": "q-fin.PM"}
{"title": "Towards Foundation Auto-Encoders for Time-Series Anomaly Detection", "abstract": "We investigate a novel approach to time-series modeling, inspired by the\nsuccesses of large pretrained foundation models. We introduce FAE (Foundation\nAuto-Encoders), a foundation generative-AI model for anomaly detection in\ntime-series data, based on Variational Auto-Encoders (VAEs). By foundation, we\nmean a model pretrained on massive amounts of time-series data which can learn\ncomplex temporal patterns useful for accurate modeling, forecasting, and\ndetection of anomalies on previously unseen datasets. FAE leverages VAEs and\nDilated Convolutional Neural Networks (DCNNs) to build a generic model for\nunivariate time-series modeling, which could eventually perform properly in\nout-of-the-box, zero-shot anomaly detection applications. We introduce the main\nconcepts of FAE, and present preliminary results in different multi-dimensional\ntime-series datasets from various domains, including a real dataset from an\noperational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.", "published": "2025-07-02 16:39:36", "link": "http://arxiv.org/abs/2507.01875v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents", "abstract": "Domain specific chatbot applications often involve multi step interactions,\nsuch as refining search filters, selecting multiple items, or performing\ncomparisons. Traditional graphical user interfaces (GUIs) handle these\nworkflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard\ndata) actions, allowing back-end systems to track user intent unambiguously. In\ncontrast, conversational agents rely on subtle language cues, which can lead to\nconfusion and incomplete context management. This paper proposes modeling these\nGUI inspired metaphors acknowledgment (submit like) and context switching\n(reset-like) as explicit tasks within large language model (LLM) prompts. By\ncapturing user acknowledgment, reset actions, and chain of thought (CoT)\nreasoning as structured session data, we preserve clarity, reduce user\nconfusion, and align domain-specific chatbot interactions with back-end logic.\nWe demonstrate our approach in hotel booking and customer management scenarios,\nhighlighting improvements in multi-turn task coherence, user satisfaction, and\nefficiency.", "published": "2025-07-02 16:24:50", "link": "http://arxiv.org/abs/2507.01862v1", "categories": ["cs.HC", "cs.AI", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics", "abstract": "Non-monotonic logic programming is the basis for a declarative problem\nsolving paradigm known as answer set programming (ASP). Departing from the\nseminal definition by Gelfond and Lifschitz in 1988 for simple normal logic\nprograms, various answer set semantics have been proposed for extensions. We\nconsider two important questions: (1) Should the minimal model property,\nconstraint monotonicity and foundedness as defined in the literature be\nmandatory conditions for an answer set semantics in general? (2) If not, what\nother properties could be considered as general principles for answer set\nsemantics? We address the two questions. First, it seems that the three\naforementioned conditions may sometimes be too strong, and we illustrate with\nexamples that enforcing them may exclude expected answer sets. Second, we\nevolve the Gelfond answer set (GAS) principles for answer set construction by\nrefining the Gelfond's rationality principle to well-supportedness, minimality\nw.r.t. negation by default and minimality w.r.t. epistemic negation. The\nprinciple of well-supportedness guarantees that every answer set is\nconstructible from if-then rules obeying a level mapping and is thus free of\ncircular justification, while the two minimality principles ensure that the\nformalism minimizes knowledge both at the level of answer sets and of world\nviews. Third, to embody the refined GAS principles, we extend the notion of\nwell-supportedness substantially to answer sets and world views, respectively.\nFourth, we define new answer set semantics in terms of the refined GAS\nprinciples. Fifth, we use the refined GAS principles as an alternative baseline\nto intuitively assess the existing answer set semantics. Finally, we analyze\nthe computational complexity.", "published": "2025-07-02 15:47:54", "link": "http://arxiv.org/abs/2507.01833v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling", "abstract": "Edge devices for temporal processing demand models that capture both short-\nand long- range dynamics under tight memory constraints. While Transformers\nexcel at sequence modeling, their quadratic memory scaling with sequence length\nmakes them impractical for such settings. Recurrent Neural Networks (RNNs)\noffer constant memory but train sequentially, and Temporal Convolutional\nNetworks (TCNs), though efficient, scale memory with kernel size. To address\nthis, we propose mGRADE (mininally Gated Recurrent Architecture with Delay\nEmbedding), a hybrid-memory system that integrates a temporal 1D-convolution\nwith learnable spacings followed by a minimal gated recurrent unit (minGRU).\nThis design allows the convolutional layer to realize a flexible delay\nembedding that captures rapid temporal variations, while the recurrent module\nefficiently maintains global context with minimal memory overhead. We validate\nour approach on two synthetic tasks, demonstrating that mGRADE effectively\nseparates and preserves multi-scale temporal features. Furthermore, on\nchallenging pixel-by-pixel image classification benchmarks, mGRADE consistently\noutperforms both pure convolutional and pure recurrent counterparts using\napproximately 20% less memory footprint, highlighting its suitability for\nmemory-constrained temporal processing at the edge. This highlights mGRADE's\npromise as an efficient solution for memory-constrained multi-scale temporal\nprocessing at the edge.", "published": "2025-07-02 15:44:35", "link": "http://arxiv.org/abs/2507.01829v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MILP-SAT-GNN: Yet Another Neural SAT Solver", "abstract": "We proposes a novel method that enables Graph Neural Networks (GNNs) to solve\nSAT problems by leveraging a technique developed for applying GNNs to Mixed\nInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped into\nMILP problems, which are then encoded as weighted bipartite graphs and\nsubsequently fed into a GNN for training and testing. From a theoretical\nperspective: (i) we establish permutation and equivalence invariance results,\ndemonstrating that the method produces outputs that are stable under reordering\nof clauses and variables; (ii) we identify a theoretical limitation, showing\nthat for a class of formulae called foldable formulae, standard GNNs cannot\nalways distinguish satisfiable from unsatisfiable instances; (iii) we prove a\nuniversal approximation theorem, establishing that with Random Node\nInitialization (RNI), the method can approximate SAT solving to arbitrary\nprecision on finite datasets, that is, the GNN becomes approximately sound and\ncomplete on such datasets. Furthermore, we show that for unfoldable formulae,\nthe same approximation guarantee can be achieved without the need for RNI.\nFinally, we conduct an experimental evaluation of our approach, which show\nthat, despite the simplicity of the neural architecture, the method achieves\npromising results.", "published": "2025-07-02 15:39:45", "link": "http://arxiv.org/abs/2507.01825v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems", "abstract": "Small- and medium-sized manufacturers need innovative data tools but, because\nof competition and privacy concerns, often do not want to share their\nproprietary data with researchers who might be interested in helping. This\npaper introduces a privacy-preserving platform by which manufacturers may\nsafely share their data with researchers through secure methods, so that those\nresearchers then create innovative tools to solve the manufacturers' real-world\nproblems, and then provide tools that execute solutions back onto the platform\nfor others to use with privacy and confidentiality guarantees. We illustrate\nthis problem through a particular use case which addresses an important problem\nin the large-scale manufacturing of food crystals, which is that quality\ncontrol relies on image analysis tools. Previous to our research, food crystals\nin the images were manually counted, which required substantial and\ntime-consuming human efforts, but we have developed and deployed a crystal\nanalysis tool which makes this process both more rapid and accurate. The tool\nenables automatic characterization of the crystal size distribution and numbers\nfrom microscope images while the natural imperfections from the sample\npreparation are automatically removed; a machine learning model to count high\nresolution translucent crystals and agglomeration of crystals was also\ndeveloped to aid in these efforts. The resulting algorithm was then packaged\nfor real-world use on the factory floor via a web-based app secured through the\noriginating privacy-preserving platform, allowing manufacturers to use it while\nkeeping their proprietary data secure. After demonstrating this full process,\nfuture directions are also explored.", "published": "2025-07-02 15:25:43", "link": "http://arxiv.org/abs/2507.01808v1", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.ET", "68T01, 68T05, 68T45, 94A60"], "primary_category": "cs.CR"}
{"title": "Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging", "abstract": "Vision transformers (ViTs) have rapidly gained prominence in medical imaging\ntasks such as disease classification, segmentation, and detection due to their\nsuperior accuracy compared to conventional deep learning models. However, due\nto their size and complex interactions via the self-attention mechanism, they\nare not well understood. In particular, it is unclear whether the\nrepresentations produced by such models are semantically meaningful. In this\npaper, using a projected gradient-based algorithm, we show that their\nrepresentations are not semantically meaningful and they are inherently\nvulnerable to small changes. Images with imperceptible differences can have\nvery different representations; on the other hand, images that should belong to\ndifferent semantic classes can have nearly identical representations. Such\nvulnerability can lead to unreliable classification results; for example,\nunnoticeable changes cause the classification accuracy to be reduced by over\n60\\%. %. To the best of our knowledge, this is the first work to systematically\ndemonstrate this fundamental lack of semantic meaningfulness in ViT\nrepresentations for medical image classification, revealing a critical\nchallenge for their deployment in safety-critical systems.", "published": "2025-07-02 15:14:06", "link": "http://arxiv.org/abs/2507.01788v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification", "abstract": "We introduce BranchNet, a neuro-symbolic learning framework that transforms\ndecision tree ensembles into sparse, partially connected neural networks. Each\nbranch, defined as a decision path from root to a parent of leaves, is mapped\nto a hidden neuron, preserving symbolic structure while enabling gradient-based\noptimization. The resulting models are compact, interpretable, and require no\nmanual architecture tuning. Evaluated on a suite of structured multi-class\nclassification benchmarks, BranchNet consistently outperforms XGBoost in\naccuracy, with statistically significant gains. We detail the architecture,\ntraining procedure, and sparsity dynamics, and discuss the model's strengths in\nsymbolic interpretability as well as its current limitations, particularly on\nbinary tasks where further adaptive calibration may be beneficial.", "published": "2025-07-02 15:07:58", "link": "http://arxiv.org/abs/2507.01781v1", "categories": ["cs.LG", "cs.AI", "68T07 (Primary) 62H30, 68T05 (Secondary)"], "primary_category": "cs.LG"}
{"title": "GPU-based complete search for nonlinear minimization subject to bounds", "abstract": "This paper introduces a GPU-based complete search method to enclose the\nglobal minimum of a nonlinear function subject to simple bounds on the\nvariables. Using interval analysis, coupled with the computational power and\narchitecture of GPU, the method iteratively rules out the regions in the search\ndomain where the global minimum cannot exist and leaves a finite set of regions\nwhere the global minimum must exist. For effectiveness, because of the rigor of\ninterval analysis, the method is guaranteed to enclose the global minimum of\nthe nonlinear function even in the presence of rounding errors. For efficiency,\nthe method employs a novel GPU-based single program, single data parallel\nprogramming style to circumvent major GPU performance bottlenecks, and a\nvariable cycling technique is also integrated into the method to reduce\ncomputational cost when minimizing large-scale nonlinear functions. The method\nis validated by minimizing 10 multimodal benchmark test functions with scalable\ndimensions, including the well-known Ackley function, Griewank function, Levy\nfunction, and Rastrigin function. These benchmark test functions represent\ngrand challenges of global optimization, and enclosing the guaranteed global\nminimum of these benchmark test functions with more than 80 dimensions has not\nbeen reported in the literature. Our method completely searches the feasible\ndomain and successfully encloses the guaranteed global minimum of these 10\nbenchmark test functions with up to 10,000 dimensions using only one GPU in a\nreasonable computation time, far exceeding the reported results in the\nliterature due to the unique method design and implementation based on GPU\narchitecture.", "published": "2025-07-02 14:54:52", "link": "http://arxiv.org/abs/2507.01770v1", "categories": ["math.NA", "cs.AI", "cs.DC", "cs.MS", "cs.NA", "math.OC", "65G20, 65G30, 65G40, 90C06, 90C26, 90C30", "G.1.6; G.4"], "primary_category": "math.NA"}
{"title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage", "abstract": "Although generative models have made remarkable progress in recent years,\ntheir use in critical applications has been hindered by their incapacity to\nreliably evaluate sample quality. Quality refers to at least two complementary\nconcepts: fidelity and coverage. Current quality metrics often lack reliable,\ninterpretable values due to an absence of calibration or insufficient\nrobustness to outliers. To address these shortcomings, we introduce two novel\nmetrics, Clipped Density and Clipped Coverage. By clipping individual sample\ncontributions and, for fidelity, the radii of nearest neighbor balls, our\nmetrics prevent out-of-distribution samples from biasing the aggregated values.\nThrough analytical and empirical calibration, these metrics exhibit linear\nscore degradation as the proportion of poor samples increases. Thus, they can\nbe straightforwardly interpreted as equivalent proportions of good samples.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nClipped Density and Clipped Coverage outperform existing methods in terms of\nrobustness, sensitivity, and interpretability for evaluating generative models.", "published": "2025-07-02 14:40:00", "link": "http://arxiv.org/abs/2507.01761v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Joint Matching and Pricing for Crowd-shipping with In-store Customers", "abstract": "This paper examines the use of in-store customers as delivery couriers in a\ncentralized crowd-shipping system, targeting the growing need for efficient\nlast-mile delivery in urban areas. We consider a brick-and-mortar retail\nsetting where shoppers are offered compensation to deliver time-sensitive\nonline orders. To manage this process, we propose a Markov Decision Process\n(MDP) model that captures key uncertainties, including the stochastic arrival\nof orders and crowd-shippers, and the probabilistic acceptance of delivery\noffers. Our solution approach integrates Neural Approximate Dynamic Programming\n(NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network\n(DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop\nrouting and accounts for offer acceptance uncertainty, aligning more closely\nwith real-world operations. Experimental results demonstrate that the\nintegrated NeurADP + DDQN policy achieves notable improvements in delivery cost\nefficiency, with up to 6.7\\% savings over NeurADP with fixed pricing and\napproximately 18\\% over myopic baselines. We also show that allowing flexible\ndelivery delays and enabling multi-destination routing further reduces\noperational costs by 8\\% and 17\\%, respectively. These findings underscore the\nadvantages of dynamic, forward-looking policies in crowd-shipping systems and\noffer practical guidance for urban logistics operators.", "published": "2025-07-02 14:27:32", "link": "http://arxiv.org/abs/2507.01749v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America", "abstract": "There is justifiable interest in leveraging conversational AI (CAI) for\nhealth across the majority world, but to be effective, CAI must respond\nappropriately within culturally and linguistically diverse contexts. Therefore,\nwe need ways to address the fact that current LLMs exclude many lived\nexperiences globally. Various advances are underway which focus on top-down\napproaches and increasing training data. In this paper, we aim to complement\nthese with a bottom-up locally-grounded approach based on qualitative data\ncollected during participatory workshops in Latin America. Our goal is to\nconstruct a rich and human-centred understanding of: a) potential areas of\ncultural misalignment in digital health; b) regional perspectives on chatbots\nfor health and c)strategies for creating culturally-appropriate CAI; with a\nfocus on the understudied Latin American context. Our findings show that\nacademic boundaries on notions of culture lose meaning at the ground level and\ntechnologies will need to engage with a broader framework; one that\nencapsulates the way economics, politics, geography and local logistics are\nentangled in cultural experience. To this end, we introduce a framework for\n'Pluriversal Conversational AI for Health' which allows for the possibility\nthat more relationality and tolerance, rather than just more data, may be\ncalled for.", "published": "2025-07-02 13:48:25", "link": "http://arxiv.org/abs/2507.01719v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI", "abstract": "Patents contain rich technical knowledge that can inspire innovative product\nideas, yet accessing and interpreting this information remains a challenge.\nThis work explores the use of Large Language Models (LLMs) and autonomous\nagents to mine and generate product concepts from a given patent. In this work,\nwe design Agent Ideate, a framework for automatically generating product-based\nbusiness ideas from patents. We experimented with open-source LLMs and\nagent-based architectures across three domains: Computer Science, Natural\nLanguage Processing, and Material Chemistry. Evaluation results show that the\nagentic approach consistently outperformed standalone LLMs in terms of idea\nquality, relevance, and novelty. These findings suggest that combining LLMs\nwith agentic workflows can significantly enhance the innovation pipeline by\nunlocking the untapped potential of business idea generation from patent data.", "published": "2025-07-02 13:47:17", "link": "http://arxiv.org/abs/2507.01717v1", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture", "abstract": "In this paper, we propose to incorporate the blackboard architecture into LLM\nmulti-agent systems (MASs) so that (1) agents with various roles can share all\nthe information and others' messages during the whole problem-solving process,\n(2) agents that will take actions are selected based on the current content of\nthe blackboard, and (3) the selection and execution round is repeated until a\nconsensus is reached on the blackboard. We develop the first implementation of\nthis proposal and conduct experiments on commonsense knowledge, reasoning and\nmathematical datasets. The results show that our system can be competitive with\nthe SOTA static and dynamic MASs by achieving the best average performance, and\nat the same time manage to spend less tokens. Our proposal has the potential to\nenable complex and dynamic problem-solving where well-defined structures or\nworkflows are unavailable.", "published": "2025-07-02 13:30:44", "link": "http://arxiv.org/abs/2507.01701v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Relational Causal Discovery with Latent Confounders", "abstract": "Estimating causal effects from real-world relational data can be challenging\nwhen the underlying causal model and potential confounders are unknown. While\nseveral causal discovery algorithms exist for learning causal models with\nlatent confounders from data, they assume that the data is independent and\nidentically distributed (i.i.d.) and are not well-suited for learning from\nrelational data. Similarly, existing relational causal discovery algorithms\nassume causal sufficiency, which is unrealistic for many real-world datasets.\nTo address this gap, we propose RelFCI, a sound and complete causal discovery\nalgorithm for relational data with latent confounders. Our work builds upon the\nFast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms\nand it defines new graphical models, necessary to support causal discovery in\nrelational domains. We also establish soundness and completeness guarantees for\nrelational d-separation with latent confounders. We present experimental\nresults demonstrating the effectiveness of RelFCI in identifying the correct\ncausal structure in relational causal models with latent confounders.", "published": "2025-07-02 13:29:35", "link": "http://arxiv.org/abs/2507.01700v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GPT, But Backwards: Exactly Inverting Language Model Outputs", "abstract": "While existing auditing techniques attempt to identify potential unwanted\nbehaviours in large language models (LLMs), we address the complementary\nforensic problem of reconstructing the exact input that led to an existing LLM\noutput - enabling post-incident analysis and potentially the detection of fake\noutput reports. We formalize exact input reconstruction as a discrete\noptimisation problem with a unique global minimum and introduce SODA, an\nefficient gradient-based algorithm that operates on a continuous relaxation of\nthe input search space with periodic restarts and parameter decay. Through\ncomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we\ndemonstrate that SODA significantly outperforms existing approaches. We succeed\nin fully recovering 79.5% of shorter out-of-distribution inputs from next-token\nlogits, without a single false positive, but struggle to extract private\ninformation from the outputs of longer (15+ token) input sequences. This\nsuggests that standard deployment practices may currently provide adequate\nprotection against malicious use of our method. Our code is available at\nhttps://doi.org/10.5281/zenodo.15539879.", "published": "2025-07-02 13:20:30", "link": "http://arxiv.org/abs/2507.01693v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization", "abstract": "Deep Recommender Models (DLRMs) inference is a fundamental AI workload\naccounting for more than 79% of the total AI workload in Meta's data centers.\nDLRMs' performance bottleneck is found in the embedding layers, which perform\nmany random memory accesses to retrieve small embedding vectors from tables of\nvarious sizes. We propose the design of tailored data flows to speedup\nembedding look-ups. Namely, we propose four strategies to look up an embedding\ntable effectively on one core, and a framework to automatically map the tables\nasymmetrically to the multiple cores of a SoC. We assess the effectiveness of\nour method using the Huawei Ascend AI accelerators, comparing it with the\ndefault Ascend compiler, and we perform high-level comparisons with Nvidia\nA100. Results show a speed-up varying from 1.5x up to 6.5x for real workload\ndistributions, and more than 20x for extremely unbalanced distributions.\nFurthermore, the method proves to be much more independent of the query\ndistribution than the baseline.", "published": "2025-07-02 13:00:39", "link": "http://arxiv.org/abs/2507.01676v1", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.IR", "C.4; D.1.3; H.3.3; H.3.4"], "primary_category": "cs.DC"}
{"title": "Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis", "abstract": "The field of numerical optimization has recently seen a surge in the\ndevelopment of \"novel\" metaheuristic algorithms, inspired by metaphors derived\nfrom natural or human-made processes, which have been widely criticized for\nobscuring meaningful innovations and failing to distinguish themselves from\nexisting approaches. Aiming to address these concerns, we investigate the\napplicability of statistical tests for comparing algorithms based on their\nsearch behavior. We utilize the cross-match statistical test to compare\nmultivariate distributions and assess the solutions produced by 114 algorithms\nfrom the MEALPY library. These findings are incorporated into an empirical\nanalysis aiming to identify algorithms with similar search behaviors.", "published": "2025-07-02 12:51:27", "link": "http://arxiv.org/abs/2507.01668v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training", "abstract": "Reinforcement learning (RL) has become a pivotal technology in the\npost-training phase of large language models (LLMs). Traditional task-colocated\nRL frameworks suffer from significant scalability bottlenecks, while\ntask-separated RL frameworks face challenges in complex dataflows and the\ncorresponding resource idling and workload imbalance. Moreover, most existing\nframeworks are tightly coupled with LLM training or inference engines, making\nit difficult to support custom-designed engines. To address these challenges,\nwe propose AsyncFlow, an asynchronous streaming RL framework for efficient\npost-training. Specifically, we introduce a distributed data storage and\ntransfer module that provides a unified data management and fine-grained\nscheduling capability in a fully streamed manner. This architecture inherently\nfacilitates automated pipeline overlapping among RL tasks and dynamic load\nbalancing. Moreover, we propose a producer-consumer-based asynchronous workflow\nengineered to minimize computational idleness by strategically deferring\nparameter update process within staleness thresholds. Finally, the core\ncapability of AsynFlow is architecturally decoupled from underlying training\nand inference engines and encapsulated by service-oriented user interfaces,\noffering a modular and customizable user experience. Extensive experiments\ndemonstrate an average of 1.59 throughput improvement compared with\nstate-of-the-art baseline. The presented architecture in this work provides\nactionable insights for next-generation RL training system designs.", "published": "2025-07-02 12:45:34", "link": "http://arxiv.org/abs/2507.01663v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective", "abstract": "Autoregressive (AR) models have garnered significant attention in image\ngeneration for their ability to effectively capture both local and global\nstructures within visual data. However, prevalent AR models predominantly rely\non the transformer architectures, which are beset by quadratic computational\ncomplexity concerning input sequence length and substantial memory overhead due\nto the necessity of maintaining key-value caches. Although linear attention\nmechanisms have successfully reduced this burden in language models, our\ninitial experiments reveal that they significantly degrade image generation\nquality because of their inability to capture critical long-range dependencies\nin visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a\nnovel attention mechanism that explicitly preserves genuine 2D spatial\nrelationships within the flattened image sequences by computing\nposition-dependent decay factors based on true 2D spatial location rather than\n1D sequence positions. Based on this mechanism, we present LASADGen, an\nautoregressive image generator that enables selective attention to relevant\nspatial contexts with linear complexity. Experiments on ImageNet show LASADGen\nachieves state-of-the-art image generation performance and computational\nefficiency, bridging the gap between linear attention's efficiency and spatial\nunderstanding needed for high-quality generation.", "published": "2025-07-02 12:27:06", "link": "http://arxiv.org/abs/2507.01652v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "GradMetaNet: An Equivariant Architecture for Learning on Gradients", "abstract": "Gradients of neural networks encode valuable information for optimization,\nediting, and analysis of models. Therefore, practitioners often treat gradients\nas inputs to task-specific algorithms, e.g. for pruning or optimization. Recent\nworks explore learning algorithms that operate directly on gradients but use\narchitectures that are not specifically designed for gradient processing,\nlimiting their applicability. In this paper, we present a principled approach\nfor designing architectures that process gradients. Our approach is guided by\nthree principles: (1) equivariant design that preserves neuron permutation\nsymmetries, (2) processing sets of gradients across multiple data points to\ncapture curvature information, and (3) efficient gradient representation\nthrough rank-1 decomposition. Based on these principles, we introduce\nGradMetaNet, a novel architecture for learning on gradients, constructed from\nsimple equivariant blocks. We prove universality results for GradMetaNet, and\nshow that previous approaches cannot approximate natural gradient-based\nfunctions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness\non a diverse set of gradient-based tasks on MLPs and transformers, such as\nlearned optimization, INR editing, and estimating loss landscape curvature.", "published": "2025-07-02 12:22:39", "link": "http://arxiv.org/abs/2507.01649v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance", "abstract": "We present an analysis of landscape features for predicting the performance\nof multi-objective combinatorial optimization algorithms. We consider features\nfrom the recently proposed compressed Pareto Local Optimal Solutions Networks\n(C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a\nset of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness\nand objective correlation. We consider the performance of three algorithms --\nPareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and\nNon-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and\nhypervolume metrics. Our tailored analysis reveals feature combinations that\ninfluence algorithm performance specific to certain landscapes. This study\nprovides deeper insights into feature importance, tailored to specific\nrmnk-landscapes and algorithms.", "published": "2025-07-02 12:11:41", "link": "http://arxiv.org/abs/2507.01638v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Depth Anything at Any Condition", "abstract": "We present Depth Anything at Any Condition (DepthAnything-AC), a foundation\nmonocular depth estimation (MDE) model capable of handling diverse\nenvironmental conditions. Previous foundation MDE models achieve impressive\nperformance across general scenes but not perform well in complex open-world\nenvironments that involve challenging conditions, such as illumination\nvariations, adverse weather, and sensor-induced distortions. To overcome the\nchallenges of data scarcity and the inability of generating high-quality\npseudo-labels from corrupted images, we propose an unsupervised consistency\nregularization finetuning paradigm that requires only a relatively small amount\nof unlabeled data. Furthermore, we propose the Spatial Distance Constraint to\nexplicitly enforce the model to learn patch-level relative relationships,\nresulting in clearer semantic boundaries and more accurate details.\nExperimental results demonstrate the zero-shot capabilities of DepthAnything-AC\nacross diverse benchmarks, including real-world adverse weather benchmarks,\nsynthetic corruption benchmarks, and general benchmarks.\n  Project Page: https://ghost233lism.github.io/depthanything-AC-page\n  Code: https://github.com/HVision-NKU/DepthAnythingAC", "published": "2025-07-02 12:05:57", "link": "http://arxiv.org/abs/2507.01634v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "abstract": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "published": "2025-07-02 11:59:36", "link": "http://arxiv.org/abs/2507.01631v1", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss", "abstract": "The task of Human-Object conTact (HOT) detection involves identifying the\nspecific areas of the human body that are touching objects. Nevertheless,\ncurrent models are restricted to just one type of image, often leading to too\nmuch segmentation in areas with little interaction, and struggling to maintain\ncategory consistency within specific regions. To tackle this issue, a HOT\nframework, termed \\textbf{P3HOT}, is proposed, which blends \\textbf{P}rompt\nguidance and human \\textbf{P}roximal \\textbf{P}erception. To begin with, we\nutilize a semantic-driven prompt mechanism to direct the network's attention\ntowards the relevant regions based on the correlation between image and text.\nThen a human proximal perception mechanism is employed to dynamically perceive\nkey depth range around the human, using learnable parameters to effectively\neliminate regions where interactions are not expected. Calculating depth\nresolves the uncertainty of the overlap between humans and objects in a 2D\nperspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss\n(RJLoss) has been created as a new loss to inhibit abnormal categories in the\nsame area. A new evaluation metric called ``AD-Acc.'' is introduced to address\nthe shortcomings of existing methods in addressing negative samples.\nComprehensive experimental results demonstrate that our approach achieves\nstate-of-the-art performance in four metrics across two benchmark datasets.\nSpecifically, our model achieves an improvement of \\textbf{0.7}$\\uparrow$,\n\\textbf{2.0}$\\uparrow$, \\textbf{1.6}$\\uparrow$, and \\textbf{11.0}$\\uparrow$ in\nSC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated\ndataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.", "published": "2025-07-02 11:59:32", "link": "http://arxiv.org/abs/2507.01630v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation", "abstract": "Group recommendation over social media streams has attracted significant\nattention due to its wide applications in domains such as e-commerce,\nentertainment, and online news broadcasting. By leveraging social connections\nand group behaviours, group recommendation (GR) aims to provide more accurate\nand engaging content to a set of users rather than individuals. Recently,\ninfluence-aware GR has emerged as a promising direction, as it considers the\nimpact of social influence on group decision-making. In earlier work, we\nproposed Influence-aware Group Recommendation (IGR) to solve this task.\nHowever, this task remains challenging due to three key factors: the large and\never-growing scale of social graphs, the inherently dynamic nature of influence\npropagation within user groups, and the high computational overhead of\nreal-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group\nRecommendation (EIGR) framework. First, we introduce a Graph Extraction-based\nSampling (GES) strategy to minimise redundancy across multiple temporal social\ngraphs and effectively capture the evolving dynamics of both groups and items.\nSecond, we design a novel DYnamic Independent Cascade (DYIC) model to predict\nhow influence propagates over time across social items and user groups.\nFinally, we develop a two-level hash-based User Group Index (UG-Index) to\nefficiently organise user groups and enable real-time recommendation\ngeneration. Extensive experiments on real-world datasets demonstrate that our\nproposed framework, EIGR, consistently outperforms state-of-the-art baselines\nin both effectiveness and efficiency.", "published": "2025-07-02 11:34:17", "link": "http://arxiv.org/abs/2507.01616v1", "categories": ["cs.IR", "cs.AI", "cs.DB"], "primary_category": "cs.IR"}
{"title": "Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems", "abstract": "The widespread use of deep learning face recognition raises several security\nconcerns. Although prior works point at existing vulnerabilities, DNN backdoor\nattacks against real-life, unconstrained systems dealing with images captured\nin the wild remain a blind spot of the literature. This paper conducts the\nfirst system-level study of backdoors in deep learning-based face recognition\nsystems. This paper yields four contributions by exploring the feasibility of\nDNN backdoors on these pipelines in a holistic fashion. We demonstrate for the\nfirst time two backdoor attacks on the face detection task: face generation and\nface landmark shift attacks. We then show that face feature extractors trained\nwith large margin losses also fall victim to backdoor attacks. Combining our\nmodels, we then show using 20 possible pipeline configurations and 15 attack\ncases that a single backdoor enables an attacker to bypass the entire function\nof a system. Finally, we provide stakeholders with several best practices and\ncountermeasures.", "published": "2025-07-02 11:21:27", "link": "http://arxiv.org/abs/2507.01607v1", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring", "abstract": "This study presents a novel classroom surveillance system that integrates\nmultiple modalities, including drowsiness, tracking of mobile phone usage, and\nface recognition,to assess student attentiveness with enhanced precision.The\nsystem leverages the YOLOv8 model to detect both mobile phone and sleep\nusage,(Ghatge et al., 2024) while facial recognition is achieved through\nLResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These\nmodels work in synergy to provide comprehensive, real-time monitoring, offering\ninsights into student engagement and behavior.(S et al., 2023) The framework is\ntrained on specialized datasets, such as the RMFD dataset for face recognition\nand a Roboflow dataset for mobile phone detection. The extensive evaluation of\nthe system shows promising results. Sleep detection achieves 97. 42% mAP@50,\nface recognition achieves 86. 45% validation accuracy and mobile phone\ndetection reach 85. 89% mAP@50. The system is implemented within a core PHP web\napplication and utilizes ESP32-CAM hardware for seamless data capture.(Neto et\nal., 2024) This integrated approach not only enhances classroom monitoring, but\nalso ensures automatic attendance recording via face recognition as students\nremain seated in the classroom, offering scalability for diverse educational\nenvironments.(Banada,2025)", "published": "2025-07-02 10:59:01", "link": "http://arxiv.org/abs/2507.01590v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder", "abstract": "The creativity of classical music arises not only from composers who craft\nthe musical sheets but also from performers who interpret the static notations\nwith expressive nuances. This paper addresses the challenge of generating\nclassical piano performances from scratch, aiming to emulate the dual roles of\ncomposer and pianist in the creative process. We introduce the Expressive\nCompound Word (ECP) representation, which effectively captures both the\nmetrical structure and expressive nuances of classical performances. Building\non this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a\nmodel featuring two branches: a Vector Quantized Variational AutoEncoder\n(VQ-VAE) branch that generates score-related content, representing the\nComposer, and a vanilla VAE branch that produces expressive details, fulfilling\nthe role of Pianist. These branches are jointly trained with similar Seq2Seq\narchitectures, leveraging a multiscale encoder to capture beat-level contextual\ninformation and an orthogonal Transformer decoder for efficient compound tokens\ndecoding. Both objective and subjective evaluations demonstrate that XMVAE\ngenerates classical performances with superior musical quality compared to\nstate-of-the-art models. Furthermore, pretraining the Composer branch on extra\nmusical score datasets contribute to a significant performance gain.", "published": "2025-07-02 10:54:23", "link": "http://arxiv.org/abs/2507.01582v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware", "abstract": "We present a full-stack emergency vehicle (EV) siren detection system\ndesigned for real-time deployment on embedded hardware. The proposed approach\nis based on E2PANNs, a fine-tuned convolutional neural network derived from\nEPANNs, and optimized for binary sound event detection under urban acoustic\nconditions. A key contribution is the creation of curated and semantically\nstructured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV -\ndeveloped using a custom AudioSet-Tools framework to overcome the low\nreliability of standard AudioSet annotations. The system is deployed on a\nRaspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing\na multithreaded inference engine with adaptive frame sizing, probability\nsmoothing, and a decision-state machine to control false positive activations.\nA remote WebSocket interface provides real-time monitoring and facilitates live\ndemonstration capabilities. Performance is evaluated using both framewise and\nevent-based metrics across multiple configurations. Results show the system\nachieves low-latency detection with improved robustness under realistic audio\nconditions. This work demonstrates the feasibility of deploying IoS-compatible\nSED solutions that can form distributed acoustic monitoring networks, enabling\ncollaborative emergency vehicle tracking across smart city infrastructures\nthrough WebSocket connectivity on low-cost edge devices.", "published": "2025-07-02 10:27:41", "link": "http://arxiv.org/abs/2507.01563v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T07 (Primary), 68T10 (Secondary)", "B.1.5; B.4.5; C.3; C.4; I.2; K.4; J.2"], "primary_category": "cs.SD"}
{"title": "AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions", "abstract": "Critical infrastructure, such as transport networks, underpins economic\ngrowth by enabling mobility and trade. However, ageing assets, climate change\nimpacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging\nfrom natural disasters to cyber attacks and conflicts pose growing risks to\ntheir resilience and functionality. This review paper explores how emerging\ndigital technologies, specifically Artificial Intelligence (AI), can enhance\ndamage assessment and monitoring of transport infrastructure. A systematic\nliterature review examines existing AI models and datasets for assessing damage\nin roads, bridges, and other critical infrastructure impacted by natural\ndisasters. Special focus is given to the unique challenges and opportunities\nassociated with bridge damage detection due to their structural complexity and\ncritical role in connectivity. The integration of SAR (Synthetic Aperture\nRadar) data with AI models is also discussed, with the review revealing a\ncritical research gap: a scarcity of studies applying AI models to SAR data for\ncomprehensive bridge damage assessment. Therefore, this review aims to identify\nthe research gaps and provide foundations for AI-driven solutions for assessing\nand monitoring critical transport infrastructures.", "published": "2025-07-02 09:59:23", "link": "http://arxiv.org/abs/2507.01547v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Chargax: A JAX Accelerated EV Charging Simulator", "abstract": "Deep Reinforcement Learning can play a key role in addressing sustainable\nenergy challenges. For instance, many grid systems are heavily congested,\nhighlighting the urgent need to enhance operational efficiency. However,\nreinforcement learning approaches have traditionally been slow due to the high\nsample complexity and expensive simulation requirements. While recent works\nhave effectively used GPUs to accelerate data generation by converting\nenvironments to JAX, these works have largely focussed on classical toy\nproblems. This paper introduces Chargax, a JAX-based environment for realistic\nsimulation of electric vehicle charging stations designed for accelerated\ntraining of RL agents. We validate our environment in a variety of scenarios\nbased on real data, comparing reinforcement learning agents against baselines.\nChargax delivers substantial computational performance improvements of over\n100x-1000x over existing environments. Additionally, Chargax' modular\narchitecture enables the representation of diverse real-world charging station\nconfigurations.", "published": "2025-07-02 09:27:14", "link": "http://arxiv.org/abs/2507.01522v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images", "abstract": "Global warming, loss of biodiversity, and air pollution are among the most\nsignificant problems facing Earth. One of the primary challenges in addressing\nthese issues is the lack of monitoring forests to protect them. To tackle this\nproblem, it is important to leverage remote sensing and computer vision methods\nto automate monitoring applications. Hence, automatic tree crown detection\nalgorithms emerged based on traditional and deep learning methods. In this\nstudy, we first introduce two different tree crown detection methods based on\nthese approaches. Then, we form a novel rule-based approach that integrates\nthese two methods to enhance robustness and accuracy of tree crown detection\nresults. While traditional methods are employed for feature extraction and\nsegmentation of forested areas, deep learning methods are used to detect tree\ncrowns in our method. With the proposed rule-based approach, we post-process\nthese results, aiming to increase the number of detected tree crowns through\nneighboring trees and localized operations. We compare the obtained results\nwith the proposed method in terms of the number of detected tree crowns and\nreport the advantages, disadvantages, and areas for improvement of the obtained\noutcomes.", "published": "2025-07-02 09:05:28", "link": "http://arxiv.org/abs/2507.01502v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Crop Pest Classification Using Deep Learning Techniques: A Review", "abstract": "Insect pests continue to bring a serious threat to crop yields around the\nworld, and traditional methods for monitoring them are often slow, manual, and\ndifficult to scale. In recent years, deep learning has emerged as a powerful\nsolution, with techniques like convolutional neural networks (CNNs), vision\ntransformers (ViTs), and hybrid models gaining popularity for automating pest\ndetection. This review looks at 37 carefully selected studies published between\n2018 and 2025, all focused on AI-based pest classification. The selected\nresearch is organized by crop type, pest species, model architecture, dataset\nusage, and key technical challenges. The early studies relied heavily on CNNs\nbut latest work is shifting toward hybrid and transformer-based models that\ndeliver higher accuracy and better contextual understanding. Still, challenges\nlike imbalanced datasets, difficulty in detecting small pests, limited\ngeneralizability, and deployment on edge devices remain significant hurdles.\nOverall, this review offers a structured overview of the field, highlights\nuseful datasets, and outlines the key challenges and future directions for\nAI-based pest monitoring systems.", "published": "2025-07-02 08:52:35", "link": "http://arxiv.org/abs/2507.01494v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning", "abstract": "Large Language Models (LLMs) have emerged as one of the most significant\ntechnological advancements in artificial intelligence in recent years. Their\nability to understand, generate, and reason with natural language has\ntransformed how we interact with AI systems. With the development of LLM-based\nagents and reinforcement-learning-based reasoning models, the study of applying\nreinforcement learning in agent frameworks has become a new research focus.\nHowever, all previous studies face the challenge of deciding the tool calling\nprocess and the reasoning process simultaneously, and the chain of reasoning\nwas solely relied on the unprocessed raw result with redundant information and\nsymbols unrelated to the task from the tool, which impose a heavy burden on the\nmodel's capability to reason. Therefore, in our research, we proposed a\nhierarchical framework Agent-as-tool that detach the tool calling process and\nthe reasoning process, which enables the model to focus on the verbally\nreasoning process while the tool calling process is handled by another agent.\nOur work had achieved comparable results with only a slight reinforcement\nfine-tuning on 180 samples, and had achieved exceptionally well performance in\nBamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding\nSearch-R1 by 4.8% in exact match and 3.2% in cover exact match.", "published": "2025-07-02 08:49:43", "link": "http://arxiv.org/abs/2507.01489v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments", "abstract": "Large language models (LLMs) and vision-language models (VLMs) have the\npotential to transform biological research by enabling autonomous\nexperimentation. Yet, their application remains constrained by rigid protocol\ndesign, limited adaptability to dynamic lab conditions, inadequate error\nhandling, and high operational complexity. Here we introduce BioMARS\n(Biological Multi-Agent Robotic System), an intelligent platform that\nintegrates LLMs, VLMs, and modular robotics to autonomously design, plan, and\nexecute biological experiments. BioMARS uses a hierarchical architecture: the\nBiologist Agent synthesizes protocols via retrieval-augmented generation; the\nTechnician Agent translates them into executable robotic pseudo-code; and the\nInspector Agent ensures procedural integrity through multimodal perception and\nanomaly detection. The system autonomously conducts cell passaging and culture\ntasks, matching or exceeding manual performance in viability, consistency, and\nmorphological integrity. It also supports context-aware optimization,\noutperforming conventional strategies in differentiating retinal pigment\nepithelial cells. A web interface enables real-time human-AI collaboration,\nwhile a modular backend allows scalable integration with laboratory hardware.\nThese results highlight the feasibility of generalizable, AI-driven laboratory\nautomation and the transformative role of language-based reasoning in\nbiological research.", "published": "2025-07-02 08:47:02", "link": "http://arxiv.org/abs/2507.01485v1", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "primary_category": "cs.RO"}
{"title": "Epistemic Scarcity: The Economics of Unresolvable Unknowns", "abstract": "This paper presents a praxeological analysis of artificial intelligence and\nalgorithmic governance, challenging assumptions about the capacity of machine\nsystems to sustain economic and epistemic order. Drawing on Misesian a priori\nreasoning and Austrian theories of entrepreneurship, we argue that AI systems\nare incapable of performing the core functions of economic coordination:\ninterpreting ends, discovering means, and communicating subjective value\nthrough prices. Where neoclassical and behavioural models treat decisions as\noptimisation under constraint, we frame them as purposive actions under\nuncertainty.\n  We critique dominant ethical AI frameworks such as Fairness, Accountability,\nand Transparency (FAT) as extensions of constructivist rationalism, which\nconflict with a liberal order grounded in voluntary action and property rights.\nAttempts to encode moral reasoning in algorithms reflect a misunderstanding of\nethics and economics. However complex, AI systems cannot originate norms,\ninterpret institutions, or bear responsibility. They remain opaque, misaligned,\nand inert.\n  Using the concept of epistemic scarcity, we explore how information abundance\ndegrades truth discernment, enabling both entrepreneurial insight and soft\ntotalitarianism. Our analysis ends with a civilisational claim: the debate over\nAI concerns the future of human autonomy, institutional evolution, and reasoned\nchoice. The Austrian tradition, focused on action, subjectivity, and\nspontaneous order, offers the only coherent alternative to rising computational\nsocial control.", "published": "2025-07-02 08:46:24", "link": "http://arxiv.org/abs/2507.01483v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "physics.hist-ph", "q-fin.EC", "91B42, 91B40, 68T01", "J.4; I.2.1; K.4.1; K.4.2"], "primary_category": "econ.GN"}
{"title": "Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals", "abstract": "This work re-examines the commonly held assumption that the frequency of\nrewards is a reliable measure of task difficulty in reinforcement learning. We\nidentify and formalize a structural challenge that undermines the effectiveness\nof current policy learning methods: when essential subgoals do not directly\nyield rewards. We characterize such settings as exhibiting zero-incentive\ndynamics, where transitions critical to success remain unrewarded. We show that\nstate-of-the-art deep subgoal-based algorithms fail to leverage these dynamics\nand that learning performance is highly sensitive to the temporal proximity\nbetween subgoal completion and eventual reward. These findings reveal a\nfundamental limitation in current approaches and point to the need for\nmechanisms that can infer latent task structure without relying on immediate\nincentives.", "published": "2025-07-02 08:33:03", "link": "http://arxiv.org/abs/2507.01470v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation", "abstract": "Instance segmentation of novel objects instances in RGB images, given some\nexample images for each object, is a well known problem in computer vision.\nDesigning a model general enough to be employed, for all kinds of novel\nobjects, without (re-) training, has proven to be a difficult task. To handle\nthis, we propose a simple, yet powerful, framework, called: Novel Object Cyclic\nThreshold based Instance Segmentation (NOCTIS). This work stems from and\nimproves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also\nleverages on recent vision foundation models, namely: Grounded-SAM 2 and\nDINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise\nbounding boxes and their corresponding segmentation masks; while DINOv2's\nzero-shot capabilities are employed to generate the image embeddings. The\nquality of those masks, together with their embeddings, is of vital importance\nto our approach; as the proposal-object matching is realized by determining an\nobject matching score based on the similarity of the class embeddings and the\naverage maximum similarity of the patch embeddings. Differently to SAM-6D,\ncalculating the latter involves a prior patch filtering based on the distance\nbetween each patch and its corresponding cyclic/roundtrip patch in the image\ngrid. Furthermore, the average confidence of the proposals' bounding box and\nmask is used as an additional weighting factor for the object matching score.\nWe empirically show that NOCTIS, without further training/fine tuning,\noutperforms the best RGB and RGB-D methods on the seven core datasets of the\nBOP 2023 challenge for the \"Model-based 2D segmentation of unseen objects\"\ntask.", "published": "2025-07-02 08:23:14", "link": "http://arxiv.org/abs/2507.01463v1", "categories": ["cs.CV", "cs.AI", "I.2; I.4; I.5"], "primary_category": "cs.CV"}
{"title": "Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0", "abstract": "This work explores the application of hybrid quantum-classical algorithms to\noptimize robotic inspection trajectories derived from Computer-Aided Design\n(CAD) models in industrial settings. By modeling the task as a 3D variant of\nthe Traveling Salesman Problem, incorporating incomplete graphs and open-route\nconstraints, this study evaluates the performance of two D-Wave-based solvers\nagainst classical methods such as GUROBI and Google OR-Tools. Results across\nfive real-world cases demonstrate competitive solution quality with\nsignificantly reduced computation times, highlighting the potential of quantum\napproaches in automation under Industry 4.0.", "published": "2025-07-02 08:21:52", "link": "http://arxiv.org/abs/2507.01462v1", "categories": ["cs.RO", "cs.AI", "cs.ET"], "primary_category": "cs.RO"}
{"title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs", "abstract": "RISC-V provides a flexible and scalable platform for applications ranging\nfrom embedded devices to high-performance computing clusters. Particularly, its\nRISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI\nworkloads. But writing software that efficiently utilizes the vector units of\nRISC-V CPUs without expert knowledge requires the programmer to rely on the\nautovectorization features of compilers or hand-crafted libraries like\nmuRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing\nthe integration with the RISC-V RVV extension, thus heavily limiting the\nefficient deployment of complex AI workloads. In this paper, we present a\nworkflow based on the TVM compiler to efficiently map AI workloads onto RISC-V\nvector units. Instead of relying on hand-crafted libraries, we integrated the\nRVV extension into TVM's MetaSchedule framework, a probabilistic program\nframework for tensor operation tuning. We implemented different RISC-V SoCs on\nan FPGA and tuned a wide range of AI workloads on them. We found that our\nproposal shows a mean improvement of 46% in execution latency when compared\nagainst the autovectorization feature of GCC, and 29% against muRISCV-NN.\nMoreover, the binary resulting from our proposal has a smaller code memory\nfootprint, making it more suitable for embedded devices. Finally, we also\nevaluated our solution on a commercially available RISC-V SoC implementing the\nRVV 1.0 Vector Extension and found our solution is able to find mappings that\nare 35% faster on average than the ones proposed by LLVM. We open-sourced our\nproposal for the community to expand it to target other RISC-V extensions.", "published": "2025-07-02 08:15:33", "link": "http://arxiv.org/abs/2507.01457v1", "categories": ["cs.LG", "cs.AI", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Using multi-agent architecture to mitigate the risk of LLM hallucinations", "abstract": "Improving customer service quality and response time are critical factors for\nmaintaining customer loyalty and increasing a company's market share. While\nadopting emerging technologies such as Large Language Models (LLMs) is becoming\na necessity to achieve these goals, the risk of hallucination remains a major\nchallenge. In this paper, we present a multi-agent system to handle customer\nrequests sent via SMS. This system integrates LLM based agents with fuzzy logic\nto mitigate hallucination risks.", "published": "2025-07-02 08:06:02", "link": "http://arxiv.org/abs/2507.01446v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices", "abstract": "Large Language Models (LLMs) have gained significant attention due to their\nversatility across a wide array of applications. Fine-tuning LLMs with\nparameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these\nmodels to efficiently adapt to downstream tasks without extensive retraining.\nDeploying fine-tuned LLMs on multi-tenant edge devices offers substantial\nbenefits, such as reduced latency, enhanced privacy, and personalized\nresponses. However, serving LLMs efficiently on resource-constrained edge\ndevices presents critical challenges, including the complexity of adapter\nselection for different tasks and memory overhead from frequent adapter\nswapping. Moreover, given the multiple requests in multi-tenant settings,\nprocessing requests sequentially results in underutilization of computational\nresources and increased latency. This paper introduces EdgeLoRA, an efficient\nsystem for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA\nincorporates three key innovations: (1) an adaptive adapter selection mechanism\nto streamline the adapter configuration process; (2) heterogeneous memory\nmanagement, leveraging intelligent adapter caching and pooling to mitigate\nmemory operation overhead; and (3) batch LoRA inference, enabling efficient\nbatch processing to significantly reduce computational latency. Comprehensive\nevaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly\noutperforms the status quo (i.e., llama.cpp) in terms of both latency and\nthroughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times\nboost in throughput. Even more impressively, it can serve several orders of\nmagnitude more adapters simultaneously. These results highlight EdgeLoRA's\npotential to transform edge deployment of LLMs in multi-tenant scenarios,\noffering a scalable and efficient solution for resource-constrained\nenvironments.", "published": "2025-07-02 07:47:28", "link": "http://arxiv.org/abs/2507.01438v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems", "abstract": "Deep neural networks generate and process large volumes of data, posing\nchallenges for low-resource embedded systems. In-memory computing has been\ndemonstrated as an efficient computing infrastructure and shows promise for\nembedded AI applications. Among newly-researched memory technologies, racetrack\nmemory is a non-volatile technology that allows high data density fabrication,\nmaking it a good fit for in-memory computing. However, integrating in-memory\narithmetic circuits with memory cells affects both the memory density and power\nefficiency. It remains challenging to build efficient in-memory arithmetic\ncircuits on racetrack memory within area and energy constraints. To this end,\nwe present an efficient in-memory convolutional neural network (CNN)\naccelerator optimized for use with racetrack memory. We design a series of\nfundamental arithmetic circuits as in-memory computing cells suited for\nmultiply-and-accumulate operations. Moreover, we explore the design space of\nracetrack memory based systems and CNN model architectures, employing co-design\nto improve the efficiency and performance of performing CNN inference in\nracetrack memory while maintaining model accuracy. Our designed circuits and\nmodel-system co-optimization strategies achieve a small memory bank area with\nsignificant improvements in energy and performance for racetrack memory based\nembedded systems.", "published": "2025-07-02 07:29:53", "link": "http://arxiv.org/abs/2507.01429v1", "categories": ["cs.ET", "cs.AI", "cs.AR"], "primary_category": "cs.ET"}
{"title": "DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal", "abstract": "Document shadow removal is a crucial task in the field of document image\nenhancement. However, existing methods tend to remove shadows with constant\ncolor background and ignore color shadows. In this paper, we first design a\ndiffusion model in latent space for document image shadow removal, called\nDocShaDiffusion. It translates shadow images from pixel space to latent space,\nenabling the model to more easily capture essential features. To address the\nissue of color shadows, we design a shadow soft-mask generation module (SSGM).\nIt is able to produce accurate shadow mask and add noise into shadow regions\nspecially. Guided by the shadow mask, a shadow mask-aware guided diffusion\nmodule (SMGDM) is proposed to remove shadows from document images by\nsupervising the diffusion and denoising process. We also propose a\nshadow-robust perceptual feature loss to preserve details and structures in\ndocument images. Moreover, we develop a large-scale synthetic document color\nshadow removal dataset (SDCSRD). It simulates the distribution of realistic\ncolor shadows and provides powerful supports for the training of models.\nExperiments on three public datasets validate the proposed method's superiority\nover state-of-the-art. Our code and dataset will be publicly available.", "published": "2025-07-02 07:22:09", "link": "http://arxiv.org/abs/2507.01422v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing", "abstract": "As AI integrates in various types of human writing, calls for transparency\naround AI assistance are growing. However, if transparency operates on uneven\nground and certain identity groups bear a heavier cost for being honest, then\nthe burden of openness becomes asymmetrical. This study investigates how AI\ndisclosure statement affects perceptions of writing quality, and whether these\neffects vary by the author's race and gender. Through a large-scale controlled\nexperiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated\na single human-written news article while disclosure statements and author\ndemographics were systematically varied. This approach reflects how both human\nand algorithmic decisions now influence access to opportunities (e.g., hiring,\npromotion) and social recognition (e.g., content recommendation algorithms). We\nfind that both human and LLM raters consistently penalize disclosed AI use.\nHowever, only LLM raters exhibit demographic interaction effects: they favor\narticles attributed to women or Black authors when no disclosure is present.\nBut these advantages disappear when AI assistance is revealed. These findings\nilluminate the complex relationships between AI disclosure and author identity,\nhighlighting disparities between machine and human evaluation patterns.", "published": "2025-07-02 07:18:09", "link": "http://arxiv.org/abs/2507.01418v1", "categories": ["cs.CY", "cs.AI", "H.5.2; I.2"], "primary_category": "cs.CY"}
{"title": "Evaluating LLM Agent Collusion in Double Auctions", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities as\nautonomous agents with rapidly expanding applications in various domains. As\nthese agents increasingly engage in socioeconomic interactions, identifying\ntheir potential for undesirable behavior becomes essential. In this work, we\nexamine scenarios where they can choose to collude, defined as secretive\ncooperation that harms another party. To systematically study this, we\ninvestigate the behavior of LLM agents acting as sellers in simulated\ncontinuous double auction markets. Through a series of controlled experiments,\nwe analyze how parameters such as the ability to communicate, choice of model,\nand presence of environmental pressures affect the stability and emergence of\nseller collusion. We find that direct seller communication increases collusive\ntendencies, the propensity to collude varies across models, and environmental\npressures, such as oversight and urgency from authority figures, influence\ncollusive behavior. Our findings highlight important economic and ethical\nconsiderations for the deployment of LLM-based market agents.", "published": "2025-07-02 07:06:49", "link": "http://arxiv.org/abs/2507.01413v1", "categories": ["cs.GT", "cs.AI", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping", "abstract": "Grey matter loss in the hippocampus is a hallmark of neurobiological aging,\nyet understanding the corresponding changes in its functional connectivity\nremains limited. Seed-based functional connectivity (FC) analysis enables\nvoxel-wise mapping of the hippocampus's synchronous activity with cortical\nregions, offering a window into functional reorganization during aging. In this\nstudy, we develop an interpretable deep learning framework to predict brain age\nfrom hippocampal FC using a three-dimensional convolutional neural network (3D\nCNN) combined with LayerCAM saliency mapping. This approach maps key\nhippocampal-cortical connections, particularly with the precuneus, cuneus,\nposterior cingulate cortex, parahippocampal cortex, left superior parietal\nlobule, and right superior temporal sulcus, that are highly sensitive to age.\nCritically, disaggregating anterior and posterior hippocampal FC reveals\ndistinct mapping aligned with their known functional specializations. These\nfindings provide new insights into the functional mechanisms of hippocampal\naging and demonstrate the power of explainable deep learning to uncover\nbiologically meaningful patterns in neuroimaging data.", "published": "2025-07-02 07:05:18", "link": "http://arxiv.org/abs/2507.01411v1", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "primary_category": "q-bio.NC"}
{"title": "A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models", "abstract": "The ontological and epistemic complexities inherent in the moral domain make\nit challenging to establish clear standards for evaluating the performance of a\nmoral machine. In this paper, we present a formal method to describe Ethical\nDecision Making models based on ethical risk assessment. Then, we show how\nthese models that are specified as fuzzy rules can be verified and validated\nusing fuzzy Petri nets. A case study from the medical field is considered to\nillustrate the proposed approach.", "published": "2025-07-02 07:05:11", "link": "http://arxiv.org/abs/2507.01410v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound", "abstract": "Fetal abdominal malformations are serious congenital anomalies that require\naccurate diagnosis to guide pregnancy management and reduce mortality. Although\nAI has demonstrated significant potential in medical diagnosis, its application\nto prenatal abdominal anomalies remains limited. Most existing studies focus on\nimage-level classification and rely on standard plane localization, placing\nless emphasis on case-level diagnosis. In this paper, we develop a case-level\nmultiple instance learning (MIL)-based method, free of standard plane\nlocalization, for classifying fetal abdominal anomalies in prenatal ultrasound.\nOur contribution is three-fold. First, we adopt a mixture-of-attention-experts\nmodule (MoAE) to weight different attention heads for various planes. Secondly,\nwe propose a medical-knowledge-driven feature selection module (MFS) to align\nimage features with medical knowledge, performing self-supervised image token\nselection at the case-level. Finally, we propose a prompt-based prototype\nlearning (PPL) to enhance the MFS. Extensively validated on a large prenatal\nabdominal ultrasound dataset containing 2,419 cases, with a total of 24,748\nimages and 6 categories, our proposed method outperforms the state-of-the-art\ncompetitors. Codes are available at:https://github.com/LL-AC/AAcls.", "published": "2025-07-02 06:31:26", "link": "http://arxiv.org/abs/2507.01401v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Distributional Soft Actor-Critic with Diffusion Policy", "abstract": "Reinforcement learning has been proven to be highly effective in handling\ncomplex control tasks. Traditional methods typically use unimodal\ndistributions, such as Gaussian distributions, to model the output of value\ndistributions. However, unimodal distribution often and easily causes bias in\nvalue function estimation, leading to poor algorithm performance. This paper\nproposes a distributional reinforcement learning algorithm called DSAC-D\n(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges\nof estimating bias in value functions and obtaining multimodal policy\nrepresentations. A multimodal distributional policy iteration framework that\ncan converge to the optimal policy was established by introducing policy\nentropy and value distribution function. A diffusion value network that can\naccurately characterize the distribution of multi peaks was constructed by\ngenerating a set of reward samples through reverse sampling using a diffusion\nmodel. Based on this, a distributional reinforcement learning algorithm with\ndual diffusion of the value network and the policy network was derived. MuJoCo\ntesting tasks demonstrate that the proposed algorithm not only learns\nmultimodal policy, but also achieves state-of-the-art (SOTA) performance in all\n9 control tasks, with significant suppression of estimation bias and total\naverage return improvement of over 10\\% compared to existing mainstream\nalgorithms. The results of real vehicle testing show that DSAC-D can accurately\ncharacterize the multimodal distribution of different driving styles, and the\ndiffusion policy network can characterize multimodal trajectories.", "published": "2025-07-02 05:50:10", "link": "http://arxiv.org/abs/2507.01381v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms", "abstract": "Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as\na critical research focus, and it typically requires the swarm to navigate\neffectively while avoiding obstacles and achieving continuous coverage over\nmultiple mission targets. Although traditional Multi-Agent Reinforcement\nLearning (MARL) approaches offer dynamic adaptability, they are hindered by the\nsemantic gap in numerical communication and the rigidity of homogeneous role\nstructures, resulting in poor generalization and limited task scalability.\nRecent advances in Large Language Model (LLM)-based control frameworks\ndemonstrate strong semantic reasoning capabilities by leveraging extensive\nprior knowledge. However, due to the lack of online learning and over-reliance\non static priors, these works often struggle with effective exploration,\nleading to reduced individual potential and overall system performance. To\naddress these limitations, we propose a Role-Adaptive LLM-Driven Yoked\nnavigation algorithm RALLY. Specifically, we first develop an LLM-driven\nsemantic decision framework that uses structured natural language for efficient\nsemantic communication and collaborative reasoning. Afterward, we introduce a\ndynamic role-heterogeneity mechanism for adaptive role switching and\npersonalized decision-making. Furthermore, we propose a Role-value Mixing\nNetwork (RMIX)-based assignment strategy that integrates LLM offline priors\nwith MARL online policies to enable semi-offline training of role selection\nstrategies. Experiments in the Multi-Agent Particle Environment (MPE)\nenvironment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY\noutperforms conventional approaches in terms of task coverage, convergence\nspeed, and generalization, highlighting its strong potential for collaborative\nnavigation in agentic multi-UAV systems.", "published": "2025-07-02 05:44:17", "link": "http://arxiv.org/abs/2507.01378v1", "categories": ["cs.MA", "cs.AI", "cs.RO"], "primary_category": "cs.MA"}
{"title": "AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing", "abstract": "AI agents are autonomous systems designed to perceive, reason, and act within\ndynamic environments. With the rapid advancements in generative AI (GenAI),\nlarge language models (LLMs) and multimodal large language models (MLLMs) have\nsignificantly improved AI agents' capabilities in semantic comprehension,\ncomplex reasoning, and autonomous decision-making. At the same time, the rise\nof Agentic AI highlights adaptability and goal-directed autonomy in dynamic and\ncomplex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents\n(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in\ninformation processing, environmental perception, and autonomous\ndecision-making, opening new avenues for smart manufacturing. However, the\ndefinitions, capability boundaries, and practical applications of these\nemerging AI paradigms in smart manufacturing remain unclear. To address this\ngap, this study systematically reviews the evolution of AI and AI agent\ntechnologies, examines the core concepts and technological advancements of\nLLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential\napplications in and integration into manufacturing, along with the potential\nchallenges they may face.", "published": "2025-07-02 05:31:17", "link": "http://arxiv.org/abs/2507.01376v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "User-guided Generative Source Separation", "abstract": "Music source separation (MSS) aims to extract individual instrument sources\nfrom their mixture. While most existing methods focus on the widely adopted\nfour-stem separation setup (vocals, bass, drums, and other instruments), this\napproach lacks the flexibility needed for real-world applications. To address\nthis, we propose GuideSep, a diffusion-based MSS model capable of\ninstrument-agnostic separation beyond the four-stem setup. GuideSep is\nconditioned on multiple inputs: a waveform mimicry condition, which can be\neasily provided by humming or playing the target melody, and mel-spectrogram\ndomain masks, which offer additional guidance for separation. Unlike prior\napproaches that relied on fixed class labels or sound queries, our conditioning\nscheme, coupled with the generative approach, provides greater flexibility and\napplicability. Additionally, we design a mask-prediction baseline using the\nsame model architecture to systematically compare predictive and generative\napproaches. Our objective and subjective evaluations demonstrate that GuideSep\nachieves high-quality separation while enabling more versatile instrument\nextraction, highlighting the potential of user participation in the\ndiffusion-based generative process for MSS. Our code and demo page are\navailable at https://yutongwen.github.io/GuideSep/", "published": "2025-07-02 03:58:52", "link": "http://arxiv.org/abs/2507.01339v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy", "abstract": "Detecting abnormal events in real-world customer service dialogues is highly\nchallenging due to the complexity of business data and the dynamic nature of\ncustomer interactions. Moreover, models must demonstrate strong out-of-domain\n(OOD) generalization to enable rapid adaptation across different business\nscenarios and maximize commercial value. In this work, we propose a novel\nAdaptive Perplexity-Aware Reinforcement Learning (APARL) framework that\nleverages the advanced reasoning capabilities of large language models for\nabnormal event detection. APARL introduces a dual-loop dynamic curriculum\nlearning architecture, enabling the model to progressively focus on more\nchallenging samples as its proficiency increases. This design effectively\naddresses performance bottlenecks and significantly enhances OOD\ntransferability. Extensive evaluations on food delivery dialogue tasks show\nthat our model achieves significantly enhanced adaptability and robustness,\nattaining the highest F1 score with an average improvement of 17.19\\%, and an\naverage improvement of 9.59\\% in OOD transfer tests. This method provides a\nsuperior solution for industrial deployment of anomaly detection models,\ncontributing to improved operational efficiency and commercial benefits.", "published": "2025-07-02 03:26:02", "link": "http://arxiv.org/abs/2507.01327v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks", "abstract": "In-context learning (ICL) has demonstrated remarkable success in large\nlanguage models (LLMs) due to its adaptability and parameter-free nature.\nHowever, it also introduces a critical vulnerability to backdoor attacks, where\nadversaries can manipulate LLM behaviors by simply poisoning a few ICL\ndemonstrations. In this paper, we propose, for the first time, the\ndual-learning hypothesis, which posits that LLMs simultaneously learn both the\ntask-relevant latent concepts and backdoor latent concepts within poisoned\ndemonstrations, jointly influencing the probability of model outputs. Through\ntheoretical analysis, we derive an upper bound for ICL backdoor effects,\nrevealing that the vulnerability is dominated by the concept preference ratio\nbetween the task and the backdoor. Motivated by these findings, we propose\nICLShield, a defense mechanism that dynamically adjusts the concept preference\nratio. Our method encourages LLMs to select clean demonstrations during the ICL\nphase by leveraging confidence and similarity scores, effectively mitigating\nsusceptibility to backdoor attacks. Extensive experiments across multiple LLMs\nand tasks demonstrate that our method achieves state-of-the-art defense\neffectiveness, significantly outperforming existing approaches (+26.02% on\naverage). Furthermore, our method exhibits exceptional adaptability and\ndefensive performance even for closed-source models (e.g., GPT-4).", "published": "2025-07-02 03:09:20", "link": "http://arxiv.org/abs/2507.01321v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Neural Hamiltonian Operator", "abstract": "Stochastic control problems in high dimensions are notoriously difficult to\nsolve due to the curse of dimensionality. An alternative to traditional dynamic\nprogramming is Pontryagin's Maximum Principle (PMP), which recasts the problem\nas a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In\nthis paper, we introduce a formal framework for solving such problems with deep\nlearning by defining a \\textbf{Neural Hamiltonian Operator (NHO)}. This\noperator parameterizes the coupled FBSDE dynamics via neural networks that\nrepresent the feedback control and an ansatz for the value function's spatial\ngradient. We show how the optimal NHO can be found by training the underlying\nnetworks to enforce the consistency conditions dictated by the PMP. By adopting\nthis operator-theoretic view, we situate the deep FBSDE method within the\nrigorous language of statistical inference, framing it as a problem of learning\nan unknown operator from simulated data. This perspective allows us to prove\nthe universal approximation capabilities of NHOs under general martingale\ndrivers and provides a clear lens for analyzing the significant optimization\nchallenges inherent to this class of models.", "published": "2025-07-02 02:56:49", "link": "http://arxiv.org/abs/2507.01313v1", "categories": ["cs.LG", "cs.AI", "math.DS", "math.OC"], "primary_category": "cs.LG"}
{"title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "abstract": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "published": "2025-07-02 01:52:40", "link": "http://arxiv.org/abs/2507.01284v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care", "abstract": "The recent boom of large language models (LLMs) has re-ignited the hope that\nartificial intelligence (AI) systems could aid medical diagnosis. Yet despite\ndazzling benchmark scores, LLM assistants have yet to deliver measurable\nimprovements at the bedside. This scoping review aims to highlight the areas\nwhere AI is limited to make practical contributions in the clinical setting,\nspecifically in dementia diagnosis and care.\n  Standalone machine-learning models excel at pattern recognition but seldom\nprovide actionable, interpretable guidance, eroding clinician trust. Adjacent\nuse of LLMs by physicians did not result in better diagnostic accuracy or\nspeed. Key limitations trace to the data-driven paradigm: black-box outputs\nwhich lack transparency, vulnerability to hallucinations, and weak causal\nreasoning. Hybrid approaches that combine statistical learning with expert\nrule-based knowledge, and involve clinicians throughout the process help bring\nback interpretability. They also fit better with existing clinical workflows,\nas seen in examples like PEIRS and ATHENA-CDS.\n  Future decision-support should prioritise explanatory coherence by linking\npredictions to clinically meaningful causes. This can be done through\nneuro-symbolic or hybrid AI that combines the language ability of LLMs with\nhuman causal expertise. AI researchers have addressed this direction, with\nexplainable AI and neuro-symbolic AI being the next logical steps in further\nadvancement in AI. However, they are still based on data-driven knowledge\nintegration instead of human-in-the-loop approaches. Future research should\nmeasure success not only by accuracy but by improvements in clinician\nunderstanding, workflow fit, and patient outcomes. A better understanding of\nwhat helps improve human-computer interactions is greatly needed for AI systems\nto become part of clinical practice.", "published": "2025-07-02 01:43:06", "link": "http://arxiv.org/abs/2507.01282v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance", "abstract": "Traditional simulator-based training for maritime professionals is critical\nfor ensuring safety at sea but often depends on subjective trainer assessments\nof technical skills, behavioral focus, communication, and body language, posing\nchallenges such as subjectivity, difficulty in measuring key features, and\ncognitive limitations. Addressing these issues, this study develops an\nAI-driven framework to enhance maritime training by objectively assessing\ntrainee performance through visual focus tracking, speech recognition, and\nstress detection, improving readiness for high-risk scenarios. The system\nintegrates AI techniques, including visual focus determination using eye\ntracking, pupil dilation analysis, and computer vision; communication analysis\nthrough a maritime-specific speech-to-text model and natural language\nprocessing; communication correctness using large language models; and mental\nstress detection via vocal pitch. Models were evaluated on data from simulated\nmaritime scenarios with seafarers exposed to controlled high-stress events. The\nAI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for\nmaritime speech recognition, and ~90% for stress detection, surpassing existing\nbenchmarks. The system provides insights into visual attention, adherence to\ncommunication checklists, and stress levels under demanding conditions. This\nstudy demonstrates how AI can transform maritime training by delivering\nobjective performance analytics, enabling personalized feedback, and improving\npreparedness for real-world operational challenges.", "published": "2025-07-02 01:19:32", "link": "http://arxiv.org/abs/2507.01274v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "abstract": "In recent years, unlearning techniques, which are methods for inducing a\nmodel to \"forget\" previously learned information, have attracted attention as a\nway to address privacy and copyright concerns in large language models (LLMs)\nand large multimodal models (LMMs). While several unlearning benchmarks have\nbeen established for LLMs, a practical evaluation framework for unlearning in\nLMMs has been less explored. Specifically, existing unlearning benchmark for\nLMMs considers only scenarios in which the model is required to unlearn\nfine-tuned knowledge through a single unlearning operation. In this study, we\nintroduce PULSE protocol for realistic unlearning scenarios for LMMs by\nintroducing two critical perspectives: (i) Pre-trained knowledge Unlearning for\nanalyzing the effect across different knowledge acquisition phases and (ii)\nLong-term Sustainability Evaluation to address sequential requests. We then\nevaluate existing unlearning methods along these dimensions. Our results reveal\nthat, although some techniques can successfully unlearn knowledge acquired\nthrough fine-tuning, they struggle to eliminate information learned during\npre-training. Moreover, methods that effectively unlearn a batch of target data\nin a single operation exhibit substantial performance degradation when the same\ndata are split and unlearned sequentially.", "published": "2025-07-02 01:13:08", "link": "http://arxiv.org/abs/2507.01271v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LLM-based Realistic Safety-Critical Driving Video Generation", "abstract": "Designing diverse and safety-critical driving scenarios is essential for\nevaluating autonomous driving systems. In this paper, we propose a novel\nframework that leverages Large Language Models (LLMs) for few-shot code\ngeneration to automatically synthesize driving scenarios within the CARLA\nsimulator, which has flexibility in scenario scripting, efficient code-based\ncontrol of traffic participants, and enforcement of realistic physical\ndynamics. Given a few example prompts and code samples, the LLM generates\nsafety-critical scenario scripts that specify the behavior and placement of\ntraffic participants, with a particular focus on collision events. To bridge\nthe gap between simulation and real-world appearance, we integrate a video\ngeneration pipeline using Cosmos-Transfer1 with ControlNet, which converts\nrendered scenes into realistic driving videos. Our approach enables\ncontrollable scenario generation and facilitates the creation of rare but\ncritical edge cases, such as pedestrian crossings under occlusion or sudden\nvehicle cut-ins. Experimental results demonstrate the effectiveness of our\nmethod in generating a wide range of realistic, diverse, and safety-critical\nscenarios, offering a promising tool for simulation-based testing of autonomous\nvehicles.", "published": "2025-07-02 00:45:19", "link": "http://arxiv.org/abs/2507.01264v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model", "abstract": "We present FreeMorph, the first tuning-free method for image morphing that\naccommodates inputs with different semantics or layouts. Unlike existing\nmethods that rely on finetuning pre-trained diffusion models and are limited by\ntime constraints and semantic/layout discrepancies, FreeMorph delivers\nhigh-fidelity image morphing without requiring per-instance training. Despite\ntheir efficiency and potential, tuning-free methods face challenges in\nmaintaining high-quality results due to the non-linear nature of the multi-step\ndenoising process and biases inherited from the pre-trained diffusion model. In\nthis paper, we introduce FreeMorph to address these challenges by integrating\ntwo key innovations. 1) We first propose a guidance-aware spherical\ninterpolation design that incorporates explicit guidance from the input images\nby modifying the self-attention modules, thereby addressing identity loss and\nensuring directional transitions throughout the generated sequence. 2) We\nfurther introduce a step-oriented variation trend that blends self-attention\nmodules derived from each input image to achieve controlled and consistent\ntransitions that respect both inputs. Our extensive evaluations demonstrate\nthat FreeMorph outperforms existing methods, being 10x ~ 50x faster and\nestablishing a new state-of-the-art for image morphing.", "published": "2025-07-02 17:58:20", "link": "http://arxiv.org/abs/2507.01953v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Kwai Keye-VL Technical Report", "abstract": "While Multimodal Large Language Models (MLLMs) demonstrate remarkable\ncapabilities on static images, they often fall short in comprehending dynamic,\ninformation-dense short-form videos, a dominant medium in today's digital\nlandscape. To bridge this gap, we introduce \\textbf{Kwai Keye-VL}, an\n8-billion-parameter multimodal foundation model engineered for leading-edge\nperformance in short-video understanding while maintaining robust\ngeneral-purpose vision-language abilities. The development of Keye-VL rests on\ntwo core pillars: a massive, high-quality dataset exceeding 600 billion tokens\nwith a strong emphasis on video, and an innovative training recipe. This recipe\nfeatures a four-stage pre-training process for solid vision-language alignment,\nfollowed by a meticulous two-phase post-training process. The first\npost-training stage enhances foundational capabilities like instruction\nfollowing, while the second phase focuses on stimulating advanced reasoning. In\nthis second phase, a key innovation is our five-mode ``cold-start'' data\nmixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``think\nwith image'', and high-quality video data. This mixture teaches the model to\ndecide when and how to reason. Subsequent reinforcement learning (RL) and\nalignment steps further enhance these reasoning capabilities and correct\nabnormal model behaviors, such as repetitive outputs. To validate our approach,\nwe conduct extensive evaluations, showing that Keye-VL achieves\nstate-of-the-art results on public video benchmarks and remains highly\ncompetitive on general image-based tasks (Figure 1). Furthermore, we develop\nand release the \\textbf{KC-MMBench}, a new benchmark tailored for real-world\nshort-video scenarios, where Keye-VL shows a significant advantage.", "published": "2025-07-02 17:57:28", "link": "http://arxiv.org/abs/2507.01949v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory", "abstract": "Animation colorization is a crucial part of real animation industry\nproduction. Long animation colorization has high labor costs. Therefore,\nautomated long animation colorization based on the video generation model has\nsignificant research value. Existing studies are limited to short-term\ncolorization. These studies adopt a local paradigm, fusing overlapping features\nto achieve smooth transitions between local segments. However, the local\nparadigm neglects global information, failing to maintain long-term color\nconsistency. In this study, we argue that ideal long-term color consistency can\nbe achieved through a dynamic global-local paradigm, i.e., dynamically\nextracting global color-consistent features relevant to the current generation.\nSpecifically, we propose LongAnimation, a novel framework, which mainly\nincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color\nConsistency Reward. The SketchDiT captures hybrid reference features to support\nthe DGLM module. The DGLM module employs a long video understanding model to\ndynamically compress global historical features and adaptively fuse them with\nthe current generation features. To refine the color consistency, we introduce\na Color Consistency Reward. During inference, we propose a color consistency\nfusion to smooth the video segment transition. Extensive experiments on both\nshort-term (14 frames) and long-term (average 500 frames) animations show the\neffectiveness of LongAnimation in maintaining short-term and long-term color\nconsistency for open-domain animation colorization task. The code can be found\nat https://cn-makers.github.io/long_animation_web/.", "published": "2025-07-02 17:55:50", "link": "http://arxiv.org/abs/2507.01945v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CI-VID: A Coherent Interleaved Text-Video Dataset", "abstract": "Text-to-video (T2V) generation has recently attracted considerable attention,\nresulting in the development of numerous high-quality datasets that have\npropelled progress in this area. However, existing public datasets are\nprimarily composed of isolated text-video (T-V) pairs and thus fail to support\nthe modeling of coherent multi-clip video sequences. To address this\nlimitation, we introduce CI-VID, a dataset that moves beyond isolated\ntext-to-video (T2V) generation toward text-and-video-to-video (TV2V)\ngeneration, enabling models to produce coherent, multi-scene video sequences.\nCI-VID contains over 340,000 samples, each featuring a coherent sequence of\nvideo clips with text captions that capture both the individual content of each\nclip and the transitions between them, enabling visually and textually grounded\ngeneration. To further validate the effectiveness of CI-VID, we design a\ncomprehensive, multi-dimensional benchmark incorporating human evaluation,\nVLM-based assessment, and similarity-based metrics. Experimental results\ndemonstrate that models trained on CI-VID exhibit significant improvements in\nboth accuracy and content consistency when generating video sequences. This\nfacilitates the creation of story-driven content with smooth visual transitions\nand strong temporal coherence, underscoring the quality and practical utility\nof the CI-VID dataset We release the CI-VID dataset and the accompanying code\nfor data construction and evaluation at: https://github.com/ymju-BAAI/CI-VID", "published": "2025-07-02 17:48:01", "link": "http://arxiv.org/abs/2507.01938v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "evMLP: An Efficient Event-Driven MLP Architecture for Vision", "abstract": "Deep neural networks have achieved remarkable results in computer vision\ntasks. In the early days, Convolutional Neural Networks (CNNs) were the\nmainstream architecture. In recent years, Vision Transformers (ViTs) have\nbecome increasingly popular. In addition, exploring applications of multi-layer\nperceptrons (MLPs) has provided new perspectives for research into vision model\narchitectures. In this paper, we present evMLP accompanied by a simple\nevent-driven local update mechanism. The proposed evMLP can independently\nprocess patches on images or feature maps via MLPs. We define changes between\nconsecutive frames as \"events\". Under the event-driven local update mechanism,\nevMLP selectively processes patches where events occur. For sequential image\ndata (e.g., video processing), this approach improves computational performance\nby avoiding redundant computations. Through ImageNet image classification\nexperiments, evMLP attains accuracy competitive with state-of-the-art models.\nMore significantly, experimental results on multiple video datasets demonstrate\nthat evMLP reduces computational cost via its event-driven local update\nmechanism while maintaining output consistency with its non-event-driven\nbaseline. The code and trained models are available at\nhttps://github.com/i-evi/evMLP.", "published": "2025-07-02 17:36:50", "link": "http://arxiv.org/abs/2507.01927v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IC-Custom: Diverse Image Customization via In-Context Learning", "abstract": "Image customization, a crucial technique for industrial media production,\naims to generate content that is consistent with reference images. However,\ncurrent approaches conventionally separate image customization into\nposition-aware and position-free customization paradigms and lack a universal\nframework for diverse customization, limiting their applications across various\nscenarios. To overcome these limitations, we propose IC-Custom, a unified\nframework that seamlessly integrates position-aware and position-free image\ncustomization through in-context learning. IC-Custom concatenates reference\nimages with target images to a polyptych, leveraging DiT's multi-modal\nattention mechanism for fine-grained token-level interactions. We introduce the\nIn-context Multi-Modal Attention (ICMA) mechanism with learnable task-oriented\nregister tokens and boundary-aware positional embeddings to enable the model to\ncorrectly handle different task types and distinguish various inputs in\npolyptych configurations. To bridge the data gap, we carefully curated a\nhigh-quality dataset of 12k identity-consistent samples with 8k from real-world\nsources and 4k from high-quality synthetic data, avoiding the overly glossy and\nover-saturated synthetic appearance. IC-Custom supports various industrial\napplications, including try-on, accessory placement, furniture arrangement, and\ncreative IP customization. Extensive evaluations on our proposed ProductBench\nand the publicly available DreamBench demonstrate that IC-Custom significantly\noutperforms community workflows, closed-source models, and state-of-the-art\nopen-source approaches. IC-Custom achieves approximately 73% higher human\npreference across identity consistency, harmonicity, and text alignment\nmetrics, while training only 0.4% of the original model parameters. Project\npage: https://liyaowei-stu.github.io/project/IC_Custom", "published": "2025-07-02 17:36:38", "link": "http://arxiv.org/abs/2507.01926v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP", "abstract": "In orchard automation, dense foliage during the canopy season severely\noccludes tree structures, minimizing visibility to various canopy parts such as\ntrunks and branches, which limits the ability of a machine vision system.\nHowever, canopy structure is more open and visible during the dormant season\nwhen trees are defoliated. In this work, we present an information fusion\nframework that integrates multi-seasonal structural data to support robotic and\nautomated crop load management during the entire growing season. The framework\ncombines high-resolution RGB-D imagery from both dormant and canopy periods\nusing YOLOv9-Seg for instance segmentation, Kinect Fusion for 3D\nreconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) for\nmodel alignment. Segmentation outputs from YOLOv9-Seg were used to extract\ndepth-informed masks, which enabled accurate 3D point cloud reconstruction via\nKinect Fusion; these reconstructed models from each season were subsequently\naligned using Fast GICP to achieve spatially coherent multi-season fusion. The\nYOLOv9-Seg model, trained on manually annotated images, achieved a mean squared\nerror (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks in\ndormant season dataset. Kinect Fusion enabled accurate reconstruction of tree\ngeometry, validated with field measurements resulting in root mean square\nerrors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and\n13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonal\nregistration with a minimum fitness score of 0.00197, allowing integrated,\ncomprehensive tree structure modeling despite heavy occlusions during the\ngrowing season. This fused structural representation enables robotic systems to\naccess otherwise obscured architectural information, improving the precision of\npruning, thinning, and other automated orchard operations.", "published": "2025-07-02 17:24:18", "link": "http://arxiv.org/abs/2507.01912v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion", "abstract": "Objective: Clinical implementation of deformable image registration (DIR)\nrequires voxel-based spatial accuracy metrics such as manually identified\nlandmarks, which are challenging to implement for highly mobile\ngastrointestinal (GI) organs. To address this, patient-specific digital twins\n(DT) modeling temporally varying motion were created to assess the accuracy of\nDIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D\nsequences were generated from static 3D patient scans using published\nanalytical GI motion models through a semi-automated pipeline. Eleven datasets,\nincluding six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,\nand three contrast-enhanced CT scans. The motion amplitudes of the DTs were\nassessed against real patient stomach motion amplitudes extracted from\nindependent 4D MRI datasets. The generated DTs were then used to assess six\ndifferent DIR methods using target registration error, Dice similarity\ncoefficient, and the 95th percentile Hausdorff distance using summary metrics\nand voxel-level granular visualizations. Finally, for a subset of T2w MRI scans\nfrom patients treated with MR-guided radiation therapy, dose distributions were\nwarped and accumulated to assess dose warping errors, including evaluations of\nDIR performance in both low- and high-dose regions for patient-specific error\nestimation. Main results: Our proposed pipeline synthesized DTs modeling\nrealistic GI motion, achieving mean and maximum motion amplitudes and a mean\nlog Jacobian determinant within 0.8 mm and 0.01, respectively, similar to\npublished real-patient gastric motion data. It also enables the extraction of\ndetailed quantitative DIR performance metrics and rigorous validation of dose\nmapping accuracy. Significance: The pipeline enables rigorously testing DIR\ntools for dynamic, anatomically complex regions enabling granular spatial and\ndosimetric accuracies.", "published": "2025-07-02 17:22:47", "link": "http://arxiv.org/abs/2507.01909v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "abstract": "Instruction-based image editing (IIE) has advanced rapidly with the success\nof diffusion models. However, existing efforts primarily focus on simple and\nexplicit instructions to execute editing operations such as adding, deleting,\nmoving, or swapping objects. They struggle to handle more complex implicit\nhypothetical instructions that require deeper reasoning to infer plausible\nvisual changes and user intent. Additionally, current datasets provide limited\nsupport for training and evaluating reasoning-aware editing capabilities.\nArchitecturally, these methods also lack mechanisms for fine-grained detail\nextraction that support such reasoning. To address these limitations, we\npropose Reason50K, a large-scale dataset specifically curated for training and\nevaluating hypothetical instruction reasoning image editing, along with\nReasonBrain, a novel framework designed to reason over and execute implicit\nhypothetical instructions across diverse scenarios. Reason50K includes over 50K\nsamples spanning four key reasoning scenarios: Physical, Temporal, Causal, and\nStory reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)\nfor editing guidance generation and a diffusion model for image synthesis,\nincorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture\ndetailed visual and textual semantics essential for supporting instruction\nreasoning. To mitigate the semantic loss, we further introduce a Cross-Modal\nEnhancer (CME) that enables rich interactions between the fine-grained cues and\nMLLM-derived features. Extensive experiments demonstrate that ReasonBrain\nconsistently outperforms state-of-the-art baselines on reasoning scenarios\nwhile exhibiting strong zero-shot generalization to conventional IIE tasks. Our\ndataset and code will be released publicly.", "published": "2025-07-02 17:22:21", "link": "http://arxiv.org/abs/2507.01908v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification", "abstract": "Current lifelong person re-identification (LReID) methods predominantly rely\non fully labeled data streams. However, in real-world scenarios where\nannotation resources are limited, a vast amount of unlabeled data coexists with\nscarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID)\nproblem where LReID methods suffer severe performance degradation. Existing\nLReID methods, even when combined with semi-supervised strategies, suffer from\nlimited long-term adaptation performance due to struggling with the noisy\nknowledge occurring during unlabeled data utilization. In this paper, we\npioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing\nPrototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key\ninnovation lies in establishing a self-reinforcing cycle between dynamic\nprototype-guided pseudo-label generation and new-old knowledge collaborative\npurification to enhance the utilization of unlabeled data. Specifically,\nlearnable identity prototypes are introduced to dynamically capture the\nidentity distributions and generate high-quality pseudo-labels. Then, the\ndual-knowledge cooperation scheme integrates current model specialization and\nhistorical model generalization, refining noisy pseudo-labels. Through this\ncyclic design, reliable pseudo-labels are progressively mined to improve\ncurrent-stage learning and ensure positive knowledge propagation over long-term\nlearning. Experiments on the established Semi-LReID benchmarks show that our\nSPRED achieves state-of-the-art performance. Our source code is available at\nhttps://github.com/zhoujiahuan1991/ICCV2025-SPRED", "published": "2025-07-02 16:53:39", "link": "http://arxiv.org/abs/2507.01884v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Future Slot Prediction for Unsupervised Object Discovery in Surgical Video", "abstract": "Object-centric slot attention is an emerging paradigm for unsupervised\nlearning of structured, interpretable object-centric representations (slots).\nThis enables effective reasoning about objects and events at a low\ncomputational cost and is thus applicable to critical healthcare applications,\nsuch as real-time interpretation of surgical video. The heterogeneous scenes in\nreal-world applications like surgery are, however, difficult to parse into a\nmeaningful set of slots. Current approaches with an adaptive slot count perform\nwell on images, but their performance on surgical videos is low. To address\nthis challenge, we propose a dynamic temporal slot transformer (DTST) module\nthat is trained both for temporal reasoning and for predicting the optimal\nfuture slot initialization. The model achieves state-of-the-art performance on\nmultiple surgical databases, demonstrating that unsupervised object-centric\nmethods can be applied to real-world data and become part of the common arsenal\nin healthcare applications.", "published": "2025-07-02 16:52:16", "link": "http://arxiv.org/abs/2507.01882v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "abstract": "Low-dose computed tomography (LDCT) imaging employed in lung cancer screening\n(LCS) programs is increasing in uptake worldwide. LCS programs herald a\ngenerational opportunity to simultaneously detect cancer and non-cancer-related\nearly-stage lung disease. Yet these efforts are hampered by a shortage of\nradiologists to interpret scans at scale. Here, we present TANGERINE, a\ncomputationally frugal, open-source vision foundation model for volumetric LDCT\nanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE can\nbe fine-tuned off the shelf for a wide range of disease-specific tasks with\nlimited computational resources and training data. Relative to models trained\nfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,\nthereby requiring significantly fewer GPU hours, and displays strong label\nefficiency, achieving comparable or superior performance with a fraction of\nfine-tuning data. Pretrained using self-supervised learning on over 98,000\nthoracic LDCTs, including the UK's largest LCS initiative to date and 27 public\ndatasets, TANGERINE achieves state-of-the-art performance across 14 disease\nclassification tasks, including lung cancer and multiple respiratory diseases,\nwhile generalising robustly across diverse clinical centres. By extending a\nmasked autoencoder framework to 3D imaging, TANGERINE offers a scalable\nsolution for LDCT analysis, departing from recent closed, resource-intensive\nmodels by combining architectural simplicity, public availability, and modest\ncomputational requirements. Its accessible, open-source lightweight design lays\nthe foundation for rapid integration into next-generation medical imaging tools\nthat could transform LCS initiatives, allowing them to pivot from a singular\nfocus on lung cancer detection to comprehensive respiratory disease management\nin high-risk populations.", "published": "2025-07-02 16:52:10", "link": "http://arxiv.org/abs/2507.01881v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices", "abstract": "Recent advancements in deep neural networks have driven significant progress\nin image enhancement (IE). However, deploying deep learning models on\nresource-constrained platforms, such as mobile devices, remains challenging due\nto high computation and memory demands. To address these challenges and\nfacilitate real-time IE on mobile, we introduce an extremely lightweight\nConvolutional Neural Network (CNN) framework with around 4K parameters. Our\napproach integrates reparameterization with an Incremental Weight Optimization\nstrategy to ensure efficiency. Additionally, we enhance performance with a\nFeature Self-Transform module and a Hierarchical Dual-Path Attention mechanism,\noptimized with a Local Variance-Weighted loss. With this efficient framework,\nwe are the first to achieve real-time IE inference at up to 1,100 frames per\nsecond (FPS) while delivering competitive image quality, achieving the best\ntrade-off between speed and performance across multiple IE tasks. The code will\nbe available at https://github.com/AVC2-UESTC/MobileIE.git.", "published": "2025-07-02 15:53:44", "link": "http://arxiv.org/abs/2507.01838v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views", "abstract": "Hyperspectral reconstruction (HSR) from RGB images is a fundamentally\nill-posed problem due to severe spectral information loss. Existing approaches\ntypically rely on a single RGB image, limiting reconstruction accuracy. In this\nwork, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR)\nframework that leverages a triple-camera smartphone system, where two lenses\nare equipped with carefully selected spectral filters. Our configuration,\ngrounded in theoretical and empirical analysis, enables richer and more diverse\nspectral observations than conventional single-camera setups. To support this\nnew paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising\naligned images from three smartphone cameras and a hyperspectral reference\ncamera across diverse scenes. We show that the proposed HSR model achieves\nconsistent improvements over existing methods on the newly proposed benchmark.\nIn a nutshell, our setup allows 30% towards more accurately estimated spectra\ncompared to an ordinary RGB camera. Our findings suggest that multi-view\nspectral filtering with commodity hardware can unlock more accurate and\npractical hyperspectral imaging solutions.", "published": "2025-07-02 15:49:12", "link": "http://arxiv.org/abs/2507.01835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Autoadaptive Medical Segment Anything Model", "abstract": "Medical image segmentation is a key task in the imaging workflow, influencing\nmany image-based decisions. Traditional, fully-supervised segmentation models\nrely on large amounts of labeled training data, typically obtained through\nmanual annotation, which can be an expensive, time-consuming, and error-prone\nprocess. This signals a need for accurate, automatic, and annotation-efficient\nmethods of training these models. We propose ADA-SAM (automated,\ndomain-specific, and adaptive segment anything model), a novel multitask\nlearning framework for medical image segmentation that leverages class\nactivation maps from an auxiliary classifier to guide the predictions of the\nsemi-supervised segmentation branch, which is based on the Segment Anything\n(SAM) framework. Additionally, our ADA-SAM model employs a novel gradient\nfeedback mechanism to create a learnable connection between the segmentation\nand classification branches by using the segmentation gradients to guide and\nimprove the classification predictions. We validate ADA-SAM on real-world\nclinical data collected during rehabilitation trials, and demonstrate that our\nproposed method outperforms both fully-supervised and semi-supervised baselines\nby double digits in limited label settings. Our code is available at:\nhttps://github.com/tbwa233/ADA-SAM.", "published": "2025-07-02 15:44:32", "link": "http://arxiv.org/abs/2507.01828v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction", "abstract": "Accurately predicting the future trajectories of traffic agents is essential\nin autonomous driving. However, due to the inherent imbalance in trajectory\ndistributions, tail data in natural datasets often represents more complex and\nhazardous scenarios. Existing studies typically rely solely on a base model's\nprediction error, without considering the diversity and uncertainty of\nlong-tail trajectory patterns. We propose an adaptive momentum and decoupled\ncontrastive learning framework (AMD), which integrates unsupervised and\nsupervised contrastive learning strategies. By leveraging an improved momentum\ncontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,\nour framework enhances the model's ability to recognize rare and complex\ntrajectories. Additionally, we design four types of trajectory random\naugmentation methods and introduce an online iterative clustering strategy,\nallowing the model to dynamically update pseudo-labels and better adapt to the\ndistributional shifts in long-tail data. We propose three different criteria to\ndefine long-tail trajectories and conduct extensive comparative experiments on\nthe nuScenes and ETH$/$UCY datasets. The results show that AMD not only\nachieves optimal performance in long-tail trajectory prediction but also\ndemonstrates outstanding overall prediction accuracy.", "published": "2025-07-02 15:20:40", "link": "http://arxiv.org/abs/2507.01801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision", "abstract": "3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the\nphysical world and perform spatial reasoning. Answer-centric supervision is a\ncommonly used training method for 3D VQA models. Many models that utilize this\nstrategy have achieved promising results in 3D VQA tasks. However, the\nanswer-centric approach only supervises the final output of models and allows\nmodels to develop reasoning pathways freely. The absence of supervision on the\nreasoning pathway enables the potential for developing superficial shortcuts\nthrough common patterns in question-answer pairs. Moreover, although\nslow-thinking methods advance large language models, they suffer from\nunderthinking. To address these issues, we propose \\textbf{HCNQA}, a 3D VQA\nmodel leveraging a hierarchical concentration narrowing supervision method. By\nmimicking the human process of gradually focusing from a broad area to specific\nobjects while searching for answers, our method guides the model to perform\nthree phases of concentration narrowing through hierarchical supervision. By\nsupervising key checkpoints on a general reasoning pathway, our method can\nensure the development of a rational and effective reasoning pathway. Extensive\nexperimental results demonstrate that our method can effectively ensure that\nthe model develops a rational reasoning pathway and performs better. The code\nis available at https://github.com/JianuoZhu/HCNQA.", "published": "2025-07-02 15:20:08", "link": "http://arxiv.org/abs/2507.01800v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Robust brain age estimation from structural MRI with contrastive learning", "abstract": "Estimating brain age from structural MRI has emerged as a powerful tool for\ncharacterizing normative and pathological aging. In this work, we explore\ncontrastive learning as a scalable and robust alternative to supervised\napproaches for brain age estimation. We introduce a novel contrastive loss\nfunction, $\\mathcal{L}^{exp}$, and evaluate it across multiple public\nneuroimaging datasets comprising over 20,000 scans. Our experiments reveal four\nkey findings. First, scaling pre-training on diverse, multi-site data\nconsistently improves generalization performance, cutting external mean\nabsolute error (MAE) nearly in half. Second, $\\mathcal{L}^{exp}$ is robust to\nsite-related confounds, maintaining low scanner-predictability as training size\nincreases. Third, contrastive models reliably capture accelerated aging in\npatients with cognitive impairment and Alzheimer's disease, as shown through\nbrain age gap analysis, ROC curves, and longitudinal trends. Lastly, unlike\nsupervised baselines, $\\mathcal{L}^{exp}$ maintains a strong correlation\nbetween brain age accuracy and downstream diagnostic performance, supporting\nits potential as a foundation model for neuroimaging. These results position\ncontrastive learning as a promising direction for building generalizable and\nclinically meaningful brain representations.", "published": "2025-07-02 15:18:03", "link": "http://arxiv.org/abs/2507.01794v1", "categories": ["eess.IV", "cs.CV", "68T07", "I.2.6"], "primary_category": "eess.IV"}
{"title": "FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization", "abstract": "Subject-driven image generation plays a crucial role in applications such as\nvirtual try-on and poster design. Existing approaches typically fine-tune\npretrained generative models or apply LoRA-based adaptations for individual\nsubjects. However, these methods struggle with multi-subject personalization,\nas combining independently adapted modules often requires complex re-tuning or\njoint optimization. We present FreeLoRA, a simple and generalizable framework\nthat enables training-free fusion of subject-specific LoRA modules for\nmulti-subject personalization. Each LoRA module is adapted on a few images of a\nspecific subject using a Full Token Tuning strategy, where it is applied across\nall tokens in the prompt to encourage weakly supervised token-content\nalignment. At inference, we adopt Subject-Aware Inference, activating each\nmodule only on its corresponding subject tokens. This enables training-free\nfusion of multiple personalized subjects within a single image, while\nmitigating overfitting and mutual interference between subjects. Extensive\nexperiments show that FreeLoRA achieves strong performance in both subject\nfidelity and prompt consistency.", "published": "2025-07-02 15:16:59", "link": "http://arxiv.org/abs/2507.01792v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation", "abstract": "The transferability of adversarial examples poses a significant security\nchallenge for deep neural networks, which can be attacked without knowing\nanything about them. In this paper, we propose a new Segmented Gaussian Pyramid\n(SGP) attack method to enhance the transferability, particularly against\ndefense models. Unlike existing methods that generally focus on single-scale\nimages, our approach employs Gaussian filtering and three types of downsampling\nto construct a series of multi-scale examples. Then, the gradients of the loss\nfunction with respect to each scale are computed, and their average is used to\ndetermine the adversarial perturbations. The proposed SGP can be considered an\ninput transformation with high extensibility that is easily integrated into\nmost existing adversarial attacks. Extensive experiments demonstrate that in\ncontrast to the state-of-the-art methods, SGP significantly enhances attack\nsuccess rates against black-box defense models, with average attack success\nrates increasing by 2.3% to 32.6%, based only on transferability.", "published": "2025-07-02 15:16:30", "link": "http://arxiv.org/abs/2507.01791v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Hybrid Ensemble Learning Framework for Image-Based Solar Panel Classification", "abstract": "The installation of solar energy systems is on the rise, and therefore,\nappropriate maintenance techniques are required to be used in order to maintain\nmaximum performance levels. One of the major challenges is the automated\ndiscrimination between clean and dirty solar panels. This paper presents a\nnovel Dual Ensemble Neural Network (DENN) to classify solar panels using\nimage-based features. The suggested approach utilizes the advantages offered by\nvarious ensemble models by integrating them into a dual framework, aimed at\nimproving both classification accuracy and robustness. The DENN model is\nevaluated in comparison to current ensemble methods, showcasing its superior\nperformance across a range of assessment metrics. The proposed approach\nperforms the best compared to other methods and reaches state-of-the-art\naccuracy on experimental results for the Deep Solar Eye dataset, effectively\nserving predictive maintenance purposes in solar energy systems. It reveals the\npotential of hybrid ensemble learning techniques to further advance the\nprospects of automated solar panel inspections as a scalable solution to\nreal-world challenges.", "published": "2025-07-02 15:07:43", "link": "http://arxiv.org/abs/2507.01778v1", "categories": ["cs.IT", "cs.CV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis", "abstract": "Recent advances in large language models (LLMs) have spurred interests in\nencoding images as discrete tokens and leveraging autoregressive (AR)\nframeworks for visual generation. However, the quantization process in AR-based\nvisual generation models inherently introduces information loss that degrades\nimage fidelity. To mitigate this limitation, recent studies have explored to\nautoregressively predict continuous tokens. Unlike discrete tokens that reside\nin a structured and bounded space, continuous representations exist in an\nunbounded, high-dimensional space, making density estimation more challenging\nand increasing the risk of generating out-of-distribution artifacts. Based on\nthe above findings, this work introduces DisCon (Discrete-Conditioned\nContinuous Autoregressive Model), a novel framework that reinterprets discrete\ntokens as conditional signals rather than generation targets. By modeling the\nconditional probability of continuous representations conditioned on discrete\ntokens, DisCon circumvents the optimization challenges of continuous token\nmodeling while avoiding the information loss caused by quantization. DisCon\nachieves a gFID score of 1.38 on ImageNet 256$\\times$256 generation,\noutperforming state-of-the-art autoregressive approaches by a clear margin.", "published": "2025-07-02 14:33:52", "link": "http://arxiv.org/abs/2507.01756v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery", "abstract": "Glaciers are losing ice mass at unprecedented rates, increasing the need for\naccurate, year-round monitoring to understand frontal ablation, particularly\nthe factors driving the calving process. Deep learning models can extract\ncalving front positions from Synthetic Aperture Radar imagery to track seasonal\nice losses at the calving fronts of marine- and lake-terminating glaciers. The\ncurrent state-of-the-art model relies on ImageNet-pretrained weights. However,\nthey are suboptimal due to the domain shift between the natural images in\nImageNet and the specialized characteristics of remote sensing imagery, in\nparticular for Synthetic Aperture Radar imagery. To address this challenge, we\npropose two novel self-supervised multimodal pretraining techniques that\nleverage SSL4SAR, a new unlabeled dataset comprising 9,563 Sentinel-1 and 14\nSentinel-2 images of Arctic glaciers, with one optical image per glacier in the\ndataset. Additionally, we introduce a novel hybrid model architecture that\ncombines a Swin Transformer encoder with a residual Convolutional Neural\nNetwork (CNN) decoder. When pretrained on SSL4SAR, this model achieves a mean\ndistance error of 293 m on the \"CAlving Fronts and where to Find thEm\" (CaFFe)\nbenchmark dataset, outperforming the prior best model by 67 m. Evaluating an\nensemble of the proposed model on a multi-annotator study of the benchmark\ndataset reveals a mean distance error of 75 m, approaching the human\nperformance of 38 m. This advancement enables precise monitoring of seasonal\nchanges in glacier calving fronts.", "published": "2025-07-02 14:24:23", "link": "http://arxiv.org/abs/2507.01747v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans", "abstract": "Vision Transformers (ViTs) have gained significant popularity in the natural\nimage domain but have been less successful in 3D medical image segmentation.\nNevertheless, 3D ViTs are particularly interesting for large medical imaging\nvolumes due to their efficient self-supervised training within the masked\nautoencoder (MAE) framework, which enables the use of imaging data without the\nneed for expensive manual annotations. intracranial arterial calcification\n(IAC) is an imaging biomarker visible on routinely acquired CT scans linked to\nneurovascular diseases such as stroke and dementia, and automated IAC\nquantification could enable their large-scale risk assessment. We pre-train\nViTs with MAE and fine-tune them for IAC segmentation for the first time. To\ndevelop our models, we use highly heterogeneous data from a large clinical\ntrial, the third International Stroke Trial (IST-3). We evaluate key aspects of\nMAE pre-trained ViTs in IAC segmentation, and analyse the clinical\nimplications. We show: 1) our calibrated self-supervised ViT beats a strong\nsupervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial\nfor ViTs for IAC segmentation and interpolation upsampling with regular\nconvolutions is preferable to transposed convolutions for ViT-based models, and\n3) our ViTs increase robustness to higher slice thicknesses and improve risk\ngroup classification in a clinical scenario by 46%. Our code is available\nonline.", "published": "2025-07-02 14:23:22", "link": "http://arxiv.org/abs/2507.01744v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy", "abstract": "Referring Image Segmentation (RIS) is a challenging task that aims to segment\nobjects in an image based on natural language expressions. While prior studies\nhave predominantly concentrated on improving vision-language interactions and\nachieving fine-grained localization, a systematic analysis of the fundamental\nbottlenecks in existing RIS frameworks remains underexplored. To bridge this\ngap, we propose DeRIS, a novel framework that decomposes RIS into two key\ncomponents: perception and cognition. This modular decomposition facilitates a\nsystematic analysis of the primary bottlenecks impeding RIS performance. Our\nfindings reveal that the predominant limitation lies not in perceptual\ndeficiencies, but in the insufficient multi-modal cognitive capacity of current\nmodels. To mitigate this, we propose a Loopback Synergy mechanism, which\nenhances the synergy between the perception and cognition modules, thereby\nenabling precise segmentation while simultaneously improving robust image-text\ncomprehension. Additionally, we analyze and introduce a simple non-referent\nsample conversion data augmentation to address the long-tail distribution issue\nrelated to target existence judgement in general scenarios. Notably, DeRIS\ndemonstrates inherent adaptability to both non- and multi-referents scenarios\nwithout requiring specialized architectural modifications, enhancing its\ngeneral applicability. The codes and models are available at\nhttps://github.com/Dmmm1997/DeRIS.", "published": "2025-07-02 14:14:35", "link": "http://arxiv.org/abs/2507.01738v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion", "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a\nchallenging task due to the difficulty of modeling detailed interaction\ndynamics. Existing methods treat human and object motions independently,\nresulting in physically implausible and causally inconsistent behaviors. In\nthis work, we present HOI-Dyn, a novel framework that formulates HOI generation\nas a driver-responder system, where human actions drive object responses. At\nthe core of our method is a lightweight transformer-based interaction dynamics\nmodel that explicitly predicts how objects should react to human motion. To\nfurther enforce consistency, we introduce a residual-based dynamics loss that\nmitigates the impact of dynamics prediction errors and prevents misleading\noptimization signals. The dynamics model is used only during training,\npreserving inference efficiency. Through extensive qualitative and quantitative\nexperiments, we demonstrate that our approach not only enhances the quality of\nHOI generation but also establishes a feasible metric for evaluating the\nquality of generated interactions.", "published": "2025-07-02 14:13:48", "link": "http://arxiv.org/abs/2507.01737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "When Does Pruning Benefit Vision Representations?", "abstract": "Pruning is widely used to reduce the complexity of deep learning models, but\nits effects on interpretability and representation learning remain poorly\nunderstood. This paper investigates how pruning influences vision models across\nthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,\nand (iii) alignment with human perception. We first analyze different vision\nnetwork architectures to examine how varying sparsity levels affect feature\nattribution interpretability methods. Additionally, we explore whether pruning\npromotes more succinct and structured representations, potentially improving\nunsupervised object discovery by discarding redundant information while\npreserving essential features. Finally, we assess whether pruning enhances the\nalignment between model representations and human perception, investigating\nwhether sparser models focus on more discriminative features similarly to\nhumans. Our findings also reveal the presence of sweet spots, where sparse\nmodels exhibit higher interpretability, downstream generalization and human\nalignment. However, these spots highly depend on the network architectures and\ntheir size in terms of trainable parameters. Our results suggest a complex\ninterplay between these three dimensions, highlighting the importance of\ninvestigating when and how pruning benefits vision representations.", "published": "2025-07-02 13:57:49", "link": "http://arxiv.org/abs/2507.01722v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation", "abstract": "We consider weakly supervised segmentation where only a fraction of pixels\nhave ground truth labels (scribbles) and focus on a self-labeling approach\noptimizing relaxations of the standard unsupervised CRF/Potts loss on unlabeled\npixels. While WSSS methods can directly optimize such losses via gradient\ndescent, prior work suggests that higher-order optimization can improve network\ntraining by introducing hidden pseudo-labels and powerful CRF sub-problem\nsolvers, e.g. graph cut. However, previously used hard pseudo-labels can not\nrepresent class uncertainty or errors, which motivates soft self-labeling. We\nderive a principled auxiliary loss and systematically evaluate standard and new\nCRF relaxations (convex and non-convex), neighborhood systems, and terms\nconnecting network predictions with soft pseudo-labels. We also propose a\ngeneral continuous sub-problem solver. Using only standard architectures, soft\nself-labeling consistently improves scribble-based training and outperforms\nsignificantly more complex specialized WSSS systems. It can outperform full\npixel-precise supervision. Our general ideas apply to other weakly-supervised\nproblems/systems.", "published": "2025-07-02 13:52:34", "link": "http://arxiv.org/abs/2507.01721v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Using Wavelet Domain Fingerprints to Improve Source Camera Identification", "abstract": "Camera fingerprint detection plays a crucial role in source identification\nand image forensics, with wavelet denoising approaches proving to be\nparticularly effective in extracting sensor pattern noise (SPN). In this\narticle, we propose a modification to wavelet-based SPN extraction. Rather than\nconstructing the fingerprint as an image, we introduce the notion of a wavelet\ndomain fingerprint. This avoids the final inversion step of the denoising\nalgorithm and allows fingerprint comparisons to be made directly in the wavelet\ndomain. As such, our modification streamlines the extraction and comparison\nprocess. Experimental results on real-world datasets demonstrate that our\nmethod not only achieves higher detection accuracy but can also significantly\nimprove processing speed.", "published": "2025-07-02 13:43:24", "link": "http://arxiv.org/abs/2507.01712v1", "categories": ["cs.CV", "eess.IV", "stat.AP"], "primary_category": "cs.CV"}
{"title": "Component Adaptive Clustering for Generalized Category Discovery", "abstract": "Generalized Category Discovery (GCD) tackles the challenging problem of\ncategorizing unlabeled images into both known and novel classes within a\npartially labeled dataset, without prior knowledge of the number of unknown\ncategories. Traditional methods often rely on rigid assumptions, such as\npredefining the number of classes, which limits their ability to handle the\ninherent variability and complexity of real-world data. To address these\nshortcomings, we propose AdaGCD, a cluster-centric contrastive learning\nframework that incorporates Adaptive Slot Attention (AdaSlot) into the GCD\nframework. AdaSlot dynamically determines the optimal number of slots based on\ndata complexity, removing the need for predefined slot counts. This adaptive\nmechanism facilitates the flexible clustering of unlabeled data into known and\nnovel categories by dynamically allocating representational capacity. By\nintegrating adaptive representation with dynamic slot allocation, our method\ncaptures both instance-specific and spatially clustered features, improving\nclass discovery in open-world scenarios. Extensive experiments on public and\nfine-grained datasets validate the effectiveness of our framework, emphasizing\nthe advantages of leveraging spatial local information for category discovery\nin unlabeled image datasets.", "published": "2025-07-02 13:41:30", "link": "http://arxiv.org/abs/2507.01711v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition", "abstract": "Facial expression recognition (FER) in 3D and 4D domains presents a\nsignificant challenge in affective computing due to the complexity of spatial\nand temporal facial dynamics. Its success is crucial for advancing applications\nin human behavior understanding, healthcare monitoring, and human-computer\ninteraction. In this work, we propose FACET-VLM, a vision-language framework\nfor 3D/4D FER that integrates multiview facial representation learning with\nsemantic guidance from natural language prompts. FACET-VLM introduces three key\ncomponents: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,\nMultiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,\nand a multiview consistency loss to enforce structural coherence across views.\nOur model achieves state-of-the-art accuracy across multiple benchmarks,\nincluding BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend\nFACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,\ndemonstrating strong performance in capturing subtle, short-lived emotional\ncues. The extensive experimental results confirm the effectiveness and\nsubstantial contributions of each individual component within the framework.\nOverall, FACET-VLM offers a robust, extensible, and high-performing solution\nfor multimodal FER in both posed and spontaneous settings.", "published": "2025-07-02 12:55:09", "link": "http://arxiv.org/abs/2507.01673v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What does really matter in image goal navigation?", "abstract": "Image goal navigation requires two different skills: firstly, core navigation\nskills, including the detection of free space and obstacles, and taking\ndecisions based on an internal representation; and secondly, computing\ndirectional information by comparing visual observations to the goal image.\nCurrent state-of-the-art methods either rely on dedicated image-matching, or\npre-training of computer vision modules on relative pose estimation. In this\npaper, we study whether this task can be efficiently solved with end-to-end\ntraining of full agents with RL, as has been claimed by recent work. A positive\nanswer would have impact beyond Embodied AI and allow training of relative pose\nestimation from reward for navigation alone. In a large study we investigate\nthe effect of architectural choices like late fusion, channel stacking,\nspace-to-depth projections and cross-attention, and their role in the emergence\nof relative pose estimators from navigation training. We show that the success\nof recent methods is influenced up to a certain extent by simulator settings,\nleading to shortcuts in simulation. However, we also show that these\ncapabilities can be transferred to more realistic setting, up to some extend.\nWe also find evidence for correlations between navigation performance and\nprobed (emerging) relative pose estimation performance, an important sub skill.", "published": "2025-07-02 12:50:26", "link": "http://arxiv.org/abs/2507.01667v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "SPoT: Subpixel Placement of Tokens in Vision Transformers", "abstract": "Vision Transformers naturally accommodate sparsity, yet standard tokenization\nmethods confine features to discrete patch grids. This constraint prevents\nmodels from fully exploiting sparse regimes, forcing awkward compromises. We\npropose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that\npositions tokens continuously within images, effectively sidestepping\ngrid-based limitations. With our proposed oracle-guided search, we uncover\nsubstantial performance gains achievable with ideal subpixel token positioning,\ndrastically reducing the number of tokens necessary for accurate predictions\nduring inference. SPoT provides a new direction for flexible, efficient, and\ninterpretable ViT architectures, redefining sparsity as a strategic advantage\nrather than an imposed limitation.", "published": "2025-07-02 12:30:32", "link": "http://arxiv.org/abs/2507.01654v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather", "abstract": "Learning-based stereo matching models struggle in adverse weather conditions\ndue to the scarcity of corresponding training data and the challenges in\nextracting discriminative features from degraded images. These limitations\nsignificantly hinder zero-shot generalization to out-of-distribution weather\nconditions. In this paper, we propose \\textbf{RobuSTereo}, a novel framework\nthat enhances the zero-shot generalization of stereo matching models under\nadverse weather by addressing both data scarcity and feature extraction\nchallenges. First, we introduce a diffusion-based simulation pipeline with a\nstereo consistency module, which generates high-quality stereo data tailored\nfor adverse conditions. By training stereo matching models on our synthetic\ndatasets, we reduce the domain gap between clean and degraded images,\nsignificantly improving the models' robustness to unseen weather conditions.\nThe stereo consistency module ensures structural alignment across synthesized\nimage pairs, preserving geometric integrity and enhancing depth estimation\naccuracy. Second, we design a robust feature encoder that combines a\nspecialized ConvNet with a denoising transformer to extract stable and reliable\nfeatures from degraded images. The ConvNet captures fine-grained local\nstructures, while the denoising transformer refines global representations,\neffectively mitigating the impact of noise, low visibility, and weather-induced\ndistortions. This enables more accurate disparity estimation even under\nchallenging visual conditions. Extensive experiments demonstrate that\n\\textbf{RobuSTereo} significantly improves the robustness and generalization of\nstereo matching models across diverse adverse weather scenarios.", "published": "2025-07-02 12:27:53", "link": "http://arxiv.org/abs/2507.01653v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement", "abstract": "Vision Transformers (ViTs) are essential as foundation backbones in\nestablishing the visual comprehension capabilities of Multimodal Large Language\nModels (MLLMs). Although most ViTs achieve impressive performance through\nimage-text pair-based contrastive learning or self-supervised mechanisms, they\nstruggle to engage in connector-based co-training directly with LLMs due to\npotential parameter initialization conflicts and modality semantic gaps. To\naddress the above challenges, this paper proposes SAILViT, a gradual feature\nlearning-enhanced ViT for facilitating MLLMs to break through performance\nbottlenecks in complex multimodal interactions. SAILViT achieves\ncoarse-to-fine-grained feature alignment and world knowledge infusion with\ngradual feature refinement, which better serves target training demands. We\nperform thorough empirical analyses to confirm the powerful robustness and\ngeneralizability of SAILViT across different dimensions, including parameter\nsizes, model architectures, training strategies, and data scales. Equipped with\nSAILViT, existing MLLMs show significant and consistent performance\nimprovements on the OpenCompass benchmark across extensive downstream tasks.\nSAILViT series models are released at\nhttps://huggingface.co/BytedanceDouyinContent.", "published": "2025-07-02 12:17:23", "link": "http://arxiv.org/abs/2507.01643v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference", "abstract": "In recent years, compressed domain semantic inference has primarily relied on\nlearned image coding models optimized for mean squared error (MSE). However,\nMSE-oriented optimization tends to yield latent spaces with limited semantic\nrichness, which hinders effective semantic inference in downstream tasks.\nMoreover, achieving high performance with these models often requires\nfine-tuning the entire vision model, which is computationally intensive,\nespecially for large models. To address these problems, we introduce\nPerception-Oriented Latent Coding (POLC), an approach that enriches the\nsemantic content of latent features for high-performance compressed domain\nsemantic inference. With the semantically rich latent space, POLC requires only\na plug-and-play adapter for fine-tuning, significantly reducing the parameter\ncount compared to previous MSE-oriented methods. Experimental results\ndemonstrate that POLC achieves rate-perception performance comparable to\nstate-of-the-art generative image coding methods while markedly enhancing\nperformance in vision tasks, with minimal fine-tuning overhead. Code is\navailable at https://github.com/NJUVISION/POLC.", "published": "2025-07-02 11:21:38", "link": "http://arxiv.org/abs/2507.01608v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation", "abstract": "Diffusion-based video depth estimation methods have achieved remarkable\nsuccess with strong generalization ability. However, predicting depth for long\nvideos remains challenging. Existing methods typically split videos into\noverlapping sliding windows, leading to accumulated scale discrepancies across\ndifferent windows, particularly as the number of windows increases.\nAdditionally, these methods rely solely on 2D diffusion priors, overlooking the\ninherent 3D geometric structure of video depths, which results in geometrically\ninconsistent predictions. In this paper, we propose DepthSync, a novel,\ntraining-free framework using diffusion guidance to achieve scale- and\ngeometry-consistent depth predictions for long videos. Specifically, we\nintroduce scale guidance to synchronize the depth scale across windows and\ngeometry guidance to enforce geometric alignment within windows based on the\ninherent 3D constraints in video depths. These two terms work synergistically,\nsteering the denoising process toward consistent depth predictions. Experiments\non various datasets validate the effectiveness of our method in producing depth\nestimates with improved scale and geometry consistency, particularly for long\nvideos.", "published": "2025-07-02 11:11:51", "link": "http://arxiv.org/abs/2507.01603v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Controllable Real Image Denoising with Camera Parameters", "abstract": "Recent deep learning-based image denoising methods have shown impressive\nperformance; however, many lack the flexibility to adjust the denoising\nstrength based on the noise levels, camera settings, and user preferences. In\nthis paper, we introduce a new controllable denoising framework that adaptively\nremoves noise from images by utilizing information from camera parameters.\nSpecifically, we focus on ISO, shutter speed, and F-number, which are closely\nrelated to noise levels. We convert these selected parameters into a vector to\ncontrol and enhance the performance of the denoising network. Experimental\nresults show that our method seamlessly adds controllability to standard\ndenoising neural networks and improves their performance. Code is available at\nhttps://github.com/OBAKSA/CPADNet.", "published": "2025-07-02 10:57:33", "link": "http://arxiv.org/abs/2507.01587v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation", "abstract": "The production of high-quality 2D animation is highly labor-intensive\nprocess, as animators are currently required to draw and color a large number\nof frames by hand. We present SketchColour, the first sketch-to-colour pipeline\nfor 2D animation built on a diffusion transformer (DiT) backbone. By replacing\nthe conventional U-Net denoiser with a DiT-style architecture and injecting\nsketch information via lightweight channel-concatenation adapters accompanied\nwith LoRA finetuning, our method natively integrates conditioning without the\nparameter and memory bloat of a duplicated ControlNet, greatly reducing\nparameter count and GPU memory usage. Evaluated on the SAKUGA dataset,\nSketchColour outperforms previous state-of-the-art video colourization methods\nacross all metrics, despite using only half the training data of competing\nmodels. Our approach produces temporally coherent animations with minimal\nartifacts such as colour bleeding or object deformation. Our code is available\nat: https://bconstantine.github.io/SketchColour .", "published": "2025-07-02 10:57:16", "link": "http://arxiv.org/abs/2507.01586v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation", "abstract": "Remote sensing semantic segmentation must address both what the ground\nobjects are within an image and where they are located. Consequently,\nsegmentation models must ensure not only the semantic correctness of\nlarge-scale patches (low-frequency information) but also the precise\nlocalization of boundaries between patches (high-frequency information).\nHowever, most existing approaches rely heavily on discriminative learning,\nwhich excels at capturing low-frequency features, while overlooking its\ninherent limitations in learning high-frequency features for semantic\nsegmentation. Recent studies have revealed that diffusion generative models\nexcel at generating high-frequency details. Our theoretical analysis confirms\nthat the diffusion denoising process significantly enhances the model's ability\nto learn high-frequency features; however, we also observe that these models\nexhibit insufficient semantic inference for low-frequency features when guided\nsolely by the original image. Therefore, we integrate the strengths of both\ndiscriminative and generative learning, proposing the Integration of\nDiscriminative and diffusion-based Generative learning for Boundary Refinement\n(IDGBR) framework. The framework first generates a coarse segmentation map\nusing a discriminative backbone model. This map and the original image are fed\ninto a conditioning guidance network to jointly learn a guidance representation\nsubsequently leveraged by an iterative denoising diffusion process refining the\ncoarse segmentation. Extensive experiments across five remote sensing semantic\nsegmentation datasets (binary and multi-class segmentation) confirm our\nframework's capability of consistent boundary refinement for coarse results\nfrom diverse discriminative architectures. The source code will be available at\nhttps://github.com/KeyanHu-git/IDGBR.", "published": "2025-07-02 10:47:59", "link": "http://arxiv.org/abs/2507.01573v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling", "abstract": "We present our solution for the Multi-Source COVID-19 Detection Challenge,\nwhich classifies chest CT scans from four distinct medical centers. To address\nmulti-source variability, we employ the Spatial-Slice Feature Learning (SSFL)\nframework with Kernel-Density-based Slice Sampling (KDS). Our preprocessing\npipeline combines lung region extraction, quality control, and adaptive slice\nsampling to select eight representative slices per scan. We compare\nEfficientNet and Swin Transformer architectures on the validation set. The\nEfficientNet model achieves an F1-score of 94.68%, compared to the Swin\nTransformer's 93.34%. The results demonstrate the effectiveness of our\nKDS-based pipeline on multi-source data and highlight the importance of dataset\nbalance in multi-institutional medical imaging evaluation.", "published": "2025-07-02 10:27:59", "link": "http://arxiv.org/abs/2507.01564v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks", "abstract": "Recent work in continual learning has highlighted the beneficial effect of\nresampling weights in the last layer of a neural network (``zapping\"). Although\nempirical results demonstrate the effectiveness of this approach, the\nunderlying mechanisms that drive these improvements remain unclear. In this\nwork, we investigate in detail the pattern of learning and forgetting that take\nplace inside a convolutional neural network when trained in challenging\nsettings such as continual learning and few-shot transfer learning, with\nhandwritten characters and natural images. Our experiments show that models\nthat have undergone zapping during training more quickly recover from the shock\nof transferring to a new domain. Furthermore, to better observe the effect of\ncontinual learning in a multi-task setting we measure how each individual task\nis affected. This shows that, not only zapping, but the choice of optimizer can\nalso deeply affect the dynamics of learning and forgetting, causing complex\npatterns of synergy/interference between tasks to emerge when the model learns\nsequentially at transfer time.", "published": "2025-07-02 10:18:35", "link": "http://arxiv.org/abs/2507.01559v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Interpolation-Based Event Visual Data Filtering Algorithms", "abstract": "The field of neuromorphic vision is developing rapidly, and event cameras are\nfinding their way into more and more applications. However, the data stream\nfrom these sensors is characterised by significant noise. In this paper, we\npropose a method for event data that is capable of removing approximately 99\\%\nof noise while preserving the majority of the valid signal. We have proposed\nfour algorithms based on the matrix of infinite impulse response (IIR) filters\nmethod. We compared them on several event datasets that were further modified\nby adding artificially generated noise and noise recorded with dynamic vision\nsensor. The proposed methods use about 30KB of memory for a sensor with a\nresolution of 1280 x 720 and is therefore well suited for implementation in\nembedded devices.", "published": "2025-07-02 10:13:20", "link": "http://arxiv.org/abs/2507.01557v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization", "abstract": "Artificial intelligence (AI) has introduced numerous opportunities for human\nassistance and task automation in medicine. However, it suffers from poor\ngeneralization in the presence of shifts in the data distribution. In the\ncontext of AI-based computed tomography (CT) analysis, significant data\ndistribution shifts can be caused by changes in scanner manufacturer,\nreconstruction technique or dose. AI harmonization techniques can address this\nproblem by reducing distribution shifts caused by various acquisition settings.\nThis paper presents an open-source benchmark dataset containing CT scans of an\nanthropomorphic phantom acquired with various scanners and settings, which\npurpose is to foster the development of AI harmonization techniques. Using a\nphantom allows fixing variations attributed to inter- and intra-patient\nvariations. The dataset includes 1378 image series acquired with 13 scanners\nfrom 4 manufacturers across 8 institutions using a harmonized protocol as well\nas several acquisition doses. Additionally, we present a methodology, baseline\nresults and open-source code to assess image- and feature-level stability and\nliver tissue classification, promoting the development of AI harmonization\nstrategies.", "published": "2025-07-02 09:47:30", "link": "http://arxiv.org/abs/2507.01539v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking", "abstract": "The Vision Transformer (ViT) model has long struggled with the challenge of\nquadratic complexity, a limitation that becomes especially critical in unmanned\naerial vehicle (UAV) tracking systems, where data must be processed in real\ntime. In this study, we explore the recently proposed State-Space Model, Mamba,\nleveraging its computational efficiency and capability for long-sequence\nmodeling to effectively process dense image sequences in tracking tasks. First,\nwe highlight the issue of temporal inconsistency in existing Mamba-based\nmethods, specifically the failure to account for temporal continuity in the\nMamba scanning mechanism. Secondly, building upon this insight,we propose\nTrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model\nfor handling image sequence of tracking problem. In our framework, the mamba\nscan is performed in a nested way while independently process temporal and\nspatial coherent patch tokens. While the template frame is encoded as query\ntoken and utilized for tracking in every scan. Extensive experiments conducted\non five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves\nstate-of-the-art precision while offering noticeable higher speed in UAV\ntracking.", "published": "2025-07-02 09:40:37", "link": "http://arxiv.org/abs/2507.01535v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights", "abstract": "Sign Language Translation (SLT) has evolved significantly, moving from\nisolated recognition approaches to complex, continuous gloss-free translation\nsystems. This paper explores the impact of pose-based data preprocessing\ntechniques - normalization, interpolation, and augmentation - on SLT\nperformance. We employ a transformer-based architecture, adapting a modified T5\nencoder-decoder model to process pose representations. Through extensive\nablation studies on YouTubeASL and How2Sign datasets, we analyze how different\npreprocessing strategies affect translation accuracy. Our results demonstrate\nthat appropriate normalization, interpolation, and augmentation techniques can\nsignificantly improve model robustness and generalization abilities.\nAdditionally, we provide a deep analysis of the model's attentions and reveal\ninteresting behavior suggesting that adding a dedicated register token can\nimprove overall model performance. We publish our code on our GitHub\nrepository, including the preprocessed YouTubeASL data.", "published": "2025-07-02 09:36:26", "link": "http://arxiv.org/abs/2507.01532v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism", "abstract": "By incorporating visual inputs, Multimodal Large Language Models (MLLMs)\nextend LLMs to support visual reasoning. However, this integration also\nintroduces new vulnerabilities, making MLLMs susceptible to multimodal\njailbreak attacks and hindering their safe deployment.Existing defense methods,\nincluding Image-to-Text Translation, Safe Prompting, and Multimodal Safety\nTuning, attempt to address this by aligning multimodal inputs with LLMs'\nbuilt-in safeguards.Yet, they fall short in uncovering root causes of\nmultimodal vulnerabilities, particularly how harmful multimodal tokens trigger\njailbreak in MLLMs? Consequently, they remain vulnerable to text-driven\nmultimodal jailbreaks, often exhibiting overdefensive behaviors and imposing\nheavy training overhead.To bridge this gap, we present an comprehensive\nanalysis of where, how and which harmful multimodal tokens bypass safeguards in\nMLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers\nare responsible for inducing unsafe behaviors, highlighting the potential of\nprecisely removing a small subset of harmful tokens, without requiring safety\ntuning, can still effectively improve safety against jailbreaks. Motivated by\nthis, we propose Safe Prune-then-Restore (SafePTR), an training-free defense\nframework that selectively prunes harmful tokens at vulnerable layers while\nrestoring benign features at subsequent layers.Without incurring additional\ncomputational overhead, SafePTR significantly enhances the safety of MLLMs\nwhile preserving efficiency. Extensive evaluations across three MLLMs and five\nbenchmarks demonstrate SafePTR's state-of-the-art performance in mitigating\njailbreak risks without compromising utility.", "published": "2025-07-02 09:22:03", "link": "http://arxiv.org/abs/2507.01513v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation", "abstract": "Polyp segmentation in colonoscopy images is crucial for early detection and\ndiagnosis of colorectal cancer. However, this task remains a significant\nchallenge due to the substantial variations in polyp shape, size, and color, as\nwell as the high similarity between polyps and surrounding tissues, often\ncompounded by indistinct boundaries. While existing encoder-decoder CNN and\ntransformer-based approaches have shown promising results, they struggle with\nstable segmentation performance on polyps with weak or blurry boundaries. These\nmethods exhibit limited abilities to distinguish between polyps and non-polyps\nand capture essential boundary cues. Moreover, their generalizability still\nfalls short of meeting the demands of real-time clinical applications. To\naddress these limitations, we propose SAM-MaGuP, a groundbreaking approach for\nrobust polyp segmentation. By incorporating a boundary distillation module and\na 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels\nat resolving weak boundary challenges and amplifies feature learning through\nenriched global contextual interactions. Extensive evaluations across five\ndiverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods,\nachieving unmatched segmentation accuracy and robustness. Our key innovations,\na Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in\nthe field, pushing the boundaries of polyp segmentation to new heights.", "published": "2025-07-02 09:16:58", "link": "http://arxiv.org/abs/2507.01509v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation", "abstract": "Rectified Flow text-to-image models surpass diffusion models in image quality\nand text alignment, but adapting ReFlow for real-image editing remains\nchallenging. We propose a new real-image editing method for ReFlow by analyzing\nthe intermediate representations of multimodal transformer blocks and\nidentifying three key features. To extract these features from real images with\nsufficient structural preservation, we leverage mid-step latent, which is\ninverted only up to the mid-step. We then adapt attention during injection to\nimprove editability and enhance alignment to the target text. Our method is\ntraining-free, requires no user-provided mask, and can be applied even without\na source prompt. Extensive experiments on two benchmarks with nine baselines\ndemonstrate its superior performance over prior methods, further validated by\nhuman evaluations confirming a strong user preference for our approach.", "published": "2025-07-02 08:58:18", "link": "http://arxiv.org/abs/2507.01496v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AVC-DPO: Aligned Video Captioning via Direct Preference Optimization", "abstract": "Although video multimodal large language models (video MLLMs) have achieved\nsubstantial progress in video captioning tasks, it remains challenging to\nadjust the focal emphasis of video captions according to human preferences. To\naddress this limitation, we propose Aligned Video Captioning via Direct\nPreference Optimization (AVC-DPO), a post-training framework designed to\nenhance captioning capabilities in video MLLMs through preference alignment.\nOur approach designs enhanced prompts that specifically target temporal\ndynamics and spatial information-two key factors that humans care about when\nwatching a video-thereby incorporating human-centric preferences. AVC-DPO\nleverages the same foundation model's caption generation responses under varied\nprompt conditions to conduct preference-aware training and caption alignment.\nUsing this framework, we have achieved exceptional performance in the\nLOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achieving\nfirst place on the Video Detailed Captioning (VDC) benchmark according to the\nVDCSCORE evaluation metric.", "published": "2025-07-02 08:51:45", "link": "http://arxiv.org/abs/2507.01492v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What Really Matters for Robust Multi-Sensor HD Map Construction?", "abstract": "High-definition (HD) map construction methods are crucial for providing\nprecise and comprehensive static environmental information, which is essential\nfor autonomous driving systems. While Camera-LiDAR fusion techniques have shown\npromising results by integrating data from both modalities, existing approaches\nprimarily focus on improving model accuracy and often neglect the robustness of\nperception models, which is a critical aspect for real-world applications. In\nthis paper, we explore strategies to enhance the robustness of multi-modal\nfusion methods for HD map construction while maintaining high accuracy. We\npropose three key components: data augmentation, a novel multi-modal fusion\nmodule, and a modality dropout training strategy. These components are\nevaluated on a challenging dataset containing 10 days of NuScenes data. Our\nexperimental results demonstrate that our proposed methods significantly\nenhance the robustness of baseline methods. Furthermore, our approach achieves\nstate-of-the-art performance on the clean validation set of the NuScenes\ndataset. Our findings provide valuable insights for developing more robust and\nreliable HD map construction models, advancing their applicability in\nreal-world autonomous driving scenarios. Project website:\nhttps://robomap-123.github.io.", "published": "2025-07-02 08:46:27", "link": "http://arxiv.org/abs/2507.01484v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects", "abstract": "Visual pose tracking is playing an increasingly vital role in industrial\ncontexts in recent years. However, the pose tracking for industrial metal\nobjects remains a challenging task especially in the real world-environments,\ndue to the reflection characteristic of metal objects. To address this issue,\nwe propose a novel 6DoF pose tracking method based on active control points.\nThe method uses image control points to generate edge feature for optimization\nactively instead of 6DoF pose-based rendering, and serve them as optimization\nvariables. We also introduce an optimal control point regression method to\nimprove robustness. The proposed tracking method performs effectively in both\ndataset evaluation and real world tasks, providing a viable solution for\nreal-time tracking of industrial metal objects. Our source code is made\npublicly available at: https://github.com/tomatoma00/ACPTracking.", "published": "2025-07-02 08:42:21", "link": "http://arxiv.org/abs/2507.01478v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware", "abstract": "Methane is a potent greenhouse gas, and detecting its leaks early via\nhyperspectral satellite imagery can help mitigate climate change. Meanwhile,\nmany existing missions operate in manual tasking regimes only, thus missing\npotential events of interest. To overcome slow downlink rates cost-effectively,\nonboard detection is a viable solution. However, traditional methane\nenhancement methods are too computationally demanding for resource-limited\nonboard hardware. This work accelerates methane detection by focusing on\nefficient, low-power algorithms. We test fast target detection methods (ACE,\nCEM) that have not been previously used for methane detection and propose a\nMag1c-SAS - a significantly faster variant of the current state-of-the-art\nalgorithm for methane detection: Mag1c. To explore their true detection\npotential, we integrate them with a machine learning model (U-Net, LinkNet).\nOur results identify two promising candidates (Mag1c-SAS and CEM), both\nacceptably accurate for the detection of strong plumes and computationally\nefficient enough for onboard deployment: one optimized more for accuracy, the\nother more for speed, achieving up to ~100x and ~230x faster computation than\noriginal Mag1c on resource-limited hardware. Additionally, we propose and\nevaluate three band selection strategies. One of them can outperform the method\ntraditionally used in the field while using fewer channels, leading to even\nfaster processing without compromising accuracy. This research lays the\nfoundation for future advancements in onboard methane detection with minimal\nhardware requirements, improving timely data delivery. The produced code, data,\nand models are open-sourced and can be accessed from\nhttps://github.com/zaitra/methane-filters-benchmark.", "published": "2025-07-02 08:34:34", "link": "http://arxiv.org/abs/2507.01472v1", "categories": ["cs.CV", "cs.LG", "cs.PF"], "primary_category": "cs.CV"}
{"title": "Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think", "abstract": "REPA and its variants effectively mitigate training challenges in diffusion\nmodels by incorporating external visual representations from pretrained models,\nthrough alignment between the noisy hidden projections of denoising networks\nand foundational clean image representations. We argue that the external\nalignment, which is absent during the entire denoising inference process, falls\nshort of fully harnessing the potential of discriminative representations. In\nthis work, we propose a straightforward method called Representation\nEntanglement for Generation (REG), which entangles low-level image latents with\na single high-level class token from pretrained foundation models for\ndenoising. REG acquires the capability to produce coherent image-class pairs\ndirectly from pure noise, substantially improving both generation quality and\ntraining efficiency. This is accomplished with negligible additional inference\noverhead, requiring only one single additional token for denoising (<0.5\\%\nincrease in FLOPs and latency). The inference process concurrently reconstructs\nboth image latents and their corresponding global semantics, where the acquired\nsemantic knowledge actively guides and enhances the image generation process.\nOn ImageNet 256$\\times$256, SiT-XL/2 + REG demonstrates remarkable convergence\nacceleration, achieving $\\textbf{63}\\times$ and $\\textbf{23}\\times$ faster\ntraining than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,\nSiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA\ntrained for 4M iterations ($\\textbf{10}\\times$ longer). Code is available at:\nhttps://github.com/Martinser/REG.", "published": "2025-07-02 08:29:18", "link": "http://arxiv.org/abs/2507.01467v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes", "abstract": "Anomaly segmentation aims to identify Out-of-Distribution (OoD) anomalous\nobjects within images. Existing pixel-wise methods typically assign anomaly\nscores individually and employ a global thresholding strategy to segment\nanomalies. Despite their effectiveness, these approaches encounter significant\nchallenges in real-world applications: (1) neglecting spatial correlations\namong pixels within the same object, resulting in fragmented segmentation; (2)\nvariabil ity in anomaly score distributions across image regions, causing\nglobal thresholds to either generate false positives in background areas or\nmiss segments of anomalous objects. In this work, we introduce OoDDINO, a novel\nmulti-level anomaly segmentation framework designed to address these\nlimitations through a coarse-to-fine anomaly detection strategy. OoDDINO\ncombines an uncertainty-guided anomaly detection model with a pixel-level\nsegmentation model within a two-stage cascade architecture. Initially, we\npropose an Orthogonal Uncertainty-Aware Fusion Strategy (OUAFS) that\nsequentially integrates multiple uncertainty metrics with visual\nrepresentations, employing orthogonal constraints to strengthen the detection\nmodel's capacity for localizing anomalous regions accurately. Subsequently, we\ndevelop an Adaptive Dual-Threshold Network (ADT-Net), which dynamically\ngenerates region-specific thresholds based on object-level detection outputs\nand pixel-wise anomaly scores. This approach allows for distinct thresholding\nstrategies within foreground and background areas, achieving fine-grained\nanomaly segmentation. The proposed framework is compatible with other\npixel-wise anomaly detection models, which acts as a plug-in to boost the\nperformance. Extensive experiments on two benchmark datasets validate our\nframework's superiority and compatibility over state-of-the-art methods.", "published": "2025-07-02 08:15:11", "link": "http://arxiv.org/abs/2507.01455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration", "abstract": "Robust estimation is essential in correspondence-based Point Cloud\nRegistration (PCR). Existing methods using maximal clique search in\ncompatibility graphs achieve high recall but suffer from exponential time\ncomplexity, limiting their use in time-sensitive applications. To address this\nchallenge, we propose a fast and robust estimator, TurboReg, built upon a novel\nlightweight clique, TurboClique, and a highly parallelizable Pivot-Guided\nSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within a\nhighly-constrained compatibility graph. The lightweight nature of the 3-clique\nallows for efficient parallel searching, and the highly-constrained\ncompatibility graph ensures robust spatial consistency for stable\ntransformation estimation. Next, PGS selects matching pairs with high SC$^2$\nscores as pivots, effectively guiding the search toward TurboCliques with\nhigher inlier ratios. Moreover, the PGS algorithm has linear time complexity\nand is significantly more efficient than the maximal clique search with\nexponential time complexity. Extensive experiments show that TurboReg achieves\nstate-of-the-art performance across multiple real-world datasets, with\nsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,\nTurboReg (1K) operates $208.22\\times$ faster than 3DMAC while also achieving\nhigher recall. Our code is accessible at\n\\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}.", "published": "2025-07-02 07:50:24", "link": "http://arxiv.org/abs/2507.01439v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiffMark: Diffusion-based Robust Watermark Against Deepfakes", "abstract": "Deepfakes pose significant security and privacy threats through malicious\nfacial manipulations. While robust watermarking can aid in authenticity\nverification and source tracking, existing methods often lack the sufficient\nrobustness against Deepfake manipulations. Diffusion models have demonstrated\nremarkable performance in image generation, enabling the seamless fusion of\nwatermark with image during generation. In this study, we propose a novel\nrobust watermarking framework based on diffusion model, called DiffMark. By\nmodifying the training and sampling scheme, we take the facial image and\nwatermark as conditions to guide the diffusion model to progressively denoise\nand generate corresponding watermarked image. In the construction of facial\ncondition, we weight the facial image by a timestep-dependent factor that\ngradually reduces the guidance intensity with the decrease of noise, thus\nbetter adapting to the sampling process of diffusion model. To achieve the\nfusion of watermark condition, we introduce a cross information fusion (CIF)\nmodule that leverages a learnable embedding table to adaptively extract\nwatermark features and integrates them with image features via cross-attention.\nTo enhance the robustness of the watermark against Deepfake manipulations, we\nintegrate a frozen autoencoder during training phase to simulate Deepfake\nmanipulations. Additionally, we introduce Deepfake-resistant guidance that\nemploys specific Deepfake model to adversarially guide the diffusion sampling\nprocess to generate more robust watermarked images. Experimental results\ndemonstrate the effectiveness of the proposed DiffMark on typical Deepfakes.\nOur code will be available at https://github.com/vpsg-research/DiffMark.", "published": "2025-07-02 07:29:33", "link": "http://arxiv.org/abs/2507.01428v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention", "abstract": "Out-of-Distribution (OOD) detection is critical for safely deploying deep\nmodels in open-world environments, where inputs may lie outside the training\ndistribution. During inference on a model trained exclusively with\nIn-Distribution (ID) data, we observe a salient gradient phenomenon: around an\nID sample, the local gradient directions for \"enhancing\" that sample's\npredicted class remain relatively consistent, whereas OOD samples--unseen in\ntraining--exhibit disorganized or conflicting gradient directions in the same\nneighborhood. Motivated by this observation, we propose an inference-stage\ntechnique to short-circuit those feature coordinates that spurious gradients\nexploit to inflate OOD confidence, while leaving ID classification largely\nintact. To circumvent the expense of recomputing the logits after this gradient\nshort-circuit, we further introduce a local first-order approximation that\naccurately captures the post-modification outputs without a second forward\npass. Experiments on standard OOD benchmarks show our approach yields\nsubstantial improvements. Moreover, the method is lightweight and requires\nminimal changes to the standard inference pipeline, offering a practical path\ntoward robust OOD detection in real-world applications.", "published": "2025-07-02 07:18:09", "link": "http://arxiv.org/abs/2507.01417v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning", "abstract": "An image captioning model flexibly switching its language pattern, e.g.,\ndescriptiveness and length, should be useful since it can be applied to diverse\napplications. However, despite the dramatic improvement in generative\nvision-language models, fine-grained control over the properties of generated\ncaptions is not easy due to two reasons: (i) existing models are not given the\nproperties as a condition during training and (ii) existing models cannot\nsmoothly transition its language pattern from one state to the other. Given\nthis challenge, we propose a new approach, CaptionSmiths, to acquire a single\ncaptioning model that can handle diverse language patterns. First, our approach\nquantifies three properties of each caption, length, descriptiveness, and\nuniqueness of a word, as continuous scalar values, without human annotation.\nGiven the values, we represent the conditioning via interpolation between two\nendpoint vectors corresponding to the extreme states, e.g., one for a very\nshort caption and one for a very long caption. Empirical results demonstrate\nthat the resulting model can smoothly change the properties of the output\ncaptions and show higher lexical alignment than baselines. For instance,\nCaptionSmiths reduces the error in controlling caption length by 506\\% despite\nbetter lexical alignment. Code will be available on\nhttps://github.com/omron-sinicx/captionsmiths.", "published": "2025-07-02 07:02:45", "link": "http://arxiv.org/abs/2507.01409v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps", "abstract": "Most autonomous cars rely on the availability of high-definition (HD) maps.\nCurrent research aims to address this constraint by directly predicting HD map\nelements from onboard sensors and reasoning about the relationships between the\npredicted map and traffic elements. Despite recent advancements, the coherent\nonline construction of HD maps remains a challenging endeavor, as it\nnecessitates modeling the high complexity of road topologies in a unified and\nconsistent manner. To address this challenge, we propose a coherent approach to\npredict lane segments and their corresponding topology, as well as road\nboundaries, all by leveraging prior map information represented by commonly\navailable standard-definition (SD) maps. We propose a network architecture,\nwhich leverages hybrid lane segment encodings comprising prior information and\ndenoising techniques to enhance training stability and performance.\nFurthermore, we facilitate past frames for temporal consistency. Our\nexperimental evaluation demonstrates that our approach outperforms previous\nmethods by a large margin, highlighting the benefits of our modeling scheme.", "published": "2025-07-02 06:26:17", "link": "http://arxiv.org/abs/2507.01397v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases", "abstract": "Talking head generation is gaining significant importance across various\ndomains, with a growing demand for high-quality rendering. However, existing\nmethods often suffer from identity leakage (IL) and rendering artifacts (RA),\nparticularly in extreme cases. Through an in-depth analysis of previous\napproaches, we identify two key insights: (1) IL arises from identity\ninformation embedded within motion features, and (2) this identity information\ncan be leveraged to address RA. Building on these findings, this paper\nintroduces FixTalk, a novel framework designed to simultaneously resolve both\nissues for high-quality talking head generation. Firstly, we propose an\nEnhanced Motion Indicator (EMI) to effectively decouple identity information\nfrom motion features, mitigating the impact of IL on generated talking heads.\nTo address RA, we introduce an Enhanced Detail Indicator (EDI), which utilizes\nthe leaked identity information to supplement missing details, thus fixing the\nartifacts. Extensive experiments demonstrate that FixTalk effectively mitigates\nIL and RA, achieving superior performance compared to state-of-the-art methods.", "published": "2025-07-02 06:10:52", "link": "http://arxiv.org/abs/2507.01390v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy", "abstract": "The limited availability of bronchoscopy images makes image synthesis\nparticularly interesting for training deep learning models. Robust image\ntranslation across different domains -- virtual bronchoscopy, phantom as well\nas in-vivo and ex-vivo image data -- is pivotal for clinical applications. This\npaper proposes BronchoGAN introducing anatomical constraints for image-to-image\ntranslation being integrated into a conditional GAN. In particular, we force\nbronchial orifices to match across input and output images. We further propose\nto use foundation model-generated depth images as intermediate representation\nensuring robustness across a variety of input domains establishing models with\nsubstantially less reliance on individual training datasets. Moreover our\nintermediate depth image representation allows to easily construct paired image\ndata for training. Our experiments showed that input images from different\ndomains (e.g. virtual bronchoscopy, phantoms) can be successfully translated to\nimages mimicking realistic human airway appearance. We demonstrated that\nanatomical settings (i.e. bronchial orifices) can be robustly preserved with\nour approach which is shown qualitatively and quantitatively by means of\nimproved FID, SSIM and dice coefficients scores. Our anatomical constraints\nenabled an improvement in the Dice coefficient of up to 0.43 for synthetic\nimages. Through foundation models for intermediate depth representations,\nbronchial orifice segmentation integrated as anatomical constraints into\nconditional GANs we are able to robustly translate images from different\nbronchoscopy input domains. BronchoGAN allows to incorporate public CT scan\ndata (virtual bronchoscopy) in order to generate large-scale bronchoscopy image\ndatasets with realistic appearance. BronchoGAN enables to bridge the gap of\nmissing public bronchoscopy images.", "published": "2025-07-02 06:04:00", "link": "http://arxiv.org/abs/2507.01387v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing", "abstract": "The weakly-supervised audio-visual video parsing (AVVP) aims to predict all\nmodality-specific events and locate their temporal boundaries. Despite\nsignificant progress, due to the limitations of the weakly-supervised and the\ndeficiencies of the model architecture, existing methods are lacking in\nsimultaneously improving both the segment-level prediction and the event-level\nprediction. In this work, we propose a audio-visual Mamba network with pseudo\nlabeling aUGmentation (MUG) for emphasising the uniqueness of each segment and\nexcluding the noise interference from the alternate modalities. Specifically,\nwe annotate some of the pseudo-labels based on previous work. Using unimodal\npseudo-labels, we perform cross-modal random combinations to generate new data,\nwhich can enhance the model's ability to parse various segment-level event\ncombinations. For feature processing and interaction, we employ a audio-visual\nmamba network. The AV-Mamba enhances the ability to perceive different segments\nand excludes additional modal noise while sharing similar modal information.\nOur extensive experiments demonstrate that MUG improves state-of-the-art\nresults on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of\nvisual Segment-level and audio Segment-level metrics). Our code is available at\nhttps://github.com/WangLY136/MUG.", "published": "2025-07-02 06:00:49", "link": "http://arxiv.org/abs/2507.01384v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Active Measurement: Efficient Estimation at Scale", "abstract": "AI has the potential to transform scientific discovery by analyzing vast\ndatasets with little human effort. However, current workflows often do not\nprovide the accuracy or statistical guarantees that are needed. We introduce\nactive measurement, a human-in-the-loop AI framework for scientific\nmeasurement. An AI model is used to predict measurements for individual units,\nwhich are then sampled for human labeling using importance sampling. With each\nnew set of human labels, the AI model is improved and an unbiased Monte Carlo\nestimate of the total measurement is refined. Active measurement can provide\nprecise estimates even with an imperfect AI model, and requires little human\neffort when the AI model is very accurate. We derive novel estimators,\nweighting schemes, and confidence intervals, and show that active measurement\nreduces estimation error compared to alternatives in several measurement tasks.", "published": "2025-07-02 05:20:32", "link": "http://arxiv.org/abs/2507.01372v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Activation Reward Models for Few-Shot Model Alignment", "abstract": "Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to\nhuman preferences is a central challenge in improving the quality of the\nmodels' generative outputs for real-world applications. A common approach is to\nuse reward modeling to encode preferences, enabling alignment via post-training\nusing reinforcement learning. However, traditional reward modeling is not\neasily adaptable to new preferences because it requires a separate reward\nmodel, commonly trained on large preference datasets. To address this, we\nintroduce Activation Reward Models (Activation RMs) -- a novel few-shot reward\nmodeling method that leverages activation steering to construct well-aligned\nreward signals using minimal supervision and no additional model finetuning.\nActivation RMs outperform existing few-shot reward modeling approaches such as\nLLM-as-a-judge with in-context learning, voting-based scoring, and token\nprobability scoring on standard reward modeling benchmarks. Furthermore, we\ndemonstrate the effectiveness of Activation RMs in mitigating reward hacking\nbehaviors, highlighting their utility for safety-critical applications. Toward\nthis end, we propose PreferenceHack, a novel few-shot setting benchmark, the\nfirst to test reward models on reward hacking in a paired preference format.\nFinally, we show that Activation RM achieves state-of-the-art performance on\nthis benchmark, surpassing even GPT-4o.", "published": "2025-07-02 05:10:29", "link": "http://arxiv.org/abs/2507.01368v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation", "abstract": "Physical adversarial attack methods expose the vulnerabilities of deep neural\nnetworks and pose a significant threat to safety-critical scenarios such as\nautonomous driving. Camouflage-based physical attack is a more promising\napproach compared to the patch-based attack, offering stronger adversarial\neffectiveness in complex physical environments. However, most prior work relies\non mesh priors of the target object and virtual environments constructed by\nsimulators, which are time-consuming to obtain and inevitably differ from the\nreal world. Moreover, due to the limitations of the backgrounds in training\nimages, previous methods often fail to produce multi-view robust adversarial\ncamouflage and tend to fall into sub-optimal solutions. Due to these reasons,\nprior work lacks adversarial effectiveness and robustness across diverse\nviewpoints and physical environments. We propose a physical attack framework\nbased on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and\nprecise reconstruction with few images, along with photo-realistic rendering\ncapabilities. Our framework further enhances cross-view robustness and\nadversarial effectiveness by preventing mutual and self-occlusion among\nGaussians and employing a min-max optimization approach that adjusts the\nimaging background of each viewpoint, helping the algorithm filter out\nnon-robust adversarial features. Extensive experiments validate the\neffectiveness and superiority of PGA. Our code is available\nat:https://github.com/TRLou/PGA.", "published": "2025-07-02 05:10:16", "link": "http://arxiv.org/abs/2507.01367v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model", "abstract": "The mixture-of-experts (MoE), which replaces dense models with sparse\narchitectures, has gained attention in large vision-language models (LVLMs) for\nachieving comparable performance with fewer activated parameters. Existing MoE\nframeworks for LVLMs focus on token-to-expert routing (TER), encouraging\ndifferent experts to specialize in processing distinct tokens. However, these\nframeworks often rely on the load balancing mechanism, overlooking the inherent\ndistributional differences between vision and language. To this end, we propose\na Long-Tailed Distribution-aware Router (LTDR) for vision-language TER,\ntackling two challenges: (1) Distribution-aware router for modality-specific\nrouting. We observe that language TER follows a uniform distribution, whereas\nvision TER exhibits a long-tailed distribution. This discrepancy necessitates\ndistinct routing strategies tailored to each modality. (2) Enhancing expert\nactivation for vision tail tokens. Recognizing the importance of vision tail\ntokens, we introduce an oversampling-like strategy by increasing the number of\nactivated experts for these tokens. Experiments on extensive benchmarks\nvalidate the effectiveness of our approach.", "published": "2025-07-02 04:38:12", "link": "http://arxiv.org/abs/2507.01351v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation", "abstract": "We introduce Generalized Test-Time Augmentation (GTTA), a highly effective\nmethod for improving the performance of a trained model, which unlike other\nexisting Test-Time Augmentation approaches from the literature is general\nenough to be used off-the-shelf for many vision and non-vision tasks, such as\nclassification, regression, image segmentation and object detection. By\napplying a new general data transformation, that randomly perturbs multiple\ntimes the PCA subspace projection of a test input, GTTA forms robust ensembles\nat test time in which, due to sound statistical properties, the structural and\nsystematic noises in the initial input data is filtered out and final estimator\nerrors are reduced. Different from other existing methods, we also propose a\nfinal self-supervised learning stage in which the ensemble output, acting as an\nunsupervised teacher, is used to train the initial single student model, thus\nreducing significantly the test time computational cost, at no loss in\naccuracy. Our tests and comparisons to strong TTA approaches and SoTA models on\nvarious vision and non-vision well-known datasets and tasks, such as image\nclassification and segmentation, speech recognition and house price prediction,\nvalidate the generality of the proposed GTTA. Furthermore, we also prove its\neffectiveness on the more specific real-world task of salmon segmentation and\ndetection in low-visibility underwater videos, for which we introduce\nDeepSalmon, the largest dataset of its kind in the literature.", "published": "2025-07-02 04:30:04", "link": "http://arxiv.org/abs/2507.01347v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Camera-Agnostic White-Balance Preferences", "abstract": "The image signal processor (ISP) pipeline in modern cameras consists of\nseveral modules that transform raw sensor data into visually pleasing images in\na display color space. Among these, the auto white balance (AWB) module is\nessential for compensating for scene illumination. However, commercial AWB\nsystems often strive to compute aesthetic white-balance preferences rather than\naccurate neutral color correction. While learning-based methods have improved\nAWB accuracy, they typically struggle to generalize across different camera\nsensors -- an issue for smartphones with multiple cameras. Recent work has\nexplored cross-camera AWB, but most methods remain focused on achieving neutral\nwhite balance. In contrast, this paper is the first to address aesthetic\nconsistency by learning a post-illuminant-estimation mapping that transforms\nneutral illuminant corrections into aesthetically preferred corrections in a\ncamera-agnostic space. Once trained, our mapping can be applied after any\nneutral AWB module to enable consistent and stylized color rendering across\nunseen cameras. Our proposed model is lightweight -- containing only $\\sim$500\nparameters -- and runs in just 0.024 milliseconds on a typical flagship mobile\nCPU. Evaluated on a dataset of 771 smartphone images from three different\ncameras, our method achieves state-of-the-art performance while remaining fully\ncompatible with existing cross-camera AWB techniques, introducing minimal\ncomputational and memory overhead.", "published": "2025-07-02 04:11:01", "link": "http://arxiv.org/abs/2507.01342v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics-informed Ground Reaction Dynamics from Human Motion Capture", "abstract": "Body dynamics are crucial information for the analysis of human motions in\nimportant research fields, ranging from biomechanics, sports science to\ncomputer vision and graphics. Modern approaches collect the body dynamics,\nexternal reactive force specifically, via force plates, synchronizing with\nhuman motion capture data, and learn to estimate the dynamics from a black-box\ndeep learning model. Being specialized devices, force plates can only be\ninstalled in laboratory setups, imposing a significant limitation on the\nlearning of human dynamics. To this end, we propose a novel method for\nestimating human ground reaction dynamics directly from the more reliable\nmotion capture data with physics laws and computational simulation as\nconstrains. We introduce a highly accurate and robust method for computing\nground reaction forces from motion capture data using Euler's integration\nscheme and PD algorithm. The physics-based reactive forces are used to inform\nthe learning model about the physics-informed motion dynamics thus improving\nthe estimation accuracy. The proposed approach was tested on the GroundLink\ndataset, outperforming the baseline model on: 1) the ground reaction force\nestimation accuracy compared to the force plates measurement; and 2) our\nsimulated root trajectory precision. The implementation code is available at\nhttps://github.com/cuongle1206/Phys-GRD", "published": "2025-07-02 04:02:16", "link": "http://arxiv.org/abs/2507.01340v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction", "abstract": "MR imaging techniques are of great benefit to disease diagnosis. However, due\nto the limitation of MR devices, significant intensity inhomogeneity often\nexists in imaging results, which impedes both qualitative and quantitative\nmedical analysis. Recently, several unsupervised deep learning-based models\nhave been proposed for MR image improvement. However, these models merely\nconcentrate on global appearance learning, and neglect constraints from image\nstructures and smoothness of bias field, leading to distorted corrected\nresults. In this paper, novel structure and smoothness constrained dual\nnetworks, named S2DNets, are proposed aiming to self-supervised bias field\ncorrection. S2DNets introduce piece-wise structural constraints and smoothness\nof bias field for network training to effectively remove non-uniform intensity\nand retain much more structural details. Extensive experiments executed on both\nclinical and simulated MR datasets show that the proposed model outperforms\nother conventional and deep learning-based models. In addition to comparison on\nvisual metrics, downstream MR image segmentation tasks are also used to\nevaluate the impact of the proposed model. The source code is available at:\nhttps://github.com/LeongDong/S2DNets}{https://github.com/LeongDong/S2DNets.", "published": "2025-07-02 03:23:43", "link": "http://arxiv.org/abs/2507.01326v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SWinMamba: Serpentine Window State Space Model for Vascular Segmentation", "abstract": "Vascular segmentation in medical images is crucial for disease diagnosis and\nsurgical navigation. However, the segmented vascular structure is often\ndiscontinuous due to its slender nature and inadequate prior modeling. In this\npaper, we propose a novel Serpentine Window Mamba (SWinMamba) to achieve\naccurate vascular segmentation. The proposed SWinMamba innovatively models the\ncontinuity of slender vascular structures by incorporating serpentine window\nsequences into bidirectional state space models. The serpentine window\nsequences enable efficient feature capturing by adaptively guiding global\nvisual context modeling to the vascular structure. Specifically, the Serpentine\nWindow Tokenizer (SWToken) adaptively splits the input image using overlapping\nserpentine window sequences, enabling flexible receptive fields (RFs) for\nvascular structure modeling. The Bidirectional Aggregation Module (BAM)\nintegrates coherent local features in the RFs for vascular continuity\nrepresentation. In addition, dual-domain learning with Spatial-Frequency Fusion\nUnit (SFFU) is designed to enhance the feature representation of vascular\nstructure. Extensive experiments on three challenging datasets demonstrate that\nthe proposed SWinMamba achieves superior performance with complete and\nconnected vessels.", "published": "2025-07-02 03:15:08", "link": "http://arxiv.org/abs/2507.01323v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction", "abstract": "Accurate motion forecasting is critical for safe and efficient autonomous\ndriving, enabling vehicles to predict future trajectories and make informed\ndecisions in complex traffic scenarios. Most of the current designs of motion\nprediction models are based on the major representation of lane centerlines,\nwhich limits their capability to capture critical road environments and traffic\nrules and constraints. In this work, we propose an enhanced motion forecasting\nmodel informed by multiple vector map elements, including lane boundaries and\nroad edges, that facilitates a richer and more complete representation of\ndriving environments. An effective feature fusion strategy is developed to\nmerge information in different vector map components, where the model learns\nholistic information on road structures and their interactions with agents.\nSince encoding more information about the road environment increases memory\nusage and is computationally expensive, we developed an effective pruning\nmechanism that filters the most relevant map connections to the target agent,\nensuring computational efficiency while maintaining essential spatial and\nsemantic relationships for accurate trajectory prediction. Overcoming the\nlimitations of lane centerline-based models, our method provides a more\ninformative and efficient representation of the driving environment and\nadvances the state of the art for autonomous vehicle motion forecasting. We\nverify our approach with extensive experiments on the Argoverse 2 motion\nforecasting dataset, where our method maintains competitiveness on AV2 while\nachieving improved performance.\n  Index Terms-Autonomous driving, trajectory prediction, vector map elements,\nroad topology, connection pruning, Argoverse 2.", "published": "2025-07-02 02:49:24", "link": "http://arxiv.org/abs/2507.01308v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting", "abstract": "We introduce a simple yet effective technique for estimating lighting from a\nsingle low-dynamic-range (LDR) image by reframing the task as a chrome ball\ninpainting problem. This approach leverages a pre-trained diffusion model,\nStable Diffusion XL, to overcome the generalization failures of existing\nmethods that rely on limited HDR panorama datasets. While conceptually simple,\nthe task remains challenging because diffusion models often insert incorrect or\ninconsistent content and cannot readily generate chrome balls in HDR format.\nOur analysis reveals that the inpainting process is highly sensitive to the\ninitial noise in the diffusion process, occasionally resulting in unrealistic\noutputs. To address this, we first introduce DiffusionLight, which uses\niterative inpainting to compute a median chrome ball from multiple outputs to\nserve as a stable, low-frequency lighting prior that guides the generation of a\nhigh-quality final result. To generate high-dynamic-range (HDR) light probes,\nan Exposure LoRA is fine-tuned to create LDR images at multiple exposure\nvalues, which are then merged. While effective, DiffusionLight is\ntime-intensive, requiring approximately 30 minutes per estimation. To reduce\nthis overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to\nabout 30 seconds with minimal quality loss. This 60x speedup is achieved by\ntraining a Turbo LoRA to directly predict the averaged chrome balls from the\niterative process. Inference is further streamlined into a single denoising\npass using a LoRA swapping technique. Experimental results that show our method\nproduces convincing light estimates across diverse settings and demonstrates\nsuperior generalization to in-the-wild scenarios. Our code is available at\nhttps://diffusionlight.github.io/turbo", "published": "2025-07-02 02:47:01", "link": "http://arxiv.org/abs/2507.01305v1", "categories": ["cs.CV", "cs.GR", "cs.LG", "I.3.3; I.4.8"], "primary_category": "cs.CV"}
{"title": "PanTS: The Pancreatic Tumor Segmentation Dataset", "abstract": "PanTS is a large-scale, multi-institutional dataset curated to advance\nresearch in pancreatic CT analysis. It contains 36,390 CT scans from 145\nmedical centers, with expert-validated, voxel-wise annotations of over 993,000\nanatomical structures, covering pancreatic tumors, pancreas head, body, and\ntail, and 24 surrounding anatomical structures such as vascular/skeletal\nstructures and abdominal/thoracic organs. Each scan includes metadata such as\npatient age, sex, diagnosis, contrast phase, in-plane spacing, slice thickness,\netc. AI models trained on PanTS achieve significantly better performance in\npancreatic tumor detection, localization, and segmentation compared to those\ntrained on existing public datasets. Our analysis indicates that these gains\nare directly attributable to the 16x larger-scale tumor annotations and\nindirectly supported by the 24 additional surrounding anatomical structures. As\nthe largest and most comprehensive resource of its kind, PanTS offers a new\nbenchmark for developing and evaluating AI models in pancreatic CT analysis.", "published": "2025-07-02 02:10:46", "link": "http://arxiv.org/abs/2507.01291v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Learning an Ensemble Token from Task-driven Priors in Facial Analysis", "abstract": "Facial analysis exhibits task-specific feature variations. While\nConvolutional Neural Networks (CNNs) have enabled the fine-grained\nrepresentation of spatial information, Vision Transformers (ViTs) have\nfacilitated the representation of semantic information at the patch level.\nAlthough the generalization of conventional methodologies has advanced visual\ninterpretability, there remains paucity of research that preserves the unified\nfeature representation on single task learning during the training process. In\nthis work, we introduce ET-Fuser, a novel methodology for learning ensemble\ntoken by leveraging attention mechanisms based on task priors derived from\npre-trained models for facial analysis. Specifically, we propose a robust prior\nunification learning method that generates a ensemble token within a\nself-attention mechanism, which shares the mutual information along the\npre-trained encoders. This ensemble token approach offers high efficiency with\nnegligible computational cost. Our results show improvements across a variety\nof facial analysis, with statistically significant enhancements observed in the\nfeature representations.", "published": "2025-07-02 02:07:31", "link": "http://arxiv.org/abs/2507.01290v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Classification based deep learning models for lung cancer and disease using medical images", "abstract": "The use of deep learning (DL) in medical image analysis has significantly\nimproved the ability to predict lung cancer. In this study, we introduce a\nnovel deep convolutional neural network (CNN) model, named ResNet+, which is\nbased on the established ResNet framework. This model is specifically designed\nto improve the prediction of lung cancer and diseases using the images. To\naddress the challenge of missing feature information that occurs during the\ndownsampling process in CNNs, we integrate the ResNet-D module, a variant\ndesigned to enhance feature extraction capabilities by modifying the\ndownsampling layers, into the traditional ResNet model. Furthermore, a\nconvolutional attention module was incorporated into the bottleneck layers to\nenhance model generalization by allowing the network to focus on relevant\nregions of the input images. We evaluated the proposed model using five public\ndatasets, comprising lung cancer (LC2500 $n$=3183, IQ-OTH/NCCD $n$=1336, and\nLCC $n$=25000 images) and lung disease (ChestXray $n$=5856, and COVIDx-CT\n$n$=425024 images). To address class imbalance, we used data augmentation\ntechniques to artificially increase the representation of underrepresented\nclasses in the training dataset. The experimental results show that ResNet+\nmodel demonstrated remarkable accuracy/F1, reaching 98.14/98.14\\% on the\nLC25000 dataset and 99.25/99.13\\% on the IQ-OTH/NCCD dataset. Furthermore, the\nResNet+ model saved computational cost compared to the original ResNet series\nin predicting lung cancer images. The proposed model outperformed the baseline\nmodels on publicly available datasets, achieving better performance metrics.\nOur codes are publicly available at\nhttps://github.com/AIPMLab/Graduation-2024/tree/main/Peng.", "published": "2025-07-02 01:36:29", "link": "http://arxiv.org/abs/2507.01279v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing", "abstract": "Unpaired image dehazing has attracted increasing attention due to its\nflexible data requirements during model training. Dominant methods based on\ncontrastive learning not only introduce haze-unrelated content information, but\nalso ignore haze-specific properties in the frequency domain (\\ie,~haze-related\ndegradation is mainly manifested in the amplitude spectrum). To address these\nissues, we propose a novel frequency domain-based diffusion model, named \\ours,\nfor fully exploiting the beneficial knowledge in unpaired clear data. In\nparticular, inspired by the strong generative ability shown by Diffusion Models\n(DMs), we tackle the dehazing task from the perspective of frequency domain\nreconstruction and perform the DMs to yield the amplitude spectrum consistent\nwith the distribution of clear images. To implement it, we propose an Amplitude\nResidual Encoder (ARE) to extract the amplitude residuals, which effectively\ncompensates for the amplitude gap from the hazy to clear domains, as well as\nprovide supervision for the DMs training. In addition, we propose a Phase\nCorrection Module (PCM) to eliminate artifacts by further refining the phase\nspectrum during dehazing with a simple attention mechanism. Experimental\nresults demonstrate that our \\ours outperforms other state-of-the-art methods\non both synthetic and real-world datasets.", "published": "2025-07-02 01:22:46", "link": "http://arxiv.org/abs/2507.01275v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advancements in Weed Mapping: A Systematic Review", "abstract": "Weed mapping plays a critical role in precision management by providing\naccurate and timely data on weed distribution, enabling targeted control and\nreduced herbicide use. This minimizes environmental impacts, supports\nsustainable land management, and improves outcomes across agricultural and\nnatural environments. Recent advances in weed mapping leverage ground-vehicle\nRed Green Blue (RGB) cameras, satellite and drone-based remote sensing combined\nwith sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The\nresulting data are processed using advanced techniques including big data\nanalytics and machine learning, significantly improving the spatial and\ntemporal resolution of weed maps and enabling site-specific management\ndecisions. Despite a growing body of research in this domain, there is a lack\nof comprehensive literature reviews specifically focused on weed mapping. In\nparticular, the absence of a structured analysis spanning the entire mapping\npipeline, from data acquisition to processing techniques and mapping tools,\nlimits progress in the field. This review addresses these gaps by\nsystematically examining state-of-the-art methods in data acquisition (sensor\nand platform technologies), data processing (including annotation and\nmodelling), and mapping techniques (such as spatiotemporal analysis and\ndecision support tools). Following PRISMA guidelines, we critically evaluate\nand synthesize key findings from the literature to provide a holistic\nunderstanding of the weed mapping landscape. This review serves as a\nfoundational reference to guide future research and support the development of\nefficient, scalable, and sustainable weed management systems.", "published": "2025-07-02 01:02:52", "link": "http://arxiv.org/abs/2507.01269v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation", "abstract": "The rapid advancement of AI-generated video models has created a pressing\nneed for robust and interpretable evaluation frameworks. Existing metrics are\nlimited to producing numerical scores without explanatory comments, resulting\nin low interpretability and human evaluation alignment. To address those\nchallenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video\nEvaluation(AIGVE), which can provide not only numerical scores but also\nmulti-aspect language comment feedback in evaluating these generated videos.\nCentral to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising\n2,500 AI-generated videos and 22,500 human-annotated detailed comments and\nnumerical scores across nine critical evaluation aspects. Leveraging\nAIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a\nnovel token-wise weighted loss and a dynamic frame sampling strategy to better\nalign with human evaluators. Comprehensive experiments across supervised and\nzero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art\nperformance in both scoring correlation and comment quality, significantly\noutperforming prior baselines including GPT-4o and VideoScore. In addition, we\nfurther showcase a multi-agent refinement framework where feedback from\nAIGVE-MACS drives iterative improvements in video generation, leading to 53.5%\nquality enhancement. This work establishes a new paradigm for comprehensive,\nhuman-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2\nand AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.", "published": "2025-07-02 00:20:06", "link": "http://arxiv.org/abs/2507.01255v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scheduling on identical machines with conflicts to minimize the mean flow time", "abstract": "This paper addresses the problem of scheduling jobs on identical machines\nwith conflict constraints, where certain jobs cannot be scheduled\nsimultaneously on different machines. We focus on the case where conflicts can\nbe represented by a simple undirected graph, and the objective is to minimize\nthe mean flow time. We show that the problem is NP-hard even on two machines\nand two distinct processing times. For unit-time jobs, the problem becomes\nNP-hard when the number of machines increases to three. We also identify\npolynomial-time solvable cases for specific classes of conflict graphs. For the\ngeneral problem, we propose mathematical models, lower bounds, and a genetic\nalgorithm. We evaluate their performance through computational experiments on a\nwide range of instances derived from well-known benchmark instances in the\nliterature.", "published": "2025-07-02 14:36:35", "link": "http://arxiv.org/abs/2507.01759v1", "categories": ["cs.DM", "math.OC"], "primary_category": "cs.DM"}
{"title": "Multipacking in Hypercubes", "abstract": "For an undirected graph $G$, a dominating broadcast on $G$ is a function $f :\nV(G) \\rightarrow \\mathbb{N}$ such that for any vertex $u \\in V(G)$, there\nexists a vertex $v \\in V(G)$ with $f(v) \\geqslant 1$ and $d(u,v) \\leqslant\nf(v)$. The cost of $f$ is $\\sum_{v \\in V} f(v)$. The minimum cost over all the\ndominating broadcasts on $G$ is defined as the broadcast domination number\n$\\gamma_b(G)$ of $G$. A multipacking in $G$ is a subset $M \\subseteq V(G)$ such\nthat, for every vertex $v \\in V(G)$ and every positive integer $r$, the number\nof vertices in $M$ within distance $r$ of $v$ is at most $r$. The multipacking\nnumber of $G$, denoted $\\operatorname{mp}(G)$, is the maximum cardinality of a\nmultipacking in $G$. These two optimisation problems are duals of each other,\nand it easily follows that $\\operatorname{mp}(G) \\leqslant \\gamma_b(G)$. It is\nknown that $\\gamma_b(G) \\leqslant 2\\operatorname{mp}(G)+3$ and conjectured that\n$\\gamma_b(G) \\leqslant 2\\operatorname{mp}(G)$.\n  In this paper, we show that for the $n$-dimensional hypercube $Q_n$ $$\n\\left\\lfloor\\frac{n}{2} \\right\\rfloor\n  \\leqslant \\operatorname{mp}(Q_n)\n  \\leqslant \\frac{n}{2} + 6\\sqrt{2n}. $$\n  Since $\\gamma_b(Q_n) = n-1$ for all $n \\geqslant 3$, this verifies the above\nconjecture on hypercubes and, more interestingly, gives a sequence of connected\ngraphs for which the ratio $\\frac{\\gamma_b(G)}{\\operatorname{mp}(G)}$\napproaches $2$, a search for which was initiated by Beaudou, Brewster and\nFoucaud in 2018. It follows that, for connected graphs $G$ $$\n  \\limsup_{\\operatorname{mp}(G) \\rightarrow \\infty}\n\\left\\{\\frac{\\gamma_b(G)}{\\operatorname{mp}(G)}\\right\\} = 2.$$\n  The lower bound on $\\operatorname{mp}(Q_n)$ is established by a recursive\nconstruction, and the upper bound is established using a classic result from\ndiscrepancy theory.", "published": "2025-07-02 10:31:09", "link": "http://arxiv.org/abs/2507.01565v1", "categories": ["math.CO", "cs.DM", "05C69"], "primary_category": "math.CO"}
{"title": "Some remarks on the uncolored versions of the original CFI-graphs", "abstract": "The CFI-graphs, named after Cai, F\\\"urer, and Immerman, are central to the\nstudy of the graph isomorphism testing and of first-order logic with counting.\nThey are colored graphs, and the coloring plays a role in many of their\napplications. As usual, it is not hard to remove the coloring by some extra\ngraph gadgets, but at the cost of blowing up the size of the graphs and\nchanging some parameters of them as well. This might lead to suboptimal\ncombinatorial bounds important to their applications. Since then for some\nuncolored variants of the CFI-graphs it has been shown that they serve the same\npurposes. We show that this already applies to the graphs obtained from the\noriginal CFI-graphs by forgetting the colors. Moreover, we will see that there\nis a first-order formula $\\varphi(x,y)$ expressing in almost all uncolored\nCFI-graphs that $x$ and $y$ have the same color in the corresponding colored\ngraphs.", "published": "2025-07-02 08:17:36", "link": "http://arxiv.org/abs/2507.01459v1", "categories": ["cs.DM", "cs.LO", "math.CO"], "primary_category": "cs.DM"}
{"title": "DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation", "abstract": "Federated recommendation (FedRec) preserves user privacy by enabling\ndecentralized training of personalized models, but this architecture is\ninherently vulnerable to adversarial attacks. Significant research has been\nconducted on targeted attacks in FedRec systems, motivated by commercial and\nsocial influence considerations. However, much of this work has largely\noverlooked the differential robustness of recommendation models. Moreover, our\nempirical findings indicate that existing targeted attack methods achieve only\nlimited effectiveness in Federated Sequential Recommendation(FSR) tasks. Driven\nby these observations, we focus on investigating targeted attacks in FSR and\npropose a novel dualview attack framework, named DV-FSR. This attack method\nuniquely combines a sampling-based explicit strategy with a contrastive\nlearning-based implicit gradient strategy to orchestrate a coordinated attack.\nAdditionally, we introduce a specific defense mechanism tailored for targeted\nattacks in FSR, aiming to evaluate the mitigation effects of the attack method\nwe proposed. Extensive experiments validate the effectiveness of our proposed\napproach on representative sequential models. Our codes are publicly available.", "published": "2025-07-02 05:57:09", "link": "http://arxiv.org/abs/2507.01383v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation", "abstract": "Graph federated recommendation systems offer a privacy-preserving alternative\nto traditional centralized recommendation architectures, which often raise\nconcerns about data security. While federated learning enables personalized\nrecommendations without exposing raw user data, existing aggregation methods\noverlook the unique properties of user embeddings in this setting. Indeed,\ntraditional aggregation methods fail to account for their complexity and the\ncritical role of user similarity in recommendation effectiveness. Moreover,\nevolving user interactions require adaptive aggregation while preserving the\ninfluence of high-relevance anchor users (the primary users before expansion in\ngraph-based frameworks). To address these limitations, we introduce\nDist-FedAvg, a novel distance-based aggregation method designed to enhance\npersonalization and aggregation efficiency in graph federated learning. Our\nmethod assigns higher aggregation weights to users with similar embeddings,\nwhile ensuring that anchor users retain significant influence in local updates.\nEmpirical evaluations on multiple datasets demonstrate that Dist-FedAvg\nconsistently outperforms baseline aggregation techniques, improving\nrecommendation accuracy while maintaining seamless integration into existing\nfederated learning frameworks.", "published": "2025-07-02 01:57:58", "link": "http://arxiv.org/abs/2507.01285v1", "categories": ["cs.LG", "cs.DC", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Joint Power Control and Precoding for Cell-Free Massive MIMO Systems With Sparse Multi-Dimensional Graph Neural Networks", "abstract": "Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as a\nprominent candidate for future networks due to its ability to significantly\nenhance spectral efficiency by eliminating inter-cell interference. However,\nits practical deployment faces considerable challenges, such as high\ncomputational complexity and the optimization of its complex processing. To\naddress these challenges, this correspondence proposes a framework based on a\nsparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies the\nconnections between access points (APs) and user equipments (UEs) to\nsignificantly reduce computational complexity while maintaining high\nperformance. In addition, the weighted minimum mean square error (WMMSE)\nalgorithm is introduced as a comparative method to further analyze the\ntrade-off between performance and complexity. Simulation results demonstrate\nthat the sparse method achieves an optimal balance between performance and\ncomplexity, significantly reducing the computational complexity of the original\nMDGNN method while incurring only a slight performance degradation, providing\ninsights for the practical deployment of CF mMIMO systems in large-scale\nnetwork.", "published": "2025-07-02 16:41:35", "link": "http://arxiv.org/abs/2507.01876v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A hierarchical invariant for line bundles and its applications in algebraic geometry codes", "abstract": "We introduce the notion of hierarchical depth for line bundles on smooth\nprojective surfaces, defined via filtrations by line subbundles with successive\nquotients supported on effective divisors. This invariant helps to investigate\nboth the algebraic and geometric complexity of line bundles through discrete\nstepwise constructions. We study some of its basic properties, including\nfunctorial behavior under restriction to curves and compatibility with\nampleness and base-point freeness. Applying this framework to algebraic\ngeometry (AG) codes, we show that hierarchical filtrations yield natural code\nfamilies whose combinatorial parameters (dimension, minimum distance) evolve\npredictably across the filtration.", "published": "2025-07-02 16:21:31", "link": "http://arxiv.org/abs/2507.01859v1", "categories": ["math.AG", "cs.IT", "math.AC", "math.IT", "14G50 (Primary) 14C20, 14H52 (Secondary)"], "primary_category": "math.AG"}
{"title": "Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization", "abstract": "In this paper, we propose SubLoRA, a rank determination method for Low-Rank\nAdaptation (LoRA) based on submodular function maximization. In contrast to\nprior approaches, such as AdaLoRA, that rely on first-order (linearized)\napproximations of the loss function, SubLoRA utilizes second-order information\nto capture the potentially complex loss landscape by incorporating the Hessian\nmatrix. We show that the linearization becomes inaccurate and ill-conditioned\nwhen the LoRA parameters have been well optimized, motivating the need for a\nmore reliable and nuanced second-order formulation. To this end, we reformulate\nthe rank determination problem as a combinatorial optimization problem with a\nquadratic objective. However, solving this problem exactly is NP-hard in\ngeneral. To overcome the computational challenge, we introduce a submodular\nfunction maximization framework and devise a greedy algorithm with\napproximation guarantees. We derive a sufficient and necessary condition under\nwhich the rank-determination objective becomes submodular, and construct a\nclosed-form projection of the Hessian matrix that satisfies this condition\nwhile maintaining computational efficiency. Our method combines solid\ntheoretical foundations, second-order accuracy, and practical computational\nefficiency. We further extend SubLoRA to a joint optimization setting,\nalternating between LoRA parameter updates and rank determination under a rank\nbudget constraint. Extensive experiments on fine-tuning physics-informed neural\nnetworks (PINNs) for solving partial differential equations (PDEs) demonstrate\nthe effectiveness of our approach. Results show that SubLoRA outperforms\nexisting methods in both rank determination and joint training performance.", "published": "2025-07-02 15:56:40", "link": "http://arxiv.org/abs/2507.01841v1", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT", "math.OC"], "primary_category": "cs.LG"}
{"title": "ASTARS empowered Satellite Positioning Approach for Urban Canyons and Indoor Environments", "abstract": "To mitigate the loss of satellite navigation signals in urban canyons and\nindoor environments, we propose an active simultaneous transmitting and\nreflecting reconfigurable intelligent surface (ASTARS) empowered satellite\npositioning approach. Deployed on building structures, ASTARS reflects\nnavigation signals to outdoor receivers in urban canyons and transmits signals\nindoors to bypass obstructions, providing high-precision positioning services\nto receivers in non-line-of-sight (NLoS) areas. The path between ASTARS and the\nreceiver is defined as the extended line-of-sight (ELoS) path and an improved\ncarrier phase observation equation is derived to accommodate that. The receiver\ncompensates for its clock bias through network time synchronization, corrects\nthe actual signal path distance to the satellite-to-receiver distance through a\ndistance correction algorithm, and determines its position by using the least\nsquares (LS) method. Mathematical modeling of the errors introduced by the\nproposed method is conducted, followed by simulation analysis to assess their\nimpact. Simulation results show that: 1) in areas where GNSS signals are\nblocked, with time synchronization accuracy within a 10 ns error range, the\nproposed method provides positioning services with errors not exceeding 4 m for\nboth indoor and outdoor receivers, outperforming conventional NLoS methods with\npositioning errors of more than 7 m; 2) the additional errors introduced by the\nproposed method do not exceed 3 m for time synchronization errors within 10 ns,\nwhich includes the phase shift, beamwidth error, time synchronization errors,\nand satellite distribution errors, outperforming traditional NLoS methods,\nwhich typically produce positioning errors greater than 5 m.", "published": "2025-07-02 15:08:37", "link": "http://arxiv.org/abs/2507.01783v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Symbiotic Backscatter Communication: A Design Perspective on the Modulation Scheme of Backscatter Devices", "abstract": "Symbiotic Backscatter Communication (SBC) has emerged as a spectrum-efficient\nand low-power communication technology, where backscatter devices (BDs)\nmodulate and reflect incident radio frequency (RF) signals from primary\ntransmitters (PTs). While previous studies have assumed a circularly symmetric\ncomplex Gaussian (CSCG) distribution for the BD's signal, this assumption may\nnot be practical because the high complexity of generating CSCG signals is not\nsupported by the low-cost BD. In this paper, we address this gap by\ninvestigating SBC for two low-complexity modulation schemes, i.e., $M$-ary\namplitude-shift keying (MASK) and $M$-ary phase-shift keying (MPSK), where BD's\nsignals inherently deviate from CSCG distribution. Our goal is to derive the\nachievable rate of the PT and BD under the MASK/MPSK and to design MASK/MPSK\nmodulation scheme for maximizing the PT's rate. Towards this end, we first\nderive the expressions of both the PT's rate and BD's rate. Theoretical results\nreveal that whether or not the BD improves the PT's rate depends on the phase\nof MASK/MPSK modulation, while the BD's rate is independent of this phase. We\nthen formulate two optimization problems to maximize the PT's rate by adjusting\nthe phase under the MASK and MPSK modulation schemes, respectively, and derive\nthe optimal phases for each modulation scheme in closed forms. Simulation\nresults demonstrate that the optimal phase of MASK/MPSK can ensure an\nimprovement in the PT's rate, and reveal that a low-order ASK modulation is\nbetter than a low-order PSK for the BD in terms of improving PT's rate,\nespecially when the direct link is not significantly weaker than the\nbackscatter link in SBC.", "published": "2025-07-02 15:07:59", "link": "http://arxiv.org/abs/2507.01782v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Reconfigurable Intelligent Surface aided Integrated-Navigation-and-Communication in Urban Canyons: A Satellite Selection Approach", "abstract": "This study investigates the application of a simultaneous transmitting and\nreflecting reconfigurable intelligent surface (STAR-RIS)-aided\nmedium-Earth-orbit (MEO) satellite network for providing both global\npositioning services and communication services in the urban canyons, where the\ndirect satellite-user links are obstructed. Superposition coding (SC) and\nsuccessive interference cancellation (SIC) techniques are utilized for the\nintegrated navigation and communication (INAC) networks, and the composed\nnavigation and communication signals are reflected or transmitted to ground\nusers or indoor users located in urban canyons. To meet diverse application\nneeds, navigation-oriented (NO)-INAC and communication-oriented (CO)-INAC have\nbeen developed, each tailored according to distinct power allocation factors.\nWe then proposed two algorithms, namely navigation-prioritized-algorithm (NPA)\nand communication-prioritized-algorithm (CPA), to improve the navigation or\ncommunication performance by selecting the satellite with the optimized\nposition dilution of precision (PDoP) or with the best channel gain. The\neffectiveness of the proposed STAR-RIS-aided INAC network is quantified by\nanalyzing the positioning error for navigation services and by evaluating\ncommunication performance through achievable ergodic rate metrics. Our\nsatellite selection approach indicates that: the positioning services at the\nurban canyon users can be completed with the aid of STAR-RIS. 2) Additionally,\nit is observed that while a single STAR-RIS array can extend the navigational\nlink, it fails to serve users in indoor scenarios, highlighting a limitation in\nthe current system design.", "published": "2025-07-02 14:46:58", "link": "http://arxiv.org/abs/2507.01766v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Half Spatially Coupled Turbo-Like Codes", "abstract": "This paper presents a new class of spatially coupled turbo-like codes\n(SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs)\nand half spatially coupled parallel concatenated codes (HSC-PCCs). Different\nfrom the conventional SC-TCs, the proposed codes have simpler and deterministic\ncoupling structures. Most notably, the coupling of HSC-BCCs is performed by\nre-encoding the whole coupling sequence in the component encoder of one time\ninstant, rather than spreading the coupling bits to component encoders of\nmultiple time instants. This simplification not only addresses the window\ndecoding threshold loss issue in existing BCCs, but also allows the proposed\ncodes to attain very close-to-capacity performance with a coupling memory as\nsmall as 2. Both theoretical and numerical results are provided to demonstrate\nthe performance advantages of the proposed codes over existing spatially\ncoupled codes.", "published": "2025-07-02 13:11:34", "link": "http://arxiv.org/abs/2507.01685v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Joint Spatial Division and Multiplexing with Customized Orthogonal Group Channels in Multi-RIS-Assisted Systems", "abstract": "Reconfigurable intelligent surfaces (RISs) offer the unique capability to\nreshape the radio environment, thereby simplifying transmission schemes\ntraditionally contingent on channel conditions. Joint spatial division and\nmultiplexing (JSDM) emerges as a low-overhead transmission scheme for\nmulti-user equipment (UE) scenarios, typically requiring complex matrix\ndecomposition to achieve block-diagonalization of the effective channel matrix.\nIn this study, we introduce an innovative JSDM design that leverages RISs to\ncustomize channels, thereby streamlining the overall procedures. By\nstrategically positioning RISs at the discrete Fourier transform (DFT)\ndirections of the base station (BS), we establish orthogonal line-of-sight\nlinks within the BS-RIS channel, enabling a straightforward pre-beamforming\ndesign. Based on UE grouping, we devise reflected beams of the RIS with\noptimized directions to mitigate inter-group interference in the RISs-UEs\nchannel. An approximation of the channel cross-correlation coefficient is\nderived and serves as a foundation for the RISs-UEs association, further\ndiminishing inter-group interference. Numerical results substantiate the\nefficacy of our RIS-customized JSDM in not only achieving effective channel\nblock-diagonalization but also in significantly enhancing the sum spectral\nefficiency for multi-UE transmissions.", "published": "2025-07-02 12:15:00", "link": "http://arxiv.org/abs/2507.01641v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Coding for Quasi-Static Fading Channel with Imperfect CSI at the Transmitter and Quantized Feedback", "abstract": "The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise\nchannel with noiseless feedback is highly efficient since its coding complexity\nis extremely low and the decoding error doubly exponentially decays as the\ncoding blocklength tends to infinity. However, its application to the fading\nchannel with imperfect CSI at the transmitter (I-CSIT) is challenging since the\nSK scheme is sensitive to the CSI. In this paper, we investigate how to design\nSK-type scheme for the quasi-static fading channel with I-CSIT and quantized\nfeedback. By introducing modulo lattice function and an auxiliary signal into\nthe SK-type encoder-decoder of the transceiver, we show that the decoding error\ncaused by the I-CSIT can be perfectly eliminated, resulting in the success of\ndesigning SK-type scheme for such a case. The study of this paper provides a\nway to design efficient coding scheme for fading channels in the presence of\nimperfect CSI and quantized feedback.", "published": "2025-07-02 08:23:54", "link": "http://arxiv.org/abs/2507.01464v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Inequalities in Fourier analysis on binary cubes", "abstract": "This paper studies two classical inequalities, namely the Hausdorff-Young\ninequality and equal-exponent Young's convolution inequality, for discrete\nfunctions supported in the binary cube $\\{0,1\\}^d\\subset\\mathbb{Z}^d$. We\ncharacterize the exact ranges of Lebesgue exponents in which sharp versions of\nthese two inequalities hold, and present several immediate consequences. First,\nif the functions are specialized to be the indicator of some set\n$A\\subseteq\\{0,1\\}^d$, then we obtain sharp upper bounds on two types of\ngeneralized additive energies of $A$, extending the works of Kane-Tao, de Dios\nPont-Greenfeld-Ivanisvili-Madrid, and one of the present authors. Second, we\nobtain a sharp binary variant of the Beckner-Hirschman entropic uncertainty\nprinciple, as well as a sharp lower estimate on the entropy of a sum of two\nindependent random variables with values in $\\{0,1\\}^d$. Finally, the sharp\nbinary Hausdorff-Young inequality also reveals the exact range of\ndimension-free estimates for the Fourier restriction to the binary cube.", "published": "2025-07-02 04:50:11", "link": "http://arxiv.org/abs/2507.01359v1", "categories": ["math.CA", "cs.IT", "math.CO", "math.IT"], "primary_category": "math.CA"}
{"title": "Dynamical Multimodal Fusion with Mixture-of-Experts for Localizations", "abstract": "Multimodal fingerprinting is a crucial technique to sub-meter 6G integrated\nsensing and communications (ISAC) localization, but two hurdles block\ndeployment: (i) the contribution each modality makes to the target position\nvaries with the operating conditions such as carrier frequency, and (ii)\nspatial and fingerprint ambiguities markedly undermine localization accuracy,\nespecially in non-line-of-sight (NLOS) scenarios. To solve these problems, we\nintroduce SCADF-MoE, a spatial-context aware dynamic fusion network built on a\nsoft mixture-of-experts backbone. SCADF-MoE first clusters neighboring points\ninto short trajectories to inject explicit spatial context. Then, it adaptively\nfuses channel state information, angle of arrival profile, distance, and gain\nthrough its learnable MoE router, so that the most reliable cues dominate at\neach carrier band. The fused representation is fed to a modality-task MoE that\nsimultaneously regresses the coordinates of every vertex in the trajectory and\nits centroid, thereby exploiting inter-point correlations. Finally, an\nauxiliary maximum-mean-discrepancy loss enforces expert diversity and mitigates\ngradient interference, stabilizing multi-task training. On three real urban\nlayouts and three carrier bands (2.6, 6, 28 GHz), the model delivers consistent\nsub-meter MSE and halves unseen-NLOS error versus the best prior work. To our\nknowledge, this is the first work that leverages large-scale multimodal MoE for\nfrequency-robust ISAC localization.", "published": "2025-07-02 03:55:13", "link": "http://arxiv.org/abs/2507.01337v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-User Generative Semantic Communication with Intent-Aware Semantic-Splitting Multiple Access", "abstract": "With the booming development of generative artificial intelligence (GAI),\nsemantic communication (SemCom) has emerged as a new paradigm for reliable and\nefficient communication. This paper considers a multi-user downlink SemCom\nsystem, using vehicular networks as the representative scenario for multi-user\ncontent dissemination. To address diverse yet overlapping user demands, we\npropose a multi-user Generative SemCom-enhanced intent-aware semantic-splitting\nmultiple access (SS-MGSC) framework. In the framework, we construct an\nintent-aware shared knowledge base (SKB) that incorporates prior knowledge of\nsemantic information (SI) and user-specific preferences. Then, we designate the\ncommon SI as a one-hot semantic map that is broadcast to all users, while the\nprivate SI is delivered as personalized text for each user. On the receiver\nside, a diffusion model enhanced with ControlNet is adopted to generate\nhigh-quality personalized images. To capture both semantic relevance and\nperceptual similarity, we design a novel semantic efficiency score (SES) metric\nas the optimization objective. Building on this, we formulate a joint\noptimization problem for multi-user semantic extraction and beamforming, solved\nusing a reinforcement learning-based algorithm due to its robustness in\nhigh-dimensional settings. Simulation results demonstrate the effectiveness of\nthe proposed scheme.", "published": "2025-07-02 03:50:08", "link": "http://arxiv.org/abs/2507.01333v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "On Securing Berrut Approximated Coded Computing Through Discrete Cosine Transforms", "abstract": "Coded computing is a reliable and fault-tolerant mechanism for implementing\nlarge computing tasks over a distributed set of worker nodes. While a majority\nof coded computing frameworks address accurate computation of the target\nfunctions, they are restricted to computing multivariate polynomial functions.\nTo generalize these computing platforms to non-polynomial target functions,\nJahani-Nezhad and Maddah-Ali recently proposed Berrut Approximated Coded\ncomputing (BACC), which was proven fault-tolerant against stragglers albiet\nwith tolerable approximation errors on the target functions. Despite these\nbenefits, there is no formal study on the security of BACC against worker nodes\nwhich report erroneous computations. To fill this research gap, we use a\ncoding-theoretic approach to propose Secure Berrut Approximated Coded Computing\n(SBACC), which is resilient to stragglers and also robust to the presence of\nsuch untrusted worker nodes. One of the highlights of SBACC is the new choice\nof evaluation points for distributed computation which makes the well-known\nDiscrete Cosine Transform (DCT) codes amenable to error detection and\ncorrection. To validate the new choice of evaluation points, first, we derive\nbounds on the accuracy of SBACC in the absence of untrusted worker nodes.\nSubsequently, to handle the presence of untrusted worker nodes, we derive\nbounds on the accuracy of SBACC and show that interesting optimization problems\ncan be formulated to study the trade-off between the error correcting\ncapability of the DCT codes and the accuracy of the target computation.", "published": "2025-07-02 03:41:39", "link": "http://arxiv.org/abs/2507.01330v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Characterizing control between interacting subsystems with deep Jacobian estimation", "abstract": "Biological function arises through the dynamical interactions of multiple\nsubsystems, including those between brain areas, within gene regulatory\nnetworks, and more. A common approach to understanding these systems is to\nmodel the dynamics of each subsystem and characterize communication between\nthem. An alternative approach is through the lens of control theory: how the\nsubsystems control one another. This approach involves inferring the\ndirectionality, strength, and contextual modulation of control between\nsubsystems. However, methods for understanding subsystem control are typically\nlinear and cannot adequately describe the rich contextual effects enabled by\nnonlinear complex systems. To bridge this gap, we devise a data-driven\nnonlinear control-theoretic framework to characterize subsystem interactions\nvia the Jacobian of the dynamics. We address the challenge of learning\nJacobians from time-series data by proposing the JacobianODE, a deep learning\nmethod that leverages properties of the Jacobian to directly estimate it for\narbitrary dynamical systems from data alone. We show that JacobianODEs\noutperform existing Jacobian estimation methods on challenging systems,\nincluding high-dimensional chaos. Applying our approach to a multi-area\nrecurrent neural network (RNN) trained on a working memory selection task, we\nshow that the \"sensory\" area gains greater control over the \"cognitive\" area\nover learning. Furthermore, we leverage the JacobianODE to directly control the\ntrained RNN, enabling precise manipulation of its behavior. Our work lays the\nfoundation for a theoretically grounded and data-driven understanding of\ninteractions among biological subsystems.", "published": "2025-07-02 17:55:53", "link": "http://arxiv.org/abs/2507.01946v1", "categories": ["q-bio.QM", "cs.LG", "math.DS", "q-bio.NC"], "primary_category": "q-bio.QM"}
{"title": "A first-order method for nonconvex-nonconcave minimax problems under a local Kurdyka-\u0141ojasiewicz condition", "abstract": "We study a class of nonconvex-nonconcave minimax problems in which the inner\nmaximization problem satisfies a local Kurdyka-{\\L}ojasiewicz (KL) condition\nthat may vary with the outer minimization variable. In contrast to the global\nKL or Polyak-{\\L}ojasiewicz (PL) conditions commonly assumed in the literature\n-- which are significantly stronger and often too restrictive in practice --\nthis local KL condition accommodates a broader range of practical scenarios.\nHowever, it also introduces new analytical challenges. In particular, as an\noptimization algorithm progresses toward a stationary point of the problem, the\nregion over which the KL condition holds may shrink, resulting in a more\nintricate and potentially ill-conditioned landscape. To address this challenge,\nwe show that the associated maximal function is locally H\\\"older smooth.\nLeveraging this key property, we develop an inexact proximal gradient method\nfor solving the minimax problem, where the inexact gradient of the maximal\nfunction is computed by applying a proximal gradient method to a KL-structured\nsubproblem. Under mild assumptions, we establish complexity guarantees for\ncomputing an approximate stationary point of the minimax problem.", "published": "2025-07-02 17:45:10", "link": "http://arxiv.org/abs/2507.01932v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.ML", "90C26, 90C30, 90C47, 90C99, 65K05"], "primary_category": "math.OC"}
{"title": "Advancing Magnetic Materials Discovery -- A structure-based machine learning approach for magnetic ordering and magnetic moment prediction", "abstract": "Accurately predicting magnetic behavior across diverse materials systems\nremains a longstanding challenge due to the complex interplay of structural and\nelectronic factors and is pivotal for the accelerated discovery and design of\nnext-generation magnetic materials. In this work, a refined descriptor is\nproposed that significantly improves the prediction of two critical magnetic\nproperties -- magnetic ordering (Ferromagnetic vs. Ferrimagnetic) and magnetic\nmoment per atom -- using only the structural information of materials. Unlike\nprevious models limited to Mn-based or lanthanide-transition metal compounds,\nthe present approach generalizes across a diverse dataset of 5741 stable,\nbinary and ternary, ferromagnetic and ferrimagnetic compounds sourced from the\nMaterials Project. Leveraging an enriched elemental vector representation and\nadvanced feature engineering, including nonlinear terms and reduced matrix\nsparsity, the LightGBM-based model achieves an accuracy of 82.4% for magnetic\nordering classification and balanced recall across FM and FiM classes,\naddressing a key limitation in prior studies. The model predicts magnetic\nmoment per atom with a correlation coefficient of 0.93, surpassing the Hund's\nmatrix and orbital field matrix descriptors. Additionally, it accurately\nestimates formation energy per atom, enabling assessment of both magnetic\nbehavior and material stability. This generalized and computationally efficient\nframework offers a robust tool for high-throughput screening of magnetic\nmaterials with tailored properties.", "published": "2025-07-02 17:24:50", "link": "http://arxiv.org/abs/2507.01913v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "STEM Diffraction Pattern Analysis with Deep Learning Networks", "abstract": "Accurate grain orientation mapping is essential for understanding and\noptimizing the performance of polycrystalline materials, particularly in\nenergy-related applications. Lithium nickel oxide (LiNiO$_{2}$) is a promising\ncathode material for next-generation lithium-ion batteries, and its\nelectrochemical behaviour is closely linked to microstructural features such as\ngrain size and crystallographic orientations. Traditional orientation mapping\nmethods--such as manual indexing, template matching (TM), or Hough\ntransform-based techniques--are often slow and noise-sensitive when handling\ncomplex or overlapping patterns, creating a bottleneck in large-scale\nmicrostructural analysis. This work presents a machine learning-based approach\nfor predicting Euler angles directly from scanning transmission electron\nmicroscopy (STEM) diffraction patterns (DPs). This enables the automated\ngeneration of high-resolution crystal orientation maps, facilitating the\nanalysis of internal microstructures at the nanoscale. Three deep learning\narchitectures--convolutional neural networks (CNNs), Dense Convolutional\nNetworks (DenseNets), and Shifted Windows (Swin) Transformers--are evaluated,\nusing an experimentally acquired dataset labelled via a commercial TM\nalgorithm. While the CNN model serves as a baseline, both DenseNets and Swin\nTransformers demonstrate superior performance, with the Swin Transformer\nachieving the highest evaluation scores and the most consistent microstructural\npredictions. The resulting crystal maps exhibit clear grain boundary\ndelineation and coherent intra-grain orientation distributions, underscoring\nthe potential of attention-based architectures for analyzing diffraction-based\nimage data. These findings highlight the promise of combining advanced machine\nlearning models with STEM data for robust, high-throughput microstructural\ncharacterization.", "published": "2025-07-02 16:58:09", "link": "http://arxiv.org/abs/2507.01889v1", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.dis-nn"}
{"title": "Evolving HPC services to enable ML workloads on HPE Cray EX", "abstract": "The Alps Research Infrastructure leverages GH200 technology at scale,\nfeaturing 10,752 GPUs. Accessing Alps provides a significant computational\nadvantage for researchers in Artificial Intelligence (AI) and Machine Learning\n(ML). While Alps serves a broad range of scientific communities, traditional\nHPC services alone are not sufficient to meet the dynamic needs of the ML\ncommunity. This paper presents an initial investigation into extending HPC\nservice capabilities to better support ML workloads. We identify key challenges\nand gaps we have observed since the early-access phase (2023) of Alps by the\nSwiss AI community and propose several technological enhancements. These\ninclude a user environment designed to facilitate the adoption of HPC for ML\nworkloads, balancing performance with flexibility; a utility for rapid\nperformance screening of ML applications during development; observability\ncapabilities and data products for inspecting ongoing large-scale ML workloads;\na utility to simplify the vetting of allocated nodes for compute readiness; a\nservice plane infrastructure to deploy various types of workloads, including\nsupport and inference services; and a storage infrastructure tailored to the\nspecific needs of ML workloads. These enhancements aim to facilitate the\nexecution of ML workloads on HPC systems, increase system usability and\nresilience, and better align with the needs of the ML community. We also\ndiscuss our current approach to security aspects. This paper concludes by\nplacing these proposals in the broader context of changes in the communities\nserved by HPC infrastructure like ours.", "published": "2025-07-02 16:50:49", "link": "http://arxiv.org/abs/2507.01880v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Out-of-Distribution Detection Methods Answer the Wrong Questions", "abstract": "To detect distribution shifts and improve model safety, many\nout-of-distribution (OOD) detection methods rely on the predictive uncertainty\nor features of supervised models trained on in-distribution data. In this\npaper, we critically re-examine this popular family of OOD detection\nprocedures, and we argue that these methods are fundamentally answering the\nwrong questions for OOD detection. There is no simple fix to this misalignment,\nsince a classifier trained only on in-distribution classes cannot be expected\nto identify OOD points; for instance, a cat-dog classifier may confidently\nmisclassify an airplane if it contains features that distinguish cats from\ndogs, despite generally appearing nothing alike. We find that uncertainty-based\nmethods incorrectly conflate high uncertainty with being OOD, while\nfeature-based methods incorrectly conflate far feature-space distance with\nbeing OOD. We show how these pathologies manifest as irreducible errors in OOD\ndetection and identify common settings where these methods are ineffective.\nAdditionally, interventions to improve OOD detection such as feature-logit\nhybrid methods, scaling of model and data size, epistemic uncertainty\nrepresentation, and outlier exposure also fail to address this fundamental\nmisalignment in objectives. We additionally consider unsupervised density\nestimation and generative models for OOD detection, which we show have their\nown fundamental limitations.", "published": "2025-07-02 15:45:17", "link": "http://arxiv.org/abs/2507.01831v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning Agents", "abstract": "We present a novel approach to knowledge transfer in model-based\nreinforcement learning, addressing the critical challenge of deploying large\nworld models in resource-constrained environments. Our method efficiently\ndistills a high-capacity multi-task agent (317M parameters) into a compact\nmodel (1M parameters) on the MT30 benchmark, significantly improving\nperformance across diverse tasks. Our distilled model achieves a\nstate-of-the-art normalized score of 28.45, surpassing the original 1M\nparameter model score of 18.93. This improvement demonstrates the ability of\nour distillation technique to capture and consolidate complex multi-task\nknowledge. We further optimize the distilled model through FP16 post-training\nquantization, reducing its size by $\\sim$50\\%. Our approach addresses practical\ndeployment limitations and offers insights into knowledge representation in\nlarge world models, paving the way for more efficient and accessible multi-task\nreinforcement learning systems in robotics and other resource-constrained\napplications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.", "published": "2025-07-02 15:38:49", "link": "http://arxiv.org/abs/2507.01823v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Towards Decentralized and Sustainable Foundation Model Training with the Edge", "abstract": "Foundation models are at the forefront of AI research, appealing for their\nability to learn from vast datasets and cater to diverse tasks. Yet, their\nsignificant computational demands raise issues of environmental impact and the\nrisk of centralized control in their development. We put forward a vision\ntowards decentralized and sustainable foundation model training that leverages\nthe collective compute of sparingly used connected edge AI devices. We present\nthe rationale behind our vision, particularly in support of its sustainability\nbenefit. We further outline a set of challenges that need to be addressed to\nturn this vision into reality.", "published": "2025-07-02 15:21:40", "link": "http://arxiv.org/abs/2507.01803v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neural Entropy-stable conservative flux form neural networks for learning hyperbolic conservation laws", "abstract": "We propose a neural entropy-stable conservative flux form neural network\n(NESCFN) for learning hyperbolic conservation laws and their associated entropy\nfunctions directly from solution trajectories, without requiring any predefined\nnumerical discretization. While recent neural network architectures have\nsuccessfully integrated classical numerical principles into learned models,\nmost rely on prior knowledge of the governing equations or assume a fixed\ndiscretization. Our approach removes this dependency by embedding\nentropy-stable design principles into the learning process itself, enabling the\ndiscovery of physically consistent dynamics in a fully data-driven setting. By\njointly learning both the numerical flux function and a corresponding entropy,\nthe proposed method ensures conservation and entropy dissipation, critical for\nlong-term stability and fidelity in the system of hyperbolic conservation laws.\nNumerical results demonstrate that the method achieves stability and\nconservation over extended time horizons and accurately captures shock\npropagation speeds, even without oracle access to future-time solution profiles\nin the training data.", "published": "2025-07-02 15:18:04", "link": "http://arxiv.org/abs/2507.01795v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math-ph", "math.MP", "65M08, 68T07, 65M22, 65M32, 65D25"], "primary_category": "math.NA"}
{"title": "A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference", "abstract": "Accurately estimating parameters of physiological models is essential to\nachieving reliable digital twins. For Type 1 Diabetes, this is particularly\nchallenging due to the complexity of glucose-insulin interactions. Traditional\nmethods based on Markov Chain Monte Carlo struggle with high-dimensional\nparameter spaces and fit parameters from scratch at inference time, making them\nslow and computationally expensive. In this study, we propose a\nSimulation-Based Inference approach based on Neural Posterior Estimation to\nefficiently capture the complex relationships between meal intake, insulin, and\nglucose level, providing faster, amortized inference. Our experiments\ndemonstrate that SBI not only outperforms traditional methods in parameter\nestimation but also generalizes better to unseen conditions, offering real-time\nposterior inference with reliable uncertainty quantification.", "published": "2025-07-02 14:21:03", "link": "http://arxiv.org/abs/2507.01740v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Token Communication in the Era of Large Models: An Information Bottleneck-Based Approach", "abstract": "This letter proposes UniToCom, a unified token communication paradigm that\ntreats tokens as the fundamental units for both processing and wireless\ntransmission. Specifically, to enable efficient token representations, we\npropose a generative information bottleneck (GenIB) principle, which\nfacilitates the learning of tokens that preserve essential information while\nsupporting reliable generation across multiple modalities. By doing this,\nGenIB-based tokenization is conducive to improving the communication efficiency\nand reducing computational complexity. Additionally, we develop $\\sigma$-GenIB\nto address the challenges of variance collapse in autoregressive modeling,\nmaintaining representational diversity and stability. Moreover, we employ a\ncausal Transformer-based multimodal large language model (MLLM) at the receiver\nto unify the processing of both discrete and continuous tokens under the\nnext-token prediction paradigm. Simulation results validate the effectiveness\nand superiority of the proposed UniToCom compared to baselines under dynamic\nchannel conditions. By integrating token processing with MLLMs, UniToCom\nenables scalable and generalizable communication in favor of multimodal\nunderstanding and generation, providing a potential solution for\nnext-generation intelligent communications.", "published": "2025-07-02 14:03:01", "link": "http://arxiv.org/abs/2507.01728v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Revisiting Learning Rate Control", "abstract": "The learning rate is one of the most important hyperparameters in deep\nlearning, and how to control it is an active area within both AutoML and deep\nlearning research. Approaches for learning rate control span from classic\noptimization to online scheduling based on gradient statistics. This paper\ncompares paradigms to assess the current state of learning rate control. We\nfind that methods from multi-fidelity hyperparameter optimization,\nfixed-hyperparameter schedules, and hyperparameter-free learning often perform\nvery well on selected deep learning tasks but are not reliable across settings.\nThis highlights the need for algorithm selection methods in learning rate\ncontrol, which have been neglected so far by both the AutoML and deep learning\ncommunities. We also observe a trend of hyperparameter optimization approaches\nbecoming less effective as models and tasks grow in complexity, even when\ncombined with multi-fidelity approaches for more expensive model trainings. A\nfocus on more relevant test tasks and new promising directions like finetunable\nmethods and meta-learning will enable the AutoML community to significantly\nstrengthen its impact on this crucial factor in deep learning.", "published": "2025-07-02 13:58:38", "link": "http://arxiv.org/abs/2507.01724v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling", "abstract": "Training physics-informed neural networks (PINNs) for forward problems often\nsuffers from severe convergence issues, hindering the propagation of\ninformation from regions where the desired solution is well-defined.\nHaitsiukevich and Ilin (2023) proposed an ensemble approach that extends the\nactive training domain of each PINN based on i) ensemble consensus and ii)\nvicinity to (pseudo-)labeled points, thus ensuring that the information from\nthe initial condition successfully propagates to the interior of the\ncomputational domain.\n  In this work, we suggest replacing the ensemble by a Bayesian PINN, and\nconsensus by an evaluation of the PINN's posterior variance. Our experiments\nshow that this mathematically principled approach outperforms the ensemble on a\nset of benchmark problems and is competitive with PINN ensembles trained with\ncombinations of Adam and LBFGS.", "published": "2025-07-02 13:44:31", "link": "http://arxiv.org/abs/2507.01714v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Variational Graph Convolutional Neural Networks", "abstract": "Estimation of model uncertainty can help improve the explainability of Graph\nConvolutional Networks and the accuracy of the models at the same time.\nUncertainty can also be used in critical applications to verify the results of\nthe model by an expert or additional models. In this paper, we propose\nVariational Neural Network versions of spatial and spatio-temporal Graph\nConvolutional Networks. We estimate uncertainty in both outputs and layer-wise\nattentions of the models, which has the potential for improving model\nexplainability. We showcase the benefits of these models in the social trading\nanalysis and the skeleton-based human action recognition tasks on the Finnish\nboard membership, NTU-60, NTU-120 and Kinetics datasets, where we show\nimprovement in model accuracy in addition to estimated model uncertainties.", "published": "2025-07-02 13:28:37", "link": "http://arxiv.org/abs/2507.01699v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamic Similarity Graph Construction with Kernel Density Estimation", "abstract": "In the kernel density estimation (KDE) problem, we are given a set $X$ of\ndata points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in\n\\mathbb{R}^d$, and the objective is to quickly output an estimate of\n$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider\n$\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that\nefficiently maintains the estimates for a set of query points as data points\nare added to $X$ over time. Based on this, we design a dynamic data structure\nthat maintains a sparse approximation of the fully connected similarity graph\non $X$, and develop a fast dynamic spectral clustering algorithm. We further\nevaluate the effectiveness of our algorithms on both synthetic and real-world\ndatasets.", "published": "2025-07-02 13:25:22", "link": "http://arxiv.org/abs/2507.01696v1", "categories": ["cs.DS", "cs.LG"], "primary_category": "cs.DS"}
{"title": "PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution", "abstract": "Deep neural networks (DNNs) have become ubiquitous thanks to their remarkable\nability to model complex patterns across various domains such as computer\nvision, speech recognition, robotics, etc. While large DNN models are often\nmore accurate than simpler, lightweight models, they are also resource- and\nenergy-hungry. Hence, it is imperative to design methods to reduce reliance on\nsuch large models without significant degradation in output accuracy. The high\ncomputational cost of these models is often necessary only for a reduced set of\nchallenging inputs, while lighter models can handle most simple ones. Thus,\ncarefully combining properties of existing DNN models in a dynamic, input-based\nway opens opportunities to improve efficiency without impacting accuracy.\n  In this work, we introduce PERTINENCE, a novel online method designed to\nanalyze the complexity of input features and dynamically select the most\nsuitable model from a pre-trained set to process a given input effectively. To\nachieve this, we employ a genetic algorithm to explore the training space of an\nML-based input dispatcher, enabling convergence towards the Pareto front in the\nsolution space that balances overall accuracy and computational efficiency.\n  We showcase our approach on state-of-the-art Convolutional Neural Networks\n(CNNs) trained on the CIFAR-10 and CIFAR-100, as well as Vision Transformers\n(ViTs) trained on TinyImageNet dataset. We report results showing PERTINENCE's\nability to provide alternative solutions to existing state-of-the-art models in\nterms of trade-offs between accuracy and number of operations. By\nopportunistically selecting among models trained for the same task, PERTINENCE\nachieves better or comparable accuracy with up to 36% fewer operations.", "published": "2025-07-02 13:22:05", "link": "http://arxiv.org/abs/2507.01695v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A generative modeling / Physics-Informed Neural Network approach to random differential equations", "abstract": "The integration of Scientific Machine Learning (SciML) techniques with\nuncertainty quantification (UQ) represents a rapidly evolving frontier in\ncomputational science. This work advances Physics-Informed Neural Networks\n(PINNs) by incorporating probabilistic frameworks to effectively model\nuncertainty in complex systems. Our approach enhances the representation of\nuncertainty in forward problems by combining generative modeling techniques\nwith PINNs. This integration enables in a systematic fashion uncertainty\ncontrol while maintaining the predictive accuracy of the model. We demonstrate\nthe utility of this method through applications to random differential\nequations and random partial differential equations (PDEs).", "published": "2025-07-02 13:14:17", "link": "http://arxiv.org/abs/2507.01687v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Dance Dance ConvLSTM", "abstract": "\\textit{Dance Dance Revolution} is a rhythm game consisting of songs and\naccompanying choreography, referred to as charts. Players press arrows on a\ndevice referred to as a dance pad in time with steps determined by the song's\nchart. In 2017, the authors of Dance Dance Convolution (DDC) developed an\nalgorithm for the automatic generation of \\textit{Dance Dance Revolution}\ncharts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM\n(DDCL), a new method for the automatic generation of DDR charts using a\nConvLSTM based model, which improves upon the DDC methodology and substantially\nincreases the accuracy of chart generation.", "published": "2025-07-02 12:17:33", "link": "http://arxiv.org/abs/2507.01644v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Kernel Recursive Least Squares Dictionary Learning Algorithm", "abstract": "We propose an efficient online dictionary learning algorithm for kernel-based\nsparse representations. In this framework, input signals are nonlinearly mapped\nto a high-dimensional feature space and represented sparsely using a virtual\ndictionary. At each step, the dictionary is updated recursively using a novel\nalgorithm based on the recursive least squares (RLS) method. This update\nmechanism works with single samples or mini-batches and maintains low\ncomputational complexity. Experiments on four datasets across different domains\nshow that our method not only outperforms existing online kernel dictionary\nlearning approaches but also achieves classification accuracy close to that of\nbatch-trained models, while remaining significantly more efficient.", "published": "2025-07-02 12:07:35", "link": "http://arxiv.org/abs/2507.01636v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "When Less Is More: Binary Feedback Can Outperform Ordinal Comparisons in Ranking Recovery", "abstract": "Paired comparison data, where users evaluate items in pairs, play a central\nrole in ranking and preference learning tasks. While ordinal comparison data\nintuitively offer richer information than binary comparisons, this paper\nchallenges that conventional wisdom. We propose a general parametric framework\nfor modeling ordinal paired comparisons without ties. The model adopts a\ngeneralized additive structure, featuring a link function that quantifies the\npreference difference between two items and a pattern function that governs the\ndistribution over ordinal response levels. This framework encompasses classical\nbinary comparison models as special cases, by treating binary responses as\nbinarized versions of ordinal data. Within this framework, we show that\nbinarizing ordinal data can significantly improve the accuracy of ranking\nrecovery. Specifically, we prove that under the counting algorithm, the ranking\nerror associated with binary comparisons exhibits a faster exponential\nconvergence rate than that of ordinal data. Furthermore, we characterize a\nsubstantial performance gap between binary and ordinal data in terms of a\nsignal-to-noise ratio (SNR) determined by the pattern function. We identify the\npattern function that minimizes the SNR and maximizes the benefit of\nbinarization. Extensive simulations and a real application on the MovieLens\ndataset further corroborate our theoretical findings.", "published": "2025-07-02 11:30:38", "link": "http://arxiv.org/abs/2507.01613v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Analysis of Muon's Convergence and Critical Batch Size", "abstract": "This paper presents a theoretical analysis of Muon, a new optimizer that\nleverages the inherent matrix structure of neural network parameters. We\nprovide convergence proofs for four practical variants of Muon: with and\nwithout Nesterov momentum, and with and without weight decay. We then show that\nadding weight decay leads to strictly tighter bounds on both the parameter and\ngradient norms, and we clarify the relationship between the weight decay\ncoefficient and the learning rate. Finally, we derive Muon's critical batch\nsize minimizing the stochastic first-order oracle (SFO) complexity, which is\nthe stochastic computational cost, and validate our theoretical findings with\nexperiments.", "published": "2025-07-02 11:03:13", "link": "http://arxiv.org/abs/2507.01598v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Privacy-Preserving Indoor Localization System based on Hierarchical Federated Learning", "abstract": "Location information serves as the fundamental element for numerous Internet\nof Things (IoT) applications. Traditional indoor localization techniques often\nproduce significant errors and raise privacy concerns due to centralized data\ncollection. In response, Machine Learning (ML) techniques offer promising\nsolutions by capturing indoor environment variations. However, they typically\nrequire central data aggregation, leading to privacy, bandwidth, and server\nreliability issues. To overcome these challenges, in this paper, we propose a\nFederated Learning (FL)-based approach for dynamic indoor localization using a\nDeep Neural Network (DNN) model. Experimental results show that FL has the\nnearby performance to Centralized Model (CL) while keeping the data privacy,\nbandwidth efficiency and server reliability. This research demonstrates that\nour proposed FL approach provides a viable solution for privacy-enhanced indoor\nlocalization, paving the way for advancements in secure and efficient indoor\nlocalization systems.", "published": "2025-07-02 10:53:31", "link": "http://arxiv.org/abs/2507.01581v1", "categories": ["cs.LG", "cs.CR", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability", "abstract": "Accurate indoor localization is crucial in industrial environments. Visible\nLight Communication (VLC) has emerged as a promising solution, offering high\naccuracy, energy efficiency, and minimal electromagnetic interference. However,\nVLC-based indoor localization faces challenges due to environmental\nvariability, such as lighting fluctuations and obstacles. To address these\nchallenges, we propose a Transfer Learning (TL)-based approach for VLC-based\nindoor localization. Using real-world data collected at a BOSCH factory, the TL\nframework integrates a deep neural network (DNN) to improve localization\naccuracy by 47\\%, reduce energy consumption by 32\\%, and decrease computational\ntime by 40\\% compared to the conventional models. The proposed solution is\nhighly adaptable under varying environmental conditions and achieves similar\naccuracy with only 30\\% of the dataset, making it a cost-efficient and scalable\noption for industrial applications in Industry 4.0.", "published": "2025-07-02 10:51:38", "link": "http://arxiv.org/abs/2507.01575v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "On the Effect of Ruleset Tuning and Data Imbalance on Explainable Network Security Alert Classifications: a Case-Study on DeepCASE", "abstract": "Automation in Security Operations Centers (SOCs) plays a prominent role in\nalert classification and incident escalation. However, automated methods must\nbe robust in the presence of imbalanced input data, which can negatively affect\nperformance. Additionally, automated methods should make explainable decisions.\nIn this work, we evaluate the effect of label imbalance on the classification\nof network intrusion alerts. As our use-case we employ DeepCASE, the\nstate-of-the-art method for automated alert classification. We show that label\nimbalance impacts both classification performance and correctness of the\nclassification explanations offered by DeepCASE. We conclude tuning the\ndetection rules used in SOCs can significantly reduce imbalance and may benefit\nthe performance and explainability offered by alert post-processing methods\nsuch as DeepCASE. Therefore, our findings suggest that traditional methods to\nimprove the quality of input data can benefit automation.", "published": "2025-07-02 10:47:42", "link": "http://arxiv.org/abs/2507.01571v1", "categories": ["cs.CR", "cs.LG", "cs.NI"], "primary_category": "cs.CR"}
{"title": "MARVIS: Modality Adaptive Reasoning over VISualizations", "abstract": "Scientific applications of machine learning often rely on small, specialized\nmodels tuned to particular domains. Such models often achieve excellent\nperformance, but lack flexibility. Foundation models offer versatility, but\ntypically underperform specialized approaches, especially on non-traditional\nmodalities and long-tail domains. We propose MARVIS (Modality Adaptive\nReasoning over VISualizations), a training-free method that enables even small\nvision-language models to predict any data modality with high accuracy. MARVIS\ntransforms latent embedding spaces into visual representations and then\nleverages the spatial and fine-grained reasoning skills of VLMs to successfully\ninterpret and utilize them. MARVIS achieves competitive performance on vision,\naudio, biological, and tabular domains using a single 3B parameter model,\nachieving results that beat Gemini by 16\\% on average and approach specialized\nmethods, without exposing personally identifiable information (P.I.I.) or\nrequiring any domain-specific training. We open source our code and datasets at\nhttps://github.com/penfever/marvis", "published": "2025-07-02 09:56:24", "link": "http://arxiv.org/abs/2507.01544v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles", "abstract": "Gaussian mixture models (GMMs) are ubiquitous in statistical learning,\nparticularly for unsupervised problems. While full GMMs suffer from the\noverparameterization of their covariance matrices in high-dimensional spaces,\nspherical GMMs (with isotropic covariance matrices) certainly lack flexibility\nto fit certain anisotropic distributions. Connecting these two extremes, we\nintroduce a new family of parsimonious GMMs with piecewise-constant covariance\neigenvalue profiles. These extend several low-rank models like the celebrated\nmixtures of probabilistic principal component analyzers (MPPCA), by enabling\nany possible sequence of eigenvalue multiplicities. If the latter are\nprespecified, then we can naturally derive an expectation-maximization (EM)\nalgorithm to learn the mixture parameters. Otherwise, to address the\nnotoriously-challenging issue of jointly learning the mixture parameters and\nhyperparameters, we propose a componentwise penalized EM algorithm, whose\nmonotonicity is proven. We show the superior likelihood-parsimony tradeoffs\nachieved by our models on a variety of unsupervised experiments: density\nfitting, clustering and single-image denoising.", "published": "2025-07-02 09:52:56", "link": "http://arxiv.org/abs/2507.01542v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Consistency of Learned Sparse Grid Quadrature Rules using NeuralODEs", "abstract": "This paper provides a proof of the consistency of sparse grid quadrature for\nnumerical integration of high dimensional distributions. In a first step, a\ntransport map is learned that normalizes the distribution to a noise\ndistribution on the unit cube. This step is built on the statistical learning\ntheory of neural ordinary differential equations, which has been established\nrecently. Secondly, the composition of the generative map with the quantity of\ninterest is integrated numerically using the Clenshaw-Curtis sparse grid\nquadrature. A decomposition of the total numerical error in quadrature error\nand statistical error is provided. As main result it is proven in the framework\nof empirical risk minimization that all error terms can be controlled in the\nsense of PAC (probably approximately correct) learning and with high\nprobability the numerical integral approximates the theoretical value up to an\narbitrary small error in the limit where the data set size is growing and the\nnetwork capacity is increased adaptively.", "published": "2025-07-02 09:37:16", "link": "http://arxiv.org/abs/2507.01533v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Loss Functions in Diffusion Models: A Comparative Study", "abstract": "Diffusion models have emerged as powerful generative models, inspiring\nextensive research into their underlying mechanisms. One of the key questions\nin this area is the loss functions these models shall train with. Multiple\nformulations have been introduced in the literature over the past several years\nwith some links and some critical differences stemming from various initial\nconsiderations. In this paper, we explore the different target objectives and\ncorresponding loss functions in detail. We present a systematic overview of\ntheir relationships, unifying them under the framework of the variational lower\nbound objective. We complement this theoretical analysis with an empirical\nstudy providing insights into the conditions under which these objectives\ndiverge in performance and the underlying factors contributing to such\ndeviations. Additionally, we evaluate how the choice of objective impacts the\nmodel ability to achieve specific goals, such as generating high-quality\nsamples or accurately estimating likelihoods. This study offers a unified\nunderstanding of loss functions in diffusion models, contributing to more\nefficient and goal-oriented model designs in future research.", "published": "2025-07-02 09:23:34", "link": "http://arxiv.org/abs/2507.01516v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Meteoroid stream identification with HDBSCAN unsupervised clustering algorithm", "abstract": "Accurate identification of meteoroid streams is central to understanding\ntheir origins and evolution. However, overlapping clusters and background noise\nhinder classification, an issue amplified for missions such as ESA's LUMIO that\nrely on meteor shower observations to infer lunar meteoroid impact parameters.\nThis study evaluates the performance of the Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) algorithm for unsupervised\nmeteoroid stream identification, comparing its outcomes with the established\nCameras for All-Sky Meteor Surveillance (CAMS) look-up table method. We analyze\nthe CAMS Meteoroid Orbit Database v3.0 using three feature vectors: LUTAB (CAMS\ngeocentric parameters), ORBIT (heliocentric orbital elements), and GEO (adapted\ngeocentric parameters). HDBSCAN is applied with varying minimum cluster sizes\nand two cluster selection methods (eom and leaf). To align HDBSCAN clusters\nwith CAMS classifications, the Hungarian algorithm determines the optimal\nmapping. Clustering performance is assessed via the Silhouette score,\nNormalized Mutual Information, and F1 score, with Principal Component Analysis\nfurther supporting the analysis. With the GEO vector, HDBSCAN confirms 39\nmeteoroid streams, 21 strongly aligning with CAMS. The ORBIT vector identifies\n30 streams, 13 with high matching scores. Less active showers pose\nidentification challenges. The eom method consistently yields superior\nperformance and agreement with CAMS. Although HDBSCAN requires careful\nselection of the minimum cluster size, it delivers robust, internally\nconsistent clusters and outperforms the look-up table method in statistical\ncoherence. These results underscore HDBSCAN's potential as a mathematically\nconsistent alternative for meteoroid stream identification, although further\nvalidation is needed to assess physical validity.", "published": "2025-07-02 09:04:44", "link": "http://arxiv.org/abs/2507.01501v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "primary_category": "astro-ph.EP"}
{"title": "How to Securely Shuffle? A survey about Secure Shufflers for privacy-preserving computations", "abstract": "Ishai et al. (FOCS'06) introduced secure shuffling as an efficient building\nblock for private data aggregation. Recently, the field of differential privacy\nhas revived interest in secure shufflers by highlighting the privacy\namplification they can provide in various computations. Although several works\nargue for the utility of secure shufflers, they often treat them as black\nboxes; overlooking the practical vulnerabilities and performance trade-offs of\nexisting implementations. This leaves a central question open: what makes a\ngood secure shuffler?\n  This survey addresses that question by identifying, categorizing, and\ncomparing 26 secure protocols that realize the necessary shuffling\nfunctionality. To enable a meaningful comparison, we adapt and unify existing\nsecurity definitions into a consistent set of properties. We also present an\noverview of privacy-preserving technologies that rely on secure shufflers,\noffer practical guidelines for selecting appropriate protocols, and outline\npromising directions for future work.", "published": "2025-07-02 08:48:53", "link": "http://arxiv.org/abs/2507.01487v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Cross-platform Smartphone Positioning at Museums", "abstract": "Indoor Positioning Systems (IPSs) hold significant potential for enhancing\nvisitor experiences in cultural heritage institutions. By enabling personalized\nnavigation, efficient artifact organization, and better interaction with\nexhibits, IPSs can transform the modalities of how individuals engage with\nmuseums, galleries and libraries. However, these institutions face several\nchallenges in implementing IPSs, including environmental constraints, technical\nlimits, and limited experimentation. In other contexts, Received Signal\nStrength (RSS)-based approaches using Bluetooth Low Energy (BLE) and WiFi have\nemerged as preferred solutions due to their non-invasive nature and minimal\ninfrastructure requirements. Nevertheless, the lack of publicly available RSS\ndatasets that specifically reflect museum environments presents a substantial\nbarrier to developing and evaluating positioning algorithms designed for the\nintricate spatial characteristics typical of cultural heritage sites. To\naddress this limitation, we present BAR, a novel RSS dataset collected in front\nof 90 artworks across 13 museum rooms using two different platforms, i.e.,\nAndroid and iOS. Additionally, we provide an advanced position classification\nbaseline taking advantage of a proximity-based method and $k$-NN algorithms. In\nour analysis, we discuss the results and offer suggestions for potential\nresearch directions.", "published": "2025-07-02 08:31:12", "link": "http://arxiv.org/abs/2507.01469v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Symbolic identification of tensor equations in multidimensional physical fields", "abstract": "Recently, data-driven methods have shown great promise for discovering\ngoverning equations from simulation or experimental data. However, most\nexisting approaches are limited to scalar equations, with few capable of\nidentifying tensor relationships. In this work, we propose a general\ndata-driven framework for identifying tensor equations, referred to as Symbolic\nIdentification of Tensor Equations (SITE). The core idea of SITE--representing\ntensor equations using a host-plasmid structure--is inspired by the\nmultidimensional gene expression programming (M-GEP) approach. To improve the\nrobustness of the evolutionary process, SITE adopts a genetic information\nretention strategy. Moreover, SITE introduces two key innovations beyond\nconventional evolutionary algorithms. First, it incorporates a dimensional\nhomogeneity check to restrict the search space and eliminate physically invalid\nexpressions. Second, it replaces traditional linear scaling with a tensor\nlinear regression technique, greatly enhancing the efficiency of numerical\ncoefficient optimization. We validate SITE using two benchmark scenarios, where\nit accurately recovers target equations from synthetic data, showing robustness\nto noise and small sample sizes. Furthermore, SITE is applied to identify\nconstitutive relations directly from molecular simulation data, which are\ngenerated without reliance on macroscopic constitutive models. It adapts to\nboth compressible and incompressible flow conditions and successfully\nidentifies the corresponding macroscopic forms, highlighting its potential for\ndata-driven discovery of tensor equation.", "published": "2025-07-02 08:25:05", "link": "http://arxiv.org/abs/2507.01466v1", "categories": ["math-ph", "cs.LG", "math.MP"], "primary_category": "math-ph"}
{"title": "Decomposing Prediction Mechanisms for In-Context Recall", "abstract": "We introduce a new family of toy problems that combine features of\nlinear-regression-style continuous in-context learning (ICL) with discrete\nassociative recall. We pretrain transformer models on sample traces from this\ntoy, specifically symbolically-labeled interleaved state observations from\nrandomly drawn linear deterministic dynamical systems. We study if the\ntransformer models can recall the state of a sequence previously seen in its\ncontext when prompted to do so with the corresponding in-context label. Taking\na closer look at this task, it becomes clear that the model must perform two\nfunctions: (1) identify which system's state should be recalled and apply that\nsystem to its last seen state, and (2) continuing to apply the correct system\nto predict the subsequent states. Training dynamics reveal that the first\ncapability emerges well into a model's training. Surprisingly, the second\ncapability, of continuing the prediction of a resumed sequence, develops much\nearlier.\n  Via out-of-distribution experiments, and a mechanistic analysis on model\nweights via edge pruning, we find that next-token prediction for this toy\nproblem involves at least two separate mechanisms. One mechanism uses the\ndiscrete symbolic labels to do the associative recall required to predict the\nstart of a resumption of a previously seen sequence. The second mechanism,\nwhich is largely agnostic to the discrete symbolic labels, performs a\n\"Bayesian-style\" prediction based on the previous token and the context. These\ntwo mechanisms have different learning dynamics.\n  To confirm that this multi-mechanism (manifesting as separate phase\ntransitions) phenomenon is not just an artifact of our toy setting, we used\nOLMo training checkpoints on an ICL translation task to see a similar\nphenomenon: a decisive gap in the emergence of first-task-token performance vs\nsecond-task-token performance.", "published": "2025-07-02 07:09:09", "link": "http://arxiv.org/abs/2507.01414v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Surrogate Modeling via Factorization Machine and Ising Model with Enhanced Higher-Order Interaction Learning", "abstract": "Recently, a surrogate model was proposed that employs a factorization machine\nto approximate the underlying input-output mapping of the original system, with\nquantum annealing used to optimize the resulting surrogate function. Inspired\nby this approach, we propose an enhanced surrogate model that incorporates\nadditional slack variables into both the factorization machine and its\nassociated Ising representation thereby unifying what was by design a two-step\nprocess into a single, integrated step. During the training phase, the slack\nvariables are iteratively updated, enabling the model to account for\nhigher-order feature interactions. We apply the proposed method to the task of\npredicting drug combination effects. Experimental results indicate that the\nintroduction of slack variables leads to a notable improvement of performance.\nOur algorithm offers a promising approach for building efficient surrogate\nmodels that exploit potential quantum advantages.", "published": "2025-07-02 06:10:49", "link": "http://arxiv.org/abs/2507.01389v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion", "abstract": "Effective hydrological modeling and extreme weather analysis demand\nprecipitation data at a kilometer-scale resolution, which is significantly\nfiner than the 10 km scale offered by standard global products like IMERG. To\naddress this, we propose the Wavelet Diffusion Model (WDM), a generative\nframework that achieves 10x spatial super-resolution (downscaling to 1 km) and\ndelivers a 9x inference speedup over pixel-based diffusion models. WDM is a\nconditional diffusion model that learns the learns the complex structure of\nprecipitation from MRMS radar data directly in the wavelet domain. By focusing\non high-frequency wavelet coefficients, it generates exceptionally realistic\nand detailed 1-km precipitation fields. This wavelet-based approach produces\nvisually superior results with fewer artifacts than pixel-space models, and\ndelivers a significant gains in sampling efficiency. Our results demonstrate\nthat WDM provides a robust solution to the dual challenges of accuracy and\nspeed in geoscience super-resolution, paving the way for more reliable\nhydrological forecasts.", "published": "2025-07-02 04:46:28", "link": "http://arxiv.org/abs/2507.01354v1", "categories": ["cs.LG", "physics.ao-ph", "86A10 (Primary) 86A22, 68U10 (Secondary)", "J.2; I.4.4"], "primary_category": "cs.LG"}
{"title": "Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability", "abstract": "Precisely classifying earthquake types is crucial for elucidating the\nrelationship between volcanic earthquakes and volcanic activity. However,\ntraditional methods rely on subjective human judgment, which requires\nconsiderable time and effort. To address this issue, we developed a deep\nlearning model using a transformer encoder for a more objective and efficient\nclassification. Tested on Mount Asama's diverse seismic activity, our model\nachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency\nearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.\nTo enhance interpretability, attention weight visualizations were analyzed,\nrevealing that the model focuses on key waveform features similarly to human\nexperts. However, inconsistencies in training data, such as ambiguously labeled\nB-type events with S-waves, were found to influence classification accuracy and\nattention weight distributions. Experiments addressing data selection and\naugmentation demonstrated the importance of balancing data quality and\ndiversity. In addition, stations within 3 km of the crater played an important\nrole in improving model performance and interpretability. These findings\nhighlight the potential of Transformer-based models for automated volcanic\nearthquake classification, particularly in improving efficiency and\ninterpretability. By addressing challenges such as data imbalance and\nsubjective labeling, our approach provides a robust framework for understanding\nseismic activity at Mount Asama. Moreover, this framework offers opportunities\nfor transfer learning to other volcanic regions, paving the way for enhanced\nvolcanic hazard assessments and disaster mitigation strategies.", "published": "2025-07-02 00:37:07", "link": "http://arxiv.org/abs/2507.01260v1", "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "physics.geo-ph"}
{"title": "Distance-based Relative Orbital Transition for Satellite Swarm Array Deployment Under J2 Perturbation", "abstract": "This paper presents an autonomous guidance and control strategy for a\nsatellite swarm that enables scalable distributed space structures for\ninnovative science and business opportunities. The averaged $J_2$ orbital\nparameters that describe the drift and periodic orbital motion were derived\nalong with their target values to achieve a distributed space structure in a\ndecentralized manner. This enabled the design of a distance-based orbital\nstabilizer to ensure autonomous deployment into a monolithic formation of a\ncoplanar equidistant configuration on a user-defined orbital plane. Continuous\nformation control was assumed to be achieved through fuel-free actuation, such\nas satellite magnetic field interaction and differential aerodynamic forces,\nthereby maintaining long-term formation stability without thruster usage. A\nmajor challenge for such actuation systems is the potential loss of control\ncapability due to increasing inter-satellite distances resulting from unstable\norbital dynamics, particularly for autonomous satellite swarms. To mitigate\nthis risk, our decentralized deployment controller minimized drift distance\nduring unexpected communication outages. As a case study, we consider the\ndeployment of palm-sized satellites into a coplanar equidistant formation in a\n$J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.", "published": "2025-07-02 14:50:21", "link": "http://arxiv.org/abs/2507.01769v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Cooperative Target Capture in 3D Engagements over Switched Dynamic Graphs", "abstract": "This paper presents a leaderless cooperative guidance strategy for\nsimultaneous time-constrained interception of a stationary target when the\ninterceptors exchange information over switched dynamic graphs. We specifically\nfocus on scenarios when the interceptors lack radial acceleration capabilities,\nrelying solely on their lateral acceleration components. This consideration\naligns with their inherent kinematic turn constraints. The proposed strategy\nexplicitly addresses the complexities of coupled 3D engagements, thereby\nmitigating performance degradation that typically arises when the pitch and yaw\nchannels are decoupled into two separate, mutually orthogonal planar\nengagements. Moreover, our formulation incorporates modeling uncertainties\nassociated with the time-to-go estimation into the derivation of cooperative\nguidance commands to ensure robustness against inaccuracies in dynamic\nengagement scenarios. To optimize control efficiency, we analytically derive\nthe lateral acceleration components in the orthogonal pitch and yaw channels by\nsolving an instantaneous optimization problem, subject to an affine constraint.\nWe show that the proposed cooperative guidance commands guarantee consensus in\ntime-to-go values within a predefined time, which can be prescribed as a design\nparameter, regardless of the interceptors' initial configurations. We provide\nsimulations to attest to the efficacy of the proposed method.", "published": "2025-07-02 04:37:37", "link": "http://arxiv.org/abs/2507.01350v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Optimal Dispersion Under Asynchrony", "abstract": "We study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\n  The goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\n  In this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.", "published": "2025-07-02 02:36:01", "link": "http://arxiv.org/abs/2507.01298v1", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "primary_category": "cs.DC"}
{"title": "Parallel-in-Time Preconditioning for Time-Dependent Variational Mean Field Games", "abstract": "We study the numerical approximation of a time-dependent variational mean\nfield game system with local couplings and either periodic or Neumann boundary\nconditions. Following a variational approach, we employ a finite difference\ndiscretization and solve the resulting finite-dimensional optimization problem\nusing the Chambolle--Pock primal--dual algorithm. As this involves computing\nproximal operators and solving ill-conditioned linear systems at each\niteration, we propose a general class of parallel-in-time preconditioners based\non diagonalization techniques using discrete Fourier transforms. These enable\nefficient, scalable iterative solvers with robustness across a wide range of\nviscosities. We further develop fast solvers for the resulting ill-conditioned\nsystems arising at each time step, using exact recursive schemes for structured\ngrids while allowing for other geometries. Numerical experiments confirm the\nimproved performance and parallel scalability of our approach.", "published": "2025-07-02 17:59:34", "link": "http://arxiv.org/abs/2507.01958v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "PDE-Constrained High-Order Mesh Optimization", "abstract": "We present a novel framework for PDE-constrained $r$-adaptivity of high-order\nmeshes. The proposed method formulates mesh movement as an optimization\nproblem, with an objective function defined as a convex combination of a mesh\nquality metric and a measure of the accuracy of the PDE solution obtained via\nfinite element discretization. The proposed formulation achieves optimized,\nwell-defined high-order meshes by integrating mesh quality control, PDE\nsolution accuracy, and robust gradient regularization. We adopt the\nTarget-Matrix Optimization Paradigm to control geometric properties across the\nmesh, independent of the PDE of interest. To incorporate the accuracy of the\nPDE solution, we introduce error measures that control the finite element\ndiscretization error. The implicit dependence of these error measures on the\nmesh nodal positions is accurately captured by adjoint sensitivity analysis.\nAdditionally, a convolution-based gradient regularization strategy is used to\nensure stable and effective adaptation of high-order meshes. We demonstrate\nthat the proposed framework can improve mesh quality and reduce the error by up\nto 10 times for the solution of Poisson and linear elasto-static problems. The\napproach is general with respect to the dimensionality, the order of the mesh,\nthe types of mesh elements, and can be applied to any PDE that admits\nwell-defined adjoint operators.", "published": "2025-07-02 17:26:33", "link": "http://arxiv.org/abs/2507.01917v1", "categories": ["math.NA", "cs.MS", "cs.NA"], "primary_category": "math.NA"}
{"title": "Faber polynomials in a deltoid region and power iteration momentum methods", "abstract": "We consider a region in the complex plane enclosed by a deltoid curve\ninscribed in the unit circle, and define a family of polynomials $P_n$ that\nsatisfy the same recurrence relation as the Faber polynomials for this region.\nWe use this family of polynomials to give a constructive proof that $z^n$ is\napproximately a polynomial of degree $\\sim\\sqrt{n}$ within the deltoid region.\nMoreover, we show that $|P_n| \\le 1$ in this deltoid region, and that, if $|z|\n= 1+\\varepsilon$, then the magnitude $|P_n(z)|$ is at least\n$\\frac{1}{3}(1+\\sqrt{\\varepsilon})^n$, for all $\\varepsilon > 0$. We illustrate\nour polynomial approximation theory with an application to iterative linear\nalgebra. In particular, we construct a higher-order momentum-based method that\naccelerates the power iteration for certain matrices with complex eigenvalues.\nWe show how the method can be run dynamically when the two dominant eigenvalues\nare real and positive.", "published": "2025-07-02 16:55:49", "link": "http://arxiv.org/abs/2507.01885v1", "categories": ["math.NA", "cs.NA", "math.CA", "math.PR"], "primary_category": "math.NA"}
{"title": "The inverse source problem of stochastic wave equation", "abstract": "To address the ill-posedness of the inverse source problem for the\none-dimensional stochastic Helmholtz equations without attenuation, this study\ndevelops a novel computational framework designed to mitigate this inherent\nchallenge at the numerical implementation level. For the stochastic wave\nequation driven by a finite-jump L\\'evy process (assuming that its jump\namplitude obeys a Gaussian distribution and the jump time interval obeys a\nPoisson distribution), this paper firstly establish the existence of a mild\nsolution to its direct problem satisfying a particular stability estimate.\nBuilding upon these theoretical foundations, we further investigate the\nwell-posedness of the inverse problem and develop a methodology to reconstruct\nthe unknown source terms $f$ and $g$ using the data of the wave field at the\nfinal time point $u(x,T)$. This work not only provides rigorous theoretical\nanalysis and effective numerical schemes for solving inverse source problems in\nthese two specific classes of stochastic wave equations, but also offers new\nperspectives and methodological approaches for addressing a broader range of\nwave propagation inverse problems characterized by non-Gaussian stochastic\nproperties. The proposed framework demonstrates significant relevance for\ncharacterizing physical phenomena influenced by jump-type stochastic\nperturbations, offering promising applications in diverse domains including but\nnot limited to seismic wave propagation analysis and financial market\nvolatility modeling.", "published": "2025-07-02 15:14:20", "link": "http://arxiv.org/abs/2507.01789v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination", "abstract": "The quality of simplex mesh is crucial for the stability and accuracy of\nnumerical simulations in finite element analysis and computational geometry.\nHowever, the presence of sliver elements in 3D simplex mesh can severely impact\nthe results. This paper presents a novel method based on a radius ratio energy\nfunction to optimize the quality of simplex mesh elements. This method can\neffectively eliminate sliver elements, thereby enhancing mesh quality.The\ngradient of the proposed energy function can be decomposed into a matrix-vector\nproduct. With minor processing, the matrix becomes symmetric positive definite,\nand this symmetric positive definite matrix can serve as a preconditioner to\nsignificantly accelerate the optimization process. Experimental results\ndemonstrate that this method has significant advantages in eliminating sliver\nelements and improving mesh quality.", "published": "2025-07-02 14:45:35", "link": "http://arxiv.org/abs/2507.01762v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "An energy-based discontinuous Galerkin method for the wave equation with nonsmooth solutions", "abstract": "We develop a stable and high-order accurate discontinuous Galerkin method for\nthe second order wave equation, specifically designed to handle nonsmooth\nsolutions. Our approach integrates the energy-based discontinuous Galerkin\nmethod with the oscillation-free technique to effectively suppress spurious\noscillations near solution discontinuities. Both stability analysis and apriori\nerror estimates are established for common choices of numerical fluxes. We\npresent a series of numerical experiments to confirm the optimal convergence\nrates for smooth solutions and its robustness in maintaining oscillation-free\nbehavior for nonsmooth solutions in wave equations without or with nonlinear\nsource terms.", "published": "2025-07-02 14:13:40", "link": "http://arxiv.org/abs/2507.01736v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A trust-region framework for optimization using Hermite kernel surrogate models", "abstract": "In this work, we present a trust-region optimization framework that employs\nHermite kernel surrogate models. The method targets optimization problems with\ncomputationally demanding objective functions, for which direct optimization is\noften impractical due to expensive function evaluations. To address these\nchallenges, we leverage a trust-region strategy, where the objective function\nis approximated by an efficient surrogate model within a local neighborhood of\nthe current iterate. In particular, we construct the surrogate using Hermite\nkernel interpolation and define the trust-region based on bounds for the\ninterpolation error. As mesh-free techniques, kernel-based methods are\nnaturally suited for medium- to high-dimensional problems. Furthermore, the\nHermite formulation incorporates gradient information, enabling precise\ngradient estimates that are crucial for many optimization algorithms. We prove\nthat the proposed algorithm converges to a stationary point, and we demonstrate\nits effectiveness through numerical experiments, which illustrate the\nconvergence behavior as well as the efficiency gains compared to direct\noptimization.", "published": "2025-07-02 14:03:11", "link": "http://arxiv.org/abs/2507.01729v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "A mixed Petrov--Galerkin Cosserat rod finite element formulation", "abstract": "This paper presents a total Lagrangian mixed Petrov--Galerkin finite element\nformulation that provides a computationally efficient approach for analyzing\nCosserat rods that is free of singularities and locking. To achieve a\nsingularity-free orientation parametrization of the rod, the nodal kinematical\nunknowns are defined as the nodal centerline positions and unit quaternions. We\napply Lagrangian interpolation to all nodal kinematic coordinates, and in\ncombination with a projection of non-unit quaternions, this leads to an\ninterpolation with orthonormal cross-section-fixed bases. To eliminate locking\neffects such as shear locking, the variational Hellinger--Reissner principle is\napplied, resulting in a mixed approach with additional fields composed of\nresultant contact forces and moments. Since the mixed formulation contains the\nconstitutive law in compliance form, it naturally incorporates constrained\ntheories, such as the Kirchhoff--Love theory. This study specifically examines\nthe influence of the additional internal force fields on the numerical\nperformance, including locking mitigation and robustness. Using\nwell-established benchmark examples, the method demonstrates enhanced\ncomputational robustness and efficiency, as evidenced by the reduction in\nrequired load steps and iterations when applying the standard Newton--Raphson\nmethod.", "published": "2025-07-02 10:07:17", "link": "http://arxiv.org/abs/2507.01552v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A surface finite element scheme for a stochastic PDE on an evolving curve", "abstract": "In this paper we consider an ESFEM method for the advection and diffusion of\na scalar quantity on a moving closed curve. The diffusion process is controlled\nby a forcing term that may include a rough term (specifically a stochastic\nnoise) which in particular destroys the classical time differentiability\nproperties of the solution. We provide a suitable variational solution concept\nand a fully discrete FEM discretization. Our error analysis appropriately\ngeneralizes classical estimates to this weaker setting. We present some\nnumerical simulations that confirm our theoretical findings.", "published": "2025-07-02 09:32:37", "link": "http://arxiv.org/abs/2507.01527v1", "categories": ["math.NA", "cs.NA", "60H35, 65M60, 65M15"], "primary_category": "math.NA"}
{"title": "An Optimal Least-Square Solver For Scaled Partial-Isometric Linear Systems", "abstract": "We present an $O(mn)$ direct least-squares solver for $m \\times n$ linear\nsystems with a scaled partial isometry. The proposed algorithm is also useful\nwhen the system is block diagonal and each block is a scaled partial isometry\nwith distinct scaling factors. We also include numerical experiments as a\ndemonstration.", "published": "2025-07-02 07:38:48", "link": "http://arxiv.org/abs/2507.01434v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Randomized subspace correction methods for convex optimization", "abstract": "This paper introduces an abstract framework for randomized subspace\ncorrection methods for convex optimization, which unifies and generalizes a\nbroad class of existing algorithms, including domain decomposition, multigrid,\nand block coordinate descent methods. We provide a convergence rate analysis\nranging from minimal assumptions to more practical settings, such as sharpness\nand strong convexity. While most existing studies on block coordinate descent\nmethods focus on nonoverlapping decompositions and smooth or strongly convex\nproblems, our framework extends to more general settings involving arbitrary\nspace decompositions, inexact local solvers, and problems with limited\nsmoothness or convexity. The proposed framework is broadly applicable to convex\noptimization problems arising in areas such as nonlinear partial differential\nequations, imaging, and data science.", "published": "2025-07-02 07:14:25", "link": "http://arxiv.org/abs/2507.01415v1", "categories": ["math.OC", "cs.NA", "math.NA", "90C25, 65N55, 65J05, 90C06"], "primary_category": "math.OC"}
{"title": "Asymptotic Preserving and Accurate scheme for Multiscale Poisson-Nernst-Planck (MPNP) system", "abstract": "In this paper, we propose and validate a two-species Multiscale model for a\nPoisson-Nernst-Planck (PNP) system, focusing on the correlated motion of\npositive and negative ions under the influence of a trap. Specifically, we aim\nto model surface traps whose attraction range, of length delta, is much smaller\nthen the scale of the problem. The physical setup we refer to is an anchored\ngas drop (bubble) surrounded by a diffusive flow of charged surfactants (ions).\nWhen the diffusing surfactants reach the surface of the trap, the anions are\nadsorbed. As in our previous works [11,6,9,4], the effect of the attractive\npotential is replaced by a suitable boundary condition derived by mass\nconservation and asymptotic analysis. The novelty of this work is the extension\nof the model proposed in [11], now incorporating the influence of both carriers\n- positive and negative ions - simultaneously, which is often neglected in\ntraditional approaches that treat ion species independently. In the second part\nof the paper, we address the treatment of the Coulomb interaction between\ncarriers. When the Debye length lambda_D (proportional to a small parameter\nepsilon) is very small, one can adopt the so-called Quasi-Neutral limit, which\nsignificantly simplifies the system, reducing it to a diffusion equation for a\nsingle carriers with effective diffusion coefficient [36,53]. This approach,\nwhile simplifying the mathematical model, does not capture the effects of non\nnegligible values of epsilon. When the Debye length is small but not\nnegligible, it may be very expensive to capture the small deviation from the\nQuasi-Neutral limit by standard methods in the literature. [...]", "published": "2025-07-02 06:33:15", "link": "http://arxiv.org/abs/2507.01402v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65M06 65M55 76D07 76M20 76R50"], "primary_category": "math.NA"}
{"title": "Reconstruction of the observable universe from the integrated Sachs-Wolfe effect", "abstract": "The integrated Sachs-Wolfe (ISW) effect is a property of the Cosmic Microwave\nBackground (CMB), in which photons from the CMB are gravitationally redshifted,\ncausing the anisotropies in the CMB. An intriguing question is whether one can\ninfer the gravitational perturbations from the ISW effect observed near the\nEarth. In this work, we address the question using a tomographic reconstruction\napproach, similar to X-ray CT reconstruction in medical imaging. We develop the\nmathematical analysis for the stable inversion of the X-ray transform in the\ncosmological setting. In addition, we provide a numerical study of\nreconstruction methods, thereby demonstrating the feasibility and potential of\nthe tomography method.", "published": "2025-07-02 06:30:21", "link": "http://arxiv.org/abs/2507.01399v1", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA"], "primary_category": "math-ph"}
{"title": "Stability and error analysis of a new class of higher-order consistent splitting schemes for the Navier-Stokes equations", "abstract": "A new class of fully decoupled consistent splitting schemes for the\nNavier-Stokes equations are constructed and analyzed in this paper. The schemes\nare based on the Taylor expansion at $t^{n+\\beta}$ with $\\beta\\ge 1$ being a\nfree parameter. It is shown that by choosing {\\color{black} $\\beta= 3,\n\\,6,\\,9$} respectively for the second-, third- and fourth-order schemes, their\nnumerical solutions are uniformed bounded in a strong norm, and admit optimal\nglobal-in-time convergence rates in both 2D and 3D. {\\color{black}These }\nresults are the first stability and convergence results for any fully\ndecoupled, higher than second-order schemes for the Navier-Stokes equations.\nNumerical results are provided to show that the third- and fourth-order schemes\nbased on the usual BDF (i.e. $\\beta=1$) are not unconditionally stable while\nthe new third- and fourth-order schemes with suitable $\\beta$ are\nunconditionally stable and lead to expected convergence rates.", "published": "2025-07-02 02:34:11", "link": "http://arxiv.org/abs/2507.01296v1", "categories": ["math.NA", "cs.NA", "65M12, 76D05, 65M15"], "primary_category": "math.NA"}
{"title": "Generative flow-based warm start of the variational quantum eigensolver", "abstract": "Hybrid quantum-classical algorithms like the variational quantum eigensolver\n(VQE) show promise for quantum simulations on near-term quantum devices, but\nare often limited by complex objective functions and expensive optimization\nprocedures. Here, we propose Flow-VQE, a generative framework leveraging\nconditional normalizing flows with parameterized quantum circuits to\nefficiently generate high-quality variational parameters. By embedding a\ngenerative model into the VQE optimization loop through preference-based\ntraining, Flow-VQE enables quantum gradient-free optimization and offers a\nsystematic approach for parameter transfer, accelerating convergence across\nrelated problems through warm-started optimization. We compare Flow-VQE to a\nnumber of standard benchmarks through numerical simulations on molecular\nsystems, including hydrogen chains, water, ammonia, and benzene. We find that\nFlow-VQE outperforms baseline optimization algorithms, achieving computational\naccuracy with fewer circuit evaluations (improvements range from modest to more\nthan two orders of magnitude) and, when used to warm-start the optimization of\nnew systems, accelerates subsequent fine-tuning by up to 50-fold compared with\nHartree--Fock initialization. Therefore, we believe Flow-VQE can become a\npragmatic and versatile paradigm for leveraging generative modeling to reduce\nthe costs of variational quantum algorithms.", "published": "2025-07-02 14:00:37", "link": "http://arxiv.org/abs/2507.01726v1", "categories": ["quant-ph", "physics.chem-ph", "stat.ML"], "primary_category": "quant-ph"}
{"title": "Entropic optimal transport beyond product reference couplings: the Gaussian case on Euclidean space", "abstract": "The optimal transport problem with squared Euclidean cost consists in finding\na coupling between two input measures that maximizes correlation. Consequently,\nthe optimal coupling is often singular with respect to Lebesgue measure.\nRegularizing the optimal transport problem with an entropy term yields an\napproximation called entropic optimal transport. Entropic penalties steer the\ninduced coupling toward a reference measure with desired properties. For\ninstance, when seeking a diffuse coupling, the most popular reference measures\nare the Lebesgue measure and the product of the two input measures. In this\nwork, we study the case where the reference coupling is not necessarily assumed\nto be a product. We focus on the Gaussian case as a motivating paradigm, and\nprovide a reduction of this more general optimal transport criterion to a\nmatrix optimization problem. This reduction enables us to provide a complete\ndescription of the solution, both in terms of the primal variable and the dual\nvariables. We argue that flexibility in terms of the reference measure can be\nimportant in statistical contexts, for instance when one has prior information,\nwhen there is uncertainty regarding the measures to be coupled, or to reduce\nbias when the entropic problem is used to estimate the un-regularized transport\nproblem. In particular, we show in numerical examples that choosing a suitable\nreference plan allows to reduce the bias caused by the entropic penalty.", "published": "2025-07-02 13:40:21", "link": "http://arxiv.org/abs/2507.01709v1", "categories": ["math.ST", "stat.ML", "stat.TH", "62H99", "G.3"], "primary_category": "math.ST"}
{"title": "Nonparametric learning of heterogeneous graphical model on network-linked data", "abstract": "Graphical models have been popularly used for capturing conditional\nindependence structure in multivariate data, which are often built upon\nindependent and identically distributed observations, limiting their\napplicability to complex datasets such as network-linked data. This paper\nproposes a nonparametric graphical model that addresses these limitations by\naccommodating heterogeneous graph structures without imposing any specific\ndistributional assumptions. The proposed estimation method effectively\nintegrates network embedding with nonparametric graphical model estimation. It\nfurther transforms the graph learning task into solving a finite-dimensional\nlinear equation system by leveraging the properties of vector-valued\nreproducing kernel Hilbert space. Moreover, theoretical guarantees are\nestablished for the proposed method in terms of the estimation consistency and\nexact recovery of the heterogeneous graph structures. Its effectiveness is also\ndemonstrated through a variety of simulated examples and a real application to\nthe statistician coauthorship dataset.", "published": "2025-07-02 08:37:15", "link": "http://arxiv.org/abs/2507.01473v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Targeted tuning of random forests for quantile estimation and prediction intervals", "abstract": "We present a novel tuning procedure for random forests (RFs) that improves\nthe accuracy of estimated quantiles and produces valid, relatively narrow\nprediction intervals. While RFs are typically used to estimate mean responses\n(conditional on covariates), they can also be used to estimate quantiles by\nestimating the full distribution of the response. However, standard approaches\nfor building RFs often result in excessively biased quantile estimates. To\nreduce this bias, our proposed tuning procedure minimizes \"quantile coverage\nloss\" (QCL), which we define as the estimated bias of the marginal quantile\ncoverage probability estimate based on the out-of-bag sample. We adapt QCL\ntuning to handle censored data and demonstrate its use with random survival\nforests. We show that QCL tuning results in quantile estimates with more\naccurate coverage probabilities than those achieved using default parameter\nvalues or traditional tuning (using MSPE for uncensored data and C-index for\ncensored data), while also reducing the estimated MSE of these coverage\nprobabilities. We discuss how the superior performance of QCL tuning is linked\nto its alignment with the estimation goal. Finally, we explore the validity and\nwidth of prediction intervals created using this method.", "published": "2025-07-02 07:32:59", "link": "http://arxiv.org/abs/2507.01430v1", "categories": ["stat.ME", "stat.AP", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Semi-supervised learning for linear extremile regression", "abstract": "Extremile regression, as a least squares analog of quantile regression, is\npotentially useful tool for modeling and understanding the extreme tails of a\ndistribution. However, existing extremile regression methods, as nonparametric\napproaches, may face challenges in high-dimensional settings due to data\nsparsity, computational inefficiency, and the risk of overfitting. While linear\nregression serves as the foundation for many other statistical and machine\nlearning models due to its simplicity, interpretability, and relatively easy\nimplementation, particularly in high-dimensional settings, this paper\nintroduces a novel definition of linear extremile regression along with an\naccompanying estimation methodology. The regression coefficient estimators of\nthis method achieve $\\sqrt{n}$-consistency, which nonparametric extremile\nregression may not provide. In particular, while semi-supervised learning can\nleverage unlabeled data to make more accurate predictions and avoid overfitting\nto small labeled datasets in high-dimensional spaces, we propose a\nsemi-supervised learning approach to enhance estimation efficiency, even when\nthe specified linear extremile regression model may be misspecified. Both\nsimulation studies and real data analyses demonstrate the finite-sample\nperformance of our proposed methods.", "published": "2025-07-02 02:59:15", "link": "http://arxiv.org/abs/2507.01314v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Perceptual Ratings Predict Speech Inversion Articulatory Kinematics in Childhood Speech Sound Disorders", "abstract": "Purpose: This study evaluated whether articulatory kinematics, inferred by\nArticulatory Phonology speech inversion neural networks, aligned with\nperceptual ratings of /r/ and /s/ in the speech of children with speech sound\ndisorders.\n  Methods: Articulatory Phonology vocal tract variables were inferred for 5,961\nutterances from 118 children and 3 adults, aged 2.25-45 years. Perceptual\nratings were standardized using the novel 5-point PERCEPT Rating Scale and\ntraining protocol. Two research questions examined if the articulatory patterns\nof inferred vocal tract variables aligned with the perceptual error category\nfor the phones investigated (e.g., tongue tip is more anterior in dentalized\n/s/ productions than in correct /s/). A third research question examined if\ngradient PERCEPT Rating Scale scores predicted articulatory proximity to\ncorrect productions.\n  Results: Estimated marginal means from linear mixed models supported 17 of 18\n/r/ hypotheses, involving tongue tip and tongue body constrictions. For /s/,\nestimated marginal means from a second linear mixed model supported 7 of 15\nhypotheses, particularly those related to the tongue tip. A third linear mixed\nmodel revealed that PERCEPT Rating Scale scores significantly predicted\narticulatory proximity of errored phones to correct productions.\n  Conclusion: Inferred vocal tract variables differentiated category and\nmagnitude of articulatory errors for /r/, and to a lesser extent for /s/,\naligning with perceptual judgments. These findings support the clinical\ninterpretability of speech inversion vocal tract variables and the PERCEPT\nRating Scale in quantifying articulatory proximity to the target sound,\nparticularly for /r/.", "published": "2025-07-02 16:57:46", "link": "http://arxiv.org/abs/2507.01888v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Low-Complexity Neural Wind Noise Reduction for Audio Recordings", "abstract": "Wind noise significantly degrades the quality of outdoor audio recordings,\nyet remains difficult to suppress in real-time on resource-constrained devices.\nIn this work, we propose a low-complexity single-channel deep neural network\nthat leverages the spectral characteristics of wind noise. Experimental results\nshow that our method achieves performance comparable to the state-of-the-art\nlow-complexity ULCNet model. The proposed model, with only 249K parameters and\nroughly 73 MHz of computational power, is suitable for embedded and mobile\naudio applications.", "published": "2025-07-02 15:36:54", "link": "http://arxiv.org/abs/2507.01821v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A Dataset for Automatic Assessment of TTS Quality in Spanish", "abstract": "This work addresses the development of a database for the automatic\nassessment of text-to-speech (TTS) systems in Spanish, aiming to improve the\naccuracy of naturalness prediction models. The dataset consists of 4,326 audio\nsamples from 52 different TTS systems and human voices and is, up to our\nknowledge, the first of its kind in Spanish. To label the audios, a subjective\ntest was designed based on the ITU-T Rec. P.807 standard and completed by 92\nparticipants. Furthermore, the utility of the collected dataset was validated\nby training automatic naturalness prediction systems. We explored two\napproaches: fine-tuning an existing model originally trained for English, and\ntraining small downstream networks on top of frozen self-supervised speech\nmodels. Our models achieve a mean absolute error of 0.8 on a five-point MOS\nscale. Further analysis demonstrates the quality and diversity of the developed\ndataset, and its potential to advance TTS research in Spanish.", "published": "2025-07-02 15:24:47", "link": "http://arxiv.org/abs/2507.01805v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "First Steps Towards Voice Anonymization for Code-Switching Speech", "abstract": "The goal of voice anonymization is to modify an audio such that the true\nidentity of its speaker is hidden. Research on this task is typically limited\nto the same English read speech datasets, thus the efficacy of current methods\nfor other types of speech data remains unknown. In this paper, we present the\nfirst investigation of voice anonymization for the multilingual phenomenon of\ncode-switching speech. We prepare two corpora for this task and propose\nadaptations to a multilingual anonymization model to make it applicable for\ncode-switching speech. By testing the anonymization performance of this and two\nlanguage-independent methods on the datasets, we find that only the\nmultilingual system performs well in terms of privacy and utility preservation.\nFurthermore, we observe challenges in performing utility evaluations on this\ndata because of its spontaneous character and the limited code-switching\nsupport by the multilingual speech recognition model.", "published": "2025-07-02 14:46:44", "link": "http://arxiv.org/abs/2507.01765v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Generalizable Detection of Audio Deepfakes", "abstract": "In this paper, we present our comprehensive study aimed at enhancing the\ngeneralization capabilities of audio deepfake detection models. We investigate\nthe performance of various pre-trained backbones, including Wav2Vec2, WavLM,\nand Whisper, across a diverse set of datasets, including those from the\nASVspoof challenges and additional sources. Our experiments focus on the\neffects of different data augmentation strategies and loss functions on model\nperformance. The results of our research demonstrate substantial enhancements\nin the generalization capabilities of audio deepfake detection models,\nsurpassing the performance of the top-ranked single system in the ASVspoof 5\nChallenge. This study contributes valuable insights into the optimization of\naudio models for more robust deepfake detection and facilitates future research\nin this critical area.", "published": "2025-07-02 14:28:11", "link": "http://arxiv.org/abs/2507.01750v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "QHARMA-GAN: Quasi-Harmonic Neural Vocoder based on Autoregressive Moving Average Model", "abstract": "Vocoders, encoding speech signals into acoustic features and allowing for\nspeech signal reconstruction from them, have been studied for decades.\nRecently, the rise of deep learning has particularly driven the development of\nneural vocoders to generate high-quality speech signals. On the other hand, the\nexisting end-to-end neural vocoders suffer from a black-box nature that blinds\nthe speech production mechanism and the intrinsic structure of speech,\nresulting in the ambiguity of separately modeling source excitation and\nresonance characteristics and the loss of flexibly synthesizing or modifying\nspeech with high quality. Moreover, their sequence-wise waveform generation\nusually requires complicated networks, leading to substantial time consumption.\nIn this work, inspired by the quasi-harmonic model (QHM) that represents speech\nas sparse components, we combine the neural network and QHM synthesis process\nto propose a novel framework for the neural vocoder. Accordingly, speech\nsignals can be encoded into autoregressive moving average (ARMA) functions to\nmodel the resonance characteristics, yielding accurate estimates of the\namplitudes and phases of quasi-harmonics at any frequency. Subsequently, the\nspeech can be resynthesized and arbitrarily modified in terms of pitch shifting\nand time stretching with high quality, whereas the time consumption and network\nsize decrease. The experiments indicate that the proposed method leverages the\nstrengths of QHM, the ARMA model, and neural networks, leading to the\noutperformance of our methods over other methods in terms of generation speed,\nsynthesis quality, and modification flexibility.", "published": "2025-07-02 11:28:53", "link": "http://arxiv.org/abs/2507.01611v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Voice Conversion for Likability Control via Automated Rating of Speech Synthesis Corpora", "abstract": "Perceived voice likability plays a crucial role in various social\ninteractions, such as partner selection and advertising. A system that provides\nreference likable voice samples tailored to target audiences would enable users\nto adjust their speaking style and voice quality, facilitating smoother\ncommunication. To this end, we propose a voice conversion method that controls\nthe likability of input speech while preserving both speaker identity and\nlinguistic content. To improve training data scalability, we train a likability\npredictor on an existing voice likability dataset and employ it to\nautomatically annotate a large speech synthesis corpus with likability ratings.\nExperimental evaluations reveal a significant correlation between the\npredictor's outputs and human-provided likability ratings. Subjective and\nobjective evaluations further demonstrate that the proposed approach\neffectively controls voice likability while preserving both speaker identity\nand linguistic content.", "published": "2025-07-02 04:47:43", "link": "http://arxiv.org/abs/2507.01356v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "IdolSongsJp Corpus: A Multi-Singer Song Corpus in the Style of Japanese Idol Groups", "abstract": "Japanese idol groups, comprising performers known as \"idols,\" are an\nindispensable part of Japanese pop culture. They frequently appear in live\nconcerts and television programs, entertaining audiences with their singing and\ndancing. Similar to other J-pop songs, idol group music covers a wide range of\nstyles, with various types of chord progressions and instrumental arrangements.\nThese tracks often feature numerous instruments and employ complex mastering\ntechniques, resulting in high signal loudness. Additionally, most songs include\na song division (utawari) structure, in which members alternate between singing\nsolos and performing together. Hence, these songs are well-suited for\nbenchmarking various music information processing techniques such as singer\ndiarization, music source separation, and automatic chord estimation under\nchallenging conditions. Focusing on these characteristics, we constructed a\nsong corpus titled IdolSongsJp by commissioning professional composers to\ncreate 15 tracks in the style of Japanese idol groups. This corpus includes not\nonly mastered audio tracks but also stems for music source separation, dry\nvocal tracks, and chord annotations. This paper provides a detailed description\nof the corpus, demonstrates its diversity through comparisons with real-world\nidol group songs, and presents its application in evaluating several music\ninformation processing techniques.", "published": "2025-07-02 04:37:04", "link": "http://arxiv.org/abs/2507.01349v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SpeechAccentLLM: A Unified Framework for Foreign Accent Conversion and Text to Speech", "abstract": "Foreign accent conversion (FAC) in speech processing remains a challenging\ntask. Building on the remarkable success of large language models (LLMs) in\nText-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based\ntechniques for FAC, which we term SpeechAccentLLM. At the core of this\nframework, we introduce SpeechCodeVAE, the first model to integrate\nconnectionist temporal classification (CTC) directly into codebook\ndiscretization for speech content tokenization. This novel architecture\ngenerates tokens with a unique \"locality\" property, as validated by experiments\ndemonstrating optimal trade-offs among content faithfulness, temporal\ncoherence, and structural recoverability. Then, to address data scarcity for\nthe FAC module, we adopted a multitask learning strategy that jointly trains\nthe FAC and TTS modules. Beyond mitigating data limitations, this approach\nyielded accelerated convergence and superior speech quality compared to\nstandalone FAC training. Moreover, leveraging the salient properties of our\ndiscrete speech representations, we introduce SpeechRestorer, a postprocessing\narchitecture designed to refine LLM-generated outputs. This module effectively\nmitigates stochastic errors prevalent in LLM inference pipelines while\nenhancing prosodic continuity, as validated by ablation experiments.", "published": "2025-07-02 04:30:23", "link": "http://arxiv.org/abs/2507.01348v1", "categories": ["eess.AS", "cs.SD", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems", "abstract": "In wireless sensing applications, such as ISAC, one of the first crucial\nsignal processing steps is the detection and estimation targets from a channel\nestimate. Effective algorithms in this context must be robust across a broad\nSNR range, capable of handling an unknown number of targets, and\ncomputationally efficient for real-time implementation. During the last decade,\ndifferent Machine Learning methods have emerged as promising solutions, either\nas standalone models or as complementing existing techniques. However, since\nmodels are often trained and evaluated on synthetic data from existing models,\napplying them to measurement is challenging. All the while, training directly\non measurement data is prohibitive in complex propagation scenarios as a\ngroundtruth is not available. Therefore, in this paper, we train a CNN approach\nfor target detection and estimation on synthetic data and evaluate it on\nmeasurement data from a suburban outdoor measurement. Using knowledge of the\nenvironment as well as available groundtruth positions, we study the detection\nprobability and accuracy of our approach. The results demonstrate that our\napproach works on measurement data and is suitable for joint detection and\nestimation of sensing targets in ISAC systems.", "published": "2025-07-02 15:19:52", "link": "http://arxiv.org/abs/2507.01799v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Higher-Order Tensor-Based Deferral of Gaussian Splitting for Orbit Uncertainty Propagation", "abstract": "Accurate propagation of orbital uncertainty is essential for a range of\napplications within space domain awareness. Adaptive Gaussian mixture-based\napproaches offer tractable nonlinear uncertainty propagation through splitting\nmixands to increase resolution in areas of stronger nonlinearities, as well as\nby reducing mixands to prevent unnecessary computational effort. Recent work\nintroduced principled heuristics that incorporate information from the system\ndynamics and initial uncertainty to determine optimal directions for splitting.\nThis paper develops adaptive uncertainty propagation methods based on these\nrobust splitting techniques. A deferred splitting algorithm tightly integrated\nwith higher-order splitting techniques is proposed and shown to offer\nsubstantial gains in computational efficiency without sacrificing accuracy.\nSecond-order propagation of mixand moments is also seen to improve accuracy\nwhile retaining significant computational savings from deferred splitting.\nDifferent immediate and deferred splitting methods are compared in three\nrepresentative test cases, including a geostationary orbit, a Molniya orbit,\nand a periodic three-body orbit.", "published": "2025-07-02 14:56:15", "link": "http://arxiv.org/abs/2507.01771v1", "categories": ["eess.SP", "math.PR"], "primary_category": "eess.SP"}
{"title": "Position and Velocity Estimation Accuracy in MIMO-OFDM ISAC Networks: A Fisher Information Analysis", "abstract": "Integrated sensing and communication (ISAC) is a core technology for future\nwireless networks, enabling high-resolution sensing and reliable data\ntransmission within a unified radio platform. This paper develops a theoretical\nframework to assess the estimation accuracy of target position and velocity in\nheterogeneous orthogonal frequency division multiplexing (OFDM)-based ISAC\nnetworks with multiple cooperative and distributed multiple-input\nmultiple-output (MIMO) base stations (BSs). Using Fisher information analysis,\nwe first derive closed-form Cram\\'er-Rao lower bounds (CRLBs) for target\nlocalization in single monostatic and bistatic configurations. We then analyze\nthe benefits of BS cooperation by deriving CRLBs for joint position and\nvelocity estimation in a general setting that encompasses multiple cooperating\nmonostatic systems and multistatic networks with multiple transmitters (Txs)\nand receivers (Rxs). The influence of key system parameters, including the\nnumber of BSs, bandwidth, antenna array configuration, and network geometry, is\nsystematically examined. Numerical results highlight the performance gains\nenabled by cooperative sensing and provide insights to guide the design of\nfuture ISAC systems.", "published": "2025-07-02 14:23:10", "link": "http://arxiv.org/abs/2507.01743v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Frequency-switching Array Enhanced Physical-Layer Security in Terahertz Bands: A Movable Antenna Perspective", "abstract": "In this paper, we propose a new frequency-switching array (FSA) enhanced\nphysical-layer security (PLS) system in terahertz bands, where the carrier\nfrequency can be flexibly switched and small frequency offsets can be imposed\non each antenna at Alice, so as to eliminate information wiretapping by\nundesired eavesdroppers. First, we analytically show that by flexibly\ncontrolling the carrier frequency parameters, FSAs can effectively form\nuniform/non-uniform sparse arrays, hence resembling movable antennas (MAs) in\nthe control of inter-antenna spacing and providing additional degree-of-freedom\n(DoF) in the beam control. Although the proposed FSA experiences additional\npath-gain attenuation in the received signals, it can overcome several hardware\nand signal processing issues incurred by MAs, such as limited positioning\naccuracy, considerable response latency, and demanding hardware and energy\ncost. To shed useful insights, we first consider a secrecy-guaranteed problem\nwith a null-steering constraint for which maximum ratio transmission (MRT)\nbeamformer is considered at Alice and the frequency offsets are set as uniform\nfrequency increment. Interestingly, it is shown that the proposed FSA can\nflexibly realize null-steering over Eve in both the angular domain (by tuning\ncarrier frequency) and range domain (by controlling per-antenna frequency\noffset), thereby achieving improved PLS performance. Then, for the general\ncase, we propose an efficient algorithm to solve the formulated non-convex\nproblem by using the block coordinate descent (BCD) and projected gradient\nascent (PGA) techniques. Finally, numerical results demonstrate the convergence\nof the proposed optimization algorithm and its superiority over fixed-position\narrays (FPAs) in terms of secrecy-rate performance.", "published": "2025-07-02 11:54:38", "link": "http://arxiv.org/abs/2507.01624v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Basis Expansion Extrapolation based Long-Term Channel Prediction for Massive MIMO OTFS Systems", "abstract": "Massive multi-input multi-output (MIMO) combined with orthogonal time\nfrequency space (OTFS) modulation has emerged as a promising technique for\nhigh-mobility scenarios. However, its performance could be severely degraded\ndue to channel aging caused by user mobility and high processing latency. In\nthis paper, an integrated scheme of uplink (UL) channel estimation and downlink\n(DL) channel prediction is proposed to alleviate channel aging in time division\nduplex (TDD) massive MIMO-OTFS systems. Specifically, first, an iterative basis\nexpansion model (BEM) based UL channel estimation scheme is proposed to\naccurately estimate UL channels with the aid of carefully designed OTFS frame\npattern. Then a set of Slepian sequences are used to model the estimated UL\nchannels, and the dynamic Slepian coefficients are fitted by a set of\northogonal polynomials. A channel predictor is derived to predict DL channels\nby iteratively extrapolating the Slepian coefficients. Simulation results\nverify that the proposed UL channel estimation and DL channel prediction\nschemes outperform the existing schemes in terms of normalized mean square\nerror of channel estimation/prediction and DL spectral efficiency, with less\npilot overhead.", "published": "2025-07-02 08:05:40", "link": "http://arxiv.org/abs/2507.01445v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SDR-Empowered Environment Sensing Design and Experimental Validation Using OTFS-ISAC Signals", "abstract": "This paper investigates the system design and experimental validation of\nintegrated sensing and communication (ISAC) for environmental sensing, which is\nexpected to be a critical enabler for next-generation wireless networks. We\nadvocate exploiting orthogonal time frequency space (OTFS) modulation for its\ninherent sparsity and stability in delay-Doppler (DD) domain channels,\nfacilitating a low-overhead environment sensing design. Moreover, a\ncomprehensive environmental sensing framework is developed, encompassing DD\ndomain channel estimation, target localization, and experimental validation. In\nparticular, we first explore the OTFS channel estimation in the presence of\nfractional delay and Doppler shifts. Given the estimated parameters, we propose\na three-ellipse positioning algorithm to localize the target's position,\nfollowed by determining the mobile transmitter's velocity. Additionally, to\nevaluate the performance of our proposed design, we conduct extensive\nsimulations and experiments using a software-defined radio (SDR)-based platform\nwith universal software radio peripheral (USRP). The experimental validations\ndemonstrate that our proposed approach outperforms the benchmarks in terms of\nlocalization accuracy and velocity estimation, confirming its effectiveness in\npractical environmental sensing applications.", "published": "2025-07-02 07:29:01", "link": "http://arxiv.org/abs/2507.01427v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MmBack: Clock-free Multi-Sensor Backscatter with Synchronous Acquisition and Multiplexing", "abstract": "Backscatter tags provide a low-power solution for sensor applications, yet\nmany real-world scenarios require multiple sensors-often of different types-for\ncomplex sensing tasks. However, existing designs support only a single sensor\nper tag, increasing spatial overhead. State-of-the-art approaches to\nmultiplexing multiple sensor streams on a single tag rely on onboard clocks or\nmultiple modulation chains, which add cost, enlarge form factor, and remain\nprone to timing drift-disrupting synchronization across sensors.\n  We present mmBack, a low-power, clock-free backscatter tag that enables\nsynchronous multi-sensor data acquisition and multiplexing over a single\nmodulation chain. mmBack synchronizes sensor inputs in parallel using a shared\nreference signal extracted from ambient RF excitation, eliminating the need for\nan onboard timing source. To efficiently multiplex sensor data, mmBack designs\na voltage-division scheme to multiplex multiple sensor inputs as backscatter\nfrequency shifts through a single oscillator and RF switch. At the receiver,\nmmBack develops a frequency tracking algorithm and a finite-state machine for\naccurate demultiplexing. mmBack's ASIC design consumes 25.56uW, while its\nprototype supports 5 concurrent sensor streams with bandwidths of up to 5kHz\nand 3 concurrent sensor streams with bandwidth of up to 18kHz. Evaluation shows\nthat mmBack achieves an average SNR surpassing 15dB in signal reconstruction.", "published": "2025-07-02 04:53:41", "link": "http://arxiv.org/abs/2507.01360v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Fluid Aerial Networks: UAV Rotation for Inter-Cell Interference Mitigation", "abstract": "With the rapid development of aerial infrastructure, unmanned aerial vehicles\n(UAVs) that function as aerial base stations (ABSs) extend terrestrial network\nservices into the sky, enabling on-demand connectivity and enhancing emergency\ncommunication capabilities in cellular networks by leveraging the flexibility\nand mobility of UAVs. In such a UAV-assisted network, this paper investigates\nposition-based beamforming between ABSs and ground users (GUs). To mitigate\ninter-cell interference, we propose a novel fluid aerial network that leverages\nABS rotation to increase multi-cell capacity and overall network efficiency.\nSpecifically, considering the line-of-sight channel model, the spatial\nbeamforming weights are determined by the orientation angles of the GUs. In\nthis direction, we examine the beamforming gain of a two-dimensional\nmultiple-input multiple-output (MIMO) array at various ground positions,\nrevealing that ABS rotation significantly affects multi-user channel\ncorrelation and inter-cell interference. Based on these findings, we propose an\nalternative low-complexity algorithm to design the optimal rotation angle for\nABSs, aiming to reduce inter-cell interference and thus maximize the sum rate\nof multi-cell systems. In simulations, exhaustive search serves as a benchmark\nto validate the optimization performance of the proposed sequential ABS\nrotation scheme. Moreover, simulation results demonstrate that, in\ninterference-limited regions, the proposed ABS rotation paradigm can\nsignificantly reduce inter-cell interference in terrestrial networks and\nimprove the multi-cell sum rate by approximately 10\\% compared to\nfixed-direction ABSs without rotation.", "published": "2025-07-02 02:06:35", "link": "http://arxiv.org/abs/2507.01289v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Pursuing the limit of chirp parameter identifiability: A computational approach", "abstract": "In this paper, it is shown that a necessary condition for unique\nidentifiability of $K$ chirps from $N$ regularly spaced samples of their\nmixture is $N\\geq 2K$ when $K\\geq 2$. A necessary and sufficient condition is\nthat a rank-constrained matrix optimization problem has a unique solution; this\nis the first result of such kind. An algorithm is proposed to solve the\noptimization problem and to identify the parameters numerically. The lower\nbound of $N=2K$ is shown to be tight by providing diverse problem instances for\nwhich the proposed algorithm succeeds to identify the parameters. The\nadvantageous performance of the proposed algorithm is also demonstrated\ncompared with the state of the art.", "published": "2025-07-02 01:58:27", "link": "http://arxiv.org/abs/2507.01286v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Decision-Oriented Text Evaluation", "abstract": "Natural language generation (NLG) is increasingly deployed in high-stakes\ndomains, yet common intrinsic evaluation methods, such as n-gram overlap or\nsentence plausibility, weakly correlate with actual decision-making efficacy.\nWe propose a decision-oriented framework for evaluating generated text by\ndirectly measuring its influence on human and large language model (LLM)\ndecision outcomes. Using market digest texts--including objective morning\nsummaries and subjective closing-bell analyses--as test cases, we assess\ndecision quality based on the financial performance of trades executed by human\ninvestors and autonomous LLM agents informed exclusively by these texts. Our\nfindings reveal that neither humans nor LLM agents consistently surpass random\nperformance when relying solely on summaries. However, richer analytical\ncommentaries enable collaborative human-LLM teams to outperform individual\nhuman or agent baselines significantly. Our approach underscores the importance\nof evaluating generated text by its ability to facilitate synergistic\ndecision-making between humans and LLMs, highlighting critical limitations of\ntraditional intrinsic metrics.", "published": "2025-07-02 17:32:35", "link": "http://arxiv.org/abs/2507.01923v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning", "abstract": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential\nin enhancing the reasoning capabilities of Large Language Models~(LLMs).\nHowever, introducing additional process reward models incurs substantial\ncomputational overhead, and there is no unified theoretical framework for\nprocess-level advantage estimation. To bridge this gap, we propose\n\\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward\n\\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables\nprocess-aware RL through two key innovations: (1) we first theoretically\ndemonstrate that process rewards can be derived intrinsically from the policy\nmodel itself, and (2) we introduce well-defined cumulative process rewards and\n\\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which\nfacilitates rigorous step-wise action advantage estimation within shared-prompt\nsampling groups. Our experimental results demonstrate that SPRO outperforms\nvaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy\nimprovement. Furthermore, SPRO maintains a stable and elevated policy entropy\nthroughout training while reducing the average response length by approximately\n$1/3$, evidencing sufficient exploration and prevention of reward hacking.\nNotably, SPRO incurs no additional computational overhead compared to\noutcome-supervised RL methods such as GRPO, which benefit industrial\nimplementation.", "published": "2025-07-02 10:05:14", "link": "http://arxiv.org/abs/2507.01551v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "abstract": "This paper explores how older adults, particularly aging migrants in urban\nChina, can engage AI-assisted co-creation to express personal narratives that\nare often fragmented, underrepresented, or difficult to verbalize. Through a\npilot workshop combining oral storytelling and the symbolic reconstruction of\nHanzi, participants shared memories of migration and recreated new character\nforms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),\ntogether with physical materials. Supported by human facilitation and a soft AI\npresence, participants transformed lived experience into visual and tactile\nexpressions without requiring digital literacy. This approach offers new\nperspectives on human-AI collaboration and aging by repositioning AI not as a\ncontent producer but as a supportive mechanism, and by supporting narrative\nagency within sociotechnical systems.", "published": "2025-07-02 10:00:12", "link": "http://arxiv.org/abs/2507.01548v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "abstract": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.", "published": "2025-07-02 04:40:29", "link": "http://arxiv.org/abs/2507.01352v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "abstract": "Navigating the complexities of physics reasoning has long been a difficult\ntask for Large Language Models (LLMs), requiring a synthesis of profound\nconceptual understanding and adept problem-solving techniques. In this study,\nwe investigate the application of advanced instruction-tuned reasoning models,\nsuch as Deepseek-R1, to address a diverse spectrum of physics problems curated\nfrom the challenging SciBench benchmark. Our comprehensive experimental\nevaluation reveals the remarkable capabilities of reasoning models. Not only do\nthey achieve state-of-the-art accuracy in answering intricate physics\nquestions, but they also generate distinctive reasoning patterns that emphasize\non symbolic derivation. Furthermore, our findings indicate that even for these\nhighly sophisticated reasoning models, the strategic incorporation of few-shot\nprompting can still yield measurable improvements in overall accuracy,\nhighlighting the potential for continued performance gains.", "published": "2025-07-02 03:51:16", "link": "http://arxiv.org/abs/2507.01334v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation", "abstract": "Recently, mobile manipulation has attracted increasing attention for enabling\nlanguage-conditioned robotic control in household tasks. However, existing\nmethods still face challenges in coordinating mobile base and manipulator,\nprimarily due to two limitations. On the one hand, they fail to explicitly\nmodel the influence of the mobile base on manipulator control, which easily\nleads to error accumulation under high degrees of freedom. On the other hand,\nthey treat the entire mobile manipulation process with the same visual\nobservation modality (e.g., either all 2D or all 3D), overlooking the distinct\nmultimodal perception requirements at different stages during mobile\nmanipulation. To address this, we propose the Adaptive Coordination Diffusion\nTransformer (AC-DiT), which enhances mobile base and manipulator coordination\nfor end-to-end mobile manipulation. First, since the motion of the mobile base\ndirectly influences the manipulator's actions, we introduce a mobility-to-body\nconditioning mechanism that guides the model to first extract base motion\nrepresentations, which are then used as context prior for predicting whole-body\nactions. This enables whole-body control that accounts for the potential impact\nof the mobile base's motion. Second, to meet the perception requirements at\ndifferent stages of mobile manipulation, we design a perception-aware\nmultimodal conditioning strategy that dynamically adjusts the fusion weights\nbetween various 2D visual images and 3D point clouds, yielding visual features\ntailored to the current perceptual needs. This allows the model to, for\nexample, adaptively rely more on 2D inputs when semantic information is crucial\nfor action prediction, while placing greater emphasis on 3D geometric\ninformation when precise spatial understanding is required. We validate AC-DiT\nthrough extensive experiments on both simulated and real-world mobile\nmanipulation tasks.", "published": "2025-07-02 17:59:54", "link": "http://arxiv.org/abs/2507.01961v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Distributional Soft Actor-Critic with Diffusion Policy", "abstract": "Reinforcement learning has been proven to be highly effective in handling\ncomplex control tasks. Traditional methods typically use unimodal\ndistributions, such as Gaussian distributions, to model the output of value\ndistributions. However, unimodal distribution often and easily causes bias in\nvalue function estimation, leading to poor algorithm performance. This paper\nproposes a distributional reinforcement learning algorithm called DSAC-D\n(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges\nof estimating bias in value functions and obtaining multimodal policy\nrepresentations. A multimodal distributional policy iteration framework that\ncan converge to the optimal policy was established by introducing policy\nentropy and value distribution function. A diffusion value network that can\naccurately characterize the distribution of multi peaks was constructed by\ngenerating a set of reward samples through reverse sampling using a diffusion\nmodel. Based on this, a distributional reinforcement learning algorithm with\ndual diffusion of the value network and the policy network was derived. MuJoCo\ntesting tasks demonstrate that the proposed algorithm not only learns\nmultimodal policy, but also achieves state-of-the-art (SOTA) performance in all\n9 control tasks, with significant suppression of estimation bias and total\naverage return improvement of over 10% compared to existing mainstream\nalgorithms. The results of real vehicle testing show that DSAC-D can accurately\ncharacterize the multimodal distribution of different driving styles, and the\ndiffusion policy network can characterize multimodal trajectories.", "published": "2025-07-02 05:50:10", "link": "http://arxiv.org/abs/2507.01381v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion", "abstract": "Objective: Clinical implementation of deformable image registration (DIR)\nrequires voxel-based spatial accuracy metrics such as manually identified\nlandmarks, which are challenging to implement for highly mobile\ngastrointestinal (GI) organs. To address this, patient-specific digital twins\n(DT) modeling temporally varying motion were created to assess the accuracy of\nDIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D\nsequences were generated from static 3D patient scans using published\nanalytical GI motion models through a semi-automated pipeline. Eleven datasets,\nincluding six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,\nand three contrast-enhanced CT scans. The motion amplitudes of the DTs were\nassessed against real patient stomach motion amplitudes extracted from\nindependent 4D MRI datasets. The generated DTs were then used to assess six\ndifferent DIR methods using target registration error, Dice similarity\ncoefficient, and the 95th percentile Hausdorff distance using summary metrics\nand voxel-level granular visualizations. Finally, for a subset of T2w MRI scans\nfrom patients treated with MR-guided radiation therapy, dose distributions were\nwarped and accumulated to assess dose warping errors, including evaluations of\nDIR performance in both low- and high-dose regions for patient-specific error\nestimation. Main results: Our proposed pipeline synthesized DTs modeling\nrealistic GI motion, achieving mean and maximum motion amplitudes and a mean\nlog Jacobian determinant within 0.8 mm and 0.01, respectively, similar to\npublished real-patient gastric motion data. It also enables the extraction of\ndetailed quantitative DIR performance metrics and rigorous validation of dose\nmapping accuracy. Significance: The pipeline enables rigorously testing DIR\ntools for dynamic, anatomically complex regions enabling granular spatial and\ndosimetric accuracies.", "published": "2025-07-02 17:22:47", "link": "http://arxiv.org/abs/2507.01909v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion", "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a\nchallenging task due to the difficulty of modeling detailed interaction\ndynamics. Existing methods treat human and object motions independently,\nresulting in physically implausible and causally inconsistent behaviors. In\nthis work, we present HOI-Dyn, a novel framework that formulates HOI generation\nas a driver-responder system, where human actions drive object responses. At\nthe core of our method is a lightweight transformer-based interaction dynamics\nmodel that explicitly predicts how objects should react to human motion. To\nfurther enforce consistency, we introduce a residual-based dynamics loss that\nmitigates the impact of dynamics prediction errors and prevents misleading\noptimization signals. The dynamics model is used only during training,\npreserving inference efficiency. Through extensive qualitative and quantitative\nexperiments, we demonstrate that our approach not only enhances the quality of\nHOI generation but also establishes a feasible metric for evaluating the\nquality of generated interactions.", "published": "2025-07-02 14:13:48", "link": "http://arxiv.org/abs/2507.01737v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration", "abstract": "Robust estimation is essential in correspondence-based Point Cloud\nRegistration (PCR). Existing methods using maximal clique search in\ncompatibility graphs achieve high recall but suffer from exponential time\ncomplexity, limiting their use in time-sensitive applications. To address this\nchallenge, we propose a fast and robust estimator, TurboReg, built upon a novel\nlightweight clique, TurboClique, and a highly parallelizable Pivot-Guided\nSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within a\nhighly-constrained compatibility graph. The lightweight nature of the 3-clique\nallows for efficient parallel searching, and the highly-constrained\ncompatibility graph ensures robust spatial consistency for stable\ntransformation estimation. Next, PGS selects matching pairs with high SC$^2$\nscores as pivots, effectively guiding the search toward TurboCliques with\nhigher inlier ratios. Moreover, the PGS algorithm has linear time complexity\nand is significantly more efficient than the maximal clique search with\nexponential time complexity. Extensive experiments show that TurboReg achieves\nstate-of-the-art performance across multiple real-world datasets, with\nsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,\nTurboReg (1K) operates $208.22\\times$ faster than 3DMAC while also achieving\nhigher recall. Our code is accessible at\n\\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}.", "published": "2025-07-02 07:50:24", "link": "http://arxiv.org/abs/2507.01439v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Half Spatially Coupled Turbo-Like Codes", "abstract": "This paper presents a new class of spatially coupled turbo-like codes\n(SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs)\nand half spatially coupled parallel concatenated codes (HSC-PCCs). Different\nfrom the conventional SC-TCs, the proposed codes have simpler and deterministic\ncoupling structures. Most notably, the coupling of HSC-BCCs is performed by\nre-encoding the whole coupling sequence in the component encoder of one time\ninstant, rather than spreading the coupling bits to component encoders of\nmultiple time instants. This simplification not only addresses the window\ndecoding threshold loss issue in existing BCCs, but also allows the proposed\ncodes to attain very close-to-capacity performance with a coupling memory as\nsmall as 2. Both theoretical and numerical results are provided to demonstrate\nthe performance advantages of the proposed codes over existing spatially\ncoupled codes.", "published": "2025-07-02 13:11:34", "link": "http://arxiv.org/abs/2507.01685v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Joint Spatial Division and Multiplexing with Customized Orthogonal Group Channels in Multi-RIS-Assisted Systems", "abstract": "Reconfigurable intelligent surfaces (RISs) offer the unique capability to\nreshape the radio environment, thereby simplifying transmission schemes\ntraditionally contingent on channel conditions. Joint spatial division and\nmultiplexing (JSDM) emerges as a low-overhead transmission scheme for\nmulti-user equipment (UE) scenarios, typically requiring complex matrix\ndecomposition to achieve block-diagonalization of the effective channel matrix.\nIn this study, we introduce an innovative JSDM design that leverages RISs to\ncustomize channels, thereby streamlining the overall procedures. By\nstrategically positioning RISs at the discrete Fourier transform (DFT)\ndirections of the base station (BS), we establish orthogonal line-of-sight\nlinks within the BS-RIS channel, enabling a straightforward pre-beamforming\ndesign. Based on UE grouping, we devise reflected beams of the RIS with\noptimized directions to mitigate inter-group interference in the RISs-UEs\nchannel. An approximation of the channel cross-correlation coefficient is\nderived and serves as a foundation for the RISs-UEs association, further\ndiminishing inter-group interference. Numerical results substantiate the\nefficacy of our RIS-customized JSDM in not only achieving effective channel\nblock-diagonalization but also in significantly enhancing the sum spectral\nefficiency for multi-UE transmissions.", "published": "2025-07-02 12:15:00", "link": "http://arxiv.org/abs/2507.01641v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning", "abstract": "Event stream based scene text recognition is a newly arising research topic\nin recent years which performs better than the widely used RGB cameras in\nextremely challenging scenarios, especially the low illumination, fast motion.\nExisting works either adopt end-to-end encoder-decoder framework or large\nlanguage models for enhanced recognition, however, they are still limited by\nthe challenges of insufficient interpretability and weak contextual logical\nreasoning. In this work, we propose a novel chain-of-thought reasoning based\nevent stream scene text recognition framework, termed ESTR-CoT. Specifically,\nwe first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input\nevent stream into tokens and utilize a Llama tokenizer to encode the given\ngeneration prompt. A Q-former is used to align the vision token to the\npre-trained large language model Vicuna-7B and output both the answer and\nchain-of-thought (CoT) reasoning process simultaneously. Our framework can be\noptimized using supervised fine-tuning in an end-to-end manner. In addition, we\nalso propose a large-scale CoT dataset to train our framework via a three stage\nprocessing (i.e., generation, polish, and expert verification). This dataset\nprovides a solid data foundation for the development of subsequent\nreasoning-based large models. Extensive experiments on three event stream STR\nbenchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the\neffectiveness and interpretability of our proposed framework. The source code\nand pre-trained models will be released on\nhttps://github.com/Event-AHU/ESTR-CoT.", "published": "2025-07-02 23:41:31", "link": "http://arxiv.org/abs/2507.02200v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer", "abstract": "Chain-of-thought (CoT) reasoning has enabled transformer-based language\nmodels to excel at complex mathematics and multi-step planning. However, in\nstandard decoder-only architectures, these reasoning steps are externalized in\nnatural language, improving interpretability at the cost of efficiency. To\ncapture reasoning that is not easily represented in words, many works have\nexplored recurrent architectures that aim to internalize reasoning in latent\nspace, potentially supporting latent CoT. In this paper, we investigate whether\nsuch reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer\nthat reuses layers at inference time without increasing parameter count. We\nexamine the model's internal behavior on arithmetic tasks using a suite of\nprobing techniques including the Logit Lens and Coda Lens. Our findings reveal\nlimited evidence of interpretable latent CoT by tracking rank trajectories of\nfinal and intermediate result tokens. Furthermore, we uncover significant\nprobing inconsistencies across recurrent blocks, where the interpretability of\nhidden states depends heavily on both the layer index and the decoding method.\nFinally, we empirically show that increasing recurrence depth yields only\nmarginal gains and falls well short of models that explicitly externalize\nreasoning steps. The code is available at\nhttps://github.com/wenquanlu/huginn-latent-cot.", "published": "2025-07-02 23:35:21", "link": "http://arxiv.org/abs/2507.02199v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing and Improving Speaker Similarity Assessment for Speech Synthesis", "abstract": "Modeling voice identity is challenging due to its multifaceted nature. In\ngenerative speech systems, identity is often assessed using automatic speaker\nverification (ASV) embeddings, designed for discrimination rather than\ncharacterizing identity. This paper investigates which aspects of a voice are\ncaptured in such representations. We find that widely used ASV embeddings focus\nmainly on static features like timbre and pitch range, while neglecting dynamic\nelements such as rhythm. We also identify confounding factors that compromise\nspeaker similarity measurements and suggest mitigation strategies. To address\nthese gaps, we propose U3D, a metric that evaluates speakers' dynamic rhythm\npatterns. This work contributes to the ongoing challenge of assessing speaker\nidentity consistency in the context of ever-better voice cloning systems. We\npublicly release our code.", "published": "2025-07-02 22:16:42", "link": "http://arxiv.org/abs/2507.02176v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization", "abstract": "Dialogue summarization is a challenging task with significant practical value\nin customer service, meeting analysis, and conversational AI. Although large\nlanguage models (LLMs) have achieved substantial progress in summarization\ntasks, the performance of step-by-step reasoning architectures-specifically\nLong Chain-of-Thought (CoT) implementations such as OpenAI-o1 and\nDeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent\nabstraction and conciseness. In this work, we present the first comprehensive\nand systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning\nLLMs across three major paradigms-generic, role-oriented, and query-oriented\ndialogue summarization. Our study spans diverse languages, domains, and summary\nlengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and\nadvanced evaluation protocols that include both LLM-based automatic metrics and\nhuman-inspired criteria. Contrary to trends in other reasoning-intensive tasks,\nour findings show that explicit stepwise reasoning does not consistently\nimprove dialogue summarization quality. Instead, reasoning LLMs are often prone\nto verbosity, factual inconsistencies, and less concise summaries compared to\ntheir non-reasoning counterparts. Through scenario-specific analyses and\ndetailed case studies, we further identify when and why explicit reasoning may\nfail to benefit-or even hinder-summarization in complex dialogue contexts. Our\nwork provides new insights into the limitations of current reasoning LLMs and\nhighlights the need for targeted modeling and evaluation strategies for\nreal-world dialogue summarization.", "published": "2025-07-02 21:02:41", "link": "http://arxiv.org/abs/2507.02145v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency", "abstract": "Large Language Models (LLMs) are increasingly being integrated into various\napplications and services running on billions of mobile devices. However,\ndeploying LLMs on resource-limited mobile devices faces a significant challenge\ndue to their high demand for computation, memory, and ultimately energy. While\ncurrent LLM frameworks for mobile use three power-hungry components-CPU, GPU,\nand Memory-even when running primarily-GPU LLM models, optimized DVFS governors\nfor CPU, GPU, and memory featured in modern mobile devices operate\nindependently and are oblivious of each other. Motivated by the above\nobservation, in this work, we first measure the energy-efficiency of a SOTA LLM\nframework consisting of various LLM models on mobile phones which showed the\ntriplet mobile governors result in up to 40.4% longer prefilling and decoding\nlatency compared to optimal combinations of CPU, GPU, and memory frequencies\nwith the same energy consumption for sampled prefill and decode lengths.\nSecond, we conduct an in-depth measurement study to uncover how the intricate\ninterplay (or lack of) among the mobile governors cause the above inefficiency\nin LLM inference. Finally, based on these insights, we design FUSE - a unified\nenergy-aware governor for optimizing the energy efficiency of LLM inference on\nmobile devices. Our evaluation using a ShareGPT dataset shows FUSE reduces the\ntime-to-first-token and time-per-output-token latencies by 7.0%-16.9% and\n25.4%-36.8% on average with the same energy-per-token for various mobile LLM\nmodels.", "published": "2025-07-02 20:47:40", "link": "http://arxiv.org/abs/2507.02135v1", "categories": ["cs.OS", "cs.CL"], "primary_category": "cs.OS"}
{"title": "Energy-Based Transformers are Scalable Learners and Thinkers", "abstract": "Inference-time computation techniques, analogous to human System 2 Thinking,\nhave recently become popular for improving model performances. However, most\nexisting approaches suffer from several limitations: they are modality-specific\n(e.g., working only in text), problem-specific (e.g., verifiable domains like\nmath and coding), or require additional supervision/training on top of\nunsupervised pretraining (e.g., verifiers or verifiable rewards). In this\npaper, we ask the question \"Is it possible to generalize these System 2\nThinking approaches, and develop models that learn to think solely from\nunsupervised learning?\" Interestingly, we find the answer is yes, by learning\nto explicitly verify the compatibility between inputs and\ncandidate-predictions, and then re-framing prediction problems as optimization\nwith respect to this verifier. Specifically, we train Energy-Based Transformers\n(EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy\nvalue to every input and candidate-prediction pair, enabling predictions\nthrough gradient descent-based energy minimization until convergence. Across\nboth discrete (text) and continuous (visual) modalities, we find EBTs scale\nfaster than the dominant Transformer++ approach during training, achieving an\nup to 35% higher scaling rate with respect to data, batch size, parameters,\nFLOPs, and depth. During inference, EBTs improve performance with System 2\nThinking by 29% more than the Transformer++ on language tasks, and EBTs\noutperform Diffusion Transformers on image denoising while using fewer forward\npasses. Further, we find that EBTs achieve better results than existing models\non most downstream tasks given the same or worse pretraining performance,\nsuggesting that EBTs generalize better than existing approaches. Consequently,\nEBTs are a promising new paradigm for scaling both the learning and thinking\ncapabilities of models.", "published": "2025-07-02 19:17:29", "link": "http://arxiv.org/abs/2507.02092v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models", "abstract": "As large language models (LLMs) are increasingly applied to various NLP\ntasks, their inherent biases are gradually disclosed. Therefore, measuring\nbiases in LLMs is crucial to mitigate its ethical risks. However, most existing\nbias evaluation datasets focus on English and North American culture, and their\nbias categories are not fully applicable to other cultures. The datasets\ngrounded in the Chinese language and culture are scarce. More importantly,\nthese datasets usually only support single evaluation tasks and cannot evaluate\nthe bias from multiple aspects in LLMs. To address these issues, we present a\nMulti-task Chinese Bias Evaluation Benchmark (McBE) that includes 4,077 bias\nevaluation instances, covering 12 single bias categories, 82 subcategories and\nintroducing 5 evaluation tasks, providing extensive category coverage, content\ndiversity, and measuring comprehensiveness. Additionally, we evaluate several\npopular LLMs from different series and with parameter sizes. In general, all\nthese LLMs demonstrated varying degrees of bias. We conduct an in-depth\nanalysis of results, offering novel insights into bias in LLMs.", "published": "2025-07-02 19:04:56", "link": "http://arxiv.org/abs/2507.02088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "abstract": "The use of large language models (LLMs) in hiring promises to streamline\ncandidate screening, but it also raises serious concerns regarding accuracy and\nalgorithmic bias where sufficient safeguards are not in place. In this work, we\nbenchmark several state-of-the-art foundational LLMs - including models from\nOpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our\nproprietary domain-specific hiring model (Match Score) for job candidate\nmatching. We evaluate each model's predictive accuracy (ROC AUC,\nPrecision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis\nacross declared gender, race, and intersectional subgroups). Our experiments on\na dataset of roughly 10,000 real-world recent candidate-job pairs show that\nMatch Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs\n0.77) and achieves significantly more equitable outcomes across demographic\ngroups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957\n(near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the\nintersectionals, respectively). We discuss why pretraining biases may cause\nLLMs with insufficient safeguards to propagate societal biases in hiring\nscenarios, whereas a bespoke supervised model can more effectively mitigate\nthese biases. Our findings highlight the importance of domain-specific modeling\nand bias auditing when deploying AI in high-stakes domains such as hiring, and\ncaution against relying on off-the-shelf LLMs for such tasks without extensive\nfairness safeguards. Furthermore, we show with empirical evidence that there\nshouldn't be a dichotomy between choosing accuracy and fairness in hiring: a\nwell-designed algorithm can achieve both accuracy in hiring and fairness in\noutcomes.", "published": "2025-07-02 19:02:18", "link": "http://arxiv.org/abs/2507.02087v1", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "abstract": "As LLMs are increasingly studied as role-playing agents to generate synthetic\ndata for human behavioral research, ensuring that their outputs remain coherent\nwith their assigned roles has become a critical concern. In this paper, we\ninvestigate how consistently LLM-based role-playing agents' stated beliefs\nabout the behavior of the people they are asked to role-play (\"what they say\")\ncorrespond to their actual behavior during role-play (\"how they act\").\nSpecifically, we establish an evaluation framework to rigorously measure how\nwell beliefs obtained by prompting the model can predict simulation outcomes in\nadvance. Using an augmented version of the GenAgents persona bank and the Trust\nGame (a standard economic game used to quantify players' trust and\nreciprocity), we introduce a belief-behavior consistency metric to\nsystematically investigate how it is affected by factors such as: (1) the types\nof beliefs we elicit from LLMs, like expected outcomes of simulations versus\ntask-relevant attributes of individual characters LLMs are asked to simulate;\n(2) when and how we present LLMs with relevant information about Trust Game;\nand (3) how far into the future we ask the model to forecast its actions. We\nalso explore how feasible it is to impose a researcher's own theoretical priors\nin the event that the originally elicited beliefs are misaligned with research\nobjectives. Our results reveal systematic inconsistencies between LLMs' stated\n(or imposed) beliefs and the outcomes of their role-playing simulation, at both\nan individual- and population-level. Specifically, we find that, even when\nmodels appear to encode plausible beliefs, they may fail to apply them in a\nconsistent way. These findings highlight the need to identify how and when\nLLMs' stated beliefs align with their simulated behavior, allowing researchers\nto use LLM-based agents appropriately in behavioral studies.", "published": "2025-07-02 23:30:51", "link": "http://arxiv.org/abs/2507.02197v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs", "abstract": "While recent advances in preference learning have enhanced alignment in human\nfeedback, mathematical reasoning remains a persistent challenge. We investigate\nhow data diversification strategies in preference optimization can improve the\nmathematical reasoning abilities of large language models (LLMs). We evaluate\nthree common data generation methods: temperature sampling, Chain-of-Thought\nprompting, and Monte Carlo Tree Search (MCTS), and introduce\nDiversified-ThinkSolve (DTS), a novel structured approach that systematically\ndecomposes problems into diverse reasoning paths. Our results show that with\nstrategically diversified preference data, models can substantially improve\nmathematical reasoning performance, with the best approach yielding gains of\n7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong\nperformance, DTS incurs only a marginal computational overhead (1.03x) compared\nto the baseline, while MCTS is nearly five times more costly with lower\nreturns. These findings demonstrate that structured exploration of diverse\nproblem-solving methods creates more effective preference data for mathematical\nalignment than traditional approaches.", "published": "2025-07-02 22:12:03", "link": "http://arxiv.org/abs/2507.02173v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "abstract": "Trajectory planning in robotics is understood as generating a sequence of\njoint configurations that will lead a robotic agent, or its manipulator, from\nan initial state to the desired final state, thus completing a manipulation\ntask while considering constraints like robot kinematics and the environment.\nTypically, this is achieved via sampling-based planners, which are\ncomputationally intensive. Recent advances demonstrate that trajectory planning\ncan also be performed by supervised sequence learning of trajectories, often\nrequiring only a single or fixed number of passes through a neural\narchitecture, thus ensuring a bounded computation time. Such fully supervised\napproaches, however, perform imitation learning; they do not learn based on\nwhether the trajectories can successfully reach a goal, but try to reproduce\nobserved trajectories. In our work, we build on this approach and propose a\ncognitively inspired self-supervised learning scheme based on a recurrent\narchitecture for building a trajectory model. We evaluate the feasibility of\nthe proposed method on a task of kinematic planning for a robotic arm. The\nresults suggest that the model is able to learn to generate trajectories only\nusing given paired forward and inverse kinematics models, and indicate that\nthis novel method could facilitate planning for more complex manipulation tasks\nrequiring adaptive solutions.", "published": "2025-07-02 22:05:58", "link": "http://arxiv.org/abs/2507.02171v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Generating Large Semi-Synthetic Graphs of Any Size", "abstract": "Graph generation is an important area in network science. Traditional\napproaches focus on replicating specific properties of real-world graphs, such\nas small diameters or power-law degree distributions. Recent advancements in\ndeep learning, particularly with Graph Neural Networks, have enabled\ndata-driven methods to learn and generate graphs without relying on predefined\nstructural properties. Despite these advances, current models are limited by\ntheir reliance on node IDs, which restricts their ability to generate graphs\nlarger than the input graph and ignores node attributes. To address these\nchallenges, we propose Latent Graph Sampling Generation (LGSG), a novel\nframework that leverages diffusion models and node embeddings to generate\ngraphs of varying sizes without retraining. The framework eliminates the\ndependency on node IDs and captures the distribution of node embeddings and\nsubgraph structures, enabling scalable and flexible graph generation.\nExperimental results show that LGSG performs on par with baseline models for\nstandard metrics while outperforming them in overlooked ones, such as the\ntendency of nodes to form clusters. Additionally, it maintains consistent\nstructural characteristics across graphs of different sizes, demonstrating\nrobustness and scalability.", "published": "2025-07-02 21:46:28", "link": "http://arxiv.org/abs/2507.02166v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies", "abstract": "Artificial intelligence systems, especially those using machine learning, are\nbeing deployed in domains from hiring to loan issuance in order to automate\nthese complex decisions. Judging both the effectiveness and fairness of these\nAI systems, and their human decision making counterpart, is a complex and\nimportant topic studied across both computational and social sciences. Within\nmachine learning, a common way to address bias in downstream classifiers is to\nresample the training data to offset disparities. For example, if hiring rates\nvary by some protected class, then one may equalize the rate within the\ntraining set to alleviate bias in the resulting classifier. While simple and\nseemingly effective, these methods have typically only been evaluated using\ndata obtained through convenience samples, introducing selection bias and label\nbias into metrics. Within the social sciences, psychology, public health, and\nmedicine, audit studies, in which fictitious ``testers'' (e.g., resumes,\nemails, patient actors) are sent to subjects (e.g., job openings, businesses,\ndoctors) in randomized control trials, provide high quality data that support\nrigorous estimates of discrimination. In this paper, we investigate how data\nfrom audit studies can be used to improve our ability to both train and\nevaluate automated hiring algorithms. We find that such data reveals cases\nwhere the common fairness intervention method of equalizing base rates across\nclasses appears to achieve parity using traditional measures, but in fact has\nroughly 10% disparity when measured appropriately. We additionally introduce\ninterventions based on individual treatment effect estimation methods that\nfurther reduce algorithmic discrimination using this data.", "published": "2025-07-02 21:15:56", "link": "http://arxiv.org/abs/2507.02152v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search", "abstract": "Large language models (LLMs) are increasingly used to assign document\nrelevance labels in information retrieval pipelines, especially in domains\nlacking human-labeled data. However, different models often disagree on\nborderline cases, raising concerns about how such disagreement affects\ndownstream retrieval. This study examines labeling disagreement between two\nopen-weight LLMs, LLaMA and Qwen, on a corpus of scholarly abstracts related to\nSustainable Development Goals (SDGs) 1, 3, and 7. We isolate disagreement\nsubsets and examine their lexical properties, rank-order behavior, and\nclassification predictability. Our results show that model disagreement is\nsystematic, not random: disagreement cases exhibit consistent lexical patterns,\nproduce divergent top-ranked outputs under shared scoring functions, and are\ndistinguishable with AUCs above 0.74 using simple classifiers. These findings\nsuggest that LLM-based filtering introduces structured variability in document\nretrieval, even under controlled prompting and shared ranking logic. We propose\nusing classification disagreement as an object of analysis in retrieval\nevaluation, particularly in policy-relevant or thematic search tasks.", "published": "2025-07-02 20:53:51", "link": "http://arxiv.org/abs/2507.02139v1", "categories": ["cs.IR", "cs.AI", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities", "abstract": "The blockchain oracle problem, which refers to the challenge of injecting\nreliable external data into decentralized systems, remains a fundamental\nlimitation to the development of trustless applications. While recent years\nhave seen a proliferation of architectural, cryptographic, and economic\nstrategies to mitigate this issue, no one has yet fully resolved the\nfundamental question of how a blockchain can gain knowledge about the off-chain\nworld. In this position paper, we critically assess the role artificial\nintelligence (AI) can play in tackling the oracle problem. Drawing from both\nacademic literature and practitioner implementations, we examine how AI\ntechniques such as anomaly detection, language-based fact extraction, dynamic\nreputation modeling, and adversarial resistance can enhance oracle systems. We\nobserve that while AI introduces powerful tools for improving data quality,\nsource selection, and system resilience, it cannot eliminate the reliance on\nunverifiable off-chain inputs. Therefore, this study supports the idea that AI\nshould be understood as a complementary layer of inference and filtering within\na broader oracle design, not a substitute for trust assumptions.", "published": "2025-07-02 20:15:21", "link": "http://arxiv.org/abs/2507.02125v1", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT", "cs.LG", "11, 62, 68, 90, 91", "F.0; F.4; H.4; H.5; I.2"], "primary_category": "cs.CR"}
{"title": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework", "abstract": "We present a hybrid machine learning framework that combines Physics-Informed\nNeural Operators (PINOs) with score-based generative diffusion models to\nsimulate the full spatio-temporal evolution of two-dimensional, incompressible,\nresistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds\nnumbers ($\\mathrm{Re}$). The framework leverages the equation-constrained\ngeneralization capabilities of PINOs to predict coherent, low-frequency\ndynamics, while a conditional diffusion model stochastically corrects\nhigh-frequency residuals, enabling accurate modeling of fully developed\nturbulence. Trained on a comprehensive ensemble of high-fidelity simulations\nwith $\\mathrm{Re} \\in \\{100, 250, 500, 750, 1000, 3000, 10000\\}$, the approach\nachieves state-of-the-art accuracy in regimes previously inaccessible to\ndeterministic surrogates. At $\\mathrm{Re}=1000$ and $3000$, the model\nfaithfully reconstructs the full spectral energy distributions of both velocity\nand magnetic fields late into the simulation, capturing non-Gaussian\nstatistics, intermittent structures, and cross-field correlations with high\nfidelity. At extreme turbulence levels ($\\mathrm{Re}=10000$), it remains the\nfirst surrogate capable of recovering the high-wavenumber evolution of the\nmagnetic field, preserving large-scale morphology and enabling statistically\nmeaningful predictions.", "published": "2025-07-02 19:33:57", "link": "http://arxiv.org/abs/2507.02106v1", "categories": ["physics.flu-dyn", "cs.AI", "cs.LG", "gr-qc", "physics.comp-ph", "J.2; I.2"], "primary_category": "physics.flu-dyn"}
{"title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "abstract": "Modern AI models, such as large language models, are usually trained once on\na huge corpus of data, potentially fine-tuned for a specific task, and then\ndeployed with fixed parameters. Their training is costly, slow, and gradual,\nrequiring billions of repetitions. In stark contrast, animals continuously\nadapt to the ever-changing contingencies in their environments. This is\nparticularly important for social species, where behavioral policies and reward\noutcomes may frequently change in interaction with peers. The underlying\ncomputational processes are often marked by rapid shifts in an animal's\nbehaviour and rather sudden transitions in neuronal population activity. Such\ncomputational capacities are of growing importance for AI systems operating in\nthe real world, like those guiding robots or autonomous vehicles, or for\nagentic AI interacting with humans online. Can AI learn from neuroscience? This\nPerspective explores this question, integrating the literature on continual and\nin-context learning in AI with the neuroscience of learning on behavioral tasks\nwith shifting rules, reward probabilities, or outcomes. We will outline an\nagenda for how specifically insights from neuroscience may inform current\ndevelopments in AI in this area, and - vice versa - what neuroscience may learn\nfrom AI, contributing to the evolving field of NeuroAI.", "published": "2025-07-02 19:30:57", "link": "http://arxiv.org/abs/2507.02103v1", "categories": ["cs.AI", "q-bio.NC", "I.2; I.6; A.1"], "primary_category": "cs.AI"}
{"title": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters", "abstract": "Geometric diffusion models have shown remarkable success in molecular\ndynamics and structure generation. However, efficiently fine-tuning them for\ndownstream tasks with varying geometric controls remains underexplored. In this\nwork, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables\nflexible and parameter-efficient fine-tuning for controlled generative tasks\nwithout modifying the original model architecture. GeoAda introduces a\nstructured adapter design: control signals are first encoded through coupling\noperators, then processed by a trainable copy of selected pretrained model\nlayers, and finally projected back via decoupling operators followed by an\nequivariant zero-initialized convolution. By fine-tuning only these lightweight\nadapter modules, GeoAda preserves the model's geometric consistency while\nmitigating overfitting and catastrophic forgetting. We theoretically prove that\nthe proposed adapters maintain SE(3)-equivariance, ensuring that the geometric\ninductive biases of the pretrained diffusion model remain intact during\nadaptation. We demonstrate the wide applicability of GeoAda across diverse\ngeometric control types, including frame control, global control, subgraph\ncontrol, and a broad range of application domains such as particle dynamics,\nmolecular dynamics, human motion prediction, and molecule generation. Empirical\nresults show that GeoAda achieves state-of-the-art fine-tuning performance\nwhile preserving original task accuracy, whereas other baselines experience\nsignificant performance degradation due to overfitting and catastrophic\nforgetting.", "published": "2025-07-02 18:44:03", "link": "http://arxiv.org/abs/2507.02085v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "abstract": "Designing experiments and result interpretations are core scientific\ncompetencies, particularly in biology, where researchers perturb complex\nsystems to uncover the underlying systems. Recent efforts to evaluate the\nscientific capabilities of large language models (LLMs) fail to test these\ncompetencies because wet-lab experimentation is prohibitively expensive: in\nexpertise, time and equipment. We introduce SciGym, a first-in-class benchmark\nthat assesses LLMs' iterative experiment design and analysis abilities in\nopen-ended scientific discovery tasks. SciGym overcomes the challenge of\nwet-lab costs by running a dry lab of biological systems. These models, encoded\nin Systems Biology Markup Language, are efficient for generating simulated\ndata, making them ideal testbeds for experimentation on realistically complex\nsystems. We evaluated six frontier LLMs on 137 small systems, and released a\ntotal of 350 systems. Our evaluation shows that while more capable models\ndemonstrated superior performance, all models' performance declined\nsignificantly as system complexity increased, suggesting substantial room for\nimprovement in the scientific capabilities of LLM agents.", "published": "2025-07-02 18:41:44", "link": "http://arxiv.org/abs/2507.02083v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "abstract": "Large language models (LLMs) have rapidly progressed into general-purpose\nagents capable of solving a broad spectrum of tasks. However, current models\nremain inefficient at reasoning: they apply fixed inference-time compute\nregardless of task complexity, often overthinking simple problems while\nunderthinking hard ones. This survey presents a comprehensive review of\nefficient test-time compute (TTC) strategies, which aim to improve the\ncomputational efficiency of LLM reasoning. We introduce a two-tiered taxonomy\nthat distinguishes between L1-controllability, methods that operate under fixed\ncompute budgets, and L2-adaptiveness, methods that dynamically scale inference\nbased on input difficulty or model confidence. We benchmark leading proprietary\nLLMs across diverse datasets, highlighting critical trade-offs between\nreasoning performance and token usage. Compared to prior surveys on efficient\nreasoning, our review emphasizes the practical control, adaptability, and\nscalability of TTC methods. Finally, we discuss emerging trends such as hybrid\nthinking models and identify key challenges for future work towards making LLMs\nmore computationally efficient, robust, and responsive to user constraints.", "published": "2025-07-02 18:27:42", "link": "http://arxiv.org/abs/2507.02076v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach", "abstract": "Compound Expression Recognition (CER), a subfield of affective computing,\naims to detect complex emotional states formed by combinations of basic\nemotions. In this work, we present a novel zero-shot multimodal approach for\nCER that combines six heterogeneous modalities into a single pipeline: static\nand dynamic facial expressions, scene and label matching, scene context, audio,\nand text. Unlike previous approaches relying on task-specific training data,\nour approach uses zero-shot components, including Contrastive Language-Image\nPretraining (CLIP)-based label matching and Qwen-VL for semantic scene\nunderstanding. We further introduce a Multi-Head Probability Fusion (MHPF)\nmodule that dynamically weights modality-specific predictions, followed by a\nCompound Expressions (CE) transformation module that uses Pair-Wise Probability\nAggregation (PPA) and Pair-Wise Feature Similarity Aggregation (PFSA) methods\nto produce interpretable compound emotion outputs. Evaluated under multi-corpus\ntraining, the proposed approach shows F1 scores of 46.95% on AffWild2, 49.02%\non Acted Facial Expressions in The Wild (AFEW), and 34.85% on C-EXPR-DB via\nzero-shot testing, which is comparable to the results of supervised approaches\ntrained on target data. This demonstrates the effectiveness of the proposed\napproach for capturing CE without domain adaptation. The source code is\npublicly available.", "published": "2025-07-02 23:51:40", "link": "http://arxiv.org/abs/2507.02205v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning", "abstract": "Monocular depth estimation has recently advanced to provide not only relative\nbut also metric depth predictions. However, its reliability in underwater\nenvironments remains limited due to light attenuation and scattering, color\ndistortion, turbidity, and the lack of high-quality metric ground-truth data.\nIn this paper, we present a comprehensive benchmark of zero-shot and fine-tuned\nmonocular metric depth estimation models on real-world underwater datasets with\nmetric depth annotations, such as FLSea and SQUID. We evaluate a diverse set of\nstate-of-the-art models across a range of underwater conditions with different\nranges. Our results show that large-scale models trained on terrestrial (real\nor synthetic) data, while effective in in-air settings, perform poorly\nunderwater due to significant domain shifts. To address this, we fine-tune\nDepth Anything V2 with a ViT-S backbone encoder on a synthetic underwater\nvariant of the Hypersim dataset, which we generated using a physically based\nunderwater image formation model. We demonstrate our fine-tuned model\nconsistently improves performance across all benchmarks and outperforms\nbaselines trained only on the clean in-air Hypersim dataset. Our study provides\na detailed evaluation and visualization for monocular metric depth estimation\nin underwater scenes, highlighting the importance of domain adaptation and\nscale-aware supervision for achieving robust and generalizable metric depth\npredictions in challenging underwater environments for future research.", "published": "2025-07-02 21:06:39", "link": "http://arxiv.org/abs/2507.02148v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction", "abstract": "Generative models have demonstrated strong performance in conditional\nsettings and can be viewed as a form of data compression, where the condition\nserves as a compact representation. However, their limited controllability and\nreconstruction accuracy restrict their practical application to data\ncompression. In this work, we propose an efficient latent diffusion framework\nthat bridges this gap by combining a variational autoencoder with a conditional\ndiffusion model. Our method compresses only a small number of keyframes into\nlatent space and uses them as conditioning inputs to reconstruct the remaining\nframes via generative interpolation, eliminating the need to store latent\nrepresentations for every frame. This approach enables accurate spatiotemporal\nreconstruction while significantly reducing storage costs. Experimental results\nacross multiple datasets show that our method achieves up to 10 times higher\ncompression ratios than rule-based state-of-the-art compressors such as SZ3,\nand up to 63 percent better performance than leading learning-based methods\nunder the same reconstruction error.", "published": "2025-07-02 20:27:38", "link": "http://arxiv.org/abs/2507.02129v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges", "abstract": "Crash detection from video feeds is a critical problem in intelligent\ntransportation systems. Recent developments in large language models (LLMs) and\nvision-language models (VLMs) have transformed how we process, reason about,\nand summarize multimodal information. This paper surveys recent methods\nleveraging LLMs for crash detection from video data. We present a structured\ntaxonomy of fusion strategies, summarize key datasets, analyze model\narchitectures, compare performance benchmarks, and discuss ongoing challenges\nand opportunities. Our review provides a foundation for future research in this\nfast-growing intersection of video understanding and foundation models.", "published": "2025-07-02 18:21:01", "link": "http://arxiv.org/abs/2507.02074v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "abstract": "Large language models (LLMs) are rapidly evolving from passive engines of\ntext generation into agentic entities that can plan, remember, invoke external\ntools, and co-operate with one another. This perspective paper investigates how\nsuch LLM agents (and societies thereof) can transform the design space of\nrecommender systems.\n  We introduce a unified formalism that (i) models an individual agent as a\ntuple comprising its language core, tool set, and hierarchical memory, and (ii)\ncaptures a multi-agent recommender as a triple of agents, shared environment,\nand communication protocol. Within this framework, we present four end-to-end\nuse cases-interactive party planning, synthetic user-simulation for offline\nevaluation, multi-modal furniture recommendation, and brand-aligned explanation\ngeneration-each illustrating a distinct capability unlocked by agentic\norchestration.\n  We then surface five cross-cutting challenge families: protocol complexity,\nscalability, hallucination and error propagation, emergent misalignment\n(including covert collusion), and brand compliance.\n  For each, we formalize the problem, review nascent mitigation strategies, and\noutline open research questions. The result is both a blueprint and an agenda:\na blueprint that shows how memory-augmented, tool-using LLM agents can be\ncomposed into robust recommendation pipelines, and an agenda inviting the\nRecSys community to develop benchmarks, theoretical guarantees, and governance\ntools that keep pace with this new degree of autonomy. By unifying agentic\nabstractions with recommender objectives, the paper lays the groundwork for the\nnext generation of personalized, trustworthy, and context-rich recommendation\nservices.", "published": "2025-07-02 19:25:44", "link": "http://arxiv.org/abs/2507.02097v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations", "abstract": "We introduce ManifoldMind, a probabilistic geometric recommender system for\nexploratory reasoning over semantic hierarchies in hyperbolic space. Unlike\nprior methods with fixed curvature and rigid embeddings, ManifoldMind\nrepresents users, items, and tags as adaptive-curvature probabilistic spheres,\nenabling personalised uncertainty modeling and geometry-aware semantic\nexploration. A curvature-aware semantic kernel supports soft, multi-hop\ninference, allowing the model to explore diverse conceptual paths instead of\noverfitting to shallow or direct interactions. Experiments on four public\nbenchmarks show superior NDCG, calibration, and diversity compared to strong\nbaselines. ManifoldMind produces explicit reasoning traces, enabling\ntransparent, trustworthy, and exploration-driven recommendations in sparse or\nabstract domains.", "published": "2025-07-02 08:42:11", "link": "http://arxiv.org/abs/2507.02014v1", "categories": ["cs.IR", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Uncertainty-Aware Complex Scientific Table Data Extraction", "abstract": "Table structure recognition (TSR) and optical character recognition (OCR)\nplay crucial roles in extracting structured data from tables in scientific\ndocuments. However, existing extraction frameworks built on top of TSR and OCR\nmethods often fail to quantify the uncertainties of extracted results. To\nobtain highly accurate data for scientific domains, all extracted data must be\nmanually verified, which can be time-consuming and labor-intensive. We propose\na framework that performs uncertainty-aware data extraction for complex\nscientific tables, built on conformal prediction, a model-agnostic method for\nuncertainty quantification (UQ). We explored various uncertainty scoring\nmethods to aggregate the uncertainties introduced by TSR and OCR. We rigorously\nevaluated the framework using a standard benchmark and an in-house dataset\nconsisting of complex scientific tables in six scientific domains. The results\ndemonstrate the effectiveness of using UQ for extraction error detection, and\nby manually verifying only 47\\% of extraction results, the data quality can be\nimproved by 30\\%. Our work quantitatively demonstrates the role of UQ with the\npotential of improving the efficiency in the human-machine cooperation process\nto obtain scientifically usable data from complex tables in scientific\ndocuments. All code and data are available on GitHub at\nhttps://github.com/lamps-lab/TSR-OCR-UQ/tree/main.", "published": "2025-07-02 03:36:15", "link": "http://arxiv.org/abs/2507.02009v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher", "abstract": "This paper introduces {\\em truncated inner $c$-differential cryptanalysis}, a\nnovel technique that for the first time enables the practical application of\n$c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE\nTrans. Inf. Theory, 2020) established the notion of $c$-differential uniformity\nusing $(F(x\\oplus a), cF(x))$, a key challenge remained: multiplication by $c$\ndisrupts the structural properties essential for block cipher analysis,\nparticularly key addition.\n  We resolve this challenge by developing an \\emph{inner} $c$-differential\napproach where multiplication by $c$ affects the input: $(F(cx\\oplus a),\nF(x))$. We prove that the inner $c$-differential uniformity of a function $F$\nequals the outer $c$-differential uniformity of $F^{-1}$, establishing a\nfundamental duality. This modification preserves cipher structure while\nenabling practical cryptanalytic applications.\n  Our main contribution is a comprehensive multi-faceted\nstatistical-computational framework, implementing truncated $c$-differential\nanalysis against the full 9-round Kuznyechik cipher (the inner\n$c$-differentials are immune to the key whitening at the backend). Through\nextensive computational analysis involving millions of differential pairs, we\ndemonstrate statistically significant non-randomness across all tested round\ncounts. For the full 9-round cipher, we identify multiple configurations\ntriggering critical security alerts, with bias ratios reaching $1.7\\times$ and\ncorrected p-values as low as $1.85 \\times 10^{-3}$, suggesting insufficient\nsecurity margin against this new attack vector. This represents the first\npractical distinguisher against the full 9-round Kuznyechik.", "published": "2025-07-02 22:27:33", "link": "http://arxiv.org/abs/2507.02181v1", "categories": ["cs.CR", "cs.IT", "math.IT", "94A60, 11T71, 12E20, 68P25, 62P99"], "primary_category": "cs.CR"}
{"title": "Matrix Pencil-Based DoA Estimation for Hybrid Receivers in Snapshot-Limited Scenarios", "abstract": "The goal of this paper is to estimate the directions of arrival (DoAs) for\nhybrid analog/digital (HAD) receivers when the number of snapshots is too small\nfor statistical averaging to be reliable. This goal is achieved in\nfully-digital receivers by employing the matrix pencil method (MPM).\nUnfortunately, the MPM cannot be directly applied in HAD receivers because of\nthe entanglement induced by the underlying analog combiners on the output\nsignals. Furthermore, these analog combiners project the received signal onto a\nlow-dimensional space, jeopardizing the reception of signals arriving from\nparticular DoA ranges. To circumvent these difficulties, we propose two\napproaches to enable the MPM to extract the DoAs in HAD receivers. The two\napproaches avoid severe attenuation induced by low-dimensional projection by\ncycling over an exhaustive set of analog combiners, collectively spanning the\nentire space. The first approach can be applied to both fully-connected (FC)\nand partially-connected (PC) HADs and relies on the availability of periodic,\npotentially unknown, signals to disentangle the output of the HAD receiver. The\nsecond approach applies to PC-HADs only, and eliminates contingency on periodic\nsignals by exploiting the underlying block diagonal structure. The superiority\nof the proposed approaches is demonstrated via numerical simulations and\ncomparisons with the Cram\\'er-Rao lower bound.", "published": "2025-07-02 20:32:32", "link": "http://arxiv.org/abs/2507.02132v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "cVLA: Towards Efficient Camera-Space VLAs", "abstract": "Vision-Language-Action (VLA) models offer a compelling framework for tackling\ncomplex robotic manipulation tasks, but they are often expensive to train. In\nthis paper, we propose a novel VLA approach that leverages the competitive\nperformance of Vision Language Models (VLMs) on 2D images to directly infer\nrobot end-effector poses in image frame coordinates. Unlike prior VLA models\nthat output low-level controls, our model predicts trajectory waypoints, making\nit both more efficient to train and robot embodiment agnostic. Despite its\nlightweight design, our next-token prediction architecture effectively learns\nmeaningful and executable robot trajectories. We further explore the\nunderutilized potential of incorporating depth images, inference-time\ntechniques such as decoding strategies, and demonstration-conditioned action\ngeneration. Our model is trained on a simulated dataset and exhibits strong\nsim-to-real transfer capabilities. We evaluate our approach using a combination\nof simulated and real data, demonstrating its effectiveness on a real robotic\nsystem.", "published": "2025-07-02 22:56:41", "link": "http://arxiv.org/abs/2507.02190v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Statistical Inference for Responsiveness Verification", "abstract": "Many safety failures in machine learning arise when models are used to assign\npredictions to people (often in settings like lending, hiring, or content\nmoderation) without accounting for how individuals can change their inputs. In\nthis work, we introduce a formal validation procedure for the responsiveness of\npredictions with respect to interventions on their features. Our procedure\nframes responsiveness as a type of sensitivity analysis in which practitioners\ncontrol a set of changes by specifying constraints over interventions and\ndistributions over downstream effects. We describe how to estimate\nresponsiveness for the predictions of any model and any dataset using only\nblack-box access, and how to use these estimates to support tasks such as\nfalsification and failure probability estimation. We develop algorithms that\nconstruct these estimates by generating a uniform sample of reachable points,\nand demonstrate how they can promote safety in real-world applications such as\nrecidivism prediction, organ transplant prioritization, and content moderation.", "published": "2025-07-02 21:50:08", "link": "http://arxiv.org/abs/2507.02169v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks", "abstract": "Conformal prediction for graph neural networks (GNNs) offers a promising\nframework for quantifying uncertainty, enhancing GNN reliability in high-stakes\napplications. However, existing methods predominantly focus on static graphs,\nneglecting the evolving nature of real-world graphs. Temporal dependencies in\ngraph structure, node attributes, and ground truth labels violate the\nfundamental exchangeability assumption of standard conformal prediction\nmethods, limiting their applicability. To address these challenges, in this\npaper, we introduce NCPNET, a novel end-to-end conformal prediction framework\ntailored for temporal graphs. Our approach extends conformal prediction to\ndynamic settings, mitigating statistical coverage violations induced by\ntemporal dependencies. To achieve this, we propose a diffusion-based\nnon-conformity score that captures both topological and temporal uncertainties\nwithin evolving networks. Additionally, we develop an efficiency-aware\noptimization algorithm that improves the conformal prediction process,\nenhancing computational efficiency and reducing coverage violations. Extensive\nexperiments on diverse real-world temporal graphs, including WIKI, REDDIT,\nDBLP, and IBM Anti-Money Laundering dataset, demonstrate NCPNET's capability to\nensure guaranteed coverage in temporal graphs, achieving up to a 31% reduction\nin prediction set size on the WIKI dataset, significantly improving efficiency\ncompared to state-of-the-art methods. Our data and code are available at\nhttps://github.com/ODYSSEYWT/NCPNET.", "published": "2025-07-02 21:15:00", "link": "http://arxiv.org/abs/2507.02151v1", "categories": ["cs.LG", "H.1.0; I.2.0"], "primary_category": "cs.LG"}
{"title": "CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs", "abstract": "Modern very large-scale integration (VLSI) design requires the implementation\nof integrated circuits using electronic design automation (EDA) tools. Due to\nthe complexity of EDA algorithms, the vast parameter space poses a huge\nchallenge to chip design optimization, as the combination of even moderate\nnumbers of parameters creates an enormous solution space to explore. Manual\nparameter selection remains industrial practice despite being excessively\nlaborious and limited by expert experience. To address this issue, we present\nCROP, the first large language model (LLM)-powered automatic VLSI design flow\ntuning framework. Our approach includes: (1) a scalable methodology for\ntransforming RTL source code into dense vector representations, (2) an\nembedding-based retrieval system for matching designs with semantically similar\ncircuits, and (3) a retrieval-augmented generation (RAG)-enhanced LLM-guided\nparameter search system that constrains the search process with prior knowledge\nfrom similar designs. Experiment results demonstrate CROP's ability to achieve\nsuperior quality-of-results (QoR) with fewer iterations than existing\napproaches on industrial designs, including a 9.9% reduction in power\nconsumption.", "published": "2025-07-02 20:25:47", "link": "http://arxiv.org/abs/2507.02128v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synergizing Logical Reasoning, Knowledge Management and Collaboration in Multi-Agent LLM System", "abstract": "This paper explores the integration of advanced Multi-Agent Systems (MAS)\ntechniques to develop a team of agents with enhanced logical reasoning,\nlong-term knowledge retention, and Theory of Mind (ToM) capabilities. By\nuniting these core components with optimized communication protocols, we create\na novel framework called SynergyMAS, which fosters collaborative teamwork and\nsuperior problem-solving skills. The system's effectiveness is demonstrated\nthrough a product development team case study, where our approach significantly\nenhances performance and adaptability. These findings highlight SynergyMAS's\npotential to tackle complex, real-world challenges.", "published": "2025-07-02 21:53:44", "link": "http://arxiv.org/abs/2507.02170v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A Hybrid DEC-SIE Framework for Potential-Based Electromagnetic Analysis of Heterogeneous Media", "abstract": "Analyzing electromagnetic fields in complex, multi-material environments\npresents substantial computational challenges. To address these, we propose a\nhybrid numerical method that couples discrete exterior calculus (DEC) with\nsurface integral equations (SIE) in the potential-based formulation of\nMaxwell's equations. The method employs the magnetic vector and electric scalar\npotentials ($\\mathbf{A}$-$\\Phi$) under the Lorenz gauge, offering natural\ncompatibility with multi-physics couplings and inherent immunity to\nlow-frequency breakdown. To effectively handle both bounded and unbounded\nregions, we divide the computational domain: the inhomogeneous interior is\ndiscretized using DEC, a coordinate-free framework that preserves topological\ninvariants and enables structure-preserving discretization on unstructured\nmeshes, while the homogeneous exterior is treated using SIEs, which inherently\nsatisfy the radiation condition and eliminate the need for artificial domain\ntruncation. A key contribution of this work is a scalar reformulation of the\nSIEs, which reduces the number of surface integral operators from fourteen to\ntwo by expressing the problem in terms of the Cartesian components of the\nvector potential and their normal derivatives. This simplification motivates a\ncorresponding adaptation in the DEC domain: each vector potential component is\nrepresented as a discrete 0-form, in contrast to the conventional 1-form\nrepresentation. This novel treatment improves compatibility at the interface\nand significantly enhances numerical performance. The proposed hybrid method\nthus offers a unified, efficient, and physically consistent framework for\nsolving electromagnetic scattering and radiation problems in complex geometries\nand heterogeneous materials", "published": "2025-07-02 19:28:41", "link": "http://arxiv.org/abs/2507.02099v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Arbitrage with bounded Liquidity", "abstract": "The arbitrage gains or, equivalently, Loss Versus Rebalacing (LVR) for\narbitrage between two imperfectly liquid markets is derived. To derive the LVR,\nI assume a quadratic trading cost to model the cost of trading on the more\nliquid exchange and discuss to which situations my model arguably applies well\n(long tail CEX-DEX arbitrage, DEX-DEX arbitrage) and to which not so well\n(CEX-DEX arbitrage for major pairs). I discuss extension to other cost\nfunctions and directions for future research.", "published": "2025-07-02 16:47:20", "link": "http://arxiv.org/abs/2507.02027v1", "categories": ["q-fin.MF", "q-fin.TR"], "primary_category": "q-fin.MF"}
{"title": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction", "abstract": "Graph representation learning methods have been widely adopted in financial\napplications to enhance company representations by leveraging inter-firm\nrelationships. However, current approaches face three key challenges: (1) The\nadvantages of relational information are obscured by limitations in downstream\ntask designs; (2) Existing graph models specifically designed for stock\nprediction often suffer from excessive complexity and poor generalization; (3)\nExperience-based construction of corporate relationship graphs lacks effective\ncomparison of different graph structures. To address these limitations, we\npropose a long-term stock prediction task and develop a Node-level Graph\nAttention Network (NGAT) specifically tailored for corporate relationship\ngraphs. Furthermore, we experimentally demonstrate the limitations of existing\ngraph comparison methods based on model downstream task performance.\nExperimental results across two datasets consistently demonstrate the\neffectiveness of our proposed task and model. The project is publicly available\non GitHub to encourage reproducibility and future research.", "published": "2025-07-02 13:59:46", "link": "http://arxiv.org/abs/2507.02018v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "I.2.1"], "primary_category": "q-fin.ST"}
{"title": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model", "abstract": "We consider infinite-horizon $\\gamma$-discounted (linear) constrained Markov\ndecision processes (CMDPs) where the objective is to find a policy that\nmaximizes the expected cumulative reward subject to expected cumulative\nconstraints. Given access to a generative model, we propose to solve CMDPs with\na primal-dual framework that can leverage any black-box unconstrained MDP\nsolver. For linear CMDPs with feature dimension $d$, we instantiate the\nframework by using mirror descent value iteration\n(\\texttt{MDVI})~\\citep{kitamura2023regularization} an example MDP solver. We\nprovide sample complexity bounds for the resulting CMDP algorithm in two cases:\n(i) relaxed feasibility, where small constraint violations are allowed, and\n(ii) strict feasibility, where the output policy is required to exactly satisfy\nthe constraint. For (i), we prove that the algorithm can return an\n$\\epsilon$-optimal policy with high probability by using\n$\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^4\\epsilon^2}\\right)$ samples. We note\nthat these results exhibit a near-optimal dependence on both $d$ and\n$\\epsilon$. For (ii), we show that the algorithm requires\n$\\tilde{O}\\left(\\frac{d^2}{(1-\\gamma)^6\\epsilon^2\\zeta^2}\\right)$ samples,\nwhere $\\zeta$ is the problem-dependent Slater constant that characterizes the\nsize of the feasible region. Finally, we instantiate our framework for tabular\nCMDPs and show that it can be used to recover near-optimal sample complexities\nin this setting.", "published": "2025-07-02 19:07:37", "link": "http://arxiv.org/abs/2507.02089v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adaptive Iterative Soft-Thresholding Algorithm with the Median Absolute Deviation", "abstract": "The adaptive Iterative Soft-Thresholding Algorithm (ISTA) has been a popular\nalgorithm for finding a desirable solution to the LASSO problem without\nexplicitly tuning the regularization parameter $\\lambda$. Despite that the\nadaptive ISTA is a successful practical algorithm, few theoretical results\nexist. In this paper, we present the theoretical analysis on the adaptive ISTA\nwith the thresholding strategy of estimating noise level by median absolute\ndeviation. We show properties of the fixed points of the algorithm, including\nscale equivariance, non-uniqueness, and local stability, prove the local linear\nconvergence guarantee, and show its global convergence behavior.", "published": "2025-07-02 18:41:59", "link": "http://arxiv.org/abs/2507.02084v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Neural simulation-based inference of the Higgs trilinear self-coupling via off-shell Higgs production", "abstract": "One of the forthcoming major challenges in particle physics is the\nexperimental determination of the Higgs trilinear self-coupling. While efforts\nhave largely focused on on-shell double- and single-Higgs production in\nproton-proton collisions, off-shell Higgs production has also been proposed as\na valuable complementary probe. In this article, we design a hybrid neural\nsimulation-based inference (NSBI) approach to construct a likelihood of the\nHiggs signal incorporating modifications from the Standard Model effective\nfield theory (SMEFT), relevant background processes, and quantum interference\neffects. It leverages the training efficiency of matrix-element-enhanced\ntechniques, which are vital for robust SMEFT applications, while also\nincorporating the practical advantages of classification-based methods for\neffective background estimates. We demonstrate that our NSBI approach achieves\nsensitivity close to the theoretical optimum and provide expected constraints\nfor the high-luminosity upgrade of the Large Hadron Collider. While we\nprimarily concentrate on the Higgs trilinear self-coupling, we also consider\nconstraints on other SMEFT operators that affect off-shell Higgs production.", "published": "2025-07-02 18:00:00", "link": "http://arxiv.org/abs/2507.02032v1", "categories": ["hep-ph", "hep-ex", "physics.data-an", "stat.ML"], "primary_category": "hep-ph"}
{"title": "An Investigation on Combining Geometry and Consistency Constraints into Phase Estimation for Speech Enhancement", "abstract": "We propose a novel iterative phase estimation framework, termed multi-source\nGriffin-Lim algorithm (MSGLA), for speech enhancement (SE) under additive noise\nconditions. The core idea is to leverage the ad-hoc consistency constraint of\ncomplex-valued short-time Fourier transform (STFT) spectrograms to address the\nsign ambiguity challenge commonly encountered in geometry-based phase\nestimation. Furthermore, we introduce a variant of the geometric constraint\nframework based on the law of sines and cosines, formulating a new phase\nreconstruction algorithm using noise phase estimates. We first validate the\nproposed technique through a series of oracle experiments, demonstrating its\neffectiveness under ideal conditions. We then evaluate its performance on the\nVB-DMD and WSJ0-CHiME3 data sets, and show that the proposed MSGLA variants\nmatch well or slightly outperform existing algorithms, including direct phase\nestimation and DNN-based sign prediction, especially in terms of background\nnoise suppression.", "published": "2025-07-02 23:01:59", "link": "http://arxiv.org/abs/2507.02192v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Pronunciation Editing for Finnish Speech using Phonetic Posteriorgrams", "abstract": "Synthesizing second-language (L2) speech is potentially highly valued for L2\nlanguage learning experience and feedback. However, due to the lack of L2\nspeech synthesis datasets, it is difficult to synthesize L2 speech for\nlow-resourced languages. In this paper, we provide a practical solution for\nediting native speech to approximate L2 speech and present PPG2Speech, a\ndiffusion-based multispeaker Phonetic-Posteriorgrams-to-Speech model that is\ncapable of editing a single phoneme without text alignment. We use Matcha-TTS's\nflow-matching decoder as the backbone, transforming Phonetic Posteriorgrams\n(PPGs) to mel-spectrograms conditioned on external speaker embeddings and\npitch. PPG2Speech strengthens the Matcha-TTS's flow-matching decoder with\nClassifier-free Guidance (CFG) and Sway Sampling. We also propose a new\ntask-specific objective evaluation metric, the Phonetic Aligned Consistency\n(PAC), between the edited PPGs and the PPGs extracted from the synthetic speech\nfor editing effects. We validate the effectiveness of our method on Finnish, a\nlow-resourced, nearly phonetic language, using approximately 60 hours of data.\nWe conduct objective and subjective evaluations of our approach to compare its\nnaturalness, speaker similarity, and editing effectiveness with TTS-based\nediting. Our source code is published at\nhttps://github.com/aalto-speech/PPG2Speech.", "published": "2025-07-02 19:57:14", "link": "http://arxiv.org/abs/2507.02115v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Parametric Neural Amp Modeling with Active Learning", "abstract": "We introduce PANAMA, an active learning framework for the training of\nend-to-end parametric guitar amp models using a WaveNet-like architecture. With\n\\model, one can create a virtual amp by recording samples that are determined\nby an active learning strategy to use a minimum amount of datapoints (i.e., amp\nknob settings). We show that gradient-based optimization algorithms can be used\nto determine the optimal datapoints to sample, and that the approach helps\nunder a constrained number of samples.", "published": "2025-07-02 19:47:23", "link": "http://arxiv.org/abs/2507.02109v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Experimental Multiport-Network Parameter Estimation and Optimization for Multi-Bit RIS", "abstract": "Physics-consistent theoretical studies on RIS-parametrized wireless channels\nuse models from multiport-network theory (MNT) to capture mutual-coupling (MC)\neffects. However, in practice, RIS design and radio environment are partially\nor completely unknown. We fill a research gap on how to estimate the MNT model\nparameters in such experimentally relevant scenarios. Our technique efficiently\ncombines closed-form and gradient-descent steps, and it can be applied to\nmulti-bit-programmable RIS elements. We discuss inevitable (but operationally\nirrelevant) parameter ambiguities. We experimentally validate our technique in\nan unknown rich-scattering environment parametrized by eight 8-bit-programmable\nRIS elements of unknown design. We experimentally evaluate the performance of\nRIS configurations optimized with the estimated MNT model and an MC-unaware\ncascaded model. While the models differ in accuracy by up to 17 dB, the\nend-to-end performance differences are small.", "published": "2025-07-02 21:48:54", "link": "http://arxiv.org/abs/2507.02168v1", "categories": ["physics.app-ph", "eess.SP"], "primary_category": "physics.app-ph"}
{"title": "AI-Empowered Channel Generation for IoV Semantic Communications in Dynamic Conditions", "abstract": "The Internet of Vehicles (IoV) transforms the transportation ecosystem\npromising pervasive connectivity and data-driven approaches. Deep learning and\ngenerative Artificial Intelligence (AI) have the potential to significantly\nenhance the operation of applications within IoV by facilitating efficient\ndecision-making and predictive capabilities, including intelligent navigation,\nvehicle safety monitoring, accident prevention, and intelligent traffic\nmanagement. Nevertheless, efficiently transmitting and processing the massive\nvolumes of data generated by the IoV in real-time remains a significant\nchallenge, particularly in dynamic and unpredictable wireless channel\nconditions. To address these challenges, this paper proposes a semantic\ncommunication framework based on channel perception to improve the accuracy and\nefficiency of data transmission. The semantic communication model extracts and\ncompresses the information to be transmitted. In addition, the wireless channel\nis estimated by using a generative diffusion model, which is employed to\npredict the dynamic channel states, thereby improving the quality of IoV\nservice. In dynamic scenarios, however, the channel estimation performance may\nbe degraded when substantially new scenarios take place, which will adversely\naffect user experience. To mitigate this limitation, we employ a large model to\nfine-tune the channel generation model to enhance its adaptability for varying\nscenarios. The performance and reliability of the proposed framework are\nevaluated on the two public datasets.", "published": "2025-07-02 08:41:42", "link": "http://arxiv.org/abs/2507.02013v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks", "abstract": "Retrieval-augmented Generation (RAG) has primarily been studied in limited\nsettings, such as factoid question answering; more challenging,\nreasoning-intensive benchmarks have seen limited success from minimal RAG. In\nthis work, we challenge this prevailing view on established,\nreasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We\nidentify a key missing component in prior work: a usable, web-scale datastore\naligned with the breadth of pretraining data. To this end, we introduce\nCompactDS: a diverse, high-quality, web-scale datastore that achieves high\nretrieval accuracy and subsecond latency on a single-node. The key insights are\n(1) most web content can be filtered out without sacrificing coverage, and a\ncompact, high-quality subset is sufficient; and (2) combining in-memory\napproximate nearest neighbor (ANN) retrieval and on-disk exact search balances\nspeed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves\nconsistent accuracy improvements across all benchmarks and model sizes\n(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,\nand 19% on MATH. No single data source suffices alone, highlighting the\nimportance of diversity of sources (web crawls, curated math, academic papers,\ntextbooks). Finally, we show that our carefully designed in-house datastore\nmatches or outperforms web search engines such as Google Search, as well as\nrecently proposed, complex agent-based RAG systems--all while maintaining\nsimplicity, reproducibility, and self-containment. We release CompactDS and our\nretrieval pipeline, supporting future research exploring retrieval-based AI\nsystems.", "published": "2025-07-02 02:35:47", "link": "http://arxiv.org/abs/2507.01297v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "PDFMathTranslate: Scientific Document Translation Preserving Layouts", "abstract": "Language barriers in scientific documents hinder the diffusion and\ndevelopment of science and technologies. However, prior efforts in translating\nsuch documents largely overlooked the information in layouts. To bridge the\ngap, we introduce PDFMathTranslate, the world's first open-source software for\ntranslating scientific documents while preserving layouts. Leveraging the most\nrecent advances in large language models and precise layout detection, we\ncontribute to the community with key improvements in precision, flexibility,\nand efficiency. The work has been open-sourced at\nhttps://github.com/byaidu/pdfmathtranslate with more than 22k downloads.", "published": "2025-07-02 10:22:05", "link": "http://arxiv.org/abs/2507.03009v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50, 68T45, 68U10, 68U15", "D.2.2; I.2.10; I.2.7; J.0"], "primary_category": "cs.CL"}
{"title": "A hierarchical invariant for line bundles and its applications in algebraic geometry codes", "abstract": "We introduce the notion of hierarchical depth for line bundles on smooth\nprojective surfaces, defined via filtrations by line subbundles with successive\nquotients supported on effective divisors. This invariant helps to investigate\nboth the algebraic and geometric complexity of line bundles through discrete\nstepwise constructions. We study some of its basic properties, including\nfunctorial behavior under restriction to curves and compatibility with\nampleness and base-point freeness. Applying this framework to algebraic\ngeometry (AG) codes, we show that hierarchical filtrations yield natural code\nfamilies whose combinatorial parameters (dimension, minimum distance) evolve\npredictably across the filtration.", "published": "2025-07-02 16:21:31", "link": "http://arxiv.org/abs/2507.01859v2", "categories": ["math.AG", "cs.IT", "math.AC", "math.IT", "14G50 (Primary) 14C20, 14H52 (Secondary)"], "primary_category": "math.AG"}
{"title": "Deterministic Cryptographic Seed Generation via Cyclic Modular Inversion over $\\mathbb{Z}/3^p\\mathbb{Z}$", "abstract": "We present a deterministic framework for cryptographic seed generation based\non cyclic modular inversion over $\\mathbb{Z}/3^p\\mathbb{Z}$. The method\nenforces algebraic admissibility on seed inputs via the identity $d_k \\equiv\n-\\left(2^{k-1}\\right)^{-1} \\bmod 3^p$, thereby producing structured and\ninvertible residue sequences. This mapping yields entropy-rich, cycle-complete\nseeds well-suited for cryptographic primitives such as DRBGs, KDFs, and\npost-quantum schemes. To assess the quality of randomness, we introduce the\nEntropy Confidence Score (ECS), a composite metric reflecting coverage,\nuniformity, and modular bias. Although not a cryptographic PRNG in itself, the\nframework serves as a deterministic entropy filter that conditions and\nvalidates seed inputs prior to their use by conventional generators. Empirical\nand hardware-based results confirm constant-time execution, minimal\nside-channel leakage, and lightweight feasibility for embedded applications.\nThe framework complements existing cryptographic stacks by acting as an\nalgebraically verifiable entropy filter, thereby enhancing structural soundness\nand auditability.", "published": "2025-07-02 00:17:55", "link": "http://arxiv.org/abs/2507.03000v1", "categories": ["cs.CR", "cs.IT", "math.IT", "Primary 05A17, Secondary 11D45, 11Y60, 94A60", "F.2.1"], "primary_category": "cs.CR"}
{"title": "CLUES: Collaborative High-Quality Data Selection for LLMs via Training Dynamics", "abstract": "Recent research has highlighted the importance of data quality in scaling\nlarge language models (LLMs). However, automated data quality control faces\nunique challenges in collaborative settings where sharing is not allowed\ndirectly between data silos. To tackle this issue, this paper proposes a novel\ndata quality control technique based on the notion of data influence on the\ntraining dynamics of LLMs, that high quality data are more likely to have\nsimilar training dynamics to the anchor dataset. We then leverage the influence\nof the training dynamics to select high-quality data from different private\ndomains, with centralized model updates on the server side in a collaborative\ntraining fashion by either model merging or federated learning. As for the data\nquality indicator, we compute the per-sample gradients with respect to the\nprivate data and the anchor dataset, and use the trace of the accumulated inner\nproducts as a measurement of data quality. In addition, we develop a quality\ncontrol evaluation tailored for collaborative settings with heterogeneous\ndomain data. Experiments show that training on the high-quality data selected\nby our method can often outperform other data selection methods for\ncollaborative fine-tuning of LLMs, across diverse private domain datasets, in\nmedical, multilingual and financial settings. Our code is released at\ngithub.com/Ryan0v0/CLUES.", "published": "2025-07-02 06:19:40", "link": "http://arxiv.org/abs/2507.03004v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "GPU-based complete search for nonlinear minimization subject to bounds", "abstract": "This paper introduces a GPU-based complete search method to enclose the\nglobal minimum of a nonlinear function subject to simple bounds on the\nvariables. Using interval analysis, coupled with the computational power and\narchitecture of GPU, the method iteratively rules out the regions in the search\ndomain where the global minimum cannot exist and leaves a finite set of regions\nwhere the global minimum must exist. For effectiveness, because of the rigor of\ninterval analysis, the method is guaranteed to enclose the global minimum of\nthe nonlinear function even in the presence of rounding errors. For efficiency,\nthe method employs a novel GPU-based single program, single data parallel\nprogramming style to circumvent major GPU performance bottlenecks, and a\nvariable cycling technique is also integrated into the method to reduce\ncomputational cost when minimizing large-scale nonlinear functions. The method\nis validated by minimizing 10 multimodal benchmark test functions with scalable\ndimensions, including the well-known Ackley function, Griewank function, Levy\nfunction, and Rastrigin function. These benchmark test functions represent\ngrand challenges of global optimization, and enclosing the guaranteed global\nminimum of these benchmark test functions with more than 80 dimensions has not\nbeen reported in the literature. Our method completely searches the feasible\ndomain and successfully encloses the guaranteed global minimum of these 10\nbenchmark test functions with up to 10,000 dimensions using only one GPU in a\nreasonable computation time, far exceeding the reported results in the\nliterature due to the unique method design and implementation based on GPU\narchitecture.", "published": "2025-07-02 14:54:52", "link": "http://arxiv.org/abs/2507.01770v2", "categories": ["math.NA", "cs.AI", "cs.DC", "cs.MS", "cs.NA", "math.OC", "65G20, 65G30, 65G40, 90C06, 90C26, 90C30", "G.1.6; G.4"], "primary_category": "math.NA"}
{"title": "Pronunciation Editing for Finnish Speech using Phonetic Posteriorgrams", "abstract": "Synthesizing second-language (L2) speech is potentially highly valued for L2\nlanguage learning experience and feedback. However, due to the lack of L2\nspeech synthesis datasets, it is difficult to synthesize L2 speech for\nlow-resourced languages. In this paper, we provide a practical solution for\nediting native speech to approximate L2 speech and present PPG2Speech, a\ndiffusion-based multispeaker Phonetic-Posteriorgrams-to-Speech model that is\ncapable of editing a single phoneme without text alignment. We use Matcha-TTS's\nflow-matching decoder as the backbone, transforming Phonetic Posteriorgrams\n(PPGs) to mel-spectrograms conditioned on external speaker embeddings and\npitch. PPG2Speech strengthens the Matcha-TTS's flow-matching decoder with\nClassifier-free Guidance (CFG) and Sway Sampling. We also propose a new\ntask-specific objective evaluation metric, the Phonetic Aligned Consistency\n(PAC), between the edited PPGs and the PPGs extracted from the synthetic speech\nfor editing effects. We validate the effectiveness of our method on Finnish, a\nlow-resourced, nearly phonetic language, using approximately 60 hours of data.\nWe conduct objective and subjective evaluations of our approach to compare its\nnaturalness, speaker similarity, and editing effectiveness with TTS-based\nediting. Our source code is published at\nhttps://github.com/aalto-speech/PPG2Speech.", "published": "2025-07-02 19:57:14", "link": "http://arxiv.org/abs/2507.02115v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "PDFMathTranslate: Scientific Document Translation Preserving Layouts", "abstract": "Language barriers in scientific documents hinder the diffusion and\ndevelopment of science and technologies. However, prior efforts in translating\nsuch documents largely overlooked the information in layouts. To bridge the\ngap, we introduce PDFMathTranslate, the world's first open-source software for\ntranslating scientific documents while preserving layouts. Leveraging the most\nrecent advances in large language models and precise layout detection, we\ncontribute to the community with key improvements in precision, flexibility,\nand efficiency. The work has been open-sourced at\nhttps://github.com/byaidu/pdfmathtranslate with more than 222k downloads.", "published": "2025-07-02 10:22:05", "link": "http://arxiv.org/abs/2507.03009v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50, 68T45, 68U10, 68U15", "D.2.2; I.2.10; I.2.7; J.0"], "primary_category": "cs.CL"}
{"title": "SpeechAccentLLM: A Unified Framework for Foreign Accent Conversion and Text to Speech", "abstract": "Foreign accent conversion (FAC) in speech processing remains a challenging\ntask. Building on the remarkable success of large language models (LLMs) in\nText-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based\ntechniques for FAC, which we term SpeechAccentLLM. At the core of this\nframework, we introduce SpeechCodeVAE, the first model to integrate\nconnectionist temporal classification (CTC) directly into codebook\ndiscretization for speech content tokenization. This novel architecture\ngenerates tokens with a unique \"locality\" property, as validated by experiments\ndemonstrating optimal trade-offs among content faithfulness, temporal\ncoherence, and structural recoverability. Then, to address data scarcity for\nthe FAC module, we adopted a multitask learning strategy that jointly trains\nthe FAC and TTS modules. Beyond mitigating data limitations, this approach\nyielded accelerated convergence and superior speech quality compared to\nstandalone FAC training. Moreover, leveraging the salient properties of our\ndiscrete speech representations, we introduce SpeechRestorer, a postprocessing\narchitecture designed to refine LLM-generated outputs. This module effectively\nmitigates stochastic errors prevalent in LLM inference pipelines while\nenhancing prosodic continuity, as validated by ablation experiments.", "published": "2025-07-02 04:30:23", "link": "http://arxiv.org/abs/2507.01348v2", "categories": ["eess.AS", "cs.SD", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Uncertainty-Aware Complex Scientific Table Data Extraction", "abstract": "Table structure recognition (TSR) and optical character recognition (OCR)\nplay crucial roles in extracting structured data from tables in scientific\ndocuments. However, existing extraction frameworks built on top of TSR and OCR\nmethods often fail to quantify the uncertainties of extracted results. To\nobtain highly accurate data for scientific domains, all extracted data must be\nmanually verified, which can be time-consuming and labor-intensive. We propose\na framework that performs uncertainty-aware data extraction for complex\nscientific tables, built on conformal prediction, a model-agnostic method for\nuncertainty quantification (UQ). We explored various uncertainty scoring\nmethods to aggregate the uncertainties introduced by TSR and OCR. We rigorously\nevaluated the framework using a standard benchmark and an in-house dataset\nconsisting of complex scientific tables in six scientific domains. The results\ndemonstrate the effectiveness of using UQ for extraction error detection, and\nby manually verifying only 47% of extraction results, the data quality can be\nimproved by 30%. Our work quantitatively demonstrates the role of UQ with the\npotential of improving the efficiency in the human-machine cooperation process\nto obtain scientifically usable data from complex tables in scientific\ndocuments. All code and data are available on GitHub at\nhttps://github.com/lamps-lab/TSR-OCR-UQ/tree/main.", "published": "2025-07-02 03:36:15", "link": "http://arxiv.org/abs/2507.02009v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Experimental Multiport-Network Parameter Estimation and Optimization for Multi-Bit RIS", "abstract": "Physics-consistent theoretical studies on RIS-parametrized wireless channels\nuse models from multiport-network theory (MNT) to capture mutual-coupling (MC)\neffects. However, in practice, RIS design and radio environment are partially\nor completely unknown. We fill a research gap on how to estimate the MNT model\nparameters in such experimentally relevant scenarios. Our technique efficiently\ncombines closed-form and gradient-descent steps, and it can be applied to\nmulti-bit-programmable RIS elements. We discuss inevitable (but operationally\nirrelevant) parameter ambiguities. We experimentally validate our technique in\nan unknown rich-scattering environment parametrized by eight 6-bit-programmable\nRIS elements of unknown design. We experimentally evaluate the performance of\nRIS configurations optimized with the estimated MNT model and an MC-unaware\ncascaded model. While the models differ in accuracy by up to 17 dB, the\nend-to-end performance differences are small.", "published": "2025-07-02 21:48:54", "link": "http://arxiv.org/abs/2507.02168v2", "categories": ["physics.app-ph", "eess.SP"], "primary_category": "physics.app-ph"}
