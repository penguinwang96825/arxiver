{"title": "Technical Report: Competition Solution For BetterMixture", "abstract": "In the era of flourishing large-scale models, the challenge of selecting and\noptimizing datasets from the vast and complex sea of data, to enhance the\nperformance of large language models within the constraints of limited\ncomputational resources, has become paramount. This paper details our solution\nfor the BetterMixture challenge, which focuses on the fine-tuning data mixing\nfor large language models. Our approach, which secured third place,\nincorporates data deduplication, low-level and high-level quality filtering,\nand diversity selection. The foundation of our solution is Ke-Data-Juicer, an\nextension of Data-Juicer, demonstrating its robust capabilities in handling and\noptimizing data for large language models.", "published": "2024-03-20 01:46:06", "link": "http://arxiv.org/abs/2403.13233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual\n  Summarization", "abstract": "Cross-lingual summarization (XLS) generates summaries in a language different\nfrom that of the input documents (e.g., English to Spanish), allowing speakers\nof the target language to gain a concise view of their content. In the present\nday, the predominant approach to this task is to take a performing, pretrained\nmultilingual language model (LM) and fine-tune it for XLS on the language pairs\nof interest. However, the scarcity of fine-tuning samples makes this approach\nchallenging in some cases. For this reason, in this paper we propose revisiting\nthe summarize-and-translate pipeline, where the summarization and translation\ntasks are performed in a sequence. This approach allows reusing the many,\npublicly-available resources for monolingual summarization and translation,\nobtaining a very competitive zero-shot performance. In addition, the proposed\npipeline is completely differentiable end-to-end, allowing it to take advantage\nof few-shot fine-tuning, where available. Experiments over two contemporary and\nwidely adopted XLS datasets (CrossSum and WikiLingua) have shown the remarkable\nzero-shot performance of the proposed approach, and also its strong few-shot\nperformance compared to an equivalent multilingual LM baseline, that the\nproposed approach has been able to outperform in many languages with only 10%\nof the fine-tuning samples.", "published": "2024-03-20 02:04:42", "link": "http://arxiv.org/abs/2403.13240v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Facilitating Pornographic Text Detection for Open-Domain Dialogue\n  Systems via Knowledge Distillation of Large Language Models", "abstract": "Pornographic content occurring in human-machine interaction dialogues can\ncause severe side effects for users in open-domain dialogue systems. However,\nresearch on detecting pornographic language within human-machine interaction\ndialogues is an important subject that is rarely studied. To advance in this\ndirection, we introduce CensorChat, a dialogue monitoring dataset aimed at\ndetecting whether the dialogue session contains pornographic content. To this\nend, we collect real-life human-machine interaction dialogues in the wild and\nbreak them down into single utterances and single-turn dialogues, with the last\nutterance spoken by the chatbot. We propose utilizing knowledge distillation of\nlarge language models to annotate the dataset. Specifically, first, the raw\ndataset is annotated by four open-source large language models, with the\nmajority vote determining the label. Second, we use ChatGPT to update the empty\nlabel from the first step. Third, to ensure the quality of the validation and\ntest sets, we utilize GPT-4 for label calibration. If the current label does\nnot match the one generated by GPT-4, we employ a self-criticism strategy to\nverify its correctness. Finally, to facilitate the detection of pornographic\ntext, we develop a series of text classifiers using a pseudo-labeled dataset.\nDetailed data analysis demonstrates that leveraging knowledge distillation\ntechniques with large language models provides a practical and cost-efficient\nmethod for developing pornographic text detectors.", "published": "2024-03-20 02:29:09", "link": "http://arxiv.org/abs/2403.13250v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LeanReasoner: Boosting Complex Logical Reasoning with Lean", "abstract": "Large language models (LLMs) often struggle with complex logical reasoning\ndue to logical inconsistencies and the inherent difficulty of such reasoning.\nWe use Lean, a theorem proving framework, to address these challenges. By\nformalizing logical reasoning problems into theorems within Lean, we can solve\nthem by proving or disproving the corresponding theorems. This method reduces\nthe risk of logical inconsistencies with the help of Lean's symbolic solver. It\nalso enhances our ability to treat complex reasoning tasks by using Lean's\nextensive library of theorem proofs. Our method achieves state-of-the-art\nperformance on the FOLIO dataset and achieves performance near this level on\nProofWriter. Notably, these results were accomplished by fine-tuning on fewer\nthan 100 in-domain samples for each dataset.", "published": "2024-03-20 05:29:06", "link": "http://arxiv.org/abs/2403.13312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Entropy-based Text Watermarking Detection Method", "abstract": "Text watermarking algorithms for large language models (LLMs) can effectively\nidentify machine-generated texts by embedding and detecting hidden features in\nthe text. Although the current text watermarking algorithms perform well in\nmost high-entropy scenarios, its performance in low-entropy scenarios still\nneeds to be improved. In this work, we opine that the influence of token\nentropy should be fully considered in the watermark detection process, $i.e.$,\nthe weight of each token during watermark detection should be customized\naccording to its entropy, rather than setting the weights of all tokens to the\nsame value as in previous methods. Specifically, we propose\n\\textbf{E}ntropy-based Text \\textbf{W}atermarking \\textbf{D}etection\n(\\textbf{EWD}) that gives higher-entropy tokens higher influence weights during\nwatermark detection, so as to better reflect the degree of watermarking.\nFurthermore, the proposed detection process is training-free and fully\nautomated. From the experiments, we demonstrate that our EWD can achieve better\ndetection performance in low-entropy scenarios, and our method is also general\nand can be applied to texts with different entropy distributions. Our code and\ndata is available\\footnote{\\url{https://github.com/luyijian3/EWD}}.\nAdditionally, our algorithm could be accessed through MarkLLM\n\\cite{pan2024markllm}\\footnote{\\url{https://github.com/THU-BPM/MarkLLM}}.", "published": "2024-03-20 10:40:01", "link": "http://arxiv.org/abs/2403.13485v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "eRST: A Signaled Graph Theory of Discourse Relations and Organization", "abstract": "In this article we present Enhanced Rhetorical Structure Theory (eRST), a new\ntheoretical framework for computational discourse analysis, based on an\nexpansion of Rhetorical Structure Theory (RST). The framework encompasses\ndiscourse relation graphs with tree-breaking, non-projective and concurrent\nrelations, as well as implicit and explicit signals which give explainable\nrationales to our analyses. We survey shortcomings of RST and other existing\nframeworks, such as Segmented Discourse Representation Theory (SDRT), the Penn\nDiscourse Treebank (PDTB) and Discourse Dependencies, and address these using\nconstructs in the proposed theory. We provide annotation, search and\nvisualization tools for data, and present and evaluate a freely available\ncorpus of English annotated according to our framework, encompassing 12 spoken\nand written genres with over 200K tokens. Finally, we discuss automatic\nparsing, evaluation metrics and applications for data in our framework.", "published": "2024-03-20 12:52:38", "link": "http://arxiv.org/abs/2403.13560v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teacher-Student Training for Debiasing: General Permutation Debiasing\n  for Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated impressive zero-shot\ncapabilities and versatility in NLP tasks, however they sometimes fail to\nmaintain crucial invariances for specific tasks. One example is permutation\nsensitivity, where LLMs' outputs may significantly vary depending on the order\nof the input options. While debiasing techniques can mitigate these issues, and\nyield better performance and reliability, they often come with a high\ncomputational cost at inference. This paper addresses this inefficiency at\ninference time. The aim is to distill the capabilities of a computationally\nintensive, debiased, teacher model into a more compact student model. We\nexplore two variants of student models: one based on pure distillation, and the\nother on an error-correction approach for more complex tasks, where the student\ncorrects a single biased decision from the teacher to achieve a debiased\noutput. Our approach is general and can be applied to both black-box and\nwhite-box LLMs. Furthermore, we demonstrate that our compact, encoder-only\nstudent models can outperform their larger, biased teacher counterparts,\nachieving better results with significantly fewer parameters.", "published": "2024-03-20 13:38:07", "link": "http://arxiv.org/abs/2403.13590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Llama meets EU: Investigating the European Political Spectrum through\n  the Lens of LLMs", "abstract": "Instruction-finetuned Large Language Models inherit clear political leanings\nthat have been shown to influence downstream task performance. We expand this\nline of research beyond the two-party system in the US and audit Llama Chat in\nthe context of EU politics in various settings to analyze the model's political\nknowledge and its ability to reason in context. We adapt, i.e., further\nfine-tune, Llama Chat on speeches of individual euro-parties from debates in\nthe European Parliament to reevaluate its political leaning based on the EUandI\nquestionnaire. Llama Chat shows considerable knowledge of national parties'\npositions and is capable of reasoning in context. The adapted, party-specific,\nmodels are substantially re-aligned towards respective positions which we see\nas a starting point for using chat-based LLMs as data-driven conversational\nengines to assist research in political science.", "published": "2024-03-20 13:42:57", "link": "http://arxiv.org/abs/2403.13592v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Not Worry if You Do Not Have Data: Building Pretrained Language\n  Models Using Translationese", "abstract": "In this paper, we explore the utility of Translationese as synthetic data\ncreated using machine translation for pre-training language models (LMs).\nPre-training requires vast amounts of monolingual data, which is mostly\nunavailable for languages other than English. Recently, there has been a\ngrowing interest in using synthetic data to address this data scarcity. We take\nthe case of English and Indic languages and translate web-crawled monolingual\ndocuments (clean) into the target language. Then, we train language models\ncontaining 28M and 85M parameters on this translationese data (synthetic). We\nshow that their performance on downstream natural language understanding and\ngenerative tasks is only 3.56% poorer on NLU tasks and 1.51% on NLG tasks than\nLMs pre-trained on clean data. Further, we propose the use of lightweight\nTinyLMs pre-trained on clean data to filter synthetic data efficiently which\nsignificantly improves the performance of our models. We also find that LMs\ntrained on synthetic data strongly benefit from extended pretraining on a tiny\nfraction (10%) of clean data. We release the data we collected and created as a\npart of this work, IndicMonoDoc, the largest collection of monolingual\ndocument-level corpora, which we hope will help bridge the gap between English\nand non-English performance for large language models.", "published": "2024-03-20 14:41:01", "link": "http://arxiv.org/abs/2403.13638v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounding Spatial Relations in Text-Only Language Models", "abstract": "This paper shows that text-only Language Models (LM) can learn to ground\nspatial relations like \"left of\" or \"below\" if they are provided with explicit\nlocation information of objects and they are properly trained to leverage those\nlocations. We perform experiments on a verbalized version of the Visual Spatial\nReasoning (VSR) dataset, where images are coupled with textual statements which\ncontain real or fake spatial relations between two objects of the image. We\nverbalize the images using an off-the-shelf object detector, adding location\ntokens to every object label to represent their bounding boxes in textual form.\nGiven the small size of VSR, we do not observe any improvement when using\nlocations, but pretraining the LM over a synthetic dataset automatically\nderived by us improves results significantly when using location tokens. We\nthus show that locations allow LMs to ground spatial relations, with our\ntext-only LMs outperforming Vision-and-Language Models and setting the new\nstate-of-the-art for the VSR dataset. Our analysis show that our text-only LMs\ncan generalize beyond the relations seen in the synthetic dataset to some\nextent, learning also more useful information than that encoded in the spatial\nrules we used to create the synthetic dataset itself.", "published": "2024-03-20 15:20:30", "link": "http://arxiv.org/abs/2403.13666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SocialBench: Sociality Evaluation of Role-Playing Conversational Agents", "abstract": "Large language models (LLMs) have advanced the development of various AI\nconversational agents, including role-playing conversational agents that mimic\ndiverse characters and human behaviors. While prior research has predominantly\nfocused on enhancing the conversational capability, role-specific knowledge,\nand stylistic attributes of these agents, there has been a noticeable gap in\nassessing their social intelligence. In this paper, we introduce SocialBench,\nthe first benchmark designed to systematically evaluate the sociality of\nrole-playing conversational agents at both individual and group levels of\nsocial interactions. The benchmark is constructed from a variety of sources and\ncovers a wide range of 500 characters and over 6,000 question prompts and\n30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations\non this benchmark using mainstream open-source and closed-source LLMs. We find\nthat agents excelling in individual level does not imply their proficiency in\ngroup level. Moreover, the behavior of individuals may drift as a result of the\ninfluence exerted by other agents within the group. Experimental results on\nSocialBench confirm its significance as a testbed for assessing the social\ninteraction of role-playing conversational agents. The benchmark is publicly\naccessible at https://github.com/X-PLUG/SocialBench.", "published": "2024-03-20 15:38:36", "link": "http://arxiv.org/abs/2403.13679v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EthioLLM: Multilingual Large Language Models for Ethiopian Languages\n  with Task Evaluation", "abstract": "Large language models (LLMs) have gained popularity recently due to their\noutstanding performance in various downstream Natural Language Processing (NLP)\ntasks. However, low-resource languages are still lagging behind current\nstate-of-the-art (SOTA) developments in the field of NLP due to insufficient\nresources to train LLMs. Ethiopian languages exhibit remarkable linguistic\ndiversity, encompassing a wide array of scripts, and are imbued with profound\nreligious and cultural significance. This paper introduces EthioLLM --\nmultilingual large language models for five Ethiopian languages (Amharic,\nGe'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a\nnew benchmark dataset for various downstream NLP tasks. We evaluate the\nperformance of these models across five downstream NLP tasks. We open-source\nour multilingual language models, new benchmark datasets for various downstream\ntasks, and task-specific fine-tuned language models and discuss the performance\nof the models. Our dataset and models are available at the\nhttps://huggingface.co/EthioNLP repository.", "published": "2024-03-20 16:43:42", "link": "http://arxiv.org/abs/2403.13737v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Different Tokenization Schemes Lead to Comparable Performance in Spanish\n  Number Agreement", "abstract": "The relationship between language model tokenization and performance is an\nopen area of research. Here, we investigate how different tokenization schemes\nimpact number agreement in Spanish plurals. We find that\nmorphologically-aligned tokenization performs similarly to other tokenization\nschemes, even when induced artificially for words that would not be tokenized\nthat way during training. We then present exploratory analyses demonstrating\nthat language model embeddings for different plural tokenizations have similar\ndistributions along the embedding space axis that maximally distinguishes\nsingular and plural nouns. Our results suggest that morphologically-aligned\ntokenization is a viable tokenization approach, and existing models already\ngeneralize some morphological patterns to new items. However, our results\nindicate that morphological tokenization is not strictly required for\nperformance.", "published": "2024-03-20 17:01:56", "link": "http://arxiv.org/abs/2403.13754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Interaction: Enhancing Large Language Models for Psychiatric\n  Behavior Understanding by Dyadic Contexts", "abstract": "Automatic coding patient behaviors is essential to support decision making\nfor psychotherapists during the motivational interviewing (MI), a collaborative\ncommunication intervention approach to address psychiatric issues, such as\nalcohol and drug addiction. While the behavior coding task has rapidly adapted\nmachine learning to predict patient states during the MI sessions, lacking of\ndomain-specific knowledge and overlooking patient-therapist interactions are\nmajor challenges in developing and deploying those models in real practice. To\nencounter those challenges, we introduce the Chain-of-Interaction (CoI)\nprompting method aiming to contextualize large language models (LLMs) for\npsychiatric decision support by the dyadic interactions. The CoI prompting\napproach systematically breaks down the coding task into three key reasoning\nsteps, extract patient engagement, learn therapist question strategies, and\nintegrates dyadic interactions between patients and therapists. This approach\nenables large language models to leverage the coding scheme, patient state, and\ndomain knowledge for patient behavioral coding. Experiments on real-world\ndatasets can prove the effectiveness and flexibility of our prompting method\nwith multiple state-of-the-art LLMs over existing prompting baselines. We have\nconducted extensive ablation analysis and demonstrate the critical role of\ndyadic interactions in applying LLMs for psychotherapy behavior understanding.", "published": "2024-03-20 17:47:49", "link": "http://arxiv.org/abs/2403.13786v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Train & Constrain: Phonologically Informed Tongue-Twister Generation\n  from Topics and Paraphrases", "abstract": "Previous work in phonologically and phonetically grounded language generation\nhas mainly focused on domains such as puns and poetry. In this article, we\npresent new work on the generation of English tongue twisters - a form of\nlanguage that is required to be conditioned on a phoneme level to maximize\nsound overlap, while maintaining semantic consistency with an input topic or\nphrase and still being grammatically correct. We present TwisterLister, a\npipeline for generating phonologically informed tongue twisters from large\nlanguage models (LLMs) that we use to generate TwistList 2.0, the largest\nannotated dataset of tongue twisters to date, consisting of 17K+ examples from\na combination of human and LLM authors. Our generation pipeline involves the\nuse of a phonologically constrained vocabulary alongside LLM prompting to\ngenerate novel, non-derivative tongue twister examples. We additionally present\nthe results of automatic and human evaluation of smaller models trained on our\ngenerated dataset to demonstrate the extent to which phonologically motivated\nlanguage types can be generated without explicit injection of phonological\nknowledge. Additionally, we introduce a phoneme-aware constrained decoding\nmodule (PACD) that can be integrated into an autoregressive language model and\ndemonstrate that this method generates good quality tongue twisters both with\nand without fine-tuning the underlying language model. We also design and\nimplement a range of automatic metrics for the task of tongue twister\ngeneration that is phonologically motivated and captures the unique essence of\ntongue twisters, primarily based on phonemic edit distance (PED)", "published": "2024-03-20 18:13:17", "link": "http://arxiv.org/abs/2403.13901v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Linguistically Enhanced Embeddings for Open Information\n  Extraction", "abstract": "Open Information Extraction (OIE) is a structured prediction (SP) task in\nNatural Language Processing (NLP) that aims to extract structured $n$-ary\ntuples - usually subject-relation-object triples - from free text. The word\nembeddings in the input text can be enhanced with linguistic features, usually\nPart-of-Speech (PoS) and Syntactic Dependency Parse (SynDP) labels. However,\npast enhancement techniques cannot leverage the power of pretrained language\nmodels (PLMs), which themselves have been hardly used for OIE. To bridge this\ngap, we are the first to leverage linguistic features with a Seq2Seq PLM for\nOIE. We do so by introducing two methods - Weighted Addition and Linearized\nConcatenation. Our work can give any neural OIE architecture the key\nperformance boost from both PLMs and linguistic features in one go. In our\nsettings, this shows wide improvements of up to 24.9%, 27.3% and 14.9% on\nPrecision, Recall and F1 scores respectively over the baseline. Beyond this, we\naddress other important challenges in the field: to reduce compute overheads\nwith the features, we are the first ones to exploit Semantic Dependency Parse\n(SemDP) tags; to address flaws in current datasets, we create a clean synthetic\ndataset; finally, we contribute the first known study of OIE behaviour in SP\nmodels.", "published": "2024-03-20 18:18:48", "link": "http://arxiv.org/abs/2403.13903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Unsupervised Dimensionality Reduction Methods for Pretrained\n  Sentence Embeddings", "abstract": "Sentence embeddings produced by Pretrained Language Models (PLMs) have\nreceived wide attention from the NLP community due to their superior\nperformance when representing texts in numerous downstream applications.\nHowever, the high dimensionality of the sentence embeddings produced by PLMs is\nproblematic when representing large numbers of sentences in memory- or\ncompute-constrained devices. As a solution, we evaluate unsupervised\ndimensionality reduction methods to reduce the dimensionality of sentence\nembeddings produced by PLMs. Our experimental results show that simple methods\nsuch as Principal Component Analysis (PCA) can reduce the dimensionality of\nsentence embeddings by almost $50\\%$, without incurring a significant loss in\nperformance in multiple downstream tasks. Surprisingly, reducing the\ndimensionality further improves performance over the original high-dimensional\nversions for the sentence embeddings produced by some PLMs in some tasks.", "published": "2024-03-20 21:58:32", "link": "http://arxiv.org/abs/2403.14001v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Massive Multilingual Dataset for High-Performance Language\n  Technologies", "abstract": "We present the HPLT (High Performance Language Technologies) language\nresources, a new massive multilingual dataset including both monolingual and\nbilingual corpora extracted from CommonCrawl and previously unused web crawls\nfrom the Internet Archive. We describe our methods for data acquisition,\nmanagement and processing of large corpora, which rely on open-source software\ntools and high-performance computing. Our monolingual collection focuses on\nlow- to medium-resourced languages and covers 75 languages and a total of ~5.6\ntrillion word tokens de-duplicated on the document level. Our English-centric\nparallel corpus is derived from its monolingual counterpart and covers 18\nlanguage pairs and more than 96 million aligned sentence pairs with roughly 1.4\nbillion English tokens. The HPLT language resources are one of the largest open\ntext corpora ever released, providing a great resource for language modeling\nand machine translation training. We publicly release the corpora, the\nsoftware, and the tools used in this work.", "published": "2024-03-20 22:14:39", "link": "http://arxiv.org/abs/2403.14009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't be a Fool: Pooling Strategies in Offensive Language Detection from\n  User-Intended Adversarial Attacks", "abstract": "Offensive language detection is an important task for filtering out abusive\nexpressions and improving online user experiences. However, malicious users\noften attempt to avoid filtering systems through the involvement of textual\nnoises. In this paper, we propose these evasions as user-intended adversarial\nattacks that insert special symbols or leverage the distinctive features of the\nKorean language. Furthermore, we introduce simple yet effective pooling\nstrategies in a layer-wise manner to defend against the proposed attacks,\nfocusing on the preceding layers not just the last layer to capture both\noffensiveness and token embeddings. We demonstrate that these pooling\nstrategies are more robust to performance degradation even when the attack rate\nis increased, without directly training of such patterns. Notably, we found\nthat models pre-trained on clean texts could achieve a comparable performance\nin detecting attacked offensive language, to models pre-trained on noisy texts\nby employing these pooling strategies.", "published": "2024-03-20 06:28:09", "link": "http://arxiv.org/abs/2403.15467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vi-Mistral-X: Building a Vietnamese Language Model with Advanced\n  Continual Pre-training", "abstract": "The advancement of Large Language Models (LLMs) has significantly transformed\nthe field of natural language processing, although the focus on English-centric\nmodels has created a noticeable research gap for specific languages, including\nVietnamese. To address this issue, this paper presents vi-mistral-x, an\ninnovative Large Language Model designed expressly for the Vietnamese language.\nIt utilizes a unique method of continual pre-training, based on the Mistral\narchitecture, which incorporates grouped-query attention and sliding window\nattention techniques. This model, vi-Mistral-X, marks a significant step\nforward in improving the understanding and generation of the Vietnamese\nlanguage. It introduces an additional phase of continual pre-training,\nspecifically adapted for Vietnamese, enhancing the model's capability in\nunderstanding complex language nuances and generating accurate, context-aware\nVietnamese text. Through comprehensive testing on various benchmarks,\nvi-mistral-x has shown to outperform existing Vietnamese LLMs in several key\nareas, including text classification, question answering, and text generation.\nParticularly, in the Vietnamese Multitask Language Understanding (VMLU)\nbenchmark, vi-mistral-x sets a new standard, outperforming other available\nmodels significantly. This paper highlights the critical role of continual\npre-training in advancing language-specific LLMs and opens new avenues for the\ndevelopment of multilingual models. We aim for vi-mistral-x to not just be an\nimportant asset for processing the Vietnamese language but also to encourage\nmore advancements in creating large language models for languages that are less\nrepresented.", "published": "2024-03-20 10:14:13", "link": "http://arxiv.org/abs/2403.15470v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient argument classification with compact language models and\n  ChatGPT-4 refinements", "abstract": "Argument mining (AM) is defined as the task of automatically identifying and\nextracting argumentative components (e.g. premises, claims, etc.) and detecting\nthe existing relations among them (i.e., support, attack, no relations). Deep\nlearning models enable us to analyze arguments more efficiently than\ntraditional methods and extract their semantics. This paper presents\ncomparative studies between a few deep learning-based models in argument\nmining. The work concentrates on argument classification. The research was done\non a wide spectrum of datasets (Args.me, UKP, US2016). The main novelty of this\npaper is the ensemble model which is based on BERT architecture and ChatGPT-4\nas fine tuning model. The presented results show that BERT+ChatGPT-4\noutperforms the rest of the models including other Transformer-based and\nLSTM-based models. The observed improvement is, in most cases, greater than\n10The presented analysis can provide crucial insights into how the models for\nargument classification should be further improved. Additionally, it can help\ndevelop a prompt-based algorithm to eliminate argument classification errors.", "published": "2024-03-20 16:24:10", "link": "http://arxiv.org/abs/2403.15473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Supervised Extractive and Generative Language Models for\n  Suicide Risk Evidence Summarization", "abstract": "We propose a method that integrates supervised extractive and generative\nlanguage models for providing supporting evidence of suicide risk in the\nCLPsych 2024 shared task. Our approach comprises three steps. Initially, we\nconstruct a BERT-based model for estimating sentence-level suicide risk and\nnegative sentiment. Next, we precisely identify high suicide risk sentences by\nemphasizing elevated probabilities of both suicide risk and negative sentiment.\nFinally, we integrate generative summaries using the MentaLLaMa framework and\nextractive summaries from identified high suicide risk sentences and a\nspecialized dictionary of suicidal risk words. SophiaADS, our team, achieved\n1st place for highlight extraction and ranked 10th for summary generation, both\nbased on recall and consistency metrics, respectively.", "published": "2024-03-20 21:16:10", "link": "http://arxiv.org/abs/2403.15478v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction Multi-Constraint Molecular Generation Using a\n  Teacher-Student Large Language Model", "abstract": "While various models and computational tools have been proposed for structure\nand property analysis of molecules, generating molecules that conform to all\ndesired structures and properties remains a challenge. Here, we introduce a\nmulti-constraint molecular generation large language model, TSMMG, which, akin\nto a student, incorporates knowledge from various small models and tools,\nnamely, the 'teachers'. To train TSMMG, we construct a large set of\ntext-molecule pairs by extracting molecular knowledge from these 'teachers',\nenabling it to generate novel molecules that conform to the descriptions\nthrough various text prompts. We experimentally show that TSMMG remarkably\nperforms in generating molecules meeting complex, natural language-described\nproperty requirements across two-, three-, and four-constraint tasks, with an\naverage molecular validity of over 99% and success ratio of 82.58%, 68.03%, and\n67.48%, respectively. The model also exhibits adaptability through zero-shot\ntesting, creating molecules that satisfy combinations of properties that have\nnot been encountered. It can comprehend text inputs with various language\nstyles, extending beyond the confines of outlined prompts, as confirmed through\nempirical validation. Additionally, the knowledge distillation feature of TSMMG\ncontributes to the continuous enhancement of small models, while the innovative\napproach to dataset construction effectively addresses the issues of data\nscarcity and quality, which positions TSMMG as a promising tool in the domains\nof drug discovery and materials science.", "published": "2024-03-20 02:15:55", "link": "http://arxiv.org/abs/2403.13244v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Document Author Classification Using Parsed Language Structure", "abstract": "Over the years there has been ongoing interest in detecting authorship of a\ntext based on statistical properties of the text, such as by using occurrence\nrates of noncontextual words. In previous work, these techniques have been\nused, for example, to determine authorship of all of \\emph{The Federalist\nPapers}. Such methods may be useful in more modern times to detect fake or AI\nauthorship. Progress in statistical natural language parsers introduces the\npossibility of using grammatical structure to detect authorship. In this paper\nwe explore a new possibility for detecting authorship using grammatical\nstructural information extracted using a statistical natural language parser.\nThis paper provides a proof of concept, testing author classification based on\ngrammatical structure on a set of \"proof texts,\" The Federalist Papers and\nSanditon which have been as test cases in previous authorship detection\nstudies. Several features extracted from the statistical natural language\nparser were explored: all subtrees of some depth from any level; rooted\nsubtrees of some depth, part of speech, and part of speech by level in the\nparse tree. It was found to be helpful to project the features into a lower\ndimensional space. Statistical experiments on these documents demonstrate that\ninformation from a statistical parser can, in fact, assist in distinguishing\nauthors.", "published": "2024-03-20 02:32:24", "link": "http://arxiv.org/abs/2403.13253v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Reading Users' Minds from What They Say: An Investigation into LLM-based\n  Empathic Mental Inference", "abstract": "In human-centered design, developing a comprehensive and in-depth\nunderstanding of user experiences, i.e., empathic understanding, is paramount\nfor designing products that truly meet human needs. Nevertheless, accurately\ncomprehending the real underlying mental states of a large human population\nremains a significant challenge today. This difficulty mainly arises from the\ntrade-off between depth and scale of user experience research: gaining in-depth\ninsights from a small group of users does not easily scale to a larger\npopulation, and vice versa. This paper investigates the use of Large Language\nModels (LLMs) for performing mental inference tasks, specifically inferring\nusers' underlying goals and fundamental psychological needs (FPNs). Baseline\nand benchmark datasets were collected from human users and designers to develop\nan empathic accuracy metric for measuring the mental inference performance of\nLLMs. The empathic accuracy of inferring goals and FPNs of different LLMs with\nvaried zero-shot prompt engineering techniques are experimented against that of\nhuman designers. Experimental results suggest that LLMs can infer and\nunderstand the underlying goals and FPNs of users with performance comparable\nto that of human designers, suggesting a promising avenue for enhancing the\nscalability of empathic design approaches through the integration of advanced\nartificial intelligence technologies. This work has the potential to\nsignificantly augment the toolkit available to designers during human-centered\ndesign, enabling the development of both large-scale and in-depth understanding\nof users' experiences.", "published": "2024-03-20 04:57:32", "link": "http://arxiv.org/abs/2403.13301v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Polaris: A Safety-focused LLM Constellation Architecture for Healthcare", "abstract": "We develop Polaris, the first safety-focused LLM constellation for real-time\npatient-AI healthcare conversations. Unlike prior LLM works in healthcare\nfocusing on tasks like question answering, our work specifically focuses on\nlong multi-turn voice conversations. Our one-trillion parameter constellation\nsystem is composed of several multibillion parameter LLMs as co-operative\nagents: a stateful primary agent that focuses on driving an engaging\nconversation and several specialist support agents focused on healthcare tasks\nperformed by nurses to increase safety and reduce hallucinations. We develop a\nsophisticated training protocol for iterative co-training of the agents that\noptimize for diverse objectives. We train our models on proprietary data,\nclinical care plans, healthcare regulatory documents, medical manuals, and\nother medical reasoning documents. We align our models to speak like medical\nprofessionals, using organic healthcare conversations and simulated ones\nbetween patient actors and experienced nurses. This allows our system to\nexpress unique capabilities such as rapport building, trust building, empathy\nand bedside manner. Finally, we present the first comprehensive clinician\nevaluation of an LLM system for healthcare. We recruited over 1100 U.S.\nlicensed nurses and over 130 U.S. licensed physicians to perform end-to-end\nconversational evaluations of our system by posing as patients and rating the\nsystem on several measures. We demonstrate Polaris performs on par with human\nnurses on aggregate across dimensions such as medical safety, clinical\nreadiness, conversational quality, and bedside manner. Additionally, we conduct\na challenging task-based evaluation of the individual specialist support\nagents, where we demonstrate our LLM agents significantly outperform a much\nlarger general-purpose LLM (GPT-4) as well as from its own medium-size class\n(LLaMA-2 70B).", "published": "2024-03-20 05:34:03", "link": "http://arxiv.org/abs/2403.13313v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hyacinth6B: A large language model for Traditional Chinese", "abstract": "This research's primary motivation of this study is to address the high\nhardware and computational demands typically associated with LLMs.Therefore,our\ngoal is to find a balance between model lightness and performance,striving to\nmaximize performance while using a comparatively lightweight model. Hyacinth6B\nwas developed with this objective in mind,aiming to fully leverage the core\ncapabilities of LLMs without incurring substantial resource costs, effectively\npushing the boundaries of smaller model's performance. The training approach\ninvolves parameter efficient finetuning using the LoRA method.", "published": "2024-03-20 06:37:59", "link": "http://arxiv.org/abs/2403.13334v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Computational Models to Study Language Processing in the Human Brain: A\n  Survey", "abstract": "Despite differing from the human language processing mechanism in\nimplementation and algorithms, current language models demonstrate remarkable\nhuman-like or surpassing language capabilities. Should computational language\nmodels be employed in studying the brain, and if so, when and how? To delve\ninto this topic, this paper reviews efforts in using computational models for\nbrain research, highlighting emerging trends. To ensure a fair comparison, the\npaper evaluates various computational models using consistent metrics on the\nsame dataset. Our analysis reveals that no single model outperforms others on\nall datasets, underscoring the need for rich testing datasets and rigid\nexperimental control to draw robust conclusions in studies involving\ncomputational models.", "published": "2024-03-20 08:01:22", "link": "http://arxiv.org/abs/2403.13368v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models", "abstract": "Efficient fine-tuning is vital for adapting large language models (LLMs) to\ndownstream tasks. However, it requires non-trivial efforts to implement these\nmethods on different models. We present LlamaFactory, a unified framework that\nintegrates a suite of cutting-edge efficient training methods. It provides a\nsolution for flexibly customizing the fine-tuning of 100+ LLMs without the need\nfor coding through the built-in web UI LlamaBoard. We empirically validate the\nefficiency and effectiveness of our framework on language modeling and text\ngeneration tasks. It has been released at\nhttps://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and\n3,000 forks.", "published": "2024-03-20 08:08:54", "link": "http://arxiv.org/abs/2403.13372v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Gender Interacts with Political Values: A Case Study on Czech BERT\n  Models", "abstract": "Neural language models, which reach state-of-the-art results on most natural\nlanguage processing tasks, are trained on large text corpora that inevitably\ncontain value-burdened content and often capture undesirable biases, which the\nmodels reflect. This case study focuses on the political biases of pre-trained\nencoders in Czech and compares them with a representative value survey. Because\nCzech is a gendered language, we also measure how the grammatical gender\ncoincides with responses to men and women in the survey. We introduce a novel\nmethod for measuring the model's perceived political values. We find that the\nmodels do not assign statement probability following value-driven reasoning,\nand there is no systematic difference between feminine and masculine sentences.\nWe conclude that BERT-sized models do not manifest systematic alignment with\npolitical values and that the biases observed in the models are rather due to\nsuperficial imitation of training data patterns than systematic value beliefs\nencoded in the models.", "published": "2024-03-20 11:30:45", "link": "http://arxiv.org/abs/2403.13514v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Dynamic Reward Adjustment in Multi-Reward Reinforcement Learning for\n  Counselor Reflection Generation", "abstract": "In this paper, we study the problem of multi-reward reinforcement learning to\njointly optimize for multiple text qualities for natural language generation.\nWe focus on the task of counselor reflection generation, where we optimize the\ngenerators to simultaneously improve the fluency, coherence, and reflection\nquality of generated counselor responses. We introduce two novel bandit\nmethods, DynaOpt and C-DynaOpt, which rely on the broad strategy of combining\nrewards into a single value and optimizing them simultaneously. Specifically,\nwe employ non-contextual and contextual multi-arm bandits to dynamically adjust\nmultiple reward weights during training. Through automatic and manual\nevaluations, we show that our proposed techniques, DynaOpt and C-DynaOpt,\noutperform existing naive and bandit baselines, showcasing their potential for\nenhancing language models.", "published": "2024-03-20 13:24:41", "link": "http://arxiv.org/abs/2403.13578v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language\n  Models", "abstract": "As Pre-trained Language Models (PLMs), a popular approach for code\nintelligence, continue to grow in size, the computational cost of their usage\nhas become prohibitively expensive. Prompt learning, a recent development in\nthe field of natural language processing, emerges as a potential solution to\naddress this challenge. In this paper, we investigate the effectiveness of\nprompt learning in code intelligence tasks. We unveil its reliance on manually\ndesigned prompts, which often require significant human effort and expertise.\nMoreover, we discover existing automatic prompt design methods are very limited\nto code intelligence tasks due to factors including gradient dependence, high\ncomputational demands, and limited applicability. To effectively address both\nissues, we propose Genetic Auto Prompt (GenAP), which utilizes an elaborate\ngenetic algorithm to automatically design prompts. With GenAP, non-experts can\neffortlessly generate superior prompts compared to meticulously manual-designed\nones. GenAP operates without the need for gradients or additional computational\ncosts, rendering it gradient-free and cost-effective. Moreover, GenAP supports\nboth understanding and generation types of code intelligence tasks, exhibiting\ngreat applicability. We conduct GenAP on three popular code intelligence PLMs\nwith three canonical code intelligence tasks including defect prediction, code\nsummarization, and code translation. The results suggest that GenAP can\neffectively automate the process of designing prompts. Specifically, GenAP\noutperforms all other methods across all three tasks (e.g., improving accuracy\nby an average of 2.13% for defect prediction). To the best of our knowledge,\nGenAP is the first work to automatically design prompts for code intelligence\nPLMs.", "published": "2024-03-20 13:37:00", "link": "http://arxiv.org/abs/2403.13588v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Information-Theoretic Distillation for Reference-less Summarization", "abstract": "The current winning recipe for automatic summarization is using proprietary\nlarge-scale language models (LLMs) such as ChatGPT as is, or imitation learning\nfrom them as teacher models. While increasingly ubiquitous dependence on such\nlarge-scale language models is convenient, there remains an important question\nof whether small-scale models could have achieved competitive results, if we\nwere to seek an alternative learning method -- that allows for a more\ncost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a\nnovel framework to distill a powerful summarizer based on the\ninformation-theoretic objective for summarization, without relying on either\nthe LLM's capability or human-written references. To achieve this, we first\npropose a novel formulation of the desiderata of summarization (saliency,\nfaithfulness and brevity) through the lens of mutual information between the\noriginal document and the summary. Based on this formulation, we start off from\nPythia-2.8B as the teacher model, which is not yet capable of summarization,\nthen self-train the model to optimize for the information-centric measures of\nideal summaries. Distilling from the improved teacher, we arrive at a compact\nbut powerful summarizer with only 568M parameters that performs competitively\nagainst ChatGPT, without ever relying on ChatGPT's capabilities. Extensive\nanalysis demonstrates that our approach outperforms in-domain supervised models\nin human evaluation, let alone state-of-the-art unsupervised methods, and wins\nover ChatGPT in controllable summarization.", "published": "2024-03-20 17:42:08", "link": "http://arxiv.org/abs/2403.13780v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reverse Training to Nurse the Reversal Curse", "abstract": "Large language models (LLMs) have a surprising failure: when trained on \"A\nhas a feature B\", they do not generalize to \"B is a feature of A\", which is\ntermed the Reversal Curse. Even when training with trillions of tokens this\nissue still appears due to Zipf's law - hence even if we train on the entire\ninternet. This work proposes an alternative training scheme, called reverse\ntraining, whereby all words are used twice, doubling the amount of available\ntokens. The LLM is trained in both forward and reverse directions by reversing\nthe training strings while preserving (i.e., not reversing) chosen substrings,\nsuch as entities. We show that data-matched reverse-trained models provide\nsuperior performance to standard models on standard tasks, and compute-matched\nreverse-trained models provide far superior performance on reversal tasks,\nhelping resolve the reversal curse issue.", "published": "2024-03-20 17:55:35", "link": "http://arxiv.org/abs/2403.13799v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visually Grounded Speech Models have a Mutual Exclusivity Bias", "abstract": "When children learn new words, they employ constraints such as the mutual\nexclusivity (ME) bias: a novel word is mapped to a novel object rather than a\nfamiliar one. This bias has been studied computationally, but only in models\nthat use discrete word representations as input, ignoring the high variability\nof spoken words. We investigate the ME bias in the context of visually grounded\nspeech models that learn from natural images and continuous speech audio.\nConcretely, we train a model on familiar words and test its ME bias by asking\nit to select between a novel and a familiar object when queried with a novel\nword. To simulate prior acoustic and visual knowledge, we experiment with\nseveral initialisation strategies using pretrained speech and vision networks.\nOur findings reveal the ME bias across the different initialisation approaches,\nwith a stronger bias in models with more prior (in particular, visual)\nknowledge. Additional tests confirm the robustness of our results, even when\ndifferent loss functions are considered.", "published": "2024-03-20 18:49:59", "link": "http://arxiv.org/abs/2403.13922v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "On Prompt Sensitivity of ChatGPT in Affective Computing", "abstract": "Recent studies have demonstrated the emerging capabilities of foundation\nmodels like ChatGPT in several fields, including affective computing. However,\naccessing these emerging capabilities is facilitated through prompt\nengineering. Despite the existence of some prompting techniques, the field is\nstill rapidly evolving and many prompting ideas still require investigation. In\nthis work, we introduce a method to evaluate and investigate the sensitivity of\nthe performance of foundation models based on different prompts or generation\nparameters. We perform our evaluation on ChatGPT within the scope of affective\ncomputing on three major problems, namely sentiment analysis, toxicity\ndetection, and sarcasm detection. First, we carry out a sensitivity analysis on\npivotal parameters in auto-regressive text generation, specifically the\ntemperature parameter $T$ and the top-$p$ parameter in Nucleus sampling,\ndictating how conservative or creative the model should be during generation.\nFurthermore, we explore the efficacy of several prompting ideas, where we\nexplore how giving different incentives or structures affect the performance.\nOur evaluation takes into consideration performance measures on the affective\ncomputing tasks, and the effectiveness of the model to follow the stated\ninstructions, hence generating easy-to-parse responses to be smoothly used in\ndownstream applications.", "published": "2024-03-20 22:11:01", "link": "http://arxiv.org/abs/2403.14006v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection", "abstract": "Misinformation can seriously impact society, affecting anything from public\nopinion to institutional confidence and the political horizon of a state. Fake\nNews (FN) proliferation on online websites and Online Social Networks (OSNs)\nhas increased profusely. Various fact-checking websites include news in English\nand barely provide information about FN in regional languages. Thus the Urdu FN\npurveyors cannot be discerned using factchecking portals. SOTA approaches for\nFake News Detection (FND) count upon appropriately labelled and large datasets.\nFND in regional and resource-constrained languages lags due to the lack of\nlimited-sized datasets and legitimate lexical resources. The previous datasets\nfor Urdu FND are limited-sized, domain-restricted, publicly unavailable and not\nmanually verified where the news is translated from English into Urdu. In this\npaper, we curate and contribute the first largest publicly available dataset\nfor Urdu FND, Ax-to-Grind Urdu, to bridge the identified gaps and limitations\nof existing Urdu datasets in the literature. It constitutes 10,083 fake and\nreal news on fifteen domains collected from leading and authentic Urdu\nnewspapers and news channel websites in Pakistan and India. FN for the\nAx-to-Grind dataset is collected from websites and crowdsourcing. The dataset\ncontains news items in Urdu from the year 2017 to the year 2023. Expert\njournalists annotated the dataset. We benchmark the dataset with an ensemble\nmodel of mBERT,XLNet, and XLM RoBERTa. The selected models are originally\ntrained on multilingual large corpora. The results of the proposed model are\nbased on performance metrics, F1-score, accuracy, precision, recall and MCC\nvalue.", "published": "2024-03-20 23:21:35", "link": "http://arxiv.org/abs/2403.14037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Representational Harms to Quality-of-Service Harms: A Case Study on\n  Llama 2 Safety Safeguards", "abstract": "Recent progress in large language models (LLMs) has led to their widespread\nadoption in various domains. However, these advancements have also introduced\nadditional safety risks and raised concerns regarding their detrimental impact\non already marginalized populations. Despite growing mitigation efforts to\ndevelop safety safeguards, such as supervised safety-oriented fine-tuning and\nleveraging safe reinforcement learning from human feedback, multiple concerns\nregarding the safety and ingrained biases in these models remain. Furthermore,\nprevious work has demonstrated that models optimized for safety often display\nexaggerated safety behaviors, such as a tendency to refrain from responding to\ncertain requests as a precautionary measure. As such, a clear trade-off between\nthe helpfulness and safety of these models has been documented in the\nliterature. In this paper, we further investigate the effectiveness of safety\nmeasures by evaluating models on already mitigated biases. Using the case of\nLlama 2 as an example, we illustrate how LLMs' safety responses can still\nencode harmful assumptions. To do so, we create a set of non-toxic prompts,\nwhich we then use to evaluate Llama models. Through our new taxonomy of LLMs\nresponses to users, we observe that the safety/helpfulness trade-offs are more\npronounced for certain demographic groups which can lead to quality-of-service\nharms for marginalized populations.", "published": "2024-03-20 00:22:38", "link": "http://arxiv.org/abs/2403.13213v4", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Arcee's MergeKit: A Toolkit for Merging Large Language Models", "abstract": "The rapid expansion of the open-source language model landscape presents an\nopportunity to merge the competencies of these model checkpoints by combining\ntheir parameters. Advances in transfer learning, the process of fine-tuning\npretrained models for specific tasks, has resulted in the development of vast\namounts of task-specific models, typically specialized in individual tasks and\nunable to utilize each other's strengths. Model merging facilitates the\ncreation of multitask models without the need for additional training, offering\na promising avenue for enhancing model performance and versatility. By\npreserving the intrinsic capabilities of the original models, model merging\naddresses complex challenges in AI - including the difficulties of catastrophic\nforgetting and multitask learning. To support this expanding area of research,\nwe introduce MergeKit, a comprehensive, open-source library designed to\nfacilitate the application of model merging strategies. MergeKit offers an\nextensible framework to efficiently merge models on any hardware, providing\nutility to researchers and practitioners. To date, thousands of models have\nbeen merged by the open-source community, leading to the creation of some of\nthe worlds most powerful open-source model checkpoints, as assessed by the Open\nLLM Leaderboard. The library is accessible at\nhttps://github.com/arcee-ai/MergeKit.", "published": "2024-03-20 02:38:01", "link": "http://arxiv.org/abs/2403.13257v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient\n  Fine-Tuning of Large Models", "abstract": "We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as\nAdaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each\npre-trained frozen weight tensor, we add a parallel path of trainable low-rank\nmatrices, namely a down-projection and an up-projection matrix, each of which\nis followed by a feature transformation vector. Based on a novel freezing\nscore, we the incrementally freeze these projection matrices during fine-tuning\nto reduce the computation and alleviate over-fitting. Our experimental results\ndemonstrate that we can achieve state-of-the-art performance with an average\nimprovement of up to $0.85\\%$ as evaluated on GLUE benchmark while yeilding up\nto $9.5\\times$ fewer average trainable parameters. While compared in terms of\nruntime, AFLoRA can yield up to $1.86\\times$ improvement as opposed to similar\nPEFT alternatives. Besides the practical utility of our approach, we provide\ninsights on the trainability requirements of LoRA paths at different modules\nand the freezing schedule for the different projection matrices. Code will be\nreleased.", "published": "2024-03-20 03:07:50", "link": "http://arxiv.org/abs/2403.13269v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Community Needs and Assets: A Computational Analysis of Community\n  Conversations", "abstract": "A community needs assessment is a tool used by non-profits and government\nagencies to quantify the strengths and issues of a community, allowing them to\nallocate their resources better. Such approaches are transitioning towards\nleveraging social media conversations to analyze the needs of communities and\nthe assets already present within them. However, manual analysis of\nexponentially increasing social media conversations is challenging. There is a\ngap in the present literature in computationally analyzing how community\nmembers discuss the strengths and needs of the community. To address this gap,\nwe introduce the task of identifying, extracting, and categorizing community\nneeds and assets from conversational data using sophisticated natural language\nprocessing methods. To facilitate this task, we introduce the first dataset\nabout community needs and assets consisting of 3,511 conversations from Reddit,\nannotated using crowdsourced workers. Using this dataset, we evaluate an\nutterance-level classification model compared to sentiment classification and a\npopular large language model (in a zero-shot setting), where we find that our\nmodel outperforms both baselines at an F1 score of 94% compared to 49% and 61%\nrespectively. Furthermore, we observe through our study that conversations\nabout needs have negative sentiments and emotions, while conversations about\nassets focus on location and entities. The dataset is available at\nhttps://github.com/towhidabsar/CommunityNeeds.", "published": "2024-03-20 03:14:54", "link": "http://arxiv.org/abs/2403.13272v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Incentivizing News Consumption on Social Media Platforms Using Large\n  Language Models and Realistic Bot Accounts", "abstract": "Polarization, declining trust, and wavering support for democratic norms are\npressing threats to U.S. democracy. Exposure to verified and quality news may\nlower individual susceptibility to these threats and make citizens more\nresilient to misinformation, populism, and hyperpartisan rhetoric. This project\nexamines how to enhance users' exposure to and engagement with verified and\nideologically balanced news in an ecologically valid setting. We rely on a\nlarge-scale two-week long field experiment (from 1/19/2023 to 2/3/2023) on\n28,457 Twitter users. We created 28 bots utilizing GPT-2 that replied to users\ntweeting about sports, entertainment, or lifestyle with a contextual reply\ncontaining two hardcoded elements: a URL to the topic-relevant section of\nquality news organization and an encouragement to follow its Twitter account.\nTo further test differential effects by gender of the bots, treated users were\nrandomly assigned to receive responses by bots presented as female or male. We\nexamine whether our over-time intervention enhances the following of news media\norganization, the sharing and the liking of news content and the tweeting about\npolitics and the liking of political content. We find that the treated users\nfollowed more news accounts and the users in the female bot treatment were more\nlikely to like news content than the control. Most of these results, however,\nwere small in magnitude and confined to the already politically interested\nTwitter users, as indicated by their pre-treatment tweeting about politics.\nThese findings have implications for social media and news organizations, and\nalso offer direction for future work on how Large Language Models and other\ncomputational interventions can effectively enhance individual on-platform\nengagement with quality news and public affairs.", "published": "2024-03-20 07:44:06", "link": "http://arxiv.org/abs/2403.13362v3", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Clinical information extraction for Low-resource languages with Few-shot\n  learning using Pre-trained language models and Prompting", "abstract": "Automatic extraction of medical information from clinical documents poses\nseveral challenges: high costs of required clinical expertise, limited\ninterpretability of model predictions, restricted computational resources and\nprivacy regulations. Recent advances in domain-adaptation and prompting methods\nshowed promising results with minimal training data using lightweight masked\nlanguage models, which are suited for well-established interpretability\nmethods. We are first to present a systematic evaluation of these methods in a\nlow-resource setting, by performing multi-class section classification on\nGerman doctor's letters. We conduct extensive class-wise evaluations supported\nby Shapley values, to validate the quality of our small training data set and\nto ensure the interpretability of model predictions. We demonstrate that a\nlightweight, domain-adapted pretrained model, prompted with just 20 shots,\noutperforms a traditional classification model by 30.5% accuracy. Our results\nserve as a process-oriented guideline for clinical information extraction\nprojects working with low-resource.", "published": "2024-03-20 08:01:33", "link": "http://arxiv.org/abs/2403.13369v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting\n  Emergent Behavior", "abstract": "Language significantly influences the formation and evolution of Human\nemergent behavior, which is crucial in understanding collective intelligence\nwithin human societies. Considering that the study of how language affects\nhuman behavior needs to put it into the dynamic scenarios in which it is used,\nwe introduce AgentGroupChat in this paper, a simulation that delves into the\ncomplex role of language in shaping collective behavior through interactive\ndebate scenarios. Central to this simulation are characters engaging in dynamic\nconversation interactions. To enable simulation, we introduce the Verbal\nStrategist Agent, utilizing large language models to enhance interaction\nstrategies by incorporating elements of persona and action. We set four\nnarrative scenarios based on AgentGroupChat to demonstrate the simulation's\ncapacity to mimic complex language use in group dynamics. Evaluations focus on\naligning agent behaviors with human expectations and the emergence of\ncollective behaviors within the simulation. Results reveal that emergent\nbehaviors materialize from a confluence of factors: a conducive environment for\nextensive information exchange, characters with diverse traits, high linguistic\ncomprehension, and strategic adaptability. During discussions on ``the impact\nof AI on humanity'' in AgentGroupChat simulation, philosophers commonly agreed\nthat ``AI could enhance societal welfare with judicious limitations'' and even\ncome to a conclusion that ``the essence of true intelligence encompasses\nunderstanding the necessity to constrain self abilities''. Additionally, in the\ncompetitive domain of casting for primary roles in films in AgentGroupChat,\ncertain actors were ready to reduce their remuneration or accept lesser roles,\nmotivated by their deep-seated desire to contribute to the project.", "published": "2024-03-20 09:21:32", "link": "http://arxiv.org/abs/2403.13433v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal\n  Large Language Models", "abstract": "Recent advancements indicate that scaling up Multimodal Large Language Models\n(MLLMs) effectively enhances performance on downstream multimodal tasks. The\nprevailing MLLM paradigm, \\emph{e.g.}, LLaVA, transforms visual features into\ntext-like tokens using a \\emph{static} vision-language mapper, thereby enabling\n\\emph{static} LLMs to develop the capability to comprehend visual information\nthrough visual instruction tuning. Although promising, the \\emph{static} tuning\nstrategy~\\footnote{The static tuning refers to the trained model with static\nparameters.} that shares the same parameters may constrain performance across\ndifferent downstream multimodal tasks. In light of this, we introduce\nHyperLLaVA, which involves adaptive tuning of the projector and LLM parameters,\nin conjunction with a dynamic visual expert and language expert, respectively.\nThese experts are derived from HyperNetworks, which generates adaptive\nparameter shifts through visual and language guidance, enabling dynamic\nprojector and LLM modeling in two-stage training.\n  Our experiments demonstrate that our solution significantly surpasses LLaVA\non existing MLLM benchmarks, including MME, MMBench, SEED-Bench, and\nLLaVA-Bench. ~\\footnote{Our project is available on the link\nhttps://github.com/DCDmllm/HyperLLaVA}.", "published": "2024-03-20 09:42:43", "link": "http://arxiv.org/abs/2403.13447v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "What if...?: Thinking Counterfactual Keywords Helps to Mitigate\n  Hallucination in Large Multi-modal Models", "abstract": "This paper presents a way of enhancing the reliability of Large Multi-modal\nModels (LMMs) in addressing hallucination, where the models generate\ncross-modal inconsistent responses. Without additional training, we propose\nCounterfactual Inception, a novel method that implants counterfactual thinking\ninto LMMs using self-generated counterfactual keywords. Our method is grounded\nin the concept of counterfactual thinking, a cognitive process where human\nconsiders alternative realities, enabling more extensive context exploration.\nBridging the human cognition mechanism into LMMs, we aim for the models to\nengage with and generate responses that span a wider contextual scene\nunderstanding, mitigating hallucinatory outputs. We further introduce\nPlausibility Verification Process (PVP), a simple yet robust keyword constraint\nthat effectively filters out sub-optimal keywords to enable the consistent\ntriggering of counterfactual thinking in the model responses. Comprehensive\nanalyses across various LMMs, including both open-source and proprietary\nmodels, corroborate that counterfactual thinking significantly reduces\nhallucination and helps to broaden contextual understanding based on true\nvisual clues.", "published": "2024-03-20 11:27:20", "link": "http://arxiv.org/abs/2403.13513v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Motion Generation from Fine-grained Textual Descriptions", "abstract": "The task of text2motion is to generate human motion sequences from given\ntextual descriptions, where the model explores diverse mappings from natural\nlanguage instructions to human body movements. While most existing works are\nconfined to coarse-grained motion descriptions, e.g., \"A man squats.\",\nfine-grained descriptions specifying movements of relevant body parts are\nbarely explored. Models trained with coarse-grained texts may not be able to\nlearn mappings from fine-grained motion-related words to motion primitives,\nresulting in the failure to generate motions from unseen descriptions. In this\npaper, we build a large-scale language-motion dataset specializing in\nfine-grained textual descriptions, FineHumanML3D, by feeding GPT-3.5-turbo with\nstep-by-step instructions with pseudo-code compulsory checks. Accordingly, we\ndesign a new text2motion model, FineMotionDiffuse, making full use of\nfine-grained textual information. Our quantitative evaluation shows that\nFineMotionDiffuse trained on FineHumanML3D improves FID by a large margin of\n0.38, compared with competitive baselines. According to the qualitative\nevaluation and case study, our model outperforms MotionDiffuse in generating\nspatially or chronologically composite motions, by learning the implicit\nmappings from fine-grained descriptions to the corresponding basic motions. We\nrelease our data at https://github.com/KunhangL/finemotiondiffuse.", "published": "2024-03-20 11:38:30", "link": "http://arxiv.org/abs/2403.13518v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "cs.AI"}
{"title": "What explains the success of cross-modal fine-tuning with ORCA?", "abstract": "ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning,\ni.e., applying pre-trained transformer models to modalities beyond their\ntraining data. The technique consists primarily of training an embedder and\nfine-tuning the embedder and model. Despite its high performance on a variety\nof downstream tasks, we do not understand precisely how each of these\ncomponents contribute to ORCA's success. Therefore, we run a series of\nablations and find that embedder training does not help 2D tasks at all,\ncontrary to what the original paper posits. In 1D tasks, some amount of\nembedder training is necessary but more is not better. In 4 out of 6 datasets\nwe experiment with, it is model fine-tuning that makes the biggest difference.\nThrough our ablations and baselines, we contribute a better understanding of\nthe individual components of ORCA.", "published": "2024-03-20 12:14:54", "link": "http://arxiv.org/abs/2403.13537v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoCoST: Automatic Complex Code Generation with Online Searching and\n  Correctness Testing", "abstract": "Large Language Models have revolutionized code generation ability by\nconverting natural language descriptions into executable code. However,\ngenerating complex code within real-world scenarios remains challenging due to\nintricate structures, subtle bugs, understanding of advanced data types, and\nlack of supplementary contents. To address these challenges, we introduce the\nCoCoST framework, which enhances complex code generation by online searching\nfor more information with planned queries and correctness testing for code\nrefinement. Moreover, CoCoST serializes the complex inputs and outputs to\nimprove comprehension and generates test cases to ensure the adaptability for\nreal-world applications. CoCoST is validated through rigorous experiments on\nthe DS-1000 and ClassEval datasets. Experimental results show that CoCoST\nsubstantially improves the quality of complex code generation, highlighting its\npotential to enhance the practicality of LLMs in generating complex code.", "published": "2024-03-20 13:33:55", "link": "http://arxiv.org/abs/2403.13583v3", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "PARAMANU-AYN: Pretrain from scratch or Continual Pretraining of LLMs for\n  Legal Domain Adaptation?", "abstract": "In this paper, we present Paramanu-Ayn, a collection of legal language models\ntrained exclusively on Indian legal case documents. This 97-million-parameter\nAuto-Regressive (AR) decoder-only model was pretrained from scratch with a\ncontext size of 8192 on a single GPU for just 185 hours, achieving an efficient\nMFU of 41.35. We also developed a legal domain specialized BPE tokenizer. We\nevaluated our model using perplexity and zero-shot tasks: case judgment\nprediction with explanation and abstractive case summarization. Paramanu-Ayn\noutperformed Llama-2 7B and Gemini-Pro in case judgment prediction with\nexplanation task on test accuracy by nearly 2 percentage points, despite being\n72 times smaller. In zero-shot abstractive summarization, it surpassed\ndecoder-only LLMs generating fixed-length summaries (5000 tokens) by over 10\npercentage points in BLEU and METEOR metrics, and by nearly 4 percentage points\nin BERTScore. Further evaluations on zero-shot commonsense and mathematical\nbenchmarks showed that Paramanu-Ayn excelled despite being trained exclusively\non legal documents, outperforming Llama-1, Llama-2, and Falcon on\nAGIEVAL-AQuA-RAT and AGIEVAL-SAT-Math tasks. We also instruction-tuned our\nmodel on 10,763 diverse legal tasks, including legal clause generation, legal\ndrafting, case summarization, etc. The Paramanu-Ayn-instruct model scored above\n8 out of 10 in clarity, relevance, completeness, and legal reasoning metrics by\nGPT-3.5-Turbo. We found that our models, were able to learn drafting knowledge\nand generalize to draft legal contracts and legal clauses with limited\ninstruction-tuning. Hence, we conclude that for a strong domain-specialized\ngenerative language model (such as legal), domain specialized pretraining from\nscratch is more cost effective, environmentally friendly, and remains\ncompetitive with larger models or even better than adapting LLMs for legal\ndomain tasks.", "published": "2024-03-20 15:39:54", "link": "http://arxiv.org/abs/2403.13681v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Language as Policies: Reasoning for Coordinate-Level Embodied\n  Control with LLMs", "abstract": "We demonstrate experimental results with LLMs that address robotics task\nplanning problems. Recently, LLMs have been applied in robotics task planning,\nparticularly using a code generation approach that converts complex high-level\ninstructions into mid-level policy codes. In contrast, our approach acquires\ntext descriptions of the task and scene objects, then formulates task planning\nthrough natural language reasoning, and outputs coordinate level control\ncommands, thus reducing the necessity for intermediate representation code as\npolicies with pre-defined APIs. Our approach is evaluated on a multi-modal\nprompt simulation benchmark, demonstrating that our prompt engineering\nexperiments with natural language reasoning significantly enhance success rates\ncompared to its absence. Furthermore, our approach illustrates the potential\nfor natural language descriptions to transfer robotics skills from known tasks\nto previously unseen tasks. The project website:\nhttps://natural-language-as-policies.github.io/", "published": "2024-03-20 17:58:12", "link": "http://arxiv.org/abs/2403.13801v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "I.2.9; I.2.7"], "primary_category": "cs.RO"}
{"title": "ZigMa: A DiT-style Zigzag Mamba Diffusion Model", "abstract": "The diffusion model has long been plagued by scalability and quadratic\ncomplexity issues, especially within transformer-based structures. In this\nstudy, we aim to leverage the long sequence modeling capability of a\nState-Space Model called Mamba to extend its applicability to visual data\ngeneration. Firstly, we identify a critical oversight in most current\nMamba-based vision methods, namely the lack of consideration for spatial\ncontinuity in the scan scheme of Mamba. Secondly, building upon this insight,\nwe introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba,\nwhich outperforms Mamba-based baselines and demonstrates improved speed and\nmemory utilization compared to transformer-based baselines. Lastly, we\nintegrate Zigzag Mamba with the Stochastic Interpolant framework to investigate\nthe scalability of the model on large-resolution visual datasets, such as\nFacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO\n$256\\times 256$ . Code will be released at https://taohu.me/zigma/", "published": "2024-03-20 17:59:14", "link": "http://arxiv.org/abs/2403.13802v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning from Synthetic Data for Visual Grounding", "abstract": "This paper extensively investigates the effectiveness of synthetic training\ndata to improve the capabilities of vision-and-language models for grounding\ntextual descriptions to image regions. We explore various strategies to best\ngenerate image-text pairs and image-text-box triplets using a series of\npretrained models under different settings and varying degrees of reliance on\nreal data. Through comparative analyses with synthetic, real, and web-crawled\ndata, we identify factors that contribute to performance differences, and\npropose SynGround, an effective pipeline for generating useful synthetic data\nfor visual grounding. Our findings show that SynGround can improve the\nlocalization capabilities of off-the-shelf vision-and-language models and\noffers the potential for arbitrarily large scale data generation. Particularly,\ndata generated with SynGround improves the pointing game accuracy of a\npretrained ALBEF and BLIP models by 4.81% and 17.11% absolute percentage\npoints, respectively, across the RefCOCO+ and the Flickr30k benchmarks.", "published": "2024-03-20 17:59:43", "link": "http://arxiv.org/abs/2403.13804v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Reducing Large Language Model Bias with Emphasis on 'Restricted\n  Industries': Automated Dataset Augmentation and Prejudice Quantification", "abstract": "Despite the growing capabilities of large language models, there exists\nconcerns about the biases they develop. In this paper, we propose a novel,\nautomated mechanism for debiasing through specified dataset augmentation in the\nlens of bias producers and in the context of 'restricted industries' with\nlimited data. We additionally create two new additional metrics, the mb-index\nand db-index, to quantify bias, considering the idea that bias occurs due to\nboth intrinsic model architecture and dataset.", "published": "2024-03-20 18:59:18", "link": "http://arxiv.org/abs/2403.13925v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Modal Hallucination Control by Visual Information Grounding", "abstract": "Generative Vision-Language Models (VLMs) are prone to generate\nplausible-sounding textual answers that, however, are not always grounded in\nthe input image. We investigate this phenomenon, usually referred to as\n\"hallucination\" and show that it stems from an excessive reliance on the\nlanguage prior. In particular, we show that as more tokens are generated, the\nreliance on the visual prompt decreases, and this behavior strongly correlates\nwith the emergence of hallucinations. To reduce hallucinations, we introduce\nMulti-Modal Mutual-Information Decoding (M3ID), a new sampling method for\nprompt amplification. M3ID amplifies the influence of the reference image over\nthe language prior, hence favoring the generation of tokens with higher mutual\ninformation with the visual prompt. M3ID can be applied to any pre-trained\nautoregressive VLM at inference time without necessitating further training and\nwith minimal computational overhead. If training is an option, we show that\nM3ID can be paired with Direct Preference Optimization (DPO) to improve the\nmodel's reliance on the prompt image without requiring any labels. Our\nempirical findings show that our algorithms maintain the fluency and linguistic\ncapabilities of pre-trained VLMs while reducing hallucinations by mitigating\nvisually ungrounded answers. Specifically, for the LLaVA 13B model, M3ID and\nM3ID+DPO reduce the percentage of hallucinated objects in captioning tasks by\n25% and 28%, respectively, and improve the accuracy on VQA benchmarks such as\nPOPE by 21% and 24%.", "published": "2024-03-20 22:05:18", "link": "http://arxiv.org/abs/2403.14003v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Defending Against Indirect Prompt Injection Attacks With Spotlighting", "abstract": "Large Language Models (LLMs), while powerful, are built and trained to\nprocess a single text input. In common applications, multiple inputs can be\nprocessed by concatenating them together into a single stream of text. However,\nthe LLM is unable to distinguish which sections of prompt belong to various\ninput sources. Indirect prompt injection attacks take advantage of this\nvulnerability by embedding adversarial instructions into untrusted data being\nprocessed alongside user commands. Often, the LLM will mistake the adversarial\ninstructions as user commands to be followed, creating a security vulnerability\nin the larger system. We introduce spotlighting, a family of prompt engineering\ntechniques that can be used to improve LLMs' ability to distinguish among\nmultiple sources of input. The key insight is to utilize transformations of an\ninput to provide a reliable and continuous signal of its provenance. We\nevaluate spotlighting as a defense against indirect prompt injection attacks,\nand find that it is a robust defense that has minimal detrimental impact to\nunderlying NLP tasks. Using GPT-family models, we find that spotlighting\nreduces the attack success rate from greater than {50}\\% to below {2}\\% in our\nexperiments with minimal impact on task efficacy.", "published": "2024-03-20 15:26:23", "link": "http://arxiv.org/abs/2403.14720v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Testing the Limits of Jailbreaking Defenses with the Purple Problem", "abstract": "The rise of \"jailbreak\" attacks on language models has led to a flurry of\ndefenses aimed at preventing undesirable responses. We critically examine the\ntwo stages of the defense pipeline: (i) defining what constitutes unsafe\noutputs, and (ii) enforcing the definition via methods such as input processing\nor fine-tuning. To test the efficacy of existing enforcement mechanisms, we\nconsider a simple and well-specified definition of unsafe outputs--outputs that\ncontain the word \"purple\". Surprisingly, existing fine-tuning and input\ndefenses fail on this simple problem, casting doubt on whether enforcement\nalgorithms can be robust for more complicated definitions. We find that real\nsafety benchmarks similarly test enforcement for a fixed definition. We hope\nthat future research can lead to effective/fast enforcement as well as high\nquality definitions used for enforcement and evaluation.", "published": "2024-03-20 21:53:56", "link": "http://arxiv.org/abs/2403.14725v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Isometric Neural Machine Translation using Phoneme Count Ratio\n  Reward-based Reinforcement Learning", "abstract": "Traditional Automatic Video Dubbing (AVD) pipeline consists of three key\nmodules, namely, Automatic Speech Recognition (ASR), Neural Machine Translation\n(NMT), and Text-to-Speech (TTS). Within AVD pipelines, isometric-NMT algorithms\nare employed to regulate the length of the synthesized output text. This is\ndone to guarantee synchronization with respect to the alignment of video and\naudio subsequent to the dubbing process. Previous approaches have focused on\naligning the number of characters and words in the source and target language\ntexts of Machine Translation models. However, our approach aims to align the\nnumber of phonemes instead, as they are closely associated with speech\nduration. In this paper, we present the development of an isometric NMT system\nusing Reinforcement Learning (RL), with a focus on optimizing the alignment of\nphoneme counts in the source and target language sentence pairs. To evaluate\nour models, we propose the Phoneme Count Compliance (PCC) score, which is a\nmeasure of length compliance. Our approach demonstrates a substantial\nimprovement of approximately 36% in the PCC score compared to the\nstate-of-the-art models when applied to English-Hindi language pairs. Moreover,\nwe propose a student-teacher architecture within the framework of our RL\napproach to maintain a trade-off between the phoneme count and translation\nquality.", "published": "2024-03-20 08:52:40", "link": "http://arxiv.org/abs/2403.15469v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Inserting Faces inside Captions: Image Captioning with Attention Guided\n  Merging", "abstract": "Image captioning models are widely used to describe recent and archived\npictures with the objective of improving their accessibility and retrieval.\nYet, these approaches tend to be inefficient and biased at retrieving people's\nnames. In this work we introduce AstroCaptions, a dataset for the image\ncaptioning task. This dataset specifically contains thousands of public\nfig-ures that are complex to identify for a traditional model. We also propose\na novel post-processing method to insert identified people's names inside the\ncaption using explainable AI tools and the grounding capabilities of\nvi-sion-language models. The results obtained with this method show\nsignifi-cant improvements of captions quality and a potential of reducing\nhalluci-nations. Up to 93.2% of the persons detected can be inserted in the\nimage captions leading to improvements in the BLEU, ROUGE, CIDEr and METEOR\nscores of each captioning model.", "published": "2024-03-20 08:38:25", "link": "http://arxiv.org/abs/2405.02305v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Ink and Individuality: Crafting a Personalised Narrative in the Age of\n  LLMs", "abstract": "Individuality and personalization comprise the distinctive characteristics\nthat make each writer unique and influence their words in order to effectively\nengage readers while conveying authenticity. However, our growing reliance on\nLLM-based writing assistants risks compromising our creativity and\nindividuality over time. We often overlook the negative impacts of this trend\non our creativity and uniqueness, despite the possible consequences. This study\ninvestigates these concerns by performing a brief survey to explore different\nperspectives and concepts, as well as trying to understand people's viewpoints,\nin conjunction with past studies in the area. Addressing these issues is\nessential for improving human-computer interaction systems and enhancing\nwriting assistants for personalization and individuality.", "published": "2024-03-20 21:02:16", "link": "http://arxiv.org/abs/2404.00026v5", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.HC"}
{"title": "LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership\n  and Reasoning", "abstract": "Sense of ownership in writing confines our investment of thoughts, time, and\ncontribution, leading to attachment to the output. However, using writing\nassistants introduces a mental dilemma, as some content isn't directly our\ncreation. For instance, we tend to credit Large Language Models (LLMs) more in\ncreative tasks, even though all tasks are equal for them. Additionally, while\nwe may not claim complete ownership of LLM-generated content, we freely claim\nauthorship. We conduct a short survey to examine these issues and understand\nunderlying cognitive processes in order to gain a better knowledge of\nhuman-computer interaction in writing and improve writing aid systems.", "published": "2024-03-20 21:06:42", "link": "http://arxiv.org/abs/2404.00027v5", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "USE: Dynamic User Modeling with Stateful Sequence Models", "abstract": "User embeddings play a crucial role in user engagement forecasting and\npersonalized services. Recent advances in sequence modeling have sparked\ninterest in learning user embeddings from behavioral data. Yet behavior-based\nuser embedding learning faces the unique challenge of dynamic user modeling. As\nusers continuously interact with the apps, user embeddings should be\nperiodically updated to account for users' recent and long-term behavior\npatterns. Existing methods highly rely on stateless sequence models that lack\nmemory of historical behavior. They have to either discard historical data and\nuse only the most recent data or reprocess the old and new data jointly. Both\ncases incur substantial computational overhead. To address this limitation, we\nintroduce User Stateful Embedding (USE). USE generates user embeddings and\nreflects users' evolving behaviors without the need for exhaustive reprocessing\nby storing previous model states and revisiting them in the future.\nFurthermore, we introduce a novel training objective named future W-behavior\nprediction to transcend the limitations of next-token prediction by forecasting\na broader horizon of upcoming user behaviors. By combining it with the Same\nUser Prediction, a contrastive learning-based objective that predicts whether\ndifferent segments of behavior sequences belong to the same user, we further\nimprove the embeddings' distinctiveness and representativeness. We conducted\nexperiments on 8 downstream tasks using Snapchat users' behavioral logs in both\nstatic (i.e., fixed user behavior sequences) and dynamic (i.e., periodically\nupdated user behavior sequences) settings. We demonstrate USE's superior\nperformance over established baselines. The results underscore USE's\neffectiveness and efficiency in integrating historical and recent user behavior\nsequences into user embeddings in dynamic user modeling.", "published": "2024-03-20 07:05:19", "link": "http://arxiv.org/abs/2403.13344v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Frequency-aware convolution for sound event detection", "abstract": "In sound event detection (SED), convolutional neural networks (CNNs) are\nwidely employed to extract time-frequency (TF) patterns from spectrograms.\nHowever, the ability of CNNs to recognize different sound events is limited by\ntheir insensitivity to shifts of TF patterns along the frequency dimension,\ncaused by translation equivariance. To address this issue, a model called\nfrequency dynamic convolution (FDY) has been proposed, which involves applying\nspecific convolution kernels to different frequency components. However, FDY\nrequires a significantly larger number of parameters and computational\nresources compared to a standard CNN. This paper proposes a more efficient\nsolution called frequency-aware convolution (FAC). FAC incorporates frequency\npositional information by encoding it in a vector, which is then explicitly\nadded to the input spectrogram. To ensure that the amplitude of the encoding\nvector matches that of the input spectrogram, the encoding vector is adaptively\nand channel-dependently scaled using self-attention. To evaluate the\neffectiveness of FAC, we conducted experiments within the context of the DCASE\n2023 task 4. The results show that FAC achieves comparable performance to FDY\nwhile requiring only an additional 515 parameters, whereas FDY necessitates an\nadditional 8.02 million parameters. Furthermore, an ablation study confirms\nthat the adaptive and channel-dependent scaling of the encoding vector is\ncritical to the performance of FAC.", "published": "2024-03-20 02:32:13", "link": "http://arxiv.org/abs/2403.13252v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Onset and offset weighted loss function for sound event detection", "abstract": "In a typical sound event detection (SED) system, the existence of a sound\nevent is detected at a frame level, and consecutive frames with the same event\ndetected are combined as one sound event. The median filter is applied as a\npost-processing step to remove detection errors as much as possible. However,\ndetection errors occurring around the onset and offset of a sound event are\nbeyond the capacity of the median filter. To address this issue, an onset and\noffset weighted binary cross-entropy (OWBCE) loss function is proposed in this\npaper, which trains the DNN model to be more robust on frames around (a) onsets\nand offsets. Experiments are carried out in the context of DCASE 2022 task 4.\nResults show that OWBCE outperforms BCE when different models are considered.\nFor a basic CRNN, relative improvements of 6.43% in event-F1, 1.96% in PSDS1,\nand 2.43% in PSDS2 can be achieved by OWBCE.", "published": "2024-03-20 02:32:41", "link": "http://arxiv.org/abs/2403.13254v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TDT-KWS: Fast And Accurate Keyword Spotting Using Token-and-duration\n  Transducer", "abstract": "Designing an efficient keyword spotting (KWS) system that delivers\nexceptional performance on resource-constrained edge devices has long been a\nsubject of significant attention. Existing KWS search algorithms typically\nfollow a frame-synchronous approach, where search decisions are made repeatedly\nat each frame despite the fact that most frames are keyword-irrelevant. In this\npaper, we propose TDT-KWS, which leverages token-and-duration Transducers (TDT)\nfor KWS tasks. We also propose a novel KWS task-specific decoding algorithm for\nTransducer-based models, which supports highly effective frame-asynchronous\nkeyword search in streaming speech scenarios. With evaluations conducted on\nboth the public Hey Snips and self-constructed LibriKWS-20 datasets, our\nproposed KWS-decoding algorithm produces more accurate results than\nconventional ASR decoding algorithms. Additionally, TDT-KWS achieves on-par or\nbetter wake word detection performance than both RNN-T and traditional TDT-ASR\nsystems while achieving significant inference speed-up. Furthermore,\nexperiments show that TDT-KWS is more robust to noisy environments compared to\nRNN-T KWS.", "published": "2024-03-20 06:24:25", "link": "http://arxiv.org/abs/2403.13332v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Building speech corpus with diverse voice characteristics for its\n  prompt-based representation", "abstract": "In text-to-speech synthesis, the ability to control voice characteristics is\nvital for various applications. By leveraging thriving text prompt-based\ngeneration techniques, it should be possible to enhance the nuanced control of\nvoice characteristics. While previous research has explored the prompt-based\nmanipulation of voice characteristics, most studies have used pre-recorded\nspeech, which limits the diversity of voice characteristics available. Thus, we\naim to address this gap by creating a novel corpus and developing a model for\nprompt-based manipulation of voice characteristics in text-to-speech synthesis,\nfacilitating a broader range of voice characteristics. Specifically, we propose\na method to build a sizable corpus pairing voice characteristics descriptions\nwith corresponding speech samples. This involves automatically gathering\nvoice-related speech data from the Internet, ensuring its quality, and manually\nannotating it using crowdsourcing. We implement this method with Japanese\nlanguage data and analyze the results to validate its effectiveness.\nSubsequently, we propose a construction method of the model to retrieve speech\nfrom voice characteristics descriptions based on a contrastive learning method.\nWe train the model using not only conservative contrastive learning but also\nfeature prediction learning to predict quantitative speech features\ncorresponding to voice characteristics. We evaluate the model performance via\nexperiments with the corpus we constructed above.", "published": "2024-03-20 07:31:27", "link": "http://arxiv.org/abs/2403.13353v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advanced Long-Content Speech Recognition With Factorized Neural\n  Transducer", "abstract": "In this paper, we propose two novel approaches, which integrate long-content\ninformation into the factorized neural transducer (FNT) based architecture in\nboth non-streaming (referred to as LongFNT ) and streaming (referred to as\nSLongFNT ) scenarios. We first investigate whether long-content transcriptions\ncan improve the vanilla conformer transducer (C-T) models. Our experiments\nindicate that the vanilla C-T models do not exhibit improved performance when\nutilizing long-content transcriptions, possibly due to the predictor network of\nC-T models not functioning as a pure language model. Instead, FNT shows its\npotential in utilizing long-content information, where we propose the LongFNT\nmodel and explore the impact of long-content information in both text\n(LongFNT-Text) and speech (LongFNT-Speech). The proposed LongFNT-Text and\nLongFNT-Speech models further complement each other to achieve better\nperformance, with transcription history proving more valuable to the model. The\neffectiveness of our LongFNT approach is evaluated on LibriSpeech and\nGigaSpeech corpora, and obtains relative 19% and 12% word error rate reduction,\nrespectively. Furthermore, we extend the LongFNT model to the streaming\nscenario, which is named SLongFNT , consisting of SLongFNT-Text and\nSLongFNT-Speech approaches to utilize long-content text and speech information.\nExperiments show that the proposed SLongFNT model achieves relative 26% and 17%\nWER reduction on LibriSpeech and GigaSpeech respectively while keeping a good\nlatency, compared to the FNT baseline. Overall, our proposed LongFNT and\nSLongFNT highlight the significance of considering long-content speech and\ntranscription knowledge for improving both non-streaming and streaming speech\nrecognition systems.", "published": "2024-03-20 09:09:49", "link": "http://arxiv.org/abs/2403.13423v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BanglaNum -- A Public Dataset for Bengali Digit Recognition from Speech", "abstract": "Automatic speech recognition (ASR) converts the human voice into readily\nunderstandable and categorized text or words. Although Bengali is one of the\nmost widely spoken languages in the world, there have been very few studies on\nBengali ASR, particularly on Bangladeshi-accented Bengali. In this study, audio\nrecordings of spoken digits (0-9) from university students were used to create\na Bengali speech digits dataset that may be employed to train artificial neural\nnetworks for voice-based digital input systems. This paper also compares the\nBengali digit recognition accuracy of several Convolutional Neural Networks\n(CNNs) using spectrograms and shows that a test accuracy of 98.23% is\nachievable using parameter-efficient models such as SqueezeNet on our dataset.", "published": "2024-03-20 10:16:33", "link": "http://arxiv.org/abs/2403.13465v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Vibration Sensitivity of one-port and two-port MEMS microphones", "abstract": "Micro-electro-mechanical system (MEMS) microphones (mics) with two acoustic\nports are currently receiving considerable interest, with the promise of\nachieving higher directional sensitivity compared to traditional one-port\narchitectures. However, measuring pressure differences in two-port microphones\ntypically commands sensing elements that are softer than in one-port mics, and\nare therefore presumably more prone to interference from external vibration.\nHere we derive a universal expression for microphone sensitivity to vibration\nand we experimentally demonstrate its validity for several emerging two-port\nmicrophone technologies. We also perform vibration measurements on a one-port\nmic, thus providing a one-stop direct comparison between one-port and two-port\nsensing approaches. We find that the acoustically-referred vibration\nsensitivity of two-port MEMS mics, in units of measured acoustic pressure per\nexternal acceleration (i.e., Pascals per g), does not depend on the sensing\nelement stiffness nor on its natural frequency. We also show that this\nvibration sensitivity in two-port mics is inversely proportional to frequency\nas opposed to the frequency independent behavior observed in one-port mics.\nThis is confirmed experimentally for several types of microphone packages.", "published": "2024-03-20 14:50:00", "link": "http://arxiv.org/abs/2403.13643v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "UTDUSS: UTokyo-SaruLab System for Interspeech2024 Speech Processing\n  Using Discrete Speech Unit Challenge", "abstract": "We present UTDUSS, the UTokyo-SaruLab system submitted to Interspeech2024\nSpeech Processing Using Discrete Speech Unit Challenge. The challenge focuses\non using discrete speech unit learned from large speech corpora for some tasks.\nWe submitted our UTDUSS system to two text-to-speech tracks: Vocoder and\nAcoustic+Vocoder. Our system incorporates neural audio codec (NAC) pre-trained\non only speech corpora, which makes the learned codec represent rich acoustic\nfeatures that are necessary for high-fidelity speech reconstruction. For the\nacoustic+vocoder track, we trained an acoustic model based on Transformer\nencoder-decoder that predicted the pre-trained NAC tokens from text input. We\ndescribe our strategies to build these models, such as data selection,\ndownsampling, and hyper-parameter tuning. Our system ranked in second and first\nfor the Vocoder and Acoustic+Vocoder tracks, respectively.", "published": "2024-03-20 16:27:13", "link": "http://arxiv.org/abs/2403.13720v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "KunquDB: An Attempt for Speaker Verification in the Chinese Opera\n  Scenario", "abstract": "This work aims to promote Chinese opera research in both musical and speech\ndomains, with a primary focus on overcoming the data limitations. We introduce\nKunquDB, a relatively large-scale, well-annotated audio-visual dataset\ncomprising 339 speakers and 128 hours of content. Originating from the Kunqu\nOpera Art Canon (Kunqu yishu dadian), KunquDB is meticulously structured by\ndialogue lines, providing explicit annotations including character names,\nspeaker names, gender information, vocal manner classifications, and\naccompanied by preliminary text transcriptions. KunquDB provides a versatile\nfoundation for role-centric acoustic studies and advancements in speech-related\nresearch, including Automatic Speaker Verification (ASV). Beyond enriching\nopera research, this dataset bridges the gap between artistic expression and\ntechnological innovation. Pioneering the exploration of ASV in Chinese opera,\nwe construct four test trials considering two distinct vocal manners in opera\nvoices: stage speech (ST) and singing (S). Implementing domain adaptation\nmethods effectively mitigates domain mismatches induced by these vocal manner\nvariations while there is still room for further improvement as a benchmark.", "published": "2024-03-20 07:34:21", "link": "http://arxiv.org/abs/2403.13356v2", "categories": ["eess.AS", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "Recursive Joint Cross-Modal Attention for Multimodal Fusion in\n  Dimensional Emotion Recognition", "abstract": "Though multimodal emotion recognition has achieved significant progress over\nrecent years, the potential of rich synergic relationships across the\nmodalities is not fully exploited. In this paper, we introduce Recursive Joint\nCross-Modal Attention (RJCMA) to effectively capture both intra- and\ninter-modal relationships across audio, visual, and text modalities for\ndimensional emotion recognition. In particular, we compute the attention\nweights based on cross-correlation between the joint audio-visual-text feature\nrepresentations and the feature representations of individual modalities to\nsimultaneously capture intra- and intermodal relationships across the\nmodalities. The attended features of the individual modalities are again fed as\ninput to the fusion model in a recursive mechanism to obtain more refined\nfeature representations. We have also explored Temporal Convolutional Networks\n(TCNs) to improve the temporal modeling of the feature representations of\nindividual modalities. Extensive experiments are conducted to evaluate the\nperformance of the proposed fusion model on the challenging Affwild2 dataset.\nBy effectively capturing the synergic intra- and inter-modal relationships\nacross audio, visual, and text modalities, the proposed fusion model achieves a\nConcordance Correlation Coefficient (CCC) of 0.585 (0.542) and 0.674 (0.619)\nfor valence and arousal respectively on the validation set(test set). This\nshows a significant improvement over the baseline of 0.240 (0.211) and 0.200\n(0.191) for valence and arousal, respectively, in the validation set (test\nset), achieving second place in the valence-arousal challenge of the 6th\nAffective Behavior Analysis in-the-Wild (ABAW) competition.", "published": "2024-03-20 15:08:43", "link": "http://arxiv.org/abs/2403.13659v4", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
