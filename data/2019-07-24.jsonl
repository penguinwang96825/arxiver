{"title": "Fine-Grained Sentence Functions for Short-Text Conversation", "abstract": "Sentence function is an important linguistic feature referring to a user's\npurpose in uttering a specific sentence. The use of sentence function has shown\npromising results to improve the performance of conversation models. However,\nthere is no large conversation dataset annotated with sentence functions. In\nthis work, we collect a new Short-Text Conversation dataset with manually\nannotated SEntence FUNctions (STC-Sefun). Classification models are trained on\nthis dataset to (i) recognize the sentence function of new data in a large\ncorpus of short-text conversations; (ii) estimate a proper sentence function of\nthe response given a test query. We later train conversation models conditioned\non the sentence functions, including information retrieval-based and neural\ngenerative models. Experimental results demonstrate that the use of sentence\nfunctions can help improve the quality of the returned responses.", "published": "2019-07-24 08:49:01", "link": "http://arxiv.org/abs/1907.10302v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unbabel's Participation in the WMT19 Translation Quality Estimation\n  Shared Task", "abstract": "We present the contribution of the Unbabel team to the WMT 2019 Shared Task\non Quality Estimation. We participated on the word, sentence, and\ndocument-level tracks, encompassing 3 language pairs: English-German,\nEnglish-Russian, and English-French. Our submissions build upon the recent\nOpenKiwi framework: we combine linear, neural, and predictor-estimator systems\nwith new transfer learning approaches using BERT and XLM pre-trained models. We\ncompare systems individually and propose new ensemble techniques for word and\nsentence-level predictions. We also propose a simple technique for converting\nword labels into document-level predictions. Overall, our submitted systems\nachieve the best results on all tracks and language pairs by a considerable\nmargin.", "published": "2019-07-24 10:30:39", "link": "http://arxiv.org/abs/1907.10352v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Translator2Vec: Understanding and Representing Human Post-Editors", "abstract": "The combination of machines and humans for translation is effective, with\nmany studies showing productivity gains when humans post-edit\nmachine-translated output instead of translating from scratch. To take full\nadvantage of this combination, we need a fine-grained understanding of how\nhuman translators work, and which post-editing styles are more effective than\nothers. In this paper, we release and analyze a new dataset with document-level\npost-editing action sequences, including edit operations from keystrokes, mouse\nactions, and waiting times. Our dataset comprises 66,268 full document sessions\npost-edited by 332 humans, the largest of the kind released to date. We show\nthat action sequences are informative enough to identify post-editors\naccurately, compared to baselines that only look at the initial and final text.\nWe build on this to learn and visualize continuous representations of\npost-editors, and we show that these representations improve the downstream\ntask of predicting post-editing time.", "published": "2019-07-24 11:01:24", "link": "http://arxiv.org/abs/1907.10362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Generation of Personalized Comment Based on User Profile", "abstract": "Comments on social media are very diverse, in terms of content, style and\nvocabulary, which make generating comments much more challenging than other\nexisting natural language generation~(NLG) tasks. Besides, since different user\nhas different expression habits, it is necessary to take the user's profile\ninto consideration when generating comments. In this paper, we introduce the\ntask of automatic generation of personalized comment~(AGPC) for social media.\nBased on tens of thousands of users' real comments and corresponding user\nprofiles on weibo, we propose Personalized Comment Generation Network~(PCGN)\nfor AGPC. The model utilizes user feature embedding with a gated memory and\nattends to user description to model personality of users. In addition,\nexternal user representation is taken into consideration during the decoding to\nenhance the comments generation. Experimental results show that our model can\ngenerate natural, human-like and personalized comments.", "published": "2019-07-24 11:37:08", "link": "http://arxiv.org/abs/1907.10371v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributional Analysis of Polysemous Function Words", "abstract": "In this paper, we are concerned with the phenomenon of function word\npolysemy. We adopt the framework of distributional semantics, which\ncharacterizes word meaning by observing occurrence contexts in large corpora\nand which is in principle well situated to model polysemy. Nevertheless,\nfunction words were traditionally considered as impossible to analyze\ndistributionally due to their highly flexible usage patterns. We establish that\ncontextualized word embeddings, the most recent generation of distributional\nmethods, offer hope in this regard. Using the German reflexive pronoun 'sich'\nas an example, we find that contextualized word embeddings capture\ntheoretically motivated word senses for 'sich' to the extent to which these\nsenses are mirrored systematically in linguistic usage.", "published": "2019-07-24 13:48:16", "link": "http://arxiv.org/abs/1907.10449v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Evaluation of Open-Domain Dialogue Systems With Human\n  Generated Multiple References", "abstract": "The aim of this paper is to mitigate the shortcomings of automatic evaluation\nof open-domain dialog systems through multi-reference evaluation. Existing\nmetrics have been shown to correlate poorly with human judgement, particularly\nin open-domain dialog. One alternative is to collect human annotations for\nevaluation, which can be expensive and time consuming. To demonstrate the\neffectiveness of multi-reference evaluation, we augment the test set of\nDailyDialog with multiple references. A series of experiments show that the use\nof multiple references results in improved correlation between several\nautomatic metrics and human judgement for both the quality and the diversity of\nsystem output.", "published": "2019-07-24 17:18:48", "link": "http://arxiv.org/abs/1907.10568v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WinoGrande: An Adversarial Winograd Schema Challenge at Scale", "abstract": "The Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011),\na benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun\nresolution problems originally designed to be unsolvable for statistical models\nthat rely on selectional preferences or word associations. However, recent\nadvances in neural language models have already reached around 90% accuracy on\nvariants of WSC. This raises an important question whether these models have\ntruly acquired robust commonsense capabilities or whether they rely on spurious\nbiases in the datasets that lead to an overestimation of the true capabilities\nof machine commonsense. To investigate this question, we introduce WinoGrande,\na large-scale dataset of 44k problems, inspired by the original WSC design, but\nadjusted to improve both the scale and the hardness of the dataset. The key\nsteps of the dataset construction consist of (1) a carefully designed\ncrowdsourcing procedure, followed by (2) systematic bias reduction using a\nnovel AfLite algorithm that generalizes human-detectable word associations to\nmachine-detectable embedding associations. The best state-of-the-art methods on\nWinoGrande achieve 59.4-79.1%, which are 15-35% below human performance of\n94.0%, depending on the amount of the training data allowed. Furthermore, we\nestablish new state-of-the-art results on five related benchmarks - WSC\n(90.1%), DPR (93.1%), COPA (90.6%), KnowRef (85.6%), and Winogender (97.1%).\nThese results have dual implications: on one hand, they demonstrate the\neffectiveness of WinoGrande when used as a resource for transfer learning. On\nthe other hand, they raise a concern that we are likely to be overestimating\nthe true capabilities of machine commonsense across all these benchmarks. We\nemphasize the importance of algorithmic bias reduction in existing and future\nbenchmarks to mitigate such overestimation.", "published": "2019-07-24 18:11:59", "link": "http://arxiv.org/abs/1907.10641v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans", "abstract": "We present SpanBERT, a pre-training method that is designed to better\nrepresent and predict spans of text. Our approach extends BERT by (1) masking\ncontiguous random spans, rather than random tokens, and (2) training the span\nboundary representations to predict the entire content of the masked span,\nwithout relying on the individual token representations within it. SpanBERT\nconsistently outperforms BERT and our better-tuned baselines, with substantial\ngains on span selection tasks such as question answering and coreference\nresolution. In particular, with the same training data and model size as\nBERT-large, our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0,\nrespectively. We also achieve a new state of the art on the OntoNotes\ncoreference resolution task (79.6\\% F1), strong performance on the TACRED\nrelation extraction benchmark, and even show gains on GLUE.", "published": "2019-07-24 15:43:40", "link": "http://arxiv.org/abs/1907.10529v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generic Intent Representation in Web Search", "abstract": "This paper presents GEneric iNtent Encoder (GEN Encoder) which learns a\ndistributed representation space for user intent in search. Leveraging large\nscale user clicks from Bing search logs as weak supervision of user intent, GEN\nEncoder learns to map queries with shared clicks into similar embeddings\nend-to-end and then finetunes on multiple paraphrase tasks. Experimental\nresults on an intrinsic evaluation task - query intent similarity modeling -\ndemonstrate GEN Encoder's robust and significant advantages over previous\nrepresentation methods. Ablation studies reveal the crucial role of learning\nfrom implicit user feedback in representing user intent and the contributions\nof multi-task learning in representation generality. We also demonstrate that\nGEN Encoder alleviates the sparsity of tail search traffic and cuts down half\nof the unseen queries by using an efficient approximate nearest neighbor search\nto effectively identify previous queries with the same search intent. Finally,\nwe demonstrate distances between GEN encodings reflect certain information\nseeking behaviors in search sessions.", "published": "2019-07-24 20:40:19", "link": "http://arxiv.org/abs/1907.10710v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Non-Parallel Voice Conversion with Cyclic Variational Autoencoder", "abstract": "In this paper, we present a novel technique for a non-parallel voice\nconversion (VC) with the use of cyclic variational autoencoder (CycleVAE)-based\nspectral modeling. In a variational autoencoder(VAE) framework, a latent space,\nusually with a Gaussian prior, is used to encode a set of input features. In a\nVAE-based VC, the encoded latent features are fed into a decoder, along with\nspeaker-coding features, to generate estimated spectra with either the original\nspeaker identity (reconstructed) or another speaker identity (converted). Due\nto the non-parallel modeling condition, the converted spectra can not be\ndirectly optimized, which heavily degrades the performance of a VAE-based VC.\nIn this work, to overcome this problem, we propose to use CycleVAE-based\nspectral model that indirectly optimizes the conversion flow by recycling the\nconverted features back into the system to obtain corresponding cyclic\nreconstructed spectra that can be directly optimized. The cyclic flow can be\ncontinued by using the cyclic reconstructed features as input for the next\ncycle. The experimental results demonstrate the effectiveness of the proposed\nCycleVAE-based VC, which yields higher accuracy of converted spectra, generates\nlatent features with higher correlation degree, and significantly improves the\nquality and conversion accuracy of the converted speech.", "published": "2019-07-24 00:37:20", "link": "http://arxiv.org/abs/1907.10185v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A CNN-based tool for automatic tongue contour tracking in ultrasound\n  images", "abstract": "For speech research, ultrasound tongue imaging provides a non-invasive means\nfor visualizing tongue position and movement during articulation. Extracting\ntongue contours from ultrasound images is a basic step in analyzing ultrasound\ndata but this task often requires non-trivial manual annotation. This study\npresents an open source tool for fully automatic tracking of tongue contours in\nultrasound frames using neural network based methods. We have implemented and\nsystematically compared two convolutional neural networks, U-Net and\nDenseU-Net, under different conditions. Though both models can perform\nautomatic contour tracking with comparable accuracy, Dense U-Net architecture\nseems more generalizable across test datasets while U-Net has faster extraction\nspeed. Our comparison also shows that the choice of loss function and data\naugmentation have a greater effect on tracking performance in this task. This\npublic available segmentation tool shows considerable promise for the automated\ntongue contour annotation of ultrasound images in speech research.", "published": "2019-07-24 02:34:58", "link": "http://arxiv.org/abs/1907.10210v1", "categories": ["eess.IV", "cs.CL", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Dynamical Triangulation Induced by Quantum Walk", "abstract": "We present the single-particle sector of a quantum cellular automaton, namely\na quantum walk, on a simple dynamical triangulated $2-$manifold. The\ntriangulation is changed through Pachner moves, induced by the walker density\nitself, allowing the surface to transform into any topologically equivalent\none. This model extends the quantum walk over triangular grid, introduced in a\nprevious work, by one of the authors, whose space-time limit recovers the Dirac\nequation in (2+1)-dimensions. Numerical simulations show that the number of\ntriangles and the local curvature grow as $t^\\alpha e^{-\\beta t^2}$, where\n$\\alpha$ and $\\beta$ parametrize the way geometry changes upon the local\ndensity of the walker, and that, in the long run, flatness emerges. Finally, we\nalso prove that the global behavior of the walker, remains the same under\nspacetime random fluctuations.", "published": "2019-07-24 20:50:33", "link": "http://arxiv.org/abs/1907.10717v5", "categories": ["quant-ph", "cs.CL", "cs.DM", "gr-qc"], "primary_category": "quant-ph"}
{"title": "Cross-Attention End-to-End ASR for Two-Party Conversations", "abstract": "We present an end-to-end speech recognition model that learns interaction\nbetween two speakers based on the turn-changing information. Unlike\nconventional speech recognition models, our model exploits two speakers'\nhistory of conversational-context information that spans across multiple turns\nwithin an end-to-end framework. Specifically, we propose a speaker-specific\ncross-attention mechanism that can look at the output of the other speaker side\nas well as the one of the current speaker for better at recognizing long\nconversations. We evaluated the models on the Switchboard conversational speech\ncorpus and show that our model outperforms standard end-to-end speech\nrecognition models.", "published": "2019-07-24 21:18:39", "link": "http://arxiv.org/abs/1907.10726v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Careful Selection of Knowledge to solve Open Book Question Answering", "abstract": "Open book question answering is a type of natural language based QA (NLQA)\nwhere questions are expected to be answered with respect to a given set of open\nbook facts, and common knowledge about a topic. Recently a challenge involving\nsuch QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus\non linguistic understanding, OpenBookQA requires deeper reasoning involving\nlinguistic understanding as well as reasoning with common knowledge. In this\npaper we address QA with respect to the OpenBookQA dataset and combine state of\nthe art language models with abductive information retrieval (IR), information\ngain based re-ranking, passage selection and weighted scoring to achieve 72.0%\naccuracy, an 11.6% improvement over the current state of the art.", "published": "2019-07-24 21:37:16", "link": "http://arxiv.org/abs/1907.10738v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visual Interaction with Deep Learning Models through Collaborative\n  Semantic Inference", "abstract": "Automation of tasks can have critical consequences when humans lose agency\nover decision processes. Deep learning models are particularly susceptible\nsince current black-box approaches lack explainable reasoning. We argue that\nboth the visual interface and model structure of deep learning systems need to\ntake into account interaction design. We propose a framework of collaborative\nsemantic inference (CSI) for the co-design of interactions and models to enable\nvisual collaboration between humans and algorithms. The approach exposes the\nintermediate reasoning process of models which allows semantic interactions\nwith the visual metaphors of a problem, which means that a user can both\nunderstand and control parts of the model reasoning process. We demonstrate the\nfeasibility of CSI with a co-designed case study of a document summarization\nsystem.", "published": "2019-07-24 21:37:29", "link": "http://arxiv.org/abs/1907.10739v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Bilingual Lexicon Induction through Unsupervised Machine Translation", "abstract": "A recent research line has obtained strong results on bilingual lexicon\ninduction by aligning independently trained word embeddings in two languages\nand using the resulting cross-lingual embeddings to induce word translation\npairs through nearest neighbor or related retrieval methods. In this paper, we\npropose an alternative approach to this problem that builds on the recent work\non unsupervised machine translation. This way, instead of directly inducing a\nbilingual lexicon from cross-lingual embeddings, we use them to build a\nphrase-table, combine it with a language model, and use the resulting machine\ntranslation system to generate a synthetic parallel corpus, from which we\nextract the bilingual lexicon using statistical word alignment techniques. As\nsuch, our method can work with any word embedding and cross-lingual mapping\ntechnique, and it does not require any additional resource besides the\nmonolingual corpus used to train the embeddings. When evaluated on the exact\nsame cross-lingual embeddings, our proposed method obtains an average\nimprovement of 6 accuracy points over nearest neighbor and 4 points over CSLS\nretrieval, establishing a new state-of-the-art in the standard MUSE dataset.", "published": "2019-07-24 22:30:04", "link": "http://arxiv.org/abs/1907.10761v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A neural network based post-filter for speech-driven head motion\n  synthesis", "abstract": "Despite the fact that neural networks are widely used for speech-driven head\nmotion synthesis, it is well-known that the output of neural networks is noisy\nor discontinuous due to the limited capability of deep neural networks in\npredicting human motion. Thus, post-processing is required to obtain smooth\nhead motion trajectories for animation. It is common to apply a linear filter\nor consider keyframes as post-processing. However, neither approach is optimal\nas there is always a trade-off between smoothness and accuracy. We propose to\nemploy a neural network trained in a way that it is capable of reconstructing\nthe head motions, in order to overcome this limitation. In the objective\nevaluation, this filter is proved to be good at de-noising data involving types\nof noise (dropout or Gaussian noise). Objective metrics also demonstrate the\nimprovement of the joined head motion's smoothness after being processed by our\nproposed filter. A detailed analysis reveals that our proposed filter learns\nthe characteristic of head motions. The subjective evaluation shows that\nparticipants were unable to distinguish the synthesised head motions with our\nproposed filter from ground truth, which was preferred over the Gaussian filter\nand moving average.", "published": "2019-07-24 17:38:37", "link": "http://arxiv.org/abs/1907.10585v2", "categories": ["eess.SP", "cs.LG", "eess.AS"], "primary_category": "eess.SP"}
