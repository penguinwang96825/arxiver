{"title": "Attentive Recurrent Tensor Model for Community Question Answering", "abstract": "A major challenge to the problem of community question answering is the\nlexical and semantic gap between the sentence representations. Some solutions\nto minimize this gap includes the introduction of extra parameters to deep\nmodels or augmenting the external handcrafted features. In this paper, we\npropose a novel attentive recurrent tensor network for solving the lexical and\nsemantic gap in community question answering. We introduce token-level and\nphrase-level attention strategy that maps input sequences to the output using\ntrainable parameters. Further, we use the tensor parameters to introduce a\n3-way interaction between question, answer and external features in vector\nspace. We introduce simplified tensor matrices with L2 regularization that\nresults in smooth optimization during training. The proposed model achieves\nstate-of-the-art performance on the task of answer sentence selection (TrecQA\nand WikiQA datasets) while outperforming the current state-of-the-art on the\ntasks of best answer selection (Yahoo! L4) and answer triggering task (WikiQA).", "published": "2018-01-21 09:01:46", "link": "http://arxiv.org/abs/1801.06792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embedding Learning Through Multilingual Concept Induction", "abstract": "We present a new method for estimating vector space representations of words:\nembedding learning by concept induction. We test this method on a highly\nparallel corpus and learn semantic representations of words in 1259 different\nlanguages in a single common space. An extensive experimental evaluation on\ncrosslingual word similarity and sentiment analysis indicates that\nconcept-based multilingual embedding learning performs better than previous\napproaches.", "published": "2018-01-21 11:19:10", "link": "http://arxiv.org/abs/1801.06807v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Multi-task Learning in Automated Assessment", "abstract": "Grammatical error detection and automated essay scoring are two tasks in the\narea of automated assessment. Traditionally these tasks have been treated\nindependently with different machine learning models and features used for each\ntask. In this paper, we develop a multi-task neural network model that jointly\noptimises for both tasks, and in particular we show that neural automated essay\nscoring can be significantly improved. We show that while the essay score\nprovides little evidence to inform grammatical error detection, the essay score\nis highly influenced by error detection.", "published": "2018-01-21 14:38:23", "link": "http://arxiv.org/abs/1801.06830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Word Embeddings Evaluation Methods", "abstract": "Word embeddings are real-valued word representations able to capture lexical\nsemantics and trained on natural language corpora. Models proposing these\nrepresentations have gained popularity in the recent years, but the issue of\nthe most adequate evaluation method still remains open. This paper presents an\nextensive overview of the field of word embeddings evaluation, highlighting\nmain problems and proposing a typology of approaches to evaluation, summarizing\n16 intrinsic methods and 12 extrinsic methods. I describe both widely-used and\nexperimental methods, systematize information about evaluation datasets and\ndiscuss some key challenges.", "published": "2018-01-21 13:23:10", "link": "http://arxiv.org/abs/1801.09536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
