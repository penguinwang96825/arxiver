{"title": "Zero-Shot Classification by Logical Reasoning on Natural Language\n  Explanations", "abstract": "Humans can classify data of an unseen category by reasoning on its language\nexplanations. This ability is owing to the compositional nature of language: we\ncan combine previously seen attributes to describe the new category. For\nexample, we might describe a sage thrasher as \"it has a slim straight\nrelatively short bill, yellow eyes and a long tail\", so that others can use\ntheir knowledge of attributes \"slim straight relatively short bill\", \"yellow\neyes\" and \"long tail\" to recognize a sage thrasher. Inspired by this\nobservation, in this work we tackle zero-shot classification task by logically\nparsing and reasoning on natural language expla-nations. To this end, we\npropose the framework CLORE (Classification by LOgical Reasoning on\nExplanations). While previous methods usually regard textual information as\nimplicit features, CLORE parses explanations into logical structures and then\nexplicitly reasons along thess structures on the input to produce a\nclassification score. Experimental results on explanation-based zero-shot\nclassification benchmarks demonstrate that CLORE is superior to baselines,\nwhich we further show mainly comes from higher scores on tasks requiring more\nlogical reasoning. We also demonstrate that our framework can be extended to\nzero-shot classification on visual modality. Alongside classification\ndecisions, CLORE can provide the logical parsing and reasoning process as a\nclear form of rationale. Through empirical analysis we demonstrate that CLORE\nis also less affected by linguistic biases than baselines.", "published": "2022-11-07 01:05:11", "link": "http://arxiv.org/abs/2211.03252v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reconciliation of Pre-trained Models and Prototypical Neural Networks in\n  Few-shot Named Entity Recognition", "abstract": "Incorporating large-scale pre-trained models with the prototypical neural\nnetworks is a de-facto paradigm in few-shot named entity recognition. Existing\nmethods, unfortunately, are not aware of the fact that embeddings from\npre-trained models contain a prominently large amount of information regarding\nword frequencies, biasing prototypical neural networks against learning word\nentities. This discrepancy constrains the two models' synergy. Thus, we propose\na one-line-code normalization method to reconcile such a mismatch with\nempirical and theoretical grounds. Our experiments based on nine benchmark\ndatasets show the superiority of our method over the counterpart models and are\ncomparable to the state-of-the-art methods. In addition to the model\nenhancement, our work also provides an analytical viewpoint for addressing the\ngeneral problems in few-shot name entity recognition or other tasks that rely\non pre-trained models or prototypical neural networks.", "published": "2022-11-07 02:33:45", "link": "http://arxiv.org/abs/2211.03270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complex Reading Comprehension Through Question Decomposition", "abstract": "Multi-hop reading comprehension requires not only the ability to reason over\nraw text but also the ability to combine multiple evidence. We propose a novel\nlearning approach that helps language models better understand difficult\nmulti-hop questions and perform \"complex, compositional\" reasoning. Our model\nfirst learns to decompose each multi-hop question into several sub-questions by\na trainable question decomposer. Instead of answering these sub-questions, we\ndirectly concatenate them with the original question and context, and leverage\na reading comprehension model to predict the answer in a sequence-to-sequence\nmanner. By using the same language model for these two components, our best\nseperate/unified t5-base variants outperform the baseline by 7.2/6.1 absolute\nF1 points on a hard subset of DROP dataset.", "published": "2022-11-07 02:54:04", "link": "http://arxiv.org/abs/2211.03277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning enhanced Author-Style Headline Generation", "abstract": "Headline generation is a task of generating an appropriate headline for a\ngiven article, which can be further used for machine-aided writing or enhancing\nthe click-through ratio. Current works only use the article itself in the\ngeneration, but have not taken the writing style of headlines into\nconsideration. In this paper, we propose a novel Seq2Seq model called CLH3G\n(Contrastive Learning enhanced Historical Headlines based Headline Generation)\nwhich can use the historical headlines of the articles that the author wrote in\nthe past to improve the headline generation of current articles. By taking\nhistorical headlines into account, we can integrate the stylistic features of\nthe author into our model, and generate a headline not only appropriate for the\narticle, but also consistent with the author's style. In order to efficiently\nlearn the stylistic features of the author, we further introduce a contrastive\nlearning based auxiliary task for the encoder of our model. Besides, we propose\ntwo methods to use the learned stylistic features to guide both the pointer and\nthe decoder during the generation. Experimental results show that historical\nheadlines of the same user can improve the headline generation significantly,\nand both the contrastive learning module and the two style features fusion\nmethods can further boost the performance.", "published": "2022-11-07 04:51:03", "link": "http://arxiv.org/abs/2211.03305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fixing Model Bugs with Natural Language Patches", "abstract": "Current approaches for fixing systematic problems in NLP models (e.g. regex\npatches, finetuning on more data) are either brittle, or labor-intensive and\nliable to shortcuts. In contrast, humans often provide corrections to each\nother through natural language. Taking inspiration from this, we explore\nnatural language patches -- declarative statements that allow developers to\nprovide corrective feedback at the right level of abstraction, either\noverriding the model (``if a review gives 2 stars, the sentiment is negative'')\nor providing additional information the model may lack (``if something is\ndescribed as the bomb, then it is good''). We model the task of determining if\na patch applies separately from the task of integrating patch information, and\nshow that with a small amount of synthetic data, we can teach models to\neffectively use real patches on real data -- 1 to 7 patches improve accuracy by\n~1-4 accuracy points on different slices of a sentiment analysis dataset, and\nF1 by 7 points on a relation extraction dataset. Finally, we show that\nfinetuning on as many as 100 labeled examples may be needed to match the\nperformance of a small set of language patches.", "published": "2022-11-07 05:49:19", "link": "http://arxiv.org/abs/2211.03318v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for\n  Unsupervised Sentence Embedding", "abstract": "Contrastive learning has become a new paradigm for unsupervised sentence\nembeddings. Previous studies focus on instance-wise contrastive learning,\nattempting to construct positive pairs with textual data augmentation. In this\npaper, we propose a novel Contrastive learning method with Prompt-derived\nVirtual semantic Prototypes (ConPVP). Specifically, with the help of prompts,\nwe construct virtual semantic prototypes to each instance, and derive negative\nprototypes by using the negative form of the prompts. Using a prototypical\ncontrastive loss, we enforce the anchor sentence embedding to be close to its\ncorresponding semantic prototypes, and far apart from the negative prototypes\nas well as the prototypes of other sentences. Extensive experimental results on\nsemantic textual similarity, transfer, and clustering tasks demonstrate the\neffectiveness of our proposed model compared to strong baselines. Code is\navailable at https://github.com/lemon0830/promptCSE.", "published": "2022-11-07 07:50:30", "link": "http://arxiv.org/abs/2211.03348v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual\n  Question Answering", "abstract": "Hybrid tabular-textual question answering (QA) requires reasoning from\nheterogeneous information, and the types of reasoning are mainly divided into\nnumerical reasoning and span extraction. Current numerical reasoning methods\nautoregressively decode program sequences, and each decoding step produces\neither an operator or an operand. However, the step-by-step decoding suffers\nfrom exposure bias, and the accuracy of program generation drops sharply as the\ndecoding steps unfold due to error propagation. In this paper, we propose a\nnon-autoregressive program generation framework, which independently generates\ncomplete program tuples containing both operators and operands, can address the\nerror propagation issue while significantly boosting the speed of program\ngeneration. Experiments on the ConvFinQA and MultiHiertt datasets show that our\nnon-autoregressive program generation method can bring about substantial\nimprovements over the strong FinQANet (+5.06 Exe Acc and +4.80 Prog Acc points)\nand MT2Net (+7.97 EM and +6.38 F1 points) baselines, establishing the new\nstate-of-the-art performance, while being much faster (21x) in program\ngeneration. Finally, with increasing numbers of numerical reasoning steps the\nperformance drop of our method is significantly smaller than that of the\nbaselines. Our code will be publicly available soon.", "published": "2022-11-07 11:25:21", "link": "http://arxiv.org/abs/2211.03462v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Deep Mixture-of-Experts to Detect Word Meaning Shift for TempoWiC", "abstract": "This paper mainly describes the dma submission to the TempoWiC task, which\nachieves a macro-F1 score of 77.05% and attains the first place in this task.\nWe first explore the impact of different pre-trained language models. Then we\nadopt data cleaning, data augmentation, and adversarial training strategies to\nenhance the model generalization and robustness. For further improvement, we\nintegrate POS information and word semantic representation using a\nMixture-of-Experts (MoE) approach. The experimental results show that MoE can\novercome the feature overuse issue and combine the context, POS, and word\nsemantic features well. Additionally, we use a model ensemble method for the\nfinal prediction, which has been proven effective by many research works.", "published": "2022-11-07 11:28:34", "link": "http://arxiv.org/abs/2211.03466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Transformers for Design Concept Generation", "abstract": "Generating novel and useful concepts is essential during the early design\nstage to explore a large variety of design opportunities, which usually\nrequires advanced design thinking ability and a wide range of knowledge from\ndesigners. Growing works on computer-aided tools have explored the retrieval of\nknowledge and heuristics from design data. However, they only provide stimuli\nto inspire designers from limited aspects. This study explores the recent\nadvance of the natural language generation (NLG) technique in the artificial\nintelligence (AI) field to automate the early-stage design concept generation.\nSpecifically, a novel approach utilizing the generative pre-trained transformer\n(GPT) is proposed to leverage the knowledge and reasoning from textual data and\ntransform them into new concepts in understandable language. Three concept\ngeneration tasks are defined to leverage different knowledge and reasoning:\ndomain knowledge synthesis, problem-driven synthesis, and analogy-driven\nsynthesis. The experiments with both human and data-driven evaluation show good\nperformance in generating novel and useful concepts.", "published": "2022-11-07 11:29:10", "link": "http://arxiv.org/abs/2211.03468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Transformer-based Multitask Learning for the Detection of\n  Media Bias in News Articles", "abstract": "Media has a substantial impact on the public perception of events. A\none-sided or polarizing perspective on any topic is usually described as media\nbias. One of the ways how bias in news articles can be introduced is by\naltering word choice. Biased word choices are not always obvious, nor do they\nexhibit high context-dependency. Hence, detecting bias is often difficult. We\npropose a Transformer-based deep learning architecture trained via Multi-Task\nLearning using six bias-related data sets to tackle the media bias detection\nproblem. Our best-performing implementation achieves a macro $F_{1}$ of 0.776,\na performance boost of 3\\% compared to our baseline, outperforming existing\nmethods. Our results indicate Multi-Task Learning as a promising alternative to\nimprove existing baseline models in identifying slanted reporting.", "published": "2022-11-07 12:22:31", "link": "http://arxiv.org/abs/2211.03491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Evaluation of a Spoken Dialogue System for Learning Basic\n  Mathematics", "abstract": "The advances in language-based Artificial Intelligence (AI) technologies\napplied to build educational applications can present AI for social-good\nopportunities with a broader positive impact. Across many disciplines,\nenhancing the quality of mathematics education is crucial in building critical\nthinking and problem-solving skills at younger ages. Conversational AI systems\nhave started maturing to a point where they could play a significant role in\nhelping students learn fundamental math concepts. This work presents a\ntask-oriented Spoken Dialogue System (SDS) built to support play-based learning\nof basic math concepts for early childhood education. The system has been\nevaluated via real-world deployments at school while the students are\npracticing early math concepts with multimodal interactions. We discuss our\nefforts to improve the SDS pipeline built for math learning, for which we\nexplore utilizing MathBERT representations for potential enhancement to the\nNatural Language Understanding (NLU) module. We perform an end-to-end\nevaluation using real-world deployment outputs from the Automatic Speech\nRecognition (ASR), Intent Recognition, and Dialogue Manager (DM) components to\nunderstand how error propagation affects the overall performance in real-world\nscenarios.", "published": "2022-11-07 12:58:24", "link": "http://arxiv.org/abs/2211.03511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Contrastive Learning on Multimodal Transformer for Review\n  Helpfulness Predictions", "abstract": "Modern Review Helpfulness Prediction systems are dependent upon multiple\nmodalities, typically texts and images. Unfortunately, those contemporary\napproaches pay scarce attention to polish representations of cross-modal\nrelations and tend to suffer from inferior optimization. This might cause harm\nto model's predictions in numerous cases. To overcome the aforementioned\nissues, we propose Multimodal Contrastive Learning for Multimodal Review\nHelpfulness Prediction (MRHP) problem, concentrating on mutual information\nbetween input modalities to explicitly elaborate cross-modal relations. In\naddition, we introduce Adaptive Weighting scheme for our contrastive learning\napproach in order to increase flexibility in optimization. Lastly, we propose\nMultimodal Interaction module to address the unalignment nature of multimodal\ndata, thereby assisting the model in producing more reasonable multimodal\nrepresentations. Experimental results show that our method outperforms prior\nbaselines and achieves state-of-the-art results on two publicly available\nbenchmark datasets for MRHP problem.", "published": "2022-11-07 13:05:56", "link": "http://arxiv.org/abs/2211.03524v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-task Model for Sentiment Aided Stance Detection of Climate\n  Change Tweets", "abstract": "Climate change has become one of the biggest challenges of our time. Social\nmedia platforms such as Twitter play an important role in raising public\nawareness and spreading knowledge about the dangers of the current climate\ncrisis. With the increasing number of campaigns and communication about climate\nchange through social media, the information could create more awareness and\nreach the general public and policy makers. However, these Twitter\ncommunications lead to polarization of beliefs, opinion-dominated ideologies,\nand often a split into two communities of climate change deniers and believers.\nIn this paper, we propose a framework that helps identify denier statements on\nTwitter and thus classifies the stance of the tweet into one of the two\nattitudes towards climate change (denier/believer). The sentimental aspects of\nTwitter data on climate change are deeply rooted in general public attitudes\ntoward climate change. Therefore, our work focuses on learning two closely\nrelated tasks: Stance Detection and Sentiment Analysis of climate change\ntweets. We propose a multi-task framework that performs stance detection\n(primary task) and sentiment analysis (auxiliary task) simultaneously. The\nproposed model incorporates the feature-specific and shared-specific attention\nframeworks to fuse multiple features and learn the generalized features for\nboth tasks. The experimental results show that the proposed framework increases\nthe performance of the primary task, i.e., stance detection by benefiting from\nthe auxiliary task, i.e., sentiment analysis compared to its uni-modal and\nsingle-task variants.", "published": "2022-11-07 13:19:44", "link": "http://arxiv.org/abs/2211.03533v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "No Word Embedding Model Is Perfect: Evaluating the Representation\n  Accuracy for Social Bias in the Media", "abstract": "News articles both shape and reflect public opinion across the political\nspectrum. Analyzing them for social bias can thus provide valuable insights,\nsuch as prevailing stereotypes in society and the media, which are often\nadopted by NLP models trained on respective data. Recent work has relied on\nword embedding bias measures, such as WEAT. However, several representation\nissues of embeddings can harm the measures' accuracy, including low-resource\nsettings and token frequency differences. In this work, we study what kind of\nembedding algorithm serves best to accurately measure types of social bias\nknown to exist in US online news articles. To cover the whole spectrum of\npolitical bias in the US, we collect 500k articles and review psychology\nliterature with respect to expected social bias. We then quantify social bias\nusing WEAT along with embedding algorithms that account for the aforementioned\nissues. We compare how models trained with the algorithms on news articles\nrepresent the expected social bias. Our results suggest that the standard way\nto quantify bias does not align well with knowledge from psychology. While the\nproposed algorithms reduce the~gap, they still do not fully match the\nliterature.", "published": "2022-11-07 15:45:52", "link": "http://arxiv.org/abs/2211.03634v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reranking Overgenerated Responses for End-to-End Task-Oriented Dialogue\n  Systems", "abstract": "End-to-end (E2E) task-oriented dialogue (ToD) systems are prone to fall into\nthe so-called \"likelihood trap\", resulting in generated responses which are\ndull, repetitive, and often inconsistent with dialogue history. Comparing\nranked lists of multiple generated responses against the \"gold response\" (from\nevaluation data) reveals a wide diversity in response quality, with many good\nresponses placed lower in the ranked list. The main challenge, addressed in\nthis work, is then how to reach beyond greedily generated system responses,\nthat is, how to obtain and select such high-quality responses from the list of\novergenerated responses at inference without availability of the gold response.\nTo this end, we propose a simple yet effective reranking method which aims to\nselect high-quality items from the lists of responses initially overgenerated\nby the system. The idea is to use any sequence-level (similarity) scoring\nfunction to divide the semantic space of responses into high-scoring versus\nlow-scoring partitions. At training, the high-scoring partition comprises all\ngenerated responses whose similarity to the gold response is higher than the\nsimilarity of the greedy response to the gold response. At inference, the aim\nis to estimate the probability that each overgenerated response belongs to the\nhigh-scoring partition, given only previous dialogue history. We validate the\nrobustness and versatility of our proposed method on the standard MultiWOZ\ndataset: our methods improve a state-of-the-art E2E ToD system by 2.0 BLEU, 1.6\nROUGE, and 1.3 METEOR scores, achieving new peak results. Additional\nexperiments on the BiTOD dataset and human evaluation further ascertain the\ngeneralisability and effectiveness of the proposed framework.", "published": "2022-11-07 15:59:49", "link": "http://arxiv.org/abs/2211.03648v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DPCSpell: A Transformer-based Detector-Purificator-Corrector Framework\n  for Spelling Error Correction of Bangla and Resource Scarce Indic Languages", "abstract": "Spelling error correction is the task of identifying and rectifying\nmisspelled words in texts. It is a potential and active research topic in\nNatural Language Processing because of numerous applications in human language\nunderstanding. The phonetically or visually similar yet semantically distinct\ncharacters make it an arduous task in any language. Earlier efforts on spelling\nerror correction in Bangla and resource-scarce Indic languages focused on\nrule-based, statistical, and machine learning-based methods which we found\nrather inefficient. In particular, machine learning-based approaches, which\nexhibit superior performance to rule-based and statistical methods, are\nineffective as they correct each character regardless of its appropriateness.\nIn this paper, we propose a novel detector-purificator-corrector framework,\nDPCSpell based on denoising transformers by addressing previous issues. In\naddition to that, we present a method for large-scale corpus creation from\nscratch which in turn resolves the resource limitation problem of any\nleft-to-right scripted language. The empirical outcomes demonstrate the\neffectiveness of our approach, which outperforms previous state-of-the-art\nmethods by attaining an exact match (EM) score of 94.78%, a precision score of\n0.9487, a recall score of 0.9478, an f1 score of 0.948, an f0.5 score of\n0.9483, and a modified accuracy (MA) score of 95.16% for Bangla spelling error\ncorrection. The models and corpus are publicly available at\nhttps://tinyurl.com/DPCSpell.", "published": "2022-11-07 17:59:05", "link": "http://arxiv.org/abs/2211.03730v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval augmentation of large language models for lay language\n  generation", "abstract": "Recent lay language generation systems have used Transformer models trained\non a parallel corpus to increase health information accessibility. However, the\napplicability of these models is constrained by the limited size and topical\nbreadth of available corpora. We introduce CELLS, the largest (63k pairs) and\nbroadest-ranging (12 journals) parallel corpus for lay language generation. The\nabstract and the corresponding lay language summary are written by domain\nexperts, assuring the quality of our dataset. Furthermore, qualitative\nevaluation of expert-authored plain language summaries has revealed background\nexplanation as a key strategy to increase accessibility. Such explanation is\nchallenging for neural models to generate because it goes beyond simplification\nby adding content absent from the source. We derive two specialized paired\ncorpora from CELLS to address key challenges in lay language generation:\ngenerating background explanations and simplifying the original abstract. We\nadopt retrieval-augmented models as an intuitive fit for the task of background\nexplanation generation, and show improvements in summary quality and simplicity\nwhile maintaining factual correctness. Taken together, this work presents the\nfirst comprehensive study of background explanation for lay language\ngeneration, paving the path for disseminating scientific knowledge to a broader\naudience. CELLS is publicly available at:\nhttps://github.com/LinguisticAnomalies/pls_retrieval.", "published": "2022-11-07 19:06:53", "link": "http://arxiv.org/abs/2211.03818v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AX-MABSA: A Framework for Extremely Weakly Supervised Multi-label Aspect\n  Based Sentiment Analysis", "abstract": "Aspect Based Sentiment Analysis is a dominant research area with potential\napplications in social media analytics, business, finance, and health. Prior\nworks in this area are primarily based on supervised methods, with a few\ntechniques using weak supervision limited to predicting a single aspect\ncategory per review sentence. In this paper, we present an extremely weakly\nsupervised multi-label Aspect Category Sentiment Analysis framework which does\nnot use any labelled data. We only rely on a single word per class as an\ninitial indicative information. We further propose an automatic word selection\ntechnique to choose these seed categories and sentiment words. We explore\nunsupervised language model post-training to improve the overall performance,\nand propose a multi-label generator model to generate multiple aspect\ncategory-sentiment pairs per review sentence. Experiments conducted on four\nbenchmark datasets showcase our method to outperform other weakly supervised\nbaselines by a significant margin.", "published": "2022-11-07 19:44:42", "link": "http://arxiv.org/abs/2211.03837v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Looking at the Overlooked: An Analysis on the Word-Overlap Bias in\n  Natural Language Inference", "abstract": "It has been shown that NLI models are usually biased with respect to the\nword-overlap between premise and hypothesis; they take this feature as a\nprimary cue for predicting the entailment label. In this paper, we focus on an\noverlooked aspect of the overlap bias in NLI models: the reverse word-overlap\nbias. Our experimental results demonstrate that current NLI models are highly\nbiased towards the non-entailment label on instances with low overlap, and the\nexisting debiasing methods, which are reportedly successful on existing\nchallenge datasets, are generally ineffective in addressing this category of\nbias. We investigate the reasons for the emergence of the overlap bias and the\nrole of minority examples in its mitigation. For the former, we find that the\nword-overlap bias does not stem from pre-training, and for the latter, we\nobserve that in contrast to the accepted assumption, eliminating minority\nexamples does not affect the generalizability of debiasing methods with respect\nto the overlap bias.", "published": "2022-11-07 21:02:23", "link": "http://arxiv.org/abs/2211.03862v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLOP: Video-and-Language Pre-Training with Knowledge Regularizations", "abstract": "Video-and-language pre-training has shown promising results for learning\ngeneralizable representations. Most existing approaches usually model video and\ntext in an implicit manner, without considering explicit structural\nrepresentations of the multi-modal content. We denote such form of\nrepresentations as structural knowledge, which express rich semantics of\nmultiple granularities. There are related works that propose object-aware\napproaches to inject similar knowledge as inputs. However, the existing methods\nusually fail to effectively utilize such knowledge as regularizations to shape\na superior cross-modal representation space. To this end, we propose a\nCross-modaL knOwledge-enhanced Pre-training (CLOP) method with Knowledge\nRegularizations. There are two key designs of ours: 1) a simple yet effective\nStructural Knowledge Prediction (SKP) task to pull together the latent\nrepresentations of similar videos; and 2) a novel Knowledge-guided sampling\napproach for Contrastive Learning (KCL) to push apart cross-modal hard negative\nsamples. We evaluate our method on four text-video retrieval tasks and one\nmulti-choice QA task. The experiments show clear improvements, outperforming\nprior works by a substantial margin. Besides, we provide ablations and insights\nof how our methods affect the latent representation space, demonstrating the\nvalue of incorporating knowledge regularizations into video-and-language\npre-training.", "published": "2022-11-07 05:32:12", "link": "http://arxiv.org/abs/2211.03314v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Probing neural language models for understanding of words of estimative\n  probability", "abstract": "Words of estimative probability (WEP) are expressions of a statement's\nplausibility (probably, maybe, likely, doubt, likely, unlikely, impossible...).\nMultiple surveys demonstrate the agreement of human evaluators when assigning\nnumerical probability levels to WEP. For example, highly likely corresponds to\na median chance of 0.90+-0.08 in Fagen-Ulmschneider (2015)'s survey. In this\nwork, we measure the ability of neural language processing models to capture\nthe consensual probability level associated to each WEP. Firstly, we use the\nUNLI dataset (Chen et al., 2020) which associates premises and hypotheses with\ntheir perceived joint probability p, to construct prompts, e.g. \"[PREMISE].\n[WEP], [HYPOTHESIS].\" and assess whether language models can predict whether\nthe WEP consensual probability level is close to p. Secondly, we construct a\ndataset of WEP-based probabilistic reasoning, to test whether language models\ncan reason with WEP compositions. When prompted \"[EVENTA] is likely. [EVENTB]\nis impossible.\", a causal language model should not express that [EVENTA&B] is\nlikely. We show that both tasks are unsolved by off-the-shelf English language\nmodels, but that fine-tuning leads to transferable improvement.", "published": "2022-11-07 08:29:11", "link": "http://arxiv.org/abs/2211.03358v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Human-Machine Collaboration Approaches to Build a Dialogue Dataset for\n  Hate Speech Countering", "abstract": "Fighting online hate speech is a challenge that is usually addressed using\nNatural Language Processing via automatic detection and removal of hate\ncontent. Besides this approach, counter narratives have emerged as an effective\ntool employed by NGOs to respond to online hate on social media platforms. For\nthis reason, Natural Language Generation is currently being studied as a way to\nautomatize counter narrative writing. However, the existing resources necessary\nto train NLG models are limited to 2-turn interactions (a hate speech and a\ncounter narrative as response), while in real life, interactions can consist of\nmultiple turns. In this paper, we present a hybrid approach for dialogical data\ncollection, which combines the intervention of human expert annotators over\nmachine generated dialogues obtained using 19 different configurations. The\nresult of this work is DIALOCONAN, the first dataset comprising over 3000\nfictitious multi-turn dialogues between a hater and an NGO operator, covering 6\ntargets of hate.", "published": "2022-11-07 10:37:13", "link": "http://arxiv.org/abs/2211.03433v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition in Indian court judgments", "abstract": "Identification of named entities from legal texts is an essential building\nblock for developing other legal Artificial Intelligence applications. Named\nEntities in legal texts are slightly different and more fine-grained than\ncommonly used named entities like Person, Organization, Location etc. In this\npaper, we introduce a new corpus of 46545 annotated legal named entities mapped\nto 14 legal entity types. The Baseline model for extracting legal named\nentities from judgment text is also developed.", "published": "2022-11-07 10:44:44", "link": "http://arxiv.org/abs/2211.03442v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Much Does Attention Actually Attend? Questioning the Importance of\n  Attention in Pretrained Transformers", "abstract": "The attention mechanism is considered the backbone of the widely-used\nTransformer architecture. It contextualizes the input by computing\ninput-specific attention matrices. We find that this mechanism, while powerful\nand elegant, is not as important as typically thought for pretrained language\nmodels. We introduce PAPA, a new probing method that replaces the\ninput-dependent attention matrices with constant ones -- the average attention\nweights over multiple inputs. We use PAPA to analyze several established\npretrained Transformers on six downstream tasks. We find that without any\ninput-dependent attention, all models achieve competitive performance -- an\naverage relative drop of only 8% from the probing baseline. Further, little or\nno performance drop is observed when replacing half of the input-dependent\nattention matrices with constant (input-independent) ones. Interestingly, we\nshow that better-performing models lose more from applying our method than\nweaker models, suggesting that the utilization of the input-dependent attention\nmechanism might be a factor in their success. Our results motivate research on\nsimpler alternatives to input-dependent attention, as well as on methods for\nbetter utilization of this mechanism in the Transformer architecture.", "published": "2022-11-07 12:37:54", "link": "http://arxiv.org/abs/2211.03495v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Semantic Textual Similarity via Topic-informed Discrete Latent\n  Variables", "abstract": "Recently, discrete latent variable models have received a surge of interest\nin both Natural Language Processing (NLP) and Computer Vision (CV), attributed\nto their comparable performance to the continuous counterparts in\nrepresentation learning, while being more interpretable in their predictions.\nIn this paper, we develop a topic-informed discrete latent variable model for\nsemantic textual similarity, which learns a shared latent space for\nsentence-pair representation via vector quantization. Compared with previous\nmodels limited to local semantic contexts, our model can explore richer\nsemantic information via topic modeling. We further boost the performance of\nsemantic similarity by injecting the quantized representation into a\ntransformer-based language model with a well-designed semantic-driven attention\nmechanism. We demonstrate, through extensive experiments across various English\nlanguage datasets, that our model is able to surpass several strong neural\nbaselines in semantic textual similarity tasks.", "published": "2022-11-07 15:09:58", "link": "http://arxiv.org/abs/2211.03616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Streaming, fast and accurate on-device Inverse Text Normalization for\n  Automatic Speech Recognition", "abstract": "Automatic Speech Recognition (ASR) systems typically yield output in lexical\nform. However, humans prefer a written form output. To bridge this gap, ASR\nsystems usually employ Inverse Text Normalization (ITN).\n  In previous works, Weighted Finite State Transducers (WFST) have been\nemployed to do ITN. WFSTs are nicely suited to this task but their size and\nrun-time costs can make deployment on embedded applications challenging.\n  In this paper, we describe the development of an on-device ITN system that is\nstreaming, lightweight & accurate. At the core of our system is a streaming\ntransformer tagger, that tags lexical tokens from ASR. The tag informs which\nITN category might be applied, if at all. Following that, we apply an\nITN-category-specific WFST, only on the tagged text, to reliably perform the\nITN conversion. We show that the proposed ITN solution performs equivalent to\nstrong baselines, while being significantly smaller in size and retaining\ncustomization capabilities.", "published": "2022-11-07 17:48:54", "link": "http://arxiv.org/abs/2211.03721v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Easily Accessible Text-to-Image Generation Amplifies Demographic\n  Stereotypes at Large Scale", "abstract": "Machine learning models that convert user-written text descriptions into\nimages are now widely available online and used by millions of users to\ngenerate millions of images a day. We investigate the potential for these\nmodels to amplify dangerous and complex stereotypes. We find a broad range of\nordinary prompts produce stereotypes, including prompts simply mentioning\ntraits, descriptors, occupations, or objects. For example, we find cases of\nprompting for basic traits or social roles resulting in images reinforcing\nwhiteness as ideal, prompting for occupations resulting in amplification of\nracial and gender disparities, and prompting for objects resulting in\nreification of American norms. Stereotypes are present regardless of whether\nprompts explicitly mention identity and demographic language or avoid such\nlanguage. Moreover, stereotypes persist despite mitigation strategies; neither\nuser attempts to counter stereotypes by requesting images with specific\ncounter-stereotypes nor institutional attempts to add system ``guardrails''\nhave prevented the perpetuation of stereotypes. Our analysis justifies concerns\nregarding the impacts of today's models, presenting striking exemplars, and\nconnecting these findings with deep insights into harms drawn from social\nscientific and humanist disciplines. This work contributes to the effort to\nshed light on the uniquely complex biases in language-vision models and\ndemonstrates the ways that the mass deployment of text-to-image generation\nmodels results in mass dissemination of stereotypes and resulting harms.", "published": "2022-11-07 18:31:07", "link": "http://arxiv.org/abs/2211.03759v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "CRIPP-VQA: Counterfactual Reasoning about Implicit Physical Properties\n  via Video Question Answering", "abstract": "Videos often capture objects, their visible properties, their motion, and the\ninteractions between different objects. Objects also have physical properties\nsuch as mass, which the imaging pipeline is unable to directly capture.\nHowever, these properties can be estimated by utilizing cues from relative\nobject motion and the dynamics introduced by collisions. In this paper, we\nintroduce CRIPP-VQA, a new video question answering dataset for reasoning about\nthe implicit physical properties of objects in a scene. CRIPP-VQA contains\nvideos of objects in motion, annotated with questions that involve\ncounterfactual reasoning about the effect of actions, questions about planning\nin order to reach a goal, and descriptive questions about visible properties of\nobjects. The CRIPP-VQA test set enables evaluation under several\nout-of-distribution settings -- videos with objects with masses, coefficients\nof friction, and initial velocities that are not observed in the training\ndistribution. Our experiments reveal a surprising and significant performance\ngap in terms of answering questions about implicit properties (the focus of\nthis paper) and explicit properties of objects (the focus of prior work).", "published": "2022-11-07 18:55:26", "link": "http://arxiv.org/abs/2211.03779v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AD-BERT: Using Pre-trained contextualized embeddings to Predict the\n  Progression from Mild Cognitive Impairment to Alzheimer's Disease", "abstract": "Objective: We develop a deep learning framework based on the pre-trained\nBidirectional Encoder Representations from Transformers (BERT) model using\nunstructured clinical notes from electronic health records (EHRs) to predict\nthe risk of disease progression from Mild Cognitive Impairment (MCI) to\nAlzheimer's Disease (AD). Materials and Methods: We identified 3657 patients\ndiagnosed with MCI together with their progress notes from Northwestern\nMedicine Enterprise Data Warehouse (NMEDW) between 2000-2020. The progress\nnotes no later than the first MCI diagnosis were used for the prediction. We\nfirst preprocessed the notes by deidentification, cleaning and splitting, and\nthen pretrained a BERT model for AD (AD-BERT) based on the publicly available\nBio+Clinical BERT on the preprocessed notes. The embeddings of all the sections\nof a patient's notes processed by AD-BERT were combined by MaxPooling to\ncompute the probability of MCI-to-AD progression. For replication, we conducted\na similar set of experiments on 2563 MCI patients identified at Weill Cornell\nMedicine (WCM) during the same timeframe. Results: Compared with the 7 baseline\nmodels, the AD-BERT model achieved the best performance on both datasets, with\nArea Under receiver operating characteristic Curve (AUC) of 0.8170 and F1 score\nof 0.4178 on NMEDW dataset and AUC of 0.8830 and F1 score of 0.6836 on WCM\ndataset. Conclusion: We developed a deep learning framework using BERT models\nwhich provide an effective solution for prediction of MCI-to-AD progression\nusing clinical note analysis.", "published": "2022-11-07 04:05:46", "link": "http://arxiv.org/abs/2212.06042v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AfroLM: A Self-Active Learning-based Multilingual Pretrained Language\n  Model for 23 African Languages", "abstract": "In recent years, multilingual pre-trained language models have gained\nprominence due to their remarkable performance on numerous downstream Natural\nLanguage Processing tasks (NLP). However, pre-training these large multilingual\nlanguage models requires a lot of training data, which is not available for\nAfrican Languages. Active learning is a semi-supervised learning algorithm, in\nwhich a model consistently and dynamically learns to identify the most\nbeneficial samples to train itself on, in order to achieve better optimization\nand performance on downstream tasks. Furthermore, active learning effectively\nand practically addresses real-world data scarcity. Despite all its benefits,\nactive learning, in the context of NLP and especially multilingual language\nmodels pretraining, has received little consideration. In this paper, we\npresent AfroLM, a multilingual language model pretrained from scratch on 23\nAfrican languages (the largest effort to date) using our novel self-active\nlearning framework. Pretrained on a dataset significantly (14x) smaller than\nexisting baselines, AfroLM outperforms many multilingual pretrained language\nmodels (AfriBERTa, XLMR-base, mBERT) on various NLP downstream tasks (NER, text\nclassification, and sentiment analysis). Additional out-of-domain sentiment\nanalysis experiments show that \\textbf{AfroLM} is able to generalize well\nacross various domains. We release the code source, and our datasets used in\nour framework at https://github.com/bonaventuredossou/MLM_AL.", "published": "2022-11-07 02:15:25", "link": "http://arxiv.org/abs/2211.03263v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Embedding: A Survey from the Perspective of\n  Representation Spaces", "abstract": "Knowledge graph embedding (KGE) is an increasingly popular technique that\naims to represent entities and relations of knowledge graphs into\nlow-dimensional semantic spaces for a wide spectrum of applications such as\nlink prediction, knowledge reasoning and knowledge completion. In this paper,\nwe provide a systematic review of existing KGE techniques based on\nrepresentation spaces. Particularly, we build a fine-grained classification to\ncategorise the models based on three mathematical perspectives of the\nrepresentation spaces: (1) Algebraic perspective, (2) Geometric perspective,\nand (3) Analytical perspective. We introduce the rigorous definitions of\nfundamental mathematical spaces before diving into KGE models and their\nmathematical properties. We further discuss different KGE methods over the\nthree categories, as well as summarise how spatial advantages work over\ndifferent embedding needs. By collating the experimental results from\ndownstream tasks, we also explore the advantages of mathematical space in\ndifferent scenarios and the reasons behind them. We further state some\npromising research directions from a representation space perspective, with\nwhich we hope to inspire researchers to design their KGE models as well as\ntheir related applications with more consideration of their mathematical space\nproperties.", "published": "2022-11-07 13:22:28", "link": "http://arxiv.org/abs/2211.03536v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "ERNIE-SAT: Speech and Text Joint Pretraining for Cross-Lingual\n  Multi-Speaker Text-to-Speech", "abstract": "Speech representation learning has improved both speech understanding and\nspeech synthesis tasks for single language. However, its ability in\ncross-lingual scenarios has not been explored. In this paper, we extend the\npretraining method for cross-lingual multi-speaker speech synthesis tasks,\nincluding cross-lingual multi-speaker voice cloning and cross-lingual\nmulti-speaker speech editing. We propose a speech-text joint pretraining\nframework, where we randomly mask the spectrogram and the phonemes given a\nspeech example and its transcription. By learning to reconstruct the masked\nparts of the input in different languages, our model shows great improvements\nover speaker-embedding-based multi-speaker TTS methods. Moreover, our framework\nis end-to-end for both the training and the inference without any finetuning\neffort. In cross-lingual multi-speaker voice cloning and cross-lingual\nmulti-speaker speech editing tasks, our experiments show that our model\noutperforms speaker-embedding-based multi-speaker TTS methods.", "published": "2022-11-07 13:35:16", "link": "http://arxiv.org/abs/2211.03545v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Egocentric Audio-Visual Noise Suppression", "abstract": "This paper studies audio-visual noise suppression for egocentric videos --\nwhere the speaker is not captured in the video. Instead, potential noise\nsources are visible on screen with the camera emulating the off-screen\nspeaker's view of the outside world. This setting is different from prior work\nin audio-visual speech enhancement that relies on lip and facial visuals. In\nthis paper, we first demonstrate that egocentric visual information is helpful\nfor noise suppression. We compare object recognition and action\nclassification-based visual feature extractors and investigate methods to align\naudio and visual representations. Then, we examine different fusion strategies\nfor the aligned features, and locations within the noise suppression model to\nincorporate visual information. Experiments demonstrate that visual features\nare most helpful when used to generate additive correction masks. Finally, in\norder to ensure that the visual features are discriminative with respect to\ndifferent noise types, we introduce a multi-task learning framework that\njointly optimizes audio-visual noise suppression and video-based acoustic event\ndetection. This proposed multi-task framework outperforms the audio-only\nbaseline on all metrics, including a 0.16 PESQ improvement. Extensive ablations\nreveal the improved performance of the proposed model with multiple active\ndistractors, overall noise types, and across different SNRs.", "published": "2022-11-07 15:53:12", "link": "http://arxiv.org/abs/2211.03643v2", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Task Learning Framework for Extracting Emotion Cause Span and\n  Entailment in Conversations", "abstract": "Predicting emotions expressed in text is a well-studied problem in the NLP\ncommunity. Recently there has been active research in extracting the cause of\nan emotion expressed in text. Most of the previous work has done causal emotion\nentailment in documents. In this work, we propose neural models to extract\nemotion cause span and entailment in conversations. For learning such models,\nwe use RECCON dataset, which is annotated with cause spans at the utterance\nlevel. In particular, we propose MuTEC, an end-to-end Multi-Task learning\nframework for extracting emotions, emotion cause, and entailment in\nconversations. This is in contrast to existing baseline models that use ground\ntruth emotions to extract the cause. MuTEC performs better than the baselines\nfor most of the data folds provided in the dataset.", "published": "2022-11-07 18:14:45", "link": "http://arxiv.org/abs/2211.03742v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Fairness Disparities in Peer Review: A Language Model\n  Enhanced Approach", "abstract": "Double-blind peer review mechanism has become the skeleton of academic\nresearch across multiple disciplines including computer science, yet several\nstudies have questioned the quality of peer reviews and raised concerns on\npotential biases in the process. In this paper, we conduct a thorough and\nrigorous study on fairness disparities in peer review with the help of large\nlanguage models (LMs). We collect, assemble, and maintain a comprehensive\nrelational database for the International Conference on Learning\nRepresentations (ICLR) conference from 2017 to date by aggregating data from\nOpenReview, Google Scholar, arXiv, and CSRanking, and extracting high-level\nfeatures using language models. We postulate and study fairness disparities on\nmultiple protective attributes of interest, including author gender, geography,\nauthor, and institutional prestige. We observe that the level of disparity\ndiffers and textual features are essential in reducing biases in the predictive\nmodeling. We distill several insights from our analysis on study the peer\nreview process with the help of large LMs. Our database also provides avenues\nfor studying new natural language processing (NLP) methods that facilitate the\nunderstanding of the peer review mechanism. We study a concrete example towards\nautomatic machine review systems and provide baseline models for the review\ngeneration and scoring tasks such that the database can be used as a benchmark.", "published": "2022-11-07 16:19:42", "link": "http://arxiv.org/abs/2211.06398v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "A Context-Aware Computational Approach for Measuring Vocal Entrainment\n  in Dyadic Conversations", "abstract": "Vocal entrainment is a social adaptation mechanism in human interaction,\nknowledge of which can offer useful insights to an individual's\ncognitive-behavioral characteristics. We propose a context-aware approach for\nmeasuring vocal entrainment in dyadic conversations. We use conformers(a\ncombination of convolutional network and transformer) for capturing both\nshort-term and long-term conversational context to model entrainment patterns\nin interactions across different domains. Specifically we use cross-subject\nattention layers to learn intra- as well as inter-personal signals from dyadic\nconversations. We first validate the proposed method based on classification\nexperiments to distinguish between real(consistent) and\nfake(inconsistent/shuffled) conversations. Experimental results on interactions\ninvolving individuals with Autism Spectrum Disorder also show evidence of a\nstatistically-significant association between the introduced entrainment\nmeasure and clinical scores relevant to symptoms, including across gender and\nage groups.", "published": "2022-11-07 03:07:37", "link": "http://arxiv.org/abs/2211.03279v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Peak-First CTC: Reducing the Peak Latency of CTC Models by Applying\n  Peak-First Regularization", "abstract": "The CTC model has been widely applied to many application scenarios because\nof its simple structure, excellent performance, and fast inference speed. There\nare many peaks in the probability distribution predicted by the CTC models, and\neach peak represents a non-blank token. The recognition latency of CTC models\ncan be reduced by encouraging the model to predict peaks earlier. Existing\nmethods to reduce latency require modifying the transition relationship between\ntokens in the forward-backward algorithm, and the gradient calculation. Some of\nthese methods even depend on the forced alignment results provided by other\npretrained models. The above methods are complex to implement. To reduce the\npeak latency, we propose a simple and novel method named peak-first\nregularization, which utilizes a frame-wise knowledge distillation function to\nforce the probability distribution of the CTC model to shift left along the\ntime axis instead of directly modifying the calculation process of CTC loss and\ngradients. All the experiments are conducted on a Chinese Mandarin dataset\nAISHELL-1. We have verified the effectiveness of the proposed regularization on\nboth streaming and non-streaming CTC models respectively. The results show that\nthe proposed method can reduce the average peak latency by about 100 to 200\nmilliseconds with almost no degradation of recognition accuracy.", "published": "2022-11-07 03:36:00", "link": "http://arxiv.org/abs/2211.03284v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hi,KIA: A Speech Emotion Recognition Dataset for Wake-Up Words", "abstract": "Wake-up words (WUW) is a short sentence used to activate a speech recognition\nsystem to receive the user's speech input. WUW utterances include not only the\nlexical information for waking up the system but also non-lexical information\nsuch as speaker identity or emotion. In particular, recognizing the user's\nemotional state may elaborate the voice communication. However, there is few\ndataset where the emotional state of the WUW utterances is labeled. In this\npaper, we introduce Hi, KIA, a new WUW dataset which consists of 488 Korean\naccent emotional utterances collected from four male and four female speakers\nand each of utterances is labeled with four emotional states including anger,\nhappy, sad, or neutral. We present the step-by-step procedure to build the\ndataset, covering scenario selection, post-processing, and human validation for\nlabel agreement. Also, we provide two classification models for WUW speech\nemotion recognition using the dataset. One is based on traditional hand-craft\nfeatures and the other is a transfer-learning approach using a pre-trained\nneural network. These classification models could be used as benchmarks in\nfurther research.", "published": "2022-11-07 08:57:16", "link": "http://arxiv.org/abs/2211.03371v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Total Least Mean M-Estimate normalized subband filter Adaptive\n  Algorithm for impulse noises and noisy inputs", "abstract": "When the input signal is correlated input signals, and the input and output\nsignal is contaminated by Gaussian noise, the total least squares normalized\nsubband adaptive filter (TLS-NSAF) algorithm shows good performance. However,\nwhen it is disturbed by impulse noise, the TLS-NSAF algorithm shows the rapidly\ndeteriorating convergence performance. To solve this problem, this paper\nproposed the robust total minimum mean M-estimator normalized subband filter\n(TLMM-NSAF) algorithm. In addition, this paper also conducts a detailed\ntheoretical performance analysis of the TLMM-NSAF algorithm and obtains the\nstable step size range and theoretical steady-state mean squared deviation\n(MSD) of the algorithm. To further improve the performance of the algorithm, we\nalso propose a new variable step size (VSS) method of the algorithm. Finally,\nthe robustness of our proposed algorithm and the consistency of theoretical and\nsimulated values are verified by computer simulations of system identification\nand echo cancellation under different noise models.", "published": "2022-11-07 03:28:04", "link": "http://arxiv.org/abs/2211.03283v2", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Accented Text-to-Speech Synthesis with a Conditional Variational\n  Autoencoder", "abstract": "Accent plays a significant role in speech communication, influencing one's\ncapability to understand as well as conveying a person's identity. This paper\nintroduces a novel and efficient framework for accented Text-to-Speech (TTS)\nsynthesis based on a Conditional Variational Autoencoder. It has the ability to\nsynthesize a selected speaker's voice, and convert this to any desired target\naccent. Our thorough experiments validate the effectiveness of the proposed\nframework using both objective and subjective evaluations. The results also\nshow remarkable performance in terms of the model's ability to manipulate\naccents in the synthesized speech. Overall, our proposed framework presents a\npromising avenue for future accented TTS research.", "published": "2022-11-07 05:36:30", "link": "http://arxiv.org/abs/2211.03316v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
