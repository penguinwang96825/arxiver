{"title": "Building Context-aware Clause Representations for Situation Entity Type\n  Classification", "abstract": "Capabilities to categorize a clause based on the type of situation entity\n(e.g., events, states and generic statements) the clause introduces to the\ndiscourse can benefit many NLP applications. Observing that the situation\nentity type of a clause depends on discourse functions the clause plays in a\nparagraph and the interpretation of discourse functions depends heavily on\nparagraph-wide contexts, we propose to build context-aware clause\nrepresentations for predicting situation entity types of clauses. Specifically,\nwe propose a hierarchical recurrent neural network model to read a whole\nparagraph at a time and jointly learn representations for all the clauses in\nthe paragraph by extensively modeling context influences and inter-dependencies\nof clauses. Experimental results show that our model achieves the\nstate-of-the-art performance for clause-level situation entity classification\non the genre-rich MASC+Wiki corpus, which approaches human-level performance.", "published": "2018-09-20 05:40:46", "link": "http://arxiv.org/abs/1809.07483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Quantitative Evaluation of Natural Language Question Interpretation\n  for Question Answering Systems", "abstract": "Systematic benchmark evaluation plays an important role in the process of\nimproving technologies for Question Answering (QA) systems. While currently\nthere are a number of existing evaluation methods for natural language (NL) QA\nsystems, most of them consider only the final answers, limiting their utility\nwithin a black box style evaluation. Herein, we propose a subdivided evaluation\napproach to enable finer-grained evaluation of QA systems, and present an\nevaluation tool which targets the NL question (NLQ) interpretation step, an\ninitial step of a QA pipeline. The results of experiments using two public\nbenchmark datasets suggest that we can get a deeper insight about the\nperformance of a QA system using the proposed approach, which should provide a\nbetter guidance for improving the systems, than using black box style\napproaches.", "published": "2018-09-20 05:49:40", "link": "http://arxiv.org/abs/1809.07485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges for Toxic Comment Classification: An In-Depth Error Analysis", "abstract": "Toxic comment classification has become an active research field with many\nrecently proposed approaches. However, while these approaches address some of\nthe task's challenges others still remain unsolved and directions for further\nresearch are needed. To this end, we compare different deep learning and\nshallow approaches on a new, large comment dataset and propose an ensemble that\noutperforms all individual models. Further, we validate our findings on a\nsecond dataset. The results of the ensemble enable us to perform an extensive\nerror analysis, which reveals open challenges for state-of-the-art methods and\ndirections towards pending future research. These challenges include missing\nparadigmatic context and inconsistent dataset labels.", "published": "2018-09-20 11:11:42", "link": "http://arxiv.org/abs/1809.07572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lessons learned in multilingual grounded language learning", "abstract": "Recent work has shown how to learn better visual-semantic embeddings by\nleveraging image descriptions in more than one language. Here, we investigate\nin detail which conditions affect the performance of this type of grounded\nlanguage learning model. We show that multilingual training improves over\nbilingual training, and that low-resource languages benefit from training with\nhigher-resource languages. We demonstrate that a multilingual model can be\ntrained equally well on either translations or comparable sentence pairs, and\nthat annotating the same set of images in multiple language enables further\nimprovements via an additional caption-caption ranking objective.", "published": "2018-09-20 13:39:10", "link": "http://arxiv.org/abs/1809.07615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Multilingual Supervision for Cross-lingual Entity Linking", "abstract": "Cross-lingual Entity Linking (XEL) aims to ground entity mentions written in\nany language to an English Knowledge Base (KB), such as Wikipedia. XEL for most\nlanguages is challenging, owing to limited availability of resources as\nsupervision. We address this challenge by developing the first XEL approach\nthat combines supervision from multiple languages jointly. This enables our\napproach to: (a) augment the limited supervision in the target language with\nadditional supervision from a high-resource language (like English), and (b)\ntrain a single entity linking model for multiple languages, improving upon\nindividually trained models for each language. Extensive evaluation on three\nbenchmark datasets across 8 languages shows that our approach significantly\nimproves over the current state-of-the-art. We also provide analyses in two\nlimited resource settings: (a) zero-shot setting, when no supervision in the\ntarget language is available, and in (b) low-resource setting, when some\nsupervision in the target language is available. Our analysis provides insights\ninto the limitations of zero-shot XEL approaches in realistic scenarios, and\nshows the value of joint supervision in low-resource settings.", "published": "2018-09-20 14:53:47", "link": "http://arxiv.org/abs/1809.07657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Symbolic Priors for RNN-based Semantic Parsing", "abstract": "Seq2seq models based on Recurrent Neural Networks (RNNs) have recently\nreceived a lot of attention in the domain of Semantic Parsing for Question\nAnswering. While in principle they can be trained directly on pairs (natural\nlanguage utterances, logical forms), their performance is limited by the amount\nof available data. To alleviate this problem, we propose to exploit various\nsources of prior knowledge: the well-formedness of the logical forms is modeled\nby a weighted context-free grammar; the likelihood that certain entities\npresent in the input utterance are also present in the logical form is modeled\nby weighted finite-state automata. The grammar and automata are combined\ntogether through an efficient intersection algorithm to form a soft guide\n(\"background\") to the RNN. We test our method on an extension of the Overnight\ndataset and show that it not only strongly improves over an RNN baseline, but\nalso outperforms non-RNN models based on rich sets of hand-crafted features.", "published": "2018-09-20 16:21:29", "link": "http://arxiv.org/abs/1809.07721v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rapid Customization for Event Extraction", "abstract": "We present a system for rapidly customizing event extraction capability to\nfind new event types and their arguments. The system allows a user to find,\nexpand and filter event triggers for a new event type by exploring an\nunannotated corpus. The system will then automatically generate mention-level\nevent annotation automatically, and train a Neural Network model for finding\nthe corresponding event. Additionally, the system uses the ACE corpus to train\nan argument model for extracting Actor, Place, and Time arguments for any event\ntypes, including ones not seen in its training data. Experiments show that with\nless than 10 minutes of human effort per event type, the system achieves good\nperformance for 67 novel event types. The code, documentation, and a\ndemonstration video will be released as open source on github.com.", "published": "2018-09-20 18:02:49", "link": "http://arxiv.org/abs/1809.07783v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Transliteration with Constrained Discovery for\n  Low-Resource Languages", "abstract": "Generating the English transliteration of a name written in a foreign script\nis an important and challenging step in multilingual knowledge acquisition and\ninformation extraction. Existing approaches to transliteration generation\nrequire a large (>5000) number of training examples. This difficulty contrasts\nwith transliteration discovery, a somewhat easier task that involves picking a\nplausible transliteration from a given list. In this work, we present a\nbootstrapping algorithm that uses constrained discovery to improve generation,\nand can be used with as few as 500 training examples, which we show can be\nsourced from annotators in a matter of hours. This opens the task to languages\nfor which large number of training examples are unavailable. We evaluate\ntransliteration generation performance itself, as well the improvement it\nbrings to cross-lingual candidate generation for entity linking, a typical\ndownstream task. We present a comprehensive evaluation of our approach on nine\nlanguages, each written in a unique script.", "published": "2018-09-20 19:05:29", "link": "http://arxiv.org/abs/1809.07807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LSTM-based Whisper Detection", "abstract": "This article presents a whisper speech detector in the far-field domain. The\nproposed system consists of a long-short term memory (LSTM) neural network\ntrained on log-filterbank energy (LFBE) acoustic features. This model is\ntrained and evaluated on recordings of human interactions with\nvoice-controlled, far-field devices in whisper and normal phonation modes. We\ncompare multiple inference approaches for utterance-level classification by\nexamining trajectories of the LSTM posteriors. In addition, we engineer a set\nof features based on the signal characteristics inherent to whisper speech, and\nevaluate their effectiveness in further separating whisper from normal speech.\nA benchmarking of these features using multilayer perceptrons (MLP) and LSTMs\nsuggests that the proposed features, in combination with LFBE features, can\nhelp us further improve our classifiers. We prove that, with enough data, the\nLSTM model is indeed as capable of learning whisper characteristics from LFBE\nfeatures alone compared to a simpler MLP model that uses both LFBE and features\nengineered for separating whisper and normal speech. In addition, we prove that\nthe LSTM classifiers accuracy can be further improved with the incorporation of\nthe proposed engineered features.", "published": "2018-09-20 20:04:07", "link": "http://arxiv.org/abs/1809.07832v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting the Argumenthood of English Prepositional Phrases", "abstract": "Distinguishing between arguments and adjuncts of a verb is a longstanding,\nnontrivial problem. In natural language processing, argumenthood information is\nimportant in tasks such as semantic role labeling (SRL) and prepositional\nphrase (PP) attachment disambiguation. In theoretical linguistics, many\ndiagnostic tests for argumenthood exist but they often yield conflicting and\npotentially gradient results. This is especially the case for syntactically\noblique items such as PPs. We propose two PP argumenthood prediction tasks\nbranching from these two motivations: (1) binary argument-adjunct\nclassification of PPs in VerbNet, and (2) gradient argumenthood prediction\nusing human judgments as gold standard, and report results from prediction\nmodels that use pretrained word embeddings and other linguistically informed\nfeatures. Our best results on each task are (1) $acc.=0.955$, $F_1=0.954$\n(ELMo+BiLSTM) and (2) Pearson's $r=0.624$ (word2vec+MLP). Furthermore, we\ndemonstrate the utility of argumenthood prediction in improving sentence\nrepresentations via performance gains on SRL when a sentence encoder is\npretrained with our tasks.", "published": "2018-09-20 23:21:39", "link": "http://arxiv.org/abs/1809.07889v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactico-Semantic Reasoning using PCFG, MEBN & PP Attachment Ambiguity", "abstract": "Probabilistic context free grammars (PCFG) have been the core of the\nprobabilistic reasoning based parsers for several years especially in the\ncontext of the NLP. Multi entity bayesian networks (MEBN) a First Order Logic\nprobabilistic reasoning methodology is widely adopted and used method for\nuncertainty reasoning. Further upper ontology like Probabilistic Ontology Web\nLanguage (PR-OWL) built using MEBN takes care of probabilistic ontologies which\nmodel and capture the uncertainties inherent in the domain's semantic\ninformation. The paper attempts to establish a link between probabilistic\nreasoning in PCFG and MEBN by proposing a formal description of PCFG driven by\nMEBN leading to usage of PR-OWL modeled ontologies in PCFG parsers.\nFurthermore, the paper outlines an approach to resolve prepositional phrase\n(PP) attachment ambiguity using the proposed mapping between PCFG and MEBN.", "published": "2018-09-20 13:20:58", "link": "http://arxiv.org/abs/1809.07607v2", "categories": ["cs.AI", "cs.CL", "I.2.0; I.2.7"], "primary_category": "cs.AI"}
{"title": "On Folding and Twisting (and whatknot): towards a characterization of\n  workspaces in syntax", "abstract": "Syntactic theory has traditionally adopted a constructivist approach, in\nwhich a set of atomic elements are manipulated by combinatory operations to\nyield derived, complex elements. Syntactic structure is thus seen as the result\nor discrete recursive combinatorics over lexical items which get assembled into\nphrases, which are themselves combined to form sentences. This view is common\nto European and American structuralism (e.g., Benveniste, 1971; Hockett, 1958)\nand different incarnations of generative grammar, transformational and\nnon-transformational (Chomsky, 1956, 1995; and Kaplan & Bresnan, 1982; Gazdar,\n1982). Since at least Uriagereka (2002), there has been some attention paid to\nthe fact that syntactic operations must apply somewhere, particularly when\ncopying and movement operations are considered. Contemporary syntactic theory\nhas thus somewhat acknowledged the importance of formalizing aspects of the\nspaces in which elements are manipulated, but it is still a vastly\nunderexplored area. In this paper we explore the consequences of\nconceptualizing syntax as a set of topological operations applying over spaces\nrather than over discrete elements. We argue that there are empirical\nadvantages in such a view for the treatment of long-distance dependencies and\ncross-derivational dependencies: constraints on possible configurations emerge\nfrom the dynamics of the system.", "published": "2018-09-20 20:57:43", "link": "http://arxiv.org/abs/1809.07853v3", "categories": ["cs.CL", "cs.CG", "cs.FL"], "primary_category": "cs.CL"}
{"title": "Neural network approach to classifying alarming student responses to\n  online assessment", "abstract": "Automated scoring engines are increasingly being used to score the free-form\ntext responses that students give to questions. Such engines are not designed\nto appropriately deal with responses that a human reader would find alarming\nsuch as those that indicate an intention to self-harm or harm others, responses\nthat allude to drug abuse or sexual abuse or any response that would elicit\nconcern for the student writing the response. Our neural network models have\nbeen designed to help identify these anomalous responses from a large\ncollection of typical responses that students give. The responses identified by\nthe neural network can be assessed for urgency, severity, and validity more\nquickly by a team of reviewers than otherwise possible. Given the anomalous\nnature of these types of responses, our goal is to maximize the chance of\nflagging these responses for review given the constraint that only a fixed\npercentage of responses can viably be assessed by a team of reviewers.", "published": "2018-09-20 14:29:22", "link": "http://arxiv.org/abs/1809.08899v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Architecture of Text Mining Application in Analyzing Public Sentiments\n  of West Java Governor Election using Naive Bayes Classification", "abstract": "The selection of West Java governor is one event that seizes the attention of\nthe public is no exception to social media users. Public opinion on a\nprospective regional leader can help predict electability and tendency of\nvoters. Data that can be used by the opinion mining process can be obtained\nfrom Twitter. Because the data is very varied form and very unstructured, it\nmust be managed and uninformed using data pre-processing techniques into\nsemi-structured data. This semi-structured information is followed by a\nclassification stage to categorize the opinion into negative or positive\nopinions. The research methodology uses a literature study where the research\nwill examine previous research on a similar topic. The purpose of this study is\nto find the right architecture to develop it into the application of twitter\nopinion mining to know public sentiments toward the election of the governor of\nwest java. The result of this research is that Twitter opinion mining is part\nof text mining where opinions in Twitter if they want to be classified, must go\nthrough the preprocessing text stage first. The preprocessing step required\nfrom twitter data is cleansing, case folding, POS Tagging and stemming. The\nresulting text mining architecture is an architecture that can be used for text\nmining research with different topics.", "published": "2018-09-20 07:14:10", "link": "http://arxiv.org/abs/1810.07767v1", "categories": ["cs.CY", "cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Permutation Invariant Gaussian Matrix Models", "abstract": "Permutation invariant Gaussian matrix models were recently developed for\napplications in computational linguistics. A 5-parameter family of models was\nsolved. In this paper, we use a representation theoretic approach to solve the\ngeneral 13-parameter Gaussian model, which can be viewed as a zero-dimensional\nquantum field theory. We express the two linear and eleven quadratic terms in\nthe action in terms of representation theoretic parameters. These parameters\nare coefficients of simple quadratic expressions in terms of appropriate linear\ncombinations of the matrix variables transforming in specific irreducible\nrepresentations of the symmetric group $S_D$ where $D$ is the size of the\nmatrices. They allow the identification of constraints which ensure a\nconvergent Gaussian measure and well-defined expectation values for polynomial\nfunctions of the random matrix at all orders. A graph-theoretic interpretation\nis known to allow the enumeration of permutation invariants of matrices at\nlinear, quadratic and higher orders. We express the expectation values of all\nthe quadratic graph-basis invariants and a selection of cubic and quartic\ninvariants in terms of the representation theoretic parameters of the model.", "published": "2018-09-20 10:32:22", "link": "http://arxiv.org/abs/1809.07559v2", "categories": ["hep-th", "cs.CL", "math-ph", "math.MP", "math.RT"], "primary_category": "hep-th"}
{"title": "Evaluating MCC-PHAT for the LOCATA Challenge - Task 1 and Task 3", "abstract": "This report presents test results for the \\mbox{LOCATA} challenge\n\\cite{lollmann2018locata} using the recently developed MCC-PHAT (multichannel\ncross correlation - phase transform) sound source localization method. The\nspecific tasks addressed are respectively the localization of a single static\nand a single moving speakers using sound recordings of a variety of static\nmicrophone arrays. The test results are compared with those of the MUSIC\n(multiple signal classification) method. The optimal subpattern assignment\n(OSPA) metric is used for quantitative performance evaluation. In most cases,\nthe MCC-PHAT method demonstrates more reliable and accurate location estimates,\nin comparison with those of the MUSIC method.", "published": "2018-09-20 09:52:36", "link": "http://arxiv.org/abs/1809.07549v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for\n  Speech Separation", "abstract": "Single-channel, speaker-independent speech separation methods have recently\nseen great progress. However, the accuracy, latency, and computational cost of\nsuch methods remain insufficient. The majority of the previous methods have\nformulated the separation problem through the time-frequency representation of\nthe mixed signal, which has several drawbacks, including the decoupling of the\nphase and magnitude of the signal, the suboptimality of time-frequency\nrepresentation for speech separation, and the long latency in calculating the\nspectrograms. To address these shortcomings, we propose a fully-convolutional\ntime-domain audio separation network (Conv-TasNet), a deep learning framework\nfor end-to-end time-domain speech separation. Conv-TasNet uses a linear encoder\nto generate a representation of the speech waveform optimized for separating\nindividual speakers. Speaker separation is achieved by applying a set of\nweighting functions (masks) to the encoder output. The modified encoder\nrepresentations are then inverted back to the waveforms using a linear decoder.\nThe masks are found using a temporal convolutional network (TCN) consisting of\nstacked 1-D dilated convolutional blocks, which allows the network to model the\nlong-term dependencies of the speech signal while maintaining a small model\nsize. The proposed Conv-TasNet system significantly outperforms previous\ntime-frequency masking methods in separating two- and three-speaker mixtures.\nAdditionally, Conv-TasNet surpasses several ideal time-frequency magnitude\nmasks in two-speaker speech separation as evaluated by both objective\ndistortion measures and subjective quality assessment by human listeners.\nFinally, Conv-TasNet has a significantly smaller model size and a shorter\nminimum latency, making it a suitable solution for both offline and real-time\nspeech separation applications.", "published": "2018-09-20 02:38:05", "link": "http://arxiv.org/abs/1809.07454v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Diffraction-Aware Sound Localization for a Non-Line-of-Sight Source", "abstract": "We present a novel sound localization algorithm for a non-line-of-sight\n(NLOS) sound source in indoor environments. Our approach exploits the\ndiffraction properties of sound waves as they bend around a barrier or an\nobstacle in the scene. We combine a ray tracing based sound propagation\nalgorithm with a Uniform Theory of Diffraction (UTD) model, which simulate\nbending effects by placing a virtual sound source on a wedge in the\nenvironment. We precompute the wedges of a reconstructed mesh of an indoor\nscene and use them to generate diffraction acoustic rays to localize the 3D\nposition of the source. Our method identifies the convergence region of those\ngenerated acoustic rays as the estimated source position based on a particle\nfilter. We have evaluated our algorithm in multiple scenarios consisting of a\nstatic and dynamic NLOS sound source. In our tested cases, our approach can\nlocalize a source position with an average accuracy error, 0.7m, measured by\nthe L2 distance between estimated and actual source locations in a 7m*7m*3m\nroom. Furthermore, we observe 37% to 130% improvement in accuracy over a\nstate-of-the-art localization method that does not model diffraction effects,\nespecially when a sound source is not visible to the robot.", "published": "2018-09-20 08:30:35", "link": "http://arxiv.org/abs/1809.07524v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "Symbolic Music Genre Transfer with CycleGAN", "abstract": "Deep generative models such as Variational Autoencoders (VAEs) and Generative\nAdversarial Networks (GANs) have recently been applied to style and domain\ntransfer for images, and in the case of VAEs, music. GAN-based models employing\nseveral generators and some form of cycle consistency loss have been among the\nmost successful for image domain transfer. In this paper we apply such a model\nto symbolic music and show the feasibility of our approach for music genre\ntransfer. Evaluations using separate genre classifiers show that the style\ntransfer works well. In order to improve the fidelity of the transformed music,\nwe add additional discriminators that cause the generators to keep the\nstructure of the original music mostly intact, while still achieving strong\ngenre transfer. Visual and audible results further show the potential of our\napproach. To the best of our knowledge, this paper represents the first\napplication of GANs to symbolic music domain transfer.", "published": "2018-09-20 11:20:11", "link": "http://arxiv.org/abs/1809.07575v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML", "I.2.1; I.2.4; I.2.6; H.5.5"], "primary_category": "cs.SD"}
{"title": "MIDI-VAE: Modeling Dynamics and Instrumentation of Music with\n  Applications to Style Transfer", "abstract": "We introduce MIDI-VAE, a neural network model based on Variational\nAutoencoders that is capable of handling polyphonic music with multiple\ninstrument tracks, as well as modeling the dynamics of music by incorporating\nnote durations and velocities. We show that MIDI-VAE can perform style transfer\non symbolic music by automatically changing pitches, dynamics and instruments\nof a music piece from, e.g., a Classical to a Jazz style. We evaluate the\nefficacy of the style transfer by training separate style validation\nclassifiers. Our model can also interpolate between short pieces of music,\nproduce medleys and create mixtures of entire songs. The interpolations\nsmoothly change pitches, dynamics and instrumentation to create a harmonic\nbridge between two music pieces. To the best of our knowledge, this work\nrepresents the first successful attempt at applying neural style transfer to\ncomplete musical compositions.", "published": "2018-09-20 13:02:30", "link": "http://arxiv.org/abs/1809.07600v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML", "I.2.1; I.2.4; I.2.6; H.5.5"], "primary_category": "cs.SD"}
{"title": "Metric Learning for Phoneme Perception", "abstract": "Metric functions for phoneme perception capture the similarity structure\namong phonemes in a given language and therefore play a central role in\nphonology and psycho-linguistics. Various phenomena depend on phoneme\nsimilarity, such as spoken word recognition or serial recall from verbal\nworking memory. This study presents a new framework for learning a metric\nfunction for perceptual distances among pairs of phonemes. Previous studies\nhave proposed various metric functions, from simple measures counting the\nnumber of phonetic dimensions that two phonemes share (place-,\nmanner-of-articulation and voicing), to more sophisticated ones such as\nderiving perceptual distances based on the number of natural classes that both\nphonemes belong to. However, previous studies have manually constructed the\nmetric function, which may lead to unsatisfactory account of the empirical\ndata. This study presents a framework to derive the metric function from\nbehavioral data on phoneme perception using learning algorithms. We first show\nthat this approach outperforms previous metrics suggested in the literature in\npredicting perceptual distances among phoneme pairs. We then study several\nmetric functions derived by the learning algorithms and show how perceptual\nsaliencies of phonological features can be derived from them. For English, we\nshow that the derived perceptual saliencies are in accordance with a previously\ndescribed order among phonological features and show how the framework extends\nthe results to more features. Finally, we explore how the metric function and\nperceptual saliencies of phonological features may vary across languages. To\nthis end, we compare results based on two English datasets and a new dataset\nthat we have collected for Hebrew.", "published": "2018-09-20 19:53:33", "link": "http://arxiv.org/abs/1809.07824v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
