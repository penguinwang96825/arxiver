{"title": "Representation Learning for Short Text Clustering", "abstract": "Effective representation learning is critical for short text clustering due\nto the sparse, high-dimensional and noise attributes of short text corpus.\nExisting pre-trained models (e.g., Word2vec and BERT) have greatly improved the\nexpressiveness for short text representations with more condensed,\nlow-dimensional and continuous features compared to the traditional\nBag-of-Words (BoW) model. However, these models are trained for general\npurposes and thus are suboptimal for the short text clustering task. In this\npaper, we propose two methods to exploit the unsupervised autoencoder (AE)\nframework to further tune the short text representations based on these\npre-trained text models for optimal clustering performance. In our first method\nStructural Text Network Graph Autoencoder (STN-GAE), we exploit the structural\ntext information among the corpus by constructing a text network, and then\nadopt graph convolutional network as encoder to fuse the structural features\nwith the pre-trained text features for text representation learning. In our\nsecond method Soft Cluster Assignment Autoencoder (SCA-AE), we adopt an extra\nsoft cluster assignment constraint on the latent space of autoencoder to\nencourage the learned text representations to be more clustering-friendly. We\ntested two methods on seven popular short text datasets, and the experimental\nresults show that when only using the pre-trained model for short text\nclustering, BERT performs better than BoW and Word2vec. However, as long as we\nfurther tune the pre-trained representations, the proposed method like SCA-AE\ncan greatly increase the clustering performance, and the accuracy improvement\ncompared to use BERT alone could reach as much as 14\\%.", "published": "2021-09-21 00:30:24", "link": "http://arxiv.org/abs/2109.09894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Kernel-Smoothed Machine Translation with Retrieved Examples", "abstract": "How to effectively adapt neural machine translation (NMT) models according to\nemerging cases without retraining? Despite the great success of neural machine\ntranslation, updating the deployed models online remains a challenge. Existing\nnon-parametric approaches that retrieve similar examples from a database to\nguide the translation process are promising but are prone to overfit the\nretrieved examples. In this work, we propose to learn Kernel-Smoothed\nTranslation with Example Retrieval (KSTER), an effective approach to adapt\nneural machine translation models online. Experiments on domain adaptation and\nmulti-domain machine translation datasets show that even without expensive\nretraining, KSTER is able to achieve improvement of 1.1 to 1.5 BLEU scores over\nthe best existing online adaptation methods. The code and trained models are\nreleased at https://github.com/jiangqn/KSTER.", "published": "2021-09-21 06:42:53", "link": "http://arxiv.org/abs/2109.09991v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Negation-Instance Based Evaluation of End-to-End Negation Resolution", "abstract": "In this paper, we revisit the task of negation resolution, which includes the\nsubtasks of cue detection (e.g. \"not\", \"never\") and scope resolution. In the\ncontext of previous shared tasks, a variety of evaluation metrics have been\nproposed. Subsequent works usually use different subsets of these, including\nvariations and custom implementations, rendering meaningful comparisons between\nsystems difficult. Examining the problem both from a linguistic perspective and\nfrom a downstream viewpoint, we here argue for a negation-instance based\napproach to evaluating negation resolution. Our proposed metrics correspond to\nexpectations over per-instance scores and hence are intuitively interpretable.\nTo render research comparable and to foster future work, we provide results for\na set of current state-of-the-art systems for negation resolution on three\nEnglish corpora, and make our implementation of the evaluation scripts publicly\navailable.", "published": "2021-09-21 07:49:41", "link": "http://arxiv.org/abs/2109.10013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Comments are Equal: Insights into Comment Moderation from a\n  Topic-Aware Model", "abstract": "Moderation of reader comments is a significant problem for online news\nplatforms. Here, we experiment with models for automatic moderation, using a\ndataset of comments from a popular Croatian newspaper. Our analysis shows that\nwhile comments that violate the moderation rules mostly share common linguistic\nand thematic features, their content varies across the different sections of\nthe newspaper. We therefore make our models topic-aware, incorporating semantic\nfeatures from a topic model into the classification decision. Our results show\nthat topic information improves the performance of the model, increases its\nconfidence in correct outputs, and helps us understand the model's outputs.", "published": "2021-09-21 08:57:17", "link": "http://arxiv.org/abs/2109.10033v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Something Old, Something New: Grammar-based CCG Parsing with Transformer\n  Models", "abstract": "This report describes the parsing problem for Combinatory Categorial Grammar\n(CCG), showing how a combination of Transformer-based neural models and a\nsymbolic CCG grammar can lead to substantial gains over existing approaches.\nThe report also documents a 20-year research program, showing how NLP methods\nhave evolved over this time. The staggering accuracy improvements provided by\nneural models for CCG parsing can be seen as a reflection of the improvements\nseen in NLP more generally. The report provides a minimal introduction to CCG\nand CCG parsing, with many pointers to the relevant literature. It then\ndescribes the CCG supertagging problem, and some recent work from Tian et al.\n(2020) which applies Transformer-based models to supertagging with great\neffect. I use this existing model to develop a CCG multitagger, which can serve\nas a front-end to an existing CCG parser. Simply using this new multitagger\nprovides substantial gains in parsing accuracy. I then show how a\nTransformer-based model from the parsing literature can be combined with the\ngrammar-based CCG parser, setting a new state-of-the-art for the CCGbank\nparsing task of almost 93% F-score for labelled dependencies, with complete\nsentence accuracies of over 50%.", "published": "2021-09-21 09:20:12", "link": "http://arxiv.org/abs/2109.10044v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stepmothers are mean and academics are pretentious: What do pretrained\n  language models learn about you?", "abstract": "In this paper, we investigate what types of stereotypical information are\ncaptured by pretrained language models. We present the first dataset comprising\nstereotypical attributes of a range of social groups and propose a method to\nelicit stereotypes encoded by pretrained language models in an unsupervised\nfashion. Moreover, we link the emergent stereotypes to their manifestation as\nbasic emotions as a means to study their emotional effects in a more\ngeneralized manner. To demonstrate how our methods can be used to analyze\nemotion and stereotype shifts due to linguistic experience, we use fine-tuning\non news sources as a case study. Our experiments expose how attitudes towards\ndifferent social groups vary across models and how quickly emotions and\nstereotypes can shift at the fine-tuning stage.", "published": "2021-09-21 09:44:57", "link": "http://arxiv.org/abs/2109.10052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InvBERT: Reconstructing Text from Contextualized Word Embeddings by\n  inverting the BERT pipeline", "abstract": "Digital Humanities and Computational Literary Studies apply text mining\nmethods to investigate literature. Such automated approaches enable\nquantitative studies on large corpora which would not be feasible by manual\ninspection alone. However, due to copyright restrictions, the availability of\nrelevant digitized literary works is limited. Derived Text Formats (DTFs) have\nbeen proposed as a solution. Here, textual materials are transformed in such a\nway that copyright-critical features are removed, but that the use of certain\nanalytical methods remains possible. Contextualized word embeddings produced by\ntransformer-encoders (like BERT) are promising candidates for DTFs because they\nallow for state-of-the-art performance on various analytical tasks and, at\nfirst sight, do not disclose the original text. However, in this paper we\ndemonstrate that under certain conditions the reconstruction of the original\ncopyrighted text becomes feasible and its publication in the form of\ncontextualized token representations is not safe. Our attempts to invert BERT\nsuggest, that publishing the encoder as a black box together with the\ncontextualized embeddings is critical, since it allows to generate data to\ntrain a decoder with a reconstruction accuracy sufficient to violate copyright\nlaws.", "published": "2021-09-21 11:35:41", "link": "http://arxiv.org/abs/2109.10104v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Review on Summarizing Financial News Using Deep Learning", "abstract": "Investors make investment decisions depending on several factors such as\nfundamental analysis, technical analysis, and quantitative analysis. Another\nfactor on which investors can make investment decisions is through sentiment\nanalysis of news headlines, the sole purpose of this study. Natural Language\nProcessing techniques are typically used to deal with such a large amount of\ndata and get valuable information out of it. NLP algorithms convert raw text\ninto numerical representations that machines can easily understand and\ninterpret. This conversion can be done using various embedding techniques. In\nthis research, embedding techniques used are BoW, TF-IDF, Word2Vec, BERT,\nGloVe, and FastText, and then fed to deep learning models such as RNN and LSTM.\nThis work aims to evaluate these model's performance to choose the robust model\nin identifying the significant factors influencing the prediction. During this\nresearch, it was expected that Deep Leaming would be applied to get the desired\nresults or achieve better accuracy than the state-of-the-art. The models are\ncompared to check their outputs to know which one has performed better.", "published": "2021-09-21 12:00:31", "link": "http://arxiv.org/abs/2109.10118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConvFiT: Conversational Fine-Tuning of Pretrained Language Models", "abstract": "Transformer-based language models (LMs) pretrained on large text collections\nare proven to store a wealth of semantic knowledge. However, 1) they are not\neffective as sentence encoders when used off-the-shelf, and 2) thus typically\nlag behind conversationally pretrained (e.g., via response selection) encoders\non conversational tasks such as intent detection (ID). In this work, we propose\nConvFiT, a simple and efficient two-stage procedure which turns any pretrained\nLM into a universal conversational encoder (after Stage 1 ConvFiT-ing) and\ntask-specialised sentence encoder (after Stage 2). We demonstrate that 1)\nfull-blown conversational pretraining is not required, and that LMs can be\nquickly transformed into effective conversational encoders with much smaller\namounts of unannotated data; 2) pretrained LMs can be fine-tuned into\ntask-specialised sentence encoders, optimised for the fine-grained semantics of\na particular task. Consequently, such specialised sentence encoders allow for\ntreating ID as a simple semantic similarity task based on interpretable nearest\nneighbours retrieval. We validate the robustness and versatility of the ConvFiT\nframework with such similarity-based inference on the standard ID evaluation\nsets: ConvFiT-ed LMs achieve state-of-the-art ID performance across the board,\nwith particular gains in the most challenging, few-shot setups.", "published": "2021-09-21 12:16:56", "link": "http://arxiv.org/abs/2109.10126v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Transformers a Modern Version of ELIZA? Observations on French\n  Object Verb Agreement", "abstract": "Many recent works have demonstrated that unsupervised sentence\nrepresentations of neural networks encode syntactic information by observing\nthat neural language models are able to predict the agreement between a verb\nand its subject. We take a critical look at this line of research by showing\nthat it is possible to achieve high accuracy on this agreement task with simple\nsurface heuristics, indicating a possible flaw in our assessment of neural\nnetworks' syntactic ability. Our fine-grained analyses of results on the\nlong-range French object-verb agreement show that contrary to LSTMs,\nTransformers are able to capture a non-trivial amount of grammatical structure.", "published": "2021-09-21 12:33:11", "link": "http://arxiv.org/abs/2109.10133v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Distillation with Noisy Labels for Natural Language\n  Understanding", "abstract": "Knowledge Distillation (KD) is extensively used to compress and deploy large\npre-trained language models on edge devices for real-world applications.\nHowever, one neglected area of research is the impact of noisy (corrupted)\nlabels on KD. We present, to the best of our knowledge, the first study on KD\nwith noisy labels in Natural Language Understanding (NLU). We document the\nscope of the problem and present two methods to mitigate the impact of label\nnoise. Experiments on the GLUE benchmark show that our methods are effective\neven under high noise levels. Nevertheless, our results indicate that more\nresearch is necessary to cope with label noise under the KD.", "published": "2021-09-21 13:00:22", "link": "http://arxiv.org/abs/2109.10147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation", "abstract": "Intermediate layer knowledge distillation (KD) can improve the standard KD\ntechnique (which only targets the output of teacher and student models)\nespecially over large pre-trained language models. However, intermediate layer\ndistillation suffers from excessive computational burdens and engineering\nefforts required for setting up a proper layer mapping. To address these\nproblems, we propose a RAndom Intermediate Layer Knowledge Distillation\n(RAIL-KD) approach in which, intermediate layers from the teacher model are\nselected randomly to be distilled into the intermediate layers of the student\nmodel. This randomized selection enforce that: all teacher layers are taken\ninto account in the training process, while reducing the computational cost of\nintermediate layer distillation. Also, we show that it act as a regularizer for\nimproving the generalizability of the student model. We perform extensive\nexperiments on GLUE tasks as well as on out-of-domain test sets. We show that\nour proposed RAIL-KD approach outperforms other state-of-the-art intermediate\nlayer KD methods considerably in both performance and training-time.", "published": "2021-09-21 13:21:13", "link": "http://arxiv.org/abs/2109.10164v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Familiar Does That Sound? Cross-Lingual Representational Similarity\n  Analysis of Acoustic Word Embeddings", "abstract": "How do neural networks \"perceive\" speech sounds from unknown languages? Does\nthe typological similarity between the model's training language (L1) and an\nunknown language (L2) have an impact on the model representations of L2 speech\nsignals? To answer these questions, we present a novel experimental design\nbased on representational similarity analysis (RSA) to analyze acoustic word\nembeddings (AWEs) -- vector representations of variable-duration spoken-word\nsegments. First, we train monolingual AWE models on seven Indo-European\nlanguages with various degrees of typological similarity. We then employ RSA to\nquantify the cross-lingual similarity by simulating native and non-native\nspoken-word processing using AWEs. Our experiments show that typological\nsimilarity indeed affects the representational similarity of the models in our\nstudy. We further discuss the implications of our work on modeling speech\nprocessing and language similarity with neural networks.", "published": "2021-09-21 13:51:39", "link": "http://arxiv.org/abs/2109.10179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TranslateLocally: Blazing-fast translation running on the local CPU", "abstract": "Every day, millions of people sacrifice their privacy and browsing habits in\nexchange for online machine translation. Companies and governments with\nconfidentiality requirements often ban online translation or pay a premium to\ndisable logging. To bring control back to the end user and demonstrate speed,\nwe developed translateLocally. Running locally on a desktop or laptop CPU,\ntranslateLocally delivers cloud-like translation speed and quality even on 10\nyear old hardware. The open-source software is based on Marian and runs on\nLinux, Windows, and macOS.", "published": "2021-09-21 14:20:39", "link": "http://arxiv.org/abs/2109.10194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Source, Two Targets: Challenges and Rewards of Dual Decoding", "abstract": "Machine translation is generally understood as generating one target text\nfrom an input source document. In this paper, we consider a stronger\nrequirement: to jointly generate two texts so that each output side effectively\ndepends on the other. As we discuss, such a device serves several practical\npurposes, from multi-target machine translation to the generation of controlled\nvariations of the target text. We present an analysis of possible\nimplementations of dual decoding, and experiment with four applications.\nViewing the problem from multiple angles allows us to better highlight the\nchallenges of dual decoding and to also thoroughly analyze the benefits of\ngenerating matched, rather than independent, translations.", "published": "2021-09-21 14:25:26", "link": "http://arxiv.org/abs/2109.10197v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blindness to Modality Helps Entailment Graph Mining", "abstract": "Understanding linguistic modality is widely seen as important for downstream\ntasks such as Question Answering and Knowledge Graph Population. Entailment\nGraph learning might also be expected to benefit from attention to modality. We\nbuild Entailment Graphs using a news corpus filtered with a modality parser,\nand show that stripping modal modifiers from predicates in fact increases\nperformance. This suggests that for some tasks, the pragmatics of modal\nmodification of predicates allows them to contribute as evidence of entailment.", "published": "2021-09-21 14:48:03", "link": "http://arxiv.org/abs/2109.10227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French\n  Tweets", "abstract": "We introduce BERTweetFR, the first large-scale pre-trained language model for\nFrench tweets. Our model is initialized using the general-domain French\nlanguage model CamemBERT which follows the base architecture of RoBERTa.\nExperiments show that BERTweetFR outperforms all previous general-domain French\nlanguage models on two downstream Twitter NLP tasks of offensiveness\nidentification and named entity recognition. The dataset used in the\noffensiveness detection task is first created and annotated by our team,\nfilling in the gap of such analytic datasets in French. We make our model\npublicly available in the transformers library with the aim of promoting future\nresearch in analytic tasks for French tweets.", "published": "2021-09-21 15:00:41", "link": "http://arxiv.org/abs/2109.10234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Learning with Sentiment, Emotion, and Target Detection to\n  Recognize Hate Speech and Offensive Language", "abstract": "The recognition of hate speech and offensive language (HOF) is commonly\nformulated as a classification task to decide if a text contains HOF. We\ninvestigate whether HOF detection can profit by taking into account the\nrelationships between HOF and similar concepts: (a) HOF is related to sentiment\nanalysis because hate speech is typically a negative statement and expresses a\nnegative opinion; (b) it is related to emotion analysis, as expressed hate\npoints to the author experiencing (or pretending to experience) anger while the\naddressees experience (or are intended to experience) fear. (c) Finally, one\nconstituting element of HOF is the mention of a targeted person or group. On\nthis basis, we hypothesize that HOF detection shows improvements when being\nmodeled jointly with these concepts, in a multi-task learning setup. We base\nour experiments on existing data sets for each of these concepts (sentiment,\nemotion, target of HOF) and evaluate our models as a participant (as team\nIMS-SINAI) in the HASOC FIRE 2021 English Subtask 1A. Based on model-selection\nexperiments in which we consider multiple available resources and submissions\nto the shared task, we find that the combination of the CrowdFlower emotion\ncorpus, the SemEval 2016 Sentiment Corpus, and the OffensEval 2019 target\ndetection data leads to an F1 =.79 in a multi-head multi-task learning model\nbased on BERT, in comparison to .7895 of plain BERT. On the HASOC 2019 test\ndata, this result is more substantial with an increase by 2pp in F1 and a\nconsiderable increase in recall. Across both data sets (2019, 2021), the recall\nis particularly increased for the class of HOF (6pp for the 2019 data and 3pp\nfor the 2021 data), showing that MTL with emotion, sentiment, and target\nidentification is an appropriate approach for early warning systems that might\nbe deployed in social media platforms.", "published": "2021-09-21 15:32:26", "link": "http://arxiv.org/abs/2109.10255v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Trade-offs of Domain Adaptation for Neural Language Models", "abstract": "This work connects language model adaptation with concepts of machine\nlearning theory. We consider a training setup with a large out-of-domain set\nand a small in-domain set. We derive how the benefit of training a model on\neither set depends on the size of the sets and the distance between their\nunderlying distributions. We analyze how out-of-domain pre-training before\nin-domain fine-tuning achieves better generalization than either solution\nindependently. Finally, we present how adaptation techniques based on data\nselection, such as importance sampling, intelligent data selection and\ninfluence functions, can be presented in a common framework which highlights\ntheir similarity and also their subtle differences.", "published": "2021-09-21 15:54:31", "link": "http://arxiv.org/abs/2109.10274v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammatical Profiling for Semantic Change Detection", "abstract": "Semantics, morphology and syntax are strongly interdependent. However, the\nmajority of computational methods for semantic change detection use\ndistributional word representations which encode mostly semantics. We\ninvestigate an alternative method, grammatical profiling, based entirely on\nchanges in the morphosyntactic behaviour of words. We demonstrate that it can\nbe used for semantic change detection and even outperforms some distributional\nsemantic methods. We present an in-depth qualitative and quantitative analysis\nof the predictions made by our grammatical profiling system, showing that they\nare plausible and interpretable.", "published": "2021-09-21 18:38:18", "link": "http://arxiv.org/abs/2109.10397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Debiasing Techniques for Intersectional Biases", "abstract": "Bias is pervasive in NLP models, motivating the development of automatic\ndebiasing techniques. Evaluation of NLP debiasing methods has largely been\nlimited to binary attributes in isolation, e.g., debiasing with respect to\nbinary gender or race, however many corpora involve multiple such attributes,\npossibly with higher cardinality. In this paper we argue that a truly fair\nmodel must consider `gerrymandering' groups which comprise not only single\nattributes, but also intersectional groups. We evaluate a form of\nbias-constrained model which is new to NLP, as well an extension of the\niterative nullspace projection technique which can handle multiple protected\nattributes.", "published": "2021-09-21 22:01:28", "link": "http://arxiv.org/abs/2109.10441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fairness-aware Class Imbalanced Learning", "abstract": "Class imbalance is a common challenge in many NLP tasks, and has clear\nconnections to bias, in that bias in training data often leads to higher\naccuracy for majority groups at the expense of minority groups. However there\nhas traditionally been a disconnect between research on class-imbalanced\nlearning and mitigating bias, and only recently have the two been looked at\nthrough a common lens. In this work we evaluate long-tail learning methods for\ntweet sentiment and occupation classification, and extend a margin-loss based\napproach with methods to enforce fairness. We empirically show through\ncontrolled experiments that the proposed approaches help mitigate both class\nimbalance and demographic biases.", "published": "2021-09-21 22:16:30", "link": "http://arxiv.org/abs/2109.10444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Fine-Grained Knowledge Graphs of Scientific Claims: Dataset\n  and Transformer-Based Results", "abstract": "Recent transformer-based approaches demonstrate promising results on\nrelational scientific information extraction. Existing datasets focus on\nhigh-level description of how research is carried out. Instead we focus on the\nsubtleties of how experimental associations are presented by building SciClaim,\na dataset of scientific claims drawn from Social and Behavior Science (SBS),\nPubMed, and CORD-19 papers. Our novel graph annotation schema incorporates not\nonly coarse-grained entity spans as nodes and relations as edges between them,\nbut also fine-grained attributes that modify entities and their relations, for\na total of 12,738 labels in the corpus. By including more label types and more\nthan twice the label density of previous datasets, SciClaim captures causal,\ncomparative, predictive, statistical, and proportional associations over\nexperimental variables along with their qualifications, subtypes, and evidence.\nWe extend work in transformer-based joint entity and relation extraction to\neffectively infer our schema, showing the promise of fine-grained knowledge\ngraphs in scientific claims and beyond.", "published": "2021-09-21 22:54:09", "link": "http://arxiv.org/abs/2109.10453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Domain Specific Language Models for Automatic Speech\n  Recognition through Machine Translation", "abstract": "Automatic Speech Recognition (ASR) systems have been gaining popularity in\nthe recent years for their widespread usage in smart phones and speakers.\nBuilding ASR systems for task-specific scenarios is subject to the availability\nof utterances that adhere to the style of the task as well as the language in\nquestion. In our work, we target such a scenario wherein task-specific text\ndata is available in a language that is different from the target language in\nwhich an ASR Language Model (LM) is expected. We use Neural Machine Translation\n(NMT) as an intermediate step to first obtain translations of the task-specific\ntext data. We then train LMs on the 1-best and N-best translations and study\nways to improve on such a baseline LM. We develop a procedure to derive word\nconfusion networks from NMT beam search graphs and evaluate LMs trained on\nthese confusion networks. With experiments on the WMT20 chat translation task\ndataset, we demonstrate that NMT confusion networks can help to reduce the\nperplexity of both n-gram and recurrent neural network LMs compared to those\ntrained only on N-best translations.", "published": "2021-09-21 10:29:20", "link": "http://arxiv.org/abs/2110.10261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distilling Relation Embeddings from Pre-trained Language Models", "abstract": "Pre-trained language models have been found to capture a surprisingly rich\namount of lexical knowledge, ranging from commonsense properties of everyday\nconcepts to detailed factual knowledge about named entities. Among others, this\nmakes it possible to distill high-quality word vectors from pre-trained\nlanguage models. However, it is currently unclear to what extent it is possible\nto distill relation embeddings, i.e. vectors that characterize the relationship\nbetween two words. Such relation embeddings are appealing because they can, in\nprinciple, encode relational knowledge in a more fine-grained way than is\npossible with knowledge graphs. To obtain relation embeddings from a\npre-trained language model, we encode word pairs using a (manually or\nautomatically generated) prompt, and we fine-tune the language model such that\nrelationally similar word pairs yield similar output vectors. We find that the\nresulting relation embeddings are highly competitive on analogy (unsupervised)\nand relation classification (supervised) benchmarks, even without any\ntask-specific fine-tuning. Source code to reproduce our experimental results\nand the model checkpoints are available in the following repository:\nhttps://github.com/asahi417/relbert", "published": "2021-09-21 15:05:27", "link": "http://arxiv.org/abs/2110.15705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalization in Text-based Games via Hierarchical Reinforcement\n  Learning", "abstract": "Deep reinforcement learning provides a promising approach for text-based\ngames in studying natural language communication between humans and artificial\nagents. However, the generalization still remains a big challenge as the agents\ndepend critically on the complexity and variety of training tasks. In this\npaper, we address this problem by introducing a hierarchical framework built\nupon the knowledge graph-based RL agent. In the high level, a meta-policy is\nexecuted to decompose the whole game into a set of subtasks specified by\ntextual goals, and select one of them based on the KG. Then a sub-policy in the\nlow level is executed to conduct goal-conditioned reinforcement learning. We\ncarry out experiments on games with various difficulty levels and show that the\nproposed method enjoys favorable generalizability.", "published": "2021-09-21 05:27:33", "link": "http://arxiv.org/abs/2109.09968v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of\n  Negations", "abstract": "Adverse Drug Event (ADE) extraction models can rapidly examine large\ncollections of social media texts, detecting mentions of drug-related adverse\nreactions and trigger medical investigations. However, despite the recent\nadvances in NLP, it is currently unknown if such models are robust in face of\nnegation, which is pervasive across language varieties.\n  In this paper we evaluate three state-of-the-art systems, showing their\nfragility against negation, and then we introduce two possible strategies to\nincrease the robustness of these models: a pipeline approach, relying on a\nspecific component for negation detection; an augmentation of an ADE extraction\ndataset to artificially create negated samples and further train the models.\n  We show that both strategies bring significant increases in performance,\nlowering the number of spurious entities predicted by the models. Our dataset\nand code will be publicly released to encourage research on the topic.", "published": "2021-09-21 10:33:29", "link": "http://arxiv.org/abs/2109.10080v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TrOCR: Transformer-based Optical Character Recognition with Pre-trained\n  Models", "abstract": "Text recognition is a long-standing research problem for document\ndigitalization. Existing approaches are usually built based on CNN for image\nunderstanding and RNN for char-level text generation. In addition, another\nlanguage model is usually needed to improve the overall accuracy as a\npost-processing step. In this paper, we propose an end-to-end text recognition\napproach with pre-trained image Transformer and text Transformer models, namely\nTrOCR, which leverages the Transformer architecture for both image\nunderstanding and wordpiece-level text generation. The TrOCR model is simple\nbut effective, and can be pre-trained with large-scale synthetic data and\nfine-tuned with human-labeled datasets. Experiments show that the TrOCR model\noutperforms the current state-of-the-art models on the printed, handwritten and\nscene text recognition tasks. The TrOCR models and code are publicly available\nat \\url{https://aka.ms/trocr}.", "published": "2021-09-21 16:01:56", "link": "http://arxiv.org/abs/2109.10282v5", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DeepSTL -- From English Requirements to Signal Temporal Logic", "abstract": "Formal methods provide very powerful tools and techniques for the design and\nanalysis of complex systems. Their practical application remains however\nlimited, due to the widely accepted belief that formal methods require\nextensive expertise and a steep learning curve. Writing correct formal\nspecifications in form of logical formulas is still considered to be a\ndifficult and error prone task.\n  In this paper we propose DeepSTL, a tool and technique for the translation of\ninformal requirements, given as free English sentences, into Signal Temporal\nLogic (STL), a formal specification language for cyber-physical systems, used\nboth by academia and advanced research labs in industry. A major challenge to\ndevise such a translator is the lack of publicly available informal\nrequirements and formal specifications. We propose a two-step workflow to\naddress this challenge. We first design a grammar-based generation technique of\nsynthetic data, where each output is a random STL formula and its associated\nset of possible English translations. In the second step, we use a\nstate-of-the-art transformer-based neural translation technique, to train an\naccurate attentional translator of English to STL. The experimental results\nshow high translation quality for patterns of English requirements that have\nbeen well trained, making this workflow promising to be extended for processing\nmore complex translation tasks.", "published": "2021-09-21 16:13:29", "link": "http://arxiv.org/abs/2109.10294v4", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From\n  Sentences to Documents", "abstract": "Document-level neural machine translation (DocNMT) achieves coherent\ntranslations by incorporating cross-sentence context. However, for most\nlanguage pairs there's a shortage of parallel documents, although parallel\nsentences are readily available. In this paper, we study whether and how\ncontextual modeling in DocNMT is transferable via multilingual modeling. We\nfocus on the scenario of zero-shot transfer from teacher languages with\ndocument level data to student languages with no documents but sentence level\ndata, and for the first time treat document-level translation as a transfer\nlearning problem. Using simple concatenation-based DocNMT, we explore the\neffect of 3 factors on the transfer: the number of teacher languages with\ndocument level data, the balance between document and sentence level data at\ntraining, and the data condition of parallel documents (genuine vs.\nbacktranslated). Our experiments on Europarl-7 and IWSLT-10 show the\nfeasibility of multilingual transfer for DocNMT, particularly on\ndocument-specific metrics. We observe that more teacher languages and adequate\ndata balance both contribute to better transfer quality. Surprisingly, the\ntransfer is less sensitive to the data condition, where multilingual DocNMT\ndelivers decent performance with either backtranslated or genuine document\npairs.", "published": "2021-09-21 17:49:34", "link": "http://arxiv.org/abs/2109.10341v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relation-Guided Pre-Training for Open-Domain Question Answering", "abstract": "Answering complex open-domain questions requires understanding the latent\nrelations between involving entities. However, we found that the existing QA\ndatasets are extremely imbalanced in some types of relations, which hurts the\ngeneralization performance over questions with long-tail relations. To remedy\nthis problem, in this paper, we propose a Relation-Guided Pre-Training\n(RGPT-QA) framework. We first generate a relational QA dataset covering a wide\nrange of relations from both the Wikidata triplets and Wikipedia hyperlinks. We\nthen pre-train a QA model to infer the latent relations from the question, and\nthen conduct extractive QA to get the target answer entity. We demonstrate that\nby pretraining with propoed RGPT-QA techique, the popular open-domain QA model,\nDense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute\nimprovement in Exact Match accuracy on Natural Questions, TriviaQA, and\nWebQuestions. Particularly, we show that RGPT-QA improves significantly on\nquestions with long-tail relations", "published": "2021-09-21 17:59:31", "link": "http://arxiv.org/abs/2109.10346v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Would it Take to get Biomedical QA Systems into Practice?", "abstract": "Medical question answering (QA) systems have the potential to answer\nclinicians uncertainties about treatment and diagnosis on demand, informed by\nthe latest evidence. However, despite the significant progress in general QA\nmade by the NLP community, medical QA systems are still not widely used in\nclinical environments. One likely reason for this is that clinicians may not\nreadily trust QA system outputs, in part because transparency, trustworthiness,\nand provenance have not been key considerations in the design of such models.\nIn this paper we discuss a set of criteria that, if met, we argue would likely\nincrease the utility of biomedical QA systems, which may in turn lead to\nadoption of such systems in practice. We assess existing models, tasks, and\ndatasets with respect to these criteria, highlighting shortcomings of\npreviously proposed approaches and pointing toward what might be more usable QA\nsystems.", "published": "2021-09-21 19:39:42", "link": "http://arxiv.org/abs/2109.10415v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval", "abstract": "In neural Information Retrieval (IR), ongoing research is directed towards\nimproving the first retriever in ranking pipelines. Learning dense embeddings\nto conduct retrieval using efficient approximate nearest neighbors methods has\nproven to work well. Meanwhile, there has been a growing interest in learning\n\\emph{sparse} representations for documents and queries, that could inherit\nfrom the desirable properties of bag-of-words models such as the exact matching\nof terms and the efficiency of inverted indexes. Introduced recently, the\nSPLADE model provides highly sparse representations and competitive results\nwith respect to state-of-the-art dense and sparse approaches. In this paper, we\nbuild on SPLADE and propose several significant improvements in terms of\neffectiveness and/or efficiency. More specifically, we modify the pooling\nmechanism, benchmark a model solely based on document expansion, and introduce\nmodels trained with distillation. We also report results on the BEIR benchmark.\nOverall, SPLADE is considerably improved with more than $9$\\% gains on NDCG@10\non TREC DL 2019, leading to state-of-the-art results on the BEIR benchmark.", "published": "2021-09-21 10:43:42", "link": "http://arxiv.org/abs/2109.10086v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "On the Difficulty of Segmenting Words with Attention", "abstract": "Word segmentation, the problem of finding word boundaries in speech, is of\ninterest for a range of tasks. Previous papers have suggested that for\nsequence-to-sequence models trained on tasks such as speech translation or\nspeech recognition, attention can be used to locate and segment the words. We\nshow, however, that even on monolingual data this approach is brittle. In our\nexperiments with different input types, data sizes, and segmentation\nalgorithms, only models trained to predict phones from words succeed in the\ntask. Models trained to predict words from either phones or speech (i.e., the\nopposite direction needed to generalize to new data), yield much worse results,\nsuggesting that attention-based segmentation is only useful in limited\nscenarios.", "published": "2021-09-21 11:37:08", "link": "http://arxiv.org/abs/2109.10107v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Does Vision-and-Language Pretraining Improve Lexical Grounding?", "abstract": "Linguistic representations derived from text alone have been criticized for\ntheir lack of grounding, i.e., connecting words to their meanings in the\nphysical world. Vision-and-Language (VL) models, trained jointly on text and\nimage or video data, have been offered as a response to such criticisms.\nHowever, while VL pretraining has shown success on multimodal tasks such as\nvisual question answering, it is not yet known how the internal linguistic\nrepresentations themselves compare to their text-only counterparts. This paper\ncompares the semantic representations learned via VL vs. text-only pretraining\nfor two recent VL models using a suite of analyses (clustering, probing, and\nperformance on a commonsense question answering task) in a language-only\nsetting. We find that the multimodal models fail to significantly outperform\nthe text-only variants, suggesting that future work is required if multimodal\npretraining is to be pursued as a means of improving NLP in general.", "published": "2021-09-21 15:12:39", "link": "http://arxiv.org/abs/2109.10246v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Audiomer: A Convolutional Transformer For Keyword Spotting", "abstract": "Transformers have seen an unprecedented rise in Natural Language Processing\nand Computer Vision tasks. However, in audio tasks, they are either infeasible\nto train due to extremely large sequence length of audio waveforms or incur a\nperformance penalty when trained on Fourier-based features. In this work, we\nintroduce an architecture, Audiomer, where we combine 1D Residual Networks with\nPerformer Attention to achieve state-of-the-art performance in keyword spotting\nwith raw audio waveforms, outperforming all previous methods while being\ncomputationally cheaper and parameter-efficient. Additionally, our model has\npractical advantages for speech processing, such as inference on arbitrarily\nlong audio clips owing to the absence of positional encoding. The code is\navailable at https://github.com/The-Learning-Machines/Audiomer-PyTorch.", "published": "2021-09-21 15:28:41", "link": "http://arxiv.org/abs/2109.10252v4", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "RETRONLU: Retrieval Augmented Task-Oriented Semantic Parsing", "abstract": "While large pre-trained language models accumulate a lot of knowledge in\ntheir parameters, it has been demonstrated that augmenting it with\nnon-parametric retrieval-based memory has a number of benefits from accuracy\nimprovements to data efficiency for knowledge-focused tasks, such as question\nanswering. In this paper, we are applying retrieval-based modeling ideas to the\nproblem of multi-domain task-oriented semantic parsing for conversational\nassistants. Our approach, RetroNLU, extends a sequence-to-sequence model\narchitecture with a retrieval component, used to fetch existing similar\nexamples and provide them as an additional input to the model. In particular,\nwe analyze two settings, where we augment an input with (a) retrieved nearest\nneighbor utterances (utterance-nn), and (b) ground-truth semantic parses of\nnearest neighbor utterances (semparse-nn). Our technique outperforms the\nbaseline method by 1.5% absolute macro-F1, especially at the low resource\nsetting, matching the baseline model accuracy with only 40% of the data.\nFurthermore, we analyze the nearest neighbor retrieval component's quality,\nmodel sensitivity and break down the performance for semantic parses of\ndifferent utterance complexity.", "published": "2021-09-21 19:30:30", "link": "http://arxiv.org/abs/2109.10410v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Add-On for Empowering Google Forms to be an Automatic Question\n  Generator in Online Assessments", "abstract": "This research suggests an add-on to empower Google Forms to be an automatic\nmachine for generating multiple-choice questions (MCQs) used in online\nassessments. In this paper, we elaborate an add-on design mainly comprising\nquestion-formulating software and data storage. The algorithm as an\nintellectual mechanism of this software can produce MCQs at an analytical\nlevel. In an experiment, we found the MCQs could assess levels of students'\nknowledge comparably with those generated by human experts. This add-on can be\napplied generally to formulate MCQs for any rational concepts. With no effort\nfrom an instructor at runtime, the add-on can transform a few data instances\ndescribing rational concepts to be variety sets of MCQs.", "published": "2021-09-21 07:18:44", "link": "http://arxiv.org/abs/2110.15220v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "An Audio Synthesis Framework Derived from Industrial Process Control", "abstract": "Since its conception, digital synthesis has significantly influenced the\nadvancement of music, leading to new genres and production styles. Through\nexisting synthesis techniques, one can recreate naturally occurring sounds as\nwell as generate innovative artificial timbres. However, research in audio\ntechnology continues to pursue new methods of synthesizing sounds, keeping the\ntransformation of music constant. This research attempts to formulate the\nframework of a new synthesis technique by redefining the popular\nProportional-Integral-Derivative (PID) algorithm used in feedback-based process\ncontrol. The framework is then implemented as a Python application to study the\navailable control parameters and their effect on the synthesized output.\nFurther, applications of this technique as an audio signal and LFO generator,\nincluding its potentiality as an alternative to FM and Wavetable synthesis\ntechniques, are studied in detail. The research concludes by highlighting some\nof the imperfections in the current framework and the possible research\ndirections to be considered to address them.", "published": "2021-09-21 23:20:51", "link": "http://arxiv.org/abs/2109.10455v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Interval Retrieval using Convolutional Neural Networks", "abstract": "Modern streaming services are increasingly labeling videos based on their\nvisual or audio content. This typically augments the use of technologies such\nas AI and ML by allowing to use natural speech for searching by keywords and\nvideo descriptions. Prior research has successfully provided a number of\nsolutions for speech to text, in the case of a human speech, but this article\naims to investigate possible solutions to retrieve sound events based on a\nnatural language query, and estimate how effective and accurate they are. In\nthis study, we specifically focus on the YamNet, AlexNet, and ResNet-50\npre-trained models to automatically classify audio samples using their\nrespective melspectrograms into a number of predefined classes. The predefined\nclasses can represent sounds associated with actions within a video fragment.\nTwo tests are conducted to evaluate the performance of the models on two\nseparate problems: audio classification and intervals retrieval based on a\nnatural language query. Results show that the benchmarked models are comparable\nin terms of performance, with YamNet slightly outperforming the other two\nmodels. YamNet was able to classify single fixed-size audio samples with 92.7%\naccuracy and 68.75% precision while its average accuracy on intervals retrieval\nwas 71.62% and precision was 41.95%. The investigated method may be embedded\ninto an automated event marking architecture for streaming services.", "published": "2021-09-21 01:32:18", "link": "http://arxiv.org/abs/2109.09906v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
