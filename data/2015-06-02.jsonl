{"title": "The Influence of Context on Dialogue Act Recognition", "abstract": "This article presents an analysis of the influence of context information on\ndialog act recognition. We performed experiments on the widely explored\nSwitchboard corpus, as well as on data annotated according to the recent ISO\n24617-2 standard. The latter was obtained from the Tilburg DialogBank and\nthrough the mapping of the annotations of a subset of the Let's Go corpus. We\nused a classification approach based on SVMs, which had proved successful in\nprevious work and allowed us to limit the amount of context information\nprovided. This way, we were able to observe the influence patterns as the\namount of context information increased. Our base features consisted of\nn-grams, punctuation, and wh-words. Context information was obtained from one\nto five preceding segments and provided either as n-grams or dialog act\nclassifications, with the latter typically leading to better results and more\nstable influence patterns. In addition to the conclusions about the importance\nand influence of context information, our experiments on the Switchboard corpus\nalso led to results that advanced the state-of-the-art on the dialog act\nrecognition task on that corpus. Furthermore, the results obtained on data\nannotated according to the ISO 24617-2 standard define a baseline for future\nwork and contribute for the standardization of experiments in the area.", "published": "2015-06-02 11:12:19", "link": "http://arxiv.org/abs/1506.00839v2", "categories": ["cs.CL", "H.1.2; H.3.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Neural Autoencoder for Paragraphs and Documents", "abstract": "Natural language generation of coherent long texts like paragraphs or longer\ndocuments is a challenging problem for recurrent networks models. In this\npaper, we explore an important step toward this generation task: training an\nLSTM (Long-short term memory) auto-encoder to preserve and reconstruct\nmulti-sentence paragraphs. We introduce an LSTM model that hierarchically\nbuilds an embedding for a paragraph from embeddings for sentences and words,\nthen decodes this embedding to reconstruct the original paragraph. We evaluate\nthe reconstructed paragraph using standard metrics like ROUGE and Entity Grid,\nshowing that neural models are able to encode texts in a way that preserve\nsyntactic, semantic, and discourse coherence. While only a first step toward\ngenerating coherent text units from neural models, our work has the potential\nto significantly impact natural language generation and\nsummarization\\footnote{Code for the three models described in this paper can be\nfound at www.stanford.edu/~jiweil/ .", "published": "2015-06-02 20:53:53", "link": "http://arxiv.org/abs/1506.01057v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visualizing and Understanding Neural Models in NLP", "abstract": "While neural networks have been successfully applied to many NLP tasks the\nresulting vector-based models are very difficult to interpret. For example it's\nnot clear how they achieve {\\em compositionality}, building sentence meaning\nfrom the meanings of words and phrases. In this paper we describe four\nstrategies for visualizing compositionality in neural models for NLP, inspired\nby similar work in computer vision. We first plot unit values to visualize\ncompositionality of negation, intensification, and concessive clauses, allow us\nto see well-known markedness asymmetries in negation. We then introduce three\nsimple and straightforward methods for visualizing a unit's {\\em salience}, the\namount it contributes to the final composed meaning: (1) gradient\nback-propagation, (2) the variance of a token from the average word node, (3)\nLSTM-style gates that measure information flow. We test our methods on\nsentiment using simple recurrent nets and LSTMs. Our general-purpose methods\nmay have wide applications for understanding compositionality and other\nsemantic properties of deep networks , and also shed light on why LSTMs\noutperform simple recurrent nets,", "published": "2015-06-02 21:17:31", "link": "http://arxiv.org/abs/1506.01066v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Multi-Sense Embeddings Improve Natural Language Understanding?", "abstract": "Learning a distinct representation for each sense of an ambiguous word could\nlead to more powerful and fine-grained models of vector-space representations.\nYet while `multi-sense' methods have been proposed and tested on artificial\nword-similarity tasks, we don't know if they improve real natural language\nunderstanding tasks. In this paper we introduce a multi-sense embedding model\nbased on Chinese Restaurant Processes that achieves state of the art\nperformance on matching human word similarity judgments, and propose a\npipelined architecture for incorporating multi-sense embeddings into language\nunderstanding.\n  We then test the performance of our model on part-of-speech tagging, named\nentity recognition, sentiment analysis, semantic relation identification and\nsemantic relatedness, controlling for embedding dimensionality. We find that\nmulti-sense embeddings do improve performance on some tasks (part-of-speech\ntagging, semantic relation identification, semantic relatedness) but not on\nothers (named entity recognition, various forms of sentiment analysis). We\ndiscuss how these differences may be caused by the different role of word sense\ninformation in each of the tasks. The results highlight the importance of\ntesting embedding models in real applications.", "published": "2015-06-02 21:30:21", "link": "http://arxiv.org/abs/1506.01070v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Speech Rate in Speech Recognition", "abstract": "A significant performance reduction is often observed in speech recognition\nwhen the rate of speech (ROS) is too low or too high. Most of present\napproaches to addressing the ROS variation focus on the change of speech\nsignals in dynamic properties caused by ROS, and accordingly modify the dynamic\nmodel, e.g., the transition probabilities of the hidden Markov model (HMM).\nHowever, an abnormal ROS changes not only the dynamic but also the static\nproperty of speech signals, and thus can not be compensated for purely by\nmodifying the dynamic model. This paper proposes an ROS learning approach based\non deep neural networks (DNN), which involves an ROS feature as the input of\nthe DNN model and so the spectrum distortion caused by ROS can be learned and\ncompensated for. The experimental results show that this approach can deliver\nbetter performance for too slow and too fast utterances, demonstrating our\nconjecture that ROS impacts both the dynamic and the static property of speech.\nIn addition, the proposed approach can be combined with the conventional HMM\ntransition adaptation method, offering additional performance gains.", "published": "2015-06-02 08:59:47", "link": "http://arxiv.org/abs/1506.00799v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Video (GIF) Sentiment Analysis using Large-Scale Mid-Level Ontology", "abstract": "With faster connection speed, Internet users are now making social network a\nhuge reservoir of texts, images and video clips (GIF). Sentiment analysis for\nsuch online platform can be used to predict political elections, evaluates\neconomic indicators and so on. However, GIF sentiment analysis is quite\nchallenging, not only because it hinges on spatio-temporal visual\ncontentabstraction, but also for the relationship between such abstraction and\nfinal sentiment remains unknown.In this paper, we dedicated to find out such\nrelationship.We proposed a SentiPairSequence basedspatiotemporal visual\nsentiment ontology, which forms the midlevel representations for GIFsentiment.\nThe establishment process of SentiPair contains two steps. First, we construct\nthe Synset Forest to define the semantic tree structure of visual sentiment\nlabel elements. Then, through theSynset Forest, we organically select and\ncombine sentiment label elements to form a mid-level visual sentiment\nrepresentation. Our experiments indicate that SentiPair outperforms other\ncompeting mid-level attributes. Using SentiPair, our analysis frameworkcan\nachieve satisfying prediction accuracy (72.6%). We also opened ourdataset\n(GSO-2015) to the research community. GSO-2015 contains more than 6,000\nmanually annotated GIFs out of more than 40,000 candidates. Each is labeled\nwith both sentiment and SentiPair Sequence.", "published": "2015-06-02 06:31:57", "link": "http://arxiv.org/abs/1506.00765v1", "categories": ["cs.MM", "cs.CL", "cs.IR"], "primary_category": "cs.MM"}
{"title": "Combining Two And Three-Way Embeddings Models for Link Prediction in\n  Knowledge Bases", "abstract": "This paper tackles the problem of endogenous link prediction for Knowledge\nBase completion. Knowledge Bases can be represented as directed graphs whose\nnodes correspond to entities and edges to relationships. Previous attempts\neither consist of powerful systems with high capacity to model complex\nconnectivity patterns, which unfortunately usually end up overfitting on rare\nrelationships, or in approaches that trade capacity for simplicity in order to\nfairly model all relationships, frequent or not. In this paper, we propose\nTatec a happy medium obtained by complementing a high-capacity model with a\nsimpler one, both pre-trained separately and then combined. We present several\nvariants of this model with different kinds of regularization and combination\nstrategies and show that this approach outperforms existing methods on\ndifferent types of relationships by achieving state-of-the-art results on four\nbenchmarks of the literature.", "published": "2015-06-02 19:34:19", "link": "http://arxiv.org/abs/1506.00999v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
