{"title": "Algorithmic Prompt Generation for Diverse Human-like Teaming and Communication with Large Language Models", "abstract": "Understanding how humans collaborate and communicate in teams is essential\nfor improving human-agent teaming and AI-assisted decision-making. However,\nrelying solely on data from large-scale user studies is impractical due to\nlogistical, ethical, and practical constraints, necessitating synthetic models\nof multiple diverse human behaviors. Recently, agents powered by Large Language\nModels (LLMs) have been shown to emulate human-like behavior in social\nsettings. But, obtaining a large set of diverse behaviors requires manual\neffort in the form of designing prompts. On the other hand, Quality Diversity\n(QD) optimization has been shown to be capable of generating diverse\nReinforcement Learning (RL) agent behavior. In this work, we combine QD\noptimization with LLM-powered agents to iteratively search for prompts that\ngenerate diverse team behavior in a long-horizon, multi-step collaborative\nenvironment. We first show, through a human-subjects experiment (n=54\nparticipants), that humans exhibit diverse coordination and communication\nbehavior in this domain. We then show that our approach can effectively\nreplicate trends from human teaming data and also capture behaviors that are\nnot easily observed without collecting large amounts of data. Our findings\nhighlight the combination of QD and LLM-powered agents as an effective tool for\nstudying teaming and communication strategies in multi-agent collaboration.", "published": "2025-04-04 23:09:40", "link": "http://arxiv.org/abs/2504.03991v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Structured Extraction of Process Structure Properties Relationships in Materials Science", "abstract": "With the advent of large language models (LLMs), the vast unstructured text\nwithin millions of academic papers is increasingly accessible for materials\ndiscovery, although significant challenges remain. While LLMs offer promising\nfew- and zero-shot learning capabilities, particularly valuable in the\nmaterials domain where expert annotations are scarce, general-purpose LLMs\noften fail to address key materials-specific queries without further\nadaptation. To bridge this gap, fine-tuning LLMs on human-labeled data is\nessential for effective structured knowledge extraction. In this study, we\nintroduce a novel annotation schema designed to extract generic\nprocess-structure-properties relationships from scientific literature. We\ndemonstrate the utility of this approach using a dataset of 128 abstracts, with\nannotations drawn from two distinct domains: high-temperature materials (Domain\nI) and uncertainty quantification in simulating materials microstructure\n(Domain II). Initially, we developed a conditional random field (CRF) model\nbased on MatBERT, a domain-specific BERT variant, and evaluated its performance\non Domain I. Subsequently, we compared this model with a fine-tuned LLM (GPT-4o\nfrom OpenAI) under identical conditions. Our results indicate that fine-tuning\nLLMs can significantly improve entity extraction performance over the BERT-CRF\nbaseline on Domain I. However, when additional examples from Domain II were\nincorporated, the performance of the BERT-CRF model became comparable to that\nof the GPT-4o model. These findings underscore the potential of our schema for\nstructured knowledge extraction and highlight the complementary strengths of\nboth modeling approaches.", "published": "2025-04-04 22:44:02", "link": "http://arxiv.org/abs/2504.03979v1", "categories": ["cs.CL", "cond-mat.mtrl-sci", "cs.IR"], "primary_category": "cs.CL"}
{"title": "VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models", "abstract": "We introduce VideoComp, a benchmark and learning framework for advancing\nvideo-text compositionality understanding, aimed at improving vision-language\nmodels (VLMs) in fine-grained temporal alignment. Unlike existing benchmarks\nfocused on static image-text compositionality or isolated single-event videos,\nour benchmark targets alignment in continuous multi-event videos. Leveraging\nvideo-text datasets with temporally localized event captions (e.g.\nActivityNet-Captions, YouCook2), we construct two compositional benchmarks,\nActivityNet-Comp and YouCook2-Comp. We create challenging negative samples with\nsubtle temporal disruptions such as reordering, action word replacement,\npartial captioning, and combined disruptions. These benchmarks comprehensively\ntest models' compositional sensitivity across extended, cohesive video-text\nsequences. To improve model performance, we propose a hierarchical pairwise\npreference loss that strengthens alignment with temporally accurate pairs and\ngradually penalizes increasingly disrupted ones, encouraging fine-grained\ncompositional learning. To mitigate the limited availability of densely\nannotated video data, we introduce a pretraining strategy that concatenates\nshort video-caption pairs to simulate multi-event sequences. We evaluate\nvideo-text foundational models and large multimodal models (LMMs) on our\nbenchmark, identifying both strengths and areas for improvement in\ncompositionality. Overall, our work provides a comprehensive framework for\nevaluating and enhancing model capabilities in achieving fine-grained,\ntemporally coherent video-text alignment.", "published": "2025-04-04 22:24:30", "link": "http://arxiv.org/abs/2504.03970v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Clinical ModernBERT: An efficient and long context encoder for biomedical text", "abstract": "We introduce Clinical ModernBERT, a transformer based encoder pretrained on\nlarge scale biomedical literature, clinical notes, and medical ontologies,\nincorporating PubMed abstracts, MIMIC IV clinical data, and medical codes with\ntheir textual descriptions. Building on ModernBERT the current state of the art\nnatural language text encoder featuring architectural upgrades such as rotary\npositional embeddings (RoPE), Flash Attention, and extended context length up\nto 8,192 tokens our model adapts these innovations specifically for biomedical\nand clinical domains. Clinical ModernBERT excels at producing semantically rich\nrepresentations tailored for long context tasks. We validate this both by\nanalyzing its pretrained weights and through empirical evaluation on a\ncomprehensive suite of clinical NLP benchmarks.", "published": "2025-04-04 22:14:12", "link": "http://arxiv.org/abs/2504.03964v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking", "abstract": "We present a novel approach for training small language models for\nreasoning-intensive document ranking that combines knowledge distillation with\nreinforcement learning optimization. While existing methods often rely on\nexpensive human annotations or large black-box language models, our methodology\nleverages web data and a teacher LLM to automatically generate high-quality\ntraining examples with relevance explanations. By framing document ranking as a\nreinforcement learning problem and incentivizing explicit reasoning\ncapabilities, we train a compact 3B parameter language model that achieves\nstate-of-the-art performance on the BRIGHT benchmark. Our model ranks third on\nthe leaderboard while using substantially fewer parameters than other\napproaches, outperforming models that are over 20 times larger. Through\nextensive experiments, we demonstrate that generating explanations during\ninference, rather than directly predicting relevance scores, enables more\neffective reasoning with smaller language models. The self-supervised nature of\nour method offers a scalable and interpretable solution for modern information\nretrieval systems.", "published": "2025-04-04 21:27:48", "link": "http://arxiv.org/abs/2504.03947v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Language Models Are Implicitly Continuous", "abstract": "Language is typically modelled with discrete sequences. However, the most\nsuccessful approaches to language modelling, namely neural networks, are\ncontinuous and smooth function approximators. In this work, we show that\nTransformer-based language models implicitly learn to represent sentences as\ncontinuous-time functions defined over a continuous input space. This\nphenomenon occurs in most state-of-the-art Large Language Models (LLMs),\nincluding Llama2, Llama3, Phi3, Gemma, Gemma2, and Mistral, and suggests that\nLLMs reason about language in ways that fundamentally differ from humans. Our\nwork formally extends Transformers to capture the nuances of time and space\ncontinuity in both input and output space. Our results challenge the\ntraditional interpretation of how LLMs understand language, with several\nlinguistic and engineering implications.", "published": "2025-04-04 21:01:20", "link": "http://arxiv.org/abs/2504.03933v1", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "YaleNLP @ PerAnsSumm 2025: Multi-Perspective Integration via Mixture-of-Agents for Enhanced Healthcare QA Summarization", "abstract": "Automated summarization of healthcare community question-answering forums is\nchallenging due to diverse perspectives presented across multiple user\nresponses to each question. The PerAnsSumm Shared Task was therefore proposed\nto tackle this challenge by identifying perspectives from different answers and\nthen generating a comprehensive answer to the question. In this study, we\naddress the PerAnsSumm Shared Task using two complementary paradigms: (i) a\ntraining-based approach through QLoRA fine-tuning of LLaMA-3.3-70B-Instruct,\nand (ii) agentic approaches including zero- and few-shot prompting with\nfrontier LLMs (LLaMA-3.3-70B-Instruct and GPT-4o) and a Mixture-of-Agents (MoA)\nframework that leverages a diverse set of LLMs by combining outputs from\nmulti-layer feedback aggregation. For perspective span\nidentification/classification, GPT-4o zero-shot achieves an overall score of\n0.57, substantially outperforming the 0.40 score of the LLaMA baseline. With a\n2-layer MoA configuration, we were able to improve LLaMA performance up by 28\npercent to 0.51. For perspective-based summarization, GPT-4o zero-shot attains\nan overall score of 0.42 compared to 0.28 for the best LLaMA zero-shot, and our\n2-layer MoA approach boosts LLaMA performance by 32 percent to 0.37.\nFurthermore, in few-shot setting, our results show that the\nsentence-transformer embedding-based exemplar selection provides more gain than\nmanually selected exemplars on LLaMA models, although the few-shot prompting is\nnot always helpful for GPT-4o. The YaleNLP team's approach ranked the overall\nsecond place in the shared task.", "published": "2025-04-04 20:59:14", "link": "http://arxiv.org/abs/2504.03932v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptation of Large Language Models", "abstract": "This tutorial on adaptation of LLMs is designed to address the growing demand\nfor models that go beyond the static capabilities of generic LLMs by providing\nan overview of dynamic, domain-specific, and task-adaptive LLM adaptation\ntechniques. While general LLMs have demonstrated strong generalization across a\nvariety of tasks, they often struggle to perform well in specialized domains\nsuch as finance, healthcare, and code generation for underrepresented\nlanguages. Additionally, their static nature limits their ability to evolve\nwith the changing world, and they are often extremely large in size, making\nthem impractical and costly to deploy at scale. As a result, the adaptation of\nLLMs has drawn much attention since the birth of LLMs and is of core\nimportance, both for industry, which focuses on serving its targeted users, and\nacademia, which can greatly benefit from small but powerful LLMs. To address\nthis gap, this tutorial aims to provide an overview of the LLM adaptation\ntechniques. We start with an introduction to LLM adaptation, from both the data\nperspective and the model perspective. We then emphasize how the evaluation\nmetrics and benchmarks are different from other techniques. After establishing\nthe problems, we explore various adaptation techniques. We categorize\nadaptation techniques into two main families. The first is parametric knowledge\nadaptation, which focuses on updating the parametric knowledge within LLMs.\nAdditionally, we will discuss real-time adaptation techniques, including model\nediting, which allows LLMs to be updated dynamically in production\nenvironments. The second kind of adaptation is semi-parametric knowledge\nadaptation, where the goal is to update LLM parameters to better leverage\nexternal knowledge or tools through techniques like retrieval-augmented\ngeneration (RAG) and agent-based systems.", "published": "2025-04-04 20:57:41", "link": "http://arxiv.org/abs/2504.03931v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CliME: Evaluating Multimodal Climate Discourse on Social Media and the Climate Alignment Quotient (CAQ)", "abstract": "The rise of Large Language Models (LLMs) has raised questions about their\nability to understand climate-related contexts. Though climate change dominates\nsocial media, analyzing its multimodal expressions is understudied, and current\ntools have failed to determine whether LLMs amplify credible solutions or\nspread unsubstantiated claims. To address this, we introduce CliME (Climate\nChange Multimodal Evaluation), a first-of-its-kind multimodal dataset,\ncomprising 2579 Twitter and Reddit posts. The benchmark features a diverse\ncollection of humorous memes and skeptical posts, capturing how these formats\ndistill complex issues into viral narratives that shape public opinion and\npolicy discussions. To systematically evaluate LLM performance, we present the\nClimate Alignment Quotient (CAQ), a novel metric comprising five distinct\ndimensions: Articulation, Evidence, Resonance, Transition, and Specificity.\nAdditionally, we propose three analytical lenses: Actionability, Criticality,\nand Justice, to guide the assessment of LLM-generated climate discourse using\nCAQ. Our findings, based on the CAQ metric, indicate that while most evaluated\nLLMs perform relatively well in Criticality and Justice, they consistently\nunderperform on the Actionability axis. Among the models evaluated, Claude 3.7\nSonnet achieves the highest overall performance. We publicly release our CliME\ndataset and code to foster further research in this domain.", "published": "2025-04-04 20:01:00", "link": "http://arxiv.org/abs/2504.03906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do LLM Evaluators Prefer Themselves for a Reason?", "abstract": "Large language models (LLMs) are increasingly used as automatic evaluators in\napplications such as benchmarking, reward modeling, and self-refinement. Prior\nwork highlights a potential self-preference bias where LLMs favor their own\ngenerated responses, a tendency often intensifying with model size and\ncapability. This raises a critical question: Is self-preference detrimental, or\ndoes it simply reflect objectively superior outputs from more capable models?\nDisentangling these has been challenging due to the usage of subjective tasks\nin previous studies. To address this, we investigate self-preference using\nverifiable benchmarks (mathematical reasoning, factual knowledge, code\ngeneration) that allow objective ground-truth assessment. This enables us to\ndistinguish harmful self-preference (favoring objectively worse responses) from\nlegitimate self-preference (favoring genuinely superior ones). We conduct\nlarge-scale experiments under controlled evaluation conditions across diverse\nmodel families (e.g., Llama, Qwen, Gemma, Mistral, Phi, GPT, DeepSeek). Our\nfindings reveal three key insights: (1) Better generators are better judges --\nLLM evaluators' accuracy strongly correlates with their task performance, and\nmuch of the self-preference in capable models is legitimate. (2) Harmful\nself-preference persists, particularly when evaluator models perform poorly as\ngenerators on specific task instances. Stronger models exhibit more pronounced\nharmful bias when they err, though such incorrect generations are less\nfrequent. (3) Inference-time scaling strategies, such as generating a long\nChain-of-Thought before evaluation, effectively reduce the harmful\nself-preference. These results provide a more nuanced understanding of\nLLM-based evaluation and practical insights for improving its reliability.", "published": "2025-04-04 18:09:23", "link": "http://arxiv.org/abs/2504.03846v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bonsai: Interpretable Tree-Adaptive Grounded Reasoning", "abstract": "To develop general-purpose collaborative agents, humans need reliable AI\nsystems that can (1) adapt to new domains and (2) transparently reason with\nuncertainty to allow for verification and correction. Black-box models\ndemonstrate powerful data processing abilities but do not satisfy these\ncriteria due to their opaqueness, domain specificity, and lack of uncertainty\nawareness. We introduce Bonsai, a compositional and probabilistic reasoning\nsystem that generates adaptable inference trees by retrieving relevant\ngrounding evidence and using it to compute likelihoods of sub-claims derived\nfrom broader natural language inferences. Bonsai's reasoning power is tunable\nat test-time via evidence scaling and it demonstrates reliable handling of\nvaried domains including transcripts, photographs, videos, audio, and\ndatabases. Question-answering and human alignment experiments demonstrate that\nBonsai matches the performance of domain-specific black-box methods while\ngenerating interpretable, grounded, and uncertainty-aware reasoning traces.", "published": "2025-04-04 17:59:50", "link": "http://arxiv.org/abs/2504.03640v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "68T50, 68T37", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks requiring complex reasoning. However, the effects of\nscaling on their reasoning abilities remain insufficiently understood. In this\npaper, we introduce a synthetic multihop reasoning environment designed to\nclosely replicate the structure and distribution of real-world large-scale\nknowledge graphs. Our reasoning task involves completing missing edges in the\ngraph, which requires advanced multi-hop reasoning and mimics real-world\nreasoning scenarios. To evaluate this, we pretrain language models (LMs) from\nscratch solely on triples from the incomplete graph and assess their ability to\ninfer the missing edges. Interestingly, we observe that overparameterization\ncan impair reasoning performance due to excessive memorization. We investigate\ndifferent factors that affect this U-shaped loss curve, including graph\nstructure, model size, and training steps. To predict the optimal model size\nfor a specific knowledge graph, we find an empirical scaling that linearly maps\nthe knowledge graph search entropy to the optimal model size. This work\nprovides new insights into the relationship between scaling and reasoning in\nLLMs, shedding light on possible ways to optimize their performance for\nreasoning tasks.", "published": "2025-04-04 17:57:22", "link": "http://arxiv.org/abs/2504.03635v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models", "abstract": "As inference-time scaling becomes critical for enhanced reasoning\ncapabilities, it is increasingly becoming important to build models that are\nefficient to infer. We introduce Nemotron-H, a family of 8B and 56B/47B hybrid\nMamba-Transformer models designed to reduce inference cost for a given accuracy\nlevel. To achieve this goal, we replace the majority of self-attention layers\nin the common Transformer model architecture with Mamba layers that perform\nconstant computation and require constant memory per generated token. We show\nthat Nemotron-H models offer either better or on-par accuracy compared to other\nsimilarly-sized state-of-the-art open-sourced Transformer models (e.g.,\nQwen-2.5-7B/72B and Llama-3.1-8B/70B), while being up to 3$\\times$ faster at\ninference. To further increase inference speed and reduce the memory required\nat inference time, we created Nemotron-H-47B-Base from the 56B model using a\nnew compression via pruning and distillation technique called MiniPuzzle.\nNemotron-H-47B-Base achieves similar accuracy to the 56B model, but is 20%\nfaster to infer. In addition, we introduce an FP8-based training recipe and\nshow that it can achieve on par results with BF16-based training. This recipe\nis used to train the 56B model. All Nemotron-H models will be released, with\nsupport in Hugging Face, NeMo, and Megatron-LM.", "published": "2025-04-04 17:41:58", "link": "http://arxiv.org/abs/2504.03624v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Align to Structure: Aligning Large Language Models with Structural Information", "abstract": "Generating long, coherent text remains a challenge for large language models\n(LLMs), as they lack hierarchical planning and structured organization in\ndiscourse generation. We introduce Structural Alignment, a novel method that\naligns LLMs with human-like discourse structures to enhance long-form text\ngeneration. By integrating linguistically grounded discourse frameworks into\nreinforcement learning, our approach guides models to produce coherent and\nwell-organized outputs. We employ a dense reward scheme within a Proximal\nPolicy Optimization framework, assigning fine-grained, token-level rewards\nbased on the discourse distinctiveness relative to human writing. Two\ncomplementary reward models are evaluated: the first improves readability by\nscoring surface-level textual features to provide explicit structuring, while\nthe second reinforces deeper coherence and rhetorical sophistication by\nanalyzing global discourse patterns through hierarchical discourse motifs,\noutperforming both standard and RLHF-enhanced models in tasks such as essay\ngeneration and long-document summarization. All training data and code will be\npublicly shared at https://github.com/minnesotanlp/struct_align.", "published": "2025-04-04 17:40:04", "link": "http://arxiv.org/abs/2504.03622v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Retrieval-Augmented Generation for Knowledge-Intensive Task", "abstract": "Retrieval-augmented generation (RAG) has become a cornerstone of contemporary\nNLP, enhancing large language models (LLMs) by allowing them to access richer\nfactual contexts through in-context retrieval. While effective in monolingual\nsettings, especially in English, its use in multilingual tasks remains\nunexplored. This paper investigates the effectiveness of RAG across multiple\nlanguages by proposing novel approaches for multilingual open-domain\nquestion-answering. We evaluate the performance of various multilingual RAG\nstrategies, including question-translation (tRAG), which translates questions\ninto English before retrieval, and Multilingual RAG (MultiRAG), where retrieval\noccurs directly across multiple languages. Our findings reveal that tRAG, while\nuseful, suffers from limited coverage. In contrast, MultiRAG improves\nefficiency by enabling multilingual retrieval but introduces inconsistencies\ndue to cross-lingual variations in the retrieved content. To address these\nissues, we propose Crosslingual RAG (CrossRAG), a method that translates\nretrieved documents into a common language (e.g., English) before generating\nthe response. Our experiments show that CrossRAG significantly enhances\nperformance on knowledge-intensive tasks, benefiting both high-resource and\nlow-resource languages.", "published": "2025-04-04 17:35:43", "link": "http://arxiv.org/abs/2504.03616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AIR: A Systematic Analysis of Annotations, Instructions, and Response Pairs in Preference Dataset", "abstract": "Preference learning is critical for aligning large language models (LLMs)\nwith human values, yet its success hinges on high-quality datasets comprising\nthree core components: Preference \\textbf{A}nnotations, \\textbf{I}nstructions,\nand \\textbf{R}esponse Pairs. Current approaches conflate these components,\nobscuring their individual impacts and hindering systematic optimization. In\nthis work, we propose \\textbf{AIR}, a component-wise analysis framework that\nsystematically isolates and optimizes each component while evaluating their\nsynergistic effects. Through rigorous experimentation, AIR reveals actionable\nprinciples: annotation simplicity (point-wise generative scoring), instruction\ninference stability (variance-based filtering across LLMs), and response pair\nquality (moderate margins + high absolute scores). When combined, these\nprinciples yield +5.3 average gains over baseline method, even with only 14k\nhigh-quality pairs. Our work shifts preference dataset design from ad hoc\nscaling to component-aware optimization, offering a blueprint for efficient,\nreproducible alignment.", "published": "2025-04-04 17:33:07", "link": "http://arxiv.org/abs/2504.03612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay", "abstract": "Training effective AI agents for multi-turn interactions requires\nhigh-quality data that captures realistic human-agent dynamics, yet such data\nis scarce and expensive to collect manually. We introduce APIGen-MT, a\ntwo-phase framework that generates verifiable and diverse multi-turn agent\ndata. In the first phase, our agentic pipeline produces detailed task\nblueprints with ground-truth actions, leveraging a committee of LLM reviewers\nand iterative feedback loops. These blueprints are then transformed into\ncomplete interaction trajectories through simulated human-agent interplay. We\ntrain a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B\nto 70B parameters. Our models outperform frontier models such as GPT-4o and\nClaude 3.5 on $\\tau$-bench and BFCL benchmarks, with the smaller models\nsurpassing their larger counterparts, particularly in multi-turn settings,\nwhile maintaining superior consistency across multiple trials. Comprehensive\nexperiments demonstrate that our verified blueprint-to-details approach yields\nhigh-quality training data, enabling the development of more reliable,\nefficient, and capable agents. We open-source both the synthetic data collected\nand the trained xLAM-2-fc-r models to advance research in AI agents. Models are\navailable on HuggingFace at\nhttps://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4\nand project website is https://apigen-mt.github.io", "published": "2025-04-04 17:13:57", "link": "http://arxiv.org/abs/2504.03601v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EnrichIndex: Using LLMs to Enrich Retrieval Indices Offline", "abstract": "Existing information retrieval systems excel in cases where the language of\ntarget documents closely matches that of the user query. However, real-world\nretrieval systems are often required to implicitly reason whether a document is\nrelevant. For example, when retrieving technical texts or tables, their\nrelevance to the user query may be implied through a particular jargon or\nstructure, rather than explicitly expressed in their content. Large language\nmodels (LLMs) hold great potential in identifying such implied relevance by\nleveraging their reasoning skills. Nevertheless, current LLM-augmented\nretrieval is hindered by high latency and computation cost, as the LLM\ntypically computes the query-document relevance online, for every query anew.\nTo tackle this issue we introduce EnrichIndex, a retrieval approach which\ninstead uses the LLM offline to build semantically-enriched retrieval indices,\nby performing a single pass over all documents in the retrieval corpus once\nduring ingestion time. Furthermore, the semantically-enriched indices can\ncomplement existing online retrieval approaches, boosting the performance of\nLLM re-rankers. We evaluated EnrichIndex on five retrieval tasks, involving\npassages and tables, and found that it outperforms strong online LLM-based\nretrieval systems, with an average improvement of 11.7 points in recall @ 10\nand 10.6 points in NDCG @ 10 compared to strong baselines. In terms of online\ncalls to the LLM, it processes 293.3 times fewer tokens which greatly reduces\nthe online latency and cost. Overall, EnrichIndex is an effective way to build\nbetter retrieval indices offline by leveraging the strong reasoning skills of\nLLMs.", "published": "2025-04-04 17:08:46", "link": "http://arxiv.org/abs/2504.03598v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Extending the SAREF4ENER Ontology with Flexibility Based on FlexOffers", "abstract": "A key element to support the increased amounts of renewable energy in the\nenergy system is flexibility, i.e., the possibility of changing energy loads in\ntime and amount. Many flexibility models have been designed; however, exact\nmodels fail to scale for long time horizons or many devices. Because of this,\nthe FlexOffer (FOs) model has been designed, to provide device-independent\napproximations of flexibility with good accuracy, and much better scaling for\nlong time horizons and many devices. An important aspect of the real-life\nimplementation of energy flexibility is enabling flexible data exchange with\nmany types of smart energy appliances and market systems, e.g., in smart\nbuildings. For this, ontologies standardizing data formats are required.\nHowever, the current industry standard ontology for integrating smart devices\nfor energy purposes, SAREF for Energy Flexibility (SAREF4ENER) only has limited\nsupport for flexibility and thus cannot support important use cases. In this\npaper we propose an extension of SAREF4ENER that integrates full support for\nthe complete FlexOffer model, including advanced use cases, while maintaining\nbackward compatibility. This novel ontology module can accurately describe\nflexibility for advanced devices such as electric vehicles, batteries, and heat\npumps. It can also capture the inherent uncertainty associated with many\nflexible load types.", "published": "2025-04-04 17:02:14", "link": "http://arxiv.org/abs/2504.03595v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement", "abstract": "In the interaction between agents and their environments, agents expand their\ncapabilities by planning and executing actions. However, LLM-based agents face\nsubstantial challenges when deployed in novel environments or required to\nnavigate unconventional action spaces. To empower agents to autonomously\nexplore environments, optimize workflows, and enhance their understanding of\nactions, we propose SynWorld, a framework that allows agents to synthesize\npossible scenarios with multi-step action invocation within the action space\nand perform Monte Carlo Tree Search (MCTS) exploration to effectively refine\ntheir action knowledge in the current environment. Our experiments demonstrate\nthat SynWorld is an effective and general approach to learning action knowledge\nin new environments. Code is available at https://github.com/zjunlp/SynWorld.", "published": "2025-04-04 16:10:57", "link": "http://arxiv.org/abs/2504.03561v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Agentic Knowledgeable Self-awareness", "abstract": "Large Language Models (LLMs) have achieved considerable performance across\nvarious agentic planning tasks. However, traditional agent planning approaches\nadopt a \"flood irrigation\" methodology that indiscriminately injects gold\ntrajectories, external feedback, and domain knowledge into agent models. This\npractice overlooks the fundamental human cognitive principle of situational\nself-awareness during decision-making-the ability to dynamically assess\nsituational demands and strategically employ resources during decision-making.\nWe propose agentic knowledgeable self-awareness to address this gap, a novel\nparadigm enabling LLM-based agents to autonomously regulate knowledge\nutilization. Specifically, we propose KnowSelf, a data-centric approach that\napplies agents with knowledgeable self-awareness like humans. Concretely, we\ndevise a heuristic situation judgement criterion to mark special tokens on the\nagent's self-explored trajectories for collecting training data. Through a\ntwo-stage training process, the agent model can switch between different\nsituations by generating specific special tokens, achieving optimal planning\neffects with minimal costs. Our experiments demonstrate that KnowSelf can\noutperform various strong baselines on different tasks and models with minimal\nuse of external knowledge. Code is available at\nhttps://github.com/zjunlp/KnowSelf.", "published": "2025-04-04 16:03:38", "link": "http://arxiv.org/abs/2504.03553v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "MultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation", "abstract": "Multilingual speech translation (ST) in the medical domain enhances patient\ncare by enabling efficient communication across language barriers, alleviating\nspecialized workforce shortages, and facilitating improved diagnosis and\ntreatment, particularly during pandemics. In this work, we present the first\nsystematic study on medical ST, to our best knowledge, by releasing\nMultiMed-ST, a large-scale ST dataset for the medical domain, spanning all\ntranslation directions in five languages: Vietnamese, English, German, French,\nTraditional Chinese and Simplified Chinese, together with the models. With\n290,000 samples, our dataset is the largest medical machine translation (MT)\ndataset and the largest many-to-many multilingual ST among all domains.\nSecondly, we present the most extensive analysis study in ST research to date,\nincluding: empirical baselines, bilingual-multilingual comparative study,\nend-to-end vs. cascaded comparative study, task-specific vs. multi-task\nsequence-to-sequence (seq2seq) comparative study, code-switch analysis, and\nquantitative-qualitative error analysis. All code, data, and models are\navailable online: https://github.com/leduckhai/MultiMed-ST.", "published": "2025-04-04 15:49:17", "link": "http://arxiv.org/abs/2504.03546v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Diverse In-Context Example Selection After Decomposing Programs and Aligned Utterances Improves Semantic Parsing", "abstract": "LLMs are increasingly used as seq2seq translators from natural language\nutterances to structured programs, a process called semantic interpretation.\nUnlike atomic labels or token sequences, programs are naturally represented as\nabstract syntax trees (ASTs). Such structured representation raises novel\nissues related to the design and selection of in-context examples (ICEs)\npresented to the LLM. We focus on decomposing the pool of available ICE trees\ninto fragments, some of which may be better suited to solving the test\ninstance. Next, we propose how to use (additional invocations of) an LLM with\nprompted syntax constraints to automatically map the fragments to corresponding\nutterances. Finally, we adapt and extend a recent method for diverse ICE\nselection to work with whole and fragmented ICE instances. We evaluate our\nsystem, SCUD4ICL, on popular diverse semantic parsing benchmarks, showing\nvisible accuracy gains from our proposed decomposed diverse demonstration\nmethod. Benefits are particularly notable for smaller LLMs, ICE pools having\nlarger labeled trees, and programs in lower resource languages.", "published": "2025-04-04 15:41:44", "link": "http://arxiv.org/abs/2504.03541v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neutralizing the Narrative: AI-Powered Debiasing of Online News Articles", "abstract": "Bias in news reporting significantly impacts public perception, particularly\nregarding crime, politics, and societal issues. Traditional bias detection\nmethods, predominantly reliant on human moderation, suffer from subjective\ninterpretations and scalability constraints. Here, we introduce an AI-driven\nframework leveraging advanced large language models (LLMs), specifically\nGPT-4o, GPT-4o Mini, Gemini Pro, Gemini Flash, Llama 8B, and Llama 3B, to\nsystematically identify and mitigate biases in news articles. To this end, we\ncollect an extensive dataset consisting of over 30,000 crime-related articles\nfrom five politically diverse news sources spanning a decade (2013-2023). Our\napproach employs a two-stage methodology: (1) bias detection, where each LLM\nscores and justifies biased content at the paragraph level, validated through\nhuman evaluation for ground truth establishment, and (2) iterative debiasing\nusing GPT-4o Mini, verified by both automated reassessment and human reviewers.\nEmpirical results indicate GPT-4o Mini's superior accuracy in bias detection\nand effectiveness in debiasing. Furthermore, our analysis reveals temporal and\ngeographical variations in media bias correlating with socio-political dynamics\nand real-world events. This study contributes to scalable computational\nmethodologies for bias mitigation, promoting fairness and accountability in\nnews reporting.", "published": "2025-04-04 15:17:53", "link": "http://arxiv.org/abs/2504.03520v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Structured Legal Document Generation in India: A Model-Agnostic Wrapper Approach with VidhikDastaavej", "abstract": "Automating legal document drafting can significantly enhance efficiency,\nreduce manual effort, and streamline legal workflows. While prior research has\nexplored tasks such as judgment prediction and case summarization, the\nstructured generation of private legal documents in the Indian legal domain\nremains largely unaddressed. To bridge this gap, we introduce VidhikDastaavej,\na novel, anonymized dataset of private legal documents, and develop NyayaShilp,\na fine-tuned legal document generation model specifically adapted to Indian\nlegal texts. We propose a Model-Agnostic Wrapper (MAW), a two-step framework\nthat first generates structured section titles and then iteratively produces\ncontent while leveraging retrieval-based mechanisms to ensure coherence and\nfactual accuracy. We benchmark multiple open-source LLMs, including\ninstruction-tuned and domain-adapted versions, alongside proprietary models for\ncomparison. Our findings indicate that while direct fine-tuning on small\ndatasets does not always yield improvements, our structured wrapper\nsignificantly enhances coherence, factual adherence, and overall document\nquality while mitigating hallucinations. To ensure real-world applicability, we\ndeveloped a Human-in-the-Loop (HITL) Document Generation System, an interactive\nuser interface that enables users to specify document types, refine section\ndetails, and generate structured legal drafts. This tool allows legal\nprofessionals and researchers to generate, validate, and refine AI-generated\nlegal documents efficiently. Extensive evaluations, including expert\nassessments, confirm that our framework achieves high reliability in structured\nlegal drafting. This research establishes a scalable and adaptable foundation\nfor AI-assisted legal drafting in India, offering an effective approach to\nstructured legal document generation.", "published": "2025-04-04 14:41:50", "link": "http://arxiv.org/abs/2504.03486v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?", "abstract": "Large language models (LLMs) are increasingly contributing to the creation of\ncontent on the Internet. This creates a feedback loop as subsequent generations\nof models will be trained on this generated, synthetic data. This phenomenon is\nreceiving increasing interest, in particular because previous studies have\nshown that it may lead to distribution shift - models misrepresent and forget\nthe true underlying distributions of human data they are expected to\napproximate (e.g. resulting in a drastic loss of quality). In this study, we\nstudy the impact of human data properties on distribution shift dynamics in\niterated training loops. We first confirm that the distribution shift dynamics\ngreatly vary depending on the human data by comparing four datasets (two based\non Twitter and two on Reddit). We then test whether data quality may influence\nthe rate of this shift. We find that it does on the twitter, but not on the\nReddit datasets. We then focus on a Reddit dataset and conduct a more\nexhaustive evaluation of a large set of dataset properties. This experiment\nassociated lexical diversity with larger, and semantic diversity with smaller\ndetrimental shifts, suggesting that incorporating text with high lexical (but\nlimited semantic) diversity could exacerbate the degradation of generated text.\nWe then focus on the evolution of political bias, and find that the type of\nshift observed (bias reduction, amplification or inversion) depends on the\npolitical lean of the human (true) distribution. Overall, our work extends the\nexisting literature on the consequences of recursive fine-tuning by showing\nthat this phenomenon is highly dependent on features of the human data on which\ntraining occurs. This suggests that different parts of internet (e.g. GitHub,\nReddit) may undergo different types of shift depending on their properties.", "published": "2025-04-04 14:41:41", "link": "http://arxiv.org/abs/2504.03814v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.LG"}
{"title": "SpectR: Dynamically Composing LM Experts with Spectral Routing", "abstract": "Training large, general-purpose language models poses significant challenges.\nThe growing availability of specialized expert models, fine-tuned from\npretrained models for specific tasks or domains, offers a promising\nalternative. Leveraging the potential of these existing expert models in\nreal-world applications requires effective methods to select or merge the\nmodels best suited for a given task. This paper introduces SPECTR, an approach\nfor dynamically composing expert models at each time step during inference.\nNotably, our method requires no additional training and enables flexible,\ntoken- and layer-wise model combinations. Our experimental results demonstrate\nthat SPECTR improves routing accuracy over alternative training-free methods,\nincreasing task performance across expert domains.", "published": "2025-04-04 13:58:44", "link": "http://arxiv.org/abs/2504.03454v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Locations of Characters in Narratives: Andersen and Persuasion Datasets", "abstract": "The ability of machines to grasp spatial understanding within narrative\ncontexts is an intriguing aspect of reading comprehension that continues to be\nstudied. Motivated by the goal to test the AI's competence in understanding the\nrelationship between characters and their respective locations in narratives,\nwe introduce two new datasets: Andersen and Persuasion. For the Andersen\ndataset, we selected fifteen children's stories from \"Andersen's Fairy Tales\"\nby Hans Christian Andersen and manually annotated the characters and their\nrespective locations throughout each story. Similarly, for the Persuasion\ndataset, characters and their locations in the novel \"Persuasion\" by Jane\nAusten were also manually annotated. We used these datasets to prompt Large\nLanguage Models (LLMs). The prompts are created by extracting excerpts from the\nstories or the novel and combining them with a question asking the location of\na character mentioned in that excerpt. Out of the five LLMs we tested, the\nbest-performing one for the Andersen dataset accurately identified the location\nin 61.85% of the examples, while for the Persuasion dataset, the\nbest-performing one did so in 56.06% of the cases.", "published": "2025-04-04 13:25:32", "link": "http://arxiv.org/abs/2504.03434v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Online Difficulty Filtering for Reasoning Oriented Reinforcement Learning", "abstract": "Reasoning-Oriented Reinforcement Learning (RORL) enhances the reasoning\nability of Large Language Models (LLMs). However, due to the sparsity of\nrewards in RORL, effective training is highly dependent on the selection of\nproblems of appropriate difficulty. Although curriculum learning attempts to\naddress this by adjusting difficulty, it often relies on static schedules, and\neven recent online filtering methods lack theoretical grounding and a\nsystematic understanding of their effectiveness. In this work, we theoretically\nand empirically show that curating the batch with the problems that the\ntraining model achieves intermediate accuracy on the fly can maximize the\neffectiveness of RORL training, namely balanced online difficulty filtering. We\nfirst derive that the lower bound of the KL divergence between the initial and\nthe optimal policy can be expressed with the variance of the sampled accuracy.\nBuilding on those insights, we show that balanced filtering can maximize the\nlower bound, leading to better performance. Experimental results across five\nchallenging math reasoning benchmarks show that balanced online filtering\nyields an additional 10% in AIME and 4% improvements in average over plain\nGRPO. Moreover, further analysis shows the gains in sample efficiency and\ntraining time efficiency, exceeding the maximum reward of plain GRPO within 60%\ntraining time and the volume of the training set.", "published": "2025-04-04 11:52:05", "link": "http://arxiv.org/abs/2504.03380v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sustainable LLM Inference for Edge AI: Evaluating Quantized LLMs for Energy Efficiency, Output Accuracy, and Inference Latency", "abstract": "Deploying Large Language Models (LLMs) on edge devices presents significant\nchallenges due to computational constraints, memory limitations, inference\nspeed, and energy consumption. Model quantization has emerged as a key\ntechnique to enable efficient LLM inference by reducing model size and\ncomputational overhead. In this study, we conduct a comprehensive analysis of\n28 quantized LLMs from the Ollama library, which applies by default\nPost-Training Quantization (PTQ) and weight-only quantization techniques,\ndeployed on an edge device (Raspberry Pi 4 with 4GB RAM). We evaluate energy\nefficiency, inference performance, and output accuracy across multiple\nquantization levels and task types. Models are benchmarked on five standardized\ndatasets (CommonsenseQA, BIG-Bench Hard, TruthfulQA, GSM8K, and HumanEval), and\nwe employ a high-resolution, hardware-based energy measurement tool to capture\nreal-world power consumption. Our findings reveal the trade-offs between energy\nefficiency, inference speed, and accuracy in different quantization settings,\nhighlighting configurations that optimize LLM deployment for\nresource-constrained environments. By integrating hardware-level energy\nprofiling with LLM benchmarking, this study provides actionable insights for\nsustainable AI, bridging a critical gap in existing research on energy-aware\nLLM deployment.", "published": "2025-04-04 11:29:30", "link": "http://arxiv.org/abs/2504.03360v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Detecting Stereotypes and Anti-stereotypes the Correct Way Using Social Psychological Underpinnings", "abstract": "Stereotypes are known to be highly pernicious, making their detection\ncritically important. However, current research predominantly focuses on\ndetecting and evaluating stereotypical biases in LLMs, leaving the study of\nstereotypes in its early stages. Many studies have failed to clearly\ndistinguish between stereotypes and stereotypical biases, which has\nsignificantly slowed progress in advancing research in this area. Stereotype\nand anti-stereotype detection is a problem that requires knowledge of society;\nhence, it is one of the most difficult areas in Responsible AI. This work\ninvestigates this task, where we propose a four-tuple definition and provide\nprecise terminology distinguishing stereotype, anti-stereotype, stereotypical\nbias, and bias, offering valuable insights into their various aspects. In this\npaper, we propose StereoDetect, a high-quality benchmarking dataset curated for\nthis task by optimally utilizing current datasets such as StereoSet and\nWinoQueer, involving a manual verification process and the transfer of semantic\ninformation. We demonstrate that language models for reasoning with fewer than\n10B parameters often get confused when detecting anti-stereotypes. We also\ndemonstrate the critical importance of well-curated datasets by comparing our\nmodel with other current models for stereotype detection. The dataset and code\nis available at https://github.com/KaustubhShejole/StereoDetect.", "published": "2025-04-04 11:14:38", "link": "http://arxiv.org/abs/2504.03352v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "BabyLM's First Words: Word Segmentation as a Phonological Probing Task", "abstract": "Language models provide a key framework for studying linguistic theories\nbased on prediction, but phonological analysis using large language models\n(LLMs) is difficult; there are few phonological benchmarks beyond English and\nthe standard input representation used in LLMs (subwords of graphemes) is not\nsuitable for analyzing the representation of phonemes. In this work, we\ndemonstrate how word segmentation can be used as a phonological probing task,\nallowing us to study the representations learned by phoneme-based language\nmodels trained on child-directed speech across 31 languages. Following\ncomputational models of word segmentation, we present unsupervised methods for\nextracting word boundaries from a trained model using the observation that\nprediction-error peaks at the start of words. We also use linear probes to\nidentify that these models implicitly track word boundaries, even when they do\nnot appear in training. This cross-lingual work corroborates statistical\nlearning theories of acquisition and empirically motivates new methods for\ntraining subword tokenizers.", "published": "2025-04-04 10:42:56", "link": "http://arxiv.org/abs/2504.03338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimal Embedding Guided Negative Sample Generation for Knowledge Graph Link Prediction", "abstract": "Knowledge graph embedding (KGE) models encode the structural information of\nknowledge graphs to predicting new links. Effective training of these models\nrequires distinguishing between positive and negative samples with high\nprecision. Although prior research has shown that improving the quality of\nnegative samples can significantly enhance model accuracy, identifying\nhigh-quality negative samples remains a challenging problem. This paper\ntheoretically investigates the condition under which negative samples lead to\noptimal KG embedding and identifies a sufficient condition for an effective\nnegative sample distribution. Based on this theoretical foundation, we propose\n\\textbf{E}mbedding \\textbf{MU}tation (\\textsc{EMU}), a novel framework that\n\\emph{generates} negative samples satisfying this condition, in contrast to\nconventional methods that focus on \\emph{identifying} challenging negative\nsamples within the training data. Importantly, the simplicity of \\textsc{EMU}\nensures seamless integration with existing KGE models and negative sampling\nmethods. To evaluate its efficacy, we conducted comprehensive experiments\nacross multiple datasets. The results consistently demonstrate significant\nimprovements in link prediction performance across various KGE models and\nnegative sampling methods. Notably, \\textsc{EMU} enables performance\nimprovements comparable to those achieved by models with embedding dimension\nfive times larger. An implementation of the method and experiments are\navailable at https://github.com/nec-research/EMU-KG.", "published": "2025-04-04 10:10:18", "link": "http://arxiv.org/abs/2504.03327v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Evaluating Compact LLMs for Zero-Shot Iberian Language Tasks on End-User Devices", "abstract": "Large Language Models have significantly advanced natural language\nprocessing, achieving remarkable performance in tasks such as language\ngeneration, translation, and reasoning. However, their substantial\ncomputational requirements restrict deployment to high-end systems, limiting\naccessibility on consumer-grade devices. This challenge is especially\npronounced for under-resourced languages like those spoken in the Iberian\nPeninsula, where relatively limited linguistic resources and benchmarks hinder\neffective evaluation. This work presents a comprehensive evaluation of compact\nstate-of-the-art LLMs across several essential NLP tasks tailored for Iberian\nlanguages. The results reveal that while some models consistently excel in\ncertain tasks, significant performance gaps remain, particularly for languages\nsuch as Basque. These findings highlight the need for further research on\nbalancing model compactness with robust multilingual performance", "published": "2025-04-04 09:47:58", "link": "http://arxiv.org/abs/2504.03312v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Noise Augmented Fine Tuning for Mitigating Hallucinations in Large Language Models", "abstract": "Large language models (LLMs) often produce inaccurate or misleading\ncontent-hallucinations. To address this challenge, we introduce Noise-Augmented\nFine-Tuning (NoiseFiT), a novel framework that leverages adaptive noise\ninjection based on the signal-to-noise ratio (SNR) to enhance model robustness.\nIn particular, NoiseFiT selectively perturbs layers identified as either\nhigh-SNR (more robust) or low-SNR (potentially under-regularized) using a\ndynamically scaled Gaussian noise. We further propose a hybrid loss that\ncombines standard cross-entropy, soft cross-entropy, and consistency\nregularization to ensure stable and accurate outputs under noisy training\nconditions. Our theoretical analysis shows that adaptive noise injection is\nboth unbiased and variance-preserving, providing strong guarantees for\nconvergence in expectation. Empirical results on multiple test and benchmark\ndatasets demonstrate that NoiseFiT significantly reduces hallucination rates,\noften improving or matching baseline performance in key tasks. These findings\nhighlight the promise of noise-driven strategies for achieving robust,\ntrustworthy language modeling without incurring prohibitive computational\noverhead. Given the comprehensive and detailed nature of our experiments, we\nhave publicly released the fine-tuning logs, benchmark evaluation artifacts,\nand source code online at W&B, Hugging Face, and GitHub, respectively, to\nfoster further research, accessibility and reproducibility.", "published": "2025-04-04 09:27:19", "link": "http://arxiv.org/abs/2504.03302v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Stance-Driven Multimodal Controlled Statement Generation: New Dataset and Task", "abstract": "Formulating statements that support diverse or controversial stances on\nspecific topics is vital for platforms that enable user expression, reshape\npolitical discourse, and drive social critique and information dissemination.\nWith the rise of Large Language Models (LLMs), controllable text generation\ntowards specific stances has become a promising research area with applications\nin shaping public opinion and commercial marketing. However, current datasets\noften focus solely on pure texts, lacking multimodal content and effective\ncontext, particularly in the context of stance detection. In this paper, we\nformally define and study the new problem of stance-driven controllable content\ngeneration for tweets with text and images, where given a multimodal post (text\nand image/video), a model generates a stance-controlled response. To this end,\nwe create the Multimodal Stance Generation Dataset (StanceGen2024), the first\nresource explicitly designed for multimodal stance-controllable text generation\nin political discourse. It includes posts and user comments from the 2024 U.S.\npresidential election, featuring text, images, videos, and stance annotations\nto explore how multimodal political content shapes stance expression.\nFurthermore, we propose a Stance-Driven Multimodal Generation (SDMG) framework\nthat integrates weighted fusion of multimodal features and stance guidance to\nimprove semantic consistency and stance control. We release the dataset and\ncode (https://anonymous.4open.science/r/StanceGen-BE9D) for public use and\nfurther research.", "published": "2025-04-04 09:20:19", "link": "http://arxiv.org/abs/2504.03295v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RWKVTTS: Yet another TTS based on RWKV-7", "abstract": "Human-AI interaction thrives on intuitive and efficient interfaces, among\nwhich voice stands out as a particularly natural and accessible modality.\nRecent advancements in transformer-based text-to-speech (TTS) systems, such as\nFish-Speech, CosyVoice, and MegaTTS 3, have delivered remarkable improvements\nin quality and realism, driving a significant evolution in the TTS domain. In\nthis paper, we introduce RWKV-7 \\cite{peng2025rwkv}, a cutting-edge RNN-based\narchitecture tailored for TTS applications. Unlike traditional transformer\nmodels, RWKV-7 leverages the strengths of recurrent neural networks to achieve\ngreater computational efficiency and scalability, while maintaining\nhigh-quality output. Our comprehensive benchmarks demonstrate that RWKV-7\noutperforms transformer-based models across multiple key metrics, including\nsynthesis speed, naturalness of speech, and resource efficiency. Furthermore,\nwe explore its adaptability to diverse linguistic contexts and low-resource\nenvironments, showcasing its potential to democratize TTS technology. These\nfindings position RWKV-7 as a powerful and innovative alternative, paving the\nway for more accessible and versatile voice synthesis solutions in real-world\napplications.Our code and weights are https://github.com/yynil/RWKVTTS,\nhttps://huggingface.co/spaces/RWKV-Red-Team", "published": "2025-04-04 09:17:20", "link": "http://arxiv.org/abs/2504.03289v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "What Large Language Models Do Not Talk About: An Empirical Study of Moderation and Censorship Practices", "abstract": "Large Language Models (LLMs) are increasingly deployed as gateways to\ninformation, yet their content moderation practices remain underexplored. This\nwork investigates the extent to which LLMs refuse to answer or omit information\nwhen prompted on political topics. To do so, we distinguish between hard\ncensorship (i.e., generated refusals, error messages, or canned denial\nresponses) and soft censorship (i.e., selective omission or downplaying of key\nelements), which we identify in LLMs' responses when asked to provide\ninformation on a broad range of political figures. Our analysis covers 14\nstate-of-the-art models from Western countries, China, and Russia, prompted in\nall six official United Nations (UN) languages. Our analysis suggests that\nalthough censorship is observed across the board, it is predominantly tailored\nto an LLM provider's domestic audience and typically manifests as either hard\ncensorship or soft censorship (though rarely both concurrently). These findings\nunderscore the need for ideological and geographic diversity among publicly\navailable LLMs, and greater transparency in LLM moderation strategies to\nfacilitate informed user choices. All data are made freely available.", "published": "2025-04-04 09:09:06", "link": "http://arxiv.org/abs/2504.03803v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inherent and emergent liability issues in LLM-based agentic systems: a principal-agent perspective", "abstract": "Agentic systems powered by large language models (LLMs) are becoming\nprogressively more complex and capable. Their increasing agency and expanding\ndeployment settings attract growing attention over effective governance\npolicies, monitoring and control protocols. Based on emerging landscapes of the\nagentic market, we analyze the potential liability issues stemming from\ndelegated use of LLM agents and their extended systems from a principal-agent\nperspective. Our analysis complements existing risk-based studies on artificial\nagency and covers the spectrum of important aspects of the principal-agent\nrelationship and their potential consequences at deployment. Furthermore, we\nmotivate method developments for technical governance along the directions of\ninterpretability and behavior evaluations, reward and conflict management, and\nthe mitigation of misalignment and misconduct through principled engineering of\ndetection and fail-safe mechanisms. By illustrating the outstanding issues in\nAI liability for LLM-based agentic systems, we aim to inform the system design,\nauditing and monitoring approaches to enhancing transparency and\naccountability.", "published": "2025-04-04 08:10:02", "link": "http://arxiv.org/abs/2504.03255v1", "categories": ["cs.CY", "cs.CL", "cs.MA"], "primary_category": "cs.CY"}
{"title": "Think When You Need: Self-Adaptive Chain-of-Thought Learning", "abstract": "Chain of Thought (CoT) reasoning enhances language models' performance but\noften leads to inefficient \"overthinking\" on simple problems. We identify that\nexisting approaches directly penalizing reasoning length fail to account for\nvarying problem complexity. Our approach constructs rewards through length and\nquality comparisons, guided by theoretical assumptions that jointly enhance\nsolution correctness with conciseness. Moreover, we further demonstrate our\nmethod to fuzzy tasks where ground truth is unavailable. Experiments across\nmultiple reasoning benchmarks demonstrate that our method maintains accuracy\nwhile generating significantly more concise explanations, effectively teaching\nmodels to \"think when needed.\"", "published": "2025-04-04 07:34:01", "link": "http://arxiv.org/abs/2504.03234v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Personalized Multi-Turn Dialogue with Curiosity Reward", "abstract": "Effective conversational agents must be able to personalize their behavior to\nsuit a user's preferences, personality, and attributes, whether they are\nassisting with writing tasks or operating in domains like education or\nhealthcare. Current training methods like Reinforcement Learning from Human\nFeedback (RLHF) prioritize helpfulness and safety but fall short in fostering\ntruly empathetic, adaptive, and personalized interactions. Traditional\napproaches to personalization often rely on extensive user history, limiting\ntheir effectiveness for new or context-limited users. To overcome these\nlimitations, we propose to incorporate an intrinsic motivation to improve the\nconversational agents's model of the user as an additional reward alongside\nmulti-turn RLHF. This reward mechanism encourages the agent to actively elicit\nuser traits by optimizing conversations to increase the accuracy of its user\nmodel. Consequently, the policy agent can deliver more personalized\ninteractions through obtaining more information about the user. We applied our\nmethod both education and fitness settings, where LLMs teach concepts or\nrecommend personalized strategies based on users' hidden learning style or\nlifestyle attributes. Using LLM-simulated users, our approach outperformed a\nmulti-turn RLHF baseline in revealing information about the users' preferences,\nand adapting to them.", "published": "2025-04-04 06:35:02", "link": "http://arxiv.org/abs/2504.03206v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explain with Visual Keypoints Like a Real Mentor! A Benchmark for Multimodal Solution Explanation", "abstract": "With the rapid advancement of mathematical reasoning capabilities in Large\nLanguage Models (LLMs), AI systems are increasingly being adopted in\neducational settings to support students' comprehension of problem-solving\nprocesses. However, a critical component remains underexplored in current\nLLM-generated explanations: visual explanation. In real-world instructional\ncontexts, human tutors routinely employ visual aids - such as diagrams,\nmarkings, and highlights - to enhance conceptual clarity. To bridge this gap,\nwe introduce a novel task of visual solution explanation, which requires\ngenerating explanations that incorporate newly introduced visual elements\nessential for understanding (e.g., auxiliary lines, annotations, or geometric\nconstructions). To evaluate model performance on this task, we propose\nMathExplain, a multimodal benchmark consisting of 997 math problems annotated\nwith visual keypoints and corresponding explanatory text that references those\nelements. Our empirical results show that while some closed-source models\ndemonstrate promising capabilities on visual solution-explaining, current\nopen-source general-purpose models perform inconsistently, particularly in\nidentifying relevant visual components and producing coherent keypoint-based\nexplanations. We expect that visual solution-explaining and the MathExplain\ndataset will catalyze further research on multimodal LLMs in education and\nadvance their deployment as effective, explanation-oriented AI tutors. Code and\ndata will be released publicly.", "published": "2025-04-04 06:03:13", "link": "http://arxiv.org/abs/2504.03197v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Natural Language Constraints for Safe Reinforcement Learning of Language Agents", "abstract": "Generalizable alignment is a core challenge for deploying Large Language\nModels (LLMs) safely in real-world NLP applications. Current alignment methods,\nincluding Reinforcement Learning from Human Feedback (RLHF), often fail to\nguarantee constraint satisfaction outside their training distribution due to\ntheir reliance on implicit, post-hoc preferences. Inspired by a paradigm shift\nto first curate data before tuning, we introduce a new framework for safe\nlanguage alignment that learns natural language constraints from positive and\nnegative demonstrations as a primary step. From inferring both a task-specific\nreward function and latent constraint functions, our approach fosters\nadaptation to novel safety requirements and robust generalization under domain\nshifts and adversarial inputs. We formalize the framework within a Constrained\nMarkov Decision Process (CMDP) and validate it via a text-based navigation\nenvironment, demonstrating safe adaptation to changing danger zones. Our\nexperiments show fewer violations upon domain shift when following a safe\nnavigation path, and we achieve zero violations by applying learned constraints\nto a distilled BERT model as a fine-tuning technique. This work offers a\npromising path toward building safety-critical and more generalizable LLMs for\npractical NLP settings.", "published": "2025-04-04 05:26:28", "link": "http://arxiv.org/abs/2504.03185v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.4; I.2.6; I.2.8"], "primary_category": "cs.CL"}
{"title": "Multi-lingual Multi-turn Automated Red Teaming for LLMs", "abstract": "Language Model Models (LLMs) have improved dramatically in the past few\nyears, increasing their adoption and the scope of their capabilities over time.\nA significant amount of work is dedicated to ``model alignment'', i.e.,\npreventing LLMs to generate unsafe responses when deployed into customer-facing\napplications. One popular method to evaluate safety risks is\n\\textit{red-teaming}, where agents attempt to bypass alignment by crafting\nelaborate prompts that trigger unsafe responses from a model. Standard\nhuman-driven red-teaming is costly, time-consuming and rarely covers all the\nrecent features (e.g., multi-lingual, multi-modal aspects), while proposed\nautomation methods only cover a small subset of LLMs capabilities (i.e.,\nEnglish or single-turn). We present Multi-lingual Multi-turn Automated Red\nTeaming (\\textbf{MM-ART}), a method to fully automate conversational,\nmulti-lingual red-teaming operations and quickly identify prompts leading to\nunsafe responses. Through extensive experiments on different languages, we show\nthe studied LLMs are on average 71\\% more vulnerable after a 5-turn\nconversation in English than after the initial turn. For conversations in\nnon-English languages, models display up to 195\\% more safety vulnerabilities\nthan the standard single-turn English approach, confirming the need for\nautomated red-teaming methods matching LLMs capabilities.", "published": "2025-04-04 05:06:12", "link": "http://arxiv.org/abs/2504.03174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Dynamic Clustering-Based Document Compression for Retrieval-Augmented-Generation", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach\nfor knowledge integration during large language model (LLM) inference in recent\nyears. However, current RAG implementations face challenges in effectively\naddressing noise, repetition and redundancy in retrieved content, primarily due\nto their limited ability to exploit fine-grained inter-document relationships.\nTo address these limitations, we propose an \\textbf{E}fficient \\textbf{D}ynamic\n\\textbf{C}lustering-based document \\textbf{C}ompression framework\n(\\textbf{EDC\\textsuperscript{2}-RAG}) that effectively utilizes latent\ninter-document relationships while simultaneously removing irrelevant\ninformation and redundant content. We validate our approach, built upon\nGPT-3.5, on widely used knowledge-QA and hallucination-detected datasets. The\nresults show that this method achieves consistent performance improvements\nacross various scenarios and experimental settings, demonstrating strong\nrobustness and applicability. Our code and datasets can be found at\nhttps://github.com/Tsinghua-dhy/EDC-2-RAG.", "published": "2025-04-04 04:43:13", "link": "http://arxiv.org/abs/2504.03165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments", "abstract": "Large Language Models (LLMs) equipped with web search capabilities have\ndemonstrated impressive potential for deep research tasks. However, current\napproaches predominantly rely on either manually engineered prompts (prompt\nengineering-based) with brittle performance or reinforcement learning within\ncontrolled Retrieval-Augmented Generation (RAG) environments (RAG-based) that\nfail to capture the complexities of real-world interaction. In this paper, we\nintroduce DeepResearcher, the first comprehensive framework for end-to-end\ntraining of LLM-based deep research agents through scaling reinforcement\nlearning (RL) in real-world environments with authentic web search\ninteractions. Unlike RAG-based approaches that assume all necessary information\nexists within a fixed corpus, our method trains agents to navigate the noisy,\nunstructured, and dynamic nature of the open web. We implement a specialized\nmulti-agent architecture where browsing agents extract relevant information\nfrom various webpage structures and overcoming significant technical\nchallenges. Extensive experiments on open-domain research tasks demonstrate\nthat DeepResearcher achieves substantial improvements of up to 28.9 points over\nprompt engineering-based baselines and up to 7.2 points over RAG-based RL\nagents. Our qualitative analysis reveals emergent cognitive behaviors from\nend-to-end RL training, including the ability to formulate plans,\ncross-validate information from multiple sources, engage in self-reflection to\nredirect research, and maintain honesty when unable to find definitive answers.\nOur results highlight that end-to-end training in real-world web environments\nis not merely an implementation detail but a fundamental requirement for\ndeveloping robust research capabilities aligned with real-world applications.\nWe release DeepResearcher at https://github.com/GAIR-NLP/DeepResearcher.", "published": "2025-04-04 04:41:28", "link": "http://arxiv.org/abs/2504.03160v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Beyond the Next Token: Towards Prompt-Robust Zero-Shot Classification via Efficient Multi-Token Prediction", "abstract": "Zero-shot text classification typically relies on prompt engineering, but the\ninherent prompt brittleness of large language models undermines its\nreliability. Minor changes in prompt can cause significant discrepancies in\nmodel performance. We attribute this prompt brittleness largely to the narrow\nfocus on nexttoken probabilities in existing methods. To address this, we\npropose Placeholding Parallel Prediction (P3), a novel approach that predicts\ntoken probabilities across multiple positions and simulates comprehensive\nsampling of generation paths in a single run of a language model. Experiments\nshow improved accuracy and up to 98% reduction in the standard deviation across\nprompts, boosting robustness. Even without a prompt, P3 maintains comparable\nperformance, reducing the need for prompt engineering.", "published": "2025-04-04 04:39:51", "link": "http://arxiv.org/abs/2504.03159v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)", "abstract": "Reasoning is central to human intelligence, enabling structured\nproblem-solving across diverse tasks. Recent advances in large language models\n(LLMs) have greatly enhanced their reasoning abilities in arithmetic,\ncommonsense, and symbolic domains. However, effectively extending these\ncapabilities into multimodal contexts-where models must integrate both visual\nand textual inputs-continues to be a significant challenge. Multimodal\nreasoning introduces complexities, such as handling conflicting information\nacross modalities, which require models to adopt advanced interpretative\nstrategies. Addressing these challenges involves not only sophisticated\nalgorithms but also robust methodologies for evaluating reasoning accuracy and\ncoherence. This paper offers a concise yet insightful overview of reasoning\ntechniques in both textual and multimodal LLMs. Through a thorough and\nup-to-date comparison, we clearly formulate core reasoning challenges and\nopportunities, highlighting practical methods for post-training optimization\nand test-time inference. Our work provides valuable insights and guidance,\nbridging theoretical frameworks and practical implementations, and sets clear\ndirections for future research.", "published": "2025-04-04 04:04:56", "link": "http://arxiv.org/abs/2504.03151v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entropy-Based Block Pruning for Efficient Large Language Models", "abstract": "As large language models continue to scale, their growing computational and\nstorage demands pose significant challenges for real-world deployment. In this\nwork, we investigate redundancy within Transformer-based models and propose an\nentropy-based pruning strategy to enhance efficiency while maintaining\nperformance. Empirical analysis reveals that the entropy of hidden\nrepresentations decreases in the early blocks but progressively increases\nacross most subsequent blocks. This trend suggests that entropy serves as a\nmore effective measure of information richness within computation blocks.\nUnlike cosine similarity, which primarily captures geometric relationships,\nentropy directly quantifies uncertainty and information content, making it a\nmore reliable criterion for pruning. Extensive experiments demonstrate that our\nentropy-based pruning approach surpasses cosine similarity-based methods in\nreducing model size while preserving accuracy, offering a promising direction\nfor efficient model deployment.", "published": "2025-04-04 03:42:34", "link": "http://arxiv.org/abs/2504.03794v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph", "abstract": "Large Language Models (LLMs) have impressive capabilities in text\nunderstanding and zero-shot reasoning. However, delays in knowledge updates may\ncause them to reason incorrectly or produce harmful results. Knowledge Graphs\n(KGs) provide rich and reliable contextual information for the reasoning\nprocess of LLMs by structurally organizing and connecting a wide range of\nentities and relations. Existing KG-based LLM reasoning methods only inject\nKGs' knowledge into prompts in a textual form, ignoring its structural\ninformation. Moreover, they mostly rely on close-source models or open-source\nmodels with large parameters, which poses challenges to high resource\nconsumption. To address this, we propose a novel Lightweight and efficient\nPrompt learning-ReasOning Framework for KGQA (LightPROF), which leverages the\nfull potential of LLMs to tackle complex reasoning tasks in a\nparameter-efficient manner. Specifically, LightPROF follows a\n\"Retrieve-Embed-Reason process\", first accurately, and stably retrieving the\ncorresponding reasoning graph from the KG through retrieval module. Next,\nthrough a Transformer-based Knowledge Adapter, it finely extracts and\nintegrates factual and structural information from the KG, then maps this\ninformation to the LLM's token embedding space, creating an LLM-friendly prompt\nto be used by the LLM for the final reasoning. Additionally, LightPROF only\nrequires training Knowledge Adapter and can be compatible with any open-source\nLLM. Extensive experiments on two public KGQA benchmarks demonstrate that\nLightPROF achieves superior performance with small-scale LLMs. Furthermore,\nLightPROF shows significant advantages in terms of input token count and\nreasoning time.", "published": "2025-04-04 03:03:47", "link": "http://arxiv.org/abs/2504.03137v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Single-Pass Document Scanning for Question Answering", "abstract": "Handling extremely large documents for question answering is challenging:\nchunk-based embedding methods often lose track of important global context,\nwhile full-context transformers can be prohibitively expensive for hundreds of\nthousands of tokens. We propose a single-pass document scanning approach that\nprocesses the entire text in linear time, preserving global coherence while\ndeciding which sentences are most relevant to the query. On 41 QA benchmarks,\nour single-pass scanner consistently outperforms chunk-based embedding methods\nand competes with large language models at a fraction of the computational\ncost. By conditioning on the entire preceding context without chunk breaks, the\nmethod preserves global coherence, which is especially important for long\ndocuments. Overall, single-pass document scanning offers a simple solution for\nquestion answering over massive text. All code, datasets, and model checkpoints\nare available at https://github.com/MambaRetriever/MambaRetriever", "published": "2025-04-04 01:08:32", "link": "http://arxiv.org/abs/2504.03101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sample, Don't Search: Rethinking Test-Time Alignment for Language Models", "abstract": "Increasing test-time computation has emerged as a promising direction for\nimproving language model performance, particularly in scenarios where model\nfinetuning is impractical or impossible due to computational constraints or\nprivate model weights. However, existing test-time search methods using a\nreward model (RM) often degrade in quality as compute scales, due to the\nover-optimization of what are inherently imperfect reward proxies. We introduce\nQAlign, a new test-time alignment approach. As we scale test-time compute,\nQAlign converges to sampling from the optimal aligned distribution for each\nindividual prompt. By adopting recent advances in Markov chain Monte Carlo for\ntext generation, our method enables better-aligned outputs without modifying\nthe underlying model or even requiring logit access. We demonstrate the\neffectiveness of QAlign on mathematical reasoning benchmarks (GSM8K and\nGSM-Symbolic) using a task-specific RM, showing consistent improvements over\nexisting test-time compute methods like best-of-n and majority voting.\nFurthermore, when applied with more realistic RMs trained on the Tulu 3\npreference dataset, QAlign outperforms direct preference optimization (DPO),\nbest-of-n, majority voting, and weighted majority voting on a diverse range of\ndatasets (GSM8K, MATH500, IFEval, MMLU-Redux, and TruthfulQA). A practical\nsolution to aligning language models at test time using additional computation\nwithout degradation, our approach expands the limits of the capability that can\nbe obtained from off-the-shelf language models without further training.", "published": "2025-04-04 00:41:40", "link": "http://arxiv.org/abs/2504.03790v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving Offline Mixed-Criticality Scheduling with Reinforcement Learning", "abstract": "This paper introduces a novel reinforcement learning (RL) approach to\nscheduling mixed-criticality (MC) systems on processors with varying speeds.\nBuilding upon the foundation laid by [1], we extend their work to address the\nnon-preemptive scheduling problem, which is known to be NP-hard. By modeling\nthis scheduling challenge as a Markov Decision Process (MDP), we develop an RL\nagent capable of generating near-optimal schedules for real-time MC systems.\nOur RL-based scheduler prioritizes high-critical tasks while maintaining\noverall system performance.\n  Through extensive experiments, we demonstrate the scalability and\neffectiveness of our approach. The RL scheduler significantly improves task\ncompletion rates, achieving around 80% overall and 85% for high-criticality\ntasks across 100,000 instances of synthetic data and real data under varying\nsystem conditions. Moreover, under stable conditions without degradation, the\nscheduler achieves 94% overall task completion and 93% for high-criticality\ntasks. These results highlight the potential of RL-based schedulers in\nreal-time and safety-critical applications, offering substantial improvements\nin handling complex and dynamic scheduling scenarios.", "published": "2025-04-04 23:28:48", "link": "http://arxiv.org/abs/2504.03994v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "CORTEX-AVD: CORner Case Testing & EXploration for Autonomous Vehicles Development", "abstract": "Autonomous Vehicles (AVs) aim to improve traffic safety and efficiency by\nreducing human error. However, ensuring AVs reliability and safety is a\nchallenging task when rare, high-risk traffic scenarios are considered. These\n'Corner Cases' (CC) scenarios, such as unexpected vehicle maneuvers or sudden\npedestrian crossings, must be safely and reliable dealt by AVs during their\noperations. But they arehard to be efficiently generated. Traditional CC\ngeneration relies on costly and risky real-world data acquisition, limiting\nscalability, and slowing research and development progress. Simulation-based\ntechniques also face challenges, as modeling diverse scenarios and capturing\nall possible CCs is complex and time-consuming. To address these limitations in\nCC generation, this research introduces CORTEX-AVD, CORner Case Testing &\nEXploration for Autonomous Vehicles Development, an open-source framework that\nintegrates the CARLA Simulator and Scenic to automatically generate CC from\ntextual descriptions, increasing the diversity and automation of scenario\nmodeling. Genetic Algorithms (GA) are used to optimize the scenario parameters\nin six case study scenarios, increasing the occurrence of high-risk events.\nUnlike previous methods, CORTEX-AVD incorporates a multi-factor fitness\nfunction that considers variables such as distance, time, speed, and collision\nlikelihood. Additionally, the study provides a benchmark for comparing GA-based\nCC generation methods, contributing to a more standardized evaluation of\nsynthetic data generation and scenario assessment. Experimental results\ndemonstrate that the CORTEX-AVD framework significantly increases CC incidence\nwhile reducing the proportion of wasted simulations.", "published": "2025-04-04 23:05:31", "link": "http://arxiv.org/abs/2504.03989v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "V-CEM: Bridging Performance and Intervenability in Concept-based Models", "abstract": "Concept-based eXplainable AI (C-XAI) is a rapidly growing research field that\nenhances AI model interpretability by leveraging intermediate,\nhuman-understandable concepts. This approach not only enhances model\ntransparency but also enables human intervention, allowing users to interact\nwith these concepts to refine and improve the model's performance. Concept\nBottleneck Models (CBMs) explicitly predict concepts before making final\ndecisions, enabling interventions to correct misclassified concepts. While CBMs\nremain effective in Out-Of-Distribution (OOD) settings with intervention, they\nstruggle to match the performance of black-box models. Concept Embedding Models\n(CEMs) address this by learning concept embeddings from both concept\npredictions and input data, enhancing In-Distribution (ID) accuracy but\nreducing the effectiveness of interventions, especially in OOD scenarios. In\nthis work, we propose the Variational Concept Embedding Model (V-CEM), which\nleverages variational inference to improve intervention responsiveness in CEMs.\nWe evaluated our model on various textual and visual datasets in terms of ID\nperformance, intervention responsiveness in both ID and OOD settings, and\nConcept Representation Cohesiveness (CRC), a metric we propose to assess the\nquality of the concept embedding representations. The results demonstrate that\nV-CEM retains CEM-level ID performance while achieving intervention\neffectiveness similar to CBM in OOD settings, effectively reducing the gap\nbetween interpretability (intervention) and generalization (performance).", "published": "2025-04-04 22:43:04", "link": "http://arxiv.org/abs/2504.03978v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "OLAF: An Open Life Science Analysis Framework for Conversational Bioinformatics Powered by Large Language Models", "abstract": "OLAF (Open Life Science Analysis Framework) is an open-source platform that\nenables researchers to perform bioinformatics analyses using natural language.\nBy combining large language models (LLMs) with a modular agent-pipe-router\narchitecture, OLAF generates and executes bioinformatics code on real\nscientific data, including formats like .h5ad. The system includes an Angular\nfront end and a Python/Firebase backend, allowing users to run analyses such as\nsingle-cell RNA-seq workflows, gene annotation, and data visualization through\na simple web interface. Unlike general-purpose AI tools, OLAF integrates code\nexecution, data handling, and scientific libraries in a reproducible,\nuser-friendly environment. It is designed to lower the barrier to computational\nbiology for non-programmers and support transparent, AI-powered life science\nresearch.", "published": "2025-04-04 22:41:16", "link": "http://arxiv.org/abs/2504.03976v1", "categories": ["q-bio.QM", "cs.AI", "q-bio.GN"], "primary_category": "q-bio.QM"}
{"title": "GREATERPROMPT: A Unified, Customizable, and High-Performing Open-Source Toolkit for Prompt Optimization", "abstract": "LLMs have gained immense popularity among researchers and the general public\nfor its impressive capabilities on a variety of tasks. Notably, the efficacy of\nLLMs remains significantly dependent on the quality and structure of the input\nprompts, making prompt design a critical factor for their performance. Recent\nadvancements in automated prompt optimization have introduced diverse\ntechniques that automatically enhance prompts to better align model outputs\nwith user expectations. However, these methods often suffer from the lack of\nstandardization and compatibility across different techniques, limited\nflexibility in customization, inconsistent performance across model scales, and\nthey often exclusively rely on expensive proprietary LLM APIs. To fill in this\ngap, we introduce GREATERPROMPT, a novel framework that democratizes prompt\noptimization by unifying diverse methods under a unified, customizable API\nwhile delivering highly effective prompts for different tasks. Our framework\nflexibly accommodates various model scales by leveraging both text\nfeedback-based optimization for larger LLMs and internal gradient-based\noptimization for smaller models to achieve powerful and precise prompt\nimprovements. Moreover, we provide a user-friendly Web UI that ensures\naccessibility for non-expert users, enabling broader adoption and enhanced\nperformance across various user groups and application scenarios. GREATERPROMPT\nis available at https://github.com/psunlpgroup/GreaterPrompt via GitHub, PyPI,\nand web user interfaces.", "published": "2025-04-04 22:36:55", "link": "http://arxiv.org/abs/2504.03975v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bridging LMS and Generative AI: Dynamic Course Content Integration (DCCI) for Connecting LLMs to Course Content -- The Ask ME Assistant", "abstract": "The integration of Large Language Models (LLMs) with Learning Management\nSystems (LMSs) has the potential to enhance task automation and accessibility\nin education. However, hallucination where LLMs generate inaccurate or\nmisleading information remains a significant challenge. This study introduces\nthe Dynamic Course Content Integration (DCCI) mechanism, which dynamically\nretrieves and integrates course content and curriculum from Canvas LMS into the\nLLM-powered assistant, Ask ME. By employing prompt engineering to structure\nretrieved content within the LLM's context window, DCCI ensures accuracy,\nrelevance, and contextual alignment, mitigating hallucination. To evaluate\nDCCI's effectiveness, Ask ME's usability, and broader student perceptions of AI\nin education, a mixed-methods approach was employed, incorporating user\nsatisfaction ratings and a structured survey. Results from a pilot study\nindicate high user satisfaction (4.614/5), with students recognizing Ask ME's\nability to provide timely and contextually relevant responses for both\nadministrative and course-related inquiries. Additionally, a majority of\nstudents agreed that Ask ME's integration with course content in Canvas LMS\nreduced platform-switching, improving usability, engagement, and comprehension.\nAI's role in reducing classroom hesitation and fostering self-directed learning\nand intellectual curiosity was also highlighted. Despite these benefits and\npositive perception of AI tools, concerns emerged regarding over-reliance on\nAI, accuracy limitations, and ethical issues such as plagiarism and reduced\nstudent-teacher interaction. These findings emphasize the need for strategic AI\nimplementation, ethical safeguards, and a pedagogical framework that\nprioritizes human-AI collaboration over substitution.", "published": "2025-04-04 22:17:30", "link": "http://arxiv.org/abs/2504.03966v1", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC", "cs.SE"], "primary_category": "cs.CY"}
{"title": "Optimizing UAV Aerial Base Station Flights Using DRL-based Proximal Policy Optimization", "abstract": "Unmanned aerial vehicle (UAV)-based base stations offer a promising solution\nin emergencies where the rapid deployment of cutting-edge networks is crucial\nfor maximizing life-saving potential. Optimizing the strategic positioning of\nthese UAVs is essential for enhancing communication efficiency. This paper\nintroduces an automated reinforcement learning approach that enables UAVs to\ndynamically interact with their environment and determine optimal\nconfigurations. By leveraging the radio signal sensing capabilities of\ncommunication networks, our method provides a more realistic perspective,\nutilizing state-of-the-art algorithm -- proximal policy optimization -- to\nlearn and generalize positioning strategies across diverse user equipment (UE)\nmovement patterns. We evaluate our approach across various UE mobility\nscenarios, including static, random, linear, circular, and mixed hotspot\nmovements. The numerical results demonstrate the algorithm's adaptability and\neffectiveness in maintaining comprehensive coverage across all movement\npatterns.", "published": "2025-04-04 22:06:01", "link": "http://arxiv.org/abs/2504.03961v1", "categories": ["cs.AI", "eess.SP"], "primary_category": "cs.AI"}
{"title": "DeepOHeat-v1: Efficient Operator Learning for Fast and Trustworthy Thermal Simulation and Optimization in 3D-IC Design", "abstract": "Thermal analysis is crucial in three-dimensional integrated circuit (3D-IC)\ndesign due to increased power density and complex heat dissipation paths.\nAlthough operator learning frameworks such as DeepOHeat have demonstrated\npromising preliminary results in accelerating thermal simulation, they face\ncritical limitations in prediction capability for multi-scale thermal patterns,\ntraining efficiency, and trustworthiness of results during design optimization.\nThis paper presents DeepOHeat-v1, an enhanced physics-informed operator\nlearning framework that addresses these challenges through three key\ninnovations. First, we integrate Kolmogorov-Arnold Networks with learnable\nactivation functions as trunk networks, enabling an adaptive representation of\nmulti-scale thermal patterns. This approach achieves a $1.25\\times$ and\n$6.29\\times$ reduction in error in two representative test cases. Second, we\nintroduce a separable training method that decomposes the basis function along\nthe coordinate axes, achieving $62\\times$ training speedup and $31\\times$ GPU\nmemory reduction in our baseline case, and enabling thermal analysis at\nresolutions previously infeasible due to GPU memory constraints. Third, we\npropose a confidence score to evaluate the trustworthiness of the predicted\nresults, and further develop a hybrid optimization workflow that combines\noperator learning with finite difference (FD) using Generalized Minimal\nResidual (GMRES) method for incremental solution refinement, enabling efficient\nand trustworthy thermal optimization. Experimental results demonstrate that\nDeepOHeat-v1 achieves accuracy comparable to optimization using high-fidelity\nfinite difference solvers, while speeding up the entire optimization process by\n$70.6\\times$ in our test cases, effectively minimizing the peak temperature\nthrough optimal placement of heat-generating components.", "published": "2025-04-04 21:39:42", "link": "http://arxiv.org/abs/2504.03955v1", "categories": ["cs.LG", "cs.AI", "physics.data-an"], "primary_category": "cs.LG"}
{"title": "TGraphX: Tensor-Aware Graph Neural Network for Multi-Dimensional Feature Learning", "abstract": "TGraphX presents a novel paradigm in deep learning by unifying convolutional\nneural networks (CNNs) with graph neural networks (GNNs) to enhance visual\nreasoning tasks. Traditional CNNs excel at extracting rich spatial features\nfrom images but lack the inherent capability to model inter-object\nrelationships. Conversely, conventional GNNs typically rely on flattened node\nfeatures, thereby discarding vital spatial details. TGraphX overcomes these\nlimitations by employing CNNs to generate multi-dimensional node features\n(e.g., (3*128*128) tensors) that preserve local spatial semantics. These\nspatially aware nodes participate in a graph where message passing is performed\nusing 1*1 convolutions, which fuse adjacent features while maintaining their\nstructure. Furthermore, a deep CNN aggregator with residual connections is used\nto robustly refine the fused messages, ensuring stable gradient flow and\nend-to-end trainability. Our approach not only bridges the gap between spatial\nfeature extraction and relational reasoning but also demonstrates significant\nimprovements in object detection refinement and ensemble reasoning.", "published": "2025-04-04 21:38:20", "link": "http://arxiv.org/abs/2504.03953v1", "categories": ["cs.CV", "cs.AI", "68T07, 68T45, 68R10", "I.2.6; I.5.1; I.4.8"], "primary_category": "cs.CV"}
{"title": "Understanding EFX Allocations: Counting and Variants", "abstract": "Envy-freeness up to any good (EFX) is a popular and important fairness\nproperty in the fair allocation of indivisible goods, of which its existence in\ngeneral is still an open question. In this work, we investigate the problem of\ndetermining the minimum number of EFX allocations for a given instance, arguing\nthat this approach may yield valuable insights into the existence and\ncomputation of EFX allocations. We focus on restricted instances where the\nnumber of goods slightly exceeds the number of agents, and extend our analysis\nto weighted EFX (WEFX) and a novel variant of EFX for general monotone\nvaluations, termed EFX+. In doing so, we identify the transition threshold for\nthe existence of allocations satisfying these fairness notions. Notably, we\nresolve open problems regarding WEFX by proving polynomial-time computability\nunder binary additive valuations, and establishing the first constant-factor\napproximation for two agents.", "published": "2025-04-04 21:36:09", "link": "http://arxiv.org/abs/2504.03951v1", "categories": ["cs.GT", "cs.AI", "econ.TH"], "primary_category": "cs.GT"}
{"title": "Analysis of Robustness of a Large Game Corpus", "abstract": "Procedural content generation via machine learning (PCGML) in games involves\nusing machine learning techniques to create game content such as maps and\nlevels. 2D tile-based game levels have consistently served as a standard\ndataset for PCGML because they are a simplified version of game levels while\nmaintaining the specific constraints typical of games, such as being solvable.\nIn this work, we highlight the unique characteristics of game levels, including\ntheir structured discrete data nature, the local and global constraints\ninherent in the games, and the sensitivity of the game levels to small changes\nin input. We define the robustness of data as a measure of sensitivity to small\nchanges in input that cause a change in output, and we use this measure to\nanalyze and compare these levels to state-of-the-art machine learning datasets,\nshowcasing the subtle differences in their nature. We also constructed a large\ndataset from four games inspired by popular classic tile-based games that\nshowcase these characteristics and address the challenge of sparse data in\nPCGML by providing a significantly larger dataset than those currently\navailable.", "published": "2025-04-04 21:15:13", "link": "http://arxiv.org/abs/2504.03940v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Have Large Language Models Learned to Reason? A Characterization via 3-SAT Phase Transition", "abstract": "Large Language Models (LLMs) have been touted as AI models possessing\nadvanced reasoning abilities. In theory, autoregressive LLMs with\nChain-of-Thought (CoT) can perform more serial computations to solve complex\nreasoning tasks. However, recent studies suggest that, despite this capacity,\nLLMs do not truly learn to reason but instead fit on statistical features. To\nstudy the reasoning capabilities in a principled fashion, we adopt a\ncomputational theory perspective and propose an experimental protocol centered\non 3-SAT -- the prototypical NP-complete problem lying at the core of logical\nreasoning and constraint satisfaction tasks. Specifically, we examine the phase\ntransitions in random 3-SAT and characterize the reasoning abilities of\nstate-of-the-art LLMs by varying the inherent hardness of the problem\ninstances. By comparing DeepSeek R1 with other LLMs, our findings reveal two\nkey insights (1) LLM accuracy drops significantly on harder instances,\nsuggesting all current models struggle when statistical shortcuts are\nunavailable (2) Unlike other LLMs, R1 shows signs of having learned the\nunderlying reasoning. Following a principled experimental protocol, our study\nmoves beyond the benchmark-driven evidence often found in LLM reasoning\nresearch. Our findings highlight important gaps and suggest clear directions\nfor future research.", "published": "2025-04-04 20:57:36", "link": "http://arxiv.org/abs/2504.03930v1", "categories": ["cs.AI", "cs.CC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "RF-BayesPhysNet: A Bayesian rPPG Uncertainty Estimation Method for Complex Scenarios", "abstract": "Remote photoplethysmography (rPPG) technology infers heart rate by capturing\nsubtle color changes in facial skin\n  using a camera, demonstrating great potential in non-contact heart rate\nmeasurement. However, measurement\n  accuracy significantly decreases in complex scenarios such as lighting\nchanges and head movements compared\n  to ideal laboratory conditions. Existing deep learning models often neglect\nthe quantification of measurement\n  uncertainty, limiting their credibility in dynamic scenes. To address the\nissue of insufficient rPPG measurement\n  reliability in complex scenarios, this paper introduces Bayesian neural\nnetworks to the rPPG field for the first time,\n  proposing the Robust Fusion Bayesian Physiological Network (RF-BayesPhysNet),\nwhich can model both aleatoric\n  and epistemic uncertainty. It leverages variational inference to balance\naccuracy and computational efficiency.\n  Due to the current lack of uncertainty estimation metrics in the rPPG field,\nthis paper also proposes a new set of\n  methods, using Spearman correlation coefficient, prediction interval\ncoverage, and confidence interval width, to\n  measure the effectiveness of uncertainty estimation methods under different\nnoise conditions. Experiments show\n  that the model, with only double the parameters compared to traditional\nnetwork models, achieves a MAE of 2.56\n  on the UBFC-RPPG dataset, surpassing most models. It demonstrates good\nuncertainty estimation capability\n  in no-noise and low-noise conditions, providing prediction confidence and\nsignificantly enhancing robustness in\n  real-world applications. We have open-sourced the code at\nhttps://github.com/AIDC-rPPG/RF-Net", "published": "2025-04-04 20:24:57", "link": "http://arxiv.org/abs/2504.03915v1", "categories": ["cs.LG", "cs.AI", "68T07, 62F15, 94A12", "I.2.6; I.5.4; C.3"], "primary_category": "cs.LG"}
{"title": "Leveraging Gait Patterns as Biomarkers: An attention-guided Deep Multiple Instance Learning Network for Scoliosis Classification", "abstract": "Scoliosis is a spinal curvature disorder that is difficult to detect early\nand can compress the chest cavity, impacting respiratory function and cardiac\nhealth. Especially for adolescents, delayed detection and treatment result in\nworsening compression. Traditional scoliosis detection methods heavily rely on\nclinical expertise, and X-ray imaging poses radiation risks, limiting\nlarge-scale early screening. We propose an Attention-Guided Deep Multi-Instance\nLearning method (Gait-MIL) to effectively capture discriminative features from\ngait patterns, which is inspired by ScoNet-MT's pioneering use of gait patterns\nfor scoliosis detection. We evaluate our method on the first large-scale\ndataset based on gait patterns for scoliosis classification. The results\ndemonstrate that our study improves the performance of using gait as a\nbiomarker for scoliosis detection, significantly enhances detection accuracy\nfor the particularly challenging Neutral cases, where subtle indicators are\noften overlooked. Our Gait-MIL also performs robustly in imbalanced scenarios,\nmaking it a promising tool for large-scale scoliosis screening.", "published": "2025-04-04 19:35:33", "link": "http://arxiv.org/abs/2504.03894v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigating Affective Use and Emotional Well-being on ChatGPT", "abstract": "As AI chatbots see increased adoption and integration into everyday life,\nquestions have been raised about the potential impact of human-like or\nanthropomorphic AI on users. In this work, we investigate the extent to which\ninteractions with ChatGPT (with a focus on Advanced Voice Mode) may impact\nusers' emotional well-being, behaviors and experiences through two parallel\nstudies. To study the affective use of AI chatbots, we perform large-scale\nautomated analysis of ChatGPT platform usage in a privacy-preserving manner,\nanalyzing over 3 million conversations for affective cues and surveying over\n4,000 users on their perceptions of ChatGPT. To investigate whether there is a\nrelationship between model usage and emotional well-being, we conduct an\nInstitutional Review Board (IRB)-approved randomized controlled trial (RCT) on\nclose to 1,000 participants over 28 days, examining changes in their emotional\nwell-being as they interact with ChatGPT under different experimental settings.\nIn both on-platform data analysis and the RCT, we observe that very high usage\ncorrelates with increased self-reported indicators of dependence. From our RCT,\nwe find that the impact of voice-based interactions on emotional well-being to\nbe highly nuanced, and influenced by factors such as the user's initial\nemotional state and total usage duration. Overall, our analysis reveals that a\nsmall number of users are responsible for a disproportionate share of the most\naffective cues.", "published": "2025-04-04 19:22:10", "link": "http://arxiv.org/abs/2504.03888v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Accurate GPU Memory Prediction for Deep Learning Jobs through Dynamic Analysis", "abstract": "The benefits of Deep Learning (DL) impose significant pressure on GPU\nresources, particularly within GPU cluster, where Out-Of-Memory (OOM) errors\npresent a primary impediment to model training and efficient resource\nutilization. Conventional OOM estimation techniques, relying either on static\ngraph analysis or direct GPU memory profiling, suffer from inherent\nlimitations: static analysis often fails to capture model dynamics, whereas\nGPU-based profiling intensifies contention for scarce GPU resources. To\novercome these constraints, VeritasEst emerges. It is an innovative, entirely\nCPU-based analysis tool capable of accurately predicting the peak GPU memory\nrequired for DL training tasks without accessing the target GPU. This \"offline\"\nprediction capability is core advantage of VeritasEst, allowing accurate memory\nfootprint information to be obtained before task scheduling, thereby\neffectively preventing OOM and optimizing GPU allocation. Its performance was\nvalidated through thousands of experimental runs across convolutional neural\nnetwork (CNN) models: Compared to baseline GPU memory estimators, VeritasEst\nsignificantly reduces the relative error by 84% and lowers the estimation\nfailure probability by 73%. VeritasEst represents a key step towards efficient\nand predictable DL training in resource-constrained environments.", "published": "2025-04-04 19:20:03", "link": "http://arxiv.org/abs/2504.03887v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Improving World Models using Deep Supervision with Linear Probes", "abstract": "Developing effective world models is crucial for creating artificial agents\nthat can reason about and navigate complex environments. In this paper, we\ninvestigate a deep supervision technique for encouraging the development of a\nworld model in a network trained end-to-end to predict the next observation.\nWhile deep supervision has been widely applied for task-specific learning, our\nfocus is on improving the world models. Using an experimental environment based\non the Flappy Bird game, where the agent receives only LIDAR measurements as\nobservations, we explore the effect of adding a linear probe component to the\nnetwork's loss function. This additional term encourages the network to encode\na subset of the true underlying world features into its hidden state. Our\nexperiments demonstrate that this supervision technique improves both training\nand test performance, enhances training stability, and results in more easily\ndecodable world features -- even for those world features which were not\nincluded in the training. Furthermore, we observe a reduced distribution drift\nin networks trained with the linear probe, particularly during high-variability\nphases of the game (flying between successive pipe encounters). Including the\nworld features loss component roughly corresponded to doubling the model size,\nsuggesting that the linear probe technique is particularly beneficial in\ncompute-limited settings or when aiming to achieve the best performance with\nsmaller models. These findings contribute to our understanding of how to\ndevelop more robust and sophisticated world models in artificial agents, paving\nthe way for further advancements in this field.", "published": "2025-04-04 18:35:21", "link": "http://arxiv.org/abs/2504.03861v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Can ChatGPT Learn My Life From a Week of First-Person Video?", "abstract": "Motivated by recent improvements in generative AI and wearable camera devices\n(e.g. smart glasses and AI-enabled pins), I investigate the ability of\nfoundation models to learn about the wearer's personal life through\nfirst-person camera data. To test this, I wore a camera headset for 54 hours\nover the course of a week, generated summaries of various lengths (e.g.\nminute-long, hour-long, and day-long summaries), and fine-tuned both GPT-4o and\nGPT-4o-mini on the resulting summary hierarchy. By querying the fine-tuned\nmodels, we are able to learn what the models learned about me. The results are\nmixed: Both models learned basic information about me (e.g. approximate age,\ngender). Moreover, GPT-4o correctly deduced that I live in Pittsburgh, am a PhD\nstudent at CMU, am right-handed, and have a pet cat. However, both models also\nsuffered from hallucination and would make up names for the individuals present\nin the video footage of my life.", "published": "2025-04-04 18:33:45", "link": "http://arxiv.org/abs/2504.03857v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Detection Limits and Statistical Separability of Tree Ring Watermarks in Rectified Flow-based Text-to-Image Generation Models", "abstract": "Tree-Ring Watermarking is a significant technique for authenticating\nAI-generated images. However, its effectiveness in rectified flow-based models\nremains unexplored, particularly given the inherent challenges of these models\nwith noise latent inversion. Through extensive experimentation, we evaluated\nand compared the detection and separability of watermarks between SD 2.1 and\nFLUX.1-dev models. By analyzing various text guidance configurations and\naugmentation attacks, we demonstrate how inversion limitations affect both\nwatermark recovery and the statistical separation between watermarked and\nunwatermarked images. Our findings provide valuable insights into the current\nlimitations of Tree-Ring Watermarking in the current SOTA models and highlight\nthe critical need for improved inversion methods to achieve reliable watermark\ndetection and separability. The official implementation, dataset release and\nall experimental results are available at this\n\\href{https://github.com/dsgiitr/flux-watermarking}{\\textbf{link}}.", "published": "2025-04-04 18:24:23", "link": "http://arxiv.org/abs/2504.03850v1", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Arti-\"fickle\" Intelligence: Using LLMs as a Tool for Inference in the Political and Social Sciences", "abstract": "Generative large language models (LLMs) are incredibly useful, versatile, and\npromising tools. However, they will be of most use to political and social\nscience researchers when they are used in a way that advances understanding\nabout real human behaviors and concerns. To promote the scientific use of LLMs,\nwe suggest that researchers in the political and social sciences need to remain\nfocused on the scientific goal of inference. To this end, we discuss the\nchallenges and opportunities related to scientific inference with LLMs, using\nvalidation of model output as an illustrative case for discussion. We propose a\nset of guidelines related to establishing the failure and success of LLMs when\ncompleting particular tasks, and discuss how we can make inferences from these\nobservations. We conclude with a discussion of how this refocus will improve\nthe accumulation of shared scientific knowledge about these tools and their\nuses in the social sciences.", "published": "2025-04-04 17:35:45", "link": "http://arxiv.org/abs/2504.03822v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution", "abstract": "Rapid advances in generative AI have enabled the creation of highly realistic\nsynthetic images, which, while beneficial in many domains, also pose serious\nrisks in terms of disinformation, fraud, and other malicious applications.\nCurrent synthetic image identification systems are typically static, relying on\nfeature representations learned from known generators; as new generative models\nemerge, these systems suffer from severe performance degradation. In this\npaper, we introduce the concept of an autonomous self-adaptive synthetic media\nidentification system -- one that not only detects synthetic images and\nattributes them to known sources but also autonomously identifies and\nincorporates novel generators without human intervention. Our approach\nleverages an open-set identification strategy with an evolvable embedding space\nthat distinguishes between known and unknown sources. By employing an\nunsupervised clustering method to aggregate unknown samples into\nhigh-confidence clusters and continuously refining its decision boundaries, our\nsystem maintains robust detection and attribution performance even as the\ngenerative landscape evolves. Extensive experiments demonstrate that our method\nsignificantly outperforms existing approaches, marking a crucial step toward\nuniversal, adaptable forensic systems in the era of rapidly advancing\ngenerative models.", "published": "2025-04-04 17:33:59", "link": "http://arxiv.org/abs/2504.03615v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards deployment-centric multimodal AI beyond vision and language", "abstract": "Multimodal artificial intelligence (AI) integrates diverse types of data via\nmachine learning to improve understanding, prediction, and decision-making\nacross disciplines such as healthcare, science, and engineering. However, most\nmultimodal AI advances focus on models for vision and language data, while\ntheir deployability remains a key challenge. We advocate a deployment-centric\nworkflow that incorporates deployment constraints early to reduce the\nlikelihood of undeployable solutions, complementing data-centric and\nmodel-centric approaches. We also emphasise deeper integration across multiple\nlevels of multimodality and multidisciplinary collaboration to significantly\nbroaden the research scope beyond vision and language. To facilitate this\napproach, we identify common multimodal-AI-specific challenges shared across\ndisciplines and examine three real-world use cases: pandemic response,\nself-driving car design, and climate change adaptation, drawing expertise from\nhealthcare, social science, engineering, science, sustainability, and finance.\nBy fostering multidisciplinary dialogue and open research practices, our\ncommunity can accelerate deployment-centric development for broad societal\nimpact.", "published": "2025-04-04 17:20:05", "link": "http://arxiv.org/abs/2504.03603v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "MedSAM2: Segment Anything in 3D Medical Images and Videos", "abstract": "Medical image and video segmentation is a critical task for precision\nmedicine, which has witnessed considerable progress in developing task or\nmodality-specific and generalist models for 2D images. However, there have been\nlimited studies on building general-purpose models for 3D images and videos\nwith comprehensive user studies. Here, we present MedSAM2, a promptable\nsegmentation foundation model for 3D image and video segmentation. The model is\ndeveloped by fine-tuning the Segment Anything Model 2 on a large medical\ndataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming\nprevious models across a wide range of organs, lesions, and imaging modalities.\nFurthermore, we implement a human-in-the-loop pipeline to facilitate the\ncreation of large-scale datasets resulting in, to the best of our knowledge,\nthe most extensive user study to date, involving the annotation of 5,000 CT\nlesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames,\ndemonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is\nalso integrated into widely used platforms with user-friendly interfaces for\nlocal and cloud deployment, making it a practical tool for supporting\nefficient, scalable, and high-quality segmentation in both research and\nhealthcare environments.", "published": "2025-04-04 17:13:37", "link": "http://arxiv.org/abs/2504.03600v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin for Real-World Robot Policy Evaluation", "abstract": "Recent advancements in behavior cloning have enabled robots to perform\ncomplex manipulation tasks. However, accurately assessing training performance\nremains challenging, particularly for real-world applications, as behavior\ncloning losses often correlate poorly with actual task success. Consequently,\nresearchers resort to success rate metrics derived from costly and\ntime-consuming real-world evaluations, making the identification of optimal\npolicies and detection of overfitting or underfitting impractical. To address\nthese issues, we propose real-is-sim, a novel behavior cloning framework that\nincorporates a dynamic digital twin (based on Embodied Gaussians) throughout\nthe entire policy development pipeline: data collection, training, and\ndeployment. By continuously aligning the simulated world with the physical\nworld, demonstrations can be collected in the real world with states extracted\nfrom the simulator. The simulator enables flexible state representations by\nrendering image inputs from any viewpoint or extracting low-level state\ninformation from objects embodied within the scene. During training, policies\ncan be directly evaluated within the simulator in an offline and highly\nparallelizable manner. Finally, during deployment, policies are run within the\nsimulator where the real robot directly tracks the simulated robot's joints,\neffectively decoupling policy execution from real hardware and mitigating\ntraditional domain-transfer challenges. We validate real-is-sim on the PushT\nmanipulation task, demonstrating strong correlation between success rates\nobtained in the simulator and real-world evaluations. Videos of our system can\nbe found at https://realissim.rai-inst.com.", "published": "2025-04-04 17:05:56", "link": "http://arxiv.org/abs/2504.03597v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Exploring Various Sequential Learning Methods for Deformation History Modeling", "abstract": "Current neural network (NN) models can learn patterns from data points with\nhistorical dependence. Specifically, in natural language processing (NLP),\nsequential learning has transitioned from recurrence-based architectures to\ntransformer-based architectures. However, it is unknown which NN architectures\nwill perform the best on datasets containing deformation history due to\nmechanical loading. Thus, this study ascertains the appropriateness of\n1D-convolutional, recurrent, and transformer-based architectures for predicting\ndeformation localization based on the earlier states in the form of deformation\nhistory. Following this investigation, the crucial incompatibility issues\nbetween the mathematical computation of the prediction process in the\nbest-performing NN architectures and the actual values derived from the natural\nphysical properties of the deformation paths are examined in detail.", "published": "2025-04-04 15:52:24", "link": "http://arxiv.org/abs/2504.03818v1", "categories": ["cs.LG", "cs.AI", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Dense Neural Network Based Arrhythmia Classification on Low-cost and Low-compute Micro-controller", "abstract": "The electrocardiogram (ECG) monitoring device is an expensive albeit\nessential device for the treatment and diagnosis of cardiovascular diseases\n(CVD). The cost of this device typically ranges from $2000 to $10000. Several\nstudies have implemented ECG monitoring systems in micro-controller units (MCU)\nto reduce industrial development costs by up to 20 times. However, to match\nindustry-grade systems and display heartbeats effectively, it is essential to\ndevelop an efficient algorithm for detecting arrhythmia (irregular heartbeat).\nHence in this study, a dense neural network is developed to detect arrhythmia\non the Arduino Nano. The Nano consists of the ATMega328 microcontroller with a\n16MHz clock, 2KB of SRAM, and 32KB of program memory. Additionally, the AD8232\nSparkFun Single-Lead Heart Rate Monitor is used as the ECG sensor. The\nimplemented neural network model consists of two layers (excluding the input)\nwith 10 and four neurons respectively with sigmoid activation function.\nHowever, four approaches are explored to choose the appropriate activation\nfunctions. The model has a size of 1.267 KB, achieves an F1 score\n(macro-average) of 78.3\\% for classifying four types of arrhythmia, an accuracy\nrate of 96.38%, and requires 0.001314 MOps of floating-point operations\n(FLOPs).", "published": "2025-04-04 15:30:02", "link": "http://arxiv.org/abs/2504.03531v1", "categories": ["cs.LG", "cs.AI", "I.2.1; I.2.6; C.3"], "primary_category": "cs.LG"}
{"title": "Quantifying Robustness: A Benchmarking Framework for Deep Learning Forecasting in Cyber-Physical Systems", "abstract": "Cyber-Physical Systems (CPS) in domains such as manufacturing and energy\ndistribution generate complex time series data crucial for Prognostics and\nHealth Management (PHM). While Deep Learning (DL) methods have demonstrated\nstrong forecasting capabilities, their adoption in industrial CPS remains\nlimited due insufficient robustness. Existing robustness evaluations primarily\nfocus on formal verification or adversarial perturbations, inadequately\nrepresenting the complexities encountered in real-world CPS scenarios. To\naddress this, we introduce a practical robustness definition grounded in\ndistributional robustness, explicitly tailored to industrial CPS, and propose a\nsystematic framework for robustness evaluation. Our framework simulates\nrealistic disturbances, such as sensor drift, noise and irregular sampling,\nenabling thorough robustness analyses of forecasting models on real-world CPS\ndatasets. The robustness definition provides a standardized score to quantify\nand compare model performance across diverse datasets, assisting in informed\nmodel selection and architecture design. Through extensive empirical studies\nevaluating prominent DL architectures (including recurrent, convolutional,\nattention-based, modular, and structured state-space models) we demonstrate the\napplicability and effectiveness of our approach. We publicly release our\nrobustness benchmark to encourage further research and reproducibility.", "published": "2025-04-04 14:50:48", "link": "http://arxiv.org/abs/2504.03494v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BUFF: Bayesian Uncertainty Guided Diffusion Probabilistic Model for Single Image Super-Resolution", "abstract": "Super-resolution (SR) techniques are critical for enhancing image quality,\nparticularly in scenarios where high-resolution imagery is essential yet\nlimited by hardware constraints. Existing diffusion models for SR have relied\npredominantly on Gaussian models for noise generation, which often fall short\nwhen dealing with the complex and variable texture inherent in natural scenes.\nTo address these deficiencies, we introduce the Bayesian Uncertainty Guided\nDiffusion Probabilistic Model (BUFF). BUFF distinguishes itself by\nincorporating a Bayesian network to generate high-resolution uncertainty masks.\nThese masks guide the diffusion process, allowing for the adjustment of noise\nintensity in a manner that is both context-aware and adaptive. This novel\napproach not only enhances the fidelity of super-resolved images to their\noriginal high-resolution counterparts but also significantly mitigates\nartifacts and blurring in areas characterized by complex textures and fine\ndetails. The model demonstrates exceptional robustness against complex noise\npatterns and showcases superior adaptability in handling textures and edges\nwithin images. Empirical evidence, supported by visual results, illustrates the\nmodel's robustness, especially in challenging scenarios, and its effectiveness\nin addressing common SR issues such as blurring. Experimental evaluations\nconducted on the DIV2K dataset reveal that BUFF achieves a notable improvement,\nwith a +0.61 increase compared to baseline in SSIM on BSD100, surpassing\ntraditional diffusion approaches by an average additional +0.20dB PSNR gain.\nThese findings underscore the potential of Bayesian methods in enhancing\ndiffusion processes for SR, paving the way for future advancements in the\nfield.", "published": "2025-04-04 14:43:45", "link": "http://arxiv.org/abs/2504.03490v1", "categories": ["cs.CV", "cs.AI", "68T45", "I.2.10; J.0"], "primary_category": "cs.CV"}
{"title": "Physics-informed 4D X-ray image reconstruction from ultra-sparse spatiotemporal data", "abstract": "The unprecedented X-ray flux density provided by modern X-ray sources offers\nnew spatiotemporal possibilities for X-ray imaging of fast dynamic processes.\nApproaches to exploit such possibilities often result in either i) a limited\nnumber of projections or spatial information due to limited scanning speed, as\nin time-resolved tomography, or ii) a limited number of time points, as in\nstroboscopic imaging, making the reconstruction problem ill-posed and unlikely\nto be solved by classical reconstruction approaches. 4D reconstruction from\nsuch data requires sample priors, which can be included via deep learning (DL).\nState-of-the-art 4D reconstruction methods for X-ray imaging combine the power\nof AI and the physics of X-ray propagation to tackle the challenge of sparse\nviews. However, most approaches do not constrain the physics of the studied\nprocess, i.e., a full physical model. Here we present 4D physics-informed\noptimized neural implicit X-ray imaging (4D-PIONIX), a novel physics-informed\n4D X-ray image reconstruction method combining the full physical model and a\nstate-of-the-art DL-based reconstruction method for 4D X-ray imaging from\nsparse views. We demonstrate and evaluate the potential of our approach by\nretrieving 4D information from ultra-sparse spatiotemporal acquisitions of\nsimulated binary droplet collisions, a relevant fluid dynamic process. We\nenvision that this work will open new spatiotemporal possibilities for various\n4D X-ray imaging modalities, such as time-resolved X-ray tomography and more\nnovel sparse acquisition approaches like X-ray multi-projection imaging, which\nwill pave the way for investigations of various rapid 4D dynamics, such as\nfluid dynamics and composite testing.", "published": "2025-04-04 14:18:51", "link": "http://arxiv.org/abs/2504.03469v1", "categories": ["eess.IV", "cs.AI", "physics.data-an"], "primary_category": "eess.IV"}
{"title": "The AI Cosmologist I: An Agentic System for Automated Data Analysis", "abstract": "We present the AI Cosmologist, an agentic system designed to automate\ncosmological/astronomical data analysis and machine learning research\nworkflows. This implements a complete pipeline from idea generation to\nexperimental evaluation and research dissemination, mimicking the scientific\nprocess typically performed by human researchers. The system employs\nspecialized agents for planning, coding, execution, analysis, and synthesis\nthat work together to develop novel approaches. Unlike traditional auto\nmachine-learning systems, the AI Cosmologist generates diverse implementation\nstrategies, writes complete code, handles execution errors, analyzes results,\nand synthesizes new approaches based on experimental outcomes. We demonstrate\nthe AI Cosmologist capabilities across several machine learning tasks, showing\nhow it can successfully explore solution spaces, iterate based on experimental\nresults, and combine successful elements from different approaches. Our results\nindicate that agentic systems can automate portions of the research process,\npotentially accelerating scientific discovery. The code and experimental data\nused in this paper are available on GitHub at\nhttps://github.com/adammoss/aicosmologist. Example papers included in the\nappendix demonstrate the system's capability to autonomously produce complete\nscientific publications, starting from only the dataset and task description", "published": "2025-04-04 13:12:08", "link": "http://arxiv.org/abs/2504.03424v1", "categories": ["astro-ph.IM", "astro-ph.CO", "astro-ph.GA", "cs.AI", "physics.data-an"], "primary_category": "astro-ph.IM"}
{"title": "Autonomous state-space segmentation for Deep-RL sparse reward scenarios", "abstract": "Dealing with environments with sparse rewards has always been crucial for\nsystems developed to operate in autonomous open-ended learning settings.\nIntrinsic Motivations could be an effective way to help Deep Reinforcement\nLearning algorithms learn in such scenarios. In fact, intrinsic reward signals,\nsuch as novelty or curiosity, are generally adopted to improve exploration when\nextrinsic rewards are delayed or absent. Building on previous works, we tackle\nthe problem of learning policies in the presence of sparse rewards by proposing\na two-level architecture that alternates an ''intrinsically driven'' phase of\nexploration and autonomous sub-goal generation, to a phase of sparse reward,\ngoal-directed policy learning. The idea is to build several small networks,\neach one specialized on a particular sub-path, and use them as starting points\nfor future exploration without the need to further explore from scratch\npreviously learnt paths. Two versions of the system have been trained and\ntested in the Gym SuperMarioBros environment without considering any additional\nextrinsic reward. The results show the validity of our approach and the\nimportance of autonomously segment the environment to generate an efficient\npath towards the final goal.", "published": "2025-04-04 13:06:23", "link": "http://arxiv.org/abs/2504.03420v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs", "abstract": "Self-driving laboratories have begun to replace human experimenters in\nperforming single experimental skills or predetermined experimental protocols.\nHowever, as the pace of idea iteration in scientific research has been\nintensified by Artificial Intelligence, the demand for rapid design of new\nprotocols for new discoveries become evident. Efforts to automate protocol\ndesign have been initiated, but the capabilities of knowledge-based machine\ndesigners, such as Large Language Models, have not been fully elicited,\nprobably for the absence of a systematic representation of experimental\nknowledge, as opposed to isolated, flatten pieces of information. To tackle\nthis issue, we propose a multi-faceted, multi-scale representation, where\ninstance actions, generalized operations, and product flow models are\nhierarchically encapsulated using Domain-Specific Languages. We further develop\na data-driven algorithm based on non-parametric modeling that autonomously\ncustomizes these representations for specific domains. The proposed\nrepresentation is equipped with various machine designers to manage protocol\ndesign tasks, including planning, modification, and adjustment. The results\ndemonstrate that the proposed method could effectively complement Large\nLanguage Models in the protocol design process, serving as an auxiliary module\nin the realm of machine-assisted scientific exploration.", "published": "2025-04-04 12:05:15", "link": "http://arxiv.org/abs/2504.03810v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Drawing a Map of Elections", "abstract": "Our main contribution is the introduction of the map of elections framework.\nA map of elections consists of three main elements: (1) a dataset of elections\n(i.e., collections of ordinal votes over given sets of candidates), (2) a way\nof measuring similarities between these elections, and (3) a representation of\nthe elections in the 2D Euclidean space as points, so that the more similar two\nelections are, the closer are their points. In our maps, we mostly focus on\ndatasets of synthetic elections, but we also show an example of a map over\nreal-life ones. To measure similarities, we would have preferred to use, e.g.,\nthe isomorphic swap distance, but this is infeasible due to its high\ncomputational complexity. Hence, we propose polynomial-time computable\npositionwise distance and use it instead. Regarding the representations in 2D\nEuclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two\nalternatives. We develop the necessary theoretical results to form our maps and\nargue experimentally that they are accurate and credible. Further, we show how\ncoloring the elections in a map according to various criteria helps in\nanalyzing results of a number of experiments. In particular, we show colorings\naccording to the scores of winning candidates or committees, running times of\nILP-based winner determination algorithms, and approximation ratios achieved by\nparticular algorithms.", "published": "2025-04-04 11:44:56", "link": "http://arxiv.org/abs/2504.03809v1", "categories": ["cs.MA", "cs.AI", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Decentralized Collective World Model for Emergent Communication and Coordination", "abstract": "We propose a fully decentralized multi-agent world model that enables both\nsymbol emergence for communication and coordinated behavior through temporal\nextension of collective predictive coding. Unlike previous research that\nfocuses on either communication or coordination separately, our approach\nachieves both simultaneously. Our method integrates world models with\ncommunication channels, enabling agents to predict environmental dynamics,\nestimate states from partial observations, and share critical information\nthrough bidirectional message exchange with contrastive learning for message\nalignment. Using a two-agent trajectory drawing task, we demonstrate that our\ncommunication-based approach outperforms non-communicative models when agents\nhave divergent perceptual capabilities, achieving the second-best coordination\nafter centralized models. Importantly, our distributed approach with\nconstraints preventing direct access to other agents' internal states\nfacilitates the emergence of more meaningful symbol systems that accurately\nreflect environmental states. These findings demonstrate the effectiveness of\ndecentralized communication for supporting coordination while developing shared\nrepresentations of the environment.", "published": "2025-04-04 11:17:52", "link": "http://arxiv.org/abs/2504.03353v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Talk2X -- An Open-Source Toolkit Facilitating Deployment of LLM-Powered Chatbots on the Web", "abstract": "Integrated into websites, LLM-powered chatbots offer alternative means of\nnavigation and information retrieval, leading to a shift in how users access\ninformation on the web. Yet, predominantly closed-sourced solutions limit\nproliferation among web hosts and suffer from a lack of transparency with\nregard to implementation details and energy efficiency. In this work, we\npropose our openly available agent Talk2X leveraging an adapted\nretrieval-augmented generation approach (RAG) combined with an automatically\ngenerated vector database, benefiting energy efficiency. Talk2X's architecture\nis generalizable to arbitrary websites offering developers a ready to use tool\nfor integration. Using a mixed-methods approach, we evaluated Talk2X's\nusability by tasking users to acquire specific assets from an open science\nrepository. Talk2X significantly improved task completion time, correctness,\nand user experience supporting users in quickly pinpointing specific\ninformation as compared to standard user-website interaction. Our findings\ncontribute technical advancements to an ongoing paradigm shift of how we access\ninformation on the web.", "published": "2025-04-04 10:58:57", "link": "http://arxiv.org/abs/2504.03343v1", "categories": ["cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.AI"}
{"title": "EOOD: Entropy-based Out-of-distribution Detection", "abstract": "Deep neural networks (DNNs) often exhibit overconfidence when encountering\nout-of-distribution (OOD) samples, posing significant challenges for\ndeployment. Since DNNs are trained on in-distribution (ID) datasets, the\ninformation flow of ID samples through DNNs inevitably differs from that of OOD\nsamples. In this paper, we propose an Entropy-based Out-Of-distribution\nDetection (EOOD) framework. EOOD first identifies specific block where the\ninformation flow differences between ID and OOD samples are more pronounced,\nusing both ID and pseudo-OOD samples. It then calculates the conditional\nentropy on the selected block as the OOD confidence score. Comprehensive\nexperiments conducted across various ID and OOD settings demonstrate the\neffectiveness of EOOD in OOD detection and its superiority over\nstate-of-the-art methods.", "published": "2025-04-04 10:57:03", "link": "http://arxiv.org/abs/2504.03342v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Mind the Prompt: Prompting Strategies in Audio Generations for Improving Sound Classification", "abstract": "This paper investigates the design of effective prompt strategies for\ngenerating realistic datasets using Text-To-Audio (TTA) models. We also analyze\ndifferent techniques for efficiently combining these datasets to enhance their\nutility in sound classification tasks. By evaluating two sound classification\ndatasets with two TTA models, we apply a range of prompt strategies. Our\nfindings reveal that task-specific prompt strategies significantly outperform\nbasic prompt approaches in data generation. Furthermore, merging datasets\ngenerated using different TTA models proves to enhance classification\nperformance more effectively than merely increasing the training dataset size.\nOverall, our results underscore the advantages of these methods as effective\ndata augmentation techniques using synthetic data.", "published": "2025-04-04 10:14:11", "link": "http://arxiv.org/abs/2504.03329v1", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Policy Optimization Algorithms in a Unified Framework", "abstract": "Policy optimization algorithms are crucial in many fields but challenging to\ngrasp and implement, often due to complex calculations related to Markov\ndecision processes and varying use of discount and average reward setups. This\npaper presents a unified framework that applies generalized ergodicity theory\nand perturbation analysis to clarify and enhance the application of these\nalgorithms. Generalized ergodicity theory sheds light on the steady-state\nbehavior of stochastic processes, aiding understanding of both discounted and\naverage rewards. Perturbation analysis provides in-depth insights into the\nfundamental principles of policy optimization algorithms. We use this framework\nto identify common implementation errors and demonstrate the correct\napproaches. Through a case study on Linear Quadratic Regulator problems, we\nillustrate how slight variations in algorithm design affect implementation\noutcomes. We aim to make policy optimization algorithms more accessible and\nreduce their misuse in practice.", "published": "2025-04-04 10:14:01", "link": "http://arxiv.org/abs/2504.03328v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Towards Effective EU E-Participation: The Development of AskThePublic", "abstract": "E-participation platforms can be an important asset for governments in\nincreasing trust and fostering democratic societies. By engaging\nnon-governmental and private institutions, domain experts, and even the general\npublic, policymakers can make informed and inclusive decisions. Drawing on the\nMedia Richness Theory and applying the Design Science Research method, we\nexplore how a chatbot can be designed to improve the effectiveness of the\npolicy-making process of existing citizen involvement platforms. Leveraging the\nHave Your Say platform, which solicits feedback on European Commission\ninitiatives and regulations, a Large Language Model based chatbot, called\nAskThePublic is created, providing policymakers, journalists, researchers, and\ninterested citizens with a convenient channel to explore and engage with public\ninput. By conducting 11 semistructured interviews, the results show that the\nparticipants value the interactive and structured responses as well as enhanced\nlanguage capabilities, thus increasing their likelihood of engaging with\nAskThePublic over the existing platform. An outlook for future iterations is\nprovided and discussed with regard to the perspectives of the different\nstakeholders.", "published": "2025-04-04 09:15:06", "link": "http://arxiv.org/abs/2504.03287v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "JanusDDG: A Thermodynamics-Compliant Model for Sequence-Based Protein Stability via Two-Fronts Multi-Head Attention", "abstract": "Understanding how residue variations affect protein stability is crucial for\ndesigning functional proteins and deciphering the molecular mechanisms\nunderlying disease-related mutations. Recent advances in protein language\nmodels (PLMs) have revolutionized computational protein analysis, enabling,\namong other things, more accurate predictions of mutational effects. In this\nwork, we introduce JanusDDG, a deep learning framework that leverages\nPLM-derived embeddings and a bidirectional cross-attention transformer\narchitecture to predict $\\Delta \\Delta G$ of single and multiple-residue\nmutations while simultaneously being constrained to respect fundamental\nthermodynamic properties, such as antisymmetry and transitivity. Unlike\nconventional self-attention, JanusDDG computes queries (Q) and values (V) as\nthe difference between wild-type and mutant embeddings, while keys (K)\nalternate between the two. This cross-interleaved attention mechanism enables\nthe model to capture mutation-induced perturbations while preserving essential\ncontextual information. Experimental results show that JanusDDG achieves\nstate-of-the-art performance in predicting $\\Delta \\Delta G$ from sequence\nalone, matching or exceeding the accuracy of structure-based methods for both\nsingle and multiple mutations.", "published": "2025-04-04 09:02:32", "link": "http://arxiv.org/abs/2504.03278v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "physics.comp-ph"], "primary_category": "q-bio.QM"}
{"title": "Monte Carlo Graph Coloring", "abstract": "Graph Coloring is probably one of the most studied and famous problem in\ngraph algorithms. Exact methods fail to solve instances with more than few\nhundred vertices, therefore, a large number of heuristics have been proposed.\nNested Monte Carlo Search (NMCS) and Nested Rollout Policy Adaptation (NRPA)\nare Monte Carlo search algorithms for single player games. Surprisingly, few\nwork has been dedicated to evaluating Monte Carlo search algorithms to\ncombinatorial graph problems. In this paper we expose how to efficiently apply\nMonte Carlo search to Graph Coloring and compare this approach to existing\nones.", "published": "2025-04-04 08:57:01", "link": "http://arxiv.org/abs/2504.03277v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Do Large Language Models Solve the Problems of Agent-Based Modeling? A Critical Review of Generative Social Simulations", "abstract": "Recent advancements in AI have reinvigorated Agent-Based Models (ABMs), as\nthe integration of Large Language Models (LLMs) has led to the emergence of\n``generative ABMs'' as a novel approach to simulating social systems. While\nABMs offer means to bridge micro-level interactions with macro-level patterns,\nthey have long faced criticisms from social scientists, pointing to e.g., lack\nof realism, computational complexity, and challenges of calibrating and\nvalidating against empirical data. This paper reviews the generative ABM\nliterature to assess how this new approach adequately addresses these\nlong-standing criticisms. Our findings show that studies show limited awareness\nof historical debates. Validation remains poorly addressed, with many studies\nrelying solely on subjective assessments of model `believability', and even the\nmost rigorous validation failing to adequately evidence operational validity.\nWe argue that there are reasons to believe that LLMs will exacerbate rather\nthan resolve the long-standing challenges of ABMs. The black-box nature of LLMs\nmoreover limit their usefulness for disentangling complex emergent causal\nmechanisms. While generative ABMs are still in a stage of early\nexperimentation, these findings question of whether and how the field can\ntransition to the type of rigorous modeling needed to contribute to social\nscientific theory.", "published": "2025-04-04 08:48:43", "link": "http://arxiv.org/abs/2504.03274v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Verification of Autonomous Neural Car Control with KeYmaera X", "abstract": "This article presents a formal model and formal safety proofs for the ABZ'25\ncase study in differential dynamic logic (dL). The case study considers an\nautonomous car driving on a highway avoiding collisions with neighbouring cars.\nUsing KeYmaera X's dL implementation, we prove absence of collision on an\ninfinite time horizon which ensures that safety is preserved independently of\ntrip length. The safety guarantees hold for time-varying reaction time and\nbrake force. Our dL model considers the single lane scenario with cars ahead or\nbehind. We demonstrate that dL with its tools is a rigorous foundation for\nruntime monitoring, shielding, and neural network verification. Doing so sheds\nlight on inconsistencies between the provided specification and simulation\nenvironment highway-env of the ABZ'25 study. We attempt to fix these\ninconsistencies and uncover numerous counterexamples which also indicate issues\nin the provided reinforcement learning environment.", "published": "2025-04-04 08:43:31", "link": "http://arxiv.org/abs/2504.03272v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.LO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "An Extended Symbolic-Arithmetic Model for Teaching Double-Black Removal with Rotation in Red-Black Trees", "abstract": "Double-black (DB) nodes have no place in red-black (RB) trees. So when DB\nnodes are formed, they are immediately removed. The removal of DB nodes that\ncause rotation and recoloring of other connected nodes poses greater challenges\nin the teaching and learning of RB trees. To ease this difficulty, this paper\nextends our previous work on the symbolic arithmetic algebraic (SA) method for\nremoving DB nodes. The SA operations that are given as, Red + Black = Black;\nBlack - Black = Red; Black + Black = DB; and DB - Black = Black removes DB\nnodes and rebalances black heights in RB trees. By extension, this paper\nprojects three SA mathematical equations, namely, general symbolic arithmetic\nrule; partial symbolic arithmetic rule1; and partial symbolic arithmetic rule2.\nThe removal of a DB node ultimately affects black heights in RB trees. To\nbalance black heights using the SA equations, all the RB tree cases, namely,\nLR, RL, LL, and RR, were considered in this work; and the position of the nodes\nconnected directly or indirectly to the DB node was also tested. In this study,\nto balance a RB tree, the issues considered w.r.t. the different cases of the\nRB tree were i) whether a DB node has an inner, outer, or both inner and outer\nblack nephews; or ii) whether a DB node has an inner, outer or both inner and\nouter red nephews. The nephews r and x in this work are the children of the\nsibling s to a DB, and further up the tree, the parent p of a DB is their\ngrandparent g. Thus, r and x have indirect relationships to a DB at the point\nof formation of the DB node. The novelty of the SA equations is in their\neffectiveness in the removal of DB that involves rotation of nodes as well as\nthe recoloring of nodes along any simple path so as to balance black heights in\na tree.", "published": "2025-04-04 08:19:26", "link": "http://arxiv.org/abs/2504.03259v1", "categories": ["cs.DS", "cs.AI"], "primary_category": "cs.DS"}
{"title": "Semantic-guided Representation Learning for Multi-Label Recognition", "abstract": "Multi-label Recognition (MLR) involves assigning multiple labels to each data\ninstance in an image, offering advantages over single-label classification in\ncomplex scenarios. However, it faces the challenge of annotating all relevant\ncategories, often leading to uncertain annotations, such as unseen or\nincomplete labels. Recent Vision and Language Pre-training (VLP) based methods\nhave made significant progress in tackling zero-shot MLR tasks by leveraging\nrich vision-language correlations. However, the correlation between multi-label\nsemantics has not been fully explored, and the learned visual features often\nlack essential semantic information. To overcome these limitations, we\nintroduce a Semantic-guided Representation Learning approach (SigRL) that\nenables the model to learn effective visual and textual representations,\nthereby improving the downstream alignment of visual images and categories.\nSpecifically, we first introduce a graph-based multi-label correlation module\n(GMC) to facilitate information exchange between labels, enriching the semantic\nrepresentation across the multi-label texts. Next, we propose a Semantic Visual\nFeature Reconstruction module (SVFR) to enhance the semantic information in the\nvisual representation by integrating the learned textual representation during\nreconstruction. Finally, we optimize the image-text matching capability of the\nVLP model using both local and global features to achieve zero-shot MLR.\nComprehensive experiments are conducted on several MLR benchmarks, encompassing\nboth zero-shot MLR (with unseen labels) and single positive multi-label\nlearning (with limited labels), demonstrating the superior performance of our\napproach compared to state-of-the-art methods. The code is available at\nhttps://github.com/MVL-Lab/SigRL.", "published": "2025-04-04 08:15:08", "link": "http://arxiv.org/abs/2504.03801v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators", "abstract": "Generalizable robotic mobile manipulation in open-world environments poses\nsignificant challenges due to long horizons, complex goals, and partial\nobservability. A promising approach to address these challenges involves\nplanning with a library of parameterized skills, where a task planner sequences\nthese skills to achieve goals specified in structured languages, such as\nlogical expressions over symbolic facts. While vision-language models (VLMs)\ncan be used to ground these expressions, they often assume full observability,\nleading to suboptimal behavior when the agent lacks sufficient information to\nevaluate facts with certainty. This paper introduces a novel framework that\nleverages VLMs as a perception module to estimate uncertainty and facilitate\nsymbolic grounding. Our approach constructs a symbolic belief representation\nand uses a belief-space planner to generate uncertainty-aware plans that\nincorporate strategic information gathering. This enables the agent to\neffectively reason about partial observability and property uncertainty. We\ndemonstrate our system on a range of challenging real-world tasks that require\nreasoning in partially observable environments. Simulated evaluations show that\nour approach outperforms both vanilla VLM-based end-to-end planning or\nVLM-based state estimation baselines by planning for and executing strategic\ninformation gathering. This work highlights the potential of VLMs to construct\nbelief-space symbolic scene representations, enabling downstream tasks such as\nuncertainty-aware planning.", "published": "2025-04-04 07:48:53", "link": "http://arxiv.org/abs/2504.03245v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Rotation Invariance in Floor Plan Digitization using Zernike Moments", "abstract": "Nowadays, a lot of old floor plans exist in printed form or are stored as\nscanned raster images. Slight rotations or shifts may occur during scanning.\nBringing floor plans of this form into a machine readable form to enable\nfurther use, still poses a problem. Therefore, we propose an end-to-end\npipeline that pre-processes the image and leverages a novel approach to create\na region adjacency graph (RAG) from the pre-processed image and predict its\nnodes. By incorporating normalization steps into the RAG feature extraction, we\nsignificantly improved the rotation invariance of the RAG feature calculation.\nMoreover, applying our method leads to an improved F1 score and IoU on rotated\ndata. Furthermore, we proposed a wall splitting algorithm for partitioning\nwalls into segments associated with the corresponding rooms.", "published": "2025-04-04 07:44:07", "link": "http://arxiv.org/abs/2504.03241v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Decision SpikeFormer: Spike-Driven Transformer for Decision Making", "abstract": "Offline reinforcement learning (RL) enables policy training solely on\npre-collected data, avoiding direct environment interaction - a crucial benefit\nfor energy-constrained embodied AI applications. Although Artificial Neural\nNetworks (ANN)-based methods perform well in offline RL, their high\ncomputational and energy demands motivate exploration of more efficient\nalternatives. Spiking Neural Networks (SNNs) show promise for such tasks, given\ntheir low power consumption. In this work, we introduce DSFormer, the first\nspike-driven transformer model designed to tackle offline RL via sequence\nmodeling. Unlike existing SNN transformers focused on spatial dimensions for\nvision tasks, we develop Temporal Spiking Self-Attention (TSSA) and Positional\nSpiking Self-Attention (PSSA) in DSFormer to capture the temporal and\npositional dependencies essential for sequence modeling in RL. Additionally, we\npropose Progressive Threshold-dependent Batch Normalization (PTBN), which\ncombines the benefits of LayerNorm and BatchNorm to preserve temporal\ndependencies while maintaining the spiking nature of SNNs. Comprehensive\nresults in the D4RL benchmark show DSFormer's superiority over both SNN and ANN\ncounterparts, achieving 78.4% energy savings, highlighting DSFormer's\nadvantages not only in energy efficiency but also in competitive performance.\nCode and models are public at https://wei-nijuan.github.io/DecisionSpikeFormer.", "published": "2025-04-04 07:42:36", "link": "http://arxiv.org/abs/2504.03800v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Malware Detection in Docker Containers: An Image is Worth a Thousand Logs", "abstract": "Malware detection is increasingly challenged by evolving techniques like\nobfuscation and polymorphism, limiting the effectiveness of traditional\nmethods. Meanwhile, the widespread adoption of software containers has\nintroduced new security challenges, including the growing threat of malicious\nsoftware injection, where a container, once compromised, can serve as entry\npoint for further cyberattacks. In this work, we address these security issues\nby introducing a method to identify compromised containers through machine\nlearning analysis of their file systems. We cast the entire software containers\ninto large RGB images via their tarball representations, and propose to use\nestablished Convolutional Neural Network architectures on a streaming,\npatch-based manner. To support our experiments, we release the COSOCO\ndataset--the first of its kind--containing 3364 large-scale RGB images of\nbenign and compromised software containers at\nhttps://huggingface.co/datasets/k3ylabs/cosoco-image-dataset. Our method\ndetects more malware and achieves higher F1 and Recall scores than all\nindividual and ensembles of VirusTotal engines, demonstrating its effectiveness\nand setting a new standard for identifying malware-compromised software\ncontainers.", "published": "2025-04-04 07:38:16", "link": "http://arxiv.org/abs/2504.03238v1", "categories": ["cs.CR", "cs.AI", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Crash Time Matters: HybridMamba for Fine-Grained Temporal Localization in Traffic Surveillance Footage", "abstract": "Traffic crash detection in long-form surveillance videos is critical for\nemergency response and infrastructure planning but remains difficult due to the\nbrief and rare nature of crash events. We introduce HybridMamba, a novel\narchitecture that combines visual transformers with state-space temporal\nmodeling to achieve accurate crash time localization. Our method uses\nmulti-level token compression and hierarchical temporal processing to remain\ncomputationally efficient without sacrificing temporal resolution. Evaluated on\na large-scale dataset from the Iowa Department of Transportation, HybridMamba\nachieves a mean absolute error of 1.50 seconds, with 65.2 percent of\npredictions within one second of the ground truth. It outperforms recent\nvideo-language models such as TimeChat and VideoLLaMA2 by up to 2.8 seconds,\nwhile using significantly fewer parameters. Our results demonstrate strong\ngeneralization across videos ranging from 2 to 40 minutes in diverse\nconditions. HybridMamba offers a robust and efficient solution for fine-grained\ntemporal localization in traffic surveillance. The code will be released upon\npublication.", "published": "2025-04-04 07:35:11", "link": "http://arxiv.org/abs/2504.03235v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Persuasive Calibration", "abstract": "We introduce and study the persuasive calibration problem, where a principal\naims to provide trustworthy predictions about underlying events to a downstream\nagent to make desired decisions. We adopt the standard calibration framework\nthat regulates predictions to be unbiased conditional on their own value, and\nthus, they can reliably be interpreted at the face value by the agent. Allowing\na small calibration error budget, we aim to answer the following question: what\nis and how to compute the optimal predictor under this calibration error\nbudget, especially when there exists incentive misalignment between the\nprincipal and the agent? We focus on standard Lt-norm Expected Calibration\nError (ECE) metric.\n  We develop a general framework by viewing predictors as post-processed\nversions of perfectly calibrated predictors. Using this framework, we first\ncharacterize the structure of the optimal predictor. Specifically, when the\nprincipal's utility is event-independent and for L1-norm ECE, we show: (1) the\noptimal predictor is over-(resp. under-) confident for high (resp. low) true\nexpected outcomes, while remaining perfectly calibrated in the middle; (2) the\nmiscalibrated predictions exhibit a collinearity structure with the principal's\nutility function. On the algorithmic side, we provide a FPTAS for computing\napproximately optimal predictor for general principal utility and general\nLt-norm ECE. Moreover, for the L1- and L-Infinity-norm ECE, we provide\npolynomial-time algorithms that compute the exact optimal predictor.", "published": "2025-04-04 06:49:56", "link": "http://arxiv.org/abs/2504.03211v1", "categories": ["cs.LG", "cs.AI", "cs.GT", "econ.TH"], "primary_category": "cs.LG"}
{"title": "Augmenting Human Cognition With Generative AI: Lessons From AI-Assisted Decision-Making", "abstract": "How can we use generative AI to design tools that augment rather than replace\nhuman cognition? In this position paper, we review our own research on\nAI-assisted decision-making for lessons to learn. We observe that in both\nAI-assisted decision-making and generative AI, a popular approach is to suggest\nAI-generated end-to-end solutions to users, which users can then accept,\nreject, or edit. Alternatively, AI tools could offer more incremental support\nto help users solve tasks themselves, which we call process-oriented support.\nWe describe findings on the challenges of end-to-end solutions, and how\nprocess-oriented support can address them. We also discuss the applicability of\nthese findings to generative AI based on a recent study in which we compared\nboth approaches to assist users in a complex decision-making task with LLMs.", "published": "2025-04-04 06:40:03", "link": "http://arxiv.org/abs/2504.03207v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Endo3R: Unified Online Reconstruction from Dynamic Monocular Endoscopic Video", "abstract": "Reconstructing 3D scenes from monocular surgical videos can enhance surgeon's\nperception and therefore plays a vital role in various computer-assisted\nsurgery tasks. However, achieving scale-consistent reconstruction remains an\nopen challenge due to inherent issues in endoscopic videos, such as dynamic\ndeformations and textureless surfaces. Despite recent advances, current methods\neither rely on calibration or instrument priors to estimate scale, or employ\nSfM-like multi-stage pipelines, leading to error accumulation and requiring\noffline optimization. In this paper, we present Endo3R, a unified 3D foundation\nmodel for online scale-consistent reconstruction from monocular surgical video,\nwithout any priors or extra optimization. Our model unifies the tasks by\npredicting globally aligned pointmaps, scale-consistent video depths, and\ncamera parameters without any offline optimization. The core contribution of\nour method is expanding the capability of the recent pairwise reconstruction\nmodel to long-term incremental dynamic reconstruction by an uncertainty-aware\ndual memory mechanism. The mechanism maintains history tokens of both\nshort-term dynamics and long-term spatial consistency. Notably, to tackle the\nhighly dynamic nature of surgical scenes, we measure the uncertainty of tokens\nvia Sampson distance and filter out tokens with high uncertainty. Regarding the\nscarcity of endoscopic datasets with ground-truth depth and camera poses, we\nfurther devise a self-supervised mechanism with a novel dynamics-aware flow\nloss. Abundant experiments on SCARED and Hamlyn datasets demonstrate our\nsuperior performance in zero-shot surgical video depth prediction and camera\npose estimation with online efficiency. Project page:\nhttps://wrld.github.io/Endo3R/.", "published": "2025-04-04 06:05:22", "link": "http://arxiv.org/abs/2504.03198v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Experimental Study on Time Series Analysis of Lower Limb Rehabilitation Exercise Data Driven by Novel Model Architecture and Large Models", "abstract": "This study investigates the application of novel model architectures and\nlarge-scale foundational models in temporal series analysis of lower limb\nrehabilitation motion data, aiming to leverage advancements in machine learning\nand artificial intelligence to empower active rehabilitation guidance\nstrategies for post-stroke patients in limb motor function recovery. Utilizing\nthe SIAT-LLMD dataset of lower limb movement data proposed by the Shenzhen\nInstitute of Advanced Technology, Chinese Academy of Sciences, we\nsystematically elucidate the implementation and analytical outcomes of the\ninnovative xLSTM architecture and the foundational model Lag-Llama in\nshort-term temporal prediction tasks involving joint kinematics and dynamics\nparameters. The research provides novel insights for AI-enabled medical\nrehabilitation applications, demonstrating the potential of cutting-edge model\narchitectures and large-scale models in rehabilitation medicine temporal\nprediction. These findings establish theoretical foundations for future\napplications of personalized rehabilitation regimens, offering significant\nimplications for the development of customized therapeutic interventions in\nclinical practice.", "published": "2025-04-04 05:40:13", "link": "http://arxiv.org/abs/2504.03799v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "An Intelligent and Privacy-Preserving Digital Twin Model for Aging-in-Place", "abstract": "The population of older adults is steadily increasing, with a strong\npreference for aging-in-place rather than moving to care facilities.\nConsequently, supporting this growing demographic has become a significant\nglobal challenge. However, facilitating successful aging-in-place is\nchallenging, requiring consideration of multiple factors such as data privacy,\nhealth status monitoring, and living environments to improve health outcomes.\nIn this paper, we propose an unobtrusive sensor system designed for\ninstallation in older adults' homes. Using data from the sensors, our system\nconstructs a digital twin, a virtual representation of events and activities\nthat occurred in the home. The system uses neural network models and decision\nrules to capture residents' activities and living environments. This digital\ntwin enables continuous health monitoring by providing actionable insights into\nresidents' well-being. Our system is designed to be low-cost and\nprivacy-preserving, with the aim of providing green and safe monitoring for the\nhealth of older adults. We have successfully deployed our system in two homes\nover a time period of two months, and our findings demonstrate the feasibility\nand effectiveness of digital twin technology in supporting independent living\nfor older adults. This study highlights that our system could revolutionize\nelder care by enabling personalized interventions, such as lifestyle\nadjustments, medical treatments, or modifications to the residential\nenvironment, to enhance health outcomes.", "published": "2025-04-04 05:37:08", "link": "http://arxiv.org/abs/2504.03798v1", "categories": ["cs.CY", "cs.AI", "68T05,", "I.2; J.3"], "primary_category": "cs.CY"}
{"title": "Real-Time Roadway Obstacle Detection for Electric Scooters Using Deep Learning and Multi-Sensor Fusion", "abstract": "The increasing adoption of electric scooters (e-scooters) in urban areas has\ncoincided with a rise in traffic accidents and injuries, largely due to their\nsmall wheels, lack of suspension, and sensitivity to uneven surfaces. While\ndeep learning-based object detection has been widely used to improve automobile\nsafety, its application for e-scooter obstacle detection remains unexplored.\nThis study introduces a novel ground obstacle detection system for e-scooters,\nintegrating an RGB camera, and a depth camera to enhance real-time road hazard\ndetection. Additionally, the Inertial Measurement Unit (IMU) measures linear\nvertical acceleration to identify surface vibrations, guiding the selection of\nsix obstacle categories: tree branches, manhole covers, potholes, pine cones,\nnon-directional cracks, and truncated domes. All sensors, including the RGB\ncamera, depth camera, and IMU, are integrated within the Intel RealSense Camera\nD435i. A deep learning model powered by YOLO detects road hazards and utilizes\ndepth data to estimate obstacle proximity. Evaluated on the seven hours of\nnaturalistic riding dataset, the system achieves a high mean average precision\n(mAP) of 0.827 and demonstrates excellent real-time performance. This approach\nprovides an effective solution to enhance e-scooter safety through advanced\ncomputer vision and data fusion. The dataset is accessible at\nhttps://zenodo.org/records/14583718, and the project code is hosted on\nhttps://github.com/Zeyang-Zheng/Real-Time-Roadway-Obstacle-Detection-for-Electric-Scooters.", "published": "2025-04-04 05:01:16", "link": "http://arxiv.org/abs/2504.03171v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving", "abstract": "Recent advancements in Vision-Language Models (VLMs) have demonstrated strong\npotential for autonomous driving tasks. However, their spatial understanding\nand reasoning-key capabilities for autonomous driving-still exhibit significant\nlimitations. Notably, none of the existing benchmarks systematically evaluate\nVLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, we\npropose NuScenes-SpatialQA, the first large-scale ground-truth-based\nQuestion-Answer (QA) benchmark specifically designed to evaluate the spatial\nunderstanding and reasoning capabilities of VLMs in autonomous driving. Built\nupon the NuScenes dataset, the benchmark is constructed through an automated 3D\nscene graph generation pipeline and a QA generation pipeline. The benchmark\nsystematically evaluates VLMs' performance in both spatial understanding and\nreasoning across multiple dimensions. Using this benchmark, we conduct\nextensive experiments on diverse VLMs, including both general and\nspatial-enhanced models, providing the first comprehensive evaluation of their\nspatial capabilities in autonomous driving. Surprisingly, the experimental\nresults show that the spatial-enhanced VLM outperforms in qualitative QA but\ndoes not demonstrate competitiveness in quantitative QA. In general, VLMs still\nface considerable challenges in spatial understanding and reasoning.", "published": "2025-04-04 04:43:10", "link": "http://arxiv.org/abs/2504.03164v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Human Digital Twin Architecture for Knowledge-based Interactions and Context-Aware Conversations", "abstract": "Recent developments in Artificial Intelligence (AI) and Machine Learning (ML)\nare creating new opportunities for Human-Autonomy Teaming (HAT) in tasks,\nmissions, and continuous coordinated activities. A major challenge is enabling\nhumans to maintain awareness and control over autonomous assets, while also\nbuilding trust and supporting shared contextual understanding. To address this,\nwe present a real-time Human Digital Twin (HDT) architecture that integrates\nLarge Language Models (LLMs) for knowledge reporting, answering, and\nrecommendation, embodied in a visual interface.\n  The system applies a metacognitive approach to enable personalized,\ncontext-aware responses aligned with the human teammate's expectations. The HDT\nacts as a visually and behaviorally realistic team member, integrated\nthroughout the mission lifecycle, from training to deployment to after-action\nreview. Our architecture includes speech recognition, context processing,\nAI-driven dialogue, emotion modeling, lip-syncing, and multimodal feedback. We\ndescribe the system design, performance metrics, and future development\ndirections for more adaptive and realistic HAT systems.", "published": "2025-04-04 03:56:26", "link": "http://arxiv.org/abs/2504.03147v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Outlook Towards Deployable Continual Learning for Particle Accelerators", "abstract": "Particle Accelerators are high power complex machines. To ensure\nuninterrupted operation of these machines, thousands of pieces of equipment\nneed to be synchronized, which requires addressing many challenges including\ndesign, optimization and control, anomaly detection and machine protection.\nWith recent advancements, Machine Learning (ML) holds promise to assist in more\nadvance prognostics, optimization, and control. While ML based solutions have\nbeen developed for several applications in particle accelerators, only few have\nreached deployment and even fewer to long term usage, due to particle\naccelerator data distribution drifts caused by changes in both measurable and\nnon-measurable parameters. In this paper, we identify some of the key areas\nwithin particle accelerators where continual learning can allow maintenance of\nML model performance with distribution drifts. Particularly, we first discuss\nexisting applications of ML in particle accelerators, and their limitations due\nto distribution drift. Next, we review existing continual learning techniques\nand investigate their potential applications to address data distribution\ndrifts in accelerators. By identifying the opportunities and challenges in\napplying continual learning, this paper seeks to open up the new field and\ninspire more research efforts towards deployable continual learning for\nparticle accelerators.", "published": "2025-04-04 03:34:39", "link": "http://arxiv.org/abs/2504.03793v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hierarchical Modeling for Medical Visual Question Answering with Cross-Attention Fusion", "abstract": "Medical Visual Question Answering (Med-VQA) answers clinical questions using\nmedical images, aiding diagnosis. Designing the MedVQA system holds profound\nimportance in assisting clinical diagnosis and enhancing diagnostic accuracy.\nBuilding upon this foundation, Hierarchical Medical VQA extends Medical VQA by\norganizing medical questions into a hierarchical structure and making\nlevel-specific predictions to handle fine-grained distinctions. Recently, many\nstudies have proposed hierarchical MedVQA tasks and established datasets,\nHowever, several issues still remain: (1) imperfect hierarchical modeling leads\nto poor differentiation between question levels causing semantic fragmentation\nacross hierarchies. (2) Excessive reliance on implicit learning in\nTransformer-based cross-modal self-attention fusion methods, which obscures\ncrucial local semantic correlations in medical scenarios. To address these\nissues, this study proposes a HiCA-VQA method, including two modules:\nHierarchical Prompting for fine-grained medical questions and Hierarchical\nAnswer Decoders. The hierarchical prompting module pre-aligns hierarchical text\nprompts with image features to guide the model in focusing on specific image\nregions according to question types, while the hierarchical decoder performs\nseparate predictions for questions at different levels to improve accuracy\nacross granularities. The framework also incorporates a cross-attention fusion\nmodule where images serve as queries and text as key-value pairs. Experiments\non the Rad-Restruct benchmark demonstrate that the HiCA-VQA framework better\noutperforms existing state-of-the-art methods in answering hierarchical\nfine-grained questions. This study provides an effective pathway for\nhierarchical visual question answering systems, advancing medical image\nunderstanding.", "published": "2025-04-04 03:03:12", "link": "http://arxiv.org/abs/2504.03135v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DP-LET: An Efficient Spatio-Temporal Network Traffic Prediction Framework", "abstract": "Accurately predicting spatio-temporal network traffic is essential for\ndynamically managing computing resources in modern communication systems and\nminimizing energy consumption. Although spatio-temporal traffic prediction has\nreceived extensive research attention, further improvements in prediction\naccuracy and computational efficiency remain necessary. In particular, existing\ndecomposition-based methods or hybrid architectures often incur heavy overhead\nwhen capturing local and global feature correlations, necessitating novel\napproaches that optimize accuracy and complexity. In this paper, we propose an\nefficient spatio-temporal network traffic prediction framework, DP-LET, which\nconsists of a data processing module, a local feature enhancement module, and a\nTransformer-based prediction module. The data processing module is designed for\nhigh-efficiency denoising of network data and spatial decoupling. In contrast,\nthe local feature enhancement module leverages multiple Temporal Convolutional\nNetworks (TCNs) to capture fine-grained local features. Meanwhile, the\nprediction module utilizes a Transformer encoder to model long-term\ndependencies and assess feature relevance. A case study on real-world cellular\ntraffic prediction demonstrates the practicality of DP-LET, which maintains low\ncomputational complexity while achieving state-of-the-art performance,\nsignificantly reducing MSE by 31.8% and MAE by 23.1% compared to baseline\nmodels.", "published": "2025-04-04 02:52:43", "link": "http://arxiv.org/abs/2504.03792v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GraphSeg: Segmented 3D Representations via Graph Edge Addition and Contraction", "abstract": "Robots operating in unstructured environments often require accurate and\nconsistent object-level representations. This typically requires segmenting\nindividual objects from the robot's surroundings. While recent large models\nsuch as Segment Anything (SAM) offer strong performance in 2D image\nsegmentation. These advances do not translate directly to performance in the\nphysical 3D world, where they often over-segment objects and fail to produce\nconsistent mask correspondences across views. In this paper, we present\nGraphSeg, a framework for generating consistent 3D object segmentations from a\nsparse set of 2D images of the environment without any depth information.\nGraphSeg adds edges to graphs and constructs dual correspondence graphs: one\nfrom 2D pixel-level similarities and one from inferred 3D structure. We\nformulate segmentation as a problem of edge addition, then subsequent graph\ncontraction, which merges multiple 2D masks into unified object-level\nsegmentations. We can then leverage \\emph{3D foundation models} to produce\nsegmented 3D representations. GraphSeg achieves robust segmentation with\nsignificantly fewer images and greater accuracy than prior methods. We\ndemonstrate state-of-the-art performance on tabletop scenes and show that\nGraphSeg enables improved performance on downstream robotic manipulation tasks.\nCode available at https://github.com/tomtang502/graphseg.git.", "published": "2025-04-04 02:42:45", "link": "http://arxiv.org/abs/2504.03129v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Graph Network Modeling Techniques for Visualizing Human Mobility Patterns", "abstract": "Human mobility analysis at urban-scale requires models to represent the\ncomplex nature of human movements, which in turn are affected by accessibility\nto nearby points of interest, underlying socioeconomic factors of a place, and\nlocal transport choices for people living in a geographic region. In this work,\nwe represent human mobility and the associated flow of movements as a grapyh.\nGraph-based approaches for mobility analysis are still in their early stages of\nadoption and are actively being researched. The challenges of graph-based\nmobility analysis are multifaceted - the lack of sufficiently high-quality data\nto represent flows at high spatial and teporal resolution whereas, limited\ncomputational resources to translate large voluments of mobility data into a\nnetwork structure, and scaling issues inherent in graph models etc. The current\nstudy develops a methodology by embedding graphs into a continuous space, which\nalleviates issues related to fast graph matching, graph time-series modeling,\nand visualization of mobility dynamics. Through experiments, we demonstrate how\nmobility data collected from taxicab trajectories could be transformed into\nnetwork structures and patterns of mobility flow changes, and can be used for\ndownstream tasks reporting approx 40% decrease in error on average in matched\ngraphs vs unmatched ones.", "published": "2025-04-04 02:21:44", "link": "http://arxiv.org/abs/2504.03119v1", "categories": ["cs.SI", "cs.AI", "stat.ML"], "primary_category": "cs.SI"}
{"title": "NuWa: Deriving Lightweight Task-Specific Vision Transformers for Edge Devices", "abstract": "Vision Transformers (ViTs) excel in computer vision tasks but lack\nflexibility for edge devices' diverse needs. A vital issue is that ViTs\npre-trained to cover a broad range of tasks are \\textit{over-qualified} for\nedge devices that usually demand only part of a ViT's knowledge for specific\ntasks. Their task-specific accuracy on these edge devices is suboptimal. We\ndiscovered that small ViTs that focus on device-specific tasks can improve\nmodel accuracy and in the meantime, accelerate model inference. This paper\npresents NuWa, an approach that derives small ViTs from the base ViT for edge\ndevices with specific task requirements. NuWa can transfer task-specific\nknowledge extracted from the base ViT into small ViTs that fully leverage\nconstrained resources on edge devices to maximize model accuracy with inference\nlatency assurance. Experiments with three base ViTs on three public datasets\ndemonstrate that compared with state-of-the-art solutions, NuWa improves model\naccuracy by up to $\\text{11.83}\\%$ and accelerates model inference by\n1.29$\\times$ - 2.79$\\times$. Code for reproduction is available at\nhttps://anonymous.4open.science/r/Task_Specific-3A5E.", "published": "2025-04-04 02:19:01", "link": "http://arxiv.org/abs/2504.03118v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi-Granularity Vision Fastformer with Fusion Mechanism for Skin Lesion Segmentation", "abstract": "Background:Convolutional Neural Networks(CNN) and Vision Transformers(ViT)\nare the main techniques used in Medical image segmentation. However, CNN is\nlimited to local contextual information, and ViT's quadratic complexity results\nin significant computational costs. At the same time, equipping the model to\ndistinguish lesion boundaries with varying degrees of severity is also a\nchallenge encountered in skin lesion segmentation. Purpose:This research aims\nto optimize the balance between computational costs and long-range dependency\nmodelling and achieve excellent generalization across lesions with different\ndegrees of severity. Methods:we propose a lightweight U-shape network that\nutilizes Vision Fastformer with Fusion Mechanism (VFFM-UNet). We inherit the\nadvantages of Fastformer's additive attention mechanism, combining element-wise\nproduct and matrix product for comprehensive feature extraction and channel\nreduction to save computational costs. In order to accurately identify the\nlesion boundaries with varying degrees of severity, we designed Fusion\nMechanism including Multi-Granularity Fusion and Channel Fusion, which can\nprocess the feature maps in the granularity and channel levels to obtain\ndifferent contextual information. Results:Comprehensive experiments on the\nISIC2017, ISIC2018 and PH2 datasets demonstrate that VFFM-UNet outperforms\nexisting state-of-the-art models regarding parameter numbers, computational\ncomplexity and segmentation performance. In short, compared to MISSFormer, our\nmodel achieves superior segmentation performance while reducing parameter and\ncomputation costs by 101x and 15x, respectively. Conclusions:Both quantitative\nand qualitative analyses show that VFFM-UNet sets a new benchmark by reaching\nan ideal balance between parameter numbers, computational complexity, and\nsegmentation performance compared to existing state-of-the-art models.", "published": "2025-04-04 01:27:43", "link": "http://arxiv.org/abs/2504.03108v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Post-processing for Fair Regression via Explainable SVD", "abstract": "This paper presents a post-processing algorithm for training fair neural\nnetwork regression models that satisfy statistical parity, utilizing an\nexplainable singular value decomposition (SVD) of the weight matrix. We propose\na linear transformation of the weight matrix, whereby the singular values\nderived from the SVD of the transformed matrix directly correspond to the\ndifferences in the first and second moments of the output distributions across\ntwo groups. Consequently, we can convert the fairness constraints into\nconstraints on the singular values. We analytically solve the problem of\nfinding the optimal weights under these constraints. Experimental validation on\nvarious datasets demonstrates that our method achieves a similar or superior\nfairness-accuracy trade-off compared to the baselines without using the\nsensitive attribute at the inference time.", "published": "2025-04-04 00:10:01", "link": "http://arxiv.org/abs/2504.03093v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Machine Learning-Based Detection and Analysis of Suspicious Activities in Bitcoin Wallet Transactions in the USA", "abstract": "The dramatic adoption of Bitcoin and other cryptocurrencies in the USA has\nrevolutionized the financial landscape and provided unprecedented investment\nand transaction efficiency opportunities. The prime objective of this research\nproject is to develop machine learning algorithms capable of effectively\nidentifying and tracking suspicious activity in Bitcoin wallet transactions.\nWith high-tech analysis, the study aims to create a model with a feature for\nidentifying trends and outliers that can expose illicit activity. The current\nstudy specifically focuses on Bitcoin transaction information in America, with\na strong emphasis placed on the importance of knowing about the immediate\nenvironment in and through which such transactions pass through. The dataset is\ncomposed of in-depth Bitcoin wallet transactional information, including\nimportant factors such as transaction values, timestamps, network flows, and\naddresses for wallets. All entries in the dataset expose information about\nfinancial transactions between wallets, including received and sent\ntransactions, and such information is significant for analysis and trends that\ncan represent suspicious activity. This study deployed three accredited\nalgorithms, most notably, Logistic Regression, Random Forest, and Support\nVector Machines. In retrospect, Random Forest emerged as the best model with\nthe highest F1 Score, showcasing its ability to handle non-linear relationships\nin the data. Insights revealed significant patterns in wallet activity, such as\nthe correlation between unredeemed transactions and final balances. The\napplication of machine algorithms in tracking cryptocurrencies is a tool for\ncreating transparent and secure U.S. markets.", "published": "2025-04-04 00:07:32", "link": "http://arxiv.org/abs/2504.03092v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ProbRes: Probabilistic Jump Diffusion for Open-World Egocentric Activity Recognition", "abstract": "Open-world egocentric activity recognition poses a fundamental challenge due\nto its unconstrained nature, requiring models to infer unseen activities from\nan expansive, partially observed search space. We introduce ProbRes, a\nProbabilistic Residual search framework based on jump-diffusion that\nefficiently navigates this space by balancing prior-guided exploration with\nlikelihood-driven exploitation. Our approach integrates structured commonsense\npriors to construct a semantically coherent search space, adaptively refines\npredictions using Vision-Language Models (VLMs) and employs a stochastic search\nmechanism to locate high-likelihood activity labels while minimizing exhaustive\nenumeration efficiently. We systematically evaluate ProbRes across multiple\nopenness levels (L0 - L3), demonstrating its adaptability to increasing search\nspace complexity. In addition to achieving state-of-the-art performance on\nbenchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, and Charades-Ego), we\nestablish a clear taxonomy for open-world recognition, delineating the\nchallenges and methodological advancements necessary for egocentric activity\nunderstanding. Our results highlight the importance of structured search\nstrategies, paving the way for scalable and efficient open-world activity\nrecognition.", "published": "2025-04-04 21:30:45", "link": "http://arxiv.org/abs/2504.03948v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Brain Disorder Diagnosis with Advanced Brain Function Representation and Kolmogorov-Arnold Networks", "abstract": "Quantifying functional connectivity (FC), a vital metric for the diagnosis of\nvarious brain disorders, traditionally relies on the use of a pre-defined brain\natlas. However, using such atlases can lead to issues regarding selection bias\nand lack of regard for specificity. Addressing this, we propose a novel\ntransformer-based classification network (AFBR-KAN) with effective brain\nfunction representation to aid in diagnosing autism spectrum disorder (ASD).\nAFBR-KAN leverages Kolmogorov-Arnold Network (KAN) blocks replacing traditional\nmulti-layer perceptron (MLP) components. Thorough experimentation reveals the\neffectiveness of AFBR-KAN in improving the diagnosis of ASD under various\nconfigurations of the model architecture. Our code is available at\nhttps://github.com/tbwa233/ABFR-KAN", "published": "2025-04-04 20:42:06", "link": "http://arxiv.org/abs/2504.03923v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments", "abstract": "We present WildGS-SLAM, a robust and efficient monocular RGB SLAM system\ndesigned to handle dynamic environments by leveraging uncertainty-aware\ngeometric mapping. Unlike traditional SLAM systems, which assume static scenes,\nour approach integrates depth and uncertainty information to enhance tracking,\nmapping, and rendering performance in the presence of moving objects. We\nintroduce an uncertainty map, predicted by a shallow multi-layer perceptron and\nDINOv2 features, to guide dynamic object removal during both tracking and\nmapping. This uncertainty map enhances dense bundle adjustment and Gaussian map\noptimization, improving reconstruction accuracy. Our system is evaluated on\nmultiple datasets and demonstrates artifact-free view synthesis. Results\nshowcase WildGS-SLAM's superior performance in dynamic environments compared to\nstate-of-the-art methods.", "published": "2025-04-04 19:19:40", "link": "http://arxiv.org/abs/2504.03886v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "3D Scene Understanding Through Local Random Access Sequence Modeling", "abstract": "3D scene understanding from single images is a pivotal problem in computer\nvision with numerous downstream applications in graphics, augmented reality,\nand robotics. While diffusion-based modeling approaches have shown promise,\nthey often struggle to maintain object and scene consistency, especially in\ncomplex real-world scenarios. To address these limitations, we propose an\nautoregressive generative approach called Local Random Access Sequence (LRAS)\nmodeling, which uses local patch quantization and randomly ordered sequence\ngeneration. By utilizing optical flow as an intermediate representation for 3D\nscene editing, our experiments demonstrate that LRAS achieves state-of-the-art\nnovel view synthesis and 3D object manipulation capabilities. Furthermore, we\nshow that our framework naturally extends to self-supervised depth estimation\nthrough a simple modification of the sequence design. By achieving strong\nperformance on multiple 3D scene understanding tasks, LRAS provides a unified\nand effective framework for building the next generation of 3D vision models.", "published": "2025-04-04 18:59:41", "link": "http://arxiv.org/abs/2504.03875v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Control Map Distribution using Map Query Bank for Online Map Generation", "abstract": "Reliable autonomous driving systems require high-definition (HD) map that\ncontains detailed map information for planning and navigation. However,\npre-build HD map requires a large cost. Visual-based Online Map Generation\n(OMG) has become an alternative low-cost solution to build a local HD map.\nQuery-based BEV Transformer has been a base model for this task. This model\nlearns HD map predictions from an initial map queries distribution which is\nobtained by offline optimization on training set. Besides the quality of BEV\nfeature, the performance of this model also highly relies on the capacity of\ninitial map query distribution. However, this distribution is limited because\nthe limited query number. To make map predictions optimal on each test sample,\nit is essential to generate a suitable initial distribution for each specific\nscenario. This paper proposes to decompose the whole HD map distribution into a\nset of point representations, namely map query bank (MQBank). To build specific\nmap query initial distributions of different scenarios, low-cost standard\ndefinition map (SD map) data is introduced as a kind of prior knowledge.\nMoreover, each layer of map decoder network learns instance-level map query\nfeatures, which will lose detailed information of each point. However, BEV\nfeature map is a point-level dense feature. It is important to keep point-level\ninformation in map queries when interacting with BEV feature map. This can also\nbe solved with map query bank method. Final experiments show a new insight on\nSD map prior and a new record on OpenLaneV2 benchmark with 40.5%, 45.7% mAP on\nvehicle lane and pedestrian area.", "published": "2025-04-04 18:47:42", "link": "http://arxiv.org/abs/2504.03868v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models", "abstract": "Existing MLLM benchmarks face significant challenges in evaluating Unified\nMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional\ntasks, leading to inconsistent comparisons; 2) absence of benchmarks for\nmixed-modality generation, which fails to assess multimodal reasoning\ncapabilities. We present a comprehensive evaluation framework designed to\nsystematically assess U-MLLMs. Our benchmark includes: Standardized Traditional\nTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30\nsubtasks, ensuring consistent and fair comparisons across studies.\" 2. Unified\nTask Assessment. We introduce five novel tasks testing multimodal reasoning,\nincluding image editing, commonsense QA with image generation, and geometric\nreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,\nsuch as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized\nunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).\nOur findings reveal substantial performance gaps in existing U-MLLMs,\nhighlighting the need for more robust models capable of handling mixed-modality\ntasks effectively. The code and evaluation data can be found in\nhttps://mme-unify.github.io/.", "published": "2025-04-04 17:59:55", "link": "http://arxiv.org/abs/2504.03641v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Shape My Moves: Text-Driven Shape-Aware Synthesis of Human Motions", "abstract": "We explore how body shapes influence human motion synthesis, an aspect often\noverlooked in existing text-to-motion generation methods due to the ease of\nlearning a homogenized, canonical body shape. However, this homogenization can\ndistort the natural correlations between different body shapes and their motion\ndynamics. Our method addresses this gap by generating body-shape-aware human\nmotions from natural language prompts. We utilize a finite scalar\nquantization-based variational autoencoder (FSQ-VAE) to quantize motion into\ndiscrete tokens and then leverage continuous body shape information to\nde-quantize these tokens back into continuous, detailed motion. Additionally,\nwe harness the capabilities of a pretrained language model to predict both\ncontinuous shape parameters and motion tokens, facilitating the synthesis of\ntext-aligned motions and decoding them into shape-aware motions. We evaluate\nour method quantitatively and qualitatively, and also conduct a comprehensive\nperceptual study to demonstrate its efficacy in generating shape-aware motions.", "published": "2025-04-04 17:59:10", "link": "http://arxiv.org/abs/2504.03639v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Algebraic Geometry Approach to Viewing Graph Solvability", "abstract": "The concept of viewing graph solvability has gained significant interest in\nthe context of structure-from-motion. A viewing graph is a mathematical\nstructure where nodes are associated to cameras and edges represent the\nepipolar geometry connecting overlapping views. Solvability studies under which\nconditions the cameras are uniquely determined by the graph. In this paper we\npropose a novel framework for analyzing solvability problems based on Algebraic\nGeometry, demonstrating its potential in understanding structure-from-motion\ngraphs and proving a conjecture that was previously proposed.", "published": "2025-04-04 17:58:03", "link": "http://arxiv.org/abs/2504.03637v1", "categories": ["cs.CV", "math.AG"], "primary_category": "cs.CV"}
{"title": "Quantifying the uncertainty of model-based synthetic image quality metrics", "abstract": "The quality of synthetically generated images (e.g. those produced by\ndiffusion models) are often evaluated using information about image contents\nencoded by pretrained auxiliary models. For example, the Fr\\'{e}chet Inception\nDistance (FID) uses embeddings from an InceptionV3 model pretrained to classify\nImageNet. The effectiveness of this feature embedding model has considerable\nimpact on the trustworthiness of the calculated metric (affecting its\nsuitability in several domains, including medical imaging). Here, uncertainty\nquantification (UQ) is used to provide a heuristic measure of the\ntrustworthiness of the feature embedding model and an FID-like metric called\nthe Fr\\'{e}chet Autoencoder Distance (FAED). We apply Monte Carlo dropout to a\nfeature embedding model (convolutional autoencoder) to model the uncertainty in\nits embeddings. The distribution of embeddings for each input are then used to\ncompute a distribution of FAED values. We express uncertainty as the predictive\nvariance of the embeddings as well as the standard deviation of the computed\nFAED values. We find that their magnitude correlates with the extent to which\nthe inputs are out-of-distribution to the model's training data, providing some\nvalidation of its ability to assess the trustworthiness of the FAED.", "published": "2025-04-04 17:41:58", "link": "http://arxiv.org/abs/2504.03623v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VISTA-OCR: Towards generative and interactive end to end OCR models", "abstract": "We introduce \\textbf{VISTA-OCR} (Vision and Spatially-aware Text Analysis\nOCR), a lightweight architecture that unifies text detection and recognition\nwithin a single generative model. Unlike conventional methods that require\nseparate branches with dedicated parameters for text recognition and detection,\nour approach leverages a Transformer decoder to sequentially generate text\ntranscriptions and their spatial coordinates in a unified branch. Built on an\nencoder-decoder architecture, VISTA-OCR is progressively trained, starting with\nthe visual feature extraction phase, followed by multitask learning with\nmultimodal token generation. To address the increasing demand for versatile OCR\nsystems capable of advanced tasks, such as content-based text localization\n\\ref{content_based_localization}, we introduce new prompt-controllable OCR\ntasks during pre-training.To enhance the model's capabilities, we built a new\ndataset composed of real-world examples enriched with bounding box annotations\nand synthetic samples. Although recent Vision Large Language Models (VLLMs) can\nefficiently perform these tasks, their high computational cost remains a\nbarrier for practical deployment. In contrast, our VISTA$_{\\text{omni}}$\nvariant processes both handwritten and printed documents with only 150M\nparameters, interactively, by prompting. Extensive experiments on multiple\ndatasets demonstrate that VISTA-OCR achieves better performance compared to\nstate-of-the-art specialized models on standard OCR tasks while showing strong\npotential for more sophisticated OCR applications, addressing the growing need\nfor interactive OCR systems. All code and annotations for VISTA-OCR will be\nmade publicly available upon acceptance.", "published": "2025-04-04 17:39:53", "link": "http://arxiv.org/abs/2504.03621v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Diffusion Bridge with Attention-Based SAR Fusion for Satellite Image Cloud Removal", "abstract": "Deep learning has achieved some success in addressing the challenge of cloud\nremoval in optical satellite images, by fusing with synthetic aperture radar\n(SAR) images. Recently, diffusion models have emerged as powerful tools for\ncloud removal, delivering higher-quality estimation by sampling from cloud-free\ndistributions, compared to earlier methods. However, diffusion models initiate\nsampling from pure Gaussian noise, which complicates the sampling trajectory\nand results in suboptimal performance. Also, current methods fall short in\neffectively fusing SAR and optical data. To address these limitations, we\npropose Diffusion Bridges for Cloud Removal, DB-CR, which directly bridges\nbetween the cloudy and cloud-free image distributions. In addition, we propose\na novel multimodal diffusion bridge architecture with a two-branch backbone for\nmultimodal image restoration, incorporating an efficient backbone and dedicated\ncross-modality fusion blocks to effectively extract and fuse features from\nsynthetic aperture radar (SAR) and optical images. By formulating cloud removal\nas a diffusion-bridge problem and leveraging this tailored architecture, DB-CR\nachieves high-fidelity results while being computationally efficient. We\nevaluated DB-CR on the SEN12MS-CR cloud-removal dataset, demonstrating that it\nachieves state-of-the-art results.", "published": "2025-04-04 17:25:49", "link": "http://arxiv.org/abs/2504.03607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Human Registration with Body Part Segmentation on Noisy Point Clouds", "abstract": "Registering human meshes to 3D point clouds is essential for applications\nsuch as augmented reality and human-robot interaction but often yields\nimprecise results due to noise and background clutter in real-world data. We\nintroduce a hybrid approach that incorporates body-part segmentation into the\nmesh fitting process, enhancing both human pose estimation and segmentation\naccuracy. Our method first assigns body part labels to individual points, which\nthen guide a two-step SMPL-X fitting: initial pose and orientation estimation\nusing body part centroids, followed by global refinement of the point cloud\nalignment. Additionally, we demonstrate that the fitted human mesh can refine\nbody part labels, leading to improved segmentation. Evaluations on the\ncluttered and noisy real-world datasets InterCap, EgoBody, and BEHAVE show that\nour approach significantly outperforms prior methods in both pose estimation\nand segmentation accuracy. Code and results are available on our project\nwebsite: https://segfit.github.io", "published": "2025-04-04 17:17:33", "link": "http://arxiv.org/abs/2504.03602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Hybrid Wavelet-Fourier Method for Next-Generation Conditional Diffusion Models", "abstract": "We present a novel generative modeling framework,Wavelet-Fourier-Diffusion,\nwhich adapts the diffusion paradigm to hybrid frequency representations in\norder to synthesize high-quality, high-fidelity images with improved spatial\nlocalization. In contrast to conventional diffusion models that rely\nexclusively on additive noise in pixel space, our approach leverages a\nmulti-transform that combines wavelet sub-band decomposition with partial\nFourier steps. This strategy progressively degrades and then reconstructs\nimages in a hybrid spectral domain during the forward and reverse diffusion\nprocesses. By supplementing traditional Fourier-based analysis with the spatial\nlocalization capabilities of wavelets, our model can capture both global\nstructures and fine-grained features more effectively. We further extend the\napproach to conditional image generation by integrating embeddings or\nconditional features via cross-attention. Experimental evaluations on CIFAR-10,\nCelebA-HQ, and a conditional ImageNet subset illustrate that our method\nachieves competitive or superior performance relative to baseline diffusion\nmodels and state-of-the-art GANs, as measured by Fr\\'echet Inception Distance\n(FID) and Inception Score (IS). We also show how the hybrid frequency-based\nrepresentation improves control over global coherence and fine texture\nsynthesis, paving the way for new directions in multi-scale generative\nmodeling.", "published": "2025-04-04 17:11:04", "link": "http://arxiv.org/abs/2504.03821v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "AdaViT: Adaptive Vision Transformer for Flexible Pretrain and Finetune with Variable 3D Medical Image Modalities", "abstract": "Pretrain techniques, whether supervised or self-supervised, are widely used\nin deep learning to enhance model performance. In real-world clinical\nscenarios, different sets of magnetic resonance (MR) contrasts are often\nacquired for different subjects/cases, creating challenges for deep learning\nmodels assuming consistent input modalities among all the cases and between\npretrain and finetune. Existing methods struggle to maintain performance when\nthere is an input modality/contrast set mismatch with the pretrained model,\noften resulting in degraded accuracy. We propose an adaptive Vision Transformer\n(AdaViT) framework capable of handling variable set of input modalities for\neach case. We utilize a dynamic tokenizer to encode different input image\nmodalities to tokens and take advantage of the characteristics of the\ntransformer to build attention mechanism across variable length of tokens.\nThrough extensive experiments, we demonstrate that this architecture\neffectively transfers supervised pretrained models to new datasets with\ndifferent input modality/contrast sets, resulting in superior performance on\nzero-shot testing, few-shot finetuning, and backward transferring in brain\ninfarct and brain tumor segmentation tasks. Additionally, for self-supervised\npretrain, the proposed method is able to maximize the pretrain data and\nfacilitate transferring to diverse downstream tasks with variable sets of input\nmodalities.", "published": "2025-04-04 16:57:06", "link": "http://arxiv.org/abs/2504.03589v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing", "abstract": "Self-Supervised Video Hashing (SSVH) compresses videos into hash codes for\nefficient indexing and retrieval using unlabeled training videos. Existing\napproaches rely on random frame sampling to learn video features and treat all\nframes equally. This results in suboptimal hash codes, as it ignores\nframe-specific information density and reconstruction difficulty. To address\nthis limitation, we propose a new framework, termed AutoSSVH, that employs\nadversarial frame sampling with hash-based contrastive learning. Our\nadversarial sampling strategy automatically identifies and selects challenging\nframes with richer information for reconstruction, enhancing encoding\ncapability. Additionally, we introduce a hash component voting strategy and a\npoint-to-set (P2Set) hash-based contrastive objective, which help capture\ncomplex inter-video semantic relationships in the Hamming space and improve the\ndiscriminability of learned hash codes. Extensive experiments demonstrate that\nAutoSSVH achieves superior retrieval efficacy and efficiency compared to\nstate-of-the-art approaches. Code is available at\nhttps://github.com/EliSpectre/CVPR25-AutoSSVH.", "published": "2025-04-04 16:56:17", "link": "http://arxiv.org/abs/2504.03587v1", "categories": ["cs.CV", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "PF3Det: A Prompted Foundation Feature Assisted Visual LiDAR 3D Detector", "abstract": "3D object detection is crucial for autonomous driving, leveraging both LiDAR\npoint clouds for precise depth information and camera images for rich semantic\ninformation. Therefore, the multi-modal methods that combine both modalities\noffer more robust detection results. However, efficiently fusing LiDAR points\nand images remains challenging due to the domain gaps. In addition, the\nperformance of many models is limited by the amount of high quality labeled\ndata, which is expensive to create. The recent advances in foundation models,\nwhich use large-scale pre-training on different modalities, enable better\nmulti-modal fusion. Combining the prompt engineering techniques for efficient\ntraining, we propose the Prompted Foundational 3D Detector (PF3Det), which\nintegrates foundation model encoders and soft prompts to enhance LiDAR-camera\nfeature fusion. PF3Det achieves the state-of-the-art results under limited\ntraining data, improving NDS by 1.19% and mAP by 2.42% on the nuScenes dataset,\ndemonstrating its efficiency in 3D detection.", "published": "2025-04-04 16:11:25", "link": "http://arxiv.org/abs/2504.03563v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HumanDreamer-X: Photorealistic Single-image Human Avatars Reconstruction via Gaussian Restoration", "abstract": "Single-image human reconstruction is vital for digital human modeling\napplications but remains an extremely challenging task. Current approaches rely\non generative models to synthesize multi-view images for subsequent 3D\nreconstruction and animation. However, directly generating multiple views from\na single human image suffers from geometric inconsistencies, resulting in\nissues like fragmented or blurred limbs in the reconstructed models. To tackle\nthese limitations, we introduce \\textbf{HumanDreamer-X}, a novel framework that\nintegrates multi-view human generation and reconstruction into a unified\npipeline, which significantly enhances the geometric consistency and visual\nfidelity of the reconstructed 3D models. In this framework, 3D Gaussian\nSplatting serves as an explicit 3D representation to provide initial geometry\nand appearance priority. Building upon this foundation, \\textbf{HumanFixer} is\ntrained to restore 3DGS renderings, which guarantee photorealistic results.\nFurthermore, we delve into the inherent challenges associated with attention\nmechanisms in multi-view human generation, and propose an attention modulation\nstrategy that effectively enhances geometric details identity consistency\nacross multi-view. Experimental results demonstrate that our approach markedly\nimproves generation and reconstruction PSNR quality metrics by 16.45% and\n12.65%, respectively, achieving a PSNR of up to 25.62 dB, while also showing\ngeneralization capabilities on in-the-wild data and applicability to various\nhuman reconstruction backbone models.", "published": "2025-04-04 15:35:14", "link": "http://arxiv.org/abs/2504.03536v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RANa: Retrieval-Augmented Navigation", "abstract": "Methods for navigation based on large-scale learning typically treat each\nepisode as a new problem, where the agent is spawned with a clean memory in an\nunknown environment. While these generalization capabilities to an unknown\nenvironment are extremely important, we claim that, in a realistic setting, an\nagent should have the capacity of exploiting information collected during\nearlier robot operations. We address this by introducing a new\nretrieval-augmented agent, trained with RL, capable of querying a database\ncollected from previous episodes in the same environment and learning how to\nintegrate this additional context information. We introduce a unique agent\narchitecture for the general navigation task, evaluated on ObjectNav, ImageNav\nand Instance-ImageNav. Our retrieval and context encoding methods are\ndata-driven and heavily employ vision foundation models (FM) for both semantic\nand geometric understanding. We propose new benchmarks for these settings and\nwe show that retrieval allows zero-shot transfer across tasks and environments\nwhile significantly improving performance.", "published": "2025-04-04 15:22:02", "link": "http://arxiv.org/abs/2504.03524v1", "categories": ["cs.CV", "cs.IR", "cs.RO"], "primary_category": "cs.CV"}
{"title": "FADConv: A Frequency-Aware Dynamic Convolution for Farmland Non-agriculturalization Identification and Segmentation", "abstract": "Cropland non-agriculturalization refers to the conversion of arable land into\nnon-agricultural uses such as forests, residential areas, and construction\nsites. This phenomenon not only directly leads to the loss of cropland\nresources but also poses systemic threats to food security and agricultural\nsustainability. Accurate identification of cropland and non-cropland areas is\ncrucial for detecting and addressing this issue. Traditional CNNs employ static\nconvolution layers, while dynamic convolution studies demonstrate that\nadaptively weighting multiple convolutional kernels through attention\nmechanisms can enhance accuracy. However, existing dynamic convolution methods\nrelying on Global Average Pooling (GAP) for attention weight allocation suffer\nfrom information loss, limiting segmentation precision. This paper proposes\nFrequency-Aware Dynamic Convolution (FADConv) and a Frequency Attention (FAT)\nmodule to address these limitations. Building upon the foundational structure\nof dynamic convolution, we designed FADConv by integrating 2D Discrete Cosine\nTransform (2D DCT) to capture frequency domain features and fuse them. FAT\nmodule generates high-quality attention weights that replace the traditional\nGAP method,making the combination between dynamic convolution kernels more\nreasonable.Experiments on the GID and Hi-CNA datasets demonstrate that FADConv\nsignificantly improves segmentation accuracy with minimal computational\noverhead. For instance, ResNet18 with FADConv achieves 1.9% and 2.7% increases\nin F1-score and IoU for cropland segmentation on GID, with only 58.87M\nadditional MAdds. Compared to other dynamic convolution approaches, FADConv\nexhibits superior performance in cropland segmentation tasks.", "published": "2025-04-04 15:13:37", "link": "http://arxiv.org/abs/2504.03510v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LV-MAE: Learning Long Video Representations through Masked-Embedding Autoencoders", "abstract": "In this work, we introduce long-video masked-embedding autoencoders (LV-MAE),\na self-supervised learning framework for long video representation. Our\napproach treats short- and long-span dependencies as two separate tasks. Such\ndecoupling allows for a more intuitive video processing where short-span\nspatiotemporal primitives are first encoded and are then used to capture\nlong-range dependencies across consecutive video segments. To achieve this, we\nleverage advanced off-the-shelf multimodal encoders to extract representations\nfrom short segments within the long video, followed by pre-training a\nmasked-embedding autoencoder capturing high-level interactions across segments.\nLV-MAE is highly efficient to train and enables the processing of much longer\nvideos by alleviating the constraint on the number of input frames.\nFurthermore, unlike existing methods that typically pre-train on short-video\ndatasets, our approach offers self-supervised pre-training using long video\nsamples (e.g., 20+ minutes video clips) at scale. Using LV-MAE representations,\nwe achieve state-of-the-art results on three long-video benchmarks -- LVU,\nCOIN, and Breakfast -- employing only a simple classification head for either\nattentive or linear probing. Finally, to assess LV-MAE pre-training and\nvisualize its reconstruction quality, we leverage the video-language aligned\nspace of short video representations to monitor LV-MAE through video-text\nretrieval.", "published": "2025-04-04 14:56:27", "link": "http://arxiv.org/abs/2504.03501v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Probabilistic Machine Learning for Noisy Labels in Earth Observation", "abstract": "Label noise poses a significant challenge in Earth Observation (EO), often\ndegrading the performance and reliability of supervised Machine Learning (ML)\nmodels. Yet, given the critical nature of several EO applications, developing\nrobust and trustworthy ML solutions is essential. In this study, we take a step\nin this direction by leveraging probabilistic ML to model input-dependent label\nnoise and quantify data uncertainty in EO tasks, accounting for the unique\nnoise sources inherent in the domain. We train uncertainty-aware probabilistic\nmodels across a broad range of high-impact EO applications-spanning diverse\nnoise sources, input modalities, and ML configurations-and introduce a\ndedicated pipeline to assess their accuracy and reliability. Our experimental\nresults show that the uncertainty-aware models consistently outperform the\nstandard deterministic approaches across most datasets and evaluation metrics.\nMoreover, through rigorous uncertainty evaluation, we validate the reliability\nof the predicted uncertainty estimates, enhancing the interpretability of model\npredictions. Our findings emphasize the importance of modeling label noise and\nincorporating uncertainty quantification in EO, paving the way for more\naccurate, reliable, and trustworthy ML solutions in the field.", "published": "2025-04-04 14:36:33", "link": "http://arxiv.org/abs/2504.03478v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ATM-Net: Anatomy-Aware Text-Guided Multi-Modal Fusion for Fine-Grained Lumbar Spine Segmentation", "abstract": "Accurate lumbar spine segmentation is crucial for diagnosing spinal\ndisorders. Existing methods typically use coarse-grained segmentation\nstrategies that lack the fine detail needed for precise diagnosis.\nAdditionally, their reliance on visual-only models hinders the capture of\nanatomical semantics, leading to misclassified categories and poor segmentation\ndetails. To address these limitations, we present ATM-Net, an innovative\nframework that employs an anatomy-aware, text-guided, multi-modal fusion\nmechanism for fine-grained segmentation of lumbar substructures, i.e.,\nvertebrae (VBs), intervertebral discs (IDs), and spinal canal (SC). ATM-Net\nadopts the Anatomy-aware Text Prompt Generator (ATPG) to adaptively convert\nimage annotations into anatomy-aware prompts in different views. These insights\nare further integrated with image features via the Holistic Anatomy-aware\nSemantic Fusion (HASF) module, building a comprehensive anatomical context. The\nChannel-wise Contrastive Anatomy-Aware Enhancement (CCAE) module further\nenhances class discrimination and refines segmentation through class-wise\nchannel-level multi-modal contrastive learning. Extensive experiments on the\nMRSpineSeg and SPIDER datasets demonstrate that ATM-Net significantly\noutperforms state-of-the-art methods, with consistent improvements regarding\nclass discrimination and segmentation details. For example, ATM-Net achieves\nDice of 79.39% and HD95 of 9.91 pixels on SPIDER, outperforming the competitive\nSpineParseNet by 8.31% and 4.14 pixels, respectively.", "published": "2025-04-04 14:36:12", "link": "http://arxiv.org/abs/2504.03476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-encoder nnU-Net outperforms Transformer models with self-supervised pretraining", "abstract": "This study addresses the essential task of medical image segmentation, which\ninvolves the automatic identification and delineation of anatomical structures\nand pathological regions in medical images. Accurate segmentation is crucial in\nradiology, as it aids in the precise localization of abnormalities such as\ntumors, thereby enabling effective diagnosis, treatment planning, and\nmonitoring of disease progression. Specifically, the size, shape, and location\nof tumors can significantly influence clinical decision-making and therapeutic\nstrategies, making accurate segmentation a key component of radiological\nworkflows. However, challenges posed by variations in MRI modalities, image\nartifacts, and the scarcity of labeled data complicate the segmentation task\nand impact the performance of traditional models. To overcome these\nlimitations, we propose a novel self-supervised learning Multi-encoder nnU-Net\narchitecture designed to process multiple MRI modalities independently through\nseparate encoders. This approach allows the model to capture modality-specific\nfeatures before fusing them for the final segmentation, thus improving\naccuracy. Our Multi-encoder nnU-Net demonstrates exceptional performance,\nachieving a Dice Similarity Coefficient (DSC) of 93.72%, which surpasses that\nof other models such as vanilla nnU-Net, SegResNet, and Swin UNETR. By\nleveraging the unique information provided by each modality, the model enhances\nsegmentation tasks, particularly in scenarios with limited annotated data.\nEvaluations highlight the effectiveness of this architecture in improving tumor\nsegmentation outcomes.", "published": "2025-04-04 14:31:06", "link": "http://arxiv.org/abs/2504.03474v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Constant Rate Isometric Embeddings of Hamming Metric into Edit Metric", "abstract": "A function $\\varphi: \\{0,1\\}^n \\to \\{0,1\\}^N$ is called an isometric\nembedding of the $n$-dimensional Hamming metric space to the $N$-dimensional\nedit metric space if, for all $x, y \\in \\{0,1\\}^n$, the Hamming distance\nbetween $x$ and $y$ is equal to the edit distance between $\\varphi(x)$ and\n$\\varphi(y)$. The rate of such an embedding is defined as the ratio $n/N$. It\nis well known in the literature how to construct isometric embeddings with a\nrate of $\\Omega(\\frac{1}{\\log n})$. However, achieving even near-isometric\nembeddings with a positive constant rate has remained elusive until now.\n  In this paper, we present an isometric embedding with a rate of 1/8 by\ndiscovering connections to synchronization strings, which were studied in the\ncontext of insertion-deletion codes (Haeupler-Shahrasbi [JACM'21]). At a\ntechnical level, we introduce a framework for obtaining high-rate isometric\nembeddings using a novel object called misaligners. As an immediate consequence\nof our constant rate isometric embedding, we improve known conditional lower\nbounds for various optimization problems in the edit metric, but now with\noptimal dependency on the dimension.\n  We complement our results by showing that no isometric embedding\n$\\varphi:\\{0, 1\\}^n \\to \\{0, 1\\}^N$ can have rate greater than 15/32 for all\npositive integers $n$. En route to proving this upper bound, we uncover\nfundamental structural properties necessary for every Hamming-to-edit isometric\nembedding. We also prove similar upper and lower bounds for embeddings over\nlarger alphabets.\n  Finally, we consider embeddings $\\varphi:\\Sigma_{\\text{in}}^n\\to\n\\Sigma_{\\text{out}}^N$ between different input and output alphabets, where the\nrate is given by\n$\\frac{n\\log|\\Sigma_{\\text{in}}|}{N\\log|\\Sigma_{\\text{out}}|}$. In this\nsetting, we show that the rate can be made arbitrarily close to 1.", "published": "2025-04-04 17:21:25", "link": "http://arxiv.org/abs/2504.03605v1", "categories": ["cs.DM", "cs.CC", "cs.DS", "cs.IT", "math.CO", "math.IT"], "primary_category": "cs.DM"}
{"title": "Towards Robust Offline Evaluation: A Causal and Information Theoretic Framework for Debiasing Ranking Systems", "abstract": "Evaluating retrieval-ranking systems is crucial for developing\nhigh-performing models. While online A/B testing is the gold standard, its high\ncost and risks to user experience require effective offline methods. However,\nrelying on historical interaction data introduces biases-such as selection,\nexposure, conformity, and position biases-that distort evaluation metrics,\ndriven by the Missing-Not-At-Random (MNAR) nature of user interactions and\nfavoring popular or frequently exposed items over true user preferences.\n  We propose a novel framework for robust offline evaluation of\nretrieval-ranking systems, transforming MNAR data into Missing-At-Random (MAR)\nthrough reweighting combined with black-box optimization, guided by neural\nestimation of information-theoretic metrics. Our contributions include (1) a\ncausal formulation for addressing offline evaluation biases, (2) a\nsystem-agnostic debiasing framework, and (3) empirical validation of its\neffectiveness. This framework enables more accurate, fair, and generalizable\nevaluations, enhancing model assessment before deployment.", "published": "2025-04-04 23:52:57", "link": "http://arxiv.org/abs/2504.03997v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Automating Personalization: Prompt Optimization for Recommendation Reranking", "abstract": "Modern recommender systems increasingly leverage large language models (LLMs)\nfor reranking to improve personalization. However, existing approaches face two\nkey limitations: (1) heavy reliance on manually crafted prompts that are\ndifficult to scale, and (2) inadequate handling of unstructured item metadata\nthat complicates preference inference. We present AGP (Auto-Guided Prompt\nRefinement), a novel framework that automatically optimizes user profile\ngeneration prompts for personalized reranking. AGP introduces two key\ninnovations: (1) position-aware feedback mechanisms for precise ranking\ncorrection, and (2) batched training with aggregated feedback to enhance\ngeneralization.", "published": "2025-04-04 22:15:47", "link": "http://arxiv.org/abs/2504.03965v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Practical Poisoning Attacks against Retrieval-Augmented Generation", "abstract": "Large language models (LLMs) have demonstrated impressive natural language\nprocessing abilities but face challenges such as hallucination and outdated\nknowledge. Retrieval-Augmented Generation (RAG) has emerged as a\nstate-of-the-art approach to mitigate these issues. While RAG enhances LLM\noutputs, it remains vulnerable to poisoning attacks. Recent studies show that\ninjecting poisoned text into the knowledge database can compromise RAG systems,\nbut most existing attacks assume that the attacker can insert a sufficient\nnumber of poisoned texts per query to outnumber correct-answer texts in\nretrieval, an assumption that is often unrealistic. To address this limitation,\nwe propose CorruptRAG, a practical poisoning attack against RAG systems in\nwhich the attacker injects only a single poisoned text, enhancing both\nfeasibility and stealth. Extensive experiments across multiple datasets\ndemonstrate that CorruptRAG achieves higher attack success rates compared to\nexisting baselines.", "published": "2025-04-04 21:49:42", "link": "http://arxiv.org/abs/2504.03957v1", "categories": ["cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Learning Sparse Disentangled Representations for Multimodal Exclusion Retrieval", "abstract": "Multimodal representations are essential for cross-modal retrieval, but they\noften lack interpretability, making it difficult to understand the reasoning\nbehind retrieved results. Sparse disentangled representations offer a promising\nsolution; however, existing methods rely heavily on text tokens, resulting in\nhigh-dimensional embeddings. In this work, we propose a novel approach that\ngenerates compact, fixed-size embeddings that maintain disentanglement while\nproviding greater control over retrieval tasks. We evaluate our method on\nchallenging exclusion queries using the MSCOCO and Conceptual Captions\nbenchmarks, demonstrating notable improvements over dense models like CLIP,\nBLIP, and VISTA (with gains of up to 11% in AP@10), as well as over sparse\ndisentangled models like VDR (achieving up to 21% gains in AP@10). Furthermore,\nwe present qualitative results that emphasize the enhanced interpretability of\nour disentangled representations.", "published": "2025-04-04 05:23:45", "link": "http://arxiv.org/abs/2504.03184v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Exploiting Fine-Grained Skip Behaviors for Micro-Video Recommendation", "abstract": "The growing trend of sharing short videos on social media platforms, where\nusers capture and share moments from their daily lives, has led to an increase\nin research efforts focused on micro-video recommendations. However,\nconventional methods oversimplify the modeling of skip behavior, categorizing\ninteractions solely as positive or negative based on whether skipping occurs.\nThis study was motivated by the importance of the first few seconds of\nmicro-videos, leading to a refinement of signals into three distinct\ncategories: highly positive, less positive, and negative. Specifically, we\nclassify skip interactions occurring within a short time as negatives, while\nthose occurring after a delay are categorized as less positive. The proposed\ndual-level graph and hierarchical ranking loss are designed to effectively\nlearn these fine-grained interactions. Our experiments demonstrated that the\nproposed method outperformed three conventional methods across eight evaluation\nmeasures on two public datasets.", "published": "2025-04-04 01:25:26", "link": "http://arxiv.org/abs/2504.03107v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Analysis of Uncertainty in Procedural Maps in Slay the Spire", "abstract": "This work investigates the role of uncertainty in Slay the Spire using an\ninformation-theoretic framework. Focusing on the entropy of game paths (which\nare based on procedurally-generated maps) we analyze how randomness influences\nplayer decision-making and success. By examining a dataset of 20,000 game runs,\nwe quantify the entropy of paths taken by players and relate it with their\noutcomes and skill levels. The results show that victorious runs are associated\nwith higher normalized entropy, suggesting more risk-taking. Additionally,\nhigher-skill players tend to exhibit distinct patterns of risk-taking behavior\nin later game stages.", "published": "2025-04-04 20:29:04", "link": "http://arxiv.org/abs/2504.03918v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Shannon Weights for binary dynamical recurrent sources of zero entropy", "abstract": "A probabilistic source is defined as the set of infinite words (over a given\ndenumerable alphabet) endowed with a probability $\\mu$. The paper deals with\ngeneral binary sources where the distribution of any symbol (0 or 1) may depend\non an unbounded part of the previous history. The paper studies Shannon\nweights: whereas the classical Shannon entropy ${\\cal E}_{\\mu}$ is the average\namount of information brought by one symbol of the emitted word, the Shannon\nweight sequence deals with the average amount of information $m_{\\mu}(n)$ that\nis brought by the emitted prefix of length $n$. For a source with a non zero\nentropy, the estimate $m_{\\mu}(n)\\sim{\\cal E}_{\\mu} \\cdot n$ thus holds. The\npaper considers the model of dynamical sources, where a source word isemitted\nas an encoded trajectory of a dynamical system of the unit interval, when\nendowed with probability $\\mu$. It focus on sources with zero entropy and gives\nexplicit constructions for sources whose Shannon weight sequence satisfies\n$m_{\\mu}(n)=o(n)$, with a prescribed behaviour. In this case, sources with zero\nentropy lead to dynamical systems built on maps with an indifferent fixed\npoint. This class notably contains the celebrated Farey source, which presents\nwell-known intermittency phenomena. Methods are based on analytic combinatorics\nand generating functions, and they are enlarged, in the present dynamical case,\nwith dynamical systems tools (mainly transfer operators).", "published": "2025-04-04 15:36:30", "link": "http://arxiv.org/abs/2504.03538v1", "categories": ["math.DS", "cs.IT", "math.IT"], "primary_category": "math.DS"}
{"title": "Fairness vs. Equality: RSMA-Based Multi-Target and Multi-User Integrated Sensing and Communications", "abstract": "This paper investigates the tradeoff between sensing and communication in an\nISAC system comprising multiple sensing targets and communication users. A\ndual-functional base station conducts downlink data transmission services based\non RSMA for multiple users, while sensing surrounding multiple targets. To\nenable effective multicast communications and ensure fair and balanced\nmulti-target sensing and under a constrained power budget, we propose a\nmulti-target sensing enhancement scheme incorporating fairness-aware BF, common\nrate splitting, and sensing power allocation. The proposed scheme minimizes the\nsensing CRB, while maximizing communication rate demands. Specifically, we\nderive closed-form expressions for both sensing CRB and communication rates.\nBuilding upon them, we formulate an optimization problem aiming to minimize the\nsensing CRB, while maximizing the communication rates. Considering the\nnon-convex nature of the original optimization problem poses significant\ncomputational challenges, we transform the tradeoff optimization into a\nPareto-optimal problem by employing Taylor series expansion, semi-definite\nrelaxation, successive convex approximation, and penalty function to transform\nthe non-convex problem and associated constraints into tractable forms.\nExtensive simulations validate the theoretical analysis and demonstrate\nsignificant advantages of the proposed RSMA-based fairness-aware BF over\nnon-orthogonal multiple access, space division multiple access, and orthogonal\nmultiple access, through comprehensive comparisons in two key aspects: CRB\nperformance improvement and sensing-communication tradeoff characteristics. The\nproposed optimization framework exhibits remarkable superiority in enhancing\nboth sensing accuracy and communication quality for ISAC systems.", "published": "2025-04-04 11:32:54", "link": "http://arxiv.org/abs/2504.03361v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On Fundamental Limits for Fluid Antenna-assisted Integrated Sensing and Communications for Unsourced Random Access", "abstract": "This paper investigates the unsourced random access (URA) problem for\nintegrated sensing and commutations (ISAC). Recent results reveal that\nconventional multiple access strategies for ISAC such as treating interference\nas noise (TIN) and time-division multiple access (TDMA) can be easily\noverwhelmed and fail to support the increasingly surging number of active\nusers. Hence, the unsourced ISAC (UNISAC) system model has emerged as a\npromising enabler for the future ISAC networks. To advance this work, we adopt\na more realistic channel model and propose to utilize fluid antenna system\n(FAS) for UNISAC. The achievable performance bound and floor of the proposed\nFAS-UNISAC are derived to validate the great potential. Our results demonstrate\nthat promising improvement on the available user volume and the sensing and\ncommunication capability can be obtained due to the spatial diversities\ninherent within fluid antenna.", "published": "2025-04-04 05:22:43", "link": "http://arxiv.org/abs/2504.03183v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Superresolution imaging with entanglement-enhanced telescopy", "abstract": "Long-baseline interferometry will be possible using pre-shared entanglement\nbetween two telescope sites to mimic the standard phase-scanning\ninterferometer, but without physical beam combination. We show that\nspatial-mode sorting at each telescope, along with pre-shared entanglement, can\nbe used to realize the most general multimode interferometry on light collected\nby any number of telescopes, enabling achieving quantitative-imaging\nperformance at the ultimate limit pursuant to the baseline as afforded by\nquantum theory. We work out an explicit example involving two telescopes\nimaging two point sources.", "published": "2025-04-04 02:12:10", "link": "http://arxiv.org/abs/2504.03117v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Regression Discontinuity Design with Distribution-Valued Outcomes", "abstract": "This article introduces Regression Discontinuity Design (RDD) with\nDistribution-Valued Outcomes (R3D), extending the standard RDD framework to\nsettings where the outcome is a distribution rather than a scalar. Such\nsettings arise when treatment is assigned at a higher level of aggregation than\nthe outcome-for example, when a subsidy is allocated based on a firm-level\nrevenue cutoff while the outcome of interest is the distribution of employee\nwages within the firm. Since standard RDD methods cannot accommodate such\ntwo-level randomness, I propose a novel approach based on random distributions.\nThe target estimand is a \"local average quantile treatment effect\", which\naverages across random quantiles. To estimate this target, I introduce two\nrelated approaches: one that extends local polynomial regression to random\nquantiles and another based on local Fr\\'echet regression, a form of functional\nregression. For both estimators, I establish asymptotic normality and develop\nuniform, debiased confidence bands together with a data-driven bandwidth\nselection procedure. Simulations validate these theoretical properties and show\nexisting methods to be biased and inconsistent in this setting. I then apply\nthe proposed methods to study the effects of gubernatorial party control on\nwithin-state income distributions in the US, using a close-election design. The\nresults suggest a classic equality-efficiency tradeoff under Democratic\ngovernorship, driven by reductions in income at the top of the distribution.", "published": "2025-04-04 23:12:35", "link": "http://arxiv.org/abs/2504.03992v1", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.AP", "stat.ME", "stat.TH"], "primary_category": "econ.EM"}
{"title": "A New Approach to Controlling Linear Dynamical Systems", "abstract": "We propose a new method for controlling linear dynamical systems under\nadversarial disturbances and cost functions. Our algorithm achieves a running\ntime that scales polylogarithmically with the inverse of the stability margin,\nimproving upon prior methods with polynomial dependence maintaining the same\nregret guarantees. The technique, which may be of independent interest, is\nbased on a novel convex relaxation that approximates linear control policies\nusing spectral filters constructed from the eigenvectors of a specific Hankel\nmatrix.", "published": "2025-04-04 21:37:46", "link": "http://arxiv.org/abs/2504.03952v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC", "stat.ML"], "primary_category": "eess.SY"}
{"title": "Batch Bayesian Optimization for High-Dimensional Experimental Design: Simulation and Visualization", "abstract": "Bayesian Optimization (BO) is increasingly used to guide experimental\noptimization tasks. To elucidate BO behavior in noisy and high-dimensional\nsettings typical for materials science applications, we perform batch BO of two\nsix-dimensional test functions: an Ackley function representing a\nneedle-in-a-haystack problem and a Hartmann function representing a problem\nwith a false maximum with a value close to the global maximum. We show learning\ncurves, performance metrics, and visualization to effectively track the\nevolution of optimization in high dimensions and evaluate how they are affected\nby noise, batch-picking method, choice of acquisition function,and its\nexploration hyperparameter values. We find that the effects of noise depend on\nthe problem landscape; therefore, prior knowledge of the domain structure and\nnoise level is needed when designing BO. The Ackley function optimization is\nsignificantly degraded by noise with a complete loss of ground truth\nresemblance when noise equals 10 % of the maximum objective value. For the\nHartmann function, even in the absence of noise, a significant fraction of the\ninitial samplings identify the false maximum instead of the ground truth\nmaximum as the optimum of the function; with increasing noise, BO remains\neffective, albeit with increasing probability of landing on the false maximum.\nThis study systematically highlights the critical issues when setting up BO and\nchoosing synthetic data to test experimental design. The results and\nmethodology will facilitate wider utilization of BO in guiding experiments,\nspecifically in high-dimensional settings.", "published": "2025-04-04 21:20:11", "link": "http://arxiv.org/abs/2504.03943v1", "categories": ["stat.ML", "cond-mat.mtrl-sci", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Random Normed k-Means: A Paradigm-Shift in Clustering within Probabilistic Metric Spaces", "abstract": "Existing approaches remain largely constrained by traditional distance\nmetrics, limiting their effectiveness in handling random data. In this work, we\nintroduce the first k-means variant in the literature that operates within a\nprobabilistic metric space, replacing conventional distance measures with a\nwell-defined distance distribution function. This pioneering approach enables\nmore flexible and robust clustering in both deterministic and random datasets,\nestablishing a new foundation for clustering in stochastic environments. By\nadopting a probabilistic perspective, our method not only introduces a fresh\nparadigm but also establishes a rigorous theoretical framework that is expected\nto serve as a key reference for future clustering research involving random\ndata. Extensive experiments on diverse real and synthetic datasets assess our\nmodel's effectiveness using widely recognized evaluation metrics, including\nSilhouette, Davies-Bouldin, Calinski Harabasz, the adjusted Rand index, and\ndistortion. Comparative analyses against established methods such as k-means++,\nfuzzy c-means, and kernel probabilistic k-means demonstrate the superior\nperformance of our proposed random normed k-means (RNKM) algorithm. Notably,\nRNKM exhibits a remarkable ability to identify nonlinearly separable\nstructures, making it highly effective in complex clustering scenarios. These\nfindings position RNKM as a groundbreaking advancement in clustering research,\noffering a powerful alternative to traditional techniques while addressing a\nlong-standing gap in the literature. By bridging probabilistic metrics with\nclustering, this study provides a foundational reference for future\ndevelopments and opens new avenues for advanced data analysis in dynamic,\ndata-driven applications.", "published": "2025-04-04 20:48:43", "link": "http://arxiv.org/abs/2504.03928v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Exploration-free Method for a Linear Stochastic Bandit Driven by a Linear Gaussian Dynamical System", "abstract": "In stochastic multi-armed bandits, a major problem the learner faces is the\ntrade-off between exploration and exploitation. Recently, exploration-free\nmethods -- methods that commit to the action predicted to return the highest\nreward -- have been studied from the perspective of linear bandits. In this\npaper, we introduce a linear bandit setting where the reward is the output of a\nlinear Gaussian dynamical system. Motivated by a problem encountered in\nhyperparameter optimization for reinforcement learning, where the number of\nactions is much higher than the number of training iterations, we propose\nKalman filter Observability Dependent Exploration (KODE), an exploration-free\nmethod that utilizes the Kalman filter predictions to select actions. Our major\ncontribution of this work is our analysis of the performance of the proposed\nmethod, which is dependent on the observability properties of the underlying\nlinear Gaussian dynamical system. We evaluate KODE via two different metrics:\nregret, which is the cumulative expected difference between the highest\npossible reward and the reward sampled by KODE, and action alignment, which\nmeasures how closely KODE's chosen action aligns with the linear Gaussian\ndynamical system's state variable. To provide intuition on the performance, we\nprove that KODE implicitly encourages the learner to explore actions depending\non the observability of the linear Gaussian dynamical system. This method is\ncompared to several well-known stochastic multi-armed bandit algorithms to\nvalidate our theoretical results.", "published": "2025-04-04 20:46:35", "link": "http://arxiv.org/abs/2504.03926v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Opening the Black-Box: Symbolic Regression with Kolmogorov-Arnold Networks for Energy Applications", "abstract": "While most modern machine learning methods offer speed and accuracy, few\npromise interpretability or explainability -- two key features necessary for\nhighly sensitive industries, like medicine, finance, and engineering. Using\neight datasets representative of one especially sensitive industry, nuclear\npower, this work compares a traditional feedforward neural network (FNN) to a\nKolmogorov-Arnold Network (KAN). We consider not only model performance and\naccuracy, but also interpretability through model architecture and\nexplainability through a post-hoc SHAP analysis. In terms of accuracy, we find\nKANs and FNNs comparable across all datasets, when output dimensionality is\nlimited. KANs, which transform into symbolic equations after training, yield\nperfectly interpretable models while FNNs remain black-boxes. Finally, using\nthe post-hoc explainability results from Kernel SHAP, we find that KANs learn\nreal, physical relations from experimental data, while FNNs simply produce\nstatistically accurate results. Overall, this analysis finds KANs a promising\nalternative to traditional machine learning methods, particularly in\napplications requiring both accuracy and comprehensibility.", "published": "2025-04-04 20:23:33", "link": "http://arxiv.org/abs/2504.03913v1", "categories": ["cs.LG", "cs.SC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Stochastic Variational Inference with Tuneable Stochastic Annealing", "abstract": "In this paper, we exploit the observation that stochastic variational\ninference (SVI) is a form of annealing and present a modified SVI approach --\napplicable to both large and small datasets -- that allows the amount of\nannealing done by SVI to be tuned. We are motivated by the fact that, in SVI,\nthe larger the batch size the more approximately Gaussian is the intrinsic\nnoise, but the smaller its variance. This low variance reduces the amount of\nannealing which is needed to escape bad local optimal solutions. We propose a\nsimple method for achieving both goals of having larger variance noise to\nescape bad local optimal solutions and more data information to obtain more\naccurate gradient directions. The idea is to set an actual batch size, which\nmay be the size of the data set, and a smaller effective batch size that\nmatches the larger level of variance at this smaller batch size. The result is\nan approximation to the maximum entropy stochastic gradient at this variance\nlevel. We theoretically motivate our approach for the framework of conjugate\nexponential family models and illustrate the method empirically on the\nprobabilistic matrix factorization collaborative filter, the Latent Dirichlet\nAllocation topic model, and the Gaussian mixture model.", "published": "2025-04-04 19:46:10", "link": "http://arxiv.org/abs/2504.03902v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient FPGA-accelerated Convolutional Neural Networks for Cloud Detection on CubeSats", "abstract": "We present the implementation of four FPGA-accelerated convolutional neural\nnetwork (CNN) models for onboard cloud detection in resource-constrained\nCubeSat missions, leveraging Xilinx's Vitis AI (VAI) framework and Deep\nLearning Processing Unit (DPU), a programmable engine with pre-implemented,\nparameterizable IP cores optimized for deep neural networks, on a Zynq\nUltraScale+ MPSoC. This study explores both pixel-wise (Pixel-Net and\nPatch-Net) and image-wise (U-Net and Scene-Net) models to benchmark trade-offs\nin accuracy, latency, and model complexity. Applying channel pruning, we\nachieved substantial reductions in model parameters (up to 98.6%) and\nfloating-point operations (up to 90.7%) with minimal accuracy loss.\nFurthermore, the VAI tool was used to quantize the models to 8-bit precision,\nensuring optimized hardware performance with negligible impact on accuracy. All\nmodels retained high accuracy post-FPGA integration, with a cumulative maximum\naccuracy drop of only 0.6% after quantization and pruning. The image-wise\nScene-Net and U-Net models demonstrated strong real-time inference\ncapabilities, achieving frame rates per second of 57.14 and 37.45,\nrespectively, with power consumption of around 2.5 W, surpassing\nstate-of-the-art onboard cloud detection solutions. Our approach underscores\nthe potential of DPU-based hardware accelerators to expand the processing\ncapabilities of small satellites, enabling efficient and flexible onboard\nCNN-based applications.", "published": "2025-04-04 19:32:47", "link": "http://arxiv.org/abs/2504.03891v1", "categories": ["eess.SP", "cs.LG", "cs.NE"], "primary_category": "eess.SP"}
{"title": "Using Attention Sinks to Identify and Evaluate Dormant Heads in Pretrained LLMs", "abstract": "Multi-head attention is foundational to large language models (LLMs),\nenabling different heads to have diverse focus on relevant input tokens.\nHowever, learned behaviors like attention sinks, where the first token receives\nmost attention despite limited semantic importance, challenge our understanding\nof multi-head attention. To analyze this phenomenon, we propose a new\ndefinition for attention heads dominated by attention sinks, known as dormant\nattention heads. We compare our definition to prior work in a model\nintervention study where we test whether dormant heads matter for inference by\nzeroing out the output of dormant attention heads. Using six pretrained models\nand five benchmark datasets, we find our definition to be more model and\ndataset-agnostic. Using our definition on most models, more than 4% of a\nmodel's attention heads can be zeroed while maintaining average accuracy, and\nzeroing more than 14% of a model's attention heads can keep accuracy to within\n1% of the pretrained model's average accuracy. Further analysis reveals that\ndormant heads emerge early in pretraining and can transition between dormant\nand active states during pretraining. Additionally, we provide evidence that\nthey depend on characteristics of the input text.", "published": "2025-04-04 19:28:23", "link": "http://arxiv.org/abs/2504.03889v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Concept-based Rubrics Improve LLM Formative Assessment and Data Synthesis", "abstract": "Formative assessment in STEM topics aims to promote student learning by\nidentifying students' current understanding, thus targeting how to promote\nfurther learning. Previous studies suggest that the assessment performance of\ncurrent generative large language models (LLMs) on constructed responses to\nopen-ended questions is significantly lower than that of supervised classifiers\ntrained on high-quality labeled data. However, we demonstrate that\nconcept-based rubrics can significantly enhance LLM performance, which narrows\nthe gap between LLMs as off-the shelf assessment tools, and smaller supervised\nmodels, which need large amounts of training data. For datasets where\nconcept-based rubrics allow LLMs to achieve strong performance, we show that\nthe concept-based rubrics help the same LLMs generate high quality synthetic\ndata for training lightweight, high-performance supervised models. Our\nexperiments span diverse STEM student response datasets with labels of varying\nquality, including a new real-world dataset that contains some AI-assisted\nresponses, which introduces additional considerations.", "published": "2025-04-04 19:02:07", "link": "http://arxiv.org/abs/2504.03877v1", "categories": ["cs.LG", "I.2.7; K.3.1"], "primary_category": "cs.LG"}
{"title": "HeterMoE: Efficient Training of Mixture-of-Experts Models on Heterogeneous GPUs", "abstract": "The Mixture-of-Experts (MoE) architecture has become increasingly popular as\na method to scale up large language models (LLMs). To save costs,\nheterogeneity-aware training solutions have been proposed to utilize GPU\nclusters made up of both newer and older-generation GPUs. However, existing\nsolutions are agnostic to the performance characteristics of different MoE\nmodel components (i.e., attention and expert) and do not fully utilize each\nGPU's compute capability.\n  In this paper, we introduce HeterMoE, a system to efficiently train MoE\nmodels on heterogeneous GPUs. Our key insight is that newer GPUs significantly\noutperform older generations on attention due to architectural advancements,\nwhile older GPUs are still relatively efficient for experts. HeterMoE\ndisaggregates attention and expert computation, where older GPUs are only\nassigned with expert modules. Through the proposed zebra parallelism, HeterMoE\noverlaps the computation on different GPUs, in addition to employing an\nasymmetric expert assignment strategy for fine-grained load balancing to\nminimize GPU idle time. Our evaluation shows that HeterMoE achieves up to 2.3x\nspeed-up compared to existing MoE training systems, and 1.4x compared to an\noptimally balanced heterogeneity-aware solution. HeterMoE efficiently utilizes\nolder GPUs by maintaining 95% training throughput on average, even with half of\nthe GPUs in a homogeneous A40 cluster replaced with V100.", "published": "2025-04-04 18:55:52", "link": "http://arxiv.org/abs/2504.03871v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "CREASE-2D Analysis of Small Angle X-ray Scattering Data from Supramolecular Dipeptide Systems", "abstract": "In this paper, we extend a recently developed machine-learning (ML) based\nCREASE-2D method to analyze the entire two-dimensional (2D) scattering pattern\nobtained from small angle X-ray scattering measurements of supramolecular\ndipeptide micellar systems. Traditional analysis of such scattering data would\ninvolve use of approximate or incorrect analytical models to fit to\nazimuthally-averaged 1D scattering patterns that can miss the anisotropic\narrangements. Analysis of the 2D scattering profiles of such micellar solutions\nusing CREASE-2D allows us to understand both isotropic and anisotropic\nstructural arrangements that are present in these systems of assembled\ndipeptides in water and in the presence of added solvents/salts. CREASE-2D\noutputs distributions of relevant structural features including ones that\ncannot be identified with existing analytical models (e.g., assembled tubes,\ncross-sectional eccentricity, tortuosity, orientational order). The\nrepresentative three-dimensional (3D) real-space structures for the optimized\nvalues of these structural features further facilitate visualization of the\nstructures. Through this detailed interpretation of these 2D SAXS profiles we\nare able to characterize the shapes of the assembled tube structures as a\nfunction of dipeptide chemistry, solution conditions with varying salts and\nsolvents, and relative concentrations of all components. This paper\ndemonstrates how CREASE-2D analysis of entire SAXS profiles can provide an\nunprecedented level of understanding of structural arrangements which has not\nbeen possible through traditional analytical model fits to the 1D SAXS data.", "published": "2025-04-04 18:53:32", "link": "http://arxiv.org/abs/2504.03869v1", "categories": ["cond-mat.soft", "cs.LG"], "primary_category": "cond-mat.soft"}
{"title": "Offline and Distributional Reinforcement Learning for Wireless Communications", "abstract": "The rapid growth of heterogeneous and massive wireless connectivity in 6G\nnetworks demands intelligent solutions to ensure scalability, reliability,\nprivacy, ultra-low latency, and effective control. Although artificial\nintelligence (AI) and machine learning (ML) have demonstrated their potential\nin this domain, traditional online reinforcement learning (RL) and deep RL\nmethods face limitations in real-time wireless networks. For instance, these\nmethods rely on online interaction with the environment, which might be\nunfeasible, costly, or unsafe. In addition, they cannot handle the inherent\nuncertainties in real-time wireless applications. We focus on offline and\ndistributional RL, two advanced RL techniques that can overcome these\nchallenges by training on static datasets and accounting for network\nuncertainties. We introduce a novel framework that combines offline and\ndistributional RL for wireless communication applications. Through case studies\non unmanned aerial vehicle (UAV) trajectory optimization and radio resource\nmanagement (RRM), we demonstrate that our proposed Conservative Quantile\nRegression (CQR) algorithm outperforms conventional RL approaches regarding\nconvergence speed and risk management. Finally, we discuss open challenges and\npotential future directions for applying these techniques in 6G networks,\npaving the way for safer and more efficient real-time wireless systems.", "published": "2025-04-04 09:24:39", "link": "http://arxiv.org/abs/2504.03804v1", "categories": ["cs.LG", "cs.MA", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Extending Data Spatial Semantics for Scale Agnostic Programming", "abstract": "We introduce extensions to Data Spatial Programming (DSP) that enable\nscale-agnostic programming for application development. Building on DSP's\nparadigm shift from data-to-compute to compute-to-data, we formalize additional\nintrinsic language constructs that abstract persistent state, multi-user\ncontexts, multiple entry points, and cross-machine distribution for\napplications. By introducing a globally accessible root node and treating\nwalkers as potential entry points, we demonstrate how programs can be written\nonce and executed across scales, from single-user to multi-user, from local to\ndistributed, without modification. These extensions allow developers to focus\non domain logic while delegating runtime concerns of persistence, multi-user\nsupport, distribution, and API interfacing to the execution environment. Our\napproach makes scale-agnostic programming a natural extension of the\ntopological semantics of DSP, allowing applications to seamlessly transition\nfrom single-user to multi-user scenarios, from ephemeral to persistent\nexecution contexts, and from local to distributed execution environments.", "published": "2025-04-04 01:33:34", "link": "http://arxiv.org/abs/2504.03109v1", "categories": ["cs.PL", "cs.DC", "cs.MA", "cs.OS", "cs.SE"], "primary_category": "cs.PL"}
{"title": "Parametric Operator Inference to Simulate the Purging Process in Semiconductor Manufacturing", "abstract": "This work presents the application of parametric Operator Inference (OpInf)\n-- a nonintrusive reduced-order modeling (ROM) technique that learns a\nlow-dimensional representation of a high-fidelity model -- to the numerical\nmodel of the purging process in semiconductor manufacturing. Leveraging the\ndata-driven nature of the OpInf framework, we aim to forecast the flow field\nwithin a plasma-enhanced chemical vapor deposition (PECVD) chamber using\ncomputational fluid dynamics (CFD) simulation data. Our model simplifies the\nsystem by excluding plasma dynamics and chemical reactions, while still\ncapturing the key features of the purging flow behavior. The parametric OpInf\nframework learns nine ROMs based on varying argon mass flow rates at the inlet\nand different outlet pressures. It then interpolates these ROMs to predict the\nsystem's behavior for 25 parameter combinations, including 16 scenarios that\nare not seen in training. The parametric OpInf ROMs, trained on 36\\% of the\ndata and tested on 64\\%, demonstrate accuracy across the entire parameter\ndomain, with a maximum error of 9.32\\%. Furthermore, the ROM achieves an\napproximate 142-fold speedup in online computations compared to the full-order\nmodel CFD simulation. These OpInf ROMs may be used for fast and accurate\npredictions of the purging flow in the PECVD chamber, which could facilitate\neffective particle contamination control in semiconductor manufacturing.", "published": "2025-04-04 23:08:38", "link": "http://arxiv.org/abs/2504.03990v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "The Fascinating World of 2 $\\times$ 2 $\\times$ 2 Tensors: Its Geometry and Optimization Challenges", "abstract": "This educational article highlights the geometric and algebraic complexities\nthat distinguish tensors from matrices, to supplement coverage in advanced\ncourses on linear algebra, matrix analysis, and tensor decompositions. Using\nthe case of real-valued 2 $\\times$ 2 $\\times$ 2 tensors, we show how tensors\nviolate many well-known properties of matrices: (1) The rank of a matrix is\nbounded by its smallest dimension, but a 2 $\\times$ 2 $\\times$ 2 tensor can be\nrank 3. (2) Matrices have a single typical rank, but the rank of a generic 2\n$\\times$ 2 $\\times$ 2 tensor can be 2 or 3 - it has two typical ranks. (3) Any\nlimit point of a sequence of matrices of rank $r$ is at most rank $r$, but a\nlimit point of a sequence of 2 $\\times$ 2 $\\times$ 2 tensors of rank 2 can be\nrank 3 (a higher rank). (4) Matrices always have a best rank-$r$ approximation,\nbut no rank-3 tensor of size 2 $\\times$ 2 $\\times$ 2 has a best rank-2\napproximation. We unify the analysis of the matrix and tensor cases using tools\nfrom algebraic geometry and optimization, providing derivations of these\nsurprising facts. To build intuition for the geometry of rank-constrained sets,\nstudents and educators can explore the geometry of matrix and tensor ranks via\nour interactive visualization tool.", "published": "2025-04-04 21:09:01", "link": "http://arxiv.org/abs/2504.03937v1", "categories": ["math.NA", "cs.NA", "math.AG", "math.OC"], "primary_category": "math.NA"}
{"title": "Optimal Krylov On Average", "abstract": "We propose an adaptive randomized truncation estimator for Krylov subspace\nmethods that optimizes the trade-off between the solution variance and the\ncomputational cost, while remaining unbiased. The estimator solves a\nconstrained optimization problem to compute the truncation probabilities on the\nfly, with minimal computational overhead. The problem has a closed-form\nsolution when the improvement of the deterministic algorithm satisfies a\ndiminishing returns property. We prove that obtaining the optimal adaptive\ntruncation distribution is impossible in the general case. Without the\ndiminishing return condition, our estimator provides a suboptimal but still\nunbiased solution. We present experimental results in GP hyperparameter\ntraining and competitive physics-informed neural networks problem to\ndemonstrate the effectiveness of our approach.", "published": "2025-04-04 20:24:47", "link": "http://arxiv.org/abs/2504.03914v1", "categories": ["math.NA", "cs.NA", "65F10, 68W20, 65B99, 65C05"], "primary_category": "math.NA"}
{"title": "Besov regularity of multivariate non-periodic functions in terms of half-period cosine coefficients and consequences for recovery and numerical integration", "abstract": "In the setting of $d$-variate periodic functions, often modelled as functions\non the torus $\\mathbb{T}^d\\cong[0,1]^d$, the classical tensorized Fourier\nsystem is the system of choice for many applications. Turning to non-periodic\nfunctions on $[0,1]^d$ the Fourier system is not as well-suited as exemplified\nby the Gibbs phenomenon at the boundary. Other systems have therefore been\nconsidered for this setting. One example is the half-period cosine system,\nwhich occurs naturally as the eigenfunctions of the Laplace operator under\nhomogeneous Neumann boundary conditions. We introduce and analyze associated\nfunction spaces, $S^{r}_{p,q}B_{\\mathrm{hpc}}([0,1]^d)$, of dominating mixed\nBesov-type generalizing earlier concepts in this direction. As a main result,\nwe show that there is a natural parameter range, where\n$S^{r}_{p,q}B_{\\mathrm{hpc}}([0,1]^d)$ coincides with the classical Besov space\nof dominating mixed smoothness $S^{r}_{p,q}B([0,1]^d)$. This finding has direct\nimplications for different functional analytic tasks in\n$S^{r}_{p,q}B([0,1]^d)$. It allows to systematically transfer methods,\noriginally taylored to the periodic domain, to the non-periodic setup. To\nillustrate this, we investigate half-period cosine approximation, sampling\nreconstruction, and tent-transformed cubature. Concerning cubature, for\ninstance, we are able to reproduce the optimal convergence rate $n^{-r}(\\log\nn)^{(d-1)(1-1/q)}$ for tent-transformed digital nets in the range $1\\le\np,q\\le\\infty$, $\\tfrac{1}{p}<r<2$, where $n$ is the number of samples. In our\nmain proof we rely on Chui-Wang discretization of the dominating mixed Besov\nspace $S^{r}_{p,q}B(\\mathbb{R}^d)$, which we provide for the first time for the\nmultivariate domain.", "published": "2025-04-04 19:48:24", "link": "http://arxiv.org/abs/2504.03903v1", "categories": ["math.NA", "cs.NA", "math.FA", "41A10, 41A25, 42C10, 42C40, 42B05, 42B35, 46E35, 65D32"], "primary_category": "math.NA"}
{"title": "A Machine Learning and Finite Element Framework for Inverse Elliptic PDEs via Dirichlet-to-Neumann Mapping", "abstract": "Inverse problems for partial differential equations (PDEs) are crucial in\nnumerous applications such as geophysics, biomedical imaging, and material\nscience, where unknown physical properties must be inferred from indirect\nmeasurements. In this work, we address the inverse problem for elliptic PDEs by\nleveraging the Dirichlet-to-Neumann (DtN) map, which captures the relationship\nbetween boundary inputs and flux responses. Thus, this approach enables to\nsolve the inverse problem that seeks the material properties inside the domain\nby utilizing the boundary data. Our framework employs an unsupervised machine\nlearning algorithm that integrates a finite element method (FEM) in the inner\nloop for the forward problem, ensuring high accuracy. Moreover our approach is\nflexible to utilize partial observations of the boundary data, which is often\nthe case in real-world scenarios. By incorporating carefully designed loss\nfunctions that accommodate discontinuities, the method refines coefficient\nreconstructions iteratively. This combined FEM and machine learning approach\noffers a robust, accurate solution strategy for a broad range of inverse\nproblems, enabling improved estimation of critical parameters in applications\nfrom medical diagnostics to subsurface exploration.", "published": "2025-04-04 19:35:33", "link": "http://arxiv.org/abs/2504.03895v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Improving Interoperability in Scientific Computing via MaRDI Open Interfaces", "abstract": "MaRDI Open Interfaces is a software project aimed at improving reuse and\ninteroperability in Scientific Computing by alleviating the difficulties of\ncrossing boundaries between different programming languages, in which numerical\npackages are usually implemented, and of switching between multiple\nimplementations of the same mathematical problem. The software consists of a\nset of formal interface specifications for common Scientific Computing tasks,\nas well as a set of loosely coupled libraries that facilitate implementing\nthese interfaces or adapting existing implementations for multiple programming\nlanguages and handle data marshalling automatically without sacrificing\nperformance, enabling users to use different implementations without\nsignificant code efforts. The software has high reuse potential due to aim to\nsolve general numerical problems.", "published": "2025-04-04 17:45:54", "link": "http://arxiv.org/abs/2504.03628v1", "categories": ["cs.MS", "cs.NA", "math.NA"], "primary_category": "cs.MS"}
{"title": "Unified interface flux evaluation in a general discontinuous Galerkin spectral element framework", "abstract": "High-order discontinuous Galerkin spectral element methods (DGSEM) have\nreceived growing attention and development, especially in the regime of\ncomputational fluid dynamics in recent years. The inherent flexibility of the\ndiscontinuous Galerkin approach in handling non-conforming interfaces, such as\nthose encountered in moving geometries or hp-refinement, presents a significant\nadvantage for real-world simulations. Despite the well-established mathematical\nframework of DG methods, practical implementation challenges persist to boost\nperformance and capability. Most previous studies only focus on certain choices\nof element shape or basis type in a structured mesh, although they have\ndemonstrated the capability of DGSEM in complex flow simulations. This work\ndiscusses the low-cost and unified interface flux evaluation approaches for\ngeneral spectral elements in unstructured meshes, alongside their\nimplementations in the open-source spectral element framework, Nektar++. The\ninitial motivation arises from the discretization of Helmholtz equations by the\nsymmetric interior penalty method, in which the system matrix can easily become\nnon-symmetric if the flux is not properly evaluated on non-conforming\ninterfaces. We focus on the polynomial non-conforming case in this work but\nextending to the geometric non-conforming case is theoretically possible.\nComparisons of different approaches, trade-offs, and performance of benchmark\nof our initial matrix-free implementation are also included, contributing to\nthe broader discourse on high-performance spectral element method\nimplementations.", "published": "2025-04-04 16:25:38", "link": "http://arxiv.org/abs/2504.03573v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Efficient Second-Order Adaptive Procedure for Inserting CAD Geometries into Hexahedral Meshes using Volume Fractions", "abstract": "This paper is concerned with inserting three-dimensional computer-aided\ndesign (CAD) geometries into meshes composed of hexahedral elements using a\nvolume fraction representation. An adaptive procedure for doing so is\npresented. The procedure consists of two steps. The first step performs spatial\nacceleration using a k-d tree. The second step involves subdividing individual\nhexahedra in an adaptive mesh refinement (AMR)-like fashion and approximating\nthe CAD geometry linearly (as a plane) at the finest subdivision. The procedure\nrequires only two geometric queries from a CAD kernel: determining whether or\nnot a queried spatial coordinate is inside or outside the CAD geometry and\ndetermining the closest point on the CAD geometry's surface from a given\nspatial coordinate. We prove that the procedure is second-order accurate for\nsufficiently smooth geometries and sufficiently refined background meshes. We\ndemonstrate the expected order of accuracy is achieved with several\nverification tests and illustrate the procedure's effectiveness for several\nexemplar CAD geometries.", "published": "2025-04-04 15:22:03", "link": "http://arxiv.org/abs/2504.03525v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Modeling and computing many-body electronic properties of twisted bilayer graphene with mechanical relaxation", "abstract": "We introduce and compute solutions of a many-body model of the electronic\nproperties of twisted bilayer graphene which systematically accounts for the\neffects of structural relaxation. We model mechanical relaxation by coupling\nlinear elasticity to a stacking energy that penalizes disregistry. Minimizers\nof the resulting functional are then input into a tight-binding model of\ntwisted bilayer graphene, from which a single-particle continuum moir\\'e-scale\n(Bistritzer-MacDonald-like) model is systematically derived. We then project\nthis model together with a Coulomb electron-electron interaction term into the\nsingle-particle model's flat moir\\'e bands. We numerically compute Hartree-Fock\nground states of this model, comparing the relative energies of competing\nmany-body ground states.", "published": "2025-04-04 14:37:55", "link": "http://arxiv.org/abs/2504.03479v1", "categories": ["math-ph", "cond-mat.mes-hall", "cond-mat.str-el", "cs.NA", "math.AP", "math.MP", "math.NA"], "primary_category": "math-ph"}
{"title": "Sobolev-Poincar\u00e9 inequalities for piecewise $W^{1,p}$ functions over general polytopic meshes", "abstract": "We establish Sobolev-Poincar\\'e inequalities for piecewise $W^{1,p}$\nfunctions over sequences of fairly general polytopic (thence also shape-regular\nsimplicial and Cartesian) meshes in any dimension; amongst others, they cover\nthe case of standard Poincar\\'e inequalities for piecewise $W^{1,p}$ functions\nand can be useful in the analysis of nonconforming finite element\ndiscretizations of nonlinear problems. Crucial tools in their derivation are\nnovel Sobolev-trace inequalities and Babu\\v ska-Aziz inequalities with mixed\nboundary conditions. We provide estimates that are constant free, i.e., that\nare fully explicit with respect to the geometric properties of the domain and\nthe underlying sequence of polytopic meshes.", "published": "2025-04-04 13:43:52", "link": "http://arxiv.org/abs/2504.03449v1", "categories": ["math.NA", "cs.NA", "46E35, 65N30"], "primary_category": "math.NA"}
{"title": "Influence of cellular mechano-calcium feedback in numerical models of cardiac electromechanics", "abstract": "Multiphysics and multiscale mathematical models enable the non-invasive study\nof cardiac function. These models often rely on simplifying assumptions that\nneglect certain biophysical processes to balance fidelity and computational\ncost. In this work, we propose an eikonal-based framework that incorporates\nmechano-calcium feedback -- the effect of mechanical deformation on\ncalcium-troponin buffering -- while introducing only negligible computational\noverhead. To assess the impact of mechano-calcium feedback at the organ level,\nwe develop a bidirectionally coupled cellular electromechanical model and\nintegrate it into two cardiac multiscale frameworks: a monodomain-driven model\nthat accounts for geometric feedback on electrophysiology and the proposed\neikonal-based approach, which instead neglects geometric feedback. By ensuring\nconsistent cellular model calibration across all scenarios, we isolate the role\nof mechano-calcium feedback and systematically compare its effects against\nmodels without it. Our results indicate that, under baseline conditions,\nmechano-calcium feedback has minimal influence on overall cardiac function.\nHowever, its effects become more pronounced in altered force generation\nscenarios, such as inotropic modulation. Furthermore, we demonstrate that the\neikonal-based framework, despite omitting other types of mechano-electric\nfeedback, effectively captures the role of mechano-calcium feedback at\nsignificantly lower computational costs than the monodomain-driven model,\nreinforcing its utility in computational cardiology.", "published": "2025-04-04 13:41:54", "link": "http://arxiv.org/abs/2504.03447v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical simulation of atmospheric transport and dispersion of Phakopsora pachyrhizi urediniospores in South America using the state of Paran\u00e1-Brazil as a model", "abstract": "Phakopsora pachyrhizi is a biotrophic fungus that requires living plant\ntissue to survive in the wild for extended periods. The fungus causes Asian\nrust and costs billions of US dollars every year for its control in South\nAmerican soy production. Despite the regulatory measure that prohibits the\ncultivation of soybeans in some months of the year (soybean-free period) in\nBrazil, the presence of soybean production areas in neighboring countries, such\nas Paraguay and Bolivia, can help the survival of the pathogen between crop\nseasons. It is known that P. pachyrhizi urediniospores can be\nspread/transported thousands of kilometres by the wind. In this context, the\nobjective of this work was to develop a mathematical model to simulate the\natmospheric transport of P. pachyrhizi urediniospores from the west,\nParaguay/Bolivia to Paran\\'a Brazil, through storms coming from cold fronts.\nThe transport of urediniospores was modeled by a diffusive-convective-reactive\nequation. Wind direction and the velocity of cold fronts that crossed Paran\\'a\nstate between October 2018 and February 2019 were used. For validation, real\ncases of rust occurrence in the Paran\\'a state informed by the Anti-rust\nConsortium Portal in the season 2018/19 were used. The results confirm\nmathematically that urediniospores from infected areas located in a country on\nthe west can be transported and deposited on the east, in the state of\nParan\\'a. The first case of soybean rust in Paran\\'a state/Brazil was\nregistered 10 days after the first cold front, suggesting that the transported\nand deposited urediniospores were still viable for host infection. This work\nreinforces the importance of the establishment of the soybean-free period in\nother soybean-producing countries. It will also provide a better understanding\nof the fungus dispersion system, potentially enabling the correct use of\nfungicides.", "published": "2025-04-04 13:25:22", "link": "http://arxiv.org/abs/2504.03433v1", "categories": ["q-bio.PE", "cs.NA", "math.NA", "physics.ao-ph", "physics.soc-ph"], "primary_category": "q-bio.PE"}
{"title": "Shape reconstruction of inclusions based on noisy data via monotonicity methods for the time harmonic elastic wave equation", "abstract": "In this paper, we extend our research concerning the standard and linearized\nmonotonicity methods for the inverse problem of the time harmonic elastic wave\nequation and introduce the modification of these methods for noisy data. In\nmore detail, the methods must provide consistent results when using noisy data\nin order to be able to perform simulations with real world data, e.g.,\nlaboratory data. We therefore consider the disturbed Neumann-to-Dirichlet\noperator and modify the bound of the eigenvalues in the monotonicity tests for\nreconstructing unknown inclusions with noisy data. In doing so, we show that\nthere exists a noise level $\\delta_0$ so that the inclusions are detected and\ntheir shape is reconstructed for all noise levels $\\delta < \\delta_0$. Finally,\nwe present some numerical simulations based on noisy data.", "published": "2025-04-04 13:08:46", "link": "http://arxiv.org/abs/2504.03421v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An adaptive multimesh rational approximation scheme for the spectral fractional Laplacian", "abstract": "The paper presents a novel multimesh rational approximation scheme for the\nnumerical solution of the (homogeneous) Dirichlet problem for the spectral\nfractional Laplacian. The scheme combines a rational approximation of the\nfunction $\\lambda \\mapsto \\lambda^{-s}$ with a set of finite element\napproximations of parameter-dependent non-fractional partial differential\nequations (PDEs). The key idea that underpins the proposed scheme is that each\nparametric PDE is numerically solved on an individually tailored finite element\nmesh. This is in contrast to the existing single-mesh approach, where the same\nfinite element mesh is employed for solving all parametric PDEs. We develop an\na posteriori error estimation strategy for the proposed rational approximation\nscheme and design an adaptive multimesh refinement algorithm. Numerical\nexperiments show improvements in convergence rates compared to the rates for\nuniform mesh refinement and up to 10 times reduction in computational costs\ncompared to the corresponding adaptive algorithm in the single-mesh setting.", "published": "2025-04-04 12:37:57", "link": "http://arxiv.org/abs/2504.03408v1", "categories": ["math.NA", "cs.NA", "65N15, 65N30, 65N50"], "primary_category": "math.NA"}
{"title": "Time-integration of Gaussian variational approximation for the magnetic Schr\u00f6dinger equation", "abstract": "In the present paper we consider the semiclassical magnetic Schr\\\"odinger\nequation, which describes the dynamics of charged particles under the influence\nof a electro-magnetic field. The solution of the time-dependent Schr\\\"odinger\nequation is approximated by a single Gaussian wave packet via the\ntime-dependent Dirac--Frenkel variational principle. For the approximation we\nuse ordinary differential equations of motion for the parameters of the\nvariational solution and extend the second-order Boris algorithm for classical\nmechanics to the quantum mechanical case. In addition, we propose a modified\nversion of the classical fourth order Runge--Kutta method. Numerical\nexperiments explore parameter convergence and geometric properties. Moreover,\nwe benchmark against the analytical solution of the Penning trap.", "published": "2025-04-04 12:35:36", "link": "http://arxiv.org/abs/2504.03407v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quasi-optimal error estimate for the approximation of the elastic flow of inextensible curves", "abstract": "A space-discretization for the elastic flow of inextensible curves is devised\nand quasi-optimal convergence of the corresponding semi-discrete problem is\nproved for a suitable discretization of the nonlinear inextensibility\nconstraint. Further a fully discrete time-stepping scheme that incorporates\nthis constraint is proposed and unconditional stability and convergence of the\ndiscrete scheme are proved. Finally some numerical simulations are used to\nverify the obtained results experimentally.", "published": "2025-04-04 12:25:26", "link": "http://arxiv.org/abs/2504.03404v1", "categories": ["math.NA", "cs.NA", "74B20 65M15 35K55"], "primary_category": "math.NA"}
{"title": "A variationally consistent membrane wrinkling model based on spectral decomposition of the stress tensor", "abstract": "We present a variationally consistent wrinkling model based on spectral\ndecomposition of the stress tensor, providing a unified formulation that\ncaptures the three distinct membrane states. Compared to the previous\nstrain-based spectral decomposition approach, the proposed model improves\naccuracy by satisfying the uniaxial tension condition from tension field theory\nand aligning with the mixed wrinkling criterion. It also demonstrates excellent\nperformance under various loading conditions and offers enhanced generality by\nunifying strain-based, stress-based, and mixed criteria within a single\nframework. Beyond these improvements, the model retains the superior\nconvergence properties of the previous approach, including the framework for\nthe flexible inclusion or omission of residual compressive stiffness. This\nmitigates nonconvergence or singularities in slackening states. With these\nadjustments, new expressions for stress and constitutive tensors are\nconsistently derived. Finally, extensive validation through analytical,\nnumerical, and experimental benchmark tests highlights the robustness of the\nmodel. The results confirm its accuracy in capturing the mechanical response of\nwrinkled thin membranes, strong convergence properties, and value for advanced\nmembrane wrinkling analysis.", "published": "2025-04-04 12:18:10", "link": "http://arxiv.org/abs/2504.03400v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Effects of Interpolation Error and Bias on the Random Mesh Finite Element Method for Inverse Problems", "abstract": "Bayesian inverse problems are an important application for probabilistic\nsolvers of partial differential equations: when fully resolving numerical error\nis computationally infeasible, probabilistic solvers can be used to\nconsistently model the error and propagate it to the posterior. In this work,\nthe performance of the random mesh finite element method (RM-FEM) is\ninvestigated in a Bayesian inverse setting. We show how interpolation error\nnegatively affects the RM-FEM posterior, and how these negative effects can be\ndiminished. In scenarios where FEM is biased for a quantity of interest, we\nfind that RM-FEM struggles to accurately model this bias.", "published": "2025-04-04 12:08:41", "link": "http://arxiv.org/abs/2504.03393v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error estimates of an exponential wave integrator for the nonlinear Schr\u00f6dinger equation with singular potential", "abstract": "We analyze a first-order exponential wave integrator (EWI) for the nonlinear\nSchr\\\"odinger equation (NLSE) with a singular potential locally in $L^2$, which\nmight be locally unbounded. The typical example is the inverse power potential\nsuch as the Coulomb potential, which is the most fundamental potential in\nquantum physics and chemistry. We prove that, under the assumption of\n$L^2$-potential and $H^2$-initial data, the $L^2$-norm convergence of the EWI\nis, roughly, first-order in one dimension (1D) and two dimensions (2D), and\n$\\frac{3}{4}$-order in three dimensions (3D). In addition, under a stronger\nintegrability assumption of $L^p$-potential for some $p>2$ in 3D, the\n$L^2$-norm convergence increases to almost ${\\frac{3}{4}} + 3(\\frac{1}{2} -\n\\frac{1}{p})$ order if $p \\leq \\frac{12}{5}$ and becomes first-order if $p >\n\\frac{12}{5}$. In particular, our results show, to the best of our knowledge\nfor the first time, that first-order $L^2$-norm convergence can be achieved\nwhen solving the NLSE with the Coulomb potential in 3D. The key advancements\nare the use of discrete (in time) Strichartz estimates, which allow us to\nhandle the loss of integrability due to the singular potential that does not\nbelong to $L^\\infty$, and the more favorable local truncation error of the EWI,\nwhich requires no (spatial) smoothness of the potential. Extensive numerical\nresults in 1D, 2D, and 3D are reported to confirm our error estimates and to\nshow the sharpness of our assumptions on the regularity of the singular\npotentials.", "published": "2025-04-04 11:01:51", "link": "http://arxiv.org/abs/2504.03346v1", "categories": ["math.NA", "cs.NA", "65M15, 35Q55, 81Q05"], "primary_category": "math.NA"}
{"title": "Multirate Runge-Kutta for Nonlinearly Partitioned Systems", "abstract": "Multirate integration is an increasingly relevant tool that enables\nscientists to simulate multiphysics systems. Existing multirate methods are\ndesigned for equations whose fast and slow variables can be linearly separated\nusing additive or component-wise partitions. However, in realistic\napplications, this assumption is not always valid. Building on the recently\ndeveloped class of nonlinearly partitioned Runge-Kutta (NPRK) methods, we\ndevelop a framework for multirate NPRK (MR-NPRK) that allows for arbitrary\nnonlinear splittings of the evolution operator. We discuss order conditions,\nformalize different types of coupling between timescales, and analyze joint\nlinear stability of MR-NPRK methods. We then introduce a class of 2nd- and\n3rd-order methods, referred to as ``implicitly-wrapped'' multirate methods,\nthat combine a user-specified explicit method for integrating the fast\ntimescale with several slow implicit stages. These methods are designed to be\nalgorithmically simple with low memory costs and minimal operator evaluations.\nLastly, we conduct numerical experiments to validate our proposed methods and\nshow the benefits of multirating a nonlinear partition.", "published": "2025-04-04 08:18:21", "link": "http://arxiv.org/abs/2504.03257v1", "categories": ["math.NA", "cs.NA", "65L05, 65L06, 65L20, 65M22"], "primary_category": "math.NA"}
{"title": "Accurate stochastic simulation of nonlinear reactions between closest particles", "abstract": "We study a system of diffusing point particles in which any triplet of\nparticles reacts and is removed from the system when the relative proximity of\nthe constituent particles satisfies a predefined condition. Proximity-based\nreaction conditions of this kind are commonly used in particle-based\nsimulations of chemical kinetics to mimic bimolecular reactions, those\ninvolving just two reactants, and have been extensively studied. The rate at\nwhich particles react within the system is determined by the reaction condition\nand particulate diffusion. In the bimolecular case, analytic relations exist\nbetween the reaction rate and the distance at which particles react allowing\nmodellers to tune the rate of the reaction within their simulations by simply\naltering the reaction condition. However, generalising proximity-based reaction\nconditions to trimolecular reactions, those involving three particles, is more\ncomplicated because it requires understanding the distribution of the closest\ndiffusing particle to a point in the vicinity of a spatially dependent\nabsorbing boundary condition. We find that in this case the evolution of the\nsystem is described by a nonlinear partial integro-differential equation with\nno known analytic solution, which makes it difficult to relate the reaction\nrate to the reaction condition. To resolve this, we use singular perturbation\ntheory to obtain a leading-order solution and show how to derive an approximate\nexpression for the reaction rate. We then use finite element methods to\nquantify the higher-order corrections to this solution and the reaction rate,\nwhich are difficult to obtain analytically. Leveraging the insights gathered\nfrom this analysis, we demonstrate how to correct for the errors that arise\nfrom adopting the approximate expression for the reaction rate, enabling for\nthe construction of more accurate particle-based simulations than previously\npossible.", "published": "2025-04-04 07:03:21", "link": "http://arxiv.org/abs/2504.03215v1", "categories": ["math.NA", "cond-mat.stat-mech", "cs.NA", "q-bio.QM", "35Q92, 65N30, 92C45"], "primary_category": "math.NA"}
{"title": "Mathematical Modeling of Option Pricing with an Extended Black-Scholes Framework", "abstract": "This study investigates enhancing option pricing by extending the\nBlack-Scholes model to include stochastic volatility and interest rate\nvariability within the Partial Differential Equation (PDE). The PDE is solved\nusing the finite difference method. The extended Black-Scholes model and a\nmachine learning-based LSTM model are developed and evaluated for pricing\nGoogle stock options. Both models were backtested using historical market data.\nWhile the LSTM model exhibited higher predictive accuracy, the finite\ndifference method demonstrated superior computational efficiency. This work\nprovides insights into model performance under varying market conditions and\nemphasizes the potential of hybrid approaches for robust financial modeling.", "published": "2025-04-04 05:06:55", "link": "http://arxiv.org/abs/2504.03175v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR", "q-fin.CP", "60G07", "G.1.0; G.1.8; G.1.7; G.3; I.2.0"], "primary_category": "math.NA"}
{"title": "An efficient numerical method for surface acoustic wave equations over unbounded domains", "abstract": "Surface acoustic wave (SAW) devices are widely used in modern communication\nequipment and SAW equations describe the critical physical processes of\nacoustic-electric conversion in SAW devices. It is very challenging to\nnumerically solve such equations, since they are typically three dimensional\nproblems defined on unbounded domains. In this paper, we first use the\nperfectly matched layer method to truncate the unbounded domain and then\npropose a finite element tearing and interconnecting algorithm for the\ntruncated equations based on the periodic structure of the truncated domain. We\nalso design an effective solver for the ill-conditioned linear system of the\nLagrange multipliers arising from discretization. Several numerical results are\nperformed to demonstrate the efficiency of the proposed algorithm.", "published": "2025-04-04 02:50:10", "link": "http://arxiv.org/abs/2504.03130v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "A stochastic volatility approximation for a tick-by-tick price model with mean-field interaction", "abstract": "We consider a tick-by-tick model of price formation, in which buy and sell\norders are modeled as self-exciting point processes (Hawkes process), similar\nto the one in [El Euch, Fukasawa, Rosenbaum, The microstructural foundations of\nleverage effect and rough volatility, Finance and Stochastics, 2018]. We adopt\nan agent based approach by studying the aggregation of a large number of these\npoint processes, mutually interacting in a mean-field sense.\n  The financial interpretation is that of an asset on which several labeled\nagents place buy and sell orders following these point processes, influencing\nthe price. The mean-field interaction introduces positive correlations between\norder volumes coming from different agents that reflect features of real\nmarkets such as herd behavior and contagion. When the large scale limit of the\naggregated asset price is computed, if parameters are set to a critical value,\na singular phenomenon occurs: the aggregated model converges to a stochastic\nvolatility model with leverage effect and faster-than-linear mean reversion of\nthe volatility process.\n  The faster-than-linear mean reversion of the volatility process is supported\nby econometric evidence, and we have linked it in [Dai Pra, Pigato,\nMulti-scaling of moments in stochastic volatility models, Stochastic Processes\nand their Applications, 2015] to the observed multifractal behavior of assets\nprices and market indices. This seems connected to the Statistical Physics\nperspective that expects anomalous scaling properties to arise in the critical\nregime.", "published": "2025-04-04 13:37:32", "link": "http://arxiv.org/abs/2504.03445v1", "categories": ["q-fin.MF", "math.PR", "60G55 (Primary) 60F05, 60G44, 91G45 (Secondary)"], "primary_category": "q-fin.MF"}
{"title": "Information Leakages in the Green Bond Market", "abstract": "Public announcement dates are used in the green bond literature to measure\nequity market reactions to upcoming green bond issues. We find a sizeable\nnumber of green bond announcements were pre-dated by anonymous information\nleakages on the Bloomberg Terminal. From a candidate set of 2,036 'Bloomberg\nNews' and 'Bloomberg First Word' headlines gathered between 2016 and 2022, we\nidentify 259 instances of green bond-related information being released before\nbeing publicly announced by the issuing firm. These pre-announcement leaks\nsignificantly alter the equity trading dynamics of the issuing firms over\nintraday and daily event windows. Significant negative abnormal returns and\nincreased trading volumes are observed following news leaks about upcoming\ngreen bond issues. These negative investor reactions are concentrated amongst\nfinancial firms, and leaks that arrive pre-market or early in market trading.\nWe find equity price movements following news leaks can be explained to a\ngreater degree than following public announcements. Sectoral differences are\nalso observed in the key drivers behind investor reactions to green bond leaks\nby non-financials (Tobin's Q and free cash flow) and financials (ROA). Our\nresults suggest that information leakages have a strong impact on market\nbehaviour, and should be accounted for in green bond literature. Our findings\nalso have broader ramifications for financial literature going forward.\nPrivileged access to financially material information, courtesy of the\nubiquitous use of Bloomberg Terminals by professional investors, highlights the\nneed for event studies to consider wider sets of communication channels to\nconfirm the date at which information first becomes available.", "published": "2025-04-04 09:46:15", "link": "http://arxiv.org/abs/2504.03311v1", "categories": ["q-fin.PR", "q-fin.GN", "q-fin.TR"], "primary_category": "q-fin.PR"}
{"title": "Stochastic Optimization with Optimal Importance Sampling", "abstract": "Importance Sampling (IS) is a widely used variance reduction technique for\nenhancing the efficiency of Monte Carlo methods, particularly in rare-event\nsimulation and related applications. Despite its power, the performance of IS\nis often highly sensitive to the choice of the proposal distribution and\nfrequently requires stochastic calibration techniques. While the design and\nanalysis of IS have been extensively studied in estimation settings, applying\nIS within stochastic optimization introduces a unique challenge: the decision\nand the IS distribution are mutually dependent, creating a circular\noptimization structure. This interdependence complicates both the analysis of\nconvergence for decision iterates and the efficiency of the IS scheme. In this\npaper, we propose an iterative gradient-based algorithm that jointly updates\nthe decision variable and the IS distribution without requiring time-scale\nseparation between the two. Our method achieves the lowest possible asymptotic\nvariance and guarantees global convergence under convexity of the objective and\nmild assumptions on the IS distribution family. Furthermore, we show that these\nproperties are preserved under linear constraints by incorporating a recent\nvariant of Nesterov's dual averaging method.", "published": "2025-04-04 16:10:18", "link": "http://arxiv.org/abs/2504.03560v1", "categories": ["math.OC", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "math.OC"}
{"title": "Operator Learning: A Statistical Perspective", "abstract": "Operator learning has emerged as a powerful tool in scientific computing for\napproximating mappings between infinite-dimensional function spaces. A primary\napplication of operator learning is the development of surrogate models for the\nsolution operators of partial differential equations (PDEs). These methods can\nalso be used to develop black-box simulators to model system behavior from\nexperimental data, even without a known mathematical model. In this article, we\nbegin by formalizing operator learning as a function-to-function regression\nproblem and review some recent developments in the field. We also discuss\nPDE-specific operator learning, outlining strategies for incorporating physical\nand mathematical constraints into architecture design and training processes.\nFinally, we end by highlighting key future directions such as active data\ncollection and the development of rigorous uncertainty quantification\nframeworks.", "published": "2025-04-04 14:58:45", "link": "http://arxiv.org/abs/2504.03503v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Conditioning Diffusions Using Malliavin Calculus", "abstract": "In stochastic optimal control and conditional generative modelling, a central\ncomputational task is to modify a reference diffusion process to maximise a\ngiven terminal-time reward. Most existing methods require this reward to be\ndifferentiable, using gradients to steer the diffusion towards favourable\noutcomes. However, in many practical settings, like diffusion bridges, the\nreward is singular, taking an infinite value if the target is hit and zero\notherwise. We introduce a novel framework, based on Malliavin calculus and\npath-space integration by parts, that enables the development of methods robust\nto such singular rewards. This allows our approach to handle a broad range of\napplications, including classification, diffusion bridges, and conditioning\nwithout the need for artificial observational noise. We demonstrate that our\napproach offers stable and reliable training, outperforming existing\ntechniques.", "published": "2025-04-04 14:10:21", "link": "http://arxiv.org/abs/2504.03461v1", "categories": ["stat.ML", "cs.LG", "math.PR", "G.3"], "primary_category": "stat.ML"}
{"title": "Block Toeplitz Sparse Precision Matrix Estimation for Large-Scale Interval-Valued Time Series Forecasting", "abstract": "Modeling and forecasting interval-valued time series (ITS) have attracted\nconsiderable attention due to their growing presence in various contexts. To\nthe best of our knowledge, there have been no efforts to model large-scale ITS.\nIn this paper, we propose a feature extraction procedure for large-scale ITS,\nwhich involves key steps such as auto-segmentation and clustering, and feature\ntransfer learning. This procedure can be seamlessly integrated with any\nsuitable prediction models for forecasting purposes. Specifically, we transform\nthe automatic segmentation and clustering of ITS into the estimation of\nToeplitz sparse precision matrices and assignment set. The\nmajorization-minimization algorithm is employed to convert this highly\nnon-convex optimization problem into two subproblems. We derive efficient\ndynamic programming and alternating direction method to solve these two\nsubproblems alternately and establish their convergence properties. By\nemploying the Joint Recurrence Plot (JRP) to image subsequence and assigning a\nclass label to each cluster, an image dataset is constructed. Then, an\nappropriate neural network is chosen to train on this image dataset and used to\nextract features for the next step of forecasting. Real data applications\ndemonstrate that the proposed method can effectively obtain invariant\nrepresentations of the raw data and enhance forecasting performance.", "published": "2025-04-04 09:57:05", "link": "http://arxiv.org/abs/2504.03322v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Adaptive sparse variational approximations for Gaussian process regression", "abstract": "Accurate tuning of hyperparameters is crucial to ensure that models can\ngeneralise effectively across different settings. In this paper, we present\ntheoretical guarantees for hyperparameter selection using variational Bayes in\nthe nonparametric regression model. We construct a variational approximation to\na hierarchical Bayes procedure, and derive upper bounds for the contraction\nrate of the variational posterior in an abstract setting. The theory is applied\nto various Gaussian process priors and variational classes, resulting in\nminimax optimal rates. Our theoretical results are accompanied with numerical\nanalysis both on synthetic and real world data sets.", "published": "2025-04-04 09:57:00", "link": "http://arxiv.org/abs/2504.03321v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Adaptive Classification of Interval-Valued Time Series", "abstract": "In recent years, the modeling and analysis of interval-valued time series\nhave garnered significant attention in the fields of econometrics and\nstatistics. However, the existing literature primarily focuses on regression\ntasks while neglecting classification aspects. In this paper, we propose an\nadaptive approach for interval-valued time series classification. Specifically,\nwe represent interval-valued time series using convex combinations of upper and\nlower bounds of intervals and transform these representations into images based\non point-valued time series imaging methods. We utilize a fine-grained image\nclassification neural network to classify these images, to achieve the goal of\nclassifying the original interval-valued time series. This proposed method is\napplicable to both univariate and multivariate interval-valued time series. On\nthe optimization front, we treat the convex combination coefficients as\nlearnable parameters similar to the parameters of the neural network and\nprovide an efficient estimation method based on the alternating direction\nmethod of multipliers (ADMM). On the theoretical front, under specific\nconditions, we establish a margin-based multiclass generalization bound for\ngeneric CNNs composed of basic blocks involving convolution, pooling, and fully\nconnected layers. Through simulation studies and real data applications, we\nvalidate the effectiveness of the proposed method and compare its performance\nagainst a wide range of point-valued time series classification methods.", "published": "2025-04-04 09:52:40", "link": "http://arxiv.org/abs/2504.03318v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Weak instrumental variables due to nonlinearities in panel data: A Super Learner Control Function estimator", "abstract": "A triangular structural panel data model with additive separable\nindividual-specific effects is used to model the causal effect of a covariate\non an outcome variable when there are unobservable confounders with some of\nthem time-invariant. In this setup, a linear reduced-form equation might be\nproblematic when the conditional mean of the endogenous covariate and the\ninstrumental variables is nonlinear. The reason is that ignoring the\nnonlinearity could lead to weak instruments As a solution, we propose a\ntriangular simultaneous equation model for panel data with additive separable\nindividual-specific fixed effects composed of a linear structural equation with\na nonlinear reduced form equation. The parameter of interest is the structural\nparameter of the endogenous variable. The identification of this parameter is\nobtained under the assumption of available exclusion restrictions and using a\ncontrol function approach. Estimating the parameter of interest is done using\nan estimator that we call Super Learner Control Function estimator (SLCFE). The\nestimation procedure is composed of two main steps and sample splitting. We\nestimate the control function using a super learner using sample splitting. In\nthe following step, we use the estimated control function to control for\nendogeneity in the structural equation. Sample splitting is done across the\nindividual dimension. We perform a Monte Carlo simulation to test the\nperformance of the estimators proposed. We conclude that the Super Learner\nControl Function Estimators significantly outperform Within 2SLS estimators.", "published": "2025-04-04 07:22:18", "link": "http://arxiv.org/abs/2504.03228v2", "categories": ["econ.EM", "stat.ML"], "primary_category": "econ.EM"}
{"title": "The Ground Cost for Optimal Transport of Angular Velocity", "abstract": "We revisit the optimal transport problem over angular velocity dynamics given\nby the controlled Euler equation. The solution of this problem enables\nstochastic guidance of spin states of a rigid body (e.g., spacecraft) over hard\ndeadline constraint by transferring a given initial state statistics to a\ndesired terminal state statistics. This is an instance of generalized optimal\ntransport over a nonlinear dynamical system. While prior work has reported\nexistence-uniqueness and numerical solution of this dynamical optimal transport\nproblem, here we present structural results about the equivalent Kantorovich\na.k.a. optimal coupling formulation. Specifically, we focus on deriving the\nground cost for the associated Kantorovich optimal coupling formulation. The\nground cost equals to the cost of transporting unit amount of mass from a\nspecific realization of the initial or source joint probability measure to a\nrealization of the terminal or target joint probability measure, and determines\nthe Kantorovich formulation. Finding the ground cost leads to solving a\nstructured deterministic nonlinear optimal control problem, which is shown to\nbe amenable to an analysis technique pioneered by Athans et. al. We show that\nsuch techniques have broader applicability in determining the ground cost (thus\nKantorovich formulation) for a class of generalized optimal mass transport\nproblems involving nonlinear dynamics with translated norm-invariant drift.", "published": "2025-04-04 05:38:00", "link": "http://arxiv.org/abs/2504.03190v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "math.OC"}
{"title": "Bayesian Optimization of Robustness Measures Using Randomized GP-UCB-based Algorithms under Input Uncertainty", "abstract": "Bayesian optimization based on Gaussian process upper confidence bound\n(GP-UCB) has a theoretical guarantee for optimizing black-box functions.\nBlack-box functions often have input uncertainty, but even in this case, GP-UCB\ncan be extended to optimize evaluation measures called robustness measures.\nHowever, GP-UCB-based methods for robustness measures include a trade-off\nparameter $\\beta$, which must be excessively large to achieve theoretical\nvalidity, just like the original GP-UCB. In this study, we propose a new method\ncalled randomized robustness measure GP-UCB (RRGP-UCB), which samples the\ntrade-off parameter $\\beta$ from a probability distribution based on a\nchi-squared distribution and avoids explicitly specifying $\\beta$. The expected\nvalue of $\\beta$ is not excessively large. Furthermore, we show that RRGP-UCB\nprovides tight bounds on the expected value of regret based on the optimal\nsolution and estimated solutions. Finally, we demonstrate the usefulness of the\nproposed method through numerical experiments.", "published": "2025-04-04 05:01:54", "link": "http://arxiv.org/abs/2504.03172v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Accelerating Particle-based Energetic Variational Inference", "abstract": "In this work, we propose a novel particle-based variational inference (ParVI)\nmethod that accelerates the EVI-Im. Inspired by energy quadratization (EQ) and\noperator splitting techniques for gradient flows, our approach efficiently\ndrives particles towards the target distribution. Unlike EVI-Im, which employs\nthe implicit Euler method to solve variational-preserving particle dynamics for\nminimizing the KL divergence, derived using a \"discretize-then-variational\"\napproach, the proposed algorithm avoids repeated evaluation of inter-particle\ninteraction terms, significantly reducing computational cost. The framework is\nalso extensible to other gradient-based sampling techniques. Through several\nnumerical experiments, we demonstrate that our method outperforms existing\nParVI approaches in efficiency, robustness, and accuracy.", "published": "2025-04-04 04:31:19", "link": "http://arxiv.org/abs/2504.03158v1", "categories": ["stat.ML", "cs.LG", "62G05, 65K10, 65L05"], "primary_category": "stat.ML"}
{"title": "Safe Screening Rules for Group OWL Models", "abstract": "Group Ordered Weighted $L_{1}$-Norm (Group OWL) regularized models have\nemerged as a useful procedure for high-dimensional sparse multi-task learning\nwith correlated features. Proximal gradient methods are used as standard\napproaches to solving Group OWL models. However, Group OWL models usually\nsuffer huge computational costs and memory usage when the feature size is large\nin the high-dimensional scenario. To address this challenge, in this paper, we\nare the first to propose the safe screening rule for Group OWL models by\neffectively tackling the structured non-separable penalty, which can quickly\nidentify the inactive features that have zero coefficients across all the\ntasks. Thus, by removing the inactive features during the training process, we\nmay achieve substantial computational gain and memory savings. More\nimportantly, the proposed screening rule can be directly integrated with the\nexisting solvers both in the batch and stochastic settings. Theoretically, we\nprove our screening rule is safe and also can be safely applied to the existing\niterative optimization algorithms. Our experimental results demonstrate that\nour screening rule can effectively identify the inactive features and leads to\na significant computational speedup without any loss of accuracy.", "published": "2025-04-04 04:07:37", "link": "http://arxiv.org/abs/2504.03152v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "From Observation to Orientation: an Adaptive Integer Programming Approach to Intervention Design", "abstract": "Using both observational and experimental data, a causal discovery process\ncan identify the causal relationships between variables. A unique adaptive\nintervention design paradigm is presented in this work, where causal directed\nacyclic graphs (DAGs) are for effectively recovered with practical budgetary\nconsiderations. In order to choose treatments that optimize information gain\nunder these considerations, an iterative integer programming (IP) approach is\nproposed, which drastically reduces the number of experiments required.\nSimulations over a broad range of graph sizes and edge densities are used to\nassess the effectiveness of the suggested approach. Results show that the\nproposed adaptive IP approach achieves full causal graph recovery with fewer\nintervention iterations and variable manipulations than random intervention\nbaselines, and it is also flexible enough to accommodate a variety of practical\nconstraints.", "published": "2025-04-04 02:35:35", "link": "http://arxiv.org/abs/2504.03122v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A computational transition for detecting multivariate shuffled linear regression by low-degree polynomials", "abstract": "In this paper, we study the problem of multivariate shuffled linear\nregression, where the correspondence between predictors and responses in a\nlinear model is obfuscated by a latent permutation. Specifically, we\ninvestigate the model $Y=\\tfrac{1}{\\sqrt{1+\\sigma^2}}(\\Pi_* X Q_* + \\sigma Z)$,\nwhere $X$ is an $n*d$ standard Gaussian design matrix, $Z$ is an $n*m$ Gaussian\nnoise matrix, $\\Pi_*$ is an unknown $n*n$ permutation matrix, and $Q_*$ is an\nunknown $d*m$ on the Grassmanian manifold satisfying $Q_*^{\\top} Q_* = \\mathbb\nI_m$.\n  Consider the hypothesis testing problem of distinguishing this model from the\ncase where $X$ and $Y$ are independent Gaussian random matrices of sizes $n*d$\nand $n*m$, respectively. Our results reveal a phase transition phenomenon in\nthe performance of low-degree polynomial algorithms for this task. (1) When\n$m=o(d)$, we show that all degree-$D$ polynomials fail to distinguish these two\nmodels even when $\\sigma=0$, provided with $D^4=o\\big( \\tfrac{d}{m} \\big)$. (2)\nWhen $m=d$ and $\\sigma=\\omega(1)$, we show that all degree-$D$ polynomials fail\nto distinguish these two models provided with $D=o(\\sigma)$. (3) When $m=d$ and\n$\\sigma=o(1)$, we show that there exists a constant-degree polynomial that\nstrongly distinguish these two models. These results establish a smooth\ntransition in the effectiveness of low-degree polynomial algorithms for this\nproblem, highlighting the interplay between the dimensions $m$ and $d$, the\nnoise level $\\sigma$, and the computational complexity of the testing task.", "published": "2025-04-04 00:32:38", "link": "http://arxiv.org/abs/2504.03097v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "An Efficient GPU-based Implementation for Noise Robust Sound Source Localization", "abstract": "Robot audition, encompassing Sound Source Localization (SSL), Sound Source\nSeparation (SSS), and Automatic Speech Recognition (ASR), enables robots and\nsmart devices to acquire auditory capabilities similar to human hearing.\nDespite their wide applicability, processing multi-channel audio signals from\nmicrophone arrays in SSL involves computationally intensive matrix operations,\nwhich can hinder efficient deployment on Central Processing Units (CPUs),\nparticularly in embedded systems with limited CPU resources. This paper\nintroduces a GPU-based implementation of SSL for robot audition, utilizing the\nGeneralized Singular Value Decomposition-based Multiple Signal Classification\n(GSVD-MUSIC), a noise-robust algorithm, within the HARK platform, an\nopen-source software suite. For a 60-channel microphone array, the proposed\nimplementation achieves significant performance improvements. On the Jetson AGX\nOrin, an embedded device powered by an NVIDIA GPU and ARM Cortex-A78AE v8.2\n64-bit CPUs, we observe speedups of 4645.1x for GSVD calculations and 8.8x for\nthe SSL module, while speedups of 2223.4x for GSVD calculation and 8.95x for\nthe entire SSL module on a server configured with an NVIDIA A100 GPU and AMD\nEPYC 7352 CPUs, making real-time processing feasible for large-scale microphone\narrays and providing ample capacity for real-time processing of potential\nsubsequent machine learning or deep learning tasks.", "published": "2025-04-04 11:44:24", "link": "http://arxiv.org/abs/2504.03373v1", "categories": ["cs.SD", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Harnessing FFT for Rapid Community Travel Distance and Step Estimation in Children with DMD", "abstract": "Accurate estimation of gait characteristics, including step length, step\nvelocity, and travel distance, is critical for assessing mobility in toddlers,\nchildren and teens with Duchenne muscular dystrophy (DMD) and typically\ndeveloping (TD) peers. This study introduces a novel method leveraging Fast\nFourier Transform (FFT)-derived step frequency from a single waist-worn\nconsumer-grade accelerometer to predict gait parameters efficiently. The\nproposed FFT-based step frequency detection approach, combined with\nregression-derived stride length estimation, enables precise measurement of\ntemporospatial gait features across various walking and running speeds. Our\nmodel, developed from a diverse cohort of children aged 3-16, demonstrated high\naccuracy in step length estimation (R^2=0.92, RMSE = 0.06) using only step\nfrequency and height as inputs. Comparative analysis with ground-truth\nobservations and AI-driven Walk4Me models validated the FFT-based method,\nshowing strong agreement across step count, step frequency, step length, step\nvelocity, and travel distance metrics. The results highlight the feasibility of\nusing widely available mobile devices for gait assessment in real-world\nsettings, offering a scalable solution for monitoring disease progression and\nmobility changes in individuals with DMD. Future work will focus on refining\nmodel performance and expanding applicability to additional movement disorders.", "published": "2025-04-04 22:57:48", "link": "http://arxiv.org/abs/2504.03986v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimized Feature Selection and Neural Network-Based Classification of Motor Imagery Using EEG Signals", "abstract": "Objective: Machine learning- and deep learning-based models have recently\nbeen employed in motor imagery intention classification from\nelectroencephalogram (EEG) signals. Nevertheless, there is a limited\nunderstanding of feature selection to assist in identifying the most\nsignificant features in different spatial locations. Methods: This study\nproposes a feature selection technique using sequential forward feature\nselection with support vector machines and feeding the selected features to\ndeep neural networks to classify motor imagery intention using multi-channel\nEEG. Results: The proposed model was evaluated with a publicly available\ndataset and achieved an average accuracy of 79.70 percent with a standard\ndeviation of 7.98 percent for classifying two motor imagery scenarios.\nConclusions: These results demonstrate that our method effectively identifies\nthe most informative and discriminative characteristics of neural activity at\ndifferent spatial locations, offering potential for future prosthetics and\nbrain-computer interface applications. Significance: This approach enhances\nmodel performance while identifying key spatial EEG features, advancing\nbrain-computer interfaces and prosthetic systems.", "published": "2025-04-04 22:55:43", "link": "http://arxiv.org/abs/2504.03984v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Meta-Learning Driven Movable-Antenna-assisted Full-Duplex RSMA for Multi-User Communication: Performance and Optimization", "abstract": "Full-duplex (FD) radios at base station (BS) have gained significant interest\nbecause of their ability to simultaneously transmit and receive signals on the\nsame frequency band. However, FD communication is hindered by self-interference\n(SI) and intra-cell interference caused by simultaneous uplink (UL)\ntransmissions affecting downlink (DL) reception. These interferences\nsignificantly limit the ability to fully exploit FD's potential. Recently,\nmovable antenna (MA) technology has emerged as a groundbreaking innovation,\noffering an effective way to mitigate interference by adjusting the position of\neach MA within the transmitter or receiver region. This dynamic repositioning\nallows MAs to move away from high-interference zones to areas with minimal\ninterference, thereby enhancing multiplexing gain and improving spectral\nefficiency (SE). In light of this, in this paper, we investigate an FD\ncommunication system by integrating it with MAs to evaluate and investigate its\neffectiveness in handling SI and intra-cell interference. Moreover, we utilize\nrate-splitting multiple access (RSMA) as our multiple access technique in both\nUL and DL transmission. To achieve the full potential of the system, we\nevaluated three different scenarios with FD-BS-RSMA with MAs where our goal is\nto maximize the total sum rate of the system by jointly optimizing the\ntransmitting and receiving beamforming vectors, UL user equipment (UE)\ntransmission power, MA positions, and common stream split ratio of RSMA while\nsatisfying the minimum data rate requirements of all UEs, common stream\nconstraint, power budget requirements of BS and UL UEs, and inter-MA distance.\nThe formulated optimization problem is highly non-convex in nature, and hence,\nwe propose a gradient-based meta-learning (GML) approach which can handle the\nnon-convexity in a discrete manner by optimizing each variable in a different\nneural network.", "published": "2025-04-04 22:54:05", "link": "http://arxiv.org/abs/2504.03982v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "FMCW Radar Interference Mitigation based on the Fractional Fourier Transform", "abstract": "In this paper, we propose a novel method for frequency modulated continuous\nwave (FMCW) radar mutual interference mitigation based on the discrete\nfractional Fourier transform (DFrFT). Interference chirps are detected and\nmitigated by compression and zeroing in the fractional domain. We provide an\nefficient implementation that can deal with multiple interferers, where we\nperform consecutive DFrFTs utilizing its angle-additivity property. For that\npurpose, we generalize and reduce the computational complexity of the\nmulti-angle centered discrete fractional Fourier transform [1]. Our algorithm\nis designed to be simple and fast such that it can be implemented in hardware.\nWe evaluate our algorithm on a synthetic I/Q-modulated dataset and outperform\nreference methods in terms of the mean squared error,\nsignal-to-interference-plus-noise ratio, error vector magnitude, true positive\nrate, false alarm rate and F1-score.", "published": "2025-04-04 22:10:46", "link": "http://arxiv.org/abs/2504.03963v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Symbol Error Probability-based Beamforming in MIMO Gaussian Wiretap Channels", "abstract": "This paper investigates beamforming schemes designed to minimize the symbol\nerror probability (SEP) for an authorized user while guaranteeing that the\nlikelihood of an eavesdropper correctly recovering symbols remains below a\npredefined threshold. Unlike previous works that focus on maximizing secrecy\ncapacity, our work is centered around finding an optimal beamforming vector for\nbinary antipodal signal detection in multiple-input multiple-output (MIMO)\nGaussian wiretap channels. Finding the optimal beamforming vector in this\nsetting is challenging. Computationally efficient algorithms such as convex\ntechniques cannot be applied to find the optimal solution. To that end, our\nproposed algorithm relies on Karush-Kuhn-Tucker (KKT) conditions and a\ngeneralized eigen-decomposition method to find the exact solution. In addition,\nwe also develop an approximate, practical algorithm to find a good beamforming\nmatrix when using M-ary detection schemes. Numerical results are presented to\nassess the performance of the proposed methods across various scenarios.", "published": "2025-04-04 21:59:28", "link": "http://arxiv.org/abs/2504.03960v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Recent Advances in Real-Time Models for UWB Transmission Systems", "abstract": "Ultrafast accurate physical layer models are essential for designing,\noptimizing and managing ultrawideband optical transmission systems. We present\na closed-form GN/EGN model based on a recent analytical breakthrough, improving\nreliability, accuracy and generality.", "published": "2025-04-04 18:58:25", "link": "http://arxiv.org/abs/2504.03873v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reciprocity-Aware Convolutional Neural Networks for Map-Based Path Loss Prediction", "abstract": "Path loss modeling is a widely used technique for estimating point-to-point\nlosses along a communications link from transmitter (Tx) to receiver (Rx).\nAccurate path loss predictions can optimize use of the radio frequency spectrum\nand minimize unwanted interference. Modern path loss modeling often leverages\ndata-driven approaches, using machine learning to train models on drive test\nmeasurement datasets. Drive tests primarily represent downlink scenarios, where\nthe Tx is located on a building and the Rx is located on a moving vehicle.\nConsequently, trained models are frequently reserved for downlink coverage\nestimation, lacking representation of uplink scenarios. In this paper, we\ndemonstrate that data augmentation can be used to train a path loss model that\nis generalized to uplink, downlink, and backhaul scenarios, training using only\ndownlink drive test measurements. By adding a small number of synthetic samples\nrepresenting uplink scenarios to the training set, root mean squared error is\nreduced by >8 dB on uplink examples in the test set.", "published": "2025-04-04 17:44:14", "link": "http://arxiv.org/abs/2504.03625v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "A New Statistical Approach to Calibration-Free Localization Using Unlabeled Crowdsourced Data", "abstract": "Fingerprinting-based indoor localization methods typically require\nlabor-intensive site surveys to collect signal measurements at known reference\nlocations and frequent recalibration, which limits their scalability. This\npaper addresses these challenges by presenting a novel approach for indoor\nlocalization that utilizes crowdsourced data {\\em without location labels}. We\nleverage the statistical information of crowdsourced data and propose a\ncumulative distribution function (CDF) based distance estimation method that\nmaps received signal strength (RSS) to distances from access points. This\napproach overcomes the limitations of conventional distance estimation based on\nthe empirical path loss model by efficiently capturing the impacts of shadow\nfading and multipath. Compared to fingerprinting, our {\\em unsupervised}\nstatistical approach eliminates the need for signal measurements at known\nreference locations. The estimated distances are then integrated into a\nthree-step framework to determine the target location. The localization\nperformance of our proposed method is evaluated using RSS data generated from\nray-tracing simulations. Our results demonstrate significant improvements in\nlocalization accuracy compared to methods based on the empirical path loss\nmodel. Furthermore, our statistical approach, which relies on unlabeled data,\nachieves localization accuracy comparable to that of the {\\em supervised}\napproach, the $k$-Nearest Neighbor ($k$NN) algorithm, which requires\nfingerprints with location labels. For reproducibility and future research, we\nmake the ray-tracing dataset publicly available at [2].", "published": "2025-04-04 17:37:30", "link": "http://arxiv.org/abs/2504.03619v1", "categories": ["eess.SP", "stat.AP"], "primary_category": "eess.SP"}
{"title": "Scalable Hypergraph Structure Learning with Diverse Smoothness Priors", "abstract": "In graph signal processing, learning the weighted connections between nodes\nfrom a set of sample signals is a fundamental task when the underlying\nrelationships are not known a priori. This task is typically addressed by\nfinding a graph Laplacian on which the observed signals are smooth. With the\nextension of graphs to hypergraphs - where edges can connect more than two\nnodes - graph learning methods have similarly been generalized to hypergraphs.\nHowever, the absence of a unified framework for calculating total variation has\nled to divergent definitions of smoothness and, consequently, differing\napproaches to hyperedge recovery. We confront this challenge through\ngeneralization of several previously proposed hypergraph total variations,\nsubsequently allowing ease of substitution into a vector based optimization. To\nthis end, we propose a novel hypergraph learning method that recovers a\nhypergraph topology from time-series signals based on a smoothness prior. Our\napproach addresses key limitations in prior works, such as hyperedge selection\nand convergence issues, by formulating the problem as a convex optimization\nsolved via a forward-backward-forward algorithm, ensuring guaranteed\nconvergence. Additionally, we introduce a process that simultaneously limits\nthe span of the hyperedge search and maintains a valid hyperedge selection set.\nIn doing so, our method becomes scalable in increasingly complex network\nstructures. The experimental results demonstrate improved performance, in terms\nof accuracy, over other state-of-the-art hypergraph inference methods;\nfurthermore, we empirically show our method to be robust to total variation\nterms, biased towards global smoothness, and scalable to larger hypergraphs.", "published": "2025-04-04 16:47:30", "link": "http://arxiv.org/abs/2504.03583v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Early detection of diabetes through transfer learning-based eye (vision) screening and improvement of machine learning model performance and advanced parameter setting algorithms", "abstract": "Diabetic Retinopathy (DR) is a serious and common complication of diabetes,\ncaused by prolonged high blood sugar levels that damage the small retinal blood\nvessels. If left untreated, DR can progress to retinal vein occlusion and\nstimulate abnormal blood vessel growth, significantly increasing the risk of\nblindness. Traditional diabetes diagnosis methods often utilize convolutional\nneural networks (CNNs) to extract visual features from retinal images, followed\nby classification algorithms such as decision trees and k-nearest neighbors\n(KNN) for disease detection. However, these approaches face several challenges,\nincluding low accuracy and sensitivity, lengthy machine learning (ML) model\ntraining due to high data complexity and volume, and the use of limited\ndatasets for testing and evaluation. This study investigates the application of\ntransfer learning (TL) to enhance ML model performance in DR detection. Key\nimprovements include dimensionality reduction, optimized learning rate\nadjustments, and advanced parameter tuning algorithms, aimed at increasing\nefficiency and diagnostic accuracy. The proposed model achieved an overall\naccuracy of 84% on the testing dataset, outperforming prior studies. The\nhighest class-specific accuracy reached 89%, with a maximum sensitivity of 97%\nand an F1-score of 92%, demonstrating strong performance in identifying DR\ncases. These findings suggest that TL-based DR screening is a promising\napproach for early diagnosis, enabling timely interventions to prevent vision\nloss and improve patient outcomes.", "published": "2025-04-04 13:30:21", "link": "http://arxiv.org/abs/2504.03439v1", "categories": ["eess.IV", "cs.CV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Fair and Energy-Efficient Activation Control Mechanisms for Repeater-Assisted Massive MIMO", "abstract": "Massive multiple-input multiple-output (mMIMO) has been the core of 5G due to\nits ability to improve spectral efficiency and spatial multiplexing\nsignificantly; however, cell-edge users still experience performance\ndegradation due to inter-cell interference and uneven signal distribution.\nWhile cell-free mMIMO (cfmMIMO) addresses this issue by providing uniform\ncoverage through distributed antennas, it requires significantly more\ndeployment cost due to the fronthaul and tight synchronization requirements.\nAlternatively, repeater-assisted massive MIMO (RA-MIMO) has recently been\nproposed to extend the coverage of cellular mMIMO by densely deploying low-cost\nsingle-antenna repeaters capable of amplifying and forwarding signals. In this\nwork, we investigate amplification control for the repeaters for two different\ngoals: (i) providing a fair performance among users, and (ii) reducing the\nextra energy consumption by the deployed repeaters. We propose a max-min\namplification control algorithm using the convex-concave procedure for fairness\nand a joint sleep mode and amplification control algorithm for energy\nefficiency, comparing long- and short-term strategies. Numerical results show\nthat RA-MIMO, with maximum amplification, improves\nsignal-to-interference-plus-noise ratio (SINR) by over 20 dB compared to mMIMO\nand performs within 1 dB of cfmMIMO when deploying the same number of repeaters\nas access points in cfmMIMO. Additionally, our majority-rule-based long-term\nsleep mechanism reduces repeater power consumption by 70% while maintaining\nless than 1% spectral efficiency outage.", "published": "2025-04-04 13:18:39", "link": "http://arxiv.org/abs/2504.03428v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Space-Time Encoded Modulation for High-Fidelity Diffuse Optical Imaging", "abstract": "Diffuse optical imaging (DOI) offers valuable insights into scattering\nmediums, but the quest for high-resolution imaging often requires dense\nsampling strategies, leading to higher imaging errors and lengthy acquisition\ntimes. This work introduces Space-Time Encoded Modulation (STEM), a novel light\nmodulation scheme enabling low-noise, high-resolution imaging with single-pixel\ndetectors. In STEM, a laser illuminates the sample, and the transmitted light\nis detected using a single pixel detector. The detected image is partitioned\ninto a two-dimensional array of sub-images, each encoded with a unique\nquasi-orthogonal code. These coded sub-images represent light transmission at\nspecific locations along the sample boundary. A single-pixel detector then\nmeasures their combined transmission. By virtue of their quasi-orthogonality,\nthe relative strength of each sub-image can be measured, enabling image\nformation. In this paper, we present a comprehensive mathematical description\nand experimental validation of the STEM method. Compared to traditional raster\nscanning, STEM significantly enhances imaging quality, reducing imaging errors\nby up to 60% and yielding a 3.5-fold increase in reconstruction contrast.", "published": "2025-04-04 07:55:05", "link": "http://arxiv.org/abs/2504.03246v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Mitigating the Impact of Electrode Shift on Classification Performance in Electromyography-Based Motion Prediction Using Sliding-Window Normalization", "abstract": "Electromyography (EMG) signals are used in many applications, including\nprosthetic hands, assistive suits, and rehabilitation. Recent advances in\nmotion estimation have improved performance, yet challenges remain in\ncross-subject generalization, electrode shift, and daily variations. When\nelectrode shift occurs, both transfer learning and adversarial domain\nadaptation improve classification performance by reducing the performance gap\nto -1\\% (eight-class scenario). However, additional data are needed for\nre-training in transfer learning or for training in adversarial domain\nadaptation. To address this issue, we investigated a sliding-window\nnormalization (SWN) technique in a real-time prediction scenario. This method\ncombines z-score normalization with a sliding-window approach to reduce the\ndecline in classification performance caused by electrode shift. We validated\nthe effectiveness of SWN using experimental data from a target trajectory\ntracking task involving the right arm. For three motions classification (rest,\nflexion, and extension of the elbow) obtained from EMG signals, our offline\nanalysis showed that SWN reduced the differential classification accuracy to\n-1.0\\%, representing a 6.6\\% improvement compared to the case without\nnormalization (-7.6\\%). Furthermore, when SWN was combined with a strategy that\nuses a mixture of multiple electrode positions, classification accuracy\nimproved by an additional 2.4\\% over the baseline. These results suggest that\nSWN can effectively reduce the performance degradation caused by electrode\nshift, thereby enhancing the practicality of EMG-based motion estimation\nsystems.", "published": "2025-04-04 05:57:02", "link": "http://arxiv.org/abs/2504.03196v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Single-Satellite Navigation on Lunar North Pole", "abstract": "The Moon is a primary focus of space exploration. Current navigation methods\nface significant limitations in providing precise location data for lunar\nmissions. In particular, existing methods often require direct Line of Sight to\nEarth, have limited capacity, and suffer from long signal travel times. This\npaper aims to tackle these challenges through a novel single satellite\nnavigation system at the lunar North Pole. By utilising the Doppler effect,\nthis system facilitates 3D geolocation of a stationary receiver on the lunar\nsurface. Key findings include choosing a Low Lunar Orbit (LLO) suitable for\nNorth Pole coverage, designing a 3-step geolocation algorithm tailored to lunar\nconditions, constructing a comprehensive error budget, and evaluating the\nsystem performance through Dilution of Position (DOP).", "published": "2025-04-04 00:01:51", "link": "http://arxiv.org/abs/2504.03091v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Improving Mixed-Criticality Scheduling with Reinforcement Learning", "abstract": "This paper introduces a novel reinforcement learning (RL) approach to\nscheduling mixed-criticality (MC) systems on processors with varying speeds.\nBuilding upon the foundation laid by [1], we extend their work to address the\nnon-preemptive scheduling problem, which is known to be NP-hard. By modeling\nthis scheduling challenge as a Markov Decision Process (MDP), we develop an RL\nagent capable of generating near-optimal schedules for real-time MC systems.\nOur RL-based scheduler prioritizes high-critical tasks while maintaining\noverall system performance.\n  Through extensive experiments, we demonstrate the scalability and\neffectiveness of our approach. The RL scheduler significantly improves task\ncompletion rates, achieving around 80% overall and 85% for high-criticality\ntasks across 100,000 instances of synthetic data and real data under varying\nsystem conditions. Moreover, under stable conditions without degradation, the\nscheduler achieves 94% overall task completion and 93% for high-criticality\ntasks. These results highlight the potential of RL-based schedulers in\nreal-time and safety-critical applications, offering substantial improvements\nin handling complex and dynamic scheduling scenarios.", "published": "2025-04-04 23:28:48", "link": "http://arxiv.org/abs/2504.03994v2", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Drawing a Map of Elections", "abstract": "Our main contribution is the introduction of the map of elections framework.\nA map of elections consists of three main elements: (1) a dataset of elections\n(i.e., collections of ordinal votes over given sets of candidates), (2) a way\nof measuring similarities between these elections, and (3) a representation of\nthe elections in the 2D Euclidean space as points, so that the more similar two\nelections are, the closer are their points. In our maps, we mostly focus on\ndatasets of synthetic elections, but we also show an example of a map over\nreal-life ones. To measure similarities, we would have preferred to use, e.g.,\nthe isomorphic swap distance, but this is infeasible due to its high\ncomputational complexity. Hence, we propose polynomial-time computable\npositionwise distance and use it instead. Regarding the representations in 2D\nEuclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two\nalternatives. We develop the necessary theoretical results to form our maps and\nargue experimentally that they are accurate and credible. Further, we show how\ncoloring the elections in a map according to various criteria helps in\nanalyzing results of a number of experiments. In particular, we show colorings\naccording to the scores of winning candidates or committees, running times of\nILP-based winner determination algorithms, and approximation ratios achieved by\nparticular algorithms.", "published": "2025-04-04 11:44:56", "link": "http://arxiv.org/abs/2504.03809v2", "categories": ["cs.MA", "cs.AI", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Safe Screening Rules for Group OWL Models", "abstract": "Group Ordered Weighted $L_{1}$-Norm (Group OWL) regularized models have\nemerged as a useful procedure for high-dimensional sparse multi-task learning\nwith correlated features. Proximal gradient methods are used as standard\napproaches to solving Group OWL models. However, Group OWL models usually\nsuffer huge computational costs and memory usage when the feature size is large\nin the high-dimensional scenario. To address this challenge, in this paper, we\nare the first to propose the safe screening rule for Group OWL models by\neffectively tackling the structured non-separable penalty, which can quickly\nidentify the inactive features that have zero coefficients across all the\ntasks. Thus, by removing the inactive features during the training process, we\nmay achieve substantial computational gain and memory savings. More\nimportantly, the proposed screening rule can be directly integrated with the\nexisting solvers both in the batch and stochastic settings. Theoretically, we\nprove our screening rule is safe and also can be safely applied to the existing\niterative optimization algorithms. Our experimental results demonstrate that\nour screening rule can effectively identify the inactive features and leads to\na significant computational speedup without any loss of accuracy.", "published": "2025-04-04 04:07:37", "link": "http://arxiv.org/abs/2504.03152v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models", "abstract": "We introduce VideoComp, a benchmark and learning framework for advancing\nvideo-text compositionality understanding, aimed at improving vision-language\nmodels (VLMs) in fine-grained temporal alignment. Unlike existing benchmarks\nfocused on static image-text compositionality or isolated single-event videos,\nour benchmark targets alignment in continuous multi-event videos. Leveraging\nvideo-text datasets with temporally localized event captions (e.g.\nActivityNet-Captions, YouCook2), we construct two compositional benchmarks,\nActivityNet-Comp and YouCook2-Comp. We create challenging negative samples with\nsubtle temporal disruptions such as reordering, action word replacement,\npartial captioning, and combined disruptions. These benchmarks comprehensively\ntest models' compositional sensitivity across extended, cohesive video-text\nsequences. To improve model performance, we propose a hierarchical pairwise\npreference loss that strengthens alignment with temporally accurate pairs and\ngradually penalizes increasingly disrupted ones, encouraging fine-grained\ncompositional learning. To mitigate the limited availability of densely\nannotated video data, we introduce a pretraining strategy that concatenates\nshort video-caption pairs to simulate multi-event sequences. We evaluate\nvideo-text foundational models and large multimodal models (LMMs) on our\nbenchmark, identifying both strengths and areas for improvement in\ncompositionality. Overall, our work provides a comprehensive framework for\nevaluating and enhancing model capabilities in achieving fine-grained,\ntemporally coherent video-text alignment.", "published": "2025-04-04 22:24:30", "link": "http://arxiv.org/abs/2504.03970v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "From Observation to Orientation: an Adaptive Integer Programming Approach to Intervention Design", "abstract": "Using both observational and experimental data, a causal discovery process\ncan identify the causal relationships between variables. A unique adaptive\nintervention design paradigm is presented in this work, where causal directed\nacyclic graphs (DAGs) are for effectively recovered with practical budgetary\nconsiderations. In order to choose treatments that optimize information gain\nunder these considerations, an iterative integer programming (IP) approach is\nproposed, which drastically reduces the number of experiments required.\nSimulations over a broad range of graph sizes and edge densities are used to\nassess the effectiveness of the suggested approach. Results show that the\nproposed adaptive IP approach achieves full causal graph recovery with fewer\nintervention iterations and variable manipulations than random intervention\nbaselines, and it is also flexible enough to accommodate a variety of practical\nconstraints.", "published": "2025-04-04 02:35:35", "link": "http://arxiv.org/abs/2504.03122v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mathematical Modeling of Option Pricing with an Extended Black-Scholes Framework", "abstract": "This study investigates enhancing option pricing by extending the\nBlack-Scholes model to include stochastic volatility and interest rate\nvariability within the Partial Differential Equation (PDE). The PDE is solved\nusing the finite difference method. The extended Black-Scholes model and a\nmachine learning-based LSTM model are developed and evaluated for pricing\nGoogle stock options. Both models were backtested using historical market data.\nWhile the LSTM model exhibited higher predictive accuracy, the finite\ndifference method demonstrated superior computational efficiency. This work\nprovides insights into model performance under varying market conditions and\nemphasizes the potential of hybrid approaches for robust financial modeling.", "published": "2025-04-04 05:06:55", "link": "http://arxiv.org/abs/2504.03175v2", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR", "q-fin.CP", "60G07", "G.1.0; G.1.8; G.1.7; G.3; I.2.0"], "primary_category": "math.NA"}
