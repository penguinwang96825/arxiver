{"title": "Thematic context vector association based on event uncertainty for\n  Twitter", "abstract": "Keyword extraction is a crucial process in text mining. The extraction of\nkeywords with respective contextual events in Twitter data is a big challenge.\nThe challenging issues are mainly because of the informality in the language\nused. The use of misspelled words, acronyms, and ambiguous terms causes\ninformality. The extraction of keywords with informal language in current\nsystems is pattern based or event based. In this paper, contextual keywords are\nextracted using thematic events with the help of data association. The thematic\ncontext for events is identified using the uncertainty principle in the\nproposed system. The thematic contexts are weighed with the help of vectors\ncalled thematic context vectors which signifies the event as certain or\nuncertain. The system is tested on the Twitter COVID-19 dataset and proves to\nbe effective. The system extracts event-specific thematic context vectors from\nthe test dataset and ranks them. The extracted thematic context vectors are\nused for the clustering of contextual thematic vectors which improves the\nsilhouette coefficient by 0.5% than state of art methods namely TF and TF-IDF.\nThe thematic context vector can be used in other applications like\nCyberbullying, sarcasm detection, figurative language detection, etc.", "published": "2023-04-04 00:13:47", "link": "http://arxiv.org/abs/2304.01423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polarity based Sarcasm Detection using Semigraph", "abstract": "Sarcasm is an advanced linguistic expression often found on various online\nplatforms. Sarcasm detection is challenging in natural language processing\ntasks that affect sentiment analysis. This article presents the inventive\nmethod of the semigraph, including semigraph construction and sarcasm detection\nprocesses. A variation of the semigraph is suggested in the pattern-relatedness\nof the text document. The proposed method is to obtain the sarcastic and\nnon-sarcastic polarity scores of a document using a semigraph. The sarcastic\npolarity score represents the possibility that a document will become\nsarcastic. Sarcasm is detected based on the polarity scoring model. The\nperformance of the proposed model enhances the existing prior art approach to\nsarcasm detection. In the Amazon product review, the model achieved the\naccuracy, recall, and f-measure of 0.87, 0.79, and 0.83, respectively.", "published": "2023-04-04 00:13:55", "link": "http://arxiv.org/abs/2304.01424v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Vector Grounding Problem", "abstract": "The remarkable performance of large language models (LLMs) on complex\nlinguistic tasks has sparked a lively debate on the nature of their\ncapabilities. Unlike humans, these models learn language exclusively from\ntextual data, without direct interaction with the real world. Nevertheless,\nthey can generate seemingly meaningful text about a wide range of topics. This\nimpressive accomplishment has rekindled interest in the classical 'Symbol\nGrounding Problem,' which questioned whether the internal representations and\noutputs of classical symbolic AI systems could possess intrinsic meaning.\nUnlike these systems, modern LLMs are artificial neural networks that compute\nover vectors rather than symbols. However, an analogous problem arises for such\nsystems, which we dub the Vector Grounding Problem. This paper has two primary\nobjectives. First, we differentiate various ways in which internal\nrepresentations can be grounded in biological or artificial systems,\nidentifying five distinct notions discussed in the literature: referential,\nsensorimotor, relational, communicative, and epistemic grounding.\nUnfortunately, these notions of grounding are often conflated. We clarify the\ndifferences between them, and argue that referential grounding is the one that\nlies at the heart of the Vector Grounding Problem. Second, drawing on theories\nof representational content in philosophy and cognitive science, we propose\nthat certain LLMs, particularly those fine-tuned with Reinforcement Learning\nfrom Human Feedback (RLHF), possess the necessary features to overcome the\nVector Grounding Problem, as they stand in the requisite causal-historical\nrelations to the world that underpin intrinsic meaning. We also argue that,\nperhaps unexpectedly, multimodality and embodiment are neither necessary nor\nsufficient conditions for referential grounding in artificial systems.", "published": "2023-04-04 02:54:04", "link": "http://arxiv.org/abs/2304.01481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Contrastive Transfer Framework with Propagation Structure for\n  Boosting Low-Resource Rumor Detection", "abstract": "The truth is significantly hampered by massive rumors that spread along with\nbreaking news or popular topics. Since there is sufficient corpus gathered from\nthe same domain for model training, existing rumor detection algorithms show\npromising performance on yesterday's news. However, due to a lack of\nsubstantial training data and prior expert knowledge, they are poor at spotting\nrumors concerning unforeseen events, especially those propagated in different\nlanguages (i.e., low-resource regimes). In this paper, we propose a unified\ncontrastive transfer framework to detect rumors by adapting the features\nlearned from well-resourced rumor data to that of the low-resourced with only\nfew-shot annotations. More specifically, we first represent rumor circulated on\nsocial media as an undirected topology for enhancing the interaction of user\nopinions, and then train a Multi-scale Graph Convolutional Network via a\nunified contrastive paradigm to mine effective clues simultaneously from post\nsemantics and propagation structure. Our model explicitly breaks the barriers\nof the domain and/or language issues, via language alignment and a novel\ndomain-adaptive contrastive learning mechanism. To well-generalize the\nrepresentation learning using a small set of annotated target events, we reveal\nthat rumor-indicative signal is closely correlated with the uniformity of the\ndistribution of these events. We design a target-wise contrastive training\nmechanism with three event-level data augmentation strategies, capable of\nunifying the representations by distinguishing target events. Extensive\nexperiments conducted on four low-resource datasets collected from real-world\nmicroblog platforms demonstrate that our framework achieves much better\nperformance than state-of-the-art methods and exhibits a superior capacity for\ndetecting rumors at early stages.", "published": "2023-04-04 03:13:03", "link": "http://arxiv.org/abs/2304.01492v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attribute-Consistent Knowledge Graph Representation Learning for\n  Multi-Modal Entity Alignment", "abstract": "The multi-modal entity alignment (MMEA) aims to find all equivalent entity\npairs between multi-modal knowledge graphs (MMKGs). Rich attributes and\nneighboring entities are valuable for the alignment task, but existing works\nignore contextual gap problems that the aligned entities have different numbers\nof attributes on specific modality when learning entity representations. In\nthis paper, we propose a novel attribute-consistent knowledge graph\nrepresentation learning framework for MMEA (ACK-MMEA) to compensate the\ncontextual gaps through incorporating consistent alignment knowledge.\nAttribute-consistent KGs (ACKGs) are first constructed via multi-modal\nattribute uniformization with merge and generate operators so that each entity\nhas one and only one uniform feature in each modality. The ACKGs are then fed\ninto a relation-aware graph neural network with random dropouts, to obtain\naggregated relation representations and robust entity representations. In order\nto evaluate the ACK-MMEA facilitated for entity alignment, we specially design\na joint alignment loss for both entity and attribute evaluation. Extensive\nexperiments conducted on two benchmark datasets show that our approach achieves\nexcellent performance compared to its competitors.", "published": "2023-04-04 06:39:36", "link": "http://arxiv.org/abs/2304.01563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Improvement of Factual Knowledge in Language Models", "abstract": "Masked language modeling (MLM) plays a key role in pretraining large language\nmodels. But the MLM objective is often dominated by high-frequency words that\nare sub-optimal for learning factual knowledge. In this work, we propose an\napproach for influencing MLM pretraining in a way that can improve language\nmodel performance on a variety of knowledge-intensive tasks. We force the\nlanguage model to prioritize informative words in a fully unsupervised way.\nExperiments demonstrate that the proposed approach can significantly improve\nthe performance of pretrained language models on tasks such as factual recall,\nquestion answering, sentiment analysis, and natural language inference in a\nclosed-book setting.", "published": "2023-04-04 07:37:06", "link": "http://arxiv.org/abs/2304.01597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EDeR: A Dataset for Exploring Dependency Relations Between Events", "abstract": "Relation extraction is a central task in natural language processing (NLP)\nand information retrieval (IR) research. We argue that an important type of\nrelation not explored in NLP or IR research to date is that of an event being\nan argument - required or optional - of another event. We introduce the\nhuman-annotated Event Dependency Relation dataset (EDeR) which provides this\ndependency relation. The annotation is done on a sample of documents from the\nOntoNotes dataset, which has the added benefit that it integrates with\nexisting, orthogonal, annotations of this dataset. We investigate baseline\napproaches for predicting the event dependency relation, the best of which\nachieves an accuracy of 82.61 for binary argument/non-argument classification.\nWe show that recognizing this relation leads to more accurate event extraction\n(semantic role labelling) and can improve downstream tasks that depend on this,\nsuch as co-reference resolution. Furthermore, we demonstrate that predicting\nthe three-way classification into the required argument, optional argument or\nnon-argument is a more challenging task.", "published": "2023-04-04 08:07:07", "link": "http://arxiv.org/abs/2304.01612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimCSum: Joint Learning of Simplification and Cross-lingual\n  Summarization for Cross-lingual Science Journalism", "abstract": "Cross-lingual science journalism generates popular science stories of\nscientific articles different from the source language for a non-expert\naudience. Hence, a cross-lingual popular summary must contain the salient\ncontent of the input document, and the content should be coherent,\ncomprehensible, and in a local language for the targeted audience. We improve\nthese aspects of cross-lingual summary generation by joint training of two\nhigh-level NLP tasks, simplification and cross-lingual summarization. The\nformer task reduces linguistic complexity, and the latter focuses on\ncross-lingual abstractive summarization. We propose a novel multi-task\narchitecture - SimCSum consisting of one shared encoder and two parallel\ndecoders jointly learning simplification and cross-lingual summarization. We\nempirically investigate the performance of SimCSum by comparing it with several\nstrong baselines over several evaluation metrics and by human evaluation.\nOverall, SimCSum demonstrates statistically significant improvements over the\nstate-of-the-art on two non-synthetic cross-lingual scientific datasets.\nFurthermore, we conduct an in-depth investigation into the linguistic\nproperties of generated summaries and an error analysis.", "published": "2023-04-04 08:24:22", "link": "http://arxiv.org/abs/2304.01621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An interpretability framework for Similar case matching", "abstract": "Similar Case Matching (SCM) plays a pivotal role in the legal system by\nfacilitating the efficient identification of similar cases for legal\nprofessionals. While previous research has primarily concentrated on enhancing\nthe performance of SCM models, the aspect of interpretability has been\nneglected. To bridge the gap, this study proposes an integrated pipeline\nframework for interpretable SCM. The framework comprises four modules: judicial\nfeature sentence identification, case matching, feature sentence alignment, and\nconflict resolution. In contrast to current SCM methods, our framework first\nextracts feature sentences within a legal case that contain essential\ninformation. Then it conducts case matching based on these extracted features.\nSubsequently, our framework aligns the corresponding sentences in two legal\ncases to provide evidence of similarity. In instances where the results of case\nmatching and feature sentence alignment exhibit conflicts, the conflict\nresolution module resolves these inconsistencies. The experimental results show\nthe effectiveness of our proposed framework, establishing a new benchmark for\ninterpretable SCM.", "published": "2023-04-04 08:25:12", "link": "http://arxiv.org/abs/2304.01622v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mastering Symbolic Operations: Augmenting Language Models with Compiled\n  Neural Networks", "abstract": "Language models' (LMs) proficiency in handling deterministic symbolic\nreasoning and rule-based tasks remains limited due to their dependency implicit\nlearning on textual data. To endow LMs with genuine rule comprehension\nabilities, we propose \"Neural Comprehension\" - a framework that synergistically\nintegrates compiled neural networks (CoNNs) into the standard transformer\narchitecture. CoNNs are neural modules designed to explicitly encode rules\nthrough artificially generated attention weights. By incorporating CoNN\nmodules, the Neural Comprehension framework enables LMs to accurately and\nrobustly execute rule-intensive symbolic tasks. Extensive experiments\ndemonstrate the superiority of our approach over existing techniques in terms\nof length generalization, efficiency, and interpretability for symbolic\noperations. Furthermore, it can be applied to LMs across different model\nscales, outperforming tool-calling methods in arithmetic reasoning tasks while\nmaintaining superior inference efficiency. Our work highlights the potential of\nseamlessly unifying explicit rule learning via CoNNs and implicit pattern\nlearning in LMs, paving the way for true symbolic comprehension capabilities.", "published": "2023-04-04 09:50:07", "link": "http://arxiv.org/abs/2304.01665v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Contextualised Semantic Shift Detection", "abstract": "Semantic Shift Detection (SSD) is the task of identifying, interpreting, and\nassessing the possible change over time in the meanings of a target word.\nTraditionally, SSD has been addressed by linguists and social scientists\nthrough manual and time-consuming activities. In the recent years,\ncomputational approaches based on Natural Language Processing and word\nembeddings gained increasing attention to automate SSD as much as possible. In\nparticular, over the past three years, significant advancements have been made\nalmost exclusively based on word contextualised embedding models, which can\nhandle the multiple usages/meanings of the words and better capture the related\nsemantic shifts. In this paper, we survey the approaches based on\ncontextualised embeddings for SSD (i.e., CSSDetection) and we propose a\nclassification framework characterised by meaning representation,\ntime-awareness, and learning modality dimensions. The framework is exploited i)\nto review the measures for shift assessment, ii) to compare the approaches on\nperformance, and iii) to discuss the current issues in terms of scalability,\ninterpretability, and robustness. Open challenges and future research\ndirections about CSSDetection are finally outlined.", "published": "2023-04-04 09:50:19", "link": "http://arxiv.org/abs/2304.01666v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can BERT eat RuCoLA? Topological Data Analysis to Explain", "abstract": "This paper investigates how Transformer language models (LMs) fine-tuned for\nacceptability classification capture linguistic features. Our approach uses the\nbest practices of topological data analysis (TDA) in NLP: we construct directed\nattention graphs from attention matrices, derive topological features from\nthem, and feed them to linear classifiers. We introduce two novel features,\nchordality, and the matching number, and show that TDA-based classifiers\noutperform fine-tuning baselines. We experiment with two datasets, CoLA and\nRuCoLA in English and Russian, typologically different languages. On top of\nthat, we propose several black-box introspection techniques aimed at detecting\nchanges in the attention mode of the LMs during fine-tuning, defining the LM's\nprediction confidences, and associating individual heads with fine-grained\ngrammar phenomena. Our results contribute to understanding the behavior of\nmonolingual LMs in the acceptability classification task, provide insights into\nthe functional roles of attention heads, and highlight the advantages of\nTDA-based approaches for analyzing LMs. We release the code and the\nexperimental results for further uptake.", "published": "2023-04-04 10:11:06", "link": "http://arxiv.org/abs/2304.01680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT a Highly Fluent Grammatical Error Correction System? A\n  Comprehensive Evaluation", "abstract": "ChatGPT, a large-scale language model based on the advanced GPT-3.5\narchitecture, has shown remarkable potential in various Natural Language\nProcessing (NLP) tasks. However, there is currently a dearth of comprehensive\nstudy exploring its potential in the area of Grammatical Error Correction\n(GEC). To showcase its capabilities in GEC, we design zero-shot\nchain-of-thought (CoT) and few-shot CoT settings using in-context learning for\nChatGPT. Our evaluation involves assessing ChatGPT's performance on five\nofficial test sets in three different languages, along with three\ndocument-level GEC test sets in English. Our experimental results and human\nevaluations demonstrate that ChatGPT has excellent error detection capabilities\nand can freely correct errors to make the corrected sentences very fluent,\npossibly due to its over-correction tendencies and not adhering to the\nprinciple of minimal edits. Additionally, its performance in non-English and\nlow-resource settings highlights its potential in multilingual GEC tasks.\nHowever, further analysis of various types of errors at the document-level has\nshown that ChatGPT cannot effectively correct agreement, coreference, tense\nerrors across sentences, and cross-sentence boundary errors.", "published": "2023-04-04 12:33:40", "link": "http://arxiv.org/abs/2304.01746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summary of ChatGPT-Related Research and Perspective Towards the Future\n  of Large Language Models", "abstract": "This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field.", "published": "2023-04-04 15:01:06", "link": "http://arxiv.org/abs/2304.01852v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "San-BERT: Extractive Summarization for Sanskrit Documents using BERT and\n  it's variants", "abstract": "In this work, we develop language models for the Sanskrit language, namely\nBidirectional Encoder Representations from Transformers (BERT) and its\nvariants: A Lite BERT (ALBERT), and Robustly Optimized BERT (RoBERTa) using\nDevanagari Sanskrit text corpus. Then we extracted the features for the given\ntext from these models. We applied the dimensional reduction and clustering\ntechniques on the features to generate an extractive summary for a given\nSanskrit document. Along with the extractive text summarization techniques, we\nhave also created and released a Sanskrit Devanagari text corpus publicly.", "published": "2023-04-04 15:47:26", "link": "http://arxiv.org/abs/2304.01894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REFINER: Reasoning Feedback on Intermediate Representations", "abstract": "Language models (LMs) have recently shown remarkable performance on reasoning\ntasks by explicitly generating intermediate inferences, e.g., chain-of-thought\nprompting. However, these intermediate inference steps may be inappropriate\ndeductions from the initial context and lead to incorrect final predictions.\nHere we introduce REFINER, a framework for finetuning LMs to explicitly\ngenerate intermediate reasoning steps while interacting with a critic model\nthat provides automated feedback on the reasoning. Specifically, the critic\nprovides structured feedback that the reasoning LM uses to iteratively improve\nits intermediate arguments. Empirical evaluations of REFINER on three diverse\nreasoning tasks show significant improvements over baseline LMs of comparable\nscale. Furthermore, when using GPT-3.5 or ChatGPT as the reasoner, the trained\ncritic significantly improves reasoning without finetuning the reasoner.\nFinally, our critic model is trained without expensive human-in-the-loop data\nbut can be substituted with humans at inference time.", "published": "2023-04-04 15:57:28", "link": "http://arxiv.org/abs/2304.01904v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resources and Few-shot Learners for In-context Learning in Slavic\n  Languages", "abstract": "Despite the rapid recent progress in creating accurate and compact in-context\nlearners, most recent work focuses on in-context learning (ICL) for tasks in\nEnglish. However, the ability to interact with users of languages outside\nEnglish presents a great potential for broadening the applicability of language\ntechnologies to non-English speakers.\n  In this work, we collect the infrastructure necessary for training and\nevaluation of ICL in a selection of Slavic languages: Czech, Polish, and\nRussian. We link a diverse set of datasets and cast these into a unified\ninstructional format through a set of transformations and newly-crafted\ntemplates written purely in target languages. Using the newly-curated dataset,\nwe evaluate a set of the most recent in-context learners and compare their\nresults to the supervised baselines. Finally, we train, evaluate and publish a\nset of in-context learning models that we train on the collected resources and\ncompare their performance to previous work.\n  We find that ICL models tuned in English are also able to learn some tasks\nfrom non-English contexts, but multilingual instruction fine-tuning\nconsistently improves the ICL ability. We also find that the massive multitask\ntraining can be outperformed by single-task training in the target language,\nuncovering the potential for specializing in-context learners to the\nlanguage(s) of their application.", "published": "2023-04-04 16:16:25", "link": "http://arxiv.org/abs/2304.01922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of\n  Large Language Models", "abstract": "The success of large language models (LLMs), like GPT-4 and ChatGPT, has led\nto the development of numerous cost-effective and accessible alternatives that\nare created by finetuning open-access LLMs with task-specific data (e.g.,\nChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning\nmethods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly\none of the most attractive topics, as it only requires fine-tuning a few\nexternal parameters instead of the entire LLMs while achieving comparable or\neven better performance. To enable further research on PEFT methods of LLMs,\nthis paper presents LLM-Adapters, an easy-to-use framework that integrates\nvarious adapters into LLMs and can execute these adapter-based PEFT methods of\nLLMs for different tasks. The framework includes state-of-the-art open-access\nLLMs such as LLaMA, BLOOM, and GPT-J, as well as widely used adapters such as\nSeries adapters, Parallel adapter, Prompt-based learning and\nReparametrization-based methods. Moreover, we conduct extensive empirical\nstudies on the impact of adapter types, placement locations, and\nhyper-parameters to the best design for each adapter-based methods. We evaluate\nthe effectiveness of the adapters on fourteen datasets from two different\nreasoning tasks, Arithmetic Reasoning and Commonsense Reasoning. The results\ndemonstrate that using adapter-based PEFT in smaller-scale LLMs (7B) with few\nextra trainable parameters yields comparable, and in some cases superior,\nperformance to powerful LLMs (175B) in zero-shot inference on both reasoning\ntasks.", "published": "2023-04-04 16:31:37", "link": "http://arxiv.org/abs/2304.01933v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Data Fusion Framework for Multi-Domain Morality Learning", "abstract": "Language models can be trained to recognize the moral sentiment of text,\ncreating new opportunities to study the role of morality in human life. As\ninterest in language and morality has grown, several ground truth datasets with\nmoral annotations have been released. However, these datasets vary in the\nmethod of data collection, domain, topics, instructions for annotators, etc.\nSimply aggregating such heterogeneous datasets during training can yield models\nthat fail to generalize well. We describe a data fusion framework for training\non multiple heterogeneous datasets that improve performance and\ngeneralizability. The model uses domain adversarial training to align the\ndatasets in feature space and a weighted loss function to deal with label\nshift. We show that the proposed framework achieves state-of-the-art\nperformance in different datasets compared to prior works in morality\ninference.", "published": "2023-04-04 22:05:02", "link": "http://arxiv.org/abs/2304.02144v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blockwise Compression of Transformer-based Models without Retraining", "abstract": "Transformer-based models, exemplified by GPT-3, ChatGPT, and GPT-4, have\nrecently garnered considerable attention in both academia and industry due to\ntheir promising performance in general language tasks. Nevertheless, these\nmodels typically involve computationally encoding processes, and in some cases,\ndecoding processes as well, both of which are fundamentally large-scale matrix\nmultiplication. These operations bring the inevitable challenges of massive\ncomputation resources and huge memory footprint, usually requiring at least\n10^23 FLOPs and hundreds of gigabytes, respectively. A common method to address\nthis issue is to reduce the computational and memory requirements by applying\nlayerwise quantization to the transformer, replacing the usual fp32 data type\nwith a low-bit equivalent. Unfortunately, this method often leads to decreased\nmodel accuracy and necessitates time-consuming retraining. Such retraining not\nonly requires fine-tuning skills but also substantial computational resources,\nposing challenges for users. To specifically tackle these issues, we propose\nBCT, a framework of blockwise compression for transformers without retraining,\naiming to facilitate model deployment. Unlike layerwise compression methods,\nBCT achieves finer compression of the entire transformer by operating\nblockwise. This method mitigates data distribution deviation caused by\nquantization, eliminating the requirement for retraining. BCT effectively\ncompresses all components of the model, including but not limited to the\nembedding, matrix multiplication, GELU, Softmax, layer normalization, and\nintermediate results. In a case study, an efficient model is compressed by BCT\nachieving up to 7.988x compression. Subsequently, we also evaluate it on\nseveral General Language Understanding Evaluation (GLUE) datasets.", "published": "2023-04-04 02:55:40", "link": "http://arxiv.org/abs/2304.01483v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multidimensional Perceptron for Efficient and Explainable Long Text\n  Classification", "abstract": "Because of the inevitable cost and complexity of transformer and pre-trained\nmodels, efficiency concerns are raised for long text classification. Meanwhile,\nin the highly sensitive domains, e.g., healthcare and legal long-text mining,\npotential model distrust, yet underrated and underexplored, may hatch vital\napprehension. Existing methods generally segment the long text, encode each\npiece with the pre-trained model, and use attention or RNNs to obtain long text\nrepresentation for classification. In this work, we propose a simple but\neffective model, Segment-aWare multIdimensional PErceptron (SWIPE), to replace\nattention/RNNs in the above framework. Unlike prior efforts, SWIPE can\neffectively learn the label of the entire text with supervised training, while\nperceive the labels of the segments and estimate their contributions to the\nlong-text labeling in an unsupervised manner. As a general classifier, SWIPE\ncan endorse different encoders, and it outperforms SOTA models in terms of\nclassification accuracy and model efficiency. It is noteworthy that SWIPE\nachieves superior interpretability to transparentize long text classification\nresults.", "published": "2023-04-04 08:49:39", "link": "http://arxiv.org/abs/2304.01638v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rumour Detection and Analysis on Twitter", "abstract": "In recent years people have become increasingly reliant on social media to\nread news and get information, and some social media users post unsubstantiated\ninformation to gain attention. Such information is known as rumours. Nowadays,\nrumour detection is receiving a growing amount of attention because of the\npandemic of the New Coronavirus, which has led to a large number of rumours\nbeing spread. In this paper, a Natural Language Processing (NLP) system is\nbuilt to predict rumours. The best model is applied to the COVID-19 tweets to\nconduct exploratory data analysis. The contribution of this study is twofold:\n(1) to compare rumours and facts using state-of-the-art natural language\nprocessing models in two dimensions: language structure and propagation route.\n(2) An analysis of how rumours differ from facts in terms of their lexical use\nand the emotions they imply. This study shows that linguistic structure is a\nbetter feature to distinguish rumours from facts compared to the propagation\npath. In addition, rumour tweets contain more vocabulary related to politics\nand negative emotions.", "published": "2023-04-04 11:20:37", "link": "http://arxiv.org/abs/2304.01712v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MEGClass: Extremely Weakly Supervised Text Classification via\n  Mutually-Enhancing Text Granularities", "abstract": "Text classification is essential for organizing unstructured text.\nTraditional methods rely on human annotations or, more recently, a set of class\nseed words for supervision, which can be costly, particularly for specialized\nor emerging domains. To address this, using class surface names alone as\nextremely weak supervision has been proposed. However, existing approaches\ntreat different levels of text granularity (documents, sentences, or words)\nindependently, disregarding inter-granularity class disagreements and the\ncontext identifiable exclusively through joint extraction. In order to tackle\nthese issues, we introduce MEGClass, an extremely weakly-supervised text\nclassification method that leverages Mutually-Enhancing Text Granularities.\nMEGClass utilizes coarse- and fine-grained context signals obtained by jointly\nconsidering a document's most class-indicative words and sentences. This\napproach enables the learning of a contextualized document representation that\ncaptures the most discriminative class indicators. By preserving the\nheterogeneity of potential classes, MEGClass can select the most informative\nclass-indicative documents as iterative feedback to enhance the initial\nword-based class representations and ultimately fine-tune a pre-trained text\nclassifier. Extensive experiments on seven benchmark datasets demonstrate that\nMEGClass outperforms other weakly and extremely weakly supervised methods.", "published": "2023-04-04 17:26:11", "link": "http://arxiv.org/abs/2304.01969v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dialogue-Contextualized Re-ranking for Medical History-Taking", "abstract": "AI-driven medical history-taking is an important component in symptom\nchecking, automated patient intake, triage, and other AI virtual care\napplications. As history-taking is extremely varied, machine learning models\nrequire a significant amount of data to train. To overcome this challenge,\nexisting systems are developed using indirect data or expert knowledge. This\nleads to a training-inference gap as models are trained on different kinds of\ndata than what they observe at inference time. In this work, we present a\ntwo-stage re-ranking approach that helps close the training-inference gap by\nre-ranking the first-stage question candidates using a dialogue-contextualized\nmodel. For this, we propose a new model, global re-ranker, which cross-encodes\nthe dialogue with all questions simultaneously, and compare it with several\nexisting neural baselines. We test both transformer and S4-based language model\nbackbones. We find that relative to the expert system, the best performance is\nachieved by our proposed global re-ranker with a transformer backbone,\nresulting in a 30% higher normalized discount cumulative gain (nDCG) and a 77%\nhigher mean average precision (mAP).", "published": "2023-04-04 17:31:32", "link": "http://arxiv.org/abs/2304.01974v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Rethinking the Role of Token Retrieval in Multi-Vector Retrieval", "abstract": "Multi-vector retrieval models such as ColBERT [Khattab and Zaharia, 2020]\nallow token-level interactions between queries and documents, and hence achieve\nstate of the art on many information retrieval benchmarks. However, their\nnon-linear scoring function cannot be scaled to millions of documents,\nnecessitating a three-stage process for inference: retrieving initial\ncandidates via token retrieval, accessing all token vectors, and scoring the\ninitial candidate documents. The non-linear scoring function is applied over\nall token vectors of each candidate document, making the inference process\ncomplicated and slow. In this paper, we aim to simplify the multi-vector\nretrieval by rethinking the role of token retrieval. We present XTR,\nConteXtualized Token Retriever, which introduces a simple, yet novel, objective\nfunction that encourages the model to retrieve the most important document\ntokens first. The improvement to token retrieval allows XTR to rank candidates\nonly using the retrieved tokens rather than all tokens in the document, and\nenables a newly designed scoring stage that is two-to-three orders of magnitude\ncheaper than that of ColBERT. On the popular BEIR benchmark, XTR advances the\nstate-of-the-art by 2.8 nDCG@10 without any distillation. Detailed analysis\nconfirms our decision to revisit the token retrieval stage, as XTR demonstrates\nmuch better recall of the token retrieval stage compared to ColBERT.", "published": "2023-04-04 17:37:06", "link": "http://arxiv.org/abs/2304.01982v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Scalable and Accurate Self-supervised Multimodal Representation Learning\n  without Aligned Video and Text Data", "abstract": "Scaling up weakly-supervised datasets has shown to be highly effective in the\nimage-text domain and has contributed to most of the recent state-of-the-art\ncomputer vision and multimodal neural networks. However, existing large-scale\nvideo-text datasets and mining techniques suffer from several limitations, such\nas the scarcity of aligned data, the lack of diversity in the data, and the\ndifficulty of collecting aligned data. Currently popular video-text data mining\napproach via automatic speech recognition (ASR) used in HowTo100M provides\nlow-quality captions that often do not refer to the video content. Other mining\napproaches do not provide proper language descriptions (video tags) and are\nbiased toward short clips (alt text). In this work, we show how recent advances\nin image captioning allow us to pre-train high-quality video models without any\nparallel video-text data. We pre-train several video captioning models that are\nbased on an OPT language model and a TimeSformer visual backbone. We fine-tune\nthese networks on several video captioning datasets. First, we demonstrate that\nimage captioning pseudolabels work better for pre-training than the existing\nHowTo100M ASR captions. Second, we show that pre-training on both images and\nvideos produces a significantly better network (+4 CIDER on MSR-VTT) than\npre-training on a single modality. Our methods are complementary to the\nexisting pre-training or data mining approaches and can be used in a variety of\nsettings. Given the efficacy of the pseudolabeling method, we are planning to\npublicly release the generated captions.", "published": "2023-04-04 19:11:05", "link": "http://arxiv.org/abs/2304.02080v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in\n  geotechnical engineering", "abstract": "The widespread adoption of large language models (LLMs), such as OpenAI's\nChatGPT, could revolutionize various industries, including geotechnical\nengineering. However, GPT models can sometimes generate plausible-sounding but\nfalse outputs, leading to hallucinations. In this article, we discuss the\nimportance of prompt engineering in mitigating these risks and harnessing the\nfull potential of GPT for geotechnical applications. We explore the challenges\nand pitfalls associated with LLMs and highlight the role of context in ensuring\naccurate and valuable responses. Furthermore, we examine the development of\ncontext-specific search engines and the potential of LLMs to become a natural\ninterface for complex tasks, such as data analysis and design. We also develop\na unified interface using natural language to handle complex geotechnical\nengineering tasks and data analysis. By integrating GPT into geotechnical\nengineering workflows, professionals can streamline their work and develop\nsustainable and resilient infrastructure systems for the future.", "published": "2023-04-04 21:47:41", "link": "http://arxiv.org/abs/2304.02138v3", "categories": ["cs.CL", "physics.geo-ph", "I.2.7; J.2.6"], "primary_category": "cs.CL"}
{"title": "To ChatGPT, or not to ChatGPT: That is the question!", "abstract": "ChatGPT has become a global sensation. As ChatGPT and other Large Language\nModels (LLMs) emerge, concerns of misusing them in various ways increase, such\nas disseminating fake news, plagiarism, manipulating public opinion, cheating,\nand fraud. Hence, distinguishing AI-generated from human-generated becomes\nincreasingly essential. Researchers have proposed various detection\nmethodologies, ranging from basic binary classifiers to more complex\ndeep-learning models. Some detection techniques rely on statistical\ncharacteristics or syntactic patterns, while others incorporate semantic or\ncontextual information to improve accuracy. The primary objective of this study\nis to provide a comprehensive and contemporary assessment of the most recent\ntechniques in ChatGPT detection. Additionally, we evaluated other AI-generated\ntext detection tools that do not specifically claim to detect ChatGPT-generated\ncontent to assess their performance in detecting ChatGPT-generated content. For\nour evaluation, we have curated a benchmark dataset consisting of prompts from\nChatGPT and humans, including diverse questions from medical, open Q&A, and\nfinance domains and user-generated responses from popular social networking\nplatforms. The dataset serves as a reference to assess the performance of\nvarious techniques in detecting ChatGPT-generated content. Our evaluation\nresults demonstrate that none of the existing methods can effectively detect\nChatGPT-generated content.", "published": "2023-04-04 03:04:28", "link": "http://arxiv.org/abs/2304.01487v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Text-Conditioned Sampling Framework for Text-to-Image Generation with\n  Masked Generative Models", "abstract": "Token-based masked generative models are gaining popularity for their fast\ninference time with parallel decoding. While recent token-based approaches\nachieve competitive performance to diffusion-based models, their generation\nperformance is still suboptimal as they sample multiple tokens simultaneously\nwithout considering the dependence among them. We empirically investigate this\nproblem and propose a learnable sampling model, Text-Conditioned Token\nSelection (TCTS), to select optimal tokens via localized supervision with text\ninformation. TCTS improves not only the image quality but also the semantic\nalignment of the generated images with the given texts. To further improve the\nimage quality, we introduce a cohesive sampling strategy, Frequency Adaptive\nSampling (FAS), to each group of tokens divided according to the self-attention\nmaps. We validate the efficacy of TCTS combined with FAS with various\ngenerative tasks, demonstrating that it significantly outperforms the baselines\nin image-text alignment and image quality. Our text-conditioned sampling\nframework further reduces the original inference time by more than 50% without\nmodifying the original generative model.", "published": "2023-04-04 03:52:49", "link": "http://arxiv.org/abs/2304.01515v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "I.5.4; I.2.10; I.4.m"], "primary_category": "cs.LG"}
{"title": "Cross-Domain Image Captioning with Discriminative Finetuning", "abstract": "Neural captioners are typically trained to mimic human-generated references\nwithout optimizing for any specific communication goal, leading to problems\nsuch as the generation of vague captions. In this paper, we show that\nfine-tuning an out-of-the-box neural captioner with a self-supervised\ndiscriminative communication objective helps to recover a plain, visually\ndescriptive language that is more informative about image contents. Given a\ntarget image, the system must learn to produce a description that enables an\nout-of-the-box text-conditioned image retriever to identify such image among a\nset of candidates. We experiment with the popular ClipCap captioner, also\nreplicating the main results with BLIP. In terms of similarity to ground-truth\nhuman descriptions, the captions emerging from discriminative finetuning lag\nslightly behind those generated by the non-finetuned model, when the latter is\ntrained and tested on the same caption dataset. However, when the model is used\nwithout further tuning to generate captions for out-of-domain datasets, our\ndiscriminatively-finetuned captioner generates descriptions that resemble human\nreferences more than those produced by the same captioner without finetuning.\nWe further show that, on the Conceptual Captions dataset, discriminatively\nfinetuned captions are more helpful than either vanilla ClipCap captions or\nground-truth captions for human annotators tasked with an image discrimination\ntask.", "published": "2023-04-04 09:33:16", "link": "http://arxiv.org/abs/2304.01662v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Black Box Few-Shot Adaptation for Vision-Language models", "abstract": "Vision-Language (V-L) models trained with contrastive learning to align the\nvisual and language modalities have been shown to be strong few-shot learners.\nSoft prompt learning is the method of choice for few-shot downstream adaptation\naiming to bridge the modality gap caused by the distribution shift induced by\nthe new domain. While parameter-efficient, prompt learning still requires\naccess to the model weights and can be computationally infeasible for large\nmodels with billions of parameters. To address these shortcomings, in this\nwork, we describe a black-box method for V-L few-shot adaptation that (a)\noperates on pre-computed image and text features and hence works without access\nto the model's weights, (b) it is orders of magnitude faster at training time,\n(c) it is amenable to both supervised and unsupervised training, and (d) it can\nbe even used to align image and text features computed from uni-modal models.\nTo achieve this, we propose Linear Feature Alignment (LFA), a simple linear\napproach for V-L re-alignment in the target domain. LFA is initialized from a\nclosed-form solution to a least-squares problem and then it is iteratively\nupdated by minimizing a re-ranking loss. Despite its simplicity, our approach\ncan even surpass soft-prompt learning methods as shown by extensive experiments\non 11 image and 2 video datasets.", "published": "2023-04-04 12:42:29", "link": "http://arxiv.org/abs/2304.01752v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A User-Centered, Interactive, Human-in-the-Loop Topic Modelling System", "abstract": "Human-in-the-loop topic modelling incorporates users' knowledge into the\nmodelling process, enabling them to refine the model iteratively. Recent\nresearch has demonstrated the value of user feedback, but there are still\nissues to consider, such as the difficulty in tracking changes, comparing\ndifferent models and the lack of evaluation based on real-world examples of\nuse. We developed a novel, interactive human-in-the-loop topic modeling system\nwith a user-friendly interface that enables users compare and record every step\nthey take, and a novel topic words suggestion feature to help users provide\nfeedback that is faithful to the ground truth. Our system also supports not\nonly what traditional topic models can do, i.e., learning the topics from the\nwhole corpus, but also targeted topic modelling, i.e., learning topics for\nspecific aspects of the corpus. In this article, we provide an overview of the\nsystem and present the results of a series of user studies designed to assess\nthe value of the system in progressively more realistic applications of topic\nmodelling.", "published": "2023-04-04 13:05:10", "link": "http://arxiv.org/abs/2304.01774v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sociocultural knowledge is needed for selection of shots in hate speech\n  detection tasks", "abstract": "We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for\nthe countries of Brazil, Germany, India and Kenya, to aid training and\ninterpretability of models. We demonstrate how our lexicon can be used to\ninterpret model predictions, showing that models developed to classify extreme\nspeech rely heavily on target words when making predictions. Further, we\npropose a method to aid shot selection for training in low-resource settings\nvia HATELEXICON. In few-shot learning, the selection of shots is of paramount\nimportance to model performance. In our work, we simulate a few-shot setting\nfor German and Hindi, using HASOC data for training and the Multilingual\nHateCheck (MHC) as a benchmark. We show that selecting shots based on our\nlexicon leads to models performing better on MHC than models trained on shots\nsampled randomly. Thus, when given only a few training examples, using our\nlexicon to select shots containing more sociocultural information leads to\nbetter few-shot performance.", "published": "2023-04-04 15:42:08", "link": "http://arxiv.org/abs/2304.01890v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia\n  Content Creation", "abstract": "This paper presents the AToMiC (Authoring Tools for Multimedia Content)\ndataset, designed to advance research in image/text cross-modal retrieval.\nWhile vision-language pretrained transformers have led to significant\nimprovements in retrieval effectiveness, existing research has relied on\nimage-caption datasets that feature only simplistic image-text relationships\nand underspecified user models of retrieval tasks. To address the gap between\nthese oversimplified settings and real-world applications for multimedia\ncontent creation, we introduce a new approach for building retrieval test\ncollections. We leverage hierarchical structures and diverse domains of texts,\nstyles, and types of images, as well as large-scale image-document associations\nembedded in Wikipedia. We formulate two tasks based on a realistic user model\nand validate our dataset through retrieval experiments using baseline models.\nAToMiC offers a testbed for scalable, diverse, and reproducible multimedia\nretrieval research. Finally, the dataset provides the basis for a dedicated\ntrack at the 2023 Text Retrieval Conference (TREC), and is publicly available\nat https://github.com/TREC-AToMiC/AToMiC.", "published": "2023-04-04 17:11:34", "link": "http://arxiv.org/abs/2304.01961v1", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Effective Theory of Transformers at Initialization", "abstract": "We perform an effective-theory analysis of forward-backward signal\npropagation in wide and deep Transformers, i.e., residual neural networks with\nmulti-head self-attention blocks and multilayer perceptron blocks. This\nanalysis suggests particular width scalings of initialization and training\nhyperparameters for these models. We then take up such suggestions, training\nVision and Language Transformers in practical setups.", "published": "2023-04-04 18:00:01", "link": "http://arxiv.org/abs/2304.02034v1", "categories": ["cs.LG", "cs.CL", "hep-th", "stat.ML"], "primary_category": "cs.LG"}
{"title": "I2I: Initializing Adapters with Improvised Knowledge", "abstract": "Adapters present a promising solution to the catastrophic forgetting problem\nin continual learning. However, training independent Adapter modules for every\nnew task misses an opportunity for cross-task knowledge transfer. We propose\nImprovise to Initialize (I2I), a continual learning algorithm that initializes\nAdapters for incoming tasks by distilling knowledge from previously-learned\ntasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning\nbenchmark, by conducting experiments on sequences of visual question answering\ntasks. Adapters trained with I2I consistently achieve better task accuracy than\nindependently-trained Adapters, demonstrating that our algorithm facilitates\nknowledge transfer between task Adapters. I2I also results in better cross-task\nknowledge transfer than the state-of-the-art AdapterFusion without incurring\nthe associated parametric cost.", "published": "2023-04-04 23:51:48", "link": "http://arxiv.org/abs/2304.02168v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FedBot: Enhancing Privacy in Chatbots with Federated Learning", "abstract": "Chatbots are mainly data-driven and usually based on utterances that might be\nsensitive. However, training deep learning models on shared data can violate\nuser privacy. Such issues have commonly existed in chatbots since their\ninception. In the literature, there have been many approaches to deal with\nprivacy, such as differential privacy and secure multi-party computation, but\nmost of them need to have access to users' data. In this context, Federated\nLearning (FL) aims to protect data privacy through distributed learning methods\nthat keep the data in its location. This paper presents Fedbot, a\nproof-of-concept (POC) privacy-preserving chatbot that leverages large-scale\ncustomer support data. The POC combines Deep Bidirectional Transformer models\nand federated learning algorithms to protect customer data privacy during\ncollaborative model training. The results of the proof-of-concept showcase the\npotential for privacy-preserving chatbots to transform the customer support\nindustry by delivering personalized and efficient customer service that meets\ndata privacy regulations and legal requirements. Furthermore, the system is\nspecifically designed to improve its performance and accuracy over time by\nleveraging its ability to learn from previous interactions.", "published": "2023-04-04 23:13:52", "link": "http://arxiv.org/abs/2304.03228v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "One Small Step for Generative AI, One Giant Leap for AGI: A Complete\n  Survey on ChatGPT in AIGC Era", "abstract": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is\ndemonstrated to be one small step for generative AI (GAI), but one giant leap\nfor artificial general intelligence (AGI). Since its official release in\nNovember 2022, ChatGPT has quickly attracted numerous users with extensive\nmedia coverage. Such unprecedented attention has also motivated numerous\nresearchers to investigate ChatGPT from various aspects. According to Google\nscholar, there are more than 500 articles with ChatGPT in their titles or\nmentioning it in their abstracts. Considering this, a review is urgently\nneeded, and our work fills this gap. Overall, this work is the first to survey\nChatGPT with a comprehensive review of its underlying technology, applications,\nand challenges. Moreover, we present an outlook on how ChatGPT might evolve to\nrealize general-purpose AIGC (a.k.a. AI-generated content), which will be a\nsignificant milestone for the development of AGI.", "published": "2023-04-04 06:22:09", "link": "http://arxiv.org/abs/2304.06488v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CY"}
{"title": "TorchAudio-Squim: Reference-less Speech Quality and Intelligibility\n  measures in TorchAudio", "abstract": "Measuring quality and intelligibility of a speech signal is usually a\ncritical step in development of speech processing systems. To enable this, a\nvariety of metrics to measure quality and intelligibility under different\nassumptions have been developed. Through this paper, we introduce tools and a\nset of models to estimate such known metrics using deep neural networks. These\nmodels are made available in the well-established TorchAudio library, the core\naudio and speech processing library within the PyTorch deep learning framework.\nWe refer to it as TorchAudio-Squim, TorchAudio-Speech QUality and\nIntelligibility Measures. More specifically, in the current version of\nTorchAudio-squim, we establish and release models for estimating PESQ, STOI and\nSI-SDR among objective metrics and MOS among subjective metrics. We develop a\nnovel approach for objective metric estimation and use a recently developed\napproach for subjective metric estimation. These models operate in a\n``reference-less\" manner, that is they do not require the corresponding clean\nspeech as reference for speech assessment. Given the unavailability of clean\nspeech and the effortful process of subjective evaluation in real-world\nsituations, such easy-to-use tools would greatly benefit speech processing\nresearch and development.", "published": "2023-04-04 01:44:24", "link": "http://arxiv.org/abs/2304.01448v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Independent Vector Extraction Constrained on Manifold of Half-Length\n  Filters", "abstract": "Independent Vector Analysis (IVA) is a popular extension of Independent\nComponent Analysis (ICA) for joint separation of a set of instantaneous linear\nmixtures, with a direct application in frequency-domain speaker separation or\nextraction. The mixtures are parameterized by mixing matrices, one matrix per\nmixture. This means that the IVA mixing model does not account for any\nrelationships between parameters across the mixtures/frequencies. The\nseparation proceeds jointly only through the source model, where statistical\ndependencies of sources across the mixtures are taken into account. In this\npaper, we propose a mixing model for joint blind source extraction where the\nmixing model parameters are linked across the frequencies. This is achieved by\nconstraining the set of feasible parameters to the manifold of half-length\nseparating filters, which has a clear interpretation and application in\nfrequency-domain speaker extraction.", "published": "2023-04-04 13:11:33", "link": "http://arxiv.org/abs/2304.01778v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Pac-HuBERT: Self-Supervised Music Source Separation via Primitive\n  Auditory Clustering and Hidden-Unit BERT", "abstract": "In spite of the progress in music source separation research, the small\namount of publicly-available clean source data remains a constant limiting\nfactor for performance. Thus, recent advances in self-supervised learning\npresent a largely-unexplored opportunity for improving separation models by\nleveraging unlabelled music data. In this paper, we propose a self-supervised\nlearning framework for music source separation inspired by the HuBERT speech\nrepresentation model. We first investigate the potential impact of the original\nHuBERT model by inserting an adapted version of it into the well-known Demucs\nV2 time-domain separation model architecture. We then propose a\ntime-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditory\nclustering HuBERT), that we later use in combination with a Res-U-Net decoder\nfor source separation. Pac-HuBERT uses primitive auditory features of music as\nunsupervised clustering labels to initialize the self-supervised pretraining\nprocess using the Free Music Archive (FMA) dataset. The resulting framework\nachieves better source-to-distortion ratio (SDR) performance on the MusDB18\ntest set than the original Demucs V2 and Res-U-Net models. We further\ndemonstrate that it can boost performance with small amounts of supervised\ndata. Ultimately, our proposed framework is an effective solution to the\nchallenge of limited clean source data for music source separation.", "published": "2023-04-04 23:19:53", "link": "http://arxiv.org/abs/2304.02160v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A2D: Anywhere Anytime Drumming", "abstract": "The drum kit, which has only been around for around 100 years, is a popular\ninstrument in many music genres such as pop, rock, and jazz. However, the road\nto owning a kit is expensive, both financially and space-wise. Also, drums are\nmore difficult to move around compared to other instruments, as they do not fit\ninto a single bag. We propose a no-drums approach that uses only two sticks and\na smartphone or a webcam to provide an air-drumming experience. The detection\nalgorithm combines deep learning tools with tracking methods for an enhanced\nuser experience. Based on both quantitative and qualitative testing with\nhumans-in-the-loop, we show that our system has zero misses for beginner level\nplay and negligible misses for advanced level play. Additionally, our limited\nhuman trials suggest potential directions for future research.", "published": "2023-04-04 21:36:37", "link": "http://arxiv.org/abs/2304.03289v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
