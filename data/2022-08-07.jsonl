{"title": "Vernacular Search Query Translation with Unsupervised Domain Adaptation", "abstract": "With the democratization of e-commerce platforms, an increasingly diversified\nuser base is opting to shop online. To provide a comfortable and reliable\nshopping experience, it's important to enable users to interact with the\nplatform in the language of their choice. An accurate query translation is\nessential for Cross-Lingual Information Retrieval (CLIR) with vernacular\nqueries. Due to internet-scale operations, e-commerce platforms get millions of\nsearch queries every day. However, creating a parallel training set to train an\nin-domain translation model is cumbersome. This paper proposes an unsupervised\ndomain adaptation approach to translate search queries without using any\nparallel corpus. We use an open-domain translation model (trained on public\ncorpus) and adapt it to the query data using only the monolingual queries from\ntwo languages. In addition, fine-tuning with a small labeled set further\nimproves the result. For demonstration, we show results for Hindi to English\nquery translation and use mBART-large-50 model as the baseline to improve upon.\nExperimental results show that, without using any parallel corpus, we obtain\nmore than 20 BLEU points improvement over the baseline while fine-tuning with a\nsmall 50k labeled set provides more than 27 BLEU points improvement over the\nbaseline.", "published": "2022-08-07 12:53:41", "link": "http://arxiv.org/abs/2208.03711v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Study of Encoder-Decoder Architectures for Code-Mix Search Query\n  Translation", "abstract": "With the broad reach of the internet and smartphones, e-commerce platforms\nhave an increasingly diversified user base. Since native language users are not\nconversant in English, their preferred browsing mode is their regional language\nor a combination of their regional language and English. From our recent study\non the query data, we noticed that many of the queries we receive are code-mix,\nspecifically Hinglish i.e. queries with one or more Hindi words written in\nEnglish (Latin) script. We propose a transformer-based approach for code-mix\nquery translation to enable users to search with these queries. We demonstrate\nthe effectiveness of pre-trained encoder-decoder models trained on a large\ncorpus of the unlabeled English text for this task. Using generic domain\ntranslation models, we created a pseudo-labelled dataset for training the model\non the search queries and verified the effectiveness of various data\naugmentation techniques. Further, to reduce the latency of the model, we use\nknowledge distillation and weight quantization. Effectiveness of the proposed\nmethod has been validated through experimental evaluations and A/B testing. The\nmodel is currently live on Flipkart app and website, serving millions of\nqueries.", "published": "2022-08-07 12:59:50", "link": "http://arxiv.org/abs/2208.03713v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciAnnotate: A Tool for Integrating Weak Labeling Sources for Sequence\n  Labeling", "abstract": "Weak labeling is a popular weak supervision strategy for Named Entity\nRecognition (NER) tasks, with the goal of reducing the necessity for\nhand-crafted annotations. Although there are numerous remarkable annotation\ntools for NER labeling, the subject of integrating weak labeling sources is\nstill unexplored. We introduce a web-based tool for text annotation called\nSciAnnotate, which stands for scientific annotation tool. Compared to\nfrequently used text annotation tools, our annotation tool allows for the\ndevelopment of weak labels in addition to providing a manual annotation\nexperience. Our tool provides users with multiple user-friendly interfaces for\ncreating weak labels. SciAnnotate additionally allows users to incorporate\ntheir own language models and visualize the output of their model for\nevaluation. In this study, we take multi-source weak label denoising as an\nexample, we utilized a Bertifying Conditional Hidden Markov Model to denoise\nthe weak label generated by our tool. We also evaluate our annotation tool\nagainst the dataset provided by Mysore which contains 230 annotated materials\nsynthesis procedures. The results shows that a 53.7% reduction in annotation\ntime obtained AND a 1.6\\% increase in recall using weak label denoising. Online\ndemo is available at https://sciannotate.azurewebsites.net/(demo account can be\nfound in README), but we don't host a model server with it, please check the\nREADME in supplementary material for model server usage.", "published": "2022-08-07 19:18:13", "link": "http://arxiv.org/abs/2208.10241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Perception as a Phenomenon of Quantization", "abstract": "For two decades, the formalism of quantum mechanics has been successfully\nused to describe human decision processes, situations of heuristic reasoning,\nand the contextuality of concepts and their combinations. The phenomenon of\n'categorical perception' has put us on track to find a possible deeper cause of\nthe presence of this quantum structure in human cognition. Thus, we show that\nin an archetype of human perception consisting of the reconciliation of a\nbottom up stimulus with a top down cognitive expectation pattern, there arises\nthe typical warping of categorical perception, where groups of stimuli clump\ntogether to form quanta, which move away from each other and lead to a\ndiscretization of a dimension. The individual concepts, which are these quanta,\ncan be modeled by a quantum prototype theory with the square of the absolute\nvalue of a corresponding Schr\\\"odinger wave function as the fuzzy prototype\nstructure, and the superposition of two such wave functions accounts for the\ninterference pattern that occurs when these concepts are combined. Using a\nsimple quantum measurement model, we analyze this archetype of human\nperception, provide an overview of the experimental evidence base for\ncategorical perception with the phenomenon of warping leading to quantization,\nand illustrate our analyses with two examples worked out in detail.", "published": "2022-08-07 13:59:23", "link": "http://arxiv.org/abs/2208.03726v2", "categories": ["q-bio.NC", "cs.CL", "quant-ph"], "primary_category": "q-bio.NC"}
{"title": "When can I Speak? Predicting initiation points for spoken dialogue\n  agents", "abstract": "Current spoken dialogue systems initiate their turns after a long period of\nsilence (700-1000ms), which leads to little real-time feedback, sluggish\nresponses, and an overall stilted conversational flow. Humans typically respond\nwithin 200ms and successfully predicting initiation points in advance would\nallow spoken dialogue agents to do the same. In this work, we predict the\nlead-time to initiation using prosodic features from a pre-trained speech\nrepresentation model (wav2vec 1.0) operating on user audio and word features\nfrom a pre-trained language model (GPT-2) operating on incremental\ntranscriptions. To evaluate errors, we propose two metrics w.r.t. predicted and\ntrue lead times. We train and evaluate the models on the Switchboard Corpus and\nfind that our method outperforms features from prior work on both metrics and\nvastly outperforms the common approach of waiting for 700ms of silence.", "published": "2022-08-07 20:58:52", "link": "http://arxiv.org/abs/2208.03812v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Debiased Cross-modal Matching for Content-based Micro-video Background\n  Music Recommendation", "abstract": "Micro-video background music recommendation is a complicated task where the\nmatching degree between videos and uploader-selected background music is a\nmajor issue. However, the selection of the user-generated content (UGC) is\nbiased caused by knowledge limitations and historical preferences among music\nof each uploader. In this paper, we propose a Debiased Cross-Modal (DebCM)\nmatching model to alleviate the influence of such selection bias. Specifically,\nwe design a teacher-student network to utilize the matching of segments of\nmusic videos, which is professional-generated content (PGC) with specialized\nmusic-matching techniques, to better alleviate the bias caused by insufficient\nknowledge of users. The PGC data is captured by a teacher network to guide the\nmatching of uploader-selected UGC data of the student network by KL-based\nknowledge transfer. In addition, uploaders' personal preferences of music\ngenres are identified as confounders that spuriously correlate music embeddings\nand background music selections, resulting in the learned recommender system to\nover-recommend music from the majority groups. To resolve such confounders in\nthe UGC data of the student network, backdoor adjustment is utilized to\ndeconfound the spurious correlation between music embeddings and prediction\nscores. We further utilize Monte Carlo (MC) estimator with batch-level average\nas the approximations to avoid integrating the entire confounder space\ncalculated by the adjustment. Extensive experiments on the TT-150k-genre\ndataset demonstrate the effectiveness of the proposed method towards the\nselection bias. The code is publicly available on:\n\\url{https://github.com/jing-1/DebCM}.", "published": "2022-08-07 04:00:43", "link": "http://arxiv.org/abs/2208.03633v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
