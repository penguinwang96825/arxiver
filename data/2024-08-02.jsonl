{"title": "Automatic Extraction of Relationships among Motivations, Emotions and\n  Actions from Natural Language Texts", "abstract": "We propose a new graph-based framework to reveal relationships among\nmotivations, emotions and actions explicitly given natural language texts. A\ndirected acyclic graph is designed to describe human's nature. Nurture beliefs\nare incorporated to connect outside events and the human's nature graph. No\nannotation resources are required due to the power of large language models.\nAmazon Fine Foods Reviews dataset is used as corpus and food-related\nmotivations are focused. Totally 92,990 relationship graphs are generated, of\nwhich 63% make logical sense. We make further analysis to investigate error\ntypes for optimization direction in future research.", "published": "2024-08-02 01:22:46", "link": "http://arxiv.org/abs/2408.00966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-domain Named Entity Recognition via Graph Matching", "abstract": "Cross-domain NER is a practical yet challenging problem since the data\nscarcity in the real-world scenario. A common practice is first to learn a NER\nmodel in a rich-resource general domain and then adapt the model to specific\ndomains. Due to the mismatch problem between entity types across domains, the\nwide knowledge in the general domain can not effectively transfer to the target\ndomain NER model. To this end, we model the label relationship as a probability\ndistribution and construct label graphs in both source and target label spaces.\nTo enhance the contextual representation with label structures, we fuse the\nlabel graph into the word embedding output by BERT. By representing label\nrelationships as graphs, we formulate cross-domain NER as a graph matching\nproblem. Furthermore, the proposed method has good applicability with\npre-training methods and is potentially capable of other cross-domain\nprediction tasks. Empirical results on four datasets show that our method\noutperforms a series of transfer learning, multi-task learning, and few-shot\nlearning methods.", "published": "2024-08-02 02:31:54", "link": "http://arxiv.org/abs/2408.00981v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UNER: A Unified Prediction Head for Named Entity Recognition in\n  Visually-rich Documents", "abstract": "The recognition of named entities in visually-rich documents (VrD-NER) plays\na critical role in various real-world scenarios and applications. However, the\nresearch in VrD-NER faces three major challenges: complex document layouts,\nincorrect reading orders, and unsuitable task formulations. To address these\nchallenges, we propose a query-aware entity extraction head, namely UNER, to\ncollaborate with existing multi-modal document transformers to develop more\nrobust VrD-NER models. The UNER head considers the VrD-NER task as a\ncombination of sequence labeling and reading order prediction, effectively\naddressing the issues of discontinuous entities in documents. Experimental\nevaluations on diverse datasets demonstrate the effectiveness of UNER in\nimproving entity extraction performance. Moreover, the UNER head enables a\nsupervised pre-training stage on various VrD-NER datasets to enhance the\ndocument transformer backbones and exhibits substantial knowledge transfer from\nthe pre-training stage to the fine-tuning stage. By incorporating universal\nlayout understanding, a pre-trained UNER-based model demonstrates significant\nadvantages in few-shot and cross-linguistic scenarios and exhibits zero-shot\nentity extraction abilities.", "published": "2024-08-02 06:21:36", "link": "http://arxiv.org/abs/2408.01038v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QUDSELECT: Selective Decoding for Questions Under Discussion Parsing", "abstract": "Question Under Discussion (QUD) is a discourse framework that uses implicit\nquestions to reveal discourse relationships between sentences. In QUD parsing,\neach sentence is viewed as an answer to a question triggered by an anchor\nsentence in prior context. The resulting QUD structure is required to conform\nto several theoretical criteria like answer compatibility (how well the\nquestion is answered), making QUD parsing a challenging task. Previous works\nconstruct QUD parsers in a pipelined manner (i.e. detect the trigger sentence\nin context and then generate the question). However, these parsers lack a\nholistic view of the task and can hardly satisfy all the criteria. In this\nwork, we introduce QUDSELECT, a joint-training framework that selectively\ndecodes the QUD dependency structures considering the QUD criteria. Using\ninstruction-tuning, we train models to simultaneously predict the anchor\nsentence and generate the associated question. To explicitly incorporate the\ncriteria, we adopt a selective decoding strategy of sampling multiple QUD\ncandidates during inference, followed by selecting the best one with criteria\nscorers. Our method outperforms the state-of-the-art baseline models by 9% in\nhuman evaluation and 4% in automatic evaluation, demonstrating the\neffectiveness of our framework.", "published": "2024-08-02 06:46:08", "link": "http://arxiv.org/abs/2408.01046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Contrastive Decoding in Retrieval-Augmented Generation for\n  Handling Noisy Contexts", "abstract": "When using large language models (LLMs) in knowledge-intensive tasks, such as\nopen-domain question answering, external context can bridge the gap between\nexternal knowledge and the LLMs' parametric knowledge. Recent research has been\ndeveloped to amplify contextual knowledge over the parametric knowledge of LLMs\nwith contrastive decoding approaches. While these approaches could yield\ntruthful responses when relevant context is provided, they are prone to\nvulnerabilities when faced with noisy contexts. We extend the scope of previous\nstudies to encompass noisy contexts and propose adaptive contrastive decoding\n(ACD) to leverage contextual influence effectively. ACD demonstrates\nimprovements in open-domain question answering tasks compared to baselines,\nespecially in robustness by remaining undistracted by noisy contexts in\nretrieval-augmented generation.", "published": "2024-08-02 08:03:38", "link": "http://arxiv.org/abs/2408.01084v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Information Gaps in Dialogues With Grounded Exchanges Using\n  Knowledge Graphs", "abstract": "Knowledge models are fundamental to dialogue systems for enabling\nconversational interactions, which require handling domain-specific knowledge.\nEnsuring effective communication in information-providing conversations entails\naligning user understanding with the knowledge available to the system.\nHowever, dialogue systems often face challenges arising from semantic\ninconsistencies in how information is expressed in natural language compared to\nhow it is represented within the system's internal knowledge. To address this\nproblem, we study the potential of large language models for conversational\ngrounding, a mechanism to bridge information gaps by establishing shared\nknowledge between dialogue participants. Our approach involves annotating human\nconversations across five knowledge domains to create a new dialogue corpus\ncalled BridgeKG. Through a series of experiments on this dataset, we\nempirically evaluate the capabilities of large language models in classifying\ngrounding acts and identifying grounded information items within a knowledge\ngraph structure. Our findings offer insights into how these models use\nin-context learning for conversational grounding tasks and common prediction\nerrors, which we illustrate with examples from challenging dialogues. We\ndiscuss how the models handle knowledge graphs as a semantic layer between\nunstructured dialogue utterances and structured information items.", "published": "2024-08-02 08:07:15", "link": "http://arxiv.org/abs/2408.01088v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation\n  for Checkworthy Claim Detection", "abstract": "This paper describes IAI group's participation for automated check-worthiness\nestimation for claims, within the framework of the 2024 CheckThat! Lab \"Task 1:\nCheck-Worthiness Estimation\". The task involves the automated detection of\ncheck-worthy claims in English, Dutch, and Arabic political debates and Twitter\ndata. We utilized various pre-trained generative decoder and encoder\ntransformer models, employing methods such as few-shot chain-of-thought\nreasoning, fine-tuning, data augmentation, and transfer learning from one\nlanguage to another. Despite variable success in terms of performance, our\nmodels achieved notable placements on the organizer's leaderboard: ninth-best\nin English, third-best in Dutch, and the top placement in Arabic, utilizing\nmultilingual datasets for enhancing the generalizability of check-worthiness\ndetection. Despite a significant drop in performance on the unlabeled test\ndataset compared to the development test dataset, our findings contribute to\nthe ongoing efforts in claim detection research, highlighting the challenges\nand potential of language-specific adaptations in claim verification systems.", "published": "2024-08-02 08:59:09", "link": "http://arxiv.org/abs/2408.01118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task Prompt Vectors: Effective Initialization through Multi-Task\n  Soft-Prompt Transfer", "abstract": "Prompt tuning is an efficient solution for training large language models\n(LLMs). However, current soft-prompt-based methods often sacrifice multi-task\nmodularity, requiring the training process to be fully or partially repeated\nfor each newly added task. While recent work on task vectors applied arithmetic\noperations on full model weights to achieve the desired multi-task performance,\na similar approach for soft-prompts is still missing. To this end, we introduce\nTask Prompt Vectors, created by element-wise difference between weights of\ntuned soft-prompts and their random initialization. Experimental results on 12\nNLU datasets show that task prompt vectors can be used in low-resource settings\nto effectively initialize prompt tuning on similar tasks. In addition, we show\nthat task prompt vectors are independent of the random initialization of prompt\ntuning on 2 different language model architectures. This allows prompt\narithmetics with the pre-trained vectors from different tasks. In this way, we\nprovide a competitive alternative to state-of-the-art baselines by arithmetic\naddition of task prompt vectors from multiple tasks.", "published": "2024-08-02 09:00:03", "link": "http://arxiv.org/abs/2408.01119v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CFBench: A Comprehensive Constraints-Following Benchmark for LLMs", "abstract": "The adeptness of Large Language Models (LLMs) in comprehending and following\nnatural language instructions is critical for their deployment in sophisticated\nreal-world applications. Existing evaluations mainly focus on fragmented\nconstraints or narrow scenarios, but they overlook the comprehensiveness and\nauthenticity of constraints from the user's perspective. To bridge this gap, we\npropose CFBench, a large-scale Comprehensive Constraints Following Benchmark\nfor LLMs, featuring 1,000 curated samples that cover more than 200 real-life\nscenarios and over 50 NLP tasks. CFBench meticulously compiles constraints from\nreal-world instructions and constructs an innovative systematic framework for\nconstraint types, which includes 10 primary categories and over 25\nsubcategories, and ensures each constraint is seamlessly integrated within the\ninstructions. To make certain that the evaluation of LLM outputs aligns with\nuser perceptions, we propose an advanced methodology that integrates\nmulti-dimensional assessment criteria with requirement prioritization, covering\nvarious perspectives of constraints, instructions, and requirement fulfillment.\nEvaluating current leading LLMs on CFBench reveals substantial room for\nimprovement in constraints following, and we further investigate influencing\nfactors and enhancement strategies. The data and code are publicly available at\nhttps://github.com/PKU-Baichuan-MLSystemLab/CFBench", "published": "2024-08-02 09:03:48", "link": "http://arxiv.org/abs/2408.01122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reconsidering Degeneration of Token Embeddings with Definitions for\n  Encoder-based Pre-trained Language Models", "abstract": "Learning token embeddings based on token co-occurrence statistics has proven\neffective for both pre-training and fine-tuning in natural language processing.\nHowever, recent studies have pointed out that the distribution of learned\nembeddings degenerates into anisotropy (i.e., non-uniform distribution), and\neven pre-trained language models (PLMs) suffer from a loss of semantics-related\ninformation in embeddings for low-frequency tokens. This study first analyzes\nthe fine-tuning dynamics of encoder-based PLMs and demonstrates their\nrobustness against degeneration. On the basis of this analysis, we propose\nDefinitionEMB, a method that utilizes definitions to re-construct isotropically\ndistributed and semantics-related token embeddings for encoder-based PLMs while\nmaintaining original robustness during fine-tuning. Our experiments demonstrate\nthe effectiveness of leveraging definitions from Wiktionary to re-construct\nsuch embeddings for two encoder-based PLMs: RoBERTa-base and BART-large.\nFurthermore, the re-constructed embeddings for low-frequency tokens improve the\nperformance of these models across various GLUE and four text summarization\ndatasets.", "published": "2024-08-02 15:00:05", "link": "http://arxiv.org/abs/2408.01308v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs\n  Only", "abstract": "Instruction fine-tuning stands as a crucial advancement in leveraging large\nlanguage models (LLMs) for enhanced task performance. However, the annotation\nof instruction datasets has traditionally been expensive and laborious, often\nrelying on manual annotations or costly API calls of proprietary LLMs. To\naddress these challenges, we introduce FANNO, a fully autonomous, open-sourced\nframework that revolutionizes the annotation process without the need for\npre-existing annotated data. Utilizing a Mistral-7b-instruct model, FANNO\nefficiently produces diverse and high-quality datasets through a structured\nprocess involving document pre-screening, instruction generation, and response\ngeneration. Experiments on Open LLM Leaderboard and AlpacaEval benchmark show\nthat the FANNO can generate high-quality data with diversity and complexity for\nfree, comparable to human-annotated or cleaned datasets like\nAlpaca-GPT4-Cleaned.", "published": "2024-08-02 15:21:20", "link": "http://arxiv.org/abs/2408.01323v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "abstract": "The emergence of Large Language Models (LLMs) have fundamentally altered the\nway we interact with digital systems and have led to the pursuit of LLM powered\nAI agents to assist in daily workflows. LLMs, whilst powerful and capable of\ndemonstrating some emergent properties, are not logical reasoners and often\nstruggle to perform well at all sub-tasks carried out by an AI agent to plan\nand execute a workflow. While existing studies tackle this lack of proficiency\nby generalised pretraining at a huge scale or by specialised fine-tuning for\ntool use, we assess if a system comprising of a coalition of pretrained LLMs,\neach exhibiting specialised performance at individual sub-tasks, can match the\nperformance of single model agents. The coalition of models approach showcases\nits potential for building robustness and reducing the operational costs of\nthese AI agents by leveraging traits exhibited by specific models. Our findings\ndemonstrate that fine-tuning can be mitigated by considering a coalition of\npretrained models and believe that this approach can be applied to other\nnon-agentic systems which utilise LLMs.", "published": "2024-08-02 16:37:44", "link": "http://arxiv.org/abs/2408.01380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Multilingual Neural Machine Translation by Utilizing Semantic\n  and Linguistic Features", "abstract": "The many-to-many multilingual neural machine translation can be regarded as\nthe process of integrating semantic features from the source sentences and\nlinguistic features from the target sentences. To enhance zero-shot\ntranslation, models need to share knowledge across languages, which can be\nachieved through auxiliary tasks for learning a universal representation or\ncross-lingual mapping. To this end, we propose to exploit both semantic and\nlinguistic features between multiple languages to enhance multilingual\ntranslation. On the encoder side, we introduce a disentangling learning task\nthat aligns encoder representations by disentangling semantic and linguistic\nfeatures, thus facilitating knowledge transfer while preserving complete\ninformation. On the decoder side, we leverage a linguistic encoder to integrate\nlow-level linguistic features to assist in the target language generation.\nExperimental results on multilingual datasets demonstrate significant\nimprovement in zero-shot translation compared to the baseline system, while\nmaintaining performance in supervised translation. Further analysis validates\nthe effectiveness of our method in leveraging both semantic and linguistic\nfeatures. The code is available at https://github.com/ictnlp/SemLing-MNMT.", "published": "2024-08-02 17:10:12", "link": "http://arxiv.org/abs/2408.01394v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DebateQA: Evaluating Question Answering on Debatable Knowledge", "abstract": "The rise of large language models (LLMs) has enabled us to seek answers to\ninherently debatable questions on LLM chatbots, necessitating a reliable way to\nevaluate their ability. However, traditional QA benchmarks assume fixed answers\nare inadequate for this purpose. To address this, we introduce DebateQA, a\ndataset of 2,941 debatable questions, each accompanied by multiple\nhuman-annotated partial answers that capture a variety of perspectives. We\ndevelop two metrics: Perspective Diversity, which evaluates the\ncomprehensiveness of perspectives, and Dispute Awareness, which assesses if the\nLLM acknowledges the question's debatable nature. Experiments demonstrate that\nboth metrics align with human preferences and are stable across different\nunderlying models. Using DebateQA with two metrics, we assess 12 popular LLMs\nand retrieval-augmented generation methods. Our findings reveal that while LLMs\ngenerally excel at recognizing debatable issues, their ability to provide\ncomprehensive answers encompassing diverse perspectives varies considerably.", "published": "2024-08-02 17:54:34", "link": "http://arxiv.org/abs/2408.01419v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoDE: Effective Multi-task Parameter Efficient Fine-Tuning with a\n  Mixture of Dyadic Experts", "abstract": "Parameter-efficient fine-tuning techniques like Low-Rank Adaptation (LoRA)\nhave revolutionized the adaptation of large language models (LLMs) to diverse\ntasks. Recent efforts have explored mixtures of LoRA modules for multi-task\nsettings. However, our analysis reveals redundancy in the down-projection\nmatrices of these architectures. This observation motivates our proposed\nmethod, Mixture of Dyadic Experts (MoDE), which introduces a novel design for\nefficient multi-task adaptation. This is done by sharing the down-projection\nmatrix across tasks and employing atomic rank-one adapters, coupled with\nrouters that allow more sophisticated task-level specialization. Our design\nallows for more fine-grained mixing, thereby increasing the model's ability to\njointly handle multiple tasks. We evaluate MoDE on the Supernatural\nInstructions (SNI) benchmark consisting of a diverse set of 700+ tasks and\ndemonstrate that it outperforms state-of-the-art multi-task parameter-efficient\nfine-tuning (PEFT) methods, without introducing additional parameters. Our\nfindings contribute to a deeper understanding of parameter efficiency in\nmulti-task LLM adaptation and provide a practical solution for deploying\nhigh-performing, lightweight models.", "published": "2024-08-02 18:05:10", "link": "http://arxiv.org/abs/2408.01505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fairness in Large Language Models in Three Hours", "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.", "published": "2024-08-02 03:44:14", "link": "http://arxiv.org/abs/2408.00992v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Encoder-only Large Language Models for Mobile App Review\n  Feature Extraction", "abstract": "Mobile app review analysis presents unique challenges due to the low quality,\nsubjective bias, and noisy content of user-generated documents. Extracting\nfeatures from these reviews is essential for tasks such as feature\nprioritization and sentiment analysis, but it remains a challenging task.\nMeanwhile, encoder-only models based on the Transformer architecture have shown\npromising results for classification and information extraction tasks for\nmultiple software engineering processes. This study explores the hypothesis\nthat encoder-only large language models can enhance feature extraction from\nmobile app reviews. By leveraging crowdsourced annotations from an industrial\ncontext, we redefine feature extraction as a supervised token classification\ntask. Our approach includes extending the pre-training of these models with a\nlarge corpus of user reviews to improve contextual understanding and employing\ninstance selection techniques to optimize model fine-tuning. Empirical\nevaluations demonstrate that this method improves the precision and recall of\nextracted features and enhances performance efficiency. Key contributions\ninclude a novel approach to feature extraction, annotated datasets, extended\npre-trained models, and an instance selection mechanism for cost-effective\nfine-tuning. This research provides practical methods and empirical evidence in\napplying large language models to natural language processing tasks within\nmobile app reviews, offering improved performance in feature extraction.", "published": "2024-08-02 07:31:57", "link": "http://arxiv.org/abs/2408.01063v2", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs", "abstract": "Entity Alignment (EA) aims to match equivalent entities in different\nKnowledge Graphs (KGs), which is essential for knowledge fusion and\nintegration. Recently, embedding-based EA has attracted significant attention\nand many approaches have been proposed. Early approaches primarily focus on\nlearning entity embeddings from the structural features of KGs, defined by\nrelation triples. Later methods incorporated entities' names and attributes as\nauxiliary information to enhance embeddings for EA. However, these approaches\noften used different techniques to encode structural and attribute information,\nlimiting their interaction and mutual enhancement. In this work, we propose a\ndense entity retrieval framework for EA, leveraging language models to\nuniformly encode various features of entities and facilitate nearest entity\nsearch across KGs. Alignment candidates are first generated through entity\nretrieval, which are subsequently reranked to determine the final alignments.\nWe conduct comprehensive experiments on both cross-lingual and monolingual EA\ndatasets, demonstrating that our approach achieves state-of-the-art performance\ncompared to existing EA methods.", "published": "2024-08-02 10:12:42", "link": "http://arxiv.org/abs/2408.01154v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Misinforming LLMs: vulnerabilities, challenges and opportunities", "abstract": "Large Language Models (LLMs) have made significant advances in natural\nlanguage processing, but their underlying mechanisms are often misunderstood.\nDespite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely\non statistical patterns in word embeddings rather than true cognitive\nprocesses. This leads to vulnerabilities such as \"hallucination\" and\nmisinformation. The paper argues that current LLM architectures are inherently\nuntrustworthy due to their reliance on correlations of sequential patterns of\nword embedding vectors. However, ongoing research into combining generative\ntransformer-based models with fact bases and logic programming languages may\nlead to the development of trustworthy LLMs capable of generating statements\nbased on given truth and explaining their self-reasoning process.", "published": "2024-08-02 10:35:49", "link": "http://arxiv.org/abs/2408.01168v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models", "abstract": "High-throughput phenotyping automates the mapping of patient signs to\nstandardized ontology concepts and is essential for precision medicine. This\nstudy evaluates the automation of phenotyping of clinical summaries from the\nOnline Mendelian Inheritance in Man (OMIM) database using large language\nmodels. Due to their rich phenotype data, these summaries can be surrogates for\nphysician notes. We conduct a performance comparison of GPT-4 and\nGPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in\nidentifying, categorizing, and normalizing signs, achieving concordance with\nmanual annotators comparable to inter-rater agreement. Despite some limitations\nin sign normalization, the extensive pre-training of GPT-4 results in high\nperformance and generalizability across several phenotyping tasks while\nobviating the need for manually annotated training data. Large language models\nare expected to be the dominant method for automating high-throughput\nphenotyping of clinical text.", "published": "2024-08-02 12:00:00", "link": "http://arxiv.org/abs/2408.01214v1", "categories": ["cs.CL", "cs.AI", "I.7; I.2"], "primary_category": "cs.CL"}
{"title": "RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework", "abstract": "Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics: Completeness,\nHallucination, and Irrelevance to evaluate LLM generated responses rigorously.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications. The code and dataset are released at\nhttps://github.com/OpenBMB/RAGEval.", "published": "2024-08-02 13:35:11", "link": "http://arxiv.org/abs/2408.01262v5", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Mismeasure of Man and Models: Evaluating Allocational Harms in Large\n  Language Models", "abstract": "Large language models (LLMs) are now being considered and even deployed for\napplications that support high-stakes decision-making, such as recruitment and\nclinical decisions. While several methods have been proposed for measuring\nbias, there remains a gap between predictions, which are what the proposed\nmethods consider, and how they are used to make decisions. In this work, we\nintroduce Rank-Allocational-Based Bias Index (RABBI), a model-agnostic bias\nmeasure that assesses potential allocational harms arising from biases in LLM\npredictions. We compare RABBI and current bias metrics on two allocation\ndecision tasks. We evaluate their predictive validity across ten LLMs and\nutility for model selection. Our results reveal that commonly-used bias metrics\nbased on average performance gap and distribution distance fail to reliably\ncapture group disparities in allocation outcomes, whereas RABBI exhibits a\nstrong correlation with allocation disparities. Our work highlights the need to\naccount for how models are used in contexts with limited resource constraints.", "published": "2024-08-02 14:13:06", "link": "http://arxiv.org/abs/2408.01285v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Deep Learning based Visually Rich Document Content Understanding: A\n  Survey", "abstract": "Visually Rich Documents (VRDs) are essential in academia, finance, medical\nfields, and marketing due to their multimodal information content. Traditional\nmethods for extracting information from VRDs depend on expert knowledge and\nmanual labor, making them costly and inefficient. The advent of deep learning\nhas revolutionized this process, introducing models that leverage multimodal\ninformation vision, text, and layout along with pretraining tasks to develop\ncomprehensive document representations. These models have achieved\nstate-of-the-art performance across various downstream tasks, significantly\nenhancing the efficiency and accuracy of information extraction from VRDs. In\nresponse to the growing demands and rapid developments in Visually Rich\nDocument Understanding (VRDU), this paper provides a comprehensive review of\ndeep learning-based VRDU frameworks. We systematically survey and analyze\nexisting methods and benchmark datasets, categorizing them based on adopted\nstrategies and downstream tasks. Furthermore, we compare different techniques\nused in VRDU models, focusing on feature representation and fusion, model\narchitecture, and pretraining methods, while highlighting their strengths,\nlimitations, and appropriate scenarios. Finally, we identify emerging trends\nand challenges in VRDU, offering insights into future research directions and\npractical applications. This survey aims to provide a thorough understanding of\nVRDU advancements, benefiting both academic and industrial sectors.", "published": "2024-08-02 14:19:34", "link": "http://arxiv.org/abs/2408.01287v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Transformers are Universal In-context Learners", "abstract": "Transformers are deep architectures that define \"in-context mappings\" which\nenable predicting new tokens based on a given set of tokens (such as a prompt\nin NLP applications or a set of patches for a vision transformer). In this\nwork, we study in particular the ability of these architectures to handle an\narbitrarily large number of context tokens. To mathematically, uniformly\naddress their expressivity, we consider the case that the mappings are\nconditioned on a context represented by a probability distribution of tokens\nwhich becomes discrete for a finite number of these. The relevant notion of\nsmoothness then corresponds to continuity in terms of the Wasserstein distance\nbetween these contexts. We demonstrate that deep transformers are universal and\ncan approximate continuous in-context mappings to arbitrary precision,\nuniformly over compact token domains. A key aspect of our results, compared to\nexisting findings, is that for a fixed precision, a single transformer can\noperate on an arbitrary (even infinite) number of tokens. Additionally, it\noperates with a fixed embedding dimension of tokens (this dimension does not\nincrease with precision) and a fixed number of heads (proportional to the\ndimension). The use of MLPs between multi-head attention layers is also\nexplicitly controlled. We consider both unmasked attentions (as used for the\nvision transformer) and masked causal attentions (as used for NLP and time\nseries applications). We tackle the causal setting leveraging a space-time\nlifting to analyze causal attention as a mapping over probability distributions\nof tokens.", "published": "2024-08-02 16:21:48", "link": "http://arxiv.org/abs/2408.01367v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM\n  Auto-Prompting", "abstract": "Large Language Models (LLMs) exhibit remarkable proficiency in addressing a\ndiverse array of tasks within the Natural Language Processing (NLP) domain,\nwith various prompt design strategies significantly augmenting their\ncapabilities. However, these prompts, while beneficial, each possess inherent\nlimitations. The primary prompt design methodologies are twofold: The first,\nexemplified by the Chain of Thought (CoT), involves manually crafting prompts\nspecific to individual datasets, hence termed Expert-Designed Prompts (EDPs).\nOnce these prompts are established, they are unalterable, and their\neffectiveness is capped by the expertise of the human designers. When applied\nto LLMs, the static nature of EDPs results in a uniform approach to both simple\nand complex problems within the same dataset, leading to the inefficient use of\ntokens for straightforward issues. The second method involves prompts\nautonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which\nprovide tailored solutions to specific problems, mitigating the limitations of\nEDPs. However, LDPs may encounter a decline in performance when tackling\ncomplex problems due to the potential for error accumulation during the\nsolution planning process. To address these challenges, we have conceived a\nnovel Prompt Recursive Search (PRS) framework that leverages the LLM to\ngenerate solutions specific to the problem, thereby conserving tokens. The\nframework incorporates an assessment of problem complexity and an adjustable\nstructure, ensuring a reduction in the likelihood of errors. We have\nsubstantiated the efficacy of PRS framework through extensive experiments using\nLLMs with different numbers of parameters across a spectrum of datasets in\nvarious domains. Compared to the CoT method, the PRS method has increased the\naccuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%\nimprovement.", "published": "2024-08-02 17:59:42", "link": "http://arxiv.org/abs/2408.01423v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized\n  Language Prompting", "abstract": "Understanding the nuances of a user's extensive interaction history is key to\nbuilding accurate and personalized natural language systems that can adapt to\nevolving user preferences. To address this, we introduce PERSOMA, Personalized\nSoft Prompt Adapter architecture. Unlike previous personalized prompting\nmethods for large language models, PERSOMA offers a novel approach to\nefficiently capture user history. It achieves this by resampling and\ncompressing interactions as free form text into expressive soft prompt\nembeddings, building upon recent research utilizing embedding representations\nas input for LLMs. We rigorously validate our approach by evaluating various\nadapter architectures, first-stage sampling strategies, parameter-efficient\ntuning techniques like LoRA, and other personalization methods. Our results\ndemonstrate PERSOMA's superior ability to handle large and complex user\nhistories compared to existing embedding-based and text-prompt-based\ntechniques.", "published": "2024-08-02 00:24:22", "link": "http://arxiv.org/abs/2408.00960v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ArchCode: Incorporating Software Requirements in Code Generation with\n  Large Language Models", "abstract": "This paper aims to extend the code generation capability of large language\nmodels (LLMs) to automatically manage comprehensive software requirements from\ngiven textual descriptions. Such requirements include both functional (i.e.\nachieving expected behavior for inputs) and non-functional (e.g., time/space\nperformance, robustness, maintainability) requirements. However, textual\ndescriptions can either express requirements verbosely or may even omit some of\nthem. We introduce ARCHCODE, a novel framework that leverages in-context\nlearning to organize requirements observed in descriptions and to extrapolate\nunexpressed requirements from them. ARCHCODE generates requirements from given\ndescriptions, conditioning them to produce code snippets and test cases. Each\ntest case is tailored to one of the requirements, allowing for the ranking of\ncode snippets based on the compliance of their execution results with the\nrequirements. Public benchmarks show that ARCHCODE enhances to satisfy\nfunctional requirements, significantly improving Pass@k scores. Furthermore, we\nintroduce HumanEval-NFR, the first evaluation of LLMs' non-functional\nrequirements in code generation, demonstrating ARCHCODE's superiority over\nbaseline methods. The implementation of ARCHCODE and the HumanEval-NFR\nbenchmark are both publicly accessible.", "published": "2024-08-02 03:54:36", "link": "http://arxiv.org/abs/2408.00994v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Enhancing Financial Market Predictions: Causality-Driven Feature\n  Selection", "abstract": "This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).", "published": "2024-08-02 04:40:15", "link": "http://arxiv.org/abs/2408.01005v1", "categories": ["cs.LG", "cs.CE", "cs.CL", "cs.DB"], "primary_category": "cs.LG"}
{"title": "The Impact of Hyperparameters on Large Language Model Inference\n  Performance: An Evaluation of vLLM and HuggingFace Pipelines", "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.", "published": "2024-08-02 06:56:59", "link": "http://arxiv.org/abs/2408.01050v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "General-purpose Dataflow Model with Neuromorphic Primitives", "abstract": "Neuromorphic computing exhibits great potential to provide high-performance\nbenefits in various applications beyond neural networks. However, a\ngeneral-purpose program execution model that aligns with the features of\nneuromorphic computing is required to bridge the gap between program\nversatility and neuromorphic hardware efficiency. The dataflow model offers a\npotential solution, but it faces high graph complexity and incompatibility with\nneuromorphic hardware when dealing with control flow programs, which decreases\nthe programmability and performance. Here, we present a dataflow model tailored\nfor neuromorphic hardware, called neuromorphic dataflow, which provides a\ncompact, concise, and neuromorphic-compatible program representation for\ncontrol logic. The neuromorphic dataflow introduces \"when\" and \"where\"\nprimitives, which restructure the view of control. The neuromorphic dataflow\nembeds these primitives in the dataflow schema with the plasticity inherited\nfrom the spiking algorithms. Our method enables the deployment of\ngeneral-purpose programs on neuromorphic hardware with both programmability and\nplasticity, while fully utilizing the hardware's potential.", "published": "2024-08-02 08:09:13", "link": "http://arxiv.org/abs/2408.01090v1", "categories": ["cs.CL", "cs.AR", "cs.NE"], "primary_category": "cs.CL"}
{"title": "BioRAG: A RAG-LLM Framework for Biological Question Reasoning", "abstract": "The question-answering system for Life science research, which is\ncharacterized by the rapid pace of discovery, evolving insights, and complex\ninteractions among knowledge entities, presents unique challenges in\nmaintaining a comprehensive knowledge warehouse and accurate information\nretrieval. To address these issues, we introduce BioRAG, a novel\nRetrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)\nframework. Our approach starts with parsing, indexing, and segmenting an\nextensive collection of 22 million scientific papers as the basic knowledge,\nfollowed by training a specialized embedding model tailored to this domain.\nAdditionally, we enhance the vector retrieval process by incorporating a\ndomain-specific knowledge hierarchy, which aids in modeling the intricate\ninterrelationships among each query and context. For queries requiring the most\ncurrent information, BioRAG deconstructs the question and employs an iterative\nretrieval process incorporated with the search engine for step-by-step\nreasoning. Rigorous experiments have demonstrated that our model outperforms\nfine-tuned LLM, LLM with search engines, and other scientific RAG frameworks\nacross multiple life science question-answering tasks.", "published": "2024-08-02 08:37:03", "link": "http://arxiv.org/abs/2408.01107v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompt Refinement or Fine-tuning? Best Practices for using LLMs in\n  Computational Social Science Tasks", "abstract": "Large Language Models are expressive tools that enable complex tasks of text\nunderstanding within Computational Social Science. Their versatility, while\nbeneficial, poses a barrier for establishing standardized best practices within\nthe field. To bring clarity on the values of different strategies, we present\nan overview of the performance of modern LLM-based classification methods on a\nbenchmark of 23 social knowledge tasks. Our results point to three best\npractices: select models with larger vocabulary and pre-training corpora; avoid\nsimple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific\ndata, and consider more complex forms instruction-tuning on multiple datasets\nonly when only training data is more abundant.", "published": "2024-08-02 15:46:36", "link": "http://arxiv.org/abs/2408.01346v1", "categories": ["cs.CY", "cs.CL", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "Toward Automatic Relevance Judgment using Vision--Language Models for\n  Image--Text Retrieval Evaluation", "abstract": "Vision--Language Models (VLMs) have demonstrated success across diverse\napplications, yet their potential to assist in relevance judgments remains\nuncertain. This paper assesses the relevance estimation capabilities of VLMs,\nincluding CLIP, LLaVA, and GPT-4V, within a large-scale \\textit{ad hoc}\nretrieval task tailored for multimedia content creation in a zero-shot fashion.\nPreliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,\nencompassing open-source and closed-source visual-instruction-tuned Large\nLanguage Models (LLMs), achieve notable Kendall's $\\tau \\sim 0.4$ when compared\nto human relevance judgments, surpassing the CLIPScore metric. (2) While\nCLIPScore is strongly preferred, LLMs are less biased towards CLIP-based\nretrieval systems. (3) GPT-4V's score distribution aligns more closely with\nhuman judgments than other models, achieving a Cohen's $\\kappa$ value of around\n0.08, which outperforms CLIPScore at approximately -0.096. These findings\nunderscore the potential of LLM-powered VLMs in enhancing relevance judgments.", "published": "2024-08-02 16:15:25", "link": "http://arxiv.org/abs/2408.01363v1", "categories": ["cs.IR", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of\n  Decision Transformer", "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.", "published": "2024-08-02 17:25:34", "link": "http://arxiv.org/abs/2408.01402v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Talk Less, Interact Better: Evaluating In-context Conversational\n  Adaptation in Multimodal LLMs", "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.", "published": "2024-08-02 17:51:57", "link": "http://arxiv.org/abs/2408.01417v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs", "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.", "published": "2024-08-02 17:55:50", "link": "http://arxiv.org/abs/2408.01420v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors\n  for a Robotics Course", "abstract": "This study evaluates the performance of Large Language Models (LLMs) as an\nArtificial Intelligence-based tutor for a university course. In particular,\ndifferent advanced techniques are utilized, such as prompt engineering,\nRetrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the\ndifferent models and applied techniques using common similarity metrics like\nBLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of\nhelpfulness and trustworthiness. Our findings indicate that RAG combined with\nprompt engineering significantly enhances model responses and produces better\nfactual answers. In the context of education, RAG appears as an ideal technique\nas it is based on enriching the input of the model with additional information\nand material which usually is already present for a university course.\nFine-tuning, on the other hand, can produce quite small, still strong expert\nmodels, but poses the danger of overfitting. Our study further asks how we\nmeasure performance of LLMs and how well current measurements represent\ncorrectness or relevance? We find high correlation on similarity metrics and a\nbias of most of these metrics towards shorter responses. Overall, our research\npoints to both the potential and challenges of integrating LLMs in educational\nsettings, suggesting a need for balanced training approaches and advanced\nevaluation frameworks.", "published": "2024-08-02 19:49:19", "link": "http://arxiv.org/abs/2408.04645v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.RO"], "primary_category": "cs.CL"}
{"title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language\n  Models", "abstract": "Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.", "published": "2024-08-02 15:34:05", "link": "http://arxiv.org/abs/2408.01337v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Using LLMs to Establish Implicit User Sentiment of Software Desirability", "abstract": "This study explores the use of LLMs for providing quantitative zero-shot\nsentiment analysis of implicit software desirability, addressing a critical\nchallenge in product evaluation where traditional review scores, though\nconvenient, fail to capture the richness of qualitative user feedback.\nInnovations include establishing a method that 1) works with qualitative user\nexperience data without the need for explicit review scores, 2) focuses on\nimplicit user satisfaction, and 3) provides scaled numerical sentiment\nanalysis, offering a more nuanced understanding of user sentiment, instead of\nsimply classifying sentiment as positive, neutral, or negative.\n  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a\nwell-known qualitative user experience analysis tool. For initial exploration,\nthe PDT metric was given to users of two software systems. PDT data was fed\nthrough several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a\nleading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,\na leading sentiment analysis tool. Each system was asked to evaluate the data\nin two ways, by looking at the sentiment expressed in the PDT word/explanation\npairs; and by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM provided a\nsentiment score, its confidence (low, medium, high) in the score, and an\nexplanation of the score.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding user\nsentiment. This study adds deeper understanding of evaluating user experiences,\ntoward the goal of creating a universal tool that quantifies implicit\nsentiment.", "published": "2024-08-02 18:40:10", "link": "http://arxiv.org/abs/2408.01527v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.SE", "I.2.7; D.2.8; I.2.6; H.5.2"], "primary_category": "cs.CL"}
{"title": "A General-Purpose Device for Interaction with LLMs", "abstract": "This paper investigates integrating large language models (LLMs) with\nadvanced hardware, focusing on developing a general-purpose device designed for\nenhanced interaction with LLMs. Initially, we analyze the current landscape,\nwhere virtual assistants and LLMs are reshaping human-technology interactions,\nhighlighting pivotal advancements and setting the stage for a new era of\nintelligent hardware. Despite substantial progress in LLM technology, a\nsignificant gap exists in hardware development, particularly concerning\nscalability, efficiency, affordability, and multimodal capabilities. This\ndisparity presents both challenges and opportunities, underscoring the need for\nhardware that is not only powerful but also versatile and capable of managing\nthe sophisticated demands of modern computation. Our proposed device addresses\nthese needs by emphasizing scalability, multimodal data processing, enhanced\nuser interaction, and privacy considerations, offering a comprehensive platform\nfor LLM integration in various applications.", "published": "2024-08-02 23:43:29", "link": "http://arxiv.org/abs/2408.10230v1", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.AR"}
{"title": "PiCoGen2: Piano cover generation with transfer learning approach and\n  weakly aligned data", "abstract": "Piano cover generation aims to create a piano cover from a pop song. Existing\napproaches mainly employ supervised learning and the training demands\nstrongly-aligned and paired song-to-piano data, which is built by remapping\npiano notes to song audio. This would, however, result in the loss of piano\ninformation and accordingly cause inconsistencies between the original and\nremapped piano versions. To overcome this limitation, we propose a transfer\nlearning approach that pre-trains our model on piano-only data and fine-tunes\nit on weakly-aligned paired data constructed without note remapping. During\npre-training, to guide the model to learn piano composition concepts instead of\nmerely transcribing audio, we use an existing lead sheet transcription model as\nthe encoder to extract high-level features from the piano recordings. The\npre-trained model is then fine-tuned on the paired song-piano data to transfer\nthe learned composition knowledge to the pop song domain. Our evaluation shows\nthat this training strategy enables our model, named PiCoGen2, to attain\nhigh-quality results, outperforming baselines on both objective and subjective\nmetrics across five pop genres.", "published": "2024-08-02 19:45:18", "link": "http://arxiv.org/abs/2408.01551v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with\n  Transformers and Novel Encoding", "abstract": "We introduce a project that revives a piece of 15th-century Korean court\nmusic, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the\nDragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean\nmusical notation system, the remaining version only consists of a rudimentary\nmelody. Our research team, commissioned by the National Gugak (Korean\nTraditional Music) Center, aimed to transform this old melody into a\nperformable arrangement for a six-part ensemble. Using Jeongganbo data acquired\nthrough bespoke optical music recognition, we trained a BERT-like masked\nlanguage model and an encoder-decoder transformer model. We also propose an\nencoding scheme that strictly follows the structure of Jeongganbo and denotes\nnote durations as positions. The resulting machine-transformed version of\nChihwapyeong and Chwipunghyeong were evaluated by experts and performed by the\nCourt Music Orchestra of National Gugak Center. Our work demonstrates that\ngenerative models can successfully be applied to traditional music with limited\ntraining data if combined with careful design.", "published": "2024-08-02 08:16:55", "link": "http://arxiv.org/abs/2408.01096v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in\n  Symbolic Music and Audio Generation", "abstract": "Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.", "published": "2024-08-02 11:02:38", "link": "http://arxiv.org/abs/2408.01180v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot\n  Learning: A General Framework", "abstract": "Generalized Zero-Shot Learning (GZSL) is a challenging task requiring\naccurate classification of both seen and unseen classes. Within this domain,\nAudio-visual GZSL emerges as an extremely exciting yet difficult task, given\nthe inclusion of both visual and acoustic features as multi-modal inputs.\nExisting efforts in this field mostly utilize either embedding-based or\ngenerative-based methods. However, generative training is difficult and\nunstable, while embedding-based methods often encounter domain shift problem.\nThus, we find it promising to integrate both methods into a unified framework\nto leverage their advantages while mitigating their respective disadvantages.\nOur study introduces a general framework employing out-of-distribution (OOD)\ndetection, aiming to harness the strengths of both approaches. We first employ\ngenerative adversarial networks to synthesize unseen features, enabling the\ntraining of an OOD detector alongside classifiers for seen and unseen classes.\nThis detector determines whether a test feature belongs to seen or unseen\nclasses, followed by classification utilizing separate classifiers for each\nfeature type. We test our framework on three popular audio-visual datasets and\nobserve a significant improvement comparing to existing state-of-the-art works.\nCodes can be found in https://github.com/liuyuan-wen/AV-OOD-GZSL.", "published": "2024-08-02 14:10:20", "link": "http://arxiv.org/abs/2408.01284v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "cs.MM"}
{"title": "Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and\n  Localization", "abstract": "In the digital age, the emergence of deepfakes and synthetic media presents a\nsignificant threat to societal and political integrity. Deepfakes based on\nmulti-modal manipulation, such as audio-visual, are more realistic and pose a\ngreater threat. Current multi-modal deepfake detectors are often based on the\nattention-based fusion of heterogeneous data streams from multiple modalities.\nHowever, the heterogeneous nature of the data (such as audio and visual\nsignals) creates a distributional modality gap and poses a significant\nchallenge in effective fusion and hence multi-modal deepfake detection. In this\npaper, we propose a novel multi-modal attention framework based on recurrent\nneural networks (RNNs) that leverages contextual information for audio-visual\ndeepfake detection. The proposed approach applies attention to multi-modal\nmulti-sequence representations and learns the contributing features among them\nfor deepfake detection and localization. Thorough experimental validations on\naudio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and\nLAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison\nwith the published studies demonstrates superior performance of our approach\nwith an improved accuracy and precision by 3.47% and 2.05% in deepfake\ndetection and localization, respectively. Thus, obtaining state-of-the-art\nperformance. To facilitate reproducibility, the code and the datasets\ninformation is available at https://github.com/vcbsl/audiovisual-deepfake/.", "published": "2024-08-02 18:45:01", "link": "http://arxiv.org/abs/2408.01532v2", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
