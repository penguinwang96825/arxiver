{"title": "Counterfactually Probing Language Identity in Multilingual Models", "abstract": "Techniques in causal analysis of language models illuminate how linguistic\ninformation is organized in LLMs. We use one such technique, AlterRep, a method\nof counterfactual probing, to explore the internal structure of multilingual\nmodels (mBERT and XLM-R). We train a linear classifier on a binary language\nidentity task, to classify tokens between Language X and Language Y. Applying a\ncounterfactual probing procedure, we use the classifier weights to project the\nembeddings into the null space and push the resulting embeddings either in the\ndirection of Language X or Language Y. Then we evaluate on a masked language\nmodeling task. We find that, given a template in Language X, pushing towards\nLanguage Y systematically increases the probability of Language Y words, above\nand beyond a third-party control language. But it does not specifically push\nthe model towards translation-equivalent words in Language Y. Pushing towards\nLanguage X (the same direction as the template) has a minimal effect, but\nsomewhat degrades these models. Overall, we take these results as further\nevidence of the rich structure of massive multilingual language models, which\ninclude both a language-specific and language-general component. And we show\nthat counterfactual probing can be fruitfully applied to multilingual models.", "published": "2023-10-29 01:21:36", "link": "http://arxiv.org/abs/2310.18862v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrofitting Light-weight Language Models for Emotions using Supervised\n  Contrastive Learning", "abstract": "We present a novel retrofitting method to induce emotion aspects into\npre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates\npre-trained network weights using contrastive learning so that the text\nfragments exhibiting similar emotions are encoded nearby in the representation\nspace, and the fragments with different emotion content are pushed apart. While\ndoing so, it also ensures that the linguistic knowledge already present in PLMs\nis not inadvertently perturbed. The language models retrofitted by our method,\ni.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as\nevaluated through different clustering and retrieval metrics. For the\ndownstream tasks on sentiment analysis and sarcasm detection, they perform\nbetter than their pre-trained counterparts (about 1% improvement in F1-score)\nand other existing approaches. Additionally, a more significant boost in\nperformance is observed for the retrofitted models over pre-trained ones in\nfew-shot learning setting.", "published": "2023-10-29 07:43:34", "link": "http://arxiv.org/abs/2310.18930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S2F-NER: Exploring Sequence-to-Forest Generation for Complex Entity\n  Recognition", "abstract": "Named Entity Recognition (NER) remains challenging due to the complex\nentities, like nested, overlapping, and discontinuous entities. Existing\napproaches, such as sequence-to-sequence (Seq2Seq) generation and span-based\nclassification, have shown impressive performance on various NER subtasks, but\nthey are difficult to scale to datasets with longer input text because of\neither exposure bias issue or inefficient computation. In this paper, we\npropose a novel Sequence-to-Forest generation paradigm, S2F-NER, which can\ndirectly extract entities in sentence via a Forest decoder that decode multiple\nentities in parallel rather than sequentially. Specifically, our model generate\neach path of each tree in forest autoregressively, where the maximum depth of\neach tree is three (which is the shortest feasible length for complex NER and\nis far smaller than the decoding length of Seq2Seq). Based on this novel\nparadigm, our model can elegantly mitigates the exposure bias problem and keep\nthe simplicity of Seq2Seq. Experimental results show that our model\nsignificantly outperforms the baselines on three discontinuous NER datasets and\non two nested NER datasets, especially for discontinuous entity recognition.", "published": "2023-10-29 09:09:10", "link": "http://arxiv.org/abs/2310.18944v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate\n  speech detection", "abstract": "In the evolving landscape of online communication, hate speech detection\nremains a formidable challenge, further compounded by the diversity of digital\nplatforms. This study investigates the effectiveness and adaptability of\npre-trained and fine-tuned Large Language Models (LLMs) in identifying hate\nspeech, to address two central questions: (1) To what extent does the model\nperformance depend on the fine-tuning and training parameters?, (2) To what\nextent do models generalize to cross-domain hate speech detection? and (3) What\nare the specific features of the datasets or models that influence the\ngeneralization potential? The experiment shows that LLMs offer a huge advantage\nover the state-of-the-art even without pretraining. Ordinary least squares\nanalyses suggest that the advantage of training with fine-grained hate speech\nlabels is washed away with the increase in dataset size. We conclude with a\nvision for the future of hate speech detection, emphasizing cross-domain\ngeneralizability and appropriate benchmarking practices.", "published": "2023-10-29 10:07:32", "link": "http://arxiv.org/abs/2310.18964v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SALMA: Arabic Sense-Annotated Corpus and WSD Benchmarks", "abstract": "SALMA, the first Arabic sense-annotated corpus, consists of ~34K tokens,\nwhich are all sense-annotated. The corpus is annotated using two different\nsense inventories simultaneously (Modern and Ghani). SALMA novelty lies in how\ntokens and senses are associated. Instead of linking a token to only one\nintended sense, SALMA links a token to multiple senses and provides a score to\neach sense. A smart web-based annotation tool was developed to support scoring\nmultiple senses against a given word. In addition to sense annotations, we also\nannotated the corpus using six types of named entities. The quality of our\nannotations was assessed using various metrics (Kappa, Linear Weighted Kappa,\nQuadratic Weighted Kappa, Mean Average Error, and Root Mean Square Error),\nwhich show very high inter-annotator agreement. To establish a Word Sense\nDisambiguation baseline using our SALMA corpus, we developed an end-to-end Word\nSense Disambiguation system using Target Sense Verification. We used this\nsystem to evaluate three Target Sense Verification models available in the\nliterature. Our best model achieved an accuracy with 84.2% using Modern and\n78.7% using Ghani. The full corpus and the annotation tool are open-source and\npublicly available at https://sina.birzeit.edu/salma/.", "published": "2023-10-29 14:36:37", "link": "http://arxiv.org/abs/2310.19029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ArBanking77: Intent Detection Neural Model and a New Dataset in Modern\n  and Dialectical Arabic", "abstract": "This paper presents the ArBanking77, a large Arabic dataset for intent\ndetection in the banking domain. Our dataset was arabized and localized from\nthe original English Banking77 dataset, which consists of 13,083 queries to\nArBanking77 dataset with 31,404 queries in both Modern Standard Arabic (MSA)\nand Palestinian dialect, with each query classified into one of the 77 classes\n(intents). Furthermore, we present a neural model, based on AraBERT, fine-tuned\non ArBanking77, which achieved an F1-score of 0.9209 and 0.8995 on MSA and\nPalestinian dialect, respectively. We performed extensive experimentation in\nwhich we simulated low-resource settings, where the model is trained on a\nsubset of the data and augmented with noisy queries to simulate colloquial\nterms, mistakes and misspellings found in real NLP systems, especially live\nchat queries. The data and the models are publicly available at\nhttps://sina.birzeit.edu/arbanking77.", "published": "2023-10-29 14:46:11", "link": "http://arxiv.org/abs/2310.19034v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Few-Shot Learning Focused Survey on Recent Named Entity Recognition\n  and Relation Classification Methods", "abstract": "Named Entity Recognition (NER) and Relation Classification (RC) are important\nsteps in extracting information from unstructured text and formatting it into a\nmachine-readable format. We present a survey of recent deep learning models\nthat address named entity recognition and relation classification, with focus\non few-shot learning performance. Our survey is helpful for researchers in\nknowing the recent techniques in text mining and extracting structured\ninformation from raw text.", "published": "2023-10-29 16:02:46", "link": "http://arxiv.org/abs/2310.19055v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language\n  Models", "abstract": "Recursion is a prominent feature of human language, and fundamentally\nchallenging for self-attention due to the lack of an explicit recursive-state\ntracking mechanism. Consequently, Transformer language models poorly capture\nlong-tail recursive structure and exhibit sample-inefficient syntactic\ngeneralization. This work introduces Pushdown Layers, a new self-attention\nlayer that models recursive state via a stack tape that tracks estimated depths\nof every token in an incremental parse of the observed prefix. Transformer LMs\nwith Pushdown Layers are syntactic language models that autoregressively and\nsynchronously update this stack tape as they predict new tokens, in turn using\nthe stack tape to softly modulate attention over tokens -- for instance,\nlearning to \"skip\" over closed constituents. When trained on a corpus of\nstrings annotated with silver constituency parses, Transformers equipped with\nPushdown Layers achieve dramatically better and 3-5x more sample-efficient\nsyntactic generalization, while maintaining similar perplexities. Pushdown\nLayers are a drop-in replacement for standard self-attention. We illustrate\nthis by finetuning GPT2-medium with Pushdown Layers on an automatically parsed\nWikiText-103, leading to improvements on several GLUE text classification\ntasks.", "published": "2023-10-29 17:27:18", "link": "http://arxiv.org/abs/2310.19089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PACuna: Automated Fine-Tuning of Language Models for Particle\n  Accelerators", "abstract": "Navigating the landscape of particle accelerators has become increasingly\nchallenging with recent surges in contributions. These intricate devices\nchallenge comprehension, even within individual facilities. To address this, we\nintroduce PACuna, a fine-tuned language model refined through publicly\navailable accelerator resources like conferences, pre-prints, and books. We\nautomated data collection and question generation to minimize expert\ninvolvement and make the data publicly available. PACuna demonstrates\nproficiency in addressing intricate accelerator questions, validated by\nexperts. Our approach shows adapting language models to scientific domains by\nfine-tuning technical texts and auto-generated corpora capturing the latest\ndevelopments can further produce pre-trained models to answer some intricate\nquestions that commercially available assistants cannot and can serve as\nintelligent assistants for individual facilities.", "published": "2023-10-29 18:43:19", "link": "http://arxiv.org/abs/2310.19106v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Representation for Non-compositional and Compositional\n  Expressions", "abstract": "Accurate processing of non-compositional language relies on generating good\nrepresentations for such expressions. In this work, we study the representation\nof language non-compositionality by proposing a language model, PIER, that\nbuilds on BART and can create semantically meaningful and contextually\nappropriate representations for English potentially idiomatic expressions\n(PIEs). PIEs are characterized by their non-compositionality and contextual\nambiguity in their literal and idiomatic interpretations. Via intrinsic\nevaluation on embedding quality and extrinsic evaluation on PIE processing and\nNLU tasks, we show that representations generated by PIER result in 33% higher\nhomogeneity score for embedding clustering than BART, whereas 3.12% and 3.29%\ngains in accuracy and sequence accuracy for PIE sense classification and span\ndetection compared to the state-of-the-art IE representation model, GIEA. These\ngains are achieved without sacrificing PIER's performance on NLU tasks (+/- 1%\naccuracy) compared to BART.", "published": "2023-10-29 19:28:22", "link": "http://arxiv.org/abs/2310.19127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-Engineering and Transformer-based Question Generation and\n  Evaluation", "abstract": "Question generation has numerous applications in the educational context.\nQuestion generation can prove helpful for students when reviewing content and\ntesting themselves. Furthermore, a question generation model can aid teachers\nby lessening the burden of creating assessments and other practice material.\nThis paper aims to find the best method to generate questions from textual data\nthrough a transformer model and prompt engineering. In this research, we\nfinetuned a pretrained distilBERT model on the SQuAD question answering dataset\nto generate questions. In addition to training a transformer model, prompt\nengineering was applied to generate questions effectively using the LLaMA\nmodel. The generated questions were compared against the baseline questions in\nthe SQuAD dataset to evaluate the effectiveness of four different prompts. All\nfour prompts demonstrated over 60% similarity on average. Of the\nprompt-generated questions, 30% achieved a high similarity score greater than\n70%.", "published": "2023-10-29 01:45:30", "link": "http://arxiv.org/abs/2310.18867v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Stacking the Odds: Transformer-Based Ensemble for AI-Generated Text\n  Detection", "abstract": "This paper reports our submission under the team name `SynthDetectives' to\nthe ALTA 2023 Shared Task. We use a stacking ensemble of Transformers for the\ntask of AI-generated text detection. Our approach is novel in terms of its\nchoice of models in that we use accessible and lightweight models in the\nensemble. We show that ensembling the models results in an improved accuracy in\ncomparison with using them individually. Our approach achieves an accuracy\nscore of 0.9555 on the official test data provided by the shared task\norganisers.", "published": "2023-10-29 05:28:44", "link": "http://arxiv.org/abs/2310.18906v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sentence Bag Graph Formulation for Biomedical Distant Supervision\n  Relation Extraction", "abstract": "We introduce a novel graph-based framework for alleviating key challenges in\ndistantly-supervised relation extraction and demonstrate its effectiveness in\nthe challenging and important domain of biomedical data. Specifically, we\npropose a graph view of sentence bags referring to an entity pair, which\nenables message-passing based aggregation of information related to the entity\npair over the sentence bag. The proposed framework alleviates the common\nproblem of noisy labeling in distantly supervised relation extraction and also\neffectively incorporates inter-dependencies between sentences within a bag.\nExtensive experiments on two large-scale biomedical relation datasets and the\nwidely utilized NYT dataset demonstrate that our proposed framework\nsignificantly outperforms the state-of-the-art methods for biomedical distant\nsupervision relation extraction while also providing excellent performance for\nrelation extraction in the general text mining domain.", "published": "2023-10-29 05:48:04", "link": "http://arxiv.org/abs/2310.18912v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Bipartite Graph Pre-training for Unsupervised Extractive Summarization\n  with Graph Convolutional Auto-Encoders", "abstract": "Pre-trained sentence representations are crucial for identifying significant\nsentences in unsupervised document extractive summarization. However, the\ntraditional two-step paradigm of pre-training and sentence-ranking, creates a\ngap due to differing optimization objectives. To address this issue, we argue\nthat utilizing pre-trained embeddings derived from a process specifically\ndesigned to optimize cohensive and distinctive sentence representations helps\nrank significant sentences. To do so, we propose a novel graph pre-training\nauto-encoder to obtain sentence embeddings by explicitly modelling\nintra-sentential distinctive features and inter-sentential cohesive features\nthrough sentence-word bipartite graphs. These pre-trained sentence\nrepresentations are then utilized in a graph-based ranking algorithm for\nunsupervised summarization. Our method produces predominant performance for\nunsupervised summarization frameworks by providing summary-worthy sentence\nrepresentations. It surpasses heavy BERT- or RoBERTa-based sentence\nrepresentations in downstream tasks.", "published": "2023-10-29 12:27:18", "link": "http://arxiv.org/abs/2310.18992v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language\n  Modeling Likewise", "abstract": "Large Language Models (LLMs) exhibit impressive reasoning and data\naugmentation capabilities in various NLP tasks. However, what about small\nmodels? In this work, we propose TeacherLM-7.1B, capable of annotating relevant\nfundamentals, chain of thought, and common mistakes for most NLP samples, which\nmakes annotation more than just an answer, thus allowing other models to learn\n\"why\" instead of just \"what\". The TeacherLM-7.1B model achieved a zero-shot\nscore of 52.3 on MMLU, surpassing most models with over 100B parameters. Even\nmore remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we\naugmented 58 NLP datasets and taught various student models with different\nparameters from OPT and BLOOM series in a multi-task setting. The experimental\nresults indicate that the data augmentation provided by TeacherLM has brought\nsignificant benefits. We will release the TeacherLM series of models and\naugmented datasets as open-source.", "published": "2023-10-29 14:16:54", "link": "http://arxiv.org/abs/2310.19019v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Roles of Scaling and Instruction Tuning in Language Perception: Model\n  vs. Human Attention", "abstract": "Recent large language models (LLMs) have revealed strong abilities to\nunderstand natural language. Since most of them share the same basic structure,\ni.e. the transformer block, possible contributors to their success in the\ntraining process are scaling and instruction tuning. However, how these factors\naffect the models' language perception is unclear. This work compares the\nself-attention of several existing LLMs (LLaMA, Alpaca and Vicuna) in different\nsizes (7B, 13B, 30B, 65B), together with eye saccade, an aspect of human\nreading attention, to assess the effect of scaling and instruction tuning on\nlanguage perception. Results show that scaling enhances the human resemblance\nand improves the effective attention by reducing the trivial pattern reliance,\nwhile instruction tuning does not. However, instruction tuning significantly\nenhances the models' sensitivity to instructions. We also find that current\nLLMs are consistently closer to non-native than native speakers in attention,\nsuggesting a sub-optimal language perception of all models. Our code and data\nused in the analysis is available on GitHub.", "published": "2023-10-29 17:16:40", "link": "http://arxiv.org/abs/2310.19084v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Three Dogmas, a Puzzle and its Solution", "abstract": "Modern Logics, as formulated notably by Frege, Russell and Tarski involved\nbasic assumptions about Natural Languages in general and Indo-European\nLanguages in particular, which are contested by Linguists. Based upon those\nassumptions, formal Languages were designed to overcome what Logicians claimed\nto be 'defects' of Natural Language. In this paper we show that those\nassumptions contradict basic principles of Arabic. More specifically: The\nLogicians ideas, that within Natural Language words refer to objects,\n'ToBe'-constructions represent identity statements, Indefinite Descriptions\nmust be replaced by existential quantifiers to form meaningful Sentences and\nSymbols can have no interpretation-independent meanings, are all falsified\nusing undisputed principles of Arabic. The here presented falsification serves\ntwo purposes. First, it is used as a factual basis for the rejection of\napproaches adopting Semantic axioms of Mathematical Logics as Models for\nmeaning of Arabic Syntax. Second, it shows a way to approach the important\ncomputational problem: Satisfiability (SAT). The described way is based upon\nthe realization that parsing Arabic utilizes the existence of\n'meaning-particles' within Syntax to efficiently recognize words, phrases and\nSentences. Similar meaning-particles are shown to exist in 3CNF formulas,\nwhich, when properly handled within the machinery of 3SAT-Solvers, enable\nstructural conditions to be imposed on formulas, sufficient alone to guarantee\nthe efficient production of non-exponentially sized Free Binary Decision\nDiagrams (FBDDs). We show, why known exponential Lower Bounds on sizes of FBDDs\ndo not contradict our results and reveal practical evidence, obtained for\nmultiplication circuits, supporting our claims.", "published": "2023-10-29 19:20:38", "link": "http://arxiv.org/abs/2310.19123v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Women Wearing Lipstick: Measuring the Bias Between an Object and Its\n  Related Gender", "abstract": "In this paper, we investigate the impact of objects on gender bias in image\ncaptioning systems. Our results show that only gender-specific objects have a\nstrong gender bias (e.g., women-lipstick). In addition, we propose a visual\nsemantic-based gender score that measures the degree of bias and can be used as\na plug-in for any image captioning system. Our experiments demonstrate the\nutility of the gender score, since we observe that our score can measure the\nbias relation between a caption and its related gender; therefore, our score\ncan be used as an additional metric to the existing Object Gender Co-Occ\napproach. Code and data are publicly available at\n\\url{https://github.com/ahmedssabir/GenderScore}.", "published": "2023-10-29 19:39:03", "link": "http://arxiv.org/abs/2310.19130v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning to Follow Object-Centric Image Editing Instructions Faithfully", "abstract": "Natural language instructions are a powerful interface for editing the\noutputs of text-to-image diffusion models. However, several challenges need to\nbe addressed: 1) underspecification (the need to model the implicit meaning of\ninstructions) 2) grounding (the need to localize where the edit has to be\nperformed), 3) faithfulness (the need to preserve the elements of the image not\naffected by the edit instruction). Current approaches focusing on image editing\nwith natural language instructions rely on automatically generated paired data,\nwhich, as shown in our investigation, is noisy and sometimes nonsensical,\nexacerbating the above issues. Building on recent advances in segmentation,\nChain-of-Thought prompting, and visual question answering, we significantly\nimprove the quality of the paired data. In addition, we enhance the supervision\nsignal by highlighting parts of the image that need to be changed by the\ninstruction. The model fine-tuned on the improved data is capable of performing\nfine-grained object-centric edits better than state-of-the-art baselines,\nmitigating the problems outlined above, as shown by automatic and human\nevaluations. Moreover, our model is capable of generalizing to domains unseen\nduring training, such as visual metaphors.", "published": "2023-10-29 20:39:11", "link": "http://arxiv.org/abs/2310.19145v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Poisoning Retrieval Corpora by Injecting Adversarial Passages", "abstract": "Dense retrievers have achieved state-of-the-art performance in various\ninformation retrieval tasks, but to what extent can they be safely deployed in\nreal-world applications? In this work, we propose a novel attack for dense\nretrieval systems in which a malicious user generates a small number of\nadversarial passages by perturbing discrete tokens to maximize similarity with\na provided set of training queries. When these adversarial passages are\ninserted into a large retrieval corpus, we show that this attack is highly\neffective in fooling these systems to retrieve them for queries that were not\nseen by the attacker. More surprisingly, these adversarial passages can\ndirectly generalize to out-of-domain queries and corpora with a high success\nattack rate -- for instance, we find that 50 generated passages optimized on\nNatural Questions can mislead >94% of questions posed in financial documents or\nonline forums. We also benchmark and compare a range of state-of-the-art dense\nretrievers, both unsupervised and supervised. Although different systems\nexhibit varying levels of vulnerability, we show they can all be successfully\nattacked by injecting up to 500 passages, a small fraction compared to a\nretrieval corpus of millions of passages.", "published": "2023-10-29 21:13:31", "link": "http://arxiv.org/abs/2310.19156v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Robustifying Language Models with Test-Time Adaptation", "abstract": "Large-scale language models achieved state-of-the-art performance over a\nnumber of language tasks. However, they fail on adversarial language examples,\nwhich are sentences optimized to fool the language models but with similar\nsemantic meanings for humans. While prior work focuses on making the language\nmodel robust at training time, retraining for robustness is often unrealistic\nfor large-scale foundation models. Instead, we propose to make the language\nmodels robust at test time. By dynamically adapting the input sentence with\npredictions from masked words, we show that we can reverse many language\nadversarial attacks. Since our approach does not require any training, it works\nfor novel tasks at test time and can adapt to novel adversarial corruptions.\nVisualizations and empirical results on two popular sentence classification\ndatasets demonstrate that our method can repair adversarial language attacks\nover 65% o", "published": "2023-10-29 22:37:54", "link": "http://arxiv.org/abs/2310.19177v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Chatbots to PhishBots? -- Preventing Phishing scams created using\n  ChatGPT, Google Bard and Claude", "abstract": "The advanced capabilities of Large Language Models (LLMs) have made them\ninvaluable across various applications, from conversational agents and content\ncreation to data analysis, research, and innovation. However, their\neffectiveness and accessibility also render them susceptible to abuse for\ngenerating malicious content, including phishing attacks. This study explores\nthe potential of using four popular commercially available LLMs, i.e., ChatGPT\n(GPT 3.5 Turbo), GPT 4, Claude, and Bard, to generate functional phishing\nattacks using a series of malicious prompts. We discover that these LLMs can\ngenerate both phishing websites and emails that can convincingly imitate\nwell-known brands and also deploy a range of evasive tactics that are used to\nelude detection mechanisms employed by anti-phishing systems. These attacks can\nbe generated using unmodified or \"vanilla\" versions of these LLMs without\nrequiring any prior adversarial exploits such as jailbreaking. We evaluate the\nperformance of the LLMs towards generating these attacks and find that they can\nalso be utilized to create malicious prompts that, in turn, can be fed back to\nthe model to generate phishing scams - thus massively reducing the\nprompt-engineering effort required by attackers to scale these threats. As a\ncountermeasure, we build a BERT-based automated detection tool that can be used\nfor the early detection of malicious prompts to prevent LLMs from generating\nphishing content. Our model is transferable across all four commercial LLMs,\nattaining an average accuracy of 96% for phishing website prompts and 94% for\nphishing email prompts. We also disclose the vulnerabilities to the concerned\nLLMs, with Google acknowledging it as a severe issue. Our detection model is\navailable for use at Hugging Face, as well as a ChatGPT Actions plugin.", "published": "2023-10-29 22:52:40", "link": "http://arxiv.org/abs/2310.19181v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "MUST: A Multilingual Student-Teacher Learning approach for low-resource\n  speech recognition", "abstract": "Student-teacher learning or knowledge distillation (KD) has been previously\nused to address data scarcity issue for training of speech recognition (ASR)\nsystems. However, a limitation of KD training is that the student model classes\nmust be a proper or improper subset of the teacher model classes. It prevents\ndistillation from even acoustically similar languages if the character sets are\nnot same. In this work, the aforementioned limitation is addressed by proposing\na MUltilingual Student-Teacher (MUST) learning which exploits a posteriors\nmapping approach. A pre-trained mapping model is used to map posteriors from a\nteacher language to the student language ASR. These mapped posteriors are used\nas soft labels for KD learning. Various teacher ensemble schemes are\nexperimented to train an ASR model for low-resource languages. A model trained\nwith MUST learning reduces relative character error rate (CER) up to 9.5% in\ncomparison with a baseline monolingual ASR.", "published": "2023-10-29 01:38:36", "link": "http://arxiv.org/abs/2310.18865v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Pre-trained Speech Processing Models Contain Human-Like Biases that\n  Propagate to Speech Emotion Recognition", "abstract": "Previous work has established that a person's demographics and speech style\naffect how well speech processing models perform for them. But where does this\nbias come from? In this work, we present the Speech Embedding Association Test\n(SpEAT), a method for detecting bias in one type of model used for many speech\ntasks: pre-trained models. The SpEAT is inspired by word embedding association\ntests in natural language processing, which quantify intrinsic bias in a\nmodel's representations of different concepts, such as race or valence\n(something's pleasantness or unpleasantness) and capture the extent to which a\nmodel trained on large-scale socio-cultural data has learned human-like biases.\nUsing the SpEAT, we test for six types of bias in 16 English speech models\n(including 4 models also trained on multilingual data), which come from the\nwav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more\nmodels reveal positive valence (pleasantness) associations with abled people\nover disabled people, with European-Americans over African-Americans, with\nfemales over males, with U.S. accented speakers over non-U.S. accented\nspeakers, and with younger people over older people. Beyond establishing that\npre-trained speech models contain these biases, we also show that they can have\nreal world effects. We compare biases found in pre-trained models to biases in\ndownstream models adapted to the task of Speech Emotion Recognition (SER) and\nfind that in 66 of the 96 tests performed (69%), the group that is more\nassociated with positive valence as indicated by the SpEAT also tends to be\npredicted as speaking with higher valence by the downstream model. Our work\nprovides evidence that, like text and image-based models, pre-trained speech\nbased-models frequently learn human-like biases. Our work also shows that bias\nfound in pre-trained models can propagate to the downstream task of SER.", "published": "2023-10-29 02:27:56", "link": "http://arxiv.org/abs/2310.18877v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Debiasing Algorithm through Model Adaptation", "abstract": "Large language models are becoming the go-to solution for the ever-growing\nnumber of tasks. However, with growing capacity, models are prone to rely on\nspurious correlations stemming from biases and stereotypes present in the\ntraining data. This work proposes a novel method for detecting and mitigating\ngender bias in language models. We perform causal analysis to identify\nproblematic model components and discover that mid-upper feed-forward layers\nare most prone to convey bias. Based on the analysis results, we intervene in\nthe model by applying a linear projection to the weight matrices of these\nlayers. Our titular method, DAMA, significantly decreases bias as measured by\ndiverse metrics while maintaining the model's performance on downstream tasks.\nWe release code for our method and models, which retrain LLaMA's\nstate-of-the-art performance while being significantly less biased.", "published": "2023-10-29 05:50:03", "link": "http://arxiv.org/abs/2310.18913v4", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply\n  Systems", "abstract": "Reply suggestion systems represent a staple component of many instant\nmessaging and email systems. However, the requirement to produce sets of\nreplies, rather than individual replies, makes the task poorly suited for\nout-of-the-box retrieval architectures, which only consider individual\nmessage-reply similarity. As a result, these system often rely on additional\npost-processing modules to diversify the outputs. However, these approaches are\nultimately bottlenecked by the performance of the initial retriever, which in\npractice struggles to present a sufficiently diverse range of options to the\ndownstream diversification module, leading to the suggestions being less\nrelevant to the user. In this paper, we consider a novel approach that\nradically simplifies this pipeline through an autoregressive text-to-text\nretrieval model, that learns the smart reply task end-to-end from a dataset of\n(message, reply set) pairs obtained via bootstrapping. Empirical results show\nthis method consistently outperforms a range of state-of-the-art baselines\nacross three datasets, corresponding to a 5.1%-17.9% improvement in relevance,\nand a 0.5%-63.1% improvement in diversity compared to the best baseline\napproach. We make our code publicly available.", "published": "2023-10-29 09:56:17", "link": "http://arxiv.org/abs/2310.18956v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes", "abstract": "Etiquettes are an essential ingredient of day-to-day interactions among\npeople. Moreover, etiquettes are region-specific, and etiquettes in one region\nmight contradict those in other regions. In this paper, we propose EtiCor, an\nEtiquettes Corpus, having texts about social norms from five different regions\nacross the globe. The corpus provides a test bed for evaluating LLMs for\nknowledge and understanding of region-specific etiquettes. Additionally, we\npropose the task of Etiquette Sensitivity. We experiment with state-of-the-art\nLLMs (Delphi, Falcon40B, and GPT-3.5). Initial results indicate that LLMs,\nmostly fail to understand etiquettes from regions from non-Western world.", "published": "2023-10-29 10:47:23", "link": "http://arxiv.org/abs/2310.18974v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MILL: Mutual Verification with Large Language Models for Zero-Shot Query\n  Expansion", "abstract": "Query expansion, pivotal in search engines, enhances the representation of\nuser information needs with additional terms. While existing methods expand\nqueries using retrieved or generated contextual documents, each approach has\nnotable limitations. Retrieval-based methods often fail to accurately capture\nsearch intent, particularly with brief or ambiguous queries. Generation-based\nmethods, utilizing large language models (LLMs), generally lack corpus-specific\nknowledge and entail high fine-tuning costs. To address these gaps, we propose\na novel zero-shot query expansion framework utilizing LLMs for mutual\nverification. Specifically, we first design a query-query-document generation\nmethod, leveraging LLMs' zero-shot reasoning ability to produce diverse\nsub-queries and corresponding documents. Then, a mutual verification process\nsynergizes generated and retrieved documents for optimal expansion. Our\nproposed method is fully zero-shot, and extensive experiments on three public\nbenchmark datasets are conducted to demonstrate its effectiveness over existing\nmethods. Our code is available online at\nhttps://github.com/Applied-Machine-Learning-Lab/MILL to ease reproduction.", "published": "2023-10-29 16:04:10", "link": "http://arxiv.org/abs/2310.19056v3", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language\n  Understanding", "abstract": "Large-scale video-language pre-training has made remarkable strides in\nadvancing video-language understanding tasks. However, the heavy computational\nburden of video encoding remains a formidable efficiency bottleneck,\nparticularly for long-form videos. These videos contain massive visual tokens\ndue to their inherent 3D properties and spatiotemporal redundancy, making it\nchallenging to capture complex temporal and spatial relationships. To tackle\nthis issue, we propose an efficient method called TEmporal-Spatial Token\nAggregation (TESTA). TESTA condenses video semantics by adaptively aggregating\nsimilar frames, as well as similar patches within each frame. TESTA can reduce\nthe number of visual tokens by 75% and thus accelerate video encoding. Building\nupon TESTA, we introduce a pre-trained video-language model equipped with a\ndivided space-time token aggregation module in each video encoder block. We\nevaluate our model on five datasets for paragraph-to-video retrieval and\nlong-form VideoQA tasks. Experimental results show that TESTA improves\ncomputing efficiency by 1.7 times, and achieves significant performance gains\nfrom its scalability in processing longer input frames, e.g., +13.7 R@1 on\nQuerYD and +6.5 R@1 on Condensed Movie.", "published": "2023-10-29 16:25:32", "link": "http://arxiv.org/abs/2310.19060v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown", "abstract": "In this paper, we systematically evaluate the robustness of multi-exit\nlanguage models against adversarial slowdown. To audit their robustness, we\ndesign a slowdown attack that generates natural adversarial text bypassing\nearly-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a\ncomprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark\nagainst adversarial slowdown. We then show our attack significantly reduces the\ncomputational savings provided by the three methods in both white-box and\nblack-box settings. The more complex a mechanism is, the more vulnerable it is\nto adversarial slowdown. We also perform a linguistic analysis of the perturbed\ntext inputs, identifying common perturbation patterns that our attack\ngenerates, and comparing them with standard adversarial text attacks. Moreover,\nwe show that adversarial training is ineffective in defeating our slowdown\nattack, but input sanitization with a conversational model, e.g., ChatGPT, can\nremove perturbations effectively. This result suggests that future work is\nneeded for developing efficient yet robust multi-exit models. Our code is\navailable at: https://github.com/ztcoalson/WAFFLE", "published": "2023-10-29 21:06:34", "link": "http://arxiv.org/abs/2310.19152v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Deep Audio Analyzer: a Framework to Industrialize the Research on Audio\n  Forensics", "abstract": "Deep Audio Analyzer is an open source speech framework that aims to simplify\nthe research and the development process of neural speech processing pipelines,\nallowing users to conceive, compare and share results in a fast and\nreproducible way. This paper describes the core architecture designed to\nsupport several tasks of common interest in the audio forensics field, showing\npossibility of creating new tasks thus customizing the framework. By means of\nDeep Audio Analyzer, forensics examiners (i.e. from Law Enforcement Agencies)\nand researchers will be able to visualize audio features, easily evaluate\nperformances on pretrained models, to create, export and share new audio\nanalysis workflows by combining deep neural network models with few clicks. One\nof the advantages of this tool is to speed up research and practical\nexperimentation, in the field of audio forensics analysis thus also improving\nexperimental reproducibility by exporting and sharing pipelines. All features\nare developed in modules accessible by the user through a Graphic User\nInterface. Index Terms: Speech Processing, Deep Learning Audio, Deep Learning\nAudio Pipeline creation, Audio Forensics.", "published": "2023-10-29 17:04:24", "link": "http://arxiv.org/abs/2310.19081v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring the Emotional Landscape of Music: An Analysis of Valence\n  Trends and Genre Variations in Spotify Music Data", "abstract": "This paper conducts an intricate analysis of musical emotions and trends\nusing Spotify music data, encompassing audio features and valence scores\nextracted through the Spotipi API. Employing regression modeling, temporal\nanalysis, mood transitions, and genre investigation, the study uncovers\npatterns within music-emotion relationships. Regression models linear, support\nvector, random forest, and ridge, are employed to predict valence scores.\nTemporal analysis reveals shifts in valence distribution over time, while mood\ntransition exploration illuminates emotional dynamics within playlists. The\nresearch contributes to nuanced insights into music's emotional fabric,\nenhancing comprehension of the interplay between music and emotions through\nyears.", "published": "2023-10-29 15:57:31", "link": "http://arxiv.org/abs/2310.19052v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Feature Aggregation in Joint Sound Classification and Localization\n  Neural Networks", "abstract": "This study addresses the application of deep learning techniques in joint\nsound signal classification and localization networks. Current state-of-the-art\nsound source localization deep learning networks lack feature aggregation\nwithin their architecture. Feature aggregation enhances model performance by\nenabling the consolidation of information from different feature scales,\nthereby improving feature robustness and invariance. This is particularly\nimportant in SSL networks, which must differentiate direct and indirect\nacoustic signals. To address this gap, we adapt feature aggregation techniques\nfrom computer vision neural networks to signal detection neural networks.\nAdditionally, we propose the Scale Encoding Network (SEN) for feature\naggregation to encode features from various scales, compressing the network for\nmore computationally efficient aggregation. To evaluate the efficacy of feature\naggregation in SSL networks, we integrated the following computer vision\nfeature aggregation sub-architectures into a SSL control architecture: Path\nAggregation Network (PANet), Weighted Bi-directional Feature Pyramid Network\n(BiFPN), and SEN. These sub-architectures were evaluated using two metrics for\nsignal classification and two metrics for direction-of-arrival regression.\nPANet and BiFPN are established aggregators in computer vision models, while\nthe proposed SEN is a more compact aggregator. The results suggest that models\nincorporating feature aggregations outperformed the control model, the Sound\nEvent Localization and Detection network (SELDnet), in both sound signal\nclassification and localization. The feature aggregation techniques enhance the\nperformance of sound detection neural networks, particularly in\ndirection-of-arrival regression.", "published": "2023-10-29 16:37:14", "link": "http://arxiv.org/abs/2310.19063v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JEN-1 Composer: A Unified Framework for High-Fidelity Multi-Track Music\n  Generation", "abstract": "With rapid advances in generative artificial intelligence, the text-to-music\nsynthesis task has emerged as a promising direction for music generation.\nNevertheless, achieving precise control over multi-track generation remains an\nopen challenge. While existing models excel in directly generating multi-track\nmix, their limitations become evident when it comes to composing individual\ntracks and integrating them in a controllable manner. This departure from the\ntypical workflows of professional composers hinders the ability to refine\ndetails in specific tracks. To address this gap, we propose JEN-1 Composer, a\nunified framework designed to efficiently model marginal, conditional, and\njoint distributions over multi-track music using a single model. Building upon\nan audio latent diffusion model, JEN-1 Composer extends the versatility of\nmulti-track music generation. We introduce a progressive curriculum training\nstrategy, which gradually escalates the difficulty of training tasks while\nensuring the model's generalization ability and facilitating smooth transitions\nbetween different scenarios. During inference, users can iteratively generate\nand select music tracks, thus incrementally composing entire musical pieces in\naccordance with the Human-AI co-composition workflow. Our approach demonstrates\nstate-of-the-art performance in controllable and high-fidelity multi-track\nmusic synthesis, marking a significant advancement in interactive AI-assisted\nmusic creation. Our demo pages are available at www.jenmusic.ai/research.", "published": "2023-10-29 22:51:49", "link": "http://arxiv.org/abs/2310.19180v4", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
