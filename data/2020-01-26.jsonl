{"title": "DUMA: Reading Comprehension with Transposition Thinking", "abstract": "Multi-choice Machine Reading Comprehension (MRC) requires model to decide the\ncorrect answer from a set of answer options when given a passage and a\nquestion. Thus in addition to a powerful Pre-trained Language Model (PrLM) as\nencoder, multi-choice MRC especially relies on a matching network design which\nis supposed to effectively capture the relationships among the triplet of\npassage, question and answers. While the newer and more powerful PrLMs have\nshown their mightiness even without the support from a matching network, we\npropose a new DUal Multi-head Co-Attention (DUMA) model, which is inspired by\nhuman's transposition thinking process solving the multi-choice MRC problem:\nrespectively considering each other's focus from the standpoint of passage and\nquestion. The proposed DUMA has been shown effective and is capable of\ngenerally promoting PrLMs. Our proposed method is evaluated on two benchmark\nmulti-choice MRC tasks, DREAM and RACE, showing that in terms of powerful\nPrLMs, DUMA can still boost the model to reach new state-of-the-art\nperformance.", "published": "2020-01-26 07:35:02", "link": "http://arxiv.org/abs/2001.09415v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Stock Prediction to Financial Relevance: Repurposing Attention\n  Weights to Assess News Relevance Without Manual Annotations", "abstract": "We present a method to automatically identify financially relevant news using\nstock price movements and news headlines as input. The method repurposes the\nattention weights of a neural network initially trained to predict stock prices\nto assign a relevance score to each headline, eliminating the need for manually\nlabeled training data. Our experiments on the four most relevant US stock\nindices and 1.5M news headlines show that the method ranks relevant news\nhighly, positively correlated with the accuracy of the initial stock price\nprediction task.", "published": "2020-01-26 15:16:37", "link": "http://arxiv.org/abs/2001.09466v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "An Effective Automatic Image Annotation Model Via Attention Model and\n  Data Equilibrium", "abstract": "Nowadays, a huge number of images are available. However, retrieving a\nrequired image for an ordinary user is a challenging task in computer vision\nsystems. During the past two decades, many types of research have been\nintroduced to improve the performance of the automatic annotation of images,\nwhich are traditionally focused on content-based image retrieval. Although,\nrecent research demonstrates that there is a semantic gap between content-based\nimage retrieval and image semantics understandable by humans. As a result,\nexisting research in this area has caused to bridge the semantic gap between\nlow-level image features and high-level semantics. The conventional method of\nbridging the semantic gap is through the automatic image annotation (AIA) that\nextracts semantic features using machine learning techniques. In this paper, we\npropose a novel AIA model based on the deep learning feature extraction method.\nThe proposed model has three phases, including a feature extractor, a tag\ngenerator, and an image annotator. First, the proposed model extracts\nautomatically the high and low-level features based on dual-tree continues\nwavelet transform (DT-CWT), singular value decomposition, distribution of color\nton, and the deep neural network. Moreover, the tag generator balances the\ndictionary of the annotated keywords by a new log-entropy auto-encoder (LEAE)\nand then describes these keywords by word embedding. Finally, the annotator\nworks based on the long-short-term memory (LSTM) network in order to obtain the\nimportance degree of specific features of the image. The experiments conducted\non two benchmark datasets confirm that the superiority of the proposed model\ncompared to the previous models in terms of performance criteria.", "published": "2020-01-26 05:59:57", "link": "http://arxiv.org/abs/2001.10590v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework\n  for Natural Language Generation", "abstract": "Current pre-training works in natural language generation pay little\nattention to the problem of exposure bias on downstream tasks. To address this\nissue, we propose an enhanced multi-flow sequence to sequence pre-training and\nfine-tuning framework named ERNIE-GEN, which bridges the discrepancy between\ntraining and inference with an infilling generation mechanism and a noise-aware\ngeneration method. To make generation closer to human writing patterns, this\nframework introduces a span-by-span generation flow that trains the model to\npredict semantically-complete spans consecutively rather than predicting word\nby word. Unlike existing pre-training methods, ERNIE-GEN incorporates\nmulti-granularity target sampling to construct pre-training data, which\nenhances the correlation between encoder and decoder. Experimental results\ndemonstrate that ERNIE-GEN achieves state-of-the-art results with a much\nsmaller amount of pre-training data and parameters on a range of language\ngeneration tasks, including abstractive summarization (Gigaword and\nCNN/DailyMail), question generation (SQuAD), dialogue generation (Persona-Chat)\nand generative question answering (CoQA).", "published": "2020-01-26 02:54:49", "link": "http://arxiv.org/abs/2001.11314v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Representative Headlines for News Stories", "abstract": "Millions of news articles are published online every day, which can be\noverwhelming for readers to follow. Grouping articles that are reporting the\nsame event into news stories is a common way of assisting readers in their news\nconsumption. However, it remains a challenging research problem to efficiently\nand effectively generate a representative headline for each story. Automatic\nsummarization of a document set has been studied for decades, while few studies\nhave focused on generating representative headlines for a set of articles.\nUnlike summaries, which aim to capture most information with least redundancy,\nheadlines aim to capture information jointly shared by the story articles in\nshort length, and exclude information that is too specific to each individual\narticle. In this work, we study the problem of generating representative\nheadlines for news stories. We develop a distant supervision approach to train\nlarge-scale generation models without any human annotation. This approach\ncenters on two technical components. First, we propose a multi-level\npre-training framework that incorporates massive unlabeled corpus with\ndifferent quality-vs.-quantity balance at different levels. We show that models\ntrained within this framework outperform those trained with pure human curated\ncorpus. Second, we propose a novel self-voting-based article attention layer to\nextract salient information shared by multiple articles. We show that models\nthat incorporate this layer are robust to potential noises in news stories and\noutperform existing baselines with or without noises. We can further enhance\nour model by incorporating human labels, and we show our distant supervision\napproach significantly reduces the demand on labeled data.", "published": "2020-01-26 02:08:22", "link": "http://arxiv.org/abs/2001.09386v4", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced\n  Graph Neural Network", "abstract": "Taxonomies consist of machine-interpretable semantics and provide valuable\nknowledge for many web applications. For example, online retailers (e.g.,\nAmazon and eBay) use taxonomies for product recommendation, and web search\nengines (e.g., Google and Bing) leverage taxonomies to enhance query\nunderstanding. Enormous efforts have been made on constructing taxonomies\neither manually or semi-automatically. However, with the fast-growing volume of\nweb content, existing taxonomies will become outdated and fail to capture\nemerging knowledge. Therefore, in many applications, dynamic expansions of an\nexisting taxonomy are in great demand. In this paper, we study how to expand an\nexisting taxonomy by adding a set of new concepts. We propose a novel\nself-supervised framework, named TaxoExpan, which automatically generates a set\nof <query concept, anchor concept> pairs from the existing taxonomy as training\ndata. Using such self-supervision data, TaxoExpan learns a model to predict\nwhether a query concept is the direct hyponym of an anchor concept. We develop\ntwo innovative techniques in TaxoExpan: (1) a position-enhanced graph neural\nnetwork that encodes the local structure of an anchor concept in the existing\ntaxonomy, and (2) a noise-robust training objective that enables the learned\nmodel to be insensitive to the label noise in the self-supervision data.\nExtensive experiments on three large-scale datasets from different domains\ndemonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy\nexpansion.", "published": "2020-01-26 21:30:21", "link": "http://arxiv.org/abs/2001.09522v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning for Voice Trigger Detection", "abstract": "We describe the design of a voice trigger detection system for smart\nspeakers. In this study, we address two major challenges. The first is that the\ndetectors are deployed in complex acoustic environments with external noise and\nloud playback by the device itself. Secondly, collecting training examples for\na specific keyword or trigger phrase is challenging resulting in a scarcity of\ntrigger phrase specific training data. We describe a two-stage cascaded\narchitecture where a low-power detector is always running and listening for the\ntrigger phrase. If a detection is made at this stage, the candidate audio\nsegment is re-scored by larger, more complex models to verify that the segment\ncontains the trigger phrase. In this study, we focus our attention on the\narchitecture and design of these second-pass detectors. We start by training a\ngeneral acoustic model that produces phonetic transcriptions given a large\nlabelled training dataset. Next, we collect a much smaller dataset of examples\nthat are challenging for the baseline system. We then use multi-task learning\nto train a model to simultaneously produce accurate phonetic transcriptions on\nthe larger dataset \\emph{and} discriminate between true and easily confusable\nexamples using the smaller dataset. Our results demonstrate that the proposed\nmodel reduces errors by half compared to the baseline in a range of challenging\ntest conditions \\emph{without} requiring extra parameters.", "published": "2020-01-26 21:13:07", "link": "http://arxiv.org/abs/2001.09519v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Multi-task Learning for Speaker Verification and Voice Trigger Detection", "abstract": "Automatic speech transcription and speaker recognition are usually treated as\nseparate tasks even though they are interdependent. In this study, we\ninvestigate training a single network to perform both tasks jointly. We train\nthe network in a supervised multi-task learning setup, where the speech\ntranscription branch of the network is trained to minimise a phonetic\nconnectionist temporal classification (CTC) loss while the speaker recognition\nbranch of the network is trained to label the input sequence with the correct\nlabel for the speaker. We present a large-scale empirical study where the model\nis trained using several thousand hours of labelled training data for each\ntask. We evaluate the speech transcription branch of the network on a voice\ntrigger detection task while the speaker recognition branch is evaluated on a\nspeaker verification task. Results demonstrate that the network is able to\nencode both phonetic \\emph{and} speaker information in its learnt\nrepresentations while yielding accuracies at least as good as the baseline\nmodels for each task, with the same number of parameters as the independent\nmodels.", "published": "2020-01-26 21:19:27", "link": "http://arxiv.org/abs/2001.10816v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
