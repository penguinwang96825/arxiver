{"title": "Neuro-Symbolic Concepts", "abstract": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer.", "published": "2025-05-09 17:02:51", "link": "http://arxiv.org/abs/2505.06191v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "abstract": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.", "published": "2025-05-09 16:55:06", "link": "http://arxiv.org/abs/2505.06186v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling", "abstract": "Social media user profiling through content analysis is crucial for tasks\nlike misinformation detection, engagement prediction, hate speech monitoring,\nand user behavior modeling. However, existing profiling techniques, including\ntweet summarization, attribute-based profiling, and latent representation\nlearning, face significant limitations: they often lack transferability,\nproduce non-interpretable features, require large labeled datasets, or rely on\nrigid predefined categories that limit adaptability. We introduce a novel large\nlanguage model (LLM)-based approach that leverages domain-defining statements,\nwhich serve as key characteristics outlining the important pillars of a domain\nas foundations for profiling. Our two-stage method first employs\nsemi-supervised filtering with a domain-specific knowledge base, then generates\nboth abstractive (synthesized descriptions) and extractive (representative\ntweet selections) user profiles. By harnessing LLMs' inherent knowledge with\nminimal human validation, our approach is adaptable across domains while\nreducing the need for large labeled datasets. Our method generates\ninterpretable natural language user profiles, condensing extensive user data\ninto a scale that unlocks LLMs' reasoning and knowledge capabilities for\ndownstream social network tasks. We contribute a Persian political Twitter (X)\ndataset and an LLM-based evaluation framework with human validation.\nExperimental results show our method significantly outperforms state-of-the-art\nLLM-based and traditional methods by 9.8%, demonstrating its effectiveness in\ncreating flexible, adaptable, and interpretable user profiles.", "published": "2025-05-09 16:51:24", "link": "http://arxiv.org/abs/2505.06184v1", "categories": ["cs.SI", "cs.CL", "cs.IR", "I.2.7"], "primary_category": "cs.SI"}
{"title": "Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework", "abstract": "Engagement between client and therapist is a critical determinant of\ntherapeutic success. We propose a multi-dimensional natural language processing\n(NLP) framework that objectively classifies engagement quality in counseling\nsessions based on textual transcripts. Using 253 motivational interviewing\ntranscripts (150 high-quality, 103 low-quality), we extracted 42 features\nacross four domains: conversational dynamics, semantic similarity as topic\nalignment, sentiment classification, and question detection. Classifiers,\nincluding Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM),\nwere hyperparameter tuned and trained using a stratified 5-fold\ncross-validation and evaluated on a holdout test set. On balanced\n(non-augmented) data, RF achieved the highest classification accuracy (76.7%),\nand SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation,\nperformance improved significantly: RF achieved up to 88.9% accuracy, 90.0%\nF1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and\n93.6% AUC. The augmented data results reflect the potential of the framework in\nfuture larger-scale applications. Feature contribution revealed conversational\ndynamics and semantic similarity between clients and therapists were among the\ntop contributors, led by words uttered by the client (mean and standard\ndeviation). The framework was robust across the original and augmented datasets\nand demonstrated consistent improvements in F1 scores and recall. While\ncurrently text-based, the framework supports future multimodal extensions\n(e.g., vocal tone, facial affect) for more holistic assessments. This work\nintroduces a scalable, data-driven method for evaluating engagement quality of\nthe therapy session, offering clinicians real-time feedback to enhance the\nquality of both virtual and in-person therapeutic interactions.", "published": "2025-05-09 16:03:14", "link": "http://arxiv.org/abs/2505.06151v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "abstract": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.", "published": "2025-05-09 16:02:23", "link": "http://arxiv.org/abs/2505.06150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "abstract": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance.", "published": "2025-05-09 16:00:01", "link": "http://arxiv.org/abs/2505.06149v1", "categories": ["cs.CL", "cs.CY", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies", "abstract": "Few-shot text classification has important application value in low-resource\nenvironments. This paper proposes a strategy that combines adaptive\nfine-tuning, contrastive learning, and regularization optimization to improve\nthe classification performance of Transformer-based models. Experiments on the\nFewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform\nwell in few-shot tasks, especially in the 5-shot setting, which can more\neffectively capture text features and improve classification accuracy. The\nexperiment also found that there are significant differences in the\nclassification difficulty of different relationship categories. Some categories\nhave fuzzy semantic boundaries or complex feature distributions, making it\ndifficult for the standard cross entropy loss to learn the discriminative\ninformation required to distinguish categories. By introducing contrastive loss\nand regularization loss, the generalization ability of the model is enhanced,\neffectively alleviating the overfitting problem in few-shot environments. In\naddition, the research results show that the use of Transformer models or\ngenerative architectures with stronger self-attention mechanisms can help\nimprove the stability and accuracy of few-shot classification.", "published": "2025-05-09 15:54:08", "link": "http://arxiv.org/abs/2505.06145v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs Get Lost In Multi-Turn Conversation", "abstract": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*.", "published": "2025-05-09 15:21:44", "link": "http://arxiv.org/abs/2505.06120v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "abstract": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis.", "published": "2025-05-09 15:10:57", "link": "http://arxiv.org/abs/2505.06110v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Differentiating Emigration from Return Migration of Scholars Using Name-Based Nationality Detection Models", "abstract": "Most web and digital trace data do not include information about an\nindividual's nationality due to privacy concerns. The lack of data on\nnationality can create challenges for migration research. It can lead to a\nleft-censoring issue since we are uncertain about the migrant's country of\norigin. Once we observe an emigration event, if we know the nationality, we can\ndifferentiate it from return migration. We propose methods to detect the\nnationality with the least available data, i.e., full names. We use the\ndetected nationality in comparison with the country of academic origin, which\nis a common approach in studying the migration of researchers. We gathered 2.6\nmillion unique name-nationality pairs from Wikipedia and categorized them into\nfamilies of nationalities with three granularity levels to use as our training\ndata. Using a character-based machine learning model, we achieved a weighted F1\nscore of 84% for the broadest and 67% for the most granular, country-level\ncategorization. In our empirical study, we used the trained and tested model to\nassign nationality to 8+ million scholars' full names in Scopus data. Our\nresults show that using the country of first publication as a proxy for\nnationality underestimates the size of return flows, especially for countries\nwith a more diverse academic workforce, such as the USA, Australia, and Canada.\nWe found that around 48% of emigration from the USA was return migration once\nwe used the country of name origin, in contrast to 33% based on academic\norigin. In the most recent period, 79% of scholars whose affiliation has\nconsistently changed from the USA to China, and are considered emigrants, have\nChinese names in contrast to 41% with a Chinese academic origin. Our proposed\nmethods for addressing left-censoring issues are beneficial for other research\nthat uses digital trace data to study migration.", "published": "2025-05-09 15:03:39", "link": "http://arxiv.org/abs/2505.06107v1", "categories": ["cs.DL", "cs.CL", "cs.MM"], "primary_category": "cs.DL"}
{"title": "Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax", "abstract": "This study analyzes the attention patterns of fine-tuned encoder-only models\nbased on the BERT architecture (BERT-based models) towards two distinct types\nof Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms\npresent challenges in semantic non-compositionality, whereas MSUs demonstrate\nunconventional syntactic behavior that does not conform to standard grammatical\ncategorizations. We aim to understand whether fine-tuning BERT-based models on\nspecific tasks influences their attention to MWEs, and how this attention\ndiffers between semantic and syntactic tasks. We examine attention scores to\nMWEs in both pre-trained and fine-tuned BERT-based models. We utilize\nmonolingual models and datasets in six Indo-European languages - English,\nGerman, Dutch, Polish, Russian, and Ukrainian. Our results show that\nfine-tuning significantly influences how models allocate attention to MWEs.\nSpecifically, models fine-tuned on semantic tasks tend to distribute attention\nto idiomatic expressions more evenly across layers. Models fine-tuned on\nsyntactic tasks show an increase in attention to MSUs in the lower layers,\ncorresponding with syntactic processing requirements.", "published": "2025-05-09 13:57:56", "link": "http://arxiv.org/abs/2505.06062v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "abstract": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics.", "published": "2025-05-09 13:42:59", "link": "http://arxiv.org/abs/2505.06046v1", "categories": ["cs.CL", "cs.LG", "68T50"], "primary_category": "cs.CL"}
{"title": "Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification", "abstract": "Reliance on spurious correlations (shortcuts) has been shown to underlie many\nof the successes of language models. Previous work focused on identifying the\ninput elements that impact prediction. We investigate how shortcuts are\nactually processed within the model's decision-making mechanism. We use actor\nnames in movie reviews as controllable shortcuts with known impact on the\noutcome. We use mechanistic interpretability methods and identify specific\nattention heads that focus on shortcuts. These heads gear the model towards a\nlabel before processing the complete input, effectively making premature\ndecisions that bypass contextual analysis. Based on these findings, we\nintroduce Head-based Token Attribution (HTA), which traces intermediate\ndecisions back to input tokens. We show that HTA is effective in detecting\nshortcuts in LLMs and enables targeted mitigation by selectively deactivating\nshortcut-related attention heads.", "published": "2025-05-09 13:26:21", "link": "http://arxiv.org/abs/2505.06032v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation", "abstract": "This paper introduces Unilogit, a novel self-distillation method for machine\nunlearning in Large Language Models. Unilogit addresses the challenge of\nselectively forgetting specific information while maintaining overall model\nutility, a critical task in compliance with data privacy regulations like GDPR.\nUnlike prior methods that rely on static hyperparameters or starting model\noutputs, Unilogit dynamically adjusts target logits to achieve a uniform\nprobability for the target token, leveraging the current model's outputs for\nmore accurate self-distillation targets. This approach not only eliminates the\nneed for additional hyperparameters but also enhances the model's ability to\napproximate the golden targets. Extensive experiments on public benchmarks and\nan in-house e-commerce dataset demonstrate Unilogit's superior performance in\nbalancing forget and retain objectives, outperforming state-of-the-art methods\nsuch as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness\nacross various scenarios, highlighting its practical applicability and\neffectiveness in achieving efficacious machine unlearning.", "published": "2025-05-09 13:19:09", "link": "http://arxiv.org/abs/2505.06027v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective", "abstract": "Current machine translation models provide us with high-quality outputs in\nmost scenarios. However, they still face some specific problems, such as\ndetecting which entities should not be changed during translation. In this\npaper, we explore the abilities of popular NMT models, including models from\nthe OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities\nsuch as URL addresses, IBAN numbers, or emails when producing translations\nbetween four languages: English, German, Polish, and Ukrainian. We investigate\nthe quality of popular NMT models in terms of accuracy, discuss errors made by\nthe models, and examine the reasons for errors. Our analysis highlights\nspecific categories, such as emojis, that pose significant challenges for many\nmodels considered. In addition to the analysis, we propose a new multilingual\nsynthetic dataset of 36,000 sentences that can help assess the quality of\nentity transfer across nine categories and four aforementioned languages.", "published": "2025-05-09 12:47:13", "link": "http://arxiv.org/abs/2505.06010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models", "abstract": "Recent language models can successfully solve various language-related tasks,\nand many understand inputs stated in different languages. In this paper, we\nexplore the performance of 17 popular models used to correct grammatical issues\nin texts stated in English, German, Italian, and Swedish when using a single\nmodel to correct texts in all those languages. We analyze the outputs generated\nby these models, focusing on decreasing the number of grammatical errors while\nkeeping the changes small. The conclusions drawn help us understand what\nproblems occur among those models and which models can be recommended for\nmultilingual grammatical error correction tasks. We list six models that\nimprove grammatical correctness in all four languages and show that Gemma 9B is\ncurrently the best performing one for the languages considered.", "published": "2025-05-09 12:35:26", "link": "http://arxiv.org/abs/2505.06004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition", "abstract": "Studies of morphological processing have shown that semantic transparency is\ncrucial for word recognition. Its computational operationalization is still\nunder discussion. Our primary objectives are to explore embedding-based\nmeasures of semantic transparency, and assess their impact on reading. First,\nwe explored the geometry of complex words in semantic space. To do so, we\nconducted a t-distributed Stochastic Neighbor Embedding clustering analysis on\n4,226 Malay prefixed words. Several clusters were observed for complex words\nvaried by their prefix class. Then, we derived five simple measures, and\ninvestigated whether they were significant predictors of lexical decision\nlatencies. Two sets of Linear Discriminant Analyses were run in which the\nprefix of a word is predicted from either word embeddings or shift vectors\n(i.e., a vector subtraction of the base word from the derived word). The\naccuracy with which the model predicts the prefix of a word indicates the\ndegree of transparency of the prefix. Three further measures were obtained by\ncomparing embeddings between each word and all other words containing the same\nprefix (i.e., centroid), between each word and the shift from their base word,\nand between each word and the predicted word of the Functional Representations\nof Affixes in Compositional Semantic Space model. In a series of Generalized\nAdditive Mixed Models, all measures predicted decision latencies after\naccounting for word frequency, word length, and morphological family size. The\nmodel that included the correlation between each word and their centroid as a\npredictor provided the best fit to the data.", "published": "2025-05-09 11:57:10", "link": "http://arxiv.org/abs/2505.05973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models", "abstract": "We propose a method for training language models in an interactive setting\ninspired by child language acquisition. In our setting, a speaker attempts to\ncommunicate some information to a listener in a single-turn dialogue and\nreceives a reward if communicative success is achieved. Unlike earlier related\nwork using image--caption data for interactive reference games, we\noperationalize communicative success in a more abstract language-only\nquestion--answering setting. First, we present a feasibility study\ndemonstrating that our reward provides an indirect signal about grammaticality.\nSecond, we conduct experiments using reinforcement learning to fine-tune\nlanguage models. We observe that cognitively plausible constraints on the\ncommunication channel lead to interpretable changes in speaker behavior.\nHowever, we do not yet see improvements on linguistic evaluations from our\ntraining regime. We outline potential modifications to the task design and\ntraining configuration that could better position future work to use our\nmethodology to observe the benefits of interaction on language learning in\ncomputational cognitive models.", "published": "2025-05-09 11:48:36", "link": "http://arxiv.org/abs/2505.05970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeoQA: Evidence-based Question Answering with Generated News Events", "abstract": "Evaluating Retrieval-Augmented Generation (RAG) in large language models\n(LLMs) is challenging because benchmarks can quickly become stale. Questions\ninitially requiring retrieval may become answerable from pretraining knowledge\nas newer models incorporate more recent information during pretraining, making\nit difficult to distinguish evidence-based reasoning from recall. We introduce\nNeoQA (News Events for Out-of-training Question Answering), a benchmark\ndesigned to address this issue. To construct NeoQA, we generated timelines and\nknowledge bases of fictional news events and entities along with news articles\nand Q\\&A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring\nthat no prior evidence exists in their training data. We propose our dataset as\na new platform for evaluating evidence-based question answering, as it requires\nLLMs to generate responses exclusively from retrieved evidence and only when\nsufficient evidence is available. NeoQA enables controlled evaluation across\nvarious evidence scenarios, including cases with missing or misleading details.\nOur findings indicate that LLMs struggle to distinguish subtle mismatches\nbetween questions and evidence, and suffer from short-cut reasoning when key\ninformation required to answer a question is missing from the evidence,\nunderscoring key limitations in evidence-based reasoning.", "published": "2025-05-09 10:51:29", "link": "http://arxiv.org/abs/2505.05949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summarisation of German Judgments in conjunction with a Class-based Evaluation", "abstract": "The automated summarisation of long legal documents can be a great aid for\nlegal experts in their daily work. We automatically create summaries (guiding\nprinciples) of German judgments by fine-tuning a decoder-based large language\nmodel. We enrich the judgments with information about legal entities before the\ntraining. For the evaluation of the created summaries, we define a set of\nevaluation classes which allows us to measure their language, pertinence,\ncompleteness and correctness. Our results show that employing legal entities\nhelps the generative model to find the relevant content, but the quality of the\ncreated summaries is not yet sufficient for a use in practice.", "published": "2025-05-09 10:44:34", "link": "http://arxiv.org/abs/2505.05947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2", "abstract": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs.", "published": "2025-05-09 10:43:37", "link": "http://arxiv.org/abs/2505.05946v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI", "abstract": "The construction of experimental datasets is essential for expanding the\nscope of data-driven scientific discovery. Recent advances in natural language\nprocessing (NLP) have facilitated automatic extraction of structured data from\nunstructured scientific literature. While existing approaches-multi-step and\ndirect methods-offer valuable capabilities, they also come with limitations\nwhen applied independently. Here, we propose a novel hybrid text-mining\nframework that integrates the advantages of both methods to convert\nunstructured scientific text into structured data. Our approach first\ntransforms raw text into entity-recognized text, and subsequently into\nstructured form. Furthermore, beyond the overall data structuring framework, we\nalso enhance entity recognition performance by introducing an entity marker-a\nsimple yet effective technique that uses symbolic annotations to highlight\ntarget entities. Specifically, our entity marker-based hybrid approach not only\nconsistently outperforms previous entity recognition approaches across three\nbenchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the\nquality of final structured data-yielding up to a 58% improvement in\nentity-level F1 score and up to 83% improvement in relation-level F1 score\ncompared to direct approach.", "published": "2025-05-09 07:58:30", "link": "http://arxiv.org/abs/2505.05864v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evolutionary ecology of words", "abstract": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species.", "published": "2025-05-09 07:57:10", "link": "http://arxiv.org/abs/2505.05863v1", "categories": ["q-bio.PE", "cs.AI", "cs.CL", "92B20"], "primary_category": "q-bio.PE"}
{"title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "abstract": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders.", "published": "2025-05-09 06:55:51", "link": "http://arxiv.org/abs/2505.05828v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted", "abstract": "The primary goal of this study is to develop and evaluate an innovative\nprompting technique, AnaQuest, for generating multiple-choice questions (MCQs)\nusing a pre-trained large language model. In AnaQuest, the choice items are\nsentence-level assertions about complex concepts. The technique integrates\nformative and summative assessments. In the formative phase, students answer\nopen-ended questions for target concepts in free text. For summative\nassessment, AnaQuest analyzes these responses to generate both correct and\nincorrect assertions. To evaluate the validity of the generated MCQs, Item\nResponse Theory (IRT) was applied to compare item characteristics between MCQs\ngenerated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An\nempirical study found that expert instructors rated MCQs generated by both AI\nmodels to be as valid as those created by human instructors. However, IRT-based\nanalysis revealed that AnaQuest-generated questions - particularly those with\nincorrect assertions (foils) - more closely resembled human-crafted items in\nterms of difficulty and discrimination than those produced by ChatGPT.", "published": "2025-05-09 06:33:55", "link": "http://arxiv.org/abs/2505.05815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM", "abstract": "Transformer-based models are the foundation of modern machine learning, but\ntheir execution, particularly during autoregressive decoding in large language\nmodels (LLMs), places significant pressure on memory systems due to frequent\nmemory accesses and growing key-value (KV) caches. This creates a bottleneck in\nmemory bandwidth, especially as context lengths increase. Processing-in-memory\n(PIM) architectures are a promising solution, offering high internal bandwidth\nand compute parallelism near memory. However, current PIM designs are primarily\noptimized for dense attention and struggle with the dynamic, irregular access\npatterns introduced by modern KV cache sparsity techniques. Consequently, they\nsuffer from workload imbalance, reducing throughput and resource utilization.\nIn this work, we propose STARC, a novel sparsity-optimized data mapping scheme\ntailored specifically for efficient LLM decoding on PIM architectures. STARC\nclusters KV pairs by semantic similarity and maps them to contiguous memory\nregions aligned with PIM bank structures. During decoding, queries retrieve\nrelevant tokens at cluster granularity by matching against precomputed\ncentroids, enabling selective attention and parallel processing without\nfrequent reclustering or data movement overhead. Experiments on the HBM-PIM\nsystem show that, compared to common token-wise sparsity methods, STARC reduces\nattention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a\nKV cache budget of 1024, it achieves up to 54%--74% latency reduction and\n45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC\nmaintains model accuracy comparable to state-of-the-art sparse attention\nmethods, demonstrating its effectiveness in enabling efficient and\nhardware-friendly long-context LLM inference on PIM architectures.", "published": "2025-05-09 04:17:05", "link": "http://arxiv.org/abs/2505.05772v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BMMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection", "abstract": "Academic misconduct detection in biomedical research remains challenging due\nto algorithmic narrowness in existing methods and fragmented analytical\npipelines. We present BMMDetect, a multimodal deep learning framework that\nintegrates journal metadata (SJR, institutional data), semantic embeddings\n(PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics,\ndata anomalies) for holistic manuscript evaluation. Key innovations include:\n(1) multimodal fusion of domain-specific features to reduce detection bias; (2)\nquantitative evaluation of feature importance, identifying journal authority\nmetrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as\ndominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with\n13,160 retracted articles and 53,411 controls. BMMDetect achieves 74.33% AUC,\noutperforming single-modality baselines by 8.6%, and demonstrates\ntransferability across biomedical subfields. This work advances scalable,\ninterpretable tools for safeguarding research integrity.", "published": "2025-05-09 03:53:10", "link": "http://arxiv.org/abs/2505.05763v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "abstract": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling.", "published": "2025-05-09 03:29:15", "link": "http://arxiv.org/abs/2505.05755v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification", "abstract": "Large Language Models (LLMs) have shown remarkable ability in solving complex\ntasks, making them a promising tool for enhancing tabular learning. However,\nexisting LLM-based methods suffer from high resource requirements, suboptimal\ndemonstration selection, and limited interpretability, which largely hinder\ntheir prediction performance and application in the real world. To overcome\nthese problems, we propose a novel in-context learning framework for tabular\nprediction. The core idea is to leverage the explanations generated by LLMs to\nguide a smaller, locally deployable Surrogate Language Model (SLM) to make\ninterpretable tabular predictions. Specifically, our framework mainly involves\nthree stages: (i) Post Hoc Explanation Generation, where LLMs are utilized to\ngenerate explanations for question-answer pairs in candidate demonstrations,\nproviding insights into the reasoning behind the answer. (ii) Post Hoc\nExplanation-Guided Demonstrations Selection, which utilizes explanations\ngenerated by LLMs to guide the process of demonstration selection from\ncandidate demonstrations. (iii) Post Hoc Explanation-Guided Interpretable SLM\nPrediction, which utilizes the demonstrations obtained in step (ii) as\nin-context and merges corresponding explanations as rationales to improve the\nperformance of SLM and guide the model to generate interpretable outputs.\nExperimental results highlight the framework's effectiveness, with an average\naccuracy improvement of 5.31% across various tabular datasets in diverse\ndomains.", "published": "2025-05-09 02:57:39", "link": "http://arxiv.org/abs/2505.05744v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications", "abstract": "The scarcity of high-quality multimodal biomedical data limits the ability to\neffectively fine-tune pretrained Large Language Models (LLMs) for specialized\nbiomedical tasks. To address this challenge, we introduce MINT (Multimodal\nIntegrated kNowledge Transfer), a framework that aligns unimodal large decoder\nmodels with domain-specific decision patterns from multimodal biomedical data\nthrough preference optimization. While MINT supports different optimization\ntechniques, we primarily implement it with the Odds Ratio Preference\nOptimization (ORPO) framework as its backbone. This strategy enables the\naligned LLMs to perform predictive tasks using text-only or image-only inputs\nwhile retaining knowledge learnt from multimodal data. MINT leverages an\nupstream multimodal machine learning (MML) model trained on high-quality\nmultimodal data to transfer domain-specific insights to downstream text-only or\nimage-only LLMs. We demonstrate its effectiveness through two key applications:\n(1) Rare genetic disease prediction from texts, where MINT uses a multimodal\nencoder model, trained on facial photos and clinical notes, to generate a\npreference dataset for aligning a lightweight Llama 3.2-3B-Instruct. Despite\nrelying on text input only, the MINT-derived model outperforms models trained\nwith SFT, RAG, or DPO, and even outperforms Llama 3.1-405B-Instruct. (2) Tissue\ntype classification using cell nucleus images, where MINT uses a\nvision-language foundation model as the preference generator, containing\nknowledge learnt from both text and histopathological images to align\ndownstream image-only models. The resulting MINT-derived model significantly\nimproves the performance of Llama 3.2-Vision-11B-Instruct on tissue type\nclassification. In summary, MINT provides an effective strategy to align\nunimodal LLMs with high-quality multimodal expertise through preference\noptimization.", "published": "2025-05-09 02:28:41", "link": "http://arxiv.org/abs/2505.05736v1", "categories": ["q-bio.QM", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries", "abstract": "Most existing multimodal machine translation (MMT) datasets are predominantly\ncomposed of static images or short video clips, lacking extensive video data\nacross diverse domains and topics. As a result, they fail to meet the demands\nof real-world MMT tasks, such as documentary translation. In this study, we\ndeveloped TopicVD, a topic-based dataset for video-supported multimodal machine\ntranslation of documentaries, aiming to advance research in this field. We\ncollected video-subtitle pairs from documentaries and categorized them into\neight topics, such as economy and nature, to facilitate research on domain\nadaptation in video-guided MMT. Additionally, we preserved their contextual\ninformation to support research on leveraging the global context of\ndocumentaries in video-guided MMT. To better capture the shared semantics\nbetween text and video, we propose an MMT model based on a cross-modal\nbidirectional attention module. Extensive experiments on the TopicVD dataset\ndemonstrate that visual information consistently improves the performance of\nthe NMT model in documentary translation. However, the MMT model's performance\nsignificantly declines in out-of-domain scenarios, highlighting the need for\neffective domain adaptation methods. Additionally, experiments demonstrate that\nglobal context can effectively improve translation performance. % Dataset and\nour implementations are available at https://github.com/JinzeLv/TopicVD", "published": "2025-05-09 01:31:02", "link": "http://arxiv.org/abs/2505.05714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models", "abstract": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations.", "published": "2025-05-09 00:39:43", "link": "http://arxiv.org/abs/2505.05704v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Let Humanoids Hike! Integrative Skill Development on Complex Trails", "abstract": "Hiking on complex trails demands balance, agility, and adaptive\ndecision-making over unpredictable terrain. Current humanoid research remains\nfragmented and inadequate for hiking: locomotion focuses on motor skills\nwithout long-term goals or situational awareness, while semantic navigation\noverlooks real-world embodiment and local terrain variability. We propose\ntraining humanoids to hike on complex trails, driving integrative skill\ndevelopment across visual perception, decision making, and motor execution. We\ndevelop a learning framework, LEGO-H, that enables a vision-equipped humanoid\nrobot to hike complex trails autonomously. We introduce two technical\ninnovations: 1) A temporal vision transformer variant - tailored into\nHierarchical Reinforcement Learning framework - anticipates future local goals\nto guide movement, seamlessly integrating locomotion with goal-directed\nnavigation. 2) Latent representations of joint movement patterns, combined with\nhierarchical metric learning - enhance Privileged Learning scheme - enable\nsmooth policy transfer from privileged training to onboard execution. These\ncomponents allow LEGO-H to handle diverse physical and environmental challenges\nwithout relying on predefined motion patterns. Experiments across varied\nsimulated trails and robot morphologies highlight LEGO-H's versatility and\nrobustness, positioning hiking as a compelling testbed for embodied autonomy\nand LEGO-H as a baseline for future humanoid development.", "published": "2025-05-09 17:53:02", "link": "http://arxiv.org/abs/2505.06218v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Turbo-ICL: In-Context Learning-Based Turbo Equalization", "abstract": "This paper introduces a novel in-context learning (ICL) framework, inspired\nby large language models (LLMs), for soft-input soft-output channel\nequalization in coded multiple-input multiple-output (MIMO) systems. The\nproposed approach learns to infer posterior symbol distributions directly from\na prompt of pilot signals and decoder feedback. A key innovation is the use of\nprompt augmentation to incorporate extrinsic information from the decoder\noutput as additional context, enabling the ICL model to refine its symbol\nestimates iteratively across turbo decoding iterations. Two model variants,\nbased on Transformer and state-space architectures, are developed and\nevaluated. Extensive simulations demonstrate that, when traditional linear\nassumptions break down, e.g., in the presence of low-resolution quantization,\nICL equalizers consistently outperform conventional model-based baselines, even\nwhen the latter are provided with perfect channel state information. Results\nalso highlight the advantage of Transformer-based models under limited training\ndiversity, as well as the efficiency of state-space models in\nresource-constrained scenarios.", "published": "2025-05-09 16:29:29", "link": "http://arxiv.org/abs/2505.06175v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks", "abstract": "Medical vision-language models (VLMs) have shown promise as clinical\nassistants across various medical fields. However, specialized dermatology VLM\ncapable of delivering professional and detailed diagnostic analysis remains\nunderdeveloped, primarily due to less specialized text descriptions in current\ndermatology multimodal datasets. To address this issue, we propose MM-Skin, the\nfirst large-scale multimodal dermatology dataset that encompasses 3 imaging\nmodalities, including clinical, dermoscopic, and pathological and nearly 10k\nhigh-quality image-text pairs collected from professional textbooks. In\naddition, we generate over 27k diverse, instruction-following vision question\nanswering (VQA) samples (9 times the size of current largest dermatology VQA\ndataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a\ndermatology-specific VLM designed for precise and nuanced skin disease\ninterpretation. Comprehensive benchmark evaluations of SkinVL on VQA,\nsupervised fine-tuning (SFT) and zero-shot classification tasks across 8\ndatasets, reveal its exceptional performance for skin diseases in comparison to\nboth general and medical VLM models. The introduction of MM-Skin and SkinVL\noffers a meaningful contribution to advancing the development of clinical\ndermatology VLM assistants. MM-Skin is available at\nhttps://github.com/ZwQ803/MM-Skin", "published": "2025-05-09 16:03:47", "link": "http://arxiv.org/abs/2505.06152v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena", "abstract": "Wasserstein distances provide a powerful framework for comparing data\ndistributions. They can be used to analyze processes over time or to detect\ninhomogeneities within data. However, simply calculating the Wasserstein\ndistance or analyzing the corresponding transport map (or coupling) may not be\nsufficient for understanding what factors contribute to a high or low\nWasserstein distance. In this work, we propose a novel solution based on\nExplainable AI that allows us to efficiently and accurately attribute\nWasserstein distances to various data components, including data subgroups,\ninput features, or interpretable subspaces. Our method achieves high accuracy\nacross diverse datasets and Wasserstein distance specifications, and its\npractical utility is demonstrated in two use cases.", "published": "2025-05-09 15:26:38", "link": "http://arxiv.org/abs/2505.06123v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review", "abstract": "Automatic lymph node segmentation is the cornerstone for advances in computer\nvision tasks for early detection and staging of cancer. Traditional\nsegmentation methods are constrained by manual delineation and variability in\noperator proficiency, limiting their ability to achieve high accuracy. The\nintroduction of deep learning technologies offers new possibilities for\nimproving the accuracy of lymph node image analysis. This study evaluates the\napplication of deep learning in lymph node segmentation and discusses the\nmethodologies of various deep learning architectures such as convolutional\nneural networks, encoder-decoder networks, and transformers in analyzing\nmedical imaging data across different modalities. Despite the advancements, it\nstill confronts challenges like the shape diversity of lymph nodes, the\nscarcity of accurately labeled datasets, and the inadequate development of\nmethods that are robust and generalizable across different imaging modalities.\nTo the best of our knowledge, this is the first study that provides a\ncomprehensive overview of the application of deep learning techniques in lymph\nnode segmentation task. Furthermore, this study also explores potential future\nresearch directions, including multimodal fusion techniques, transfer learning,\nand the use of large-scale pre-trained models to overcome current limitations\nwhile enhancing cancer diagnosis and treatment planning strategies.", "published": "2025-05-09 15:17:00", "link": "http://arxiv.org/abs/2505.06118v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions", "abstract": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.", "published": "2025-05-09 15:11:13", "link": "http://arxiv.org/abs/2505.06111v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "abstract": "This study systematically evaluates 27 frontier Large Language Models on\neight diverse biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with the top model now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including LAB-Bench CloningScenarios and the biology\nsubsets of GPQA and WMDP. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.", "published": "2025-05-09 15:05:57", "link": "http://arxiv.org/abs/2505.06108v1", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs", "abstract": "Limitations in Large Language Model (LLM) capabilities for hardware design\ntasks, such as generating functional Verilog codes, have motivated various\nfine-tuning optimizations utilizing curated hardware datasets from open-source\nrepositories. However, these datasets remain limited in size and contain\nminimal checks on licensing for reuse, resulting in potential copyright\nviolations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to\nestimate the risk of Verilog-trained LLMs to generate copyright-protected\ncodes. To minimize this risk, we present an open-source Verilog dataset,\nFreeSet, containing over 220k files, along with the automated dataset curation\nframework utilized to provide additional guarantees of fair-use Verilog data.\nWe then execute an LLM fine-tuning framework consisting of continual\npre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our\nresults indicate that FreeV demonstrates the smallest risk of\ncopyright-infringement among prior works, with only a 3% violation rate.\nFurthermore, experimental results demonstrate improvements in Verilog\ngeneration functionality over its baseline model, improving VerilogEval pass@10\nrates by over 10%.", "published": "2025-05-09 14:44:07", "link": "http://arxiv.org/abs/2505.06096v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "UniSymNet: A Unified Symbolic Network Guided by Transformer", "abstract": "Symbolic Regression (SR) is a powerful technique for automatically\ndiscovering mathematical expressions from input data. Mainstream SR algorithms\nsearch for the optimal symbolic tree in a vast function space, but the\nincreasing complexity of the tree structure limits their performance. Inspired\nby neural networks, symbolic networks have emerged as a promising new paradigm.\nHowever, most existing symbolic networks still face certain challenges: binary\nnonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to\nmultivariate operators, and training with fixed architecture often leads to\nhigher complexity and overfitting. In this work, we propose a Unified Symbolic\nNetwork that unifies nonlinear binary operators into nested unary operators and\ndefine the conditions under which UniSymNet can reduce complexity. Moreover, we\npre-train a Transformer model with a novel label encoding method to guide\nstructural selection, and adopt objective-specific optimization strategies to\nlearn the parameters of the symbolic network. UniSymNet shows high fitting\naccuracy, excellent symbolic solution rate, and relatively low expression\ncomplexity, achieving competitive performance on low-dimensional Standard\nBenchmarks and high-dimensional SRBench.", "published": "2025-05-09 14:38:25", "link": "http://arxiv.org/abs/2505.06091v1", "categories": ["cs.LG", "cs.AI", "cs.SC"], "primary_category": "cs.LG"}
{"title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", "abstract": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.", "published": "2025-05-09 14:29:37", "link": "http://arxiv.org/abs/2505.06085v1", "categories": ["cs.PF", "cs.AI", "cs.AR"], "primary_category": "cs.PF"}
{"title": "Seqret: Mining Rule Sets from Event Sequences", "abstract": "Summarizing event sequences is a key aspect of data mining. Most existing\nmethods neglect conditional dependencies and focus on discovering sequential\npatterns only. In this paper, we study the problem of discovering both\nconditional and unconditional dependencies from event sequence data. We do so\nby discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are\nsequential patterns. Rules like these are simple to understand and provide a\nclear description of the relation between the antecedent and the consequent. To\ndiscover succinct and non-redundant sets of rules we formalize the problem in\nterms of the Minimum Description Length principle. As the search space is\nenormous and does not exhibit helpful structure, we propose the Seqret method\nto discover high-quality rule sets in practice. Through extensive empirical\nevaluation we show that unlike the state of the art, Seqret ably recovers the\nground truth on synthetic datasets and finds useful rules from real datasets.", "published": "2025-05-09 13:44:15", "link": "http://arxiv.org/abs/2505.06049v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks", "abstract": "Irregular temporal data, characterized by varying recording frequencies,\ndiffering observation durations, and missing values, presents significant\nchallenges across fields like mobility, healthcare, and environmental science.\nExisting research communities often overlook or address these challenges in\nisolation, leading to fragmented tools and methods. To bridge this gap, we\nintroduce a unified framework, and the first standardized dataset repository\nfor irregular time series classification, built on a common array format to\nenhance interoperability. This repository comprises 34 datasets on which we\nbenchmark 12 classifier models from diverse domains and communities. This work\naims to centralize research efforts and enable a more robust evaluation of\nirregular temporal data analysis methods.", "published": "2025-05-09 13:43:43", "link": "http://arxiv.org/abs/2505.06047v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects", "abstract": "Combining natural language and geometric shapes is an emerging research area\nwith multiple applications in robotics and language-assisted design. A crucial\ntask in this domain is object referent identification, which involves selecting\na 3D object given a textual description of the target. Variability in language\ndescriptions and spatial relationships of 3D objects makes this a complex task,\nincreasing the need to better understand the behavior of neural network models\nin this domain. However, limited research has been conducted in this area.\nSpecifically, when a model makes an incorrect prediction despite being provided\nwith a seemingly correct object description, practitioners are left wondering:\n\"Why is the model wrong?\". In this work, we present a method answering this\nquestion by generating counterfactual examples. Our method takes a\nmisclassified sample, which includes two objects and a text description, and\ngenerates an alternative yet similar formulation that would have resulted in a\ncorrect prediction by the model. We have evaluated our approach with data from\nthe ShapeTalk dataset along with three distinct models. Our counterfactual\nexamples maintain the structure of the original description, are semantically\nsimilar and meaningful. They reveal weaknesses in the description, model bias\nand enhance the understanding of the models behavior. Theses insights help\npractitioners to better interact with systems as well as engineers to improve\nmodels.", "published": "2025-05-09 13:24:44", "link": "http://arxiv.org/abs/2505.06030v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Universal Approximation Theorem for Deep Q-Learning via FBSDE System", "abstract": "The approximation capabilities of Deep Q-Networks (DQNs) are commonly\njustified by general Universal Approximation Theorems (UATs) that do not\nleverage the intrinsic structural properties of the optimal Q-function, the\nsolution to a Bellman equation. This paper establishes a UAT for a class of\nDQNs whose architecture is designed to emulate the iterative refinement process\ninherent in Bellman updates. A central element of our analysis is the\npropagation of regularity: while the transformation induced by a single Bellman\noperator application exhibits regularity, for which Backward Stochastic\nDifferential Equations (BSDEs) theory provides analytical tools, the uniform\nregularity of the entire sequence of value iteration iterates--specifically,\ntheir uniform Lipschitz continuity on compact domains under standard Lipschitz\nassumptions on the problem data--is derived from finite-horizon dynamic\nprogramming principles. We demonstrate that layers of a deep residual network,\nconceived as neural operators acting on function spaces, can approximate the\naction of the Bellman operator. The resulting approximation theorem is thus\nintrinsically linked to the control problem's structure, offering a proof\ntechnique wherein network depth directly corresponds to iterations of value\nfunction refinement, accompanied by controlled error propagation. This\nperspective reveals a dynamic systems view of the network's operation on a\nspace of value functions.", "published": "2025-05-09 13:11:55", "link": "http://arxiv.org/abs/2505.06023v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding", "abstract": "Understanding visual art requires reasoning across multiple perspectives --\ncultural, historical, and stylistic -- beyond mere object recognition. While\nrecent multimodal large language models (MLLMs) perform well on general image\ncaptioning, they often fail to capture the nuanced interpretations that fine\nart demands. We propose ArtRAG, a novel, training-free framework that combines\nstructured knowledge with retrieval-augmented generation (RAG) for\nmulti-perspective artwork explanation. ArtRAG automatically constructs an Art\nContext Knowledge Graph (ACKG) from domain-specific textual sources, organizing\nentities such as artists, movements, themes, and historical events into a rich,\ninterpretable graph. At inference time, a multi-granular structured retriever\nselects semantically and topologically relevant subgraphs to guide generation.\nThis enables MLLMs to produce contextually grounded, culturally informed art\ndescriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG\noutperforms several heavily trained baselines. Human evaluations further\nconfirm that ArtRAG generates coherent, insightful, and culturally enriched\ninterpretations.", "published": "2025-05-09 13:08:27", "link": "http://arxiv.org/abs/2505.06020v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned", "abstract": "MiniCalc is a web app for teaching first-order logic based on a minimal\nsequent calculus. As an option the proofs can be verified in the Isabelle proof\nassistant. We present the lessons learned using the tool in recent years at our\nuniversity.", "published": "2025-05-09 12:18:17", "link": "http://arxiv.org/abs/2505.05988v1", "categories": ["cs.LO", "cs.AI", "F.4; I.2.3; K.3.1"], "primary_category": "cs.LO"}
{"title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs", "abstract": "Configurable systems typically consist of reusable assets that have\ndependencies between each other. To specify such dependencies, feature models\nare commonly used. As feature models in practice are often complex, automated\nreasoning is typically employed to analyze the dependencies. Here, the de facto\nstandard is translating the feature model to conjunctive normal form (CNF) to\nenable employing off-the-shelf tools, such as SAT or #SAT solvers. However,\nmodern feature-modeling dialects often contain constructs, such as cardinality\nconstraints, that are ill-suited for conversion to CNF. This mismatch between\nthe input of reasoning engines and the available feature-modeling dialects\nlimits the applicability of the more expressive constructs. In this work, we\nshorten this gap between expressive constructs and scalable automated\nreasoning. Our contribution is twofold: First, we provide a pseudo-Boolean\nencoding for feature models, which facilitates smaller representations of\ncommonly employed constructs compared to Boolean encoding. Second, we propose a\nnovel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the\ncompiled d-DNNFs, we can resort to a plethora of efficient analyses already\nused in feature modeling. Our empirical evaluation shows that our proposal\nsubstantially outperforms the state-of-the-art based on CNF inputs for\nexpressive constructs. For every considered dataset representing different\nfeature models and feature-modeling constructs, the feature models can be\nsignificantly faster translated to pseudo-Boolean than to CNF. Overall,\nderiving d-DNNFs from a feature model with the targeted expressive constraints\ncan be substantially accelerated using our pseudo-Boolean approach.\nFurthermore, our approach is competitive on feature models with only basic\nconstructs.", "published": "2025-05-09 12:00:43", "link": "http://arxiv.org/abs/2505.05976v1", "categories": ["cs.AI", "cs.LO", "cs.SE"], "primary_category": "cs.AI"}
{"title": "A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection", "abstract": "Community detection in networks with overlapping structures remains a\nsignificant challenge, particularly in noisy real-world environments where\nintegrating topology, node attributes, and prior information is critical. To\naddress this, we propose a semi-supervised graph autoencoder that combines\ngraph multi-head attention and modularity maximization to robustly detect\noverlapping communities. The model learns semantic representations by fusing\nstructural, attribute, and prior knowledge while explicitly addressing noise in\nnode features. Key innovations include a noise-resistant architecture and a\nsemantic semi-supervised design optimized for community quality through\nmodularity constraints. Experiments demonstrate superior performance the model\noutperforms state-of-the-art methods in overlapping community detection\n(improvements in NMI and F1-score) and exhibits exceptional robustness to\nattribute noise, maintaining stable performance under 60\\% feature corruption.\nThese results highlight the importance of integrating attribute semantics and\nstructural patterns for accurate community discovery in complex networks.", "published": "2025-05-09 11:34:07", "link": "http://arxiv.org/abs/2505.05965v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Achieving 3D Attention via Triplet Squeeze and Excitation Block", "abstract": "The emergence of ConvNeXt and its variants has reaffirmed the conceptual and\nstructural suitability of CNN-based models for vision tasks, re-establishing\nthem as key players in image classification in general, and in facial\nexpression recognition (FER) in particular. In this paper, we propose a new set\nof models that build on these advancements by incorporating a new set of\nattention mechanisms that combines Triplet attention with\nSqueeze-and-Excitation (TripSE) in four different variants. We demonstrate the\neffectiveness of these variants by applying them to the ResNet18, DenseNet and\nConvNext architectures to validate their versatility and impact. Our study\nshows that incorporating a TripSE block in these CNN models boosts their\nperformances, particularly for the ConvNeXt architecture, indicating its\nutility. We evaluate the proposed mechanisms and associated models across four\ndatasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where\nConvNext with TripSE achieves state-of-the-art results with an accuracy of\n\\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset.", "published": "2025-05-09 10:36:30", "link": "http://arxiv.org/abs/2505.05943v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction", "abstract": "Many real-world datasets are time series that are sequentially collected and\ncontain rich temporal information. Thus, a common interest in practice is to\ncapture dynamics of time series and predict their future evolutions. To this\nend, the recurrent neural network (RNN) has been a prevalent and effective\nmachine learning option, which admits a nonlinear state-space model\nrepresentation. Motivated by the resemblance between RNN and Kalman filter (KF)\nfor linear state-space models, we propose in this paper Innovation-driven RNN\n(IRNN), a novel RNN architecture tailored to time-series data modeling and\nprediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past\nprediction errors are adopted as additional input signals to update hidden\nstates of RNN and boost prediction performance. Since innovation data depend on\nnetwork parameters, existing training algorithms for RNN do not apply to IRNN\nstraightforwardly. Thus, a tailored training algorithm dubbed input\nupdating-based back-propagation through time (IU-BPTT) is further proposed,\nwhich alternates between updating innovations and optimizing network parameters\nvia gradient descent. Experiments on real-world benchmark datasets show that\nthe integration of innovations into various forms of RNN leads to remarkably\nimproved prediction accuracy of IRNN without increasing the training cost\nsubstantially.", "published": "2025-05-09 09:43:40", "link": "http://arxiv.org/abs/2505.05916v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection", "abstract": "In this paper, we go beyond identifying anomalies only in structural terms\nand think about better anomaly detection motivated by anomaly causes. Most\nanomalies are regarded as the result of unpredictable defective forces from\ninternal and external sources, and their opposite forces are sought to correct\nthe anomalies. We introduced a Mechanics Complementary framework for 3D anomaly\ndetection (MC4AD) to generate internal and external Corrective forces for each\npoint. A Diverse Anomaly-Generation (DA-Gen) module is first proposed to\nsimulate various anomalies. Then, we present a Corrective Force Prediction\nNetwork (CFP-Net) with complementary representations for point-level\nrepresentation to simulate the different contributions of internal and external\ncorrective forces. A combined loss was proposed, including a new symmetric loss\nand an overall loss, to constrain the corrective forces properly. As a\nhighlight, we consider 3D anomaly detection in industry more comprehensively,\ncreating a hierarchical quality control strategy based on a three-way decision\nand contributing a dataset named Anomaly-IntraVariance with intraclass variance\nto evaluate the model. On the proposed and existing five datasets, we obtained\nnine state-of-the-art performers with the minimum parameters and the fastest\ninference speed. The source is available at\nhttps://github.com/hzzzzzhappy/MC4AD", "published": "2025-05-09 09:09:08", "link": "http://arxiv.org/abs/2505.05901v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI", "abstract": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.2% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.4% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs.", "published": "2025-05-09 09:01:52", "link": "http://arxiv.org/abs/2505.05895v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization", "abstract": "Recent advances in Protein Structure Prediction Models (PPMs), such as\nAlphaFold2 and ESMFold, have revolutionized computational biology by achieving\nunprecedented accuracy in predicting three-dimensional protein folding\nstructures. However, these models face significant scalability challenges,\nparticularly when processing proteins with long amino acid sequences (e.g.,\nsequence length > 1,000). The primary bottleneck that arises from the\nexponential growth in activation sizes is driven by the unique data structure\nin PPM, which introduces an additional dimension that leads to substantial\nmemory and computational demands. These limitations have hindered the effective\nscaling of PPM for real-world applications, such as analyzing large proteins or\ncomplex multimers with critical biological and pharmaceutical relevance.\n  In this paper, we present LightNobel, the first hardware-software co-designed\naccelerator developed to overcome scalability limitations on the sequence\nlength in PPM. At the software level, we propose Token-wise Adaptive Activation\nQuantization (AAQ), which leverages unique token-wise characteristics, such as\ndistogram patterns in PPM activations, to enable fine-grained quantization\ntechniques without compromising accuracy. At the hardware level, LightNobel\nintegrates the multi-precision reconfigurable matrix processing unit (RMPU) and\nversatile vector processing unit (VVPU) to enable the efficient execution of\nAAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup\nand 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100\nGPUs, respectively, while maintaining negligible accuracy loss. It also reduces\nthe peak memory requirement up to 120.05x in PPM, enabling scalable processing\nfor proteins with long sequences.", "published": "2025-05-09 09:01:10", "link": "http://arxiv.org/abs/2505.05893v1", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.LG", "B.7; I.2; J.3"], "primary_category": "cs.AR"}
{"title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams", "abstract": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.", "published": "2025-05-09 08:45:07", "link": "http://arxiv.org/abs/2505.05880v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multi-Modal Molecular Representation Learning via Structure Awareness", "abstract": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.", "published": "2025-05-09 08:37:29", "link": "http://arxiv.org/abs/2505.05877v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Facial Image Compression with Consistency Preserving Diffusion Prior", "abstract": "With the widespread application of facial image data across various domains,\nthe efficient storage and transmission of facial images has garnered\nsignificant attention. However, the existing learned face image compression\nmethods often produce unsatisfactory reconstructed image quality at low bit\nrates. Simply adapting diffusion-based compression methods to facial\ncompression tasks results in reconstructed images that perform poorly in\ndownstream applications due to insufficient preservation of high-frequency\ninformation. To further explore the diffusion prior in facial image\ncompression, we propose Facial Image Compression with a Stable Diffusion Prior\n(FaSDiff), a method that preserves consistency through frequency enhancement.\nFaSDiff employs a high-frequency-sensitive compressor in an end-to-end\nframework to capture fine image details and produce robust visual prompts.\nAdditionally, we introduce a hybrid low-frequency enhancement module that\ndisentangles low-frequency facial semantics and stably modulates the diffusion\nprior alongside visual prompts. The proposed modules allow FaSDiff to leverage\ndiffusion priors for superior human visual perception while minimizing\nperformance loss in machine vision due to semantic inconsistency. Extensive\nexperiments show that FaSDiff outperforms state-of-the-art methods in balancing\nhuman visual quality and machine vision accuracy. The code will be released\nafter the paper is accepted.", "published": "2025-05-09 08:13:51", "link": "http://arxiv.org/abs/2505.05870v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Generative Discovery of Partial Differential Equations by Learning from Math Handbooks", "abstract": "Data driven discovery of partial differential equations (PDEs) is a promising\napproach for uncovering the underlying laws governing complex systems. However,\npurely data driven techniques face the dilemma of balancing search space with\noptimization efficiency. This study introduces a knowledge guided approach that\nincorporates existing PDEs documented in a mathematical handbook to facilitate\nthe discovery process. These PDEs are encoded as sentence like structures\ncomposed of operators and basic terms, and used to train a generative model,\ncalled EqGPT, which enables the generation of free form PDEs. A loop of\ngeneration evaluation optimization is constructed to autonomously identify the\nmost suitable PDE. Experimental results demonstrate that this framework can\nrecover a variety of PDE forms with high accuracy and computational efficiency,\nparticularly in cases involving complex temporal derivatives or intricate\nspatial terms, which are often beyond the reach of conventional methods. The\napproach also exhibits generalizability to irregular spatial domains and higher\ndimensional settings. Notably, it succeeds in discovering a previously\nunreported PDE governing strongly nonlinear surface gravity waves propagating\ntoward breaking, based on real world experimental data, highlighting its\napplicability to practical scenarios and its potential to support scientific\ndiscovery.", "published": "2025-05-09 08:09:21", "link": "http://arxiv.org/abs/2505.05869v1", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "abstract": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites.", "published": "2025-05-09 07:40:17", "link": "http://arxiv.org/abs/2505.05849v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design", "abstract": "Mixture-of-Experts (MoE) models face deployment challenges due to their large\nparameter counts and computational demands. We explore quantization for MoE\nmodels and highlight two key insights: 1) linear blocks exhibit varying\nquantization sensitivity, and 2) divergent expert activation frequencies create\nheterogeneous computational characteristics. Based on these observations, we\nintroduce MxMoE, a mixed-precision optimization framework for MoE models that\nconsiders both algorithmic and system perspectives. MxMoE navigates the design\nspace defined by parameter sensitivity, expert activation dynamics, and\nhardware resources to derive efficient mixed-precision configurations.\nAdditionally, MxMoE automatically generates optimized mixed-precision GroupGEMM\nkernels, enabling parallel execution of GEMMs with different precisions.\nEvaluations show that MxMoE outperforms existing methods, achieving 2.4 lower\nWikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup\nover full precision, as well as up to 29.4% speedup over uniform quantization\nat equivalent accuracy with 5-bit weight-activation quantization. Our code is\navailable at https://github.com/cat538/MxMoE.", "published": "2025-05-09 05:32:21", "link": "http://arxiv.org/abs/2505.05799v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency", "abstract": "Heating, Ventilation, and Air Conditioning (HVAC) systems account for\napproximately 38% of building energy consumption globally, making them one of\nthe most energy-intensive services. The increasing emphasis on energy\nefficiency and sustainability, combined with the need for enhanced occupant\ncomfort, presents a significant challenge for traditional HVAC systems. These\nsystems often fail to dynamically adjust to real-time changes in electricity\nmarket rates or individual comfort preferences, leading to increased energy\ncosts and reduced comfort. In response, we propose a Human-in-the-Loop (HITL)\nArtificial Intelligence framework that optimizes HVAC performance by\nincorporating real-time user feedback and responding to fluctuating electricity\nprices. Unlike conventional systems that require predefined information about\noccupancy or comfort levels, our approach learns and adapts based on ongoing\nuser input. By integrating the occupancy prediction model with reinforcement\nlearning, the system improves operational efficiency and reduces energy costs\nin line with electricity market dynamics, thereby contributing to demand\nresponse initiatives. Through simulations, we demonstrate that our method\nachieves significant cost reductions compared to baseline approaches while\nmaintaining or enhancing occupant comfort. This feedback-driven approach\nensures personalized comfort control without the need for predefined settings,\noffering a scalable solution that balances individual preferences with economic\nand environmental goals.", "published": "2025-05-09 05:23:37", "link": "http://arxiv.org/abs/2505.05796v1", "categories": ["eess.SY", "cs.AI", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips", "abstract": "Large language models (LLMs) are rapidly pushing the limits of contemporary\ncomputing hardware. For example, training GPT-3 has been estimated to consume\naround 1300 MWh of electricity, and projections suggest future models may\nrequire city-scale (gigawatt) power budgets. These demands motivate exploration\nof computing paradigms beyond conventional von Neumann architectures. This\nreview surveys emerging photonic hardware optimized for next-generation\ngenerative AI computing. We discuss integrated photonic neural network\narchitectures (e.g., Mach-Zehnder interferometer meshes, lasers,\nwavelength-multiplexed microring resonators) that perform ultrafast matrix\noperations. We also examine promising alternative neuromorphic devices,\nincluding spiking neural network circuits and hybrid spintronic-photonic\nsynapses, which combine memory and processing. The integration of\ntwo-dimensional materials (graphene, TMDCs) into silicon photonic platforms is\nreviewed for tunable modulators and on-chip synaptic elements.\nTransformer-based LLM architectures (self-attention and feed-forward layers)\nare analyzed in this context, identifying strategies and challenges for mapping\ndynamic matrix multiplications onto these novel hardware substrates. We then\ndissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and\nLLaMA, highlighting their architectural similarities and differences. We\nsynthesize state-of-the-art components, algorithms, and integration methods,\nhighlighting key advances and open issues in scaling such systems to mega-sized\nLLM models. We find that photonic computing systems could potentially surpass\nelectronic processors by orders of magnitude in throughput and energy\nefficiency, but require breakthroughs in memory, especially for long-context\nwindows and long token sequences, and in storage of ultra-large datasets.", "published": "2025-05-09 05:19:14", "link": "http://arxiv.org/abs/2505.05794v1", "categories": ["cs.AR", "cs.AI", "cs.NE"], "primary_category": "cs.AR"}
{"title": "FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions", "abstract": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.", "published": "2025-05-09 04:58:14", "link": "http://arxiv.org/abs/2505.05784v1", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "q-fin.CP"], "primary_category": "q-fin.TR"}
{"title": "PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection", "abstract": "This paper presents PyResBugs, a curated dataset of residual bugs, i.e.,\ndefects that persist undetected during traditional testing but later surface in\nproduction, collected from major Python frameworks. Each bug in the dataset is\npaired with its corresponding fault-free (fixed) version and annotated with\nmulti-level natural language (NL) descriptions. These NL descriptions enable\nnatural language-driven fault injection, offering a novel approach to\nsimulating real-world faults in software systems. By bridging the gap between\nsoftware fault injection techniques and real-world representativeness,\nPyResBugs provides researchers with a high-quality resource for advancing\nAI-driven automated testing in Python systems.", "published": "2025-05-09 04:39:09", "link": "http://arxiv.org/abs/2505.05777v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition", "abstract": "Diabetic macular edema (DME) significantly contributes to visual impairment\nin diabetic patients. Treatment responses to intravitreal therapies vary,\nhighlighting the need for patient stratification to predict therapeutic\nbenefits and enable personalized strategies. To our knowledge, this study is\nthe first to explore pre-treatment stratification for predicting DME treatment\nresponses. To advance this research, we organized the 2nd Asia-Pacific\nTele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The\ncompetition focused on improving predictive accuracy for anti-VEGF therapy\nresponses using ophthalmic OCT images. We provided a dataset containing tens of\nthousands of OCT images from 2,000 patients with labels across four sub-tasks.\nThis paper details the competition's structure, dataset, leading methods, and\nevaluation metrics. The competition attracted strong scientific community\nparticipation, with 170 teams initially registering and 41 reaching the final\nround. The top-performing team achieved an AUC of 80.06%, highlighting the\npotential of AI in personalized DME treatment and clinical decision-making.", "published": "2025-05-09 04:12:05", "link": "http://arxiv.org/abs/2505.05768v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Multi-Agent Systems for Robotic Autonomy with LLMs", "abstract": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications.", "published": "2025-05-09 03:52:37", "link": "http://arxiv.org/abs/2505.05762v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning", "abstract": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.", "published": "2025-05-09 03:38:31", "link": "http://arxiv.org/abs/2505.05758v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms", "abstract": "Large Language Models (LLMs) have unveiled remarkable capabilities in\nunderstanding and generating both natural language and code, but LLM reasoning\nis prone to hallucination and struggle with complex, novel scenarios, often\ngetting stuck on partial or incorrect solutions. However, the inherent ability\nof Evolutionary Algorithms (EAs) to explore extensive and complex search spaces\nmakes them particularly effective in scenarios where traditional optimization\nmethodologies may falter. However, EAs explore a vast search space when applied\nto complex problems.\n  To address the computational bottleneck of evaluating large populations,\nparticularly crucial for complex evolutionary tasks, we introduce a highly\nefficient evaluation framework. This implementation maintains compatibility\nwith existing primitive definitions, ensuring the generation of valid\nindividuals.\n  Using LLMs, we propose an enhanced evolutionary search strategy that enables\na more focused exploration of expansive solution spaces. LLMs facilitate the\ngeneration of superior candidate solutions, as evidenced by empirical results\ndemonstrating their efficacy in producing improved outcomes.", "published": "2025-05-09 03:32:18", "link": "http://arxiv.org/abs/2505.05756v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Towards Embodiment Scaling Laws in Robot Locomotion", "abstract": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond.", "published": "2025-05-09 03:25:43", "link": "http://arxiv.org/abs/2505.05753v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering", "abstract": "Accurate and efficient multivariate time series (MTS) forecasting is\nessential for applications such as traffic management and weather prediction,\nwhich depend on capturing long-range temporal dependencies and interactions\nbetween entities. Existing methods, particularly those based on Transformer\narchitectures, compute pairwise dependencies across all time steps, leading to\na computational complexity that scales quadratically with the length of the\ninput. To overcome these challenges, we introduce the Forecaster with Offline\nClustering Using Segments (FOCUS), a novel approach to MTS forecasting that\nsimplifies long-range dependency modeling through the use of prototypes\nextracted via offline clustering. These prototypes encapsulate high-level\nevents in the real-world system underlying the data, summarizing the key\ncharacteristics of similar time segments. In the online phase, FOCUS\ndynamically adapts these patterns to the current input and captures\ndependencies between the input segment and high-level events, enabling both\naccurate and efficient forecasting. By identifying prototypes during the\noffline clustering phase, FOCUS reduces the computational complexity of\nmodeling long-range dependencies in the online phase to linear scaling.\nExtensive experiments across diverse benchmarks demonstrate that FOCUS achieves\nstate-of-the-art accuracy while significantly reducing computational costs.", "published": "2025-05-09 02:34:06", "link": "http://arxiv.org/abs/2505.05738v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder", "abstract": "Hyperspectral imagery provides rich spectral detail but poses unique\nchallenges because of its high dimensionality in both spatial and spectral\ndomains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation\nmodel for hyperspectral data that employs a \\textit{dual masking} strategy:\nduring pre-training we randomly occlude 50\\% of spatial patches and 50\\% of\nspectral bands. This forces the model to learn representations capable of\nreconstructing missing information across both dimensions. To encode spectral\norder, we introduce learnable harmonic Fourier positional embeddings based on\nwavelength. The reconstruction objective combines mean-squared error (MSE) with\nthe spectral angle mapper (SAM) to balance pixel-level accuracy and\nspectral-shape fidelity.\n  The resulting model contains about $1.8\\times10^{8}$ parameters and produces\n768-dimensional embeddings, giving it sufficient capacity for transfer\nlearning. We pre-trained HyperspectralMAE on two large hyperspectral corpora --\nNASA EO-1 Hyperion ($\\sim$1\\,600 scenes, $\\sim$$3\\times10^{11}$ pixel spectra)\nand DLR EnMAP Level-0 ($\\sim$1\\,300 scenes, $\\sim$$3\\times10^{11}$ pixel\nspectra) -- and fine-tuned it for land-cover classification on the Indian Pines\nbenchmark. HyperspectralMAE achieves state-of-the-art transfer-learning\naccuracy on Indian Pines, confirming that masked dual-dimensional pre-training\nyields robust spectral-spatial representations. These results demonstrate that\ndual masking and wavelength-aware embeddings advance hyperspectral image\nreconstruction and downstream analysis.", "published": "2025-05-09 01:16:42", "link": "http://arxiv.org/abs/2505.05710v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning", "abstract": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets.", "published": "2025-05-09 00:26:01", "link": "http://arxiv.org/abs/2505.05701v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Anymate: A Dataset and Baselines for Learning 3D Object Rigging", "abstract": "Rigging and skinning are essential steps to create realistic 3D animations,\noften requiring significant expertise and manual effort. Traditional attempts\nat automating these processes rely heavily on geometric heuristics and often\nstruggle with objects of complex geometry. Recent data-driven approaches show\npotential for better generality, but are often constrained by limited training\ndata. We present the Anymate Dataset, a large-scale dataset of 230K 3D assets\npaired with expert-crafted rigging and skinning information -- 70 times larger\nthan existing datasets. Using this dataset, we propose a learning-based\nauto-rigging framework with three sequential modules for joint, connectivity,\nand skinning weight prediction. We systematically design and experiment with\nvarious architectures as baselines for each module and conduct comprehensive\nevaluations on our dataset to compare their performance. Our models\nsignificantly outperform existing methods, providing a foundation for comparing\nfuture methods in automated rigging and skinning. Code and dataset can be found\nat https://anymate3d.github.io/.", "published": "2025-05-09 17:59:33", "link": "http://arxiv.org/abs/2505.06227v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction", "abstract": "Next Best View (NBV) algorithms aim to acquire an optimal set of images using\nminimal resources, time, or number of captures to enable efficient 3D\nreconstruction of a scene. Existing approaches often rely on prior scene\nknowledge or additional image captures and often develop policies that maximize\ncoverage. Yet, for many real scenes with complex geometry and self-occlusions,\ncoverage maximization does not lead to better reconstruction quality directly.\nIn this paper, we propose the View Introspection Network (VIN), which is\ntrained to predict the reconstruction quality improvement of views directly,\nand the VIN-NBV policy. A greedy sequential sampling-based policy, where at\neach acquisition step, we sample multiple query views and choose the one with\nthe highest VIN predicted improvement score. We design the VIN to perform\n3D-aware featurization of the reconstruction built from prior acquisitions, and\nfor each query view create a feature that can be decoded into an improvement\nscore. We then train the VIN using imitation learning to predict the\nreconstruction improvement score. We show that VIN-NBV improves reconstruction\nquality by ~30% over a coverage maximization baseline when operating with\nconstraints on the number of acquisitions or the time in motion.", "published": "2025-05-09 17:54:10", "link": "http://arxiv.org/abs/2505.06219v1", "categories": ["cs.CV", "cs.RO", "I.2.10; I.2.9"], "primary_category": "cs.CV"}
{"title": "Adapting a Segmentation Foundation Model for Medical Image Classification", "abstract": "Recent advancements in foundation models, such as the Segment Anything Model\n(SAM), have shown strong performance in various vision tasks, particularly\nimage segmentation, due to their impressive zero-shot segmentation\ncapabilities. However, effectively adapting such models for medical image\nclassification is still a less explored topic. In this paper, we introduce a\nnew framework to adapt SAM for medical image classification. First, we utilize\nthe SAM image encoder as a feature extractor to capture segmentation-based\nfeatures that convey important spatial and contextual details of the image,\nwhile freezing its weights to avoid unnecessary overhead during training. Next,\nwe propose a novel Spatially Localized Channel Attention (SLCA) mechanism to\ncompute spatially localized attention weights for the feature maps. The\nfeatures extracted from SAM's image encoder are processed through SLCA to\ncompute attention weights, which are then integrated into deep learning\nclassification models to enhance their focus on spatially relevant or\nmeaningful regions of the image, thus improving classification performance.\nExperimental results on three public medical image classification datasets\ndemonstrate the effectiveness and data-efficiency of our approach.", "published": "2025-05-09 17:51:51", "link": "http://arxiv.org/abs/2505.06217v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation", "abstract": "Convolutional neural network (CNN) and Transformer-based architectures are\ntwo dominant deep learning models for polyp segmentation. However, CNNs have\nlimited capability for modeling long-range dependencies, while Transformers\nincur quadratic computational complexity. Recently, State Space Models such as\nMamba have been recognized as a promising approach for polyp segmentation\nbecause they not only model long-range interactions effectively but also\nmaintain linear computational complexity. However, Mamba-based architectures\nstill struggle to capture topological features (e.g., connected components,\nloops, voids), leading to inaccurate boundary delineation and polyp\nsegmentation. To address these limitations, we propose a new approach called\nTopo-VM-UNetV2, which encodes topological features into the Mamba-based\nstate-of-the-art polyp segmentation model, VM-UNetV2. Our method consists of\ntwo stages: Stage 1: VM-UNetV2 is used to generate probability maps (PMs) for\nthe training and test images, which are then used to compute topology attention\nmaps. Specifically, we first compute persistence diagrams of the PMs, then we\ngenerate persistence score maps by assigning persistence values (i.e., the\ndifference between death and birth times) of each topological feature to its\nbirth location, finally we transform persistence scores into attention weights\nusing the sigmoid function. Stage 2: These topology attention maps are\nintegrated into the semantics and detail infusion (SDI) module of VM-UNetV2 to\nform a topology-guided semantics and detail infusion (Topo-SDI) module for\nenhancing the segmentation results. Extensive experiments on five public polyp\nsegmentation datasets demonstrate the effectiveness of our proposed method. The\ncode will be made publicly available.", "published": "2025-05-09 17:41:13", "link": "http://arxiv.org/abs/2505.06210v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet", "abstract": "This paper proposes a method MTL-Swin-Unet which is multi-task learning using\ntransformers for classification and semantic segmentation. For\nspurious-correlation problems, this method allows us to enhance the image\nrepresentation with two other image representations: representation obtained by\nsemantic segmentation and representation obtained by image reconstruction. In\nour experiments, the proposed method outperformed in F-value measure than other\nclassifiers when the test data included slices from the same patient (no\ncovariate shift). Similarly, when the test data did not include slices from the\nsame patient (covariate shift setting), the proposed method outperformed in AUC\nmeasure.", "published": "2025-05-09 16:54:26", "link": "http://arxiv.org/abs/2505.06185v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills", "abstract": "Retouching is an essential task in post-manipulation of raw photographs.\nGenerative editing, guided by text or strokes, provides a new tool accessible\nto users but can easily change the identity of the original objects in\nunacceptable and unpredictable ways. In contrast, although traditional\nprocedural edits, as commonly supported by photoediting tools (e.g., Gimp,\nLightroom), are conservative, they are still preferred by professionals.\nUnfortunately, professional quality retouching involves many individual\nprocedural editing operations that is challenging to plan for most novices. In\nthis paper, we ask if a multimodal large language model (MLLM) can be taught to\ncritique raw photographs, suggest suitable remedies, and finally realize them\nwith a given set of pre-authored procedural image operations. We demonstrate\nthat MLLMs can be first made aware of the underlying image processing\noperations, by training them to solve specially designed visual puzzles.\nSubsequently, such an operation-aware MLLM can both plan and propose edit\nsequences. To facilitate training, given a set of expert-edited photos, we\nsynthesize a reasoning dataset by procedurally manipulating the expert edits\nand then grounding a pretrained LLM on the visual adjustments, to synthesize\nreasoning for finetuning. The proposed retouching operations are, by\nconstruction, understandable by the users, preserve object details and\nresolution, and can be optionally overridden. We evaluate our setup on a\nvariety of test examples and show advantages, in terms of explainability and\nidentity preservation, over existing generative and other procedural\nalternatives. Code, data, models, and supplementary results can be found via\nour project website at https://monetgpt.github.io.", "published": "2025-05-09 16:38:27", "link": "http://arxiv.org/abs/2505.06176v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models", "abstract": "We address the task of generating 3D hair geometry from a single image, which\nis challenging due to the diversity of hairstyles and the lack of paired\nimage-to-3D hair data. Previous methods are primarily trained on synthetic data\nand cope with the limited amount of such data by using low-dimensional\nintermediate representations, such as guide strands and scalp-level embeddings,\nthat require post-processing to decode, upsample, and add realism. These\napproaches fail to reconstruct detailed hair, struggle with curly hair, or are\nlimited to handling only a few hairstyles. To overcome these limitations, we\npropose DiffLocks, a novel framework that enables detailed reconstruction of a\nwide variety of hairstyles directly from a single image. First, we address the\nlack of 3D hair data by automating the creation of the largest synthetic hair\ndataset to date, containing 40K hairstyles. Second, we leverage the synthetic\nhair dataset to learn an image-conditioned diffusion-transfomer model that\ngenerates accurate 3D strands from a single frontal image. By using a\npretrained image backbone, our method generalizes to in-the-wild images despite\nbeing trained only on synthetic data. Our diffusion model predicts a scalp\ntexture map in which any point in the map contains the latent code for an\nindividual hair strand. These codes are directly decoded to 3D strands without\npost-processing techniques. Representing individual strands, instead of guide\nstrands, enables the transformer to model the detailed spatial structure of\ncomplex hairstyles. With this, DiffLocks can recover highly curled hair, like\nafro hairstyles, from a single image for the first time. Data and code is\navailable at https://radualexandru.github.io/difflocks/", "published": "2025-05-09 16:16:42", "link": "http://arxiv.org/abs/2505.06166v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation", "abstract": "The segmentation of substantial brain lesions is a significant and\nchallenging task in the field of medical image segmentation. Substantial brain\nlesions in brain imaging exhibit high heterogeneity, with indistinct boundaries\nbetween lesion regions and normal brain tissue. Small lesions in single slices\nare difficult to identify, making the accurate and reproducible segmentation of\nabnormal regions, as well as their feature description, highly complex.\nExisting methods have the following limitations: 1) They rely solely on\nsingle-modal information for learning, neglecting the multi-modal information\ncommonly used in diagnosis. This hampers the ability to comprehensively acquire\nbrain lesion information from multiple perspectives and prevents the effective\nintegration and utilization of multi-modal data inputs, thereby limiting a\nholistic understanding of lesions. 2) They are constrained by the amount of\ndata available, leading to low sensitivity to small lesions and difficulty in\ndetecting subtle pathological changes. 3) Current SAM-based models rely on\nexternal prompts, which cannot achieve automatic segmentation and, to some\nextent, affect diagnostic efficiency.To address these issues, we have developed\na large-scale fully automated segmentation model specifically designed for\nbrain lesion segmentation, named BrainSegDMLF. This model has the following\nfeatures: 1) Dynamic Modal Interactive Fusion (DMIF) module that processes and\nintegrates multi-modal data during the encoding process, providing the SAM\nencoder with more comprehensive modal information. 2) Layer-by-Layer Upsampling\nDecoder, enabling the model to extract rich low-level and high-level features\neven with limited data, thereby detecting the presence of small lesions. 3)\nAutomatic segmentation masks, allowing the model to generate lesion masks\nautomatically without requiring manual prompts.", "published": "2025-05-09 15:40:09", "link": "http://arxiv.org/abs/2505.06133v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation", "abstract": "Accurate defect detection of photovoltaic (PV) cells is critical for ensuring\nquality and efficiency in intelligent PV manufacturing systems. However, the\nscarcity of rich defect data poses substantial challenges for effective model\ntraining. While existing methods have explored generative models to augment\ndatasets, they often suffer from instability, limited diversity, and domain\nshifts. To address these issues, we propose PDIG, a Photovoltaic Defect Image\nGenerator based on Stable Diffusion (SD). PDIG leverages the strong priors\nlearned from large-scale datasets to enhance generation quality under limited\ndata. Specifically, we introduce a Semantic Concept Embedding (SCE) module that\nincorporates text-conditioned priors to capture the relational concepts between\ndefect types and their appearances. To further enrich the domain distribution,\nwe design a Lightweight Industrial Style Adaptor (LISA), which injects\nindustrial defect characteristics into the SD model through cross-disentangled\nattention. At inference, we propose a Text-Image Dual-Space Constraints (TIDSC)\nmodule, enforcing the quality of generated images via positional consistency\nand spatial smoothing alignment. Extensive experiments demonstrate that PDIG\nachieves superior realism and diversity compared to state-of-the-art methods.\nSpecifically, our approach improves Frechet Inception Distance (FID) by 19.16\npoints over the second-best method and significantly enhances the performance\nof downstream defect detection tasks.", "published": "2025-05-09 15:16:42", "link": "http://arxiv.org/abs/2505.06117v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles", "abstract": "Autonomous vehicle perception systems have traditionally relied on costly\nLiDAR sensors to generate precise environmental representations. In this paper,\nwe propose a camera-only perception framework that produces Bird's Eye View\n(BEV) maps by extending the Lift-Splat-Shoot architecture. Our method combines\nYOLOv11-based object detection with DepthAnythingV2 monocular depth estimation\nacross multi-camera inputs to achieve comprehensive 360-degree scene\nunderstanding. We evaluate our approach on the OpenLane-V2 and NuScenes\ndatasets, achieving up to 85% road segmentation accuracy and 85-90% vehicle\ndetection rates when compared against LiDAR ground truth, with average\npositional errors limited to 1.2 meters. These results highlight the potential\nof deep learning to extract rich spatial information using only camera inputs,\nenabling cost-efficient autonomous navigation without sacrificing accuracy.", "published": "2025-05-09 15:13:04", "link": "http://arxiv.org/abs/2505.06113v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "S2MNet: Speckle-To-Mesh Net for Three-Dimensional Cardiac Morphology Reconstruction via Echocardiogram", "abstract": "Echocardiogram is the most commonly used imaging modality in cardiac\nassessment duo to its non-invasive nature, real-time capability, and\ncost-effectiveness. Despite its advantages, most clinical echocardiograms\nprovide only two-dimensional views, limiting the ability to fully assess\ncardiac anatomy and function in three dimensions. While three-dimensional\nechocardiography exists, it often suffers from reduced resolution, limited\navailability, and higher acquisition costs. To overcome these challenges, we\npropose a deep learning framework S2MNet that reconstructs continuous and\nhigh-fidelity 3D heart models by integrating six slices of routinely acquired\n2D echocardiogram views. Our method has three advantages. First, our method\navoid the difficulties on training data acquasition by simulate six of 2D\nechocardiogram images from corresponding slices of a given 3D heart mesh.\nSecond, we introduce a deformation field-based method, which avoid spatial\ndiscontinuities or structural artifacts in 3D echocardiogram reconstructions.\nWe validate our method using clinically collected echocardiogram and\ndemonstrate that our estimated left ventricular volume, a key clinical\nindicator of cardiac function, is strongly correlated with the doctor measured\nGLPS, a clinical measurement that should demonstrate a negative correlation\nwith LVE in medical theory. This association confirms the reliability of our\nproposed 3D construction method.", "published": "2025-05-09 14:56:48", "link": "http://arxiv.org/abs/2505.06105v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations", "abstract": "Preference feedback collected by human or VLM annotators is often noisy,\npresenting a significant challenge for preference-based reinforcement learning\nthat relies on accurate preference labels. To address this challenge, we\npropose TREND, a novel framework that integrates few-shot expert demonstrations\nwith a tri-teaching strategy for effective noise mitigation. Our method trains\nthree reward models simultaneously, where each model views its small-loss\npreference pairs as useful knowledge and teaches such useful pairs to its peer\nnetwork for updating the parameters. Remarkably, our approach requires as few\nas one to three expert demonstrations to achieve high performance. We evaluate\nTREND on various robotic manipulation tasks, achieving up to 90% success rates\neven with noise levels as high as 40%, highlighting its effective robustness in\nhandling noisy preference feedback. Project page:\nhttps://shuaiyihuang.github.io/publications/TREND.", "published": "2025-05-09 14:22:43", "link": "http://arxiv.org/abs/2505.06079v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation", "abstract": "Deep learning has revolutionized medical image segmentation, yet its full\npotential remains constrained by the paucity of annotated datasets. While\ndiffusion models have emerged as a promising approach for generating synthetic\nimage-mask pairs to augment these datasets, they paradoxically suffer from the\nsame data scarcity challenges they aim to mitigate. Traditional mask-only\nmodels frequently yield low-fidelity images due to their inability to\nadequately capture morphological intricacies, which can critically compromise\nthe robustness and reliability of segmentation models. To alleviate this\nlimitation, we introduce Siamese-Diffusion, a novel dual-component model\ncomprising Mask-Diffusion and Image-Diffusion. During training, a Noise\nConsistency Loss is introduced between these components to enhance the\nmorphological fidelity of Mask-Diffusion in the parameter space. During\nsampling, only Mask-Diffusion is used, ensuring diversity and scalability.\nComprehensive experiments demonstrate the superiority of our method.\nSiamese-Diffusion boosts SANet's mDice and mIoU by 3.6% and 4.4% on the Polyps,\nwhile UNet improves by 1.52% and 1.64% on the ISIC2018. Code is available at\nGitHub.", "published": "2025-05-09 14:07:27", "link": "http://arxiv.org/abs/2505.06068v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Better Cephalometric Landmark Detection with Diffusion Data Generation", "abstract": "Cephalometric landmark detection is essential for orthodontic diagnostics and\ntreatment planning. Nevertheless, the scarcity of samples in data collection\nand the extensive effort required for manual annotation have significantly\nimpeded the availability of diverse datasets. This limitation has restricted\nthe effectiveness of deep learning-based detection methods, particularly those\nbased on large-scale vision models. To address these challenges, we have\ndeveloped an innovative data generation method capable of producing diverse\ncephalometric X-ray images along with corresponding annotations without human\nintervention. To achieve this, our approach initiates by constructing new\ncephalometric landmark annotations using anatomical priors. Then, we employ a\ndiffusion-based generator to create realistic X-ray images that correspond\nclosely with these annotations. To achieve precise control in producing samples\nwith different attributes, we introduce a novel prompt cephalometric X-ray\nimage dataset. This dataset includes real cephalometric X-ray images and\ndetailed medical text prompts describing the images. By leveraging these\ndetailed prompts, our method improves the generation process to control\ndifferent styles and attributes. Facilitated by the large, diverse generated\ndata, we introduce large-scale vision detection models into the cephalometric\nlandmark detection task to improve accuracy. Experimental results demonstrate\nthat training with the generated data substantially enhances the performance.\nCompared to methods without using the generated data, our approach improves the\nSuccess Detection Rate (SDR) by 6.5%, attaining a notable 82.2%. All code and\ndata are available at: https://um-lab.github.io/cepha-generation", "published": "2025-05-09 13:50:27", "link": "http://arxiv.org/abs/2505.06055v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Document Image Rectification Bases on Self-Adaptive Multitask Fusion", "abstract": "Deformed document image rectification is essential for real-world document\nunderstanding tasks, such as layout analysis and text recognition. However,\ncurrent multi-task methods -- such as background removal, 3D coordinate\nprediction, and text line segmentation -- often overlook the complementary\nfeatures between tasks and their interactions. To address this gap, we propose\na self-adaptive learnable multi-task fusion rectification network named\nSalmRec. This network incorporates an inter-task feature aggregation module\nthat adaptively improves the perception of geometric distortions, enhances\nfeature complementarity, and reduces negative interference. We also introduce a\ngating mechanism to balance features both within global tasks and between local\ntasks effectively. Experimental results on two English benchmarks (DIR300 and\nDocUNet) and one Chinese benchmark (DocReal) demonstrate that our method\nsignificantly improves rectification performance. Ablation studies further\nhighlight the positive impact of different tasks on dewarping and the\neffectiveness of our proposed module.", "published": "2025-05-09 13:35:25", "link": "http://arxiv.org/abs/2505.06038v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection", "abstract": "Understanding the decision-making process of machine learning models provides\nvaluable insights into the task, the data, and the reasons behind a model's\nfailures. In this work, we propose a method that performs inherently\ninterpretable predictions through the instance-wise sparsification of input\nimages. To align the sparsification with human perception, we learn the masking\nin the space of semantically meaningful pixel regions rather than on\npixel-level. Additionally, we introduce an explicit way to dynamically\ndetermine the required level of sparsity for each instance. We show empirically\non semi-synthetic and natural image datasets that our inherently interpretable\nclassifier produces more meaningful, human-understandable predictions than\nstate-of-the-art benchmarks.", "published": "2025-05-09 12:34:11", "link": "http://arxiv.org/abs/2505.06003v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "abstract": "Large-scale pre-trained models have achieved remarkable success in language\nand image tasks, leading an increasing number of studies to explore the\napplication of pre-trained image models, such as CLIP, in the domain of\nfew-shot action recognition (FSAR). However, current methods generally suffer\nfrom several problems: 1) Direct fine-tuning often undermines the\ngeneralization capability of the pre-trained model; 2) The exploration of\ntask-specific information is insufficient in the visual tasks; 3) The semantic\norder information is typically overlooked during text modeling; 4) Existing\ncross-modal alignment techniques ignore the temporal coupling of multimodal\ninformation. To address these, we propose Task-Adapter++, a parameter-efficient\ndual adaptation method for both image and text encoders. Specifically, to make\nfull use of the variations across different few-shot learning tasks, we design\na task-specific adaptation for the image encoder so that the most\ndiscriminative information can be well noticed during feature extraction.\nFurthermore, we leverage large language models (LLMs) to generate detailed\nsequential sub-action descriptions for each action class, and introduce\nsemantic order adapters into the text encoder to effectively model the\nsequential relationships between these sub-actions. Finally, we develop an\ninnovative fine-grained cross-modal alignment strategy that actively maps\nvisual features to reside in the same temporal stage as semantic descriptions.\nExtensive experiments fully demonstrate the effectiveness and superiority of\nthe proposed method, which achieves state-of-the-art performance on 5\nbenchmarks consistently. The code is open-sourced at\nhttps://github.com/Jaulin-Bage/Task-Adapter-pp.", "published": "2025-05-09 12:34:10", "link": "http://arxiv.org/abs/2505.06002v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints", "abstract": "While classical convolutional neural networks (CNNs) have revolutionized\nimage classification, the emergence of quantum computing presents new\nopportunities for enhancing neural network architectures. Quantum CNNs (QCNNs)\nleverage quantum mechanical properties and hold potential to outperform\nclassical approaches. However, their implementation on current noisy\nintermediate-scale quantum (NISQ) devices remains challenging due to hardware\nlimitations. In our research, we address this challenge by introducing an\nencoding scheme that significantly reduces the input dimensionality. We\ndemonstrate that a primitive QCNN architecture with 49 qubits is sufficient to\ndirectly process $28\\times 28$ pixel MNIST images, eliminating the need for\nclassical dimensionality reduction pre-processing. Additionally, we propose an\nautomated framework based on expressibility, entanglement, and complexity\ncharacteristics to identify the building blocks of QCNNs, parameterized quantum\ncircuits (PQCs). Our approach demonstrates advantages in accuracy and\nconvergence speed with a similar parameter count compared to both hybrid QCNNs\nand classical CNNs. We validated our experiments on IBM's Heron r2 quantum\nprocessor, achieving $96.08\\%$ classification accuracy, surpassing the\n$71.74\\%$ benchmark of traditional approaches under identical training\nconditions. These results represent one of the first implementations of image\nclassifications on real quantum hardware and validate the potential of quantum\ncomputing in this area.", "published": "2025-05-09 11:09:52", "link": "http://arxiv.org/abs/2505.05957v1", "categories": ["quant-ph", "cs.CV", "cs.LG"], "primary_category": "quant-ph"}
{"title": "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking", "abstract": "Recent advancements in visual object tracking have markedly improved the\ncapabilities of unmanned aerial vehicle (UAV) tracking, which is a critical\ncomponent in real-world robotics applications. While the integration of\nhierarchical lightweight networks has become a prevalent strategy for enhancing\nefficiency in UAV tracking, it often results in a significant drop in network\ncapacity, which further exacerbates challenges in UAV scenarios, such as\nfrequent occlusions and extreme changes in viewing angles. To address these\nissues, we introduce a novel family of UAV trackers, termed CGTrack, which\ncombines explicit and implicit techniques to expand network capacity within a\ncoarse-to-fine framework. Specifically, we first introduce a Hierarchical\nFeature Cascade (HFC) module that leverages the spirit of feature reuse to\nincrease network capacity by integrating the deep semantic cues with the rich\nspatial information, incurring minimal computational costs while enhancing\nfeature representation. Based on this, we design a novel Lightweight Gated\nCenter Head (LGCH) that utilizes gating mechanisms to decouple target-oriented\ncoordinates from previously expanded features, which contain dense local\ndiscriminative information. Extensive experiments on three challenging UAV\ntracking benchmarks demonstrate that CGTrack achieves state-of-the-art\nperformance while running fast. Code will be available at\nhttps://github.com/Nightwatch-Fox11/CGTrack.", "published": "2025-05-09 10:27:01", "link": "http://arxiv.org/abs/2505.05936v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DFEN: Dual Feature Equalization Network for Medical Image Segmentation", "abstract": "Current methods for medical image segmentation primarily focus on extracting\ncontextual feature information from the perspective of the whole image. While\nthese methods have shown effective performance, none of them take into account\nthe fact that pixels at the boundary and regions with a low number of class\npixels capture more contextual feature information from other classes, leading\nto misclassification of pixels by unequal contextual feature information. In\nthis paper, we propose a dual feature equalization network based on the hybrid\narchitecture of Swin Transformer and Convolutional Neural Network, aiming to\naugment the pixel feature representations by image-level equalization feature\ninformation and class-level equalization feature information. Firstly, the\nimage-level feature equalization module is designed to equalize the contextual\ninformation of pixels within the image. Secondly, we aggregate regions of the\nsame class to equalize the pixel feature representations of the corresponding\nclass by class-level feature equalization module. Finally, the pixel feature\nrepresentations are enhanced by learning weights for image-level equalization\nfeature information and class-level equalization feature information. In\naddition, Swin Transformer is utilized as both the encoder and decoder, thereby\nbolstering the ability of the model to capture long-range dependencies and\nspatial correlations. We conducted extensive experiments on Breast Ultrasound\nImages (BUSI), International Skin Imaging Collaboration (ISIC2017), Automated\nCardiac Diagnosis Challenge (ACDC) and PH$^2$ datasets. The experimental\nresults demonstrate that our method have achieved state-of-the-art performance.\nOur code is publicly available at https://github.com/JianJianYin/DFEN.", "published": "2025-05-09 09:38:43", "link": "http://arxiv.org/abs/2505.05913v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Register and CLS tokens yield a decoupling of local and global features in large ViTs", "abstract": "Recent work has shown that the attention maps of the widely popular DINOv2\nmodel exhibit artifacts, which hurt both model interpretability and performance\non dense image tasks. These artifacts emerge due to the model repurposing patch\ntokens with redundant local information for the storage of global image\ninformation. To address this problem, additional register tokens have been\nincorporated in which the model can store such information instead. We\ncarefully examine the influence of these register tokens on the relationship\nbetween global and local image features, showing that while register tokens\nyield cleaner attention maps, these maps do not accurately reflect the\nintegration of local image information in large models. Instead, global\ninformation is dominated by information extracted from register tokens, leading\nto a disconnect between local and global features. Inspired by these findings,\nwe show that the CLS token itself, which can be interpreted as a register,\nleads to a very similar phenomenon in models without explicit register tokens.\nOur work shows that care must be taken when interpreting attention maps of\nlarge ViTs. Further, by clearly attributing the faulty behaviour to register\nand CLS tokens, we show a path towards more interpretable vision models.", "published": "2025-05-09 09:00:17", "link": "http://arxiv.org/abs/2505.05892v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Decoupling Multi-Contrast Super-Resolution: Pairing Unpaired Synthesis with Implicit Representations", "abstract": "Magnetic Resonance Imaging (MRI) is critical for clinical diagnostics but is\noften limited by long acquisition times and low signal-to-noise ratios,\nespecially in modalities like diffusion and functional MRI. The multi-contrast\nnature of MRI presents a valuable opportunity for cross-modal enhancement,\nwhere high-resolution (HR) modalities can serve as references to boost the\nquality of their low-resolution (LR) counterparts-motivating the development of\nMulti-Contrast Super-Resolution (MCSR) techniques. Prior work has shown that\nleveraging complementary contrasts can improve SR performance; however,\neffective feature extraction and fusion across modalities with varying\nresolutions remains a major challenge. Moreover, existing MCSR methods often\nassume fixed resolution settings and all require large, perfectly paired\ntraining datasets-conditions rarely met in real-world clinical environments. To\naddress these challenges, we propose a novel Modular Multi-Contrast\nSuper-Resolution (MCSR) framework that eliminates the need for paired training\ndata and supports arbitrary upscaling. Our method decouples the MCSR task into\ntwo stages: (1) Unpaired Cross-Modal Synthesis (U-CMS), which translates a\nhigh-resolution reference modality into a synthesized version of the target\ncontrast, and (2) Unsupervised Super-Resolution (U-SR), which reconstructs the\nfinal output using implicit neural representations (INRs) conditioned on\nspatial coordinates. This design enables scale-agnostic and anatomically\nfaithful reconstruction by bridging un-paired cross-modal synthesis with\nunsupervised resolution enhancement. Experiments show that our method achieves\nsuperior performance at 4x and 8x upscaling, with improved fidelity and\nanatomical consistency over existing baselines. Our framework demonstrates\nstrong potential for scalable, subject-specific, and data-efficient MCSR in\nreal-world clinical settings.", "published": "2025-05-09 07:48:52", "link": "http://arxiv.org/abs/2505.05855v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PICD: Versatile Perceptual Image Compression with Diffusion Rendering", "abstract": "Recently, perceptual image compression has achieved significant advancements,\ndelivering high visual quality at low bitrates for natural images. However, for\nscreen content, existing methods often produce noticeable artifacts when\ncompressing text. To tackle this challenge, we propose versatile perceptual\nscreen image compression with diffusion rendering (PICD), a codec that works\nwell for both screen and natural images. More specifically, we propose a\ncompression framework that encodes the text and image separately, and renders\nthem into one image using diffusion model. For this diffusion rendering, we\nintegrate conditional information into diffusion models at three distinct\nlevels: 1). Domain level: We fine-tune the base diffusion model using text\ncontent prompts with screen content. 2). Adaptor level: We develop an efficient\nadaptor to control the diffusion model using compressed image and text as\ninput. 3). Instance level: We apply instance-wise guidance to further enhance\nthe decoding process. Empirically, our PICD surpasses existing perceptual\ncodecs in terms of both text accuracy and perceptual quality. Additionally,\nwithout text conditions, our approach serves effectively as a perceptual codec\nfor natural images.", "published": "2025-05-09 07:45:01", "link": "http://arxiv.org/abs/2505.05853v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects", "abstract": "Modern 3D reconstruction and novel view synthesis approaches have\ndemonstrated strong performance on scenes with opaque Lambertian objects.\nHowever, most assume straight light paths and therefore cannot properly handle\nrefractive and reflective materials. Moreover, datasets specialized for these\neffects are limited, stymieing efforts to evaluate performance and develop\nsuitable techniques. In this work, we introduce a synthetic RefRef dataset and\nbenchmark for reconstructing scenes with refractive and reflective objects from\nposed images. Our dataset has 50 such objects of varying complexity, from\nsingle-material convex shapes to multi-material non-convex shapes, each placed\nin three different background types, resulting in 150 scenes. We also propose\nan oracle method that, given the object geometry and refractive indices,\ncalculates accurate light paths for neural rendering, and an approach based on\nthis that avoids these assumptions. We benchmark these against several\nstate-of-the-art methods and show that all methods lag significantly behind the\noracle, highlighting the challenges of the task and dataset.", "published": "2025-05-09 07:38:59", "link": "http://arxiv.org/abs/2505.05848v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Knot Detection and Pairing for Wood Analysis in the Timber Industry", "abstract": "Knots in wood are critical to both aesthetics and structural integrity,\nmaking their detection and pairing essential in timber processing. However,\ntraditional manual annotation was labor-intensive and inefficient,\nnecessitating automation. This paper proposes a lightweight and fully automated\npipeline for knot detection and pairing based on machine learning techniques.\nIn the detection stage, high-resolution surface images of wooden boards were\ncollected using industrial-grade cameras, and a large-scale dataset was\nmanually annotated and preprocessed. After the transfer learning, the YOLOv8l\nachieves an mAP@0.5 of 0.887. In the pairing stage, detected knots were\nanalyzed and paired based on multidimensional feature extraction. A triplet\nneural network was used to map the features into a latent space, enabling\nclustering algorithms to identify and pair corresponding knots. The triplet\nnetwork with learnable weights achieved a pairing accuracy of 0.85. Further\nanalysis revealed that he distances from the knot's start and end points to the\nbottom of the wooden board, and the longitudinal coordinates play crucial roles\nin achieving high pairing accuracy. Our experiments validate the effectiveness\nof the proposed solution, demonstrating the potential of AI in advancing wood\nscience and industry.", "published": "2025-05-09 07:36:47", "link": "http://arxiv.org/abs/2505.05845v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression", "abstract": "Ordinal regression bridges regression and classification by assigning objects\nto ordered classes. While human experts rely on discriminative patch-level\nfeatures for decisions, current approaches are limited by the availability of\nonly image-level ordinal labels, overlooking fine-grained patch-level\ncharacteristics. In this paper, we propose a Dual-level Fuzzy Learning with\nPatch Guidance framework, named DFPG that learns precise feature-based grading\nboundaries from ambiguous ordinal labels, with patch-level supervision.\nSpecifically, we propose patch-labeling and filtering strategies to enable the\nmodel to focus on patch-level features exclusively with only image-level\nordinal labels available. We further design a dual-level fuzzy learning module,\nwhich leverages fuzzy logic to quantitatively capture and handle label\nambiguity from both patch-wise and channel-wise perspectives. Extensive\nexperiments on various image ordinal regression datasets demonstrate the\nsuperiority of our proposed method, further confirming its ability in\ndistinguishing samples from difficult-to-classify categories. The code is\navailable at https://github.com/ZJUMAI/DFPG-ord.", "published": "2025-05-09 07:01:14", "link": "http://arxiv.org/abs/2505.05834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition", "abstract": "Diffusion transformer (DiT) models have achieved remarkable success in image\ngeneration, thanks for their exceptional generative capabilities and\nscalability. Nonetheless, the iterative nature of diffusion models (DMs)\nresults in high computation complexity, posing challenges for deployment.\nAlthough existing cache-based acceleration methods try to utilize the inherent\ntemporal similarity to skip redundant computations of DiT, the lack of\ncorrection may induce potential quality degradation. In this paper, we propose\nincrement-calibrated caching, a training-free method for DiT acceleration,\nwhere the calibration parameters are generated from the pre-trained model\nitself with low-rank approximation. To deal with the possible correction\nfailure arising from outlier activations, we introduce channel-aware Singular\nValue Decomposition (SVD), which further strengthens the calibration effect.\nExperimental results show that our method always achieve better performance\nthan existing naive caching methods with a similar computation resource budget.\nWhen compared with 35-step DDIM, our method eliminates more than 45%\ncomputation and improves IS by 12 at the cost of less than 0.06 FID increase.\nCode is available at https://github.com/ccccczzy/icc.", "published": "2025-05-09 06:56:17", "link": "http://arxiv.org/abs/2505.05829v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Towards order of magnitude X-ray dose reduction in breast cancer imaging using phase contrast and deep denoising", "abstract": "Breast cancer is the most frequently diagnosed human cancer in the United\nStates at present. Early detection is crucial for its successful treatment.\nX-ray mammography and digital breast tomosynthesis are currently the main\nmethods for breast cancer screening. However, both have known limitations in\nterms of their sensitivity and specificity to breast cancers, while also\nfrequently causing patient discomfort due to the requirement for breast\ncompression. Breast computed tomography is a promising alternative, however, to\nobtain high-quality images, the X-ray dose needs to be sufficiently high. As\nthe breast is highly radiosensitive, dose reduction is particularly important.\nPhase-contrast computed tomography (PCT) has been shown to produce\nhigher-quality images at lower doses and has no need for breast compression. It\nis demonstrated in the present study that, when imaging full fresh mastectomy\nsamples with PCT, deep learning-based image denoising can further reduce the\nradiation dose by a factor of 16 or more, without any loss of image quality.\nThe image quality has been assessed both in terms of objective metrics, such as\nspatial resolution and contrast-to-noise ratio, as well as in an observer study\nby experienced medical imaging specialists and radiologists. This work was\ncarried out in preparation for live patient PCT breast cancer imaging,\ninitially at specialized synchrotron facilities.", "published": "2025-05-09 06:15:28", "link": "http://arxiv.org/abs/2505.05812v1", "categories": ["physics.med-ph", "cs.CV"], "primary_category": "physics.med-ph"}
{"title": "Image Segmentation via Variational Model Based Tailored UNet: A Deep Variational Framework", "abstract": "Traditional image segmentation methods, such as variational models based on\npartial differential equations (PDEs), offer strong mathematical\ninterpretability and precise boundary modeling, but often suffer from\nsensitivity to parameter settings and high computational costs. In contrast,\ndeep learning models such as UNet, which are relatively lightweight in\nparameters, excel in automatic feature extraction but lack theoretical\ninterpretability and require extensive labeled data. To harness the\ncomplementary strengths of both paradigms, we propose Variational Model Based\nTailored UNet (VM_TUNet), a novel hybrid framework that integrates the\nfourth-order modified Cahn-Hilliard equation with the deep learning backbone of\nUNet, which combines the interpretability and edge-preserving properties of\nvariational methods with the adaptive feature learning of neural networks.\nSpecifically, a data-driven operator is introduced to replace manual parameter\ntuning, and we incorporate the tailored finite point method (TFPM) to enforce\nhigh-precision boundary preservation. Experimental results on benchmark\ndatasets demonstrate that VM_TUNet achieves superior segmentation performance\ncompared to existing approaches, especially for fine boundary delineation.", "published": "2025-05-09 05:50:22", "link": "http://arxiv.org/abs/2505.05806v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Describe Anything in Medical Images", "abstract": "Localized image captioning has made significant progress with models like the\nDescribe Anything Model (DAM), which can generate detailed region-specific\ndescriptions without explicit region-text supervision. However, such\ncapabilities have yet to be widely applied to specialized domains like medical\nimaging, where diagnostic interpretation relies on subtle regional findings\nrather than global understanding. To mitigate this gap, we propose MedDAM, the\nfirst comprehensive framework leveraging large vision-language models for\nregion-specific captioning in medical images. MedDAM employs medical\nexpert-designed prompts tailored to specific imaging modalities and establishes\na robust evaluation benchmark comprising a customized assessment protocol, data\npre-processing pipeline, and specialized QA template library. This benchmark\nevaluates both MedDAM and other adaptable large vision-language models,\nfocusing on clinical factuality through attribute-level verification tasks,\nthereby circumventing the absence of ground-truth region-caption pairs in\nmedical datasets. Extensive experiments on the VinDr-CXR, LIDC-IDRI, and\nSkinCon datasets demonstrate MedDAM's superiority over leading peers (including\nGPT-4o, Claude 3.7 Sonnet, LLaMA-3.2 Vision, Qwen2.5-VL, GPT-4Rol, and\nOMG-LLaVA) in the task, revealing the importance of region-level semantic\nalignment in medical image understanding and establishing MedDAM as a promising\nfoundation for clinical vision-language integration.", "published": "2025-05-09 05:45:31", "link": "http://arxiv.org/abs/2505.05804v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks", "abstract": "Robotic manipulation in 3D requires learning an $N$ degree-of-freedom joint\nspace trajectory of a robot manipulator. Robots must possess semantic and\nvisual perception abilities to transform real-world mappings of their workspace\ninto the low-level control necessary for object manipulation. Recent work has\ndemonstrated the capabilities of fine-tuning large Vision-Language Models\n(VLMs) to learn the mapping between RGB images, language instructions, and\njoint space control. These models typically take as input RGB images of the\nworkspace and language instructions, and are trained on large datasets of\nteleoperated robot demonstrations. In this work, we explore methods to improve\nthe scene context awareness of a popular recent Vision-Language-Action model by\nintegrating chain-of-thought reasoning, depth perception, and task-oriented\nregion of interest detection. Our experiments in the LIBERO simulation\nenvironment show that our proposed model, 3D-CAVLA, improves the success rate\nacross various LIBERO task suites, achieving an average success rate of\n98.1$\\%$. We also evaluate the zero-shot capabilities of our method,\ndemonstrating that 3D scene awareness leads to robust learning and adaptation\nfor completely unseen tasks. 3D-CAVLA achieves an absolute improvement of\n8.8$\\%$ on unseen tasks. We will open-source our code and the unseen tasks\ndataset to promote community-driven research here: https://3d-cavla.github.io", "published": "2025-05-09 05:32:40", "link": "http://arxiv.org/abs/2505.05800v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes", "abstract": "Kolmogorov-Arnold Networks (KAN) offer universal function approximation using\nunivariate spline compositions without nonlinear activations. In this work, we\nintegrate Error-Correcting Output Codes (ECOC) into the KAN framework to\ntransform multi-class classification into multiple binary tasks, improving\nrobustness via Hamming-distance decoding. Our proposed KAN with ECOC method\noutperforms vanilla KAN on a challenging blood cell classification dataset,\nachieving higher accuracy under diverse hyperparameter settings. Ablation\nstudies further confirm that ECOC consistently enhances performance across\nFastKAN and FasterKAN variants. These results demonstrate that ECOC integration\nsignificantly boosts KAN generalizability in critical healthcare AI\napplications. To the best of our knowledge, this is the first integration of\nECOC with KAN for enhancing multi-class medical image classification\nperformance.", "published": "2025-05-09 05:31:10", "link": "http://arxiv.org/abs/2505.05798v1", "categories": ["cs.LG", "cs.CV", "eess.IV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "A review of advancements in low-light image enhancement using deep learning", "abstract": "In low-light environments, the performance of computer vision algorithms\noften deteriorates significantly, adversely affecting key vision tasks such as\nsegmentation, detection, and classification. With the rapid advancement of deep\nlearning, its application to low-light image processing has attracted\nwidespread attention and seen significant progress in recent years. However,\nthere remains a lack of comprehensive surveys that systematically examine how\nrecent deep-learning-based low-light image enhancement methods function and\nevaluate their effectiveness in enhancing downstream vison tasks. To address\nthis gap, this review provides a detailed elaboration on how various recent\napproaches (from 2020) operate and their enhancement mechanisms, supplemented\nwith clear illustrations. It also investigates the impact of different\nenhancement techniques on subsequent vision tasks, critically analyzing their\nstrengths and limitations. Additionally, it proposes future research\ndirections. This review serves as a useful reference for determining low-light\nimage enhancement techniques and optimizing vision task performance in\nlow-light conditions.", "published": "2025-05-09 03:39:23", "link": "http://arxiv.org/abs/2505.05759v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data", "abstract": "Automation can play a prominent role in improving efficiency, accuracy, and\nscalability in infrastructure surveying and assessing construction and\ncompliance standards. This paper presents a framework for automation of\ngeometric measurements and compliance assessment using point cloud data. The\nproposed approach integrates deep learning-based detection and segmentation, in\nconjunction with geometric and signal processing techniques, to automate\nsurveying tasks. As a proof of concept, we apply this framework to\nautomatically evaluate the compliance of curb ramps with the Americans with\nDisabilities Act (ADA), demonstrating the utility of point cloud data in survey\nautomation. The method leverages a newly collected, large annotated dataset of\ncurb ramps, made publicly available as part of this work, to facilitate robust\nmodel training and evaluation. Experimental results, including comparison with\nmanual field measurements of several ramps, validate the accuracy and\nreliability of the proposed method, highlighting its potential to significantly\nreduce manual effort and improve consistency in infrastructure assessment.\nBeyond ADA compliance, the proposed framework lays the groundwork for broader\napplications in infrastructure surveying and automated construction evaluation,\npromoting wider adoption of point cloud data in these domains. The annotated\ndatabase, manual ramp survey data, and developed algorithms are publicly\navailable on the project's GitHub page:\nhttps://github.com/Soltanilara/SurveyAutomation.", "published": "2025-05-09 03:24:09", "link": "http://arxiv.org/abs/2505.05752v1", "categories": ["cs.CV", "cs.CY", "cs.LG", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "kFuse: A novel density based agglomerative clustering", "abstract": "Agglomerative clustering has emerged as a vital tool in data analysis due to\nits intuitive and flexible characteristics. However, existing agglomerative\nclustering methods often involve additional parameters for sub-cluster\npartitioning and inter-cluster similarity assessment. This necessitates\ndifferent parameter settings across various datasets, which is undoubtedly\nchallenging in the absence of prior knowledge. Moreover, existing agglomerative\nclustering techniques are constrained by the calculation method of connection\ndistance, leading to unstable clustering results. To address these issues, this\npaper introduces a novel density-based agglomerative clustering method, termed\nkFuse. kFuse comprises four key components: (1) sub-cluster partitioning based\non natural neighbors; (2) determination of boundary connectivity between\nsub-clusters through the computation of adjacent samples and shortest\ndistances; (3) assessment of density similarity between sub-clusters via the\ncalculation of mean density and variance; and (4) establishment of merging\nrules between sub-clusters based on boundary connectivity and density\nsimilarity. kFuse requires the specification of the number of clusters only at\nthe final merging stage. Additionally, by comprehensively considering adjacent\nsamples, distances, and densities among different sub-clusters, kFuse\nsignificantly enhances accuracy during the merging phase, thereby greatly\nimproving its identification capability. Experimental results on both synthetic\nand real-world datasets validate the effectiveness of kFuse.", "published": "2025-05-09 03:11:04", "link": "http://arxiv.org/abs/2505.05748v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection", "abstract": "Tiny object detection plays a vital role in drone surveillance, remote\nsensing, and autonomous systems, enabling the identification of small targets\nacross vast landscapes. However, existing methods suffer from inefficient\nfeature leverage and high computational costs due to redundant feature\nprocessing and rigid query allocation. To address these challenges, we propose\nDome-DETR, a novel framework with Density-Oriented Feature-Query Manipulation\nfor Efficient Tiny Object Detection. To reduce feature redundancies, we\nintroduce a lightweight Density-Focal Extractor (DeFE) to produce clustered\ncompact foreground masks. Leveraging these masks, we incorporate Masked Window\nAttention Sparsification (MWAS) to focus computational resources on the most\ninformative regions via sparse attention. Besides, we propose Progressive\nAdaptive Query Initialization (PAQI), which adaptively modulates query density\nacross spatial areas for better query allocation. Extensive experiments\ndemonstrate that Dome-DETR achieves state-of-the-art performance (+3.3 AP on\nAI-TOD-V2 and +2.5 AP on VisDrone) while maintaining low computational\ncomplexity and a compact model size. Code will be released upon acceptance.", "published": "2025-05-09 02:44:06", "link": "http://arxiv.org/abs/2505.05741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Learning of Semantic Embedding Representations for Diffusion Models", "abstract": "Generative models capture the true distribution of data, yielding\nsemantically rich representations. Denoising diffusion models (DDMs) exhibit\nsuperior generative capabilities, though efficient representation learning for\nthem are lacking. In this work, we employ a multi-level denoising autoencoder\nframework to expand the representation capacity of DDMs, which introduces\nsequentially consistent Diffusion Transformers and an additional\ntimestep-dependent encoder to acquire embedding representations on the\ndenoising Markov chain through self-conditional diffusion learning.\nIntuitively, the encoder, conditioned on the entire diffusion process,\ncompresses high-dimensional data into directional vectors in latent under\ndifferent noise levels, facilitating the learning of image embeddings across\nall timesteps. To verify the semantic adequacy of embeddings generated through\nthis approach, extensive experiments are conducted on various datasets,\ndemonstrating that optimally learned embeddings by DDMs surpass\nstate-of-the-art self-supervised representation learning methods in most cases,\nachieving remarkable discriminative semantic representation quality. Our work\njustifies that DDMs are not only suitable for generative tasks, but also\npotentially advantageous for general-purpose deep learning applications.", "published": "2025-05-09 02:10:46", "link": "http://arxiv.org/abs/2505.05732v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "You Are Your Best Teacher: Semi-Supervised Surgical Point Tracking with Cycle-Consistent Self-Distillation", "abstract": "Synthetic datasets have enabled significant progress in point tracking by\nproviding large-scale, densely annotated supervision. However, deploying these\nmodels in real-world domains remains challenging due to domain shift and lack\nof labeled data-issues that are especially severe in surgical videos, where\nscenes exhibit complex tissue deformation, occlusion, and lighting variation.\nWhile recent approaches adapt synthetic-trained trackers to natural videos\nusing teacher ensembles or augmentation-heavy pseudo-labeling pipelines, their\neffectiveness in high-shift domains like surgery remains unexplored. This work\npresents SurgTracker, a semi-supervised framework for adapting\nsynthetic-trained point trackers to surgical video using filtered\nself-distillation. Pseudo-labels are generated online by a fixed\nteacher-identical in architecture and initialization to the student-and are\nfiltered using a cycle consistency constraint to discard temporally\ninconsistent trajectories. This simple yet effective design enforces geometric\nconsistency and provides stable supervision throughout training, without the\ncomputational overhead of maintaining multiple teachers. Experiments on the\nSTIR benchmark show that SurgTracker improves tracking performance using only\n80 unlabeled videos, demonstrating its potential for robust adaptation in\nhigh-shift, data-scarce domains.", "published": "2025-05-09 01:45:01", "link": "http://arxiv.org/abs/2505.05722v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic-Space-Intervened Diffusive Alignment for Visual Classification", "abstract": "Cross-modal alignment is an effective approach to improving visual\nclassification. Existing studies typically enforce a one-step mapping that uses\ndeep neural networks to project the visual features to mimic the distribution\nof textual features. However, they typically face difficulties in finding such\na projection due to the two modalities in both the distribution of class-wise\nsamples and the range of their feature values. To address this issue, this\npaper proposes a novel Semantic-Space-Intervened Diffusive Alignment method,\ntermed SeDA, models a semantic space as a bridge in the visual-to-textual\nprojection, considering both types of features share the same class-level\ninformation in classification. More importantly, a bi-stage diffusion framework\nis developed to enable the progressive alignment between the two modalities.\nSpecifically, SeDA first employs a Diffusion-Controlled Semantic Learner to\nmodel the semantic features space of visual features by constraining the\ninteractive features of the diffusion model and the category centers of visual\nfeatures. In the later stage of SeDA, the Diffusion-Controlled Semantic\nTranslator focuses on learning the distribution of textual features from the\nsemantic space. Meanwhile, the Progressive Feature Interaction Network\nintroduces stepwise feature interactions at each alignment step, progressively\nintegrating textual information into mapped features. Experimental results show\nthat SeDA achieves stronger cross-modal feature alignment, leading to superior\nperformance over existing methods across multiple scenarios.", "published": "2025-05-09 01:41:23", "link": "http://arxiv.org/abs/2505.05721v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer", "abstract": "In this paper, we examine a key limitation in query-based detectors for\ntemporal action detection (TAD), which arises from their direct adaptation of\noriginally designed architectures for object detection. Despite the\neffectiveness of the existing models, they struggle to fully address the unique\nchallenges of TAD, such as the redundancy in multi-scale features and the\nlimited ability to capture sufficient temporal context. To address these\nissues, we propose a multi-dilated gated encoder and central-adjacent region\nintegrated decoder for temporal action detection transformer (DiGIT). Our\napproach replaces the existing encoder that consists of multi-scale deformable\nattention and feedforward network with our multi-dilated gated encoder. Our\nproposed encoder reduces the redundant information caused by multi-level\nfeatures while maintaining the ability to capture fine-grained and long-range\ntemporal information. Furthermore, we introduce a central-adjacent region\nintegrated decoder that leverages a more comprehensive sampling strategy for\ndeformable cross-attention to capture the essential information. Extensive\nexperiments demonstrate that DiGIT achieves state-of-the-art performance on\nTHUMOS14, ActivityNet v1.3, and HACS-Segment. Code is available at:\nhttps://github.com/Dotori-HJ/DiGIT", "published": "2025-05-09 01:17:30", "link": "http://arxiv.org/abs/2505.05711v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hybrid Learning: A Novel Combination of Self-Supervised and Supervised Learning for MRI Reconstruction without High-Quality Training Reference", "abstract": "Purpose: Deep learning has demonstrated strong potential for MRI\nreconstruction, but conventional supervised learning methods require\nhigh-quality reference images, which are often unavailable in practice.\nSelf-supervised learning offers an alternative, yet its performance degrades at\nhigh acceleration rates. To overcome these limitations, we propose hybrid\nlearning, a novel two-stage training framework that combines self-supervised\nand supervised learning for robust image reconstruction.\n  Methods: Hybrid learning is implemented in two sequential stages. In the\nfirst stage, self-supervised learning is employed to generate improved images\nfrom noisy or undersampled reference data. These enhanced images then serve as\npseudo-ground truths for the second stage, which uses supervised learning to\nrefine reconstruction performance and support higher acceleration rates. We\nevaluated hybrid learning in two representative applications: (1) accelerated\n0.55T spiral-UTE lung MRI using noisy reference data, and (2) 3D T1 mapping of\nthe brain without access to fully sampled ground truth.\n  Results: For spiral-UTE lung MRI, hybrid learning consistently improved image\nquality over both self-supervised and conventional supervised methods across\ndifferent acceleration rates, as measured by SSIM and NMSE. For 3D T1 mapping,\nhybrid learning achieved superior T1 quantification accuracy across a wide\ndynamic range, outperforming self-supervised learning in all tested conditions.\n  Conclusions: Hybrid learning provides a practical and effective solution for\ntraining deep MRI reconstruction networks when only low-quality or incomplete\nreference data are available. It enables improved image quality and accurate\nquantitative mapping across different applications and field strengths,\nrepresenting a promising technique toward broader clinical deployment of deep\nlearning-based MRI.", "published": "2025-05-09 00:35:14", "link": "http://arxiv.org/abs/2505.05703v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "On the Depth of Monotone ReLU Neural Networks and ICNNs", "abstract": "We study two models of ReLU neural networks: monotone networks (ReLU$^+$) and\ninput convex neural networks (ICNN). Our focus is on expressivity, mostly in\nterms of depth, and we prove the following lower bounds. For the maximum\nfunction MAX$_n$ computing the maximum of $n$ real numbers, we show that\nReLU$^+$ networks cannot compute MAX$_n$, or even approximate it. We prove a\nsharp $n$ lower bound on the ICNN depth complexity of MAX$_n$. We also prove\ndepth separations between ReLU networks and ICNNs; for every $k$, there is a\ndepth-2 ReLU network of size $O(k^2)$ that cannot be simulated by a depth-$k$\nICNN. The proofs are based on deep connections between neural networks and\npolyhedral geometry, and also use isoperimetric properties of triangulations.", "published": "2025-05-09 16:19:34", "link": "http://arxiv.org/abs/2505.06169v1", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "primary_category": "cs.LG"}
{"title": "Scheduled Jacobian Chaining", "abstract": "This paper addresses the efficient computation of Jacobian matrices for\nprograms composed of sequential differentiable subprograms. By representing the\noverall Jacobian as a chain product of the Jacobians of these subprograms, we\nreduce the problem to optimizing the sequence of matrix multiplications, known\nas the Jacobian Matrix Chain Product problem. Solutions to this problem yield\n\"optimal bracketings\", which induce a precedence-constraint scheduling problem.\nWe investigate the inherent parallelism in the solutions and develop a new\ndynamic programming algorithm as a heuristic that incorporates the scheduling.\nTo assess its performance, we benchmark it against the global optimum, which is\ncomputed via a branch-and-bound algorithm.", "published": "2025-05-09 13:50:55", "link": "http://arxiv.org/abs/2505.06056v1", "categories": ["cs.DM", "cs.DC", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "Second Price Matching with Complete Allocation and Degree Constraints", "abstract": "We study the Second Price Matching problem, introduced by Azar, Birnbaum,\nKarlin, and Nguyen in 2009. In this problem, a bipartite graph (bidders and\ngoods) is given, and the profit of a matching is the number of matches\ncontaining a second unmatched bidder. Maximizing profit is known to be APX-hard\nand the current best approximation guarantee is $1/2$. APX-hardness even holds\nwhen all degrees are bounded by a constant. In this paper, we investigate the\napproximability of the problem under regular degree constraints. Our main\nresult is an improved approximation guarantee of $9/10$ for Second Price\nMatching in $(3,2)$-regular graphs and an exact polynomial-time algorithm for\n$(d,2)$-regular graphs if $d\\geq 4$. Our algorithm and its analysis are based\non structural results in non-bipartite matching, in particular the Tutte-Berge\nformula coupled with novel combinatorial augmentation methods.\n  We also introduce a variant of Second Price Matching where all goods have to\nbe matched, which models the setting of expiring goods. We prove that this\nproblem is hard to approximate within a factor better than $(1-1/e)$ and show\nthat the problem can be approximated to a tight $(1-1/e)$ factor by maximizing\na submodular function subject to a matroid constraint. We then show that our\nalgorithm also solves this problem exactly on regular degree constrained graphs\nas above.", "published": "2025-05-09 12:35:45", "link": "http://arxiv.org/abs/2505.06005v1", "categories": ["cs.DS", "cs.CC", "cs.DM"], "primary_category": "cs.DS"}
{"title": "A Polynomial-Time Approximation Algorithm for Complete Interval Minors", "abstract": "As shown by Robertson and Seymour, deciding whether the complete graph $K_t$\nis a minor of an input graph $G$ is a fixed parameter tractable problem when\nparameterized by $t$. From the approximation viewpoint, the gap to fill is\nquite large, as there is no PTAS for finding the largest complete minor unless\n$P = NP$, whereas a polytime $O(\\sqrt n)$-approximation algorithm was given by\nAlon, Lingas and Wahl\\'en.\n  We investigate the complexity of finding $K_t$ as interval minor in ordered\ngraphs (i.e. graphs with a linear order on the vertices, in which intervals are\ncontracted to form minors). Our main result is a polytime $f(t)$-approximation\nalgorithm, where $f$ is triply exponential in $t$ but independent of $n$. The\nalgorithm is based on delayed decompositions and shows that ordered graphs\nwithout a $K_t$ interval minor can be constructed via a bounded number of three\noperations: closure under substitutions, edge union, and concatenation of a\nstable set. As a byproduct, graphs avoiding $K_t$ as an interval minor have\nbounded chromatic number.", "published": "2025-05-09 12:25:12", "link": "http://arxiv.org/abs/2505.05997v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "Minimal $L^p$-congestion spanning trees on weighted graphs", "abstract": "A generalization of the notion of spanning tree congestion for weighted\ngraphs is introduced. The $L^p$ congestion of a spanning tree is defined as the\n$L^p$ norm of the edge congestion of that tree. In this context, the classical\ncongestion is the $L^\\infty$-congestion. Explicit estimations of the minimal\nspanning tree $L^p$ congestion for some families of graphs are given. In\naddition, we introduce a polynomial-time algorithm for approximating the\nminimal $L^p$-congestion spanning tree in any weighted graph and another two\nsimilar algorithms for weighted planar graphs. The performance of these\nalgorithms is tested in several graphs.", "published": "2025-05-09 11:47:42", "link": "http://arxiv.org/abs/2505.05969v1", "categories": ["cs.DM", "math.CO", "05C22, 05C85, 90C59"], "primary_category": "cs.DM"}
{"title": "Modeling Multi-Hop Semantic Paths for Recommendation in Heterogeneous Information Networks", "abstract": "This study focuses on the problem of path modeling in heterogeneous\ninformation networks and proposes a multi-hop path-aware recommendation\nframework. The method centers on multi-hop paths composed of various types of\nentities and relations. It models user preferences through three stages: path\nselection, semantic representation, and attention-based fusion. In the path\nselection stage, a path filtering mechanism is introduced to remove redundant\nand noisy information. In the representation learning stage, a sequential\nmodeling structure is used to jointly encode entities and relations, preserving\nthe semantic dependencies within paths. In the fusion stage, an attention\nmechanism assigns different weights to each path to generate a global user\ninterest representation. Experiments conducted on real-world datasets such as\nAmazon-Book show that the proposed method significantly outperforms existing\nrecommendation models across multiple evaluation metrics, including HR@10,\nRecall@10, and Precision@10. The results confirm the effectiveness of multi-hop\npaths in capturing high-order interaction semantics and demonstrate the\nexpressive modeling capabilities of the framework in heterogeneous\nrecommendation scenarios. This method provides both theoretical and practical\nvalue by integrating structural information modeling in heterogeneous networks\nwith recommendation algorithm design. It offers a more expressive and flexible\nparadigm for learning user preferences in complex data environments.", "published": "2025-05-09 12:18:34", "link": "http://arxiv.org/abs/2505.05989v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Cost-Effective, Low Latency Vector Search with Azure Cosmos DB", "abstract": "Vector indexing enables semantic search over diverse corpora and has become\nan important interface to databases for both users and AI agents. Efficient\nvector search requires deep optimizations in database systems. This has\nmotivated a new class of specialized vector databases that optimize for vector\nsearch quality and cost. Instead, we argue that a scalable, high-performance,\nand cost-efficient vector search system can be built inside a cloud-native\noperational database like Azure Cosmos DB while leveraging the benefits of a\ndistributed database such as high availability, durability, and scale. We do\nthis by deeply integrating DiskANN, a state-of-the-art vector indexing library,\ninside Azure Cosmos DB NoSQL. This system uses a single vector index per\npartition stored in existing index trees, and kept in sync with underlying\ndata. It supports < 20ms query latency over an index spanning 10 million of\nvectors, has stable recall over updates, and offers nearly 15x and 41x lower\nquery cost compared to Zilliz and Pinecone serverless enterprise products. It\nalso scales out to billions of vectors via automatic partitioning. This\nconvergent design presents a point in favor of integrating vector indices into\noperational databases in the context of recent debates on specialized vector\ndatabases, and offers a template for vector indexing in other databases.", "published": "2025-05-09 08:53:59", "link": "http://arxiv.org/abs/2505.05885v1", "categories": ["cs.DB", "cs.IR", "H.3.3"], "primary_category": "cs.DB"}
{"title": "Decoding Algorithms for Two-dimensional Constacyclic Codes over $\\mathbb{F}_q$", "abstract": "We derive the spectral domain properties of two-dimensional (2-D)\n$(\\lambda_1, \\lambda_2)$-constacyclic codes over $\\mathbb{F}_q$ using the 2-D\nfinite field Fourier transform (FFFT). Based on the spectral nulls of 2-D\n$(\\lambda_1, \\lambda_2)$-constacyclic codes, we characterize the structure of\n2-D constacyclic coded arrays. The proposed 2-D construction has flexible code\nrates and works for any code areas, be it odd or even area. We present an\nalgorithm to detect the location of 2-D errors. Further, we also propose\ndecoding algorithms for extracting the error values using both time and\nfrequency domain properties by exploiting the sparsity that arises due to\nduality in the time and frequency domains. Through several illustrative\nexamples, we demonstrate the working of the proposed decoding algorithms.", "published": "2025-05-09 17:28:51", "link": "http://arxiv.org/abs/2505.06201v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On Optimal Batch Size in Coded Computing", "abstract": "We consider computing systems that partition jobs into tasks, add redundancy\nthrough coding, and assign the encoded tasks to different computing nodes for\nparallel execution. The expected execution time depends on the level of\nredundancy. The computing nodes execute large jobs in batches of tasks. We show\nthat the expected execution time depends on the batch size as well. The optimal\nbatch size that minimizes the execution time depends on the level of redundancy\nunder a fixed number of parallel servers and other system parameters.\nFurthermore, we show how to (jointly) optimize the redundancy level and batch\nsize to reduce the expected job completion time for two service-time\ndistributions. The simulation presented helps us appreciate the claims.", "published": "2025-05-09 17:25:38", "link": "http://arxiv.org/abs/2505.06199v1", "categories": ["cs.IT", "cs.DC", "cs.PF", "math.IT"], "primary_category": "cs.IT"}
{"title": "Advancing Finite-Length Quantum Error Correction Using Generalized Bicycle Codes", "abstract": "Generalized bicycle (GB) codes have emerged as a promising class of quantum\nerror-correcting codes with practical decoding capabilities. While numerous\nasymptotically good quantum codes and quantum low-density parity-check code\nconstructions have been proposed, their finite block-length performance often\nremains unquantified. In this work, we demonstrate that GB codes exhibit\ncomparable or superior error correction performance in finite-length settings,\nparticularly when designed with higher or unrestricted row weights. Leveraging\ntheir flexible construction, GB codes can be tailored to achieve high rates\nwhile maintaining efficient decoding. We evaluate GB codes against other\nleading quantum code families, such as quantum Tanner codes and\nsingle-parity-check product codes, highlighting their versatility in practical\nfinite-length applications.", "published": "2025-05-09 16:08:02", "link": "http://arxiv.org/abs/2505.06157v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Discretized Approximate Ancestral Sampling", "abstract": "The Fourier Basis Density Model (FBM) was recently introduced as a flexible\nprobability model for band-limited distributions, i.e. ones which are smooth in\nthe sense of having a characteristic function with limited support around the\norigin. Its density and cumulative distribution functions can be efficiently\nevaluated and trained with stochastic optimization methods, which makes the\nmodel suitable for deep learning applications. However, the model lacked\nsupport for sampling. Here, we introduce a method inspired by\ndiscretization--interpolation methods common in Digital Signal Processing,\nwhich directly take advantage of the band-limited property. We review\nmathematical properties of the FBM, and prove quality bounds of the sampled\ndistribution in terms of the total variation (TV) and Wasserstein--1\ndivergences from the model. These bounds can be used to inform the choice of\nhyperparameters to reach any desired sample quality. We discuss these results\nin comparison to a variety of other sampling techniques, highlighting tradeoffs\nbetween computational complexity and sampling quality.", "published": "2025-05-09 14:44:40", "link": "http://arxiv.org/abs/2505.06098v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Beyond Diagonal RIS Design for Parameter Estimation With and Without Eavesdropping", "abstract": "In this letter, we investigate the transmission of a complex-valued parameter\nvector from a transmitter to an intended receiver, considering both the\npresence and absence of an eavesdropper. The direct links from the transmitter\nto both the intended receiver and the eavesdropper are assumed to be blocked,\nand communications occur solely through cascaded channels facilitated by a\nbeyond-diagonal reconfigurable intelligent surface (BD-RIS). While previous\nresearch has considered this system under conventional (diagonal) RIS\nassistance, we extend the setup to incorporate BD-RIS and quantify the\nresulting improvement in estimation performance at the intended receiver. This\nperformance is measured by the trace of the Fisher information matrix (FIM), or\nequivalently, the average Fisher information, while simultaneously limiting the\nestimation capability of the eavesdropper. We propose solutions and algorithms\nfor optimizing the BD-RIS response matrix and demonstrate their effectiveness.\nNumerical results reveal that the BD-RIS provides a significant enhancement in\nestimation quality compared to conventional diagonal RIS architectures.", "published": "2025-05-09 11:48:39", "link": "http://arxiv.org/abs/2505.05971v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "List-Recovery of Random Linear Codes over Small Fields", "abstract": "We study list-recoverability of random linear codes over small fields, both\nfrom errors and from erasures. We consider codes of rate $\\epsilon$-close to\ncapacity, and aim to bound the dependence of the output list size $L$ on\n$\\epsilon$, the input list size $\\ell$, and the alphabet size $q$. Prior to our\nwork, the best upper bound was $L = q^{O(\\ell/\\epsilon)}$ (Zyablov and Pinsker,\nProb. Per. Inf. 1981).\n  Previous work has identified cases in which linear codes provably perform\nworse than non-linear codes with respect to list-recovery. While there exist\nnon-linear codes that achieve $L=O(\\ell/\\epsilon)$, we know that $L \\ge\n\\ell^{\\Omega(1/\\epsilon)}$ is necessary for list recovery from erasures over\nfields of small characteristic, and for list recovery from errors over large\nalphabets. We show that in other relevant regimes there is no significant price\nto pay for linearity, in the sense that we get the correct dependence on the\ngap-to-capacity $\\epsilon$ and go beyond the Zyablov-Pinsker bound for the\nfirst time. Specifically, when $q$ is constant and $\\epsilon$ approaches zero:\n  - For list-recovery from erasures over prime fields, we show that $L \\leq\nC_1/\\epsilon$. By prior work, such a result cannot be obtained for\nlow-characteristic fields.\n  - For list-recovery from errors over arbitrary fields, we prove that $L \\leq\nC_2/\\epsilon$.\n  Above, $C_1$ and $C_2$ depend on the decoding radius, input list size, and\nfield size. We provide concrete bounds on the constants above, and the upper\nbounds on $L$ improve upon the Zyablov-Pinsker bound whenever $q\\leq\n2^{(1/\\epsilon)^c}$ for some small universal constant $c>0$.", "published": "2025-05-09 10:26:12", "link": "http://arxiv.org/abs/2505.05935v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Mechanical Power Modeling and Energy Efficiency Maximization for Movable Antenna Systems", "abstract": "Movable antennas (MAs) have recently garnered significant attention in\nwireless communications due to their capability to reshape wireless channels\nvia local antenna movement within a confined region. However, to achieve\naccurate antenna movement, MA drivers introduce non-negligible mechanical power\nconsumption, rendering energy efficiency (EE) optimization more critical\ncompared to conventional fixed-position antenna (FPA) systems. To address this\nproblem, we develop in this paper a fundamental power consumption model for\nstepper motor-driven MA systems by resorting to basic electric motor theory.\nBased on this model, we formulate an EE maximization problem by jointly\noptimizing an MA's position, moving speed, and transmit power. However, this\nproblem is difficult to solve optimally due to the intricate relationship\nbetween the mechanical power consumption and the design variables. To tackle\nthis issue, we first uncover a hidden monotonicity of the EE performance with\nrespect to the MA's moving speed. Then, we apply the Dinkelbach algorithm to\nobtain the optimal transmit power in a semi-closed form for any given MA\nposition, followed by an enumeration to determine the optimal MA position.\nNumerical results demonstrate that despite the additional mechanical power\nconsumption, the MA system can outperform the conventional FPA system in terms\nof EE.", "published": "2025-05-09 09:40:22", "link": "http://arxiv.org/abs/2505.05914v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Price of Differential Privacy for Spectral Clustering over Stochastic Block Models", "abstract": "We investigate privacy-preserving spectral clustering for community detection\nwithin stochastic block models (SBMs). Specifically, we focus on edge\ndifferential privacy (DP) and propose private algorithms for community\nrecovery. Our work explores the fundamental trade-offs between the privacy\nbudget and the accurate recovery of community labels. Furthermore, we establish\ninformation-theoretic conditions that guarantee the accuracy of our methods,\nproviding theoretical assurances for successful community recovery under edge\nDP.", "published": "2025-05-09 06:34:56", "link": "http://arxiv.org/abs/2505.05816v1", "categories": ["cs.SI", "cs.CR", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.SI"}
{"title": "Anti-concentration inequalities for log-concave variables on the real line", "abstract": "We prove sharp anti-concentration results for log-concave random variables on\nthe real line in both the discrete and continuous setting. Our approach is\nelementary and uses majorization techniques to recover and extend some recent\nand not so recent results.", "published": "2025-05-09 05:19:08", "link": "http://arxiv.org/abs/2505.05793v1", "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "math.PR"}
{"title": "Towards Secure Semantic Transmission In the Era of GenAI: A Diffusion-based Framework", "abstract": "Semantic communication, due to its focus on the transmitting meaning rather\nthan the raw bit data, poses unique security challenges compared to the\ntraditional communication systems. In particular, semantic communication\nsystems are vulnerable to the malicious attacks that focus on the semantic\nlayer, with the intention of understanding or distorting the intended meaning\nof the transmitted privacy data. Diffusion models, a class of generative\nartificial intelligence (GenAI), are well-suited for ensuring data security to\nattack. Through iteratively adding and then removing noise, diffusion models\ncan generate meaningful information despite the presence of the unknown noise.\nThis article proposes a diffusion-based framework to enhance the security of\nsemantic transmission for the attacks including eavesdropping and jamming.\nSpecifically, the proposed framework incorporates both the artificial noise and\nnatural channel noise into the forward process of the diffusion models during\nthe semantic transmission, with the reverse process used to remove noise at the\nlegitimate receiver. In the eavesdropping scenarios, the artificial noise is\nthe friendly noise designed to prevent semantic eavesdropping. In the jamming\nscenarios, the artificial noise is the malicious jamming generated by the\njammer, which disrupts the semantic transmission. The case studies show that\nthe proposed diffusion-based framework is promising in securing the semantic\ntransmission. We also consolidate several broad research directions associated\nwith the proposed framework.", "published": "2025-05-09 01:51:56", "link": "http://arxiv.org/abs/2505.05724v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "LLM-Text Watermarking based on Lagrange Interpolation", "abstract": "The rapid advancement of LLMs (Large Language Models) has established them as\na foundational technology for many AI and ML powered human computer\ninteractions. A critical challenge in this context is the attribution of\nLLM-generated text, either to the specific language model used or to the\nindividual user who generated it. This is essential for combating\nmisinformation, fake news, misinterpretation, and plagiarism. One of the key\ntechniques for addressing this issue is watermarking.\n  This work presents a watermarking scheme for LLM-generated text based on\nLagrange interpolation, which enables the recovery of a secret author identity\neven when the text has been heavily redacted by an adversary. The core idea is\nto embed a continuous sequence of points (x, f(x)) that lie on a single\nstraight line. The x-coordinates are generated pseudorandomly using either an\nLFSR (when security is not a priority) or a cryptographically secure NFSR for\nhigh-security applications. The scheme efficiency and resilience to adversarial\nmodifications are analysed. Experimental results show that the proposed method\nis highly effective, allowing the recovery of the author identity when as few\nas three points survive adversarial manipulation.", "published": "2025-05-09 01:19:01", "link": "http://arxiv.org/abs/2505.05712v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "A Machine-Learning Compositional Study of Exoplanetary Material Accreted Onto Five Helium-Atmosphere White Dwarfs with $\\texttt{cecilia}$", "abstract": "We present the first application of the Machine Learning (ML) pipeline\n$\\texttt{cecilia}$ to determine the physical parameters and photospheric\ncomposition of five metal-polluted He-atmosphere white dwarfs without\nwell-characterised elemental abundances. To achieve this, we perform a joint\nand iterative Bayesian fit to their $\\textit{SDSS}$ (R=2,000) and\n$\\textit{Keck/ESI}$ (R=4,500) optical spectra, covering the wavelength range\nfrom about 3,800\\r{A} to 9,000\\r{A}. Our analysis measures the abundances of at\nleast two $-$and up to six$-$ chemical elements in their atmospheres with a\npredictive accuracy similar to that of conventional WD analysis techniques\n($\\approx$0.20 dex). The white dwarfs with the largest number of detected heavy\nelements are SDSS J0859$+$5732 and SDSS J2311$-$0041, which simultaneously\nexhibit O, Mg, Si, Ca, and Fe in their $\\textit{Keck/ESI}$ spectra. For all\nsystems, we find that the bulk composition of their pollutants is largely\nconsistent with those of primitive CI chondrites to within 1-2$\\sigma$. We also\nfind evidence of statistically significant ($>2\\sigma$) oxygen excesses for\nSDSS J0859$+$5732 and SDSS J2311$-$0041, which could point to the accretion of\noxygen-rich exoplanetary material. In the future, as wide-field astronomical\nsurveys deliver millions of public WD spectra to the scientific community,\n$\\texttt{cecilia}$ aspires to unlock population-wide studies of polluted WDs,\ntherefore helping to improve our statistical knowledge of extrasolar\ncompositions.", "published": "2025-05-09 17:59:50", "link": "http://arxiv.org/abs/2505.06228v1", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "primary_category": "astro-ph.EP"}
{"title": "Towards a Unified Representation Evaluation Framework Beyond Downstream Tasks", "abstract": "Downstream probing has been the dominant method for evaluating model\nrepresentations, an important process given the increasing prominence of\nself-supervised learning and foundation models. However, downstream probing\nprimarily assesses the availability of task-relevant information in the model's\nlatent space, overlooking attributes such as equivariance, invariance, and\ndisentanglement, which contribute to the interpretability, adaptability, and\nutility of representations in real-world applications. While some attempts have\nbeen made to measure these qualities in representations, no unified evaluation\nframework with modular, generalizable, and interpretable metrics exists.\n  In this paper, we argue for the importance of representation evaluation\nbeyond downstream probing. We introduce a standardized protocol to quantify\ninformativeness, equivariance, invariance, and disentanglement of factors of\nvariation in model representations. We use it to evaluate representations from\na variety of models in the image and speech domains using different\narchitectures and pretraining approaches on identified controllable factors of\nvariation. We find that representations from models with similar downstream\nperformance can behave substantially differently with regard to these\nattributes. This hints that the respective mechanisms underlying their\ndownstream performance are functionally different, prompting new research\ndirections to understand and improve representations.", "published": "2025-05-09 17:58:52", "link": "http://arxiv.org/abs/2505.06224v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Leveraging Multi-Task Learning for Multi-Label Power System Security Assessment", "abstract": "This paper introduces a novel approach to the power system security\nassessment using Multi-Task Learning (MTL), and reformulating the problem as a\nmulti-label classification task. The proposed MTL framework simultaneously\nassesses static, voltage, transient, and small-signal stability, improving both\naccuracy and interpretability with respect to the most state of the art machine\nlearning methods. It consists of a shared encoder and multiple decoders,\nenabling knowledge transfer between stability tasks. Experiments on the IEEE\n68-bus system demonstrate a measurable superior performance of the proposed\nmethod compared to the extant state-of-the-art approaches.", "published": "2025-05-09 17:36:59", "link": "http://arxiv.org/abs/2505.06207v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Auto Tensor Singular Value Thresholding: A Non-Iterative and Rank-Free Framework for Tensor Denoising", "abstract": "In modern data-driven tasks such as classification, optimization, and\nforecasting, mitigating the effects of intrinsic noise is crucial for improving\npredictive accuracy. While numerous denoising techniques have been developed,\nthe rising dimensionality of real-world datasets limits conventional\nmatrix-based methods in preserving data structure and accuracy. This challenge\nhas led to increasing interest in tensor-based approaches, which naturally\ncapture multi-way data relationships. However, classical tensor decomposition\nmethods (e.g., HOSVD, HOOI) typically require pre-specified ranks and iterative\noptimization, making them computationally expensive and less practical. In this\nwork, we propose a novel low-rank approximation method for tensor data that\navoids these limitations. Our approach applies statistically grounded singular\nvalue thresholding to mode-wise matricizations, enabling automatic extraction\nof significant components without requiring prior rank specification or\niterative refinement. Experiments on synthetic and real-world tensors show that\nour method consistently outperforms existing techniques in terms of estimation\naccuracy and computational efficiency, especially in noisy high-dimensional\nsettings.", "published": "2025-05-09 17:30:16", "link": "http://arxiv.org/abs/2505.06203v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Active Perception for Tactile Sensing: A Task-Agnostic Attention-Based Approach", "abstract": "Humans make extensive use of haptic exploration to map and identify the\nproperties of the objects that we touch. In robotics, active tactile perception\nhas emerged as an important research domain that complements vision for tasks\nsuch as object classification, shape reconstruction, and manipulation. This\nwork introduces TAP (Task-agnostic Active Perception) -- a novel framework that\nleverages reinforcement learning (RL) and transformer-based architectures to\naddress the challenges posed by partially observable environments. TAP\nintegrates Soft Actor-Critic (SAC) and CrossQ algorithms within a unified\noptimization objective, jointly training a perception module and\ndecision-making policy. By design, TAP is completely task-agnostic and can, in\nprinciple, generalize to any active perception problem. We evaluate TAP across\ndiverse tasks, including toy examples and realistic applications involving\nhaptic exploration of 3D models from the Tactile MNIST benchmark. Experiments\ndemonstrate the efficacy of TAP, achieving high accuracies on the Tactile MNIST\nhaptic digit recognition task and a tactile pose estimation task. These\nfindings underscore the potential of TAP as a versatile and generalizable\nframework for advancing active tactile perception in robotics.", "published": "2025-05-09 16:49:26", "link": "http://arxiv.org/abs/2505.06182v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows", "abstract": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nclassic NP-hard combinatorial optimization problem widely applied in logistics\ndistribution and transportation management. Its complexity stems from the\nconstraints of vehicle capacity and time windows, which pose significant\nchallenges to traditional approaches. Advances in Large Language Models (LLMs)\nprovide new possibilities for finding approximate solutions to CVRPTW. This\npaper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW\nwith real-time emergency constraints. Our solution introduces an adaptive\ntwo-phase training mechanism that transitions from the LLM-guided exploration\nphase to the autonomous optimization phase of Q-network. To ensure reliability,\nwe design a three-tier self-correction mechanism based on the Chain-of-Thought\n(CoT) for LLMs: syntactic validation, semantic verification, and physical\nconstraint enforcement. In addition, we also prioritized replay of the\nexperience generated by LLMs to amplify the regulatory role of LLMs in the\narchitecture. Experimental results demonstrate that our framework achieves a\n7.3\\% average reduction in cost compared to traditional Q-learning, with fewer\ntraining steps required for convergence.", "published": "2025-05-09 16:45:43", "link": "http://arxiv.org/abs/2505.06178v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning-Augmented Algorithms for Boolean Satisfiability", "abstract": "Learning-augmented algorithms are a prominent recent development in beyond\nworst-case analysis. In this framework, a problem instance is provided with a\nprediction (``advice'') from a machine-learning oracle, which provides partial\ninformation about an optimal solution, and the goal is to design algorithms\nthat leverage this advice to improve worst-case performance. We study the\nclassic Boolean satisfiability (SAT) decision and optimization problems within\nthis framework using two forms of advice. ``Subset advice\" provides a random\n$\\epsilon$ fraction of the variables from an optimal assignment, whereas\n``label advice\" provides noisy predictions for all variables in an optimal\nassignment.\n  For the decision problem $k$-SAT, by using the subset advice we accelerate\nthe exponential running time of the PPSZ family of algorithms due to Paturi,\nPudlak, Saks and Zane, which currently represent the state of the art in the\nworst case. We accelerate the running time by a multiplicative factor of\n$2^{-c}$ in the base of the exponent, where $c$ is a function of $\\epsilon$ and\n$k$. For the optimization problem, we show how to incorporate subset advice in\na black-box fashion with any $\\alpha$-approximation algorithm, improving the\napproximation ratio to $\\alpha + (1 - \\alpha)\\epsilon$. Specifically, we\nachieve approximations of $0.94 + \\Omega(\\epsilon)$ for MAX-$2$-SAT, $7/8 +\n\\Omega(\\epsilon)$ for MAX-$3$-SAT, and $0.79 + \\Omega(\\epsilon)$ for MAX-SAT.\nMoreover, for label advice, we obtain near-optimal approximation for instances\nwith large average degree, thereby generalizing recent results on MAX-CUT and\nMAX-$2$-LIN.", "published": "2025-05-09 15:54:34", "link": "http://arxiv.org/abs/2505.06146v1", "categories": ["cs.DS", "cs.CC", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation", "abstract": "Trajectory prediction is a key element of autonomous vehicle systems,\nenabling them to anticipate and react to the movements of other road users.\nEvaluating the robustness of prediction models against adversarial attacks is\nessential to ensure their reliability in real-world traffic. However, current\napproaches tend to focus on perturbing the past positions of surrounding\nagents, which can generate unrealistic scenarios and overlook critical\nvulnerabilities. This limitation may result in overly optimistic assessments of\nmodel performance in real-world conditions.\n  In this work, we demonstrate that perturbing not just past but also future\nstates of adversarial agents can uncover previously undetected weaknesses and\nthereby provide a more rigorous evaluation of model robustness. Our novel\napproach incorporates dynamic constraints and preserves tactical behaviors,\nenabling more effective and realistic adversarial attacks. We introduce new\nperformance measures to assess the realism and impact of these adversarial\ntrajectories. Testing our method on a state-of-the-art prediction model\nrevealed significant increases in prediction errors and collision rates under\nadversarial conditions. Qualitative analysis further showed that our attacks\ncan expose critical weaknesses, such as the inability of the model to detect\npotential collisions in what appear to be safe predictions. These results\nunderscore the need for more comprehensive adversarial testing to better\nevaluate and improve the reliability of trajectory prediction models for\nautonomous vehicles.", "published": "2025-05-09 15:40:32", "link": "http://arxiv.org/abs/2505.06134v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "FIC-TSC: Learning Time Series Classification with Fisher Information Constraint", "abstract": "Analyzing time series data is crucial to a wide spectrum of applications,\nincluding economics, online marketplaces, and human healthcare. In particular,\ntime series classification plays an indispensable role in segmenting different\nphases in stock markets, predicting customer behavior, and classifying worker\nactions and engagement levels. These aspects contribute significantly to the\nadvancement of automated decision-making and system optimization in real-world\napplications. However, there is a large consensus that time series data often\nsuffers from domain shifts between training and test sets, which dramatically\ndegrades the classification performance. Despite the success of (reversible)\ninstance normalization in handling the domain shifts for time series regression\ntasks, its performance in classification is unsatisfactory. In this paper, we\npropose \\textit{FIC-TSC}, a training framework for time series classification\nthat leverages Fisher information as the constraint. We theoretically and\nempirically show this is an efficient and effective solution to guide the model\nconverge toward flatter minima, which enhances its generalizability to\ndistribution shifts. We rigorously evaluate our method on 30 UEA multivariate\nand 85 UCR univariate datasets. Our empirical results demonstrate the\nsuperiority of the proposed method over 14 recent state-of-the-art methods.", "published": "2025-05-09 15:13:27", "link": "http://arxiv.org/abs/2505.06114v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Diffusion Maps", "abstract": "One of the fundamental problems within the field of machine learning is\ndimensionality reduction. Dimensionality reduction methods make it possible to\ncombat the so-called curse of dimensionality, visualize high-dimensional data\nand, in general, improve the efficiency of storing and processing large data\nsets. One of the best-known nonlinear dimensionality reduction methods is\nDiffusion Maps. However, despite their virtues, both Diffusion Maps and many\nother manifold learning methods based on the spectral decomposition of kernel\nmatrices have drawbacks such as the inability to apply them to data outside the\ninitial set, their computational complexity, and high memory costs for large\ndata sets. In this work, we propose to alleviate these problems by resorting to\ndeep learning. Specifically, a new formulation of Diffusion Maps embedding is\noffered as a solution to a certain unconstrained minimization problem and,\nbased on it, a cost function to train a neural network which computes Diffusion\nMaps embedding -- both inside and outside the training sample -- without the\nneed to perform any spectral decomposition. The capabilities of this approach\nare compared on different data sets, both real and synthetic, with those of\nDiffusion Maps and the Nystrom method.", "published": "2025-05-09 14:31:58", "link": "http://arxiv.org/abs/2505.06087v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fault Diagnosis of 3D-Printed Scaled Wind Turbine Blades", "abstract": "This study presents an integrated methodology for fault detection in wind\nturbine blades using 3D-printed scaled models, finite element simulations,\nexperimental modal analysis, and machine learning techniques. A scaled model of\nthe NREL 5MW blade was fabricated using 3D printing, and crack-type damages\nwere introduced at critical locations. Finite Element Analysis was employed to\npredict the impact of these damages on the natural frequencies, with the\nresults validated through controlled hammer impact tests. Vibration data was\nprocessed to extract both time-domain and frequency-domain features, and key\ndiscriminative variables were identified using statistical analyses (ANOVA).\nMachine learning classifiers, including Support Vector Machine and K-Nearest\nNeighbors, achieved classification accuracies exceeding 94%. The results\nrevealed that vibration modes 3, 4, and 6 are particularly sensitive to\nstructural anomalies for this blade. This integrated approach confirms the\nfeasibility of combining numerical simulations with experimental validations\nand paves the way for structural health monitoring systems in wind energy\napplications.", "published": "2025-05-09 14:25:57", "link": "http://arxiv.org/abs/2505.06080v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Safe-EF: Error Feedback for Nonsmooth Constrained Optimization", "abstract": "Federated learning faces severe communication bottlenecks due to the high\ndimensionality of model updates. Communication compression with contractive\ncompressors (e.g., Top-K) is often preferable in practice but can degrade\nperformance without proper handling. Error feedback (EF) mitigates such issues\nbut has been largely restricted for smooth, unconstrained problems, limiting\nits real-world applicability where non-smooth objectives and safety constraints\nare critical. We advance our understanding of EF in the canonical non-smooth\nconvex setting by establishing new lower complexity bounds for first-order\nalgorithms with contractive compression. Next, we propose Safe-EF, a novel\nalgorithm that matches our lower bound (up to a constant) while enforcing\nsafety constraints essential for practical applications. Extending our approach\nto the stochastic setting, we bridge the gap between theory and practical\nimplementation. Extensive experiments in a reinforcement learning setup,\nsimulating distributed humanoid robot training, validate the effectiveness of\nSafe-EF in ensuring safety and reducing communication complexity.", "published": "2025-05-09 13:49:05", "link": "http://arxiv.org/abs/2505.06053v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Music Audio Representations With Limited Data", "abstract": "Large deep-learning models for music, including those focused on learning\ngeneral-purpose music audio representations, are often assumed to require\nsubstantial training data to achieve high performance. If true, this would pose\nchallenges in scenarios where audio data or annotations are scarce, such as for\nunderrepresented music traditions, non-popular genres, and personalized music\ncreation and listening. Understanding how these models behave in limited-data\nscenarios could be crucial for developing techniques to tackle them.\n  In this work, we investigate the behavior of several music audio\nrepresentation models under limited-data learning regimes. We consider music\nmodels with various architectures, training paradigms, and input durations, and\ntrain them on data collections ranging from 5 to 8,000 minutes long. We\nevaluate the learned representations on various music information retrieval\ntasks and analyze their robustness to noise. We show that, under certain\nconditions, representations from limited-data and even random models perform\ncomparably to ones from large-dataset models, though handcrafted features\noutperform all learned representations in some tasks.", "published": "2025-05-09 13:39:53", "link": "http://arxiv.org/abs/2505.06042v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems", "abstract": "This paper focuses on the impact of rule representation in Michigan-style\nLearning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A\nwell-representation of the rules in an LFCS is crucial for improving its\nperformance. However, conventional rule representations frequently need help\naddressing problems with unknown data characteristics. To address this issue,\nthis paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive\nrule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates\na fuzzy indicator as a new rule parameter that sets the membership function of\na rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes.\nThe fuzzy indicator is optimized with evolutionary operators, allowing the\nsystem to search for an optimal rule representation. Results from extensive\nexperiments conducted on continuous space problems demonstrate that\nAdaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular\nand fuzzy-hypertrapezoidal rule representations in classification accuracy.\nAdditionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and\nreal-world problems with inherent uncertainty, such as missing values, leading\nto stable classification performance.", "published": "2025-05-09 12:59:29", "link": "http://arxiv.org/abs/2505.06017v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Differentiable Fuzzy Neural Networks for Recommender Systems", "abstract": "As recommender systems become increasingly complex, transparency is essential\nto increase user trust, accountability, and regulatory compliance.\nNeuro-symbolic approaches that integrate symbolic reasoning with sub-symbolic\nlearning offer a promising approach toward transparent and user-centric\nsystems. In this work-in-progress, we investigate using fuzzy neural networks\n(FNNs) as a neuro-symbolic approach for recommendations that learn logic-based\nrules over predefined, human-readable atoms. Each rule corresponds to a fuzzy\nlogic expression, making the recommender's decision process inherently\ntransparent. In contrast to black-box machine learning methods, our approach\nreveals the reasoning behind a recommendation while maintaining competitive\nperformance. We evaluate our method on a synthetic and MovieLens 1M datasets\nand compare it to state-of-the-art recommendation algorithms. Our results\ndemonstrate that our approach accurately captures user behavior while providing\na transparent decision-making process. Finally, the differentiable nature of\nthis approach facilitates an integration with other neural models, enabling the\ndevelopment of hybrid, transparent recommender systems.", "published": "2025-05-09 12:31:56", "link": "http://arxiv.org/abs/2505.06000v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Architectural Exploration of Hybrid Neural Decoders for Neuromorphic Implantable BMI", "abstract": "This work presents an efficient decoding pipeline for neuromorphic\nimplantable brain-machine interfaces (Neu-iBMI), leveraging sparse neural event\ndata from an event-based neural sensing scheme. We introduce a tunable event\nfilter (EvFilter), which also functions as a spike detector (EvFilter-SPD),\nsignificantly reducing the number of events processed for decoding by 192X and\n554X, respectively. The proposed pipeline achieves high decoding performance,\nup to R^2=0.73, with ANN- and SNN-based decoders, eliminating the need for\nsignal recovery, spike detection, or sorting, commonly performed in\nconventional iBMI systems. The SNN-Decoder reduces computations and memory\nrequired by 5-23X compared to NN-, and LSTM-Decoders, while the ST-NN-Decoder\ndelivers similar performance to an LSTM-Decoder requiring 2.5X fewer resources.\nThis streamlined approach significantly reduces computational and memory\ndemands, making it ideal for low-power, on-implant, or wearable iBMIs.", "published": "2025-05-09 12:15:09", "link": "http://arxiv.org/abs/2505.05983v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Offline Multi-agent Reinforcement Learning via Score Decomposition", "abstract": "Offline multi-agent reinforcement learning (MARL) faces critical challenges\ndue to distributional shifts, further exacerbated by the high dimensionality of\njoint action spaces and the diversity in coordination strategies and quality\namong agents. Conventional approaches, including independent learning\nframeworks and value decomposition methods based on pessimistic principles,\nremain susceptible to out-of-distribution (OOD) joint actions and often yield\nsuboptimal performance. Through systematic analysis of prevalent offline MARL\nbenchmarks, we identify that this limitation primarily stems from the\ninherently multimodal nature of joint collaborative policies induced by offline\ndata collection. To address these challenges, we propose a novel two-stage\nframework: First, we employ a diffusion-based generative model to explicitly\ncapture the complex behavior policy, enabling accurate modeling of diverse\nmulti-agent coordination patterns. Second, we introduce a sequential score\nfunction decomposition mechanism to regularize individual policies and enable\ndecentralized execution. Extensive experiments on continuous control tasks\ndemonstrate state-of-the-art performance across multiple standard offline MARL\nbenchmarks, outperforming existing methods by 26.3\\% in normalized returns. Our\napproach provides new insights into offline coordination and equilibrium\nselection in cooperative multi-agent systems.", "published": "2025-05-09 11:42:31", "link": "http://arxiv.org/abs/2505.05968v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Learning Power Control Protocol for In-Factory 6G Subnetworks", "abstract": "In-X Subnetworks are envisioned to meet the stringent demands of short-range\ncommunication in diverse 6G use cases. In the context of In-Factory scenarios,\neffective power control is critical to mitigating the impact of interference\nresulting from potentially high subnetwork density. Existing approaches to\npower control in this domain have predominantly emphasized the data plane,\noften overlooking the impact of signaling overhead. Furthermore, prior work has\ntypically adopted a network-centric perspective, relying on the assumption of\ncomplete and up-to-date channel state information (CSI) being readily available\nat the central controller. This paper introduces a novel multi-agent\nreinforcement learning (MARL) framework designed to enable access points to\nautonomously learn both signaling and power control protocols in an In-Factory\nSubnetwork environment. By formulating the problem as a partially observable\nMarkov decision process (POMDP) and leveraging multi-agent proximal policy\noptimization (MAPPO), the proposed approach achieves significant advantages.\nThe simulation results demonstrate that the learning-based method reduces\nsignaling overhead by a factor of 8 while maintaining a buffer flush rate that\nlags the ideal \"Genie\" approach by only 5%.", "published": "2025-05-09 11:39:18", "link": "http://arxiv.org/abs/2505.05967v1", "categories": ["cs.LG", "cs.NI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Multi-User Beamforming with Deep Reinforcement Learning in Sensing-Aided Communication", "abstract": "Mobile users are prone to experience beam failure due to beam drifting in\nmillimeter wave (mmWave) communications. Sensing can help alleviate beam\ndrifting with timely beam changes and low overhead since it does not need user\nfeedback. This work studies the problem of optimizing sensing-aided\ncommunication by dynamically managing beams allocated to mobile users. A\nmulti-beam scheme is introduced, which allocates multiple beams to the users\nthat need an update on the angle of departure (AoD) estimates and a single beam\nto the users that have satisfied AoD estimation precision. A deep reinforcement\nlearning (DRL) assisted method is developed to optimize the beam allocation\npolicy, relying only upon the sensing echoes. For comparison, a heuristic\nAoD-based method using approximated Cram\\'er-Rao lower bound (CRLB) for\nallocation is also presented. Both methods require neither user feedback nor\nprior state evolution information. Results show that the DRL-assisted method\nachieves a considerable gain in throughput than the conventional beam sweeping\nmethod and the AoD-based method, and it is robust to different user speeds.", "published": "2025-05-09 11:07:29", "link": "http://arxiv.org/abs/2505.05956v1", "categories": ["eess.SP", "cs.LG", "cs.NI"], "primary_category": "eess.SP"}
{"title": "FloE: On-the-Fly MoE Inference", "abstract": "With the widespread adoption of Mixture-of-Experts (MoE) models, there is a\ngrowing demand for efficient inference on memory-constrained devices. While\noffloading expert parameters to CPU memory and loading activated experts on\ndemand has emerged as a potential solution, the large size of activated experts\noverburdens the limited PCIe bandwidth, hindering the effectiveness in\nlatency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly\nMoE inference system on memory-constrained GPUs. FloE is built on the insight\nthat there exists substantial untapped redundancy within sparsely activated\nexperts. It employs various compression techniques on the expert's internal\nparameter matrices to reduce the data movement load, combined with low-cost\nsparse prediction, achieving perceptible inference acceleration in wall-clock\ntime on resource-constrained devices. Empirically, FloE achieves a 9.3x\ncompression of parameters per expert in Mixtral-8x7B; enables deployment on a\nGPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and\ndelivers a 48.7x inference speedup compared to DeepSpeed-MII on a single\nGeForce RTX 3090.", "published": "2025-05-09 10:53:47", "link": "http://arxiv.org/abs/2505.05950v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast Differentiable Modal Simulation of Non-linear Strings, Membranes, and Plates", "abstract": "Modal methods for simulating vibrations of strings, membranes, and plates are\nwidely used in acoustics and physically informed audio synthesis. However,\ntraditional implementations, particularly for non-linear models like the von\nK\\'arm\\'an plate, are computationally demanding and lack differentiability,\nlimiting inverse modelling and real-time applications. We introduce a fast,\ndifferentiable, GPU-accelerated modal framework built with the JAX library,\nproviding efficient simulations and enabling gradient-based inverse modelling.\nBenchmarks show that our approach significantly outperforms CPU and GPU-based\nimplementations, particularly for simulations with many modes. Inverse\nmodelling experiments demonstrate that our approach can recover physical\nparameters, including tension, stiffness, and geometry, from both synthetic and\nexperimental data. Although fitting physical parameters is more sensitive to\ninitialisation compared to other methods, it provides greater interpretability\nand more compact parameterisation. The code is released as open source to\nsupport future research and applications in differentiable physical modelling\nand sound synthesis.", "published": "2025-05-09 10:28:36", "link": "http://arxiv.org/abs/2505.05940v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "primary_category": "cs.SD"}
{"title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "abstract": "In class-incremental learning (CIL), effective incremental learning\nstrategies are essential to mitigate task confusion and catastrophic\nforgetting, especially as the number of tasks $t$ increases. Current exemplar\nreplay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We\npropose an autoencoder-based hybrid replay (AHR) strategy that leverages our\nnew hybrid autoencoder (HAE) to function as a compressor to alleviate the\nrequirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case\nwith the computing complexity of $\\mathcal{O}(t)$ while accomplishing\nstate-of-the-art performance. The decoder later recovers the exemplar data\nstored in the latent space, rather than in raw format. Additionally, HAE is\ndesigned for both discriminative and generative modeling, enabling\nclassification and replay capabilities, respectively. HAE adopts the charged\nparticle system energy minimization equations and repulsive force algorithm for\nthe incremental embedding and distribution of new class centroids in its latent\nspace. Our results demonstrate that AHR consistently outperforms recent\nbaselines across multiple benchmarks while operating with the same\nmemory/compute budgets. The source code is included in the supplementary\nmaterial and will be open-sourced upon publication.", "published": "2025-05-09 09:59:12", "link": "http://arxiv.org/abs/2505.05926v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy", "abstract": "Large Language Models (LLMs) have gained significant popularity due to their\nremarkable capabilities in text understanding and generation. However, despite\ntheir widespread deployment in inference services such as ChatGPT, concerns\nabout the potential leakage of sensitive user data have arisen. Existing\nsolutions primarily rely on privacy-enhancing technologies to mitigate such\nrisks, facing the trade-off among efficiency, privacy, and utility. To narrow\nthis gap, we propose Cape, a context-aware prompt perturbation mechanism based\non differential privacy, to enable efficient inference with an improved\nprivacy-utility trade-off. Concretely, we introduce a hybrid utility function\nthat better captures the token similarity. Additionally, we propose a\nbucketized sampling mechanism to handle large sampling space, which might lead\nto long-tail phenomenons. Extensive experiments across multiple datasets, along\nwith ablation studies, demonstrate that Cape achieves a better privacy-utility\ntrade-off compared to prior state-of-the-art works.", "published": "2025-05-09 09:54:07", "link": "http://arxiv.org/abs/2505.05922v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A 3D pocket-aware and evolutionary conserved interaction guided diffusion model for molecular optimization", "abstract": "Generating molecules that bind to specific protein targets via diffusion\nmodels has shown good promise for structure-based drug design and molecule\noptimization. Especially, the diffusion models with binding interaction\nguidance enables molecule generation with high affinity through forming\nfavorable interaction within protein pocket. However, the generated molecules\nmay not form interactions with the highly conserved residues, which are\nimportant for protein functions and bioactivities of the ligands. Herein, we\ndeveloped a new 3D target-aware diffusion model DiffDecip, which explicitly\nincorporates the protein-ligand binding interactions and evolutionary\nconservation information of protein residues into both diffusion and sampling\nprocess, for molecule optimization through scaffold decoration. The model\nperformance revealed that DiffDecip outperforms baseline model DiffDec on\nmolecule optimization towards higher affinity through forming more non-covalent\ninteractions with highly conserved residues in the protein pocket.", "published": "2025-05-09 08:33:45", "link": "http://arxiv.org/abs/2505.05874v1", "categories": ["cs.LG", "physics.chem-ph", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "A Taxonomy of Attacks and Defenses in Split Learning", "abstract": "Split Learning (SL) has emerged as a promising paradigm for distributed deep\nlearning, allowing resource-constrained clients to offload portions of their\nmodel computation to servers while maintaining collaborative learning. However,\nrecent research has demonstrated that SL remains vulnerable to a range of\nprivacy and security threats, including information leakage, model inversion,\nand adversarial attacks. While various defense mechanisms have been proposed, a\nsystematic understanding of the attack landscape and corresponding\ncountermeasures is still lacking. In this study, we present a comprehensive\ntaxonomy of attacks and defenses in SL, categorizing them along three key\ndimensions: employed strategies, constraints, and effectiveness. Furthermore,\nwe identify key open challenges and research gaps in SL based on our\nsystematization, highlighting potential future directions.", "published": "2025-05-09 08:19:15", "link": "http://arxiv.org/abs/2505.05872v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Open Set Label Shift with Test Time Out-of-Distribution Reference", "abstract": "Open set label shift (OSLS) occurs when label distributions change from a\nsource to a target distribution, and the target distribution has an additional\nout-of-distribution (OOD) class. In this work, we build estimators for both\nsource and target open set label distributions using a source domain\nin-distribution (ID) classifier and an ID/OOD classifier. With reasonable\nassumptions on the ID/OOD classifier, the estimators are assembled into a\nsequence of three stages: 1) an estimate of the source label distribution of\nthe OOD class, 2) an EM algorithm for Maximum Likelihood estimates (MLE) of the\ntarget label distribution, and 3) an estimate of the target label distribution\nof OOD class under relaxed assumptions on the OOD classifier. The sampling\nerrors of estimates in 1) and 3) are quantified with a concentration\ninequality. The estimation result allows us to correct the ID classifier\ntrained on the source distribution to the target distribution without\nretraining. Experiments on a variety of open set label shift settings\ndemonstrate the effectiveness of our model. Our code is available at\nhttps://github.com/ChangkunYe/OpenSetLabelShift.", "published": "2025-05-09 08:09:08", "link": "http://arxiv.org/abs/2505.05868v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Mixed-Integer Optimization for Responsible Machine Learning", "abstract": "In the last few decades, Machine Learning (ML) has achieved significant\nsuccess across domains ranging from healthcare, sustainability, and the social\nsciences, to criminal justice and finance. But its deployment in increasingly\nsophisticated, critical, and sensitive areas affecting individuals, the groups\nthey belong to, and society as a whole raises critical concerns around\nfairness, transparency, robustness, and privacy, among others. As the\ncomplexity and scale of ML systems and of the settings in which they are\ndeployed grow, so does the need for responsible ML methods that address these\nchallenges while providing guaranteed performance in deployment.\n  Mixed-integer optimization (MIO) offers a powerful framework for embedding\nresponsible ML considerations directly into the learning process while\nmaintaining performance. For example, it enables learning of inherently\ntransparent models that can conveniently incorporate fairness or other domain\nspecific constraints. This tutorial paper provides an accessible and\ncomprehensive introduction to this topic discussing both theoretical and\npractical aspects. It outlines some of the core principles of responsible ML,\ntheir importance in applications, and the practical utility of MIO for building\nML models that align with these principles. Through examples and mathematical\nformulations, it illustrates practical strategies and available tools for\nefficiently solving MIO problems for responsible ML. It concludes with a\ndiscussion on current limitations and open research questions, providing\nsuggestions for future work.", "published": "2025-05-09 07:51:36", "link": "http://arxiv.org/abs/2505.05857v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Collecting Human Motion Data in Large and Occlusion-Prone Environments using Ultra-Wideband Localization", "abstract": "With robots increasingly integrating into human environments, understanding\nand predicting human motion is essential for safe and efficient interactions.\nModern human motion and activity prediction approaches require high quality and\nquantity of data for training and evaluation, usually collected from motion\ncapture systems, onboard or stationary sensors. Setting up these systems is\nchallenging due to the intricate setup of hardware components, extensive\ncalibration procedures, occlusions, and substantial costs. These constraints\nmake deploying such systems in new and large environments difficult and limit\ntheir usability for in-the-wild measurements. In this paper we investigate the\npossibility to apply the novel Ultra-Wideband (UWB) localization technology as\na scalable alternative for human motion capture in crowded and occlusion-prone\nenvironments. We include additional sensing modalities such as eye-tracking,\nonboard robot LiDAR and radar sensors, and record motion capture data as ground\ntruth for evaluation and comparison. The environment imitates a museum setup,\nwith up to four active participants navigating toward random goals in a natural\nway, and offers more than 130 minutes of multi-modal data. Our investigation\nprovides a step toward scalable and accurate motion data collection beyond\nvision-based systems, laying a foundation for evaluating sensing modalities\nlike UWB in larger and complex environments like warehouses, airports, or\nconvention centers.", "published": "2025-05-09 07:44:57", "link": "http://arxiv.org/abs/2505.05851v1", "categories": ["cs.RO", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "DaringFed: A Dynamic Bayesian Persuasion Pricing for Online Federated Learning under Two-sided Incomplete Information", "abstract": "Online Federated Learning (OFL) is a real-time learning paradigm that\nsequentially executes parameter aggregation immediately for each random\narriving client. To motivate clients to participate in OFL, it is crucial to\noffer appropriate incentives to offset the training resource consumption.\nHowever, the design of incentive mechanisms in OFL is constrained by the\ndynamic variability of Two-sided Incomplete Information (TII) concerning\nresources, where the server is unaware of the clients' dynamically changing\ncomputational resources, while clients lack knowledge of the real-time\ncommunication resources allocated by the server. To incentivize clients to\nparticipate in training by offering dynamic rewards to each arriving client, we\ndesign a novel Dynamic Bayesian persuasion pricing for online Federated\nlearning (DaringFed) under TII. Specifically, we begin by formulating the\ninteraction between the server and clients as a dynamic signaling and pricing\nallocation problem within a Bayesian persuasion game, and then demonstrate the\nexistence of a unique Bayesian persuasion Nash equilibrium. By deriving the\noptimal design of DaringFed under one-sided incomplete information, we further\nanalyze the approximate optimal design of DaringFed with a specific bound under\nTII. Finally, extensive evaluation conducted on real datasets demonstrate that\nDaringFed optimizes accuracy and converges speed by 16.99%, while experiments\nwith synthetic datasets validate the convergence of estimate unknown values and\nthe effectiveness of DaringFed in improving the server's utility by up to\n12.6%.", "published": "2025-05-09 07:24:21", "link": "http://arxiv.org/abs/2505.05842v1", "categories": ["cs.GT", "cs.LG", "stat.ML"], "primary_category": "cs.GT"}
{"title": "New Statistical and Computational Results for Learning Junta Distributions", "abstract": "We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a\ndistribution is a $k$-junta if its probability mass function depends on a\nsubset of at most $k$ variables. We make two main contributions:\n  - We show that learning $k$-junta distributions is \\emph{computationally}\nequivalent to learning $k$-parity functions with noise (LPN), a landmark\nproblem in computational learning theory.\n  - We design an algorithm for learning junta distributions whose statistical\ncomplexity is optimal, up to polylogarithmic factors. Computationally, our\nalgorithm matches the complexity of previous (non-sample-optimal) algorithms.\n  Combined, our two contributions imply that our algorithm cannot be\nsignificantly improved, statistically or computationally, barring a\nbreakthrough for LPN.", "published": "2025-05-09 06:44:35", "link": "http://arxiv.org/abs/2505.05819v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "BCE vs. CE in Deep Feature Learning", "abstract": "When training classification models, it expects that the learned features are\ncompact within classes, and can well separate different classes. As the\ndominant loss function for training classification models, minimizing\ncross-entropy (CE) loss maximizes the compactness and distinctiveness, i.e.,\nreaching neural collapse (NC). The recent works show that binary CE (BCE)\nperforms also well in multi-class tasks. In this paper, we compare BCE and CE\nin deep feature learning. For the first time, we prove that BCE can also\nmaximize the intra-class compactness and inter-class distinctiveness when\nreaching its minimum, i.e., leading to NC. We point out that CE measures the\nrelative values of decision scores in the model training, implicitly enhancing\nthe feature properties by classifying samples one-by-one. In contrast, BCE\nmeasures the absolute values of decision scores and adjust the\npositive/negative decision scores across all samples to uniformly high/low\nlevels. Meanwhile, the classifier biases in BCE present a substantial\nconstraint on the decision scores to explicitly enhance the feature properties\nin the training. The experimental results are aligned with above analysis, and\nshow that BCE could improve the classification and leads to better compactness\nand distinctiveness among sample features. The codes will be released.", "published": "2025-05-09 06:18:31", "link": "http://arxiv.org/abs/2505.05813v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A novel Neural-ODE model for the state of health estimation of lithium-ion battery using charging curve", "abstract": "The state of health (SOH) of lithium-ion batteries (LIBs) is crucial for\nensuring the safe and reliable operation of electric vehicles. Nevertheless,\nthe prevailing SOH estimation methods often have limited generalizability. This\npaper introduces a data-driven approach for estimating the SOH of LIBs, which\nis designed to improve generalization. We construct a hybrid model named ACLA,\nwhich integrates the attention mechanism, convolutional neural network (CNN),\nand long short-term memory network (LSTM) into the augmented neural ordinary\ndifferential equation (ANODE) framework. This model employs normalized charging\ntime corresponding to specific voltages in the constant current charging phase\nas input and outputs the SOH as well as remaining useful of life. The model is\ntrained on NASA and Oxford datasets and validated on the TJU and HUST datasets.\nCompared to the benchmark models NODE and ANODE, ACLA exhibits higher accuracy\nwith root mean square errors (RMSE) for SOH estimation as low as 1.01% and\n2.24% on the TJU and HUST datasets, respectively.", "published": "2025-05-09 05:40:55", "link": "http://arxiv.org/abs/2505.05803v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rethinking Graph Out-Of-Distribution Generalization: A Learnable Random Walk Perspective", "abstract": "Out-Of-Distribution (OOD) generalization has gained increasing attentions for\nmachine learning on graphs, as graph neural networks (GNNs) often exhibit\nperformance degradation under distribution shifts. Existing graph OOD methods\ntend to follow the basic ideas of invariant risk minimization and structural\ncausal models, interpreting the invariant knowledge across datasets under\nvarious distribution shifts as graph topology or graph spectrum. However, these\ninterpretations may be inconsistent with real-world scenarios, as neither\ninvariant topology nor spectrum is assured. In this paper, we advocate the\nlearnable random walk (LRW) perspective as the instantiation of invariant\nknowledge, and propose LRW-OOD to realize graph OOD generalization learning.\nInstead of employing fixed probability transition matrix (i.e.,\ndegree-normalized adjacency matrix), we parameterize the transition matrix with\nan LRW-sampler and a path encoder. Furthermore, we propose the kernel density\nestimation (KDE)-based mutual information (MI) loss to generate random walk\nsequences that adhere to OOD principles. Extensive experiment demonstrates that\nour model can effectively enhance graph OOD generalization under various types\nof distribution shifts and yield a significant accuracy improvement of 3.87%\nover state-of-the-art graph OOD generalization baselines.", "published": "2025-05-09 04:58:48", "link": "http://arxiv.org/abs/2505.05785v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep-ICE: The first globally optimal algorithm for empirical risk minimization of two-layer maxout and ReLU networks", "abstract": "This paper introduces the first globally optimal algorithm for the empirical\nrisk minimization problem of two-layer maxout and ReLU networks, i.e.,\nminimizing the number of misclassifications. The algorithm has a worst-case\ntime complexity of $O\\left(N^{DK+1}\\right)$, where $K$ denotes the number of\nhidden neurons and $D$ represents the number of features. It can be can be\ngeneralized to accommodate arbitrary computable loss functions without\naffecting its computational complexity. Our experiments demonstrate that the\nproposed algorithm provides provably exact solutions for small-scale datasets.\nTo handle larger datasets, we introduce a novel coreset selection method that\nreduces the data size to a manageable scale, making it feasible for our\nalgorithm. This extension enables efficient processing of large-scale datasets\nand achieves significantly improved performance, with a 20-30\\% reduction in\nmisclassifications for both training and prediction, compared to\nstate-of-the-art approaches (neural networks trained using gradient descent and\nsupport vector machines), when applied to the same models (two-layer networks\nwith fixed hidden nodes and linear models).", "published": "2025-05-09 02:34:54", "link": "http://arxiv.org/abs/2505.05740v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Understanding Stragglers in Large Model Training Using What-if Analysis", "abstract": "Large language model (LLM) training is one of the most demanding distributed\ncomputations today, often requiring thousands of GPUs with frequent\nsynchronization across machines. Such a workload pattern makes it susceptible\nto stragglers, where the training can be stalled by few slow workers. At\nByteDance we find stragglers are not trivially always caused by hardware\nfailures, but can arise from multiple complex factors. This work aims to\npresent a comprehensive study on the straggler issues in LLM training, using a\nfive-month trace collected from our ByteDance LLM training cluster. The core\nmethodology is what-if analysis that simulates the scenario without any\nstragglers and contrasts with the actual case. We use this method to study the\nfollowing questions: (1) how often do stragglers affect training jobs, and what\neffect do they have on job performance; (2) do stragglers exhibit temporal or\nspatial patterns; and (3) what are the potential root causes for stragglers?", "published": "2025-05-09 01:24:24", "link": "http://arxiv.org/abs/2505.05713v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Crowding Out The Noise: Algorithmic Collective Action Under Differential Privacy", "abstract": "The integration of AI into daily life has generated considerable attention\nand excitement, while also raising concerns about automating algorithmic harms\nand re-entrenching existing social inequities. While the responsible deployment\nof trustworthy AI systems is a worthy goal, there are many possible ways to\nrealize it, from policy and regulation to improved algorithm design and\nevaluation. In fact, since AI trains on social data, there is even a\npossibility for everyday users, citizens, or workers to directly steer its\nbehavior through Algorithmic Collective Action, by deliberately modifying the\ndata they share with a platform to drive its learning process in their favor.\nThis paper considers how these grassroots efforts to influence AI interact with\nmethods already used by AI firms and governments to improve model\ntrustworthiness. In particular, we focus on the setting where the AI firm\ndeploys a differentially private model, motivated by the growing regulatory\nfocus on privacy and data protection. We investigate how the use of\nDifferentially Private Stochastic Gradient Descent (DPSGD) affects the\ncollective's ability to influence the learning process. Our findings show that\nwhile differential privacy contributes to the protection of individual data, it\nintroduces challenges for effective algorithmic collective action. We\ncharacterize lower bounds on the success of algorithmic collective action under\ndifferential privacy as a function of the collective's size and the firm's\nprivacy parameters, and verify these trends experimentally by simulating\ncollective action during the training of deep neural network classifiers across\nseveral datasets.", "published": "2025-05-09 00:55:12", "link": "http://arxiv.org/abs/2505.05707v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning", "abstract": "The absence of intrinsic adjacency relations and orientation systems in\nhypergraphs creates fundamental challenges for constructing sheaf Laplacians of\narbitrary degrees. We resolve these limitations through symmetric simplicial\nsets derived directly from hypergraphs, which encode all possible oriented\nsubrelations within each hyperedge as ordered tuples. This construction\ncanonically defines adjacency via facet maps while inherently preserving\nhyperedge provenance. We establish that the normalized degree zero sheaf\nLaplacian on our induced symmetric simplicial set reduces exactly to the\ntraditional graph normalized sheaf Laplacian when restricted to graphs,\nvalidating its mathematical consistency with prior graph-based sheaf theory.\nFurthermore, the induced structure preserves all structural information from\nthe original hypergraph, ensuring that every multi-way relational detail is\nfaithfully retained. Leveraging this framework, we introduce Hypergraph Neural\nSheaf Diffusion (HNSD), the first principled extension of Neural Sheaf\nDiffusion (NSD) to hypergraphs. HNSD operates via normalized degree zero sheaf\nLaplacians over symmetric simplicial sets, resolving orientation ambiguity and\nadjacency sparsity inherent to hypergraph learning. Experimental evaluations\ndemonstrate HNSD's competitive performance across established benchmarks.", "published": "2025-05-09 00:26:38", "link": "http://arxiv.org/abs/2505.05702v1", "categories": ["cs.LG", "05C65, 55U10, 68T07"], "primary_category": "cs.LG"}
{"title": "Extending Stress Detection Reproducibility to Consumer Wearable Sensors", "abstract": "Wearable sensors are widely used to collect physiological data and develop\nstress detection models. However, most studies focus on a single dataset,\nrarely evaluating model reproducibility across devices, populations, or study\nconditions. We previously assessed the reproducibility of stress detection\nmodels across multiple studies, testing models trained on one dataset against\nothers using heart rate (with R-R interval) and electrodermal activity (EDA).\nIn this study, we extended our stress detection reproducibility to consumer\nwearable sensors. We compared validated research-grade devices, to consumer\nwearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s,\nassessing device-specific stress detection performance by conducting a new\nstress study on undergraduate students. Thirty-five students completed three\nstandardized stress-induction tasks in a lab setting. Biopac MP160 performed\nthe best, being consistent with our expectations of it as the gold standard,\nthough performance varied across devices and models. Combining heart rate\nvariability (HRV) and EDA enhanced stress prediction across most scenarios.\nHowever, Empatica E4 showed variability; while HRV and EDA improved stress\ndetection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953),\ndevice-specific limitations led to underperformance when tested with our\npre-trained stress detection tool (AUROC 0.723), highlighting generalizability\nchallenges related to hardware-model compatibility. Garmin Forerunner 55s\ndemonstrated strong potential for real-world stress monitoring, achieving the\nbest mental arithmetic stress detection performance in LOSO (AUROC up to 0.961)\ncomparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica\nE4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with\nthe added advantage of consumer-friendly wearability for free-living contexts.", "published": "2025-05-09 00:06:06", "link": "http://arxiv.org/abs/2505.05694v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Physics-informed Temporal Difference Metric Learning for Robot Motion Planning", "abstract": "The motion planning problem involves finding a collision-free path from a\nrobot's starting to its target configuration. Recently, self-supervised\nlearning methods have emerged to tackle motion planning problems without\nrequiring expensive expert demonstrations. They solve the Eikonal equation for\ntraining neural networks and lead to efficient solutions. However, these\nmethods struggle in complex environments because they fail to maintain key\nproperties of the Eikonal equation, such as optimal value functions and\ngeodesic distances. To overcome these limitations, we propose a novel\nself-supervised temporal difference metric learning approach that solves the\nEikonal equation more accurately and enhances performance in solving complex\nand unseen planning tasks. Our method enforces Bellman's principle of\noptimality over finite regions, using temporal difference learning to avoid\nspurious local minima while incorporating metric learning to preserve the\nEikonal equation's essential geodesic properties. We demonstrate that our\napproach significantly outperforms existing self-supervised learning methods in\nhandling complex environments and generalizing to unseen environments, with\nrobot configurations ranging from 2 to 12 degrees of freedom (DOF).", "published": "2025-05-09 00:02:22", "link": "http://arxiv.org/abs/2505.05691v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Robust Multi-Agent Decision-Making in Finite-Population Games", "abstract": "We study the robustness of an agent decision-making model in\nfinite-population games, with a particular focus on the Kullback-Leibler\nDivergence Regularized Learning (KLD-RL) model. Specifically, we examine how\nthe model's parameters influence the effects of various sources of noise and\nmodeling inaccuracies -- factors commonly encountered in engineering\napplications of population games -- on agents' decision-making. Our analysis\nprovides insights into how these parameters can be effectively tuned to\nmitigate such effects. Theoretical results are supported by numerical examples\nand simulation studies that validate the analysis and illustrate practical\nstrategies for parameter selection.", "published": "2025-05-09 17:25:53", "link": "http://arxiv.org/abs/2505.06200v1", "categories": ["cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "Assessing the Dynamics of the Coffee Value Chain in Davao del Sur: An Agent-Based Modeling Approach", "abstract": "The study investigates the coffee value chain dynamics in Davao del Sur using\nan agent-based model. Three main factors driving interactions among key players\nwere identified: trust, risk, and transaction costs. The model was constructed\nusing NetLogo 6.3.0, and data from a survey questionnaire collected three data\npoints from BACOFA members. Five cases were explored, with each scenario\nsimulated 1000 times. Findings suggest that producers often sell to the market\nrather than the cooperative due to higher prices. However, producers tend to\nprioritize trust in buyers and their risk attitude, leading to increased sales\nto the cooperative. The producer's risk attitude significantly influences their\ndecision-making, affecting performance outcomes such as loans, demand, and\nprice changes. All three factors play a role and exert varying impacts on the\nvalue chain. So, the stakeholders' decisions on prioritizing factors in\nimproving relationships depend on their priorities. Nonetheless, simulations\nshow that establishing a harmonious system benefiting all parties is possible.\nHowever, achieving this requires adjustments to demand, pricing, trust, and\nrisk attitudes of key players, which may not align with the preferences of some\nparties in reality.", "published": "2025-05-09 05:24:51", "link": "http://arxiv.org/abs/2505.05797v1", "categories": ["econ.GN", "cs.CY", "cs.MA", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Stable fully practical finite element methods for axisymmetric Willmore flow", "abstract": "We consider fully discrete numerical approximations for axisymmetric Willmore\nflow that are unconditionally stable and work reliably without remeshing. We\nrestrict our attention to surfaces without boundary, but allow for spontaneous\ncurvature effects. The axisymmetric setting allows us to formulate our schemes\nin terms of the generating curve of the considered surface. We propose a novel\nweak formulation, that combines an evolution equation for the surface's mean\ncurvature and the curvature identity of the generating curve. The mean\ncurvature is used to describe the gradient flow structure, which enables an\nunconditional stability result for the discrete solutions. The generating\ncurve's curvature, on the other hand, describes the surface's in-plane\nprincipal curvature and plays the role of a Lagrange multiplier for an\nequidistribution property on the discrete level. We introduce two fully\ndiscrete schemes and prove their unconditional stability. Numerical results are\nprovided to confirm the convergence, stability and equidistribution properties\nof the introduced schemes.", "published": "2025-05-09 17:20:49", "link": "http://arxiv.org/abs/2505.06195v1", "categories": ["math.NA", "cs.NA", "65M60, 65M15, 65M12, 35R01"], "primary_category": "math.NA"}
{"title": "Efficient time-domain scattering synthesis via frequency-domain singularity subtraction", "abstract": "Fourier-transform-based methods enable accurate, dispersion-free\n  simulations of time-domain scattering problems by evaluating\n  solutions to the Helmholtz equation at a discrete set of\n  frequencies, sufficient to approximate the inverse Fourier\n  transform. However, in the case of scattering by trapping obstacles,\n  the Helmholtz solution exhibits nearly-real complex\n  resonances -- which significantly slows the convergence of numerical\n  inverse transform. To address this difficulty this paper introduces\n  a frequency-domain singularity subtraction technique that\n  regularizes the integrand of the inverse transform and efficiently\n  computes the singularity contribution via a combination of a\n  straightforward and inexpensive numerical technique together with a\n  large-time asymptotic expansion. Crucially, all relevant\n  complex resonances and their residues are determined via rational\n  approximation of integral equation solutions at real\n  frequencies. An adaptive algorithm is employed to ensure that all\n  relevant complex resonances are properly identified.", "published": "2025-05-09 16:59:28", "link": "http://arxiv.org/abs/2505.06189v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Convergent Inexact Abedin-Kitagawa Iteration Method for Monge-Amp\u00e8re Eigenvalue Problems", "abstract": "In this paper, we propose an inexact Aleksandrov solution based\nAbedin-Kitagawa iteration (AKI) method for solving (real) Monge-Amp{\\`e}re\neigenvalue problems. The proposed approach utilizes the convergent Rayleigh\ninverse iterative formulation introduced by Abedin and Kitagawa as the\nprototype. More importantly, it employs an error tolerance criterion of inexact\nAleksandrov solutions to approximately solve the subproblems without spoiling\nthe convergence, which becomes the most crucial issue for the efficient\nimplementation of the iterative method. For the two-dimensional case, by\nproperly taking advantage of the flexibility rendered by the proposed inexact\napproach and a convergent fixed-point-based approach to solve the subproblems,\nconsiderable advancements in computational efficiency can be achieved by the\ninexact AKI method with its convergence under the ${\\cal C}^{2,\\alpha}$\nboundary condition being rigorously established. Numerical experiments are\nconducted to demonstrate the efficiency of the proposed inexact AKI method. The\nnumerical results suggest that the inexact AKI method can be more than eight\ntimes faster than the original AKI method, at least for all the tested\nproblems.", "published": "2025-05-09 16:10:52", "link": "http://arxiv.org/abs/2505.06160v1", "categories": ["math.NA", "cs.NA", "65H17, 35J96, 65N25"], "primary_category": "math.NA"}
{"title": "Unconditionally local bounds preserving numerical scheme based on inverse Lax-Wendroff procedure for advection on networks", "abstract": "We derive an implicit numerical scheme for the solution of advection equation\nwhere the roles of space and time variables are exchanged using the inverse\nLax-Wendroff procedure. The scheme contains a linear weight for which it is\nalways second order accurate in time and space, and the stencil in the implicit\npart is fully upwinded for any value of the weight, enabling a direct\ncomputation of numerical solutions by forward substitution. To fulfill the\nlocal bounds for the solution represented by the discrete minimum and maximum\nprinciple (DMP), we use a predicted value obtained with the linear weight and\ncheck a priori if the DMP is valid. If not, we can use either a nonlinear\nweight or a limiter function that depends on Courant number and apply such a\nhigh-resolution version of the scheme to obtain a corrected value. The\nadvantage of the scheme obtained with the inverse Lax-Wendroff procedure is\nthat only in the case of too small Courant numbers, the limiting is towards the\nfirst order accurate scheme, which is not a situation occurring in numerical\nsimulations with implicit schemes very often. In summary, the local bounds are\nsatisfied up to rounding errors unconditionally for any Courant numbers, and\nthe formulas for the predictor and the corrector are explicit. The\nhigh-resolution scheme can be extended straightforwardly for advection with\nnonlinear retardation coefficient with numerical solutions satisfying the DMP,\nand a scalar nonlinear algebraic equation has to be solved to obtain each\npredicted and corrected value. In numerical experiments, including transport on\na sewer network, we can confirm the advantageous properties of numerical\nsolutions for several representative examples.", "published": "2025-05-09 15:01:31", "link": "http://arxiv.org/abs/2505.06106v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Triangular preconditioners for double saddle point linear systems arising in the mixed form of poroelasticity equations", "abstract": "In this paper, we study a class of inexact block triangular preconditioners\nfor double saddle-point symmetric linear systems arising from the mixed finite\nelement and mixed hybrid finite element discretization of Biot's poroelasticity\nequations. We develop a spectral analysis of the preconditioned matrix, showing\nthat the complex eigenvalues lie in a circle of center $(1,0)$ and radius\nsmaller than 1. In contrast, the real eigenvalues are described in terms of the\nroots of a third-degree polynomial with real coefficients. The results of\nnumerical experiments are reported to show the quality of the theoretical\nbounds and illustrate the efficiency of the proposed preconditioners used with\nGMRES, especially in comparison with similar block diagonal preconditioning\nstrategies along with the MINRES iteration.", "published": "2025-05-09 13:39:58", "link": "http://arxiv.org/abs/2505.06043v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Discretization of Dirac systems and port-Hamiltonian systems: the role of the constraint algorithm", "abstract": "We study the discretization of (almost-)Dirac structures using the notion of\nretraction and discretization maps on manifolds. Additionally, we apply the\nproposed discretization techniques to obtain numerical integrators for\nport-Hamiltonian systems and we discuss how to merge the discretization\nprocedure and the constraint algorithm associated to systems of implicit\ndifferential equations.", "published": "2025-05-09 13:15:20", "link": "http://arxiv.org/abs/2505.06024v1", "categories": ["math.NA", "cs.NA", "math.DG", "65P10, 34A26, 34C40, 37J39, 53D17"], "primary_category": "math.NA"}
{"title": "Discontinuous Galerkin time integration for second-order differential problems: formulations, analysis, and analogies", "abstract": "We thoroughly investigate Discontinuous Galerkin (DG) discretizations as time\nintegrators for second-order oscillatory systems, considering both second-order\nand first-order formulations of the original problem. Key contributions include\nnew convergence analyses for the second-order formulation and equivalence\nproofs between DG and classical time-stepping schemes (such as Newmark schemes\nand general linear methods). In addition, the chapter provides a detailed\nreview and convergence analysis for the first-order formulation, alongside\ncomparisons of the proposed schemes in terms of accuracy, consistency, and\ncomputational cost.", "published": "2025-05-09 12:17:05", "link": "http://arxiv.org/abs/2505.05985v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A review of discontinuous Galerkin time-stepping methods for wave propagation problems", "abstract": "This chapter reviews and compares discontinuous Galerkin time-stepping\nmethods for the numerical approximation of second-order ordinary differential\nequations, particularly those stemming from space finite element discretization\nof wave propagation problems. Two formulations, tailored for second- and\nfirst-order systems of ordinary differential equations, are discussed within a\ngeneralized framework, assessing their stability, accuracy, and computational\nefficiency. Theoretical results are supported by various illustrative examples\nthat validate the findings, enhancing the understanding and applicability of\nthese methods in practical scenarios.", "published": "2025-05-09 12:06:30", "link": "http://arxiv.org/abs/2505.05978v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On removing orders from amplitude equations", "abstract": "In this paper, we introduce a modified version of the renormalization group\n(RG) method and test its numerical accuracy. It has been tested on numerous\nscalar ODEs and systems of ODEs. Our method is primarily motivated by the\npossibility of simplifying amplitude equations. The key feature of our method\nis the introduction of a new homogeneous function at each order of the\nperturbation hierarchy, which is then used to remove terms from the amplitude\nequations. We have shown that there is a limit to how many terms can be\nremoved, as doing so beyond a certain point would reintroduce linear growth.\nThere is thus a \\textit{core} in the amplitude equation, which consists of the\nterms that cannot be removed while avoiding linear growth. Using our modified\nRG method, higher accuracy can also be achieved while maintaining the same\nlevel of complexity in the amplitude equation.", "published": "2025-05-09 09:41:07", "link": "http://arxiv.org/abs/2505.05915v1", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA"], "primary_category": "math-ph"}
{"title": "On the Stability Barrier of Hermite Type Discretizations of Advection Equations", "abstract": "In this paper we establish a stability barrier of a class of high-order\nHermite-type discretization of 1D advection equations underlying the\nhybrid-variable (HV) and active flux (AF) methods. These methods seek numerical\napproximations to both cell-averages and nodal solutions and evolves them in\ntime simultaneously. It was shown in earlier work that the HV methods are\nsupraconvergent, providing that the discretization uses more unknowns in the\nupwind direction than the downwind one, similar to the \"upwind condition\" of\nclassical finite-difference schemes. Although it is well known that the stencil\nof finite-difference methods could not be too biased towards the upwind\ndirection for stability consideration, known as \"stability barrier\", such a\nbarrier has not been established for Hermite-type methods. In this work, we\nfirst show by numerical evidence that a similar barrier exists for HV methods\nand make a conjecture on the sharp bound on the stencil. Next, we prove the\nexistence of stability barrier by showing that the semi-discretized HV methods\nare unstable given a stencil sufficiently biased towards the upwind direction.\nTighter barriers are then proved using combinatorical tools, and finally we\nextend the analysis to studying other Hermite-type methods built on\napproximating nodal solutions and derivatives, such as those widely used in\nHermite WENO methods.", "published": "2025-05-09 05:18:41", "link": "http://arxiv.org/abs/2505.05792v1", "categories": ["math.NA", "cs.NA", "65M06, 65M08, 65M12"], "primary_category": "math.NA"}
{"title": "Beyond the Mean: Limit Theory and Tests for Infinite-Mean Autoregressive Conditional Durations", "abstract": "Integrated autoregressive conditional duration (ACD) models serve as natural\ncounterparts to the well-known integrated GARCH models used for financial\nreturns. However, despite their resemblance, asymptotic theory for ACD is\nchallenging and also not complete, in particular for integrated ACD. Central\nchallenges arise from the facts that (i) integrated ACD processes imply\ndurations with infinite expectation, and (ii) even in the non-integrated case,\nconventional asymptotic approaches break down due to the randomness in the\nnumber of durations within a fixed observation period. Addressing these\nchallenges, we provide here unified asymptotic theory for the (quasi-) maximum\nlikelihood estimator for ACD models; a unified theory which includes integrated\nACD models. Based on the new results, we also provide a novel framework for\nhypothesis testing in duration models, enabling inference on a key empirical\nquestion: whether durations possess a finite or infinite expectation. We apply\nour results to high-frequency cryptocurrency ETF trading data. Motivated by\nparameter estimates near the integrated ACD boundary, we assess whether\ndurations between trades in these markets have finite expectation, an\nassumption often made implicitly in the literature on point process models. Our\nempirical findings indicate infinite-mean durations for all the five\ncryptocurrencies examined, with the integrated ACD hypothesis rejected --\nagainst alternatives with tail index less than one -- for four out of the five\ncryptocurrencies considered.", "published": "2025-05-09 17:00:28", "link": "http://arxiv.org/abs/2505.06190v1", "categories": ["econ.EM", "math.ST", "q-fin.ST", "stat.TH"], "primary_category": "econ.EM"}
{"title": "Smooth optimization algorithms for global and locally low-rank regularizers", "abstract": "Many inverse problems and signal processing problems involve low-rank\nregularizers based on the nuclear norm. Commonly, proximal gradient methods\n(PGM) are adopted to solve this type of non-smooth problems as they can offer\nfast and guaranteed convergence. However, PGM methods cannot be simply applied\nin settings where low-rank models are imposed locally on overlapping patches;\ntherefore, heuristic approaches have been proposed that lack convergence\nguarantees. In this work we propose to replace the nuclear norm with a smooth\napproximation in which a Huber-type function is applied to each singular value.\nBy providing a theoretical framework based on singular value function theory,\nwe show that important properties can be established for the proposed\nregularizer, such as: convexity, differentiability, and Lipschitz continuity of\nthe gradient. Moreover, we provide a closed-form expression for the regularizer\ngradient, enabling the use of standard iterative gradient-based optimization\nalgorithms (e.g., nonlinear conjugate gradient) that can easily address the\ncase of overlapping patches and have well-known convergence guarantees. In\naddition, we provide a novel step-size selection strategy based on a quadratic\nmajorizer of the line-search function that leverages the Huber characteristics\nof the proposed regularizer. Finally, we assess the proposed optimization\nframework by providing empirical results in dynamic magnetic resonance imaging\n(MRI) reconstruction in the context of locally low-rank models with overlapping\npatches.", "published": "2025-05-09 14:15:36", "link": "http://arxiv.org/abs/2505.06073v1", "categories": ["eess.SP", "eess.IV"], "primary_category": "eess.SP"}
{"title": "Quantum Noise Limited Temperature-Change Estimation for Phase-OTDR Employing Coherent Detection", "abstract": "The quantum limit is a fundamental lower bound on the uncertainty when\nestimating a parameter in a system dominated by the minimum amount of noise\n(quantum noise). For the first time, we derive and demonstrate a quantum limit\nfor temperature-change estimation for coherent phase-OTDR sensing-systems.", "published": "2025-05-09 12:36:40", "link": "http://arxiv.org/abs/2505.06007v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI-assisted Automatic Jump Detection and Height Estimation in Volleyball Using a Waist-worn IMU", "abstract": "The physical load of jumps plays a critical role in injury prevention for\nvolleyball players. However, manual video analysis of jump activities is\ntime-intensive and costly, requiring significant effort and expensive hardware\nsetups. The advent of the inertial measurement unit (IMU) and machine learning\nalgorithms offers a convenient and efficient alternative. Despite this,\nprevious research has largely focused on either jump classification or physical\nload estimation, leaving a gap in integrated solutions. This study aims to\npresent a pipeline to automatically detect jumps and predict heights using data\nfrom a waist-worn IMU. The pipeline leverages a Multi-Stage Temporal\nConvolutional Network (MS-TCN) to detect jump segments in time-series data and\nclassify the specific jump category. Subsequently, jump heights are estimated\nusing three downstream regression machine learning models based on the\nidentified segments. Our method is verified on a dataset comprising 10 players\nand 337 jumps. Compared to the result of VERT in height estimation\n(R-squared=-1.53), a commercial device commonly used in jump landing tasks, our\nmethod not only accurately identifies jump activities and their specific types\n(F1-score=0.90) but also demonstrates superior performance in height prediction\n(R-squared=0.50). This integrated solution offers a promising tool for\nmonitoring physical load and mitigating injury risk in volleyball players.", "published": "2025-05-09 09:25:18", "link": "http://arxiv.org/abs/2505.05907v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "abstract": "This study systematically evaluates 27 frontier Large Language Models on\neight biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with OpenAI's o3 now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including the biology subsets of GPQA and WMDP and\nLAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.", "published": "2025-05-09 15:05:57", "link": "http://arxiv.org/abs/2505.06108v2", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Multi-Modal Molecular Representation Learning via Structure Awareness", "abstract": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.", "published": "2025-05-09 08:37:29", "link": "http://arxiv.org/abs/2505.05877v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning", "abstract": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.", "published": "2025-05-09 03:38:31", "link": "http://arxiv.org/abs/2505.05758v2", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "LLM-Text Watermarking based on Lagrange Interpolation", "abstract": "The rapid advancement of LLMs (Large Language Models) has established them as\na foundational technology for many AI and ML-powered human computer\ninteractions. A critical challenge in this context is the attribution of\nLLM-generated text -- either to the specific language model that produced it or\nto the individual user who embedded their identity via a so-called multi-bit\nwatermark. This capability is essential for combating misinformation, fake\nnews, misinterpretation, and plagiarism. One of the key techniques for\naddressing this challenge is digital watermarking.\n  This work presents a watermarking scheme for LLM-generated text based on\nLagrange interpolation, enabling the recovery of a multi-bit author identity\neven when the text has been heavily redacted by an adversary. The core idea is\nto embed a continuous sequence of points $(x, f(x))$ that lie on a single\nstraight line. The $x$-coordinates are computed pseudorandomly using a\ncryptographic hash function $H$ applied to the concatenation of the previous\ntoken's identity and a secret key $s_k$. Crucially, the $x$-coordinates do not\nneed to be embedded into the text -- only the corresponding $f(x)$ values are\nembedded. During extraction, the algorithm recovers the original points along\nwith many spurious ones, forming an instance of the Maximum Collinear Points\n(MCP) problem, which can be solved efficiently. Experimental results\ndemonstrate that the proposed method is highly effective, allowing the recovery\nof the author identity even when as few as three genuine points remain after\nadversarial manipulation.", "published": "2025-05-09 01:19:01", "link": "http://arxiv.org/abs/2505.05712v2", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "FloE: On-the-Fly MoE Inference on Memory-constrained GPU", "abstract": "With the widespread adoption of Mixture-of-Experts (MoE) models, there is a\ngrowing demand for efficient inference on memory-constrained devices. While\noffloading expert parameters to CPU memory and loading activated experts on\ndemand has emerged as a potential solution, the large size of activated experts\noverburdens the limited PCIe bandwidth, hindering the effectiveness in\nlatency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly\nMoE inference system on memory-constrained GPUs. FloE is built on the insight\nthat there exists substantial untapped redundancy within sparsely activated\nexperts. It employs various compression techniques on the expert's internal\nparameter matrices to reduce the data movement load, combined with low-cost\nsparse prediction, achieving perceptible inference acceleration in wall-clock\ntime on resource-constrained devices. Empirically, FloE achieves a 9.3x\ncompression of parameters per expert in Mixtral-8x7B; enables deployment on a\nGPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and\ndelivers a 48.7x inference speedup compared to DeepSpeed-MII on a single\nGeForce RTX 3090 - all with only a 4.4$\\%$ - 7.6$\\%$ average performance\ndegradation.", "published": "2025-05-09 10:53:47", "link": "http://arxiv.org/abs/2505.05950v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Understanding Stragglers in Large Model Training Using What-if Analysis", "abstract": "Large language model (LLM) training is one of the most demanding distributed\ncomputations today, often requiring thousands of GPUs with frequent\nsynchronization across machines. Such a workload pattern makes it susceptible\nto stragglers, where the training can be stalled by few slow workers. At\nByteDance we find stragglers are not trivially always caused by hardware\nfailures, but can arise from multiple complex factors. This work aims to\npresent a comprehensive study on the straggler issues in LLM training, using a\nfive-month trace collected from our ByteDance LLM training cluster. The core\nmethodology is what-if analysis that simulates the scenario without any\nstragglers and contrasts with the actual case. We use this method to study the\nfollowing questions: (1) how often do stragglers affect training jobs, and what\neffect do they have on job performance; (2) do stragglers exhibit temporal or\nspatial patterns; and (3) what are the potential root causes for stragglers?", "published": "2025-05-09 01:24:24", "link": "http://arxiv.org/abs/2505.05713v2", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Is your multimodal large language model a good science tutor?", "abstract": "Multimodal large language models (MLLMs) demonstrate impressive performance\non scientific reasoning tasks (e.g., ScienceQA). However, most existing\nbenchmarks focus narrowly on the accuracy of the final answer while ignoring\nother metrics. In particular, when applying MLLMs to educational contexts, the\ngoal is not only correctness but also the ability to teach. In this paper, we\npropose a framework that evaluates MLLMs as science tutors using a\ncomprehensive educational rubric and a simulated student model that judges the\nteaching performance of the tutors. Given a list of candidate MLLM science\ntutors, we use rubric-based student judgments to produce a range of tutor\nperformance scores, identifying both strong and weak tutors. Using the training\nsection of the ScienceQA dataset, we then construct a data set of pairwise\ncomparisons between the outputs of strong and weak tutors. This enables us to\napply multiple preference optimization methods to fine-tune an underperforming\ntutor model (Qwen2-VL-2B) into more effective ones. Our results also show that\nstrong problem-solving skills do not guarantee high-quality tutoring and that\nperformance optimization-guided refinements can yield more educationally\naligned tutor models. This approach opens avenues for building MLLMs that serve\nnot only as problem solvers, but as genuinely helpful educational assistants.", "published": "2025-05-09 20:38:23", "link": "http://arxiv.org/abs/2505.06418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents", "abstract": "Recent advancements in Large Language Models (LLMs) and the introduction of\nthe Model Context Protocol (MCP) have significantly expanded LLM agents'\ncapability to interact dynamically with external tools and APIs. However,\nexisting tool selection frameworks do not integrate MCP servers, instead\nrelying heavily on error-prone manual updates to monolithic local tool\nrepositories, leading to duplication, inconsistencies, and inefficiencies.\nAdditionally, current approaches abstract tool selection before the LLM agent\nis invoked, limiting its autonomy and hindering dynamic re-querying\ncapabilities during multi-turn interactions. To address these issues, we\nintroduce ScaleMCP, a novel tool selection approach that dynamically equips LLM\nagents with a MCP tool retriever, giving agents the autonomy to add tools into\ntheir memory, as well as an auto-synchronizing tool storage system pipeline\nthrough CRUD (create, read, update, delete) operations with MCP servers as the\nsingle source of truth. We also propose a novel embedding strategy, Tool\nDocument Weighted Average (TDWA), designed to selectively emphasize critical\ncomponents of tool documents (e.g. tool name or synthetic questions) during the\nembedding process. Comprehensive evaluations conducted on a created dataset of\n5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models,\nand 5 retriever types, demonstrate substantial improvements in tool retrieval\nand agent invocation performance, emphasizing ScaleMCP's effectiveness in\nscalable, dynamic tool selection and invocation.", "published": "2025-05-09 20:30:37", "link": "http://arxiv.org/abs/2505.06416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tweedie Regression for Video Recommendation System", "abstract": "Modern recommendation systems aim to increase click-through rates (CTR) for\nbetter user experience, through commonly treating ranking as a classification\ntask focused on predicting CTR. However, there is a gap between this method and\nthe actual objectives of businesses across different sectors. In video\nrecommendation services, the objective of video on demand (VOD) extends beyond\nmerely encouraging clicks, but also guiding users to discover their true\ninterests, leading to increased watch time. And longer users watch time will\nleads to more revenue through increased chances of presenting online display\nadvertisements. This research addresses the issue by redefining the problem\nfrom classification to regression, with a focus on maximizing revenue through\nuser viewing time. Due to the lack of positive labels on recommendation, the\nstudy introduces Tweedie Loss Function, which is better suited in this scenario\nthan the traditional mean square error loss. The paper also provides insights\non how Tweedie process capture users diverse interests. Our offline simulation\nand online A/B test revealed that we can substantially enhance our core\nbusiness objectives: user engagement in terms of viewing time and,\nconsequently, revenue. Additionally, we provide a theoretical comparison\nbetween the Tweedie Loss and the commonly employed viewing time weighted\nLogloss, highlighting why Tweedie Regression stands out as an efficient\nsolution. We further outline a framework for designing a loss function that\nfocuses on a singular objective.", "published": "2025-05-09 21:27:59", "link": "http://arxiv.org/abs/2505.06445v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Document Attribution: Examining Citation Relationships using Large Language Models", "abstract": "As Large Language Models (LLMs) are increasingly applied to document-based\ntasks - such as document summarization, question answering, and information\nextraction - where user requirements focus on retrieving information from\nprovided documents rather than relying on the model's parametric knowledge,\nensuring the trustworthiness and interpretability of these systems has become a\ncritical concern. A central approach to addressing this challenge is\nattribution, which involves tracing the generated outputs back to their source\ndocuments. However, since LLMs can produce inaccurate or imprecise responses,\nit is crucial to assess the reliability of these citations.\n  To tackle this, our work proposes two techniques. (1) A zero-shot approach\nthat frames attribution as a straightforward textual entailment task. Our\nmethod using flan-ul2 demonstrates an improvement of 0.27% and 2.4% over the\nbest baseline of ID and OOD sets of AttributionBench, respectively. (2) We also\nexplore the role of the attention mechanism in enhancing the attribution\nprocess. Using a smaller LLM, flan-t5-small, the F1 scores outperform the\nbaseline across almost all layers except layer 4 and layers 8 through 11.", "published": "2025-05-09 04:40:11", "link": "http://arxiv.org/abs/2505.06324v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Mixing and Merging Metric Spaces using Directed Graphs", "abstract": "Let $(X_1,d_1),\\dots, (X_N,d_N)$ be metric spaces with respective distance\nfunctions $d_i: X_i \\times X_i \\rightarrow [0,1]$, $i=1,\\dots,N$. Let\n$\\mathcal{X}$ denote the set theoretic product $X_1\\times \\cdots \\times X_N$\nand let $\\mathbf{g} \\in \\mathcal{X}$ and $\\mathbf{h} \\in \\mathcal{X}$ denote\ntwo elements in this product space. Let $\\mathcal{G} =\n\\left(\\mathcal{V},\\mathcal{E}\\right)$ be a directed graph with vertices\n$\\mathcal{V} =\\{1,\\dots, N\\}$ and with a positive weight $\\mathcal{P} =\n\\{p_{ij}\\}, p_{ij}\\in (0, 1], i,j = 1,..,N$ associated with each edge $(i,j)\n\\in \\mathcal{E}$ of $\\mathcal{G}$. We define the function \\begin{align*}\nd_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}(\\mathbf{g},\\mathbf{h}) := \\left(1 -\n\\frac{1}{N}\\sum_{j=1}^N \\prod_{i=1}^N \\left[1-\nd_i(g_i,h_i)\\right]^{\\frac{1}{p_{ji}}} \\right). \\end{align*} In this paper we\nshow that $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ defines a metric space over\n$\\mathcal{X}$ and we investigate the properties of this distance under graph\noperations, which includes disjoint unions and cartesian products. We show two\nlimiting cases: (a) where $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ defined\nover a finite field leads to a broad generalization of graph-based distances\nthat is widely studied in the theory of error-correcting codes; and (b) where\n$d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ is extended to measuring distances\nover graphons.", "published": "2025-05-09 20:04:57", "link": "http://arxiv.org/abs/2505.06405v1", "categories": ["math.CO", "cs.IT", "math.IT", "math.MG", "math.ST", "stat.TH"], "primary_category": "math.CO"}
{"title": "Quantum strategies, error bounds, optimality, and duality gaps for multiplayer XOR, $\\mathrm{XOR}^{*}$, compiled XOR, $\\mathrm{XOR}^{*}$, and strong parallel repetiton of XOR, $\\mathrm{XOR}^{*}$, and FFL games", "abstract": "We characterize exact, and approximate, optimality of games that players can\ninteract with using quantum strategies. In comparison to a previous work of the\nauthor, arXiv: 2311.12887, which applied a 2016 framework due to Ostrev for\nconstructing error bounds beyond CHSH and XOR games, in addition to the\nexistence of well-posed semidefinite programs for determining primal feasible\nsolutions, along with quantum-classical duality gaps, it continues to remain of\ninterest to further develop the construction of error bounds, and related\nobjects, to game-theoretic settings with several participants. In such\nsettings, one encounters a rich information theoretic landscape, not only from\nthe fact that there exists a significantly larger combinatorial space of\npossible strategies for each player, but also several opportunities for\npronounced quantum advantage. We conclude this effort by describing other\nvariants of other possible strategies, as proposed sources for quantum\nadvantage, in $\\mathrm{XOR}^{*}$, compiled $\\mathrm{XOR}^{*}$, and strong\nparallel repetition variants of $\\mathrm{XOR}^{*}$ games.", "published": "2025-05-09 03:47:41", "link": "http://arxiv.org/abs/2505.06322v1", "categories": ["quant-ph", "cs.IT", "math.IT", "math.PR", "81P02, 81Q02"], "primary_category": "quant-ph"}
{"title": "Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models", "abstract": "As AI models scale to billions of parameters and operate with increasing\nautonomy, ensuring their safe, reliable operation demands engineering-grade\nsecurity and assurance frameworks. This paper presents an enterprise-level,\nrisk-aware, security-by-design approach for large-scale autonomous AI systems,\nintegrating standardized threat metrics, adversarial hardening techniques, and\nreal-time anomaly detection into every phase of the development lifecycle. We\ndetail a unified pipeline - from design-time risk assessments and secure\ntraining protocols to continuous monitoring and automated audit logging - that\ndelivers provable guarantees of model behavior under adversarial and\noperational stress. Case studies in national security, open-source model\ngovernance, and industrial automation demonstrate measurable reductions in\nvulnerability and compliance overhead. Finally, we advocate cross-sector\ncollaboration - uniting engineering teams, standards bodies, and regulatory\nagencies - to institutionalize these technical safeguards within a resilient,\nend-to-end assurance ecosystem for the next generation of AI.", "published": "2025-05-09 20:14:53", "link": "http://arxiv.org/abs/2505.06409v1", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.CR"}
{"title": "Quantum medical image encoding and compression using Fourier-based methods", "abstract": "Quantum image processing (QIMP) has recently emerged as a promising field for\nmodern image processing applications. In QIMP algorithms, encoding classical\nimage informaiton into quantum circuit is important as the first step. However,\nmost of existing encoding methods use gates almost twice the number of pixels\nin an image, and simulating even a modest sized image is computationally\ndemanding. In this work, we propose a quantum image encoding method that\neffectively reduces gates than the number of pixels by a factor at least 4. We\ndemonstrate our method for various 1024 by 1024 high-quality medical images\ncaptured during the Bilateral Axillo-Breast Approach (BABA) robotic\nthyroidectomy surgery. Additionally, two compression techniques are proposed to\nfurther reduce the number of gates as well as pre-processing time with\nnegligible loss of image quality. We suggest our image encoding strategy as a\nvaluable option for large scale medical imaging.", "published": "2025-05-09 23:56:06", "link": "http://arxiv.org/abs/2505.06471v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "A Hybridizable Discontinuous Galerkin Method for the Miscible Displacement Problem Under Minimal Regularity", "abstract": "A numerical method based on the hybridizable discontinuous Galerkin method in\nspace and backward Euler in time is formulated and analyzed for solving the\nmiscible displacement problem. Under low regularity assumptions, convergence is\nestablished by proving that, up to a subsequence, the discrete pressure,\nvelocity and concentration converge to a weak solution as the mesh size and\ntime step tend to zero. The analysis is based on several key features: an\nH(div) reconstruction of the velocity, the skew-symmetrization of the\nconcentration equation, the introduction of an auxiliary variable and the\ndefinition of a new numerical flux. Numerical examples demonstrate optimal\nrates of convergence for smooth solutions, and convergence for problems of low\nregularity.", "published": "2025-05-09 22:38:54", "link": "http://arxiv.org/abs/2505.06458v1", "categories": ["math.NA", "cs.NA", "65M12, 65M60, 76S05"], "primary_category": "math.NA"}
{"title": "Initialization and training of matrix product state probabilistic models", "abstract": "Modeling probability distributions via the wave function of a quantum state\nis central to quantum-inspired generative modeling and quantum state tomography\n(QST). We investigate a common failure mode in training randomly initialized\nmatrix product states (MPS) using gradient descent. The results show that the\ntrained MPS models do not accurately predict the strong interactions between\nboundary sites in periodic spin chain models. In the case of the Born machine\nalgorithm, we further identify a causality trap, where the trained MPS models\nresemble causal models that ignore the non-local correlations in the true\ndistribution. We propose two complementary strategies to overcome the training\nfailure -- one through optimization and one through initialization. First, we\ndevelop a natural gradient descent (NGD) method, which approximately simulates\nthe gradient flow on tensor manifolds and significantly enhances training\nefficiency. Numerical experiments show that NGD avoids local minima in both\nBorn machines and in general MPS tomography. Remarkably, we show that NGD with\nline search can converge to the global minimum in only a few iterations.\nSecond, for the BM algorithm, we introduce a warm-start initialization based on\nthe TTNS-Sketch algorithm. We show that gradient descent under a warm\ninitialization does not encounter the causality trap and admits rapid\nconvergence to the ground truth.", "published": "2025-05-09 20:39:25", "link": "http://arxiv.org/abs/2505.06419v1", "categories": ["math.NA", "cs.NA", "quant-ph"], "primary_category": "math.NA"}
{"title": "Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles", "abstract": "Physics-Informed Neural Networks (PINNs) have been widely used to obtain\nsolutions to various physical phenomena modeled as Differential Equations. As\nPINNs are not naturally equipped with mechanisms for Uncertainty\nQuantification, some work has been done to quantify the different uncertainties\nthat arise when dealing with PINNs. In this paper, we use a two-step procedure\nto train Bayesian Neural Networks that provide uncertainties over the solutions\nto differential equation systems provided by PINNs. We use available error\nbounds over PINNs to formulate a heteroscedastic variance that improves the\nuncertainty estimation. Furthermore, we solve forward problems and utilize the\nobtained uncertainties when doing parameter estimation in inverse problems in\ncosmology.", "published": "2025-05-09 22:40:39", "link": "http://arxiv.org/abs/2505.06459v1", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fair Representation Learning for Continuous Sensitive Attributes using Expectation of Integral Probability Metrics", "abstract": "AI fairness, also known as algorithmic fairness, aims to ensure that\nalgorithms operate without bias or discrimination towards any individual or\ngroup. Among various AI algorithms, the Fair Representation Learning (FRL)\napproach has gained significant interest in recent years. However, existing FRL\nalgorithms have a limitation: they are primarily designed for categorical\nsensitive attributes and thus cannot be applied to continuous sensitive\nattributes, such as age or income. In this paper, we propose an FRL algorithm\nfor continuous sensitive attributes. First, we introduce a measure called the\nExpectation of Integral Probability Metrics (EIPM) to assess the fairness level\nof representation space for continuous sensitive attributes. We demonstrate\nthat if the distribution of the representation has a low EIPM value, then any\nprediction head constructed on the top of the representation become fair,\nregardless of the selection of the prediction head. Furthermore, EIPM possesses\na distinguished advantage in that it can be accurately estimated using our\nproposed estimator with finite samples. Based on these properties, we propose a\nnew FRL algorithm called Fair Representation using EIPM with MMD (FREM).\nExperimental evidences show that FREM outperforms other baseline methods.", "published": "2025-05-09 21:08:52", "link": "http://arxiv.org/abs/2505.06435v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "CAST: Time-Varying Treatment Effects with Application to Chemotherapy and Radiotherapy on Head and Neck Squamous Cell Carcinoma", "abstract": "Causal machine learning (CML) enables individualized estimation of treatment\neffects, offering critical advantages over traditional correlation-based\nmethods. However, existing approaches for medical survival data with censoring\nsuch as causal survival forests estimate effects at fixed time points, limiting\ntheir ability to capture dynamic changes over time. We introduce Causal\nAnalysis for Survival Trajectories (CAST), a novel framework that models\ntreatment effects as continuous functions of time following treatment. By\ncombining parametric and non-parametric methods, CAST overcomes the limitations\nof discrete time-point analysis to estimate continuous effect trajectories.\nUsing the RADCURE dataset [1] of 2,651 patients with head and neck squamous\ncell carcinoma (HNSCC) as a clinically relevant example, CAST models how\nchemotherapy and radiotherapy effects evolve over time at the population and\nindividual levels. By capturing the temporal dynamics of treatment response,\nCAST reveals how treatment effects rise, peak, and decline over the follow-up\nperiod, helping clinicians determine when and for whom treatment benefits are\nmaximized. This framework advances the application of CML to personalized care\nin HNSCC and other life-threatening medical conditions. Source code/data\navailable at: https://github.com/CAST-FW/HNSCC", "published": "2025-05-09 18:19:41", "link": "http://arxiv.org/abs/2505.06367v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Development of Reduced Feeder and Load Models Using Practical Topological and Loading Data", "abstract": "Distribution feeder and load model reduction methods are essential for\nmaintaining a good tradeoff between accurate representation of grid behavior\nand reduced computational complexity in power system studies. An effective\nalgorithm to obtain a reduced order representation of the practical feeders\nusing utility topological and loading data has been presented in this paper.\nSimulations conducted in this work show that the reduced feeder and load model\nof a utility feeder, obtained using the proposed method, can accurately capture\ncontactor and motor stalling behaviors for critical events such as fault\ninduced delayed voltage recovery.", "published": "2025-05-09 21:15:34", "link": "http://arxiv.org/abs/2505.06439v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "An Improved Approach to Estimate the Internal Resistance of a Battery", "abstract": "This paper considers the problem of resistance estimation in electronic\nsystems including battery management systems (BMS) and battery chargers. In\ntypical applications, the battery resistance is obtained through an approximate\nmethod computed as the ratio of the voltage difference to the applied current\nexcitation pulse or vice versa for admittance. When estimating the battery\nresistance, this approach ignores the change in the open circuit voltage (OCV)\nas a result of the excitation signal. In this paper, we formally demonstrate\nand quantify the effect of the OCV drop on the errors in internal resistance\nestimation. Then, we propose a novel method to accurately estimate the internal\nresistance by accounting for the change in OCV caused by the applied current\nexcitation signal. The proposed approach is based on a novel observation model\nthat allows one to estimate the effect of OCV without requiring any additional\ninformation, such as the state of charge (SOC), parameters of the OCV-SOC\ncurve, and the battery capacity. As such, the proposed approach is independent\nof the battery chemistry, size, age, and the ambient temperature. A performance\nanalysis of the proposed approach using the battery simulator shows significant\nperformance gain in the range of 30% to more than 250% in percentage estimation\nerror. Then, the proposed approach is applied for resistance estimation during\nthe hybrid pulse power characterization (HPPC) of cylindrical Li-ion battery\ncells. Results from tested batteries show that the proposed approach reduced\nthe overestimated internal resistance of the batteries by up to 20 m{\\Omega}.", "published": "2025-05-09 20:17:37", "link": "http://arxiv.org/abs/2505.06410v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Comprehensive Data Description for LoRaWAN Path Loss Measurements in an Indoor Office Setting: Effects of Environmental Factors", "abstract": "This paper presents a comprehensive dataset of LoRaWAN technology path loss\nmeasurements collected in an indoor office environment, focusing on quantifying\nthe effects of environmental factors on signal propagation. Utilizing a network\nof six strategically placed LoRaWAN end devices (EDs) and a single indoor\ngateway (GW) at the University of Siegen, City of Siegen, Germany, we\nsystematically measured signal strength indicators such as the Received Signal\nStrength Indicator (RSSI) and the Signal-to-Noise Ratio (SNR) under various\nenvironmental conditions, including temperature, relative humidity, carbon\ndioxide (CO$_2$) concentration, barometric pressure, and particulate matter\nlevels (PM$_{2.5}$). Our empirical analysis confirms that transient phenomena\nsuch as reflections, scattering, interference, occupancy patterns (induced by\nenvironmental parameter variations), and furniture rearrangements can alter\nsignal attenuation by as much as 10.58 dB, highlighting the dynamic nature of\nindoor propagation. As an example of how this dataset can be utilized, we\ntested and evaluated a refined Log-Distance Path Loss and Shadowing Model that\nintegrates both structural obstructions (Multiple Walls) and Environmental\nParameters (LDPLSM-MW-EP). Compared to a baseline model that considers only\nMultiple Walls (LDPLSM-MW), the enhanced approach reduced the root mean square\nerror (RMSE) from 10.58 dB to 8.04 dB and increased the coefficient of\ndetermination (R$^2$) from 0.6917 to 0.8222. By capturing the extra effects of\nenvironmental conditions and occupancy dynamics, this improved model provides\nvaluable insights for optimizing power usage and prolonging device battery\nlife, enhancing network reliability in indoor Internet of Things (IoT)\ndeployments, among other applications. This dataset offers a solid foundation\nfor future research and development in indoor wireless communication.", "published": "2025-05-09 18:41:42", "link": "http://arxiv.org/abs/2505.06375v1", "categories": ["cs.NI", "cs.AR", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring", "abstract": "Non-intrusive Load Monitoring (NILM) aims to disaggregate aggregate household\nelectricity consumption into individual appliance usage, enabling more\neffective energy management. While deep learning has advanced NILM, it remains\nlimited by its dependence on labeled data, restricted generalization, and lack\nof interpretability. In this paper, we introduce the first prompt-based NILM\nframework that leverages Large Language Models (LLMs) with in-context learning.\nWe design and evaluate prompt strategies that integrate appliance features,\ntimestamps and contextual information, as well as representative time-series\nexamples, using the REDD dataset. With optimized prompts, LLMs achieve\ncompetitive state detection accuracy, reaching an average F1-score of 0.676 on\nunseen households, and demonstrate robust generalization without the need for\nfine-tuning. LLMs also enhance interpretability by providing clear,\nhuman-readable explanations for their predictions. Our results show that LLMs\ncan reduce data requirements, improve adaptability, and provide transparent\nenergy disaggregation in NILM applications.", "published": "2025-05-09 15:35:11", "link": "http://arxiv.org/abs/2505.06330v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "abstract": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.", "published": "2025-05-09 16:55:06", "link": "http://arxiv.org/abs/2505.06186v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM-Text Watermarking based on Lagrange Interpolation", "abstract": "The rapid advancement of LLMs (Large Language Models) has established them as\na foundational technology for many AI and ML-powered human computer\ninteractions. A critical challenge in this context is the attribution of\nLLM-generated text -- either to the specific language model that produced it or\nto the individual user who embedded their identity via a so-called multi-bit\nwatermark. This capability is essential for combating misinformation, fake\nnews, misinterpretation, and plagiarism. One of the key techniques for\naddressing this challenge is digital watermarking.\n  This work presents a watermarking scheme for LLM-generated text based on\nLagrange interpolation, enabling the recovery of a multi-bit author identity\neven when the text has been heavily redacted by an adversary. The core idea is\nto embed a continuous sequence of points $(x, f(x))$ that lie on a single\nstraight line. The $x$-coordinates are computed pseudorandomly using a\ncryptographic hash function $H$ applied to the concatenation of the previous\ntoken's identity and a secret key $s_k$. Crucially, the $x$-coordinates do not\nneed to be embedded into the text -- only the corresponding $f(x)$ values are\nembedded. During extraction, the algorithm recovers the original points along\nwith many spurious ones, forming an instance of the Maximum Collinear Points\n(MCP) problem, which can be solved efficiently. Experimental results\ndemonstrate that the proposed method is highly effective, allowing the recovery\nof the author identity even when as few as three genuine points remain after\nadversarial manipulation.", "published": "2025-05-09 01:19:01", "link": "http://arxiv.org/abs/2505.05712v3", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
