{"title": "A Variational Framework for Improving Naturalness in Generative Spoken Language Models", "abstract": "The success of large language models in text processing has inspired their\nadaptation to speech modeling. However, since speech is continuous and complex,\nit is often discretized for autoregressive modeling. Speech tokens derived from\nself-supervised models (known as semantic tokens) typically focus on the\nlinguistic aspects of speech but neglect prosodic information. As a result,\nmodels trained on these tokens can generate speech with reduced naturalness.\nExisting approaches try to fix this by adding pitch features to the semantic\ntokens. However, pitch alone cannot fully represent the range of paralinguistic\nattributes, and selecting the right features requires careful hand-engineering.\nTo overcome this, we propose an end-to-end variational approach that\nautomatically learns to encode these continuous speech attributes to enhance\nthe semantic tokens. Our approach eliminates the need for manual extraction and\nselection of paralinguistic features. Moreover, it produces preferred speech\ncontinuations according to human raters. Code, samples and models are available\nat https://github.com/b04901014/vae-gslm.", "published": "2025-06-17 17:58:17", "link": "http://arxiv.org/abs/2506.14767v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM", "abstract": "Multimodal Large Language Model (MLLM) often suffer from hallucinations. They\nover-rely on partial cues and generate incorrect responses. Recently, methods\nlike Visual Contrastive Decoding (VCD) and Instruction Contrastive Decoding\n(ICD) have been proposed to mitigate hallucinations by contrasting predictions\nfrom perturbed or negatively prefixed inputs against original outputs. In this\nwork, we uncover that methods like VCD and ICD fundamentally influence internal\nattention dynamics of the model. This observation suggests that their\neffectiveness may not stem merely from surface-level modifications to logits\nbut from deeper shifts in attention distribution. Inspired by this insight, we\npropose an attention-steerable contrastive decoding framework that directly\nintervenes in attention mechanisms of the model to offer a more principled\napproach to mitigating hallucinations. Our experiments across multiple MLLM\narchitectures and diverse decoding methods demonstrate that our approach\nsignificantly reduces hallucinations and improves the performance on benchmarks\nsuch as POPE, CHAIR, and MMHal-Bench, while simultaneously enhancing\nperformance on standard VQA benchmarks.", "published": "2025-06-17 17:58:11", "link": "http://arxiv.org/abs/2506.14766v1", "categories": ["cs.CV", "cs.CL", "68T45"], "primary_category": "cs.CV"}
{"title": "From Bytes to Ideas: Language Modeling with Autoregressive U-Nets", "abstract": "Tokenization imposes a fixed granularity on the input text, freezing how a\nlanguage model operates on data and how far in the future it predicts. Byte\nPair Encoding (BPE) and similar schemes split text once, build a static\nvocabulary, and leave the model stuck with that choice. We relax this rigidity\nby introducing an autoregressive U-Net that learns to embed its own tokens as\nit trains. The network reads raw bytes, pools them into words, then pairs of\nwords, then up to 4 words, giving it a multi-scale view of the sequence. At\ndeeper stages, the model must predict further into the future -- anticipating\nthe next few words rather than the next byte -- so deeper stages focus on\nbroader semantic patterns while earlier stages handle fine details. When\ncarefully tuning and controlling pretraining compute, shallow hierarchies tie\nstrong BPE baselines, and deeper hierarchies have a promising trend. Because\ntokenization now lives inside the model, the same system can handle\ncharacter-level tasks and carry knowledge across low-resource languages.", "published": "2025-06-17 17:55:11", "link": "http://arxiv.org/abs/2506.14761v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning with Exploration: An Entropy Perspective", "abstract": "Balancing exploration and exploitation is a central goal in reinforcement\nlearning (RL). Despite recent advances in enhancing language model (LM)\nreasoning, most methods lean toward exploitation, and increasingly encounter\nperformance plateaus. In this work, we revisit entropy -- a signal of\nexploration in RL -- and examine its relationship to exploratory reasoning in\nLMs. Through empirical analysis, we uncover strong positive correlations\nbetween high-entropy regions and three types of exploratory reasoning actions:\n(1) pivotal tokens that determine or connect logical steps, (2) reflective\nactions such as self-verification and correction, and (3) rare behaviors\nunder-explored by the base LMs. Motivated by this, we introduce a minimal\nmodification to standard RL with only one line of code: augmenting the\nadvantage function with an entropy-based term. Unlike traditional\nmaximum-entropy methods which encourage exploration by promoting uncertainty,\nwe encourage exploration by promoting longer and deeper reasoning chains.\nNotably, our method achieves significant gains on the Pass@K metric -- an\nupper-bound estimator of LM reasoning capabilities -- even when evaluated with\nextremely large K values, pushing the boundaries of LM reasoning.", "published": "2025-06-17 17:54:03", "link": "http://arxiv.org/abs/2506.14758v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Length Compression in Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) have achieved remarkable success, yet they\noften suffer from producing unnecessary and verbose reasoning chains. We\nidentify a core aspect of this issue as \"invalid thinking\" -- models tend to\nrepeatedly double-check their work after having derived the correct answer. To\naddress this specific inefficiency, we move beyond the general principles of\nEfficacy and Efficiency to propose two new, fine-grained principles: Brevity,\nwhich advocates for eliminating redundancy, and Sufficiency, which ensures\ncritical reasoning steps are preserved. Guided by these principles, we\nintroduce LC-R1, a post-training method based on Group Relative Policy\nOptimization (GRPO). LC-R1 employs a novel combination of a Length Reward for\noverall conciseness and a Compress Reward that is specifically designed to\nremove the invalid portion of the thinking process. Extensive experiments on\nmultiple reasoning benchmarks demonstrate that LC-R1 achieves a significant\nreduction in sequence length (~50%) with only a marginal (~2%) drop in\naccuracy, achieving a favorable trade-off point on the Pareto frontier that\nprioritizes high compression. Our analysis further validates the robustness of\nLC-R1 and provides valuable insights for developing more powerful yet\ncomputationally efficient LRMs. Our code is released at\nhttps://github.com/zxiangx/LC-R1.", "published": "2025-06-17 17:50:16", "link": "http://arxiv.org/abs/2506.14755v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs", "abstract": "We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model\noptimized via reinforcement learning (RL) to achieve efficient and robust\nreasoning capabilities. Built upon the publicly available Ling-lite model, a\n16.8 billion parameter model with 2.75 billion activated parameters, our\napproach matches the performance of state-of-the-art (SOTA) small-scale\nreasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench,\nGPQA-Diamond) while activating only one-third of the parameters required by\ncomparable models. To accomplish this, we introduce a joint training pipeline\nintegrating distillation with RL, revealing undocumented challenges in MoE RL\ntraining. First, we identify optimization instability during RL training, and\nwe propose Constrained Contextual Computation Policy Optimization(C3PO), a\nnovel approach that enhances training stability and improves computational\nthroughput via algorithm-system co-design methodology. Second, we empirically\ndemonstrate that selecting distillation checkpoints based on entropy loss for\nRL training, rather than validation metrics, yields superior\nperformance-efficiency trade-offs in subsequent RL training. Finally, we\ndevelop a two-stage training paradigm to harmonize multi-domain data\nintegration, addressing domain conflicts that arise in training with mixed\ndataset. We will release the model, dataset, and code.", "published": "2025-06-17 17:12:34", "link": "http://arxiv.org/abs/2506.14731v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Capacity Matters: a Proof-of-Concept for Transformer Memorization on Real-World Data", "abstract": "This paper studies how the model architecture and data configurations\ninfluence the empirical memorization capacity of generative transformers. The\nmodels are trained using synthetic text datasets derived from the Systematized\nNomenclature of Medicine (SNOMED) knowledge graph: triplets, representing\nstatic connections, and sequences, simulating complex relation patterns. The\nresults show that embedding size is the primary determinant of learning speed\nand capacity, while additional layers provide limited benefits and may hinder\nperformance on simpler datasets. Activation functions play a crucial role, and\nSoftmax demonstrates greater stability and capacity. Furthermore, increasing\nthe complexity of the data set seems to improve the final memorization. These\ninsights improve our understanding of transformer memory mechanisms and provide\na framework for optimizing model design with structured real-world data.", "published": "2025-06-17 16:42:54", "link": "http://arxiv.org/abs/2506.14704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers", "abstract": "One of the most profound challenges of modern machine learning is performing\nwell on the long-tail of rare and underrepresented features. Large\ngeneral-purpose models are trained for many tasks, but work best on\nhigh-frequency use cases. After training, it is hard to adapt a model to\nperform well on specific use cases underrepresented in the training corpus.\nRelying on prompt engineering or few-shot examples to maximize the output\nquality on a particular test case can be frustrating, as models can be highly\nsensitive to small changes, react in unpredicted ways or rely on a fixed system\nprompt for maintaining performance. In this work, we ask: \"Can we optimize our\ntraining protocols to both improve controllability and performance on\nunderrepresented use cases at inference time?\" We revisit the divide between\ntraining and inference techniques to improve long-tail performance while\nproviding users with a set of control levers the model is trained to be\nresponsive to. We create a detailed taxonomy of data characteristics and task\nprovenance to explicitly control generation attributes and implicitly condition\ngenerations at inference time. We fine-tune a base model to infer these markers\nautomatically, which makes them optional at inference time. This principled and\nflexible approach yields pronounced improvements in performance, especially on\nexamples from the long tail of the training distribution. While we observe an\naverage lift of 5.7% win rates in open-ended generation quality with our\nmarkers, we see over 9.1% gains in underrepresented domains. We also observe\nrelative lifts of up to 14.1% on underrepresented tasks like CodeRepair and\nabsolute improvements of 35.3% on length instruction following evaluations.", "published": "2025-06-17 16:40:42", "link": "http://arxiv.org/abs/2506.14702v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality", "abstract": "Supervised fine-tuning (SFT) is a critical step in aligning large language\nmodels (LLMs) with human instructions and values, yet many aspects of SFT\nremain poorly understood. We trained a wide range of base models on a variety\nof datasets including code generation, mathematical reasoning, and\ngeneral-domain tasks, resulting in 1,000+ SFT models under controlled\nconditions. We then identified the dataset properties that matter most and\nexamined the layer-wise modifications introduced by SFT. Our findings reveal\nthat some training-task synergies persist across all models while others vary\nsubstantially, emphasizing the importance of model-specific strategies.\nMoreover, we demonstrate that perplexity consistently predicts SFT\neffectiveness--often surpassing superficial similarity between trained data and\nbenchmark--and that mid-layer weight changes correlate most strongly with\nperformance gains. We will release these 1,000+ SFT models and benchmark\nresults to accelerate further research.", "published": "2025-06-17 16:13:15", "link": "http://arxiv.org/abs/2506.14681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors", "abstract": "Parameter-efficient fine-tuning (PEFT) methods, particularly Low-Rank\nAdaptation (LoRA), offer an efficient way to adapt large language models with\nreduced computational costs. However, their performance is limited by the small\nnumber of trainable parameters. Recent work combines LoRA with the\nMixture-of-Experts (MoE), i.e., LoRA-MoE, to enhance capacity, but two\nlimitations remain in hindering the full exploitation of its potential: 1) the\ninfluence of downstream tasks when assigning expert numbers, and 2) the uniform\nrank assignment across all LoRA experts, which restricts representational\ndiversity. To mitigate these gaps, we propose GuiLoMo, a fine-grained\nlayer-wise expert numbers and ranks allocation strategy with GuidedSelection\nVectors (GSVs). GSVs are learned via a prior bilevel optimization process to\ncapture both model- and task-specific needs, and are then used to allocate\noptimal expert numbers and ranks. Experiments on three backbone models across\ndiverse benchmarks show that GuiLoMo consistently achieves superior or\ncomparable performance to all baselines. Further analysis offers key insights\ninto how expert numbers and ranks vary across layers and tasks, highlighting\nthe benefits of adaptive expert configuration. Our code is available at\nhttps://github.com/Liar406/Gui-LoMo.git.", "published": "2025-06-17 15:41:33", "link": "http://arxiv.org/abs/2506.14646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments", "abstract": "The increasing sophistication of large language models (LLMs) has sparked\ngrowing concerns regarding their potential role in exacerbating ideological\npolarization through the automated generation of persuasive and biased content.\nThis study explores the extent to which fine-tuned LLMs can replicate and\namplify polarizing discourse within online environments. Using a curated\ndataset of politically charged discussions extracted from Reddit, we fine-tune\nan open-source LLM to produce context-aware and ideologically aligned\nresponses. The model's outputs are evaluated through linguistic analysis,\nsentiment scoring, and human annotation, with particular attention to\ncredibility and rhetorical alignment with the original discourse. The results\nindicate that, when trained on partisan data, LLMs are capable of producing\nhighly plausible and provocative comments, often indistinguishable from those\nwritten by humans. These findings raise significant ethical questions about the\nuse of AI in political discourse, disinformation, and manipulation campaigns.\nThe paper concludes with a discussion of the broader implications for AI\ngovernance, platform regulation, and the development of detection tools to\nmitigate adversarial fine-tuning risks.", "published": "2025-06-17 15:41:26", "link": "http://arxiv.org/abs/2506.14645v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot", "abstract": "In-Context Learning (ICL) is an essential emergent ability of Large Language\nModels (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars\nof ICL to enhance the reasoning capability, especially in mathematics tasks.\nHowever, given the continuous advancement of model capabilities, it remains\nunclear whether CoT exemplars still benefit recent, stronger models in such\ntasks. Through systematic experiments, we find that for recent strong models\nsuch as the Qwen2.5 series, adding traditional CoT exemplars does not improve\nreasoning performance compared to Zero-Shot CoT. Instead, their primary\nfunction is to align the output format with human expectations. We further\ninvestigate the effectiveness of enhanced CoT exemplars, constructed using\nanswers from advanced models such as \\texttt{Qwen2.5-Max} and\n\\texttt{DeepSeek-R1}. Experimental results indicate that these enhanced\nexemplars still fail to improve the model's reasoning performance. Further\nanalysis reveals that models tend to ignore the exemplars and focus primarily\non the instructions, leading to no observable gain in reasoning ability.\nOverall, our findings highlight the limitations of the current ICL+CoT\nframework in mathematical reasoning, calling for a re-examination of the ICL\nparadigm and the definition of exemplars.", "published": "2025-06-17 15:39:33", "link": "http://arxiv.org/abs/2506.14641v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "abstract": "The recent development and wider accessibility of LLMs have spurred\ndiscussions about how they can be used in survey research, including\nclassifying open-ended survey responses. Due to their linguistic capacities, it\nis possible that LLMs are an efficient alternative to time-consuming manual\ncoding and the pre-training of supervised machine learning models. As most\nexisting research on this topic has focused on English-language responses\nrelating to non-complex topics or on single LLMs, it is unclear whether its\nfindings generalize and how the quality of these classifications compares to\nestablished methods. In this study, we investigate to what extent different\nLLMs can be used to code open-ended survey responses in other contexts, using\nGerman data on reasons for survey participation as an example. We compare\nseveral state-of-the-art LLMs and several prompting approaches, and evaluate\nthe LLMs' performance by using human expert codings. Overall performance\ndiffers greatly between LLMs, and only a fine-tuned LLM achieves satisfactory\nlevels of predictive performance. Performance differences between prompting\napproaches are conditional on the LLM used. Finally, LLMs' unequal\nclassification performance across different categories of reasons for survey\nparticipation results in different categorical distributions when not using\nfine-tuning. We discuss the implications of these findings, both for\nmethodological research on coding open-ended responses and for their\nsubstantive analysis, and for practitioners processing or substantively\nanalyzing such data. Finally, we highlight the many trade-offs researchers need\nto consider when choosing automated methods for open-ended response\nclassification in the age of LLMs. In doing so, our study contributes to the\ngrowing body of research about the conditions under which LLMs can be\nefficiently, accurately, and reliably leveraged in survey research.", "published": "2025-06-17 15:28:53", "link": "http://arxiv.org/abs/2506.14634v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning", "abstract": "Mosquito-borne diseases pose a major global health risk, requiring early\ndetection and proactive control of breeding sites to prevent outbreaks. In this\npaper, we present VisText-Mosquito, a multimodal dataset that integrates visual\nand textual data to support automated detection, segmentation, and reasoning\nfor mosquito breeding site analysis. The dataset includes 1,828 annotated\nimages for object detection, 142 images for water surface segmentation, and\nnatural language reasoning texts linked to each image. The YOLOv9s model\nachieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object\ndetection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and\nmAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves\na final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and\nROUGE-L of 0.87. This dataset and model framework emphasize the theme\n\"Prevention is Better than Cure\", showcasing how AI-based detection can\nproactively address mosquito-borne disease risks. The dataset and\nimplementation code are publicly available at GitHub:\nhttps://github.com/adnanul-islam-jisun/VisText-Mosquito", "published": "2025-06-17 15:24:30", "link": "http://arxiv.org/abs/2506.14629v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models", "abstract": "Large Language Models (LLMs) have shown impressive moral reasoning abilities.\nYet they often diverge when confronted with complex, multi-factor moral\ndilemmas. To address these discrepancies, we propose a framework that\nsynthesizes multiple LLMs' moral judgments into a collectively formulated moral\njudgment, realigning models that deviate significantly from this consensus. Our\naggregation mechanism fuses continuous moral acceptability scores (beyond\nbinary labels) into a collective probability, weighting contributions by model\nreliability. For misaligned models, a targeted embedding-optimization procedure\nfine-tunes token embeddings for moral philosophical theories, minimizing JS\ndivergence to the consensus while preserving semantic integrity. Experiments on\na large-scale social moral dilemma dataset show our approach builds robust\nconsensus and improves individual model fidelity. These findings highlight the\nvalue of data-driven moral alignment across multiple models and its potential\nfor safer, more consistent AI systems.", "published": "2025-06-17 15:22:21", "link": "http://arxiv.org/abs/2506.14625v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When Does Meaning Backfire? Investigating the Role of AMRs in NLI", "abstract": "Natural Language Inference (NLI) relies heavily on adequately parsing the\nsemantic content of the premise and hypothesis. In this work, we investigate\nwhether adding semantic information in the form of an Abstract Meaning\nRepresentation (AMR) helps pretrained language models better generalize in NLI.\nOur experiments integrating AMR into NLI in both fine-tuning and prompting\nsettings show that the presence of AMR in fine-tuning hinders model\ngeneralization while prompting with AMR leads to slight gains in\n\\texttt{GPT-4o}. However, an ablation study reveals that the improvement comes\nfrom amplifying surface-level differences rather than aiding semantic\nreasoning. This amplification can mislead models to predict non-entailment even\nwhen the core meaning is preserved.", "published": "2025-06-17 15:12:54", "link": "http://arxiv.org/abs/2506.14613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees", "abstract": "The hardware ecosystem is rapidly evolving, with increasing interest in\ntranslating low-level programs across different instruction set architectures\n(ISAs) in a quick, flexible, and correct way to enhance the portability and\nlongevity of existing code. A particularly challenging class of this\ntranspilation problem is translating between complex- (CISC) and reduced-\n(RISC) hardware architectures, due to fundamental differences in instruction\ncomplexity, memory models, and execution paradigms. In this work, we introduce\nGG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the\ntranslation power of pre-trained large language models (LLMs) with the rigor of\nestablished software testing constructs. Our method generates candidate\ntranslations using an LLM from one ISA to another, and embeds such translations\nwithin a software-testing framework to build quantifiable confidence in the\ntranslation. We evaluate our GG approach over two diverse datasets, enforce\nhigh code coverage (>98%) across unit tests, and achieve functional/semantic\ncorrectness of 99% on HumanEval programs and 49% on BringupBench programs,\nrespectively. Further, we compare our approach to the state-of-the-art Rosetta\n2 framework on Apple Silicon, showcasing 1.73x faster runtime performance,\n1.47x better energy efficiency, and 2.41x better memory usage for our\ntranspiled code, demonstrating the effectiveness of GG for real-world\nCISC-to-RISC translation tasks. We will open-source our codes, data, models,\nand benchmarks to establish a common foundation for ISA-level code translation\nresearch.", "published": "2025-06-17 15:06:54", "link": "http://arxiv.org/abs/2506.14606v1", "categories": ["cs.CL", "cs.AR", "cs.LG", "cs.PL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Computational Studies in Influencer Marketing: A Systematic Literature Review", "abstract": "Influencer marketing has become a crucial feature of digital marketing\nstrategies. Despite its rapid growth and algorithmic relevance, the field of\ncomputational studies in influencer marketing remains fragmented, especially\nwith limited systematic reviews covering the computational methodologies\nemployed. This makes overarching scientific measurements in the influencer\neconomy very scarce, to the detriment of interested stakeholders outside of\nplatforms themselves, such as regulators, but also researchers from other\nfields. This paper aims to provide an overview of the state of the art of\ncomputational studies in influencer marketing by conducting a systematic\nliterature review (SLR) based on the PRISMA model. The paper analyses 69\nstudies to identify key research themes, methodologies, and future directions\nin this research field. The review identifies four major research themes:\nInfluencer identification and characterisation, Advertising strategies and\nengagement, Sponsored content analysis and discovery, and Fairness.\nMethodologically, the studies are categorised into machine learning-based\ntechniques (e.g., classification, clustering) and non-machine-learning-based\ntechniques (e.g., statistical analysis, network analysis). Key findings reveal\na strong focus on optimising commercial outcomes, with limited attention to\nregulatory compliance and ethical considerations. The review highlights the\nneed for more nuanced computational research that incorporates contextual\nfactors such as language, platform, and industry type, as well as improved\nmodel explainability and dataset reproducibility. The paper concludes by\nproposing a multidisciplinary research agenda that emphasises the need for\nfurther links to regulation and compliance technology, finer granularity in\nanalysis, and the development of standardised datasets.", "published": "2025-06-17 15:05:57", "link": "http://arxiv.org/abs/2506.14602v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "GenerationPrograms: Fine-grained Attribution with Executable Programs", "abstract": "Recent large language models (LLMs) achieve impressive performance in\nsource-conditioned text generation but often fail to correctly provide\nfine-grained attributions for their outputs, undermining verifiability and\ntrust. Moreover, existing attribution methods do not explain how and why models\nleverage the provided source documents to generate their final responses,\nlimiting interpretability. To overcome these challenges, we introduce a modular\ngeneration framework, GenerationPrograms, inspired by recent advancements in\nexecutable \"code agent\" architectures. Unlike conventional generation methods\nthat simultaneously generate outputs and attributions or rely on post-hoc\nattribution, GenerationPrograms decomposes the process into two distinct\nstages: first, creating an executable program plan composed of modular text\noperations (such as paraphrasing, compression, and fusion) explicitly tailored\nto the query, and second, executing these operations following the program's\nspecified instructions to produce the final response. Empirical evaluations\ndemonstrate that GenerationPrograms significantly improves attribution quality\nat both the document level and sentence level across two long-form\nquestion-answering tasks and a multi-document summarization task. We further\ndemonstrate that GenerationPrograms can effectively function as a post-hoc\nattribution method, outperforming traditional techniques in recovering accurate\nattributions. In addition, the interpretable programs generated by\nGenerationPrograms enable localized refinement through modular-level\nimprovements that further enhance overall attribution quality.", "published": "2025-06-17 14:37:09", "link": "http://arxiv.org/abs/2506.14580v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization", "abstract": "Recent advancements in reinforcement learning from human feedback have shown\nthat utilizing fine-grained token-level reward models can substantially enhance\nthe performance of Proximal Policy Optimization (PPO) in aligning large\nlanguage models. However, it is challenging to leverage such token-level reward\nas guidance for Direct Preference Optimization (DPO), since DPO is formulated\nas a sequence-level bandit problem. To address this challenge, this work\ndecomposes the sequence-level PPO into a sequence of token-level proximal\npolicy optimization problems and then frames the problem of token-level PPO\nwith token-level reward guidance, from which closed-form optimal token-level\npolicy and the corresponding token-level reward can be derived. Using the\nobtained reward and Bradley-Terry model, this work establishes a framework of\ncomputable loss functions with token-level reward guidance for DPO, and\nproposes a practical reward guidance based on the induced DPO reward. This\nformulation enables different tokens to exhibit varying degrees of deviation\nfrom reference policy based on their respective rewards. Experiment results\ndemonstrate that our method achieves substantial performance improvements over\nDPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on\nAlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at\nhttps://github.com/dvlab-research/TGDPO.", "published": "2025-06-17 14:30:06", "link": "http://arxiv.org/abs/2506.14574v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs", "abstract": "Weight decay is a standard regularization technique for training large\nlanguage models (LLMs). While it is common to assign a uniform decay rate to\nevery layer, this approach overlooks the structural diversity of LLMs and the\nvarying spectral properties across modules. In this paper, we introduce\nAlphaDecay, a simple yet effective method that adaptively assigns different\nweight decay strengths to each module of an LLM. Our approach is guided by\nHeavy-Tailed Self-Regularization (HT-SR) theory, which analyzes the empirical\nspectral density (ESD) of weight correlation matrices to quantify\n\"heavy-tailedness.\" Modules exhibiting more pronounced heavy-tailed ESDs,\nreflecting stronger feature learning, are assigned weaker decay, while modules\nwith lighter-tailed spectra receive stronger decay. Our method leverages\ntailored weight decay assignments to balance the module-wise differences in\nspectral properties, leading to improved performance. Extensive pre-training\ntasks with various model sizes from 60M to 1B demonstrate that AlphaDecay\nachieves better perplexity and generalization than conventional uniform decay\nand other adaptive decay baselines.", "published": "2025-06-17 14:21:10", "link": "http://arxiv.org/abs/2506.14562v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models", "abstract": "This paper introduces a novel neural network framework called M2BeamLLM for\nbeam prediction in millimeter-wave (mmWave) massive multi-input multi-output\n(mMIMO) communication systems. M2BeamLLM integrates multi-modal sensor data,\nincluding images, radar, LiDAR, and GPS, leveraging the powerful reasoning\ncapabilities of large language models (LLMs) such as GPT-2 for beam prediction.\nBy combining sensing data encoding, multimodal alignment and fusion, and\nsupervised fine-tuning (SFT), M2BeamLLM achieves significantly higher beam\nprediction accuracy and robustness, demonstrably outperforming traditional deep\nlearning (DL) models in both standard and few-shot scenarios. Furthermore, its\nprediction performance consistently improves with increased diversity in\nsensing modalities. Our study provides an efficient and intelligent beam\nprediction solution for vehicle-to-infrastructure (V2I) mmWave communication\nsystems.", "published": "2025-06-17 13:58:36", "link": "http://arxiv.org/abs/2506.14532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LingoLoop Attack: Trapping MLLMs via Linguistic Context and State Entrapment into Endless Loops", "abstract": "Multimodal Large Language Models (MLLMs) have shown great promise but require\nsubstantial computational resources during inference. Attackers can exploit\nthis by inducing excessive output, leading to resource exhaustion and service\ndegradation. Prior energy-latency attacks aim to increase generation time by\nbroadly shifting the output token distribution away from the EOS token, but\nthey neglect the influence of token-level Part-of-Speech (POS) characteristics\non EOS and sentence-level structural patterns on output counts, limiting their\nefficacy. To address this, we propose LingoLoop, an attack designed to induce\nMLLMs to generate excessively verbose and repetitive sequences. First, we find\nthat the POS tag of a token strongly affects the likelihood of generating an\nEOS token. Based on this insight, we propose a POS-Aware Delay Mechanism to\npostpone EOS token generation by adjusting attention weights guided by POS\ninformation. Second, we identify that constraining output diversity to induce\nrepetitive loops is effective for sustained generation. We introduce a\nGenerative Path Pruning Mechanism that limits the magnitude of hidden states,\nencouraging the model to produce persistent loops. Extensive experiments\ndemonstrate LingoLoop can increase generated tokens by up to 30 times and\nenergy consumption by a comparable factor on models like Qwen2.5-VL-3B,\nconsistently driving MLLMs towards their maximum generation limits. These\nfindings expose significant MLLMs' vulnerabilities, posing challenges for their\nreliable deployment. The code will be released publicly following the paper's\nacceptance.", "published": "2025-06-17 13:14:55", "link": "http://arxiv.org/abs/2506.14493v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data", "abstract": "Large language models (LLMs) can be trained or fine-tuned on data obtained\nwithout the owner's consent. Verifying whether a specific LLM was trained on\nparticular data instances or an entire dataset is extremely challenging.\nDataset watermarking addresses this by embedding identifiable modifications in\ntraining data to detect unauthorized use. However, existing methods often lack\nstealth, making them relatively easy to detect and remove. In light of these\nlimitations, we propose LexiMark, a novel watermarking technique designed for\ntext and documents, which embeds synonym substitutions for carefully selected\nhigh-entropy words. Our method aims to enhance an LLM's memorization\ncapabilities on the watermarked text without altering the semantic integrity of\nthe text. As a result, the watermark is difficult to detect, blending\nseamlessly into the text with no visible markers, and is resistant to removal\ndue to its subtle, contextually appropriate substitutions that evade automated\nand manual detection. We evaluated our method using baseline datasets from\nrecent studies and seven open-source models: LLaMA-1 7B, LLaMA-3 8B, Mistral\n7B, Pythia 6.9B, as well as three smaller variants from the Pythia family\n(160M, 410M, and 1B). Our evaluation spans multiple training settings,\nincluding continued pretraining and fine-tuning scenarios. The results\ndemonstrate significant improvements in AUROC scores compared to existing\nmethods, underscoring our method's effectiveness in reliably verifying whether\nunauthorized watermarked data was used in LLM training.", "published": "2025-06-17 12:41:53", "link": "http://arxiv.org/abs/2506.14474v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison", "abstract": "As evaluation designs of large language models may shape our trajectory\ntoward artificial general intelligence, comprehensive and forward-looking\nassessment is essential. Existing benchmarks primarily assess static knowledge,\nwhile intelligence also entails the ability to rapidly learn from experience.\nTo this end, we advocate for the evaluation of Test-time Learning, the capacity\nto improve performance in experience-based, reasoning-intensive tasks during\ntest time. In this work, we propose semantic games as effective testbeds for\nevaluating test-time learning, due to their resistance to saturation and\ninherent demand for strategic reasoning. We introduce an objective evaluation\nframework that compares model performance under both limited and cumulative\nexperience settings, and contains four forms of experience representation. To\nprovide a comparative baseline, we recruit eight human participants to complete\nthe same task. Results show that LLMs exhibit measurable test-time learning\ncapabilities; however, their improvements are less stable under cumulative\nexperience and progress more slowly than those observed in humans. These\nfindings underscore the potential of LLMs as general-purpose learning machines,\nwhile also revealing a substantial intellectual gap between models and humans,\nirrespective of how well LLMs perform on static benchmarks.", "published": "2025-06-17 12:13:56", "link": "http://arxiv.org/abs/2506.14448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs", "abstract": "Large Language Diffusion Models, or diffusion LLMs, have emerged as a\nsignificant focus in NLP research, with substantial effort directed toward\nunderstanding their scalability and downstream task performance. However, their\nlong-context capabilities remain unexplored, lacking systematic analysis or\nmethods for context extension. In this work, we present the first systematic\ninvestigation comparing the long-context performance of diffusion LLMs and\ntraditional auto-regressive LLMs. We first identify a unique characteristic of\ndiffusion LLMs, unlike auto-regressive LLMs, they maintain remarkably\n\\textbf{\\textit{stable perplexity}} during direct context extrapolation.\nFurthermore, where auto-regressive models fail outright during the\nNeedle-In-A-Haystack task with context exceeding their pretrained length, we\ndiscover diffusion LLMs exhibit a distinct \\textbf{\\textit{local perception}}\nphenomenon, enabling successful retrieval from recent context segments. We\nexplain both phenomena through the lens of Rotary Position Embedding (RoPE)\nscaling theory. Building on these observations, we propose LongLLaDA, a\ntraining-free method that integrates LLaDA with the NTK-based RoPE\nextrapolation. Our results validate that established extrapolation scaling laws\nremain effective for extending the context windows of diffusion LLMs.\nFurthermore, we identify long-context tasks where diffusion LLMs outperform\nauto-regressive LLMs and others where they fall short. Consequently, this study\nestablishes the first context extrapolation method for diffusion LLMs while\nproviding essential theoretical insights and empirical benchmarks critical for\nadvancing future research on long-context diffusion LLMs.", "published": "2025-06-17 11:45:37", "link": "http://arxiv.org/abs/2506.14429v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge", "abstract": "Retrieval systems are central to many NLP pipelines, but often rely on\nsurface-level cues such as keyword overlap and lexical semantic similarity. To\nevaluate retrieval beyond these shallow signals, recent benchmarks introduce\nreasoning-heavy queries; however, they primarily shift the burden to query-side\nprocessing techniques -- like prompting or multi-hop retrieval -- that can help\nresolve complexity. In contrast, we present ImpliRet, a benchmark that shifts\nthe reasoning challenge to document-side processing: The queries are simple,\nbut relevance depends on facts stated implicitly in documents through temporal\n(e.g., resolving \"two days ago\"), arithmetic, and world knowledge\nrelationships. We evaluate a range of sparse and dense retrievers, all of which\nstruggle in this setting: the best nDCG@10 is only 15.07%. We also test whether\nlong-context models can overcome this limitation. But even with a short context\nof only ten documents, including the positive document, GPT-4.1 scores only\n35.06%, showing that document-side reasoning remains a challenge. Our codes are\navailable at github.com/ZeinabTaghavi/IMPLIRET.Contribution.", "published": "2025-06-17 11:08:29", "link": "http://arxiv.org/abs/2506.14407v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding", "abstract": "Negation is a fundamental linguistic phenomenon that poses persistent\nchallenges for Large Language Models (LLMs), particularly in tasks requiring\ndeep semantic understanding. Existing benchmarks often treat negation as a side\ncase within broader tasks like natural language inference, resulting in a lack\nof benchmarks that exclusively target negation understanding. In this work, we\nintroduce \\textbf{Thunder-NUBench}, a novel benchmark explicitly designed to\nassess sentence-level negation understanding in LLMs. Thunder-NUBench goes\nbeyond surface-level cue detection by contrasting standard negation with\nstructurally diverse alternatives such as local negation, contradiction, and\nparaphrase. The benchmark consists of manually curated sentence-negation pairs\nand a multiple-choice dataset that enables in-depth evaluation of models'\nnegation understanding.", "published": "2025-06-17 10:51:39", "link": "http://arxiv.org/abs/2506.14397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection", "abstract": "The widespread adoption of chat interfaces based on Large Language Models\n(LLMs) raises concerns about promoting superficial learning and undermining the\ndevelopment of critical thinking skills. Instead of relying on LLMs purely for\nretrieving factual information, this work explores their potential to foster\ndeeper reasoning by generating critical questions that challenge unsupported or\nvague claims in debate interventions. This study is part of a shared task of\nthe 12th Workshop on Argument Mining, co-located with ACL 2025, focused on\nautomatic critical question generation. We propose a two-step framework\ninvolving two small-scale open source language models: a Questioner that\ngenerates multiple candidate questions and a Judge that selects the most\nrelevant ones. Our system ranked first in the shared task competition,\ndemonstrating the potential of the proposed LLM-based approach to encourage\ncritical engagement with argumentative texts.", "published": "2025-06-17 10:10:51", "link": "http://arxiv.org/abs/2506.14371v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits", "abstract": "Search engines play a crucial role as digital gatekeepers, shaping the\nvisibility of Web and social media content through algorithmic curation. This\nstudy investigates how search engines like Google selectively promotes or\nsuppresses certain hashtags and subreddits, impacting the information users\nencounter. By comparing search engine results with nonsampled data from Reddit\nand Twitter/X, we reveal systematic biases in content visibility. Google's\nalgorithms tend to suppress subreddits and hashtags related to sexually\nexplicit material, conspiracy theories, advertisements, and cryptocurrencies,\nwhile promoting content associated with higher engagement. These findings\nsuggest that Google's gatekeeping practices influence public discourse by\ncurating the social media narratives available to users.", "published": "2025-06-17 10:10:39", "link": "http://arxiv.org/abs/2506.14370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis", "abstract": "The emergence of Large Language Models (LLMs) has transformed information\naccess, with current LLMs also powering deep research systems that can generate\ncomprehensive report-style answers, through planned iterative search,\nretrieval, and reasoning. Still, current deep research systems lack the\ngeo-temporal capabilities that are essential for answering context-rich\nquestions involving geographic and/or temporal constraints, frequently\noccurring in domains like public health, environmental science, or\nsocio-economic analysis. This paper reports our vision towards next generation\nsystems, identifying important technical, infrastructural, and evaluative\nchallenges in integrating geo-temporal reasoning into deep research pipelines.\nWe argue for augmenting retrieval and synthesis processes with the ability to\nhandle geo-temporal constraints, supported by open and reproducible\ninfrastructures and rigorous evaluation protocols. Our vision outlines a path\ntowards more advanced and geo-temporally aware deep research systems, of\npotential impact to the future of AI-driven information access.", "published": "2025-06-17 09:38:45", "link": "http://arxiv.org/abs/2506.14345v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluation Should Not Ignore Variation: On the Impact of Reference Set Choice on Summarization Metrics", "abstract": "Human language production exhibits remarkable richness and variation,\nreflecting diverse communication styles and intents. However, this variation is\noften overlooked in summarization evaluation. While having multiple reference\nsummaries is known to improve correlation with human judgments, the impact of\nusing different reference sets on reference-based metrics has not been\nsystematically investigated. This work examines the sensitivity of widely used\nreference-based metrics in relation to the choice of reference sets, analyzing\nthree diverse multi-reference summarization datasets: SummEval, GUMSum, and\nDUC2004. We demonstrate that many popular metrics exhibit significant\ninstability. This instability is particularly concerning for n-gram-based\nmetrics like ROUGE, where model rankings vary depending on the reference sets,\nundermining the reliability of model comparisons. We also collect human\njudgments on LLM outputs for genre-diverse data and examine their correlation\nwith metrics to supplement existing findings beyond newswire summaries, finding\nweak-to-no correlation. Taken together, we recommend incorporating reference\nset variation into summarization evaluation to enhance consistency alongside\ncorrelation with human judgments, especially when evaluating LLMs.", "published": "2025-06-17 09:17:41", "link": "http://arxiv.org/abs/2506.14335v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\npropelled the development of Conversational Recommendation Agents (CRAs).\nHowever, these agents often generate short-sighted responses that fail to\nsustain user guidance and meet expectations. Although preference optimization\nhas proven effective in aligning LLMs with user expectations, it remains costly\nand performs poorly in multi-turn dialogue. To address this challenge, we\nintroduce a novel multi-turn preference optimization (MTPO) paradigm ECPO,\nwhich leverages Expectation Confirmation Theory to explicitly model the\nevolution of user satisfaction throughout multi-turn dialogues, uncovering the\nunderlying causes of dissatisfaction. These causes can be utilized to support\ntargeted optimization of unsatisfactory responses, thereby achieving turn-level\npreference optimization. ECPO ingeniously eliminates the significant sampling\noverhead of existing MTPO methods while ensuring the optimization process\ndrives meaningful improvements. To support ECPO, we introduce an LLM-based user\nsimulator, AILO, to simulate user feedback and perform expectation confirmation\nduring conversational recommendations. Experimental results show that ECPO\nsignificantly enhances CRA's interaction capabilities, delivering notable\nimprovements in both efficiency and effectiveness over existing MTPO methods.", "published": "2025-06-17 08:29:04", "link": "http://arxiv.org/abs/2506.14302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents", "abstract": "While research on dialogue response generation has primarily focused on\ngenerating coherent responses conditioning on textual context, the critical\nquestion of when to respond grounded on the temporal context remains\nunderexplored. To bridge this gap, we propose a novel task called timely\ndialogue response generation and introduce the TimelyChat benchmark, which\nevaluates the capabilities of language models to predict appropriate time\nintervals and generate time-conditioned responses. Additionally, we construct a\nlarge-scale training dataset by leveraging unlabeled event knowledge from a\ntemporal commonsense knowledge graph and employing a large language model (LLM)\nto synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent\ndesigned to proactively predict time intervals and generate timely responses\nthat align with those intervals. Experimental results show that Timer\noutperforms prompting-based LLMs and other fine-tuned baselines in both\nturn-level and dialogue-level evaluations. We publicly release our data, model,\nand code.", "published": "2025-06-17 07:56:32", "link": "http://arxiv.org/abs/2506.14285v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving LoRA with Variational Learning", "abstract": "Bayesian methods have recently been used to improve LoRA finetuning and,\nalthough they improve calibration, their effect on other metrics (such as\naccuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian\nmethods also increase computational overheads and require additional tricks for\nthem to work well. Here, we fix these issues by using a recently proposed\nvariational algorithm called IVON. We show that IVON is easy to implement and\nhas similar costs to AdamW, and yet it can also drastically improve many\nmetrics by using a simple posterior pruning technique. We present extensive\nresults on billion-scale LLMs (Llama and Qwen series) going way beyond the\nscale of existing applications of IVON. For example, we finetune a Llama-3.2-3B\nmodel on a set of commonsense reasoning tasks and improve accuracy over AdamW\nby 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian\nmethods like Laplace-LoRA and BLoB. Overall, our results show that variational\nlearning with IVON can effectively improve LoRA finetuning.", "published": "2025-06-17 07:49:43", "link": "http://arxiv.org/abs/2506.14280v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Re-Initialization Token Learning for Tool-Augmented Large Language Models", "abstract": "Large language models have demonstrated exceptional performance, yet struggle\nwith complex tasks such as numerical reasoning, plan generation. Integrating\nexternal tools, such as calculators and databases, into large language models\n(LLMs) is crucial for enhancing problem-solving capabilities. Current methods\nassign a unique token to each tool, enabling LLMs to call tools through token\nprediction-similar to word generation. However, this approach fails to account\nfor the relationship between tool and word tokens, limiting adaptability within\npre-trained LLMs. To address this issue, we propose a novel token learning\nmethod that aligns tool tokens with the existing word embedding space from the\nperspective of initialization, thereby enhancing model performance. We begin by\nconstructing prior token embeddings for each tool based on the tool's name or\ndescription, which are used to initialize and regularize the learnable tool\ntoken embeddings. This ensures the learned embeddings are well-aligned with the\nword token space, improving tool call accuracy. We evaluate the method on tasks\nsuch as numerical reasoning, knowledge-based question answering, and embodied\nplan generation using GSM8K-XL, FuncQA, KAMEL, and VirtualHome datasets. The\nresults demonstrate clear improvements over recent baselines, including CoT,\nREACT, ICL, and ToolkenGPT, indicating that our approach effectively augments\nLLMs with tools through relevant tokens across diverse domains.", "published": "2025-06-17 07:11:00", "link": "http://arxiv.org/abs/2506.14248v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npromising paradigm for advancing the reasoning capabilities of Large Language\nModels (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned\nmodels often underperform their base models on the $Pass@K$ metric for\nsolution-finding, leading to the hypothesis that RLVR merely re-weights\nexisting reasoning paths at the cost of reasoning diversity. In this work, we\nresolve this contradiction by identifying the source of the problem: the\n$Pass@K$ metric itself is a flawed measure of reasoning, as it credits correct\nfinal answers that probably arise from inaccurate or incomplete chains of\nthought (CoTs). To address this, we introduce a more precise evaluation metric,\n$CoT$-$Pass@K$, which mandates that both the reasoning path and the final\nanswer be correct. We provide a new theoretical foundation that formalizes how\nRLVR, unlike traditional RL, is uniquely structured to incentivize logical\nintegrity. Our empirical results are supportive: using $CoT$-$Pass@K$, we\nobserve that RLVR can incentivize the generalization of correct reasoning for\nall values of $K$. Furthermore, by analyzing the training dynamics, we find\nthat this enhanced reasoning capability emerges early in the training process\nand smoothly generalizes. Our work provides a clear perspective on the role of\nRLVR, offers a more reliable method for its evaluation, and confirms its\npotential to genuinely advance machine reasoning.", "published": "2025-06-17 07:06:56", "link": "http://arxiv.org/abs/2506.14245v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs", "abstract": "Temporal knowledge graph reasoning aims to predict future events with\nknowledge of existing facts and plays a key role in various downstream tasks.\nPrevious methods focused on either graph structure learning or semantic\nreasoning, failing to integrate dual reasoning perspectives to handle different\nprediction scenarios. Moreover, they lack the capability to capture the\ninherent differences between historical and non-historical events, which limits\ntheir generalization across different temporal contexts. To this end, we\npropose a Multi-Expert Structural-Semantic Hybrid (MESH) framework that employs\nthree kinds of expert modules to integrate both structural and semantic\ninformation, guiding the reasoning process for different events. Extensive\nexperiments on three datasets demonstrate the effectiveness of our approach.", "published": "2025-06-17 06:49:13", "link": "http://arxiv.org/abs/2506.14235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team", "abstract": "Despite impressive progress on complex reasoning, current large language\nmodels (LLMs) typically operate in isolation - treating each problem as an\nindependent attempt, without accumulating or integrating experiential\nknowledge. In contrast, expert problem solvers - such as Olympiad or\nprogramming contest teams - leverage a rich tapestry of experiences: absorbing\nmentorship from coaches, developing intuition from past problems, leveraging\nknowledge of tool usage and library functionality, adapting strategies based on\nthe expertise and experiences of peers, continuously refining their reasoning\nthrough trial and error, and learning from other related problems even during\ncompetition. We introduce Xolver, a training-free multi-agent reasoning\nframework that equips a black-box LLM with a persistent, evolving memory of\nholistic experience. Xolver integrates diverse experience modalities, including\nexternal and self-retrieval, tool use, collaborative interactions, agent-driven\nevaluation, and iterative refinement. By learning from relevant strategies,\ncode fragments, and abstract reasoning patterns at inference time, Xolver\navoids generating solutions from scratch - marking a transition from isolated\ninference toward experience-aware language agents. Built on both open-weight\nand proprietary models, Xolver consistently outperforms specialized reasoning\nagents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses\nadvanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high.\nWith o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24\n(94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) -\nhighlighting holistic experience learning as a key step toward generalist\nagents capable of expert-level reasoning. Code and data are available at\nhttps://kagnlp.github.io/xolver.github.io/.", "published": "2025-06-17 06:47:19", "link": "http://arxiv.org/abs/2506.14234v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription", "abstract": "Music transcription plays a pivotal role in Music Information Retrieval\n(MIR), particularly for stringed instruments like the guitar, where symbolic\nmusic notations such as MIDI lack crucial playability information. This\ncontribution introduces the Fretting-Transformer, an encoderdecoder model that\nutilizes a T5 transformer architecture to automate the transcription of MIDI\nsequences into guitar tablature. By framing the task as a symbolic translation\nproblem, the model addresses key challenges, including string-fret ambiguity\nand physical playability. The proposed system leverages diverse datasets,\nincluding DadaGP, GuitarToday, and Leduc, with novel data pre-processing and\ntokenization strategies. We have developed metrics for tablature accuracy and\nplayability to quantitatively evaluate the performance. The experimental\nresults demonstrate that the Fretting-Transformer surpasses baseline methods\nlike A* and commercial applications like Guitar Pro. The integration of\ncontext-sensitive processing and tuning/capo conditioning further enhances the\nmodel's performance, laying a robust foundation for future developments in\nautomated guitar transcription.", "published": "2025-06-17 06:25:35", "link": "http://arxiv.org/abs/2506.14223v1", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Chaining Event Spans for Temporal Relation Grounding", "abstract": "Accurately understanding temporal relations between events is a critical\nbuilding block of diverse tasks, such as temporal reading comprehension (TRC)\nand relation extraction (TRE). For example in TRC, we need to understand the\ntemporal semantic differences between the following two questions that are\nlexically near-identical: \"What finished right before the decision?\" or \"What\nfinished right after the decision?\". To discern the two questions, existing\nsolutions have relied on answer overlaps as a proxy label to contrast similar\nand dissimilar questions. However, we claim that answer overlap can lead to\nunreliable results, due to spurious overlaps of two dissimilar questions with\ncoincidentally identical answers. To address the issue, we propose a novel\napproach that elicits proper reasoning behaviors through a module for\npredicting time spans of events. We introduce the Timeline Reasoning Network\n(TRN) operating in a two-step inductive reasoning process: In the first step\nmodel initially answers each question with semantic and syntactic information.\nThe next step chains multiple questions on the same event to predict a\ntimeline, which is then used to ground the answers. Results on the TORQUE and\nTB-dense, TRC and TRE tasks respectively, demonstrate that TRN outperforms\nprevious methods by effectively resolving the spurious overlaps using the\npredicted timeline.", "published": "2025-06-17 06:06:01", "link": "http://arxiv.org/abs/2506.14213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explainable Detection of Implicit Influential Patterns in Conversations via Data Augmentation", "abstract": "In the era of digitalization, as individuals increasingly rely on digital\nplatforms for communication and news consumption, various actors employ\nlinguistic strategies to influence public perception. While models have become\nproficient at detecting explicit patterns, which typically appear in texts as\nsingle remarks referred to as utterances, such as social media posts, malicious\nactors have shifted toward utilizing implicit influential verbal patterns\nembedded within conversations. These verbal patterns aim to mentally penetrate\nthe victim's mind in order to influence them, enabling the actor to obtain the\ndesired information through implicit means. This paper presents an improved\napproach for detecting such implicit influential patterns. Furthermore, the\nproposed model is capable of identifying the specific locations of these\ninfluential elements within a conversation. To achieve this, the existing\ndataset was augmented using the reasoning capabilities of state-of-the-art\nlanguage models. Our designed framework resulted in a 6% improvement in the\ndetection of implicit influential patterns in conversations. Moreover, this\napproach improved the multi-label classification tasks related to both the\ntechniques used for influence and the vulnerability of victims by 33% and 43%,\nrespectively.", "published": "2025-06-17 06:00:07", "link": "http://arxiv.org/abs/2506.14211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CausalDiffTab: Mixed-Type Causal-Aware Diffusion for Tabular Data Generation", "abstract": "Training data has been proven to be one of the most critical components in\ntraining generative AI. However, obtaining high-quality data remains\nchallenging, with data privacy issues presenting a significant hurdle. To\naddress the need for high-quality data. Synthesize data has emerged as a\nmainstream solution, demonstrating impressive performance in areas such as\nimages, audio, and video. Generating mixed-type data, especially high-quality\ntabular data, still faces significant challenges. These primarily include its\ninherent heterogeneous data types, complex inter-variable relationships, and\nintricate column-wise distributions. In this paper, we introduce CausalDiffTab,\na diffusion model-based generative model specifically designed to handle mixed\ntabular data containing both numerical and categorical features, while being\nmore flexible in capturing complex interactions among variables. We further\npropose a hybrid adaptive causal regularization method based on the principle\nof Hierarchical Prior Fusion. This approach adaptively controls the weight of\ncausal regularization, enhancing the model's performance without compromising\nits generative capabilities. Comprehensive experiments conducted on seven\ndatasets demonstrate that CausalDiffTab outperforms baseline methods across all\nmetrics. Our code is publicly available at:\nhttps://github.com/Godz-z/CausalDiffTab.", "published": "2025-06-17 05:48:44", "link": "http://arxiv.org/abs/2506.14206v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents", "abstract": "We introduce AgentSynth, a scalable and cost-efficient pipeline for\nautomatically synthesizing high-quality tasks and trajectory datasets for\ngeneralist computer-use agents. Leveraging information asymmetry, AgentSynth\nconstructs subtasks that are simple during generation but significantly more\nchallenging when composed into long-horizon tasks, enabling the creation of\nover 6,000 diverse and realistic tasks. Our pipeline begins with an LLM-based\ntask proposer guided by a persona, followed by an execution agent that\ncompletes the task and logs the trajectory. This process is repeated\niteratively to form a sequence of subtasks, which are then summarized by a\nseparate agent into a composite task of controllable difficulty. A key strength\nof AgentSynth is its ability to precisely modulate task complexity by varying\nthe number of subtasks. Empirical evaluations show that state-of-the-art LLM\nagents suffer a steep performance drop, from 18% success at difficulty level 1\nto just 4% at level 6, highlighting the benchmark's difficulty and\ndiscriminative power. Moreover, our pipeline achieves a low average cost of\n\\$0.60 per trajectory, orders of magnitude cheaper than human annotations. Our\ncode and data are publicly available at\nhttps://github.com/sunblaze-ucb/AgentSynth", "published": "2025-06-17 05:46:52", "link": "http://arxiv.org/abs/2506.14205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios", "abstract": "We extend the frameworks of Serialized Output Training (SOT) to address\npractical needs of both streaming and offline automatic speech recognition\n(ASR) applications. Our approach focuses on balancing latency and accuracy,\ncatering to real-time captioning and summarization requirements. We propose\nseveral key improvements: (1) Leveraging Continuous Speech Separation (CSS)\nsingle-channel front-end with end-to-end (E2E) systems for highly overlapping\nscenarios, challenging the conventional wisdom of E2E versus cascaded setups.\nThe CSS framework improves the accuracy of the ASR system by separating\noverlapped speech from multiple speakers. (2) Implementing dual models --\nConformer Transducer for streaming and Sequence-to-Sequence for offline -- or\nalternatively, a two-pass model based on cascaded encoders. (3) Exploring\nsegment-based SOT (segSOT) which is better suited for offline scenarios while\nalso enhancing readability of multi-talker transcriptions.", "published": "2025-06-17 05:46:38", "link": "http://arxiv.org/abs/2506.14204v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation", "abstract": "In this study, we investigate the potential of language models (LMs) in\naiding patients experiencing anomia, a difficulty identifying the names of\nitems. Identifying the intended target item from patient's circumlocution\ninvolves the two challenges of term failure and error: (1) The terms relevant\nto identifying the item remain unseen. (2) What makes the challenge unique is\ninherent perturbed terms by semantic paraphasia, which are not exactly related\nto the target item, hindering the identification process. To address each, we\npropose robustifying the model from semantically paraphasic errors and\nenhancing the model with unseen terms with gradient-based selective\naugmentation. Specifically, the gradient value controls augmented data quality\namid semantic errors, while the gradient variance guides the inclusion of\nunseen but relevant terms. Due to limited domain-specific datasets, we evaluate\nthe model on the Tip-of-the-Tongue dataset as an intermediary task and then\napply our findings to real patient data from AphasiaBank. Our results\ndemonstrate strong performance against baselines, aiding anomia patients by\naddressing the outlined challenges.", "published": "2025-06-17 05:44:55", "link": "http://arxiv.org/abs/2506.14203v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations", "abstract": "Language models today are widely used in education, yet their ability to\ntailor responses for learners with varied informational needs and knowledge\nbackgrounds remains under-explored. To this end, we introduce ELI-Why, a\nbenchmark of 13.4K \"Why\" questions to evaluate the pedagogical capabilities of\nlanguage models. We then conduct two extensive human studies to assess the\nutility of language model-generated explanatory answers (explanations) on our\nbenchmark, tailored to three distinct educational grades: elementary,\nhigh-school and graduate school. In our first study, human raters assume the\nrole of an \"educator\" to assess model explanations' fit to different\neducational grades. We find that GPT-4-generated explanations match their\nintended educational background only 50% of the time, compared to 79% for lay\nhuman-curated explanations. In our second study, human raters assume the role\nof a learner to assess if an explanation fits their own informational needs.\nAcross all educational backgrounds, users deemed GPT-4-generated explanations\n20% less suited on average to their informational needs, when compared to\nexplanations curated by lay people. Additionally, automated evaluation metrics\nreveal that explanations generated across different language model families for\ndifferent informational needs remain indistinguishable in their grade-level,\nlimiting their pedagogical effectiveness.", "published": "2025-06-17 05:36:39", "link": "http://arxiv.org/abs/2506.14200v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment", "abstract": "Literary translation requires preserving cultural nuances and stylistic\nelements, which traditional metrics like BLEU and METEOR fail to assess due to\ntheir focus on lexical overlap. This oversight neglects the narrative\nconsistency and stylistic fidelity that are crucial for literary works. To\naddress this, we propose MAS-LitEval, a multi-agent system using Large Language\nModels (LLMs) to evaluate translations based on terminology, narrative, and\nstyle. We tested MAS-LitEval on translations of The Little Prince and A\nConnecticut Yankee in King Arthur's Court, generated by various LLMs, and\ncompared it to traditional metrics. \\textbf{MAS-LitEval} outperformed these\nmetrics, with top models scoring up to 0.890 in capturing literary nuances.\nThis work introduces a scalable, nuanced framework for Translation Quality\nAssessment (TQA), offering a practical tool for translators and researchers.", "published": "2025-06-17 05:33:40", "link": "http://arxiv.org/abs/2506.14199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR", "abstract": "Developing code-switched ASR systems is challenging due to language ambiguity\nand limited exposure to multilingual, code-switched data, while collecting such\nspeech is costly. Prior work generates synthetic audio from text, but these\nmethods are computationally intensive and hard to scale. We introduce\nAsyncSwitch, a novel asynchronous adaptation framework that leverages\nlarge-scale, text-rich web data to pre-expose ASR models to diverse\ncode-switched domains before fine-tuning on paired speech-text corpora. Our\nthree-stage process (1) trains decoder self-attention and feedforward layers on\ncode-switched text, (2) aligns decoder and encoder via cross-attention using\nlimited speech-text data, and (3) fully fine-tunes the entire model.\nExperiments with Whisper on Malay-English code-switching demonstrate a 9.02%\nrelative WER reduction, while improving monolingual performance in Singlish,\nMalay, and other English variants.", "published": "2025-06-17 05:05:09", "link": "http://arxiv.org/abs/2506.14190v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages", "abstract": "Code-switching (CS), common in multilingual settings, presents challenges for\nASR due to scarce and costly transcribed data caused by linguistic complexity.\nThis study investigates building CS-ASR using synthetic CS data. We propose a\nphrase-level mixing method to generate synthetic CS data that mimics natural\npatterns. Utilizing monolingual augmented with synthetic phrase-mixed CS data\nto fine-tune large pretrained ASR models (Whisper, MMS, SeamlessM4T). This\npaper focuses on three under-resourced Southeast Asian language pairs:\nMalay-English (BM-EN), Mandarin-Malay (ZH-BM), and Tamil-English (TA-EN),\nestablishing a new comprehensive benchmark for CS-ASR to evaluate the\nperformance of leading ASR models. Experimental results show that the proposed\ntraining strategy enhances ASR performance on monolingual and CS tests, with\nBM-EN showing highest gains, then TA-EN and ZH-BM. This finding offers a\ncost-effective approach for CS-ASR development, benefiting research and\nindustry.", "published": "2025-06-17 04:37:16", "link": "http://arxiv.org/abs/2506.14177v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "GRAM: A Generative Foundation Reward Model for Reward Generalization", "abstract": "In aligning large language models (LLMs), reward models have played an\nimportant role, but are standardly trained as discriminative models and rely\nonly on labeled human preference data. In this paper, we explore methods that\ntrain reward models using both unlabeled and labeled data. Building on the\ngenerative models in LLMs, we develop a generative reward model that is first\ntrained via large-scale unsupervised learning and then fine-tuned via\nsupervised learning. We also show that by using label smoothing, we are in fact\noptimizing a regularized pairwise ranking loss. This result, in turn, provides\na new view of training reward models, which links generative models and\ndiscriminative models under the same class of training objectives. The outcome\nof these techniques is a foundation reward model, which can be applied to a\nwide range of tasks with little or no further fine-tuning effort. Extensive\nexperiments show that this model generalizes well across several tasks,\nincluding response ranking, reinforcement learning from human feedback, and\ntask adaptation with fine-tuning, achieving significant performance\nimprovements over several strong baseline models.", "published": "2025-06-17 04:34:27", "link": "http://arxiv.org/abs/2506.14175v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind", "abstract": "Theory of Mind (ToM) in Large Language Models (LLMs) refers to their capacity\nfor reasoning about mental states, yet failures in this capacity often manifest\nas systematic implicit bias. Evaluating this bias is challenging, as\nconventional direct-query methods are susceptible to social desirability\neffects and fail to capture its subtle, multi-dimensional nature. To this end,\nwe propose an evaluation framework that leverages the Stereotype Content Model\n(SCM) to reconceptualize bias as a multi-dimensional failure in ToM across\nCompetence, Sociability, and Morality. The framework introduces two indirect\ntasks: the Word Association Bias Test (WABT) to assess implicit lexical\nassociations and the Affective Attribution Test (AAT) to measure covert\naffective leanings, both designed to probe latent stereotypes without\ntriggering model avoidance. Extensive experiments on 8 State-of-the-Art LLMs\ndemonstrate our framework's capacity to reveal complex bias structures,\nincluding pervasive sociability bias, multi-dimensional divergence, and\nasymmetric stereotype amplification, thereby providing a more robust\nmethodology for identifying the structural nature of implicit bias.", "published": "2025-06-17 03:50:57", "link": "http://arxiv.org/abs/2506.14161v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models", "abstract": "Large language models (LLMs) exhibit remarkable reasoning capabilities across\ndiverse downstream tasks. However, their autoregressive nature leads to\nsubstantial inference latency, posing challenges for real-time applications.\nSpeculative sampling mitigates this issue by introducing a drafting phase\nfollowed by a parallel validation phase, enabling faster token generation and\nverification. Existing approaches, however, overlook the inherent coherence in\ntext generation, limiting their efficiency. To address this gap, we propose a\nSpeculative Sampling with Syntactic and Semantic Coherence (S$^4$C) framework,\nwhich extends speculative sampling by leveraging multi-head drafting for rapid\ntoken generation and a continuous verification tree for efficient candidate\nvalidation and feature reuse. Experimental results demonstrate that S$^4$C\nsurpasses baseline methods across mainstream tasks, offering enhanced\nefficiency, parallelism, and the ability to generate more valid tokens with\nfewer computational resources. On Spec-bench benchmarks, S$^4$C achieves an\nacceleration ratio of 2.26x-2.60x, outperforming state-of-the-art methods.", "published": "2025-06-17 03:38:19", "link": "http://arxiv.org/abs/2506.14158v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization", "abstract": "Recent research has attempted to associate preference optimization (PO)\nperformance with the underlying preference datasets. In this work, our\nobservation is that the differences between the preferred response $y^+$ and\ndispreferred response $y^-$ influence what LLMs can learn, which may not match\nthe desirable differences to learn. Therefore, we use distance and reward\nmargin to quantify these differences, and combine them to get Distance\nCalibrated Reward Margin (DCRM), a metric that measures the quality of a\nresponse pair for PO. Intuitively, DCRM encourages minimal noisy differences\nand maximal desired differences. With this, we study 3 types of commonly used\npreference datasets, classified along two axes: the source of the responses and\nthe preference labeling function. We establish a general correlation between\nhigher DCRM of the training set and better learning outcome. Inspired by this,\nwe propose a best-of-$N^2$ pairing method that selects response pairs with the\nhighest DCRM. Empirically, in various settings, our method produces training\ndatasets that can further improve models' performance on AlpacaEval, MT-Bench,\nand Arena-Hard over the existing training sets.", "published": "2025-06-17 03:37:41", "link": "http://arxiv.org/abs/2506.14157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models", "abstract": "Recent advancements in speech synthesis technologies have led to increasingly\nadvanced spoofing attacks, posing significant challenges for automatic speaker\nverification systems. While systems based on self-supervised learning (SSL)\nmodels, particularly the XLSR-Conformer model, have demonstrated remarkable\nperformance in synthetic speech detection, there remains room for architectural\nimprovements. In this paper, we propose a novel approach that replaces the\ntraditional Multi-Layer Perceptron in the XLSR-Conformer model with a\nKolmogorov-Arnold Network (KAN), a novel architecture based on the\nKolmogorov-Arnold representation theorem. Our results on ASVspoof2021\ndemonstrate that integrating KAN into the SSL-based models can improve the\nperformance by 60.55% relatively on LA and DF sets, further achieving 0.70% EER\non the 21LA set. These findings suggest that incorporating KAN into SSL-based\nmodels is a promising direction for advances in synthetic speech detection.", "published": "2025-06-17 03:30:58", "link": "http://arxiv.org/abs/2506.14153v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment", "abstract": "This paper presents a novel non-invasive object classification approach using\nacoustic scattering, demonstrated through a case study on hair assessment. When\nan incident wave interacts with an object, it generates a scattered acoustic\nfield encoding structural and material properties. By emitting acoustic stimuli\nand capturing the scattered signals from head-with-hair-sample objects, we\nclassify hair type and moisture using AI-driven, deep-learning-based sound\nclassification. We benchmark comprehensive methods, including (i) fully\nsupervised deep learning, (ii) embedding-based classification, (iii) supervised\nfoundation model fine-tuning, and (iv) self-supervised model fine-tuning. Our\nbest strategy achieves nearly 90% classification accuracy by fine-tuning all\nparameters of a self-supervised model. These results highlight acoustic\nscattering as a privacy-preserving, non-contact alternative to visual\nclassification, opening huge potential for applications in various industries.", "published": "2025-06-17 03:25:38", "link": "http://arxiv.org/abs/2506.14148v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RadFabric: Agentic AI System with Reasoning Capability for Radiology", "abstract": "Chest X ray (CXR) imaging remains a critical diagnostic tool for thoracic\nconditions, but current automated systems face limitations in pathology\ncoverage, diagnostic accuracy, and integration of visual and textual reasoning.\nTo address these gaps, we propose RadFabric, a multi agent, multimodal\nreasoning framework that unifies visual and textual analysis for comprehensive\nCXR interpretation. RadFabric is built on the Model Context Protocol (MCP),\nenabling modularity, interoperability, and scalability for seamless integration\nof new diagnostic agents. The system employs specialized CXR agents for\npathology detection, an Anatomical Interpretation Agent to map visual findings\nto precise anatomical structures, and a Reasoning Agent powered by large\nmultimodal reasoning models to synthesize visual, anatomical, and clinical data\ninto transparent and evidence based diagnoses. RadFabric achieves significant\nperformance improvements, with near-perfect detection of challenging\npathologies like fractures (1.000 accuracy) and superior overall diagnostic\naccuracy (0.799) compared to traditional systems (0.229 to 0.527). By\nintegrating cross modal feature alignment and preference-driven reasoning,\nRadFabric advances AI-driven radiology toward transparent, anatomically\nprecise, and clinically actionable CXR analysis.", "published": "2025-06-17 03:10:33", "link": "http://arxiv.org/abs/2506.14142v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Sampling from Your Language Model One Byte at a Time", "abstract": "Tokenization is used almost universally by modern language models, enabling\nefficient text representation using multi-byte or multi-character tokens.\nHowever, prior work has shown that tokenization can introduce distortion into\nthe model's generations. For example, users are often advised not to end their\nprompts with a space because it prevents the model from including the space as\npart of the next token. This Prompt Boundary Problem (PBP) also arises in\nlanguages such as Chinese and in code generation, where tokens often do not\nline up with syntactic boundaries. Additionally mismatching tokenizers often\nhinder model composition and interoperability. For example, it is not possible\nto directly ensemble models with different tokenizers due to their mismatching\nvocabularies. To address these issues, we present an inference-time method to\nconvert any autoregressive LM with a BPE tokenizer into a character-level or\nbyte-level LM, without changing its generative distribution at the text level.\nOur method efficient solves the PBP and is also able to unify the vocabularies\nof language models with different tokenizers, allowing one to ensemble LMs with\ndifferent tokenizers at inference time as well as transfer the post-training\nfrom one model to another using proxy-tuning. We demonstrate in experiments\nthat the ensemble and proxy-tuned models outperform their constituents on\ndownstream evals.", "published": "2025-06-17 02:37:04", "link": "http://arxiv.org/abs/2506.14123v1", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Essential-Web v1.0: 24T tokens of organized web data", "abstract": "Data plays the most prominent role in how language models acquire skills and\nknowledge. The lack of massive, well-organized pre-training datasets results in\ncostly and inaccessible data pipelines. We present Essential-Web v1.0, a\n24-trillion-token dataset in which every document is annotated with a\ntwelve-category taxonomy covering topic, format, content complexity, and\nquality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned\n0.5b-parameter model that achieves an annotator agreement within 3% of\nQwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain\ncompetitive web-curated datasets in math (-8.0% relative to SOTA), web code\n(+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on\nHuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0", "published": "2025-06-17 02:03:36", "link": "http://arxiv.org/abs/2506.14111v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints", "abstract": "Yangliuqing woodblock prints, a cornerstone of China's intangible cultural\nheritage, are celebrated for their intricate designs and vibrant colors.\nHowever, preserving these traditional art forms while fostering innovation\npresents significant challenges. This study explores the DeepSeek + MidJourney\napproach to generating creative, themed Yangliuqing woodblock prints focused on\nthe fight against COVID-19 and depicting joyous winners. Using Fr\\'echet\nInception Distance (FID) scores for evaluation, the method that combined\nDeepSeek-generated thematic prompts, MidJourney-generated thematic images,\noriginal Yangliuqing prints, and DeepSeek-generated key prompts in\nMidJourney-generated outputs achieved the lowest mean FID score (150.2) with\nminimal variability ({\\sigma} = 4.9). Additionally, feedback from 62\nparticipants, collected via questionnaires, confirmed that this hybrid approach\nproduced the most representative results. Moreover, the questionnaire data\nrevealed that participants demonstrated the highest willingness to promote\ntraditional culture and the strongest interest in consuming the AI-generated\nimages produced through this method. These findings underscore the\neffectiveness of an innovative approach that seamlessly blends traditional\nartistic elements with modern AI-driven creativity, ensuring both cultural\npreservation and contemporary relevance.", "published": "2025-06-17 01:47:17", "link": "http://arxiv.org/abs/2506.14104v1", "categories": ["cs.GR", "cs.CL", "cs.CY"], "primary_category": "cs.GR"}
{"title": "Abstract Meaning Representation for Hospital Discharge Summarization", "abstract": "The Achilles heel of Large Language Models (LLMs) is hallucination, which has\ndrastic consequences for the clinical domain. This is particularly important\nwith regards to automatically generating discharge summaries (a lengthy medical\ndocument that summarizes a hospital in-patient visit). Automatically generating\nthese summaries would free physicians to care for patients and reduce\ndocumentation burden. The goal of this work is to discover new methods that\ncombine language-based graphs and deep learning models to address provenance of\ncontent and trustworthiness in automatic summarization. Our method shows\nimpressive reliability results on the publicly available Medical Information\nMart for Intensive III (MIMIC-III) corpus and clinical notes written by\nphysicians at Anonymous Hospital. rovide our method, generated discharge ary\noutput examples, source code and trained models.", "published": "2025-06-17 01:33:01", "link": "http://arxiv.org/abs/2506.14101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking", "abstract": "Large Language Models (LLMs) have demonstrated significant strides across\nvarious information retrieval tasks, particularly as rerankers, owing to their\nstrong generalization and knowledge-transfer capabilities acquired from\nextensive pretraining. In parallel, the rise of LLM-based chat interfaces has\nraised user expectations, encouraging users to pose more complex queries that\nnecessitate retrieval by ``reasoning'' over documents rather than through\nsimple keyword matching or semantic similarity. While some recent efforts have\nexploited reasoning abilities of LLMs for reranking such queries, considerable\npotential for improvement remains. In that regards, we introduce InsertRank, an\nLLM-based reranker that leverages lexical signals like BM25 scores during\nreranking to further improve retrieval performance. InsertRank demonstrates\nimproved retrieval effectiveness on -- BRIGHT, a reasoning benchmark spanning\n12 diverse domains, and R2MED, a specialized medical reasoning retrieval\nbenchmark spanning 8 different tasks. We conduct an exhaustive evaluation and\nseveral ablation studies and demonstrate that InsertRank consistently improves\nretrieval effectiveness across multiple families of LLMs, including GPT,\nGemini, and Deepseek models. %In addition, we also conduct ablation studies on\nnormalization by varying the scale of the BM25 scores, and positional bias by\nshuffling the order of the documents. With Deepseek-R1, InsertRank achieves a\nscore of 37.5 on the BRIGHT benchmark. and 51.1 on the R2MED benchmark,\nsurpassing previous methods.", "published": "2025-06-17 01:04:45", "link": "http://arxiv.org/abs/2506.14086v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.7", "H.3.3; I.5.4"], "primary_category": "cs.IR"}
{"title": "Exploring Speaker Diarization with Mixture of Experts", "abstract": "In this paper, we propose a novel neural speaker diarization system using\nmemory-aware multi-speaker embedding with sequence-to-sequence architecture\n(NSD-MS2S), which integrates a memory-aware multi-speaker embedding module with\na sequence-to-sequence architecture. The system leverages a memory module to\nenhance speaker embeddings and employs a Seq2Seq framework to efficiently map\nacoustic features to speaker labels. Additionally, we explore the application\nof mixture of experts in speaker diarization, and introduce a Shared and Soft\nMixture of Experts (SS-MoE) module to further mitigate model bias and enhance\nperformance. Incorporating SS-MoE leads to the extended model NSD-MS2S-SSMoE.\nExperiments on multiple complex acoustic datasets, including CHiME-6, DiPCo,\nMixer 6 and DIHARD-III evaluation sets, demonstrate meaningful improvements in\nrobustness and generalization. The proposed methods achieve state-of-the-art\nresults, showcasing their effectiveness in challenging real-world scenarios.", "published": "2025-06-17 17:42:54", "link": "http://arxiv.org/abs/2506.14750v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes", "abstract": "While knowledge distillation has become a mature field for compressing large\nlanguage models (LLMs) into smaller ones by aligning their outputs or internal\nrepresentations, the distillation of LLM-based agents, which involve planning,\nmemory, and tool use, remains relatively underexplored. Existing agent\ndistillation methods typically replay full teacher trajectories or imitate\nstep-by-step teacher tool usage, but they often struggle to train student\nagents to dynamically plan and act in novel environments. We propose\nAgentDistill, a novel, training-free agent distillation framework that enables\nefficient and scalable knowledge transfer via direct reuse of\nModel-Context-Protocols (MCPs), which are structured and reusable task-solving\nmodules autonomously generated by teacher agents. The reuse of these distilled\nMCPs enables student agents to generalize their capabilities across domains and\nsolve new problems with minimal supervision or human intervention. Experiments\non biomedical and mathematical benchmarks demonstrate that our distilled\nstudent agents, built on small language models, can achieve performance\ncomparable to advanced systems using large LLMs such as OctoTools (GPT-4o),\nhighlighting the effectiveness of our framework in building scalable and\ncost-efficient intelligent agents.", "published": "2025-06-17 17:08:32", "link": "http://arxiv.org/abs/2506.14728v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models", "abstract": "Assistive teleoperation, where control is shared between a human and a robot,\nenables efficient and intuitive human-robot collaboration in diverse and\nunstructured environments. A central challenge in real-world assistive\nteleoperation is for the robot to infer a wide range of human intentions from\nuser control inputs and to assist users with correct actions. Existing methods\nare either confined to simple, predefined scenarios or restricted to\ntask-specific data distributions at training, limiting their support for\nreal-world assistance. We introduce Casper, an assistive teleoperation system\nthat leverages commonsense knowledge embedded in pre-trained visual language\nmodels (VLMs) for real-time intent inference and flexible skill execution.\nCasper incorporates an open-world perception module for a generalized\nunderstanding of novel objects and scenes, a VLM-powered intent inference\nmechanism that leverages commonsense reasoning to interpret snippets of\nteleoperated user input, and a skill library that expands the scope of prior\nassistive teleoperation systems to support diverse, long-horizon mobile\nmanipulation tasks. Extensive empirical evaluation, including human studies and\nsystem ablations, demonstrates that Casper improves task performance, reduces\nhuman cognitive load, and achieves higher user satisfaction than direct\nteleoperation and assistive teleoperation baselines.", "published": "2025-06-17 17:06:43", "link": "http://arxiv.org/abs/2506.14727v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Adaptive Accompaniment with ReaLchords", "abstract": "Jamming requires coordination, anticipation, and collaborative creativity\nbetween musicians. Current generative models of music produce expressive output\nbut are not able to generate in an \\emph{online} manner, meaning simultaneously\nwith other musicians (human or otherwise). We propose ReaLchords, an online\ngenerative model for improvising chord accompaniment to user melody. We start\nwith an online model pretrained by maximum likelihood, and use reinforcement\nlearning to finetune the model for online use. The finetuning objective\nleverages both a novel reward model that provides feedback on both harmonic and\ntemporal coherency between melody and chord, and a divergence term that\nimplements a novel type of distillation from a teacher model that can see the\nfuture melody. Through quantitative experiments and listening tests, we\ndemonstrate that the resulting model adapts well to unfamiliar input and\nproduce fitting accompaniment. ReaLchords opens the door to live jamming, as\nwell as simultaneous co-creation in other modalities.", "published": "2025-06-17 16:59:05", "link": "http://arxiv.org/abs/2506.14723v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Refining music sample identification with a self-supervised graph neural network", "abstract": "Automatic sample identification (ASID), the detection and identification of\nportions of audio recordings that have been reused in new musical works, is an\nessential but challenging task in the field of audio query-based retrieval.\nWhile a related task, audio fingerprinting, has made significant progress in\naccurately retrieving musical content under \"real world\" (noisy, reverberant)\nconditions, ASID systems struggle to identify samples that have undergone\nmusical modifications. Thus, a system robust to common music production\ntransformations such as time-stretching, pitch-shifting, effects processing,\nand underlying or overlaying music is an important open challenge.\n  In this work, we propose a lightweight and scalable encoding architecture\nemploying a Graph Neural Network within a contrastive learning framework. Our\nmodel uses only 9% of the trainable parameters compared to the current\nstate-of-the-art system while achieving comparable performance, reaching a mean\naverage precision (mAP) of 44.2%.\n  To enhance retrieval quality, we introduce a two-stage approach consisting of\nan initial coarse similarity search for candidate selection, followed by a\ncross-attention classifier that rejects irrelevant matches and refines the\nranking of retrieved candidates - an essential capability absent in prior\nmodels. In addition, because queries in real-world applications are often short\nin duration, we benchmark our system for short queries using new fine-grained\nannotations for the Sample100 dataset, which we publish as part of this work.", "published": "2025-06-17 16:19:21", "link": "http://arxiv.org/abs/2506.14684v1", "categories": ["cs.SD", "cs.AI", "cs.IR", "H.5.5; I.2.6"], "primary_category": "cs.SD"}
{"title": "Unified Software Engineering agent as AI Software Engineer", "abstract": "The growth of Large Language Model (LLM) technology has raised expectations\nfor automated coding. However, software engineering is more than coding and is\nconcerned with activities including maintenance and evolution of a project. In\nthis context, the concept of LLM agents has gained traction, which utilize LLMs\nas reasoning engines to invoke external tools autonomously. But is an LLM agent\nthe same as an AI software engineer? In this paper, we seek to understand this\nquestion by developing a Unified Software Engineering agent or USEagent. Unlike\nexisting work which builds specialized agents for specific software tasks such\nas testing, debugging, and repair, our goal is to build a unified agent which\ncan orchestrate and handle multiple capabilities. This gives the agent the\npromise of handling complex scenarios in software development such as fixing an\nincomplete patch, adding new features, or taking over code written by others.\nWe envision USEagent as the first draft of a future AI Software Engineer which\ncan be a team member in future software development teams involving both AI and\nhumans. To evaluate the efficacy of USEagent, we build a Unified Software\nEngineering bench (USEbench) comprising of myriad tasks such as coding,\ntesting, and patching. USEbench is a judicious mixture of tasks from existing\nbenchmarks such as SWE-bench, SWT-bench, and REPOCOD. In an evaluation on\nUSEbench consisting of 1,271 repository-level software engineering tasks,\nUSEagent shows improved efficacy compared to existing general agents such as\nOpenHands CodeActAgent. There exist gaps in the capabilities of USEagent for\ncertain coding tasks, which provides hints on further developing the AI\nSoftware Engineer of the future.", "published": "2025-06-17 16:19:13", "link": "http://arxiv.org/abs/2506.14683v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Design an Editable Speech-to-Sign-Language Transformer System: A Human-Centered AI Approach", "abstract": "This paper presents a human-centered, real-time, user-adaptive speech-to-sign\nlanguage animation system that integrates Transformer-based motion generation\nwith a transparent, user-editable JSON intermediate layer. The framework\novercomes key limitations in prior sign language technologies by enabling\ndirect user inspection and modification of sign segments, thus enhancing\nnaturalness, expressiveness, and user agency. Leveraging a streaming Conformer\nencoder and autoregressive Transformer-MDN decoder, the system synchronizes\nspoken input into upper-body and facial motion for 3D avatar rendering. Edits\nand user ratings feed into a human-in-the-loop optimization loop for continuous\nimprovement. Experiments with 20 deaf signers and 5 interpreters show that the\neditable interface and participatory feedback significantly improve\ncomprehension, naturalness, usability, and trust, while lowering cognitive\nload. With sub-20 ms per-frame inference on standard hardware, the system is\nready for real-time communication and education. This work illustrates how\ntechnical and participatory innovation together enable accessible, explainable,\nand user-adaptive AI for sign language technology.", "published": "2025-06-17 16:08:48", "link": "http://arxiv.org/abs/2506.14677v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery", "abstract": "Traditionally, neighborhood studies have employed interviews, surveys, and\nmanual image annotation guided by detailed protocols to identify environmental\ncharacteristics, including physical disorder, decay, street safety, and\nsociocultural symbols, and to examine their impact on developmental and health\noutcomes. While these methods yield rich insights, they are time-consuming and\nrequire intensive expert intervention. Recent technological advances, including\nvision-language models (VLMs), have begun to automate parts of this process;\nhowever, existing efforts are often ad hoc and lack adaptability across\nresearch designs and geographic contexts. In this demo paper, we present\nStreetLens, a human-centered, researcher-configurable workflow that embeds\nrelevant social science expertise in a VLM for scalable neighborhood\nenvironmental assessments. StreetLens mimics the process of trained human\ncoders by grounding the analysis in questions derived from established\ninterview protocols, retrieving relevant street view imagery (SVI), and\ngenerating a wide spectrum of semantic annotations from objective features\n(e.g., the number of cars) to subjective perceptions (e.g., the sense of\ndisorder in an image). By enabling researchers to define the VLM's role through\ndomain-informed prompting, StreetLens places domain knowledge at the core of\nthe analysis process. It also supports the integration of prior survey data to\nenhance robustness and expand the range of characteristics assessed across\ndiverse settings. We provide a Google Colab notebook to make StreetLens\naccessible and extensible for researchers working with public or custom SVI\ndatasets. StreetLens represents a shift toward flexible, agentic AI systems\nthat work closely with researchers to accelerate and scale neighborhood\nstudies.", "published": "2025-06-17 16:06:03", "link": "http://arxiv.org/abs/2506.14670v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Accurate and scalable exchange-correlation with deep learning", "abstract": "Density Functional Theory (DFT) is the most widely used electronic structure\nmethod for predicting the properties of molecules and materials. Although DFT\nis, in principle, an exact reformulation of the Schr\\\"odinger equation,\npractical applications rely on approximations to the unknown\nexchange-correlation (XC) functional. Most existing XC functionals are\nconstructed using a limited set of increasingly complex, hand-crafted features\nthat improve accuracy at the expense of computational efficiency. Yet, no\ncurrent approximation achieves the accuracy and generality for predictive\nmodeling of laboratory experiments at chemical accuracy -- typically defined as\nerrors below 1 kcal/mol. In this work, we present Skala, a modern deep\nlearning-based XC functional that bypasses expensive hand-designed features by\nlearning representations directly from data. Skala achieves chemical accuracy\nfor atomization energies of small molecules while retaining the computational\nefficiency typical of semi-local DFT. This performance is enabled by training\non an unprecedented volume of high-accuracy reference data generated using\ncomputationally intensive wavefunction-based methods. Notably, Skala\nsystematically improves with additional training data covering diverse\nchemistry. By incorporating a modest amount of additional high-accuracy data\ntailored to chemistry beyond atomization energies, Skala achieves accuracy\ncompetitive with the best-performing hybrid functionals across general main\ngroup chemistry, at the cost of semi-local DFT. As the training dataset\ncontinues to expand, Skala is poised to further enhance the predictive power of\nfirst-principles simulations.", "published": "2025-06-17 15:56:56", "link": "http://arxiv.org/abs/2506.14665v1", "categories": ["physics.chem-ph", "cs.AI", "cs.CE", "cs.LG", "physics.comp-ph"], "primary_category": "physics.chem-ph"}
{"title": "Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor", "abstract": "In AI research and practice, rigor remains largely understood in terms of\nmethodological rigor -- such as whether mathematical, statistical, or\ncomputational methods are correctly applied. We argue that this narrow\nconception of rigor has contributed to the concerns raised by the responsible\nAI community, including overblown claims about AI capabilities. Our position is\nthat a broader conception of what rigorous AI research and practice should\nentail is needed. We believe such a conception -- in addition to a more\nexpansive understanding of (1) methodological rigor -- should include aspects\nrelated to (2) what background knowledge informs what to work on (epistemic\nrigor); (3) how disciplinary, community, or personal norms, standards, or\nbeliefs influence the work (normative rigor); (4) how clearly articulated the\ntheoretical constructs under use are (conceptual rigor); (5) what is reported\nand how (reporting rigor); and (6) how well-supported the inferences from\nexisting evidence are (interpretative rigor). In doing so, we also aim to\nprovide useful language and a framework for much-needed dialogue about the AI\ncommunity's work by researchers, policymakers, journalists, and other\nstakeholders.", "published": "2025-06-17 15:44:41", "link": "http://arxiv.org/abs/2506.14652v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning", "abstract": "Preference-based Reinforcement Learning (PbRL) methods provide a solution to\navoid reward engineering by learning reward models based on human preferences.\nHowever, poor feedback- and sample- efficiency still remain the problems that\nhinder the application of PbRL. In this paper, we present a novel efficient\nquery selection and preference-guided exploration method, called SENIOR, which\ncould select the meaningful and easy-to-comparison behavior segment pairs to\nimprove human feedback-efficiency and accelerate policy learning with the\ndesigned preference-guided intrinsic rewards. Our key idea is twofold: (1) We\ndesigned a Motion-Distinction-based Selection scheme (MDS). It selects segment\npairs with apparent motion and different directions through kernel density\nestimation of states, which is more task-related and easy for human preference\nlabeling; (2) We proposed a novel preference-guided exploration method (PGE).\nIt encourages the exploration towards the states with high preference and low\nvisits and continuously guides the agent achieving the valuable samples. The\nsynergy between the two mechanisms could significantly accelerate the progress\nof reward and policy learning. Our experiments show that SENIOR outperforms\nother five existing methods in both human feedback-efficiency and policy\nconvergence speed on six complex robot manipulation tasks from simulation and\nfour real-worlds.", "published": "2025-06-17 15:42:19", "link": "http://arxiv.org/abs/2506.14648v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Navigating the growing field of research on AI for software testing -- the taxonomy for AI-augmented software testing and an ontology-driven literature survey", "abstract": "In industry, software testing is the primary method to verify and validate\nthe functionality, performance, security, usability, and so on, of\nsoftware-based systems. Test automation has gained increasing attention in\nindustry over the last decade, following decades of intense research into test\nautomation and model-based testing. However, designing, developing, maintaining\nand evolving test automation is a considerable effort. Meanwhile, AI's\nbreakthroughs in many engineering fields are opening up new perspectives for\nsoftware testing, for both manual and automated testing. This paper reviews\nrecent research on AI augmentation in software test automation, from no\nautomation to full automation. It also discusses new forms of testing made\npossible by AI. Based on this, the newly developed taxonomy, ai4st, is\npresented and used to classify recent research and identify open research\nquestions.", "published": "2025-06-17 15:38:24", "link": "http://arxiv.org/abs/2506.14640v1", "categories": ["cs.SE", "cs.AI", "D.2.5"], "primary_category": "cs.SE"}
{"title": "ACM Survey Draft on Formalising Software Requirements with Large Language Models", "abstract": "This draft is a working document, having a summary of nighty-four (94) papers\nwith additional sections on Traceability of Software Requirements (Section 4),\nFormal Methods and Its Tools (Section 5), Unifying Theories of Programming\n(UTP) and Theory of Institutions (Section 6). Please refer to abstract of\n[7,8]. Key difference of this draft from our recently anticipated ones with\nsimilar titles, i.e. AACS 2025 [7] and SAIV 2025 [8] is:\n  [7] is a two page submission to ADAPT Annual Conference, Ireland. Submitted\non 18th of March, 2025, it went through the light-weight blind review and\naccepted for poster presentation. Conference was held on 15th of May, 2025.\n  [8] is a nine page paper with additional nine pages of references and summary\ntables, submitted to Symposium on AI Verification (SAIV 2025) on 24th of April,\n2025. It went through rigorous review process. The uploaded version on\narXiv.org [8] is the improved one of the submission, after addressing the\nspecific suggestions to improve the paper.", "published": "2025-06-17 15:23:56", "link": "http://arxiv.org/abs/2506.14627v1", "categories": ["cs.SE", "cs.AI", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "primary_category": "cs.SE"}
{"title": "Low-code to fight climate change: the Climaborough project", "abstract": "The EU-funded Climaborough project supports European cities to achieve carbon\nneutrality by 2030. Eleven cities in nine countries will deploy in real\nconditions products and services fostering climate transition in their local\nenvironment. The Climaborough City Platform is being developed to monitor the\ncities' overall progress towards their climate goals by aggregating historic\nand real-time data and displaying the results in user-friendly dashboards that\nwill be used by non-technical experts to evaluate the effectiveness of local\nexperimental initiatives, identify those that yield significant impact, and\nassess the potential consequences of scaling them up to a broader level. In\nthis paper, we explain how we have put in place a low-code/no-code strategy in\nClimaborough in response to the project's aim to quickly deploy climate\ndashboards. A low-code strategy is used to accelerate the development of the\ndashboards. The dashboards embed a no-code philosophy that enables all types of\ncitizen profiles to configure and adapt the dashboard to their specific needs.", "published": "2025-06-17 15:19:12", "link": "http://arxiv.org/abs/2506.14623v1", "categories": ["cs.SE", "cs.AI", "cs.CY"], "primary_category": "cs.SE"}
{"title": "PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation", "abstract": "Existing monocular 3D pose estimation methods primarily rely on joint\npositional features, while overlooking intrinsic directional and angular\ncorrelations within the skeleton. As a result, they often produce implausible\nposes under joint occlusions or rapid motion changes. To address these\nchallenges, we propose the PoseGRAF framework. We first construct a dual graph\nconvolutional structure that separately processes joint and bone graphs,\neffectively capturing their local dependencies. A Cross-Attention module is\nthen introduced to model interdependencies between bone directions and joint\nfeatures. Building upon this, a dynamic fusion module is designed to adaptively\nintegrate both feature types by leveraging the relational dependencies between\njoints and bones. An improved Transformer encoder is further incorporated in a\nresidual manner to generate the final output. Experimental results on the\nHuman3.6M and MPI-INF-3DHP datasets show that our method exceeds\nstate-of-the-art approaches. Additional evaluations on in-the-wild videos\nfurther validate its generalizability. The code is publicly available at\nhttps://github.com/iCityLab/PoseGRAF.", "published": "2025-06-17 14:59:56", "link": "http://arxiv.org/abs/2506.14596v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images", "abstract": "Document pages captured by smartphones or scanners often contain tables, yet\nmanual extraction is slow and error-prone. We introduce an automated\nLaTeX-based pipeline that synthesizes realistic two-column pages with visually\ndiverse table layouts and aligned ground-truth masks. The generated corpus\naugments the real-world Marmot benchmark and enables a systematic resolution\nstudy of TableNet. Training TableNet on our synthetic data achieves a\npixel-wise XOR error of 4.04% on our synthetic test set with a 256x256 input\nresolution, and 4.33% with 1024x1024. The best performance on the Marmot\nbenchmark is 9.18% (at 256x256), while cutting manual annotation effort through\nautomation.", "published": "2025-06-17 14:41:31", "link": "http://arxiv.org/abs/2506.14583v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Object-Centric Neuro-Argumentative Learning", "abstract": "Over the last decade, as we rely more on deep learning technologies to make\ncritical decisions, concerns regarding their safety, reliability and\ninterpretability have emerged. We introduce a novel Neural Argumentative\nLearning (NAL) architecture that integrates Assumption-Based Argumentation\n(ABA) with deep learning for image analysis. Our architecture consists of\nneural and symbolic components. The former segments and encodes images into\nfacts using object-centric learning, while the latter applies ABA learning to\ndevelop ABA frameworks enabling predictions with images. Experiments on\nsynthetic data show that the NAL architecture can be competitive with a\nstate-of-the-art alternative.", "published": "2025-06-17 14:35:01", "link": "http://arxiv.org/abs/2506.14577v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places", "abstract": "Capturing human mobility is essential for modeling how people interact with\nand move through physical spaces, reflecting social behavior, access to\nresources, and dynamic spatial patterns. To support scalable and transferable\nanalysis across diverse geographies and contexts, there is a need for a\ngeneralizable foundation model for spatiotemporal data. While foundation models\nhave transformed language and vision, they remain limited in handling the\nunique challenges posed by the spatial, temporal, and semantic complexity of\nmobility data. This vision paper advocates for a new class of spatial\nfoundation models that integrate geolocation semantics with human mobility\nacross multiple scales. Central to our vision is a shift from modeling discrete\npoints of interest to understanding places: dynamic, context-rich regions\nshaped by human behavior and mobility that may comprise many places of\ninterest. We identify key gaps in adaptability, scalability, and multi-granular\nreasoning, and propose research directions focused on modeling places and\nenabling efficient learning. Our goal is to guide the development of scalable,\ncontext-aware models for next-generation geospatial intelligence. These models\nunlock powerful applications ranging from personalized place discovery and\nlogistics optimization to urban planning, ultimately enabling smarter and more\nresponsive spatial decision-making.", "published": "2025-06-17 14:27:24", "link": "http://arxiv.org/abs/2506.14570v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing Symbolic Machine Learning by Subsymbolic Representations", "abstract": "The goal of neuro-symbolic AI is to integrate symbolic and subsymbolic AI\napproaches, to overcome the limitations of either. Prominent systems include\nLogic Tensor Networks (LTN) or DeepProbLog, which offer neural predicates and\nend-to-end learning. The versatility of systems like LTNs and DeepProbLog,\nhowever, makes them less efficient in simpler settings, for instance, for\ndiscriminative machine learning, in particular in domains with many constants.\nTherefore, we follow a different approach: We propose to enhance symbolic\nmachine learning schemes by giving them access to neural embeddings. In the\npresent paper, we show this for TILDE and embeddings of constants used by TILDE\nin similarity predicates. The approach can be fine-tuned by further refining\nthe embeddings depending on the symbolic theory. In experiments in three\nreal-world domain, we show that this simple, yet effective, approach\noutperforms all other baseline methods in terms of the F1 score. The approach\ncould be useful beyond this setting: Enhancing symbolic learners in this way\ncould be extended to similarities between instances (effectively working like\nkernels within a logical language), for analogical reasoning, or for\npropositionalization.", "published": "2025-06-17 14:26:21", "link": "http://arxiv.org/abs/2506.14569v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents", "abstract": "Automating table extraction (TE) from business documents is critical for\nindustrial workflows but remains challenging due to sparse annotations and\nerror-prone multi-stage pipelines. While semi-supervised learning (SSL) can\nleverage unlabeled data, existing methods rely on confidence scores that poorly\nreflect extraction quality. We propose QUEST, a Quality-aware Semi-supervised\nTable extraction framework designed for business documents. QUEST introduces a\nnovel quality assessment model that evaluates structural and contextual\nfeatures of extracted tables, trained to predict F1 scores instead of relying\non confidence metrics. This quality-aware approach guides pseudo-label\nselection during iterative SSL training, while diversity measures (DPP, Vendi\nscore, IntDiv) mitigate confirmation bias. Experiments on a proprietary\nbusiness dataset (1000 annotated + 10000 unannotated documents) show QUEST\nimproves F1 from 64% to 74% and reduces empty predictions by 45% (from 12% to\n6.5%). On the DocILE benchmark (600 annotated + 20000 unannotated documents),\nQUEST achieves a 50% F1 score (up from 42%) and reduces empty predictions by\n19% (from 27% to 22%). The framework's interpretable quality assessments and\nrobustness to annotation scarcity make it particularly suited for business\ndocuments, where structural consistency and data completeness are paramount.", "published": "2025-06-17 14:25:44", "link": "http://arxiv.org/abs/2506.14568v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Controlling Context: Generative AI at Work in Integrated Circuit Design and Other High-Precision Domains", "abstract": "Generative AI tools have become more prevalent in engineering workflows,\nparticularly through chatbots and code assistants. As the perceived accuracy of\nthese tools improves, questions arise about whether and how those who work in\nhigh-precision domains might maintain vigilance for errors, and what other\naspects of using such tools might trouble their work. This paper analyzes\ninterviews with hardware and software engineers, and their collaborators, who\nwork in integrated circuit design to identify the role accuracy plays in their\nuse of generative AI tools and what other forms of trouble they face in using\nsuch tools. The paper inventories these forms of trouble, which are then mapped\nto elements of generative AI systems, to conclude that controlling the context\nof interactions between engineers and the generative AI tools is one of the\nlargest challenges they face. The paper concludes with recommendations for\nmitigating this form of trouble by increasing the ability to control context\ninteractively.", "published": "2025-06-17 14:25:32", "link": "http://arxiv.org/abs/2506.14567v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Doppelg\u00e4nger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack", "abstract": "Since the advent of large language models, prompt engineering now enables the\nrapid, low-effort creation of diverse autonomous agents that are already in\nwidespread use. Yet this convenience raises urgent concerns about the safety,\nrobustness, and behavioral consistency of the underlying prompts, along with\nthe pressing challenge of preventing those prompts from being exposed to user's\nattempts. In this paper, we propose the ''Doppelg\\\"anger method'' to\ndemonstrate the risk of an agent being hijacked, thereby exposing system\ninstructions and internal information. Next, we define the ''Prompt Alignment\nCollapse under Adversarial Transfer (PACAT)'' level to evaluate the\nvulnerability to this adversarial transfer attack. We also propose a ''Caution\nfor Adversarial Transfer (CAT)'' prompt to counter the Doppelg\\\"anger method.\nThe experimental results demonstrate that the Doppelg\\\"anger method can\ncompromise the agent's consistency and expose its internal information. In\ncontrast, CAT prompts enable effective defense against this adversarial attack.", "published": "2025-06-17 14:01:39", "link": "http://arxiv.org/abs/2506.14539v1", "categories": ["cs.AI", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "abstract": "Machine learning-based decision support systems are increasingly deployed in\nclinical settings, where probabilistic scoring functions are used to inform and\nprioritize patient management decisions. However, widely used scoring rules,\nsuch as accuracy and AUC-ROC, fail to adequately reflect key clinical\npriorities, including calibration, robustness to distributional shifts, and\nsensitivity to asymmetric error costs. In this work, we propose a principled\nyet practical evaluation framework for selecting calibrated thresholded\nclassifiers that explicitly accounts for the uncertainty in class prevalences\nand domain-specific cost asymmetries often found in clinical settings. Building\non the theory of proper scoring rules, particularly the Schervish\nrepresentation, we derive an adjusted variant of cross-entropy (log score) that\naverages cost-weighted performance over clinically relevant ranges of class\nbalance. The resulting evaluation is simple to apply, sensitive to clinical\ndeployment conditions, and designed to prioritize models that are both\ncalibrated and robust to real-world variations.", "published": "2025-06-17 14:01:39", "link": "http://arxiv.org/abs/2506.14540v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Automatic Qiskit Code Refactoring Using Large Language Models", "abstract": "As quantum software frameworks evolve, developers face increasing challenges\nin maintaining compatibility with rapidly changing APIs. In this work, we\npresent a novel methodology for refactoring Qiskit code using large language\nmodels (LLMs). We begin by extracting a taxonomy of migration scenarios from\nthe different sources of official Qiskit documentation (such as release notes),\ncapturing common patterns such as migration of functionality to different\nmodules and deprecated usage. This taxonomy, along with the original Python\nsource code, is provided as input to an LLM, which is then tasked with\nidentifying instances of migration scenarios in the code and suggesting\nappropriate refactoring solutions. Our approach is designed to address the\ncontext length limitations of current LLMs by structuring the input and\nreasoning process in a targeted, efficient manner. The results demonstrate that\nLLMs, when guided by domain-specific migration knowledge, can effectively\nassist in automating Qiskit code migration. This work contributes both a set of\nproven prompts and taxonomy for Qiskit code migration from earlier versions to\nversion 0.46 and a methodology to asses the capabilities of LLMs to assist in\nthe migration of quantum code.", "published": "2025-06-17 14:00:48", "link": "http://arxiv.org/abs/2506.14535v1", "categories": ["cs.SE", "cs.AI", "cs.ET"], "primary_category": "cs.SE"}
{"title": "Complete Characterization for Adjustment in Summary Causal Graphs of Time Series", "abstract": "The identifiability problem for interventions aims at assessing whether the\ntotal causal effect can be written with a do-free formula, and thus be\nestimated from observational data only. We study this problem, considering\nmultiple interventions, in the context of time series when only an abstraction\nof the true causal graph, in the form of a summary causal graph, is available.\nWe propose in particular both necessary and sufficient conditions for the\nadjustment criterion, which we show is complete in this setting, and provide a\npseudo-linear algorithm to decide whether the query is identifiable or not.", "published": "2025-06-17 14:00:31", "link": "http://arxiv.org/abs/2506.14534v1", "categories": ["math.ST", "cs.AI", "stat.TH"], "primary_category": "math.ST"}
{"title": "Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters", "abstract": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted\nparameter-efficient fine-tuning (PEFT) technique for foundation models. Recent\nwork has highlighted an inherent asymmetry in the initialization of LoRA's\nlow-rank factors, which has been present since its inception and was presumably\nderived experimentally. This paper focuses on providing a comprehensive\ntheoretical characterization of asymmetric LoRA with frozen random factors.\nFirst, while existing research provides upper-bound generalization guarantees\nbased on averages over multiple experiments, the behaviour of a single\nfine-tuning run with specific random factors remains an open question. We\naddress this by investigating the concentration of the typical LoRA\ngeneralization gap around its mean. Our main upper bound reveals a sample\ncomplexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{r}}{\\sqrt{N}}\\right)$ with\nhigh probability for rank $r$ LoRAs trained on $N$ samples. Additionally, we\nalso determine the fundamental limits in terms of sample efficiency,\nestablishing a matching lower bound of\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)$. By more closely reflecting the\npractical scenario of a single fine-tuning run, our findings offer crucial\ninsights into the reliability and practicality of asymmetric LoRA.", "published": "2025-06-17 13:55:13", "link": "http://arxiv.org/abs/2506.14530v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "cs.NE", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments", "abstract": "The convergence of robotics and virtual reality (VR) has enabled safer and\nmore efficient workflows in high-risk laboratory settings, particularly\nvirology labs. As biohazard complexity increases, minimizing direct human\nexposure while maintaining precision becomes essential. We propose GAMORA\n(Gesture Articulated Meta Operative Robotic Arm), a novel VR-guided robotic\nsystem that enables remote execution of hazardous tasks using natural hand\ngestures. Unlike existing scripted automation or traditional teleoperation,\nGAMORA integrates the Oculus Quest 2, NVIDIA Jetson Nano, and Robot Operating\nSystem (ROS) to provide real-time immersive control, digital twin simulation,\nand inverse kinematics-based articulation. The system supports VR-based\ntraining and simulation while executing precision tasks in physical\nenvironments via a 3D-printed robotic arm. Inverse kinematics ensure accurate\nmanipulation for delicate operations such as specimen handling and pipetting.\nThe pipeline includes Unity-based 3D environment construction, real-time motion\nplanning, and hardware-in-the-loop testing. GAMORA achieved a mean positional\ndiscrepancy of 2.2 mm (improved from 4 mm), pipetting accuracy within 0.2 mL,\nand repeatability of 1.2 mm across 50 trials. Integrated object detection via\nYOLOv8 enhances spatial awareness, while energy-efficient operation (50%\nreduced power output) ensures sustainable deployment. The system's\ndigital-physical feedback loop enables safe, precise, and repeatable automation\nof high-risk lab tasks. GAMORA offers a scalable, immersive solution for\nrobotic control and biosafety in biomedical research environments.", "published": "2025-06-17 13:40:16", "link": "http://arxiv.org/abs/2506.14513v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow", "abstract": "Despite the recent advancements in artificial intelligence technologies have\nshown great potential in improving transport efficiency and safety, autonomous\nvehicles(AVs) still face great challenge of driving in time-varying traffic\nflow, especially in dense and interactive situations. Meanwhile, human have\nfree wills and usually do not make the same decisions even situate in the\nexactly same scenarios, leading to the data-driven methods suffer from poor\nmigratability and high search cost problems, decreasing the efficiency and\neffectiveness of the behavior policy. In this research, we propose a\nsafety-first human-like decision-making framework(SF-HLDM) for AVs to drive\nsafely, comfortably, and social compatiblely in effiency. The framework\nintegrates a hierarchical progressive framework, which combines a\nspatial-temporal attention (S-TA) mechanism for other road users' intention\ninference, a social compliance estimation module for behavior regulation, and a\nDeep Evolutionary Reinforcement Learning(DERL) model for expanding the search\nspace efficiently and effectively to make avoidance of falling into the local\noptimal trap and reduce the risk of overfitting, thus make human-like decisions\nwith interpretability and flexibility. The SF-HLDM framework enables autonomous\ndriving AI agents dynamically adjusts decision parameters to maintain safety\nmargins and adhering to contextually appropriate driving behaviors at the same\ntime.", "published": "2025-06-17 13:28:19", "link": "http://arxiv.org/abs/2506.14502v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?", "abstract": "Swarm intelligence traditionally refers to systems of simple, decentralized\nagents whose local interactions lead to emergent, collective behavior.\nRecently, the term 'swarm' has been extended to describe AI systems like\nOpenAI's Swarm, where large language models (LLMs) act as collaborative agents.\nThis paper contrasts traditional swarm algorithms with LLM-driven swarms\nexploring how decentralization, scalability, and emergence are redefined in\nmodern artificial intelligence (AI). We implement and compare both paradigms\nusing Boids and Ant Colony Optimization (ACO), evaluating latency, resource\nusage, and behavioral accuracy. The suitability of both cloud-based and local\nLLMs is assessed for the agent-based use in swarms. Although LLMs offer\npowerful reasoning and abstraction capabilities, they introduce new constraints\nin computation and coordination that challenge traditional notions of swarm\ndesign. This study highlights the opportunities and limitations of integrating\nLLMs into swarm systems and discusses the evolving definition of 'swarm' in\nmodern AI research.", "published": "2025-06-17 13:18:34", "link": "http://arxiv.org/abs/2506.14496v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies", "abstract": "The development of high-quality datasets is crucial for benchmarking and\nadvancing research in Graphical User Interface (GUI) agents. Despite their\nimportance, existing datasets are often constructed under idealized conditions,\noverlooking the diverse anomalies frequently encountered in real-world\ndeployments. To address this limitation, we introduce GUI-Robust, a novel\ndataset designed for comprehensive GUI agent evaluation, explicitly\nincorporating seven common types of anomalies observed in everyday GUI\ninteractions. Furthermore, we propose a semi-automated dataset construction\nparadigm that collects user action sequences from natural interactions via RPA\ntools and then generate corresponding step and task descriptions for these\nactions with the assistance of MLLMs. This paradigm significantly reduces\nannotation time cost by a factor of over 19 times. Finally, we assess\nstate-of-the-art GUI agents using the GUI-Robust dataset, revealing their\nsubstantial performance degradation in abnormal scenarios. We anticipate that\nour work will highlight the importance of robustness in GUI agents and inspires\nmore future research in this direction. The dataset and code are available at\nhttps://github.com/chessbean1/GUI-Robust..", "published": "2025-06-17 12:50:35", "link": "http://arxiv.org/abs/2506.14477v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks", "abstract": "Accurate electrical consumption forecasting is crucial for efficient energy\nmanagement and resource allocation. While traditional time series forecasting\nrelies on historical patterns and temporal dependencies, incorporating external\nfactors -- such as weather indicators -- has shown significant potential for\nimproving prediction accuracy in complex real-world applications. However, the\ninclusion of these additional features often degrades the performance of global\npredictive models trained on entire populations, despite improving individual\nhousehold-level models. To address this challenge, we found that a hypernetwork\narchitecture can effectively leverage external factors to enhance the accuracy\nof global electrical consumption forecasting models, by specifically adjusting\nthe model weights to each consumer.\n  We collected a comprehensive dataset spanning two years, comprising\nconsumption data from over 6000 luxembourgish households and corresponding\nexternal factors such as weather indicators, holidays, and major local events.\nBy comparing various forecasting models, we demonstrate that a hypernetwork\napproach outperforms existing methods when associated to external factors,\nreducing forecasting errors and achieving the best accuracy while maintaining\nthe benefits of a global model.", "published": "2025-06-17 12:35:24", "link": "http://arxiv.org/abs/2506.14472v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection", "abstract": "As one of the most detrimental code smells, code clones significantly\nincrease software maintenance costs and heighten vulnerability risks, making\ntheir detection a critical challenge in software engineering. Abstract Syntax\nTrees (ASTs) dominate deep learning-based code clone detection due to their\nprecise syntactic structure representation, but they inherently lack semantic\ndepth. Recent studies address this by enriching AST-based representations with\nsemantic graphs, such as Control Flow Graphs (CFGs) and Data Flow Graphs\n(DFGs). However, the effectiveness of various enriched AST-based\nrepresentations and their compatibility with different graph-based machine\nlearning techniques remains an open question, warranting further investigation\nto unlock their full potential in addressing the complexities of code clone\ndetection. In this paper, we present a comprehensive empirical study to\nrigorously evaluate the effectiveness of AST-based hybrid graph representations\nin Graph Neural Network (GNN)-based code clone detection. We systematically\ncompare various hybrid representations ((CFG, DFG, Flow-Augmented ASTs\n(FA-AST)) across multiple GNN architectures. Our experiments reveal that hybrid\nrepresentations impact GNNs differently: while AST+CFG+DFG consistently\nenhances accuracy for convolution- and attention-based models (Graph\nConvolutional Networks (GCN), Graph Attention Networks (GAT)), FA-AST\nfrequently introduces structural complexity that harms performance. Notably,\nGMN outperforms others even with standard AST representations, highlighting its\nsuperior cross-code similarity detection and reducing the need for enriched\nstructures.", "published": "2025-06-17 12:35:17", "link": "http://arxiv.org/abs/2506.14470v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks", "abstract": "Recurrent spiking neural networks (RSNNs) can be implemented very efficiently\nin neuromorphic systems. Nevertheless, training of these models with powerful\ngradient-based learning algorithms is mostly performed on standard digital\nhardware using Backpropagation through time (BPTT). However, BPTT has\nsubstantial limitations. It does not permit online training and its memory\nconsumption scales linearly with the number of computation steps. In contrast,\nlearning methods using forward propagation of gradients operate in an online\nmanner with a memory consumption independent of the number of time steps. These\nmethods enable SNNs to learn from continuous, infinite-length input sequences.\nYet, slow execution speed on conventional hardware as well as inferior\nperformance has hindered their widespread application. In this work, we\nintroduce HYbrid PRopagation (HYPR) that combines the efficiency of\nparallelization with approximate online forward learning. Our algorithm yields\nhigh-throughput online learning through parallelization, paired with constant,\ni.e., sequence length independent, memory demands. HYPR enables parallelization\nof parameter update computation over the sub sequences for RSNNs consisting of\nalmost arbitrary non-linear spiking neuron models. We apply HYPR to networks of\nspiking neurons with oscillatory subthreshold dynamics. We find that this type\nof neuron model is particularly well trainable by HYPR, resulting in an\nunprecedentedly low task performance gap between approximate forward gradient\nlearning and BPTT.", "published": "2025-06-17 12:27:25", "link": "http://arxiv.org/abs/2506.14464v1", "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Hamiltonian Formalism for Comparing Quantum and Classical Intelligence", "abstract": "The prospect of AGI instantiated on quantum substrates motivates the\ndevelopment of mathematical frameworks that enable direct comparison of their\noperation in classical and quantum environments. To this end, we introduce a\nHamiltonian formalism for describing classical and quantum AGI tasks as a means\nof contrasting their interaction with the environment. We propose a\ndecomposition of AGI dynamics into Hamiltonian generators for core functions\nsuch as induction, reasoning, recursion, learning, measurement, and memory.\nThis formalism aims to contribute to the development of a precise mathematical\nlanguage for how quantum and classical agents differ via environmental\ninteraction.", "published": "2025-06-17 12:17:05", "link": "http://arxiv.org/abs/2506.14456v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Adapting Lightweight Vision Language Models for Radiological Visual Question Answering", "abstract": "Recent advancements in vision-language systems have improved the accuracy of\nRadiological Visual Question Answering (VQA) Models. However, some challenges\nremain across each stage of model development: limited expert-labeled images\nhinders data procurement at scale; the intricate and nuanced patterns of\nradiological images make modeling inherently difficult; and the lack of\nevaluation evaluation efforts makes it difficult to identify cases where the\nmodel might be ill-conditioned. In this study, we fine-tune a lightweight 3B\nparameter vision-language model for Radiological VQA, demonstrating that small\nmodels, when appropriately tuned with curated data, can achieve robust\nperformance across both open- and closed-ended questions. We propose a\ncost-effective training pipeline from synthetic question-answer pair generation\nto multi-stage fine-tuning on specialised radiological domain-targeted datasets\n(e.g., ROCO v2.0, MedPix v2.0). Our results show that despite operating at a\nfraction of the scale of state-of-the-art models such as LLaVA-Med, our model\nachieves promising performance given its small parameter size and the limited\nscale of training data. We introduce a lightweight saliency-based diagnostic\ntool that enables domain experts to inspect VQA model performance and identify\nill-conditioned failure modes through saliency analysis.", "published": "2025-06-17 12:15:08", "link": "http://arxiv.org/abs/2506.14451v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Model compression using knowledge distillation with integrated gradients", "abstract": "Model compression is critical for deploying deep learning models on\nresource-constrained devices. We introduce a novel method enhancing knowledge\ndistillation with integrated gradients (IG) as a data augmentation strategy.\nOur approach overlays IG maps onto input images during training, providing\nstudent models with deeper insights into teacher models' decision-making\nprocesses. Extensive evaluation on CIFAR-10 demonstrates that our IG-augmented\nknowledge distillation achieves 92.6% testing accuracy with a 4.1x compression\nfactor-a significant 1.1 percentage point improvement ($p<0.001$) over\nnon-distilled models (91.5%). This compression reduces inference time from 140\nms to 13 ms. Our method precomputes IG maps before training, transforming\nsubstantial runtime costs into a one-time preprocessing step. Our comprehensive\nexperiments include: (1) comparisons with attention transfer, revealing\ncomplementary benefits when combined with our approach; (2) Monte Carlo\nsimulations confirming statistical robustness; (3) systematic evaluation of\ncompression factor versus accuracy trade-offs across a wide range (2.2x-1122x);\nand (4) validation on an ImageNet subset aligned with CIFAR-10 classes,\ndemonstrating generalisability beyond the initial dataset. These extensive\nablation studies confirm that IG-based knowledge distillation consistently\noutperforms conventional approaches across varied architectures and compression\nratios. Our results establish this framework as a viable compression technique\nfor real-world deployment on edge devices while maintaining competitive\naccuracy.", "published": "2025-06-17 12:00:23", "link": "http://arxiv.org/abs/2506.14440v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T05, 68T07", "I.2.6; I.4.2; I.4.9"], "primary_category": "cs.CV"}
{"title": "sHGCN: Simplified hyperbolic graph convolutional neural networks", "abstract": "Hyperbolic geometry has emerged as a powerful tool for modeling complex,\nstructured data, particularly where hierarchical or tree-like relationships are\npresent. By enabling embeddings with lower distortion, hyperbolic neural\nnetworks offer promising alternatives to Euclidean-based models for capturing\nintricate data structures. Despite these advantages, they often face\nperformance challenges, particularly in computational efficiency and tasks\nrequiring high precision. In this work, we address these limitations by\nsimplifying key operations within hyperbolic neural networks, achieving notable\nimprovements in both runtime and performance. Our findings demonstrate that\nstreamlined hyperbolic operations can lead to substantial gains in\ncomputational speed and predictive accuracy, making hyperbolic neural networks\na more viable choice for a broader range of applications.", "published": "2025-06-17 11:58:07", "link": "http://arxiv.org/abs/2506.14438v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Unifying Streaming and Non-streaming Zipformer-based ASR", "abstract": "There has been increasing interest in unifying streaming and non-streaming\nautomatic speech recognition (ASR) models to reduce development, training, and\ndeployment costs. We present a unified framework that trains a single\nend-to-end ASR model for both streaming and non-streaming applications,\nleveraging future context information. We propose to use dynamic right-context\nthrough the chunked attention masking in the training of zipformer-based ASR\nmodels. We demonstrate that using right-context is more effective in zipformer\nmodels compared to other conformer models due to its multi-scale nature. We\nanalyze the effect of varying the number of right-context frames on accuracy\nand latency of the streaming ASR models. We use Librispeech and large in-house\nconversational datasets to train different versions of streaming and\nnon-streaming models and evaluate them in a production grade server-client\nsetup across diverse testsets of different domains. The proposed strategy\nreduces word error by relative 7.9\\% with a small degradation in user-perceived\nlatency. By adding more right-context frames, we are able to achieve streaming\nperformance close to that of non-streaming models. Our approach also allows\nflexible control of the latency-accuracy tradeoff according to customers\nrequirements.", "published": "2025-06-17 11:52:41", "link": "http://arxiv.org/abs/2506.14434v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Is Selection All You Need in Differential Evolution?", "abstract": "Differential Evolution (DE) is a widely used evolutionary algorithm for\nblack-box optimization problems. However, in modern DE implementations, a major\nchallenge lies in the limited population diversity caused by the fixed\npopulation size enforced by the generational replacement. Population size is a\ncritical control parameter that significantly affects DE performance. Larger\npopulations inherently contain a more diverse set of individuals, thereby\nfacilitating broader exploration of the search space. Conversely, when the\nmaximum evaluation budgets is constrained, smaller populations focusing on a\nlimited number of promising candidates may be more suitable. Many\nstate-of-the-art DE variants incorporate an archive mechanism, in which a\nsubset of discarded individuals is preserved in an archive during generation\nreplacement and reused in mutation operations. However, maintaining what is\nessentially a secondary population via an archive introduces additional design\nconsiderations, such as policies for insertion, deletion, and appropriate\nsizing. To address these limitations, we propose a novel DE framework called\nUnbounded Differential Evolution (UDE), which adds all generated candidates to\nthe population without discarding any individual based on fitness. Unlike\nconventional DE, which removes inferior individuals during generational\nreplacement, UDE eliminates replacement altogether, along with the associated\ncomplexities of archive management and dynamic population sizing. UDE\nrepresents a fundamentally new approach to DE, relying solely on selection\nmechanisms and enabling a more straightforward yet powerful search algorithm.", "published": "2025-06-17 11:41:44", "link": "http://arxiv.org/abs/2506.14425v1", "categories": ["cs.NE", "cs.AI", "G.1.6; I.2.8"], "primary_category": "cs.NE"}
{"title": "Compositional Attribute Imbalance in Vision Datasets", "abstract": "Visual attribute imbalance is a common yet underexplored issue in image\nclassification, significantly impacting model performance and generalization.\nIn this work, we first define the first-level and second-level attributes of\nimages and then introduce a CLIP-based framework to construct a visual\nattribute dictionary, enabling automatic evaluation of image attributes. By\nsystematically analyzing both single-attribute imbalance and compositional\nattribute imbalance, we reveal how the rarity of attributes affects model\nperformance. To tackle these challenges, we propose adjusting the sampling\nprobability of samples based on the rarity of their compositional attributes.\nThis strategy is further integrated with various data augmentation techniques\n(such as CutMix, Fmix, and SaliencyMix) to enhance the model's ability to\nrepresent rare attributes. Extensive experiments on benchmark datasets\ndemonstrate that our method effectively mitigates attribute imbalance, thereby\nimproving the robustness and fairness of deep neural networks. Our research\nhighlights the importance of modeling visual attribute distributions and\nprovides a scalable solution for long-tail image classification tasks.", "published": "2025-06-17 11:28:07", "link": "http://arxiv.org/abs/2506.14418v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition", "abstract": "Retrieval-Augmented Generation (RAG) enriches Large Language Models (LLMs) by\ncombining their internal, parametric knowledge with external, non-parametric\nsources, with the goal of improving factual correctness and minimizing\nhallucinations. The LiveRAG 2025 challenge explores RAG solutions to maximize\naccuracy on DataMorgana's QA pairs, which are composed of single-hop and\nmulti-hop questions. The challenge provides access to sparse OpenSearch and\ndense Pinecone indices of the Fineweb 10BT dataset. It restricts model use to\nLLMs with up to 10B parameters and final answer generation with Falcon-3-10B. A\njudge-LLM assesses the submitted answers along with human evaluators. By\nexploring distinct retriever combinations and RAG solutions under the challenge\nconditions, our final solution emerged using InstructRAG in combination with a\nPinecone retriever and a BGE reranker. Our solution achieved a correctness\nscore of 1.13 and a faithfulness score of 0.55, placing fourth in the SIGIR\n2025 LiveRAG Challenge.", "published": "2025-06-17 11:14:22", "link": "http://arxiv.org/abs/2506.14412v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Adaptive Reinforcement Learning for Unobservable Random Delays", "abstract": "In standard Reinforcement Learning (RL) settings, the interaction between the\nagent and the environment is typically modeled as a Markov Decision Process\n(MDP), which assumes that the agent observes the system state instantaneously,\nselects an action without delay, and executes it immediately. In real-world\ndynamic environments, such as cyber-physical systems, this assumption often\nbreaks down due to delays in the interaction between the agent and the system.\nThese delays can vary stochastically over time and are typically unobservable,\nmeaning they are unknown when deciding on an action. Existing methods deal with\nthis uncertainty conservatively by assuming a known fixed upper bound on the\ndelay, even if the delay is often much lower. In this work, we introduce the\ninteraction layer, a general framework that enables agents to adaptively and\nseamlessly handle unobservable and time-varying delays. Specifically, the agent\ngenerates a matrix of possible future actions to handle both unpredictable\ndelays and lost action packets sent over networks. Building on this framework,\nwe develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA),\nwhich dynamically adjusts to delay patterns. Our method significantly\noutperforms state-of-the-art approaches across a wide range of locomotion\nbenchmark environments.", "published": "2025-06-17 11:11:37", "link": "http://arxiv.org/abs/2506.14411v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Causally Steered Diffusion for Automated Video Counterfactual Generation", "abstract": "Adapting text-to-image (T2I) latent diffusion models for video editing has\nshown strong visual fidelity and controllability, but challenges remain in\nmaintaining causal relationships in video content. Edits affecting causally\ndependent attributes risk generating unrealistic or misleading outcomes if\nthese relationships are ignored. In this work, we propose a causally faithful\nframework for counterfactual video generation, guided by a vision-language\nmodel (VLM). Our method is agnostic to the underlying video editing system and\ndoes not require access to its internal mechanisms or finetuning. Instead, we\nguide the generation by optimizing text prompts based on an assumed causal\ngraph, addressing the challenge of latent space control in LDMs. We evaluate\nour approach using standard video quality metrics and counterfactual-specific\ncriteria, such as causal effectiveness and minimality. Our results demonstrate\nthat causally faithful video counterfactuals can be effectively generated\nwithin the learned distribution of LDMs through prompt-based causal steering.\nWith its compatibility with any black-box video editing system, our method\nholds significant potential for generating realistic \"what-if\" video scenarios\nin diverse areas such as healthcare and digital media.", "published": "2025-06-17 11:06:22", "link": "http://arxiv.org/abs/2506.14404v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models", "abstract": "Counterfactual image generation aims to simulate realistic visual outcomes\nunder specific causal interventions. Diffusion models have recently emerged as\na powerful tool for this task, combining DDIM inversion with conditional\ngeneration via classifier-free guidance (CFG). However, standard CFG applies a\nsingle global weight across all conditioning variables, which can lead to poor\nidentity preservation and spurious attribute changes - a phenomenon known as\nattribute amplification. To address this, we propose Decoupled Classifier-Free\nGuidance (DCFG), a flexible and model-agnostic framework that introduces\ngroup-wise conditioning control. DCFG builds on an attribute-split embedding\nstrategy that disentangles semantic inputs, enabling selective guidance on\nuser-defined attribute groups. For counterfactual generation, we partition\nattributes into intervened and invariant sets based on a causal graph and apply\ndistinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show\nthat DCFG improves intervention fidelity, mitigates unintended changes, and\nenhances reversibility, enabling more faithful and interpretable counterfactual\nimage generation.", "published": "2025-06-17 10:56:09", "link": "http://arxiv.org/abs/2506.14399v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control", "abstract": "Efficient traffic signal control (TSC) is essential for mitigating urban\ncongestion, yet existing reinforcement learning (RL) methods face challenges in\nscaling to large networks while maintaining global coordination. Centralized RL\nsuffers from scalability issues, while decentralized approaches often lack\nunified objectives, resulting in limited network-level efficiency. In this\npaper, we propose HiLight, a hierarchical reinforcement learning framework with\nglobal adversarial guidance for large-scale TSC. HiLight consists of a\nhigh-level Meta-Policy, which partitions the traffic network into subregions\nand generates sub-goals using a Transformer-LSTM architecture, and a low-level\nSub-Policy, which controls individual intersections with global awareness. To\nimprove the alignment between global planning and local execution, we introduce\nan adversarial training mechanism, where the Meta-Policy generates challenging\nyet informative sub-goals, and the Sub-Policy learns to surpass these targets,\nleading to more effective coordination. We evaluate HiLight across both\nsynthetic and real-world benchmarks, and additionally construct a large-scale\nManhattan network with diverse traffic conditions, including peak transitions,\nadverse weather, and holiday surges. Experimental results show that HiLight\nexhibits significant advantages in large-scale scenarios and remains\ncompetitive across standard benchmarks of varying sizes.", "published": "2025-06-17 10:39:42", "link": "http://arxiv.org/abs/2506.14391v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning", "abstract": "Existing work on mitigating catastrophic forgetting in large language model\n(LLM) fine-tuning has primarily focused on preserving specific data or tasks,\nwhile critically overlooking the degradation of essential capabilities\ninstilled through safety alignment, particularly the model's ability to\nfaithfully express ignorance. In this work, we show that this capability is\nsignificantly degraded during conventional fine-tuning, leading to undesired\nbehaviors such as hallucinations. To address this novel but highly practical\nproblem, we propose SEAT, a simple and effective fine-tuning approach that\npreserves both fine-tuning performance and the model's inherent ability to\nacknowledge its ignorance. SEAT integrates two key components: (1) sparse\ntraining that constrains activation drift, and (2) a novel entity perturbation\nmethod with KL-divergence regularization, designed to counter knowledge\nentanglement. Experimental results demonstrate that SEAT significantly\noutperforms baselines in preserving ignorance awareness while retaining\nfine-tuning performance, offering a more robust solution for LLM fine-tuning.", "published": "2025-06-17 10:33:23", "link": "http://arxiv.org/abs/2506.14387v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ResNets Are Deeper Than You Think", "abstract": "Residual connections remain ubiquitous in modern neural network architectures\nnearly a decade after their introduction. Their widespread adoption is often\ncredited to their dramatically improved trainability: residual networks train\nfaster, more stably, and achieve higher accuracy than their feedforward\ncounterparts. While numerous techniques, ranging from improved initialization\nto advanced learning rate schedules, have been proposed to close the\nperformance gap between residual and feedforward networks, this gap has\npersisted. In this work, we propose an alternative explanation: residual\nnetworks do not merely reparameterize feedforward networks, but instead inhabit\na different function space. We design a controlled post-training comparison to\nisolate generalization performance from trainability; we find that\nvariable-depth architectures, similar to ResNets, consistently outperform\nfixed-depth networks, even when optimization is unlikely to make a difference.\nThese results suggest that residual connections confer performance advantages\nbeyond optimization, pointing instead to a deeper inductive bias aligned with\nthe structure of natural data.", "published": "2025-06-17 10:33:22", "link": "http://arxiv.org/abs/2506.14386v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DepthSeg: Depth prompting in remote sensing semantic segmentation", "abstract": "Remote sensing semantic segmentation is crucial for extracting detailed land\nsurface information, enabling applications such as environmental monitoring,\nland use planning, and resource assessment. In recent years, advancements in\nartificial intelligence have spurred the development of automatic remote\nsensing semantic segmentation methods. However, the existing semantic\nsegmentation methods focus on distinguishing spectral characteristics of\ndifferent objects while ignoring the differences in the elevation of the\ndifferent targets. This results in land cover misclassification in complex\nscenarios involving shadow occlusion and spectral confusion. In this paper, we\nintroduce a depth prompting two-dimensional (2D) remote sensing semantic\nsegmentation framework (DepthSeg). It automatically models depth/height\ninformation from 2D remote sensing images and integrates it into the semantic\nsegmentation framework to mitigate the effects of spectral confusion and shadow\nocclusion. During the feature extraction phase of DepthSeg, we introduce a\nlightweight adapter to enable cost-effective fine-tuning of the large-parameter\nvision transformer encoder pre-trained by natural images. In the depth\nprompting phase, we propose a depth prompter to model depth/height features\nexplicitly. In the semantic prediction phase, we introduce a semantic\nclassification decoder that couples the depth prompts with high-dimensional\nland-cover features, enabling accurate extraction of land-cover types.\nExperiments on the LiuZhou dataset validate the advantages of the DepthSeg\nframework in land cover mapping tasks. Detailed ablation studies further\nhighlight the significance of the depth prompts in remote sensing semantic\nsegmentation.", "published": "2025-06-17 10:27:59", "link": "http://arxiv.org/abs/2506.14382v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards", "abstract": "Invasive mechanical ventilation (MV) is a life-sustaining therapy for\ncritically ill patients in the intensive care unit (ICU). However, optimizing\nits settings remains a complex and error-prone process due to patient-specific\nvariability. While Offline Reinforcement Learning (RL) shows promise for MV\ncontrol, current stateof-the-art (SOTA) methods struggle with the hybrid\n(continuous and discrete) nature of MV actions. Discretizing the action space\nlimits available actions due to exponential growth in combinations and\nintroduces distribution shifts that can compromise safety. In this paper, we\npropose optimizations that build upon prior work in action space reduction to\naddress the challenges of discrete action spaces. We also adapt SOTA offline RL\nalgorithms (IQL and EDAC) to operate directly on hybrid action spaces, thereby\navoiding the pitfalls of discretization. Additionally, we introduce a\nclinically grounded reward function based on ventilator-free days and\nphysiological targets, which provides a more meaningful optimization objective\ncompared to traditional sparse mortality-based rewards. Our findings\ndemonstrate that AI-assisted MV optimization may enhance patient safety and\nenable individualized lung support, representing a significant advancement\ntoward intelligent, data-driven critical care solutions.", "published": "2025-06-17 10:17:26", "link": "http://arxiv.org/abs/2506.14375v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization", "abstract": "Egocentric video-language understanding demands both high efficiency and\naccurate spatial-temporal modeling. Existing approaches face three key\nchallenges: 1) Excessive pre-training cost arising from multi-stage\npre-training pipelines, 2) Ineffective spatial-temporal encoding due to\nmanually split 3D rotary positional embeddings that hinder feature\ninteractions, and 3) Imprecise learning objectives in soft-label multi-instance\nretrieval, which neglect negative pair correlations. In this paper, we\nintroduce EVA02-AT, a suite of EVA02-based video-language foundation models\ntailored to egocentric video understanding tasks. EVA02-AT first efficiently\ntransfers an image-based CLIP model into a unified video encoder via a\nsingle-stage pretraining. Second, instead of applying rotary positional\nembeddings to isolated dimensions, we introduce spatial-temporal rotary\npositional embeddings along with joint attention, which can effectively encode\nboth spatial and temporal information on the entire hidden dimension. This\njoint encoding of spatial-temporal features enables the model to learn\ncross-axis relationships, which are crucial for accurately modeling motion and\ninteraction in videos. Third, focusing on multi-instance video-language\nretrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and a\nnovel training framework that advances all soft labels for both positive and\nnegative pairs, providing a more precise learning objective. Extensive\nexperiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot and\nfine-tuning settings demonstrate that EVA02-AT achieves state-of-the-art\nperformance across diverse egocentric video-language tasks with fewer\nparameters. Models with our SMS loss also show significant performance gains on\nmulti-instance retrieval benchmarks. Our code and models are publicly available\nat https://github.com/xqwang14/EVA02-AT .", "published": "2025-06-17 09:51:51", "link": "http://arxiv.org/abs/2506.14356v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLM-Powered Intent-Based Categorization of Phishing Emails", "abstract": "Phishing attacks remain a significant threat to modern cybersecurity, as they\nsuccessfully deceive both humans and the defense mechanisms intended to protect\nthem. Traditional detection systems primarily focus on email metadata that\nusers cannot see in their inboxes. Additionally, these systems struggle with\nphishing emails, which experienced users can often identify empirically by the\ntext alone. This paper investigates the practical potential of Large Language\nModels (LLMs) to detect these emails by focusing on their intent. In addition\nto the binary classification of phishing emails, the paper introduces an\nintent-type taxonomy, which is operationalized by the LLMs to classify emails\ninto distinct categories and, therefore, generate actionable threat\ninformation. To facilitate our work, we have curated publicly available\ndatasets into a custom dataset containing a mix of legitimate and phishing\nemails. Our results demonstrate that existing LLMs are capable of detecting and\ncategorizing phishing emails, underscoring their potential in this domain.", "published": "2025-06-17 09:21:55", "link": "http://arxiv.org/abs/2506.14337v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "AviationLLM: An LLM-based Knowledge System for Aviation Training", "abstract": "Aviation training is a core link in ensuring flight safety, improving\nindustry efficiency and promoting sustainable development. It not only involves\nflight simulation but also requires the learning of a great deal of\nprofessional aviation theory knowledge. In the existing training system, the\nknowledge is mainly imparted by the the instructors. However, the number of\ninstructors is limited and the professional answers obtained from the Internet\nare not accurate enough, resulting in low training efficiency. To address this,\nwe introduced LLM, but the basic pre-trained model cannot provide accurate\nanswers to professional fields, so we fine-tuned it. Traditional Supervised\nFine-Tuning (SFT) risk generating superficially plausible but factually\nincorrect responses due to insufficient data coverage. To address this, we\nemploy Direct Preference Optimization(DPO). This paper proposes\nRetrieval-Augmented LLM Alignment via Direct Preference Optimization(RALA-DPO).\nWe select open source pre-trained LLM Qwen and adapt it to aviation theory\ntraining through DPO-based domain alignment. Simultaneously, to mitigate\nhallucinations caused by training data biases, knowledge obsolescence, or\ndomain knowledge gaps, we implement Retrieval-Augmented Generation(RAG)\ntechnology that combines generative and retrieval models. RALA-DPO effectively\nretrieves relevant information from external knowledge bases and delivers\nprecise and high-quality responses through the generative model. Experimental\nresults demonstrate that RALA-DPO can improve accuracy in response to\nprofessional aviation knowledge. With integrated RAG mechanisms, this system\ncan further improve the accuracy of answers and achieve zero-cost knowledge\nupdates simultaneously.", "published": "2025-06-17 09:20:09", "link": "http://arxiv.org/abs/2506.14336v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adjustment for Confounding using Pre-Trained Representations", "abstract": "There is growing interest in extending average treatment effect (ATE)\nestimation to incorporate non-tabular data, such as images and text, which may\nact as sources of confounding. Neglecting these effects risks biased results\nand flawed scientific conclusions. However, incorporating non-tabular data\nnecessitates sophisticated feature extractors, often in combination with ideas\nof transfer learning. In this work, we investigate how latent features from\npre-trained neural networks can be leveraged to adjust for sources of\nconfounding. We formalize conditions under which these latent features enable\nvalid adjustment and statistical inference in ATE estimation, demonstrating\nresults along the example of double machine learning. We discuss critical\nchallenges inherent to latent feature learning and downstream parameter\nestimation arising from the high dimensionality and non-identifiability of\nrepresentations. Common structural assumptions for obtaining fast convergence\nrates with additive or sparse linear models are shown to be unrealistic for\nlatent features. We argue, however, that neural networks are largely\ninsensitive to these issues. In particular, we show that neural networks can\nachieve fast convergence rates by adapting to intrinsic notions of sparsity and\ndimension of the learning problem.", "published": "2025-06-17 09:11:17", "link": "http://arxiv.org/abs/2506.14329v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels", "abstract": "Deep learning in medical imaging faces obstacles: limited data diversity,\nethical issues, high acquisition costs, and the need for precise annotations.\nBleeding detection and localization during surgery is especially challenging\ndue to the scarcity of high-quality datasets that reflect real surgical\nscenarios. We propose orGAN, a GAN-based system for generating high-fidelity,\nannotated surgical images of bleeding. By leveraging small \"mimicking organ\"\ndatasets, synthetic models that replicate tissue properties and bleeding, our\napproach reduces ethical concerns and data-collection costs. orGAN builds on\nStyleGAN with Relational Positional Learning to simulate bleeding events\nrealistically and mark bleeding coordinates. A LaMa-based inpainting module\nthen restores clean, pre-bleed visuals, enabling precise pixel-level\nannotations. In evaluations, a balanced dataset of orGAN and mimicking-organ\nimages achieved 90% detection accuracy in surgical settings and up to 99%\nframe-level accuracy. While our development data lack diverse organ\nmorphologies and contain intraoperative artifacts, orGAN markedly advances\nethical, efficient, and cost-effective creation of realistic annotated bleeding\ndatasets, supporting broader integration of AI in surgical practice.", "published": "2025-06-17 08:29:40", "link": "http://arxiv.org/abs/2506.14303v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems", "abstract": "How to construct an interpretable autonomous driving decision-making system\nhas become a focal point in academic research. In this study, we propose a\nnovel approach that leverages large language models (LLMs) to generate\nexecutable, rule-based decision systems to address this challenge.\nSpecifically, harnessing the strong reasoning and programming capabilities of\nLLMs, we introduce the ADRD(LLM-Driven Autonomous Driving Based on Rule-based\nDecision Systems) framework, which integrates three core modules: the\nInformation Module, the Agents Module, and the Testing Module. The framework\noperates by first aggregating contextual driving scenario information through\nthe Information Module, then utilizing the Agents Module to generate rule-based\ndriving tactics. These tactics are iteratively refined through continuous\ninteraction with the Testing Module. Extensive experimental evaluations\ndemonstrate that ADRD exhibits superior performance in autonomous driving\ndecision tasks. Compared to traditional reinforcement learning approaches and\nthe most advanced LLM-based methods, ADRD shows significant advantages in terms\nof interpretability, response speed, and driving performance. These results\nhighlight the framework's ability to achieve comprehensive and accurate\nunderstanding of complex driving scenarios, and underscore the promising future\nof transparent, rule-based decision systems that are easily modifiable and\nbroadly applicable. To the best of our knowledge, this is the first work that\nintegrates large language models with rule-based systems for autonomous driving\ndecision-making, and our findings validate its potential for real-world\ndeployment.", "published": "2025-06-17 08:18:20", "link": "http://arxiv.org/abs/2506.14299v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Uncertainty-Driven Radar-Inertial Fusion for Instantaneous 3D Ego-Velocity Estimation", "abstract": "We present a method for estimating ego-velocity in autonomous navigation by\nintegrating high-resolution imaging radar with an inertial measurement unit.\nThe proposed approach addresses the limitations of traditional radar-based\nego-motion estimation techniques by employing a neural network to process\ncomplex-valued raw radar data and estimate instantaneous linear ego-velocity\nalong with its associated uncertainty. This uncertainty-aware velocity estimate\nis then integrated with inertial measurement unit data using an Extended Kalman\nFilter. The filter leverages the network-predicted uncertainty to refine the\ninertial sensor's noise and bias parameters, improving the overall robustness\nand accuracy of the ego-motion estimation. We evaluated the proposed method on\nthe publicly available ColoRadar dataset. Our approach achieves significantly\nlower error compared to the closest publicly available method and also\noutperforms both instantaneous and scan matching-based techniques.", "published": "2025-06-17 08:10:39", "link": "http://arxiv.org/abs/2506.14294v1", "categories": ["cs.RO", "cs.AI", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Steering Robots with Inference-Time Interactions", "abstract": "Imitation learning has driven the development of generalist policies capable\nof autonomously solving multiple tasks. However, when a pretrained policy makes\nerrors during deployment, there are limited mechanisms for users to correct its\nbehavior. While collecting additional data for finetuning can address such\nissues, doing so for each downstream use case is inefficient at deployment. My\nresearch proposes an alternative: keeping pretrained policies frozen as a fixed\nskill repertoire while allowing user interactions to guide behavior generation\ntoward user preferences at inference time. By making pretrained policies\nsteerable, users can help correct policy errors when the model struggles to\ngeneralize-without needing to finetune the policy. Specifically, I propose (1)\ninference-time steering, which leverages user interactions to switch between\ndiscrete skills, and (2) task and motion imitation, which enables user\ninteractions to edit continuous motions while satisfying task constraints\ndefined by discrete symbolic plans. These frameworks correct misaligned policy\npredictions without requiring additional training, maximizing the utility of\npretrained models while achieving inference-time user objectives.", "published": "2025-06-17 07:59:07", "link": "http://arxiv.org/abs/2506.14287v1", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Don't throw the baby out with the bathwater: How and why deep learning for ARC", "abstract": "The Abstraction and Reasoning Corpus (ARC-AGI) presents a formidable\nchallenge for AI systems. Despite the typically low performance on ARC, the\ndeep learning paradigm remains the most effective known strategy for generating\nskillful (state-of-the-art) neural networks (NN) across varied modalities and\ntasks in vision, language etc. The deep learning paradigm has proven to be able\nto train these skillful neural networks and learn the abstractions needed in\nthese diverse domains. Our work doubles down on that and continues to leverage\nthis paradigm by incorporating on-the-fly NN training at test time. We\ndemonstrate that fully committing to deep learning's capacity to acquire novel\nabstractions yields state-of-the-art performance on ARC. Specifically, we treat\nboth the neural network and the optimizer (rather than just a pre-trained\nnetwork) as integral components of the inference process, fostering\ngeneralization to unseen tasks. Concretely, we propose a methodology for\ntraining on ARC, starting from pretrained LLMs, and enhancing their ARC\nreasoning. We also propose Test-Time Fine-Tuning (TTFT) and the Augment\nInference Reverse-Augmentation and Vote (AIRV) as effective test-time\ntechniques. We are the first to propose and show deep learning can be used\neffectively for ARC, showing boosts of up to 260% in accuracy with AIRV and a\nfurther 300% boost with TTFT. An early version of this approach secured first\nplace in the 2023 ARCathon competition, while the final version achieved the\ncurrent best score on the ARC private test-set (58%). Our findings highlight\nthe key ingredients of a robust reasoning system in unfamiliar domains,\nunderscoring the central mechanisms that improve broad perceptual reasoning.", "published": "2025-06-17 07:40:39", "link": "http://arxiv.org/abs/2506.14276v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Knowledge Adaptation as Posterior Correction", "abstract": "Adaptation is the holy grail of intelligence, but even the best AI models\n(like GPT) lack the adaptivity of toddlers. So the question remains: how can\nmachines adapt quickly? Despite a lot of progress on model adaptation to\nfacilitate continual and federated learning, as well as model merging, editing,\nunlearning, etc., little is known about the mechanisms by which machines can\nnaturally learn to adapt in a similar way as humans and animals. Here, we show\nthat all such adaptation methods can be seen as different ways of `correcting'\nthe approximate posteriors. More accurate posteriors lead to smaller\ncorrections, which in turn imply quicker adaptation. The result is obtained by\nusing a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023)\nwhere interference created during adaptation is characterized by the\nnatural-gradient mismatch over the past data. We present many examples to\ndemonstrate the use of posterior-correction as a natural mechanism for the\nmachines to learn to adapt quickly.", "published": "2025-06-17 07:22:32", "link": "http://arxiv.org/abs/2506.14262v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents", "abstract": "People need to internalize the skills of AI agents to improve their own\ncapabilities. Our paper focuses on Mahjong, a multiplayer game involving\nimperfect information and requiring effective long-term decision-making amidst\nrandomness and hidden information. Through the efforts of AI researchers,\nseveral impressive Mahjong AI agents have already achieved performance levels\ncomparable to those of professional human players; however, these agents are\noften treated as black boxes from which few insights can be gleaned. This paper\nintroduces Mxplainer, a parameterized search algorithm that can be converted\ninto an equivalent neural network to learn the parameters of black-box agents.\nExperiments conducted on AI and human player data demonstrate that the learned\nparameters provide human-understandable insights into these agents'\ncharacteristics and play styles. In addition to analyzing the learned\nparameters, we also showcase how our search-based framework can locally explain\nthe decision-making processes of black-box agents for most Mahjong game states.", "published": "2025-06-17 07:07:13", "link": "http://arxiv.org/abs/2506.14246v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?", "abstract": "We propose a test for abstract causal reasoning in AI, based on scholarship\nin the philosophy of causation, in particular on the neuron diagrams\npopularized by D. Lewis. We illustrate the test on advanced Large Language\nModels (ChatGPT, DeepSeek and Gemini). Remarkably, these chatbots are already\ncapable of correctly identifying causes in cases that are hotly debated in the\nliterature. In order to assess the results of these LLMs and future dedicated\nAI, we propose a definition of cause in neuron diagrams with a wider validity\nthan published hitherto, which challenges the widespread view that such a\ndefinition is elusive. We submit that these results are an illustration of how\nfuture philosophical research might evolve: as an interplay between human and\nartificial expertise.", "published": "2025-06-17 06:55:54", "link": "http://arxiv.org/abs/2506.14239v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ImpReSS: Implicit Recommender System for Support Conversations", "abstract": "Following recent advancements in large language models (LLMs), LLM-based\nchatbots have transformed customer support by automating interactions and\nproviding consistent, scalable service. While LLM-based conversational\nrecommender systems (CRSs) have attracted attention for their ability to\nenhance the quality of recommendations, limited research has addressed the\nimplicit integration of recommendations within customer support interactions.\nIn this work, we introduce ImpReSS, an implicit recommender system designed for\ncustomer support conversations. ImpReSS operates alongside existing support\nchatbots, where users report issues and chatbots provide solutions. Based on a\ncustomer support conversation, ImpReSS identifies opportunities to recommend\nrelevant solution product categories (SPCs) that help resolve the issue or\nprevent its recurrence -- thereby also supporting business growth. Unlike\ntraditional CRSs, ImpReSS functions entirely implicitly and does not rely on\nany assumption of a user's purchasing intent. Our empirical evaluation of\nImpReSS's ability to recommend relevant SPCs that can help address issues\nraised in support conversations shows promising results, including an MRR@1\n(and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for\ninformation security support, and 0.85 (0.67) for cybersecurity\ntroubleshooting. To support future research, our data and code will be shared\nupon request.", "published": "2025-06-17 06:38:46", "link": "http://arxiv.org/abs/2506.14231v1", "categories": ["cs.AI", "cs.IR"], "primary_category": "cs.AI"}
{"title": "HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction", "abstract": "3D Gaussian Splatting (3DGS) has made significant strides in real-time 3D\nscene reconstruction, but faces memory scalability issues in high-resolution\nscenarios. To address this, we propose Hierarchical Gaussian Splatting (HRGS),\na memory-efficient framework with hierarchical block-level optimization. First,\nwe generate a global, coarse Gaussian representation from low-resolution data.\nThen, we partition the scene into multiple blocks, refining each block with\nhigh-resolution data. The partitioning involves two steps: Gaussian\npartitioning, where irregular scenes are normalized into a bounded cubic space\nwith a uniform grid for task distribution, and training data partitioning,\nwhere only relevant observations are retained for each block. By guiding block\nrefinement with the coarse Gaussian prior, we ensure seamless Gaussian fusion\nacross adjacent blocks. To reduce computational demands, we introduce\nImportance-Driven Gaussian Pruning (IDGP), which computes importance scores for\neach Gaussian and removes those with minimal contribution, speeding up\nconvergence and reducing memory usage. Additionally, we incorporate normal\npriors from a pretrained model to enhance surface reconstruction quality. Our\nmethod enables high-quality, high-resolution 3D scene reconstruction even under\nmemory constraints. Extensive experiments on three benchmarks show that HRGS\nachieves state-of-the-art performance in high-resolution novel view synthesis\n(NVS) and surface reconstruction tasks.", "published": "2025-06-17 06:35:38", "link": "http://arxiv.org/abs/2506.14229v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models", "abstract": "As large language models evolve, there is growing anticipation that they will\nemulate human-like Theory of Mind (ToM) to assist with routine tasks. However,\nexisting methods for evaluating machine ToM focus primarily on unimodal models\nand largely treat these models as black boxes, lacking an interpretative\nexploration of their internal mechanisms. In response, this study adopts an\napproach based on internal mechanisms to provide an interpretability-driven\nassessment of ToM in multimodal large language models (MLLMs). Specifically, we\nfirst construct a multimodal ToM test dataset, GridToM, which incorporates\ndiverse belief testing tasks and perceptual information from multiple\nperspectives. Next, our analysis shows that attention heads in multimodal large\nmodels can distinguish cognitive information across perspectives, providing\nevidence of ToM capabilities. Furthermore, we present a lightweight,\ntraining-free approach that significantly enhances the model's exhibited ToM by\nadjusting in the direction of the attention head.", "published": "2025-06-17 06:27:42", "link": "http://arxiv.org/abs/2506.14224v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift", "abstract": "Deep neural networks often achieve high accuracy, but ensuring their\nreliability under adversarial and distributional shifts remains a pressing\nchallenge. We propose TriGuard, a unified safety evaluation framework that\ncombines (1) formal robustness verification, (2) attribution entropy to\nquantify saliency concentration, and (3) a novel Attribution Drift Score\nmeasuring explanation stability. TriGuard reveals critical mismatches between\nmodel accuracy and interpretability: verified models can still exhibit unstable\nreasoning, and attribution-based signals provide complementary safety insights\nbeyond adversarial accuracy. Extensive experiments across three datasets and\nfive architectures show how TriGuard uncovers subtle fragilities in neural\nreasoning. We further demonstrate that entropy-regularized training reduces\nexplanation drift without sacrificing performance. TriGuard advances the\nfrontier in robust, interpretable model evaluation.", "published": "2025-06-17 06:12:36", "link": "http://arxiv.org/abs/2506.14217v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "What's in the Box? Reasoning about Unseen Objects from Multimodal Cues", "abstract": "People regularly make inferences about objects in the world that they cannot\nsee by flexibly integrating information from multiple sources: auditory and\nvisual cues, language, and our prior beliefs and knowledge about the scene. How\nare we able to so flexibly integrate many sources of information to make sense\nof the world around us, even if we have no direct knowledge? In this work, we\npropose a neurosymbolic model that uses neural networks to parse open-ended\nmultimodal inputs and then applies a Bayesian model to integrate different\nsources of information to evaluate different hypotheses. We evaluate our model\nwith a novel object guessing game called ``What's in the Box?'' where humans\nand models watch a video clip of an experimenter shaking boxes and then try to\nguess the objects inside the boxes. Through a human experiment, we show that\nour model correlates strongly with human judgments, whereas unimodal ablated\nmodels and large multimodal neural model baselines show poor correlation.", "published": "2025-06-17 06:03:44", "link": "http://arxiv.org/abs/2506.14212v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT", "abstract": "Advances in treatment technology now allow for the use of customizable\n3D-printed hydrogel wound dressings for patients with osteoradionecrosis (ORN)\nof the jaw (ONJ). Meanwhile, deep learning has enabled precise segmentation of\n3D medical images using tools like nnUNet.\n  However, the scarcity of labeled data in ONJ imaging makes supervised\ntraining impractical. This study aims to develop an unsupervised training\napproach for automatically identifying anomalies in imaging scans.\n  We propose a novel two-stage training pipeline. In the first stage, a VQ-GAN\nis trained to accurately reconstruct normal subjects. In the second stage,\nrandom cube masking and ONJ-specific masking are applied to train a new encoder\ncapable of recovering the data.\n  The proposed method achieves successful segmentation on both simulated and\nreal patient data.\n  This approach provides a fast initial segmentation solution, reducing the\nburden of manual labeling. Additionally, it has the potential to be directly\nused for 3D printing when combined with hand-tuned post-processing.", "published": "2025-06-17 05:58:04", "link": "http://arxiv.org/abs/2506.14209v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion", "abstract": "Training large neural networks with end-to-end backpropagation creates\nsignificant memory bottlenecks, limiting accessibility to state-of-the-art AI\nresearch. We propose $\\textit{DiffusionBlocks}$, a novel training framework\nthat interprets neural network blocks as performing denoising operations in a\ncontinuous-time diffusion process. By partitioning the network into\nindependently trainable blocks and optimizing noise level assignments based on\nequal cumulative probability mass, our approach achieves significant memory\nefficiency while maintaining competitive performance compared to traditional\nbackpropagation in generative tasks. Experiments on image generation and\nlanguage modeling tasks demonstrate memory reduction proportional to the number\nof blocks while achieving superior performance. DiffusionBlocks provides a\npromising pathway for democratizing access to large-scale neural network\ntraining with limited computational resources.", "published": "2025-06-17 05:44:18", "link": "http://arxiv.org/abs/2506.14202v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Balancing Caregiving and Self-Care: Exploring Mental Health Needs of Alzheimer's and Dementia Caregivers", "abstract": "Alzheimer's Disease and Related Dementias (AD/ADRD) are progressive\nneurodegenerative conditions that impair memory, thought processes, and\nfunctioning. Family caregivers of individuals with AD/ADRD face significant\nmental health challenges due to long-term caregiving responsibilities. Yet,\ncurrent support systems often overlook the evolving nature of their mental\nwellbeing needs. Our study examines caregivers' mental wellbeing concerns,\nfocusing on the practices they adopt to manage the burden of caregiving and the\ntechnologies they use for support. Through semi-structured interviews with 25\nfamily caregivers of individuals with AD/ADRD, we identified the key causes and\neffects of mental health challenges, and developed a temporal mapping of how\ncaregivers' mental wellbeing evolves across three distinct stages of the\ncaregiving journey. Additionally, our participants shared insights into\nimprovements for existing mental health technologies, emphasizing the need for\naccessible, scalable, and personalized solutions that adapt to caregivers'\nchanging needs over time. These findings offer a foundation for designing\ndynamic, stage-sensitive interventions that holistically support caregivers'\nmental wellbeing, benefiting both caregivers and care recipients.", "published": "2025-06-17 05:25:12", "link": "http://arxiv.org/abs/2506.14196v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "A multi-stage augmented multimodal interaction network for fish feeding intensity quantification", "abstract": "In recirculating aquaculture systems, accurate and effective assessment of\nfish feeding intensity is crucial for reducing feed costs and calculating\noptimal feeding times. However, current studies have limitations in modality\nselection, feature extraction and fusion, and co-inference for decision making,\nwhich restrict further improvement in the accuracy, applicability and\nreliability of multimodal fusion models. To address this problem, this study\nproposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for\nquantifying fish feeding intensity. Firstly, a general feature extraction\nframework is proposed to efficiently extract feature information from input\nimage, audio and water wave datas. Second, an Auxiliary-modality Reinforcement\nPrimary-modality Mechanism (ARPM) is designed for inter-modal interaction and\ngenerate enhanced features, which consists of a Channel Attention Fusion\nNetwork (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an\nEvidence Reasoning (ER) rule is introduced to fuse the output results of each\nmodality and make decisions, thereby completing the quantification of fish\nfeeding intensity. The experimental results show that the constructed MAINet\nreaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and\nF1-Score respectively, and its performance is significantly higher than the\ncomparison models. Compared with models that adopt single-modality,\ndual-modality fusion and different decision-making fusion methods, it also has\nobvious advantages. Meanwhile, the ablation experiments further verified the\nkey role of the proposed improvement strategy in improving the robustness and\nfeature utilization efficiency of model, which can effectively improve the\naccuracy of the quantitative results of fish feeding intensity.", "published": "2025-06-17 04:09:43", "link": "http://arxiv.org/abs/2506.14170v1", "categories": ["cs.CV", "cs.AI", "cs.ET"], "primary_category": "cs.CV"}
{"title": "VideoMAR: Autoregressive Video Generatio with Continuous Tokens", "abstract": "Masked-based autoregressive models have demonstrated promising image\ngeneration capability in continuous space. However, their potential for video\ngeneration remains under-explored. In this paper, we propose \\textbf{VideoMAR},\na concise and efficient decoder-only autoregressive image-to-video model with\ncontinuous tokens, composing temporal frame-by-frame and spatial masked\ngeneration. We first identify temporal causality and spatial bi-directionality\nas the first principle of video AR models, and propose the next-frame diffusion\nloss for the integration of mask and video generation. Besides, the huge cost\nand difficulty of long sequence autoregressive modeling is a basic but crucial\nissue. To this end, we propose the temporal short-to-long curriculum learning\nand spatial progressive resolution training, and employ progressive temperature\nstrategy at inference time to mitigate the accumulation error. Furthermore,\nVideoMAR replicates several unique capacities of language models to video\ngeneration. It inherently bears high efficiency due to simultaneous\ntemporal-wise KV cache and spatial-wise parallel generation, and presents the\ncapacity of spatial and temporal extrapolation via 3D rotary embeddings. On the\nVBench-I2V benchmark, VideoMAR surpasses the previous state-of-the-art (Cosmos\nI2V) while requiring significantly fewer parameters ($9.3\\%$), training data\n($0.5\\%$), and GPU resources ($0.2\\%$).", "published": "2025-06-17 04:08:18", "link": "http://arxiv.org/abs/2506.14168v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework", "abstract": "Every individual carries a unique and personal life story shaped by their\nmemories and experiences. However, these memories are often scattered and\ndifficult to organize into a coherent narrative, a challenge that defines the\ntask of autobiography writing. Existing conversational writing assistants tend\nto rely on generic user interactions and pre-defined guidelines, making it\ndifficult for these systems to capture personal memories and develop a complete\nbiography over time. We introduce StorySage, a user-driven software system\ndesigned to meet the needs of a diverse group of users that supports a flexible\nconversation and a structured approach to autobiography writing. Powered by a\nmulti-agent framework composed of an Interviewer, Session Scribe, Planner,\nSection Writer, and Session Coordinator, our system iteratively collects user\nmemories, updates their autobiography, and plans for future conversations. In\nexperimental simulations, StorySage demonstrates its ability to navigate\nmultiple sessions and capture user memories across many conversations. User\nstudies (N=28) highlight how StorySage maintains improved conversational flow,\nnarrative completeness, and higher user satisfaction when compared to a\nbaseline. In summary, StorySage contributes both a novel architecture for\nautobiography writing and insights into how multi-agent systems can enhance\nhuman-AI creative partnerships.", "published": "2025-06-17 03:44:47", "link": "http://arxiv.org/abs/2506.14159v1", "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Collaborative Editable Model", "abstract": "Vertical-domain large language models (LLMs) play a crucial role in\nspecialized scenarios such as finance, healthcare, and law; however, their\ntraining often relies on large-scale annotated data and substantial\ncomputational resources, impeding rapid development and continuous iteration.\nTo address these challenges, we introduce the Collaborative Editable Model\n(CoEM), which constructs a candidate knowledge pool from user-contributed\ndomain snippets, leverages interactive user-model dialogues combined with user\nratings and attribution analysis to pinpoint high-value knowledge fragments,\nand injects these fragments via in-context prompts for lightweight domain\nadaptation. With high-value knowledge, the LLM can generate more accurate and\ndomain-specific content. In a financial information scenario, we collect 15k\nfeedback from about 120 users and validate CoEM with user ratings to assess the\nquality of generated insights, demonstrating significant improvements in\ndomain-specific generation while avoiding the time and compute overhead of\ntraditional fine-tuning workflows.", "published": "2025-06-17 03:20:41", "link": "http://arxiv.org/abs/2506.14146v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability", "abstract": "Accurate prediction of pedestrian trajectories is essential for applications\nin robotics and surveillance systems. While existing approaches primarily focus\non social interactions between pedestrians, they often overlook the rich\nenvironmental context that significantly shapes human movement patterns. In\nthis paper, we propose SceneAware, a novel framework that explicitly\nincorporates scene understanding to enhance trajectory prediction accuracy. Our\nmethod leverages a Vision Transformer~(ViT) scene encoder to process\nenvironmental context from static scene images, while Multi-modal Large\nLanguage Models~(MLLMs) generate binary walkability masks that distinguish\nbetween accessible and restricted areas during training. We combine a\nTransformer-based trajectory encoder with the ViT-based scene encoder,\ncapturing both temporal dynamics and spatial constraints. The framework\nintegrates collision penalty mechanisms that discourage predicted trajectories\nfrom violating physical boundaries, ensuring physically plausible predictions.\nSceneAware is implemented in both deterministic and stochastic variants.\nComprehensive experiments on the ETH/UCY benchmark datasets show that our\napproach outperforms state-of-the-art methods, with more than 50\\% improvement\nover previous models. Our analysis based on different trajectory categories\nshows that the model performs consistently well across various types of\npedestrian movement. This highlights the importance of using explicit scene\ninformation and shows that our scene-aware approach is both effective and\nreliable in generating accurate and physically plausible predictions. Code is\navailable at: https://github.com/juho127/SceneAware.", "published": "2025-06-17 03:11:31", "link": "http://arxiv.org/abs/2506.14144v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning", "abstract": "Spiking Neural Networks (SNNs) are computational models inspired by the\nstructure and dynamics of biological neuronal networks. Their event-driven\nnature enables them to achieve high energy efficiency, particularly when\ndeployed on neuromorphic hardware platforms. Unlike conventional Artificial\nNeural Networks (ANNs), which primarily rely on layered architectures, SNNs\nnaturally support a wide range of connectivity patterns, from traditional\nlayered structures to small-world graphs characterized by locally dense and\nglobally sparse connections. In this work, we introduce NeuroCoreX, an\nFPGA-based emulator designed for the flexible co-design and testing of SNNs.\nNeuroCoreX supports all-to-all connectivity, providing the capability to\nimplement diverse network topologies without architectural restrictions. It\nfeatures a biologically motivated local learning mechanism based on\nSpike-Timing-Dependent Plasticity (STDP). The neuron model implemented within\nNeuroCoreX is the Leaky Integrate-and-Fire (LIF) model, with current-based\nsynapses facilitating spike integration and transmission . A Universal\nAsynchronous Receiver-Transmitter (UART) interface is provided for programming\nand configuring the network parameters, including neuron, synapse, and learning\nrule settings. Users interact with the emulator through a simple Python-based\ninterface, streamlining SNN deployment from model design to hardware execution.\nNeuroCoreX is released as an open-source framework, aiming to accelerate\nresearch and development in energy-efficient, biologically inspired computing.", "published": "2025-06-17 03:02:04", "link": "http://arxiv.org/abs/2506.14138v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "KDMOS:Knowledge Distillation for Motion Segmentation", "abstract": "Motion Object Segmentation (MOS) is crucial for autonomous driving, as it\nenhances localization, path planning, map construction, scene flow estimation,\nand future state prediction. While existing methods achieve strong performance,\nbalancing accuracy and real-time inference remains a challenge. To address\nthis, we propose a logits-based knowledge distillation framework for MOS,\naiming to improve accuracy while maintaining real-time efficiency.\nSpecifically, we adopt a Bird's Eye View (BEV) projection-based model as the\nstudent and a non-projection model as the teacher. To handle the severe\nimbalance between moving and non-moving classes, we decouple them and apply\ntailored distillation strategies, allowing the teacher model to better learn\nkey motion-related features. This approach significantly reduces false\npositives and false negatives. Additionally, we introduce dynamic upsampling,\noptimize the network architecture, and achieve a 7.69% reduction in parameter\ncount, mitigating overfitting. Our method achieves a notable IoU of 78.8% on\nthe hidden test set of the SemanticKITTI-MOS dataset and delivers competitive\nresults on the Apollo dataset. The KDMOS implementation is available at\nhttps://github.com/SCNU-RISLAB/KDMOS.", "published": "2025-06-17 02:47:49", "link": "http://arxiv.org/abs/2506.14130v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Less is More: Undertraining Experts Improves Model Upcycling", "abstract": "Modern deep learning is increasingly characterized by the use of open-weight\nfoundation models that can be fine-tuned on specialized datasets. This has led\nto a proliferation of expert models and adapters, often shared via platforms\nlike HuggingFace and AdapterHub. To leverage these resources, numerous model\nupcycling methods have emerged, enabling the reuse of fine-tuned models in\nmulti-task systems. A natural pipeline has thus formed to harness the benefits\nof transfer learning and amortize sunk training costs: models are pre-trained\non general data, fine-tuned on specific tasks, and then upcycled into more\ngeneral-purpose systems. A prevailing assumption is that improvements at one\nstage of this pipeline propagate downstream, leading to gains at subsequent\nsteps. In this work, we challenge that assumption by examining how expert\nfine-tuning affects model upcycling. We show that long fine-tuning of experts\nthat optimizes for their individual performance leads to degraded merging\nperformance, both for fully fine-tuned and LoRA-adapted models, and to worse\ndownstream results when LoRA adapters are upcycled into MoE layers. We trace\nthis degradation to the memorization of a small set of difficult examples that\ndominate late fine-tuning steps and are subsequently forgotten during merging.\nFinally, we demonstrate that a task-dependent aggressive early stopping\nstrategy can significantly improve upcycling performance.", "published": "2025-06-17 02:42:10", "link": "http://arxiv.org/abs/2506.14126v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Situational-Constrained Sequential Resources Allocation via Reinforcement Learning", "abstract": "Sequential Resource Allocation with situational constraints presents a\nsignificant challenge in real-world applications, where resource demands and\npriorities are context-dependent. This paper introduces a novel framework,\nSCRL, to address this problem. We formalize situational constraints as logic\nimplications and develop a new algorithm that dynamically penalizes constraint\nviolations. To handle situational constraints effectively, we propose a\nprobabilistic selection mechanism to overcome limitations of traditional\nconstraint reinforcement learning (CRL) approaches. We evaluate SCRL across two\nscenarios: medical resource allocation during a pandemic and pesticide\ndistribution in agriculture. Experiments demonstrate that SCRL outperforms\nexisting baselines in satisfying constraints while maintaining high resource\nefficiency, showcasing its potential for real-world, context-sensitive\ndecision-making tasks.", "published": "2025-06-17 02:40:49", "link": "http://arxiv.org/abs/2506.14125v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs", "abstract": "Temporal Betweenness Centrality (TBC) measures how often a node appears on\noptimal temporal paths, reflecting its importance in temporal networks.\nHowever, exact computation is highly expensive, and real-world TBC\ndistributions are extremely imbalanced. The severe imbalance leads\nlearning-based models to overfit to zero-centrality nodes, resulting in\ninaccurate TBC predictions and failure to identify truly central nodes.\nExisting graph neural network (GNN) methods either fail to handle such\nimbalance or ignore temporal dependencies altogether. To address these issues,\nwe propose a scalable and inductive contrastive learning-based GNN (CLGNN) for\naccurate and efficient TBC prediction. CLGNN builds an instance graph to\npreserve path validity and temporal order, then encodes structural and temporal\nfeatures using dual aggregation, i.e., mean and edge-to-node multi-head\nattention mechanisms, enhanced by temporal path count and time encodings. A\nstability-based clustering-guided contrastive module (KContrastNet) is\nintroduced to separate high-, median-, and low-centrality nodes in\nrepresentation space, mitigating class imbalance, while a regression module\n(ValueNet) estimates TBC values. CLGNN also supports multiple optimal path\ndefinitions to accommodate diverse temporal semantics. Extensive experiments\ndemonstrate the effectiveness and efficiency of CLGNN across diverse\nbenchmarks. CLGNN achieves up to a 663.7~$\\times$ speedup compared to\nstate-of-the-art exact TBC computation methods. It outperforms leading static\nGNN baselines with up to 31.4~$\\times$ lower MAE and 16.7~$\\times$ higher\nSpearman correlation, and surpasses state-of-the-art temporal GNNs with up to\n5.7~$\\times$ lower MAE and 3.9~$\\times$ higher Spearman correlation.", "published": "2025-06-17 02:34:09", "link": "http://arxiv.org/abs/2506.14122v1", "categories": ["cs.LG", "cs.AI", "I.2.6; G.2.2; I.5.1"], "primary_category": "cs.LG"}
{"title": "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting", "abstract": "Koopman operator theory provides a framework for nonlinear dynamical system\nanalysis and time-series forecasting by mapping dynamics to a space of\nreal-valued measurement functions, enabling a linear operator representation.\nDespite the advantage of linearity, the operator is generally\ninfinite-dimensional. Therefore, the objective is to learn measurement\nfunctions that yield a tractable finite-dimensional Koopman operator\napproximation. In this work, we establish a connection between Koopman operator\napproximation and linear Recurrent Neural Networks (RNNs), which have recently\ndemonstrated remarkable success in sequence modeling. We show that by\nconsidering an extended state consisting of lagged observations, we can\nestablish an equivalence between a structured Koopman operator and linear RNN\nupdates. Building on this connection, we present SKOLR, which integrates a\nlearnable spectral decomposition of the input signal with a multilayer\nperceptron (MLP) as the measurement functions and implements a structured\nKoopman operator via a highly parallel linear RNN stack. Numerical experiments\non various forecasting benchmarks and dynamical systems show that this\nstreamlined, Koopman-theory-based design delivers exceptional performance.", "published": "2025-06-17 02:11:06", "link": "http://arxiv.org/abs/2506.14113v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks", "abstract": "A foundation model like GPT elicits many emergent abilities, owing to the\npre-training with broad inclusion of data and the use of the powerful\nTransformer architecture. While foundation models in natural languages are\nprevalent, can we build similar models for graphs? This paper describes an\napproach toward a graph foundation model that is pre-trained with diverse graph\ndatasets by adapting the Transformer backbone. A central challenge toward this\nend is how a sequence model encodes graphs of varying sizes and from different\ndomains. We propose representing a node as multiple random walks, such that the\nTransformer can extract node representations from sequences, which in turn form\nedge and graph representations. We develop a novel context prediction loss for\nthese random walks and theoretically analyze their expressive power in\ndistinguishing neighborhoods and graphs. We also demonstrate the pre-training\nof our model and its adaptation to downstream tasks, showcasing its potential\nas a foundation for processing and reasoning with graph-structured data.", "published": "2025-06-17 01:28:34", "link": "http://arxiv.org/abs/2506.14098v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion", "abstract": "Diffusion Policy (DP) enables robots to learn complex behaviors by imitating\nexpert demonstrations through action diffusion. However, in practical\napplications, hardware limitations often degrade data quality, while real-time\nconstraints restrict model inference to instantaneous state and scene\nobservations. These limitations seriously reduce the efficacy of learning from\nexpert demonstrations, resulting in failures in object localization, grasp\nplanning, and long-horizon task execution. To address these challenges, we\npropose Causal Diffusion Policy (CDP), a novel transformer-based diffusion\nmodel that enhances action prediction by conditioning on historical action\nsequences, thereby enabling more coherent and context-aware visuomotor policy\nlearning. To further mitigate the computational cost associated with\nautoregressive inference, a caching mechanism is also introduced to store\nattention key-value pairs from previous timesteps, substantially reducing\nredundant computations during execution. Extensive experiments in both\nsimulated and real-world environments, spanning diverse 2D and 3D manipulation\ntasks, demonstrate that CDP uniquely leverages historical action sequences to\nachieve significantly higher accuracy than existing methods. Moreover, even\nwhen faced with degraded input observation quality, CDP maintains remarkable\nprecision by reasoning through temporal continuity, which highlights its\npractical robustness for robotic control under realistic, imperfect conditions.", "published": "2025-06-17 17:59:12", "link": "http://arxiv.org/abs/2506.14769v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset", "abstract": "Today, Earth Observation (EO) satellites generate massive volumes of data,\nwith the Copernicus Sentinel-2 constellation alone producing approximately\n1.6TB per day. To fully exploit this information, it is essential to pretrain\nEO Foundation Models (FMs) on large unlabeled datasets, enabling efficient\nfine-tuning for several different downstream tasks with minimal labeled data.\nIn this work, we present the scaling-up of our recently proposed EO Foundation\nModel, PhilEO Geo-Aware U-Net, on the unlabeled 23TB dataset MajorTOM, which\ncovers the vast majority of the Earth's surface, as well as on the specialized\nsubset FastTOM 2TB that does not include oceans and ice. We develop and study\nvarious PhilEO model variants with different numbers of parameters and\narchitectures. Finally, we fine-tune the models on the PhilEO Bench for road\ndensity estimation, building density pixel-wise regression, and land cover\nsemantic segmentation, and we evaluate the performance. Our results demonstrate\nthat for all n-shots for road density regression, the PhilEO 44M MajorTOM 23TB\nmodel outperforms PhilEO Globe 0.5TB 44M. We also show that for most n-shots\nfor road density estimation and building density regression, PhilEO 200M\nFastTOM outperforms all the other models. The effectiveness of both dataset and\nmodel scaling is validated using the PhilEO Bench. We also study the impact of\narchitecture scaling, transitioning from U-Net Convolutional Neural Networks\n(CNN) to Vision Transformers (ViT).", "published": "2025-06-17 17:58:08", "link": "http://arxiv.org/abs/2506.14765v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cost-Aware Routing for Efficient Text-To-Image Generation", "abstract": "Diffusion models are well known for their ability to generate a high-fidelity\nimage for an input prompt through an iterative denoising process.\nUnfortunately, the high fidelity also comes at a high computational cost due\nthe inherently sequential generative process. In this work, we seek to\noptimally balance quality and computational cost, and propose a framework to\nallow the amount of computation to vary for each prompt, depending on its\ncomplexity. Each prompt is automatically routed to the most appropriate\ntext-to-image generation function, which may correspond to a distinct number of\ndenoising steps of a diffusion model, or a disparate, independent text-to-image\nmodel. Unlike uniform cost reduction techniques (e.g., distillation, model\nquantization), our approach achieves the optimal trade-off by learning to\nreserve expensive choices (e.g., 100+ denoising steps) only for a few complex\nprompts, and employ more economical choices (e.g., small distilled model) for\nless sophisticated prompts. We empirically demonstrate on COCO and DiffusionDB\nthat by learning to route to nine already-trained text-to-image models, our\napproach is able to deliver an average quality that is higher than that\nachievable by any of these models alone.", "published": "2025-06-17 17:48:50", "link": "http://arxiv.org/abs/2506.14753v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting", "abstract": "Achieving high synchronization in the synthesis of realistic, speech-driven\ntalking head videos presents a significant challenge. A lifelike talking head\nrequires synchronized coordination of subject identity, lip movements, facial\nexpressions, and head poses. The absence of these synchronizations is a\nfundamental flaw, leading to unrealistic results. To address the critical issue\nof synchronization, identified as the ''devil'' in creating realistic talking\nheads, we introduce SyncTalk++, which features a Dynamic Portrait Renderer with\nGaussian Splatting to ensure consistent subject identity preservation and a\nFace-Sync Controller that aligns lip movements with speech while innovatively\nusing a 3D facial blendshape model to reconstruct accurate facial expressions.\nTo ensure natural head movements, we propose a Head-Sync Stabilizer, which\noptimizes head poses for greater stability. Additionally, SyncTalk++ enhances\nrobustness to out-of-distribution (OOD) audio by incorporating an Expression\nGenerator and a Torso Restorer, which generate speech-matched facial\nexpressions and seamless torso regions. Our approach maintains consistency and\ncontinuity in visual details across frames and significantly improves rendering\nspeed and quality, achieving up to 101 frames per second. Extensive experiments\nand user studies demonstrate that SyncTalk++ outperforms state-of-the-art\nmethods in synchronization and realism. We recommend watching the supplementary\nvideo: https://ziqiaopeng.github.io/synctalk++.", "published": "2025-06-17 17:22:12", "link": "http://arxiv.org/abs/2506.14742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Active InSAR monitoring of building damage in Gaza during the Israel-Hamas War", "abstract": "Aerial bombardment of the Gaza Strip beginning October 7, 2023 is one of the\nmost intense bombing campaigns of the twenty-first century, driving widespread\nurban damage. Characterizing damage over a geographically dynamic and\nprotracted armed conflict requires active monitoring. Synthetic aperture radar\n(SAR) has precedence for mapping disaster-induced damage with bi-temporal\nmethods but applications to active monitoring during sustained crises are\nlimited. Using interferometric SAR data from Sentinel-1, we apply a long\ntemporal-arc coherent change detection (LT-CCD) approach to track weekly damage\ntrends over the first year of the 2023- Israel-Hamas War. We detect 92.5% of\ndamage labels in reference data from the United Nations with a negligible\n(1.2%) false positive rate. The temporal fidelity of our approach reveals\nrapidly increasing damage during the first three months of the war focused in\nnorthern Gaza, a notable pause in damage during a temporary ceasefire, and\nsurges of new damage as conflict hot-spots shift from north to south.\nThree-fifths (191,263) of all buildings are damaged or destroyed by the end of\nthe study. With massive need for timely data on damage in armed conflict zones,\nour low-cost and low-latency approach enables rapid uptake of damage\ninformation at humanitarian and journalistic organizations.", "published": "2025-06-17 17:12:22", "link": "http://arxiv.org/abs/2506.14730v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plug-and-Play with 2.5D Artifact Reduction Prior for Fast and Accurate Industrial Computed Tomography Reconstruction", "abstract": "Cone-beam X-ray computed tomography (XCT) is an essential imaging technique\nfor generating 3D reconstructions of internal structures, with applications\nranging from medical to industrial imaging. Producing high-quality\nreconstructions typically requires many X-ray measurements; this process can be\nslow and expensive, especially for dense materials. Recent work incorporating\nartifact reduction priors within a plug-and-play (PnP) reconstruction framework\nhas shown promising results in improving image quality from sparse-view XCT\nscans while enhancing the generalizability of deep learning-based solutions.\nHowever, this method uses a 2D convolutional neural network (CNN) for artifact\nreduction, which captures only slice-independent information from the 3D\nreconstruction, limiting performance. In this paper, we propose a PnP\nreconstruction method that uses a 2.5D artifact reduction CNN as the prior.\nThis approach leverages inter-slice information from adjacent slices, capturing\nricher spatial context while remaining computationally efficient. We show that\nthis 2.5D prior not only improves the quality of reconstructions but also\nenables the model to directly suppress commonly occurring XCT artifacts (such\nas beam hardening), eliminating the need for artifact correction\npre-processing. Experiments on both experimental and synthetic cone-beam XCT\ndata demonstrate that the proposed method better preserves fine structural\ndetails, such as pore size and shape, leading to more accurate defect detection\ncompared to 2D priors. In particular, we demonstrate strong performance on\nexperimental XCT data using a 2.5D artifact reduction prior trained entirely on\nsimulated scans, highlighting the proposed method's ability to generalize\nacross domains.", "published": "2025-06-17 16:52:57", "link": "http://arxiv.org/abs/2506.14719v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning", "abstract": "Depth estimation is crucial for intelligent systems, enabling applications\nfrom autonomous navigation to augmented reality. While traditional stereo and\nactive depth sensors have limitations in cost, power, and robustness,\ndual-pixel (DP) technology, ubiquitous in modern cameras, offers a compelling\nalternative. This paper introduces DiFuse-Net, a novel modality decoupled\nnetwork design for disentangled RGB and DP based depth estimation. DiFuse-Net\nfeatures a window bi-directional parallax attention mechanism (WBiPAM)\nspecifically designed to capture the subtle DP disparity cues unique to\nsmartphone cameras with small aperture. A separate encoder extracts contextual\ninformation from the RGB image, and these features are fused to enhance depth\nprediction. We also propose a Cross-modal Transfer Learning (CmTL) mechanism to\nutilize large-scale RGB-D datasets in the literature to cope with the\nlimitations of obtaining large-scale RGB-DP-D dataset. Our evaluation and\ncomparison of the proposed method demonstrates its superiority over the DP and\nstereo-based baseline methods. Additionally, we contribute a new, high-quality,\nreal-world RGB-DP-D training dataset, named Dual-Camera Dual-Pixel (DCDP)\ndataset, created using our novel symmetric stereo camera hardware setup, stereo\ncalibration and rectification protocol, and AI stereo disparity estimation\nmethod.", "published": "2025-06-17 16:49:27", "link": "http://arxiv.org/abs/2506.14709v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion", "abstract": "Cameras and LiDAR are essential sensors for autonomous vehicles. The fusion\nof camera and LiDAR data addresses the limitations of individual sensors but\nrelies on precise extrinsic calibration. Recently, numerous end-to-end\ncalibration methods have been proposed; however, most predict extrinsic\nparameters in a single step and lack iterative optimization capabilities. To\naddress the increasing demand for higher accuracy, we propose a versatile\niterative framework based on surrogate diffusion. This framework can enhance\nthe performance of any calibration method without requiring architectural\nmodifications. Specifically, the initial extrinsic parameters undergo iterative\nrefinement through a denoising process, in which the original calibration\nmethod serves as a surrogate denoiser to estimate the final extrinsics at each\nstep. For comparative analysis, we selected four state-of-the-art calibration\nmethods as surrogate denoisers and compared the results of our diffusion\nprocess with those of two other iterative approaches. Extensive experiments\ndemonstrate that when integrated with our diffusion model, all calibration\nmethods achieve higher accuracy, improved robustness, and greater stability\ncompared to other iterative techniques and their single-step counterparts.", "published": "2025-06-17 16:44:51", "link": "http://arxiv.org/abs/2506.14706v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Desiderata-Driven Design of Visual Counterfactual Explainers", "abstract": "Visual counterfactual explainers (VCEs) are a straightforward and promising\napproach to enhancing the transparency of image classifiers. VCEs complement\nother types of explanations, such as feature attribution, by revealing the\nspecific data transformations to which a machine learning model responds most\nstrongly. In this paper, we argue that existing VCEs focus too narrowly on\noptimizing sample quality or change minimality; they fail to consider the more\nholistic desiderata for an explanation, such as fidelity, understandability,\nand sufficiency. To address this shortcoming, we explore new mechanisms for\ncounterfactual generation and investigate how they can help fulfill these\ndesiderata. We combine these mechanisms into a novel 'smooth counterfactual\nexplorer' (SCE) algorithm and demonstrate its effectiveness through systematic\nevaluations on synthetic and real data.", "published": "2025-06-17 16:38:15", "link": "http://arxiv.org/abs/2506.14698v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework", "abstract": "Multispectral object detection, which integrates information from multiple\nbands, can enhance detection accuracy and environmental adaptability, holding\ngreat application potential across various fields. Although existing methods\nhave made progress in cross-modal interaction, low-light conditions, and model\nlightweight, there are still challenges like the lack of a unified single-stage\nframework, difficulty in balancing performance and fusion strategy, and\nunreasonable modality weight allocation. To address these, based on the YOLOv11\nframework, we present YOLOv11-RGBT, a new comprehensive multimodal object\ndetection framework. We designed six multispectral fusion modes and\nsuccessfully applied them to models from YOLOv3 to YOLOv12 and RT-DETR. After\nreevaluating the importance of the two modalities, we proposed a P3 mid-fusion\nstrategy and multispectral controllable fine-tuning (MCF) strategy for\nmultispectral models. These improvements optimize feature fusion, reduce\nredundancy and mismatches, and boost overall model performance. Experiments\nshow our framework excels on three major open-source multispectral object\ndetection datasets, like LLVIP and FLIR. Particularly, the multispectral\ncontrollable fine-tuning strategy significantly enhanced model adaptability and\nrobustness. On the FLIR dataset, it consistently improved YOLOv11 models' mAP\nby 3.41%-5.65%, reaching a maximum of 47.61%, verifying the framework and\nstrategies' effectiveness. The code is available at:\nhttps://github.com/wandahangFY/YOLOv11-RGBT.", "published": "2025-06-17 16:37:00", "link": "http://arxiv.org/abs/2506.14696v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FocalClick-XL: Towards Unified and High-quality Interactive Segmentation", "abstract": "Interactive segmentation enables users to extract binary masks of target\nobjects through simple interactions such as clicks, scribbles, and boxes.\nHowever, existing methods often support only limited interaction forms and\nstruggle to capture fine details. In this paper, we revisit the classical\ncoarse-to-fine design of FocalClick and introduce significant extensions.\nInspired by its multi-stage strategy, we propose a novel pipeline,\nFocalClick-XL, to address these challenges simultaneously. Following the\nemerging trend of large-scale pretraining, we decompose interactive\nsegmentation into meta-tasks that capture different levels of information --\ncontext, object, and detail -- assigning a dedicated subnet to each level.This\ndecomposition allows each subnet to undergo scaled pretraining with independent\ndata and supervision, maximizing its effectiveness. To enhance flexibility, we\nshare context- and detail-level information across different interaction forms\nas common knowledge while introducing a prompting layer at the object level to\nencode specific interaction types. As a result, FocalClick-XL achieves\nstate-of-the-art performance on click-based benchmarks and demonstrates\nremarkable adaptability to diverse interaction formats, including boxes,\nscribbles, and coarse masks. Beyond binary mask generation, it is also capable\nof predicting alpha mattes with fine-grained details, making it a versatile and\npowerful tool for interactive segmentation.", "published": "2025-06-17 16:21:32", "link": "http://arxiv.org/abs/2506.14686v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models", "abstract": "Previous methods for image geo-localization have typically treated the task\nas either classification or retrieval, often relying on black-box decisions\nthat lack interpretability. The rise of large vision-language models (LVLMs)\nhas enabled a rethinking of geo-localization as a reasoning-driven task\ngrounded in visual cues. However, two major challenges persist. On the data\nside, existing reasoning-focused datasets are primarily based on street-view\nimagery, offering limited scene diversity and constrained viewpoints. On the\nmodeling side, current approaches predominantly rely on supervised fine-tuning,\nwhich yields only marginal improvements in reasoning capabilities. To address\nthese challenges, we propose a novel pipeline that constructs a\nreasoning-oriented geo-localization dataset, MP16-Reason, using diverse social\nmedia images. We introduce GLOBE, Group-relative policy optimization for\nLocatability assessment and Optimized visual-clue reasoning, yielding\nBi-objective geo-Enhancement for the VLM in recognition and reasoning. GLOBE\nincorporates task-specific rewards that jointly enhance locatability\nassessment, visual clue reasoning, and geolocation accuracy. Both qualitative\nand quantitative results demonstrate that GLOBE outperforms state-of-the-art\nopen-source LVLMs on geo-localization tasks, particularly in diverse visual\nscenes, while also generating more insightful and interpretable reasoning\ntrajectories.", "published": "2025-06-17 16:07:58", "link": "http://arxiv.org/abs/2506.14674v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification", "abstract": "In order to address the scalability challenge within Neural Architecture\nSearch (NAS), we speed up NAS training via dynamic hard example mining within a\ncurriculum learning framework. By utilizing an autoencoder that enforces an\nimage similarity embedding in latent space, we construct an efficient kd-tree\nstructure to order images by furthest neighbour dissimilarity in a\nlow-dimensional embedding. From a given query image from our subsample dataset,\nwe can identify the most dissimilar image within the global dataset in\nlogarithmic time. Via curriculum learning, we then dynamically re-formulate an\nunbiased subsample dataset for NAS optimisation, upon which the current NAS\nsolution architecture performs poorly. We show that our DDS-NAS framework\nspeeds up gradient-based NAS strategies by up to 27x without loss in\nperformance. By maximising the contribution of each image sample during\ntraining, we reduce the duration of a NAS training cycle and the number of\niterations required for convergence.", "published": "2025-06-17 15:58:10", "link": "http://arxiv.org/abs/2506.14667v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a promising approach for novel\nview synthesis, offering real-time rendering with high visual fidelity.\nHowever, its substantial storage requirements present significant challenges\nfor practical applications. While recent state-of-the-art (SOTA) 3DGS methods\nincreasingly incorporate dedicated compression modules, there is a lack of a\ncomprehensive framework to evaluate their perceptual impact. Therefore we\npresent 3DGS-IEval-15K, the first large-scale image quality assessment (IQA)\ndataset specifically designed for compressed 3DGS representations. Our dataset\nencompasses 15,200 images rendered from 10 real-world scenes through 6\nrepresentative 3DGS algorithms at 20 strategically selected viewpoints, with\ndifferent compression levels leading to various distortion effects. Through\ncontrolled subjective experiments, we collect human perception data from 60\nviewers. We validate dataset quality through scene diversity and MOS\ndistribution analysis, and establish a comprehensive benchmark with 30\nrepresentative IQA metrics covering diverse types. As the largest-scale 3DGS\nquality assessment dataset to date, our work provides a foundation for\ndeveloping 3DGS specialized IQA metrics, and offers essential data for\ninvestigating view-dependent quality distribution patterns unique to 3DGS. The\ndatabase is publicly available at https://github.com/YukeXing/3DGS-IEval-15K.", "published": "2025-06-17 15:39:34", "link": "http://arxiv.org/abs/2506.14642v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching", "abstract": "This work addresses image restoration tasks through the lens of inverse\nproblems using unpaired datasets. In contrast to traditional approaches --\nwhich typically assume full knowledge of the forward model or access to paired\ndegraded and ground-truth images -- the proposed method operates under minimal\nassumptions and relies only on small, unpaired datasets. This makes it\nparticularly well-suited for real-world scenarios, where the forward model is\noften unknown or misspecified, and collecting paired data is costly or\ninfeasible. The method leverages conditional flow matching to model the\ndistribution of degraded observations, while simultaneously learning the\nforward model via a distribution-matching loss that arises naturally from the\nframework. Empirically, it outperforms both single-image blind and unsupervised\napproaches on deblurring and non-uniform point spread function (PSF)\ncalibration tasks. It also matches state-of-the-art performance on blind\nsuper-resolution. We also showcase the effectiveness of our method with a proof\nof concept for lens calibration: a real-world application traditionally\nrequiring time-consuming experiments and specialized equipment. In contrast,\nour approach achieves this with minimal data acquisition effort.", "published": "2025-06-17 15:06:43", "link": "http://arxiv.org/abs/2506.14605v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Align Your Flow: Scaling Continuous-Time Flow Map Distillation", "abstract": "Diffusion- and flow-based models have emerged as state-of-the-art generative\nmodeling approaches, but they require many sampling steps. Consistency models\ncan distill these models into efficient one-step generators; however, unlike\nflow- and diffusion-based methods, their performance inevitably degrades when\nincreasing the number of steps, which we show both analytically and\nempirically. Flow maps generalize these approaches by connecting any two noise\nlevels in a single step and remain effective across all step counts. In this\npaper, we introduce two new continuous-time objectives for training flow maps,\nalong with additional novel training techniques, generalizing existing\nconsistency and flow matching objectives. We further demonstrate that\nautoguidance can improve performance, using a low-quality model for guidance\nduring distillation, and an additional boost can be achieved by adversarial\nfinetuning, with minimal loss in sample diversity. We extensively validate our\nflow map models, called Align Your Flow, on challenging image generation\nbenchmarks and achieve state-of-the-art few-step generation performance on both\nImageNet 64x64 and 512x512, using small and efficient neural networks. Finally,\nwe show text-to-image flow map models that outperform all existing\nnon-adversarially trained few-step samplers in text-conditioned synthesis.", "published": "2025-06-17 15:06:07", "link": "http://arxiv.org/abs/2506.14603v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Busting the Paper Ballot: Voting Meets Adversarial Machine Learning", "abstract": "We show the security risk associated with using machine learning classifiers\nin United States election tabulators. The central classification task in\nelection tabulation is deciding whether a mark does or does not appear on a\nbubble associated to an alternative in a contest on the ballot. Barretto et al.\n(E-Vote-ID 2021) reported that convolutional neural networks are a viable\noption in this field, as they outperform simple feature-based classifiers.\n  Our contributions to election security can be divided into four parts. To\ndemonstrate and analyze the hypothetical vulnerability of machine learning\nmodels on election tabulators, we first introduce four new ballot datasets.\nSecond, we train and test a variety of different models on our new datasets.\nThese models include support vector machines, convolutional neural networks (a\nbasic CNN, VGG and ResNet), and vision transformers (Twins and CaiT). Third,\nusing our new datasets and trained models, we demonstrate that traditional\nwhite box attacks are ineffective in the voting domain due to gradient masking.\nOur analyses further reveal that gradient masking is a product of numerical\ninstability. We use a modified difference of logits ratio loss to overcome this\nissue (Croce and Hein, ICML 2020). Fourth, in the physical world, we conduct\nattacks with the adversarial examples generated using our new methods. In\ntraditional adversarial machine learning, a high (50% or greater) attack\nsuccess rate is ideal. However, for certain elections, even a 5% attack success\nrate can flip the outcome of a race. We show such an impact is possible in the\nphysical domain. We thoroughly discuss attack realism, and the challenges and\npracticality associated with printing and scanning ballot adversarial examples.", "published": "2025-06-17 14:38:08", "link": "http://arxiv.org/abs/2506.14582v1", "categories": ["cs.CR", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images", "abstract": "Medical imaging plays a crucial role in assessing knee osteoarthritis (OA)\nrisk by enabling early detection and disease monitoring. Recent machine\nlearning methods have improved risk estimation (i.e., predicting the likelihood\nof disease progression) and predictive modelling (i.e., the forecasting of\nfuture outcomes based on current data) using medical images, but clinical\nadoption remains limited due to their lack of interpretability. Existing\napproaches that generate future images for risk estimation are complex and\nimpractical. Additionally, previous methods fail to localize anatomical knee\nlandmarks, limiting interpretability. We address these gaps with a new\ninterpretable machine learning method to estimate the risk of knee OA\nprogression via multi-task predictive modelling that classifies future knee OA\nseverity and predicts anatomical knee landmarks from efficiently generated\nhigh-quality future images. Such image generation is achieved by leveraging a\ndiffusion model in a class-conditioned latent space to forecast disease\nprogression, offering a visual representation of how particular health\nconditions may evolve. Applied to the Osteoarthritis Initiative dataset, our\napproach improves the state-of-the-art (SOTA) by 2\\%, achieving an AUC of 0.71\nin predicting knee OA progression while offering ~9% faster inference time.", "published": "2025-06-17 14:15:39", "link": "http://arxiv.org/abs/2506.14560v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DreamLight: Towards Harmonious and Consistent Image Relighting", "abstract": "We introduce a model named DreamLight for universal image relighting in this\nwork, which can seamlessly composite subjects into a new background while\nmaintaining aesthetic uniformity in terms of lighting and color tone. The\nbackground can be specified by natural images (image-based relighting) or\ngenerated from unlimited text prompts (text-based relighting). Existing studies\nprimarily focus on image-based relighting, while with scant exploration into\ntext-based scenarios. Some works employ intricate disentanglement pipeline\ndesigns relying on environment maps to provide relevant information, which\ngrapples with the expensive data cost required for intrinsic decomposition and\nlight source. Other methods take this task as an image translation problem and\nperform pixel-level transformation with autoencoder architecture. While these\nmethods have achieved decent harmonization effects, they struggle to generate\nrealistic and natural light interaction effects between the foreground and\nbackground. To alleviate these challenges, we reorganize the input data into a\nunified format and leverage the semantic prior provided by the pretrained\ndiffusion model to facilitate the generation of natural results. Moreover, we\npropose a Position-Guided Light Adapter (PGLA) that condenses light information\nfrom different directions in the background into designed light query\nembeddings, and modulates the foreground with direction-biased masked\nattention. In addition, we present a post-processing module named Spectral\nForeground Fixer (SFF) to adaptively reorganize different frequency components\nof subject and relighted background, which helps enhance the consistency of\nforeground appearance. Extensive comparisons and user study demonstrate that\nour DreamLight achieves remarkable relighting performance.", "published": "2025-06-17 14:05:24", "link": "http://arxiv.org/abs/2506.14549v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MobileHolo: A Lightweight Complex-Valued Deformable CNN for High-Quality Computer-Generated Hologram", "abstract": "Holographic displays have significant potential in virtual reality and\naugmented reality owing to their ability to provide all the depth cues. Deep\nlearning-based methods play an important role in computer-generated holograms\n(CGH). During the diffraction process, each pixel exerts an influence on the\nreconstructed image. However, previous works face challenges in capturing\nsufficient information to accurately model this process, primarily due to the\ninadequacy of their effective receptive field (ERF). Here, we designed\ncomplex-valued deformable convolution for integration into network, enabling\ndynamic adjustment of the convolution kernel's shape to increase flexibility of\nERF for better feature extraction. This approach allows us to utilize a single\nmodel while achieving state-of-the-art performance in both simulated and\noptical experiment reconstructions, surpassing existing open-source models.\nSpecifically, our method has a peak signal-to-noise ratio that is 2.04 dB, 5.31\ndB, and 9.71 dB higher than that of CCNN-CGH, HoloNet, and Holo-encoder,\nrespectively, when the resolution is 1920$\\times$1072. The number of parameters\nof our model is only about one-eighth of that of CCNN-CGH.", "published": "2025-06-17 14:02:41", "link": "http://arxiv.org/abs/2506.14542v1", "categories": ["physics.optics", "cs.CV"], "primary_category": "physics.optics"}
{"title": "Exploring Diffusion with Test-Time Training on Efficient Image Restoration", "abstract": "Image restoration faces challenges including ineffective feature fusion,\ncomputational bottlenecks and inefficient diffusion processes. To address\nthese, we propose DiffRWKVIR, a novel framework unifying Test-Time Training\n(TTT) with efficient diffusion. Our approach introduces three key innovations:\n(1) Omni-Scale 2D State Evolution extends RWKV's location-dependent\nparameterization to hierarchical multi-directional 2D scanning, enabling global\ncontextual awareness with linear complexity O(L); (2) Chunk-Optimized Flash\nProcessing accelerates intra-chunk parallelism by 3.2x via contiguous chunk\nprocessing (O(LCd) complexity), reducing sequential dependencies and\ncomputational overhead; (3) Prior-Guided Efficient Diffusion extracts a compact\nImage Prior Representation (IPR) in only 5-20 steps, proving 45% faster\ntraining/inference than DiffIR while solving computational inefficiency in\ndenoising. Evaluated across super-resolution and inpainting benchmarks (Set5,\nSet14, BSD100, Urban100, Places365), DiffRWKVIR outperforms SwinIR, HAT, and\nMambaIR/v2 in PSNR, SSIM, LPIPS, and efficiency metrics. Our method establishes\na new paradigm for adaptive, high-efficiency image restoration with optimized\nhardware utilization.", "published": "2025-06-17 14:01:59", "link": "http://arxiv.org/abs/2506.14541v1", "categories": ["cs.CV", "I.4.9"], "primary_category": "cs.CV"}
{"title": "VisLanding: Monocular 3D Perception for UAV Safe Landing via Depth-Normal Synergy", "abstract": "This paper presents VisLanding, a monocular 3D perception-based framework for\nsafe UAV (Unmanned Aerial Vehicle) landing. Addressing the core challenge of\nautonomous UAV landing in complex and unknown environments, this study\ninnovatively leverages the depth-normal synergy prediction capabilities of the\nMetric3D V2 model to construct an end-to-end safe landing zones (SLZ)\nestimation framework. By introducing a safe zone segmentation branch, we\ntransform the landing zone estimation task into a binary semantic segmentation\nproblem. The model is fine-tuned and annotated using the WildUAV dataset from a\nUAV perspective, while a cross-domain evaluation dataset is constructed to\nvalidate the model's robustness. Experimental results demonstrate that\nVisLanding significantly enhances the accuracy of safe zone identification\nthrough a depth-normal joint optimization mechanism, while retaining the\nzero-shot generalization advantages of Metric3D V2. The proposed method\nexhibits superior generalization and robustness in cross-domain testing\ncompared to other approaches. Furthermore, it enables the estimation of landing\nzone area by integrating predicted depth and normal information, providing\ncritical decision-making support for practical applications.", "published": "2025-06-17 13:51:16", "link": "http://arxiv.org/abs/2506.14525v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Integrating Radiomics with Deep Learning Enhances Multiple Sclerosis Lesion Delineation", "abstract": "Background: Accurate lesion segmentation is critical for multiple sclerosis\n(MS) diagnosis, yet current deep learning approaches face robustness\nchallenges.\n  Aim: This study improves MS lesion segmentation by combining data fusion and\ndeep learning techniques.\n  Materials and Methods: We suggested novel radiomic features (concentration\nrate and R\\'enyi entropy) to characterize different MS lesion types and fused\nthese with raw imaging data. The study integrated radiomic features with\nimaging data through a ResNeXt-UNet architecture and attention-augmented U-Net\narchitecture. Our approach was evaluated on scans from 46 patients (1102\nslices), comparing performance before and after data fusion.\n  Results: The radiomics-enhanced ResNeXt-UNet demonstrated high segmentation\naccuracy, achieving significant improvements in precision and sensitivity over\nthe MRI-only baseline and a Dice score of 0.774$\\pm$0.05; p<0.001 according to\nBonferroni-adjusted Wilcoxon signed-rank tests. The radiomics-enhanced\nattention-augmented U-Net model showed a greater model stability evidenced by\nreduced performance variability (SDD = 0.18 $\\pm$ 0.09 vs. 0.21 $\\pm$ 0.06;\np=0.03) and smoother validation curves with radiomics integration.\n  Conclusion: These results validate our hypothesis that fusing radiomics with\nraw imaging data boosts segmentation performance and stability in\nstate-of-the-art models.", "published": "2025-06-17 13:50:42", "link": "http://arxiv.org/abs/2506.14524v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning", "abstract": "As machine learning systems increasingly rely on data subject to privacy\nregulation, selectively unlearning specific information from trained models has\nbecome essential. In image classification, this involves removing the influence\nof particular training samples, semantic classes, or visual styles without full\nretraining. We introduce \\textbf{Forget-Aligned Model Reconstruction (FAMR)}, a\ntheoretically grounded and computationally efficient framework for post-hoc\nunlearning in deep image classifiers. FAMR frames forgetting as a constrained\noptimization problem that minimizes a uniform-prediction loss on the forget set\nwhile anchoring model parameters to their original values via an $\\ell_2$\npenalty. A theoretical analysis links FAMR's solution to\ninfluence-function-based retraining approximations, with bounds on parameter\nand output deviation. Empirical results on class forgetting tasks using\nCIFAR-10 and ImageNet-100 demonstrate FAMR's effectiveness, with strong\nperformance retention and minimal computational overhead. The framework\ngeneralizes naturally to concept and style erasure, offering a scalable and\ncertifiable route to efficient post-hoc forgetting in vision models.", "published": "2025-06-17 13:40:48", "link": "http://arxiv.org/abs/2506.14515v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks", "abstract": "Large Language Models (LLMs) are experiencing rapid advancements in complex\nreasoning, exhibiting remarkable generalization in mathematics and programming.\nIn contrast, while spatial intelligence is fundamental for Vision-Language\nModels (VLMs) in real-world interaction, the systematic evaluation of their\ncomplex reasoning ability within spatial contexts remains underexplored. To\nbridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate\nVLMs' spatial intelligence through video-based reasoning tasks. SIRI-Bench\ncomprises nearly 1K video-question-answer triplets, where each problem is\nembedded in a realistic 3D scene and captured by video. By carefully designing\nquestions and corresponding 3D scenes, our benchmark ensures that solving the\nquestions requires both spatial comprehension for extracting information and\nhigh-level reasoning for deriving solutions, making it a challenging benchmark\nfor evaluating VLMs. To facilitate large-scale data synthesis, we develop an\nAutomatic Scene Creation Engine. This engine, leveraging multiple specialized\nLLM agents, can generate realistic 3D scenes from abstract math problems,\nensuring faithfulness to the original descriptions. Experimental results reveal\nthat state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring\nthe challenge of spatial reasoning. We hope that our study will bring\nresearchers' attention to spatially grounded reasoning and advance VLMs in\nvisual problem-solving.", "published": "2025-06-17 13:40:00", "link": "http://arxiv.org/abs/2506.14512v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution", "abstract": "Facial micro-expression recognition (MER) is a challenging problem, due to\ntransient and subtle micro-expression (ME) actions. Most existing methods\ndepend on hand-crafted features, key frames like onset, apex, and offset\nframes, or deep networks limited by small-scale and low-diversity datasets. In\nthis paper, we propose an end-to-end micro-action-aware deep learning framework\nwith advantages from transformer, graph convolution, and vanilla convolution.\nIn particular, we propose a novel F5C block composed of fully-connected\nconvolution and channel correspondence convolution to directly extract\nlocal-global features from a sequence of raw frames, without the prior\nknowledge of key frames. The transformer-style fully-connected convolution is\nproposed to extract local features while maintaining global receptive fields,\nand the graph-style channel correspondence convolution is introduced to model\nthe correlations among feature patterns. Moreover, MER, optical flow\nestimation, and facial landmark detection are jointly trained by sharing the\nlocal-global features. The two latter tasks contribute to capturing facial\nsubtle action information for MER, which can alleviate the impact of\ninsufficient training data. Extensive experiments demonstrate that our\nframework (i) outperforms the state-of-the-art MER methods on CASME II, SAMM,\nand SMIC benchmarks, (ii) works well for optical flow estimation and facial\nlandmark detection, and (iii) can capture facial subtle muscle actions in local\nregions associated with MEs. The code is available at\nhttps://github.com/CYF-cuber/MOL.", "published": "2025-06-17 13:35:06", "link": "http://arxiv.org/abs/2506.14511v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation", "abstract": "Accurate segmentation of white matter hyperintensities (WMH) is crucial for\nclinical decision-making, particularly in the context of multiple sclerosis.\nHowever, domain shifts, such as variations in MRI machine types or acquisition\nparameters, pose significant challenges to model calibration and uncertainty\nestimation. This study investigates the impact of domain shift on WMH\nsegmentation by proposing maximum-entropy regularization techniques to enhance\nmodel calibration and uncertainty estimation, with the purpose of identifying\nerrors post-deployment using predictive uncertainty as a proxy measure that\ndoes not require ground-truth labels. To do this, we conducted experiments\nusing a U-Net architecture to evaluate these regularization schemes on two\npublicly available datasets, assessing performance with the Dice coefficient,\nexpected calibration error, and entropy-based uncertainty estimates. Our\nresults show that entropy-based uncertainty estimates can anticipate\nsegmentation errors, and that maximum-entropy regularization further\nstrengthens the correlation between uncertainty and segmentation performance\nwhile also improving model calibration under domain shift.", "published": "2025-06-17 13:21:29", "link": "http://arxiv.org/abs/2506.14497v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs", "abstract": "Existing 3D visual grounding methods rely on precise text prompts to locate\nobjects within 3D scenes. Speech, as a natural and intuitive modality, offers a\npromising alternative. Real-world speech inputs, however, often suffer from\ntranscription errors due to accents, background noise, and varying speech\nrates, limiting the applicability of existing 3DVG methods. To address these\nchallenges, we propose \\textbf{SpeechRefer}, a novel 3DVG framework designed to\nenhance performance in the presence of noisy and ambiguous speech-to-text\ntranscriptions. SpeechRefer integrates seamlessly with xisting 3DVG models and\nintroduces two key innovations. First, the Speech Complementary Module captures\nacoustic similarities between phonetically related words and highlights subtle\ndistinctions, generating complementary proposal scores from the speech signal.\nThis reduces dependence on potentially erroneous transcriptions. Second, the\nContrastive Complementary Module employs contrastive learning to align\nerroneous text features with corresponding speech features, ensuring robust\nperformance even when transcription errors dominate. Extensive experiments on\nthe SpeechRefer and peechNr3D datasets demonstrate that SpeechRefer improves\nthe performance of existing 3DVG methods by a large margin, which highlights\nSpeechRefer's potential to bridge the gap between noisy speech inputs and\nreliable 3DVG, enabling more intuitive and practical multimodal systems.", "published": "2025-06-17 13:17:31", "link": "http://arxiv.org/abs/2506.14495v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection", "abstract": "One-shot subset selection serves as an effective tool to reduce deep learning\ntraining costs by identifying an informative data subset based on the\ninformation extracted by an information extractor (IE). Traditional IEs,\ntypically pre-trained on the target dataset, are inherently dataset-dependent.\nFoundation models (FMs) offer a promising alternative, potentially mitigating\nthis limitation. This work investigates two key questions: (1) Can FM-based\nsubset selection outperform traditional IE-based methods across diverse\ndatasets? (2) Do all FMs perform equally well as IEs for subset selection?\nExtensive experiments uncovered surprising insights: FMs consistently\noutperform traditional IEs on fine-grained datasets, whereas their advantage\ndiminishes on coarse-grained datasets with noisy labels. Motivated by these\nfinding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), a\nmethod tailored for fine-grained image datasets. RAM-APL leverages multiple FMs\nto enhance subset selection by exploiting their complementary strengths. Our\napproach achieves state-of-the-art performance on fine-grained datasets,\nincluding Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.", "published": "2025-06-17 12:37:24", "link": "http://arxiv.org/abs/2506.14473v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dense360: Dense Understanding from Omnidirectional Panoramas", "abstract": "Multimodal Large Language Models (MLLMs) require comprehensive visual inputs\nto achieve dense understanding of the physical world. While existing MLLMs\ndemonstrate impressive world understanding capabilities through limited\nfield-of-view (FOV) visual inputs (e.g., 70 degree), we take the first step\ntoward dense understanding from omnidirectional panoramas. We first introduce\nan omnidirectional panoramas dataset featuring a comprehensive suite of\nreliability-scored annotations. Specifically, our dataset contains 160K\npanoramas with 5M dense entity-level captions, 1M unique referring expressions,\nand 100K entity-grounded panoramic scene descriptions. Compared to multi-view\nalternatives, panoramas can provide more complete, compact, and continuous\nscene representations through equirectangular projections (ERP). However, the\nuse of ERP introduces two key challenges for MLLMs: i) spatial continuity along\nthe circle of latitude, and ii) latitude-dependent variation in information\ndensity. We address these challenges through ERP-RoPE, a position encoding\nscheme specifically designed for panoramic ERP. In addition, we introduce\nDense360-Bench, the first benchmark for evaluating MLLMs on omnidirectional\ncaptioning and grounding, establishing a comprehensive framework for advancing\ndense visual-language understanding in panoramic settings.", "published": "2025-06-17 12:35:23", "link": "http://arxiv.org/abs/2506.14471v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models", "abstract": "Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size\nto boost performance while maintaining fixed active parameters. However,\nprevious works primarily utilized full-precision experts during sparse\nup-cycling. Despite they show superior performance on end tasks, the large\namount of experts introduces higher memory footprint, which poses significant\nchallenges for the deployment on edge devices. In this work, we propose MoTE, a\nscalable and memory-efficient approach to train Mixture-of-Ternary-Experts\nmodels from dense checkpoint. Instead of training fewer high-precision experts,\nwe propose to train more low-precision experts during up-cycling. Specifically,\nwe use the pre-trained FFN as a shared expert and train ternary routed experts\nwith parameters in {-1, 0, 1}. Extensive experiments show that our approach has\npromising scaling trend along model size. MoTE achieves comparable performance\nto full-precision baseline MoE-LLaVA while offering lower memory footprint.\nFurthermore, our approach is compatible with post-training quantization methods\nand the advantage further amplifies when memory-constraint goes lower. Given\nthe same amount of expert memory footprint of 3.4GB and combined with\npost-training quantization, MoTE outperforms MoE-LLaVA by a gain of 4.3%\naverage accuracy on end tasks, demonstrating its effectiveness and potential\nfor memory-constrained devices.", "published": "2025-06-17 11:53:49", "link": "http://arxiv.org/abs/2506.14435v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A large-scale heterogeneous 3D magnetic resonance brain imaging dataset for self-supervised learning", "abstract": "We present FOMO60K, a large-scale, heterogeneous dataset of 60,529 brain\nMagnetic Resonance Imaging (MRI) scans from 13,900 sessions and 11,187\nsubjects, aggregated from 16 publicly available sources. The dataset includes\nboth clinical- and research-grade images, multiple MRI sequences, and a wide\nrange of anatomical and pathological variability, including scans with large\nbrain anomalies. Minimal preprocessing was applied to preserve the original\nimage characteristics while reducing barriers to entry for new users.\nAccompanying code for self-supervised pretraining and finetuning is provided.\nFOMO60K is intended to support the development and benchmarking of\nself-supervised learning methods in medical imaging at scale.", "published": "2025-06-17 11:48:05", "link": "http://arxiv.org/abs/2506.14432v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Toward Rich Video Human-Motion2D Generation", "abstract": "Generating realistic and controllable human motions, particularly those\ninvolving rich multi-character interactions, remains a significant challenge\ndue to data scarcity and the complexities of modeling inter-personal dynamics.\nTo address these limitations, we first introduce a new large-scale rich video\nhuman motion 2D dataset (Motion2D-Video-150K) comprising 150,000 video\nsequences. Motion2D-Video-150K features a balanced distribution of diverse\nsingle-character and, crucially, double-character interactive actions, each\npaired with detailed textual descriptions. Building upon this dataset, we\npropose a novel diffusion-based rich video human motion2D generation (RVHM2D)\nmodel. RVHM2D incorporates an enhanced textual conditioning mechanism utilizing\neither dual text encoders (CLIP-L/B) or T5-XXL with both global and local\nfeatures. We devise a two-stage training strategy: the model is first trained\nwith a standard diffusion objective, and then fine-tuned using reinforcement\nlearning with an FID-based reward to further enhance motion realism and text\nalignment. Extensive experiments demonstrate that RVHM2D achieves leading\nperformance on the Motion2D-Video-150K benchmark in generating both single and\ninteractive double-character scenarios.", "published": "2025-06-17 11:45:33", "link": "http://arxiv.org/abs/2506.14428v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection", "abstract": "Understanding the decision-making and trusting the reliability of Deep\nMachine Learning Models is crucial for adopting such methods to safety-relevant\napplications. We extend self-explainable Prototypical Variational models with\nautoencoder-based out-of-distribution (OOD) detection: A Variational\nAutoencoder is applied to learn a meaningful latent space which can be used for\ndistance-based classification, likelihood estimation for OOD detection, and\nreconstruction. The In-Distribution (ID) region is defined by a Gaussian\nmixture distribution with learned prototypes representing the center of each\nmode. Furthermore, a novel restriction loss is introduced that promotes a\ncompact ID region in the latent space without collapsing it into single points.\nThe reconstructive capabilities of the Autoencoder ensure the explainability of\nthe prototypes and the ID region of the classifier, further aiding the\ndiscrimination of OOD samples. Extensive evaluations on common OOD detection\nbenchmarks as well as a large-scale dataset from a real-world railway\napplication demonstrate the usefulness of the approach, outperforming previous\nmethods.", "published": "2025-06-17 10:38:29", "link": "http://arxiv.org/abs/2506.14390v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GrFormer: A Novel Transformer on Grassmann Manifold for Infrared and Visible Image Fusion", "abstract": "In the field of image fusion, promising progress has been made by modeling\ndata from different modalities as linear subspaces.\n  However, in practice, the source images are often located in a non-Euclidean\nspace, where the Euclidean methods usually cannot\n  encapsulate the intrinsic topological structure. Typically, the inner product\nperformed in the Euclidean space calculates the algebraic\n  similarity rather than the semantic similarity, which results in undesired\nattention output and a decrease in fusion performance.\n  While the balance of low-level details and high-level semantics should be\nconsidered in infrared and visible image fusion task. To\n  address this issue, in this paper, we propose a novel attention mechanism\nbased on Grassmann manifold for infrared and visible\n  image fusion (GrFormer). Specifically, our method constructs a low-rank\nsubspace mapping through projection constraints on the\n  Grassmann manifold, compressing attention features into subspaces of varying\nrank levels. This forces the features to decouple into\n  high-frequency details (local low-rank) and low-frequency semantics (global\nlow-rank), thereby achieving multi-scale semantic\n  fusion. Additionally, to effectively integrate the significant information,\nwe develop a cross-modal fusion strategy (CMS) based on\n  a covariance mask to maximise the complementary properties between different\nmodalities and to suppress the features with high\n  correlation, which are deemed redundant. The experimental results demonstrate\nthat our network outperforms SOTA methods both\n  qualitatively and quantitatively on multiple image fusion benchmarks. The\ncodes are available at https://github.com/Shaoyun2023.", "published": "2025-06-17 10:32:05", "link": "http://arxiv.org/abs/2506.14384v1", "categories": ["cs.CV", "I.4"], "primary_category": "cs.CV"}
{"title": "Compressed Video Super-Resolution based on Hierarchical Encoding", "abstract": "This paper presents a general-purpose video super-resolution (VSR) method,\ndubbed VSR-HE, specifically designed to enhance the perceptual quality of\ncompressed content. Targeting scenarios characterized by heavy compression, the\nmethod upscales low-resolution videos by a ratio of four, from 180p to 720p or\nfrom 270p to 1080p. VSR-HE adopts hierarchical encoding transformer blocks and\nhas been sophisticatedly optimized to eliminate a wide range of compression\nartifacts commonly introduced by H.265/HEVC encoding across various\nquantization parameter (QP) levels. To ensure robustness and generalization,\nthe model is trained and evaluated under diverse compression settings, allowing\nit to effectively restore fine-grained details and preserve visual fidelity.\nThe proposed VSR-HE has been officially submitted to the ICME 2025 Grand\nChallenge on VSR for Video Conferencing (Team BVI-VSR), under both the Track 1\n(General-Purpose Real-World Video Content) and Track 2 (Talking Head Videos).", "published": "2025-06-17 10:26:07", "link": "http://arxiv.org/abs/2506.14381v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Discrete JEPA: Learning Discrete Token Representations without Reconstruction", "abstract": "The cornerstone of cognitive intelligence lies in extracting hidden patterns\nfrom observations and leveraging these principles to systematically predict\nfuture outcomes. However, current image tokenization methods demonstrate\nsignificant limitations in tasks requiring symbolic abstraction and logical\nreasoning capabilities essential for systematic inference. To address this\nchallenge, we propose Discrete-JEPA, extending the latent predictive coding\nframework with semantic tokenization and novel complementary objectives to\ncreate robust tokenization for symbolic reasoning tasks. Discrete-JEPA\ndramatically outperforms baselines on visual symbolic prediction tasks, while\nstriking visual evidence reveals the spontaneous emergence of deliberate\nsystematic patterns within the learned semantic token space. Though an initial\nmodel, our approach promises a significant impact for advancing Symbolic world\nmodeling and planning capabilities in artificial intelligence systems.", "published": "2025-06-17 10:15:17", "link": "http://arxiv.org/abs/2506.14373v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI", "abstract": "Accurate diagnosis of brain disorders such as Alzheimer's disease and brain\ntumors remains a critical challenge in medical imaging. Conventional methods\nbased on manual MRI analysis are often inefficient and error-prone. To address\nthis, we propose DGG-XNet, a hybrid deep learning model integrating VGG16 and\nDenseNet121 to enhance feature extraction and classification. DenseNet121\npromotes feature reuse and efficient gradient flow through dense connectivity,\nwhile VGG16 contributes strong hierarchical spatial representations. Their\nfusion enables robust multiclass classification of neurological conditions.\nGrad-CAM is applied to visualize salient regions, enhancing model transparency.\nTrained on a combined dataset from BraTS 2021 and Kaggle, DGG-XNet achieved a\ntest accuracy of 91.33\\%, with precision, recall, and F1-score all exceeding\n91\\%. These results highlight DGG-XNet's potential as an effective and\ninterpretable tool for computer-aided diagnosis (CAD) of neurodegenerative and\noncological brain disorders.", "published": "2025-06-17 10:07:59", "link": "http://arxiv.org/abs/2506.14367v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HydroChronos: Forecasting Decades of Surface Water Change", "abstract": "Forecasting surface water dynamics is crucial for water resource management\nand climate change adaptation. However, the field lacks comprehensive datasets\nand standardized benchmarks. In this paper, we introduce HydroChronos, a\nlarge-scale, multi-modal spatiotemporal dataset for surface water dynamics\nforecasting designed to address this gap. We couple the dataset with three\nforecasting tasks. The dataset includes over three decades of aligned Landsat 5\nand Sentinel-2 imagery, climate data, and Digital Elevation Models for diverse\nlakes and rivers across Europe, North America, and South America. We also\npropose AquaClimaTempo UNet, a novel spatiotemporal architecture with a\ndedicated climate data branch, as a strong benchmark baseline. Our model\nsignificantly outperforms a Persistence baseline for forecasting future water\ndynamics by +14% and +11% F1 across change detection and direction of change\nclassification tasks, and by +0.1 MAE on the magnitude of change regression.\nFinally, we conduct an Explainable AI analysis to identify the key climate\nvariables and input channels that influence surface water change, providing\ninsights to inform and guide future modeling efforts.", "published": "2025-06-17 10:02:48", "link": "http://arxiv.org/abs/2506.14362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FGA-NN: Film Grain Analysis Neural Network", "abstract": "Film grain, once a by-product of analog film, is now present in most\ncinematographic content for aesthetic reasons. However, when such content is\ncompressed at medium to low bitrates, film grain is lost due to its random\nnature. To preserve artistic intent while compressing efficiently, film grain\nis analyzed and modeled before encoding and synthesized after decoding. This\npaper introduces FGA-NN, the first learning-based film grain analysis method to\nestimate conventional film grain parameters compatible with conventional\nsynthesis. Quantitative and qualitative results demonstrate FGA-NN's superior\nbalance between analysis accuracy and synthesis complexity, along with its\nrobustness and applicability.", "published": "2025-06-17 09:48:27", "link": "http://arxiv.org/abs/2506.14350v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "FRIDU: Functional Map Refinement with Guided Image Diffusion", "abstract": "We propose a novel approach for refining a given correspondence map between\ntwo shapes. A correspondence map represented as a functional map, namely a\nchange of basis matrix, can be additionally treated as a 2D image. With this\nperspective, we train an image diffusion model directly in the space of\nfunctional maps, enabling it to generate accurate maps conditioned on an\ninaccurate initial map. The training is done purely in the functional space,\nand thus is highly efficient. At inference time, we use the pointwise map\ncorresponding to the current functional map as guidance during the diffusion\nprocess. The guidance can additionally encourage different functional map\nobjectives, such as orthogonality and commutativity with the Laplace-Beltrami\noperator. We show that our approach is competitive with state-of-the-art\nmethods of map refinement and that guided diffusion models provide a promising\npathway to functional map processing.", "published": "2025-06-17 09:02:46", "link": "http://arxiv.org/abs/2506.14322v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification with Swin-HAFNet", "abstract": "Accurate segmentation and classification of brain tumors from Magnetic\nResonance Imaging (MRI) remain key challenges in medical image analysis,\nlargely due to the lack of high-quality, balanced, and diverse datasets. In\nthis work, we present a new curated MRI dataset designed specifically for brain\ntumor segmentation and classification tasks. The dataset comprises 6,000\ncontrast-enhanced T1-weighted MRI scans annotated by certified radiologists and\nphysicians, spanning three major tumor types-glioma, meningioma, and\npituitary-as well as non-tumorous cases. Each sample includes high-resolution\nlabels and is categorized across axial, sagittal, and coronal imaging planes to\nfacilitate robust model development and cross-view generalization. To\ndemonstrate the utility of the dataset, we propose a transformer-based\nsegmentation model and benchmark it against established baselines. Our method\nachieves the highest weighted mean Intersection-over-Union (IoU) of 82.3%, with\nimprovements observed across all tumor categories. Importantly, this study\nserves primarily as an introduction to the dataset, establishing foundational\nbenchmarks for future research. We envision this dataset as a valuable resource\nfor advancing machine learning applications in neuro-oncology, supporting both\nacademic research and clinical decision-support development. datasetlink:\nhttps://www.kaggle.com/datasets/briscdataset/brisc2025/", "published": "2025-06-17 08:56:05", "link": "http://arxiv.org/abs/2506.14318v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies", "abstract": "Automatic creation of 3D scenes for immersive VR presence has been a\nsignificant research focus for decades. However, existing methods often rely on\neither high-poly mesh modeling with post-hoc simplification or massive 3D\nGaussians, resulting in a complex pipeline or limited visual realism. In this\npaper, we demonstrate that such exhaustive modeling is unnecessary for\nachieving compelling immersive experience. We introduce ImmerseGen, a novel\nagent-guided framework for compact and photorealistic world modeling.\nImmerseGen represents scenes as hierarchical compositions of lightweight\ngeometric proxies, i.e., simplified terrain and billboard meshes, and generates\nphotorealistic appearance by synthesizing RGBA textures onto these proxies.\nSpecifically, we propose terrain-conditioned texturing for user-centric base\nworld synthesis, and RGBA asset texturing for midground and foreground\nscenery.This reformulation offers several advantages: (i) it simplifies\nmodeling by enabling agents to guide generative models in producing coherent\ntextures that integrate seamlessly with the scene; (ii) it bypasses complex\ngeometry creation and decimation by directly synthesizing photorealistic\ntextures on proxies, preserving visual quality without degradation; (iii) it\nenables compact representations suitable for real-time rendering on mobile VR\nheadsets. To automate scene creation from text prompts, we introduce VLM-based\nmodeling agents enhanced with semantic grid-based analysis for improved spatial\nreasoning and accurate asset placement. ImmerseGen further enriches scenes with\ndynamic effects and ambient audio to support multisensory immersion.\nExperiments on scene generation and live VR showcases demonstrate that\nImmerseGen achieves superior photorealism, spatial coherence and rendering\nefficiency compared to prior methods. Project webpage:\nhttps://immersegen.github.io.", "published": "2025-06-17 08:50:05", "link": "http://arxiv.org/abs/2506.14315v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment", "abstract": "360 video captures the complete surrounding scenes with the ultra-large field\nof view of 360X180. This makes 360 scene understanding tasks, eg, segmentation\nand tracking, crucial for appications, such as autonomous driving, robotics.\nWith the recent emergence of foundation models, the community is, however,\nimpeded by the lack of large-scale, labelled real-world datasets. This is\ncaused by the inherent spherical properties, eg, severe distortion in polar\nregions, and content discontinuities, rendering the annotation costly yet\ncomplex. This paper introduces Leader360V, the first large-scale, labeled\nreal-world 360 video datasets for instance segmentation and tracking. Our\ndatasets enjoy high scene diversity, ranging from indoor and urban settings to\nnatural and dynamic outdoor scenes. To automate annotation, we design an\nautomatic labeling pipeline, which subtly coordinates pre-trained 2D segmentors\nand large language models to facilitate the labeling. The pipeline operates in\nthree novel stages. Specifically, in the Initial Annotation Phase, we introduce\na Semantic- and Distortion-aware Refinement module, which combines object mask\nproposals from multiple 2D segmentors with LLM-verified semantic labels. These\nare then converted into mask prompts to guide SAM2 in generating\ndistortion-aware masks for subsequent frames. In the Auto-Refine Annotation\nPhase, missing or incomplete regions are corrected either by applying the SDR\nagain or resolving the discontinuities near the horizontal borders. The Manual\nRevision Phase finally incorporates LLMs and human annotators to further refine\nand validate the annotations. Extensive user studies and evaluations\ndemonstrate the effectiveness of our labeling pipeline. Meanwhile, experiments\nconfirm that Leader360V significantly enhances model performance for 360 video\nsegmentation and tracking, paving the way for more scalable 360 scene\nunderstanding.", "published": "2025-06-17 07:37:08", "link": "http://arxiv.org/abs/2506.14271v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling", "abstract": "Image-based cell profiling aims to create informative representations of cell\nimages. This technique is critical in drug discovery and has greatly advanced\nwith recent improvements in computer vision. Inspired by recent developments in\nnon-contrastive Self-Supervised Learning (SSL), this paper provides an initial\nexploration into training a generalizable feature extractor for cell images\nusing such methods. However, there are two major challenges: 1) There is a\nlarge difference between the distributions of cell images and natural images,\ncausing the view-generation process in existing SSL methods to fail; and 2)\nUnlike typical scenarios where each representation is based on a single image,\ncell profiling often involves multiple input images, making it difficult to\neffectively combine all available information. To overcome these challenges, we\npropose SSLProfiler, a non-contrastive SSL framework specifically designed for\ncell profiling. We introduce specialized data augmentation and representation\npost-processing methods tailored to cell images, which effectively address the\nissues mentioned above and result in a robust feature extractor. With these\nimprovements, SSLProfiler won the Cell Line Transferability challenge at CVPR\n2025.", "published": "2025-06-17 07:25:57", "link": "http://arxiv.org/abs/2506.14265v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Comparison of Two Methods for Stationary Incident Detection Based on Background Image", "abstract": "In general, background subtraction-based methods are used to detect moving\nobjects in visual tracking applications. In this paper, we employed a\nbackground subtraction-based scheme to detect the temporarily stationary\nobjects. We proposed two schemes for stationary object detection, and we\ncompare those in terms of detection performance and computational complexity.\nIn the first approach, we used a single background, and in the second approach,\nwe used dual backgrounds, generated with different learning rates, in order to\ndetect temporarily stopped objects. Finally, we used normalized cross\ncorrelation (NCC) based image comparison to monitor and track the detected\nstationary object in a video scene. The proposed method is robust with partial\nocclusion, short-time fully occlusion, and illumination changes, and it can\noperate in real time.", "published": "2025-06-17 07:18:04", "link": "http://arxiv.org/abs/2506.14256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "synth-dacl: Does Synthetic Defect Data Enhance Segmentation Accuracy and Robustness for Real-World Bridge Inspections?", "abstract": "Adequate bridge inspection is increasingly challenging in many countries due\nto growing ailing stocks, compounded with a lack of staff and financial\nresources. Automating the key task of visual bridge inspection, classification\nof defects and building components on pixel level, improves efficiency,\nincreases accuracy and enhances safety in the inspection process and resulting\nbuilding assessment. Models overtaking this task must cope with an assortment\nof real-world conditions. They must be robust to variations in image quality,\nas well as background texture, as defects often appear on surfaces of diverse\ntexture and degree of weathering. dacl10k is the largest and most diverse\ndataset for real-world concrete bridge inspections. However, the dataset\nexhibits class imbalance, which leads to notably poor model performance\nparticularly when segmenting fine-grained classes such as cracks and cavities.\nThis work introduces \"synth-dacl\", a compilation of three novel dataset\nextensions based on synthetic concrete textures. These extensions are designed\nto balance class distribution in dacl10k and enhance model performance,\nespecially for crack and cavity segmentation. When incorporating the synth-dacl\nextensions, we observe substantial improvements in model robustness across 15\nperturbed test sets. Notably, on the perturbed test set, a model trained on\ndacl10k combined with all synthetic extensions achieves a 2% increase in mean\nIoU, F1 score, Recall, and Precision compared to the same model trained solely\non dacl10k.", "published": "2025-06-17 07:17:15", "link": "http://arxiv.org/abs/2506.14255v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition", "abstract": "LiDAR-based place recognition serves as a crucial enabler for long-term\nautonomy in robotics and autonomous driving systems. Yet, prevailing\nmethodologies relying on handcrafted feature extraction face dual challenges:\n(1) Inconsistent point cloud density, induced by ego-motion dynamics and\nenvironmental disturbances during repeated traversals, leads to descriptor\ninstability, and (2) Representation fragility stems from reliance on\nsingle-level geometric abstractions that lack discriminative power in\nstructurally complex scenarios. To address these limitations, we propose a\nnovel framework that redefines 3D place recognition through density-agnostic\ngeometric reasoning. Specifically, we introduce an implicit 3D representation\nbased on elastic points, which is immune to the interference of original scene\npoint cloud density and achieves the characteristic of uniform distribution.\nSubsequently, we derive the occupancy grid and normal vector information of the\nscene from this implicit representation. Finally, with the aid of these two\ntypes of information, we obtain descriptors that fuse geometric information\nfrom both bird's-eye view (capturing macro-level spatial layouts) and 3D\nsegment (encoding micro-scale surface geometries) perspectives. We conducted\nextensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT)\nacross diverse environments. The experimental results demonstrate that our\nmethod achieves state-of-the-art performance. Moreover, our approach strikes an\noptimal balance between accuracy, runtime, and memory optimization for\nhistorical maps, showcasing excellent Resilient and scalability. Our code will\nbe open-sourced in the future.", "published": "2025-06-17 07:04:07", "link": "http://arxiv.org/abs/2506.14243v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unified Representation Space for 3D Visual Grounding", "abstract": "3D visual grounding (3DVG) is a critical task in scene understanding that\naims to identify objects in 3D scenes based on text descriptions. However,\nexisting methods rely on separately pre-trained vision and text encoders,\nresulting in a significant gap between the two modalities in terms of spatial\ngeometry and semantic categories. This discrepancy often causes errors in\nobject positioning and classification. The paper proposes UniSpace-3D, which\ninnovatively introduces a unified representation space for 3DVG, effectively\nbridging the gap between visual and textual features. Specifically, UniSpace-3D\nincorporates three innovative designs: i) a unified representation encoder that\nleverages the pre-trained CLIP model to map visual and textual features into a\nunified representation space, effectively bridging the gap between the two\nmodalities; ii) a multi-modal contrastive learning module that further reduces\nthe modality gap; iii) a language-guided query selection module that utilizes\nthe positional and semantic information to identify object candidate points\naligned with textual descriptions. Extensive experiments demonstrate that\nUniSpace-3D outperforms baseline models by at least 2.24% on the ScanRefer and\nNr3D/Sr3D datasets. The code will be made available upon acceptance of the\npaper.", "published": "2025-06-17 06:53:15", "link": "http://arxiv.org/abs/2506.14238v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AMPLIFY: Actionless Motion Priors for Robot Learning from Videos", "abstract": "Action-labeled data for robotics is scarce and expensive, limiting the\ngeneralization of learned policies. In contrast, vast amounts of action-free\nvideo data are readily available, but translating these observations into\neffective policies remains a challenge. We introduce AMPLIFY, a novel framework\nthat leverages large-scale video data by encoding visual dynamics into compact,\ndiscrete motion tokens derived from keypoint trajectories. Our modular approach\nseparates visual motion prediction from action inference, decoupling the\nchallenges of learning what motion defines a task from how robots can perform\nit. We train a forward dynamics model on abundant action-free videos and an\ninverse dynamics model on a limited set of action-labeled examples, allowing\nfor independent scaling. Extensive evaluations demonstrate that the learned\ndynamics are both accurate, achieving up to 3.7x better MSE and over 2.5x\nbetter pixel prediction accuracy compared to prior approaches, and broadly\nuseful. In downstream policy learning, our dynamics predictions enable a\n1.2-2.2x improvement in low-data regimes, a 1.4x average improvement by\nlearning from action-free human videos, and the first generalization to LIBERO\ntasks from zero in-distribution action data. Beyond robotic control, we find\nthe dynamics learned by AMPLIFY to be a versatile latent world model, enhancing\nvideo prediction quality. Our results present a novel paradigm leveraging\nheterogeneous data sources to build efficient, generalizable world models. More\ninformation can be found at https://amplify-robotics.github.io/.", "published": "2025-06-17 05:31:42", "link": "http://arxiv.org/abs/2506.14198v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Egocentric Human-Object Interaction Detection: A New Benchmark and Method", "abstract": "Understanding the interaction between humans and objects has gained much\nattention in recent years. Existing human-object interaction (HOI) detection\nmethods mainly focus on the third-person perspectives, overlooking a more\nintuitive way from the egocentric view of HOI, namely Ego-HOI. This paper\nintroduces an Ego-HOIBench, a new dataset to promote the benchmarking and\ndevelopment of Ego-HOI detection. Our Ego-HOIBench comprises more than 27K\negocentric images with high-quality hand-verb-object triplet annotations across\n123 fine-grained interaction categories and locations, covering a rich\ndiversity of scenarios, object types, and hand configurations in daily\nactivities. In addition, we explore and adapt third-person HOI detection\nmethods to Ego-HOIBench and illustrate the challenges of hand-occluded objects\nand the complexity of single- and two-hand interactions. To build a new\nbaseline, we propose a Hand Geometry and Interactivity Refinement (HGIR)\nscheme, which leverages hand pose and geometric information as valuable cues\nfor interpreting interactions. Specifically, the HGIR scheme explicitly\nextracts global hand geometric features from the estimated hand pose proposals\nand refines the interaction-specific features using pose-interaction attention.\nThis scheme enables the model to obtain a robust and powerful interaction\nrepresentation, significantly improving the Ego-HOI detection capability. Our\napproach is lightweight and effective, and it can be easily applied to HOI\nbaselines in a plug-and-play manner to achieve state-of-the-art results on\nEgo-HOIBench. Our project is available at:\nhttps://dengkunyuan.github.io/EgoHOIBench/", "published": "2025-06-17 05:03:42", "link": "http://arxiv.org/abs/2506.14189v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Meta-SurDiff: Classification Diffusion Model Optimized by Meta Learning is Reliable for Online Surgical Phase Recognition", "abstract": "Online surgical phase recognition has drawn great attention most recently due\nto its potential downstream applications closely related to human life and\nhealth. Despite deep models have made significant advances in capturing the\ndiscriminative long-term dependency of surgical videos to achieve improved\nrecognition, they rarely account for exploring and modeling the uncertainty in\nsurgical videos, which should be crucial for reliable online surgical phase\nrecognition. We categorize the sources of uncertainty into two types, frame\nambiguity in videos and unbalanced distribution among surgical phases, which\nare inevitable in surgical videos. To address this pivot issue, we introduce a\nmeta-learning-optimized classification diffusion model (Meta-SurDiff), to take\nfull advantage of the deep generative model and meta-learning in achieving\nprecise frame-level distribution estimation for reliable online surgical phase\nrecognition. For coarse recognition caused by ambiguous video frames, we employ\na classification diffusion model to assess the confidence of recognition\nresults at a finer-grained frame-level instance. For coarse recognition caused\nby unbalanced phase distribution, we use a meta-learning based objective to\nlearn the diffusion model, thus enhancing the robustness of classification\nboundaries for different surgical phases.We establish effectiveness of\nMeta-SurDiff in online surgical phase recognition through extensive experiments\non five widely used datasets using more than four practical metrics. The\ndatasets include Cholec80, AutoLaparo, M2Cai16, OphNet, and NurViD, where\nOphNet comes from ophthalmic surgeries, NurViD is the daily care dataset, while\nthe others come from laparoscopic surgeries. We will release the code upon\nacceptance.", "published": "2025-06-17 04:48:59", "link": "http://arxiv.org/abs/2506.14181v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "One-Shot Neural Architecture Search with Network Similarity Directed Initialization for Pathological Image Classification", "abstract": "Deep learning-based pathological image analysis presents unique challenges\ndue to the practical constraints of network design. Most existing methods apply\ncomputer vision models directly to medical tasks, neglecting the distinct\ncharacteristics of pathological images. This mismatch often leads to\ncomputational inefficiencies, particularly in edge-computing scenarios. To\naddress this, we propose a novel Network Similarity Directed Initialization\n(NSDI) strategy to improve the stability of neural architecture search (NAS).\nFurthermore, we introduce domain adaptation into one-shot NAS to better handle\nvariations in staining and semantic scale across pathology datasets.\nExperiments on the BRACS dataset demonstrate that our method outperforms\nexisting approaches, delivering both superior classification performance and\nclinically relevant feature localization.", "published": "2025-06-17 04:37:02", "link": "http://arxiv.org/abs/2506.14176v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology", "abstract": "In this paper, we construct two research objectives: i) explore the learned\nembedding space of BiomedCLIP, an open-source large vision language model, to\nanalyse meaningful class separations, and ii) quantify the limitations of\nBiomedCLIP when applied to a highly imbalanced, out-of-distribution multi-label\nmedical dataset. We experiment on IU-xray dataset, which exhibits the\naforementioned criteria, and evaluate BiomedCLIP in classifying images\n(radiographs) in three contexts: zero-shot inference, full finetuning, and\nlinear probing. The results show that the model under zero-shot settings\nover-predicts all labels, leading to poor precision and inter-class\nseparability. Full fine-tuning improves classification of distinct diseases,\nwhile linear probing detects overlapping features. We demonstrate visual\nunderstanding of the model using Grad-CAM heatmaps and compare with 15\nannotations by a radiologist. We highlight the need for careful adaptations of\nthe models to foster reliability and applicability in a real-world setting. The\ncode for the experiments in this work is available and maintained on GitHub.", "published": "2025-06-17 02:59:42", "link": "http://arxiv.org/abs/2506.14136v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation", "abstract": "Accurate action inference is critical for vision-based robotic manipulation.\nExisting approaches typically follow either a Vision-to-Action (V-A) paradigm,\npredicting actions directly from visual inputs, or a Vision-to-3D-to-Action\n(V-3D-A) paradigm, leveraging intermediate 3D representations. However, these\nmethods often struggle with action inaccuracies due to the complexity and\ndynamic nature of manipulation scenes. In this paper, we propose a V-4D-A\nframework that enables direct action reasoning from motion-aware 4D\nrepresentations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian\nSplatting (3DGS) by incorporating learnable motion attributes, allowing\nsimultaneous modeling of dynamic scenes and manipulation actions. To learn\ntime-varying scene geometry and action-aware robot motion, GAF supports three\nkey query types: reconstruction of the current scene, prediction of future\nframes, and estimation of initial action via robot motion. Furthermore, the\nhigh-quality current and future frames generated by GAF facilitate manipulation\naction refinement through a GAF-guided diffusion model. Extensive experiments\ndemonstrate significant improvements, with GAF achieving +11.5385 dB PSNR and\n-0.5574 LPIPS improvements in reconstruction quality, while boosting the\naverage success rate in robotic manipulation tasks by 10.33% over\nstate-of-the-art methods. Project page:\nhttp://chaiying1.github.io/GAF.github.io/project_page/", "published": "2025-06-17 02:55:20", "link": "http://arxiv.org/abs/2506.14135v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "FADPNet: Frequency-Aware Dual-Path Network for Face Super-Resolution", "abstract": "Face super-resolution (FSR) under limited computational costs remains an open\nproblem. Existing approaches typically treat all facial pixels equally,\nresulting in suboptimal allocation of computational resources and degraded FSR\nperformance. CNN is relatively sensitive to high-frequency facial features,\nsuch as component contours and facial outlines. Meanwhile, Mamba excels at\ncapturing low-frequency features like facial color and fine-grained texture,\nand does so with lower complexity than Transformers. Motivated by these\nobservations, we propose FADPNet, a Frequency-Aware Dual-Path Network that\ndecomposes facial features into low- and high-frequency components and\nprocesses them via dedicated branches. For low-frequency regions, we introduce\na Mamba-based Low-Frequency Enhancement Block (LFEB), which combines\nstate-space attention with squeeze-and-excitation operations to extract\nlow-frequency global interactions and emphasize informative channels. For\nhigh-frequency regions, we design a CNN-based Deep Position-Aware Attention\n(DPA) module to enhance spatially-dependent structural details, complemented by\na lightweight High-Frequency Refinement (HFR) module that further refines\nfrequency-specific representations. Through the above designs, our method\nachieves an excellent balance between FSR quality and model efficiency,\noutperforming existing approaches.", "published": "2025-06-17 02:33:42", "link": "http://arxiv.org/abs/2506.14121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "D\u00e9j\u00e0 Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse", "abstract": "Recently, Video-Language Models (VideoLMs) have demonstrated remarkable\ncapabilities, offering significant potential for flexible and powerful video\nquery systems. These models typically rely on Vision Transformers (ViTs), which\nprocess video frames individually to extract visual embeddings. However,\ngenerating embeddings for large-scale videos requires ViT inferencing across\nnumerous frames, posing a major hurdle to real-world deployment and\nnecessitating solutions for integration into scalable video data management\nsystems. This paper introduces D\\'ej\\`a Vu, a video-language query engine that\naccelerates ViT-based VideoLMs by reusing computations across consecutive\nframes. At its core is ReuseViT, a modified ViT model specifically designed for\nVideoLM tasks, which learns to detect inter-frame reuse opportunities, striking\nan effective balance between accuracy and reuse. Although ReuseViT\nsignificantly reduces computation, these savings do not directly translate into\nperformance gains on GPUs. To overcome this, D\\'ej\\`a Vu integrates\nmemory-compute joint compaction techniques that convert the FLOP savings into\ntangible performance gains. Evaluations on three VideoLM tasks show that\nD\\'ej\\`a Vu accelerates embedding generation by up to a 2.64x within a 2% error\nbound, dramatically enhancing the practicality of VideoLMs for large-scale\nvideo analytics.", "published": "2025-06-17 01:59:10", "link": "http://arxiv.org/abs/2506.14107v1", "categories": ["cs.DC", "cs.CV"], "primary_category": "cs.DC"}
{"title": "Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems", "abstract": "The integration of Large Language Models (LLMs) with computer vision is\nprofoundly transforming perception tasks like image segmentation. For\nintelligent transportation systems (ITS), where accurate scene understanding is\ncritical for safety and efficiency, this new paradigm offers unprecedented\ncapabilities. This survey systematically reviews the emerging field of\nLLM-augmented image segmentation, focusing on its applications, challenges, and\nfuture directions within ITS. We provide a taxonomy of current approaches based\non their prompting mechanisms and core architectures, and we highlight how\nthese innovations can enhance road scene understanding for autonomous driving,\ntraffic monitoring, and infrastructure maintenance. Finally, we identify key\nchallenges, including real-time performance and safety-critical reliability,\nand outline a perspective centered on explainable, human-centric AI as a\nprerequisite for the successful deployment of this technology in\nnext-generation transportation systems.", "published": "2025-06-17 01:20:50", "link": "http://arxiv.org/abs/2506.14096v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Ultimate Signs of Second-Order Holonomic Sequences", "abstract": "A real-valued sequence $f = \\{ f(n) \\}_{n \\in \\mathbb{N}}$ is said to be\nsecond-order holonomic if it satisfies a linear recurrence $f (n + 2) = P (n) f\n(n + 1) + Q (n) f (n)$ for all sufficiently large $n$, where $P, Q \\in\n\\mathbb{R}(x)$ are rational functions. We study the ultimate sign of such a\nsequence, i.e., the repeated pattern that the signs of $f (n)$ follow for\nsufficiently large $n$. For each $P$, $Q$ we determine all the ultimate signs\nthat $f$ can have, and show how they partition the space of initial values of\n$f$. This completes the prior work by Neumann, Ouaknine and Worrell, who have\nsettled some restricted cases. As a corollary, it follows that when $P$, $Q$\nhave rational coefficients, $f$ either has an ultimate sign of length $1$, $2$,\n$3$, $4$, $6$, $8$ or $12$, or never falls into a repeated sign pattern. We\nalso give a partial algorithm that finds the ultimate sign of $f$ (or tells\nthat there is none) in almost all cases.", "published": "2025-06-17 17:43:13", "link": "http://arxiv.org/abs/2506.14751v1", "categories": ["cs.DM", "68R06", "G.2.m; F.2.2"], "primary_category": "cs.DM"}
{"title": "A group-theoretic approach to Shannon capacity of graphs and a limit theorem from lattice packings", "abstract": "We develop a group-theoretic approach to the Shannon capacity problem. Using\nthis approach we extend and recover, in a structured and unified manner,\nvarious families of previously known lower bounds on the Shannon capacity.\nBohman (2003) proved that, in the limit $p\\to\\infty$, the Shannon capacity of\ncycle graphs $\\Theta(C_p)$ converges to the fractional clique covering number,\nthat is, $\\lim_{p \\to \\infty} p/2 - \\Theta(C_p) = 0$. We strengthen this result\nby proving that the same is true for all fraction graphs: $\\lim_{p/q \\to\n\\infty} p/q - \\Theta(E_{p/q}) = 0$. Here the fraction graph $E_{p/q}$ is the\ngraph with vertex set $\\mathbb{Z}/p\\mathbb{Z}$ in which two distinct vertices\nare adjacent if and only if their distance mod $p$ is strictly less than $q$.\nWe obtain the limit via the group-theoretic approach. In particular, the\nindependent sets we construct in powers of fraction graphs are subgroups (and,\nin fact, lattices). Our approach circumvents known barriers for structured\n(\"linear\") constructions of independent sets of\nCalderbank-Frankl-Graham-Li-Shepp (1993) and Guruswami-Riazanov (2021).", "published": "2025-06-17 15:46:28", "link": "http://arxiv.org/abs/2506.14654v1", "categories": ["math.CO", "cs.DM", "math.GR", "05C69", "G.2.2"], "primary_category": "math.CO"}
{"title": "What is and is not inside a Cayley graph?", "abstract": "In this note we show that there is a cubic graph of girth $5$ that is not a\nsubgraph of any minimal Cayley graph. On the other hand, we show that any\nGeneralized Petersen Graph $G(n,k)$ with $\\gcd(n,k)=1$ is an induced subgraph\nof a minimal Cayley graph. These results give insights into two comments of\nL\\'aszl\\'o Babai in [L. Babai, \\emph{Automorphism groups, isomorphism,\nreconstruction}. Graham, R. L. (ed.) et al., Handbook of combinatorics. Vol.\n1-2, 1994].", "published": "2025-06-17 01:06:54", "link": "http://arxiv.org/abs/2506.14088v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "A Systematic Replicability and Comparative Study of BSARec and SASRec for Sequential Recommendation", "abstract": "This study aims at comparing two sequential recommender systems:\nSelf-Attention based Sequential Recommendation (SASRec), and Beyond\nSelf-Attention based Sequential Recommendation (BSARec) in order to check the\nimprovement frequency enhancement - the added element in BSARec - has on\nrecommendations. The models in the study, have been re-implemented with a\ncommon base-structure from EasyRec, with the aim of obtaining a fair and\nreproducible comparison. The results obtained displayed how BSARec, by\nincluding bias terms for frequency enhancement, does indeed outperform SASRec,\nalthough the increases in performance obtained, are not as high as those\npresented by the authors. This work aims at offering an overview on existing\nmethods, and most importantly at underlying the importance of implementation\ndetails for performance comparison.", "published": "2025-06-17 16:29:55", "link": "http://arxiv.org/abs/2506.14692v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RMIT-ADM+S at the SIGIR 2025 LiveRAG Challenge", "abstract": "This paper presents the RMIT--ADM+S participation in the SIGIR 2025 LiveRAG\nChallenge. Our Generation-Retrieval-Augmented Generation (GRAG) approach relies\non generating a hypothetical answer that is used in the retrieval phase,\nalongside the original question. GRAG also incorporates a pointwise large\nlanguage model (LLM)-based re-ranking step prior to final answer generation. We\ndescribe the system architecture and the rationale behind our design choices.\nIn particular, a systematic evaluation using the Grid of Points (GoP) framework\nand N-way ANOVA enabled comparison across multiple configurations, including\nquery variant generation, question decomposition, rank fusion strategies, and\nprompting techniques for answer generation. Our system achieved a Relevance\nscore of 1.199 and a Faithfulness score of 0.477 on the private leaderboard,\nplacing among the top four finalists in the LiveRAG 2025 Challenge.", "published": "2025-06-17 13:41:12", "link": "http://arxiv.org/abs/2506.14516v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Vela: Scalable Embeddings with Voice Large Language Models for Multimodal Retrieval", "abstract": "Multimodal large language models (MLLMs) have seen substantial progress in\nrecent years. However, their ability to represent multimodal information in the\nacoustic domain remains underexplored. In this work, we introduce Vela, a novel\nframework designed to adapt MLLMs for the generation of universal multimodal\nembeddings. By leveraging MLLMs with specially crafted prompts and selected\nin-context learning examples, Vela effectively bridges the modality gap across\nvarious modalities. We then propose a single-modality training approach, where\nthe model is trained exclusively on text pairs. Our experiments show that Vela\noutperforms traditional CLAP models in standard text-audio retrieval tasks.\nFurthermore, we introduce new benchmarks that expose CLAP models' limitations\nin handling long texts and complex retrieval tasks. In contrast, Vela, by\nharnessing the capabilities of MLLMs, demonstrates robust performance in these\nscenarios. Our code will soon be available.", "published": "2025-06-17 12:10:19", "link": "http://arxiv.org/abs/2506.14445v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Similarity = Value? Consultation Value Assessment and Alignment for Personalized Search", "abstract": "Personalized search systems in e-commerce platforms increasingly involve user\ninteractions with AI assistants, where users consult about products, usage\nscenarios, and more. Leveraging consultation to personalize search services is\ntrending. Existing methods typically rely on semantic similarity to align\nhistorical consultations with current queries due to the absence of 'value'\nlabels, but we observe that semantic similarity alone often fails to capture\nthe true value of consultation for personalization. To address this, we propose\na consultation value assessment framework that evaluates historical\nconsultations from three novel perspectives: (1) Scenario Scope Value, (2)\nPosterior Action Value, and (3) Time Decay Value. Based on this, we introduce\nVAPS, a value-aware personalized search model that selectively incorporates\nhigh-value consultations through a consultation-user action interaction module\nand an explicit objective that aligns consultations with user actions.\nExperiments on both public and commercial datasets show that VAPS consistently\noutperforms baselines in both retrieval and ranking tasks.", "published": "2025-06-17 11:56:11", "link": "http://arxiv.org/abs/2506.14437v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "hyperFA*IR: A hypergeometric approach to fair rankings with finite candidate pool", "abstract": "Ranking algorithms play a pivotal role in decision-making processes across\ndiverse domains, from search engines to job applications. When rankings\ndirectly impact individuals, ensuring fairness becomes essential, particularly\nfor groups that are marginalised or misrepresented in the data. Most of the\nexisting group fairness frameworks often rely on ensuring proportional\nrepresentation of protected groups. However, these approaches face limitations\nin accounting for the stochastic nature of ranking processes or the finite size\nof candidate pools. To this end, we present hyperFA*IR, a framework for\nassessing and enforcing fairness in rankings drawn from a finite set of\ncandidates. It relies on a generative process based on the hypergeometric\ndistribution, which models real-world scenarios by sampling without replacement\nfrom fixed group sizes. This approach improves fairness assessment when top-$k$\nselections are large relative to the pool or when protected groups are small.\nWe compare our approach to the widely used binomial model, which treats each\ndraw as independent with fixed probability, and demonstrate$-$both analytically\nand empirically$-$that our method more accurately reproduces the statistical\nproperties of sampling from a finite population. To operationalise this\nframework, we propose a Monte Carlo-based algorithm that efficiently detects\nunfair rankings by avoiding computationally expensive parameter tuning.\nFinally, we adapt our generative approach to define affirmative action policies\nby introducing weights into the sampling process.", "published": "2025-06-17 09:45:08", "link": "http://arxiv.org/abs/2506.14349v1", "categories": ["cs.CY", "cs.IR", "stat.AP"], "primary_category": "cs.CY"}
{"title": "Joint Error Correction and Fading Channel Estimation Enhancement Leveraging GRAND", "abstract": "We present a novel method for error correction in the presence of fading\nchannel estimation errors (CEE). When such errors are significant, considerable\nperformance losses can be observed if the wireless transceiver is not adapted.\nInstead of refining the estimate by increasing the pilot sequence length or\nimproving the estimation algorithm, we propose two new approaches based on\nGuessing Random Additive Noise Decoding (GRAND) decoders. The first method\ninvolves testing multiple candidates for the channel estimate located in the\ncomplex neighborhood around the original pilot-based estimate. All these\ncandidates are employed in parallel to compute log-likelihood ratios (LLR).\nThese LLRs are used as soft input to Ordered Reliability Bits GRAND (ORBGRAND).\nPosterior likelihood formulas associated with ORBGRAND are then computed to\ndetermine which channel candidate leads to the most probable codeword. The\nsecond method is a refined version of the first approach accounting for the\npresence of residual CEE in the LLR computation. The performance of these two\ntechniques is evaluated for [128,112] 5G NR CA-Polar and CRC codes. For the\nconsidered settings, block error rate (BLER) gains of several dBs are observed\ncompared to cases where CEE is ignored.", "published": "2025-06-17 17:50:44", "link": "http://arxiv.org/abs/2506.14756v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Union-Intersection Union-Find for Decoding Depolarizing Errors in Topological Codes", "abstract": "In this paper, we introduce the Union-Intersection Union-Find (UIUF)\nalgorithm for decoding depolarizing errors in topological codes, combining the\nstrengths of iterative and standard Union-Find (UF) decoding. While iterative\nUF improves performance at moderate error rates, it lacks an error correction\nguarantee. To address this, we develop UIUF, which maintains the enhanced\nperformance of iterative UF while ensuring error correction up to half the code\ndistance. Through simulations under code capacity, phenomenological, and biased\nnoise models, we show that UIUF significantly outperforms UF, reducing the\nlogical error rate by over an order of magnitude (at around $10^{-5}$).\nMoreover, UIUF achieves lower logical error rates than the Minimum Weight\nPerfect Matching (MWPM) decoder on rotated surface codes under both the code\ncapacity and phenomenological noise models, while preserving efficient\nlinear-time complexity.", "published": "2025-06-17 17:30:14", "link": "http://arxiv.org/abs/2506.14745v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "A stochastic noise model based excess noise factor expressions for staircase avalanche photodiodes", "abstract": "Multistep staircase avalanche photodiodes (APDs) are the solid-state analogue\nof photomultiplier tubes, owing to their deterministic amplification with\ntwofold stepwise gain via impact ionization. Yet, the stepwise impact\nionization irregularities worsen with increasing step counts, which are a major\nsource of internal noise in these APDs. Some noise models for staircase APDs\nhave been previously reported, where the excess noise factor expressions are\nbased on Friis' noise factor formula for cascade networks, erroneously\nconsidering the power gains as the gains. Excess noise factor being a key\ncomponent in staircase APDs' noise models, we formulate generalized excess\nnoise factor expressions for multilayer graded-bandgap APDs in terms of their\nlayer-wise ionization probabilities, applicable for all operating biases, which\ninclude the sub-threshold, staircase, and tunnelling breakdown regimes. We\nfurther derive simplified expressions for staircase APDs and prove that these\nexpressions match Bangera's corrections to Friis' noise factor formulas for\ncascade networks.", "published": "2025-06-17 16:58:44", "link": "http://arxiv.org/abs/2506.14722v1", "categories": ["eess.SP", "cs.IT", "math.IT", "math.PR", "physics.app-ph", "physics.comp-ph"], "primary_category": "eess.SP"}
{"title": "Fronthaul-Aware User-Centric Generalized Cell-Free Massive MIMO Systems", "abstract": "We consider fronthaul-limited generalized zeroforcing-based cell-free massive\nmultiple-input multiple-output (CF-mMIMO) systems with multiple-antenna users\nand multipleantenna access points (APs) relying on both cooperative beamforming\n(CB) and user-centric (UC) clustering. The proposed framework is very general\nand can be degenerated into different special cases, such as pure CB/pure UC\nclustering, or fully centralized CB/fully distributed beamforming. We\ncomprehensively analyze the spectral efficiency (SE) performance of the system\nwherein the users use the minimum mean-squared errorbased successive\ninterference cancellation (MMSE-SIC) scheme to detect the desired signals.\nSpecifically, we formulate an optimization problem for the user association and\npower control for maximizing the sum SE. The formulated problem is under per-AP\ntransmit power and fronthaul constraints, and is based on only long-term\nchannel state information (CSI). The challenging formulated problem is\ntransformed into tractable form and a novel algorithm is proposed to solve it\nusing minorization maximization (MM) technique. We analyze the trade-offs\nprovided by the CF-mMIMO system with different number of CB clusters, hence\nhighlighting the importance of the appropriate choice of CB design for\ndifferent system setups. Numerical results show that for the centralized CB,\nthe proposed power optimization provides nearly 59% improvement in the average\nsum SE over the heuristic approach, and 312% improvement, when the distributed\nbeamforming is employed.", "published": "2025-06-17 13:15:03", "link": "http://arxiv.org/abs/2506.14494v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Covert Capacity of AWGN Channels under Average Error Probability", "abstract": "We derive upper and lower bounds for the covert capacity of Additive White\nGaussian Noise channels when measuring reliability in terms of the average\nerror probability and covertness in terms of Kullback-Leibler divergence. This\ncharacterization confirms the absence of strong converse for this setting in\nboth the reliability and covertness parameters. The crux of our approach is to\nanalyze a codebook of BPSK-modulated codewords carefully augmented with\n\"all-zero\" codewords.", "published": "2025-06-17 13:00:12", "link": "http://arxiv.org/abs/2506.14483v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Identification for Molecular Communication Based on Diffusion Channel with Poisson Reception Process", "abstract": "Molecular communication (MC) enables information exchange at the nano- and\nmicroscale, with applications in areas like drug delivery and health\nmonitoring. These event-driven scenarios often require alternatives to\ntraditional transmission. Identification communication, introduced by Ahlswede\nand Dueck, offers such an approach, in which the receiver only determines\nwhether a specific message was sent, suiting resource-limited and\nevent-triggered systems. This paper combines MC with identification and\nproposes a one-dimensional (1D) diffusion-based model. Diffusion noise is\nmodeled as a Poisson process, and a lower bound on channel capacity is derived.\nSimulations, microscopic, and with short-length deterministic codes, validate\ntheoretical results, including the channel impulse response and error bounds.\nThe findings support the design of practical MC systems, with potential use in\ntestbed development.", "published": "2025-06-17 10:00:31", "link": "http://arxiv.org/abs/2506.14360v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacity Characterization of Pinching-Antenna Systems", "abstract": "Unlike conventional systems using a fixed-location antenna, the channel\ncapacity of the pinching-antenna system (PASS) is determined by the activated\npositions of pinching antennas. This article characterizes the capacity region\nof multiuser PASS, where a single pinched waveguide is deployed to enable both\nuplink and downlink communications. The capacity region of the uplink channel\nis first characterized. \\romannumeral1) For the single-pinch case, closed-form\nexpressions are derived for the optimal antenna activation position, along with\nthe corresponding capacity region and the achievable data rate regions under\ntime-division multiple access (TDMA) and frequency-division multiple access\n(FDMA). It is proven that the capacity region of PASS encompasses that of\nconventional fixed-antenna systems, and that the FDMA rate region contains the\nTDMA rate region. \\romannumeral2) For the multiple-pinch case, inner and outer\nbounds on the capacity region are derived using an element-wise alternating\nantenna position optimization technique and the Cauchy-Schwarz inequality,\nrespectively. The achievable FDMA rate region is also derived using the same\noptimization framework, while the TDMA rate region is obtained through an\nantenna position refinement approach. The analysis is then extended to the\ndownlink PASS using the uplink-downlink duality framework. It is proven that\nthe relationships among the downlink capacity and rate regions are consistent\nwith those in the uplink case. Numerical results demonstrate that:\n\\romannumeral1) the derived bounds closely approximate the exact capacity\nregion, \\romannumeral2) PASS yields a significantly enlarged capacity region\ncompared to conventional fixed-antenna systems, and \\romannumeral3) in the\nmultiple-pinch case, TDMA and FDMA are capable of approaching the channel\ncapacity limit.", "published": "2025-06-17 08:17:21", "link": "http://arxiv.org/abs/2506.14298v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Large Language Model Empowered Design of Fluid Antenna Systems: Challenges, Frameworks, and Case Studies for 6G", "abstract": "The Fluid Antenna System (FAS), which enables flexible Multiple-Input\nMultiple-Output (MIMO) communications, introduces new spatial degrees of\nfreedom for next-generation wireless networks. Unlike traditional MIMO, FAS\ninvolves joint port selection and precoder design, a combinatorial NP-hard\noptimization problem. Moreover, fully leveraging FAS requires acquiring Channel\nState Information (CSI) across its ports, a challenge exacerbated by the\nsystem's near-continuous reconfigurability. These factors make traditional\nsystem design methods impractical for FAS due to nonconvexity and prohibitive\ncomputational complexity. While deep learning (DL)-based approaches have been\nproposed for MIMO optimization, their limited generalization and fitting\ncapabilities render them suboptimal for FAS. In contrast, Large Language Models\n(LLMs) extend DL's capabilities by offering general-purpose adaptability,\nreasoning, and few-shot learning, thereby overcoming the limitations of\ntask-specific, data-intensive models. This article presents a vision for\nLLM-driven FAS design, proposing a novel flexible communication framework. To\ndemonstrate the potential, we examine LLM-enhanced FAS in multiuser scenarios,\nshowcasing how LLMs can revolutionize FAS optimization.", "published": "2025-06-17 08:02:19", "link": "http://arxiv.org/abs/2506.14288v1", "categories": ["cs.IT", "math.IT", "fluid antenna system"], "primary_category": "cs.IT"}
{"title": "Markov Regime-Switching Intelligent Driver Model for Interpretable Car-Following Behavior", "abstract": "Accurate and interpretable car-following models are essential for traffic\nsimulation and autonomous vehicle development. However, classical models like\nthe Intelligent Driver Model (IDM) are fundamentally limited by their\nparsimonious and single-regime structure. They fail to capture the multi-modal\nnature of human driving, where a single driving state (e.g., speed, relative\nspeed, and gap) can elicit many different driver actions. This forces the model\nto average across distinct behaviors, reducing its fidelity and making its\nparameters difficult to interpret. To overcome this, we introduce a\nregime-switching framework that allows driving behavior to be governed by\ndifferent IDM parameter sets, each corresponding to an interpretable behavioral\nmode. This design enables the model to dynamically switch between interpretable\nbehavioral modes, rather than averaging across diverse driving contexts. We\ninstantiate the framework using a Factorial Hidden Markov Model with IDM\ndynamics (FHMM-IDM), which explicitly separates intrinsic driving regimes\n(e.g., aggressive acceleration, steady-state following) from external traffic\nscenarios (e.g., free-flow, congestion, stop-and-go) through two independent\nlatent Markov processes. Bayesian inference via Markov chain Monte Carlo (MCMC)\nis used to jointly estimate the regime-specific parameters, transition\ndynamics, and latent state trajectories. Experiments on the HighD dataset\ndemonstrate that FHMM-IDM uncovers interpretable structure in human driving,\neffectively disentangling internal driver actions from contextual traffic\nconditions and revealing dynamic regime-switching patterns. This framework\nprovides a tractable and principled solution to modeling context-dependent\ndriving behavior under uncertainty, offering improvements in the fidelity of\ntraffic simulations, the efficacy of safety analyses, and the development of\nmore human-centric ADAS.", "published": "2025-06-17 17:55:42", "link": "http://arxiv.org/abs/2506.14762v1", "categories": ["stat.AP", "cs.LG", "cs.RO"], "primary_category": "stat.AP"}
{"title": "On the Hardness of Bandit Learning", "abstract": "We study the task of bandit learning, also known as best-arm identification,\nunder the assumption that the true reward function f belongs to a known, but\narbitrary, function class F. We seek a general theory of bandit learnability,\nakin to the PAC framework for classification. Our investigation is guided by\nthe following two questions: (1) which classes F are learnable, and (2) how\nthey are learnable. For example, in the case of binary PAC classification,\nlearnability is fully determined by a combinatorial dimension - the VC\ndimension- and can be attained via a simple algorithmic principle, namely,\nempirical risk minimization (ERM). In contrast to classical learning-theoretic\nresults, our findings reveal limitations of learning in structured bandits,\noffering insights into the boundaries of bandit learnability. First, for the\nquestion of \"which\", we show that the paradigm of identifying the learnable\nclasses via a dimension-like quantity fails for bandit learning. We give a\nsimple proof demonstrating that no combinatorial dimension can characterize\nbandit learnability, even in finite classes, following a standard definition of\ndimension introduced by Ben-David et al. (2019). For the question of \"how\", we\nprove a computational hardness result: we construct a reward function class for\nwhich at most two queries are needed to find the optimal action, yet no\nalgorithm can do so in polynomial time unless RP=NP. We also prove that this\nclass admits efficient algorithms for standard algorithmic operations often\nconsidered in learning theory, such as an ERM. This implies that computational\nhardness is in this case inherent to the task of bandit learning. Beyond these\nresults, we investigate additional themes such as learning under noise,\ntrade-offs between noise models, and the relationship between query complexity\nand regret minimization.", "published": "2025-06-17 17:35:25", "link": "http://arxiv.org/abs/2506.14746v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "abstract": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks.", "published": "2025-06-17 16:07:36", "link": "http://arxiv.org/abs/2506.14673v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Feasibility-Driven Trust Region Bayesian Optimization", "abstract": "Bayesian optimization is a powerful tool for solving real-world optimization\ntasks under tight evaluation budgets, making it well-suited for applications\ninvolving costly simulations or experiments. However, many of these tasks are\nalso characterized by the presence of expensive constraints whose analytical\nformulation is unknown and often defined in high-dimensional spaces where\nfeasible regions are small, irregular, and difficult to identify. In such\ncases, a substantial portion of the optimization budget may be spent just\ntrying to locate the first feasible solution, limiting the effectiveness of\nexisting methods. In this work, we present a Feasibility-Driven Trust Region\nBayesian Optimization (FuRBO) algorithm. FuRBO iteratively defines a trust\nregion from which the next candidate solution is selected, using information\nfrom both the objective and constraint surrogate models. Our adaptive strategy\nallows the trust region to shift and resize significantly between iterations,\nenabling the optimizer to rapidly refocus its search and consistently\naccelerate the discovery of feasible and good-quality solutions. We empirically\ndemonstrate the effectiveness of FuRBO through extensive testing on the full\nBBOB-constrained COCO benchmark suite and other physics-inspired benchmarks,\ncomparing it against state-of-the-art baselines for constrained black-box\noptimization across varying levels of constraint severity and problem\ndimensionalities ranging from 2 to 60.", "published": "2025-06-17 15:16:22", "link": "http://arxiv.org/abs/2506.14619v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Expressive Score-Based Priors for Distribution Matching with Geometry-Preserving Regularization", "abstract": "Distribution matching (DM) is a versatile domain-invariant representation\nlearning technique that has been applied to tasks such as fair classification,\ndomain adaptation, and domain translation. Non-parametric DM methods struggle\nwith scalability and adversarial DM approaches suffer from instability and mode\ncollapse. While likelihood-based methods are a promising alternative, they\noften impose unnecessary biases through fixed priors or require explicit\ndensity models (e.g., flows) that can be challenging to train. We address this\nlimitation by introducing a novel approach to training likelihood-based DM\nusing expressive score-based prior distributions. Our key insight is that\ngradient-based DM training only requires the prior's score function -- not its\ndensity -- allowing us to train the prior via denoising score matching. This\napproach eliminates biases from fixed priors (e.g., in VAEs), enabling more\neffective use of geometry-preserving regularization, while avoiding the\nchallenge of learning an explicit prior density model (e.g., a flow-based\nprior). Our method also demonstrates better stability and computational\nefficiency compared to other diffusion-based priors (e.g., LSGM). Furthermore,\nexperiments demonstrate superior performance across multiple tasks,\nestablishing our score-based method as a stable and effective approach to\ndistribution matching. Source code available at\nhttps://github.com/inouye-lab/SAUB.", "published": "2025-06-17 15:08:16", "link": "http://arxiv.org/abs/2506.14607v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Deep Learning Surrogates for Real-Time Gas Emission Inversion", "abstract": "Real-time identification and quantification of greenhouse-gas emissions under\ntransient atmospheric conditions is a critical challenge in environmental\nmonitoring. We introduce a spatio-temporal inversion framework that embeds a\ndeep-learning surrogate of computational fluid dynamics (CFD) within a\nsequential Monte Carlo algorithm to perform Bayesian inference of both emission\nrate and source location in dynamic flow fields. By substituting costly\nnumerical solvers with a multilayer perceptron trained on high-fidelity CFD\noutputs, our surrogate captures spatial heterogeneity and temporal evolution of\ngas dispersion, while delivering near-real-time predictions. Validation on the\nChilbolton methane release dataset demonstrates comparable accuracy to full CFD\nsolvers and Gaussian plume models, yet achieves orders-of-magnitude faster\nruntimes. Further experiments under simulated obstructed-flow scenarios confirm\nrobustness in complex environments. This work reconciles physical fidelity with\ncomputational feasibility, offering a scalable solution for industrial\nemissions monitoring and other time-sensitive spatio-temporal inversion tasks\nin environmental and scientific modeling.", "published": "2025-06-17 15:03:21", "link": "http://arxiv.org/abs/2506.14597v1", "categories": ["cs.LG", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SCISSOR: Mitigating Semantic Bias through Cluster-Aware Siamese Networks for Robust Classification", "abstract": "Shortcut learning undermines model generalization to out-of-distribution\ndata. While the literature attributes shortcuts to biases in superficial\nfeatures, we show that imbalances in the semantic distribution of sample\nembeddings induce spurious semantic correlations, compromising model\nrobustness. To address this issue, we propose SCISSOR (Semantic Cluster\nIntervention for Suppressing ShORtcut), a Siamese network-based debiasing\napproach that remaps the semantic space by discouraging latent clusters\nexploited as shortcuts. Unlike prior data-debiasing approaches, SCISSOR\neliminates the need for data augmentation and rewriting. We evaluate SCISSOR on\n6 models across 4 benchmarks: Chest-XRay and Not-MNIST in computer vision, and\nGYAFC and Yelp in NLP tasks. Compared to several baselines, SCISSOR reports\n+5.3 absolute points in F1 score on GYAFC, +7.3 on Yelp, +7.7 on Chest-XRay,\nand +1 on Not-MNIST. SCISSOR is also highly advantageous for lightweight models\nwith ~9.5% improvement on F1 for ViT on computer vision datasets and ~11.9% for\nBERT on NLP. Our study redefines the landscape of model generalization by\naddressing overlooked semantic biases, establishing SCISSOR as a foundational\nframework for mitigating shortcut learning and fostering more robust,\nbias-resistant AI systems.", "published": "2025-06-17 14:49:29", "link": "http://arxiv.org/abs/2506.14587v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Perception of Phase Intercept Distortion and its Application in Data Augmentation", "abstract": "Phase distortion refers to the alteration of the phase relationships between\nfrequencies in a signal, which can be perceptible. In this paper, we discuss a\nspecial case of phase distortion known as phase-intercept distortion, which is\ncreated by a frequency-independent phase shift. We hypothesize that, though\nthis form of distortion changes a signal's waveform significantly, the\ndistortion is imperceptible. Human-subject experiment results are reported\nwhich are consistent with this hypothesis. Furthermore, we discuss how the\nimperceptibility of phase-intercept distortion can be useful for machine\nlearning, specifically for data augmentation. We conducted multiple experiments\nusing phase-intercept distortion as a novel approach to data augmentation, and\nobtained improved results for audio machine learning tasks.", "published": "2025-06-17 14:28:14", "link": "http://arxiv.org/abs/2506.14571v1", "categories": ["eess.SP", "cs.LG", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Single-Example Learning in a Mixture of GPDMs with Latent Geometries", "abstract": "We present the Gaussian process dynamical mixture model (GPDMM) and show its\nutility in single-example learning of human motion data. The Gaussian process\ndynamical model (GPDM) is a form of the Gaussian process latent variable model\n(GPLVM), but optimized with a hidden Markov model dynamical prior. The GPDMM\ncombines multiple GPDMs in a probabilistic mixture-of-experts framework,\nutilizing embedded geometric features to allow for diverse sequences to be\nencoded in a single latent space, enabling the categorization and generation of\neach sequence class. GPDMs and our mixture model are particularly advantageous\nin addressing the challenges of modeling human movement in scenarios where data\nis limited and model interpretability is vital, such as in patient-specific\nmedical applications like prosthesis control. We score the GPDMM on\nclassification accuracy and generative ability in single-example learning,\nshowcase model variations, and benchmark it against LSTMs, VAEs, and\ntransformers.", "published": "2025-06-17 14:22:07", "link": "http://arxiv.org/abs/2506.14563v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution", "abstract": "Effective decision-making on networks often relies on learning from\ngraph-structured data, where Graph Neural Networks (GNNs) play a central role,\nbut they take efforts to configure and tune. In this demo, we propose LLMNet,\nshowing how to design GNN automated through Large Language Models. Our system\ndevelops a set of agents that construct graph-related knowlege bases and then\nleverages Retrieval-Augmented Generation (RAG) to support automated\nconfiguration and refinement of GNN models through a knowledge-guided evolution\nprocess. These agents, equipped with specialized knowledge bases, extract\ninsights into tasks and graph structures by interacting with the knowledge\nbases. Empirical results show LLMNet excels in twelve datasets across three\ngraph learning tasks, validating its effectiveness of GNN model designing.", "published": "2025-06-17 13:53:48", "link": "http://arxiv.org/abs/2506.14529v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Improved Research Methodologies for Industrial AI: A case study of false call reduction", "abstract": "Are current artificial intelligence (AI) research methodologies ready to\ncreate successful, productive, and profitable AI applications? This work\npresents a case study on an industrial AI use case called false call reduction\nfor automated optical inspection to demonstrate the shortcomings of current\nbest practices. We identify seven weaknesses prevalent in related peer-reviewed\nwork and experimentally show their consequences. We show that the best-practice\nmethodology would fail for this use case. We argue amongst others for the\nnecessity of requirement-aware metrics to ensure achieving business objectives,\nclear definitions of success criteria, and a thorough analysis of temporal\ndynamics in experimental datasets. Our work encourages researchers to\ncritically assess their methodologies for more successful applied AI research.", "published": "2025-06-17 13:48:38", "link": "http://arxiv.org/abs/2506.14521v1", "categories": ["cs.LG", "I.2"], "primary_category": "cs.LG"}
{"title": "Two-Player Zero-Sum Games with Bandit Feedback", "abstract": "We study a two-player zero-sum game (TPZSG) in which the row player aims to\nmaximize their payoff against an adversarial column player, under an unknown\npayoff matrix estimated through bandit feedback. We propose and analyze two\nalgorithms: ETC-TPZSG, which directly applies ETC to the TPZSG setting and\nETC-TPZSG-AE, which improves upon it by incorporating an action pair\nelimination (AE) strategy that leverages the $\\varepsilon$-Nash Equilibrium\nproperty to efficiently select the optimal action pair. Our objective is to\ndemonstrate the applicability of ETC in a TPZSG setting by focusing on learning\npure strategy Nash Equilibrium. A key contribution of our work is a derivation\nof instance-dependent upper bounds on the expected regret for both algorithms,\nhas received limited attention in the literature on zero-sum games.\nParticularly, after $T$ rounds, we achieve an instance-dependent regret upper\nbounds of $O(\\Delta + \\sqrt{T})$ for ETC-TPZSG and $O(\\frac{\\log (T\n\\Delta^2)}{\\Delta})$ for ETC-TPZSG-AE, where $\\Delta$ denotes the suboptimality\ngap. Therefore, our results indicate that ETC-based algorithms perform\neffectively in adversarial game settings, achieving regret bounds comparable to\nexisting methods while providing insights through instance-dependent analysis.", "published": "2025-06-17 13:46:32", "link": "http://arxiv.org/abs/2506.14518v1", "categories": ["cs.LG", "cs.GT"], "primary_category": "cs.LG"}
{"title": "Reimagining Target-Aware Molecular Generation through Retrieval-Enhanced Aligned Diffusion", "abstract": "Breakthroughs in high-accuracy protein structure prediction, such as\nAlphaFold, have established receptor-based molecule design as a critical driver\nfor rapid early-phase drug discovery. However, most approaches still struggle\nto balance pocket-specific geometric fit with strict valence and synthetic\nconstraints. To resolve this trade-off, a Retrieval-Enhanced Aligned Diffusion\ntermed READ is introduced, which is the first to merge molecular\nRetrieval-Augmented Generation with an SE(3)-equivariant diffusion model.\nSpecifically, a contrastively pre-trained encoder aligns atom-level\nrepresentations during training, then retrieves graph embeddings of\npocket-matched scaffolds to guide each reverse-diffusion step at inference.\nThis single mechanism can inject real-world chemical priors exactly where\nneeded, producing valid, diverse, and shape-complementary ligands. Experimental\nresults demonstrate that READ can achieve very competitive performance in\nCBGBench, surpassing state-of-the-art generative models and even native\nligands. That suggests retrieval and diffusion can be co-optimized for faster,\nmore reliable structure-based drug design.", "published": "2025-06-17 13:09:11", "link": "http://arxiv.org/abs/2506.14488v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Adaptive Data Augmentation for Thompson Sampling", "abstract": "In linear contextual bandits, the objective is to select actions that\nmaximize cumulative rewards, modeled as a linear function with unknown\nparameters. Although Thompson Sampling performs well empirically, it does not\nachieve optimal regret bounds. This paper proposes a nearly minimax optimal\nThompson Sampling for linear contextual bandits by developing a novel estimator\nwith the adaptive augmentation and coupling of the hypothetical samples that\nare designed for efficient parameter learning. The proposed estimator\naccurately predicts rewards for all arms without relying on assumptions for the\ncontext distribution. Empirical results show robust performance and significant\nimprovement over existing methods.", "published": "2025-06-17 12:57:33", "link": "http://arxiv.org/abs/2506.14479v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Zeroth-Order Optimization is Secretly Single-Step Policy Optimization", "abstract": "Zeroth-Order Optimization (ZOO) provides powerful tools for optimizing\nfunctions where explicit gradients are unavailable or expensive to compute.\nHowever, the underlying mechanisms of popular ZOO methods, particularly those\nemploying randomized finite differences, and their connection to other\noptimization paradigms like Reinforcement Learning (RL) are not fully\nelucidated. This paper establishes a fundamental and previously unrecognized\nconnection: ZOO with finite differences is equivalent to a specific instance of\nsingle-step Policy Optimization (PO). We formally unveil that the implicitly\nsmoothed objective function optimized by common ZOO algorithms is identical to\na single-step PO objective. Furthermore, we show that widely used ZOO gradient\nestimators, are mathematically equivalent to the REINFORCE gradient estimator\nwith a specific baseline function, revealing the variance-reducing mechanism in\nZOO from a PO perspective.Built on this unified framework, we propose ZoAR\n(Zeroth-Order Optimization with Averaged Baseline and Query Reuse), a novel ZOO\nalgorithm incorporating PO-inspired variance reduction techniques: an averaged\nbaseline from recent evaluations and query reuse analogous to experience\nreplay. Our theoretical analysis further substantiates these techniques reduce\nvariance and enhance convergence. Extensive empirical studies validate our\ntheory and demonstrate that ZoAR significantly outperforms other methods in\nterms of convergence speed and final performance. Overall, our work provides a\nnew theoretical lens for understanding ZOO and offers practical algorithmic\nimprovements derived from its connection to PO.", "published": "2025-06-17 12:20:04", "link": "http://arxiv.org/abs/2506.14460v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Model-Mediated Stacked Ensemble Approach for Depression Prediction Among Professionals", "abstract": "Depression is a significant mental health concern, particularly in\nprofessional environments where work-related stress, financial pressure, and\nlifestyle imbalances contribute to deteriorating well-being. Despite increasing\nawareness, researchers and practitioners face critical challenges in developing\naccurate and generalizable predictive models for mental health disorders.\nTraditional classification approaches often struggle with the complexity of\ndepression, as it is influenced by multifaceted, interdependent factors,\nincluding occupational stress, sleep patterns, and job satisfaction. This study\naddresses these challenges by proposing a stacking-based ensemble learning\napproach to improve the predictive accuracy of depression classification among\nprofessionals. The Depression Professional Dataset has been collected from\nKaggle. The dataset comprises demographic, occupational, and lifestyle\nattributes that influence mental well-being. Our stacking model integrates\nmultiple base learners with a logistic regression-mediated model, effectively\ncapturing diverse learning patterns. The experimental results demonstrate that\nthe proposed model achieves high predictive performance, with an accuracy of\n99.64% on training data and 98.75% on testing data, with precision, recall, and\nF1-score all exceeding 98%. These findings highlight the effectiveness of\nensemble learning in mental health analytics and underscore its potential for\nearly detection and intervention strategies.", "published": "2025-06-17 12:19:40", "link": "http://arxiv.org/abs/2506.14459v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dataset distillation for memorized data: Soft labels can leak held-out teacher knowledge", "abstract": "Dataset distillation aims to compress training data into fewer examples via a\nteacher, from which a student can learn effectively. While its success is often\nattributed to structure in the data, modern neural networks also memorize\nspecific facts, but if and how such memorized information is can transferred in\ndistillation settings remains less understood. In this work, we show that\nstudents trained on soft labels from teachers can achieve non-trivial accuracy\non held-out memorized data they never directly observed. This effect persists\non structured data when the teacher has not generalized.To analyze it in\nisolation, we consider finite random i.i.d. datasets where generalization is a\npriori impossible and a successful teacher fit implies pure memorization.\nStill, students can learn non-trivial information about the held-out data, in\nsome cases up to perfect accuracy. In those settings, enough soft labels are\navailable to recover the teacher functionally - the student matches the\nteacher's predictions on all possible inputs, including the held-out memorized\ndata. We show that these phenomena strongly depend on the temperature with\nwhich the logits are smoothed, but persist across varying network capacities,\narchitectures and dataset compositions.", "published": "2025-06-17 12:18:37", "link": "http://arxiv.org/abs/2506.14457v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Detecting immune cells with label-free two-photon autofluorescence and deep learning", "abstract": "Label-free imaging has gained broad interest because of its potential to omit\nelaborate staining procedures which is especially relevant for in vivo use.\nLabel-free multiphoton microscopy (MPM), for instance, exploits two-photon\nexcitation of natural autofluorescence (AF) from native, metabolic proteins,\nmaking it ideal for in vivo endomicroscopy. Deep learning (DL) models have been\nwidely used in other optical imaging technologies to predict specific target\nannotations and thereby digitally augment the specificity of these label-free\nimages. However, this computational specificity has only rarely been\nimplemented for MPM. In this work, we used a data set of label-free MPM images\nfrom a series of different immune cell types (5,075 individual cells for binary\nclassification in mixed samples and 3,424 cells for a multi-class\nclassification task) and trained a convolutional neural network (CNN) to\nclassify cell types based on this label-free AF as input. A low-complexity\nsqueezeNet architecture was able to achieve reliable immune cell classification\nresults (0.89 ROC-AUC, 0.95 PR-AUC, for binary classification in mixed samples;\n0.689 F1 score, 0.697 precision, 0.748 recall, and 0.683 MCC for six-class\nclassification in isolated samples). Perturbation tests confirmed that the\nmodel is not confused by extracellular environment and that both input AF\nchannels (NADH and FAD) are about equally important to the classification. In\nthe future, such predictive DL models could directly detect specific immune\ncells in unstained images and thus, computationally improve the specificity of\nlabel-free MPM which would have great potential for in vivo endomicroscopy.", "published": "2025-06-17 12:14:02", "link": "http://arxiv.org/abs/2506.14449v1", "categories": ["cs.LG", "physics.optics"], "primary_category": "cs.LG"}
{"title": "A General Framework for Off-Policy Learning with Partially-Observed Reward", "abstract": "Off-policy learning (OPL) in contextual bandits aims to learn a\ndecision-making policy that maximizes the target rewards by using only\nhistorical interaction data collected under previously developed policies.\nUnfortunately, when rewards are only partially observed, the effectiveness of\nOPL degrades severely. Well-known examples of such partial rewards include\nexplicit ratings in content recommendations, conversion signals on e-commerce\nplatforms that are partial due to delay, and the issue of censoring in medical\nproblems. One possible solution to deal with such partial rewards is to use\nsecondary rewards, such as dwelling time, clicks, and medical indicators, which\nare more densely observed. However, relying solely on such secondary rewards\ncan also lead to poor policy learning since they may not align with the target\nreward. Thus, this work studies a new and general problem of OPL where the goal\nis to learn a policy that maximizes the expected target reward by leveraging\ndensely observed secondary rewards as supplemental data. We then propose a new\nmethod called Hybrid Policy Optimization for Partially-Observed Reward (HyPeR),\nwhich effectively uses the secondary rewards in addition to the\npartially-observed target reward to achieve effective OPL despite the\nchallenging scenario. We also discuss a case where we aim to optimize not only\nthe expected target reward but also the expected secondary rewards to some\nextent; counter-intuitively, we will show that leveraging the two objectives is\nin fact advantageous also for the optimization of only the target reward. Along\nwith statistical analysis of our proposed methods, empirical evaluations on\nboth synthetic and real-world data show that HyPeR outperforms existing methods\nin various scenarios.", "published": "2025-06-17 11:58:11", "link": "http://arxiv.org/abs/2506.14439v1", "categories": ["cs.LG", "62L05, 68T05", "I.2.6; G.3"], "primary_category": "cs.LG"}
{"title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "abstract": "Adapting large-scale foundation models in multi-task scenarios often suffers\nfrom task conflict and oblivion. To mitigate such issues, we propose a novel\n''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistant\nmulti-task adaptation method. Given a weight matrix of a pre-trained model, our\nmethod applies SVD to it and introduces a learnable router to adjust its\nsingular values based on tasks and samples. Accordingly, the weight matrix\nbecomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert\ncorresponds to the outer product of a left singular vector and the\ncorresponding right one. We can improve the model capacity by imposing a\nlearnable orthogonal transform on the right singular vectors. Unlike low-rank\nadaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts'\northogonality and maintains the column space of the original weight matrix.\nThese two properties make the adapted model resistant to the conflicts among\nthe new tasks and the oblivion of its original tasks, respectively. Experiments\non various datasets demonstrate that MoORE outperforms existing multi-task\nadaptation methods consistently, showing its superiority in terms of conflict-\nand oblivion-resistance. The code of the experiments is available at\nhttps://github.com/DaShenZi721/MoORE.", "published": "2025-06-17 11:55:08", "link": "http://arxiv.org/abs/2506.14436v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Unsupervised Skill Discovery through Skill Regions Differentiation", "abstract": "Unsupervised Reinforcement Learning (RL) aims to discover diverse behaviors\nthat can accelerate the learning of downstream tasks. Previous methods\ntypically focus on entropy-based exploration or empowerment-driven skill\nlearning. However, entropy-based exploration struggles in large-scale state\nspaces (e.g., images), and empowerment-based methods with Mutual Information\n(MI) estimations have limitations in state exploration. To address these\nchallenges, we propose a novel skill discovery objective that maximizes the\ndeviation of the state density of one skill from the explored regions of other\nskills, encouraging inter-skill state diversity similar to the initial MI\nobjective. For state-density estimation, we construct a novel conditional\nautoencoder with soft modularization for different skill policies in\nhigh-dimensional space. Meanwhile, to incentivize intra-skill exploration, we\nformulate an intrinsic reward based on the learned autoencoder that resembles\ncount-based exploration in a compact latent space. Through extensive\nexperiments in challenging state and image-based tasks, we find our method\nlearns meaningful skills and achieves superior performance in various\ndownstream tasks.", "published": "2025-06-17 11:30:04", "link": "http://arxiv.org/abs/2506.14420v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "One Size Fits None: Rethinking Fairness in Medical AI", "abstract": "Machine learning (ML) models are increasingly used to support clinical\ndecision-making. However, real-world medical datasets are often noisy,\nincomplete, and imbalanced, leading to performance disparities across patient\nsubgroups. These differences raise fairness concerns, particularly when they\nreinforce existing disadvantages for marginalized groups. In this work, we\nanalyze several medical prediction tasks and demonstrate how model performance\nvaries with patient characteristics. While ML models may demonstrate good\noverall performance, we argue that subgroup-level evaluation is essential\nbefore integrating them into clinical workflows. By conducting a performance\nanalysis at the subgroup level, differences can be clearly identified-allowing,\non the one hand, for performance disparities to be considered in clinical\npractice, and on the other hand, for these insights to inform the responsible\ndevelopment of more effective models. Thereby, our work contributes to a\npractical discussion around the subgroup-sensitive development and deployment\nof medical ML models and the interconnectedness of fairness and transparency.", "published": "2025-06-17 10:59:02", "link": "http://arxiv.org/abs/2506.14400v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Excessive Reasoning Attack on Reasoning LLMs", "abstract": "Recent reasoning large language models (LLMs), such as OpenAI o1 and\nDeepSeek-R1, exhibit strong performance on complex tasks through test-time\ninference scaling. However, prior studies have shown that these models often\nincur significant computational costs due to excessive reasoning, such as\nfrequent switching between reasoning trajectories (e.g., underthinking) or\nredundant reasoning on simple questions (e.g., overthinking). In this work, we\nexpose a novel threat: adversarial inputs can be crafted to exploit excessive\nreasoning behaviors and substantially increase computational overhead without\ncompromising model utility. Therefore, we propose a novel loss framework\nconsisting of three components: (1) Priority Cross-Entropy Loss, a modification\nof the standard cross-entropy objective that emphasizes key tokens by\nleveraging the autoregressive nature of LMs; (2) Excessive Reasoning Loss,\nwhich encourages the model to initiate additional reasoning paths during\ninference; and (3) Delayed Termination Loss, which is designed to extend the\nreasoning process and defer the generation of final outputs. We optimize and\nevaluate our attack for the GSM8K and ORCA datasets on\nDeepSeek-R1-Distill-LLaMA and DeepSeek-R1-Distill-Qwen. Empirical results\ndemonstrate a 3x to 9x increase in reasoning length with comparable utility\nperformance. Furthermore, our crafted adversarial inputs exhibit\ntransferability, inducing computational overhead in o3-mini, o1-mini,\nDeepSeek-R1, and QWQ models.", "published": "2025-06-17 10:16:52", "link": "http://arxiv.org/abs/2506.14374v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Fair for a few: Improving Fairness in Doubly Imbalanced Datasets", "abstract": "Fairness has been identified as an important aspect of Machine Learning and\nArtificial Intelligence solutions for decision making. Recent literature offers\na variety of approaches for debiasing, however many of them fall short when the\ndata collection is imbalanced. In this paper, we focus on a particular case,\nfairness in doubly imbalanced datasets, such that the data collection is\nimbalanced both for the label and the groups in the sensitive attribute.\nFirstly, we present an exploratory analysis to illustrate limitations in\ndebiasing on a doubly imbalanced dataset. Then, a multi-criteria based solution\nis proposed for finding the most suitable sampling and distribution for label\nand sensitive attribute, in terms of fairness and classification accuracy", "published": "2025-06-17 08:34:56", "link": "http://arxiv.org/abs/2506.14306v1", "categories": ["cs.LG", "cs.CY"], "primary_category": "cs.LG"}
{"title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling", "abstract": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music\nand song. To the best of our knowledge, there are no open-source high-quality\ndataset representing popular and well-known songs for generative music modeling\ntasks such as text-music, music-captioning, singing-voice synthesis, melody\nreconstruction and cross-model retrieval. Past contributions focused on\nisolated and constrained factors whose core perspective was to create synthetic\nor re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily\nlarge-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another\nfocus for the community. Unfortunately, adoption of these datasets has been\nbelow substantial in the generative music community as these datasets fail to\nreflect real-world music and its flavour. Our dataset changes this narrative\nand provides a dataset that is constructed using actual popular music and\nworld-renowned artists.", "published": "2025-06-17 08:08:08", "link": "http://arxiv.org/abs/2506.14293v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "abstract": "Graph machine learning architectures are typically tailored to specific tasks\non specific datasets, which hinders their broader applicability. This has led\nto a new quest in graph machine learning: how to build graph foundation models\ncapable of generalizing across arbitrary graphs and features? In this work, we\npresent a recipe for designing graph foundation models for node-level tasks\nfrom first principles. The key ingredient underpinning our study is a\nsystematic investigation of the symmetries that a graph foundation model must\nrespect. In a nutshell, we argue that label permutation-equivariance alongside\nfeature permutation-invariance are necessary in addition to the common node\npermutation-equivariance on each local neighborhood of the graph. To this end,\nwe first characterize the space of linear transformations that are equivariant\nto permutations of nodes and labels, and invariant to permutations of features.\nWe then prove that the resulting network is a universal approximator on\nmultisets that respect the aforementioned symmetries. Our recipe uses such\nlayers on the multiset of features induced by the local neighborhood of the\ngraph to obtain a class of graph foundation models for node property\nprediction. We validate our approach through extensive experiments on 29\nreal-world node classification datasets, demonstrating both strong zero-shot\nempirical performance and consistent improvement as the number of training\ngraphs increases.", "published": "2025-06-17 08:05:08", "link": "http://arxiv.org/abs/2506.14291v1", "categories": ["cs.LG", "cs.SI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "NeuralPDR: Neural Differential Equations as surrogate models for Photodissociation Regions", "abstract": "Computational astrochemical models are essential for helping us interpret and\nunderstand the observations of different astrophysical environments. In the age\nof high-resolution telescopes such as JWST and ALMA, the substructure of many\nobjects can be resolved, raising the need for astrochemical modeling at these\nsmaller scales, meaning that the simulations of these objects need to include\nboth the physics and chemistry to accurately model the observations. The\ncomputational cost of the simulations coupling both the three-dimensional\nhydrodynamics and chemistry is enormous, creating an opportunity for surrogate\nmodels that can effectively substitute the chemical solver. In this work we\npresent surrogate models that can replace the original chemical code, namely\nLatent Augmented Neural Ordinary Differential Equations. We train these\nsurrogate architectures on three datasets of increasing physical complexity,\nwith the last dataset derived directly from a three-dimensional simulation of a\nmolecular cloud using a Photodissociation Region (PDR) code, 3D-PDR. We show\nthat these surrogate models can provide speedup and reproduce the original\nobservable column density maps of the dataset. This enables the rapid inference\nof the chemistry (on the GPU), allowing for the faster statistical inference of\nobservations or increasing the resolution in hydrodynamical simulations of\nastrophysical environments.", "published": "2025-06-17 07:35:02", "link": "http://arxiv.org/abs/2506.14270v1", "categories": ["astro-ph.GA", "cs.LG"], "primary_category": "astro-ph.GA"}
{"title": "Towards Robust Learning to Optimize with Theoretical Guarantees", "abstract": "Learning to optimize (L2O) is an emerging technique to solve mathematical\noptimization problems with learning-based methods. Although with great success\nin many real-world scenarios such as wireless communications, computer\nnetworks, and electronic design, existing L2O works lack theoretical\ndemonstration of their performance and robustness in out-of-distribution (OOD)\nscenarios. We address this gap by providing comprehensive proofs. First, we\nprove a sufficient condition for a robust L2O model with homogeneous\nconvergence rates over all In-Distribution (InD) instances. We assume an L2O\nmodel achieves robustness for an InD scenario. Based on our proposed\nmethodology of aligning OOD problems to InD problems, we also demonstrate that\nthe L2O model's convergence rate in OOD scenarios will deteriorate by an\nequation of the L2O model's input features. Moreover, we propose an L2O model\nwith a concise gradient-only feature construction and a novel gradient-based\nhistory modeling method. Numerical simulation demonstrates that our proposed\nmodel outperforms the state-of-the-art baseline in both InD and OOD scenarios\nand achieves up to 10 $\\times$ convergence speedup. The code of our method can\nbe found from https://github.com/NetX-lab/GoMathL2O-Official.", "published": "2025-06-17 07:25:07", "link": "http://arxiv.org/abs/2506.14263v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?", "abstract": "Latent-space monitors aim to detect undesirable behaviours in large language\nmodels by leveraging internal model representations rather than relying solely\non black-box outputs. These methods have shown promise in identifying\nbehaviours such as deception and unsafe completions, but a critical open\nquestion remains: can LLMs learn to evade such monitors? To study this, we\nintroduce RL-Obfuscation, in which LLMs are finetuned via reinforcement\nlearning to bypass latent-space monitors while maintaining coherent\ngenerations. We apply RL-Obfuscation to LLMs ranging from 7B to 14B parameters\nand evaluate evasion success against a suite of monitors. We find that\ntoken-level latent-space monitors are highly vulnerable to this attack. More\nholistic monitors, such as max-pooling or attention-based probes, remain\nrobust. Moreover, we show that adversarial policies trained to evade a single\nstatic monitor generalise to unseen monitors of the same type. Finally, we\nstudy how the policy learned by RL bypasses these monitors and find that the\nmodel can also learn to repurpose tokens to mean something different\ninternally.", "published": "2025-06-17 07:22:20", "link": "http://arxiv.org/abs/2506.14261v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Convergence-Privacy-Fairness Trade-Off in Personalized Federated Learning", "abstract": "Personalized federated learning (PFL), e.g., the renowned Ditto, strikes a\nbalance between personalization and generalization by conducting federated\nlearning (FL) to guide personalized learning (PL). While FL is unaffected by\npersonalized model training, in Ditto, PL depends on the outcome of the FL.\nHowever, the clients' concern about their privacy and consequent perturbation\nof their local models can affect the convergence and (performance) fairness of\nPL. This paper presents PFL, called DP-Ditto, which is a non-trivial extension\nof Ditto under the protection of differential privacy (DP), and analyzes the\ntrade-off among its privacy guarantee, model convergence, and performance\ndistribution fairness. We also analyze the convergence upper bound of the\npersonalized models under DP-Ditto and derive the optimal number of global\naggregations given a privacy budget. Further, we analyze the performance\nfairness of the personalized models, and reveal the feasibility of optimizing\nDP-Ditto jointly for convergence and fairness. Experiments validate our\nanalysis and demonstrate that DP-Ditto can surpass the DP-perturbed versions of\nthe state-of-the-art PFL models, such as FedAMP, pFedMe, APPLE, and FedALA, by\nover 32.71% in fairness and 9.66% in accuracy.", "published": "2025-06-17 07:15:28", "link": "http://arxiv.org/abs/2506.14251v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Can Large Language Models Improve Spectral Graph Neural Networks?", "abstract": "Spectral Graph Neural Networks (SGNNs) have attracted significant attention\ndue to their ability to approximate arbitrary filters. They typically rely on\nsupervision from downstream tasks to adaptively learn appropriate filters.\nHowever, under label-scarce conditions, SGNNs may learn suboptimal filters,\nleading to degraded performance. Meanwhile, the remarkable success of Large\nLanguage Models (LLMs) has inspired growing interest in exploring their\npotential within the GNN domain. This naturally raises an important question:\n\\textit{Can LLMs help overcome the limitations of SGNNs and enhance their\nperformance?} In this paper, we propose a novel approach that leverages LLMs to\nestimate the homophily of a given graph. The estimated homophily is then used\nto adaptively guide the design of polynomial spectral filters, thereby\nimproving the expressiveness and adaptability of SGNNs across diverse graph\nstructures. Specifically, we introduce a lightweight pipeline in which the LLM\ngenerates homophily-aware priors, which are injected into the filter\ncoefficients to better align with the underlying graph topology. Extensive\nexperiments on benchmark datasets demonstrate that our LLM-driven SGNN\nframework consistently outperforms existing baselines under both homophilic and\nheterophilic settings, with minimal computational and monetary overhead.", "published": "2025-06-17 06:17:19", "link": "http://arxiv.org/abs/2506.14220v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Variational Information Theoretic Approach to Out-of-Distribution Detection", "abstract": "We present a theory for the construction of out-of-distribution (OOD)\ndetection features for neural networks. We introduce random features for OOD\nthrough a novel information-theoretic loss functional consisting of two terms,\nthe first based on the KL divergence separates resulting in-distribution (ID)\nand OOD feature distributions and the second term is the Information\nBottleneck, which favors compressed features that retain the OOD information.\nWe formulate a variational procedure to optimize the loss and obtain OOD\nfeatures. Based on assumptions on OOD distributions, one can recover properties\nof existing OOD features, i.e., shaping functions. Furthermore, we show that\nour theory can predict a new shaping function that out-performs existing ones\non OOD benchmarks. Our theory provides a general framework for constructing a\nvariety of new features with clear explainability.", "published": "2025-06-17 05:17:36", "link": "http://arxiv.org/abs/2506.14194v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Hard Contacts with Soft Gradients: Refining Differentiable Simulators for Learning and Control", "abstract": "Contact forces pose a major challenge for gradient-based optimization of\nrobot dynamics as they introduce jumps in the system's velocities.\nPenalty-based simulators, such as MuJoCo, simplify gradient computation by\nsoftening the contact forces. However, realistically simulating hard contacts\nrequires very stiff contact settings, which leads to incorrect gradients when\nusing automatic differentiation. On the other hand, using non-stiff settings\nstrongly increases the sim-to-real gap. We analyze the contact computation of\npenalty-based simulators to identify the causes of gradient errors. Then, we\npropose DiffMJX, which combines adaptive integration with MuJoCo XLA, to\nnotably improve gradient quality in the presence of hard contacts. Finally, we\naddress a key limitation of contact gradients: they vanish when objects do not\ntouch. To overcome this, we introduce Contacts From Distance (CFD), a mechanism\nthat enables the simulator to generate informative contact gradients even\nbefore objects are in contact. To preserve physical realism, we apply CFD only\nin the backward pass using a straight-through trick, allowing us to compute\nuseful gradients without modifying the forward simulation.", "published": "2025-06-17 04:58:08", "link": "http://arxiv.org/abs/2506.14186v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "I.2.9; I.2.6; I.6.4; G.1.6"], "primary_category": "cs.RO"}
{"title": "Structured and Informed Probabilistic Modeling with the Thermodynamic Kolmogorov-Arnold Model", "abstract": "We adapt the Kolmogorov-Arnold Representation Theorem to generative modeling\nby reinterpreting its inner functions as a Markov Kernel between probability\nspaces via inverse transform sampling. We present a generative model that is\ninterpretable, easy to design, and efficient. Our approach couples a\nKolmogorov-Arnold Network generator with independent energy-based priors,\ntrained via Maximum Likelihood. Inverse sampling enables fast inference, while\nprior knowledge can be incorporated before training to better align priors with\nposteriors, thereby improving learning efficiency and sample quality. The\nlearned prior is also recoverable and visualizable post-training, offering an\nempirical Bayes perspective. To address inflexibility and mitigate\nprior-posterior mismatch, we introduce scalable extensions based on mixture\ndistributions and Langevin Monte Carlo methods, admitting a trade-off between\nflexibility and training efficiency. Our contributions connect classical\nrepresentation theorems with modern probabilistic modeling, while balancing\ntraining stability, inference speed, and the quality and diversity of\ngenerations.", "published": "2025-06-17 04:07:32", "link": "http://arxiv.org/abs/2506.14167v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Light Aircraft Game : Basic Implementation and training results analysis", "abstract": "This paper investigates multi-agent reinforcement learning (MARL) in a\npartially observable, cooperative-competitive combat environment known as LAG.\nWe describe the environment's setup, including agent actions, hierarchical\ncontrols, and reward design across different combat modes such as No Weapon and\nShootMissile. Two representative algorithms are evaluated: HAPPO, an on-policy\nhierarchical variant of PPO, and HASAC, an off-policy method based on soft\nactor-critic. We analyze their training stability, reward progression, and\ninter-agent coordination capabilities. Experimental results show that HASAC\nperforms well in simpler coordination tasks without weapons, while HAPPO\ndemonstrates stronger adaptability in more dynamic and expressive scenarios\ninvolving missile combat. These findings provide insights into the trade-offs\nbetween on-policy and off-policy methods in multi-agent settings.", "published": "2025-06-17 03:57:28", "link": "http://arxiv.org/abs/2506.14164v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Common Benchmarks Undervalue the Generalization Power of Programmatic Policies", "abstract": "Algorithms for learning programmatic representations for sequential\ndecision-making problems are often evaluated on out-of-distribution (OOD)\nproblems, with the common conclusion that programmatic policies generalize\nbetter than neural policies on OOD problems. In this position paper, we argue\nthat commonly used benchmarks undervalue the generalization capabilities of\nprogrammatic representations. We analyze the experiments of four papers from\nthe literature and show that neural policies, which were shown not to\ngeneralize, can generalize as effectively as programmatic policies on OOD\nproblems. This is achieved with simple changes in the neural policies training\npipeline. Namely, we show that simpler neural architectures with the same type\nof sparse observation used with programmatic policies can help attain OOD\ngeneralization. Another modification we have shown to be effective is the use\nof reward functions that allow for safer policies (e.g., agents that drive\nslowly can generalize better). Also, we argue for creating benchmark problems\nhighlighting concepts needed for OOD generalization that may challenge neural\npolicies but align with programmatic representations, such as tasks requiring\nalgorithmic constructs like stacks.", "published": "2025-06-17 03:53:18", "link": "http://arxiv.org/abs/2506.14162v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Leveraging Predictive Equivalence in Decision Trees", "abstract": "Decision trees are widely used for interpretable machine learning due to\ntheir clearly structured reasoning process. However, this structure belies a\nchallenge we refer to as predictive equivalence: a given tree's decision\nboundary can be represented by many different decision trees. The presence of\nmodels with identical decision boundaries but different evaluation processes\nmakes model selection challenging. The models will have different variable\nimportance and behave differently in the presence of missing values, but most\noptimization procedures will arbitrarily choose one such model to return. We\npresent a boolean logical representation of decision trees that does not\nexhibit predictive equivalence and is faithful to the underlying decision\nboundary. We apply our representation to several downstream machine learning\ntasks. Using our representation, we show that decision trees are surprisingly\nrobust to test-time missingness of feature values; we address predictive\nequivalence's impact on quantifying variable importance; and we present an\nalgorithm to optimize the cost of reaching predictions.", "published": "2025-06-17 03:11:30", "link": "http://arxiv.org/abs/2506.14143v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluating Loss Functions for Graph Neural Networks: Towards Pretraining and Generalization", "abstract": "Graph Neural Networks (GNNs) became useful for learning on non-Euclidean\ndata. However, their best performance depends on choosing the right model\narchitecture and the training objective, also called the loss function.\nResearchers have studied these parts separately, but a large-scale evaluation\nhas not looked at how GNN models and many loss functions work together across\ndifferent tasks. To fix this, we ran a thorough study - it included seven\nwell-known GNN architectures. We also used a large group of 30 single plus\nmixed loss functions. The study looked at both inductive and transductive\nsettings. Our evaluation spanned three distinct real-world datasets, assessing\nperformance in both inductive and transductive settings using 21 comprehensive\nevaluation metrics. From these extensive results (detailed in supplementary\ninformation 1 \\& 2), we meticulously analyzed the top ten model-loss\ncombinations for each metric based on their average rank. Our findings reveal\nthat, especially for the inductive case: 1) Hybrid loss functions generally\nyield superior and more robust performance compared to single loss functions,\nindicating the benefit of multi-objective optimization. 2) The GIN architecture\nalways showed the highest-level average performance, especially with\nCross-Entropy loss. 3) Although some combinations had overall lower average\nranks, models such as GAT, particularly with certain hybrid losses,\ndemonstrated incredible specialized strengths, maximizing the most top-1\nresults among the individual metrics, emphasizing subtle strengths for\nparticular task demands. 4) On the other hand, the MPNN architecture typically\nlagged behind the scenarios it was tested against.", "published": "2025-06-17 02:12:19", "link": "http://arxiv.org/abs/2506.14114v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Universal Rates of ERM for Agnostic Learning", "abstract": "The universal learning framework has been developed to obtain guarantees on\nthe learning rates that hold for any fixed distribution, which can be much\nfaster than the ones uniformly hold over all the distributions. Given that the\nEmpirical Risk Minimization (ERM) principle being fundamental in the PAC theory\nand ubiquitous in practical machine learning, the recent work of\narXiv:2412.02810 studied the universal rates of ERM for binary classification\nunder the realizable setting. However, the assumption of realizability is too\nrestrictive to hold in practice. Indeed, the majority of the literature on\nuniversal learning has focused on the realizable case, leaving the\nnon-realizable case barely explored.\n  In this paper, we consider the problem of universal learning by ERM for\nbinary classification under the agnostic setting, where the ''learning curve\"\nreflects the decay of the excess risk as the sample size increases. We explore\nthe possibilities of agnostic universal rates and reveal a compact trichotomy:\nthere are three possible agnostic universal rates of ERM, being either\n$e^{-n}$, $o(n^{-1/2})$, or arbitrarily slow. We provide a complete\ncharacterization of which concept classes fall into each of these categories.\nMoreover, we also establish complete characterizations for the target-dependent\nuniversal rates as well as the Bayes-dependent universal rates.", "published": "2025-06-17 02:02:11", "link": "http://arxiv.org/abs/2506.14110v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Transformers Learn Faster with Semantic Focus", "abstract": "Various forms of sparse attention have been explored to mitigate the\nquadratic computational and memory cost of the attention mechanism in\ntransformers. We study sparse transformers not through a lens of efficiency but\nrather in terms of learnability and generalization. Empirically studying a\nrange of attention mechanisms, we find that input-dependent sparse attention\nmodels appear to converge faster and generalize better than standard attention\nmodels, while input-agnostic sparse attention models show no such benefits -- a\nphenomenon that is robust across architectural and optimization hyperparameter\nchoices. This can be interpreted as demonstrating that concentrating a model's\n\"semantic focus\" with respect to the tokens currently being considered (in the\nform of input-dependent sparse attention) accelerates learning. We develop a\ntheoretical characterization of the conditions that explain this behavior. We\nestablish a connection between the stability of the standard softmax and the\nloss function's Lipschitz properties, then show how sparsity affects the\nstability of the softmax and the subsequent convergence and generalization\nguarantees resulting from the attention mechanism. This allows us to\ntheoretically establish that input-agnostic sparse attention does not provide\nany benefits. We also characterize conditions when semantic focus\n(input-dependent sparse attention) can provide improved guarantees, and we\nvalidate that these conditions are in fact met in our empirical evaluations.", "published": "2025-06-17 01:19:28", "link": "http://arxiv.org/abs/2506.14095v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Scale Finetuning for Encoder-based Time Series Foundation Models", "abstract": "Time series foundation models (TSFMs) demonstrate impressive zero-shot\nperformance for time series forecasting. However, an important yet\nunderexplored challenge is how to effectively finetune TSFMs on specific\ndownstream tasks. While naive finetuning can yield performance gains, we argue\nthat it falls short of fully leveraging TSFMs' capabilities, often resulting in\noverfitting and suboptimal performance. Given the diverse temporal patterns\nacross sampling scales and the inherent multi-scale forecasting capabilities of\nTSFMs, we adopt a causal perspective to analyze finetuning process, through\nwhich we highlight the critical importance of explicitly modeling multiple\nscales and reveal the shortcomings of naive approaches. Focusing on\n\\textit{encoder-based} TSFMs, we propose \\textbf{M}ulti\\textbf{\\textsc{s}}cale\n\\textbf{\\textsc{f}}ine\\textbf{\\textsc{t}}uning (\\textbf{MSFT}), a simple yet\ngeneral framework that explicitly integrates multi-scale modeling into the\nfinetuning process. Experimental results on three different backbones (\\moirai,\n\\moment\\ and \\units) demonstrate that TSFMs finetuned with MSFT not only\noutperform naive and typical parameter efficient finetuning methods but also\nsurpass state-of-the-art deep learning methods.", "published": "2025-06-17 01:06:01", "link": "http://arxiv.org/abs/2506.14087v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification", "abstract": "We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new\ndataset and infrastructure to advance LLM and agent research in hardware design\nand verification. CVDP includes 783 problems across 13 task categories,\ncovering RTL generation, verification, debugging, specification alignment, and\ntechnical Q&A authored by experienced hardware engineers. Problems are offered\nin both non-agentic and agentic formats. The benchmark introduces more\nrealistic and challenging contexts than prior work, with state-of-the-art\nmodels achieving no more than 34% pass@1 on code generation. Agentic\ntasks$\\unicode{x2013}$especially those involving RTL reuse and\nverification$\\unicode{x2013}$are particularly difficult. Evaluation uses\nopen-source tools and model scoring infrastructure, with comprehension tasks\nassessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in\ncurrent model capabilities, underscoring the need for continued research toward\nrobust, real-world hardware design automation.", "published": "2025-06-17 00:11:13", "link": "http://arxiv.org/abs/2506.14074v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Hierarchical Multi-Agent Reinforcement Learning-based Coordinated Spatial Reuse for Next Generation WLANs", "abstract": "High-density Wi-Fi deployments often result in significant co-channel\ninterference, which degrades overall network performance. To address this\nissue, coordination of multi access points (APs) has been considered to enable\ncoordinated spatial reuse (CSR) in next generation wireless local area\nnetworks. This paper tackles the challenge of downlink spatial reuse in Wi-Fi\nnetworks, specifically in scenarios involving overlapping basic service sets,\nby employing hierarchical multi-agent reinforcement learning (HMARL). We\ndecompose the CSR process into two phases, i.e., a polling phase and a decision\nphase, and introduce the HMARL algorithm to enable efficient CSR. To enhance\ntraining efficiency, the proposed HMARL algorithm employs a hierarchical\nstructure, where station selection and power control are determined by a high-\nand low-level policy network, respectively. Simulation results demonstrate that\nthis approach consistently outperforms baseline methods in terms of throughput\nand latency across various network topologies. Moreover, the algorithm exhibits\nrobust performance when coexisting with legacy APs. Additional experiments in a\nrepresentative topology further reveal that the carefully designed reward\nfunction not only maximizes the overall network throughput, but also improves\nfairness in transmission opportunities for APs in high-interference regions.", "published": "2025-06-17 05:00:38", "link": "http://arxiv.org/abs/2506.14187v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Posterior contraction rates of computational methods for Bayesian data assimilation", "abstract": "In this paper, we analyze posterior consistency of a Bayesian data\nassimilation problem under discretization. We prove convergence rates for the\ndiscrete posterior to ground truth solution under both conforming\ndiscretization and finite element discretization (usually non-conforming). The\nanalysis is based on the coupling of asymptotics between the number of samples\nand the dimension of discrete spaces. In the finite element discretization,\ntailor-made discrete priors, instead of the discretization of continuous\npriors, are used to generate an optimal convergence rate.", "published": "2025-06-17 16:20:07", "link": "http://arxiv.org/abs/2506.14685v1", "categories": ["math.NA", "cs.NA", "math.PR", "math.ST", "stat.TH", "65N21, 62F15, 35R30, 65N30, 65C60, 35R25"], "primary_category": "math.NA"}
{"title": "Convergence of generalized cross-validation with applications to ill-posed integral equations", "abstract": "In this article, we rigorously establish the consistency of generalized\ncross-validation as a parameter-choice rule for solving inverse problems. We\nprove that the index chosen by leave-one-out GCV achieves a non-asymptotic,\norder-optimal error bound with high probability for polynomially ill-posed\ncompact operators. Hereby it is remarkable that the unknown true solution need\nnot satisfy a self-similarity condition, which is generally needed for other\nheuristic parameter choice rules. We quantify the rate and demonstrate\nconvergence numerically on integral equation test cases, including image\ndeblurring and CT reconstruction.", "published": "2025-06-17 14:14:16", "link": "http://arxiv.org/abs/2506.14558v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Using BDF schemes in the temporal integration of POD-ROM methods", "abstract": "In this paper we consider the numerical approximation of a semilinear\nreaction-diffusion model problem (PDEs) by means of reduced order methods\n(ROMs) based on proper orthogonal decomposition (POD). We focus on the time\nintegration of the fully discrete reduced order model. Most of the analysis in\nthe literature has been carried out for the implicit Euler method as time\nintegrator. We integrate in time the reduced order model with the BDF-q time\nstepping ($1\\le q\\le 5$) and prove optimal rate of convergence of order $q$ in\ntime. Our set of snapshots is obtained from finite element approximations to\nthe original model problem computed at different times. These finite element\napproximations can be obtained with any time integrator. The POD method is\nbased on first order difference quotients of the snapshots. The reason for\ndoing this is twofold. On the one hand, the use of difference quotients allow\nus to provide pointwise-in-time error bounds. On the other, the use of\ndifference quotients is essential to get the expected rate $q$ in time since we\napply that the BDF-q time stepping, $1\\le q\\le 5$, can be written as a linear\ncombination of first order difference quotients.", "published": "2025-06-17 14:03:01", "link": "http://arxiv.org/abs/2506.14543v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Unified numerical analysis for thermoelastic diffusion and thermo-poroelasticity of thin plates", "abstract": "We investigate a coupled hyperbolic-parabolic system modeling thermoelastic\ndiffusion (resp. thermo-poroelasticity) in plates, consisting of a fourth-order\nhyperbolic partial differential equation for plate deflection and two\nsecond-order parabolic partial differential equations for the first moments of\ntemperature and chemical potential (resp. pore pressure). The unique\nsolvability of the system is established via Galerkin approach, and the\nadditional regularity of the solution is obtained under appropriately\nstrengthened data. For numerical approximation, we employ the Newmark method\nfor time discretization of the hyperbolic term and a continuous interior\npenalty scheme for the spatial discretization of displacement. For the\nparabolic equations that represent the first moments of temperature and\nchemical potential (resp. pore pressure), we use the Crank--Nicolson method for\ntime discretization and conforming finite elements for spatial discretization.\nThe convergence of the fully discrete scheme with quasi-optimal rates in space\nand time is established. The numerical experiments demonstrate the\neffectiveness of the 2D Kirchhoff--Love plate model in capturing thermoelastic\ndiffusion and thermo-poroelastic behavior in specific materials. We illustrate\nthat as plate thickness decreases, the two-dimensional simulations closely\napproximate the results of three-dimensional problem. Finally, the numerical\nexperiments also validate the theoretical rates of convergence.", "published": "2025-06-17 12:16:25", "link": "http://arxiv.org/abs/2506.14455v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical approximation of effective diffusivities in homogenization of nondivergence-form equations with large drift by a Lagrangian method", "abstract": "In this paper, we study numerical methods for the homogenization of linear\nsecond-order elliptic equations in nondivergence-form with periodic diffusion\ncoefficients and large drift terms. Upon noting that the effective diffusion\nmatrix can be characterized through the long-time variance of an associated\ndiffusion process, we construct a Lagrangian numerical scheme based on a direct\nsimulation of the underlying stochastic differential equation and utilizing the\nframework of modified equations, thereby avoiding the need to solve the\nFokker--Planck--Kolmogorov equation. Through modified equation analysis, we\nderive higher-order weak convergence rates for our method. Finally, we conduct\nnumerical experiments to demonstrate the accuracy of the proposed method. The\nresults show that the method efficiently computes effective diffusivities, even\nin high dimensions.", "published": "2025-06-17 00:08:12", "link": "http://arxiv.org/abs/2506.14073v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On Quantum BSDE Solver for High-Dimensional Parabolic PDEs", "abstract": "We propose a quantum machine learning framework for approximating solutions\nto high-dimensional parabolic partial differential equations (PDEs) that can be\nreformulated as backward stochastic differential equations (BSDEs). In contrast\nto popular quantum-classical network hybrid approaches, this study employs the\npure Variational Quantum Circuit (VQC) as the core solver without trainable\nclassical neural networks. The quantum BSDE solver performs pathwise\napproximation via temporal discretization and Monte Carlo simulation, framed as\nmodel-based reinforcement learning. We benchmark VQCbased and classical deep\nneural network (DNN) solvers on two canonical PDEs as representatives: the\nBlack-Scholes and nonlinear Hamilton-Jacobi-Bellman (HJB) equations. The VQC\nachieves lower variance and improved accuracy in most cases, particularly in\nhighly nonlinear regimes and for out-of-themoney options, demonstrating greater\nrobustness than DNNs. These results, obtained via quantum circuit simulation,\nhighlight the potential of VQCs as scalable and stable solvers for\nhighdimensional stochastic control problems.", "published": "2025-06-17 15:10:42", "link": "http://arxiv.org/abs/2506.14612v1", "categories": ["q-fin.MF", "q-fin.CP"], "primary_category": "q-fin.MF"}
{"title": "Pricing options on the cryptocurrency futures contracts", "abstract": "The cryptocurrency options market is notable for its high volatility and\nlower liquidity compared to traditional markets. These characteristics\nintroduce significant challenges to traditional option pricing methodologies.\nAddressing these complexities requires advanced models that can effectively\ncapture the dynamics of the market. We explore which option pricing models are\nmost effective in valuing cryptocurrency options. Specifically, we calibrate\nand evaluate the performance of the Black-Scholes, Merton Jump Diffusion,\nVariance Gamma, Kou, Heston, and Bates models. Our analysis focuses on pricing\nvanilla options on futures contracts for Bitcoin (BTC) and Ether (ETH). We find\nthat the Black-Scholes model exhibits the highest pricing errors. In contrast,\nthe Kou and Bates models achieve the lowest errors, with the Kou model\nperforming the best for the BTC options and the Bates model for ETH options.\nThe results highlight the importance of incorporating jumps and stochastic\nvolatility into pricing models to better reflect the behavior of these assets.", "published": "2025-06-17 15:13:39", "link": "http://arxiv.org/abs/2506.14614v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Robust Hedging of American Options via Aggregated Snell Envelopes", "abstract": "We construct an aggregator for a family of Snell envelopes in a nondominated\nframework. We apply this construction to establish a robust hedging duality,\nalong with the existence of a minimal hedging strategy, in a general\nsemi-martingale setting for American-style options. Our results encompass\ncontinuous processes, or processes with jumps and non-vanishing diffusion. A\nkey application is to financial market models, where uncertainty is quantified\nthrough the semi-martingale characteristics.", "published": "2025-06-17 14:09:37", "link": "http://arxiv.org/abs/2506.14553v1", "categories": ["q-fin.MF", "math.OC", "math.PR", "60G40, 60G44, 91G20, 93E20"], "primary_category": "q-fin.MF"}
{"title": "The use of cross validation in the analysis of designed experiments", "abstract": "Cross-validation (CV) is a common method to tune machine learning methods and\ncan be used for model selection in regression as well. Because of the\nstructured nature of small, traditional experimental designs, the literature\nhas warned against using CV in their analysis. The striking increase in the use\nof machine learning, and thus CV, in the analysis of experimental designs, has\nled us to empirically study the effectiveness of CV compared to other methods\nof selecting models in designed experiments, including the little bootstrap. We\nconsider both response surface settings where prediction is of primary\ninterest, as well as screening where factor selection is most important.\nOverall, we provide evidence that the use of leave-one-out cross-validation\n(LOOCV) in the analysis of small, structured is often useful. More general\n$k$-fold CV may also be competitive but its performance is uneven.", "published": "2025-06-17 14:58:30", "link": "http://arxiv.org/abs/2506.14593v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Bayesian Hybrid Machine Learning of Gallstone Risk", "abstract": "Gallstone disease is a complex, multifactorial condition with significant\nglobal health burdens. Identifying underlying risk factors and their\ninteractions is crucial for early diagnosis, targeted prevention, and effective\nclinical management. Although logistic regression remains a standard tool for\nassessing associations between predictors and gallstone status, it often\nunderperforms in high-dimensional settings and may fail to capture intricate\nrelationships among variables. To address these limitations, we propose a\nhybrid machine learning framework that integrates robust variable selection\nwith advanced interaction detection. Specifically, Adaptive LASSO is employed\nto identify a sparse and interpretable subset of influential features, followed\nby Bayesian Additive Regression Trees (BART) to model nonlinear effects and\nuncover key interactions. Selected interactions are further characterized by\nphysiological knowledge through differential equation-informed interaction\nterms, grounding the model in biologically plausible mechanisms. The insights\ngained from these steps are then integrated into a final logistic regression\nmodel within a Bayesian framework, providing a balance between predictive\naccuracy and clinical interpretability. This proposed framework not only\nenhances prediction but also yields actionable insights, offering a valuable\nsupport tool for medical research and decision-making.", "published": "2025-06-17 14:19:02", "link": "http://arxiv.org/abs/2506.14561v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "ASAP-FE: Energy-Efficient Feature Extraction Enabling Multi-Channel Keyword Spotting on Edge Processors", "abstract": "Multi-channel keyword spotting (KWS) has become crucial for voice-based\napplications in edge environments. However, its substantial computational and\nenergy requirements pose significant challenges. We introduce ASAP-FE (Agile\nSparsity-Aware Parallelized-Feature Extractor), a hardware-oriented front-end\ndesigned to address these challenges. Our framework incorporates three key\ninnovations: (1) Half-overlapped Infinite Impulse Response (IIR) Framing: This\nreduces redundant data by approximately 25% while maintaining essential phoneme\ntransition cues. (2) Sparsity-aware Data Reduction: We exploit frame-level\nsparsity to achieve an additional 50% data reduction by combining frame\nskipping with stride-based filtering. (3) Dynamic Parallel Processing: We\nintroduce a parameterizable filter cluster and a priority-based scheduling\nalgorithm that allows parallel execution of IIR filtering tasks, reducing\nlatency and optimizing energy efficiency. ASAP-FE is implemented with various\nfilter cluster sizes on edge processors, with functionality verified on FPGA\nprototypes and designs synthesized at 45 nm. Experimental results using\nTC-ResNet8, DS-CNN, and KWT-1 demonstrate that ASAP-FE reduces the average\nworkload by 62.73% while supporting real-time processing for up to 32 channels.\nCompared to a conventional fully overlapped baseline, ASAP-FE achieves less\nthan a 1% accuracy drop (e.g., 96.22% vs. 97.13% for DS-CNN), which is well\nwithin acceptable limits for edge AI. By adjusting the number of filter\nmodules, our design optimizes the trade-off between performance and energy,\nwith 15 parallel filters providing optimal performance for up to 25 channels.\nOverall, ASAP-FE offers a practical and efficient solution for multi-channel\nKWS on energy-constrained edge devices.", "published": "2025-06-17 15:50:24", "link": "http://arxiv.org/abs/2506.14657v1", "categories": ["eess.AS", "cs.AR"], "primary_category": "eess.AS"}
{"title": "An Open Research Dataset of the 1932 Cairo Congress of Arab Music", "abstract": "This paper introduces ORD-CC32 , an open research dataset derived from the\n1932 Cairo Congress of Arab Music recordings, a historically significant\ncollection representing diverse Arab musical traditions. The dataset includes\nstructured metadata, melodic and rhythmic mode tags (maqam and iqa), manually\nlabeled tonic information, and acoustic features extracted using\nstate-of-the-art pitch detection methods. These resources support computational\nstudies of tuning, temperament, and regional variations in Arab music. A case\nstudy using pitch histograms demonstrates the potential for data-driven\nanalysis of microtonal differences across regions. By making this dataset\nopenly available, we aim to enable interdisciplinary research in computational\nethnomusicology, music information retrieval (MIR), cultural studies, and\ndigital heritage preservation. ORD-CC32 is shared on Zenodo with tools for\nfeature extraction and metadata retrieval.", "published": "2025-06-17 13:28:27", "link": "http://arxiv.org/abs/2506.14503v1", "categories": ["cs.SD", "cs.DL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "M3SD: Multi-modal, Multi-scenario and Multi-language Speaker Diarization Dataset", "abstract": "In the field of speaker diarization, the development of technology is\nconstrained by two problems: insufficient data resources and poor\ngeneralization ability of deep learning models. To address these two problems,\nfirstly, we propose an automated method for constructing speaker diarization\ndatasets, which generates more accurate pseudo-labels for massive data through\nthe combination of audio and video. Relying on this method, we have released\nMulti-modal, Multi-scenario and Multi-language Speaker Diarization (M3SD)\ndatasets. This dataset is derived from real network videos and is highly\ndiverse. In addition, we further propose a scenario-related model fine-tuning\nstrategy. Based on the general model pre-trained using the above dataset, we\ncombine the specific data of the target scenario (e.g., meetings) and achieve\ntargeted optimization by using Adapter and LoRA joint fine-tuning, thus\nachieving the model's domain adaptation. Our dataset and code have been\nopen-sourced at https://huggingface.co/spaces/OldDragon/m3sd.", "published": "2025-06-17 11:44:20", "link": "http://arxiv.org/abs/2506.14427v1", "categories": ["eess.AS", "cs.MM"], "primary_category": "eess.AS"}
{"title": "Integrating Movable Antennas and Intelligent Reflecting Surfaces (MA-IRS): Fundamentals, Practical Solutions, and Opportunities", "abstract": "Movable antennas (MAs) and intelligent reflecting surfaces (IRSs) enable\nactive antenna repositioning and passive phase-shift tuning for channel\nreconfiguration, respectively. Integrating MAs and IRSs boosts spatial degrees\nof freedom, significantly enhancing wireless network capacity, coverage, and\nreliability. In this article, we first present the fundamentals of MA-IRS\nintegration, involving clarifying the key design issues, revealing performance\ngain, and identifying the conditions where MA-IRS synergy persists. Then, we\nexamine practical challenges and propose pragmatic design solutions, including\noptimization schemes, hardware architectures, deployment strategies, and robust\ndesigns for hardware impairments and mobility management. In addition, we\nhighlight how MA-IRS architectures uniquely support advanced integrated sensing\nand communication, enhancing sensing performance and dual-functional\nflexibility. Overall, MA-IRS integration emerges as a compelling approach\ntoward next-generation reconfigurable wireless systems.", "published": "2025-06-17 15:30:42", "link": "http://arxiv.org/abs/2506.14636v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Widely Linear Augmented Extreme Learning Machine Based Impairments Compensation for Satellite Communications", "abstract": "Satellite communications are crucial for the evolution beyond\nfifth-generation networks. However, the dynamic nature of satellite channels\nand their inherent impairments present significant challenges. In this paper, a\nnovel post-compensation scheme that combines the complex-valued extreme\nlearning machine with augmented hidden layer (CELMAH) architecture and widely\nlinear processing (WLP) is developed to address these issues by exploiting\nsignal impropriety in satellite communications. Although CELMAH shares\nstructural similarities with WLP, it employs a different core algorithm and\ndoes not fully exploit the signal impropriety. By incorporating WLP principles,\nwe derive a tailored formulation suited to the network structure and propose\nthe CELM augmented by widely linear least squares (CELM-WLLS) for\npost-distortion. The proposed approach offers enhanced communication robustness\nand is highly effective for satellite communication scenarios characterized by\ndynamic channel conditions and non-linear impairments. CELM-WLLS is designed to\nimprove signal recovery performance and outperform traditional methods such as\nleast square (LS) and minimum mean square error (MMSE). Compared to CELMAH,\nCELM-WLLS demonstrates approximately 0.8 dB gain in BER performance, and also\nachieves a two-thirds reduction in computational complexity, making it a more\nefficient solution.", "published": "2025-06-17 14:12:55", "link": "http://arxiv.org/abs/2506.14557v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Characterization of Continuous Reconfigurable Intelligent Surfaces", "abstract": "We consider a reconfigurable intelligent surface (RIS) that can implement a\nphase rotation continuously over the whole surface rather than via a finite\nnumber of discrete elements. Such an RIS can be considered a design for future\nsystems where advances in metamaterials make such an implementation feasible or\nas the limiting case where the number of elements in a traditional RIS\nincreases in a given area. We derive the optimal RIS design for the single-user\n(SU) scenario assuming a line-of-sight (LoS) from the RIS to the base station\n(BS) and correlated Rayleigh fading for the other links. We also derive the\nassociated optimal signal-to-noise ratio (SNR) and its mean, a bound on the\nmean spectral efficiency (SE), an approximation to the SNR outage probability\nand an approximation to the coefficient of variation for the investigation of\nchannel hardening.", "published": "2025-06-17 10:32:18", "link": "http://arxiv.org/abs/2506.14385v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Lightweight Node Selection in Hexagonal Grid Topology for TDoA-Based UAV Localization", "abstract": "This paper investigates the optimization problem for TDoA-based UAV\nlocalization in low-altitude urban environments with hexagonal grid node\ndeployment. We derive a lightweight optimized node selection strategy based on\nonly RSSI measurements, to pre-select optimal nodes, avoiding extensive TDoA\nmeasurements in energy-constrained UAV scenarios. Theoretical and simulation\nresults demonstrate that dynamically selecting the number of reference nodes\nimproves localization performance while minimizing resource overhead.", "published": "2025-06-17 08:42:00", "link": "http://arxiv.org/abs/2506.14311v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Distributed Activity Detection for Cell-Free Hybrid Near-Far Field Communications", "abstract": "A great amount of endeavor has recently been devoted to activity detection\nfor massive machine-type communications in cell-free massive MIMO. However, in\npractice, as the number of antennas at the access points (APs) increases, the\nRayleigh distance that separates the near-field and far-field regions also\nexpands, rendering the conventional assumption of far-field propagation alone\nimpractical. To address this challenge, this paper considers a hybrid near-far\nfield activity detection in cell-free massive MIMO, and establishes a\ncovariance-based formulation, which facilitates the development of a\ndistributed algorithm to alleviate the computational burden at the central\nprocessing unit (CPU). Specifically, each AP performs local activity detection\nfor the devices and then transmits the detection result to the CPU for further\nprocessing. In particular, a novel coordinate descent algorithm based on the\nSherman-Morrison-Woodbury update with Taylor expansion is proposed to handle\nthe local detection problem at each AP. Moreover, we theoretically analyze how\nthe hybrid near-far field channels affect the detection performance. Simulation\nresults validate the theoretical analysis and demonstrate the superior\nperformance of the proposed approach compared with existing approaches.", "published": "2025-06-17 07:16:58", "link": "http://arxiv.org/abs/2506.14254v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Comprehensive Survey on Underwater Acoustic Target Positioning and Tracking: Progress, Challenges, and Perspectives", "abstract": "Underwater target tracking technology plays a pivotal role in marine resource\nexploration, environmental monitoring, and national defense security. Given\nthat acoustic waves represent an effective medium for long-distance\ntransmission in aquatic environments, underwater acoustic target tracking has\nbecome a prominent research area of underwater communications and networking.\nExisting literature reviews often offer a narrow perspective or inadequately\naddress the paradigm shifts driven by emerging technologies like deep learning\nand reinforcement learning. To address these gaps, this work presents a\nsystematic survey of this field and introduces an innovative multidimensional\ntaxonomy framework based on target scale, sensor perception modes, and sensor\ncollaboration patterns. Within this framework, we comprehensively survey the\nliterature (more than 180 publications) over the period 2016-2025, spanning\nfrom the theoretical foundations to diverse algorithmic approaches in\nunderwater acoustic target tracking. Particularly, we emphasize the\ntransformative potential and recent advancements of machine learning\ntechniques, including deep learning and reinforcement learning, in enhancing\nthe performance and adaptability of underwater tracking systems. Finally, this\nsurvey concludes by identifying key challenges in the field and proposing\nfuture avenues based on emerging technologies such as federated learning,\nblockchain, embodied intelligence, and large models.", "published": "2025-06-17 03:57:40", "link": "http://arxiv.org/abs/2506.14165v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size", "abstract": "Pretraining large language models is a costly process. To make this process\nmore efficient, several methods have been proposed to optimize model\narchitecture/parametrization and hardware use. On the parametrization side,\n$\\mu P$ (Maximal Update Parametrization) parametrizes model weights and\nlearning rate (LR) in a way that makes hyperparameters (HPs) transferable with\nwidth (embedding dimension): HPs can be tuned for a small model and used for\nlarger models without additional tuning. While $\\mu$P showed impressive results\nin practice, recent empirical studies have reported conflicting observations\nwhen applied to LLMs. One limitation of the theory behind $\\mu$P is the fact\nthat input dimension (vocabulary size in LLMs) is considered fixed when taking\nthe width to infinity. This is unrealistic since vocabulary size is generally\nmuch larger than width in practice. In this work, we provide a theoretical\nanalysis of the effect of vocabulary size on training dynamics, and\nsubsequently show that as vocabulary size increases, the training dynamics\n\\emph{interpolate between the $\\mu$P regime and another regime that we call\nLarge Vocab (LV) Regime}, where optimal scaling rules are different from those\npredicted by $\\mu$P. Our analysis reveals that in the LV regime, the optimal\nembedding LR to hidden LR ratio should roughly scale as $\\Theta(\\sqrt{width})$,\nsurprisingly close to the empirical findings previously reported in the\nliterature, and different from the $\\Theta(width)$ ratio predicted by $\\mu$P.\nWe conduct several experiments to validate our theory, and pretrain a 1B model\nfrom scratch to show the benefit of our suggested scaling rule for the\nembedding LR.", "published": "2025-06-17 23:57:30", "link": "http://arxiv.org/abs/2506.15025v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "abstract": "In this work, we observe an interesting phenomenon: it is possible to\ngenerate reversible sentence embeddings that allow an LLM to reconstruct the\noriginal text exactly, without modifying the model's weights. This is achieved\nby introducing a special memory token, whose embedding is optimized through\ntraining on a fixed sequence. When prompted with this embedding, the model\nreconstructs the fixed sequence exactly. We evaluate this phenomenon across\nEnglish and Spanish datasets, sequences of up to approximately 240 tokens, and\nmodel scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B\nsuccessfully reconstructs all tested sequences. Our findings highlight an\ninteresting capability of LLMs and suggest potential applications in\nmemory-based retrieval, compression, and controlled text generation.", "published": "2025-06-17 22:13:34", "link": "http://arxiv.org/abs/2506.15001v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings", "abstract": "As Large Language Models (LLMs) increasingly appear in social science\nresearch (e.g., economics and marketing), it becomes crucial to assess how well\nthese models replicate human behavior. In this work, using hypothesis testing,\nwe present a quantitative framework to assess the misalignment between\nLLM-simulated and actual human behaviors in multiple-choice survey settings.\nThis framework allows us to determine in a principled way whether a specific\nlanguage model can effectively simulate human opinions, decision-making, and\ngeneral behaviors represented through multiple-choice options. We applied this\nframework to a popular language model for simulating people's opinions in\nvarious public surveys and found that this model is ill-suited for simulating\nthe tested sub-populations (e.g., across different races, ages, and incomes)\nfor contentious questions. This raises questions about the alignment of this\nlanguage model with the tested populations, highlighting the need for new\npractices in using LLMs for social science studies beyond naive simulations of\nhuman subjects.", "published": "2025-06-17 22:04:55", "link": "http://arxiv.org/abs/2506.14997v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective", "abstract": "Reinforcement learning (RL) has emerged as a promising approach to improve\nlarge language model (LLM) reasoning, yet most open efforts focus narrowly on\nmath and code, limiting our understanding of its broader applicability to\ngeneral reasoning. A key challenge lies in the lack of reliable, scalable RL\nreward signals across diverse reasoning domains. We introduce Guru, a curated\nRL reasoning corpus of 92K verifiable examples spanning six reasoning\ndomains--Math, Code, Science, Logic, Simulation, and Tabular--each built\nthrough domain-specific reward design, deduplication, and filtering to ensure\nreliability and effectiveness for RL training. Based on Guru, we systematically\nrevisit established findings in RL for LLM reasoning and observe significant\nvariation across domains. For example, while prior work suggests that RL\nprimarily elicits existing knowledge from pretrained models, our results reveal\na more nuanced pattern: domains frequently seen during pretraining (Math, Code,\nScience) easily benefit from cross-domain RL training, while domains with\nlimited pretraining exposure (Logic, Simulation, and Tabular) require in-domain\ntraining to achieve meaningful performance gains, suggesting that RL is likely\nto facilitate genuine skill acquisition. Finally, we present Guru-7B and\nGuru-32B, two models that achieve state-of-the-art performance among open\nmodels RL-trained with publicly available data, outperforming best baselines by\n7.9% and 6.7% on our 17-task evaluation suite across six reasoning domains. We\nalso show that our models effectively improve the Pass@k performance of their\nbase models, particularly on complex tasks less likely to appear in pretraining\ndata. We release data, models, training and evaluation code to facilitate\ngeneral-purpose reasoning at: https://github.com/LLM360/Reasoning360", "published": "2025-06-17 20:24:00", "link": "http://arxiv.org/abs/2506.14965v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?", "abstract": "While Machine Learning (ML) and Deep Learning (DL) models have been widely\nused for diabetes prediction, the use of Large Language Models (LLMs) for\nstructured numerical data is still not well explored. In this study, we test\nthe effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and\nthree-shot prompting methods. We conduct an empirical analysis using the Pima\nIndian Diabetes Database (PIDD). We evaluate six LLMs, including four\nopen-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We\nalso test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we\ncompare their performance with three traditional machine learning models:\nRandom Forest, Logistic Regression, and Support Vector Machine (SVM). We use\naccuracy, precision, recall, and F1-score as evaluation metrics. Our results\nshow that proprietary LLMs perform better than open-source ones, with GPT-4o\nand Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,\nGemma-2-27B also outperforms the traditional ML models in terms of F1-score.\nHowever, there are still issues such as performance variation across prompting\nstrategies and the need for domain-specific fine-tuning. This study shows that\nLLMs can be useful for medical prediction tasks and encourages future work on\nprompt engineering and hybrid approaches to improve healthcare predictions.", "published": "2025-06-17 20:00:16", "link": "http://arxiv.org/abs/2506.14949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance", "abstract": "Natural language processing evaluation has made significant progress, largely\ndriven by the proliferation of powerful large language mod-els (LLMs). New\nevaluation benchmarks are of increasing priority as the reasoning capabilities\nof LLMs are expanding at a rapid pace. In particular, while multi-document (MD)\nreasoning is an area of extreme relevance given LLM capabilities in handling\nlonger-context inputs, few benchmarks exist to rigorously examine model\nbehavior in this setting. Moreover, the multi-document setting is historically\nchallenging for benchmark creation due to the expensive cost of annotating long\ninputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs\non the task of multi-document reasoning. Notably, MDBench is created through a\nnovel synthetic generation process, allowing us to controllably and efficiently\ngenerate challenging document sets and the corresponding question-answer (QA)\nexamples. Our novel technique operates on condensed structured seed knowledge,\nmodifying it through LLM-assisted edits to induce MD-specific reasoning\nchallenges. We then convert this structured knowledge into a natural text\nsurface form, generating a document set and corresponding QA example. We\nanalyze the behavior of popular LLMs and prompting techniques, finding that\nMDBENCH poses significant challenges for all methods, even with relatively\nshort document sets. We also see our knowledge-guided generation technique (1)\nallows us to readily perform targeted analysis of MD-specific reasoning\ncapabilities and (2) can be adapted quickly to account for new challenges and\nfuture modeling improvements.", "published": "2025-06-17 19:14:30", "link": "http://arxiv.org/abs/2506.14927v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision", "abstract": "The integration of contextual information has significantly enhanced the\nperformance of large language models (LLMs) on knowledge-intensive tasks.\nHowever, existing methods often overlook a critical challenge: the credibility\nof context documents can vary widely, potentially leading to the propagation of\nunreliable information. In this paper, we introduce CrEst, a novel weakly\nsupervised framework for assessing the credibility of context documents during\nLLM inference--without requiring manual annotations. Our approach is grounded\nin the insight that credible documents tend to exhibit higher semantic\ncoherence with other credible documents, enabling automated credibility\nestimation through inter-document agreement. To incorporate credibility into\nLLM inference, we propose two integration strategies: a black-box approach for\nmodels without access to internal weights or activations, and a white-box\nmethod that directly modifies attention mechanisms. Extensive experiments\nacross three model architectures and five datasets demonstrate that CrEst\nconsistently outperforms strong baselines, achieving up to a 26.86% improvement\nin accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst\nmaintains robust performance even under high-noise conditions.", "published": "2025-06-17 18:44:21", "link": "http://arxiv.org/abs/2506.14912v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction", "abstract": "Many recent approaches to structured NLP tasks use an autoregressive language\nmodel $M$ to map unstructured input text $x$ to output text $y$ representing\nstructured objects (such as tuples, lists, trees, code, etc.), where the\ndesired output structure is enforced via constrained decoding. During training,\nthese approaches do not require the model to be aware of the constraints, which\nare merely implicit in the training outputs $y$. This is advantageous as it\nallows for dynamic constraints without requiring retraining, but can lead to\nlow-quality output during constrained decoding at test time. We overcome this\nproblem with Boosted Constrained Decoding (BoostCD), which combines constrained\nand unconstrained decoding in two phases: Phase 1 decodes from the base model\n$M$ twice, in constrained and unconstrained mode, obtaining two weak\npredictions. In phase 2, a learned autoregressive boosted model combines the\ntwo weak predictions into one final prediction. The mistakes made by the base\nmodel with vs. without constraints tend to be complementary, which the boosted\nmodel learns to exploit for improved performance. We demonstrate the power of\nBoostCD by applying it to closed information extraction. Our model, BoostIE,\noutperforms prior approaches both in and out of distribution, addressing\nseveral common errors identified in those approaches.", "published": "2025-06-17 18:16:17", "link": "http://arxiv.org/abs/2506.14901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings", "abstract": "In this work, we present a manually annotated corpus for Adverse Event (AE)\nextraction from discharge summaries of elderly patients, a population often\nunderrepresented in clinical NLP resources. The dataset includes 14 clinically\nsignificant AEs-such as falls, delirium, and intracranial haemorrhage, along\nwith contextual attributes like negation, diagnosis type, and in-hospital\noccurrence. Uniquely, the annotation schema supports both discontinuous and\noverlapping entities, addressing challenges rarely tackled in prior work. We\nevaluate multiple models using FlairNLP across three annotation granularities:\nfine-grained, coarse-grained, and coarse-grained with negation. While\ntransformer-based models (e.g., BERT-cased) achieve strong performance on\ndocument-level coarse-grained extraction (F1 = 0.943), performance drops\nnotably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly\nfor rare events and complex attributes. These results demonstrate that despite\nhigh-level scores, significant challenges remain in detecting underrepresented\nAEs and capturing nuanced clinical language. Developed within a Trusted\nResearch Environment (TRE), the dataset is available upon request via DataLoch\nand serves as a robust benchmark for evaluating AE extraction methods and\nsupporting future cross-dataset generalisation.", "published": "2025-06-17 18:13:40", "link": "http://arxiv.org/abs/2506.14900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs", "abstract": "We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model\noptimized via reinforcement learning (RL) to achieve efficient and robust\nreasoning capabilities. Built upon the publicly available Ling-lite model, a\n16.8 billion parameter model with 2.75 billion activated parameters, our\napproach matches the performance of state-of-the-art (SOTA) small-scale\nreasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench,\nGPQA-Diamond) while activating only one-third of the parameters required by\ncomparable models. To accomplish this, we introduce a joint training pipeline\nintegrating distillation with RL, revealing undocumented challenges in MoE RL\ntraining. First, we identify optimization instability during RL training, and\nwe propose Constrained Contextual Computation Policy Optimization(C3PO), a\nnovel approach that enhances training stability and improves computational\nthroughput via algorithm-system co-design methodology. Second, we empirically\ndemonstrate that selecting distillation checkpoints based on entropy loss for\nRL training, rather than validation metrics, yields superior\nperformance-efficiency trade-offs in subsequent RL training. Finally, we\ndevelop a two-stage training paradigm to harmonize multi-domain data\nintegration, addressing domain conflicts that arise in training with mixed\ndataset. We will release the model, dataset, and code.", "published": "2025-06-17 17:12:34", "link": "http://arxiv.org/abs/2506.14731v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation", "abstract": "The recent development and wider accessibility of LLMs have spurred\ndiscussions about how they can be used in survey research, including\nclassifying open-ended survey responses. Due to their linguistic capacities, it\nis possible that LLMs are an efficient alternative to time-consuming manual\ncoding and the pre-training of supervised machine learning models. As most\nexisting research on this topic has focused on English-language responses\nrelating to non-complex topics or on single LLMs, it is unclear whether its\nfindings generalize and how the quality of these classifications compares to\nestablished methods. In this study, we investigate to what extent different\nLLMs can be used to code open-ended survey responses in other contexts, using\nGerman data on reasons for survey participation as an example. We compare\nseveral state-of-the-art LLMs and several prompting approaches, and evaluate\nthe LLMs' performance by using human expert codings. Overall performance\ndiffers greatly between LLMs, and only a fine-tuned LLM achieves satisfactory\nlevels of predictive performance. Performance differences between prompting\napproaches are conditional on the LLM used. Finally, LLMs' unequal\nclassification performance across different categories of reasons for survey\nparticipation results in different categorical distributions when not using\nfine-tuning. We discuss the implications of these findings, both for\nmethodological research on coding open-ended responses and for their\nsubstantive analysis, and for practitioners processing or substantively\nanalyzing such data. Finally, we highlight the many trade-offs researchers need\nto consider when choosing automated methods for open-ended response\nclassification in the age of LLMs. In doing so, our study contributes to the\ngrowing body of research about the conditions under which LLMs can be\nefficiently, accurately, and reliably leveraged in survey research.", "published": "2025-06-17 15:28:53", "link": "http://arxiv.org/abs/2506.14634v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models", "abstract": "Large Language Models (LLMs) have shown impressive moral reasoning abilities.\nYet they often diverge when confronted with complex, multi-factor moral\ndilemmas. To address these discrepancies, we propose a framework that\nsynthesizes multiple LLMs' moral judgments into a collectively formulated moral\njudgment, realigning models that deviate significantly from this consensus. Our\naggregation mechanism fuses continuous moral acceptability scores (beyond\nbinary labels) into a collective probability, weighting contributions by model\nreliability. For misaligned models, a targeted embedding-optimization procedure\nfine-tunes token embeddings for moral philosophical theories, minimizing JS\ndivergence to the consensus while preserving semantic integrity. Experiments on\na large-scale social moral dilemma dataset show our approach builds robust\nconsensus and improves individual model fidelity. These findings highlight the\nvalue of data-driven moral alignment across multiple models and its potential\nfor safer, more consistent AI systems.", "published": "2025-06-17 15:22:21", "link": "http://arxiv.org/abs/2506.14625v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding", "abstract": "Negation is a fundamental linguistic phenomenon that poses persistent\nchallenges for Large Language Models (LLMs), particularly in tasks requiring\ndeep semantic understanding. Existing benchmarks often treat negation as a side\ncase within broader tasks like natural language inference, resulting in a lack\nof benchmarks that exclusively target negation understanding. In this work, we\nintroduce Thunder-NUBench, a novel benchmark explicitly designed to assess\nsentence-level negation understanding in LLMs. Thunder-NUBench goes beyond\nsurface-level cue detection by contrasting standard negation with structurally\ndiverse alternatives such as local negation, contradiction, and paraphrase. The\nbenchmark consists of manually curated sentence-negation pairs and a\nmultiple-choice dataset that enables in-depth evaluation of models' negation\nunderstanding.", "published": "2025-06-17 10:51:39", "link": "http://arxiv.org/abs/2506.14397v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SFT-GO: Supervised Fine-Tuning with Group Optimization for Large Language Models", "abstract": "Supervised fine-tuning (SFT) has become an essential step in tailoring large\nlanguage models (LLMs) to align with human expectations and specific downstream\ntasks. However, existing SFT methods typically treat each training instance as\na uniform sequence, giving equal importance to all tokens regardless of their\nrelevance. This overlooks the fact that only a subset of tokens often contains\ncritical, task-specific information. To address this limitation, we introduce\nSupervised Fine-Tuning with Group Optimization (SFT-GO), a novel approach that\ntreats groups of tokens differently based on their importance.SFT-GO groups\ntokens in each sample based on their importance values and optimizes the LLM\nusing a weighted combination of the worst-group loss and the standard\ncross-entropy loss. This mechanism adaptively emphasizes the most challenging\ntoken groups and guides the model to better handle different group\ndistributions, thereby improving overall learning dynamics. We provide a\ntheoretical analysis of SFT-GO's convergence rate, demonstrating its\nefficiency. Empirically, we apply SFT-GO with three different token grouping\nstrategies and show that models trained with SFT-GO consistently outperform\nbaseline approaches across popular LLM benchmarks. These improvements hold\nacross various datasets and base models, demonstrating the robustness and the\neffectiveness of our method.", "published": "2025-06-17 23:12:28", "link": "http://arxiv.org/abs/2506.15021v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment", "abstract": "Effective reinforcement learning (RL) for sepsis treatment depends on\nlearning stable, clinically meaningful state representations from irregular ICU\ntime series. While previous works have explored representation learning for\nthis task, the critical challenge of training instability in sequential\nrepresentations and its detrimental impact on policy performance has been\noverlooked. This work demonstrates that Controlled Differential Equations (CDE)\nstate representation can achieve strong RL policies when two key factors are\nmet: (1) ensuring training stability through early stopping or stabilization\nmethods, and (2) enforcing acuity-aware representations by correlation\nregularization with clinical scores (SOFA, SAPS-II, OASIS). Experiments on the\nMIMIC-III sepsis cohort reveal that stable CDE autoencoder produces\nrepresentations strongly correlated with acuity scores and enables RL policies\nwith superior performance (WIS return $> 0.9$). In contrast, unstable CDE\nrepresentation leads to degraded representations and policy failure (WIS return\n$\\sim$ 0). Visualizations of the latent space show that stable CDEs not only\nseparate survivor and non-survivor trajectories but also reveal clear acuity\nscore gradients, whereas unstable training fails to capture either pattern.\nThese findings highlight practical guidelines for using CDEs to encode\nirregular medical time series in clinical RL, emphasizing the need for training\nstability in sequential representation learning.", "published": "2025-06-17 23:10:51", "link": "http://arxiv.org/abs/2506.15019v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Insights Informed Generative AI for Design: Incorporating Real-world Data for Text-to-Image Output", "abstract": "Generative AI, specifically text-to-image models, have revolutionized\ninterior architectural design by enabling the rapid translation of conceptual\nideas into visual representations from simple text prompts. While generative AI\ncan produce visually appealing images they often lack actionable data for\ndesigners In this work, we propose a novel pipeline that integrates DALL-E 3\nwith a materials dataset to enrich AI-generated designs with sustainability\nmetrics and material usage insights. After the model generates an interior\ndesign image, a post-processing module identifies the top ten materials present\nand pairs them with carbon dioxide equivalent (CO2e) values from a general\nmaterials dictionary. This approach allows designers to immediately evaluate\nenvironmental impacts and refine prompts accordingly. We evaluate the system\nthrough three user tests: (1) no mention of sustainability to the user prior to\nthe prompting process with generative AI, (2) sustainability goals communicated\nto the user before prompting, and (3) sustainability goals communicated along\nwith quantitative CO2e data included in the generative AI outputs. Our\nqualitative and quantitative analyses reveal that the introduction of\nsustainability metrics in the third test leads to more informed design\ndecisions, however, it can also trigger decision fatigue and lower overall\nsatisfaction. Nevertheless, the majority of participants reported incorporating\nsustainability principles into their workflows in the third test, underscoring\nthe potential of integrated metrics to guide more ecologically responsible\npractices. Our findings showcase the importance of balancing design freedom\nwith practical constraints, offering a clear path toward holistic, data-driven\nsolutions in AI-assisted architectural design.", "published": "2025-06-17 22:33:11", "link": "http://arxiv.org/abs/2506.15008v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Scaling Intelligence: Designing Data Centers for Next-Gen Language Models", "abstract": "The explosive growth of Large Language Models (LLMs) - such as GPT-4 with 1.8\ntrillion parameters - demands a radical rethinking of data center architecture\nto ensure scalability, efficiency, and cost-effectiveness. Our work provides a\ncomprehensive co-design framework that jointly explores FLOPS, HBM bandwidth\nand capacity, multiple network topologies (two-tier vs. FullFlat optical), the\nsize of the scale-out domain, and popular parallelism/optimization strategies\nused in LLMs. We introduce and evaluate FullFlat network architectures, which\nprovide uniform high-bandwidth, low-latency connectivity between all nodes, and\ndemonstrate their transformative impact on performance and scalability. Through\ndetailed sensitivity analyses, we quantify the benefits of overlapping compute\nand communication, leveraging hardware-accelerated collectives, wider scale-out\ndomains, and larger memory capacity. Our study spans both sparse (mixture of\nexperts) and dense transformer-based LLMs, revealing how system design choices\naffect Model FLOPS Utilization (MFU = Model flops per token x Observed tokens\nper sec / Peak flops of the hardware) and overall throughput. For the co-design\nstudy, we extended and validated a performance modeling tool capable of\npredicting LLM runtime within 10% of real-world measurements. Our findings\noffer actionable insights and a practical roadmap for designing AI data centers\nthat can efficiently support trillion-parameter models, reduce optimization\ncomplexity, and sustain the rapid evolution of AI capabilities.", "published": "2025-06-17 22:29:37", "link": "http://arxiv.org/abs/2506.15006v1", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.ET", "cs.PF"], "primary_category": "cs.AR"}
{"title": "Improved Image Reconstruction and Diffusion Parameter Estimation Using a Temporal Convolutional Network Model of Gradient Trajectory Errors", "abstract": "Summary: Errors in gradient trajectories introduce significant artifacts and\ndistortions in magnetic resonance images, particularly in non-Cartesian imaging\nsequences, where imperfect gradient waveforms can greatly reduce image quality.\nPurpose: Our objective is to develop a general, nonlinear gradient system model\nthat can accurately predict gradient distortions using convolutional networks.\nMethods: A set of training gradient waveforms were measured on a small animal\nimaging system, and used to train a temporal convolutional network to predict\nthe gradient waveforms produced by the imaging system. Results: The trained\nnetwork was able to accurately predict nonlinear distortions produced by the\ngradient system. Network prediction of gradient waveforms was incorporated into\nthe image reconstruction pipeline and provided improvements in image quality\nand diffusion parameter mapping compared to both the nominal gradient waveform\nand the gradient impulse response function. Conclusion: Temporal convolutional\nnetworks can more accurately model gradient system behavior than existing\nlinear methods and may be used to retrospectively correct gradient errors.", "published": "2025-06-17 22:01:06", "link": "http://arxiv.org/abs/2506.14995v1", "categories": ["physics.med-ph", "cs.AI"], "primary_category": "physics.med-ph"}
{"title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "abstract": "Benchmarks play a crucial role in the development and analysis of\nreinforcement learning (RL) algorithms, with environment availability strongly\nimpacting research. One particularly underexplored intersection is continual\nlearning (CL) in cooperative multi-agent settings. To remedy this, we introduce\nMEAL (Multi-agent Environments for Adaptive Learning), the first benchmark\ntailored for continual multi-agent reinforcement learning (CMARL). Existing CL\nbenchmarks run environments on the CPU, leading to computational bottlenecks\nand limiting the length of task sequences. MEAL leverages JAX for GPU\nacceleration, enabling continual learning across sequences of 100 tasks on a\nstandard desktop PC in a few hours. We show that naively combining popular CL\nand MARL methods yields strong performance on simple environments, but fails to\nscale to more complex settings requiring sustained coordination and adaptation.\nOur ablation study identifies architectural and algorithmic features critical\nfor CMARL on MEAL.", "published": "2025-06-17 21:50:04", "link": "http://arxiv.org/abs/2506.14990v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "abstract": "We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at\nensuring fair outcomes across agents while maximizing overall system\nperformance. A key challenge in this setting is decision-making under limited\ninformation about arm rewards. To address this, we introduce a novel probing\nframework that strategically gathers information about selected arms before\nallocation. In the offline setting, where reward distributions are known, we\nleverage submodular properties to design a greedy probing algorithm with a\nprovable performance bound. For the more complex online setting, we develop an\nalgorithm that achieves sublinear regret while maintaining fairness. Extensive\nexperiments on synthetic and real-world datasets show that our approach\noutperforms baseline methods, achieving better fairness and efficiency.", "published": "2025-06-17 21:43:21", "link": "http://arxiv.org/abs/2506.14988v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition", "abstract": "Recent studies have demonstrated that prompting large language models (LLM)\nwith audio encodings enables effective speech recognition capabilities.\nHowever, the ability of Speech LLMs to comprehend and process multi-channel\naudio with spatial cues remains a relatively uninvestigated area of research.\nIn this work, we present directional-SpeechLlama, a novel approach that\nleverages the microphone array of smart glasses to achieve directional speech\nrecognition, source localization, and bystander cross-talk suppression. To\nenhance the model's ability to understand directivity, we propose two key\ntechniques: serialized directional output training (S-DOT) and contrastive\ndirection data augmentation (CDDA). Experimental results show that our proposed\ndirectional-SpeechLlama effectively captures the relationship between textual\ncues and spatial audio, yielding strong performance in both speech recognition\nand source localization tasks.", "published": "2025-06-17 20:49:41", "link": "http://arxiv.org/abs/2506.14973v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization", "abstract": "Physical caregiving robots hold promise for improving the quality of life of\nmillions worldwide who require assistance with feeding. However, in-home meal\nassistance remains challenging due to the diversity of activities (e.g.,\neating, drinking, mouth wiping), contexts (e.g., socializing, watching TV),\nfood items, and user preferences that arise during deployment. In this work, we\npropose FEAST, a flexible mealtime-assistance system that can be personalized\nin-the-wild to meet the unique needs of individual care recipients. Developed\nin collaboration with two community researchers and informed by a formative\nstudy with a diverse group of care recipients, our system is guided by three\nkey tenets for in-the-wild personalization: adaptability, transparency, and\nsafety. FEAST embodies these principles through: (i) modular hardware that\nenables switching between assisted feeding, drinking, and mouth-wiping, (ii)\ndiverse interaction methods, including a web interface, head gestures, and\nphysical buttons, to accommodate diverse functional abilities and preferences,\nand (iii) parameterized behavior trees that can be safely and transparently\nadapted using a large language model. We evaluate our system based on the\npersonalization requirements identified in our formative study, demonstrating\nthat FEAST offers a wide range of transparent and safe adaptations and\noutperforms a state-of-the-art baseline limited to fixed customizations. To\ndemonstrate real-world applicability, we conduct an in-home user study with two\ncare recipients (who are community researchers), feeding them three meals each\nacross three diverse scenarios. We further assess FEAST's ecological validity\nby evaluating with an Occupational Therapist previously unfamiliar with the\nsystem. In all cases, users successfully personalize FEAST to meet their\nindividual needs and preferences. Website: https://emprise.cs.cornell.edu/feast", "published": "2025-06-17 20:30:11", "link": "http://arxiv.org/abs/2506.14968v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Flat Channels to Infinity in Neural Loss Landscapes", "abstract": "The loss landscapes of neural networks contain minima and saddle points that\nmay be connected in flat regions or appear in isolation. We identify and\ncharacterize a special structure in the loss landscape: channels along which\nthe loss decreases extremely slowly, while the output weights of at least two\nneurons, $a_i$ and $a_j$, diverge to $\\pm$infinity, and their input weight\nvectors, $\\mathbf{w_i}$ and $\\mathbf{w_j}$, become equal to each other. At\nconvergence, the two neurons implement a gated linear unit:\n$a_i\\sigma(\\mathbf{w_i} \\cdot \\mathbf{x}) + a_j\\sigma(\\mathbf{w_j} \\cdot\n\\mathbf{x}) \\rightarrow \\sigma(\\mathbf{w} \\cdot \\mathbf{x}) + (\\mathbf{v} \\cdot\n\\mathbf{x}) \\sigma'(\\mathbf{w} \\cdot \\mathbf{x})$. Geometrically, these\nchannels to infinity are asymptotically parallel to symmetry-induced lines of\ncritical points. Gradient flow solvers, and related optimization methods like\nSGD or ADAM, reach the channels with high probability in diverse regression\nsettings, but without careful inspection they look like flat local minima with\nfinite parameter values. Our characterization provides a comprehensive picture\nof these quasi-flat regions in terms of gradient dynamics, geometry, and\nfunctional interpretation. The emergence of gated linear units at the end of\nthe channels highlights a surprising aspect of the computational capabilities\nof fully connected layers.", "published": "2025-06-17 20:04:15", "link": "http://arxiv.org/abs/2506.14951v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Determina\u00e7\u00e3o Autom\u00e1tica de Limiar de Detec\u00e7\u00e3o de Ataques em Redes de Computadores Utilizando Autoencoders", "abstract": "Currently, digital security mechanisms like Anomaly Detection Systems using\nAutoencoders (AE) show great potential for bypassing problems intrinsic to the\ndata, such as data imbalance. Because AE use a non-trivial and nonstandardized\nseparation threshold to classify the extracted reconstruction error, the\ndefinition of this threshold directly impacts the performance of the detection\nprocess. Thus, this work proposes the automatic definition of this threshold\nusing some machine learning algorithms. For this, three algorithms were\nevaluated: the K-Nearst Neighbors, the K-Means and the Support Vector Machine.", "published": "2025-06-17 19:45:25", "link": "http://arxiv.org/abs/2506.14937v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NI", "cs.PF"], "primary_category": "cs.LG"}
{"title": "CALM: Contextual Analog Logic with Multimodality", "abstract": "In this work, we introduce Contextual Analog Logic with Multimodality (CALM).\nCALM unites symbolic reasoning with neural generation, enabling systems to make\ncontext-sensitive decisions grounded in real-world multi-modal data.\n  Background: Classic bivalent logic systems cannot capture the nuance of human\ndecision-making. They also require human grounding in multi-modal environments,\nwhich can be ad-hoc, rigid, and brittle. Neural networks are good at extracting\nrich contextual information from multi-modal data, but lack interpretable\nstructures for reasoning.\n  Objectives: CALM aims to bridge the gap between logic and neural perception,\ncreating an analog logic that can reason over multi-modal inputs. Without this\nintegration, AI systems remain either brittle or unstructured, unable to\ngeneralize robustly to real-world tasks. In CALM, symbolic predicates evaluate\nto analog truth values computed by neural networks and constrained search.\n  Methods: CALM represents each predicate using a domain tree, which\niteratively refines its analog truth value when the contextual groundings of\nits entities are determined. The iterative refinement is predicted by neural\nnetworks capable of capturing multi-modal information and is filtered through a\nsymbolic reasoning module to ensure constraint satisfaction.\n  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%\naccuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It\nalso demonstrated spatial heatmap generation aligned with logical constraints\nand delicate human preferences, as shown by a human study.\n  Conclusions: CALM demonstrates the potential to reason with logic structure\nwhile aligning with preferences in multi-modal environments. It lays the\nfoundation for next-gen AI systems that require the precision and\ninterpretation of logic and the multimodal information processing of neural\nnetworks.", "published": "2025-06-17 19:40:32", "link": "http://arxiv.org/abs/2506.14936v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection", "abstract": "The decentralized finance (DeFi) community has grown rapidly in recent years,\npushed forward by cryptocurrency enthusiasts interested in the vast untapped\npotential of new markets. The surge in popularity of cryptocurrency has ushered\nin a new era of financial crime. Unfortunately, the novelty of the technology\nmakes the task of catching and prosecuting offenders particularly challenging.\nThus, it is necessary to implement automated detection tools related to\npolicies to address the growing criminality in the cryptocurrency realm.", "published": "2025-06-17 19:30:21", "link": "http://arxiv.org/abs/2506.14933v1", "categories": ["cs.CE", "cs.AI", "cs.CR", "68T09 (Primary) 05C82, 68T07, 94A60 (Secondary)", "I.2.6; I.2.7; G.2.2; H.2.8; K.4.4"], "primary_category": "cs.CE"}
{"title": "Forecasting the spatiotemporal evolution of fluid-induced microearthquakes with deep learning", "abstract": "Microearthquakes (MEQs) generated by subsurface fluid injection record the\nevolving stress state and permeability of reservoirs. Forecasting their full\nspatiotemporal evolution is therefore critical for applications such as\nenhanced geothermal systems (EGS), CO$_2$ sequestration and other\ngeo-engineering applications. We present a transformer-based deep learning\nmodel that ingests hydraulic stimulation history and prior MEQ observations to\nforecast four key quantities: cumulative MEQ count, cumulative logarithmic\nseismic moment, and the 50th- and 95th-percentile extents ($P_{50}, P_{95}$) of\nthe MEQ cloud. Applied to the EGS Collab Experiment 1 dataset, the model\nachieves $R^2 >0.98$ for the 1-second forecast horizon and $R^2 >0.88$ for the\n15-second forecast horizon across all targets, and supplies uncertainty\nestimates through a learned standard deviation term. These accurate,\nuncertainty-quantified forecasts enable real-time inference of fracture\npropagation and permeability evolution, demonstrating the strong potential of\ndeep-learning approaches to improve seismic-risk assessment and guide\nmitigation strategies in future fluid-injection operations.", "published": "2025-06-17 19:10:05", "link": "http://arxiv.org/abs/2506.14923v1", "categories": ["physics.geo-ph", "cs.AI", "cs.LG"], "primary_category": "physics.geo-ph"}
{"title": "Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)", "abstract": "Background: Facial appearance offers a noninvasive window into health. We\nbuilt FAHR-Face, a foundation model trained on >40 million facial images and\nfine-tuned it for two distinct tasks: biological age estimation (FAHR-FaceAge)\nand survival risk prediction (FAHR-FaceSurvival).\n  Methods: FAHR-FaceAge underwent a two-stage, age-balanced fine-tuning on\n749,935 public images; FAHR-FaceSurvival was fine-tuned on 34,389 photos of\ncancer patients. Model robustness (cosmetic surgery, makeup, pose, lighting)\nand independence (saliency mapping) was tested extensively. Both models were\nclinically tested in two independent cancer patient datasets with survival\nanalyzed by multivariable Cox models and adjusted for clinical prognostic\nfactors.\n  Findings: For age estimation, FAHR-FaceAge had the lowest mean absolute error\nof 5.1 years on public datasets, outperforming benchmark models and maintaining\naccuracy across the full human lifespan. In cancer patients, FAHR-FaceAge\noutperformed a prior facial age estimation model in survival prognostication.\nFAHR-FaceSurvival demonstrated robust prediction of mortality, and the\nhighest-risk quartile had more than triple the mortality of the lowest\n(adjusted hazard ratio 3.22; P<0.001). These findings were validated in the\nindependent cohort and both models showed generalizability across age, sex,\nrace and cancer subgroups. The two algorithms provided distinct, complementary\nprognostic information; saliency mapping revealed each model relied on distinct\nfacial regions. The combination of FAHR-FaceAge and FAHR-FaceSurvival improved\nprognostic accuracy.\n  Interpretation: A single foundation model can generate inexpensive, scalable\nfacial biomarkers that capture both biological ageing and disease-related\nmortality risk. The foundation model enabled effective training using\nrelatively small clinical datasets.", "published": "2025-06-17 18:28:11", "link": "http://arxiv.org/abs/2506.14909v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning", "abstract": "Inspired by the impressive reasoning capabilities demonstrated by\nreinforcement learning approaches like DeepSeek-R1, recent emerging research\nhas begun exploring the use of reinforcement learning (RL) to enhance\nvision-language models (VLMs) for multimodal reasoning tasks. However, most\nexisting multimodal reinforcement learning approaches remain limited to spatial\nreasoning within single-image contexts, yet still struggle to generalize to\nmore complex and real-world scenarios involving multi-image positional\nreasoning, where understanding the relationships across images is crucial. To\naddress this challenge, we propose a general reinforcement learning approach\nPeRL tailored for interleaved multimodal tasks, and a multi-stage strategy\ndesigned to enhance the exploration-exploitation trade-off, thereby improving\nlearning efficiency and task performance. Specifically, we introduce\npermutation of image sequences to simulate varied positional relationships to\nexplore more spatial and positional diversity. Furthermore, we design a rollout\nfiltering mechanism for resampling to focus on trajectories that contribute\nmost to learning optimal behaviors to exploit learned policies effectively. We\nevaluate our model on 5 widely-used multi-image benchmarks and 3 single-image\nbenchmarks. Our experiments confirm that PeRL trained model consistently\nsurpasses R1-related and interleaved VLM baselines by a large margin, achieving\nstate-of-the-art performance on multi-image benchmarks, while preserving\ncomparable performance on single-image tasks.", "published": "2025-06-17 18:25:56", "link": "http://arxiv.org/abs/2506.14907v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Preparing for the Intelligence Explosion", "abstract": "AI that can accelerate research could drive a century of technological\nprogress over just a few years. During such a period, new technological or\npolitical developments will raise consequential and hard-to-reverse decisions,\nin rapid succession. We call these developments grand challenges. These\nchallenges include new weapons of mass destruction, AI-enabled autocracies,\nraces to grab offworld resources, and digital beings worthy of moral\nconsideration, as well as opportunities to dramatically improve quality of life\nand collective decision-making. We argue that these challenges cannot always be\ndelegated to future AI systems, and suggest things we can do today to\nmeaningfully improve our prospects. AGI preparedness is therefore not just\nabout ensuring that advanced AI systems are aligned: we should be preparing,\nnow, for the disorienting range of developments an intelligence explosion would\nbring.", "published": "2025-06-17 17:37:39", "link": "http://arxiv.org/abs/2506.14863v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Identifiability by common backdoor in summary causal graphs of time series", "abstract": "The identifiability problem for interventions aims at assessing whether the\ntotal effect of some given interventions can be written with a do-free formula,\nand thus be computed from observational data only. We study this problem,\nconsidering multiple interventions and multiple effects, in the context of time\nseries when only abstractions of the true causal graph in the form of summary\ncausal graphs are available. We focus in this study on identifiability by a\ncommon backdoor set, and establish, for time series with and without\nconsistency throughout time, conditions under which such a set exists. We also\nprovide algorithms of limited complexity to decide whether the problem is\nidentifiable or not.", "published": "2025-06-17 17:37:27", "link": "http://arxiv.org/abs/2506.14862v1", "categories": ["math.ST", "cs.AI", "stat.TH"], "primary_category": "math.ST"}
{"title": "Hyper-Local Deformable Transformers for Text Spotting on Historical Maps", "abstract": "Text on historical maps contains valuable information providing georeferenced\nhistorical, political, and cultural contexts. However, text extraction from\nhistorical maps is challenging due to the lack of (1) effective methods and (2)\ntraining data. Previous approaches use ad-hoc steps tailored to only specific\nmap styles. Recent machine learning-based text spotters (e.g., for scene\nimages) have the potential to solve these challenges because of their\nflexibility in supporting various types of text instances. However, these\nmethods remain challenges in extracting precise image features for predicting\nevery sub-component (boundary points and characters) in a text instance. This\nis critical because map text can be lengthy and highly rotated with complex\nbackgrounds, posing difficulties in detecting relevant image features from a\nrough text region. This paper proposes PALETTE, an end-to-end text spotter for\nscanned historical maps of a wide variety. PALETTE introduces a novel\nhyper-local sampling module to explicitly learn localized image features around\nthe target boundary points and characters of a text instance for detection and\nrecognition. PALETTE also enables hyper-local positional embeddings to learn\nspatial interactions between boundary points and characters within and across\ntext instances. In addition, this paper presents a novel approach to\nautomatically generate synthetic map images, SynthMap+, for training text\nspotters for historical maps. The experiment shows that PALETTE with SynthMap+\noutperforms SOTA text spotters on two new benchmark datasets of historical\nmaps, particularly for long and angled text. We have deployed PALETTE with\nSynthMap+ to process over 60,000 maps in the David Rumsey Historical Map\ncollection and generated over 100 million text labels to support map searching.\nThe project is released at\nhttps://github.com/kartta-foundation/mapkurator-palette-doc.", "published": "2025-06-17 22:41:10", "link": "http://arxiv.org/abs/2506.15010v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advances in Compliance Detection: Novel Models Using Vision-Based Tactile Sensors", "abstract": "Compliance is a critical parameter for describing objects in engineering,\nagriculture, and biomedical applications. Traditional compliance detection\nmethods are limited by their lack of portability and scalability, rely on\nspecialized, often expensive equipment, and are unsuitable for robotic\napplications. Moreover, existing neural network-based approaches using\nvision-based tactile sensors still suffer from insufficient prediction\naccuracy. In this paper, we propose two models based on Long-term Recurrent\nConvolutional Networks (LRCNs) and Transformer architectures that leverage RGB\ntactile images and other information captured by the vision-based sensor\nGelSight to predict compliance metrics accurately. We validate the performance\nof these models using multiple metrics and demonstrate their effectiveness in\naccurately estimating compliance. The proposed models exhibit significant\nperformance improvement over the baseline. Additionally, we investigated the\ncorrelation between sensor compliance and object compliance estimation, which\nrevealed that objects that are harder than the sensor are more challenging to\nestimate.", "published": "2025-06-17 21:10:05", "link": "http://arxiv.org/abs/2506.14980v1", "categories": ["cs.CV", "cs.RO", "I.2.9"], "primary_category": "cs.CV"}
{"title": "NeuroMoE: A Transformer-Based Mixture-of-Experts Framework for Multi-Modal Neurological Disorder Classification", "abstract": "The integration of multi-modal Magnetic Resonance Imaging (MRI) and clinical\ndata holds great promise for enhancing the diagnosis of neurological disorders\n(NDs) in real-world clinical settings. Deep Learning (DL) has recently emerged\nas a powerful tool for extracting meaningful patterns from medical data to aid\nin diagnosis. However, existing DL approaches struggle to effectively leverage\nmulti-modal MRI and clinical data, leading to suboptimal performance.\n  To address this challenge, we utilize a unique, proprietary multi-modal\nclinical dataset curated for ND research. Based on this dataset, we propose a\nnovel transformer-based Mixture-of-Experts (MoE) framework for ND\nclassification, leveraging multiple MRI modalities-anatomical (aMRI), Diffusion\nTensor Imaging (DTI), and functional (fMRI)-alongside clinical assessments. Our\nframework employs transformer encoders to capture spatial relationships within\nvolumetric MRI data while utilizing modality-specific experts for targeted\nfeature extraction. A gating mechanism with adaptive fusion dynamically\nintegrates expert outputs, ensuring optimal predictive performance.\nComprehensive experiments and comparisons with multiple baselines demonstrate\nthat our multi-modal approach significantly enhances diagnostic accuracy,\nparticularly in distinguishing overlapping disease states. Our framework\nachieves a validation accuracy of 82.47\\%, outperforming baseline methods by\nover 10\\%, highlighting its potential to improve ND diagnosis by applying\nmulti-modal learning to real-world clinical data.", "published": "2025-06-17 20:40:06", "link": "http://arxiv.org/abs/2506.14970v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Vision Transformers for End-to-End Quark-Gluon Jet Classification from Calorimeter Images", "abstract": "Distinguishing between quark- and gluon-initiated jets is a critical and\nchallenging task in high-energy physics, pivotal for improving new physics\nsearches and precision measurements at the Large Hadron Collider. While deep\nlearning, particularly Convolutional Neural Networks (CNNs), has advanced jet\ntagging using image-based representations, the potential of Vision Transformer\n(ViT) architectures, renowned for modeling global contextual information,\nremains largely underexplored for direct calorimeter image analysis, especially\nunder realistic detector and pileup conditions. This paper presents a\nsystematic evaluation of ViTs and ViT-CNN hybrid models for quark-gluon jet\nclassification using simulated 2012 CMS Open Data. We construct multi-channel\njet-view images from detector-level energy deposits (ECAL, HCAL) and\nreconstructed tracks, enabling an end-to-end learning approach. Our\ncomprehensive benchmarking demonstrates that ViT-based models, notably\nViT+MaxViT and ViT+ConvNeXt hybrids, consistently outperform established CNN\nbaselines in F1-score, ROC-AUC, and accuracy, highlighting the advantage of\ncapturing long-range spatial correlations within jet substructure. This work\nestablishes the first systematic framework and robust performance baselines for\napplying ViT architectures to calorimeter image-based jet classification using\npublic collider data, alongside a structured dataset suitable for further deep\nlearning research in this domain.", "published": "2025-06-17 19:32:04", "link": "http://arxiv.org/abs/2506.14934v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models", "abstract": "The increasing use of diffusion models for image generation, especially in\nsensitive areas like medical imaging, has raised significant privacy concerns.\nMembership Inference Attack (MIA) has emerged as a potential approach to\ndetermine if a specific image was used to train a diffusion model, thus\nquantifying privacy risks. Existing MIA methods often rely on diffusion\nreconstruction errors, where member images are expected to have lower\nreconstruction errors than non-member images. However, applying these methods\ndirectly to medical images faces challenges. Reconstruction error is influenced\nby inherent image difficulty, and diffusion models struggle with high-frequency\ndetail reconstruction. To address these issues, we propose a\nFrequency-Calibrated Reconstruction Error (FCRE) method for MIAs on medical\nimage diffusion models. By focusing on reconstruction errors within a specific\nmid-frequency range and excluding both high-frequency (difficult to\nreconstruct) and low-frequency (less informative) regions, our\nfrequency-selective approach mitigates the confounding factor of inherent image\ndifficulty. Specifically, we analyze the reverse diffusion process, obtain the\nmid-frequency reconstruction error, and compute the structural similarity index\nscore between the reconstructed and original images. Membership is determined\nby comparing this score to a threshold. Experiments on several medical image\ndatasets demonstrate that our FCRE method outperforms existing MIA methods.", "published": "2025-06-17 18:59:43", "link": "http://arxiv.org/abs/2506.14919v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Recursive Variational Autoencoders for 3D Blood Vessel Generative Modeling", "abstract": "Anatomical trees play an important role in clinical diagnosis and treatment\nplanning. Yet, accurately representing these structures poses significant\nchallenges owing to their intricate and varied topology and geometry. Most\nexisting methods to synthesize vasculature are rule based, and despite\nproviding some degree of control and variation in the structures produced, they\nfail to capture the diversity and complexity of actual anatomical data. We\ndeveloped a Recursive variational Neural Network (RvNN) that fully exploits the\nhierarchical organization of the vessel and learns a low-dimensional manifold\nencoding branch connectivity along with geometry features describing the target\nsurface. After training, the RvNN latent space can be sampled to generate new\nvessel geometries. By leveraging the power of generative neural networks, we\ngenerate 3D models of blood vessels that are both accurate and diverse, which\nis crucial for medical and surgical training, hemodynamic simulations, and many\nother purposes. These results closely resemble real data, achieving high\nsimilarity in vessel radii, length, and tortuosity across various datasets,\nincluding those with aneurysms. To the best of our knowledge, this work is the\nfirst to utilize this technique for synthesizing blood vessels.", "published": "2025-06-17 18:47:27", "link": "http://arxiv.org/abs/2506.14914v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "DETONATE: A Benchmark for Text-to-Image Alignment and Kernelized Direct Preference Optimization", "abstract": "Alignment is crucial for text-to-image (T2I) models to ensure that generated\nimages faithfully capture user intent while maintaining safety and fairness.\nDirect Preference Optimization (DPO), prominent in large language models\n(LLMs), is extending its influence to T2I systems. This paper introduces\nDPO-Kernels for T2I models, a novel extension enhancing alignment across three\ndimensions: (i) Hybrid Loss, integrating embedding-based objectives with\ntraditional probability-based loss for improved optimization; (ii) Kernelized\nRepresentations, employing Radial Basis Function (RBF), Polynomial, and Wavelet\nkernels for richer feature transformations and better separation between safe\nand unsafe inputs; and (iii) Divergence Selection, expanding beyond DPO's\ndefault Kullback-Leibler (KL) regularizer by incorporating Wasserstein and\nR'enyi divergences for enhanced stability and robustness. We introduce\nDETONATE, the first large-scale benchmark of its kind, comprising approximately\n100K curated image pairs categorized as chosen and rejected. DETONATE\nencapsulates three axes of social bias and discrimination: Race, Gender, and\nDisability. Prompts are sourced from hate speech datasets, with images\ngenerated by leading T2I models including Stable Diffusion 3.5 Large, Stable\nDiffusion XL, and Midjourney. Additionally, we propose the Alignment Quality\nIndex (AQI), a novel geometric measure quantifying latent-space separability of\nsafe/unsafe image activations, revealing hidden vulnerabilities. Empirically,\nwe demonstrate that DPO-Kernels maintain strong generalization bounds via\nHeavy-Tailed Self-Regularization (HT-SR). DETONATE and complete code are\npublicly released.", "published": "2025-06-17 18:17:35", "link": "http://arxiv.org/abs/2506.14903v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "pycnet-audio: A Python package to support bioacoustics data processing", "abstract": "Passive acoustic monitoring is an emerging approach in wildlife research that\nleverages recent improvements in purpose-made automated recording units (ARUs).\nThe general approach is to deploy ARUs in the field to record on a programmed\nschedule for extended periods (weeks or months), after which the audio data are\nretrieved. These data must then be processed, typically either by measuring or\nanalyzing characteristics of the audio itself (e.g. calculating acoustic\nindices), or by searching for some signal of interest within the recordings,\ne.g. vocalizations or other sounds produced by some target species,\nanthropogenic or environmental noise, etc. In the latter case, some method is\nrequired to locate the signal(s) of interest within the audio. While very small\ndatasets can simply be searched manually, even modest projects can produce\naudio datasets on the order of 105 hours of recordings, making manual review\nimpractical and necessitating some form of automated detection. pycnet-audio\n(Ruff 2024) is intended to provide a practical processing workflow for acoustic\ndata, built around the PNW-Cnet model, which was initially developed by the\nU.S. Forest Service to support population monitoring of northern spotted owls\n(Strix occidentalis caurina) and other forest owls (Lesmeister and Jenkins\n2022; Ruff et al. 2020). PNW-Cnet has been expanded to detect vocalizations of\nca. 80 forest wildlife species and numerous forms of anthropogenic and\nenvironmental noise (Ruff et al. 2021, 2023).", "published": "2025-06-17 17:40:21", "link": "http://arxiv.org/abs/2506.14864v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework", "abstract": "Multispectral object detection, which integrates information from multiple\nbands, can enhance detection accuracy and environmental adaptability, holding\ngreat application potential across various fields. Although existing methods\nhave made progress in cross-modal interaction, low-light conditions, and model\nlightweight, there are still challenges like the lack of a unified single-stage\nframework, difficulty in balancing performance and fusion strategy, and\nunreasonable modality weight allocation. To address these, based on the YOLOv11\nframework, we present YOLOv11-RGBT, a new comprehensive multimodal object\ndetection framework. We designed six multispectral fusion modes and\nsuccessfully applied them to models from YOLOv3 to YOLOv12 and RT-DETR. After\nreevaluating the importance of the two modalities, we proposed a P3 mid-fusion\nstrategy and multispectral controllable fine-tuning (MCF) strategy for\nmultispectral models. These improvements optimize feature fusion, reduce\nredundancy and mismatches, and boost overall model performance. Experiments\nshow our framework excels on three major open-source multispectral object\ndetection datasets, like LLVIP and FLIR. Particularly, the multispectral\ncontrollable fine-tuning strategy significantly enhanced model adaptability and\nrobustness. On the FLIR dataset, it consistently improved YOLOv11 models' mAP\nby 3.41%-5.65%, reaching a maximum of 47.61%, verifying the framework and\nstrategies' effectiveness. The code is available at:\nhttps://github.com/wandahangFY/YOLOv11-RGBT.", "published": "2025-06-17 16:37:00", "link": "http://arxiv.org/abs/2506.14696v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data analysis using discrete cubical homology", "abstract": "We present a new tool for data analysis: persistence discrete homology, which\nis well-suited to analyze filtrations of graphs. In particular, we provide a\nnovel way of representing high-dimensional data as a filtration of graphs using\npairwise correlations. We discuss several applications of these tools, e.g., in\nweather and financial data, comparing them to the standard methods used in the\nrespective fields.", "published": "2025-06-17 23:12:00", "link": "http://arxiv.org/abs/2506.15020v1", "categories": ["math.AT", "cs.LG", "math.CO", "62R40, 68T09, 05C90, 55U05"], "primary_category": "math.AT"}
{"title": "Private Continual Counting of Unbounded Streams", "abstract": "We study the problem of differentially private continual counting in the\nunbounded setting where the input size $n$ is not known in advance. Current\nstate-of-the-art algorithms based on optimal instantiations of the matrix\nmechanism cannot be directly applied here because their privacy guarantees only\nhold when key parameters are tuned to $n$. Using the common `doubling trick'\navoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve\nthis problem by introducing novel matrix factorizations based on logarithmic\nperturbations of the function $\\frac{1}{\\sqrt{1-z}}$ studied in prior works,\nwhich may be of independent interest. The resulting algorithm has smooth error,\nand for any $\\alpha > 0$ and $t\\leq n$ it is able to privately estimate the sum\nof the first $t$ data points with $O(\\log^{2+2\\alpha}(t))$ variance. It\nrequires $O(t)$ space and amortized $O(\\log t)$ time per round, compared to\n$O(\\log(n)\\log(t))$ variance, $O(n)$ space and $O(n \\log n)$ pre-processing\ntime for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA\n2023). Empirically, we find that our algorithm's performance is also comparable\nto theirs in absolute terms: our variance is less than $1.5\\times$ theirs for\n$t$ as large as $2^{24}$.", "published": "2025-06-17 23:09:53", "link": "http://arxiv.org/abs/2506.15018v1", "categories": ["cs.CR", "cs.DS", "cs.LG"], "primary_category": "cs.CR"}
{"title": "GCN-Driven Reinforcement Learning for Probabilistic Real-Time Guarantees in Industrial URLLC", "abstract": "Ensuring packet-level communication quality is vital for ultra-reliable,\nlow-latency communications (URLLC) in large-scale industrial wireless networks.\nWe enhance the Local Deadline Partition (LDP) algorithm by introducing a Graph\nConvolutional Network (GCN) integrated with a Deep Q-Network (DQN)\nreinforcement learning framework for improved interference coordination in\nmulti-cell, multi-channel networks. Unlike LDP's static priorities, our\napproach dynamically learns link priorities based on real-time traffic demand,\nnetwork topology, remaining transmission opportunities, and interference\npatterns. The GCN captures spatial dependencies, while the DQN enables adaptive\nscheduling decisions through reward-guided exploration. Simulation results show\nthat our GCN-DQN model achieves mean SINR improvements of 179.6\\%, 197.4\\%, and\n175.2\\% over LDP across three network configurations. Additionally, the GCN-DQN\nmodel demonstrates mean SINR improvements of 31.5\\%, 53.0\\%, and 84.7\\% over\nour previous CNN-based approach across the same configurations. These results\nunderscore the effectiveness of our GCN-DQN model in addressing complex URLLC\nrequirements with minimal overhead and superior network performance.", "published": "2025-06-17 22:48:22", "link": "http://arxiv.org/abs/2506.15011v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments", "abstract": "Speech enhancement, particularly denoising, is vital in improving the\nintelligibility and quality of speech signals for real-world applications,\nespecially in noisy environments. While prior research has introduced various\ndeep learning models for this purpose, many struggle to balance noise\nsuppression, perceptual quality, and speaker-specific feature preservation,\nleaving a critical research gap in their comparative performance evaluation.\nThis study benchmarks three state-of-the-art models Wave-U-Net, CMGAN, and\nU-Net, on diverse datasets such as SpEAR, VPQAD, and Clarkson datasets. These\nmodels were chosen due to their relevance in the literature and code\naccessibility. The evaluation reveals that U-Net achieves high noise\nsuppression with SNR improvements of +71.96% on SpEAR, +64.83% on VPQAD, and\n+364.2% on the Clarkson dataset. CMGAN outperforms in perceptual quality,\nattaining the highest PESQ scores of 4.04 on SpEAR and 1.46 on VPQAD, making it\nwell-suited for applications prioritizing natural and intelligible speech.\nWave-U-Net balances these attributes with improvements in speaker-specific\nfeature retention, evidenced by VeriSpeak score gains of +10.84% on SpEAR and\n+27.38% on VPQAD. This research indicates how advanced methods can optimize\ntrade-offs between noise suppression, perceptual quality, and speaker\nrecognition. The findings may contribute to advancing voice biometrics,\nforensic audio analysis, telecommunication, and speaker verification in\nchallenging acoustic conditions.", "published": "2025-06-17 22:12:40", "link": "http://arxiv.org/abs/2506.15000v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CNN-Enabled Scheduling for Probabilistic Real-Time Guarantees in Industrial URLLC", "abstract": "Ensuring packet-level communication quality is vital for ultra-reliable,\nlow-latency communications (URLLC) in large-scale industrial wireless networks.\nWe enhance the Local Deadline Partition (LDP) algorithm by introducing a\nCNN-based dynamic priority prediction mechanism for improved interference\ncoordination in multi-cell, multi-channel networks. Unlike LDP's static\npriorities, our approach uses a Convolutional Neural Network and graph coloring\nto adaptively assign link priorities based on real-time traffic, transmission\nopportunities, and network conditions. Assuming that first training phase is\nperformed offline, our approach introduced minimal overhead, while enabling\nmore efficient resource allocation, boosting network capacity, SINR, and\nschedulability. Simulation results show SINR gains of up to 113\\%, 94\\%, and\n49\\% over LDP across three network configurations, highlighting its\neffectiveness for complex URLLC scenarios.", "published": "2025-06-17 21:40:19", "link": "http://arxiv.org/abs/2506.14987v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Early Prediction of Multiple Sclerosis Disability Progression via Multimodal Foundation Model Benchmarks", "abstract": "Early multiple sclerosis (MS) disability progression prediction is\nchallenging due to disease heterogeneity. This work predicts 48- and 72-week\ndisability using sparse baseline clinical data and 12 weeks of daily digital\nFloodlight data from the CONSONANCE clinical trial. We employed\nstate-of-the-art tabular and time-series foundation models (FMs), a custom\nmultimodal attention-based transformer, and machine learning methods. Despite\nthe difficulty of early prediction (AUROC 0.63), integrating digital data via\nadvanced models improved performance over clinical data alone. A transformer\nmodel using unimodal embeddings from the Moment FM yielded the best result, but\nour multimodal transformer consistently outperformed its unimodal counterpart,\nconfirming the advantages of combining clinical with digital data. Our findings\ndemonstrate the promise of FMs and multimodal approaches to extract predictive\nsignals from complex and diverse clinical and digital life sciences data (e.g.,\nimaging, omics), enabling more accurate prognostics for MS and potentially\nother complex diseases.", "published": "2025-06-17 21:37:45", "link": "http://arxiv.org/abs/2506.14986v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Extending Spike-Timing Dependent Plasticity to Learning Synaptic Delays", "abstract": "Synaptic delays play a crucial role in biological neuronal networks, where\ntheir modulation has been observed in mammalian learning processes. In the\nrealm of neuromorphic computing, although spiking neural networks (SNNs) aim to\nemulate biology more closely than traditional artificial neural networks do,\nsynaptic delays are rarely incorporated into their simulation. We introduce a\nnovel learning rule for simultaneously learning synaptic connection strengths\nand delays, by extending spike-timing dependent plasticity (STDP), a Hebbian\nmethod commonly used for learning synaptic weights. We validate our approach by\nextending a widely-used SNN model for classification trained with unsupervised\nlearning. Then we demonstrate the effectiveness of our new method by comparing\nit against another existing methods for co-learning synaptic weights and delays\nas well as against STDP without synaptic delays. Results demonstrate that our\nproposed method consistently achieves superior performance across a variety of\ntest scenarios. Furthermore, our experimental results yield insight into the\ninterplay between synaptic efficacy and delay.", "published": "2025-06-17 21:24:58", "link": "http://arxiv.org/abs/2506.14984v1", "categories": ["cs.NE", "cs.LG", "I.2.6"], "primary_category": "cs.NE"}
{"title": "ODD: Overlap-aware Estimation of Model Performance under Distribution Shift", "abstract": "Reliable and accurate estimation of the error of an ML model in unseen test\ndomains is an important problem for safe intelligent systems. Prior work uses\ndisagreement discrepancy (DIS^2) to derive practical error bounds under\ndistribution shifts. It optimizes for a maximally disagreeing classifier on the\ntarget domain to bound the error of a given source classifier. Although this\napproach offers a reliable and competitively accurate estimate of the target\nerror, we identify a problem in this approach which causes the disagreement\ndiscrepancy objective to compete in the overlapping region between source and\ntarget domains. With an intuitive assumption that the target disagreement\nshould be no more than the source disagreement in the overlapping region due to\nhigh enough support, we devise Overlap-aware Disagreement Discrepancy (ODD).\nMaximizing ODD only requires disagreement in the non-overlapping target domain,\nremoving the competition. Our ODD-based bound uses domain-classifiers to\nestimate domain-overlap and better predicts target performance than DIS^2. We\nconduct experiments on a wide array of benchmarks to show that our method\nimproves the overall performance-estimation error while remaining valid and\nreliable. Our code and results are available on GitHub.", "published": "2025-06-17 21:05:42", "link": "http://arxiv.org/abs/2506.14978v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimal alignment of Lorentz orientation and generalization to matrix Lie groups", "abstract": "There exist elegant methods of aligning point clouds in $\\mathbb R^3$.\nUnfortunately, these methods rely on the positive definite property of the\nEuclidean metric, and do not easily extend to the indefinite Minkowski metric.\nIn this paper, we propose two solutions to the following problem: given\ninertial reference frames $A$ and $B$, and given (possibly noisy) measurements\nof a set of 4-vectors $\\{v_i\\}$ made in those reference frames with components\n$\\{v_{A,i}\\}$ and $\\{v_{B,i}\\}$, find the optimal Lorentz transformation\n$\\Lambda$ such that $\\Lambda v_{A,i}=v_{B,i}$. The method we outline is\nconceptually simple and easily extends to alignment problems in other matrix\nLie groups.", "published": "2025-06-17 22:00:36", "link": "http://arxiv.org/abs/2506.14994v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "math.OC", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Interpolation-based reproducing kernel particle method", "abstract": "Meshfree methods, including the reproducing kernel particle method (RKPM),\nhave been widely used within the computational mechanics community to model\nphysical phenomena in materials undergoing large deformations or extreme\ntopology changes. RKPM shape functions and their derivatives cannot be\naccurately integrated with the Gauss-quadrature methods widely employed for the\nfinite element method (FEM) and typically require sophisticated nodal\nintegration techniques, preventing them from easily being implemented in\nexisting FEM software. Interpolation-based methods have been developed to\naddress similar problems with isogeometric and immersed boundary methods,\nallowing these techniques to be implemented within open-source finite element\nsoftware. With interpolation-based methods, background basis functions are\nrepresented as linear combinations of Lagrange polynomial foreground basis\nfunctions defined upon a boundary-conforming foreground mesh. This work extends\nthe applications of interpolation-based methods to implement RKPM within\nopen-source finite element software. Interpolation-based RKPM is applied to\nseveral PDEs, and error convergence rates are equivalent to classic RKPM\nintegrated using high-order Gauss-quadrature schemes. The interpolation-based\nmethod is able to exploit the continuity of the RKPM basis to solve\nhigher-order PDEs, demonstrated through the biharmonic problem. The method is\nextended to multi-material problems through Heaviside enrichment schemes, using\nlocal foreground refinement to reduce geometric integration error and achieve\nhigh-order accuracy. The computational cost of interpolation-based RKPM is\nsimilar to the smoothed gradient nodal integration schemes, offering\nsignificant savings over Gauss-quadrature-based meshfree methods while enabling\neasy implementation within existing finite element software.", "published": "2025-06-17 18:50:21", "link": "http://arxiv.org/abs/2506.14916v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Observation on Lloyd's k-Means Algorithm in High Dimensions", "abstract": "Clustering and estimating cluster means are core problems in statistics and\nmachine learning, with k-means and Expectation Maximization (EM) being two\nwidely used algorithms. In this work, we provide a theoretical explanation for\nthe failure of k-means in high-dimensional settings with high noise and limited\nsample sizes, using a simple Gaussian Mixture Model (GMM). We identify regimes\nwhere, with high probability, almost every partition of the data becomes a\nfixed point of the k-means algorithm. This study is motivated by challenges in\nthe analysis of more complex cases, such as masked GMMs, and those arising from\napplications in Cryo-Electron Microscopy.", "published": "2025-06-17 20:06:41", "link": "http://arxiv.org/abs/2506.14952v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Double Machine Learning for Conditional Moment Restrictions: IV regression, Proximal Causal Learning and Beyond", "abstract": "Solving conditional moment restrictions (CMRs) is a key problem considered in\nstatistics, causal inference, and econometrics, where the aim is to solve for a\nfunction of interest that satisfies some conditional moment equalities.\nSpecifically, many techniques for causal inference, such as instrumental\nvariable (IV) regression and proximal causal learning (PCL), are CMR problems.\nMost CMR estimators use a two-stage approach, where the first-stage estimation\nis directly plugged into the second stage to estimate the function of interest.\nHowever, naively plugging in the first-stage estimator can cause heavy bias in\nthe second stage. This is particularly the case for recently proposed CMR\nestimators that use deep neural network (DNN) estimators for both stages, where\nregularisation and overfitting bias is present. We propose DML-CMR, a two-stage\nCMR estimator that provides an unbiased estimate with fast convergence rate\nguarantees. We derive a novel learning objective to reduce bias and develop the\nDML-CMR algorithm following the double/debiased machine learning (DML)\nframework. We show that our DML-CMR estimator can achieve the minimax optimal\nconvergence rate of $O(N^{-1/2})$ under parameterisation and mild regularity\nconditions, where $N$ is the sample size. We apply DML-CMR to a range of\nproblems using DNN estimators, including IV regression and proximal causal\nlearning on real-world datasets, demonstrating state-of-the-art performance\nagainst existing CMR estimators and algorithms tailored to those problems.", "published": "2025-06-17 20:00:34", "link": "http://arxiv.org/abs/2506.14950v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Digital twin for virtual sensing of ferry quays via a Gaussian Process Latent Force Model", "abstract": "Ferry quays experience rapid deterioration due to their exposure to harsh\nmaritime environments and ferry impacts. Vibration-based structural health\nmonitoring offers a valuable approach to assessing structural integrity and\nunderstanding the structural implications of these impacts. However, practical\nlimitations often restrict sensor placement at critical locations.\nConsequently, virtual sensing techniques become essential for establishing a\nDigital Twin and estimating the structural response. This study investigates\nthe application of the Gaussian Process Latent Force Model (GPLFM) for virtual\nsensing on the Magerholm ferry quay, combining in-operation experimental data\ncollected during a ferry impact with a detailed physics-based model. The\nproposed Physics-Encoded Machine Learning model integrates a reduced-order\nstructural model with a data-driven GPLFM representing the unknown impact\nforces via their modal contributions. Significant challenges are addressed for\nthe development of the Digital Twin of the ferry quay, including unknown impact\ncharacteristics (location, direction, intensity), time-varying boundary\nconditions, and sparse sensor configurations. Results show that the GPLFM\nprovides accurate acceleration response estimates at most locations, even under\nsimplifying modeling assumptions such as linear time-invariant behavior during\nthe impact phase. Lower accuracy was observed at locations in the impact zone.\nA numerical study was conducted to explore an optimal real-world sensor\nplacement strategy using a Backward Sequential Sensor Placement approach.\nSensitivity analyses were conducted to examine the influence of sensor types,\nsampling frequencies, and incorrectly assumed damping ratios. The results\nsuggest that the GP latent forces can help accommodate modeling and measurement\nuncertainties, maintaining acceptable estimation accuracy across scenarios.", "published": "2025-06-17 19:14:11", "link": "http://arxiv.org/abs/2506.14925v1", "categories": ["stat.AP", "cs.LG", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning", "abstract": "The pre-training of large language models (LLMs) relies on massive text\ndatasets sourced from diverse and difficult-to-curate origins. Although\nmembership inference attacks and hidden canaries have been explored to trace\ndata usage, such methods rely on memorization of training data, which LM\nproviders try to limit. In this work, we demonstrate that indirect data\npoisoning (where the targeted behavior is absent from training data) is not\nonly feasible but also allow to effectively protect a dataset and trace its\nuse. Using gradient-based optimization prompt-tuning, we make a model learn\narbitrary secret sequences: secret responses to secret prompts that are absent\nfrom the training corpus. We validate our approach on language models\npre-trained from scratch and show that less than 0.005% of poisoned tokens are\nsufficient to covertly make a LM learn a secret and detect it with extremely\nhigh confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.\nCrucially, this occurs without performance degradation (on LM benchmarks) and\ndespite secrets never appearing in the training set.", "published": "2025-06-17 18:46:45", "link": "http://arxiv.org/abs/2506.14913v1", "categories": ["cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Optimal Convergence Rates of Deep Neural Network Classifiers", "abstract": "In this paper, we study the binary classification problem on $[0,1]^d$ under\nthe Tsybakov noise condition (with exponent $s \\in [0,\\infty]$) and the\ncompositional assumption. This assumption requires the conditional class\nprobability function of the data distribution to be the composition of $q+1$\nvector-valued multivariate functions, where each component function is either a\nmaximum value function or a H\\\"{o}lder-$\\beta$ smooth function that depends\nonly on $d_*$ of its input variables. Notably, $d_*$ can be significantly\nsmaller than the input dimension $d$. We prove that, under these conditions,\nthe optimal convergence rate for the excess 0-1 risk of classifiers is $$\n\\left( \\frac{1}{n}\n\\right)^{\\frac{\\beta\\cdot(1\\wedge\\beta)^q}{{\\frac{d_*}{s+1}+(1+\\frac{1}{s+1})\\cdot\\beta\\cdot(1\\wedge\\beta)^q}}}\\;\\;\\;,\n$$ which is independent of the input dimension $d$. Additionally, we\ndemonstrate that ReLU deep neural networks (DNNs) trained with hinge loss can\nachieve this optimal convergence rate up to a logarithmic factor. This result\nprovides theoretical justification for the excellent performance of ReLU DNNs\nin practical classification tasks, particularly in high-dimensional settings.\nThe technique used to establish these results extends the oracle inequality\npresented in our previous work. The generalized approach is of independent\ninterest.", "published": "2025-06-17 18:13:09", "link": "http://arxiv.org/abs/2506.14899v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "abstract": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks.", "published": "2025-06-17 16:07:36", "link": "http://arxiv.org/abs/2506.14673v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Beyond Universality: Cultural Diversity in Music and Its Implications for Sound Design and Sonification", "abstract": "The Audio Mostly (AM) conference has long been a platform for exploring the\nintersection of sound, technology, and culture. Despite growing interest in\nsonic cultures, discussions on the role of cultural diversity in sound design\nand sonification remain limited. This paper investigates the implicit biases\nand gaps within the discourse on music and sound aesthetics, challenging the\nnotion of music as a 'universal language'. Through a historical and\ncross-cultural analysis of musicology and ethnomusicology, the profound\ninfluence of cultural context on auditory perception and aesthetic appraisal is\nhighlighted. By drawing parallels between historical music practices and\ncontemporary sound design, the paper advocates for a more inclusive approach\nthat recognizes the diversity of sonic traditions. Using music as a case study,\nwe underscore broader implications for sound design and sonification,\nemphasizing the need to integrate cultural perspectives into auditory design\npractices. A reevaluation of existing frameworks in sound design and\nsonification is proposed, emphasizing the necessity of culturally informed\npractices that resonate with global audiences. Ultimately, embracing cultural\ndiversity in sound design is suggested to lead to richer, more meaningful\nauditory experiences and to foster greater inclusivity within the field.", "published": "2025-06-17 18:00:02", "link": "http://arxiv.org/abs/2506.14877v1", "categories": ["physics.soc-ph", "cs.SD", "eess.AS"], "primary_category": "physics.soc-ph"}
{"title": "Secure Time-Modulated Intelligent Reflecting Surface via Generative Flow Networks", "abstract": "We propose a novel directional modulation (DM) design for OFDM transmitters\naided by a time-modulated intelligent reflecting surface (TM-IRS). The TM-IRS\nis configured to preserve the integrity of transmitted signals toward multiple\nlegitimate users while scrambling the signal in all other directions. Existing\nTM-IRS design methods typically target a single user direction and follow\npredefined rule-based procedures, making them unsuitable for multi-user\nscenarios. Here, we propose a generative AI-based approach to design good sets\nof TM-IRS parameters out of a set of all possible quantized ranges of\nparameters. The design objective is to maximize the sum rate across the\nauthorized directions. We model the TM-IRS parameter selection as a\ndeterministic Markov decision process (MDP), where each terminal state\ncorresponds to a specific configuration of TM-IRS parameters. GFlowNets are\nemployed to learn a stochastic policy that samples TM-IRS parameter sets with\nprobability proportional to their associated sum rate reward. Experimental\nresults demonstrate that the proposed method effectively enhances the security\nof the TM-IRS-aided OFDM systems with multi-users. Also, despite the vast size\nof the TM-IRS configuration space, the GFlowNet is able to converge after\ntraining on fewer than 0.000001% of all possible configurations, demonstrating\nremarkable efficiency compared to exhaustive combinatorial search.\nImplementation code is available at https://github.com/ZhihaoTao/GFN4TM-RIS to\nfacilitate reproducibility.", "published": "2025-06-17 21:56:14", "link": "http://arxiv.org/abs/2506.14992v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Metasurfaces-Integrated Doubly-Dispersive MIMO: Channel Modeling and Optimization", "abstract": "The doubly-dispersive (DD) channel structure has played a pivotal role in\nwireless communications, particularly in high-mobility scenarios and integrated\nsensing and communications (ISAC), due to its ability to capture the key fading\neffects experienced by a transmitted signal as it propagates through a dynamic\nmedium. However, extending the DD framework to multiple-input multiple-output\n(MIMO) systems, especially in environments artificially enhanced by\nreconfigurable intelligent surfaces (RISs) and stacked intelligent metasurfaces\n(SIM), remains a challenging open problem. In this chapter, a novel\nmetasurfaces-parametrized DD (MPDD) channel model that integrates an arbitrary\nnumber of RISs, while also incorporating SIM at both the transmitter and\nreceiver is introduced. Next, the application of this model to some key\nwaveforms optimized for DD environments -- namely orthogonal frequency division\nmultiplexing (OFDM), orthogonal time frequency space (OTFS), and affine\nfrequency division multiplexing (AFDM) -- is discussed. Finally, the\nprogrammability of the proposed model is highlighted through an illustrative\napplication, demonstrating its potential for enhancing waveform performance in\nSIM-assisted wireless systems.", "published": "2025-06-17 21:33:05", "link": "http://arxiv.org/abs/2506.14985v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Demonstrating Superresolution in Radar Range Estimation Using a Denoising Autoencoder", "abstract": "We apply machine learning methods to demonstrate range superresolution in\nremote sensing radar detection. Specifically, we implement a denoising\nautoencoder to estimate the distance between two equal intensity scatterers in\nthe subwavelength regime. The machine learning models are trained on waveforms\nsubject to a bandlimit constraint such that ranges much smaller than the\ninverse bandlimit are optimized in their precision. The autoencoder achieves\neffective dimensionality reduction, with the bottleneck layer exhibiting a\nstrong and consistent correlation with the true scatterer separation. We\nconfirm reproducibility across different training sessions and network\ninitializations by analyzing the scaled encoder outputs and their robustness to\nnoise. We investigate the behavior of the bottleneck layer for the following\ntypes of pulses: a traditional sinc pulse, a bandlimited triangle-type pulse,\nand a theoretically near-optimal pulse created from a spherical Bessel function\nbasis. The Bessel signal performs best, followed by the triangle wave, with the\nsinc signal performing worst, highlighting the crucial role of signal design in\nthe success of machine-learning-based range resolution.", "published": "2025-06-17 18:25:44", "link": "http://arxiv.org/abs/2506.14906v1", "categories": ["eess.SP", "physics.optics"], "primary_category": "eess.SP"}
{"title": "Refining music sample identification with a self-supervised graph neural network", "abstract": "Automatic sample identification (ASID), the detection and identification of\nportions of audio recordings that have been reused in new musical works, is an\nessential but challenging task in the field of audio query-based retrieval.\nWhile a related task, audio fingerprinting, has made significant progress in\naccurately retrieving musical content under \"real world\" (noisy, reverberant)\nconditions, ASID systems struggle to identify samples that have undergone\nmusical modifications. Thus, a system robust to common music production\ntransformations such as time-stretching, pitch-shifting, effects processing,\nand underlying or overlaying music is an important open challenge.\n  In this work, we propose a lightweight and scalable encoding architecture\nemploying a Graph Neural Network within a contrastive learning framework. Our\nmodel uses only 9% of the trainable parameters compared to the current\nstate-of-the-art system while achieving comparable performance, reaching a mean\naverage precision (mAP) of 44.2%.\n  To enhance retrieval quality, we introduce a two-stage approach consisting of\nan initial coarse similarity search for candidate selection, followed by a\ncross-attention classifier that rejects irrelevant matches and refines the\nranking of retrieved candidates - an essential capability absent in prior\nmodels. In addition, because queries in real-world applications are often short\nin duration, we benchmark our system for short queries using new fine-grained\nannotations for the Sample100 dataset, which we publish as part of this work.", "published": "2025-06-17 16:19:21", "link": "http://arxiv.org/abs/2506.14684v2", "categories": ["cs.SD", "cs.AI", "cs.IR", "H.5.5; I.2.6"], "primary_category": "cs.SD"}
{"title": "Optimal alignment of Lorentz orientation and generalization to matrix Lie groups", "abstract": "There exist elegant methods of aligning point clouds in $\\mathbb R^3$.\nUnfortunately, these methods rely on the positive definite property of the\nEuclidean metric, and do not easily extend to the indefinite Minkowski metric.\nIn this paper, we propose two solutions to the following problem: given\ninertial reference frames $A$ and $B$, and given (possibly noisy) measurements\nof a set of 4-vectors $\\{v_i\\}$ made in those reference frames with components\n$\\{v_{A,i}\\}$ and $\\{v_{B,i}\\}$, find the optimal Lorentz transformation\n$\\Lambda$ such that $\\Lambda v_{A,i}=v_{B,i}$. The method we outline is\nconceptually simple and easily extends to alignment problems in other matrix\nLie groups.", "published": "2025-06-17 22:00:36", "link": "http://arxiv.org/abs/2506.14994v2", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "math.OC", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Sampling conditioned diffusions via Pathspace Projected Monte Carlo", "abstract": "We present an algorithm to sample stochastic differential equations\nconditioned on rather general constraints, including integral constraints,\nendpoint constraints, and stochastic integral constraints. The algorithm is a\npathspace Metropolis-adjusted manifold sampling scheme, which samples\nstochastic paths on the submanifold of realizations that adhere to the\nconditioning constraint. We demonstrate the effectiveness of the algorithm by\nsampling a dynamical condensation phase transition, conditioning a random walk\non a fixed Levy stochastic area, conditioning a stochastic nonlinear wave\nequation on high amplitude waves, and sampling a stochastic partial\ndifferential equation model of turbulent pipe flow conditioned on\nrelaminarization events.", "published": "2025-06-17 23:01:24", "link": "http://arxiv.org/abs/2506.15743v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "abstract": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks.", "published": "2025-06-17 16:07:36", "link": "http://arxiv.org/abs/2506.14673v3", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Uncertainty in AI-driven Monte Carlo simulations", "abstract": "In the study of complex systems, evaluating physical observables often\nrequires sampling representative configurations via Monte Carlo techniques.\nThese methods rely on repeated evaluations of the system's energy and force\nfields, which can become computationally expensive, particularly in the\npresence of long-range interactions. To accelerate these simulations, deep\nlearning models are increasingly employed as surrogate functions to approximate\nthe energy landscape or force fields. However, such models introduce epistemic\nuncertainty in their predictions, which may propagate through the sampling\nprocess and affect the system's macroscopic behavior. In this work, we present\nthe Penalty Ensemble Method (PEM) to quantify epistemic uncertainty and\nmitigate its impact on Monte Carlo sampling. Our approach introduces an\nuncertainty-aware modification of the Metropolis acceptance rule, which\nincreases the rejection probability in regions of high uncertainty, thereby\nenhancing the reliability of the simulation outcomes.", "published": "2025-06-17 14:58:39", "link": "http://arxiv.org/abs/2506.14594v1", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "stat.ML"], "primary_category": "cond-mat.dis-nn"}
{"title": "Widely Linear Augmented Extreme Learning Machine Based Impairments Compensation for Satellite Communications", "abstract": "Satellite communications are crucial for the evolution beyond\nfifth-generation networks. However, the dynamic nature of satellite channels\nand their inherent impairments present significant challenges. In this paper, a\nnovel post-compensation scheme that combines the complex-valued extreme\nlearning machine with augmented hidden layer (CELMAH) architecture and widely\nlinear processing (WLP) is developed to address these issues by exploiting\nsignal impropriety in satellite communications. Although CELMAH shares\nstructural similarities with WLP, it employs a different core algorithm and\ndoes not fully exploit the signal impropriety. By incorporating WLP principles,\nwe derive a tailored formulation suited to the network structure and propose\nthe CELM augmented by widely linear least squares (CELM-WLLS) for\npost-distortion. The proposed approach offers enhanced communication robustness\nand is highly effective for satellite communication scenarios characterized by\ndynamic channel conditions and non-linear impairments. CELM-WLLS is designed to\nimprove signal recovery performance and outperform traditional methods such as\nleast square (LS) and minimum mean square error (MMSE). Compared to CELMAH,\nCELM-WLLS demonstrates approximately 0.8 dB gain in BER performance, and also\nachieves a two-thirds reduction in computational complexity, making it a more\nefficient solution.", "published": "2025-06-17 14:12:55", "link": "http://arxiv.org/abs/2506.14557v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Double Machine Learning for Conditional Moment Restrictions: IV Regression, Proximal Causal Learning and Beyond", "abstract": "Solving conditional moment restrictions (CMRs) is a key problem considered in\nstatistics, causal inference, and econometrics, where the aim is to solve for a\nfunction of interest that satisfies some conditional moment equalities.\nSpecifically, many techniques for causal inference, such as instrumental\nvariable (IV) regression and proximal causal learning (PCL), are CMR problems.\nMost CMR estimators use a two-stage approach, where the first-stage estimation\nis directly plugged into the second stage to estimate the function of interest.\nHowever, naively plugging in the first-stage estimator can cause heavy bias in\nthe second stage. This is particularly the case for recently proposed CMR\nestimators that use deep neural network (DNN) estimators for both stages, where\nregularisation and overfitting bias is present. We propose DML-CMR, a two-stage\nCMR estimator that provides an unbiased estimate with fast convergence rate\nguarantees. We derive a novel learning objective to reduce bias and develop the\nDML-CMR algorithm following the double/debiased machine learning (DML)\nframework. We show that our DML-CMR estimator can achieve the minimax optimal\nconvergence rate of $O(N^{-1/2})$ under parameterisation and mild regularity\nconditions, where $N$ is the sample size. We apply DML-CMR to a range of\nproblems using DNN estimators, including IV regression and proximal causal\nlearning on real-world datasets, demonstrating state-of-the-art performance\nagainst existing CMR estimators and algorithms tailored to those problems.", "published": "2025-06-17 20:00:34", "link": "http://arxiv.org/abs/2506.14950v2", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling", "abstract": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music\nand song. To the best of our knowledge, there are no open-source high-quality\ndataset representing popular and well-known songs for generative music modeling\ntasks such as text-music, music-captioning, singing-voice synthesis, melody\nreconstruction and cross-model retrieval. Past contributions focused on\nisolated and constrained factors whose core perspective was to create synthetic\nor re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily\nlarge-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another\nfocus for the community. Unfortunately, adoption of these datasets has been\nbelow substantial in the generative music community as these datasets fail to\nreflect real-world music and its flavour. Our dataset changes this narrative\nand provides a dataset that is constructed using actual popular music and\nworld-renowned artists.", "published": "2025-06-17 08:08:08", "link": "http://arxiv.org/abs/2506.14293v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
