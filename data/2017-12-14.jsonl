{"title": "Passing the Brazilian OAB Exam: data preparation and some experiments", "abstract": "In Brazil, all legal professionals must demonstrate their knowledge of the\nlaw and its application by passing the OAB exams, the national bar exams. The\nOAB exams therefore provide an excellent benchmark for the performance of legal\ninformation systems since passing the exam would arguably signal that the\nsystem has acquired capacity of legal reasoning comparable to that of a human\nlawyer. This article describes the construction of a new data set and some\npreliminary experiments on it, treating the problem of finding the\njustification for the answers to questions. The results provide a baseline\nperformance measure against which to evaluate future improvements. We discuss\nthe reasons to the poor performance and propose next steps.", "published": "2017-12-14 08:40:10", "link": "http://arxiv.org/abs/1712.05128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monotonic Chunkwise Attention", "abstract": "Sequence-to-sequence models with soft attention have been successfully\napplied to a wide variety of problems, but their decoding process incurs a\nquadratic time and space cost and is inapplicable to real-time sequence\ntransduction. To address these issues, we propose Monotonic Chunkwise Attention\n(MoChA), which adaptively splits the input sequence into small chunks over\nwhich soft attention is computed. We show that models utilizing MoChA can be\ntrained efficiently with standard backpropagation while allowing online and\nlinear-time decoding at test time. When applied to online speech recognition,\nwe obtain state-of-the-art results and match the performance of a model using\nan offline soft attention mechanism. In document summarization experiments\nwhere we do not expect monotonic alignments, we show significantly improved\nperformance compared to a baseline monotonic attention-based model.", "published": "2017-12-14 18:29:42", "link": "http://arxiv.org/abs/1712.05382v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Rasa: Open Source Language Understanding and Dialogue Management", "abstract": "We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source\npython libraries for building conversational software. Their purpose is to make\nmachine-learning based dialogue management and language understanding\naccessible to non-specialist software developers. In terms of design\nphilosophy, we aim for ease of use, and bootstrapping from minimal (or no)\ninitial training data. Both packages are extensively documented and ship with a\ncomprehensive suite of tests. The code is available at\nhttps://github.com/RasaHQ/", "published": "2017-12-14 11:37:18", "link": "http://arxiv.org/abs/1712.05181v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relation Extraction : A Survey", "abstract": "With the advent of the Internet, large amount of digital text is generated\neveryday in the form of news articles, research publications, blogs, question\nanswering forums and social media. It is important to develop techniques for\nextracting information automatically from these documents, as lot of important\ninformation is hidden within them. This extracted information can be used to\nimprove access and management of knowledge hidden in large text corpora.\nSeveral applications such as Question Answering, Information Retrieval would\nbenefit from this information. Entities like persons and organizations, form\nthe most basic unit of the information. Occurrences of entities in a sentence\nare often linked through well-defined relations; e.g., occurrences of person\nand organization in a sentence may be linked through relations such as employed\nat. The task of Relation Extraction (RE) is to identify such relations\nautomatically. In this paper, we survey several important supervised,\nsemi-supervised and unsupervised RE techniques. We also cover the paradigms of\nOpen Information Extraction (OIE) and Distant Supervision. Finally, we describe\nsome of the recent trends in the RE techniques and possible future research\ndirections. This survey would be useful for three kinds of readers - i)\nNewcomers in the field who want to quickly learn about RE; ii) Researchers who\nwant to know how the various RE techniques evolved over time and what are\npossible future research directions and iii) Practitioners who just need to\nknow which RE technique works best in various settings.", "published": "2017-12-14 12:04:10", "link": "http://arxiv.org/abs/1712.05191v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning to Attend via Word-Aspect Associative Fusion for Aspect-based\n  Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a\ngiven document with respect to a given aspect entity. While neural network\narchitectures have been successful in predicting the overall polarity of\nsentences, aspect-specific sentiment analysis still remains as an open problem.\nIn this paper, we propose a novel method for integrating aspect information\ninto the neural model. More specifically, we incorporate aspect information\ninto the neural model by modeling word-aspect relationships. Our novel model,\n\\textit{Aspect Fusion LSTM} (AF-LSTM) learns to attend based on associative\nrelationships between sentence words and aspect which allows our model to\nadaptively focus on the correct words given an aspect term. This ameliorates\nthe flaws of other state-of-the-art models that utilize naive concatenations to\nmodel word-aspect similarity. Instead, our model adopts circular convolution\nand circular correlation to model the similarity between aspect and words and\nelegantly incorporates this within a differentiable neural attention framework.\nFinally, our model is end-to-end differentiable and highly related to\nconvolution-correlation (holographic like) memories. Our proposed neural model\nachieves state-of-the-art performance on benchmark datasets, outperforming\nATAE-LSTM by $4\\%-5\\%$ on average across multiple datasets.", "published": "2017-12-14 12:46:44", "link": "http://arxiv.org/abs/1712.05403v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards Deep Modeling of Music Semantics using EEG Regularizers", "abstract": "Modeling of music audio semantics has been previously tackled through\nlearning of mappings from audio data to high-level tags or latent unsupervised\nspaces. The resulting semantic spaces are theoretically limited, either because\nthe chosen high-level tags do not cover all of music semantics or because audio\ndata itself is not enough to determine music semantics. In this paper, we\npropose a generic framework for semantics modeling that focuses on the\nperception of the listener, through EEG data, in addition to audio data. We\nimplement this framework using a novel end-to-end 2-view Neural Network (NN)\narchitecture and a Deep Canonical Correlation Analysis (DCCA) loss function\nthat forces the semantic embedding spaces of both views to be maximally\ncorrelated. We also detail how the EEG dataset was collected and use it to\ntrain our proposed model. We evaluate the learned semantic space in a transfer\nlearning context, by using it as an audio feature extractor in an independent\ndataset and proxy task: music audio-lyrics cross-modal retrieval. We show that\nour embedding model outperforms Spotify features and performs comparably to a\nstate-of-the-art embedding model that was trained on 700 times more data. We\nfurther discuss improvements to the model that are likely to improve its\nperformance.", "published": "2017-12-14 12:27:11", "link": "http://arxiv.org/abs/1712.05197v2", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS", "q-bio.NC", "H.5.5; H.5.1"], "primary_category": "cs.IR"}
