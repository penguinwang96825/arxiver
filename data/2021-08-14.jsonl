{"title": "Findings of the LoResMT 2021 Shared Task on COVID and Sign Language for\n  Low-resource Languages", "abstract": "We present the findings of the LoResMT 2021 shared task which focuses on\nmachine translation (MT) of COVID-19 data for both low-resource spoken and sign\nlanguages. The organization of this task was conducted as part of the fourth\nworkshop on technologies for machine translation of low resource languages\n(LoResMT). Parallel corpora is presented and publicly available which includes\nthe following directions: English$\\leftrightarrow$Irish,\nEnglish$\\leftrightarrow$Marathi, and Taiwanese Sign\nlanguage$\\leftrightarrow$Traditional Chinese. Training data consists of 8112,\n20933 and 128608 segments, respectively. There are additional monolingual data\nsets for Marathi and English that consist of 21901 segments. The results\npresented here are based on entries from a total of eight teams. Three teams\nsubmitted systems for English$\\leftrightarrow$Irish while five teams submitted\nsystems for English$\\leftrightarrow$Marathi. Unfortunately, there were no\nsystems submissions for the Taiwanese Sign language$\\leftrightarrow$Traditional\nChinese task. Maximum system performance was computed using BLEU and follow as\n36.0 for English--Irish, 34.6 for Irish--English, 24.2 for English--Marathi,\nand 31.3 for Marathi--English.", "published": "2021-08-14 17:52:13", "link": "http://arxiv.org/abs/2108.06598v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The SelectGen Challenge: Finding the Best Training Samples for Few-Shot\n  Neural Text Generation", "abstract": "We propose a shared task on training instance selection for few-shot neural\ntext generation. Large-scale pretrained language models have led to dramatic\nimprovements in few-shot text generation. Nonetheless, almost all previous work\nsimply applies random sampling to select the few-shot training instances.\nLittle to no attention has been paid to the selection strategies and how they\nwould affect model performance. The study of the selection strategy can help us\nto (1) make the most use of our annotation budget in downstream tasks and (2)\nbetter benchmark few-shot text generative models. We welcome submissions that\npresent their selection strategies and the effects on the generation quality.", "published": "2021-08-14 21:20:35", "link": "http://arxiv.org/abs/2108.06614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Entity Extraction Method Based on Machine Reading Comprehension", "abstract": "Entity extraction is a key technology for obtaining information from massive\ntexts in natural language processing. The further interaction between them does\nnot meet the standards of human reading comprehension, thus limiting the\nunderstanding of the model, and also the omission or misjudgment of the answer\n(ie the target entity) due to the reasoning question. An effective MRC-based\nentity extraction model-MRC-I2DP, which uses the proposed gated\nattention-attracting mechanism to adjust the restoration of each part of the\ntext pair, creating problems and thinking for multi-level interactive attention\ncalculations to increase the target entity It also uses the proposed 2D\nprobability coding module, TALU function and mask mechanism to strengthen the\ndetection of all possible targets of the target, thereby improving the\nprobability and accuracy of prediction. Experiments have proved that MRC-I2DP\nrepresents an overall state-of-the-art model in 7 from the scientific and\npublic domains, achieving a performance improvement of up to compared to the\nmodel model in F1.", "published": "2021-08-14 02:11:41", "link": "http://arxiv.org/abs/2108.06444v2", "categories": ["cs.CL", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Investigating Bias In Automatic Toxic Comment Detection: An Empirical\n  Study", "abstract": "With surge in online platforms, there has been an upsurge in the user\nengagement on these platforms via comments and reactions. A large portion of\nsuch textual comments are abusive, rude and offensive to the audience. With\nmachine learning systems in-place to check such comments coming onto platform,\nbiases present in the training data gets passed onto the classifier leading to\ndiscrimination against a set of classes, religion and gender. In this work, we\nevaluate different classifiers and feature to estimate the bias in these\nclassifiers along with their performance on downstream task of toxicity\nclassification. Results show that improvement in performance of automatic toxic\ncomment detection models is positively correlated to mitigating biases in these\nmodels. In our work, LSTM with attention mechanism proved to be a better\nmodelling strategy than a CNN model. Further analysis shows that fasttext\nembeddings is marginally preferable than glove embeddings on training models\nfor toxicity comment detection. Deeper analysis reveals the findings that such\nautomatic models are particularly biased to specific identity groups even\nthough the model has a high AUC score. Finally, in effort to mitigate bias in\ntoxicity detection models, a multi-task setup trained with auxiliary task of\ntoxicity sub-types proved to be useful leading to upto 0.26% (6% relative) gain\nin AUC scores.", "published": "2021-08-14 08:24:13", "link": "http://arxiv.org/abs/2108.06487v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Few-Sample Named Entity Recognition for Security Vulnerability Reports\n  by Fine-Tuning Pre-Trained Language Models", "abstract": "Public security vulnerability reports (e.g., CVE reports) play an important\nrole in the maintenance of computer and network systems. Security companies and\nadministrators rely on information from these reports to prioritize tasks on\ndeveloping and deploying patches to their customers. Since these reports are\nunstructured texts, automatic information extraction (IE) can help scale up the\nprocessing by converting the unstructured reports to structured forms, e.g.,\nsoftware names and versions and vulnerability types. Existing works on\nautomated IE for security vulnerability reports often rely on a large number of\nlabeled training samples. However, creating massive labeled training set is\nboth expensive and time consuming. In this work, for the first time, we propose\nto investigate this problem where only a small number of labeled training\nsamples are available. In particular, we investigate the performance of\nfine-tuning several state-of-the-art pre-trained language models on our small\ntraining dataset. The results show that with pre-trained language models and\ncarefully tuned hyperparameters, we have reached or slightly outperformed the\nstate-of-the-art system on this task. Consistent with previous two-step process\nof first fine-tuning on main category and then transfer learning to others as\nin [7], if otherwise following our proposed approach, the number of required\nlabeled samples substantially decrease in both stages: 90% reduction in\nfine-tuning from 5758 to 576,and 88.8% reduction in transfer learning with 64\nlabeled samples per category. Our experiments thus demonstrate the\neffectiveness of few-sample learning on NER for security vulnerability report.\nThis result opens up multiple research opportunities for few-sample learning\nfor security vulnerability reports, which is discussed in the paper. Code:\nhttps://github.com/guanqun-yang/FewVulnerability.", "published": "2021-08-14 17:08:03", "link": "http://arxiv.org/abs/2108.06590v1", "categories": ["cs.CL", "cs.CR", "cs.SE"], "primary_category": "cs.CL"}
