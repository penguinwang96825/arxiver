{"title": "Semantic categories of artifacts and animals reflect efficient coding", "abstract": "It has been argued that semantic categories across languages reflect pressure\nfor efficient communication. Recently, this idea has been cast in terms of a\ngeneral information-theoretic principle of efficiency, the Information\nBottleneck (IB) principle, and it has been shown that this principle accounts\nfor the emergence and evolution of named color categories across languages,\nincluding soft structure and patterns of inconsistent naming. However, it is\nnot yet clear to what extent this account generalizes to semantic domains other\nthan color. Here we show that it generalizes to two qualitatively different\nsemantic domains: names for containers, and for animals. First, we show that\ncontainer naming in Dutch and French is near-optimal in the IB sense, and that\nIB broadly accounts for soft categories and inconsistent naming patterns in\nboth languages. Second, we show that a hierarchy of animal categories derived\nfrom IB captures cross-linguistic tendencies in the growth of animal\ntaxonomies. Taken together, these findings suggest that fundamental\ninformation-theoretic principles of efficient coding may shape semantic\ncategories across languages and across domains.", "published": "2019-05-11 17:50:12", "link": "http://arxiv.org/abs/1905.04562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlled Natural Languages and Default Reasoning", "abstract": "Controlled natural languages (CNLs) are effective languages for knowledge\nrepresentation and reasoning. They are designed based on certain natural\nlanguages with restricted lexicon and grammar. CNLs are unambiguous and simple\nas opposed to their base languages. They preserve the expressiveness and\ncoherence of natural languages. In this report, we focus on a class of CNLs,\ncalled machine-oriented CNLs, which have well-defined semantics that can be\ndeterministically translated into formal languages, such as Prolog, to do\nlogical reasoning. Over the past 20 years, a number of machine-oriented CNLs\nemerged and have been used in many application domains for problem solving and\nquestion answering. However, few of them support non-monotonic inference. In\nour work, we propose non-monotonic extensions of CNL to support defeasible\nreasoning.\n  In the first part of this report, we survey CNLs and compare three\ninfluential systems: Attempto Controlled English (ACE), Processable English\n(PENG), and Computer-processable English (CPL). We compare their language\ndesign, semantic interpretations, and reasoning services. In the second part of\nthis report, we first identify typical non-monotonicity in natural languages,\nsuch as defaults, exceptions and conversational implicatures. Then, we propose\ntheir representation in CNL and the corresponding formalizations in a form of\ndefeasible reasoning known as Logic Programming with Defaults and Argumentation\nTheory (LPDA).", "published": "2019-05-11 02:02:55", "link": "http://arxiv.org/abs/1905.04422v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Time-Contrastive Learning Based Deep Bottleneck Features for\n  Text-Dependent Speaker Verification", "abstract": "There are a number of studies about extraction of bottleneck (BN) features\nfrom deep neural networks (DNNs)trained to discriminate speakers, pass-phrases\nand triphone states for improving the performance of text-dependent speaker\nverification (TD-SV). However, a moderate success has been achieved. A recent\nstudy [1] presented a time contrastive learning (TCL) concept to explore the\nnon-stationarity of brain signals for classification of brain states. Speech\nsignals have similar non-stationarity property, and TCL further has the\nadvantage of having no need for labeled data. We therefore present a TCL based\nBN feature extraction method. The method uniformly partitions each speech\nutterance in a training dataset into a predefined number of multi-frame\nsegments. Each segment in an utterance corresponds to one class, and class\nlabels are shared across utterances. DNNs are then trained to discriminate all\nspeech frames among the classes to exploit the temporal structure of speech. In\naddition, we propose a segment-based unsupervised clustering algorithm to\nre-assign class labels to the segments. TD-SV experiments were conducted on the\nRedDots challenge database. The TCL-DNNs were trained using speech data of\nfixed pass-phrases that were excluded from the TD-SV evaluation set, so the\nlearned features can be considered phrase-independent. We compare the\nperformance of the proposed TCL bottleneck (BN) feature with those of\nshort-time cepstral features and BN features extracted from DNNs discriminating\nspeakers, pass-phrases, speaker+pass-phrase, as well as monophones whose labels\nand boundaries are generated by three different automatic speech recognition\n(ASR) systems. Experimental results show that the proposed TCL-BN outperforms\ncepstral features and speaker+pass-phrase discriminant BN features, and its\nperformance is on par with those of ASR derived BN features. Moreover,....", "published": "2019-05-11 17:20:19", "link": "http://arxiv.org/abs/1905.04554v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Encrypted Speech Recognition using Deep Polynomial Networks", "abstract": "The cloud-based speech recognition/API provides developers or enterprises an\neasy way to create speech-enabled features in their applications. However,\nsending audios about personal or company internal information to the cloud,\nraises concerns about the privacy and security issues. The recognition results\ngenerated in cloud may also reveal some sensitive information. This paper\nproposes a deep polynomial network (DPN) that can be applied to the encrypted\nspeech as an acoustic model. It allows clients to send their data in an\nencrypted form to the cloud to ensure that their data remains confidential, at\nmean while the DPN can still make frame-level predictions over the encrypted\nspeech and return them in encrypted form. One good property of the DPN is that\nit can be trained on unencrypted speech features in the traditional way. To\nkeep the cloud away from the raw audio and recognition results, a cloud-local\njoint decoding framework is also proposed. We demonstrate the effectiveness of\nmodel and framework on the Switchboard and Cortana voice assistant tasks with\nsmall performance degradation and latency increased comparing with the\ntraditional cloud-based DNNs.", "published": "2019-05-11 00:14:09", "link": "http://arxiv.org/abs/1905.05605v1", "categories": ["cs.CR", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Machine learning in acoustics: theory and applications", "abstract": "Acoustic data provide scientific and engineering insights in fields ranging\nfrom biology and communications to ocean and Earth science. We survey the\nrecent advances and transformative potential of machine learning (ML),\nincluding deep learning, in the field of acoustics. ML is a broad family of\ntechniques, which are often based in statistics, for automatically detecting\nand utilizing patterns in data. Relative to conventional acoustics and signal\nprocessing, ML is data-driven. Given sufficient training data, ML can discover\ncomplex relationships between features and desired labels or actions, or\nbetween features themselves. With large volumes of training data, ML can\ndiscover models describing complex acoustic phenomena such as human speech and\nreverberation. ML in acoustics is rapidly developing with compelling results\nand significant future promise. We first introduce ML, then highlight ML\ndevelopments in four acoustics research areas: source localization in speech\nprocessing, source localization in ocean acoustics, bioacoustics, and\nenvironmental sounds in everyday scenes.", "published": "2019-05-11 01:14:55", "link": "http://arxiv.org/abs/1905.04418v4", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS", "physics.app-ph"], "primary_category": "eess.SP"}
