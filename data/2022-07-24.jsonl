{"title": "Towards a Sentiment-Aware Conversational Agent", "abstract": "In this paper, we propose an end-to-end sentiment-aware conversational agent\nbased on two models: a reply sentiment prediction model, which leverages the\ncontext of the dialogue to predict an appropriate sentiment for the agent to\nexpress in its reply; and a text generation model, which is conditioned on the\npredicted sentiment and the context of the dialogue, to produce a reply that is\nboth context and sentiment appropriate. Additionally, we propose to use a\nsentiment classification model to evaluate the sentiment expressed by the agent\nduring the development of the model. This allows us to evaluate the agent in an\nautomatic way. Both automatic and human evaluation results show that explicitly\nguiding the text generation model with a pre-defined set of sentences leads to\nclear improvements, both regarding the expressed sentiment and the quality of\nthe generated text.", "published": "2022-07-24 16:59:44", "link": "http://arxiv.org/abs/2207.11774v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancements to the BOUN Treebank Reflecting the Agglutinative Nature of\n  Turkish", "abstract": "In this study, we aim to offer linguistically motivated solutions to resolve\nthe issues of the lack of representation of null morphemes, highly productive\nderivational processes, and syncretic morphemes of Turkish in the BOUN Treebank\nwithout diverging from the Universal Dependencies framework.\n  In order to tackle these issues, new annotation conventions were introduced\nby splitting certain lemmas and employing the MISC (miscellaneous) tab in the\nUD framework to denote derivation. Representational capabilities of the\nre-annotated treebank were tested on a LSTM-based dependency parser and an\nupdated version of the BoAT Tool is introduced.", "published": "2022-07-24 17:56:27", "link": "http://arxiv.org/abs/2207.11782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment\n  Analysis", "abstract": "Existing studies on multimodal sentiment analysis heavily rely on textual\nmodality and unavoidably induce the spurious correlations between textual words\nand sentiment labels. This greatly hinders the model generalization ability. To\naddress this problem, we define the task of out-of-distribution (OOD)\nmultimodal sentiment analysis. This task aims to estimate and mitigate the bad\neffect of textual modality for strong OOD generalization. To this end, we\nembrace causal inference, which inspects the causal relationships via a causal\ngraph. From the graph, we find that the spurious correlations are attributed to\nthe direct effect of textual modality on the model prediction while the\nindirect one is more reliable by considering multimodal semantics. Inspired by\nthis, we devise a model-agnostic counterfactual framework for multimodal\nsentiment analysis, which captures the direct effect of textual modality via an\nextra text model and estimates the indirect one by a multimodal model. During\nthe inference, we first estimate the direct effect by the counterfactual\ninference, and then subtract it from the total effect of all modalities to\nobtain the indirect effect for reliable prediction. Extensive experiments show\nthe superior effectiveness and generalization ability of our proposed\nframework.", "published": "2022-07-24 03:57:40", "link": "http://arxiv.org/abs/2207.11652v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoWeird: Weird Translational Scoring Function Identified by Random\n  Search", "abstract": "Scoring function (SF) measures the plausibility of triplets in knowledge\ngraphs. Different scoring functions can lead to huge differences in link\nprediction performances on different knowledge graphs. In this report, we\ndescribe a weird scoring function found by random search on the open graph\nbenchmark (OGB). This scoring function, called AutoWeird, only uses tail entity\nand relation in a triplet to compute its plausibility score. Experimental\nresults show that AutoWeird achieves top-1 performance on ogbl-wikikg2 data\nset, but has much worse performance than other methods on ogbl-biokg data set.\nBy analyzing the tail entity distribution and evaluation protocol of these two\ndata sets, we attribute the unexpected success of AutoWeird on ogbl-wikikg2 to\ninappropriate evaluation and concentrated tail entity distribution. Such\nresults may motivate further research on how to accurately evaluate the\nperformance of different link prediction methods for knowledge graphs.", "published": "2022-07-24 06:43:06", "link": "http://arxiv.org/abs/2207.11673v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Anti-Overestimation Dialogue Policy Learning for Task-Completion\n  Dialogue System", "abstract": "A dialogue policy module is an essential part of task-completion dialogue\nsystems. Recently, increasing interest has focused on reinforcement learning\n(RL)-based dialogue policy. Its favorable performance and wise action decisions\nrely on an accurate estimation of action values. The overestimation problem is\na widely known issue of RL since its estimate of the maximum action value is\nlarger than the ground truth, which results in an unstable learning process and\nsuboptimal policy. This problem is detrimental to RL-based dialogue policy\nlearning. To mitigate this problem, this paper proposes a dynamic partial\naverage estimator (DPAV) of the ground truth maximum action value. DPAV\ncalculates the partial average between the predicted maximum action value and\nminimum action value, where the weights are dynamically adaptive and\nproblem-dependent. We incorporate DPAV into a deep Q-network as the dialogue\npolicy and show that our method can achieve better or comparable results\ncompared to top baselines on three dialogue datasets of different domains with\na lower computational load. In addition, we also theoretically prove the\nconvergence and derive the upper and lower bounds of the bias compared with\nthose of other methods.", "published": "2022-07-24 15:38:08", "link": "http://arxiv.org/abs/2207.11762v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ArmanEmo: A Persian Dataset for Text-based Emotion Detection", "abstract": "With the recent proliferation of open textual data on social media platforms,\nEmotion Detection (ED) from Text has received more attention over the past\nyears. It has many applications, especially for businesses and online service\nproviders, where emotion detection techniques can help them make informed\ncommercial decisions by analyzing customers/users' feelings towards their\nproducts and services. In this study, we introduce ArmanEmo, a human-labeled\nemotion dataset of more than 7000 Persian sentences labeled for seven\ncategories. The dataset has been collected from different resources, including\nTwitter, Instagram, and Digikala (an Iranian e-commerce company) comments.\nLabels are based on Ekman's six basic emotions (Anger, Fear, Happiness, Hatred,\nSadness, Wonder) and another category (Other) to consider any other emotion not\nincluded in Ekman's model. Along with the dataset, we have provided several\nbaseline models for emotion classification focusing on the state-of-the-art\ntransformer-based language models. Our best model achieves a macro-averaged F1\nscore of 75.39 percent across our test dataset. Moreover, we also conduct\ntransfer learning experiments to compare our proposed dataset's generalization\nagainst other Persian emotion datasets. Results of these experiments suggest\nthat our dataset has superior generalizability among the existing Persian\nemotion datasets. ArmanEmo is publicly available for non-commercial use at\nhttps://github.com/Arman-Rayan-Sharif/arman-text-emotion.", "published": "2022-07-24 20:35:23", "link": "http://arxiv.org/abs/2207.11808v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generalized Attention Mechanism and Relative Position for Transformer", "abstract": "In this paper, we propose generalized attention mechanism (GAM) by first\nsuggesting a new interpretation for self-attention mechanism of Vaswani et al.\n. Following the interpretation, we provide description for different variants\nof attention mechanism which together form GAM. Further, we propose a new\nrelative position representation within the framework of GAM. This\nrepresentation can be easily utilized for cases in which elements next to each\nother in input sequence can be at random locations in actual dataset/corpus.", "published": "2022-07-24 00:57:06", "link": "http://arxiv.org/abs/2208.10247v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Composing RNNs and FSTs for Small Data: Recovering Missing Characters in\n  Old Hawaiian Text", "abstract": "In contrast to the older writing system of the 19th century, modern Hawaiian\northography employs characters for long vowels and glottal stops. These extra\ncharacters account for about one-third of the phonemes in Hawaiian, so\nincluding them makes a big difference to reading comprehension and\npronunciation. However, transliterating between older and newer texts is a\nlaborious task when performed manually. We introduce two related methods to\nhelp solve this transliteration problem automatically, given that there were\nnot enough data to train an end-to-end deep learning model. One method is\nimplemented, end-to-end, using finite state transducers (FSTs). The other is a\nhybrid deep learning approach which approximately composes an FST with a\nrecurrent neural network (RNN). We find that the hybrid approach outperforms\nthe end-to-end FST by partitioning the original problem into one part that can\nbe modelled by hand, using an FST, and into another part, which is easily\nsolved by an RNN trained on the available data.", "published": "2022-07-24 00:46:21", "link": "http://arxiv.org/abs/2208.10248v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Mandarin Speech Recogntion with Block-augmented Transformer", "abstract": "Recently Convolution-augmented Transformer (Conformer) has shown promising\nresults in Automatic Speech Recognition (ASR), outperforming the previous best\npublished Transformer Transducer. In this work, we believe that the output\ninformation of each block in the encoder and decoder is not completely\ninclusive, in other words, their output information may be complementary. We\nstudy how to take advantage of the complementary information of each block in a\nparameter-efficient way, and it is expected that this may lead to more robust\nperformance. Therefore we propose the Block-augmented Transformer for speech\nrecognition, named Blockformer. We have implemented two block ensemble methods:\nthe base Weighted Sum of the Blocks Output (Base-WSBO), and the\nSqueeze-and-Excitation module to Weighted Sum of the Blocks Output (SE-WSBO).\nExperiments have proved that the Blockformer significantly outperforms the\nstate-of-the-art Conformer-based models on AISHELL-1, our model achieves a CER\nof 4.29\\% without using a language model and 4.05\\% with an external language\nmodel on the testset.", "published": "2022-07-24 09:23:04", "link": "http://arxiv.org/abs/2207.11697v5", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Cognitive Study on Semantic Similarity Analysis of Large Corpora: A\n  Transformer-based Approach", "abstract": "Semantic similarity analysis and modeling is a fundamentally acclaimed task\nin many pioneering applications of natural language processing today. Owing to\nthe sensation of sequential pattern recognition, many neural networks like RNNs\nand LSTMs have achieved satisfactory results in semantic similarity modeling.\nHowever, these solutions are considered inefficient due to their inability to\nprocess information in a non-sequential manner, thus leading to the improper\nextraction of context. Transformers function as the state-of-the-art\narchitecture due to their advantages like non-sequential data processing and\nself-attention. In this paper, we perform semantic similarity analysis and\nmodeling on the U.S Patent Phrase to Phrase Matching Dataset using both\ntraditional and transformer-based techniques. We experiment upon four different\nvariants of the Decoding Enhanced BERT - DeBERTa and enhance its performance by\nperforming K-Fold Cross-Validation. The experimental results demonstrate our\nmethodology's enhanced performance compared to traditional techniques, with an\naverage Pearson correlation score of 0.79.", "published": "2022-07-24 11:06:56", "link": "http://arxiv.org/abs/2207.11716v3", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Assessment of a cost-effective headphone calibration procedure for\n  soundscape evaluations", "abstract": "To increase the availability and adoption of the soundscape standard, a\nlow-cost calibration procedure for reproduction of audio stimuli over\nheadphones was proposed as part of the global ``Soundscape Attributes\nTranslation Project'' (SATP) for validating ISO/TS~12913-2:2018 perceived\naffective quality (PAQ) attribute translations. A previous preliminary study\nrevealed significant deviations from the intended equivalent continuous\nA-weighted sound pressure levels ($L_{\\text{A,eq}}$) using the open-circuit\nvoltage (OCV) calibration procedure. For a more holistic human-centric\nperspective, the OCV method is further investigated here in terms of\npsychoacoustic parameters, including relevant exceedance levels to account for\ntemporal effects on the same 27 stimuli from the SATP. Moreover, a\nwithin-subjects experiment with 36 participants was conducted to examine the\neffects of OCV calibration on the PAQ attributes in ISO/TS~12913-2:2018.\nBland-Altman analysis of the objective indicators revealed large biases in the\nOCV method across all weighted sound level and loudness indicators; and\nroughness indicators at \\SI{5}{\\%} and \\SI{10}{\\%} exceedance levels.\nSignificant perceptual differences due to the OCV method were observed in about\n\\SI{20}{\\%} of the stimuli, which did not correspond clearly with the biased\nacoustic indicators. A cautioned interpretation of the objective and perceptual\ndifferences due to small and unpaired samples nevertheless provide grounds for\nfurther investigation.", "published": "2022-07-24 05:39:09", "link": "http://arxiv.org/abs/2207.12899v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HouseX: A Fine-grained House Music Dataset and its Potential in the\n  Music Industry", "abstract": "Machine sound classification has been one of the fundamental tasks of music\ntechnology. A major branch of sound classification is the classification of\nmusic genres. However, though covering most genres of music, existing music\ngenre datasets often do not contain fine-grained labels that indicate the\ndetailed sub-genres of music. In consideration of the consistency of genres of\nsongs in a mixtape or in a DJ (live) set, we have collected and annotated a\ndataset of house music that provide 4 sub-genre labels, namely future house,\nbass house, progressive house and melodic house. Experiments show that our\nannotations well exhibit the characteristics of different categories. Also, we\nhave built baseline models that classify the sub-genre based on the\nmel-spectrograms of a track, achieving strongly competitive results. Besides,\nwe have put forward a few application scenarios of our dataset and baseline\nmodel, with a simulated sci-fi tunnel as a short demo built and rendered in a\n3D modeling software, with the colors of the lights automated by the output of\nour model.", "published": "2022-07-24 08:19:19", "link": "http://arxiv.org/abs/2207.11690v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Simultaneous source separation of unknown numbers of single-channel\n  underwater acoustic signals based on deep neural networks with\n  separator-decoder structure", "abstract": "The separation of single-channel underwater acoustic signals is a challenging\nproblem with practical significance. Few existing studies focus on the source\nseparation problem with unknown numbers of signals, and how to evaluate the\nperformance of the systems is not yet clear. In this paper, a deep\nlearning-based simultaneous separating solution with a fixed number of output\nchannels equal to the maximum number of possible targets is proposed to address\nthese two problems. This solution avoids the dimensional disaster caused by the\npermutation problem induced by the alignment of outputs to targets.\nSpecifically, we propose a two-step learning-based separation model with a\nseparator-decoder structure. A performance evaluation method with two\nquantitative metrics of the separation system for situations with mute channels\nin the output channels that do not contain target signals is also proposed.\nExperiments conducted on simulated mixtures of radiated ship noise show that\nthe proposed solution can achieve similar separation performance to that\nattained with a known number of signals. The proposed separation model with\nseparator-decoder structure achieved competitive performance as two models\ndeveloped for known numbers of signals, which is highly explainable and\nextensible and gets the state of the art under this framework.", "published": "2022-07-24 14:04:34", "link": "http://arxiv.org/abs/2207.11749v4", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "68T07, 94A12, 76Q05, 68U99", "I.2.6; I.5.4; J.2"], "primary_category": "cs.SD"}
