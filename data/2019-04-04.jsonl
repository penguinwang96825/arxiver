{"title": "Answer-based Adversarial Training for Generating Clarification Questions", "abstract": "We present an approach for generating clarification questions with the goal\nof eliciting new information that would make the given textual context more\ncomplete. We propose that modeling hypothetical answers (to clarification\nquestions) as latent variables can guide our approach into generating more\nuseful clarification questions. We develop a Generative Adversarial Network\n(GAN) where the generator is a sequence-to-sequence model and the discriminator\nis a utility function that models the value of updating the context with the\nanswer to the clarification question. We evaluate on two datasets, using both\nautomatic metrics and human judgments of usefulness, specificity and relevance,\nshowing that our approach outperforms both a retrieval-based model and\nablations that exclude the utility model and the adversarial training.", "published": "2019-04-04 00:30:20", "link": "http://arxiv.org/abs/1904.02281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Style Transfer for Text", "abstract": "Research in the area of style transfer for text is currently bottlenecked by\na lack of standard evaluation practices. This paper aims to alleviate this\nissue by experimentally identifying best practices with a Yelp sentiment\ndataset. We specify three aspects of interest (style transfer intensity,\ncontent preservation, and naturalness) and show how to obtain more reliable\nmeasures of them from human evaluation than in previous work. We propose a set\nof metrics for automated evaluation and demonstrate that they are more strongly\ncorrelated and in agreement with human judgment: direction-corrected Earth\nMover's Distance, Word Mover's Distance on style-masked texts, and adversarial\nclassification for the respective aspects. We also show that the three examined\nmodels exhibit tradeoffs between aspects of interest, demonstrating the\nimportance of evaluating style transfer models at specific points of their\ntradeoff plots. We release software with our evaluation metrics to facilitate\nresearch.", "published": "2019-04-04 01:18:56", "link": "http://arxiv.org/abs/1904.02295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple Joint Model for Improved Contextual Neural Lemmatization", "abstract": "English verbs have multiple forms. For instance, talk may also appear as\ntalks, talked or talking, depending on the context. The NLP task of\nlemmatization seeks to map these diverse forms back to a canonical one, known\nas the lemma. We present a simple joint neural model for lemmatization and\nmorphological tagging that achieves state-of-the-art results on 20 languages\nfrom the Universal Dependencies corpora. Our paper describes the model in\naddition to training and decoding procedures. Error analysis indicates that\njoint morphological tagging and lemmatization is especially helpful in\nlow-resource lemmatization and languages that display a larger degree of\nmorphological complexity. Code and pre-trained models are available at\nhttps://sigmorphon.github.io/sharedtasks/2019/task2/.", "published": "2019-04-04 02:03:19", "link": "http://arxiv.org/abs/1904.02306v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding Extractive Summarization with Question-Answering Rewards", "abstract": "Highlighting while reading is a natural behavior for people to track salient\ncontent of a document. It would be desirable to teach an extractive summarizer\nto do the same. However, a major obstacle to the development of a supervised\nsummarizer is the lack of ground-truth. Manual annotation of extraction units\nis cost-prohibitive, whereas acquiring labels by automatically aligning human\nabstracts and source documents can yield inferior results. In this paper we\ndescribe a novel framework to guide a supervised, extractive summarization\nsystem with question-answering rewards. We argue that quality summaries should\nserve as a document surrogate to answer important questions, and such\nquestion-answer pairs can be conveniently obtained from human abstracts. The\nsystem learns to promote summaries that are informative, fluent, and perform\ncompetitively on question-answering. Our results compare favorably with those\nreported by strong summarization baselines as evaluated by automatic metrics\nand human assessors.", "published": "2019-04-04 02:57:59", "link": "http://arxiv.org/abs/1904.02321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extract and Edit: An Alternative to Back-Translation for Unsupervised\n  Neural Machine Translation", "abstract": "The overreliance on large parallel corpora significantly limits the\napplicability of machine translation systems to the majority of language pairs.\nBack-translation has been dominantly used in previous approaches for\nunsupervised neural machine translation, where pseudo sentence pairs are\ngenerated to train the models with a reconstruction loss. However, the pseudo\nsentences are usually of low quality as translation errors accumulate during\ntraining. To avoid this fundamental issue, we propose an alternative but more\neffective approach, extract-edit, to extract and then edit real sentences from\nthe target monolingual corpora. Furthermore, we introduce a comparative\ntranslation loss to evaluate the translated target sentences and thus train the\nunsupervised translation systems. Experiments show that the proposed approach\nconsistently outperforms the previous state-of-the-art unsupervised machine\ntranslation systems across two benchmarks (English-French and English-German)\nand two low-resource language pairs (English-Romanian and English-Russian) by\nmore than 2 (up to 3.63) BLEU points.", "published": "2019-04-04 03:22:40", "link": "http://arxiv.org/abs/1904.02331v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Generation from Knowledge Graphs with Graph Transformers", "abstract": "Generating texts which express complex ideas spanning multiple sentences\nrequires a structured representation of their content (document plan), but\nthese representations are prohibitively expensive to manually produce. In this\nwork, we address the problem of generating coherent multi-sentence texts from\nthe output of an information extraction system, and in particular a knowledge\ngraph. Graphical knowledge representations are ubiquitous in computing, but\npose a significant challenge for text generation techniques due to their\nnon-hierarchical nature, collapsing of long-distance dependencies, and\nstructural variety. We introduce a novel graph transforming encoder which can\nleverage the relational structure of such knowledge graphs without imposing\nlinearization or hierarchical constraints. Incorporated into an encoder-decoder\nsetup, we provide an end-to-end trainable system for graph-to-text generation\nthat we apply to the domain of scientific text. Automatic and human evaluations\nshow that our technique produces more informative texts which exhibit better\ndocument structure than competitive encoder-decoder methods.", "published": "2019-04-04 04:33:15", "link": "http://arxiv.org/abs/1904.02342v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-Level $N$-ary Relation Extraction with Multiscale\n  Representation Learning", "abstract": "Most information extraction methods focus on binary relations expressed\nwithin single sentences. In high-value domains, however, $n$-ary relations are\nof great demand (e.g., drug-gene-mutation interactions in precision oncology).\nSuch relations often involve entity mentions that are far apart in the\ndocument, yet existing work on cross-sentence relation extraction is generally\nconfined to small text spans (e.g., three consecutive sentences), which\nseverely limits recall. In this paper, we propose a novel multiscale neural\narchitecture for document-level $n$-ary relation extraction. Our system\ncombines representations learned over various text spans throughout the\ndocument and across the subrelation hierarchy. Widening the system's purview to\nthe entire document maximizes potential recall. Moreover, by integrating weak\nsignals across the document, multiscale modeling increases precision, even in\nthe presence of noisy labels from distant supervision. Experiments on\nbiomedical machine reading show that our approach substantially outperforms\nprevious $n$-ary relation extraction methods.", "published": "2019-04-04 05:02:38", "link": "http://arxiv.org/abs/1904.02347v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plan, Write, and Revise: an Interactive System for Open-Domain Story\n  Generation", "abstract": "Story composition is a challenging problem for machines and even for humans.\nWe present a neural narrative generation system that interacts with humans to\ngenerate stories. Our system has different levels of human interaction, which\nenables us to understand at what stage of story-writing human collaboration is\nmost productive, both to improving story quality and human engagement in the\nwriting process. We compare different varieties of interaction in\nstory-writing, story-planning, and diversity controls under time constraints,\nand show that increased types of human collaboration at both planning and\nwriting stages results in a 10-50% improvement in story quality as compared to\nless interactive baselines. We also show an accompanying increase in user\nengagement and satisfaction with stories as compared to our own less\ninteractive systems and to previous turn-taking approaches to interaction.\nFinally, we find that humans tasked with collaboratively improving a particular\ncharacteristic of a story are in fact able to do so, which has implications for\nfuture uses of human-in-the-loop systems.", "published": "2019-04-04 05:42:53", "link": "http://arxiv.org/abs/1904.02357v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-reference Tacotron by Intercross Training for Style\n  Disentangling,Transfer and Control in Speech Synthesis", "abstract": "Speech style control and transfer techniques aim to enrich the diversity and\nexpressiveness of synthesized speech. Existing approaches model all speech\nstyles into one representation, lacking the ability to control a specific\nspeech feature independently. To address this issue, we introduce a novel\nmulti-reference structure to Tacotron and propose intercross training approach,\nwhich together ensure that each sub-encoder of the multi-reference encoder\nindependently disentangles and controls a specific style. Experimental results\nshow that our model is able to control and transfer desired speech styles\nindividually.", "published": "2019-04-04 06:37:19", "link": "http://arxiv.org/abs/1904.02373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReWE: Regressing Word Embeddings for Regularization of Neural Machine\n  Translation Systems", "abstract": "Regularization of neural machine translation is still a significant problem,\nespecially in low-resource settings. To mollify this problem, we propose\nregressing word embeddings (ReWE) as a new regularization technique in a system\nthat is jointly trained to predict the next word in the translation\n(categorical value) and its word embedding (continuous value). Such a joint\ntraining allows the proposed system to learn the distributional properties\nrepresented by the word embeddings, empirically improving the generalization to\nunseen sentences. Experiments over three translation datasets have showed a\nconsistent improvement over a strong baseline, ranging between 0.91 and 2.54\nBLEU points, and also a marked improvement over a state-of-the-art system.", "published": "2019-04-04 10:30:52", "link": "http://arxiv.org/abs/1904.02461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Composition of Sentence Embeddings:Lessons from Statistical Relational\n  Learning", "abstract": "Various NLP problems -- such as the prediction of sentence similarity,\nentailment, and discourse relations -- are all instances of the same general\ntask: the modeling of semantic relations between a pair of textual elements. A\npopular model for such problems is to embed sentences into fixed size vectors,\nand use composition functions (e.g. concatenation or sum) of those vectors as\nfeatures for the prediction. At the same time, composition of embeddings has\nbeen a main focus within the field of Statistical Relational Learning (SRL)\nwhose goal is to predict relations between entities (typically from knowledge\nbase triples). In this article, we show that previous work on relation\nprediction between texts implicitly uses compositions from baseline SRL models.\nWe show that such compositions are not expressive enough for several tasks\n(e.g. natural language inference). We build on recent SRL models to address\ntextual relational problems, showing that they are more expressive, and can\nalleviate issues from simpler compositions. The resulting models significantly\nimprove the state of the art in both transferable sentence representation\nlearning and relation prediction.", "published": "2019-04-04 10:38:33", "link": "http://arxiv.org/abs/1904.02464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue Act Classification with Context-Aware Self-Attention", "abstract": "Recent work in Dialogue Act classification has treated the task as a sequence\nlabeling problem using hierarchical deep neural networks. We build on this\nprior work by leveraging the effectiveness of a context-aware self-attention\nmechanism coupled with a hierarchical recurrent neural network. We conduct\nextensive evaluations on standard Dialogue Act classification datasets and show\nsignificant improvement over state-of-the-art results on the Switchboard\nDialogue Act (SwDA) Corpus. We also investigate the impact of different\nutterance-level representation learning methods and show that our method is\neffective at capturing utterance-level semantic text representations while\nmaintaining high accuracy.", "published": "2019-04-04 15:02:20", "link": "http://arxiv.org/abs/1904.02594v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Sequence Speech Recognition with Time-Depth Separable\n  Convolutions", "abstract": "We propose a fully convolutional sequence-to-sequence encoder architecture\nwith a simple and efficient decoder. Our model improves WER on LibriSpeech\nwhile being an order of magnitude more efficient than a strong RNN baseline.\nKey to our approach is a time-depth separable convolution block which\ndramatically reduces the number of parameters in the model while keeping the\nreceptive field large. We also give a stable and efficient beam search\ninference procedure which allows us to effectively integrate a language model.\nCoupled with a convolutional language model, our time-depth separable\nconvolution architecture improves by more than 22% relative WER over the best\npreviously reported sequence-to-sequence results on the noisy LibriSpeech test\nset.", "published": "2019-04-04 15:44:39", "link": "http://arxiv.org/abs/1904.02619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with\n  Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a\nhuman (or machine) to read a given passage, question pair and select one of the\nn given options. The current state of the art model for this task first\ncomputes a question-aware representation for the passage and then selects the\noption which has the maximum similarity with this representation. However, when\nhumans perform this task they do not just focus on option selection but use a\ncombination of elimination and selection. Specifically, a human would first try\nto eliminate the most irrelevant option and then read the passage again in the\nlight of this new information (and perhaps ignore portions corresponding to the\neliminated option). This process could be repeated multiple times till the\nreader is finally ready to select the correct option. We propose ElimiNet, a\nneural network-based model which tries to mimic this process. Specifically, it\nhas gates which decide whether an option can be eliminated given the passage,\nquestion pair and if so it tries to make the passage representation orthogonal\nto this eliminated option (akin to ignoring portions of the passage\ncorresponding to the eliminated option). The model makes multiple rounds of\npartial elimination to refine the passage representation and finally uses a\nselection module to pick the best option. We evaluate our model on the recently\nreleased large scale RACE dataset and show that it outperforms the current\nstate of the art model on 7 out of the $13$ question types in this dataset.\nFurther, we show that taking an ensemble of our elimination-selection based\nmethod with a selection based method gives us an improvement of 3.1% over the\nbest-reported performance on this dataset.", "published": "2019-04-04 16:44:44", "link": "http://arxiv.org/abs/1904.02651v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recommendations for Datasets for Source Code Summarization", "abstract": "Source Code Summarization is the task of writing short, natural language\ndescriptions of source code. The main use for these descriptions is in software\ndocumentation e.g. the one-sentence Java method descriptions in JavaDocs. Code\nsummarization is rapidly becoming a popular research problem, but progress is\nrestrained due to a lack of suitable datasets. In addition, a lack of community\nstandards for creating datasets leads to confusing and unreproducible research\nresults -- we observe swings in performance of more than 33% due only to\nchanges in dataset design. In this paper, we make recommendations for these\nstandards from experimental results. We release a dataset based on prior work\nof over 2.1m pairs of Java methods and one sentence method descriptions from\nover 28k Java projects. We describe the dataset and point out key differences\nfrom natural language data, to guide and support future researchers.", "published": "2019-04-04 16:56:01", "link": "http://arxiv.org/abs/1904.02660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frustratingly Poor Performance of Reading Comprehension Models on\n  Non-adversarial Examples", "abstract": "When humans learn to perform a difficult task (say, reading comprehension\n(RC) over longer passages), it is typically the case that their performance\nimproves significantly on an easier version of this task (say, RC over shorter\npassages). Ideally, we would want an intelligent agent to also exhibit such a\nbehavior. However, on experimenting with state of the art RC models using the\nstandard RACE dataset, we observe that this is not true. Specifically, we see\ncounter-intuitive results wherein even when we show frustratingly easy examples\nto the model at test time, there is hardly any improvement in its performance.\nWe refer to this as non-adversarial evaluation as opposed to adversarial\nevaluation. Such non-adversarial examples allow us to assess the utility of\nspecialized neural components. For example, we show that even for easy examples\nwhere the answer is clearly embedded in the passage, the neural components\ndesigned for paying attention to relevant portions of the passage fail to serve\ntheir intended purpose. We believe that the non-adversarial dataset created as\na part of this work would complement the research on adversarial evaluation and\ngive a more realistic assessment of the ability of RC models. All the datasets\nand codes developed as a part of this work will be made publicly available.", "published": "2019-04-04 17:00:48", "link": "http://arxiv.org/abs/1904.02665v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inoculation by Fine-Tuning: A Method for Analyzing Challenge Datasets", "abstract": "Several datasets have recently been constructed to expose brittleness in\nmodels trained on existing benchmarks. While model performance on these\nchallenge datasets is significantly lower compared to the original benchmark,\nit is unclear what particular weaknesses they reveal. For example, a challenge\ndataset may be difficult because it targets phenomena that current models\ncannot capture, or because it simply exploits blind spots in a model's specific\ntraining set. We introduce inoculation by fine-tuning, a new analysis method\nfor studying challenge datasets by exposing models (the metaphorical patient)\nto a small amount of data from the challenge dataset (a metaphorical pathogen)\nand assessing how well they can adapt. We apply our method to analyze the NLI\n\"stress tests\" (Naik et al., 2018) and the Adversarial SQuAD dataset (Jia and\nLiang, 2017). We show that after slight exposure, some of these datasets are no\nlonger challenging, while others remain difficult. Our results indicate that\nfailures on challenge datasets may lead to very different conclusions about\nmodels, training datasets, and the challenge datasets themselves.", "published": "2019-04-04 17:04:30", "link": "http://arxiv.org/abs/1904.02668v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Studying Cultural Differences in Emoji Usage across the East and the\n  West", "abstract": "Global acceptance of Emojis suggests a cross-cultural, normative use of\nEmojis. Meanwhile, nuances in Emoji use across cultures may also exist due to\nlinguistic differences in expressing emotions and diversity in conceptualizing\ntopics. Indeed, literature in cross-cultural psychology has found both\nnormative and culture-specific ways in which emotions are expressed. In this\npaper, using social media, we compare the Emoji usage based on frequency,\ncontext, and topic associations across countries in the East (China and Japan)\nand the West (United States, United Kingdom, and Canada). Across the East and\nthe West, our study examines a) similarities and differences on the usage of\ndifferent categories of Emojis such as People, Food \\& Drink, Travel \\& Places\netc., b) potential mapping of Emoji use differences with previously identified\ncultural differences in users' expression about diverse concepts such as death,\nmoney emotions and family, and c) relative correspondence of validated\npsycho-linguistic categories with Ekman's emotions. The analysis of Emoji use\nin the East and the West reveals recognizable normative and culture specific\npatterns. This research reveals the ways in which Emojis can be used for\ncross-cultural communication.", "published": "2019-04-04 17:12:25", "link": "http://arxiv.org/abs/1904.02671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing NLP with Cognitive Language Processing Signals", "abstract": "When we read, our brain processes language and generates cognitive processing\ndata such as gaze patterns and brain activity. These signals can be recorded\nwhile reading. Cognitive language processing data such as eye-tracking features\nhave shown improvements on single NLP tasks. We analyze whether using such\nhuman features can show consistent improvement across tasks and data sources.\nWe present an extensive investigation of the benefits and limitations of using\ncognitive processing data for NLP. Specifically, we use gaze and EEG features\nto augment models of named entity recognition, relation classification, and\nsentiment analysis. These methods significantly outperform the baselines and\nshow the potential and current limitations of employing human language\nprocessing data for NLP.", "published": "2019-04-04 17:38:16", "link": "http://arxiv.org/abs/1904.02682v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExCL: Extractive Clip Localization Using Natural Language Descriptions", "abstract": "The task of retrieving clips within videos based on a given natural language\nquery requires cross-modal reasoning over multiple frames. Prior approaches\nsuch as sliding window classifiers are inefficient, while text-clip similarity\ndriven ranking-based approaches such as segment proposal networks are far more\ncomplicated. In order to select the most relevant video clip corresponding to\nthe given text description, we propose a novel extractive approach that\npredicts the start and end frames by leveraging cross-modal interactions\nbetween the text and video - this removes the need to retrieve and re-rank\nmultiple proposal segments. Using recurrent networks we encode the two\nmodalities into a joint representation which is then used in different variants\nof start-end frame predictor networks. Through extensive experimentation and\nablative analysis, we demonstrate that our simple and elegant approach\nsignificantly outperforms state of the art on two datasets and has comparable\nperformance on a third.", "published": "2019-04-04 19:17:04", "link": "http://arxiv.org/abs/1904.02755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complexity-Weighted Loss and Diverse Reranking for Sentence\n  Simplification", "abstract": "Sentence simplification is the task of rewriting texts so they are easier to\nunderstand. Recent research has applied sequence-to-sequence (Seq2Seq) models\nto this task, focusing largely on training-time improvements via reinforcement\nlearning and memory augmentation. One of the main problems with applying\ngeneric Seq2Seq models for simplification is that these models tend to copy\ndirectly from the original sentence, resulting in outputs that are relatively\nlong and complex. We aim to alleviate this issue through the use of two main\ntechniques. First, we incorporate content word complexities, as predicted with\na leveled word complexity model, into our loss function during training.\nSecond, we generate a large set of diverse candidate simplifications at test\ntime, and rerank these to promote fluency, adequacy, and simplicity. Here, we\nmeasure simplicity through a novel sentence complexity model. These extensions\nallow our models to perform competitively with state-of-the-art systems while\ngenerating simpler sentences. We report standard automatic and human evaluation\nmetrics.", "published": "2019-04-04 19:47:17", "link": "http://arxiv.org/abs/1904.02767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Dialogue State Tracking by Discerning the Relevant Context", "abstract": "A typical conversation comprises of multiple turns between participants where\nthey go back-and-forth between different topics. At each user turn, dialogue\nstate tracking (DST) aims to estimate user's goal by processing the current\nutterance. However, in many turns, users implicitly refer to the previous goal,\nnecessitating the use of relevant dialogue history. Nonetheless, distinguishing\nrelevant history is challenging and a popular method of using dialogue recency\nfor that is inefficient. We, therefore, propose a novel framework for DST that\nidentifies relevant historical context by referring to the past utterances\nwhere a particular slot-value changes and uses that together with weighted\nsystem utterance to identify the relevant context. Specifically, we use the\ncurrent user utterance and the most recent system utterance to determine the\nrelevance of a system utterance. Empirical analyses show that our method\nimproves joint goal accuracy by 2.75% and 2.36% on WoZ 2.0 and MultiWoZ 2.0\nrestaurant domain datasets respectively over the previous state-of-the-art GLAD\nmodel.", "published": "2019-04-04 21:53:41", "link": "http://arxiv.org/abs/1904.02800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Density Matching for Bilingual Word Embedding", "abstract": "Recent approaches to cross-lingual word embedding have generally been based\non linear transformations between the sets of embedding vectors in the two\nlanguages. In this paper, we propose an approach that instead expresses the two\nmonolingual embedding spaces as probability densities defined by a Gaussian\nmixture model, and matches the two densities using a method called normalizing\nflow. The method requires no explicit supervision, and can be learned with only\na seed dictionary of words that have identical strings. We argue that this\nformulation has several intuitively attractive properties, particularly with\nthe respect to improving robustness and generalization to mappings between\ndifficult language pairs or word pairs. On a benchmark data set of bilingual\nlexicon induction and cross-lingual word similarity, our approach can achieve\ncompetitive or superior performance compared to state-of-the-art published\nresults, with particularly strong results being found on etymologically distant\nand/or morphologically rich languages.", "published": "2019-04-04 04:36:11", "link": "http://arxiv.org/abs/1904.02343v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Riemannian Normalizing Flow on Variational Wasserstein Autoencoder for\n  Text Modeling", "abstract": "Recurrent Variational Autoencoder has been widely used for language modeling\nand text generation tasks. These models often face a difficult optimization\nproblem, also known as the Kullback-Leibler (KL) term vanishing issue, where\nthe posterior easily collapses to the prior, and the model will ignore latent\ncodes in generative tasks. To address this problem, we introduce an improved\nWasserstein Variational Autoencoder (WAE) with Riemannian Normalizing Flow\n(RNF) for text modeling. The RNF transforms a latent variable into a space that\nrespects the geometric characteristics of input space, which makes posterior\nimpossible to collapse to the non-informative prior. The Wasserstein objective\nminimizes the distance between the marginal distribution and the prior directly\nand therefore does not force the posterior to match the prior. Empirical\nexperiments show that our model avoids KL vanishing over a range of datasets\nand has better performances in tasks such as language modeling, likelihood\napproximation, and text generation. Through a series of experiments and\nanalysis over latent space, we show that our model learns latent distributions\nthat respect latent space geometry and is able to generate sentences that are\nmore diverse.", "published": "2019-04-04 08:13:42", "link": "http://arxiv.org/abs/1904.02399v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Context Term Embeddings: the Use Case of Corpus-based Term Set\n  Expansion", "abstract": "In this paper, we present a novel algorithm that combines multi-context term\nembeddings using a neural classifier and we test this approach on the use case\nof corpus-based term set expansion. In addition, we present a novel and unique\ndataset for intrinsic evaluation of corpus-based term set expansion algorithms.\nWe show that, over this dataset, our algorithm provides up to 5 mean average\nprecision points over the best baseline.", "published": "2019-04-04 11:45:52", "link": "http://arxiv.org/abs/1904.02496v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Clinically Accurate Chest X-Ray Report Generation", "abstract": "The automatic generation of radiology reports given medical radiographs has\nsignificant potential to operationally and improve clinical patient care. A\nnumber of prior works have focused on this problem, employing advanced methods\nfrom computer vision and natural language generation to produce readable\nreports. However, these works often fail to account for the particular nuances\nof the radiology domain, and, in particular, the critical importance of\nclinical accuracy in the resulting generated reports. In this work, we present\na domain-aware automatic chest X-ray radiology report generation system which\nfirst predicts what topics will be discussed in the report, then conditionally\ngenerates sentences corresponding to these topics. The resulting system is\nfine-tuned using reinforcement learning, considering both readability and\nclinical accuracy, as assessed by the proposed Clinically Coherent Reward. We\nverify this system on two datasets, Open-I and MIMIC-CXR, and demonstrate that\nour model offers marked improvements on both language generation metrics and\nCheXpert assessed accuracy over a variety of competitive baselines.", "published": "2019-04-04 16:04:30", "link": "http://arxiv.org/abs/1904.02633v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Neural Models of the Psychosemantics of `Most'", "abstract": "How are the meanings of linguistic expressions related to their use in\nconcrete cognitive tasks? Visual identification tasks show human speakers can\nexhibit considerable variation in their understanding, representation and\nverification of certain quantifiers. This paper initiates an investigation into\nneural models of these psycho-semantic tasks. We trained two types of network\n-- a convolutional neural network (CNN) model and a recurrent model of visual\nattention (RAM) -- on the \"most\" verification task from \\citet{Pietroski2009},\nmanipulating the visual scene and novel notions of task duration. Our results\nqualitatively mirror certain features of human performance (such as sensitivity\nto the ratio of set sizes, indicating a reliance on approximate number) while\ndiffering in interesting ways (such as exhibiting a subtly different pattern\nfor the effect of image type). We conclude by discussing the prospects for\nusing neural models as cognitive models of this and other psychosemantic tasks.", "published": "2019-04-04 18:14:23", "link": "http://arxiv.org/abs/1904.02734v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Differentiable Sampling with Flexible Reference Word Order for Neural\n  Machine Translation", "abstract": "Despite some empirical success at correcting exposure bias in machine\ntranslation, scheduled sampling algorithms suffer from a major drawback: they\nincorrectly assume that words in the reference translations and in sampled\nsequences are aligned at each time step. Our new differentiable sampling\nalgorithm addresses this issue by optimizing the probability that the reference\ncan be aligned with the sampled output, based on a soft alignment predicted by\nthe model itself. As a result, the output distribution at each time step is\nevaluated with respect to the whole predicted sequence. Experiments on IWSLT\ntranslation tasks show that our approach improves BLEU compared to maximum\nlikelihood and scheduled sampling baselines. In addition, our approach is\nsimpler to train with no need for sampling schedule and yields models that\nachieve larger improvements with smaller beam sizes.", "published": "2019-04-04 04:48:07", "link": "http://arxiv.org/abs/1904.04079v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Generative Adversarial Networks for text using word2vec intermediaries", "abstract": "Generative adversarial networks (GANs) have shown considerable success,\nespecially in the realistic generation of images. In this work, we apply\nsimilar techniques for the generation of text. We propose a novel approach to\nhandle the discrete nature of text, during training, using word embeddings. Our\nmethod is agnostic to vocabulary size and achieves competitive results relative\nto methods with various discrete gradient estimators.", "published": "2019-04-04 01:17:29", "link": "http://arxiv.org/abs/1904.02293v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Consistency by Agreement in Zero-shot Neural Machine Translation", "abstract": "Generalization and reliability of multilingual translation often highly\ndepend on the amount of available parallel data for each language pair of\ninterest. In this paper, we focus on zero-shot generalization---a challenging\nsetup that tests models on translation directions they have not been optimized\nfor at training time. To solve the problem, we (i) reformulate multilingual\ntranslation as probabilistic inference, (ii) define the notion of zero-shot\nconsistency and show why standard training often results in models unsuitable\nfor zero-shot tasks, and (iii) introduce a consistent agreement-based training\nmethod that encourages the model to produce equivalent translations of parallel\nsentences in auxiliary languages. We test our multilingual NMT models on\nmultiple public zero-shot translation benchmarks (IWSLT17, UN corpus, Europarl)\nand show that agreement-based learning often results in 2-3 BLEU zero-shot\nimprovement over strong baselines without any loss in performance on supervised\ntranslation directions.", "published": "2019-04-04 03:49:05", "link": "http://arxiv.org/abs/1904.02338v2", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning to Decipher Hate Symbols", "abstract": "Existing computational models to understand hate speech typically frame the\nproblem as a simple classification task, bypassing the understanding of hate\nsymbols (e.g., 14 words, kigy) and their secret connotations. In this paper, we\npropose a novel task of deciphering hate symbols. To do this, we leverage the\nUrban Dictionary and collected a new, symbol-rich Twitter corpus of hate\nspeech. We investigate neural network latent context models for deciphering\nhate symbols. More specifically, we study Sequence-to-Sequence models and show\nhow they are able to crack the ciphers based on context. Furthermore, we\npropose a novel Variational Decipher and show how it can generalize better to\nunseen hate symbols in a more challenging testing setting.", "published": "2019-04-04 09:11:24", "link": "http://arxiv.org/abs/1904.02418v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Robust Evaluation of Language-Brain Encoding Experiments", "abstract": "Language-brain encoding experiments evaluate the ability of language models\nto predict brain responses elicited by language stimuli. The evaluation\nscenarios for this task have not yet been standardized which makes it difficult\nto compare and interpret results. We perform a series of evaluation experiments\nwith a consistent encoding setup and compute the results for multiple fMRI\ndatasets. In addition, we test the sensitivity of the evaluation measures to\nrandomized data and analyze the effect of voxel selection methods. Our\nexperimental framework is publicly available to make modelling decisions more\ntransparent and support reproducibility for future comparisons.", "published": "2019-04-04 13:34:18", "link": "http://arxiv.org/abs/1904.02547v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "In Other News: A Bi-style Text-to-speech Model for Synthesizing\n  Newscaster Voice with Limited Data", "abstract": "Neural text-to-speech synthesis (NTTS) models have shown significant progress\nin generating high-quality speech, however they require a large quantity of\ntraining data. This makes creating models for multiple styles expensive and\ntime-consuming. In this paper different styles of speech are analysed based on\nprosodic variations, from this a model is proposed to synthesise speech in the\nstyle of a newscaster, with just a few hours of supplementary data. We pose the\nproblem of synthesising in a target style using limited data as that of\ncreating a bi-style model that can synthesise both neutral-style and\nnewscaster-style speech via a one-hot vector which factorises the two styles.\nWe also propose conditioning the model on contextual word embeddings, and\nextensively evaluate it against neutral NTTS, and neutral concatenative-based\nsynthesis. This model closes the gap in perceived style-appropriateness between\nnatural recordings for newscaster-style of speech, and neutral speech synthesis\nby approximately two-thirds.", "published": "2019-04-04 20:59:20", "link": "http://arxiv.org/abs/1904.02790v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Unifying Human and Statistical Evaluation for Natural Language\n  Generation", "abstract": "How can we measure whether a natural language generation system produces both\nhigh quality and diverse outputs? Human evaluation captures quality but not\ndiversity, as it does not catch models that simply plagiarize from the training\nset. On the other hand, statistical evaluation (i.e., perplexity) captures\ndiversity but not quality, as models that occasionally emit low quality samples\nwould be insufficiently penalized. In this paper, we propose a unified\nframework which evaluates both diversity and quality, based on the optimal\nerror rate of predicting whether a sentence is human- or machine-generated. We\ndemonstrate that this error rate can be efficiently estimated by combining\nhuman and statistical evaluation, using an evaluation metric which we call\nHUSE. On summarization and chit-chat dialogue, we show that (i) HUSE detects\ndiversity defects which fool pure human evaluation and that (ii) techniques\nsuch as annealing for improving quality actually decrease HUSE due to decreased\ndiversity.", "published": "2019-04-04 21:03:34", "link": "http://arxiv.org/abs/1904.02792v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Affect-Driven Dialog Generation", "abstract": "The majority of current systems for end-to-end dialog generation focus on\nresponse quality without an explicit control over the affective content of the\nresponses. In this paper, we present an affect-driven dialog system, which\ngenerates emotional responses in a controlled manner using a continuous\nrepresentation of emotions. The system achieves this by modeling emotions at a\nword and sequence level using: (1) a vector representation of the desired\nemotion, (2) an affect regularizer, which penalizes neutral words, and (3) an\naffect sampling method, which forces the neural network to generate diverse\nwords that are emotionally relevant. During inference, we use a reranking\nprocedure that aims to extract the most emotionally relevant responses using a\nhuman-in-the-loop optimization process. We study the performance of our system\nin terms of both quantitative (BLEU score and response diversity), and\nqualitative (emotional appropriateness) measures.", "published": "2019-04-04 21:05:13", "link": "http://arxiv.org/abs/1904.02793v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Topic Spotting using Hierarchical Networks with Self Attention", "abstract": "Success of deep learning techniques have renewed the interest in development\nof dialogue systems. However, current systems struggle to have consistent long\nterm conversations with the users and fail to build rapport. Topic spotting,\nthe task of automatically inferring the topic of a conversation, has been shown\nto be helpful in making a dialog system more engaging and efficient. We propose\na hierarchical model with self attention for topic spotting. Experiments on the\nSwitchboard corpus show the superior performance of our model over previously\nproposed techniques for topic spotting and deep models for text classification.\nAdditionally, in contrast to offline processing of dialog, we also analyze the\nperformance of our model in a more realistic setting i.e. in an online setting\nwhere the topic is identified in real time as the dialog progresses. Results\nshow that our model is able to generalize even with limited information in the\nonline setting.", "published": "2019-04-04 22:54:57", "link": "http://arxiv.org/abs/1904.02815v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence\n  Labeling", "abstract": "Contextualized word embeddings such as ELMo and BERT provide a foundation for\nstrong performance across a wide range of natural language processing tasks by\npretraining on large corpora of unlabeled text. However, the applicability of\nthis approach is unknown when the target domain varies substantially from the\npretraining corpus. We are specifically interested in the scenario in which\nlabeled data is available in only a canonical source domain such as newstext,\nand the target domain is distinct from both the labeled and pretraining texts.\nTo address this scenario, we propose domain-adaptive fine-tuning, in which the\ncontextualized embeddings are adapted by masked language modeling on text from\nthe target domain. We test this approach on sequence labeling in two\nchallenging domains: Early Modern English and Twitter. Both domains differ\nsubstantially from existing pretraining corpora, and domain-adaptive\nfine-tuning yields substantial improvements over strong BERT baselines, with\nparticularly impressive results on out-of-vocabulary words. We conclude that\ndomain-adaptive fine-tuning offers a simple and effective approach for the\nunsupervised adaptation of sequence labeling to difficult new domains.", "published": "2019-04-04 23:05:45", "link": "http://arxiv.org/abs/1904.02817v2", "categories": ["cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Networks for Modeling Source Code Edits", "abstract": "Programming languages are emerging as a challenging and interesting domain\nfor machine learning. A core task, which has received significant attention in\nrecent years, is building generative models of source code. However, to our\nknowledge, previous generative models have always been framed in terms of\ngenerating static snapshots of code. In this work, we instead treat source code\nas a dynamic object and tackle the problem of modeling the edits that software\ndevelopers make to source code files. This requires extracting intent from\nprevious edits and leveraging it to generate subsequent edits. We develop\nseveral neural networks and use synthetic data to test their ability to learn\nchallenging edit patterns that require strong generalization. We then collect\nand train our models on a large-scale dataset of Google source code, consisting\nof millions of fine-grained edits from thousands of Python developers. From the\nmodeling perspective, our main conclusion is that a new composition of\nattentional and pointer network components provides the best overall\nperformance and scalability. From the application perspective, our results\nprovide preliminary evidence of the feasibility of developing tools that learn\nto predict future edits.", "published": "2019-04-04 23:06:09", "link": "http://arxiv.org/abs/1904.02818v1", "categories": ["cs.LG", "cs.CL", "cs.SE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Simple Question Answering with Subgraph Ranking and Joint-Scoring", "abstract": "Knowledge graph based simple question answering (KBSQA) is a major area of\nresearch within question answering. Although only dealing with simple\nquestions, i.e., questions that can be answered through a single knowledge base\n(KB) fact, this task is neither simple nor close to being solved. Targeting on\nthe two main steps, subgraph selection and fact selection, the research\ncommunity has developed sophisticated approaches. However, the importance of\nsubgraph ranking and leveraging the subject--relation dependency of a KB fact\nhave not been sufficiently explored. Motivated by this, we present a unified\nframework to describe and analyze existing approaches. Using this framework as\na starting point, we focus on two aspects: improving subgraph selection through\na novel ranking method and leveraging the subject--relation dependency by\nproposing a joint scoring CNN model with a novel loss function that enforces\nthe well-order of scores. Our methods achieve a new state of the art (85.44% in\naccuracy) on the SimpleQuestions dataset.", "published": "2019-04-04 02:20:50", "link": "http://arxiv.org/abs/1904.04049v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Deep Learning Sentiment Analysis of Amazon.com Reviews and Ratings", "abstract": "Our study employs sentiment analysis to evaluate the compatibility of\nAmazon.com reviews with their corresponding ratings. Sentiment analysis is the\ntask of identifying and classifying the sentiment expressed in a piece of text\nas being positive or negative. On e-commerce websites such as Amazon.com,\nconsumers can submit their reviews along with a specific polarity rating. In\nsome instances, there is a mismatch between the review and the rating. To\nidentify the reviews with mismatched ratings we performed sentiment analysis\nusing deep learning on Amazon.com product review data. Product reviews were\nconverted to vectors using paragraph vector, which then was used to train a\nrecurrent neural network with gated recurrent unit. Our model incorporated both\nsemantic relationship of review text and product information. We also developed\na web service application that predicts the rating score for a submitted review\nusing the trained model and if there is a mismatch between predicted rating\nscore and submitted rating score, it provides feedback to the reviewer.", "published": "2019-04-04 21:34:45", "link": "http://arxiv.org/abs/1904.04096v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Revisiting Adversarial Autoencoder for Unsupervised Word Translation\n  with Cycle Consistency and Improved Training", "abstract": "Adversarial training has shown impressive success in learning bilingual\ndictionary without any parallel data by mapping monolingual embeddings to a\nshared space. However, recent work has shown superior performance for\nnon-adversarial methods in more challenging language pairs. In this work, we\nrevisit adversarial autoencoder for unsupervised word translation and propose\ntwo novel extensions to it that yield more stable training and improved\nresults. Our method includes regularization terms to enforce cycle consistency\nand input reconstruction, and puts the target encoders as an adversary against\nthe corresponding discriminator. Extensive experimentations with European,\nnon-European and low-resource languages show that our method is more robust and\nachieves better performance than recently proposed adversarial and\nnon-adversarial approaches.", "published": "2019-04-04 12:46:07", "link": "http://arxiv.org/abs/1904.04116v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-modal Blind Source Separation with Microphones and Blinkies", "abstract": "We propose a blind source separation algorithm that jointly exploits\nmeasurements by a conventional microphone array and an ad hoc array of low-rate\nsound power sensors called blinkies. While providing less information than\nmicrophones, blinkies circumvent some difficulties of microphone arrays in\nterms of manufacturing, synchronization, and deployment. The algorithm is\nderived from a joint probabilistic model of the microphone and sound power\nmeasurements. We assume the separated sources to follow a time-varying\nspherical Gaussian distribution, and the non-negative power measurement\nspace-time matrix to have a low-rank structure. We show that alternating\nupdates similar to those of independent vector analysis and Itakura-Saito\nnon-negative matrix factorization decrease the negative log-likelihood of the\njoint distribution. The proposed algorithm is validated via numerical\nexperiments. Its median separation performance is found to be up to 8 dB more\nthan that of independent vector analysis, with significantly reduced\nvariability.", "published": "2019-04-04 03:34:46", "link": "http://arxiv.org/abs/1904.02334v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
