{"title": "Attention Focusing for Neural Machine Translation by Bridging Source and\n  Target Embeddings", "abstract": "In neural machine translation, a source sequence of words is encoded into a\nvector from which a target sequence is generated in the decoding phase.\nDifferently from statistical machine translation, the associations between\nsource words and their possible target counterparts are not explicitly stored.\nSource and target words are at the two ends of a long information processing\nprocedure, mediated by hidden states at both the source encoding and the target\ndecoding phases. This makes it possible that a source word is incorrectly\ntranslated into a target word that is not any of its admissible equivalent\ncounterparts in the target language.\n  In this paper, we seek to somewhat shorten the distance between source and\ntarget words in that procedure, and thus strengthen their association, by means\nof a method we term bridging source and target word embeddings. We experiment\nwith three strategies: (1) a source-side bridging model, where source word\nembeddings are moved one step closer to the output target sequence; (2) a\ntarget-side bridging model, which explores the more relevant source word\nembeddings for the prediction of the target sequence; and (3) a direct bridging\nmodel, which directly connects source and target word embeddings seeking to\nminimize errors in the translation of ones by the others.\n  Experiments and analysis presented in this paper demonstrate that the\nproposed bridging models are able to significantly improve quality of both\nsentence translation, in general, and alignment and translation of individual\nsource words with target words, in particular.", "published": "2017-11-15 02:12:34", "link": "http://arxiv.org/abs/1711.05380v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sequential Neural Encoder with Latent Structured Description for\n  Modeling Sentences", "abstract": "In this paper, we propose a sequential neural encoder with latent structured\ndescription (SNELSD) for modeling sentences. This model introduces latent\nchunk-level representations into conventional sequential neural encoders, i.e.,\nrecurrent neural networks (RNNs) with long short-term memory (LSTM) units, to\nconsider the compositionality of languages in semantic modeling. An SNELSD\nmodel has a hierarchical structure that includes a detection layer and a\ndescription layer. The detection layer predicts the boundaries of latent word\nchunks in an input sentence and derives a chunk-level vector for each word. The\ndescription layer utilizes modified LSTM units to process these chunk-level\nvectors in a recurrent manner and produces sequential encoding outputs. These\noutput vectors are further concatenated with word vectors or the outputs of a\nchain LSTM encoder to obtain the final sentence representation. All the model\nparameters are learned in an end-to-end manner without a dependency on\nadditional text chunking or syntax parsing. A natural language inference (NLI)\ntask and a sentiment analysis (SA) task are adopted to evaluate the performance\nof our proposed model. The experimental results demonstrate the effectiveness\nof the proposed SNELSD model on exploring task-dependent chunking patterns\nduring the semantic modeling of sentences. Furthermore, the proposed method\nachieves better performance than conventional chain LSTMs and tree-structured\nLSTMs on both tasks.", "published": "2017-11-15 07:13:13", "link": "http://arxiv.org/abs/1711.05433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aicyber's System for NLPCC 2017 Shared Task 2: Voting of Baselines", "abstract": "This paper presents Aicyber's system for NLPCC 2017 shared task 2. It is\nformed by a voting of three deep learning based system trained on\ncharacter-enhanced word vectors and a well known bag-of-word model.", "published": "2017-11-15 09:17:34", "link": "http://arxiv.org/abs/1711.05467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracking Typological Traits of Uralic Languages in Distributed Language\n  Representations", "abstract": "Although linguistic typology has a long history, computational approaches\nhave only recently gained popularity. The use of distributed representations in\ncomputational linguistics has also become increasingly popular. A recent\ndevelopment is to learn distributed representations of language, such that\ntypologically similar languages are spatially close to one another. Although\nempirical successes have been shown for such language representations, they\nhave not been subjected to much typological probing. In this paper, we first\nlook at whether this type of language representations are empirically useful\nfor model transfer between Uralic languages in deep neural networks. We then\ninvestigate which typological features are encoded in these representations by\nattempting to predict features in the World Atlas of Language Structures, at\nvarious stages of fine-tuning of the representations. We focus on Uralic\nlanguages, and find that some typological traits can be automatically inferred\nwith accuracies well above a strong baseline.", "published": "2017-11-15 09:20:43", "link": "http://arxiv.org/abs/1711.05468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Inner Properties of Multimodal Representation and Semantic\n  Compositionality with Brain-based Componential Semantics", "abstract": "Multimodal models have been proven to outperform text-based approaches on\nlearning semantic representations. However, it still remains unclear what\nproperties are encoded in multimodal representations, in what aspects do they\noutperform the single-modality representations, and what happened in the\nprocess of semantic compositionality in different input modalities. Considering\nthat multimodal models are originally motivated by human concept\nrepresentations, we assume that correlating multimodal representations with\nbrain-based semantics would interpret their inner properties to answer the\nabove questions. To that end, we propose simple interpretation methods based on\nbrain-based componential semantics. First we investigate the inner properties\nof multimodal representations by correlating them with corresponding\nbrain-based property vectors. Then we map the distributed vector space to the\ninterpretable brain-based componential space to explore the inner properties of\nsemantic compositionality. Ultimately, the present paper sheds light on the\nfundamental questions of natural language understanding, such as how to\nrepresent the meaning of words and how to combine word meanings into larger\nunits.", "published": "2017-11-15 12:18:44", "link": "http://arxiv.org/abs/1711.05516v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting and assessing contextual change in diachronic text documents\n  using context volatility", "abstract": "Terms in diachronic text corpora may exhibit a high degree of semantic\ndynamics that is only partially captured by the common notion of semantic\nchange. The new measure of context volatility that we propose models the degree\nby which terms change context in a text collection over time. The computation\nof context volatility for a word relies on the significance-values of its\nco-occurrent terms and the corresponding co-occurrence ranks in sequential time\nspans. We define a baseline and present an efficient computational approach in\norder to overcome problems related to computational issues in the data\nstructure. Results are evaluated both, on synthetic documents that are used to\nsimulate contextual changes, and a real example based on British newspaper\ntexts.", "published": "2017-11-15 12:42:48", "link": "http://arxiv.org/abs/1711.05538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue Act Recognition via CRF-Attentive Structured Network", "abstract": "Dialogue Act Recognition (DAR) is a challenging problem in dialogue\ninterpretation, which aims to attach semantic labels to utterances and\ncharacterize the speaker's intention. Currently, many existing approaches\nformulate the DAR problem ranging from multi-classification to structured\nprediction, which suffer from handcrafted feature extensions and attentive\ncontextual structural dependencies. In this paper, we consider the problem of\nDAR from the viewpoint of extending richer Conditional Random Field (CRF)\nstructural dependencies without abandoning end-to-end training. We incorporate\nhierarchical semantic inference with memory mechanism on the utterance\nmodeling. We then extend structured attention network to the linear-chain\nconditional random field layer which takes into account both contextual\nutterances and corresponding dialogue acts. The extensive experiments on two\nmajor benchmark datasets Switchboard Dialogue Act (SWDA) and Meeting Recorder\nDialogue Act (MRDA) datasets show that our method achieves better performance\nthan other state-of-the-art solutions to the problem. It is a remarkable fact\nthat our method is nearly close to the human annotator's performance on SWDA\nwithin 2% gap.", "published": "2017-11-15 13:43:02", "link": "http://arxiv.org/abs/1711.05568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Words are Malleable: Computing Semantic Shifts in Political and Media\n  Discourse", "abstract": "Recently, researchers started to pay attention to the detection of temporal\nshifts in the meaning of words. However, most (if not all) of these approaches\nrestricted their efforts to uncovering change over time, thus neglecting other\nvaluable dimensions such as social or political variability. We propose an\napproach for detecting semantic shifts between different viewpoints--broadly\ndefined as a set of texts that share a specific metadata feature, which can be\na time-period, but also a social entity such as a political party. For each\nviewpoint, we learn a semantic space in which each word is represented as a low\ndimensional neural embedded vector. The challenge is to compare the meaning of\na word in one space to its meaning in another space and measure the size of the\nsemantic shifts. We compare the effectiveness of a measure based on optimal\ntransformations between the two spaces with a measure based on the similarity\nof the neighbors of the word in the respective spaces. Our experiments\ndemonstrate that the combination of these two performs best. We show that the\nsemantic shifts not only occur over time, but also along different viewpoints\nin a short period of time. For evaluation, we demonstrate how this approach\ncaptures meaningful semantic shifts and can help improve other tasks such as\nthe contrastive viewpoint summarization and ideology detection (measured as\nclassification accuracy) in political texts. We also show that the two laws of\nsemantic change which were empirically shown to hold for temporal shifts also\nhold for shifts across viewpoints. These laws state that frequent words are\nless likely to shift meaning while words with many senses are more likely to do\nso.", "published": "2017-11-15 14:51:20", "link": "http://arxiv.org/abs/1711.05603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Morphological Expansion of Small Datasets for Improving\n  Word Embeddings", "abstract": "We present a language independent, unsupervised method for building word\nembeddings using morphological expansion of text. Our model handles the problem\nof data sparsity and yields improved word embeddings by relying on training\nword embeddings on artificially generated sentences. We evaluate our method\nusing small sized training sets on eleven test sets for the word similarity\ntask across seven languages. Further, for English, we evaluated the impacts of\nour approach using a large training set on three standard test sets. Our method\nimproved results across all languages.", "published": "2017-11-15 17:14:44", "link": "http://arxiv.org/abs/1711.05678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Unsupervised Approach for Mapping between Vector Spaces", "abstract": "We present a language independent, unsupervised approach for transforming\nword embeddings from source language to target language using a transformation\nmatrix. Our model handles the problem of data scarcity which is faced by many\nlanguages in the world and yields improved word embeddings for words in the\ntarget language by relying on transformed embeddings of words of the source\nlanguage. We initially evaluate our approach via word similarity tasks on a\nsimilar language pair - Hindi as source and Urdu as the target language, while\nwe also evaluate our method on French and German as target languages and\nEnglish as source language. Our approach improves the current state of the art\nresults - by 13% for French and 19% for German. For Urdu, we saw an increment\nof 16% over our initial baseline score. We further explore the prospects of our\napproach by applying it on multiple models of the same language and\ntransferring words between the two models, thus solving the problem of missing\nwords in a model. We evaluate this on word similarity and word analogy tasks.", "published": "2017-11-15 17:15:05", "link": "http://arxiv.org/abs/1711.05680v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with\n  Millions of Machine Translations", "abstract": "We describe PARANMT-50M, a dataset of more than 50 million English-English\nsentential paraphrase pairs. We generated the pairs automatically by using\nneural machine translation to translate the non-English side of a large\nparallel corpus, following Wieting et al. (2017). Our hope is that ParaNMT-50M\ncan be a valuable resource for paraphrase generation and can provide a rich\nsource of semantic knowledge to improve downstream natural language\nunderstanding tasks. To show its utility, we use ParaNMT-50M to train\nparaphrastic sentence embeddings that outperform all supervised systems on\nevery SemEval semantic textual similarity competition, in addition to showing\nhow it can be used for paraphrase generation.", "published": "2017-11-15 18:59:29", "link": "http://arxiv.org/abs/1711.05732v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Egregious Conversations between Customers and Virtual Agents", "abstract": "Virtual agents are becoming a prominent channel of interaction in customer\nservice. Not all customer interactions are smooth, however, and some can become\nalmost comically bad. In such instances, a human agent might need to step in\nand salvage the conversation. Detecting bad conversations is important since\ndisappointing customer service may threaten customer loyalty and impact\nrevenue. In this paper, we outline an approach to detecting such egregious\nconversations, using behavioral cues from the user, patterns in agent\nresponses, and user-agent interaction. Using logs of two commercial systems, we\nshow that using these features improves the detection F1-score by around 20%\nover using textual features alone. In addition, we show that those features are\ncommon across two quite different domains and, arguably, universal.", "published": "2017-11-15 19:56:24", "link": "http://arxiv.org/abs/1711.05780v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can clone detection support quality assessments of requirements\n  specifications?", "abstract": "Due to their pivotal role in software engineering, considerable effort is\nspent on the quality assurance of software requirements specifications. As they\nare mainly described in natural language, relatively few means of automated\nquality assessment exist. However, we found that clone detection, a technique\nwidely applied to source code, is promising to assess one important quality\naspect in an automated way, namely redundancy that stems from copy&paste\noperations. This paper describes a large-scale case study that applied clone\ndetection to 28 requirements specifications with a total of 8,667 pages. We\nreport on the amount of redundancy found in real-world specifications, discuss\nits nature as well as its consequences and evaluate in how far existing code\nclone detection approaches can be applied to assess the quality of requirements\nspecifications in practice.", "published": "2017-11-15 09:33:44", "link": "http://arxiv.org/abs/1711.05472v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "CMU LiveMedQA at TREC 2017 LiveQA: A Consumer Health Question Answering\n  System", "abstract": "In this paper, we present LiveMedQA, a question answering system that is\noptimized for consumer health question. On top of the general QA system\npipeline, we introduce several new features that aim to exploit domain-specific\nknowledge and entity structures for better performance. This includes a\nquestion type/focus analyzer based on deep text classification model, a\ntree-based knowledge graph for answer generation and a complementary\nstructure-aware searcher for answer retrieval. LiveMedQA system is evaluated in\nthe TREC 2017 LiveQA medical subtask, where it received an average score of\n0.356 on a 3 point scale. Evaluation results revealed 3 substantial drawbacks\nin current LiveMedQA system, based on which we provide a detailed discussion\nand propose a few solutions that constitute the main focus of our subsequent\nwork.", "published": "2017-11-15 20:26:42", "link": "http://arxiv.org/abs/1711.05789v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Finer Grained Entity Typing with TypeNet", "abstract": "We consider the challenging problem of entity typing over an extremely fine\ngrained set of types, wherein a single mention or entity can have many\nsimultaneous and often hierarchically-structured types. Despite the importance\nof the problem, there is a relative lack of resources in the form of\nfine-grained, deep type hierarchies aligned to existing knowledge bases. In\nresponse, we introduce TypeNet, a dataset of entity types consisting of over\n1941 types organized in a hierarchy, obtained by manually annotating a mapping\nfrom 1081 Freebase types to WordNet. We also experiment with several models\ncomparable to state-of-the-art systems and explore techniques to incorporate a\nstructure loss on the hierarchy with the standard mention typing loss, as a\nfirst step towards future research on this dataset.", "published": "2017-11-15 20:37:44", "link": "http://arxiv.org/abs/1711.05795v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Go for a Walk and Arrive at the Answer: Reasoning Over Paths in\n  Knowledge Bases using Reinforcement Learning", "abstract": "Knowledge bases (KB), both automatically and manually constructed, are often\nincomplete --- many valid facts can be inferred from the KB by synthesizing\nexisting information. A popular approach to KB completion is to infer new\nrelations by combinatory reasoning over the information found along other paths\nconnecting a pair of entities. Given the enormous size of KBs and the\nexponential number of paths, previous path-based models have considered only\nthe problem of predicting a missing relation given two entities or evaluating\nthe truth of a proposed triple. Additionally, these methods have traditionally\nused random paths between fixed entity pairs or more recently learned to pick\npaths between them. We propose a new algorithm MINERVA, which addresses the\nmuch more difficult and practical task of answering questions where the\nrelation is known, but only one entity. Since random walks are impractical in a\nsetting with combinatorially many destinations from a start node, we present a\nneural reinforcement learning approach which learns how to navigate the graph\nconditioned on the input query to find predictive paths. Empirically, this\napproach obtains state-of-the-art results on several datasets, significantly\noutperforming prior methods.", "published": "2017-11-15 23:45:18", "link": "http://arxiv.org/abs/1711.05851v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sentiment analysis of twitter data", "abstract": "Social networks are the main resources to gather information about people's\nopinion and sentiments towards different topics as they spend hours daily on\nsocial media and share their opinion. In this technical paper, we show the\napplication of sentimental analysis and how to connect to Twitter and run\nsentimental analysis queries. We run experiments on different queries from\npolitics to humanity and show the interesting results. We realized that the\nneutral sentiments for tweets are significantly high which clearly shows the\nlimitations of the current works.", "published": "2017-11-15 17:32:59", "link": "http://arxiv.org/abs/1711.10377v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Recurrent Neural Networks as Weighted Language Recognizers", "abstract": "We investigate the computational complexity of various problems for simple\nrecurrent neural networks (RNNs) as formal models for recognizing weighted\nlanguages. We focus on the single-layer, ReLU-activation, rational-weight RNNs\nwith softmax, which are commonly used in natural language processing\napplications. We show that most problems for such RNNs are undecidable,\nincluding consistency, equivalence, minimization, and the determination of the\nhighest-weighted string. However, for consistent RNNs the last problem becomes\ndecidable, although the solution length can surpass all computable bounds. If\nadditionally the string is limited to polynomial length, the problem becomes\nNP-complete and APX-hard. In summary, this shows that approximations and\nheuristic algorithms are necessary in practical applications of those RNNs.", "published": "2017-11-15 04:54:08", "link": "http://arxiv.org/abs/1711.05408v2", "categories": ["cs.FL", "cs.CC", "cs.CL"], "primary_category": "cs.FL"}
{"title": "Human and Machine Speaker Recognition Based on Short Trivial Events", "abstract": "Trivial events are ubiquitous in human to human conversations, e.g., cough,\nlaugh and sniff. Compared to regular speech, these trivial events are usually\nshort and unclear, thus generally regarded as not speaker discriminative and so\nare largely ignored by present speaker recognition research. However, these\ntrivial events are highly valuable in some particular circumstances such as\nforensic examination, as they are less subjected to intentional change, so can\nbe used to discover the genuine speaker from disguised speech. In this paper,\nwe collect a trivial event speech database that involves 75 speakers and 6\ntypes of events, and report preliminary speaker recognition results on this\ndatabase, by both human listeners and machines. Particularly, the deep feature\nlearning technique recently proposed by our group is utilized to analyze and\nrecognize the trivial events, which leads to acceptable equal error rates\n(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.\nComparing different types of events, 'hmm' seems more speaker discriminative.", "published": "2017-11-15 08:21:20", "link": "http://arxiv.org/abs/1711.05443v3", "categories": ["cs.SD", "cs.CL", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Emotional End-to-End Neural Speech Synthesizer", "abstract": "In this paper, we introduce an emotional speech synthesizer based on the\nrecent end-to-end neural model, named Tacotron. Despite its benefits, we found\nthat the original Tacotron suffers from the exposure bias problem and\nirregularity of the attention alignment. Later, we address the problem by\nutilization of context vector and residual connection at recurrent neural\nnetworks (RNNs). Our experiments showed that the model could successfully train\nand generate speech for given emotion labels.", "published": "2017-11-15 08:27:35", "link": "http://arxiv.org/abs/1711.05447v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Lattice Rescoring Strategies for Long Short Term Memory Language Models\n  in Speech Recognition", "abstract": "Recurrent neural network (RNN) language models (LMs) and Long Short Term\nMemory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform\ntraditional N-gram LMs on speech recognition tasks. However, these models are\ncomputationally more expensive than N-gram LMs for decoding, and thus,\nchallenging to integrate into speech recognizers. Recent research has proposed\nthe use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an\nefficient strategy to integrate these models into a speech recognition system.\nIn this paper, we evaluate existing lattice rescoring algorithms along with new\nvariants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs\nreduces the word error rate (WER) for this task by 8\\% relative to the WER\nobtained using an N-gram LM.", "published": "2017-11-15 08:30:56", "link": "http://arxiv.org/abs/1711.05448v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time", "abstract": "Dynamic topic modeling facilitates the identification of topical trends over\ntime in temporal collections of unstructured documents. We introduce a novel\nunsupervised neural dynamic topic model named as Recurrent Neural\nNetwork-Replicated Softmax Model (RNNRSM), where the discovered topics at each\ntime influence the topic discovery in the subsequent time steps. We account for\nthe temporal ordering of documents by explicitly modeling a joint distribution\nof latent topical dependencies over time, using distributional estimators with\ntemporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP\nresearch, we demonstrate that compared to state-of-the art topic models, RNNRSM\nshows better generalization, topic interpretation, evolution and trends. We\nalso introduce a metric (named as SPAN) to quantify the capability of dynamic\ntopic model to capture word evolution in topics over time.", "published": "2017-11-15 15:33:59", "link": "http://arxiv.org/abs/1711.05626v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for\n  Task-Oriented Dialogue Systems", "abstract": "We present a new algorithm that significantly improves the efficiency of\nexploration for deep Q-learning agents in dialogue systems. Our agents explore\nvia Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop\nneural network. Our algorithm learns much faster than common exploration\nstrategies such as \\epsilon-greedy, Boltzmann, bootstrapping, and\nintrinsic-reward-based ones. Additionally, we show that spiking the replay\nbuffer with experiences from just a few successful episodes can make Q-learning\nfeasible when it might otherwise fail.", "published": "2017-11-15 18:23:48", "link": "http://arxiv.org/abs/1711.05715v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Pitch and timbre discrimination at wave-to-spike transition in the\n  cochlea", "abstract": "A new definition of musical pitch is proposed. A Finite-Difference Time\nDomain (FDTM) model of the cochlea is used to calculate spike trains caused by\ntone complexes and by a recorded classical guitar tone. All harmonic tone\ncomplexes, musical notes, show a narrow-band Interspike Interval (ISI) pattern\nat the respective fundamental frequency of the tone complex. Still this\nfundamental frequency is not only present at the bark band holding the\nrespective best frequency of this fundamental frequency, but rather at all bark\nbands driven by the tone complex partials. This is caused by drop-outs in the\nbasically regular, periodic spike train in the respective bands. These\ndrop-outs are caused by the energy distribution in the wave form, where time\nspans of low energy are not able to drive spikes. The presence of the\nfundamental periodicity in all bark bands can be interpreted as pitch. Contrary\nto pitch, timbre is represented as a wide distribution of different ISIs over\nbark bands. The definition of pitch is shown to also works with residue\npitches. The spike drop-outs in times of low energy of the wave form also cause\nundertones, integer multiple subdivisions in periodicity, but in no case\novertones can appear. This might explain the musical minor scale, which was\nproposed to be caused by undertones already in 1880 by Hugo Riemann, still\nuntil now without knowledge about any physical realization of such undertones.", "published": "2017-11-15 14:44:27", "link": "http://arxiv.org/abs/1711.05596v1", "categories": ["q-bio.NC", "eess.AS"], "primary_category": "q-bio.NC"}
{"title": "Sound Event Detection in Synthetic Audio: Analysis of the DCASE 2016\n  Task Results", "abstract": "As part of the 2016 public evaluation challenge on Detection and\nClassification of Acoustic Scenes and Events (DCASE 2016), the second task\nfocused on evaluating sound event detection systems using synthetic mixtures of\noffice sounds. This task, which follows the `Event Detection - Office\nSynthetic' task of DCASE 2013, studies the behaviour of tested algorithms when\nfacing controlled levels of audio complexity with respect to background noise\nand polyphony/density, with the added benefit of a very accurate ground truth.\nThis paper presents the task formulation, evaluation metrics, submitted\nsystems, and provides a statistical analysis of the results achieved, with\nrespect to various aspects of the evaluation dataset.", "published": "2017-11-15 12:59:13", "link": "http://arxiv.org/abs/1711.05551v1", "categories": ["eess.AS", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Exploring Speech Enhancement with Generative Adversarial Networks for\n  Robust Speech Recognition", "abstract": "We investigate the effectiveness of generative adversarial networks (GANs)\nfor speech enhancement, in the context of improving noise robustness of\nautomatic speech recognition (ASR) systems. Prior work demonstrates that GANs\ncan effectively suppress additive noise in raw waveform speech signals,\nimproving perceptual quality metrics; however this technique was not justified\nin the context of ASR. In this work, we conduct a detailed study to measure the\neffectiveness of GANs in enhancing speech contaminated by both additive and\nreverberant noise. Motivated by recent advances in image processing, we propose\noperating GANs on log-Mel filterbank spectra instead of waveforms, which\nrequires less computation and is more robust to reverberant noise. While GAN\nenhancement improves the performance of a clean-trained ASR system on noisy\nspeech, it falls short of the performance achieved by conventional multi-style\ntraining (MTR). By appending the GAN-enhanced features to the noisy inputs and\nretraining, we achieve a 7% WER improvement relative to the MTR system.", "published": "2017-11-15 19:00:07", "link": "http://arxiv.org/abs/1711.05747v2", "categories": ["cs.SD", "cs.LG", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
