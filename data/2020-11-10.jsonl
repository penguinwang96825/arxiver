{"title": "Simultaneous Speech-to-Speech Translation System with Neural Incremental\n  ASR, MT, and TTS", "abstract": "This paper presents a newly developed, simultaneous neural speech-to-speech\ntranslation system and its evaluation. The system consists of three\nfully-incremental neural processing modules for automatic speech recognition\n(ASR), machine translation (MT), and text-to-speech synthesis (TTS). We\ninvestigated its overall latency in the system's Ear-Voice Span and speaking\nlatency along with module-level performance.", "published": "2020-11-10 00:40:20", "link": "http://arxiv.org/abs/2011.04845v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Inference in Context -- Investigating Contextual\n  Reasoning over Long Texts", "abstract": "Natural language inference (NLI) is a fundamental NLP task, investigating the\nentailment relationship between two texts. Popular NLI datasets present the\ntask at sentence-level. While adequate for testing semantic representations,\nthey fall short for testing contextual reasoning over long texts, which is a\nnatural part of the human inference process. We introduce ConTRoL, a new\ndataset for ConTextual Reasoning over Long texts. Consisting of 8,325\nexpert-designed \"context-hypothesis\" pairs with gold labels, ConTRoL is a\npassage-level NLI dataset with a focus on complex contextual reasoning types\nsuch as logical reasoning. It is derived from competitive selection and\nrecruitment test (verbal reasoning test) for police recruitment, with expert\nlevel quality. Compared with previous NLI benchmarks, the materials in ConTRoL\nare much more challenging, involving a range of reasoning types. Empirical\nresults show that state-of-the-art language models perform by far worse than\neducated humans. Our dataset can also serve as a testing-set for downstream\ntasks like Checking Factual Correctness of Summaries.", "published": "2020-11-10 02:31:31", "link": "http://arxiv.org/abs/2011.04864v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Do You Need Billions of Words of Pretraining Data?", "abstract": "NLP is currently dominated by general-purpose pretrained language models like\nRoBERTa, which achieve strong performance on NLU tasks through pretraining on\nbillions of words. But what exact knowledge or skills do Transformer LMs learn\nfrom large-scale pretraining that they cannot learn from less data? We adopt\nfour probing methods---classifier probing, information-theoretic probing,\nunsupervised relative acceptability judgment, and fine-tuning on NLU\ntasks---and draw learning curves that track the growth of these different\nmeasures of linguistic ability with respect to pretraining data volume using\nthe MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B\nwords. We find that LMs require only about 10M or 100M words to learn\nrepresentations that reliably encode most syntactic and semantic features we\ntest. A much larger quantity of data is needed in order to acquire enough\ncommonsense knowledge and other skills required to master typical downstream\nNLU tasks. The results suggest that, while the ability to encode linguistic\nfeatures is almost certainly necessary for language understanding, it is likely\nthat other forms of knowledge are the major drivers of recent improvements in\nlanguage understanding among large pretrained models.", "published": "2020-11-10 07:16:18", "link": "http://arxiv.org/abs/2011.04946v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Social Support Expressed in Post Titles Elicit Comments in Online\n  Substance Use Recovery Forums?", "abstract": "Individuals recovering from substance use often seek social support\n(emotional and informational) on online recovery forums, where they can both\nwrite and comment on posts, expressing their struggles and successes. A common\nchallenge in these forums is that certain posts (some of which may be support\nseeking) receive no comments. In this work, we use data from two Reddit\nsubstance recovery forums:/r/Leaves and/r/OpiatesRecovery, to determine the\nrelationship between the social supports expressed in the titles of posts and\nthe number of comments they receive. We show that the types of social support\nexpressed in post titles that elicit comments vary from one substance use\nrecovery forum to the other.", "published": "2020-11-10 14:00:42", "link": "http://arxiv.org/abs/2011.05103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level\n  Annotation", "abstract": "In this paper we propose a multi-task sequence prediction system, based on\nrecurrent neural networks and used to annotate on multiple levels an Arabizi\nTunisian corpus. The annotation performed are text classification,\ntokenization, PoS tagging and encoding of Tunisian Arabizi into CODA* Arabic\northography. The system is learned to predict all the annotation levels in\ncascade, starting from Arabizi input. We evaluate the system on the TIGER\nGerman corpus, suitably converting data to have a multi-task problem, in order\nto show the effectiveness of our neural architecture. We show also how we used\nthe system in order to annotate a Tunisian Arabizi corpus, which has been\nafterwards manually corrected and used to further evaluate sequence models on\nTunisian data. Our system is developed for the Fairseq framework, which allows\nfor a fast and easy use for any other sequence prediction problem.", "published": "2020-11-10 15:19:01", "link": "http://arxiv.org/abs/2011.05152v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the State of Social Media Data for Mental Health Research", "abstract": "Data-driven methods for mental health treatment and surveillance have become\na major focus in computational science research in the last decade. However,\nprogress in the domain, in terms of both medical understanding and system\nperformance, remains bounded by the availability of adequate data. Prior\nsystematic reviews have not necessarily made it possible to measure the degree\nto which data-related challenges have affected research progress. In this\npaper, we offer an analysis specifically on the state of social media data that\nexists for conducting mental health research. We do so by introducing an\nopen-source directory of mental health datasets, annotated using a standardized\nschema to facilitate meta-analysis.", "published": "2020-11-10 16:45:52", "link": "http://arxiv.org/abs/2011.05233v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Preemptive Detection of Depression and Anxiety in Twitter", "abstract": "Depression and anxiety are psychiatric disorders that are observed in many\nareas of everyday life. For example, these disorders manifest themselves\nsomewhat frequently in texts written by nondiagnosed users in social media.\nHowever, detecting users with these conditions is not a straightforward task as\nthey may not explicitly talk about their mental state, and if they do,\ncontextual cues such as immediacy must be taken into account. When available,\nlinguistic flags pointing to probable anxiety or depression could be used by\nmedical experts to write better guidelines and treatments. In this paper, we\ndevelop a dataset designed to foster research in depression and anxiety\ndetection in Twitter, framing the detection task as a binary tweet\nclassification problem. We then apply state-of-the-art classification models to\nthis dataset, providing a competitive set of baselines alongside qualitative\nerror analysis. Our results show that language models perform reasonably well,\nand better than more traditional baselines. Nonetheless, there is clear room\nfor improvement, particularly with unbalanced training sets and in cases where\nseemingly obvious linguistic cues (keywords) are used counter-intuitively.", "published": "2020-11-10 17:17:23", "link": "http://arxiv.org/abs/2011.05249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medical Knowledge-enriched Textual Entailment Framework", "abstract": "One of the cardinal tasks in achieving robust medical question answering\nsystems is textual entailment. The existing approaches make use of an ensemble\nof pre-trained language models or data augmentation, often to clock higher\nnumbers on the validation metrics. However, two major shortcomings impede\nhigher success in identifying entailment: (1) understanding the focus/intent of\nthe question and (2) ability to utilize the real-world background knowledge to\ncapture the context beyond the sentence. In this paper, we present a novel\nMedical Knowledge-Enriched Textual Entailment framework that allows the model\nto acquire a semantic and global representation of the input medical text with\nthe help of a relevant domain-specific knowledge graph. We evaluate our\nframework on the benchmark MEDIQA-RQE dataset and manifest that the use of\nknowledge enriched dual-encoding mechanism help in achieving an absolute\nimprovement of 8.27% over SOTA language models. We have made the source code\navailable here.", "published": "2020-11-10 17:25:27", "link": "http://arxiv.org/abs/2011.05257v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation for Extremely Low-Resource African Languages:\n  A Case Study on Bambara", "abstract": "Low-resource languages present unique challenges to (neural) machine\ntranslation. We discuss the case of Bambara, a Mande language for which\ntraining data is scarce and requires significant amounts of pre-processing.\nMore than the linguistic situation of Bambara itself, the socio-cultural\ncontext within which Bambara speakers live poses challenges for automated\nprocessing of this language. In this paper, we present the first parallel data\nset for machine translation of Bambara into and from English and French and the\nfirst benchmark results on machine translation to and from Bambara. We discuss\nchallenges in working with low-resource languages and propose strategies to\ncope with data scarcity in low-resource machine translation (MT).", "published": "2020-11-10 18:04:26", "link": "http://arxiv.org/abs/2011.05284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DoLFIn: Distributions over Latent Features for Interpretability", "abstract": "Interpreting the inner workings of neural models is a key step in ensuring\nthe robustness and trustworthiness of the models, but work on neural network\ninterpretability typically faces a trade-off: either the models are too\nconstrained to be very useful, or the solutions found by the models are too\ncomplex to interpret. We propose a novel strategy for achieving\ninterpretability that -- in our experiments -- avoids this trade-off. Our\napproach builds on the success of using probability as the central quantity,\nsuch as for instance within the attention mechanism. In our architecture,\nDoLFIn (Distributions over Latent Features for Interpretability), we do no\ndetermine beforehand what each feature represents, and features go altogether\ninto an unordered set. Each feature has an associated probability ranging from\n0 to 1, weighing its importance for further processing. We show that, unlike\nattention and saliency map approaches, this set-up makes it straight-forward to\ncompute the probability with which an input component supports the decision the\nneural model makes. To demonstrate the usefulness of the approach, we apply\nDoLFIn to text classification, and show that DoLFIn not only provides\ninterpretable solutions, but even slightly outperforms the classical CNN and\nBiLSTM text classifiers on the SST2 and AG-news datasets.", "published": "2020-11-10 18:32:53", "link": "http://arxiv.org/abs/2011.05295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OCR Post Correction for Endangered Language Texts", "abstract": "There is little to no data available to build natural language processing\nmodels for most endangered languages. However, textual data in these languages\noften exists in formats that are not machine-readable, such as paper books and\nscanned images. In this work, we address the task of extracting text from these\nresources. We create a benchmark dataset of transcriptions for scanned books in\nthree critically endangered languages and present a systematic analysis of how\ngeneral-purpose OCR tools are not robust to the data-scarce setting of\nendangered languages. We develop an OCR post-correction method tailored to ease\ntraining in this data-scarce setting, reducing the recognition error rate by\n34% on average across the three languages.", "published": "2020-11-10 21:21:08", "link": "http://arxiv.org/abs/2011.05402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual AMR-to-Text Generation", "abstract": "Generating text from structured data is challenging because it requires\nbridging the gap between (i) structure and natural language (NL) and (ii)\nsemantically underspecified input and fully specified NL output. Multilingual\ngeneration brings in an additional challenge: that of generating into languages\nwith varied word order and morphological properties. In this work, we focus on\nAbstract Meaning Representations (AMRs) as structured input, where previous\nresearch has overwhelmingly focused on generating only into English. We\nleverage advances in cross-lingual embeddings, pretraining, and multilingual\nmodels to create multilingual AMR-to-text models that generate in twenty one\ndifferent languages. For eighteen languages, based on automatic metrics, our\nmultilingual models surpass baselines that generate into a single language. We\nanalyse the ability of our multilingual models to accurately capture morphology\nand word order using human evaluation, and find that native speakers judge our\ngenerations to be fluent.", "published": "2020-11-10 22:47:14", "link": "http://arxiv.org/abs/2011.05443v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Fact Checking Briefs", "abstract": "Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.", "published": "2020-11-10 23:02:47", "link": "http://arxiv.org/abs/2011.05448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Unsupervised Machine Translation To Adversarial Text Generation", "abstract": "We present a self-attention based bilingual adversarial text generator\n(B-GAN) which can learn to generate text from the encoder representation of an\nunsupervised neural machine translation system. B-GAN is able to generate a\ndistributed latent space representation which can be paired with an attention\nbased decoder to generate fluent sentences. When trained on an encoder shared\nbetween two languages and paired with the appropriate decoder, it can generate\nsentences in either language. B-GAN is trained using a combination of\nreconstruction loss for auto-encoder, a cross domain loss for translation and a\nGAN based adversarial loss for text generation. We demonstrate that B-GAN,\ntrained on monolingual corpora only using multiple losses, generates more\nfluent sentences compared to monolingual baselines while effectively using half\nthe number of parameters.", "published": "2020-11-10 23:03:50", "link": "http://arxiv.org/abs/2011.05449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pretraining Strategies, Waveform Model Choice, and Acoustic\n  Configurations for Multi-Speaker End-to-End Speech Synthesis", "abstract": "We explore pretraining strategies including choice of base corpus with the\naim of choosing the best strategy for zero-shot multi-speaker end-to-end\nsynthesis. We also examine choice of neural vocoder for waveform synthesis, as\nwell as acoustic configurations used for mel spectrograms and final audio\noutput. We find that fine-tuning a multi-speaker model from found audiobook\ndata that has passed a simple quality threshold can improve naturalness and\nsimilarity to unseen target speakers of synthetic speech. Additionally, we find\nthat listeners can discern between a 16kHz and 24kHz sampling rate, and that\nWaveRNN produces output waveforms of a comparable quality to WaveNet, with a\nfaster inference time.", "published": "2020-11-10 00:19:04", "link": "http://arxiv.org/abs/2011.04839v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Multi-document Summarization via Deep Learning Techniques: A Survey", "abstract": "Multi-document summarization (MDS) is an effective tool for information\naggregation that generates an informative and concise summary from a cluster of\ntopic-related documents. Our survey, the first of its kind, systematically\noverviews the recent deep learning based MDS models. We propose a novel\ntaxonomy to summarize the design strategies of neural networks and conduct a\ncomprehensive summary of the state-of-the-art. We highlight the differences\nbetween various objective functions that are rarely discussed in the existing\nliterature. Finally, we propose several future directions pertaining to this\nnew and exciting field.", "published": "2020-11-10 00:35:46", "link": "http://arxiv.org/abs/2011.04843v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Transfer Learning Approach for Dialogue Act Classification of GitHub\n  Issue Comments", "abstract": "Social coding platforms, such as GitHub, serve as laboratories for studying\ncollaborative problem solving in open source software development; a key\nfeature is their ability to support issue reporting which is used by teams to\ndiscuss tasks and ideas. Analyzing the dialogue between team members, as\nexpressed in issue comments, can yield important insights about the performance\nof virtual teams. This paper presents a transfer learning approach for\nperforming dialogue act classification on issue comments. Since no large\nlabeled corpus of GitHub issue comments exists, employing transfer learning\nenables us to leverage standard dialogue act datasets in combination with our\nown GitHub comment dataset. We compare the performance of several word and\nsentence level encoding models including Global Vectors for Word\nRepresentations (GloVe), Universal Sentence Encoder (USE), and Bidirectional\nEncoder Representations from Transformers (BERT). Being able to map the issue\ncomments to dialogue acts is a useful stepping stone towards understanding\ncognitive team processes.", "published": "2020-11-10 02:56:18", "link": "http://arxiv.org/abs/2011.04867v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Determining Question-Answer Plausibility in Crowdsourced Datasets Using\n  Multi-Task Learning", "abstract": "Datasets extracted from social networks and online forums are often prone to\nthe pitfalls of natural language, namely the presence of unstructured and noisy\ndata. In this work, we seek to enable the collection of high-quality\nquestion-answer datasets from social media by proposing a novel task for\nautomated quality analysis and data cleaning: question-answer (QA)\nplausibility. Given a machine or user-generated question and a crowd-sourced\nresponse from a social media user, we determine if the question and response\nare valid; if so, we identify the answer within the free-form response. We\ndesign BERT-based models to perform the QA plausibility task, and we evaluate\nthe ability of our models to generate a clean, usable question-answer dataset.\nOur highest-performing approach consists of a single-task model which\ndetermines the plausibility of the question, followed by a multi-task model\nwhich evaluates the plausibility of the response as well as extracts answers\n(Question Plausibility AUROC=0.75, Response Plausibility AUROC=0.78, Answer\nExtraction F1=0.665).", "published": "2020-11-10 04:11:44", "link": "http://arxiv.org/abs/2011.04883v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "To What Degree Can Language Borders Be Blurred In BERT-based\n  Multilingual Spoken Language Understanding?", "abstract": "This paper addresses the question as to what degree a BERT-based multilingual\nSpoken Language Understanding (SLU) model can transfer knowledge across\nlanguages. Through experiments we will show that, although it works\nsubstantially well even on distant language groups, there is still a gap to the\nideal multilingual performance. In addition, we propose a novel BERT-based\nadversarial model architecture to learn language-shared and language-specific\nrepresentations for multilingual SLU. Our experimental results prove that the\nproposed model is capable of narrowing the gap to the ideal multilingual\nperformance.", "published": "2020-11-10 09:59:24", "link": "http://arxiv.org/abs/2011.05007v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Translating Similar Languages: Role of Mutual Intelligibility in\n  Multilingual Transformers", "abstract": "We investigate different approaches to translate between similar languages\nunder low resource conditions, as part of our contribution to the WMT 2020\nSimilar Languages Translation Shared Task. We submitted Transformer-based\nbilingual and multilingual systems for all language pairs, in the two\ndirections. We also leverage back-translation for one of the language pairs,\nacquiring an improvement of more than 3 BLEU points. We interpret our results\nin light of the degree of mutual intelligibility (based on Jaccard similarity)\nbetween each pair, finding a positive correlation between mutual\nintelligibility and model performance. Our Spanish-Catalan model has the best\nperformance of all the five language pairs. Except for the case of\nHindi-Marathi, our bilingual models achieve better performance than the\nmultilingual models on all pairs.", "published": "2020-11-10 10:58:38", "link": "http://arxiv.org/abs/2011.05037v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Biomedical Information Extraction for Disease Gene Prioritization", "abstract": "We introduce a biomedical information extraction (IE) pipeline that extracts\nbiological relationships from text and demonstrate that its components, such as\nnamed entity recognition (NER) and relation extraction (RE), outperform\nstate-of-the-art in BioNLP. We apply it to tens of millions of PubMed abstracts\nto extract protein-protein interactions (PPIs) and augment these extractions to\na biomedical knowledge graph that already contains PPIs extracted from STRING,\nthe leading structured PPI database. We show that, despite already containing\nPPIs from an established structured source, augmenting our own IE-based\nextractions to the graph allows us to predict novel disease-gene associations\nwith a 20% relative increase in hit@30, an important step towards developing\ndrug targets for uncured diseases.", "published": "2020-11-10 15:38:42", "link": "http://arxiv.org/abs/2011.05188v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "UmBERTo-MTSA @ AcCompl-It: Improving Complexity and Acceptability\n  Prediction with Multi-task Learning on Self-Supervised Annotations", "abstract": "This work describes a self-supervised data augmentation approach used to\nimprove learning models' performances when only a moderate amount of labeled\ndata is available. Multiple copies of the original model are initially trained\non the downstream task. Their predictions are then used to annotate a large set\nof unlabeled examples. Finally, multi-task training is performed on the\nparallel annotations of the resulting training set, and final scores are\nobtained by averaging annotator-specific head predictions. Neural language\nmodels are fine-tuned using this procedure in the context of the AcCompl-it\nshared task at EVALITA 2020, obtaining considerable improvements in prediction\nquality.", "published": "2020-11-10 15:50:37", "link": "http://arxiv.org/abs/2011.05197v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7; J.5"], "primary_category": "cs.CL"}
{"title": "E.T.: Entity-Transformers. Coreference augmented Neural Language Model\n  for richer mention representations via Entity-Transformer blocks", "abstract": "In the last decade, the field of Neural Language Modelling has witnessed\nenormous changes, with the development of novel models through the use of\nTransformer architectures. However, even these models struggle to model long\nsequences due to memory constraints and increasing computational complexity.\nCoreference annotations over the training data can provide context far beyond\nthe modelling limitations of such language models. In this paper we present an\nextension over the Transformer-block architecture used in neural language\nmodels, specifically in GPT2, in order to incorporate entity annotations during\ntraining. Our model, GPT2E, extends the Transformer layers architecture of GPT2\nto Entity-Transformers, an architecture designed to handle coreference\ninformation when present. To that end, we achieve richer representations for\nentity mentions, with insignificant training cost. We show the comparative\nmodel performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL\n2012 and LAMBADA datasets as well as the key differences in the entity\nrepresentations and their effects in downstream tasks such as Named Entity\nRecognition. Furthermore, our approach can be adopted by the majority of\nTransformer-based language models.", "published": "2020-11-10 22:28:00", "link": "http://arxiv.org/abs/2011.05431v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Resource Constrained Dialog Policy Learning via Differentiable Inductive\n  Logic Programming", "abstract": "Motivated by the needs of resource constrained dialog policy learning, we\nintroduce dialog policy via differentiable inductive logic (DILOG). We explore\nthe tasks of one-shot learning and zero-shot domain transfer with DILOG on\nSimDial and MultiWoZ. Using a single representative dialog from the restaurant\ndomain, we train DILOG on the SimDial dataset and obtain 99+% in-domain test\naccuracy. We also show that the trained DILOG zero-shot transfers to all other\ndomains with 99+% accuracy, proving the suitability of DILOG to slot-filling\ndialogs. We further extend our study to the MultiWoZ dataset achieving 90+%\ninform and success metrics. We also observe that these metrics are not\ncapturing some of the shortcomings of DILOG in terms of false positives,\nprompting us to measure an auxiliary Action F1 score. We show that DILOG is\n100x more data efficient than state-of-the-art neural approaches on MultiWoZ\nwhile achieving similar performance metrics. We conclude with a discussion on\nthe strengths and weaknesses of DILOG.", "published": "2020-11-10 23:28:00", "link": "http://arxiv.org/abs/2011.05457v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on Text-Independent Speaker Verification based on the\n  GE2E Method", "abstract": "While many researchers in the speaker recognition area have started to\nreplace the former classical state-of-the-art methods with deep learning\ntechniques, some of the traditional i-vector-based methods are still\nstate-of-the-art in the context of text-independent speaker verification.\nGoogle's Generalized End-to-End Loss for Speaker Verification (GE2E), a deep\nlearning-based technique using long short-term memory units, has recently\ngained a lot of attention due to its speed in convergence and generalization.\nIn this study, we aim at further studying the GE2E method and comparing\ndifferent scenarios in order to investigate all of its aspects. Various\nexperiments including the effects of a random sampling of test and enrollment\nutterances, test utterance duration, and the number of enrollment utterances\nare discussed in this article. Furthermore, we compare the GE2E method with the\nbaseline state-of-the-art i-vector-based methods for text-independent speaker\nverification and show that it outperforms them by resulting in lower error\nrates while being end-to-end and requiring less training time for convergence.", "published": "2020-11-10 17:17:06", "link": "http://arxiv.org/abs/2011.04896v4", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Detecting Social Media Manipulation in Low-Resource Languages", "abstract": "Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data -- the\nnorm when dealing with detecting malicious activity in online platforms.", "published": "2020-11-10 19:38:03", "link": "http://arxiv.org/abs/2011.05367v2", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Don't Read Too Much into It: Adaptive Computation for Open-Domain\n  Question Answering", "abstract": "Most approaches to Open-Domain Question Answering consist of a light-weight\nretriever that selects a set of candidate passages, and a computationally\nexpensive reader that examines the passages to identify the correct answer.\nPrevious works have shown that as the number of retrieved passages increases,\nso does the performance of the reader. However, they assume all retrieved\npassages are of equal importance and allocate the same amount of computation to\nthem, leading to a substantial increase in computational cost. To reduce this\ncost, we propose the use of adaptive computation to control the computational\nbudget allocated for the passages to be read. We first introduce a technique\noperating on individual passages in isolation which relies on anytime\nprediction and a per-layer estimation of an early exit probability. We then\nintroduce SkylineBuilder, an approach for dynamically deciding on which passage\nto allocate computation at each step, based on a resource allocation policy\ntrained via reinforcement learning. Our results on SQuAD-Open show that\nadaptive computation with global prioritisation improves over several strong\nstatic and adaptive methods, leading to a 4.3x reduction in computation while\nretaining 95% performance of the full model.", "published": "2020-11-10 22:37:56", "link": "http://arxiv.org/abs/2011.05435v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Sound Change: Deep and Iterative Learning, Convolutional Neural\n  Networks, and Language Change", "abstract": "This paper proposes a framework for modeling sound change that combines deep\nlearning and iterative learning. Acquisition and transmission of speech is\nmodeled by training generations of Generative Adversarial Networks (GANs) on\nunannotated raw speech data. The paper argues that several properties of sound\nchange emerge from the proposed architecture. GANs (Goodfellow et al. 2014\narXiv:1406.2661, Donahue et al. 2019 arXiv:1705.07904) are uniquely appropriate\nfor modeling language change because the networks are trained on raw\nunsupervised acoustic data, contain no language-specific features and, as\nargued in Begu\\v{s} (2020 arXiv:2006.03965), encode phonetic and phonological\nrepresentations in their latent space and generate linguistically informative\ninnovative data. The first generation of networks is trained on the relevant\nsequences in human speech from TIMIT. The subsequent generations are not\ntrained on TIMIT, but on generated outputs from the previous generation and\nthus start learning from each other in an iterative learning task. The initial\nallophonic distribution is progressively being lost with each generation,\nlikely due to pressures from the global distribution of aspiration in the\ntraining data. The networks show signs of a gradual shift in phonetic targets\ncharacteristic of a gradual phonetic sound change. At endpoints, the outputs\nsuperficially resemble a phonological change -- rule loss.", "published": "2020-11-10 23:49:09", "link": "http://arxiv.org/abs/2011.05463v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multimodal Pretraining for Dense Video Captioning", "abstract": "Learning specific hands-on skills such as cooking, car maintenance, and home\nrepairs increasingly happens via instructional videos. The user experience with\nsuch videos is known to be improved by meta-information such as time-stamped\nannotations for the main steps involved. Generating such annotations\nautomatically is challenging, and we describe here two relevant contributions.\nFirst, we construct and release a new dense video captioning dataset, Video\nTimeline Tags (ViTT), featuring a variety of instructional videos together with\ntime-stamped annotations. Second, we explore several multimodal\nsequence-to-sequence pretraining strategies that leverage large unsupervised\ndatasets of videos and caption-like texts. We pretrain and subsequently\nfinetune dense video captioning models using both YouCook2 and ViTT. We show\nthat such models generalize well and are robust over a wide variety of\ninstructional videos.", "published": "2020-11-10 21:49:14", "link": "http://arxiv.org/abs/2011.11760v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Deconstruct and Reconstruct Dizi Music of the Northern School and the\n  Southern School", "abstract": "Today's research on Chinese music technology is mainly focused on three\naspects: data collection, music deconstruction, and music reconstruction. In\nthis paper, a general method is proposed to collect Chinese music in the form\nof numbered musical notation, and a Dizi dataset is collected using this\nmethod. Based on the collected Dizi dataset, we conduct research on the Dizi\nmusic styles of the Northern school and the Southern School. Characteristics\ninclude melody and playing techniques of the two different music styles are\ndeconstructed. A reconstruction example, music style transfer which includes\nmelody transfer and playing techniques transfer is given and audience\nevaluation is done to evaluate the reconstruction results.", "published": "2020-11-10 08:45:17", "link": "http://arxiv.org/abs/2011.04974v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor\n  and Neural Waveform Model", "abstract": "High-quality speech corpora are essential foundations for most speech\napplications. However, such speech data are expensive and limited since they\nare collected in professional recording environments. In this work, we propose\nan encoder-decoder neural network to automatically enhance low-quality\nrecordings to professional high-quality recordings. To address channel\nvariability, we first filter out the channel characteristics from the original\ninput audio using the encoder network with adversarial training. Next, we\ndisentangle the channel factor from a reference audio. Conditioned on this\nfactor, an auto-regressive decoder is then used to predict the\ntarget-environment Mel spectrogram. Finally, we apply a neural vocoder to\nsynthesize the speech waveform. Experimental results show that the proposed\nsystem can generate a professional high-quality speech waveform when setting\nhigh-quality audio as the reference. It also improves speech enhancement\nperformance compared with several state-of-the-art baseline systems.", "published": "2020-11-10 11:00:20", "link": "http://arxiv.org/abs/2011.05038v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Supervised attention for speaker recognition", "abstract": "The recently proposed self-attentive pooling (SAP) has shown good performance\nin several speaker recognition systems. In SAP systems, the context vector is\ntrained end-to-end together with the feature extractor, where the role of\ncontext vector is to select the most discriminative frames for speaker\nrecognition. However, the SAP underperforms compared to the temporal average\npooling (TAP) baseline in some settings, which implies that the attention is\nnot learnt effectively in end-to-end training. To tackle this problem, we\nintroduce strategies for training the attention mechanism in a supervised\nmanner, which learns the context vector using classified samples. With our\nproposed methods, context vector can be boosted to select the most informative\nframes. We show that our method outperforms existing methods in various\nexperimental settings including short utterance speaker recognition, and\nachieves competitive performance over the existing baselines on the VoxCeleb\ndatasets.", "published": "2020-11-10 15:38:47", "link": "http://arxiv.org/abs/2011.05189v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
