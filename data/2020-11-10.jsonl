{"title": "TRSM-RS: A Movie Recommender System Based on Users' Gender and New Weighted Similarity Measure", "abstract": "With the growing data on the Internet, recommender systems have been able to predict users' preferences and offer related movies. Collaborative filtering is one of the most popular algorithms in these systems. The main purpose of collaborative filtering is to find the users or the same items using the rating matrix. By increasing the number of users and items, this algorithm suffers from the scalability problem. On the other hand, due to the unavailability of a large number of user preferences for different items, there is a cold start problem for a new user or item that has a significant impact on system performance. The purpose of this paper is to design a movie recommender system named TRSM-RS using users' demographic information (just users' gender) along with the new weighted similarity measure. By segmenting users based on their gender, the scalability problem is improved, and by considering the reliability of the users' similarity as the weight in the new similarity measure (Tanimoto Reliability Similarity Measure, TRSM), the effect of the cold-start problem is undermined and the performance of the system is improved. Experiments were performed on the MovieLens dataset and the system was evaluated using mean absolute error (MAE), Accuracy, Precision, and Recall metrics. The results of the experiments indicate improved performance (accuracy and precision) and system error rate compared to other research methods of the researchers. The maximum improved MAE rate of the system for men and women is 5.5% and 13.8%, respectively.", "published": "2020-11-10 14:41:40", "link": "http://arxiv.org/abs/2011.05119v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Uses and Abuses of the Cross-Entropy Loss: Case Studies in Modern Deep Learning", "abstract": "Modern deep learning is primarily an experimental science, in which empirical advances occasionally come at the expense of probabilistic rigor. Here we focus on one such example; namely the use of the categorical cross-entropy loss to model data that is not strictly categorical, but rather takes values on the simplex. This practice is standard in neural network architectures with label smoothing and actor-mimic reinforcement learning, amongst others. Drawing on the recently discovered continuous-categorical distribution, we propose probabilistically-inspired alternatives to these models, providing an approach that is more principled and theoretically appealing. Through careful experimentation, including an ablation study, we identify the potential for outperformance in these models, thereby highlighting the importance of a proper probabilistic treatment, as well as illustrating some of the failure modes thereof.", "published": "2020-11-10 16:44:35", "link": "http://arxiv.org/abs/2011.05231v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Gaussian Compression Stream: Principle and Preliminary Results", "abstract": "Random projections became popular tools to process big data. In particular, when applied to Nonnegative Matrix Factorization (NMF), it was shown that structured random projections were far more efficient than classical strategies based on Gaussian compression. However, they remain costly and might not fully benefit from recent fast random projection techniques. In this paper, we thus investigate an alternative to structured ran-om projections-named Gaussian compression stream-which (i) is based on Gaussian compressions only, (ii) can benefit from the above fast techniques, and (iii) is shown to be well-suited to NMF.", "published": "2020-11-10 20:56:15", "link": "http://arxiv.org/abs/2011.05390v2", "categories": ["eess.SP", "cs.IT", "cs.LG"], "primary_category": "eess.SP"}
