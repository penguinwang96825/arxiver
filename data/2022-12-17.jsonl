{"title": "RISE: Leveraging Retrieval Techniques for Summarization Evaluation", "abstract": "Evaluating automatically-generated text summaries is a challenging task.\nWhile there have been many interesting approaches, they still fall short of\nhuman evaluations. We present RISE, a new approach for evaluating summaries by\nleveraging techniques from information retrieval. RISE is first trained as a\nretrieval task using a dual-encoder retrieval setup, and can then be\nsubsequently utilized for evaluating a generated summary given an input\ndocument, without gold reference summaries. RISE is especially well suited when\nworking on new datasets where one may not have reference summaries available\nfor evaluation. We conduct comprehensive experiments on the SummEval benchmark\n(Fabbri et al., 2021) and the results show that RISE has higher correlation\nwith human evaluations compared to many past approaches to summarization\nevaluation. Furthermore, RISE also demonstrates data-efficiency and\ngeneralizability across languages.", "published": "2022-12-17 01:09:22", "link": "http://arxiv.org/abs/2212.08775v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Cross-task Generalization of Unified Table-to-text Models with\n  Compositional Task Configurations", "abstract": "There has been great progress in unifying various table-to-text tasks using a\nsingle encoder-decoder model trained via multi-task learning (Xie et al.,\n2022). However, existing methods typically encode task information with a\nsimple dataset name as a prefix to the encoder. This not only limits the\neffectiveness of multi-task learning, but also hinders the model's ability to\ngeneralize to new domains or tasks that were not seen during training, which is\ncrucial for real-world applications. In this paper, we propose compositional\ntask configurations, a set of prompts prepended to the encoder to improve\ncross-task generalization of unified models. We design the task configurations\nto explicitly specify the task type, as well as its input and output types. We\nshow that this not only allows the model to better learn shared knowledge\nacross different tasks at training, but also allows us to control the model by\ncomposing new configurations that apply novel input-output combinations in a\nzero-shot manner. We demonstrate via experiments over ten table-to-text tasks\nthat our method outperforms the UnifiedSKG baseline by noticeable margins in\nboth in-domain and zero-shot settings, with average improvements of +0.5 and\n+12.6 from using a T5-large backbone, respectively.", "published": "2022-12-17 02:20:14", "link": "http://arxiv.org/abs/2212.08780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Importance of Synthesizing High-quality Data for Text-to-SQL Parsing", "abstract": "Recently, there has been increasing interest in synthesizing data to improve\ndownstream text-to-SQL tasks. In this paper, we first examined the existing\nsynthesized datasets and discovered that state-of-the-art text-to-SQL\nalgorithms did not further improve on popular benchmarks when trained with\naugmented synthetic data. We observed two shortcomings: illogical synthetic SQL\nqueries from independent column sampling and arbitrary table joins. To address\nthese issues, we propose a novel synthesis framework that incorporates key\nrelationships from schema, imposes strong typing, and conducts\nschema-distance-weighted column sampling. We also adopt an intermediate\nrepresentation (IR) for the SQL-to-text task to further improve the quality of\nthe generated natural language questions. When existing powerful semantic\nparsers are pre-finetuned on our high-quality synthesized data, our experiments\nshow that these models have significant accuracy boosts on popular benchmarks,\nincluding new state-of-the-art performance on Spider.", "published": "2022-12-17 02:53:21", "link": "http://arxiv.org/abs/2212.08785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relational Sentence Embedding for Flexible Semantic Matching", "abstract": "We present Relational Sentence Embedding (RSE), a new paradigm to further\ndiscover the potential of sentence embeddings. Prior work mainly models the\nsimilarity between sentences based on their embedding distance. Because of the\ncomplex semantic meanings conveyed, sentence pairs can have various relation\ntypes, including but not limited to entailment, paraphrasing, and\nquestion-answer. It poses challenges to existing embedding methods to capture\nsuch relational information. We handle the problem by learning associated\nrelational embeddings. Specifically, a relation-wise translation operation is\napplied to the source sentence to infer the corresponding target sentence with\na pre-trained Siamese-based encoder. The fine-grained relational similarity\nscores can be computed from learned embeddings. We benchmark our method on 19\ndatasets covering a wide range of tasks, including semantic textual similarity,\ntransfer, and domain-specific tasks. Experimental results show that our method\nis effective and flexible in modeling sentence relations and outperforms a\nseries of state-of-the-art sentence embedding methods.\nhttps://github.com/BinWang28/RSE", "published": "2022-12-17 05:25:17", "link": "http://arxiv.org/abs/2212.08802v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Datastore, Better Translation: Generating Datastores from\n  Pre-Trained Models for Nearest Neural Machine Translation", "abstract": "Nearest Neighbor Machine Translation (kNNMT) is a simple and effective method\nof augmenting neural machine translation (NMT) with a token-level nearest\nneighbor retrieval mechanism. The effectiveness of kNNMT directly depends on\nthe quality of retrieved neighbors. However, original kNNMT builds datastores\nbased on representations from NMT models, which would result in poor retrieval\naccuracy when NMT models are not good enough, leading to sub-optimal\ntranslation performance. In this paper, we propose PRED, a framework that\nleverages Pre-trained models for Datastores in kNN-MT. Better representations\nfrom pre-trained models allow us to build datastores of better quality. We also\ndesign a novel contrastive alignment objective to mitigate the representation\ngap between the NMT model and pre-trained models, enabling the NMT model to\nretrieve from better datastores. We conduct extensive experiments on both\nbilingual and multilingual translation benchmarks, including WMT17 English\n$\\leftrightarrow$ Chinese, WMT14 English $\\leftrightarrow$ German, IWSLT14\nGerman $\\leftrightarrow$ English, and IWSLT14 multilingual datasets. Empirical\nresults demonstrate the effectiveness of PRED.", "published": "2022-12-17 08:34:20", "link": "http://arxiv.org/abs/2212.08822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HyPe: Better Pre-trained Language Model Fine-tuning with Hidden\n  Representation Perturbation", "abstract": "Language models with the Transformers structure have shown great performance\nin natural language processing. However, there still poses problems when\nfine-tuning pre-trained language models on downstream tasks, such as\nover-fitting or representation collapse. In this work, we propose HyPe, a\nsimple yet effective fine-tuning technique to alleviate such problems by\nperturbing hidden representations of Transformers layers. Unlike previous works\nthat only add noise to inputs or parameters, we argue that the hidden\nrepresentations of Transformers layers convey more diverse and meaningful\nlanguage information. Therefore, making the Transformers layers more robust to\nhidden representation perturbations can further benefit the fine-tuning of PLMs\nen bloc. We conduct extensive experiments and analyses on GLUE and other\nnatural language inference datasets. Results demonstrate that HyPe outperforms\nvanilla fine-tuning and enhances generalization of hidden representations from\ndifferent layers. In addition, HyPe acquires negligible computational\noverheads, and is better than and compatible with previous state-of-the-art\nfine-tuning techniques.", "published": "2022-12-17 11:56:21", "link": "http://arxiv.org/abs/2212.08853v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Rich Textual User-Product Context for Improving Sentiment\n  Analysis", "abstract": "User and product information associated with a review is useful for sentiment\npolarity prediction. Typical approaches incorporating such information focus on\nmodeling users and products as implicitly learned representation vectors. Most\ndo not exploit the potential of historical reviews, or those that currently do\nrequire unnecessary modifications to model architecture or do not make full use\nof user/product associations. The contribution of this work is twofold: i) a\nmethod to explicitly employ historical reviews belonging to the same\nuser/product to initialize representations, and ii) efficient incorporation of\ntextual associations between users and products via a user-product\ncross-context module. Experiments on IMDb, Yelp-2013 and Yelp-2014 benchmarks\nshow that our approach substantially outperforms previous state-of-the-art.\nSince we employ BERT-base as the encoder, we additionally provide experiments\nin which our approach performs well with Span-BERT and Longformer. Furthermore,\nexperiments where the reviews of each user/product in the training data are\ndownsampled demonstrate the effectiveness of our approach under a low-resource\nsetting.", "published": "2022-12-17 14:57:52", "link": "http://arxiv.org/abs/2212.08888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PolQA: Polish Question Answering Dataset", "abstract": "Recently proposed systems for open-domain question answering (OpenQA) require\nlarge amounts of training data to achieve state-of-the-art performance.\nHowever, data annotation is known to be time-consuming and therefore expensive\nto acquire. As a result, the appropriate datasets are available only for a\nhandful of languages (mainly English and Chinese). In this work, we introduce\nand publicly release PolQA, the first Polish dataset for OpenQA. It consists of\n7,000 questions, 87,525 manually labeled evidence passages, and a corpus of\nover 7,097,322 candidate passages. Each question is classified according to its\nformulation, type, as well as entity type of the answer. This resource allows\nus to evaluate the impact of different annotation choices on the performance of\nthe QA system and propose an efficient annotation strategy that increases the\npassage retrieval accuracy@10 by 10.55 p.p. while reducing the annotation cost\nby 82%.", "published": "2022-12-17 15:20:18", "link": "http://arxiv.org/abs/2212.08897v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Know What I don't Know: Handling Ambiguous and Unanswerable Questions\n  for Text-to-SQL", "abstract": "The task of text-to-SQL aims to convert a natural language question into its\ncorresponding SQL query within the context of relational tables. Existing\ntext-to-SQL parsers generate a \"plausible\" SQL query for an arbitrary user\nquestion, thereby failing to correctly handle problematic user questions. To\nformalize this problem, we conduct a preliminary study on the observed\nambiguous and unanswerable cases in text-to-SQL and summarize them into 6\nfeature categories. Correspondingly, we identify the causes behind each\ncategory and propose requirements for handling ambiguous and unanswerable\nquestions. Following this study, we propose a simple yet effective\ncounterfactual example generation approach that automatically produces\nambiguous and unanswerable text-to-SQL examples. Furthermore, we propose a\nweakly supervised DTE (Detecting-Then-Explaining) model for error detection,\nlocalization, and explanation. Experimental results show that our model\nachieves the best result on both real-world examples and generated examples\ncompared with various baselines. We release our data and code at:\n\\href{https://github.com/wbbeyourself/DTE}{https://github.com/wbbeyourself/DTE}.", "published": "2022-12-17 15:32:00", "link": "http://arxiv.org/abs/2212.08902v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Styles in Neural Machine Translation with Activation Prompt", "abstract": "Controlling styles in neural machine translation (NMT) has attracted wide\nattention, as it is crucial for enhancing user experience. Earlier studies on\nthis topic typically concentrate on regulating the level of formality and\nachieve some progress in this area. However, they still encounter two major\nchallenges. The first is the difficulty in style evaluation. The style\ncomprises various aspects such as lexis, syntax, and others that provide\nabundant information. Nevertheless, only formality has been thoroughly\ninvestigated. The second challenge involves excessive dependence on incremental\nadjustments, particularly when new styles are necessary. To address both\nchallenges, this paper presents a new benchmark and approach. A multiway\nstylized machine translation (MSMT) benchmark is introduced, incorporating\ndiverse categories of styles across four linguistic domains. Then, we propose a\nmethod named style activation prompt (StyleAP) by retrieving prompts from\nstylized monolingual corpus, which does not require extra fine-tuning.\nExperiments show that StyleAP could effectively control the style of\ntranslation and achieve remarkable performance.", "published": "2022-12-17 16:05:50", "link": "http://arxiv.org/abs/2212.08909v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Claim Optimization in Computational Argumentation", "abstract": "An optimal delivery of arguments is key to persuasion in any debate, both for\nhumans and for AI systems. This requires the use of clear and fluent claims\nrelevant to the given debate. Prior work has studied the automatic assessment\nof argument quality extensively. Yet, no approach actually improves the quality\nso far. To fill this gap, this paper proposes the task of claim optimization:\nto rewrite argumentative claims in order to optimize their delivery. As\nmultiple types of optimization are possible, we approach this task by first\ngenerating a diverse set of candidate claims using a large language model, such\nas BART, taking into account contextual information. Then, the best candidate\nis selected using various quality metrics. In automatic and human evaluation on\nan English-language corpus, our quality-based candidate selection outperforms\nseveral baselines, improving 60% of all claims (worsening 16% only). Follow-up\nanalyses reveal that, beyond copy editing, our approach often specifies claims\nwith details, whereas it adds less evidence than humans do. Moreover, its\ncapabilities generalize well to other domains, such as instructional texts.", "published": "2022-12-17 16:30:27", "link": "http://arxiv.org/abs/2212.08913v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Instance Interactions for Joint Information Extraction with\n  Neural High-Order Conditional Random Field", "abstract": "Prior works on joint Information Extraction (IE) typically model instance\n(e.g., event triggers, entities, roles, relations) interactions by\nrepresentation enhancement, type dependencies scoring, or global decoding. We\nfind that the previous models generally consider binary type dependency scoring\nof a pair of instances, and leverage local search such as beam search to\napproximate global solutions. To better integrate cross-instance interactions,\nin this work, we introduce a joint IE framework (CRFIE) that formulates joint\nIE as a high-order Conditional Random Field. Specifically, we design binary\nfactors and ternary factors to directly model interactions between not only a\npair of instances but also triplets. Then, these factors are utilized to\njointly predict labels of all instances. To address the intractability problem\nof exact high-order inference, we incorporate a high-order neural decoder that\nis unfolded from a mean-field variational inference method, which achieves\nconsistent learning and inference. The experimental results show that our\napproach achieves consistent improvements on three IE tasks compared with our\nbaseline and prior work.", "published": "2022-12-17 18:45:23", "link": "http://arxiv.org/abs/2212.08929v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards leveraging latent knowledge and Dialogue context for real-world\n  conversational question answering", "abstract": "In many real-world scenarios, the absence of external knowledge source like\nWikipedia restricts question answering systems to rely on latent internal\nknowledge in limited dialogue data. In addition, humans often seek answers by\nasking several questions for more comprehensive information. As the dialog\nbecomes more extensive, machines are challenged to refer to previous\nconversation rounds to answer questions. In this work, we propose to leverage\nlatent knowledge in existing conversation logs via a neural Retrieval-Reading\nsystem, enhanced with a TFIDF-based text summarizer refining lengthy\nconversational history to alleviate the long context issue. Our experiments\nshow that our Retrieval-Reading system can exploit retrieved background\nknowledge to generate significantly better answers. The results also indicate\nthat our context summarizer significantly helps both the retriever and the\nreader by introducing more concise and less noisy contextual information.", "published": "2022-12-17 20:36:17", "link": "http://arxiv.org/abs/2212.08946v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AugTriever: Unsupervised Dense Retrieval and Domain Adaptation by\n  Scalable Data Augmentation", "abstract": "Dense retrievers have made significant strides in text retrieval and\nopen-domain question answering. However, most of these achievements have relied\nheavily on extensive human-annotated supervision. In this study, we aim to\ndevelop unsupervised methods for improving dense retrieval models. We propose\ntwo approaches that enable annotation-free and scalable training by creating\npseudo querydocument pairs: query extraction and transferred query generation.\nThe query extraction method involves selecting salient spans from the original\ndocument to generate pseudo queries. On the other hand, the transferred query\ngeneration method utilizes generation models trained for other NLP tasks, such\nas summarization, to produce pseudo queries. Through extensive experimentation,\nwe demonstrate that models trained using these augmentation methods can achieve\ncomparable, if not better, performance than multiple strong dense baselines.\nMoreover, combining these strategies leads to further improvements, resulting\nin superior performance of unsupervised dense retrieval, unsupervised domain\nadaptation and supervised finetuning, benchmarked on both BEIR and ODQA\ndatasets. Code and datasets are publicly available at\nhttps://github.com/salesforce/AugTriever.", "published": "2022-12-17 10:43:25", "link": "http://arxiv.org/abs/2212.08841v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "'If you build they will come': Automatic Identification of\n  News-Stakeholders to detect Party Preference in News Coverage", "abstract": "The coverage of different stakeholders mentioned in the news articles\nsignificantly impacts the slant or polarity detection of the concerned news\npublishers. For instance, the pro-government media outlets would give more\ncoverage to the government stakeholders to increase their accessibility to the\nnews audiences. In contrast, the anti-government news agencies would focus more\non the views of the opponent stakeholders to inform the readers about the\nshortcomings of government policies. In this paper, we address the problem of\nstakeholder extraction from news articles and thereby determine the inherent\nbias present in news reporting. Identifying potential stakeholders in\nmulti-topic news scenarios is challenging because each news topic has different\nstakeholders. The research presented in this paper utilizes both contextual\ninformation and external knowledge to identify the topic-specific stakeholders\nfrom news articles. We also apply a sequential incremental clustering algorithm\nto group the entities with similar stakeholder types. We carried out all our\nexperiments on news articles on four Indian government policies published by\nnumerous national and international news agencies. We also further generalize\nour system, and the experimental results show that the proposed model can be\nextended to other news topics.", "published": "2022-12-17 13:08:39", "link": "http://arxiv.org/abs/2212.08864v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech\n  Translation", "abstract": "To alleviate the data scarcity problem in End-to-end speech translation (ST),\npre-training on data for speech recognition and machine translation is\nconsidered as an important technique. However, the modality gap between speech\nand text prevents the ST model from efficiently inheriting knowledge from the\npre-trained models. In this work, we propose AdaTranS for end-to-end ST. It\nadapts the speech features with a new shrinking mechanism to mitigate the\nlength mismatch between speech and text features by predicting word boundaries.\nExperiments on the MUST-C dataset demonstrate that AdaTranS achieves better\nperformance than the other shrinking-based methods, with higher inference speed\nand lower memory usage. Further experiments also show that AdaTranS can be\nequipped with additional alignment losses to further improve performance.", "published": "2022-12-17 16:14:30", "link": "http://arxiv.org/abs/2212.08911v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Simple Baseline for Beam Search Reranking", "abstract": "Reranking methods in machine translation aim to close the gap between common\nevaluation metrics (e.g. BLEU) and maximum likelihood learning and decoding\nalgorithms. Prior works address this challenge by training models to rerank\nbeam search candidates according to their predicted BLEU scores, building upon\nlarge models pretrained on massive monolingual corpora -- a privilege that was\nnever made available to the baseline translation model. In this work, we\nexamine a simple approach for training rerankers to predict translation\ncandidates' BLEU scores without introducing additional data or parameters. Our\napproach can be used as a clean baseline, decoupled from external factors, for\nfuture research in this area.", "published": "2022-12-17 18:22:20", "link": "http://arxiv.org/abs/2212.08926v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond the C: Retargetable Decompilation using Neural Machine\n  Translation", "abstract": "The problem of reversing the compilation process, decompilation, is an\nimportant tool in reverse engineering of computer software. Recently,\nresearchers have proposed using techniques from neural machine translation to\nautomate the process in decompilation. Although such techniques hold the\npromise of targeting a wider range of source and assembly languages, to date\nthey have primarily targeted C code. In this paper we argue that existing\nneural decompilers have achieved higher accuracy at the cost of requiring\nlanguage-specific domain knowledge such as tokenizers and parsers to build an\nabstract syntax tree (AST) for the source language, which increases the\noverhead of supporting new languages. We explore a different tradeoff that, to\nthe extent possible, treats the assembly and source languages as plain text,\nand show that this allows us to build a decompiler that is easily retargetable\nto new languages. We evaluate our prototype decompiler, Beyond The C (BTC), on\nGo, Fortran, OCaml, and C, and examine the impact of parameters such as\ntokenization and training data selection on the quality of decompilation,\nfinding that it achieves comparable decompilation results to prior work in\nneural decompilation with significantly less domain knowledge. We will release\nour training data, trained decompilation models, and code to help encourage\nfuture research into language-agnostic decompilation.", "published": "2022-12-17 20:45:59", "link": "http://arxiv.org/abs/2212.08950v1", "categories": ["cs.CR", "cs.CL", "cs.PL"], "primary_category": "cs.CR"}
{"title": "Learning from Taxonomy: Multi-label Few-Shot Classification for Everyday\n  Sound Recognition", "abstract": "Everyday sound recognition aims to infer types of sound events in audio\nstreams. While many works succeeded in training models with high performance in\na fully-supervised manner, they are still restricted to the demand of large\nquantities of labelled data and the range of predefined classes. To overcome\nthese drawbacks, this work firstly curates a new database named FSD-FS for\nmulti-label few-shot audio classification. It then explores how to incorporate\naudio taxonomy in few-shot learning. Specifically, this work proposes\nlabel-dependent prototypical networks (LaD-protonet) to exploit parent-children\nrelationships between labels. Plus, it applies taxonomy-aware label smoothing\ntechniques to boost model performance. Experiments demonstrate that\nLaD-protonet outperforms original prototypical networks as well as other\nstate-of-the-art methods. Moreover, its performance can be further boosted when\ncombined with taxonomy-aware label smoothing.", "published": "2022-12-17 20:56:55", "link": "http://arxiv.org/abs/2212.08952v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
