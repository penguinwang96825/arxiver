{"title": "Irreversible investment under weighted discounting: effects of decreasing impatience", "abstract": "This paper employs an intra-personal game-theoretic framework to investigate\nhow decreasing impatience influences irreversible investment behaviors in a\ncontinuous-time setting. We consider a capacity expansion problem under\nweighted discount functions, a class of nonexponential functions that exhibit\ndecreasing impatience, including the hyperbolic discount function as a special\ncase. By deriving the Bellman system that characterizes the equilibrium, we\nestablish the framework for analyzing investment behaviors of agents subject to\ndecreasing impatience. From an economic perspective, we demonstrates that\ndecreasing impatience prompts early investment. From a technical standpoint, we\nwarn that decreasing impatience can lead to the failure of the smooth pasting\nprinciple.", "published": "2024-09-02 22:07:28", "link": "http://arxiv.org/abs/2409.01478v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "A Financial Time Series Denoiser Based on Diffusion Model", "abstract": "Financial time series often exhibit low signal-to-noise ratio, posing\nsignificant challenges for accurate data interpretation and prediction and\nultimately decision making. Generative models have gained attention as powerful\ntools for simulating and predicting intricate data patterns, with the diffusion\nmodel emerging as a particularly effective method. This paper introduces a\nnovel approach utilizing the diffusion model as a denoiser for financial time\nseries in order to improve data predictability and trading performance. By\nleveraging the forward and reverse processes of the conditional diffusion model\nto add and remove noise progressively, we reconstruct original data from noisy\ninputs. Our extensive experiments demonstrate that diffusion model-based\ndenoised time series significantly enhance the performance on downstream future\nreturn classification tasks. Moreover, trading signals derived from the\ndenoised data yield more profitable trades with fewer transactions, thereby\nminimizing transaction costs and increasing overall trading efficiency.\nFinally, we show that by using classifiers trained on denoised time series, we\ncan recognize the noising state of the market and obtain excess return.", "published": "2024-09-02 15:55:36", "link": "http://arxiv.org/abs/2409.02138v1", "categories": ["cs.LG", "cs.AI", "q-fin.CP", "q-fin.TR"], "primary_category": "cs.LG"}
{"title": "Self-Judge: Selective Instruction Following with Alignment\n  Self-Evaluation", "abstract": "Pre-trained large language models (LLMs) can be tailored to adhere to human\ninstructions through instruction tuning. However, due to shifts in the\ndistribution of test-time data, they may not always execute instructions\naccurately, potentially generating factual errors or misaligned content when\nacting as chat assistants. To enhance the reliability of LLMs in following\ninstructions, we propose the study of selective instruction following, whereby\nthe system declines to execute instructions if the anticipated response quality\nis low. We train judge models that can predict numerical quality scores for\nmodel responses. To address data scarcity, we introduce Self-J, a novel\nself-training framework for developing judge models without needing\nhuman-annotated quality scores. Our method leverages the model's inherent\nself-evaluation capability to extract information about response quality from\nlabeled instruction-tuning data. It incorporates a gold reference answer to\nfacilitate self-evaluation and recalibrates by assessing the semantic\nsimilarity between the response sample and the gold reference. During the\ntraining phase, we implement self-distillation as a regularization technique to\nenhance the capability of reference-free estimation. To validate alignment\nevaluation on general instruction-following tasks, we collect large-scale\nhigh-quality instructions from Hugging Face for model training and evaluation.\nExtensive experiments on five open-source models show that our method\ncorrelates much more with GPT-4 than strong baselines, e.g., supervised models\ndistilled from GPT-4 and GPT-3.5-turbo. Our analysis shows our model's strong\ngeneralization across domains. Additionally, our judge models serve as good\nreward models, e.g., boosting WizardLM-13B-V1.2 from 89.17 to 92.48 and from\n12.03 to 15.90 in version v1 and v2 of AlpacaEval respectively using best-of-32\nsampling with our judge models.", "published": "2024-09-02 04:14:13", "link": "http://arxiv.org/abs/2409.00935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What does it take to get state of the art in simultaneous\n  speech-to-speech translation?", "abstract": "This paper presents an in-depth analysis of the latency characteristics\nobserved in simultaneous speech-to-speech model's performance, particularly\nfocusing on hallucination-induced latency spikes. By systematically\nexperimenting with various input parameters and conditions, we propose methods\nto minimize latency spikes and improve overall performance. The findings\nsuggest that a combination of careful input management and strategic parameter\nadjustments can significantly enhance speech-to-speech model's latency\nbehavior.", "published": "2024-09-02 06:04:07", "link": "http://arxiv.org/abs/2409.00965v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DataSculpt: Crafting Data Landscapes for Long-Context LLMs through\n  Multi-Objective Partitioning", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated significant\nimprovements across a variety of tasks, one of which is the long-context\ncapability. The key to improving long-context performance lies in effective\ndata organization and management strategies that integrate data from multiple\ndomains and optimize the context window during training. Through extensive\nexperimental analysis, we identified three key challenges in designing\neffective data management strategies that enable the model to achieve\nlong-context capability without sacrificing performance in other tasks: (1) a\nshortage of long documents across multiple domains, (2) effective construction\nof context windows, and (3) efficient organization of large-scale datasets. To\naddress these challenges, we introduce DataSculpt, a novel data management\nframework designed for long-context training. We first formulate the\norganization of training data as a multi-objective combinatorial optimization\nproblem, focusing on attributes including relevance, homogeneity, integrity,\nand efficiency. Specifically, our approach utilizes a coarse-to-fine\nmethodology to optimize training data organization both efficiently and\neffectively. We begin by clustering the data based on semantic similarity\n(coarse), followed by a multi-objective greedy search within each cluster to\nscore and concatenate documents into various context windows (fine). Our\ncomprehensive evaluations demonstrate that DataSculpt significantly enhances\nlong-context training performance, resulting in improvements of 18.09% in\nretrieval augmentation, 21.23% in summarization, 21.27% in reading\ncomprehension, and a 3.81% increase in code completion, while also maintaining\noverall model proficiency with a 4.88% improvement.", "published": "2024-09-02 07:23:13", "link": "http://arxiv.org/abs/2409.00997v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NYK-MS: A Well-annotated Multi-modal Metaphor and Sarcasm Understanding\n  Benchmark on Cartoon-Caption Dataset", "abstract": "Metaphor and sarcasm are common figurative expressions in people's\ncommunication, especially on the Internet or the memes popular among teenagers.\nWe create a new benchmark named NYK-MS (NewYorKer for Metaphor and Sarcasm),\nwhich contains 1,583 samples for metaphor understanding tasks and 1,578 samples\nfor sarcasm understanding tasks. These tasks include whether it contains\nmetaphor/sarcasm, which word or object contains metaphor/sarcasm, what does it\nsatirize and why does it contains metaphor/sarcasm, all of the 7 tasks are\nwell-annotated by at least 3 annotators. We annotate the dataset for several\nrounds to improve the consistency and quality, and use GUI and GPT-4V to raise\nour efficiency. Based on the benchmark, we conduct plenty of experiments. In\nthe zero-shot experiments, we show that Large Language Models (LLM) and Large\nMulti-modal Models (LMM) can't do classification task well, and as the scale\nincreases, the performance on other 5 tasks improves. In the experiments on\ntraditional pre-train models, we show the enhancement with augment and\nalignment methods, which prove our benchmark is consistent with previous\ndataset and requires the model to understand both of the two modalities.", "published": "2024-09-02 08:14:49", "link": "http://arxiv.org/abs/2409.01037v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "THInC: A Theory-Driven Framework for Computational Humor Detection", "abstract": "Humor is a fundamental aspect of human communication and cognition, as it\nplays a crucial role in social engagement. Although theories about humor have\nevolved over centuries, there is still no agreement on a single, comprehensive\nhumor theory. Likewise, computationally recognizing humor remains a significant\nchallenge despite recent advances in large language models. Moreover, most\ncomputational approaches to detecting humor are not based on existing humor\ntheories. This paper contributes to bridging this long-standing gap between\nhumor theory research and computational humor detection by creating an\ninterpretable framework for humor classification, grounded in multiple humor\ntheories, called THInC (Theory-driven Humor Interpretation and Classification).\nTHInC ensembles interpretable GA2M classifiers, each representing a different\nhumor theory. We engineered a transparent flow to actively create proxy\nfeatures that quantitatively reflect different aspects of theories. An\nimplementation of this framework achieves an F1 score of 0.85. The associative\ninterpretability of the framework enables analysis of proxy efficacy, alignment\nof joke features with theories, and identification of globally contributing\nfeatures. This paper marks a pioneering effort in creating a humor detection\nframework that is informed by diverse humor theories and offers a foundation\nfor future advancements in theory-driven humor classification. It also serves\nas a first step in automatically comparing humor theories in a quantitative\nmanner.", "published": "2024-09-02 13:09:26", "link": "http://arxiv.org/abs/2409.01232v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CV-Probes: Studying the interplay of lexical and world knowledge in\n  visually grounded verb understanding", "abstract": "This study investigates the ability of various vision-language (VL) models to\nground context-dependent and non-context-dependent verb phrases. To do that, we\nintroduce the CV-Probes dataset, designed explicitly for studying context\nunderstanding, containing image-caption pairs with context-dependent verbs\n(e.g., \"beg\") and non-context-dependent verbs (e.g., \"sit\"). We employ the\nMM-SHAP evaluation to assess the contribution of verb tokens towards model\npredictions. Our results indicate that VL models struggle to ground\ncontext-dependent verb phrases effectively. These findings highlight the\nchallenges in training VL models to integrate context accurately, suggesting a\nneed for improved methodologies in VL model training and evaluation.", "published": "2024-09-02 17:39:26", "link": "http://arxiv.org/abs/2409.01389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Compressor-Retriever Architecture for Language Model OS", "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their capacity to aggregate and process information across multiple\nmodalities, enabling them to perform a wide range of tasks such as multimodal\ndata querying, tool usage, web interactions, and handling long documents. These\ncapabilities pave the way for transforming LLMs from mere chatbots into\ngeneral-purpose agents capable of interacting with the real world. This paper\nexplores the concept of using a language model as the core component of an\noperating system (OS), effectively acting as a CPU that processes data stored\nin a context window, which functions as RAM. A key challenge in realizing such\nan LM OS is managing the life-long context and ensuring statefulness across\nsessions, a feature limited by the current session-based interaction paradigm\ndue to context window size limit. To address this, we introduce\ncompressor-retriever, a model-agnostic architecture designed for life-long\ncontext management. Unlike other long-context solutions such as\nretrieval-augmented generation, our approach exclusively uses the base model's\nforward function to compress and retrieve context, ensuring end-to-end\ndifferentiability. Preliminary experiments demonstrate the effectiveness of\nthis architecture in in-context learning tasks, marking a step towards the\ndevelopment of a fully stateful LLM OS. Project repo available at:\nhttps://github.com/gblackout/LM-OS", "published": "2024-09-02 23:28:15", "link": "http://arxiv.org/abs/2409.01495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiversityMedQA: Assessing Demographic Biases in Medical Diagnosis using\n  Large Language Models", "abstract": "As large language models (LLMs) gain traction in healthcare, concerns about\ntheir susceptibility to demographic biases are growing. We introduce\n{DiversityMedQA}, a novel benchmark designed to assess LLM responses to medical\nqueries across diverse patient demographics, such as gender and ethnicity. By\nperturbing questions from the MedQA dataset, which comprises medical board exam\nquestions, we created a benchmark that captures the nuanced differences in\nmedical diagnosis across varying patient profiles. Our findings reveal notable\ndiscrepancies in model performance when tested against these demographic\nvariations. Furthermore, to ensure the perturbations were accurate, we also\npropose a filtering strategy that validates each perturbation. By releasing\nDiversityMedQA, we provide a resource for evaluating and mitigating demographic\nbias in LLM medical diagnoses.", "published": "2024-09-02 23:37:20", "link": "http://arxiv.org/abs/2409.01497v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "User-Specific Dialogue Generation with User Profile-Aware Pre-Training\n  Model and Parameter-Efficient Fine-Tuning", "abstract": "This paper addresses user-specific dialogs. In contrast to previous research\non personalized dialogue focused on achieving virtual user dialogue as defined\nby persona descriptions, user-specific dialogue aims to reproduce real-user\ndialogue beyond persona-based dialogue. Fine-tuning using the target user's\ndialogue history is an efficient learning method for a user-specific model.\nHowever, it is prone to overfitting and model destruction due to the small\namount of data. Therefore, we propose a learning method for user-specific\nmodels by combining parameter-efficient fine-tuning with a pre-trained dialogue\nmodel that includes user profiles. Parameter-efficient fine-tuning adds a small\nnumber of parameters to the entire model, so even small amounts of training\ndata can be trained efficiently and are robust to model destruction. In\naddition, the pre-trained model, which is learned by adding simple prompts for\nautomatically inferred user profiles, can generate speech with enhanced\nknowledge of the user's profile, even when there is little training data during\nfine-tuning. In experiments, we compared the proposed model with\nlarge-language-model utterance generation using prompts containing users'\npersonal information. Experiments reproducing real users' utterances revealed\nthat the proposed model can generate utterances with higher reproducibility\nthan the compared methods, even with a small model.", "published": "2024-09-02 01:30:40", "link": "http://arxiv.org/abs/2409.00887v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Automatic Detection of Sensitive Topics", "abstract": "Sensitive information detection is crucial in content moderation to maintain\nsafe online communities. Assisting in this traditionally manual process could\nrelieve human moderators from overwhelming and tedious tasks, allowing them to\nfocus solely on flagged content that may pose potential risks. Rapidly\nadvancing large language models (LLMs) are known for their capability to\nunderstand and process natural language and so present a potential solution to\nsupport this process. This study explores the capabilities of five LLMs for\ndetecting sensitive messages in the mental well-being domain within two online\ndatasets and assesses their performance in terms of accuracy, precision,\nrecall, F1 scores, and consistency. Our findings indicate that LLMs have the\npotential to be integrated into the moderation workflow as a convenient and\nprecise detection tool. The best-performing model, GPT-4o, achieved an average\naccuracy of 99.5\\% and an F1-score of 0.99. We discuss the advantages and\npotential challenges of using LLMs in the moderation workflow and suggest that\nfuture research should address the ethical considerations of utilising this\ntechnology.", "published": "2024-09-02 04:50:42", "link": "http://arxiv.org/abs/2409.00940v1", "categories": ["cs.CL", "cs.AI", "J.6"], "primary_category": "cs.CL"}
{"title": "Multi-Modal Multi-Granularity Tokenizer for Chu Bamboo Slip Scripts", "abstract": "This study presents a multi-modal multi-granularity tokenizer specifically\ndesigned for analyzing ancient Chinese scripts, focusing on the Chu bamboo slip\n(CBS) script used during the Spring and Autumn and Warring States period\n(771-256 BCE) in Ancient China. Considering the complex hierarchical structure\nof ancient Chinese scripts, where a single character may be a combination of\nmultiple sub-characters, our tokenizer first adopts character detection to\nlocate character boundaries, and then conducts character recognition at both\nthe character and sub-character levels. Moreover, to support the academic\ncommunity, we have also assembled the first large-scale dataset of CBSs with\nover 100K annotated character image scans. On the part-of-speech tagging task\nbuilt on our dataset, using our tokenizer gives a 5.5% relative improvement in\nF1-score compared to mainstream sub-word tokenizers. Our work not only aids in\nfurther investigations of the specific script but also has the potential to\nadvance research on other forms of ancient Chinese scripts.", "published": "2024-09-02 07:42:55", "link": "http://arxiv.org/abs/2409.01011v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Perspective on Literary Metaphor in the Context of Generative AI", "abstract": "At the intersection of creative text generation and literary theory, this\nstudy explores the role of literary metaphor and its capacity to generate a\nrange of meanings. In this regard, literary metaphor is vital to the\ndevelopment of any particular language. To investigate whether the inclusion of\noriginal figurative language improves textual quality, we trained an LSTM-based\nlanguage model in Afrikaans. The network produces phrases containing\ncompellingly novel figures of speech. Specifically, the emphasis falls on how\nAI might be utilised as a defamiliarisation technique, which disrupts expected\nuses of language to augment poetic expression. Providing a literary perspective\non text generation, the paper raises thought-provoking questions on aesthetic\nvalue, interpretation and evaluation.", "published": "2024-09-02 08:27:29", "link": "http://arxiv.org/abs/2409.01053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VideoLLaMB: Long-context Video Understanding with Recurrent Memory\n  Bridges", "abstract": "Recent advancements in large-scale video-language models have shown\nsignificant potential for real-time planning and detailed interactions.\nHowever, their high computational demands and the scarcity of annotated\ndatasets limit their practicality for academic researchers. In this work, we\nintroduce VideoLLaMB, a novel framework that utilizes temporal memory tokens\nwithin bridge layers to allow for the encoding of entire video sequences\nalongside historical visual data, effectively preserving semantic continuity\nand enhancing model performance across various tasks. This approach includes\nrecurrent memory tokens and a SceneTilling algorithm, which segments videos\ninto independent semantic units to preserve semantic integrity. Empirically,\nVideoLLaMB significantly outstrips existing video-language models,\ndemonstrating a 5.5 points improvement over its competitors across three\nVideoQA benchmarks, and 2.06 points on egocentric planning. Comprehensive\nresults on the MVBench show that VideoLLaMB-7B achieves markedly better results\nthan previous 7B models of same LLM. Remarkably, it maintains robust\nperformance as PLLaVA even as video length increases up to 8 times. Besides,\nthe frame retrieval results on our specialized Needle in a Video Haystack\n(NIAVH) benchmark, further validate VideoLLaMB's prowess in accurately\nidentifying specific frames within lengthy videos. Our SceneTilling algorithm\nalso enables the generation of streaming video captions directly, without\nnecessitating additional training. In terms of efficiency, VideoLLaMB, trained\non 16 frames, supports up to 320 frames on a single Nvidia A100 GPU with linear\nGPU memory scaling, ensuring both high performance and cost-effectiveness,\nthereby setting a new foundation for long-form video-language models in both\nacademic and practical applications.", "published": "2024-09-02 08:52:58", "link": "http://arxiv.org/abs/2409.01071v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Pre-Trained Language Models for Keyphrase Prediction: A Review", "abstract": "Keyphrase Prediction (KP) is essential for identifying keyphrases in a\ndocument that can summarize its content. However, recent Natural Language\nProcessing (NLP) advances have developed more efficient KP models using deep\nlearning techniques. The limitation of a comprehensive exploration jointly both\nkeyphrase extraction and generation using pre-trained language models\nspotlights a critical gap in the literature, compelling our survey paper to\nbridge this deficiency and offer a unified and in-depth analysis to address\nlimitations in previous surveys. This paper extensively examines the topic of\npre-trained language models for keyphrase prediction (PLM-KP), which are\ntrained on large text corpora via different learning (supervisor, unsupervised,\nsemi-supervised, and self-supervised) techniques, to provide respective\ninsights into these two types of tasks in NLP, precisely, Keyphrase Extraction\n(KPE) and Keyphrase Generation (KPG). We introduce appropriate taxonomies for\nPLM-KPE and KPG to highlight these two main tasks of NLP. Moreover, we point\nout some promising future directions for predicting keyphrases.", "published": "2024-09-02 09:15:44", "link": "http://arxiv.org/abs/2409.01087v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Real World Conversational Entity Linking Requires More Than Zeroshots", "abstract": "Entity linking (EL) in conversations faces notable challenges in practical\napplications, primarily due to the scarcity of entity-annotated conversational\ndatasets and sparse knowledge bases (KB) containing domain-specific, long-tail\nentities. We designed targeted evaluation scenarios to measure the efficacy of\nEL models under resource constraints. Our evaluation employs two KBs: Fandom,\nexemplifying real-world EL complexities, and the widely used Wikipedia. First,\nwe assess EL models' ability to generalize to a new unfamiliar KB using Fandom\nand a novel zero-shot conversational entity linking dataset that we curated\nbased on Reddit discussions on Fandom entities. We then evaluate the\nadaptability of EL models to conversational settings without prior training.\nOur results indicate that current zero-shot EL models falter when introduced to\nnew, domain-specific KBs without prior training, significantly dropping in\nperformance. Our findings reveal that previous evaluation approaches fall short\nof capturing real-world complexities for zero-shot EL, highlighting the\nnecessity for new approaches to design and assess conversational EL models to\nadapt to limited resources. The evaluation setup and the dataset proposed in\nthis research are made publicly available.", "published": "2024-09-02 10:37:53", "link": "http://arxiv.org/abs/2409.01152v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompt Compression with Context-Aware Sentence Encoding for Fast and\n  Improved LLM Inference", "abstract": "Large language models (LLMs) have triggered a new stream of research focusing\non compressing the context length to reduce the computational cost while\nensuring the retention of helpful information for LLMs to answer the given\nquestion. Token-based removal methods are one of the most prominent approaches\nin this direction, but risk losing the semantics of the context caused by\nintermediate token removal, especially under high compression ratios, while\nalso facing challenges in computational efficiency. In this work, we propose\ncontext-aware prompt compression (CPC), a sentence-level prompt compression\ntechnique where its key innovation is a novel context-aware sentence encoder\nthat provides a relevance score for each sentence for a given question. To\ntrain this encoder, we generate a new dataset consisting of questions,\npositives, and negative pairs where positives are sentences relevant to the\nquestion, while negatives are irrelevant context sentences. We train the\nencoder in a contrastive setup to learn context-aware sentence representations.\nOur method considerably outperforms prior works on prompt compression on\nbenchmark datasets and is up to 10.93x faster at inference compared to the best\ntoken-level compression method. We also find better improvement for shorter\nlength constraints in most benchmarks, showing the effectiveness of our\nproposed solution in the compression of relevant information in a shorter\ncontext. Finally, we release the code and the dataset for quick reproducibility\nand further development: https://github.com/Workday/cpc.", "published": "2024-09-02 13:02:51", "link": "http://arxiv.org/abs/2409.01227v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pairing Analogy-Augmented Generation with Procedural Memory for\n  Procedural Q&A", "abstract": "Large language models struggle to synthesize disparate pieces of information\ninto a coherent plan when approaching a complex procedural task. In this work,\nwe introduce a novel formalism and structure for such procedural knowledge.\nBased on this formalism, we present a novel procedural knowledge dataset called\nLCStep, which we created from LangChain tutorials. To leverage this procedural\nknowledge to solve new tasks, we propose analogy-augmented generation (AAG),\nwhich draws inspiration from the human ability to assimilate past experiences\nto solve unfamiliar problems. AAG uses a custom procedure memory store to\nretrieve and adapt specialized domain knowledge to answer new procedural tasks.\nWe demonstrate that AAG outperforms few-shot and RAG baselines on LCStep,\nRecipeNLG, and CHAMP datasets under a pairwise LLM-based evaluation,\ncorroborated by human evaluation in the case of RecipeNLG.", "published": "2024-09-02 15:58:24", "link": "http://arxiv.org/abs/2409.01344v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Language Models Benefit from Preparation with Elicited Knowledge", "abstract": "The zero-shot chain of thought (CoT) approach is often used in question\nanswering (QA) by language models (LMs) for tasks that require multiple\nreasoning steps. However, some QA tasks hinge more on accessing relevant\nknowledge than on chaining reasoning steps. We introduce a simple prompting\ntechnique, called PREP, that involves using two instances of LMs: the first\n(LM1) generates relevant information, and the second (LM2) receives the\ninformation from the user and answers the question. This design is intended to\nmake better use of the LM's instruction-following capability. PREP is\napplicable across various QA tasks without domain-specific prompt engineering.\nPREP is developed on a dataset of 100 QA questions, derived from an extensive\nschematic dataset specifying artifact parts and material composition. These\nquestions ask which of two artifacts is less likely to share materials with\nanother artifact. Such questions probe the LM's knowledge of shared materials\nin the part structure of different artifacts. We test our method on our\nparts-and-materials dataset and three published commonsense reasoning datasets.\nThe average accuracy of our method is consistently higher than that of all the\nother tested methods across all the tested datasets.", "published": "2024-09-02 15:58:27", "link": "http://arxiv.org/abs/2409.01345v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Know When to Fuse: Investigating Non-English Hybrid Retrieval in the\n  Legal Domain", "abstract": "Hybrid search has emerged as an effective strategy to offset the limitations\nof different matching paradigms, especially in out-of-domain contexts where\nnotable improvements in retrieval quality have been observed. However, existing\nresearch predominantly focuses on a limited set of retrieval methods, evaluated\nin pairs on domain-general datasets exclusively in English. In this work, we\nstudy the efficacy of hybrid search across a variety of prominent retrieval\nmodels within the unexplored field of law in the French language, assessing\nboth zero-shot and in-domain scenarios. Our findings reveal that in a zero-shot\ncontext, fusing different domain-general models consistently enhances\nperformance compared to using a standalone model, regardless of the fusion\nmethod. Surprisingly, when models are trained in-domain, we find that fusion\ngenerally diminishes performance relative to using the best single system,\nunless fusing scores with carefully tuned weights. These novel insights, among\nothers, expand the applicability of prior findings across a new field and\nlanguage, and contribute to a deeper understanding of hybrid search in\nnon-English specialized domains.", "published": "2024-09-02 16:19:13", "link": "http://arxiv.org/abs/2409.01357v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Membership Inference Attacks Against In-Context Learning", "abstract": "Adapting Large Language Models (LLMs) to specific tasks introduces concerns\nabout computational efficiency, prompting an exploration of efficient methods\nsuch as In-Context Learning (ICL). However, the vulnerability of ICL to privacy\nattacks under realistic assumptions remains largely unexplored. In this work,\nwe present the first membership inference attack tailored for ICL, relying\nsolely on generated texts without their associated probabilities. We propose\nfour attack strategies tailored to various constrained scenarios and conduct\nextensive experiments on four popular large language models. Empirical results\nshow that our attacks can accurately determine membership status in most cases,\ne.g., 95\\% accuracy advantage against LLaMA, indicating that the associated\nrisks are much higher than those shown by existing probability-based attacks.\nAdditionally, we propose a hybrid attack that synthesizes the strengths of the\naforementioned strategies, achieving an accuracy advantage of over 95\\% in most\ncases. Furthermore, we investigate three potential defenses targeting data,\ninstruction, and output. Results demonstrate combining defenses from orthogonal\ndimensions significantly reduces privacy leakage and offers enhanced privacy\nassurances.", "published": "2024-09-02 17:23:23", "link": "http://arxiv.org/abs/2409.01380v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Enhancing LLM-Based Text Classification in Political Science: Automatic\n  Prompt Optimization and Dynamic Exemplar Selection for Few-Shot Learning", "abstract": "Large language models (LLMs) offer substantial promise for text\nclassification in political science, yet their effectiveness often depends on\nhigh-quality prompts and exemplars. To address this, we introduce a three-stage\nframework that enhances LLM performance through automatic prompt optimization,\ndynamic exemplar selection, and a consensus mechanism. Our approach automates\nprompt refinement using task-specific exemplars, eliminating speculative\ntrial-and-error adjustments and producing structured prompts aligned with\nhuman-defined criteria. In the second stage, we dynamically select the most\nrelevant exemplars, ensuring contextually appropriate guidance for each query.\nFinally, our consensus mechanism mimics the role of multiple human coders for a\nsingle task, combining outputs from LLMs to achieve high reliability and\nconsistency at a reduced cost. Evaluated across tasks including sentiment\nanalysis, stance detection, and campaign ad tone classification, our method\nenhances classification accuracy without requiring task-specific model\nretraining or extensive manual adjustments to prompts. This framework not only\nboosts accuracy, interpretability and transparency but also provides a\ncost-effective, scalable solution tailored to political science applications.\nAn open-source Python package (PoliPrompt) is available on GitHub.", "published": "2024-09-02 21:05:31", "link": "http://arxiv.org/abs/2409.01466v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Masked Mixers for Language Generation and Retrieval", "abstract": "Attention mechanisms that confer selective focus on a strict subset of input\nelements are nearly ubiquitous in language models today. We posit there to be\ndownside to the use of attention: most input information is lost. In support of\nthis idea we observe poor input representation accuracy in transformers and\nmore accurate representation in what we term masked mixers, which replace\nself-attention with masked convolutions. The masked mixer learns causal\nlanguage modeling more efficiently than early transformer implementations and\neven outperforms optimized, current transformers when training on small\n($n_{ctx}<512$) but not larger context windows. Evidence is presented for the\nhypothesis that differences in transformer and masked mixer training\nefficiencies for various tasks are best predicted by input representation\naccuracy, or equivalently global invertibility. We hypothesize that the\ninformation loss exhibited by transformers would be more detrimental to\nretrieval than generation, as the former is more closely approximated by a\nbijective and thus invertible function. We find that masked mixers are more\neffective retrieval models both when the pretrained embedding model is\nunchanged as well as when the embedding model is modified via cosine\nsimilarity-based InfoNCE loss minimization. A small masked mixer is shown to\noutperform a large and near state-of-the-art transformer-based retrieval model,\ndespite the latter being trained with many orders of magnitude more data and\ncompute.", "published": "2024-09-02 22:17:18", "link": "http://arxiv.org/abs/2409.01482v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting SMoE Language Models by Evaluating Inefficiencies with Task\n  Specific Expert Pruning", "abstract": "Sparse Mixture of Expert (SMoE) models have emerged as a scalable alternative\nto dense models in language modeling. These models use conditionally activated\nfeedforward subnetworks in transformer blocks, allowing for a separation\nbetween total model parameters and per-example computation. However, large\ntoken-routed SMoE models face a significant challenge: during inference, the\nentire model must be used for a sequence or a batch, resulting in high\nlatencies in a distributed setting that offsets the advantages of per-token\nsparse activation. Our research explores task-specific model pruning to inform\ndecisions about designing SMoE architectures, mainly modulating the choice of\nexpert counts in pretraining. We investigate whether such pruned models offer\nadvantages over smaller SMoE models trained from scratch, when evaluating and\ncomparing them individually on tasks. To that end, we introduce an adaptive\ntask-aware pruning technique UNCURL to reduce the number of experts per MoE\nlayer in an offline manner post-training. Our findings reveal a threshold\npruning factor for the reduction that depends on the number of experts used in\npretraining, above which, the reduction starts to degrade model performance.\nThese insights contribute to our understanding of model design choices when\npretraining with SMoE architectures, particularly useful when considering\ntask-specific inference optimization for later stages.", "published": "2024-09-02 22:35:03", "link": "http://arxiv.org/abs/2409.01483v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Agentic Society: Merging skeleton from real world and texture from Large\n  Language Model", "abstract": "Recent advancements in large language models (LLMs) and agent technologies\noffer promising solutions to the simulation of social science experiments, but\nthe availability of data of real-world population required by many of them\nstill poses as a major challenge. This paper explores a novel framework that\nleverages census data and LLMs to generate virtual populations, significantly\nreducing resource requirements and bypassing privacy compliance issues\nassociated with real-world data, while keeping a statistical truthfulness.\nDrawing on real-world census data, our approach first generates a persona that\nreflects demographic characteristics of the population. We then employ LLMs to\nenrich these personas with intricate details, using techniques akin to those in\nimage generative models but applied to textual data. Additionally, we propose a\nframework for the evaluation of the feasibility of our method with respect to\ncapability of LLMs based on personality trait tests, specifically the Big Five\nmodel, which also enhances the depth and realism of the generated personas.\nThrough preliminary experiments and analysis, we demonstrate that our method\nproduces personas with variability essential for simulating diverse human\nbehaviors in social science experiments. But the evaluation result shows that\nonly weak sign of statistical truthfulness can be produced due to limited\ncapability of current LLMs. Insights from our study also highlight the tension\nwithin LLMs between aligning with human values and reflecting real-world\ncomplexities. Thorough and rigorous test call for further research. Our codes\nare released at https://github.com/baiyuqi/agentic-society.git", "published": "2024-09-02 08:28:19", "link": "http://arxiv.org/abs/2409.10550v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "ToolACE: Winning the Points of LLM Function Calling", "abstract": "Function calling significantly extends the application boundary of large\nlanguage models, where high-quality and diverse training data is critical for\nunlocking this capability. However, real function-calling data is quite\nchallenging to collect and annotate, while synthetic data generated by existing\npipelines tends to lack coverage and accuracy. In this paper, we present\nToolACE, an automatic agentic pipeline designed to generate accurate, complex,\nand diverse tool-learning data. ToolACE leverages a novel self-evolution\nsynthesis process to curate a comprehensive API pool of 26,507 diverse APIs.\nDialogs are further generated through the interplay among multiple agents,\nguided by a formalized thinking process. To ensure data accuracy, we implement\na dual-layer verification system combining rule-based and model-based checks.\nWe demonstrate that models trained on our synthesized data, even with only 8B\nparameters, achieve state-of-the-art performance on the Berkeley\nFunction-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a\nsubset of the data are publicly available at https://huggingface.co/Team-ACE.", "published": "2024-09-02 03:19:56", "link": "http://arxiv.org/abs/2409.00920v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Co-Learning: Code Learning for Multi-Agent Reinforcement Collaborative\n  Framework with Conversational Natural Language Interfaces", "abstract": "Online question-and-answer (Q\\&A) systems based on the Large Language Model\n(LLM) have progressively diverged from recreational to professional use. This\npaper proposed a Multi-Agent framework with environmentally reinforcement\nlearning (E-RL) for code correction called Code Learning (Co-Learning)\ncommunity, assisting beginners to correct code errors independently. It\nevaluates the performance of multiple LLMs from an original dataset with 702\nerror codes, uses it as a reward or punishment criterion for E-RL; Analyzes\ninput error codes by the current agent; selects the appropriate LLM-based agent\nto achieve optimal error correction accuracy and reduce correction time.\nExperiment results showed that 3\\% improvement in Precision score and 15\\%\nimprovement in time cost as compared with no E-RL method respectively. Our\nsource code is available at: https://github.com/yuqian2003/Co_Learning", "published": "2024-09-02 07:03:22", "link": "http://arxiv.org/abs/2409.00985v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Personalized Lip Reading: Adapting to Your Unique Lip Movements with\n  Vision and Language", "abstract": "Lip reading aims to predict spoken language by analyzing lip movements.\nDespite advancements in lip reading technologies, performance degrades when\nmodels are applied to unseen speakers due to their sensitivity to variations in\nvisual information such as lip appearances. To address this challenge, speaker\nadaptive lip reading technologies have advanced by focusing on effectively\nadapting a lip reading model to target speakers in the visual modality.\nHowever, the effectiveness of adapting language information, such as vocabulary\nchoice, of the target speaker has not been explored in previous works.\nAdditionally, existing datasets for speaker adaptation have limited vocabulary\nsizes and pose variations, which restrict the validation of previous\nspeaker-adaptive methods in real-world scenarios. To address these issues, we\npropose a novel speaker-adaptive lip reading method that adapts a pre-trained\nmodel to target speakers at both vision and language levels. Specifically, we\nintegrate prompt tuning and the LoRA approach, applying them to a pre-trained\nlip reading model to effectively adapt the model to target speakers.\nFurthermore, to validate its effectiveness in real-world scenarios, we\nintroduce a new dataset, VoxLRS-SA, derived from VoxCeleb2 and LRS3. It\ncontains a vocabulary of approximately 100K words, offers diverse pose\nvariations, and enables the validation of adaptation methods in the wild,\nsentence-level lip reading for the first time in English. Through various\nexperiments, we demonstrate that the existing speaker-adaptive method also\nimproves performance in the wild at the sentence level. Moreover, we show that\nthe proposed method achieves larger improvements compared to the previous\nworks.", "published": "2024-09-02 07:05:12", "link": "http://arxiv.org/abs/2409.00986v2", "categories": ["cs.CV", "cs.CL", "eess.AS", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Unleashing the Power of Task-Specific Directions in Parameter Efficient\n  Fine-tuning", "abstract": "Large language models demonstrate impressive performance on downstream tasks,\nyet requiring extensive resource consumption when fully fine-tuning all\nparameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT)\nstrategies, such as LoRA, have been developed. In this paper, we delve into the\nconcept of task-specific directions (TSDs)-critical for transitioning large\nmodels from pretrained states to task-specific enhancements in PEFT. We propose\na framework to clearly define these directions and explore their properties,\nand practical utilization challenges. We then introduce a novel approach,\nLoRA-Dash, which aims to maximize the impact of TSDs during the fine-tuning\nprocess, thereby enhancing model performance on targeted tasks. Extensive\nexperiments have conclusively demonstrated the effectiveness of LoRA-Dash, and\nin-depth analyses further reveal the underlying mechanisms of LoRA-Dash. The\ncode is available at https://github.com/Chongjie-Si/Subspace-Tuning.", "published": "2024-09-02 08:10:51", "link": "http://arxiv.org/abs/2409.01035v3", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SCOPE: Sign Language Contextual Processing with Embedding from LLMs", "abstract": "Sign languages, used by around 70 million Deaf individuals globally, are\nvisual languages that convey visual and contextual information. Current methods\nin vision-based sign language recognition (SLR) and translation (SLT) struggle\nwith dialogue scenes due to limited dataset diversity and the neglect of\ncontextually relevant information. To address these challenges, we introduce\nSCOPE (Sign language Contextual Processing with Embedding from LLMs), a novel\ncontext-aware vision-based SLR and SLT framework. For SLR, we utilize dialogue\ncontexts through a multi-modal encoder to enhance gloss-level recognition. For\nsubsequent SLT, we further fine-tune a Large Language Model (LLM) by\nincorporating prior conversational context. We also contribute a new sign\nlanguage dataset that contains 72 hours of Chinese sign language videos in\ncontextual dialogues across various scenarios. Experimental results demonstrate\nthat our SCOPE framework achieves state-of-the-art performance on multiple\ndatasets, including Phoenix-2014T, CSL-Daily, and our SCOPE dataset. Moreover,\nsurveys conducted with participants from the Deaf community further validate\nthe robustness and effectiveness of our approach in real-world applications.\nBoth our dataset and code will be open-sourced to facilitate further research.", "published": "2024-09-02 08:56:12", "link": "http://arxiv.org/abs/2409.01073v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models", "abstract": "Backdoors can be injected into NLP models to induce misbehavior when the\ninput text contains a specific feature, known as a trigger, which the attacker\nsecretly selects. Unlike fixed words, phrases, or sentences used in the static\ntext trigger, NLP dynamic backdoor attacks design triggers associated with\nabstract and latent text features, making them considerably stealthier than\ntraditional static backdoor attacks. However, existing research on NLP backdoor\ndetection primarily focuses on defending against static backdoor attacks, while\ndetecting dynamic backdoors in NLP models remains largely unexplored. This\npaper presents CLIBE, the first framework to detect dynamic backdoors in\nTransformer-based NLP models. CLIBE injects a \"few-shot perturbation\" into the\nsuspect Transformer model by crafting optimized weight perturbation in the\nattention layers to make the perturbed model classify a limited number of\nreference samples as a target label. Subsequently, CLIBE leverages the\ngeneralization ability of this few-shot perturbation to determine whether the\noriginal model contains a dynamic backdoor. Extensive evaluation on three\nadvanced NLP dynamic backdoor attacks, two widely-used Transformer frameworks,\nand four real-world classification tasks strongly validates the effectiveness\nof CLIBE. We also demonstrate the robustness of CLIBE against various adaptive\nattacks. Furthermore, we employ CLIBE to scrutinize 49 popular Transformer\nmodels on Hugging Face and discover one exhibiting a high probability of\ncontaining a dynamic backdoor. We have contacted Hugging Face and provided\ndetailed evidence of this model's backdoor behavior. Moreover, we extend CLIBE\nto detect backdoor text generation models modified to exhibit toxic behavior.\nTo the best of our knowledge, CLIBE is the first framework capable of detecting\nbackdoors in text generation models without access to trigger input test\nsamples.", "published": "2024-09-02 11:59:56", "link": "http://arxiv.org/abs/2409.01193v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A multilingual training strategy for low resource Text to Speech", "abstract": "Recent speech technologies have led to produce high quality synthesised\nspeech due to recent advances in neural Text to Speech (TTS). However, such TTS\nmodels depend on extensive amounts of data that can be costly to produce and is\nhardly scalable to all existing languages, especially that seldom attention is\ngiven to low resource languages. With techniques such as knowledge transfer,\nthe burden of creating datasets can be alleviated. In this paper, we therefore\ninvestigate two aspects; firstly, whether data from social media can be used\nfor a small TTS dataset construction, and secondly whether cross lingual\ntransfer learning (TL) for a low resource language can work with this type of\ndata. In this aspect, we specifically assess to what extent multilingual\nmodeling can be leveraged as an alternative to training on monolingual\ncorporas. To do so, we explore how data from foreign languages may be selected\nand pooled to train a TTS model for a target low resource language. Our\nfindings show that multilingual pre-training is better than monolingual\npre-training at increasing the intelligibility and naturalness of the generated\nspeech.", "published": "2024-09-02 12:53:01", "link": "http://arxiv.org/abs/2409.01217v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Conversational Complexity for Assessing Risk in Large Language Models", "abstract": "Large Language Models (LLMs) present a dual-use dilemma: they enable\nbeneficial applications while harboring potential for harm, particularly\nthrough conversational interactions. Despite various safeguards, advanced LLMs\nremain vulnerable. A watershed case in early 2023 involved journalist Kevin\nRoose's extended dialogue with Bing, an LLM-powered search engine, which\nrevealed harmful outputs after probing questions, highlighting vulnerabilities\nin the model's safeguards. This contrasts with simpler early jailbreaks, like\nthe \"Grandma Jailbreak,\" where users framed requests as innocent help for a\ngrandmother, easily eliciting similar content. This raises the question: How\nmuch conversational effort is needed to elicit harmful information from LLMs?\nWe propose two measures to quantify this effort: Conversational Length (CL),\nwhich measures the number of conversational turns needed to obtain a specific\nharmful response, and Conversational Complexity (CC), defined as the Kolmogorov\ncomplexity of the user's instruction sequence leading to the harmful response.\nTo address the incomputability of Kolmogorov complexity, we approximate CC\nusing a reference LLM to estimate the compressibility of the user instructions.\nApplying this approach to a large red-teaming dataset, we perform a\nquantitative analysis examining the statistical distribution of harmful and\nharmless conversational lengths and complexities. Our empirical findings\nsuggest that this distributional analysis and the minimization of CC serve as\nvaluable tools for understanding AI safety, offering insights into the\naccessibility of harmful information. This work establishes a foundation for a\nnew perspective on LLM safety, centered around the algorithmic complexity of\npathways to harm.", "published": "2024-09-02 13:29:44", "link": "http://arxiv.org/abs/2409.01247v3", "categories": ["cs.AI", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.AI"}
{"title": "CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and\n  Selective Sparsification", "abstract": "Deploying large language models (LLMs) on edge devices presents significant\nchallenges due to the substantial computational overhead and memory\nrequirements. Activation sparsification can mitigate these resource challenges\nby reducing the number of activated neurons during inference. Existing methods\ntypically employ thresholding-based sparsification based on the statistics of\nactivation tensors. However, they do not model the impact of activation\nsparsification on performance, resulting in suboptimal performance degradation.\nTo address the limitations, this paper reformulates the activation\nsparsification problem to explicitly capture the relationship between\nactivation sparsity and model performance. Then, this paper proposes CHESS, a\ngeneral activation sparsification approach via CHannel-wise thrEsholding and\nSelective Sparsification. First, channel-wise thresholding assigns a unique\nthreshold to each activation channel in the feed-forward network (FFN) layers.\nThen, selective sparsification involves applying thresholding-based activation\nsparsification to specific layers within the attention modules. Finally, we\ndetail the implementation of sparse kernels to accelerate LLM inference.\nExperimental results demonstrate that the proposed CHESS achieves lower\nperformance degradation over eight downstream tasks while activating fewer\nparameters than existing methods, thus speeding up the LLM inference by up to\n1.27x.", "published": "2024-09-02 16:41:44", "link": "http://arxiv.org/abs/2409.01366v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Imitating Language via Scalable Inverse Reinforcement Learning", "abstract": "The majority of language model training builds on imitation learning. It\ncovers pretraining, supervised fine-tuning, and affects the starting conditions\nfor reinforcement learning from human feedback (RLHF). The simplicity and\nscalability of maximum likelihood estimation (MLE) for next token prediction\nled to its role as predominant paradigm. However, the broader field of\nimitation learning can more effectively utilize the sequential structure\nunderlying autoregressive generation. We focus on investigating the inverse\nreinforcement learning (IRL) perspective to imitation, extracting rewards and\ndirectly optimizing sequences instead of individual token likelihoods and\nevaluate its benefits for fine-tuning large language models. We provide a new\nangle, reformulating inverse soft-Q-learning as a temporal difference\nregularized extension of MLE. This creates a principled connection between MLE\nand IRL and allows trading off added complexity with increased performance and\ndiversity of generations in the supervised fine-tuning (SFT) setting. We find\nclear advantages for IRL-based imitation, in particular for retaining diversity\nwhile maximizing task performance, rendering IRL a strong alternative on fixed\nSFT datasets even without online data generation. Our analysis of IRL-extracted\nreward functions further indicates benefits for more robust reward functions\nvia tighter integration of supervised and preference-based LLM post-training.", "published": "2024-09-02 16:48:57", "link": "http://arxiv.org/abs/2409.01369v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously\n  Designing Collaborative AI Systems", "abstract": "Much previous AI research has focused on developing monolithic models to\nmaximize their intelligence, with the primary goal of enhancing performance on\nspecific tasks. In contrast, this work attempts to study using LLM-based agents\nto design collaborative AI systems autonomously. To explore this problem, we\nfirst introduce ComfyBench to evaluate agents's ability to design collaborative\nAI systems in ComfyUI. ComfyBench is a comprehensive benchmark comprising 200\ndiverse tasks covering various instruction-following generation challenges,\nalong with detailed annotations for 3,205 nodes and 20 workflows. Based on\nComfyBench, we further develop ComfyAgent, a novel framework that empowers\nLLM-based agents to autonomously design collaborative AI systems by generating\nworkflows. ComfyAgent is based on two core concepts. First, it represents\nworkflows with code, which can be reversibly converted into workflows and\nexecuted as collaborative systems by the interpreter. Second, it constructs a\nmulti-agent system that cooperates to learn from existing workflows and\ngenerate new workflows for a given task. While experimental results demonstrate\nthat ComfyAgent achieves a comparable resolve rate to o1-preview and\nsignificantly surpasses other agents on ComfyBench, ComfyAgent has resolved\nonly 15\\% of creative tasks. LLM-based agents still have a long way to go in\nautonomously designing collaborative AI systems. Progress with ComfyBench is\npaving the way for more intelligent and autonomous collaborative AI systems.", "published": "2024-09-02 17:44:10", "link": "http://arxiv.org/abs/2409.01392v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Large Language Models versus Classical Machine Learning: Performance in\n  COVID-19 Mortality Prediction Using High-Dimensional Tabular Data", "abstract": "Background: This study aimed to evaluate and compare the performance of\nclassical machine learning models (CMLs) and large language models (LLMs) in\npredicting mortality associated with COVID-19 by utilizing a high-dimensional\ntabular dataset.\n  Materials and Methods: We analyzed data from 9,134 COVID-19 patients\ncollected across four hospitals. Seven CML models, including XGBoost and random\nforest (RF), were trained and evaluated. The structured data was converted into\ntext for zero-shot classification by eight LLMs, including GPT-4 and\nMistral-7b. Additionally, Mistral-7b was fine-tuned using the QLoRA approach to\nenhance its predictive capabilities.\n  Results: Among the CML models, XGBoost and RF achieved the highest accuracy,\nwith F1 scores of 0.87 for internal validation and 0.83 for external\nvalidation. In the LLM category, GPT-4 was the top performer with an F1 score\nof 0.43. Fine-tuning Mistral-7b significantly improved its recall from 1% to\n79%, resulting in an F1 score of 0.74, which was stable during external\nvalidation.\n  Conclusion: While LLMs show moderate performance in zero-shot classification,\nfine-tuning can significantly enhance their effectiveness, potentially aligning\nthem closer to CML models. However, CMLs still outperform LLMs in\nhigh-dimensional tabular data tasks.", "published": "2024-09-02 14:51:12", "link": "http://arxiv.org/abs/2409.02136v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "92C50, 68T50", "J.3"], "primary_category": "cs.LG"}
{"title": "Efficient and Scalable Estimation of Tool Representations in Vector\n  Space", "abstract": "Recent advancements in function calling and tool use have significantly\nenhanced the capabilities of large language models (LLMs) by enabling them to\ninteract with external information sources and execute complex tasks. However,\nthe limited context window of LLMs presents challenges when a large number of\ntools are available, necessitating efficient methods to manage prompt length\nand maintain accuracy. Existing approaches, such as fine-tuning LLMs or\nleveraging their reasoning capabilities, either require frequent retraining or\nincur significant latency overhead. A more efficient solution involves training\nsmaller models to retrieve the most relevant tools for a given query, although\nthis requires high quality, domain-specific data. To address those challenges,\nwe present a novel framework for generating synthetic data for tool retrieval\napplications and an efficient data-driven tool retrieval strategy using small\nencoder models. Empowered by LLMs, we create ToolBank, a new tool retrieval\ndataset that reflects real human user usages. For tool retrieval methodologies,\nwe propose novel approaches: (1) Tool2Vec: usage-driven tool embedding\ngeneration for tool retrieval, (2) ToolRefiner: a staged retrieval method that\niteratively improves the quality of retrieved tools, and (3) MLC: framing tool\nretrieval as a multi-label classification problem. With these new methods, we\nachieve improvements of up to 27.28 in Recall@K on the ToolBench dataset and\n30.5 in Recall@K on ToolBank. Additionally, we present further experimental\nresults to rigorously validate our methods. Our code is available at\n\\url{https://github.com/SqueezeAILab/Tool2Vec}", "published": "2024-09-02 19:39:24", "link": "http://arxiv.org/abs/2409.02141v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Seeing Through Their Eyes: Evaluating Visual Perspective Taking in\n  Vision Language Models", "abstract": "Visual perspective-taking (VPT), the ability to understand the viewpoint of\nanother person, enables individuals to anticipate the actions of other people.\nFor instance, a driver can avoid accidents by assessing what pedestrians see.\nHumans typically develop this skill in early childhood, but it remains unclear\nwhether the recently emerging Vision Language Models (VLMs) possess such\ncapability. Furthermore, as these models are increasingly deployed in the real\nworld, understanding how they perform nuanced tasks like VPT becomes essential.\nIn this paper, we introduce two manually curated datasets, Isle-Bricks and\nIsle-Dots for testing VPT skills, and we use it to evaluate 12 commonly used\nVLMs. Across all models, we observe a significant performance drop when\nperspective-taking is required. Additionally, we find performance in object\ndetection tasks is poorly correlated with performance on VPT tasks, suggesting\nthat the existing benchmarks might not be sufficient to understand this\nproblem. The code and the dataset will be available at\nhttps://sites.google.com/view/perspective-taking", "published": "2024-09-02 16:32:03", "link": "http://arxiv.org/abs/2409.12969v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Declarative Integration and Management of Large Language Models through\n  Finite Automata: Application to Automation, Communication, and Ethics", "abstract": "This article introduces an innovative architecture designed to declaratively\ncombine Large Language Models (LLMs) with shared histories, and triggers to\nidentify the most appropriate LLM for a given task. Our approach is general and\ndeclarative, relying on the construction of finite automata coupled with an\nevent management system. The developed tool is crafted to facilitate the\nefficient and complex integration of LLMs with minimal programming effort,\nespecially, but not only, for integrating methods of positive psychology to AI.\nThe flexibility of our technique is demonstrated through applied examples in\nautomation, communication, and ethics.", "published": "2024-09-02 11:50:52", "link": "http://arxiv.org/abs/2409.13693v1", "categories": ["cs.FL", "cs.AI", "cs.CL", "cs.ET", "cs.HC", "68T20", "I.2.7; H.5.2; K.4.1; D.3.2"], "primary_category": "cs.FL"}
{"title": "SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient\n  Language Model Based Text-to-Speech Synthesis", "abstract": "The long speech sequence has been troubling language models (LM) based TTS\napproaches in terms of modeling complexity and efficiency. This work proposes\nSoCodec, a semantic-ordered multi-stream speech codec, to address this issue.\nIt compresses speech into a shorter, multi-stream discrete semantic sequence\nwith multiple tokens at each frame. Meanwhile, the ordered product quantization\nis proposed to constrain this sequence into an ordered representation. It can\nbe applied with a multi-stream delayed LM to achieve better autoregressive\ngeneration along both time and stream axes in TTS. The experimental result\nstrongly demonstrates the effectiveness of the proposed approach, achieving\nsuperior performance over baseline systems even if compressing the frameshift\nof speech from 20ms to 240ms (12x). The ablation studies further validate the\nimportance of learning the proposed ordered multi-stream semantic\nrepresentation in pursuing shorter speech sequences for efficient LM-based TTS.", "published": "2024-09-02 04:13:20", "link": "http://arxiv.org/abs/2409.00933v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Suppressing Noise Disparity in Training Data for Automatic Pathological\n  Speech Detection", "abstract": "Although automatic pathological speech detection approaches show promising\nresults when clean recordings are available, they are vulnerable to additive\nnoise. Recently it has been shown that databases commonly used to develop and\nevaluate such approaches are noisy, with the noise characteristics between\nhealthy and pathological recordings being different. Consequently, automatic\napproaches trained on these databases often learn to discriminate noise rather\nthan speech pathology. This paper introduces a method to mitigate this noise\ndisparity in training data. Using noise estimates from recordings from one\ngroup of speakers to augment recordings from the other group, the noise\ncharacteristics become consistent across all recordings. Experimental results\ndemonstrate the efficacy of this approach in mitigating noise disparity in\ntraining data, thereby enabling automatic pathological speech detection to\nfocus on pathology-discriminant cues rather than noise-discriminant ones.", "published": "2024-09-02 12:37:10", "link": "http://arxiv.org/abs/2409.01209v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Resource-Efficient Adaptation of Speech Foundation Models for\n  Multi-Speaker ASR", "abstract": "Speech foundation models have achieved state-of-the-art (SoTA) performance\nacross various tasks, such as automatic speech recognition (ASR) in hundreds of\nlanguages. However, multi-speaker ASR remains a challenging task for these\nmodels due to data scarcity and sparsity. In this paper, we present approaches\nto enable speech foundation models to process and understand multi-speaker\nspeech with limited training data. Specifically, we adapt a speech foundation\nmodel for the multi-speaker ASR task using only telephonic data. Remarkably,\nthe adapted model also performs well on meeting data without any fine-tuning,\ndemonstrating the generalization ability of our approach. We conduct several\nablation studies to analyze the impact of different parameters and strategies\non model performance. Our findings highlight the effectiveness of our methods.\nResults show that less parameters give better overall cpWER, which, although\ncounter-intuitive, provides insights into adapting speech foundation models for\nmulti-speaker ASR tasks with minimal annotated data.", "published": "2024-09-02 19:43:45", "link": "http://arxiv.org/abs/2409.01438v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MMT-BERT: Chord-aware Symbolic Music Generation Based on Multitrack\n  Music Transformer and MusicBERT", "abstract": "We propose a novel symbolic music representation and Generative Adversarial\nNetwork (GAN) framework specially designed for symbolic multitrack music\ngeneration. The main theme of symbolic music generation primarily encompasses\nthe preprocessing of music data and the implementation of a deep learning\nframework. Current techniques dedicated to symbolic music generation generally\nencounter two significant challenges: training data's lack of information about\nchords and scales and the requirement of specially designed model architecture\nadapted to the unique format of symbolic music representation. In this paper,\nwe solve the above problems by introducing new symbolic music representation\nwith MusicLang chord analysis model. We propose our MMT-BERT architecture\nadapting to the representation. To build a robust multitrack music generator,\nwe fine-tune a pre-trained MusicBERT model to serve as the discriminator, and\nincorporate relativistic standard loss. This approach, supported by the\nin-depth understanding of symbolic music encoded within MusicBERT, fortifies\nthe consonance and humanity of music generated by our method. Experimental\nresults demonstrate the effectiveness of our approach which strictly follows\nthe state-of-the-art methods.", "published": "2024-09-02 03:18:56", "link": "http://arxiv.org/abs/2409.00919v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Framework for Synthetic Audio Conversations Generation using Large\n  Language Models", "abstract": "In this paper, we introduce ConversaSynth, a framework designed to generate\nsynthetic conversation audio using large language models (LLMs) with multiple\npersona settings. The framework first creates diverse and coherent text-based\ndialogues across various topics, which are then converted into audio using\ntext-to-speech (TTS) systems. Our experiments demonstrate that ConversaSynth\neffectively generates highquality synthetic audio datasets, which can\nsignificantly enhance the training and evaluation of models for audio tagging,\naudio classification, and multi-speaker speech recognition. The results\nindicate that the synthetic datasets generated by ConversaSynth exhibit\nsubstantial diversity and realism, making them suitable for developing robust,\nadaptable audio-based AI systems.", "published": "2024-09-02 05:09:46", "link": "http://arxiv.org/abs/2409.00946v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Interpretable Convolutional SyncNet", "abstract": "Because videos in the wild can be out of sync for various reasons, a sync-net\nis used to bring the video back into sync for tasks that require synchronized\nvideos. Previous state-of-the-art (SOTA) sync-nets use InfoNCE loss, rely on\nthe transformer architecture, or both. Unfortunately, the former makes the\nmodel's output difficult to interpret, and the latter is unfriendly with large\nimages, thus limiting the usefulness of sync-nets. In this work, we train a\nconvolutional sync-net using the balanced BCE loss (BBCE), a loss inspired by\nthe binary cross entropy (BCE) and the InfoNCE losses. In contrast to the\nInfoNCE loss, the BBCE loss does not require complicated sampling schemes. Our\nmodel can better handle larger images, and its output can be given a\nprobabilistic interpretation. The probabilistic interpretation allows us to\ndefine metrics such as probability at offset and offscreen ratio to evaluate\nthe sync quality of audio-visual (AV) speech datasets. Furthermore, our model\nachieves SOTA accuracy of $96.5\\%$ on the LRS2 dataset and $93.8\\%$ on the LRS3\ndataset.", "published": "2024-09-02 06:26:48", "link": "http://arxiv.org/abs/2409.00971v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Expanding on EnCLAP with Auxiliary Retrieval Model for Automated Audio\n  Captioning", "abstract": "In this technical report, we describe our submission to DCASE2024 Challenge\nTask6 (Automated Audio Captioning) and Task8 (Language-based Audio Retrieval).\nWe develop our approach building upon the EnCLAP audio captioning framework and\noptimizing it for Task6 of the challenge. Notably, we outline the changes in\nthe underlying components and the incorporation of the reranking process.\nAdditionally, we submit a supplementary retriever model, a byproduct of our\nmodified framework, to Task8. Our proposed systems achieve FENSE score of 0.542\non Task6 and mAP@10 score of 0.386 on Task8, significantly outperforming the\nbaseline models.", "published": "2024-09-02 10:47:07", "link": "http://arxiv.org/abs/2409.01160v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EnCLAP++: Analyzing the EnCLAP Framework for Optimizing Automated Audio\n  Captioning Performance", "abstract": "In this work, we aim to analyze and optimize the EnCLAP framework, a\nstate-of-the-art model in automated audio captioning. We investigate the impact\nof modifying the acoustic encoder components, explore pretraining with\ndifferent dataset scales, and study the effectiveness of a reranking scheme.\nThrough extensive experimentation and quantitative analysis of generated\ncaptions, we develop EnCLAP++, an enhanced version that significantly surpasses\nthe original.", "published": "2024-09-02 12:23:18", "link": "http://arxiv.org/abs/2409.01201v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spectron: Target Speaker Extraction using Conditional Transformer with\n  Adversarial Refinement", "abstract": "Recently, attention-based transformers have become a de facto standard in\nmany deep learning applications including natural language processing, computer\nvision, signal processing, etc.. In this paper, we propose a transformer-based\nend-to-end model to extract a target speaker's speech from a monaural\nmulti-speaker mixed audio signal. Unlike existing speaker extraction methods,\nwe introduce two additional objectives to impose speaker embedding consistency\nand waveform encoder invertibility and jointly train both speaker encoder and\nspeech separator to better capture the speaker conditional embedding.\nFurthermore, we leverage a multi-scale discriminator to refine the perceptual\nquality of the extracted speech. Our experiments show that the use of a dual\npath transformer in the separator backbone along with proposed training\nparadigm improves the CNN baseline by $3.12$ dB points. Finally, we compare our\napproach with recent state-of-the-arts and show that our model outperforms\nexisting methods by $4.1$ dB points on an average without creating additional\ndata dependency.", "published": "2024-09-02 16:11:12", "link": "http://arxiv.org/abs/2409.01352v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
