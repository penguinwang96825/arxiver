{"title": "SinSpell: A Comprehensive Spelling Checker for Sinhala", "abstract": "We have built SinSpell, a comprehensive spelling checker for the Sinhala\nlanguage which is spoken by over 16 million people, mainly in Sri Lanka.\nHowever, until recently, Sinhala had no spelling checker with acceptable\ncoverage. Sinspell is still the only open source Sinhala spelling checker.\nSinSpell identifies possible spelling errors and suggests corrections. It also\ncontains a module which auto-corrects evident errors. To maintain accuracy,\nSinSpell was designed as a rule-based system based on Hunspell. A set of words\nwas compiled from several sources and verified. These were divided into\nmorphological classes, and the valid roots, suffixes and prefixes for each\nclass were identified, together with lists of irregular words and exceptions.\nThe errors in a corpus of Sinhala documents were analysed and commonly\nmisspelled words and types of common errors were identified. We found that the\nmost common errors were in vowel length and similar sounding letters. Errors\ndue to incorrect typing and encoding were also found. This analysis was used to\ndevelop the suggestion generator and auto-corrector.", "published": "2021-07-07 02:36:43", "link": "http://arxiv.org/abs/2107.02983v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MedGPT: Medical Concept Prediction from Clinical Narratives", "abstract": "The data available in Electronic Health Records (EHRs) provides the\nopportunity to transform care, and the best way to provide better care for one\npatient is through learning from the data available on all other patients.\nTemporal modelling of a patient's medical history, which takes into account the\nsequence of past events, can be used to predict future events such as a\ndiagnosis of a new disorder or complication of a previous or existing disorder.\nWhile most prediction approaches use mostly the structured data in EHRs or a\nsubset of single-domain predictions and outcomes, we present MedGPT a novel\ntransformer-based pipeline that uses Named Entity Recognition and Linking tools\n(i.e. MedCAT) to structure and organize the free text portion of EHRs and\nanticipate a range of future medical events (initially disorders). Since a\nlarge portion of EHR data is in text form, such an approach benefits from a\ngranular and detailed view of a patient while introducing modest additional\nnoise. MedGPT effectively deals with the noise and the added granularity, and\nachieves a precision of 0.344, 0.552 and 0.640 (vs LSTM 0.329, 0.538 and 0.633)\nwhen predicting the top 1, 3 and 5 candidate future disorders on real world\nhospital data from King's College Hospital, London, UK (\\textasciitilde600k\npatients). We also show that our model captures medical knowledge by testing it\non an experimental medical multiple choice question answering task, and by\nexamining the attentional focus of the model using gradient-based saliency\nmethods.", "published": "2021-07-07 10:36:28", "link": "http://arxiv.org/abs/2107.03134v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Text Classification of Urdu News using Deep Neural Network", "abstract": "Digital text is increasing day by day on the internet. It is very challenging\nto classify a large and heterogeneous collection of data, which require\nimproved information processing methods to organize text. To classify large\nsize of corpus, one common approach is to use hierarchical text classification,\nwhich aims to classify textual data in a hierarchical structure. Several\napproaches have been proposed to tackle classification of text but most of the\nresearch has been done on English language. This paper proposes a deep learning\nmodel for hierarchical text classification of news in Urdu language -\nconsisting of 51,325 sentences from 8 online news websites belonging to the\nfollowing genres: Sports; Technology; and Entertainment. The objectives of this\npaper are twofold: (1) to develop a large human-annotated dataset of news in\nUrdu language for hierarchical text classification; and (2) to classify Urdu\nnews hierarchically using our proposed model based on LSTM mechanism named as\nHierarchical Multi-layer LSTMs (HMLSTM). Our model consists of two modules:\nText Representing Layer, for obtaining text representation in which we use\nWord2vec embedding to transform the words to vector and Urdu Hierarchical LSTM\nLayer (UHLSTML) an end-to-end fully connected deep LSTMs network to perform\nautomatic feature learning, we train one LSTM layer for each level of the class\nhierarchy. We have performed extensive experiments on our self created dataset\nnamed as Urdu News Dataset for Hierarchical Text Classification (UNDHTC). The\nresult shows that our proposed method is very effective for hierarchical text\nclassification and it outperforms baseline methods significantly and also\nachieved good results as compare to deep neural model.", "published": "2021-07-07 11:06:11", "link": "http://arxiv.org/abs/2107.03141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Dialogue Summarization: Recent Advances and New Frontiers", "abstract": "Dialogue summarization aims to condense the original dialogue into a shorter\nversion covering salient information, which is a crucial way to reduce dialogue\ndata overload. Recently, the promising achievements in both dialogue systems\nand natural language generation techniques drastically lead this task to a new\nlandscape, which results in significant research attentions. However, there\nstill remains a lack of a comprehensive survey for this task. To this end, we\ntake the first step and present a thorough review of this research field\ncarefully and widely. In detail, we systematically organize the current works\naccording to the characteristics of each domain, covering meeting, chat, email\nthread, customer service and medical dialogue. Additionally, we provide an\noverview of publicly available research datasets as well as organize two\nleaderboards under unified metrics. Furthermore, we discuss some future\ndirections, including faithfulness, multi-modal, multi-domain and multi-lingual\ndialogue summarization, and give our thoughts respectively. We hope that this\nfirst survey of dialogue summarization can provide the community with a quick\naccess and a general picture to this task and motivate future researches.", "published": "2021-07-07 12:11:14", "link": "http://arxiv.org/abs/2107.03175v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Time-Aware Ancient Chinese Text Translation and Inference", "abstract": "In this paper, we aim to address the challenges surrounding the translation\nof ancient Chinese text: (1) The linguistic gap due to the difference in eras\nresults in translations that are poor in quality, and (2) most translations are\nmissing the contextual information that is often very crucial to understanding\nthe text. To this end, we improve upon past translation techniques by proposing\nthe following: We reframe the task as a multi-label prediction task where the\nmodel predicts both the translation and its particular era. We observe that\nthis helps to bridge the linguistic gap as chronological context is also used\nas auxiliary information. % As a natural step of generalization, we pivot on\nthe modern Chinese translations to generate multilingual outputs. %We show\nexperimentally the efficacy of our framework in producing quality translation\noutputs and also validate our framework on a collected task-specific parallel\ncorpus. We validate our framework on a parallel corpus annotated with\nchronology information and show experimentally its efficacy in producing\nquality translation outputs. We release both the code and the data\nhttps://github.com/orina1123/time-aware-ancient-text-translation for future\nresearch.", "published": "2021-07-07 12:23:52", "link": "http://arxiv.org/abs/2107.03179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustifying Multi-hop QA through Pseudo-Evidentiality Training", "abstract": "This paper studies the bias problem of multi-hop question answering models,\nof answering correctly without correct reasoning. One way to robustify these\nmodels is by supervising to not only answer right, but also with right\nreasoning chains. An existing direction is to annotate reasoning chains to\ntrain models, requiring expensive additional annotations. In contrast, we\npropose a new approach to learn evidentiality, deciding whether the answer\nprediction is supported by correct evidences, without such annotations.\nInstead, we compare counterfactual changes in answer confidence with and\nwithout evidence sentences, to generate \"pseudo-evidentiality\" annotations. We\nvalidate our proposed model on an original set and challenge set in HotpotQA,\nshowing that our method is accurate and robust in multi-hop reasoning.", "published": "2021-07-07 14:15:14", "link": "http://arxiv.org/abs/2107.03242v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lemmatization of Historical Old Literary Finnish Texts in Modern\n  Orthography", "abstract": "Texts written in Old Literary Finnish represent the first literary work ever\nwritten in Finnish starting from the 16th century. There have been several\nprojects in Finland that have digitized old publications and made them\navailable for research use. However, using modern NLP methods in such data\nposes great challenges. In this paper we propose an approach for simultaneously\nnormalizing and lemmatizing Old Literary Finnish into modern spelling. Our best\nmodel reaches to 96.3\\% accuracy in texts written by Agricola and 87.7\\%\naccuracy in other contemporary out-of-domain text. Our method has been made\nfreely available on Zenodo and Github.", "published": "2021-07-07 15:01:13", "link": "http://arxiv.org/abs/2107.03266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DORA: Toward Policy Optimization for Task-oriented Dialogue System with\n  Efficient Context", "abstract": "Recently, reinforcement learning (RL) has been applied to task-oriented\ndialogue systems by using latent actions to solve shortcomings of supervised\nlearning (SL). In this paper, we propose a multi-domain task-oriented dialogue\nsystem, called Dialogue System with Optimizing a Recurrent Action Policy using\nEfficient Context (DORA), that uses SL, with subsequently applied RL to\noptimize dialogue systems using a recurrent dialogue policy. This dialogue\npolicy recurrently generates explicit system actions as a both word-level and\nhigh-level policy. As a result, DORA is clearly optimized during both SL and RL\nsteps by using an explicit system action policy that considers an efficient\ncontext instead of the entire dialogue history. The system actions are both\ninterpretable and controllable, whereas the latent actions are not. DORA\nimproved the success rate by 6.6 points on MultiWOZ 2.0 and by 10.9 points on\nMultiWOZ 2.1.", "published": "2021-07-07 15:24:27", "link": "http://arxiv.org/abs/2107.03286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keep it Simple: Unsupervised Simplification of Multi-Paragraph Text", "abstract": "This work presents Keep it Simple (KiS), a new approach to unsupervised text\nsimplification which learns to balance a reward across three properties:\nfluency, salience and simplicity. We train the model with a novel algorithm to\noptimize the reward (k-SCST), in which the model proposes several candidate\nsimplifications, computes each candidate's reward, and encourages candidates\nthat outperform the mean reward. Finally, we propose a realistic text\ncomprehension task as an evaluation method for text simplification. When tested\non the English news domain, the KiS model outperforms strong supervised\nbaselines by more than 4 SARI points, and can help people complete a\ncomprehension task an average of 18% faster while retaining accuracy, when\ncompared to the original text. Code available:\nhttps://github.com/tingofurro/keep_it_simple", "published": "2021-07-07 19:12:44", "link": "http://arxiv.org/abs/2107.03444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Transformer Models Measure Coherence In Text? Re-Thinking the\n  Shuffle Test", "abstract": "The Shuffle Test is the most common task to evaluate whether NLP models can\nmeasure coherence in text. Most recent work uses direct supervision on the\ntask; we show that by simply finetuning a RoBERTa model, we can achieve a near\nperfect accuracy of 97.8%, a state-of-the-art. We argue that this outstanding\nperformance is unlikely to lead to a good model of text coherence, and suggest\nthat the Shuffle Test should be approached in a Zero-Shot setting: models\nshould be evaluated without being trained on the task itself. We evaluate\ncommon models in this setting, such as Generative and Bi-directional\nTransformers, and find that larger architectures achieve high-performance\nout-of-the-box. Finally, we suggest the k-Block Shuffle Test, a modification of\nthe original by increasing the size of blocks shuffled. Even though human\nreader performance remains high (around 95% accuracy), model performance drops\nfrom 94% to 78% as block size increases, creating a conceptually simple\nchallenge to benchmark NLP models. Code available:\nhttps://github.com/tingofurro/shuffle_test/", "published": "2021-07-07 19:19:35", "link": "http://arxiv.org/abs/2107.03448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Handling Heavily Abbreviated Manuscripts: HTR engines vs text\n  normalisation approaches", "abstract": "Although abbreviations are fairly common in handwritten sources, particularly\nin medieval and modern Western manuscripts, previous research dealing with\ncomputational approaches to their expansion is scarce. Yet abbreviations\npresent particular challenges to computational approaches such as handwritten\ntext recognition and natural language processing tasks. Often, pre-processing\nultimately aims to lead from a digitised image of the source to a normalised\ntext, which includes expansion of the abbreviations. We explore different\nsetups to obtain such a normalised text, either directly, by training HTR\nengines on normalised (i.e., expanded, disabbreviated) text, or by decomposing\nthe process into discrete steps, each making use of specialist models for\nrecognition, word segmentation and normalisation. The case studies considered\nhere are drawn from the medieval Latin tradition.", "published": "2021-07-07 19:23:22", "link": "http://arxiv.org/abs/2107.03450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "POSLAN: Disentangling Chat with Positional and Language encoded Post\n  Embeddings", "abstract": "Most online message threads inherently will be cluttered and any new user or\nan existing user visiting after a hiatus will have a difficult time\nunderstanding whats being discussed in the thread. Similarly cluttered\nresponses in a message thread makes analyzing the messages a difficult problem.\nThe need for disentangling the clutter is much higher when the platform where\nthe discussion is taking place does not provide functions to retrieve reply\nrelations of the messages. This introduces an interesting problem to which\n\\cite{wang2011learning} phrases as a structural learning problem. We create\nvector embeddings for posts in a thread so that it captures both linguistic and\npositional features in relation to a context of where a given message is in.\nUsing these embeddings for posts we compute a similarity based connectivity\nmatrix which then converted into a graph. After employing a pruning mechanisms\nthe resultant graph can be used to discover the reply relation for the posts in\nthe thread. The process of discovering or disentangling chat is kept as an\nunsupervised mechanism. We present our experimental results on a data set\nobtained from Telegram with limited meta data.", "published": "2021-07-07 23:32:17", "link": "http://arxiv.org/abs/2107.03529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Natural Language Processing for Unstructured Data in Electronic\n  Health Records: a Review", "abstract": "Electronic health records (EHRs), digital collections of patient healthcare\nevents and observations, are ubiquitous in medicine and critical to healthcare\ndelivery, operations, and research. Despite this central role, EHRs are\nnotoriously difficult to process automatically. Well over half of the\ninformation stored within EHRs is in the form of unstructured text (e.g.\nprovider notes, operation reports) and remains largely untapped for secondary\nuse. Recently, however, newer neural network and deep learning approaches to\nNatural Language Processing (NLP) have made considerable advances,\noutperforming traditional statistical and rule-based systems on a variety of\ntasks. In this survey paper, we summarize current neural NLP methods for EHR\napplications. We focus on a broad scope of tasks, namely, classification and\nprediction, word embeddings, extraction, generation, and other topics such as\nquestion answering, phenotyping, knowledge graphs, medical dialogue,\nmultilinguality, interpretability, etc.", "published": "2021-07-07 01:50:02", "link": "http://arxiv.org/abs/2107.02975v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "EchoEA: Echo Information between Entities and Relations for Entity\n  Alignment", "abstract": "Entity alignment (EA) plays an important role in automatically integrating\nknowledge graphs (KGs) from multiple sources. Recent approaches based on Graph\nNeural Network (GNN) obtain entity representation from relation information and\nhave achieved promising results. Besides, more and more methods introduce\nsemi-supervision to ask for more labeled training data. However, two challenges\nstill exist in GNN-based EA methods: (1) Deeper GNN Encoder: The GNN encoder of\ncurrent methods has limited depth (usually 2-layers). (2) Low-quality\nBootstrapping: The generated semi-supervised data is of low quality. In this\npaper, we propose a novel framework, Echo Entity Alignment (EchoEA), which\nleverages 4-levels self-attention mechanism to spread entity information to\nrelations and echo back to entities. Furthermore, we propose attribute-combined\nbi-directional global-filtered strategy (ABGS) to improve bootstrapping, reduce\nfalse samples and generate high-quality training data. The experimental results\non three real-world cross-lingual datasets are stable at around 96\\% at hits@1\non average, showing that our approach not only significantly outperforms the\nstate-of-the-art GNN-based methods, but also is universal and transferable for\nexisting EA methods.", "published": "2021-07-07 07:34:21", "link": "http://arxiv.org/abs/2107.03054v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Data Augmentation for Text Classification", "abstract": "Data augmentation, the artificial creation of training data for machine\nlearning by transformations, is a widely studied research field across machine\nlearning disciplines. While it is useful for increasing a model's\ngeneralization capabilities, it can also address many other challenges and\nproblems, from overcoming a limited amount of training data, to regularizing\nthe objective, to limiting the amount data used to protect privacy. Based on a\nprecise description of the goals and applications of data augmentation and a\ntaxonomy for existing works, this survey is concerned with data augmentation\nmethods for textual classification and aims to provide a concise and\ncomprehensive overview for researchers and practitioners. Derived from the\ntaxonomy, we divide more than 100 methods into 12 different groupings and give\nstate-of-the-art references expounding which methods are highly promising by\nrelating them to each other. Finally, research perspectives that may constitute\na building block for future work are provided.", "published": "2021-07-07 11:37:03", "link": "http://arxiv.org/abs/2107.03158v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Training Instance Selection for Few-Shot Neural Text Generation", "abstract": "Large-scale pretrained language models have led to dramatic improvements in\ntext generation. Impressive performance can be achieved by finetuning only on a\nsmall number of instances (few-shot setting). Nonetheless, almost all previous\nwork simply applies random sampling to select the few-shot training instances.\nLittle to no attention has been paid to the selection strategies and how they\nwould affect model performance. In this work, we present a study on training\ninstance selection in few-shot neural text generation. The selection decision\nis made based only on the unlabeled data so as to identify the most worthwhile\ndata points that should be annotated under some budget of labeling cost. Based\non the intuition that the few-shot training instances should be diverse and\nrepresentative of the entire data distribution, we propose a simple selection\nstrategy with K-means clustering. We show that even with the naive\nclustering-based approach, the generation models consistently outperform random\nsampling on three text generation tasks: data-to-text generation, document\nsummarization and question generation. We hope that this work will call for\nmore attention on this largely unexplored area.", "published": "2021-07-07 12:16:16", "link": "http://arxiv.org/abs/2107.03176v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Linear-time calculation of the expected sum of edge lengths in random\n  projective linearizations of trees", "abstract": "The syntactic structure of a sentence is often represented using syntactic\ndependency trees. The sum of the distances between syntactically related words\nhas been in the limelight for the past decades. Research on dependency\ndistances led to the formulation of the principle of dependency distance\nminimization whereby words in sentences are ordered so as to minimize that sum.\nNumerous random baselines have been defined to carry out related quantitative\nstudies on languages. The simplest random baseline is the expected value of the\nsum in unconstrained random permutations of the words in the sentence, namely\nwhen all the shufflings of the words of a sentence are allowed and equally\nlikely. Here we focus on a popular baseline: random projective permutations of\nthe words of the sentence, that is, permutations where the syntactic dependency\nstructure is projective, a formal constraint that sentences satisfy often in\nlanguages. Thus far, the expectation of the sum of dependency distances in\nrandom projective shufflings of a sentence has been estimated approximately\nwith a Monte Carlo procedure whose cost is of the order of $Rn$, where $n$ is\nthe number of words of the sentence and $R$ is the number of samples; it is\nwell known that the larger $R$, the lower the error of the estimation but the\nlarger the time cost. Here we present formulae to compute that expectation\nwithout error in time of the order of $n$. Furthermore, we show that star trees\nmaximize it, and give an algorithm to retrieve the trees that minimize it.", "published": "2021-07-07 15:11:53", "link": "http://arxiv.org/abs/2107.03277v3", "categories": ["cs.CL", "cs.DM"], "primary_category": "cs.CL"}
{"title": "Anticipating Safety Issues in E2E Conversational AI: Framework and\n  Tooling", "abstract": "Over the last several years, end-to-end neural conversational agents have\nvastly improved in their ability to carry a chit-chat conversation with humans.\nHowever, these models are often trained on large datasets from the internet,\nand as a result, may learn undesirable behaviors from this data, such as toxic\nor otherwise harmful language. Researchers must thus wrestle with the issue of\nhow and when to release these models. In this paper, we survey the problem\nlandscape for safety for end-to-end conversational AI and discuss recent and\nrelated work. We highlight tensions between values, potential positive impact\nand potential harms, and provide a framework for making decisions about whether\nand how to release these models, following the tenets of value-sensitive\ndesign. We additionally provide a suite of tools to enable researchers to make\nbetter-informed decisions about training and releasing end-to-end\nconversational AI models.", "published": "2021-07-07 19:25:57", "link": "http://arxiv.org/abs/2107.03451v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A repeated-measures study on emotional responses after a year in the\n  pandemic", "abstract": "The introduction of COVID-19 lockdown measures and an outlook on return to\nnormality are demanding societal changes. Among the most pressing questions is\nhow individuals adjust to the pandemic. This paper examines the emotional\nresponses to the pandemic in a repeated-measures design. Data (n=1698) were\ncollected in April 2020 (during strict lockdown measures) and in April 2021\n(when vaccination programmes gained traction). We asked participants to report\ntheir emotions and express these in text data. Statistical tests revealed an\naverage trend towards better adjustment to the pandemic. However, clustering\nanalyses suggested a more complex heterogeneous pattern with a well-coping and\na resigning subgroup of participants. Linguistic computational analyses\nuncovered that topics and n-gram frequencies shifted towards attention to the\nvaccination programme and away from general worrying. Implications for public\nmental health efforts in identifying people at heightened risk are discussed.\nThe dataset is made publicly available.", "published": "2021-07-07 20:20:10", "link": "http://arxiv.org/abs/2107.03466v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Can Evolutionary Computation Help us to Crib the Voynich Manuscript ?", "abstract": "Departing from the postulate that Voynich Manuscript is not a hoax but rather\nencodes authentic contents, our article presents an evolutionary algorithm\nwhich aims to find the most optimal mapping between voynichian glyphs and\ncandidate phonemic values. Core component of the decoding algorithm is a\nprocess of maximization of a fitness function which aims to find most optimal\nset of substitution rules allowing to transcribe the part of the manuscript --\nwhich we call the Calendar -- into lists of feminine names. This leads to sets\nof character subsitution rules which allow us to consistently transcribe dozens\namong three hundred calendar tokens into feminine names: a result far\nsurpassing both ``popular'' as well as \"state of the art\" tentatives to crack\nthe manuscript. What's more, by using name lists stemming from different\nlanguages as potential cribs, our ``adaptive'' method can also be useful in\nidentification of the language in which the manuscript is written.\n  As far as we can currently tell, results of our experiments indicate that the\nCalendar part of the manuscript contains names from baltoslavic, balkanic or\nhebrew language strata. Two further indications are also given: primo, highest\nfitness values were obtained when the crib list contains names with specific\ninfixes at token's penultimate position as is the case, for example, for slavic\n\\textbf{feminine diminutives} (i.e. names ending with -ka and not -a). In the\nmost successful scenario, 240 characters contained in 35 distinct Voynichese\ntokens were successfully transcribed. Secundo, in case of crib stemming from\nHebrew language, whole adaptation process converges to significantly better\nfitness values when transcribing voynichian tokens whose order of individual\ncharacters have been reversed, and when lists feminine and not masculine names\nare used as the crib.", "published": "2021-07-07 23:39:59", "link": "http://arxiv.org/abs/2107.05381v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Deep Extrapolation for Attribute-Enhanced Generation", "abstract": "Attribute extrapolation in sample generation is challenging for deep neural\nnetworks operating beyond the training distribution. We formulate a new task\nfor extrapolation in sequence generation, focusing on natural language and\nproteins, and propose GENhance, a generative framework that enhances attributes\nthrough a learned latent space. Trained on movie reviews and a computed protein\nstability dataset, GENhance can generate strongly-positive text reviews and\nhighly stable protein sequences without being exposed to similar data during\ntraining. We release our benchmark tasks and models to contribute to the study\nof generative modeling extrapolation and data-driven design in biology and\nchemistry.", "published": "2021-07-07 01:30:36", "link": "http://arxiv.org/abs/2107.02968v2", "categories": ["cs.LG", "cs.CL", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Structured Denoising Diffusion Models in Discrete State-Spaces", "abstract": "Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown\nimpressive results on image and waveform generation in continuous state spaces.\nHere, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),\ndiffusion-like generative models for discrete data that generalize the\nmultinomial diffusion model of Hoogeboom et al. 2021, by going beyond\ncorruption processes with uniform transition probabilities. This includes\ncorruption with transition matrices that mimic Gaussian kernels in continuous\nspace, matrices based on nearest neighbors in embedding space, and matrices\nthat introduce absorbing states. The third allows us to draw a connection\nbetween diffusion models and autoregressive and mask-based generative models.\nWe show that the choice of transition matrix is an important design decision\nthat leads to improved results in image and text domains. We also introduce a\nnew loss function that combines the variational lower bound with an auxiliary\ncross entropy loss. For text, this model class achieves strong results on\ncharacter-level text generation while scaling to large vocabularies on LM1B. On\nthe image dataset CIFAR-10, our models approach the sample quality and exceed\nthe log-likelihood of the continuous-space DDPM model.", "published": "2021-07-07 04:11:00", "link": "http://arxiv.org/abs/2107.03006v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Advancing CTC-CRF Based End-to-End Speech Recognition with Wordpieces\n  and Conformers", "abstract": "Automatic speech recognition systems have been largely improved in the past\nfew decades and current systems are mainly hybrid-based and end-to-end-based.\nThe recently proposed CTC-CRF framework inherits the data-efficiency of the\nhybrid approach and the simplicity of the end-to-end approach. In this paper,\nwe further advance CTC-CRF based ASR technique with explorations on modeling\nunits and neural architectures. Specifically, we investigate techniques to\nenable the recently developed wordpiece modeling units and Conformer neural\nnetworks to be succesfully applied in CTC-CRFs. Experiments are conducted on\ntwo English datasets (Switchboard, Librispeech) and a German dataset from\nCommonVoice. Experimental results suggest that (i) Conformer can improve the\nrecognition performance significantly; (ii) Wordpiece-based systems perform\nslightly worse compared with phone-based systems for the target language with a\nlow degree of grapheme-phoneme correspondence (e.g. English), while the two\nsystems can perform equally strong when such degree of correspondence is high\nfor the target language (e.g. German).", "published": "2021-07-07 04:12:06", "link": "http://arxiv.org/abs/2107.03007v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient Transformer for Direct Speech Translation", "abstract": "The advent of Transformer-based models has surpassed the barriers of text.\nWhen working with speech, we must face a problem: the sequence length of an\naudio input is not suitable for the Transformer. To bypass this problem, a\nusual approach is adding strided convolutional layers, to reduce the sequence\nlength before using the Transformer. In this paper, we propose a new approach\nfor direct Speech Translation, where thanks to an efficient Transformer we can\nwork with a spectrogram without having to use convolutional layers before the\nTransformer. This allows the encoder to learn directly from the spectrogram and\nno information is lost. We have created an encoder-decoder model, where the\nencoder is an efficient Transformer -- the Longformer -- and the decoder is a\ntraditional Transformer decoder. Our results, which are close to the ones\nobtained with the standard approach, show that this is a promising research\ndirection.", "published": "2021-07-07 08:13:40", "link": "http://arxiv.org/abs/2107.03069v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Android Security using NLP Techniques: A Review", "abstract": "Android is among the most targeted platform by attackers. While attackers are\nimproving their techniques, traditional solutions based on static and dynamic\nanalysis have been also evolving. In addition to the application code, Android\napplications have some metadata that could be useful for security analysis of\napplications. Unlike traditional application distribution mechanisms, Android\napplications are distributed centrally in mobile markets. Therefore, beside\napplication packages, such markets contain app information provided by app\ndevelopers and app users. The availability of such useful textual data together\nwith the advancement in Natural Language Processing (NLP) that is used to\nprocess and understand textual data has encouraged researchers to investigate\nthe use of NLP techniques in Android security. Especially, security solutions\nbased on NLP have accelerated in the last 5 years and proven to be useful. This\nstudy reviews these proposals and aim to explore possible research directions\nfor future studies by presenting state-of-the-art in this domain. We mainly\nfocus on NLP-based solutions under four categories: description-to-behaviour\nfidelity, description generation, privacy and malware detection.", "published": "2021-07-07 08:33:00", "link": "http://arxiv.org/abs/2107.03072v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "MACCIF-TDNN: Multi aspect aggregation of channel and context\n  interdependence features in TDNN-based speaker verification", "abstract": "Most of the recent state-of-the-art results for speaker verification are\nachieved by X-vector and its subsequent variants. In this paper, we propose a\nnew network architecture which aggregates the channel and context\ninterdependence features from multi aspect based on Time Delay Neural Network\n(TDNN). Firstly, we use the SE-Res2Blocks as in ECAPA-TDNN to explicitly model\nthe channel interdependence to realize adaptive calibration of channel\nfeatures, and process local context features in a multi-scale way at a more\ngranular level compared with conventional TDNN-based methods. Secondly, we\nexplore to use the encoder structure of Transformer to model the global context\ninterdependence features at an utterance level which can capture better long\nterm temporal characteristics. Before the pooling layer, we aggregate the\noutputs of SE-Res2Blocks and Transformer encoder to leverage the complementary\nchannel and context interdependence features learned by themself respectively.\nFinally, instead of performing a single attentive statistics pooling, we also\nfind it beneficial to extend the pooling method in a multi-head way which can\ndiscriminate features from multiple aspect. The proposed MACCIF-TDNN\narchitecture can outperform most of the state-of-the-art TDNN-based systems on\nVoxCeleb1 test sets.", "published": "2021-07-07 09:43:42", "link": "http://arxiv.org/abs/2107.03104v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LanguageRefer: Spatial-Language Model for 3D Visual Grounding", "abstract": "For robots to understand human instructions and perform meaningful tasks in\nthe near future, it is important to develop learned models that comprehend\nreferential language to identify common objects in real-world 3D scenes. In\nthis paper, we introduce a spatial-language model for a 3D visual grounding\nproblem. Specifically, given a reconstructed 3D scene in the form of point\nclouds with 3D bounding boxes of potential object candidates, and a language\nutterance referring to a target object in the scene, our model successfully\nidentifies the target object from a set of potential candidates. Specifically,\nLanguageRefer uses a transformer-based architecture that combines spatial\nembedding from bounding boxes with fine-tuned language embeddings from\nDistilBert to predict the target object. We show that it performs competitively\non visio-linguistic datasets proposed by ReferIt3D. Further, we analyze its\nspatial reasoning task performance decoupled from perception noise, the\naccuracy of view-dependent utterances, and viewpoint annotations for potential\nrobotics applications.", "published": "2021-07-07 18:55:03", "link": "http://arxiv.org/abs/2107.03438v3", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "DISCO : efficient unsupervised decoding for discrete natural language\n  problems via convex relaxation", "abstract": "In this paper we study test time decoding; an ubiquitous step in almost all\nsequential text generation task spanning across a wide array of natural\nlanguage processing (NLP) problems. Our main contribution is to develop a\ncontinuous relaxation framework for the combinatorial NP-hard decoding problem\nand propose Disco - an efficient algorithm based on standard first order\ngradient based. We provide tight analysis and show that our proposed algorithm\nlinearly converges to within $\\epsilon$ neighborhood of the optima. Finally, we\nperform preliminary experiments on the task of adversarial text generation and\nshow superior performance of Disco over several popular decoding approaches.", "published": "2021-07-07 00:40:25", "link": "http://arxiv.org/abs/2107.05380v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-End Rich Transcription-Style Automatic Speech Recognition with\n  Semi-Supervised Learning", "abstract": "We propose a semi-supervised learning method for building end-to-end rich\ntranscription-style automatic speech recognition (RT-ASR) systems from\nsmall-scale rich transcription-style and large-scale common transcription-style\ndatasets. In spontaneous speech tasks, various speech phenomena such as\nfillers, word fragments, laughter and coughs, etc. are often included. While\ncommon transcriptions do not give special awareness to these phenomena, rich\ntranscriptions explicitly convert them into special phenomenon tokens as well\nas textual tokens. In previous studies, the textual and phenomenon tokens were\nsimultaneously estimated in an end-to-end manner. However, it is difficult to\nbuild accurate RT-ASR systems because large-scale rich transcription-style\ndatasets are often unavailable. To solve this problem, our training method uses\na limited rich transcription-style dataset and common transcription-style\ndataset simultaneously. The Key process in our semi-supervised learning is to\nconvert the common transcription-style dataset into a pseudo-rich\ntranscription-style dataset. To this end, we introduce style tokens which\ncontrol phenomenon tokens are generated or not into transformer-based\nautoregressive modeling. We use this modeling for generating the pseudo-rich\ntranscription-style datasets and for building RT-ASR system from the pseudo and\noriginal datasets. Our experiments on spontaneous ASR tasks showed the\neffectiveness of the proposed method.", "published": "2021-07-07 12:52:49", "link": "http://arxiv.org/abs/2107.05382v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Identifying Hijacked Reviews", "abstract": "Fake reviews and review manipulation are growing problems on online\nmarketplaces globally. Review Hijacking is a new review manipulation tactic in\nwhich unethical sellers \"hijack\" an existing product page (usually one with\nmany positive reviews), then update the product details like title, photo, and\ndescription with those of an entirely different product. With the earlier\nreviews still attached, the new item appears well-reviewed. However, there are\nno public datasets of review hijacking and little is known in the literature\nabout this tactic. Hence, this paper proposes a three-part study: (i) we\npropose a framework to generate synthetically labeled data for review hijacking\nby swapping products and reviews; (ii) then, we evaluate the potential of both\na Twin LSTM network and BERT sequence pair classifier to distinguish legitimate\nreviews from hijacked ones using this data; and (iii) we then deploy the best\nperforming model on a collection of 31K products (with 6.5 M reviews) in the\noriginal data, where we find 100s of previously unknown examples of review\nhijacking.", "published": "2021-07-07 20:43:36", "link": "http://arxiv.org/abs/2107.05385v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Msdtron: a high-capability multi-speaker speech synthesis system for\n  diverse data using characteristic information", "abstract": "In multi-speaker speech synthesis, data from a number of speakers usually\ntend to have great diversity due to the fact that the speakers may differ\nlargely in ages, speaking styles, emotions, and so on. It is important but\nchallenging to improve the modeling capabilities for multi-speaker speech\nsynthesis. To address the issue, this paper proposes a high-capability speech\nsynthesis system, called Msdtron, in which 1) a representation of the harmonic\nstructure of speech, called excitation spectrogram, is designed to directly\nguide the learning of harmonics in mel-spectrogram. 2) conditional gated LSTM\n(CGLSTM) is proposed to control the flow of text content information through\nthe network by re-weighting the gates of LSTM using speaker information. The\nexperiments show a significant reduction in reconstruction error of\nmel-spectrogram in the training of the multi-speaker model, and a great\nimprovement is observed in the subjective evaluation of speaker adapted model.", "published": "2021-07-07 08:00:58", "link": "http://arxiv.org/abs/2107.03065v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adversarial Auto-Encoding for Packet Loss Concealment", "abstract": "Communication technologies like voice over IP operate under constrained\nreal-time conditions, with voice packets being subject to delays and losses\nfrom the network. In such cases, the packet loss concealment (PLC) algorithm\nreconstructs missing frames until a new real packet is received. Recently,\nautoregressive deep neural networks have been shown to surpass the quality of\nsignal processing methods for PLC, specially for long-term predictions beyond\n60 ms. In this work, we propose a non-autoregressive adversarial auto-encoder,\nnamed PLAAE, to perform real-time PLC in the waveform domain. PLAAE has a\ncausal convolutional structure, and it learns in an auto-encoder fashion to\nreconstruct signals with gaps, with the help of an adversarial loss. During\ninference, it is able to predict smooth and coherent continuations of such gaps\nin a single feed-forward step, as opposed to autoregressive models. Our\nevaluation highlights the superiority of PLAAE over two classic PLCs and two\ndeep autoregressive models in terms of spectral and intonation reconstruction,\nperceptual quality, and intelligibility.", "published": "2021-07-07 09:35:33", "link": "http://arxiv.org/abs/2107.03100v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Speech Recognition Accuracy of Local POI Using Geographical\n  Models", "abstract": "Nowadays voice search for points of interest (POI) is becoming increasingly\npopular. However, speech recognition for local POI has remained to be a\nchallenge due to multi-dialect and massive POI. This paper improves speech\nrecognition accuracy for local POI from two aspects. Firstly, a geographic\nacoustic model (Geo-AM) is proposed. The Geo-AM deals with multi-dialect\nproblem using dialect-specific input feature and dialect-specific top layer.\nSecondly, a group of geo-specific language models (Geo-LMs) are integrated into\nour speech recognition system to improve recognition accuracy of long tail and\nhomophone POI. During decoding, specific language models are selected on demand\naccording to users' geographic location. Experiments show that the proposed\nGeo-AM achieves 6.5%$\\sim$10.1% relative character error rate (CER) reduction\non an accent testset and the proposed Geo-AM and Geo-LM totally achieve over\n18.7% relative CER reduction on Tencent Map task.", "published": "2021-07-07 11:46:44", "link": "http://arxiv.org/abs/2107.03165v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive\n  Text-to-Speech Synthesis", "abstract": "This paper describes a variational auto-encoder based non-autoregressive\ntext-to-speech (VAENAR-TTS) model. The autoregressive TTS (AR-TTS) models based\non the sequence-to-sequence architecture can generate high-quality speech, but\ntheir sequential decoding process can be time-consuming. Recently,\nnon-autoregressive TTS (NAR-TTS) models have been shown to be more efficient\nwith the parallel decoding process. However, these NAR-TTS models rely on\nphoneme-level durations to generate a hard alignment between the text and the\nspectrogram. Obtaining duration labels, either through forced alignment or\nknowledge distillation, is cumbersome. Furthermore, hard alignment based on\nphoneme expansion can degrade the naturalness of the synthesized speech. In\ncontrast, the proposed model of VAENAR-TTS is an end-to-end approach that does\nnot require phoneme-level durations. The VAENAR-TTS model does not contain\nrecurrent structures and is completely non-autoregressive in both the training\nand inference phases. Based on the VAE architecture, the alignment information\nis encoded in the latent variable, and attention-based soft alignment between\nthe text and the latent variable is used in the decoder to reconstruct the\nspectrogram. Experiments show that VAENAR-TTS achieves state-of-the-art\nsynthesis quality, while the synthesis speed is comparable with other NAR-TTS\nmodels.", "published": "2021-07-07 15:32:36", "link": "http://arxiv.org/abs/2107.03298v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SoundStream: An End-to-End Neural Audio Codec", "abstract": "We present SoundStream, a novel neural audio codec that can efficiently\ncompress speech, music and general audio at bitrates normally targeted by\nspeech-tailored codecs. SoundStream relies on a model architecture composed by\na fully convolutional encoder/decoder network and a residual vector quantizer,\nwhich are trained jointly end-to-end. Training leverages recent advances in\ntext-to-speech and speech enhancement, which combine adversarial and\nreconstruction losses to allow the generation of high-quality audio content\nfrom quantized embeddings. By training with structured dropout applied to\nquantizer layers, a single model can operate across variable bitrates from\n3kbps to 18kbps, with a negligible quality loss when compared with models\ntrained at fixed bitrates. In addition, the model is amenable to a low latency\nimplementation, which supports streamable inference and runs in real time on a\nsmartphone CPU. In subjective evaluations using audio at 24kHz sampling rate,\nSoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps.\nMoreover, we are able to perform joint compression and enhancement either at\nthe encoder or at the decoder side with no additional latency, which we\ndemonstrate through background noise suppression for speech.", "published": "2021-07-07 15:45:42", "link": "http://arxiv.org/abs/2107.03312v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BumbleBee: A Transformer for Music", "abstract": "We will introduce BumbleBee, a transformer model that will generate MIDI\nmusic data . We will tackle the issue of transformers applied to long sequences\nby implementing a longformer generative model that uses dilating sliding\nwindows to compute the attention layers. We will compare our results to that of\nthe music transformer and Long-Short term memory (LSTM) to benchmark our\nresults. This analysis will be performed using piano MIDI files, in particular\n, the JSB Chorales dataset that has already been used for other research works\n(Huang et al., 2018)", "published": "2021-07-07 19:08:16", "link": "http://arxiv.org/abs/2107.03443v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T07", "I.2.6"], "primary_category": "cs.SD"}
