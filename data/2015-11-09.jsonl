{"title": "Sentiment Expression via Emoticons on Social Media", "abstract": "Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and\nother NLP tasks as features to ma- chine learning algorithms or as entries of\nsentiment lexicons. In this paper, we argue that while emoticons are strong and\ncommon signals of sentiment expression on social media the relationship between\nemoticons and sentiment polarity are not always clear. Thus, any algorithm that\ndeals with sentiment polarity should take emoticons into account but extreme\ncau- tion should be exercised in which emoticons to depend on. First, to\ndemonstrate the prevalence of emoticons on social media, we analyzed the\nfrequency of emoticons in a large re- cent Twitter data set. Then we carried\nout four analyses to examine the relationship between emoticons and sentiment\npolarity as well as the contexts in which emoticons are used. The first\nanalysis surveyed a group of participants for their perceived sentiment\npolarity of the most frequent emoticons. The second analysis examined\nclustering of words and emoti- cons to better understand the meaning conveyed\nby the emoti- cons. The third analysis compared the sentiment polarity of\nmicroblog posts before and after emoticons were removed from the text. The last\nanalysis tested the hypothesis that removing emoticons from text hurts\nsentiment classification by training two machine learning models with and\nwithout emoticons in the text respectively. The results confirms the arguments\nthat: 1) a few emoticons are strong and reliable signals of sentiment polarity\nand one should take advantage of them in any senti- ment analysis; 2) a large\ngroup of the emoticons conveys com- plicated sentiment hence they should be\ntreated with extreme caution.", "published": "2015-11-09 02:31:31", "link": "http://arxiv.org/abs/1511.02556v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Explicit Knowledge-based Reasoning for Visual Question Answering", "abstract": "We describe a method for visual question answering which is capable of\nreasoning about contents of an image on the basis of information extracted from\na large-scale knowledge base. The method not only answers natural language\nquestions using concepts not contained in the image, but can provide an\nexplanation of the reasoning by which it developed its answer. The method is\ncapable of answering far more complex questions than the predominant long\nshort-term memory-based approach, and outperforms it significantly in the\ntesting. We also provide a dataset and a protocol by which to evaluate such\nmethods, thus addressing one of the key issues in general visual ques- tion\nanswering.", "published": "2015-11-09 05:25:57", "link": "http://arxiv.org/abs/1511.02570v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enacting textual entailment and ontologies for automated essay grading\n  in chemical domain", "abstract": "We propose a system for automated essay grading using ontologies and textual\nentailment. The process of textual entailment is guided by hypotheses, which\nare extracted from a domain ontology. Textual entailment checks if the truth of\nthe hypothesis follows from a given text. We enact textual entailment to\ncompare students answer to a model answer obtained from ontology. We validated\nthe solution against various essays written by students in the chemistry\ndomain.", "published": "2015-11-09 13:21:02", "link": "http://arxiv.org/abs/1511.02669v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Neural Module Networks", "abstract": "Visual question answering is fundamentally compositional in nature---a\nquestion like \"where is the dog?\" shares substructure with questions like \"what\ncolor is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously\nexploit the representational capacity of deep networks and the compositional\nlinguistic structure of questions. We describe a procedure for constructing and\nlearning *neural module networks*, which compose collections of jointly-trained\nneural \"modules\" into deep networks for question answering. Our approach\ndecomposes questions into their linguistic substructures, and uses these\nstructures to dynamically instantiate modular networks (with reusable\ncomponents for recognizing dogs, classifying colors, etc.). The resulting\ncompound networks are jointly trained. We evaluate our approach on two\nchallenging datasets for visual question answering, achieving state-of-the-art\nresults on both the VQA natural image dataset and a new dataset of complex\nquestions about abstract shapes.", "published": "2015-11-09 18:48:39", "link": "http://arxiv.org/abs/1511.02799v4", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CV"}
