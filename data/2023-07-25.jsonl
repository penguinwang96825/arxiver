{"title": "Towards Resolving Word Ambiguity with Word Embeddings", "abstract": "Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is\nespecially important in information retrieval tasks. While word embeddings\ncarry semantic information, they fail to handle ambiguity well. Transformer\nmodels have been shown to handle word ambiguity for complex queries, but they\ncannot be used to identify ambiguous words, e.g. for a 1-word query.\nFurthermore, training these models is costly in terms of time, hardware\nresources, and training data, prohibiting their use in specialized environments\nwith sensitive data. Word embeddings can be trained using moderate hardware\nresources. This paper shows that applying DBSCAN clustering to the latent space\ncan identify ambiguous words and evaluate their level of ambiguity. An\nautomatic DBSCAN parameter selection leads to high-quality clusters, which are\nsemantically coherent and correspond well to the perceived meanings of a given\nword.", "published": "2023-07-25 11:29:55", "link": "http://arxiv.org/abs/2307.13417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Holistic Exploration on Universal Decompositional Semantic Parsing:\n  Architecture, Data Augmentation, and LLM Paradigm", "abstract": "In this paper, we conduct a holistic exploration of the Universal\nDecompositional Semantic (UDS) Parsing. We first introduce a cascade model for\nUDS parsing that decomposes the complex parsing task into semantically\nappropriate subtasks. Our approach outperforms the prior models, while\nsignificantly reducing inference time. We also incorporate syntactic\ninformation and further optimized the architecture. Besides, different ways for\ndata augmentation are explored, which further improve the UDS Parsing. Lastly,\nwe conduct experiments to investigate the efficacy of ChatGPT in handling the\nUDS task, revealing that it excels in attribute parsing but struggles in\nrelation parsing, and using ChatGPT for data augmentation yields suboptimal\nresults. Our code is available at https://github.com/hexuandeng/HExp4UDS.", "published": "2023-07-25 11:44:28", "link": "http://arxiv.org/abs/2307.13424v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XDLM: Cross-lingual Diffusion Language Model for Machine Translation", "abstract": "Recently, diffusion models have excelled in image generation tasks and have\nalso been applied to neural language processing (NLP) for controllable text\ngeneration. However, the application of diffusion models in a cross-lingual\nsetting is less unexplored. Additionally, while pretraining with diffusion\nmodels has been studied within a single language, the potential of\ncross-lingual pretraining remains understudied. To address these gaps, we\npropose XDLM, a novel Cross-lingual diffusion model for machine translation,\nconsisting of pretraining and fine-tuning stages. In the pretraining stage, we\npropose TLDM, a new training objective for mastering the mapping between\ndifferent languages; in the fine-tuning stage, we build up the translation\nsystem based on the pretrained model. We evaluate the result on several machine\ntranslation benchmarks and outperformed both diffusion and Transformer\nbaselines.", "published": "2023-07-25 15:08:34", "link": "http://arxiv.org/abs/2307.13560v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contributions to the Improvement of Question Answering Systems in the\n  Biomedical Domain", "abstract": "This thesis work falls within the framework of question answering (QA) in the\nbiomedical domain where several specific challenges are addressed, such as\nspecialized lexicons and terminologies, the types of treated questions, and the\ncharacteristics of targeted documents. We are particularly interested in\nstudying and improving methods that aim at finding accurate and short answers\nto biomedical natural language questions from a large scale of biomedical\ntextual documents in English. QA aims at providing inquirers with direct, short\nand precise answers to their natural language questions. In this Ph.D. thesis,\nwe propose four contributions to improve the performance of QA in the\nbiomedical domain. In our first contribution, we propose a machine\nlearning-based method for question type classification to determine the types\nof given questions which enable to a biomedical QA system to use the\nappropriate answer extraction method. We also propose an another machine\nlearning-based method to assign one or more topics (e.g., pharmacological,\ntest, treatment, etc.) to given questions in order to determine the semantic\ntypes of the expected answers which are very useful in generating specific\nanswer retrieval strategies. In the second contribution, we first propose a\ndocument retrieval method to retrieve a set of relevant documents that are\nlikely to contain the answers to biomedical questions from the MEDLINE\ndatabase. We then present a passage retrieval method to retrieve a set of\nrelevant passages to questions. In the third contribution, we propose specific\nanswer extraction methods to generate both exact and ideal answers. Finally, in\nthe fourth contribution, we develop a fully automated semantic biomedical QA\nsystem called SemBioNLQA which is able to deal with a variety of natural\nlanguage questions and to generate appropriate answers by providing both exact\nand ideal answers.", "published": "2023-07-25 16:31:20", "link": "http://arxiv.org/abs/2307.13631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check", "abstract": "With the development of pre-trained models and the incorporation of phonetic\nand graphic information, neural models have achieved high scores in Chinese\nSpelling Check (CSC). However, it does not provide a comprehensive reflection\nof the models' capability due to the limited test sets. In this study, we\nabstract the representative model paradigm, implement it with nine structures\nand experiment them on comprehensive test sets we constructed with different\npurposes. We perform a detailed analysis of the results and find that: 1)\nFusing phonetic and graphic information reasonably is effective for CSC. 2)\nModels are sensitive to the error distribution of the test set, which reflects\nthe shortcomings of models and reveals the direction we should work on. 3)\nWhether or not the errors and contexts have been seen has a significant impact\non models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate\nmodels' performance.", "published": "2023-07-25 17:02:38", "link": "http://arxiv.org/abs/2307.13655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models for Radiology Natural Language\n  Processing", "abstract": "The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.", "published": "2023-07-25 17:57:18", "link": "http://arxiv.org/abs/2307.13693v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trustworthiness of Children Stories Generated by Large Language Models", "abstract": "Large Language Models (LLMs) have shown a tremendous capacity for generating\nliterary text. However, their effectiveness in generating children's stories\nhas yet to be thoroughly examined. In this study, we evaluate the\ntrustworthiness of children's stories generated by LLMs using various measures,\nand we compare and contrast our results with both old and new children's\nstories to better assess their significance. Our findings suggest that LLMs\nstill struggle to generate children's stories at the level of quality and\nnuance found in actual stories", "published": "2023-07-25 22:55:51", "link": "http://arxiv.org/abs/2308.00073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Generalization Ability in Essay Coherence Evaluation\n  through Monotonic Constraints", "abstract": "Coherence is a crucial aspect of evaluating text readability and can be\nassessed through two primary factors when evaluating an essay in a scoring\nscenario. The first factor is logical coherence, characterized by the\nappropriate use of discourse connectives and the establishment of logical\nrelationships between sentences. The second factor is the appropriateness of\npunctuation, as inappropriate punctuation can lead to confused sentence\nstructure. To address these concerns, we propose a coherence scoring model\nconsisting of a regression model with two feature extractors: a local coherence\ndiscriminative model and a punctuation correction model. We employ\ngradient-boosting regression trees as the regression model and impose\nmonotonicity constraints on the input features. The results show that our\nproposed model better generalizes unseen data. The model achieved third place\nin track 1 of NLPCC 2023 shared task 7. Additionally, we briefly introduce our\nsolution for the remaining tracks, which achieves second place for track 2 and\nfirst place for both track 3 and track 4.", "published": "2023-07-25 08:26:46", "link": "http://arxiv.org/abs/2308.02506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA\n  Composition", "abstract": "Low-rank adaptations (LoRA) are often employed to fine-tune large language\nmodels (LLMs) for new tasks. This paper investigates LoRA composability for\ncross-task generalization and introduces LoraHub, a simple framework devised\nfor the purposive assembly of LoRA modules trained on diverse given tasks, with\nthe objective of achieving adaptable performance on unseen tasks. With just a\nfew examples from a new task, LoraHub can fluidly combine multiple LoRA\nmodules, eliminating the need for human expertise and assumptions. Notably, the\ncomposition requires neither additional model parameters nor gradients.\nEmpirical results on the Big-Bench Hard benchmark suggest that LoraHub, while\nnot surpassing the performance of in-context learning, offers a notable\nperformance-efficiency trade-off in few-shot scenarios by employing a\nsignificantly reduced number of tokens per example during inference. Notably,\nLoraHub establishes a better upper bound compared to in-context learning when\npaired with different demonstration examples, demonstrating its potential for\nfuture development. Our vision is to establish a platform for LoRA modules,\nempowering users to share their trained LoRA modules. This collaborative\napproach facilitates the seamless application of LoRA modules to novel tasks,\ncontributing to an adaptive ecosystem. Our code is available at\nhttps://github.com/sail-sg/lorahub, and all the pre-trained LoRA modules are\nreleased at https://huggingface.co/lorahub.", "published": "2023-07-25 05:39:21", "link": "http://arxiv.org/abs/2307.13269v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Intent Taxonomy of Legal Case Retrieval", "abstract": "Legal case retrieval is a special Information Retrieval~(IR) task focusing on\nlegal case documents. Depending on the downstream tasks of the retrieved case\ndocuments, users' information needs in legal case retrieval could be\nsignificantly different from those in Web search and traditional ad-hoc\nretrieval tasks. While there are several studies that retrieve legal cases\nbased on text similarity, the underlying search intents of legal retrieval\nusers, as shown in this paper, are more complicated than that yet mostly\nunexplored. To this end, we present a novel hierarchical intent taxonomy of\nlegal case retrieval. It consists of five intent types categorized by three\ncriteria, i.e., search for Particular Case(s), Characterization, Penalty,\nProcedure, and Interest. The taxonomy was constructed transparently and\nevaluated extensively through interviews, editorial user studies, and query log\nanalysis. Through a laboratory user study, we reveal significant differences in\nuser behavior and satisfaction under different search intents in legal case\nretrieval. Furthermore, we apply the proposed taxonomy to various downstream\nlegal retrieval tasks, e.g., result ranking and satisfaction prediction, and\ndemonstrate its effectiveness. Our work provides important insights into the\nunderstanding of user intents in legal case retrieval and potentially leads to\nbetter retrieval techniques in the legal domain, such as intent-aware ranking\nstrategies and evaluation methodologies.", "published": "2023-07-25 07:27:32", "link": "http://arxiv.org/abs/2307.13298v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "QuIP: 2-Bit Quantization of Large Language Models With Guarantees", "abstract": "This work studies post-training parameter quantization in large language\nmodels (LLMs). We introduce quantization with incoherence processing (QuIP), a\nnew method based on the insight that quantization benefits from\n$\\textit{incoherent}$ weight and Hessian matrices, i.e., from the weights being\neven in magnitude and the directions in which it is important to round them\naccurately being unaligned with the coordinate axes. QuIP consists of two\nsteps: (1) an adaptive rounding procedure minimizing a quadratic proxy\nobjective; (2) efficient pre- and post-processing that ensures weight and\nHessian incoherence via multiplication by random orthogonal matrices. We\ncomplement QuIP with the first theoretical analysis for an LLM-scale\nquantization algorithm, and show that our theory also applies to an existing\nmethod, OPTQ. Empirically, we find that our incoherence preprocessing improves\nseveral existing quantization algorithms and yields the first LLM quantization\nmethods that produce viable results using only two bits per weight. Our code\ncan be found at https://github.com/Cornell-RelaxML/QuIP.", "published": "2023-07-25 07:44:06", "link": "http://arxiv.org/abs/2307.13304v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Analyzing Chain-of-Thought Prompting in Large Language Models via\n  Gradient-based Feature Attributions", "abstract": "Chain-of-thought (CoT) prompting has been shown to empirically improve the\naccuracy of large language models (LLMs) on various question answering tasks.\nWhile understanding why CoT prompting is effective is crucial to ensuring that\nthis phenomenon is a consequence of desired model behavior, little work has\naddressed this; nonetheless, such an understanding is a critical prerequisite\nfor responsible model deployment. We address this question by leveraging\ngradient-based feature attribution methods which produce saliency scores that\ncapture the influence of input tokens on model output. Specifically, we probe\nseveral open-source LLMs to investigate whether CoT prompting affects the\nrelative importances they assign to particular input tokens. Our results\nindicate that while CoT prompting does not increase the magnitude of saliency\nscores attributed to semantically relevant tokens in the prompt compared to\nstandard few-shot prompting, it increases the robustness of saliency scores to\nquestion perturbations and variations in model output.", "published": "2023-07-25 08:51:30", "link": "http://arxiv.org/abs/2307.13339v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pay Attention to What You Need", "abstract": "Although large language models (LLMs) have achieved significant success in\nnatural language processing, they still struggle with long-context\ncomprehension. Traditional approaches to mitigating this issue typically rely\non fine-tuning or retraining, which is both resource-intensive and challenging\nto deploy in lightweight industrial settings. In this paper, we investigate the\npotential to accomplish this without any additional resources. Through an\nin-depth study of the attention mechanism in LLMs, we propose a method called\nScaled ReAttention (SRA) to strengthen LLMs' ability to interpret and retrieve\ninformation by strategically manipulating their attention scores during\ninference. Through extensive experiments, we demonstrate that integrating SRA\nsignificantly boosts LLMs' performance on a variety of downstream tasks,\nhighlighting its practical potential for enhancing language understanding\nwithout incurring the overhead of traditional training.", "published": "2023-07-25 09:34:42", "link": "http://arxiv.org/abs/2307.13365v3", "categories": ["cs.CL", "cs.AI", "68T07, 68T50"], "primary_category": "cs.CL"}
{"title": "Towards Bridging the Digital Language Divide", "abstract": "It is a well-known fact that current AI-based language technology -- language\nmodels, machine translation systems, multilingual dictionaries and corpora --\nfocuses on the world's 2-3% most widely spoken languages. Recent research\nefforts have attempted to expand the coverage of AI technology to\n`under-resourced languages.' The goal of our paper is to bring attention to a\nphenomenon that we call linguistic bias: multilingual language processing\nsystems often exhibit a hardwired, yet usually involuntary and hidden\nrepresentational preference towards certain languages. Linguistic bias is\nmanifested in uneven per-language performance even in the case of similar test\nconditions. We show that biased technology is often the result of research and\ndevelopment methodologies that do not do justice to the complexity of the\nlanguages being represented, and that can even become ethically problematic as\nthey disregard valuable aspects of diversity as well as the needs of the\nlanguage communities themselves. As our attempt at building diversity-aware\nlanguage resources, we present a new initiative that aims at reducing\nlinguistic bias through both technological design and methodology, based on an\neye-level collaboration with local communities.", "published": "2023-07-25 10:53:20", "link": "http://arxiv.org/abs/2307.13405v1", "categories": ["cs.CL", "cs.AI", "I.2.7; K.4.2"], "primary_category": "cs.CL"}
{"title": "FacTool: Factuality Detection in Generative AI -- A Tool Augmented\n  Framework for Multi-Task and Multi-Domain Scenarios", "abstract": "The emergence of generative pre-trained models has facilitated the synthesis\nof high-quality text, but it has also posed challenges in identifying factual\nerrors in the generated text. In particular: (1) A wider range of tasks now\nface an increasing risk of containing factual errors when handled by generative\nmodels. (2) Generated texts tend to be lengthy and lack a clearly defined\ngranularity for individual facts. (3) There is a scarcity of explicit evidence\navailable during the process of fact checking. With the above challenges in\nmind, in this paper, we propose FacTool, a task and domain agnostic framework\nfor detecting factual errors of texts generated by large language models (e.g.,\nChatGPT). Experiments on four different tasks (knowledge-based QA, code\ngeneration, mathematical reasoning, and scientific literature review) show the\nefficacy of the proposed method. We release the code of FacTool associated with\nChatGPT plugin interface at https://github.com/GAIR-NLP/factool .", "published": "2023-07-25 14:20:51", "link": "http://arxiv.org/abs/2307.13528v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GPT-3 Models are Few-Shot Financial Reasoners", "abstract": "Financial analysis is an important tool for evaluating company performance.\nPractitioners work to answer financial questions to make profitable investment\ndecisions, and use advanced quantitative analyses to do so. As a result,\nFinancial Question Answering (QA) is a question answering task that requires\ndeep reasoning about numbers. Furthermore, it is unknown how well pre-trained\nlanguage models can reason in the financial domain. The current\nstate-of-the-art requires a retriever to collect relevant facts about the\nfinancial question from the text and a generator to produce a valid financial\nprogram and a final answer. However, recently large language models like GPT-3\nhave achieved state-of-the-art performance on wide variety of tasks with just a\nfew shot examples. We run several experiments with GPT-3 and find that a\nseparate retrieval model and logic engine continue to be essential components\nto achieving SOTA performance in this task, particularly due to the precise\nnature of financial questions and the complex information stored in financial\ndocuments. With this understanding, our refined prompt-engineering approach on\nGPT-3 achieves near SOTA accuracy without any fine-tuning.", "published": "2023-07-25 16:21:07", "link": "http://arxiv.org/abs/2307.13617v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ARB: Advanced Reasoning Benchmark for Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious quantitative reasoning and knowledge benchmarks. However, many of these\nbenchmarks are losing utility as LLMs get increasingly high scores, despite not\nyet reaching expert performance in these domains. We introduce ARB, a novel\nbenchmark composed of advanced reasoning problems in multiple fields. ARB\npresents a more challenging test than prior benchmarks, featuring problems in\nmathematics, physics, biology, chemistry, and law. As a subset of ARB, we\nintroduce a challenging set of math and physics problems which require advanced\nsymbolic reasoning and domain knowledge. We evaluate recent models such as\nGPT-4 and Claude on ARB and demonstrate that current models score well below\n50% on more demanding tasks. In order to improve both automatic and assisted\nevaluation capabilities, we introduce a rubric-based evaluation approach,\nallowing GPT-4 to score its own intermediate reasoning steps. Further, we\nconduct a human evaluation of the symbolic subset of ARB, finding promising\nagreement between annotators and GPT-4 rubric evaluation scores.", "published": "2023-07-25 17:55:19", "link": "http://arxiv.org/abs/2307.13692v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diversity and Language Technology: How Techno-Linguistic Bias Can Cause\n  Epistemic Injustice", "abstract": "It is well known that AI-based language technology -- large language models,\nmachine translation systems, multilingual dictionaries, and corpora -- is\ncurrently limited to 2 to 3 percent of the world's most widely spoken and/or\nfinancially and politically best supported languages. In response, recent\nresearch efforts have sought to extend the reach of AI technology to\n``underserved languages.'' In this paper, we show that many of these attempts\nproduce flawed solutions that adhere to a hard-wired representational\npreference for certain languages, which we call techno-linguistic bias.\nTechno-linguistic bias is distinct from the well-established phenomenon of\nlinguistic bias as it does not concern the languages represented but rather the\ndesign of the technologies. As we show through the paper, techno-linguistic\nbias can result in systems that can only express concepts that are part of the\nlanguage and culture of dominant powers, unable to correctly represent concepts\nfrom other communities. We argue that at the root of this problem lies a\nsystematic tendency of technology developer communities to apply a simplistic\nunderstanding of diversity which does not do justice to the more profound\ndifferences that languages, and ultimately the communities that speak them,\nembody. Drawing on the concept of epistemic injustice, we point to the broader\nsociopolitical consequences of the bias we identify and show how it can lead\nnot only to a disregard for valuable aspects of diversity but also to an\nunder-representation of the needs and diverse worldviews of marginalized\nlanguage communities.", "published": "2023-07-25 16:08:27", "link": "http://arxiv.org/abs/2307.13714v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning\n  Sparse Contextualized Word Representations", "abstract": "In this paper, we advocate for using large pre-trained monolingual language\nmodels in cross lingual zero-shot word sense disambiguation (WSD) coupled with\na contextualized mapping mechanism. We also report rigorous experiments that\nillustrate the effectiveness of employing sparse contextualized word\nrepresentations obtained via a dictionary learning procedure. Our experimental\nresults demonstrate that the above modifications yield a significant\nimprovement of nearly 6.5 points of increase in the average F-score (from 62.0\nto 68.5) over a collection of 17 typologically diverse set of target languages.\nWe release our source code for replicating our experiments at\nhttps://github.com/begab/sparsity_makes_sense.", "published": "2023-07-25 19:20:50", "link": "http://arxiv.org/abs/2307.13776v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Watermarking Conditional Text Generation for AI Detection: Unveiling\n  Challenges and a Semantic-Aware Watermark Remedy", "abstract": "To mitigate potential risks associated with language models, recent AI\ndetection research proposes incorporating watermarks into machine-generated\ntext through random vocabulary restrictions and utilizing this information for\ndetection. While these watermarks only induce a slight deterioration in\nperplexity, our empirical investigation reveals a significant detriment to the\nperformance of conditional text generation. To address this issue, we introduce\na simple yet effective semantic-aware watermarking algorithm that considers the\ncharacteristics of conditional text generation and the input context.\nExperimental results demonstrate that our proposed method yields substantial\nimprovements across various text generation models, including BART and Flan-T5,\nin tasks such as summarization and data-to-text generation while maintaining\ndetection ability.", "published": "2023-07-25 20:24:22", "link": "http://arxiv.org/abs/2307.13808v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal\n  Methods Boosted by Ensemble Learning, Syntactical and Entity Features", "abstract": "Text-embedded images can serve as a means of spreading hate speech,\npropaganda, and extremist beliefs. Throughout the Russia-Ukraine war, both\nopposing factions heavily relied on text-embedded images as a vehicle for\nspreading propaganda and hate speech. Ensuring the effective detection of hate\nspeech and propaganda is of utmost importance to mitigate the negative effect\nof hate speech dissemination. In this paper, we outline our methodologies for\ntwo subtasks of Multimodal Hate Speech Event Detection 2023. For the first\nsubtask, hate speech detection, we utilize multimodal deep learning models\nboosted by ensemble learning and syntactical text attributes. For the second\nsubtask, target detection, we employ multimodal deep learning models boosted by\nnamed entity features. Through experimentation, we demonstrate the superior\nperformance of our models compared to all textual, visual, and text-visual\nbaselines employed in multimodal hate speech detection. Furthermore, our models\nachieve the first place in both subtasks on the final leaderboard of the shared\ntask.", "published": "2023-07-25 21:56:14", "link": "http://arxiv.org/abs/2307.13829v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "How Can Large Language Models Help Humans in Design and Manufacturing?", "abstract": "The advancement of Large Language Models (LLMs), including GPT-4, provides\nexciting new opportunities for generative design. We investigate the\napplication of this tool across the entire design and manufacturing workflow.\nSpecifically, we scrutinize the utility of LLMs in tasks such as: converting a\ntext-based prompt into a design specification, transforming a design into\nmanufacturing instructions, producing a design space and design variations,\ncomputing the performance of a design, and searching for designs predicated on\nperformance. Through a series of examples, we highlight both the benefits and\nthe limitations of the current LLMs. By exposing these limitations, we aspire\nto catalyze the continued improvement and progression of these models.", "published": "2023-07-25 17:30:38", "link": "http://arxiv.org/abs/2307.14377v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Embedding Models for Supervised Automatic Extraction and Classification\n  of Named Entities in Scientific Acknowledgements", "abstract": "Acknowledgments in scientific papers may give an insight into aspects of the\nscientific community, such as reward systems, collaboration patterns, and\nhidden research trends. The aim of the paper is to evaluate the performance of\ndifferent embedding models for the task of automatic extraction and\nclassification of acknowledged entities from the acknowledgment text in\nscientific papers. We trained and implemented a named entity recognition (NER)\ntask using the Flair NLP framework. The training was conducted using three\ndefault Flair NER models with four differently-sized corpora and different\nversions of the Flair NLP framework. The Flair Embeddings model trained on the\nmedium corpus with the latest FLAIR version showed the best accuracy of 0.79.\nExpanding the size of a training corpus from very small to medium size\nmassively increased the accuracy of all training algorithms, but further\nexpansion of the training corpus did not bring further improvement. Moreover,\nthe performance of the model slightly deteriorated. Our model is able to\nrecognize six entity types: funding agency, grant number, individuals,\nuniversity, corporation, and miscellaneous. The model works more precisely for\nsome entity types than for others; thus, individuals and grant numbers showed a\nvery good F1-Score over 0.9. Most of the previous works on acknowledgment\nanalysis were limited by the manual evaluation of data and therefore by the\namount of processed data. This model can be applied for the comprehensive\nanalysis of acknowledgment texts and may potentially make a great contribution\nto the field of automated acknowledgment analysis.", "published": "2023-07-25 09:51:17", "link": "http://arxiv.org/abs/2307.13377v1", "categories": ["cs.DL", "cs.CL", "cs.IR", "J.4; J.5; I.5.1; H.3.3; I.2.7"], "primary_category": "cs.DL"}
{"title": "Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition\n  and Relation Extraction", "abstract": "The Zero-Shot Learning (ZSL) task pertains to the identification of entities\nor relations in texts that were not seen during training. ZSL has emerged as a\ncritical research area due to the scarcity of labeled data in specific domains,\nand its applications have grown significantly in recent years. With the advent\nof large pretrained language models, several novel methods have been proposed,\nresulting in substantial improvements in ZSL performance. There is a growing\ndemand, both in the research community and industry, for a comprehensive ZSL\nframework that facilitates the development and accessibility of the latest\nmethods and pretrained models.In this study, we propose a novel ZSL framework\ncalled Zshot that aims to address the aforementioned challenges. Our primary\nobjective is to provide a platform that allows researchers to compare different\nstate-of-the-art ZSL methods with standard benchmark datasets. Additionally, we\nhave designed our framework to support the industry with readily available APIs\nfor production under the standard SpaCy NLP pipeline. Our API is extendible and\nevaluable, moreover, we include numerous enhancements such as boosting the\naccuracy with pipeline ensembling and visualization utilities available as a\nSpaCy extension.", "published": "2023-07-25 13:46:36", "link": "http://arxiv.org/abs/2307.13497v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is GPT a Computational Model of Emotion? Detailed Analysis", "abstract": "This paper investigates the emotional reasoning abilities of the GPT family\nof large language models via a component perspective. The paper first examines\nhow the model reasons about autobiographical memories. Second, it\nsystematically varies aspects of situations to impact emotion intensity and\ncoping tendencies. Even without the use of prompt engineering, it is shown that\nGPT's predictions align significantly with human-provided appraisals and\nemotional labels. However, GPT faces difficulties predicting emotion intensity\nand coping responses. GPT-4 showed the highest performance in the initial study\nbut fell short in the second, despite providing superior results after minor\nprompt engineering. This assessment brings up questions on how to effectively\nemploy the strong points and address the weak areas of these models,\nparticularly concerning response variability. These studies underscore the\nmerits of evaluating models from a componential perspective.", "published": "2023-07-25 19:34:44", "link": "http://arxiv.org/abs/2307.13779v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "WebArena: A Realistic Web Environment for Building Autonomous Agents", "abstract": "With advances in generative AI, there is now potential for autonomous agents\nto manage daily tasks via natural language commands. However, current agents\nare primarily created and tested in simplified synthetic environments, leading\nto a disconnect with real-world scenarios. In this paper, we build an\nenvironment for language-guided agents that is highly realistic and\nreproducible. Specifically, we focus on agents that perform tasks on the web,\nand create an environment with fully functional websites from four common\ndomains: e-commerce, social forum discussions, collaborative software\ndevelopment, and content management. Our environment is enriched with tools\n(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage\nhuman-like task-solving. Building upon our environment, we release a set of\nbenchmark tasks focusing on evaluating the functional correctness of task\ncompletions. The tasks in our benchmark are diverse, long-horizon, and designed\nto emulate tasks that humans routinely perform on the internet. We experiment\nwith several baseline agents, integrating recent techniques such as reasoning\nbefore acting. The results demonstrate that solving complex tasks is\nchallenging: our best GPT-4-based agent only achieves an end-to-end task\nsuccess rate of 14.41%, significantly lower than the human performance of\n78.24%. These results highlight the need for further development of robust\nagents, that current state-of-the-art large language models are far from\nperfect performance in these real-life tasks, and that WebArena can be used to\nmeasure such progress.", "published": "2023-07-25 22:59:32", "link": "http://arxiv.org/abs/2307.13854v4", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Prot2Text: Multimodal Protein's Function Generation with GNNs and\n  Transformers", "abstract": "In recent years, significant progress has been made in the field of protein\nfunction prediction with the development of various machine-learning\napproaches. However, most existing methods formulate the task as a\nmulti-classification problem, i.e. assigning predefined labels to proteins. In\nthis work, we propose a novel approach, Prot2Text, which predicts a protein's\nfunction in a free text style, moving beyond the conventional binary or\ncategorical classifications. By combining Graph Neural Networks(GNNs) and Large\nLanguage Models(LLMs), in an encoder-decoder framework, our model effectively\nintegrates diverse data types including protein sequence, structure, and\ntextual annotation and description. This multimodal approach allows for a\nholistic representation of proteins' functions, enabling the generation of\ndetailed and accurate functional descriptions. To evaluate our model, we\nextracted a multimodal protein dataset from SwissProt, and demonstrate\nempirically the effectiveness of Prot2Text. These results highlight the\ntransformative impact of multimodal models, specifically the fusion of GNNs and\nLLMs, empowering researchers with powerful tools for more accurate function\nprediction of existing as well as first-to-see proteins.", "published": "2023-07-25 09:35:43", "link": "http://arxiv.org/abs/2307.14367v3", "categories": ["q-bio.QM", "cs.CL", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Word Sense Disambiguation as a Game of Neurosymbolic Darts", "abstract": "Word Sense Disambiguation (WSD) is one of the hardest tasks in natural\nlanguage understanding and knowledge engineering. The glass ceiling of 80% F1\nscore is recently achieved through supervised deep-learning, enriched by a\nvariety of knowledge graphs. Here, we propose a novel neurosymbolic methodology\nthat is able to push the F1 score above 90%. The core of our methodology is a\nneurosymbolic sense embedding, in terms of a configuration of nested balls in\nn-dimensional space. The centre point of a ball well-preserves word embedding,\nwhich partially fix the locations of balls. Inclusion relations among balls\nprecisely encode symbolic hypernym relations among senses, and enable simple\nlogic deduction among sense embeddings, which cannot be realised before. We\ntrained a Transformer to learn the mapping from a contextualized word embedding\nto its sense ball embedding, just like playing the game of darts (a game of\nshooting darts into a dartboard). A series of experiments are conducted by\nutilizing pre-training n-ball embeddings, which have the coverage of around 70%\ntraining data and 75% testing data in the benchmark WSD corpus. The F1 scores\nin experiments range from 90.1% to 100.0% in all six groups of test data-sets\n(each group has 4 testing data with different sizes of n-ball embeddings). Our\nnovel neurosymbolic methodology has the potential to break the ceiling of\ndeep-learning approaches for WSD. Limitations and extensions of our current\nworks are listed.", "published": "2023-07-25 07:22:57", "link": "http://arxiv.org/abs/2307.16663v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech representation learning: Learning bidirectional encoders with\n  single-view, multi-view, and multi-task methods", "abstract": "This thesis focuses on representation learning for sequence data over time or\nspace, aiming to improve downstream sequence prediction tasks by using the\nlearned representations. Supervised learning has been the most dominant\napproach for training deep neural networks for learning good sequential\nrepresentations. However, one limiting factor to scale supervised learning is\nthe lack of enough annotated data. Motivated by this challenge, it is natural\nto explore representation learning methods that can utilize large amounts of\nunlabeled and weakly labeled data, as well as an additional data modality. I\ndescribe my broad study of representation learning for speech data. Unlike most\nother works that focus on a single learning setting, this thesis studies\nmultiple settings: supervised learning with auxiliary losses, unsupervised\nlearning, semi-supervised learning, and multi-view learning. Besides different\nlearning problems, I also explore multiple approaches for representation\nlearning. Though I focus on speech data, the methods described in this thesis\ncan also be applied to other domains. Overall, the field of representation\nlearning is developing rapidly. State-of-the-art results on speech related\ntasks are typically based on Transformers pre-trained with large-scale\nself-supervised learning, which aims to learn generic representations that can\nbenefit multiple downstream tasks. Since 2020, large-scale pre-training has\nbeen the de facto choice to achieve good performance. This delayed thesis does\nnot attempt to summarize and compare with the latest results on speech\nrepresentation learning; instead, it presents a unique study on speech\nrepresentation learning before the Transformer era, that covers multiple\nlearning settings. Some of the findings in this thesis can still be useful\ntoday.", "published": "2023-07-25 20:38:55", "link": "http://arxiv.org/abs/2308.00129v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "CQNV: A combination of coarsely quantized bitstream and neural vocoder\n  for low rate speech coding", "abstract": "Recently, speech codecs based on neural networks have proven to perform\nbetter than traditional methods. However, redundancy in traditional parameter\nquantization is visible within the codec architecture of combining the\ntraditional codec with the neural vocoder. In this paper, we propose a novel\nframework named CQNV, which combines the coarsely quantized parameters of a\ntraditional parametric codec to reduce the bitrate with a neural vocoder to\nimprove the quality of the decoded speech. Furthermore, we introduce a\nparameters processing module into the neural vocoder to enhance the application\nof the bitstream of traditional speech coding parameters to the neural vocoder,\nfurther improving the reconstructed speech's quality. In the experiments, both\nsubjective and objective evaluations demonstrate the effectiveness of the\nproposed CQNV framework. Specifically, our proposed method can achieve higher\nquality reconstructed speech at 1.1 kbps than Lyra and Encodec at 3 kbps.", "published": "2023-07-25 07:21:27", "link": "http://arxiv.org/abs/2307.13295v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On-Device Speaker Anonymization of Acoustic Embeddings for ASR based\n  onFlexible Location Gradient Reversal Layer", "abstract": "Smart devices serviced by large-scale AI models necessitates user data\ntransfer to the cloud for inference. For speech applications, this means\ntransferring private user information, e.g., speaker identity. Our paper\nproposes a privacy-enhancing framework that targets speaker identity\nanonymization while preserving speech recognition accuracy for our downstream\ntask~-~Automatic Speech Recognition (ASR). The proposed framework attaches\nflexible gradient reversal based speaker adversarial layers to target layers\nwithin an ASR model, where speaker adversarial training anonymizes acoustic\nembeddings generated by the targeted layers to remove speaker identity. We\npropose on-device deployment by execution of initial layers of the ASR model,\nand transmitting anonymized embeddings to the cloud, where the rest of the\nmodel is executed while preserving privacy. Experimental results show that our\nmethod efficiently reduces speaker recognition relative accuracy by 33%, and\nimproves ASR performance by achieving 6.2% relative Word Error Rate (WER)\nreduction.", "published": "2023-07-25 08:57:55", "link": "http://arxiv.org/abs/2307.13343v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Snoring Sound Dataset for Body Position Recognition: Collection,\n  Annotation, and Analysis", "abstract": "Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a chronic breathing\ndisorder caused by a blockage in the upper airways. Snoring is a prominent\nsymptom of OSAHS, and previous studies have attempted to identify the\nobstruction site of the upper airways by snoring sounds. Despite some progress,\nthe classification of the obstruction site remains challenging in real-world\nclinical settings due to the influence of sleep body position on upper airways.\nTo address this challenge, this paper proposes a snore-based sleep body\nposition recognition dataset (SSBPR) consisting of 7570 snoring recordings,\nwhich comprises six distinct labels for sleep body position: supine, supine but\nleft lateral head, supine but right lateral head, left-side lying, right-side\nlying and prone. Experimental results show that snoring sounds exhibit certain\nacoustic features that enable their effective utilization for identifying body\nposture during sleep in real-world scenarios.", "published": "2023-07-25 09:03:27", "link": "http://arxiv.org/abs/2307.13346v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals\n  using Self Supervised Speech Representations", "abstract": "Self-supervised speech representations (SSSRs) have been successfully applied\nto a number of speech-processing tasks, e.g. as feature extractor for speech\nquality (SQ) prediction, which is, in turn, relevant for assessment and\ntraining speech enhancement systems for users with normal or impaired hearing.\nHowever, exact knowledge of why and how quality-related information is encoded\nwell in such representations remains poorly understood. In this work,\ntechniques for non-intrusive prediction of SQ ratings are extended to the\nprediction of intelligibility for hearing-impaired users. It is found that\nself-supervised representations are useful as input features to non-intrusive\nprediction models, achieving competitive performance to more complex systems. A\ndetailed analysis of the performance depending on Clarity Prediction Challenge\n1 listeners and enhancement systems indicates that more data might be needed to\nallow generalisation to unknown systems and (hearing-impaired) individuals", "published": "2023-07-25 11:42:52", "link": "http://arxiv.org/abs/2307.13423v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Histogram Layer Time Delay Neural Networks for Passive Sonar\n  Classification", "abstract": "Underwater acoustic target detection in remote marine sensing operations is\nchallenging due to complex sound wave propagation. Despite the availability of\nreliable sonar systems, target recognition remains a difficult problem. Various\nmethods address improved target recognition. However, most struggle to\ndisentangle the high-dimensional, non-linear patterns in the observed target\nrecordings. In this work, a novel method combines a time delay neural network\nand histogram layer to incorporate statistical contexts for improved feature\nlearning and underwater acoustic target classification. The proposed method\noutperforms the baseline model, demonstrating the utility in incorporating\nstatistical contexts for passive sonar target recognition. The code for this\nwork is publicly available.", "published": "2023-07-25 19:47:26", "link": "http://arxiv.org/abs/2307.13788v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation", "abstract": "The goal of the audio-visual segmentation (AVS) task is to segment the\nsounding objects in the video frames using audio cues. However, current\nfusion-based methods have the performance limitations due to the small\nreceptive field of convolution and inadequate fusion of audio-visual features.\nTo overcome these issues, we propose a novel \\textbf{Au}dio-aware\nquery-enhanced \\textbf{TR}ansformer (AuTR) to tackle the task. Unlike existing\nmethods, our approach introduces a multimodal transformer architecture that\nenables deep fusion and aggregation of audio-visual features. Furthermore, we\ndevise an audio-aware query-enhanced transformer decoder that explicitly helps\nthe model focus on the segmentation of the pinpointed sounding objects based on\naudio signals, while disregarding silent yet salient objects. Experimental\nresults show that our method outperforms previous methods and demonstrates\nbetter generalization ability in multi-sound and open-set scenarios.", "published": "2023-07-25 03:59:04", "link": "http://arxiv.org/abs/2307.13236v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fitting Auditory Filterbanks with Multiresolution Neural Networks", "abstract": "Waveform-based deep learning faces a dilemma between nonparametric and\nparametric approaches. On one hand, convolutional neural networks (convnets)\nmay approximate any linear time-invariant system; yet, in practice, their\nfrequency responses become more irregular as their receptive fields grow. On\nthe other hand, a parametric model such as LEAF is guaranteed to yield Gabor\nfilters, hence an optimal time-frequency localization; yet, this strong\ninductive bias comes at the detriment of representational capacity. In this\npaper, we aim to overcome this dilemma by introducing a neural audio model,\nnamed multiresolution neural network (MuReNN). The key idea behind MuReNN is to\ntrain separate convolutional operators over the octave subbands of a discrete\nwavelet transform (DWT). Since the scale of DWT atoms grows exponentially\nbetween octaves, the receptive fields of the subsequent learnable convolutions\nin MuReNN are dilated accordingly. For a given real-world dataset, we fit the\nmagnitude response of MuReNN to that of a well-established auditory filterbank:\nGammatone for speech, CQT for music, and third-octave for urban sounds,\nrespectively. This is a form of knowledge distillation (KD), in which the\nfilterbank ''teacher'' is engineered by domain knowledge while the neural\nnetwork ''student'' is optimized from data. We compare MuReNN to the state of\nthe art in terms of goodness of fit after KD on a hold-out set and in terms of\nHeisenberg time-frequency localization. Compared to convnets and Gabor\nconvolutions, we find that MuReNN reaches state-of-the-art performance on all\nthree optimization problems.", "published": "2023-07-25 21:20:12", "link": "http://arxiv.org/abs/2307.13821v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "math.FA"], "primary_category": "cs.SD"}
