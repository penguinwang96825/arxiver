{"title": "Language Cognition and Language Computation -- Human and Machine\n  Language Understanding", "abstract": "Language understanding is a key scientific issue in the fields of cognitive\nand computer science. However, the two disciplines differ substantially in the\nspecific research questions. Cognitive science focuses on analyzing the\nspecific mechanism of the brain and investigating the brain's response to\nlanguage; few studies have examined the brain's language system as a whole. By\ncontrast, computer scientists focus on the efficiency of practical applications\nwhen choosing research questions but may ignore the most essential laws of\nlanguage. Given these differences, can a combination of the disciplines offer\nnew insights for building intelligent language models and studying language\ncognitive mechanisms? In the following text, we first review the research\nquestions, history, and methods of language understanding in cognitive and\ncomputer science, focusing on the current progress and challenges. We then\ncompare and contrast the research of language understanding in cognitive and\ncomputer sciences. Finally, we review existing work that combines insights from\nlanguage cognition and language computation and offer prospects for future\ndevelopment trends.", "published": "2023-01-12 02:37:00", "link": "http://arxiv.org/abs/2301.04788v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dataset of Kurdish (Sorani) Named Entities -- An Amendment to\n  Kurdish-BLARK Named Entities", "abstract": "Named Entity Recognition (NER) is one of the essential applications of\nNatural Language Processing (NLP). It is also an instrument that plays a\nsignificant role in many other NLP applications, such as Machine Translation\n(MT), Information Retrieval (IR), and Part of Speech Tagging (POST). Kurdish is\nan under-resourced language from the NLP perspective. Particularly, in all the\ncategories, the lack of NER resources hinders other aspects of Kurdish\nprocessing. In this work, we present a data set that covers several categories\nof NEs in Kurdish (Sorani). The dataset is a significant amendment to a\npreviously developed dataset in the Kurdish BLARK (Basic Language Resource\nKit). It covers 11 categories and 33261 entries in total. The dataset is\npublicly available for non-commercial use under CC BY-NC-SA 4.0 license at\nhttps://kurdishblark.github.io/.", "published": "2023-01-12 12:13:44", "link": "http://arxiv.org/abs/2301.04962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blind Judgement: Agent-Based Supreme Court Modelling With GPT", "abstract": "We present a novel Transformer-based multi-agent system for simulating the\njudicial rulings of the 2010-2016 Supreme Court of the United States. We train\nnine separate models with the respective authored opinions of each supreme\njustice active ca. 2015 and test the resulting system on 96 real-world cases.\nWe find our system predicts the decisions of the real-world Supreme Court with\nbetter-than-random accuracy. We further find a correlation between model\naccuracy with respect to individual justices and their alignment between legal\nconservatism & liberalism. Our methods and results hold significance for\nresearchers interested in using language models to simulate politically-charged\ndiscourse between multiple agents.", "published": "2023-01-12 23:07:55", "link": "http://arxiv.org/abs/2301.05327v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Cohesive Distillation Architecture for Neural Language Models", "abstract": "A recent trend in Natural Language Processing is the exponential growth in\nLanguage Model (LM) size, which prevents research groups without a necessary\nhardware infrastructure from participating in the development process. This\nstudy investigates methods for Knowledge Distillation (KD) to provide efficient\nalternatives to large-scale models. In this context, KD means extracting\ninformation about language encoded in a Neural Network and Lexical Knowledge\nDatabases. We developed two methods to test our hypothesis that efficient\narchitectures can gain knowledge from LMs and extract valuable information from\nlexical sources. First, we present a technique to learn confident probability\ndistribution for Masked Language Modeling by prediction weighting of multiple\nteacher networks. Second, we propose a method for Word Sense Disambiguation\n(WSD) and lexical KD that is general enough to be adapted to many LMs. Our\nresults show that KD with multiple teachers leads to improved training\nconvergence. When using our lexical pre-training method, LM characteristics are\nnot lost, leading to increased performance in Natural Language Understanding\n(NLU) tasks over the state-of-the-art while adding no parameters. Moreover, the\nimproved semantic understanding of our model increased the task performance\nbeyond WSD and NLU in a real-problem scenario (Plagiarism Detection). This\nstudy suggests that sophisticated training methods and network architectures\ncan be superior over scaling trainable parameters. On this basis, we suggest\nthe research area should encourage the development and use of efficient models\nand rate impacts resulting from growing LM size equally against task\nperformance.", "published": "2023-01-12 08:01:53", "link": "http://arxiv.org/abs/2301.08130v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Memorize Entailment and Discourse Relations for\n  Persona-Consistent Dialogues", "abstract": "Maintaining engagement and consistency is particularly important in dialogue\nsystems. Existing works have improved the performance of dialogue systems by\nintentionally learning interlocutor personas with sophisticated network\nstructures. One issue with this approach is that it requires more personal\ncorpora with annotations. Additionally, these models typically perform the next\nutterance prediction to generate a response but neglect the discourse coherence\nin the entire conversation. To address these issues, this study proposes a\nmethod of learning to memorize entailment and discourse relations for\npersona-consistent dialogue tasks. Entailment text pairs in natural language\ninference dataset were applied to learn latent entailment relations as external\nmemories by premise-to-hypothesis generation task. Furthermore, an internal\nmemory with a similar architecture was applied to the discourse information in\nthe dialogue. Placing orthogonality restrictions on these two memory spaces\nensures that the latent entailment relations remain dialogue-independent. Both\nmemories collaborate to obtain entailment and discourse representation for the\ngeneration, allowing a deeper understanding of both consistency and coherence.\nExperiments on two large public datasets, PersonaChat and DSTC7-AVSD,\ndemonstrated the effectiveness of the proposed method. Both automatic and human\nevaluations indicate that the proposed model outperforms several strong\nbaselines in terms of both persona consistency and response coherence. Our\nsource code is available at https://github.com/Chenrj233/LMEDR.", "published": "2023-01-12 08:37:00", "link": "http://arxiv.org/abs/2301.04871v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SlideVQA: A Dataset for Document Visual Question Answering on Multiple\n  Images", "abstract": "Visual question answering on document images that contain textual, visual,\nand layout information, called document VQA, has received much attention\nrecently. Although many datasets have been proposed for developing document VQA\nsystems, most of the existing datasets focus on understanding the content\nrelationships within a single image and not across multiple images. In this\nstudy, we propose a new multi-image document VQA dataset, SlideVQA, containing\n2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a\nslide deck. SlideVQA requires complex reasoning, including single-hop,\nmulti-hop, and numerical reasoning, and also provides annotated arithmetic\nexpressions of numerical answers for enhancing the ability of numerical\nreasoning. Moreover, we developed a new end-to-end document VQA model that\ntreats evidence selection and question answering in a unified\nsequence-to-sequence format. Experiments on SlideVQA show that our model\noutperformed existing state-of-the-art QA models, but that it still has a large\ngap behind human performance. We believe that our dataset will facilitate\nresearch on document VQA.", "published": "2023-01-12 09:00:42", "link": "http://arxiv.org/abs/2301.04883v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Think Twice: A Human-like Two-stage Conversational Agent for Emotional\n  Response Generation", "abstract": "Towards human-like dialogue systems, current emotional dialogue approaches\njointly model emotion and semantics with a unified neural network. This\nstrategy tends to generate safe responses due to the mutual restriction between\nemotion and semantics, and requires rare emotion-annotated large-scale dialogue\ncorpus. Inspired by the \"think twice\" behavior in human dialogue, we propose a\ntwo-stage conversational agent for the generation of emotional dialogue.\nFirstly, a dialogue model trained without the emotion-annotated dialogue corpus\ngenerates a prototype response that meets the contextual semantics. Secondly,\nthe first-stage prototype is modified by a controllable emotion refiner with\nthe empathy hypothesis. Experimental results on the DailyDialog and\nEmpatheticDialogues datasets demonstrate that the proposed conversational\noutperforms the comparison models in emotion generation and maintains the\nsemantic performance in automatic and human evaluations.", "published": "2023-01-12 10:03:56", "link": "http://arxiv.org/abs/2301.04907v3", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "KAER: A Knowledge Augmented Pre-Trained Language Model for Entity\n  Resolution", "abstract": "Entity resolution has been an essential and well-studied task in data\ncleaning research for decades. Existing work has discussed the feasibility of\nutilizing pre-trained language models to perform entity resolution and achieved\npromising results. However, few works have discussed injecting domain knowledge\nto improve the performance of pre-trained language models on entity resolution\ntasks. In this study, we propose Knowledge Augmented Entity Resolution (KAER),\na novel framework named for augmenting pre-trained language models with\nexternal knowledge for entity resolution. We discuss the results of utilizing\ndifferent knowledge augmentation and prompting methods to improve entity\nresolution performance. Our model improves on Ditto, the existing\nstate-of-the-art entity resolution method. In particular, 1) KAER performs more\nrobustly and achieves better results on \"dirty data\", and 2) with more general\nknowledge injection, KAER outperforms the existing baseline models on the\ntextual dataset and dataset from the online product domain. 3) KAER achieves\ncompetitive results on highly domain-specific datasets, such as citation\ndatasets, requiring the injection of expert knowledge in future work.", "published": "2023-01-12 00:15:40", "link": "http://arxiv.org/abs/2301.04770v1", "categories": ["cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Deep Learning", "abstract": "This book is the result of a seminar in which we reviewed multimodal\napproaches and attempted to create a solid overview of the field, starting with\nthe current state-of-the-art approaches in the two subfields of Deep Learning\nindividually. Further, modeling frameworks are discussed where one modality is\ntransformed into the other, as well as models in which one modality is utilized\nto enhance representation learning for the other. To conclude the second part,\narchitectures with a focus on handling both modalities simultaneously are\nintroduced. Finally, we also cover other modalities as well as general-purpose\nmulti-modal models, which are able to handle different tasks on different\nmodalities within one unified architecture. One interesting application\n(Generative Art) eventually caps off this booklet.", "published": "2023-01-12 07:42:36", "link": "http://arxiv.org/abs/2301.04856v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Everyone's Voice Matters: Quantifying Annotation Disagreement Using\n  Demographic Information", "abstract": "In NLP annotation, it is common to have multiple annotators label the text\nand then obtain the ground truth labels based on the agreement of major\nannotators. However, annotators are individuals with different backgrounds, and\nminors' opinions should not be simply ignored. As annotation tasks become\nsubjective and topics are controversial in modern NLP tasks, we need NLP\nsystems that can represent people's diverse voices on subjective matters and\npredict the level of diversity. This paper examines whether the text of the\ntask and annotators' demographic background information can be used to estimate\nthe level of disagreement among annotators. Particularly, we extract\ndisagreement labels from the annotators' voting histories in the five\nsubjective datasets, and then fine-tune language models to predict annotators'\ndisagreement. Our results show that knowing annotators' demographic\ninformation, like gender, ethnicity, and education level, helps predict\ndisagreements. In order to distinguish the disagreement from the inherent\ncontroversy from text content and the disagreement in the annotators' different\nperspectives, we simulate everyone's voices with different combinations of\nannotators' artificial demographics and examine its variance of the finetuned\ndisagreement predictor. Our paper aims to improve the annotation process for\nmore efficient and inclusive NLP systems through a novel disagreement\nprediction mechanism. Our code and dataset are publicly available.", "published": "2023-01-12 14:04:53", "link": "http://arxiv.org/abs/2301.05036v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Adversarial Adaptation for French Named Entity Recognition", "abstract": "Named Entity Recognition (NER) is the task of identifying and classifying\nnamed entities in large-scale texts into predefined classes. NER in French and\nother relatively limited-resource languages cannot always benefit from\napproaches proposed for languages like English due to a dearth of large, robust\ndatasets. In this paper, we present our work that aims to mitigate the effects\nof this dearth of large, labeled datasets. We propose a Transformer-based NER\napproach for French, using adversarial adaptation to similar domain or general\ncorpora to improve feature extraction and enable better generalization. Our\napproach allows learning better features using large-scale unlabeled corpora\nfrom the same domain or mixed domains to introduce more variations during\ntraining and reduce overfitting. Experimental results on three labeled datasets\nshow that our adaptation framework outperforms the corresponding non-adaptive\nmodels for various combinations of Transformer models, source datasets, and\ntarget corpora. We also show that adversarial adaptation to large-scale\nunlabeled corpora can help mitigate the performance dip incurred on using\nTransformer models pre-trained on smaller corpora.", "published": "2023-01-12 18:58:36", "link": "http://arxiv.org/abs/2301.05220v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "See, Think, Confirm: Interactive Prompting Between Vision and Language\n  Models for Knowledge-based Visual Reasoning", "abstract": "Large pre-trained vision and language models have demonstrated remarkable\ncapacities for various tasks. However, solving the knowledge-based visual\nreasoning tasks remains challenging, which requires a model to comprehensively\nunderstand image content, connect the external world knowledge, and perform\nstep-by-step reasoning to answer the questions correctly. To this end, we\npropose a novel framework named Interactive Prompting Visual Reasoner (IPVR)\nfor few-shot knowledge-based visual reasoning. IPVR contains three stages, see,\nthink and confirm. The see stage scans the image and grounds the visual concept\ncandidates with a visual perception model. The think stage adopts a pre-trained\nlarge language model (LLM) to attend to the key concepts from candidates\nadaptively. It then transforms them into text context for prompting with a\nvisual captioning model and adopts the LLM to generate the answer. The confirm\nstage further uses the LLM to generate the supporting rationale to the answer,\nverify the generated rationale with a cross-modality classifier and ensure that\nthe rationale can infer the predicted output consistently. We conduct\nexperiments on a range of knowledge-based visual reasoning datasets. We found\nour IPVR enjoys several benefits, 1). it achieves better performance than the\nprevious few-shot learning baselines; 2). it enjoys the total transparency and\ntrustworthiness of the whole reasoning process by providing rationales for each\nreasoning step; 3). it is computation-efficient compared with other fine-tuning\nbaselines.", "published": "2023-01-12 18:59:50", "link": "http://arxiv.org/abs/2301.05226v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Inaccessible Neural Language Models Could Reinvigorate Linguistic\n  Nativism", "abstract": "Large Language Models (LLMs) have been making big waves in the machine\nlearning community within the past few years. The impressive scalability of\nLLMs due to the advent of deep learning can be seen as a continuation of\nempiricist lingusitic methods, as opposed to rule-based linguistic methods that\nare grounded in a nativist perspective. Current LLMs are generally inaccessible\nto resource-constrained researchers, due to a variety of factors including\nclosed source code. This work argues that this lack of accessibility could\ninstill a nativist bias in researchers new to computational linguistics, given\nthat new researchers may only have rule-based, nativist approaches to study to\nproduce new work. Also, given that there are numerous critics of deep learning\nclaiming that LLMs and related methods may soon lose their relevancy, we\nspeculate that such an event could trigger a new wave of nativism in the\nlanguage processing community. To prevent such a dramatic shift and placing\nfavor in hybrid methods of rules and deep learning, we call upon researchers to\nopen source their LLM code wherever possible to allow both empircist and hybrid\napproaches to remain accessible.", "published": "2023-01-12 19:41:47", "link": "http://arxiv.org/abs/2301.05272v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rock Guitar Tablature Generation via Natural Language Processing", "abstract": "Deep learning has recently empowered and democratized generative modeling of\nimages and text, with additional concurrent works exploring the possibility of\ngenerating more complex forms of data, such as audio. However, the high\ndimensionality, long-range dependencies, and lack of standardized datasets\ncurrently makes generative modeling of audio and music very challenging. We\npropose to model music as a series of discrete notes upon which we can use\nautoregressive natural language processing techniques for successful generative\nmodeling. While previous works used similar pipelines on data such as sheet\nmusic and MIDI, we aim to extend such approaches to the under-studied medium of\nguitar tablature. Specifically, we develop the first work to our knowledge that\nmodels one specific genre as guitar tablature: heavy rock. Unlike other works\nin guitar tablature generation, we have a freely available public demo at\nhttps://huggingface.co/spaces/josuelmet/Metal_Music_Interpolator", "published": "2023-01-12 21:12:08", "link": "http://arxiv.org/abs/2301.05295v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
