{"title": "Speculative Beam Search for Simultaneous Translation", "abstract": "Beam search is universally used in full-sentence translation but its\napplication to simultaneous translation remains non-trivial, where output words\nare committed on the fly. In particular, the recently proposed wait-k policy\n(Ma et al., 2019a) is a simple and effective method that (after an initial\nwait) commits one output word on receiving each input word, making beam search\nseemingly impossible. To address this challenge, we propose a speculative beam\nsearch algorithm that hallucinates several steps into the future in order to\nreach a more accurate decision, implicitly benefiting from a target language\nmodel. This makes beam search applicable for the first time to the generation\nof a single word in each step. Experiments over diverse language pairs show\nlarge improvements over previous work.", "published": "2019-09-12 01:00:59", "link": "http://arxiv.org/abs/1909.05421v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VizSeq: A Visual Analysis Toolkit for Text Generation Tasks", "abstract": "Automatic evaluation of text generation tasks (e.g. machine translation, text\nsummarization, image captioning and video description) usually relies heavily\non task-specific metrics, such as BLEU and ROUGE. They, however, are abstract\nnumbers and are not perfectly aligned with human assessment. This suggests\ninspecting detailed examples as a complement to identify system error patterns.\nIn this paper, we present VizSeq, a visual analysis toolkit for instance-level\nand corpus-level system evaluation on a wide variety of text generation tasks.\nIt supports multimodal sources and multiple text references, providing\nvisualization in Jupyter notebook or a web app interface. It can be used\nlocally or deployed onto public servers for centralized data hosting and\nbenchmarking. It covers most common n-gram based metrics accelerated with\nmultiprocessing, and also provides latest embedding-based metrics such as\nBERTScore.", "published": "2019-09-12 01:16:27", "link": "http://arxiv.org/abs/1909.05424v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Semantic Parsing in Low-Resource Settings with Back-Translation\n  and Meta-Learning", "abstract": "Neural semantic parsing has achieved impressive results in recent years, yet\nits success relies on the availability of large amounts of supervised data. Our\ngoal is to learn a neural semantic parser when only prior knowledge about a\nlimited number of simple rules is available, without access to either annotated\nprograms or execution results. Our approach is initialized by rules, and\nimproved in a back-translation paradigm using generated question-program pairs\nfrom the semantic parser and the question generator. A phrase table with\nfrequent mapping patterns is automatically derived, also updated as training\nprogresses, to measure the quality of generated instances. We train the model\nwith model-agnostic meta-learning to guarantee the accuracy and stability on\nexamples covered by rules, and meanwhile acquire the versatility to generalize\nwell on examples uncovered by rules. Results on three benchmark datasets with\ndifferent domains and programs show that our approach incrementally improves\nthe accuracy. On WikiSQL, our best model is comparable to the SOTA system\nlearned from denotations.", "published": "2019-09-12 02:47:47", "link": "http://arxiv.org/abs/1909.05438v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncover the Ground-Truth Relations in Distant Supervision: A Neural\n  Expectation-Maximization Framework", "abstract": "Distant supervision for relation extraction enables one to effectively\nacquire structured relations out of very large text corpora with less human\nefforts. Nevertheless, most of the prior-art models for such tasks assume that\nthe given text can be noisy, but their corresponding labels are clean. Such\nunrealistic assumption is contradictory with the fact that the given labels are\noften noisy as well, thus leading to significant performance degradation of\nthose models on real-world data. To cope with this challenge, we propose a\nnovel label-denoising framework that combines neural network with probabilistic\nmodelling, which naturally takes into account the noisy labels during learning.\nWe empirically demonstrate that our approach significantly improves the current\nart in uncovering the ground-truth relation labels.", "published": "2019-09-12 04:20:51", "link": "http://arxiv.org/abs/1909.05448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visualizing Trends of Key Roles in News Articles", "abstract": "There are tons of news articles generated every day reflecting the activities\nof key roles such as people, organizations and political parties. Analyzing\nthese key roles allows us to understand the trends in news. In this paper, we\npresent a demonstration system that visualizes the trend of key roles in news\narticles based on natural language processing techniques. Specifically, we\napply a semantic role labeler and the dynamic word embedding technique to\nunderstand relationships between key roles in the news across different time\nperiods and visualize the trends of key role and news topics change over time.", "published": "2019-09-12 04:21:41", "link": "http://arxiv.org/abs/1909.05449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI System for the Building Educational Applications 2019 Shared Task:\n  Grammatical Error Correction", "abstract": "In this paper, we describe our systems submitted to the Building Educational\nApplications (BEA) 2019 Shared Task (Bryant et al., 2019). We participated in\nall three tracks. Our models are NMT systems based on the Transformer model,\nwhich we improve by incorporating several enhancements: applying dropout to\nwhole source and target words, weighting target subwords, averaging model\ncheckpoints, and using the trained model iteratively for correcting the\nintermediate translations. The system in the Restricted Track is trained on the\nprovided corpora with oversampled \"cleaner\" sentences and reaches 59.39 F0.5\nscore on the test set. The system in the Low-Resource Track is trained from\nWikipedia revision histories and reaches 44.13 F0.5 score. Finally, we finetune\nthe system from the Low-Resource Track on restricted data and achieve 64.55\nF0.5 score, placing third in the Unrestricted Track.", "published": "2019-09-12 10:31:25", "link": "http://arxiv.org/abs/1909.05553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Evaluation: Misleading Benchmarks for Bilingual Dictionary\n  Induction", "abstract": "The task of bilingual dictionary induction (BDI) is commonly used for\nintrinsic evaluation of cross-lingual word embeddings. The largest dataset for\nBDI was generated automatically, so its quality is dubious. We study the\ncomposition and quality of the test sets for five diverse languages from this\ndataset, with concerning findings: (1) a quarter of the data consists of proper\nnouns, which can be hardly indicative of BDI performance, and (2) there are\npervasive gaps in the gold-standard targets. These issues appear to affect the\nranking between cross-lingual embedding systems on individual languages, and\nthe overall degree to which the systems differ in performance. With proper\nnouns removed from the data, the margin between the top two systems included in\nthe study grows from 3.4% to 17.2%. Manual verification of the predictions, on\nthe other hand, reveals that gaps in the gold standard targets artificially\ninflate the margin between the two systems on English to Bulgarian BDI from\n0.1% to 6.7%. We thus suggest that future research either avoids drawing\nconclusions from quantitative results on this BDI dataset, or accompanies such\nevaluation with rigorous error analysis.", "published": "2019-09-12 14:21:54", "link": "http://arxiv.org/abs/1909.05708v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Scalable Multi-domain Conversational Agents: The Schema-Guided\n  Dialogue Dataset", "abstract": "Virtual assistants such as Google Assistant, Alexa and Siri provide a\nconversational interface to a large number of services and APIs spanning\nmultiple domains. Such systems need to support an ever-increasing number of\nservices with possibly overlapping functionality. Furthermore, some of these\nservices have little to no training data available. Existing public datasets\nfor task-oriented dialogue do not sufficiently capture these challenges since\nthey cover few domains and assume a single static ontology per domain. In this\nwork, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing\nover 16k multi-domain conversations spanning 16 domains. Our dataset exceeds\nthe existing task-oriented dialogue corpora in scale, while also highlighting\nthe challenges associated with building large-scale virtual assistants. It\nprovides a challenging testbed for a number of tasks including language\nunderstanding, slot filling, dialogue state tracking and response generation.\nAlong the same lines, we present a schema-guided paradigm for task-oriented\ndialogue, in which predictions are made over a dynamic set of intents and\nslots, provided as input, using their natural language descriptions. This\nallows a single dialogue system to easily support a large number of services\nand facilitates simple integration of new services without requiring additional\ntraining data. Building upon the proposed paradigm, we release a model for\ndialogue state tracking capable of zero-shot generalization to new APIs, while\nremaining competitive in the regular setting.", "published": "2019-09-12 17:57:57", "link": "http://arxiv.org/abs/1909.05855v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MOSS: End-to-End Dialog System Framework with Modular Supervision", "abstract": "A major bottleneck in training end-to-end task-oriented dialog system is the\nlack of data. To utilize limited training data more efficiently, we propose\nModular Supervision Network (MOSS), an encoder-decoder training framework that\ncould incorporate supervision from various intermediate dialog system modules\nincluding natural language understanding, dialog state tracking, dialog policy\nlearning, and natural language generation. With only 60% of the training data,\nMOSS-all (i.e., MOSS with supervision from all four dialog modules) outperforms\nstate-of-the-art models on CamRest676. Moreover, introducing modular\nsupervision has even bigger benefits when the dialog task has a more complex\ndialog state and action space. With only 40% of the training data, MOSS-all\noutperforms the state-of-the-art model on a complex laptop network\ntroubleshooting dataset, LaptopNetwork, that we introduced. LaptopNetwork\nconsists of conversations between real customers and customer service agents in\nChinese. Moreover, MOSS framework can accommodate dialogs that have supervision\nfrom different dialog modules at both the framework level and model level.\nTherefore, MOSS is extremely flexible to update in a real-world deployment.", "published": "2019-09-12 09:27:37", "link": "http://arxiv.org/abs/1909.05528v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ABSApp: A Portable Weakly-Supervised Aspect-Based Sentiment Extraction\n  System", "abstract": "We present ABSApp, a portable system for weakly-supervised aspect-based\nsentiment extraction. The system is interpretable and user friendly and does\nnot require labeled training data, hence can be rapidly and cost-effectively\nused across different domains in applied setups. The system flow includes three\nstages: First, it generates domain-specific aspect and opinion lexicons based\non an unlabeled dataset; second, it enables the user to view and edit those\nlexicons (weak supervision); and finally, it enables the user to select an\nunlabeled target dataset from the same domain, classify it, and generate an\naspect-based sentiment report. ABSApp has been successfully used in a number of\nreal-life use cases, among them movie review analysis and convention impact\nanalysis.", "published": "2019-09-12 12:50:34", "link": "http://arxiv.org/abs/1909.05608v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UER: An Open-Source Toolkit for Pre-training Models", "abstract": "Existing works, including ELMO and BERT, have revealed the importance of\npre-training for NLP tasks. While there does not exist a single pre-training\nmodel that works best in all cases, it is of necessity to develop a framework\nthat is able to deploy various pre-training models efficiently. For this\npurpose, we propose an assemble-on-demand pre-training toolkit, namely\nUniversal Encoder Representations (UER). UER is loosely coupled, and\nencapsulated with rich modules. By assembling modules on demand, users can\neither reproduce a state-of-the-art pre-training model or develop a\npre-training model that remains unexplored. With UER, we have built a model\nzoo, which contains pre-trained models based on different corpora, encoders,\nand targets (objectives). With proper pre-trained models, we could achieve new\nstate-of-the-art results on a range of downstream datasets.", "published": "2019-09-12 13:46:58", "link": "http://arxiv.org/abs/1909.05658v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InstructableCrowd: Creating IF-THEN Rules for Smartphones via\n  Conversations with the Crowd", "abstract": "Natural language interfaces have become a common part of modern digital life.\nChatbots utilize text-based conversations to communicate with users; personal\nassistants on smartphones such as Google Assistant take direct speech commands\nfrom their users; and speech-controlled devices such as Amazon Echo use voice\nas their only input mode. In this paper, we introduce InstructableCrowd, a\ncrowd-powered system that allows users to program their devices via\nconversation. The user verbally expresses a problem to the system, in which a\ngroup of crowd workers collectively respond and program relevant multi-part\nIF-THEN rules to help the user. The IF-THEN rules generated by\nInstructableCrowd connect relevant sensor combinations (e.g., location,\nweather, device acceleration, etc.) to useful effectors (e.g., text messages,\ndevice alarms, etc.). Our study showed that non-programmers can use the\nconversational interface of InstructableCrowd to create IF-THEN rules that have\nsimilar quality compared with the rules created manually. InstructableCrowd\ngenerally illustrates how users may converse with their devices, not only to\ntrigger simple voice commands, but also to personalize their increasingly\npowerful and complicated devices.", "published": "2019-09-12 14:43:38", "link": "http://arxiv.org/abs/1909.05725v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT", "abstract": "Transformer based architectures have become de-facto models used for a range\nof Natural Language Processing tasks. In particular, the BERT based models\nachieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However,\nBERT based models have a prohibitive memory footprint and latency. As a result,\ndeploying BERT based models in resource constrained environments has become a\nchallenging task. In this work, we perform an extensive analysis of fine-tuned\nBERT models using second order Hessian information, and we use our results to\npropose a novel method for quantizing BERT models to ultra low precision. In\nparticular, we propose a new group-wise quantization scheme, and we use a\nHessian based mix-precision method to compress the model further. We\nextensively test our proposed method on BERT downstream tasks of SST-2, MNLI,\nCoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at\nmost $2.3\\%$ performance degradation, even with ultra-low precision\nquantization down to 2 bits, corresponding up to $13\\times$ compression of the\nmodel parameters, and up to $4\\times$ compression of the embedding table as\nwell as activations. Among all tasks, we observed the highest performance loss\nfor BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as\nwell as visualization, we show that this is related to the fact that current\ntraining/fine-tuning strategy of BERT does not converge for SQuAD.", "published": "2019-09-12 17:45:59", "link": "http://arxiv.org/abs/1909.05840v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Style-aware Neural Model with Application in Authorship Attribution", "abstract": "Writing style is a combination of consistent decisions associated with a\nspecific author at different levels of language production, including lexical,\nsyntactic, and structural. In this paper, we introduce a style-aware neural\nmodel to encode document information from three stylistic levels and evaluate\nit in the domain of authorship attribution. First, we propose a simple way to\njointly encode syntactic and lexical representations of sentences.\nSubsequently, we employ an attention-based hierarchical neural network to\nencode the syntactic and semantic structure of sentences in documents while\nrewarding the sentences which contribute more to capturing the writing style.\nOur experimental results, based on four benchmark datasets, reveal the benefits\nof encoding document information from all three stylistic levels when compared\nto the baseline methods in the literature.", "published": "2019-09-12 16:25:05", "link": "http://arxiv.org/abs/1909.06194v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrofitting Contextualized Word Embeddings with Paraphrases", "abstract": "Contextualized word embedding models, such as ELMo, generate meaningful\nrepresentations of words and their context. These models have been shown to\nhave a great impact on downstream applications. However, in many cases, the\ncontextualized embedding of a word changes drastically when the context is\nparaphrased. As a result, the downstream model is not robust to paraphrasing\nand other linguistic variations. To enhance the stability of contextualized\nword embedding models, we propose an approach to retrofitting contextualized\nembedding models with paraphrase contexts. Our method learns an orthogonal\ntransformation on the input space, which seeks to minimize the variance of word\nrepresentations on paraphrased contexts. Experiments show that the retrofitted\nmodel significantly outperforms the original ELMo on various sentence\nclassification and language inference tasks.", "published": "2019-09-12 22:35:53", "link": "http://arxiv.org/abs/1909.09700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Robust Hybrid Approach for Textual Document Classification", "abstract": "Text document classification is an important task for diverse natural\nlanguage processing based applications. Traditional machine learning approaches\nmainly focused on reducing dimensionality of textual data to perform\nclassification. This although improved the overall classification accuracy, the\nclassifiers still faced sparsity problem due to lack of better data\nrepresentation techniques. Deep learning based text document classification, on\nthe other hand, benefitted greatly from the invention of word embeddings that\nhave solved the sparsity problem and researchers focus mainly remained on the\ndevelopment of deep architectures. Deeper architectures, however, learn some\nredundant features that limit the performance of deep learning based solutions.\nIn this paper, we propose a two stage text document classification methodology\nwhich combines traditional feature engineering with automatic feature\nengineering (using deep learning). The proposed methodology comprises a filter\nbased feature selection (FSE) algorithm followed by a deep convolutional neural\nnetwork. This methodology is evaluated on the two most commonly used public\ndatasets, i.e., 20 Newsgroups data and BBC news data. Evaluation results reveal\nthat the proposed methodology outperforms the state-of-the-art of both the\n(traditional) machine learning and deep learning based text document\nclassification methodologies with a significant margin of 7.7% on 20 Newsgroups\nand 6.6% on BBC news datasets.", "published": "2019-09-12 06:39:07", "link": "http://arxiv.org/abs/1909.05478v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Classifying Multilingual User Feedback using Traditional Machine\n  Learning and Deep Learning", "abstract": "With the rise of social media like Twitter and of software distribution\nplatforms like app stores, users got various ways to express their opinion\nabout software products. Popular software vendors get user feedback\nthousandfold per day. Research has shown that such feedback contains valuable\ninformation for software development teams such as problem reports or feature\nand support inquires. Since the manual analysis of user feedback is cumbersome\nand hard to manage many researchers and tool vendors suggested to use automated\nanalyses based on traditional supervised machine learning approaches. In this\nwork, we compare the results of traditional machine learning and deep learning\nin classifying user feedback in English and Italian into problem reports,\ninquiries, and irrelevant. Our results show that using traditional machine\nlearning, we can still achieve comparable results to deep learning, although we\ncollected thousands of labels.", "published": "2019-09-12 08:35:54", "link": "http://arxiv.org/abs/1909.05504v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Entity Typing for Domain Independent Entity Linking", "abstract": "Neural entity linking models are very powerful, but run the risk of\noverfitting to the domain they are trained in. For this problem, a domain is\ncharacterized not just by genre of text but even by factors as specific as the\nparticular distribution of entities, as neural models tend to overfit by\nmemorizing properties of frequent entities in a dataset. We tackle the problem\nof building robust entity linking models that generalize effectively and do not\nrely on labeled entity linking data with a specific entity distribution. Rather\nthan predicting entities directly, our approach models fine-grained entity\nproperties, which can help disambiguate between even closely related entities.\nWe derive a large inventory of types (tens of thousands) from Wikipedia\ncategories, and use hyperlinked mentions in Wikipedia to distantly label data\nand train an entity typing model. At test time, we classify a mention with this\ntyping model and use soft type predictions to link the mention to the most\nsimilar candidate entity. We evaluate our entity linking system on the\nCoNLL-YAGO dataset (Hoffart et al., 2011) and show that our approach\noutperforms prior domain-independent entity linking systems. We also test our\napproach in a harder setting derived from the WikilinksNED dataset (Eshel et\nal., 2017) where all the mention-entity pairs are unseen during test time.\nResults indicate that our approach generalizes better than a state-of-the-art\nneural model on the dataset.", "published": "2019-09-12 16:29:24", "link": "http://arxiv.org/abs/1909.05780v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning", "abstract": "Multi-hop QA requires a model to connect multiple pieces of evidence\nscattered in a long context to answer the question. The recently proposed\nHotpotQA (Yang et al., 2018) dataset is comprised of questions embodying four\ndifferent multi-hop reasoning paradigms (two bridge entity setups, checking\nmultiple properties, and comparing two entities), making it challenging for a\nsingle neural network to handle all four. In this work, we present an\ninterpretable, controller-based Self-Assembling Neural Modular Network (Hu et\nal., 2017, 2018) for multi-hop reasoning, where we design four novel modules\n(Find, Relocate, Compare, NoOp) to perform unique types of language reasoning.\nBased on a question, our layout controller RNN dynamically infers a series of\nreasoning modules to construct the entire network. Empirically, we show that\nour dynamic, multi-hop modular network achieves significant improvements over\nthe static, single-hop baseline (on both regular and adversarial evaluation).\nWe further demonstrate the interpretability of our model via three analyses.\nFirst, the controller can softly decompose the multi-hop question into multiple\nsingle-hop sub-questions to promote compositional reasoning behavior of the\nmain network. Second, the controller can predict layouts that conform to the\nlayouts designed by human experts. Finally, the intermediate module can infer\nthe entity that connects two distantly-located supporting facts by addressing\nthe sub-question from the controller.", "published": "2019-09-12 17:00:45", "link": "http://arxiv.org/abs/1909.05803v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Query Obfuscation Semantic Decomposition", "abstract": "We propose a method to protect the privacy of search engine users by\ndecomposing the queries using semantically \\emph{related} and unrelated\n\\emph{distractor} terms. Instead of a single query, the search engine receives\nmultiple decomposed query terms. Next, we reconstruct the search results\nrelevant to the original query term by aggregating the search results retrieved\nfor the decomposed query terms. We show that the word embeddings learnt using a\ndistributed representation learning method can be used to find semantically\nrelated and distractor query terms. We derive the relationship between the\n\\emph{obfuscity} achieved through the proposed query anonymisation method and\nthe \\emph{reconstructability} of the original search results using the\ndecomposed queries. We analytically study the risk of discovering the search\nengine users' information intents under the proposed query obfuscation method,\nand empirically evaluate its robustness against clustering-based attacks. Our\nexperimental results show that the proposed method can accurately reconstruct\nthe search results for user queries, without compromising the privacy of the\nsearch engine users.", "published": "2019-09-12 17:27:46", "link": "http://arxiv.org/abs/1909.05819v2", "categories": ["cs.CL", "cs.CR", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Finding Generalizable Evidence by Learning to Convince Q&A Models", "abstract": "We propose a system that finds the strongest supporting evidence for a given\nanswer to a question, using passage-based question-answering (QA) as a testbed.\nWe train evidence agents to select the passage sentences that most convince a\npretrained QA model of a given answer, if the QA model received those sentences\ninstead of the full passage. Rather than finding evidence that convinces one\nmodel alone, we find that agents select evidence that generalizes; agent-chosen\nevidence increases the plausibility of the supported answer, as judged by other\nQA models and humans. Given its general nature, this approach improves QA in a\nrobust manner: using agent-selected evidence (i) humans can correctly answer\nquestions with only ~20% of the full passage and (ii) QA models can generalize\nto longer passages and harder questions.", "published": "2019-09-12 18:00:00", "link": "http://arxiv.org/abs/1909.05863v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.MA"], "primary_category": "cs.CL"}
{"title": "The emotions that we perceive in music: the influence of language and\n  lyrics comprehension on agreement", "abstract": "In the present study, we address the relationship between the emotions\nperceived in pop and rock music (mainly in Euro-American styles with English\nlyrics) and the language spoken by the listener. Our goal is to understand the\ninfluence of lyrics comprehension on the perception of emotions and use this\ninformation to improve Music Emotion Recognition (MER) models. Two main\nresearch questions are addressed: 1. Are there differences and similarities\nbetween the emotions perceived in pop/rock music by listeners raised with\ndifferent mother tongues? 2. Do personal characteristics have an influence on\nthe perceived emotions for listeners of a given language? Personal\ncharacteristics include the listeners' general demographics, familiarity and\npreference for the fragments, and music sophistication. Our hypothesis is that\ninter-rater agreement (as defined by Krippendorff's alpha coefficient) from\nsubjects is directly influenced by the comprehension of lyrics.", "published": "2019-09-12 18:02:03", "link": "http://arxiv.org/abs/1909.05882v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analyzing machine-learned representations: A natural language case study", "abstract": "As modern deep networks become more complex, and get closer to human-like\ncapabilities in certain domains, the question arises of how the representations\nand decision rules they learn compare to the ones in humans. In this work, we\nstudy representations of sentences in one such artificial system for natural\nlanguage processing. We first present a diagnostic test dataset to examine the\ndegree of abstract composable structure represented. Analyzing performance on\nthese diagnostic tests indicates a lack of systematicity in the representations\nand decision rules, and reveals a set of heuristic strategies. We then\ninvestigate the effect of the training distribution on learning these heuristic\nstrategies, and study changes in these representations with various\naugmentations to the training set. Our results reveal parallels to the\nanalogous representations in people. We find that these systems can learn\nabstract rules and generalize them to new contexts under certain circumstances\n-- similar to human zero-shot reasoning. However, we also note some\nshortcomings in this generalization behavior -- similar to human judgment\nerrors like belief bias. Studying these parallels suggests new ways to\nunderstand psychological phenomena in humans as well as informs best strategies\nfor building artificial intelligence with human-like language understanding.", "published": "2019-09-12 18:03:17", "link": "http://arxiv.org/abs/1909.05885v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Determining the Scale of Impact from Denial-of-Service Attacks in Real\n  Time Using Twitter", "abstract": "Denial of Service (DoS) attacks are common in on-line and mobile services\nsuch as Twitter, Facebook and banking. As the scale and frequency of\nDistributed Denial of Service (DDoS) attacks increase, there is an urgent need\nfor determining the impact of the attack. Two central challenges of the task\nare to get feedback from a large number of users and to get it in a timely\nmanner. In this paper, we present a weakly-supervised model that does not need\nannotated data to measure the impact of DoS issues by applying Latent Dirichlet\nAllocation and symmetric Kullback-Leibler divergence on tweets. There is a\nlimitation to the weakly-supervised module. It assumes that the event detected\nin a time window is a DoS attack event. This will become less of a problem,\nwhen more non-attack events twitter got collected and become less likely to be\nidentified as a new event. Another way to remove that limitation, an optional\nclassification layer, trained on manually annotated DoS attack tweets, to\nfilter out non-attack tweets can be used to increase precision at the expense\nof recall. Experimental results show that we can learn weakly-supervised models\nthat can achieve comparable precision to supervised ones and can be generalized\nacross entities in the same industry.", "published": "2019-09-12 18:11:56", "link": "http://arxiv.org/abs/1909.05890v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "End-to-End Neural Speaker Diarization with Permutation-Free Objectives", "abstract": "In this paper, we propose a novel end-to-end neural-network-based speaker\ndiarization method. Unlike most existing methods, our proposed method does not\nhave separate modules for extraction and clustering of speaker representations.\nInstead, our model has a single neural network that directly outputs speaker\ndiarization results. To realize such a model, we formulate the speaker\ndiarization problem as a multi-label classification problem, and introduces a\npermutation-free objective function to directly minimize diarization errors\nwithout being suffered from the speaker-label permutation problem. Besides its\nend-to-end simplicity, the proposed method also benefits from being able to\nexplicitly handle overlapping speech during training and inference. Because of\nthe benefit, our model can be easily trained/adapted with real-recorded\nmulti-speaker conversations just by feeding the corresponding multi-speaker\nsegment labels. We evaluated the proposed method on simulated speech mixtures.\nThe proposed method achieved diarization error rate of 12.28%, while a\nconventional clustering-based system produced diarization error rate of 28.77%.\nFurthermore, the domain adaptation with real-recorded speech provided 25.6%\nrelative improvement on the CALLHOME dataset. Our source code is available\nonline at https://github.com/hitachi-speech/EEND.", "published": "2019-09-12 21:12:10", "link": "http://arxiv.org/abs/1909.05952v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent\n  Neural Networks", "abstract": "Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the\nmost powerful dynamic classifiers publicly known. The network itself and the\nrelated learning algorithms are reasonably well documented to get an idea how\nit works. This paper will shed more light into understanding how LSTM-RNNs\nevolved and why they work impressively well, focusing on the early,\nground-breaking publications. We significantly improved documentation and fixed\na number of errors and inconsistencies that accumulated in previous\npublications. To support understanding we as well revised and unified the\nnotation used.", "published": "2019-09-12 15:44:51", "link": "http://arxiv.org/abs/1909.09586v1", "categories": ["cs.NE", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
{"title": "A Deep Learning-Based Approach for Measuring the Domain Similarity of\n  Persian Texts", "abstract": "In this paper, we propose a novel approach for measuring the degree of\nsimilarity between categories of two pieces of Persian text, which were\npublished as descriptions of two separate advertisements. We built an\nappropriate dataset for this work using a dataset which consists of\nadvertisements posted on an e-commerce website. We generated a significant\nnumber of paired texts from this dataset and assigned each pair a score from 0\nto 3, which demonstrates the degree of similarity between the domains of the\npair. In this work, we represent words with word embedding vectors derived from\nword2vec. Then deep neural network models are used to represent texts.\nEventually, we employ concatenation of absolute difference and bit-wise\nmultiplication and a fully-connected neural network to produce a probability\ndistribution vector for the score of the pairs. Through a supervised learning\napproach, we trained our model on a GPU, and our best model achieved an F1\nscore of 0.9865.", "published": "2019-09-12 16:29:14", "link": "http://arxiv.org/abs/1909.09690v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "NSURL-2019 Shared Task 8: Semantic Question Similarity in Arabic", "abstract": "Question semantic similarity (Q2Q) is a challenging task that is very useful\nin many NLP applications, such as detecting duplicate questions and question\nanswering systems. In this paper, we present the results and findings of the\nshared task (Semantic Question Similarity in Arabic). The task was organized as\npart of the first workshop on NLP Solutions for Under Resourced Languages\n(NSURL 2019) The goal of the task is to predict whether two questions are\nsemantically similar or not, even if they are phrased differently. A total of 9\nteams participated in the task. The datasets created for this task are made\npublicly available to support further research on Arabic Q2Q.", "published": "2019-09-12 14:45:43", "link": "http://arxiv.org/abs/1909.09691v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Using Clinical Notes with Time Series Data for ICU Management", "abstract": "Monitoring patients in ICU is a challenging and high-cost task. Hence,\npredicting the condition of patients during their ICU stay can help provide\nbetter acute care and plan the hospital's resources. There has been continuous\nprogress in machine learning research for ICU management, and most of this work\nhas focused on using time series signals recorded by ICU instruments. In our\nwork, we show that adding clinical notes as another modality improves the\nperformance of the model for three benchmark tasks: in-hospital mortality\nprediction, modeling decompensation, and length of stay forecasting that play\nan important role in ICU management. While the time-series data is measured at\nregular intervals, doctor notes are charted at irregular times, making it\nchallenging to model them together. We propose a method to model them jointly,\nachieving considerable improvement across benchmark tasks over baseline\ntime-series model. Our implementation can be found at\n\\url{https://github.com/kaggarwal/ClinicalNotesICU}.", "published": "2019-09-12 04:27:32", "link": "http://arxiv.org/abs/1909.09702v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Measuring Domain Portability and ErrorPropagation in Biomedical QA", "abstract": "In this work we present Google's submission to the BioASQ 7 biomedical\nquestion answering (QA) task (specifically Task 7b, Phase B). The core of our\nsystems are based on BERT QA models, specifically the model of\n\\cite{alberti2019bert}. In this report, and via our submissions, we aimed to\ninvestigate two research questions. We start by studying how domain portable\nare QA systems that have been pre-trained and fine-tuned on general texts,\ne.g., Wikipedia. We measure this via two submissions. The first is a\nnon-adapted model that uses a public pre-trained BERT model and is fine-tuned\non the Natural Questions data set \\cite{kwiatkowski2019natural}. The second\nsystem takes this non-adapted model and fine-tunes it with the BioASQ training\ndata. Next, we study the impact of error propagation in end-to-end retrieval\nand QA systems. Again we test this via two submissions. The first uses human\nannotated relevant documents and snippets as input to the model and the second\npredicted documents and snippets. Our main findings are that domain specific\nfine-tuning can benefit Biomedical QA. However, the biggest quality bottleneck\nis at the retrieval stage, where we see large drops in metrics -- over 10pts\nabsolute -- when using non gold inputs to the QA model.", "published": "2019-09-12 17:25:24", "link": "http://arxiv.org/abs/1909.09704v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sams-Net: A Sliced Attention-based Neural Network for Music Source\n  Separation", "abstract": "Convolutional Neural Network (CNN) or Long short-term memory (LSTM) based\nmodels with the input of spectrogram or waveforms are commonly used for deep\nlearning based audio source separation. In this paper, we propose a Sliced\nAttention-based neural network (Sams-Net) in the spectrogram domain for the\nmusic source separation task. It enables spectral feature interactions with\nmulti-head attention mechanism, achieves easier parallel computing and has a\nlarger receptive field compared with LSTMs and CNNs respectively. Experimental\nresults on the MUSDB18 dataset show that the proposed method, with fewer\nparameters, outperforms most of the state-of-the-art DNN-based methods.", "published": "2019-09-12 15:21:36", "link": "http://arxiv.org/abs/1909.05746v4", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
