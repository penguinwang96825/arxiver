{"title": "Examining the rhetorical capacities of neural language models", "abstract": "Recently, neural language models (LMs) have demonstrated impressive abilities\nin generating high-quality discourse. While many recent papers have analyzed\nthe syntactic aspects encoded in LMs, there has been no analysis to date of the\ninter-sentential, rhetorical knowledge. In this paper, we propose a method that\nquantitatively evaluates the rhetorical capacities of neural LMs. We examine\nthe capacities of neural LMs understanding the rhetoric of discourse by\nevaluating their abilities to encode a set of linguistic features derived from\nRhetorical Structure Theory (RST). Our experiments show that BERT-based LMs\noutperform other Transformer LMs, revealing the richer discourse knowledge in\ntheir intermediate layer representations. In addition, GPT-2 and XLNet\napparently encode less rhetorical knowledge, and we suggest an explanation\ndrawing from linguistic philosophy. Our method shows an avenue towards\nquantifying the rhetorical capacities of neural LMs.", "published": "2020-10-01 00:18:43", "link": "http://arxiv.org/abs/2010.00153v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Compare Aggregate Transformer for Understanding Document-grounded\n  Dialogue", "abstract": "Unstructured documents serving as external knowledge of the dialogues help to\ngenerate more informative responses. Previous research focused on knowledge\nselection (KS) in the document with dialogue. However, dialogue history that is\nnot related to the current dialogue may introduce noise in the KS processing.\nIn this paper, we propose a Compare Aggregate Transformer (CAT) to jointly\ndenoise the dialogue context and aggregate the document information for\nresponse generation. We designed two different comparison mechanisms to reduce\nnoise (before and during decoding). In addition, we propose two metrics for\nevaluating document utilization efficiency based on word overlap. Experimental\nresults on the CMUDoG dataset show that the proposed CAT model outperforms the\nstate-of-the-art approach and strong baselines.", "published": "2020-10-01 03:44:44", "link": "http://arxiv.org/abs/2010.00190v1", "categories": ["cs.CL", "68T07 68T50"], "primary_category": "cs.CL"}
{"title": "Improving Vietnamese Named Entity Recognition from Speech Using Word\n  Capitalization and Punctuation Recovery Models", "abstract": "Studies on the Named Entity Recognition (NER) task have shown outstanding\nresults that reach human parity on input texts with correct text formattings,\nsuch as with proper punctuation and capitalization. However, such conditions\nare not available in applications where the input is speech, because the text\nis generated from a speech recognition system (ASR), and that the system does\nnot consider the text formatting. In this paper, we (1) presented the first\nVietnamese speech dataset for NER task, and (2) the first pre-trained public\nlarge-scale monolingual language model for Vietnamese that achieved the new\nstate-of-the-art for the Vietnamese NER task by 1.3% absolute F1 score\ncomparing to the latest study. And finally, (3) we proposed a new pipeline for\nNER task from speech that overcomes the text formatting problem by introducing\na text capitalization and punctuation recovery model (CaPu) into the pipeline.\nThe model takes input text from an ASR system and performs two tasks at the\nsame time, producing proper text formatting that helps to improve NER\nperformance. Experimental results indicated that the CaPu model helps to\nimprove by nearly 4% of F1-score.", "published": "2020-10-01 05:21:32", "link": "http://arxiv.org/abs/2010.00198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Persian Word Segmentation Correction and Zero-Width Non-Joiner\n  Recognition Using BERT", "abstract": "Words are properly segmented in the Persian writing system; in practice,\nhowever, these writing rules are often neglected, resulting in single words\nbeing written disjointedly and multiple words written without any white spaces\nbetween them. This paper addresses the problems of word segmentation and\nzero-width non-joiner (ZWNJ) recognition in Persian, which we approach jointly\nas a sequence labeling problem. We achieved a macro-averaged F1-score of 92.40%\non a carefully collected corpus of 500 sentences with a high level of\ndifficulty.", "published": "2020-10-01 10:32:17", "link": "http://arxiv.org/abs/2010.00287v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phonemer at WNUT-2020 Task 2: Sequence Classification Using COVID\n  Twitter BERT and Bagging Ensemble Technique based on Plurality Voting", "abstract": "This paper presents the approach that we employed to tackle the EMNLP\nWNUT-2020 Shared Task 2 : Identification of informative COVID-19 English\nTweets. The task is to develop a system that automatically identifies whether\nan English Tweet related to the novel coronavirus (COVID-19) is informative or\nnot. We solve the task in three stages. The first stage involves pre-processing\nthe dataset by filtering only relevant information. This is followed by\nexperimenting with multiple deep learning models like CNNs, RNNs and\nTransformer based models. In the last stage, we propose an ensemble of the best\nmodel trained on different subsets of the provided dataset. Our final approach\nachieved an F1-score of 0.9037 and we were ranked sixth overall with F1-score\nas the evaluation criteria.", "published": "2020-10-01 10:54:54", "link": "http://arxiv.org/abs/2010.00294v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Did you really mean what you said?\" : Sarcasm Detection in\n  Hindi-English Code-Mixed Data using Bilingual Word Embeddings", "abstract": "With the increased use of social media platforms by people across the world,\nmany new interesting NLP problems have come into existence. One such being the\ndetection of sarcasm in the social media texts. We present a corpus of tweets\nfor training custom word embeddings and a Hinglish dataset labelled for sarcasm\ndetection. We propose a deep learning based approach to address the issue of\nsarcasm detection in Hindi-English code mixed tweets using bilingual word\nembeddings derived from FastText and Word2Vec approaches. We experimented with\nvarious deep learning models, including CNNs, LSTMs, Bi-directional LSTMs (with\nand without attention). We were able to outperform all state-of-the-art\nperformances with our deep learning models, with attention based Bi-directional\nLSTMs giving the best performance exhibiting an accuracy of 78.49%.", "published": "2020-10-01 11:41:44", "link": "http://arxiv.org/abs/2010.00310v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How LSTM Encodes Syntax: Exploring Context Vectors and Semi-Quantization\n  on Natural Text", "abstract": "Long Short-Term Memory recurrent neural network (LSTM) is widely used and\nknown to capture informative long-term syntactic dependencies. However, how\nsuch information are reflected in its internal vectors for natural text has not\nyet been sufficiently investigated. We analyze them by learning a language\nmodel where syntactic structures are implicitly given. We empirically show that\nthe context update vectors, i.e. outputs of internal gates, are approximately\nquantized to binary or ternary values to help the language model to count the\ndepth of nesting accurately, as Suzgun et al. (2019) recently show for\nsynthetic Dyck languages. For some dimensions in the context vector, we show\nthat their activations are highly correlated with the depth of phrase\nstructures, such as VP and NP. Moreover, with an $L_1$ regularization, we also\nfound that it can accurately predict whether a word is inside a phrase\nstructure or not from a small number of components of the context vector. Even\nfor the case of learning from raw text, context vectors are shown to still\ncorrelate well with the phrase structures. Finally, we show that natural\nclusters of the functional words and the part of speeches that trigger phrases\nare represented in a small but principal subspace of the context-update vector\nof LSTM.", "published": "2020-10-01 12:49:01", "link": "http://arxiv.org/abs/2010.00363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Citation Sentiment Changes Analysis", "abstract": "Metrics for measuring the citation sentiment changes were introduced.\nCitation sentiment changes can be observed from global citation sentiment\nsequences (GCSSs). With respect to a cited paper, the citation sentiment\nsequences were analysed across a collection of citing papers ordered by the\npublished time. For analysing GCSSs, Eddy Dissipation Rate (EDR) was adopted,\nwith the hypothesis that the GCSSs pattern differences can be spotted by EDR\nbased method. Preliminary evidence showed that EDR based method holds the\npotential for analysing a publication's impact in a time series fashion.", "published": "2020-10-01 13:10:03", "link": "http://arxiv.org/abs/2010.00372v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Multilingual BERT for Estonian", "abstract": "Recently, large pre-trained language models, such as BERT, have reached\nstate-of-the-art performance in many natural language processing tasks, but for\nmany languages, including Estonian, BERT models are not yet available. However,\nthere exist several multilingual BERT models that can handle multiple languages\nsimultaneously and that have been trained also on Estonian data. In this paper,\nwe evaluate four multilingual models -- multilingual BERT, multilingual\ndistilled BERT, XLM and XLM-RoBERTa -- on several NLP tasks including POS and\nmorphological tagging, NER and text classification. Our aim is to establish a\ncomparison between these multilingual BERT models and the existing baseline\nneural models for these tasks. Our results show that multilingual BERT models\ncan generalise well on different Estonian NLP tasks outperforming all baselines\nmodels for POS and morphological tagging and text classification, and reaching\nthe comparable level with the best baseline for NER, with XLM-RoBERTa achieving\nthe highest results compared with other multilingual models.", "published": "2020-10-01 14:48:31", "link": "http://arxiv.org/abs/2010.00454v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Question-Answering as an Automatic Metric for Evaluating the\n  Content Quality of a Summary", "abstract": "A desirable property of a reference-based evaluation metric that measures the\ncontent quality of a summary is that it should estimate how much information\nthat summary has in common with a reference. Traditional text overlap based\nmetrics such as ROUGE fail to achieve this because they are limited to matching\ntokens, either lexically or via embeddings. In this work, we propose a metric\nto evaluate the content quality of a summary using question-answering (QA).\nQA-based methods directly measure a summary's information overlap with a\nreference, making them fundamentally different than text overlap metrics. We\ndemonstrate the experimental benefits of QA-based metrics through an analysis\nof our proposed metric, QAEval. QAEval out-performs current state-of-the-art\nmetrics on most evaluations using benchmark datasets, while being competitive\non others due to limitations of state-of-the-art models. Through a careful\nanalysis of each component of QAEval, we identify its performance bottlenecks\nand estimate that its potential upper-bound performance surpasses all other\nautomatic metrics, approaching that of the gold-standard Pyramid Method.", "published": "2020-10-01 15:33:09", "link": "http://arxiv.org/abs/2010.00490v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LiveQA: A Question Answering Dataset over Sports Live", "abstract": "In this paper, we introduce LiveQA, a new question answering dataset\nconstructed from play-by-play live broadcast. It contains 117k multiple-choice\nquestions written by human commentators for over 1,670 NBA games, which are\ncollected from the Chinese Hupu (https://nba.hupu.com/games) website. Derived\nfrom the characteristics of sports games, LiveQA can potentially test the\nreasoning ability across timeline-based live broadcasts, which is challenging\ncompared to the existing datasets. In LiveQA, the questions require\nunderstanding the timeline, tracking events or doing mathematical computations.\nOur preliminary experiments show that the dataset introduces a challenging\nproblem for question answering models, and a strong baseline model only\nachieves the accuracy of 53.1\\% and cannot beat the dominant option rule. We\nrelease the code and data of this paper for future research.", "published": "2020-10-01 16:18:51", "link": "http://arxiv.org/abs/2010.00526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discontinuous Constituent Parsing as Sequence Labeling", "abstract": "This paper reduces discontinuous parsing to sequence labeling. It first shows\nthat existing reductions for constituent parsing as labeling do not support\ndiscontinuities. Second, it fills this gap and proposes to encode tree\ndiscontinuities as nearly ordered permutations of the input sequence. Third, it\nstudies whether such discontinuous representations are learnable. The\nexperiments show that despite the architectural simplicity, under the right\nrepresentation, the models are fast and accurate.", "published": "2020-10-01 18:17:58", "link": "http://arxiv.org/abs/2010.00633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nearest Neighbor Machine Translation", "abstract": "We introduce $k$-nearest-neighbor machine translation ($k$NN-MT), which\npredicts tokens with a nearest neighbor classifier over a large datastore of\ncached examples, using representations from a neural translation model for\nsimilarity search. This approach requires no additional training and scales to\ngive the decoder direct access to billions of examples at test time, resulting\nin a highly expressive model that consistently improves performance across many\nsettings. Simply adding nearest neighbor search improves a state-of-the-art\nGerman-English translation model by 1.5 BLEU. $k$NN-MT allows a single model to\nbe adapted to diverse domains by using a domain-specific datastore, improving\nresults by an average of 9.2 BLEU over zero-shot transfer, and achieving new\nstate-of-the-art results -- without training on these domains. A massively\nmultilingual model can also be specialized for particular language pairs, with\nimprovements of 3 BLEU for translating from English into German and Chinese.\nQualitatively, $k$NN-MT is easily interpretable; it combines source and target\ncontext to retrieve highly relevant examples.", "published": "2020-10-01 22:24:46", "link": "http://arxiv.org/abs/2010.00710v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Investigation Towards Efficient Multi-Domain Language Model\n  Pre-training", "abstract": "Pre-training large language models has become a standard in the natural\nlanguage processing community. Such models are pre-trained on generic data\n(e.g. BookCorpus and English Wikipedia) and often fine-tuned on tasks in the\nsame domain. However, in order to achieve state-of-the-art performance on out\nof domain tasks such as clinical named entity recognition and relation\nextraction, additional in domain pre-training is required. In practice, staged\nmulti-domain pre-training presents performance deterioration in the form of\ncatastrophic forgetting (CF) when evaluated on a generic benchmark such as\nGLUE. In this paper we conduct an empirical investigation into known methods to\nmitigate CF. We find that elastic weight consolidation provides best overall\nscores yielding only a 0.33% drop in performance across seven generic tasks\nwhile remaining competitive in bio-medical tasks. Furthermore, we explore\ngradient and latent clustering based data selection techniques to improve\ncoverage when using elastic weight consolidation and experience replay methods.", "published": "2020-10-01 09:20:18", "link": "http://arxiv.org/abs/2010.00784v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RRF102: Meeting the TREC-COVID Challenge with a 100+ Runs Ensemble", "abstract": "In this paper, we report the results of our participation in the TREC-COVID\nchallenge. To meet the challenge of building a search engine for rapidly\nevolving biomedical collection, we propose a simple yet effective weighted\nhierarchical rank fusion approach, that ensembles together 102 runs from (a)\nlexical and semantic retrieval systems, (b) pre-trained and fine-tuned BERT\nrankers, and (c) relevance feedback runs. Our ablation studies demonstrate the\ncontributions of each of these systems to the overall ensemble. The submitted\nensemble runs achieved state-of-the-art performance in rounds 4 and 5 of the\nTREC-COVID challenge.", "published": "2020-10-01 05:27:51", "link": "http://arxiv.org/abs/2010.00200v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "CoLAKE: Contextualized Language and Knowledge Embedding", "abstract": "With the emerging branch of incorporating factual knowledge into pre-trained\nlanguage models such as BERT, most existing models consider shallow, static,\nand separately pre-trained entity embeddings, which limits the performance\ngains of these models. Few works explore the potential of deep contextualized\nknowledge representation when injecting knowledge. In this paper, we propose\nthe Contextualized Language and Knowledge Embedding (CoLAKE), which jointly\nlearns contextualized representation for both language and knowledge with the\nextended MLM objective. Instead of injecting only entity embeddings, CoLAKE\nextracts the knowledge context of an entity from large-scale knowledge bases.\nTo handle the heterogeneity of knowledge context and language context, we\nintegrate them in a unified data structure, word-knowledge graph (WK graph).\nCoLAKE is pre-trained on large-scale WK graphs with the modified Transformer\nencoder. We conduct experiments on knowledge-driven tasks, knowledge probing\ntasks, and language understanding tasks. Experimental results show that CoLAKE\noutperforms previous counterparts on most of the tasks. Besides, CoLAKE\nachieves surprisingly high performance on our synthetic task called\nword-knowledge graph completion, which shows the superiority of simultaneously\ncontextualizing language and knowledge representation.", "published": "2020-10-01 11:39:32", "link": "http://arxiv.org/abs/2010.00309v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting White Supremacist Hate Speech using Domain Specific Word\n  Embedding with Deep Learning and BERT", "abstract": "White supremacists embrace a radical ideology that considers white people\nsuperior to people of other races. The critical influence of these groups is no\nlonger limited to social media; they also have a significant effect on society\nin many ways by promoting racial hatred and violence. White supremacist hate\nspeech is one of the most recently observed harmful content on social\nmedia.Traditional channels of reporting hate speech have proved inadequate due\nto the tremendous explosion of information, and therefore, it is necessary to\nfind an automatic way to detect such speech in a timely manner. This research\ninvestigates the viability of automatically detecting white supremacist hate\nspeech on Twitter by using deep learning and natural language processing\ntechniques. Through our experiments, we used two approaches, the first approach\nis by using domain-specific embeddings which are extracted from white\nsupremacist corpus in order to catch the meaning of this white supremacist\nslang with bidirectional Long Short-Term Memory (LSTM) deep learning model,\nthis approach reached a 0.74890 F1-score. The second approach is by using the\none of the most recent language model which is BERT, BERT model provides the\nstate of the art of most NLP tasks. It reached to a 0.79605 F1-score. Both\napproaches are tested on a balanced dataset given that our experiments were\nbased on textual data only. The dataset was combined from dataset created from\nTwitter and a Stormfront dataset compiled from that white supremacist forum.", "published": "2020-10-01 12:44:24", "link": "http://arxiv.org/abs/2010.00357v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Explainability in Machine Reading Comprehension", "abstract": "This paper presents a systematic review of benchmarks and approaches for\nexplainability in Machine Reading Comprehension (MRC). We present how the\nrepresentation and inference challenges evolved and the steps which were taken\nto tackle these challenges. We also present the evaluation methodologies to\nassess the performance of explainable systems. In addition, we identify\npersisting open research questions and highlight critical directions for future\nwork.", "published": "2020-10-01 13:26:58", "link": "http://arxiv.org/abs/2010.00389v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Referring Image Segmentation via Cross-Modal Progressive Comprehension", "abstract": "Referring image segmentation aims at segmenting the foreground masks of the\nentities that can well match the description given in the natural language\nexpression. Previous approaches tackle this problem using implicit feature\ninteraction and fusion between visual and linguistic modalities, but usually\nfail to explore informative words of the expression to well align features from\nthe two modalities for accurately identifying the referred entity. In this\npaper, we propose a Cross-Modal Progressive Comprehension (CMPC) module and a\nText-Guided Feature Exchange (TGFE) module to effectively address the\nchallenging task. Concretely, the CMPC module first employs entity and\nattribute words to perceive all the related entities that might be considered\nby the expression. Then, the relational words are adopted to highlight the\ncorrect entity as well as suppress other irrelevant ones by multimodal graph\nreasoning. In addition to the CMPC module, we further leverage a simple yet\neffective TGFE module to integrate the reasoned multimodal features from\ndifferent levels with the guidance of textual information. In this way,\nfeatures from multi-levels could communicate with each other and be refined\nbased on the textual context. We conduct extensive experiments on four popular\nreferring segmentation benchmarks and achieve new state-of-the-art\nperformances.", "published": "2020-10-01 16:02:30", "link": "http://arxiv.org/abs/2010.00514v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Linguistic Structure Guided Context Modeling for Referring Image\n  Segmentation", "abstract": "Referring image segmentation aims to predict the foreground mask of the\nobject referred by a natural language sentence. Multimodal context of the\nsentence is crucial to distinguish the referent from the background. Existing\nmethods either insufficiently or redundantly model the multimodal context. To\ntackle this problem, we propose a \"gather-propagate-distribute\" scheme to model\nmultimodal context by cross-modal interaction and implement this scheme as a\nnovel Linguistic Structure guided Context Modeling (LSCM) module. Our LSCM\nmodule builds a Dependency Parsing Tree suppressed Word Graph (DPT-WG) which\nguides all the words to include valid multimodal context of the sentence while\nexcluding disturbing ones through three steps over the multimodal feature,\ni.e., gathering, constrained propagation and distributing. Extensive\nexperiments on four benchmarks demonstrate that our method outperforms all the\nprevious state-of-the-arts.", "published": "2020-10-01 16:03:51", "link": "http://arxiv.org/abs/2010.00515v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Predicting User Engagement Status for Online Evaluation of Intelligent\n  Assistants", "abstract": "Evaluation of intelligent assistants in large-scale and online settings\nremains an open challenge. User behavior-based online evaluation metrics have\ndemonstrated great effectiveness for monitoring large-scale web search and\nrecommender systems. Therefore, we consider predicting user engagement status\nas the very first and critical step to online evaluation for intelligent\nassistants. In this work, we first proposed a novel framework for classifying\nuser engagement status into four categories -- fulfillment, continuation,\nreformulation and abandonment. We then demonstrated how to design simple but\nindicative metrics based on the framework to quantify user engagement levels.\nWe also aim for automating user engagement prediction with machine learning\nmethods. We compare various models and features for predicting engagement\nstatus using four real-world datasets. We conducted detailed analyses on\nfeatures and failure cases to discuss the performance of current models as well\nas challenges.", "published": "2020-10-01 19:33:27", "link": "http://arxiv.org/abs/2010.00656v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Learning Variational Word Masks to Improve the Interpretability of\n  Neural Text Classifiers", "abstract": "To build an interpretable neural text classifier, most of the prior work has\nfocused on designing inherently interpretable models or finding faithful\nexplanations. A new line of work on improving model interpretability has just\nstarted, and many existing methods require either prior information or human\nannotations as additional inputs in training. To address this limitation, we\npropose the variational word mask (VMASK) method to automatically learn\ntask-specific important words and reduce irrelevant information on\nclassification, which ultimately improves the interpretability of model\npredictions. The proposed method is evaluated with three neural text\nclassifiers (CNN, LSTM, and BERT) on seven benchmark text classification\ndatasets. Experiments show the effectiveness of VMASK in improving both model\nprediction accuracy and interpretability.", "published": "2020-10-01 20:02:43", "link": "http://arxiv.org/abs/2010.00667v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Near-imperceptible Neural Linguistic Steganography via Self-Adjusting\n  Arithmetic Coding", "abstract": "Linguistic steganography studies how to hide secret messages in natural\nlanguage cover texts. Traditional methods aim to transform a secret message\ninto an innocent text via lexical substitution or syntactical modification.\nRecently, advances in neural language models (LMs) enable us to directly\ngenerate cover text conditioned on the secret message. In this study, we\npresent a new linguistic steganography method which encodes secret messages\nusing self-adjusting arithmetic coding based on a neural language model. We\nformally analyze the statistical imperceptibility of this method and\nempirically show it outperforms the previous state-of-the-art methods on four\ndatasets by 15.3% and 38.9% in terms of bits/word and KL metrics, respectively.\nFinally, human evaluations show that 51% of generated cover texts can indeed\nfool eavesdroppers.", "published": "2020-10-01 20:40:23", "link": "http://arxiv.org/abs/2010.00677v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Beyond The Text: Analysis of Privacy Statements through Syntactic and\n  Semantic Role Labeling", "abstract": "This paper formulates a new task of extracting privacy parameters from a\nprivacy policy, through the lens of Contextual Integrity, an established social\ntheory framework for reasoning about privacy norms. Privacy policies, written\nby lawyers, are lengthy and often comprise incomplete and vague statements. In\nthis paper, we show that traditional NLP tasks, including the recently proposed\nQuestion-Answering based solutions, are insufficient to address the privacy\nparameter extraction problem and provide poor precision and recall. We describe\n4 different types of conventional methods that can be partially adapted to\naddress the parameter extraction task with varying degrees of success: Hidden\nMarkov Models, BERT fine-tuned models, Dependency Type Parsing (DP) and\nSemantic Role Labeling (SRL). Based on a detailed evaluation across 36\nreal-world privacy policies of major enterprises, we demonstrate that a\nsolution combining syntactic DP coupled with type-specific SRL tasks provides\nthe highest accuracy for retrieving contextual privacy parameters from privacy\nstatements. We also observe that incorporating domain-specific knowledge is\ncritical to achieving high precision and recall, thus inspiring new NLP\nresearch to address this important problem in the privacy domain.", "published": "2020-10-01 20:48:37", "link": "http://arxiv.org/abs/2010.00678v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and\n  Act in Fantasy Worlds", "abstract": "We seek to create agents that both act and communicate with other agents in\npursuit of a goal. Towards this end, we extend LIGHT (Urbanek et al. 2019) -- a\nlarge-scale crowd-sourced fantasy text-game -- with a dataset of quests. These\ncontain natural language motivations paired with in-game goals and human\ndemonstrations; completing a quest might require dialogue or actions (or both).\nWe introduce a reinforcement learning system that (1) incorporates large-scale\nlanguage modeling-based and commonsense reasoning-based pre-training to imbue\nthe agent with relevant priors; and (2) leverages a factorized action space of\naction commands and dialogue, balancing between the two. We conduct zero-shot\nevaluations using held-out human expert demonstrations, showing that our agents\nare able to act consistently and talk naturally with respect to their\nmotivations.", "published": "2020-10-01 21:06:21", "link": "http://arxiv.org/abs/2010.00685v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Large Multi-Target Dataset of Common Bengali Handwritten Graphemes", "abstract": "Latin has historically led the state-of-the-art in handwritten optical\ncharacter recognition (OCR) research. Adapting existing systems from Latin to\nalpha-syllabary languages is particularly challenging due to a sharp contrast\nbetween their orthographies. The segmentation of graphical constituents\ncorresponding to characters becomes significantly hard due to a cursive writing\nsystem and frequent use of diacritics in the alpha-syllabary family of\nlanguages. We propose a labeling scheme based on graphemes (linguistic segments\nof word formation) that makes segmentation in-side alpha-syllabary words linear\nand present the first dataset of Bengali handwritten graphemes that are\ncommonly used in an everyday context. The dataset contains 411k curated samples\nof 1295 unique commonly used Bengali graphemes. Additionally, the test set\ncontains 900 uncommon Bengali graphemes for out of dictionary performance\nevaluation. The dataset is open-sourced as a part of a public Handwritten\nGrapheme Classification Challenge on Kaggle to benchmark vision algorithms for\nmulti-target grapheme classification. The unique graphemes present in this\ndataset are selected based on commonality in the Google Bengali ASR corpus.\nFrom competition proceedings, we see that deep-learning methods can generalize\nto a large span of out of dictionary graphemes which are absent during\ntraining. Dataset and starter codes at www.kaggle.com/c/bengaliai-cv19.", "published": "2020-10-01 01:51:45", "link": "http://arxiv.org/abs/2010.00170v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dual Attention Model for Citation Recommendation", "abstract": "Based on an exponentially increasing number of academic articles, discovering\nand citing comprehensive and appropriate resources has become a non-trivial\ntask. Conventional citation recommender methods suffer from severe information\nloss. For example, they do not consider the section of the paper that the user\nis writing and for which they need to find a citation, the relatedness between\nthe words in the local context (the text span that describes a citation), or\nthe importance on each word from the local context. These shortcomings make\nsuch methods insufficient for recommending adequate citations to academic\nmanuscripts. In this study, we propose a novel embedding-based neural network\ncalled \"dual attention model for citation recommendation (DACR)\" to recommend\ncitations during manuscript preparation. Our method adapts embedding of three\ndimensions of semantic information: words in the local context, structural\ncontexts, and the section on which a user is working. A neural network is\ndesigned to maximize the similarity between the embedding of the three input\n(local context words, section and structural contexts) and the target citation\nappearing in the context. The core of the neural network is composed of\nself-attention and additive attention, where the former aims to capture the\nrelatedness between the contextual words and structural context, and the latter\naims to learn the importance of them. The experiments on real-world datasets\ndemonstrate the effectiveness of the proposed approach.", "published": "2020-10-01 02:41:47", "link": "http://arxiv.org/abs/2010.00182v5", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "WeChat Neural Machine Translation Systems for WMT20", "abstract": "We participate in the WMT 2020 shared news translation task on Chinese to\nEnglish. Our system is based on the Transformer (Vaswani et al., 2017a) with\neffective variants and the DTMT (Meng and Zhang, 2019) architecture. In our\nexperiments, we employ data selection, several synthetic data generation\napproaches (i.e., back-translation, knowledge distillation, and iterative\nin-domain knowledge transfer), advanced finetuning approaches and self-bleu\nbased model ensemble. Our constrained Chinese to English system achieves 36.9\ncase-sensitive BLEU score, which is the highest among all submissions.", "published": "2020-10-01 08:15:09", "link": "http://arxiv.org/abs/2010.00247v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A survey on natural language processing (nlp) and applications in\n  insurance", "abstract": "Text is the most widely used means of communication today. This data is\nabundant but nevertheless complex to exploit within algorithms. For years,\nscientists have been trying to implement different techniques that enable\ncomputers to replicate some mechanisms of human reading. During the past five\nyears, research disrupted the capacity of the algorithms to unleash the value\nof text data. It brings today, many opportunities for the insurance\nindustry.Understanding those methods and, above all, knowing how to apply them\nis a major challenge and key to unleash the value of text data that have been\nstored for many years. Processing language with computer brings many new\nopportunities especially in the insurance sector where reports are central in\nthe information used by insurers. SCOR's Data Analytics team has been working\non the implementation of innovative tools or products that enable the use of\nthe latest research on text analysis. Understanding text mining techniques in\ninsurance enhances the monitoring of the underwritten risks and many processes\nthat finally benefit policyholders.This article proposes to explain\nopportunities that Natural Language Processing (NLP) are providing to\ninsurance. It details different methods used today in practice traces back the\nstory of them. We also illustrate the implementation of certain methods using\nopen source libraries and python codes that we have developed to facilitate the\nuse of these techniques.After giving a general overview on the evolution of\ntext mining during the past few years,we share about how to conduct a full\nstudy with text mining and share some examples to serve those models into\ninsurance products or services. Finally, we explained in more details every\nstep that composes a Natural Language Processing study to ensure the reader can\nhave a deep understanding on the implementation.", "published": "2020-10-01 14:56:18", "link": "http://arxiv.org/abs/2010.00462v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "AMUSED: An Annotation Framework of Multi-modal Social Media Data", "abstract": "In this paper, we present a semi-automated framework called AMUSED for\ngathering multi-modal annotated data from the multiple social media platforms.\nThe framework is designed to mitigate the issues of collecting and annotating\nsocial media data by cohesively combining machine and human in the data\ncollection process. From a given list of the articles from professional news\nmedia or blog, AMUSED detects links to the social media posts from news\narticles and then downloads contents of the same post from the respective\nsocial media platform to gather details about that specific post. The framework\nis capable of fetching the annotated data from multiple platforms like Twitter,\nYouTube, Reddit. The framework aims to reduce the workload and problems behind\nthe data annotation from the social media platforms. AMUSED can be applied in\nmultiple application domains, as a use case, we have implemented the framework\nfor collecting COVID-19 misinformation data from different social media\nplatforms.", "published": "2020-10-01 15:50:41", "link": "http://arxiv.org/abs/2010.00502v2", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "ISAAQ -- Mastering Textbook Questions with Pre-trained Transformers and\n  Bottom-Up and Top-Down Attention", "abstract": "Textbook Question Answering is a complex task in the intersection of Machine\nComprehension and Visual Question Answering that requires reasoning with\nmultimodal information from text and diagrams. For the first time, this paper\ntaps on the potential of transformer language models and bottom-up and top-down\nattention to tackle the language and visual understanding challenges this task\nentails. Rather than training a language-visual transformer from scratch we\nrely on pre-trained transformers, fine-tuning and ensembling. We add bottom-up\nand top-down attention to identify regions of interest corresponding to diagram\nconstituents and their relationships, improving the selection of relevant\nvisual information for each question and answer options. Our system ISAAQ\nreports unprecedented success in all TQA question types, with accuracies of\n81.36%, 71.11% and 55.12% on true/false, text-only and diagram multiple choice\nquestions. ISAAQ also demonstrates its broad applicability, obtaining\nstate-of-the-art results in other demanding datasets.", "published": "2020-10-01 17:28:47", "link": "http://arxiv.org/abs/2010.00562v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Understanding tables with intermediate pre-training", "abstract": "Table entailment, the binary classification task of finding if a sentence is\nsupported or refuted by the content of a table, requires parsing language and\ntable structure as well as numerical and discrete reasoning. While there is\nextensive work on textual entailment, table entailment is less well studied. We\nadapt TAPAS (Herzig et al., 2020), a table-based BERT model, to recognize\nentailment. Motivated by the benefits of data augmentation, we create a\nbalanced dataset of millions of automatically created training examples which\nare learned in an intermediate step prior to fine-tuning. This new data is not\nonly useful for table entailment, but also for SQA (Iyyer et al., 2017), a\nsequential table QA task. To be able to use long examples as input of BERT\nmodels, we evaluate table pruning techniques as a pre-processing step to\ndrastically improve the training and prediction efficiency at a moderate drop\nin accuracy. The different methods set the new state-of-the-art on the TabFact\n(Chen et al., 2020) and SQA datasets.", "published": "2020-10-01 17:43:27", "link": "http://arxiv.org/abs/2010.00571v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge\n  Masking", "abstract": "Graph neural networks (GNNs) have become a popular approach to integrating\nstructural inductive biases into NLP models. However, there has been little\nwork on interpreting them, and specifically on understanding which parts of the\ngraphs (e.g. syntactic trees or co-reference structures) contribute to a\nprediction. In this work, we introduce a post-hoc method for interpreting the\npredictions of GNNs which identifies unnecessary edges. Given a trained GNN\nmodel, we learn a simple classifier that, for every edge in every layer,\npredicts if that edge can be dropped. We demonstrate that such a classifier can\nbe trained in a fully differentiable fashion, employing stochastic gates and\nencouraging sparsity through the expected $L_0$ norm. We use our technique as\nan attribution method to analyze GNN models for two tasks -- question answering\nand semantic role labeling -- providing insights into the information flow in\nthese models. We show that we can drop a large proportion of edges without\ndeteriorating the performance of the model, while we can analyse the remaining\nedges for interpreting model predictions.", "published": "2020-10-01 17:51:19", "link": "http://arxiv.org/abs/2010.00577v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Survey of the State of Explainable AI for Natural Language Processing", "abstract": "Recent years have seen important advances in the quality of state-of-the-art\nmodels, but this has come at the expense of models becoming less interpretable.\nThis survey presents an overview of the current state of Explainable AI (XAI),\nconsidered within the domain of Natural Language Processing (NLP). We discuss\nthe main categorization of explanations, as well as the various ways\nexplanations can be arrived at and visualized. We detail the operations and\nexplainability techniques currently available for generating explanations for\nNLP model predictions, to serve as a resource for model developers in the\ncommunity. Finally, we point out the current gaps and encourage directions for\nfuture work in this important research area.", "published": "2020-10-01 22:33:21", "link": "http://arxiv.org/abs/2010.00711v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Evaluating a Generative Adversarial Framework for Information Retrieval", "abstract": "Recent advances in Generative Adversarial Networks (GANs) have resulted in\nits widespread applications to multiple domains. A recent model, IRGAN, applies\nthis framework to Information Retrieval (IR) and has gained significant\nattention over the last few years. In this focused work, we critically analyze\nmultiple components of IRGAN, while providing experimental and theoretical\nevidence of some of its shortcomings. Specifically, we identify issues with the\nconstant baseline term in the policy gradients optimization and show that the\ngenerator harms IRGAN's performance. Motivated by our findings, we propose two\nmodels influenced by self-contrastive estimation and co-training which\noutperform IRGAN on two out of the three tasks considered.", "published": "2020-10-01 23:11:23", "link": "http://arxiv.org/abs/2010.00722v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Assessing Robustness of Text Classification through Maximal Safe Radius\n  Computation", "abstract": "Neural network NLP models are vulnerable to small modifications of the input\nthat maintain the original meaning but result in a different prediction. In\nthis paper, we focus on robustness of text classification against word\nsubstitutions, aiming to provide guarantees that the model prediction does not\nchange if a word is replaced with a plausible alternative, such as a synonym.\nAs a measure of robustness, we adopt the notion of the maximal safe radius for\na given input text, which is the minimum distance in the embedding space to the\ndecision boundary. Since computing the exact maximal safe radius is not\nfeasible in practice, we instead approximate it by computing a lower and upper\nbound. For the upper bound computation, we employ Monte Carlo Tree Search in\nconjunction with syntactic filtering to analyse the effect of single and\nmultiple word substitutions. The lower bound computation is achieved through an\nadaptation of the linear bounding techniques implemented in tools CNN-Cert and\nPOPQORN, respectively for convolutional and recurrent network models. We\nevaluate the methods on sentiment analysis and news classification models for\nfour datasets (IMDB, SST, AG News and NEWS) and a range of embeddings, and\nprovide an analysis of robustness trends. We also apply our framework to\ninterpretability analysis and compare it with LIME.", "published": "2020-10-01 09:46:32", "link": "http://arxiv.org/abs/2010.02004v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Helicality: An Isomap-based Measure of Octave Equivalence in Audio Data", "abstract": "Octave equivalence serves as domain-knowledge in MIR systems, including\nchromagram, spiral convolutional networks, and harmonic CQT. Prior work has\napplied the Isomap manifold learning algorithm to unlabeled audio data to embed\nfrequency sub-bands in 3-D space where the Euclidean distances are inversely\nproportional to the strength of their Pearson correlations. However,\ndiscovering octave equivalence via Isomap requires visual inspection and is not\nscalable. To address this problem, we define \"helicality\" as the goodness of\nfit of the 3-D Isomap embedding to a Shepherd-Risset helix. Our method is\nunsupervised and uses a custom Frank-Wolfe algorithm to minimize a\nleast-squares objective inside a convex hull. Numerical experiments indicate\nthat isolated musical notes have a higher helicality than speech, followed by\ndrum hits.", "published": "2020-10-01 20:30:05", "link": "http://arxiv.org/abs/2010.00673v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SESQA: semi-supervised learning for speech quality assessment", "abstract": "Automatic speech quality assessment is an important, transversal task whose\nprogress is hampered by the scarcity of human annotations, poor generalization\nto unseen recording conditions, and a lack of flexibility of existing\napproaches. In this work, we tackle these problems with a semi-supervised\nlearning approach, combining available annotations with programmatically\ngenerated data, and using 3 different optimization criteria together with 5\ncomplementary auxiliary tasks. Our results show that such a semi-supervised\napproach can cut the error of existing methods by more than 36%, while\nproviding additional benefits in terms of reusable features or auxiliary\noutputs. Improvement is further corroborated with an out-of-sample test showing\npromising generalization capabilities.", "published": "2020-10-01 12:59:58", "link": "http://arxiv.org/abs/2010.00368v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FSD50K: An Open Dataset of Human-Labeled Sound Events", "abstract": "Most existing datasets for sound event recognition (SER) are relatively small\nand/or domain-specific, with the exception of AudioSet, based on over 2M tracks\nfrom YouTube videos and encompassing over 500 sound classes. However, AudioSet\nis not an open dataset as its official release consists of pre-computed audio\nfeatures. Downloading the original audio tracks can be problematic due to\nYouTube videos gradually disappearing and usage rights issues. To provide an\nalternative benchmark dataset and thus foster SER research, we introduce\nFSD50K, an open dataset containing over 51k audio clips totalling over 100h of\naudio manually labeled using 200 classes drawn from the AudioSet Ontology. The\naudio clips are licensed under Creative Commons licenses, making the dataset\nfreely distributable (including waveforms). We provide a detailed description\nof the FSD50K creation process, tailored to the particularities of Freesound\ndata, including challenges encountered and solutions adopted. We include a\ncomprehensive dataset characterization along with discussion of limitations and\nkey factors to allow its audio-informed usage. Finally, we conduct sound event\nclassification experiments to provide baseline systems as well as insight on\nthe main factors to consider when splitting Freesound audio data for SER. Our\ngoal is to develop a dataset to be widely adopted by the community as a new\nopen benchmark for SER research.", "published": "2020-10-01 15:07:25", "link": "http://arxiv.org/abs/2010.00475v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Classifying Songs with EEG", "abstract": "This research study aims to use machine learning methods to characterize the\nEEG response to music. Specifically, we investigate how resonance in the EEG\nresponse correlates with individual aesthetic enjoyment. Inspired by the notion\nof musical processing as resonance, we hypothesize that the intensity of an\naesthetic experience is based on the degree to which a participants EEG\nentrains to the perceptual input. To test this and other hypotheses, we have\nbuilt an EEG dataset from 20 subjects listening to 12 two minute-long songs in\nrandom order. After preprocessing and feature construction, we used this\ndataset to train and test multiple machine learning models.", "published": "2020-10-01 14:02:11", "link": "http://arxiv.org/abs/2010.04087v1", "categories": ["eess.SP", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
