{"title": "SEE: Syntax-aware Entity Embedding for Neural Relation Extraction", "abstract": "Distant supervised relation extraction is an efficient approach to scale\nrelation extraction to very large corpora, and has been widely used to find\nnovel relational facts from plain text. Recent studies on neural relation\nextraction have shown great progress on this task via modeling the sentences in\nlow-dimensional spaces, but seldom considered syntax information to model the\nentities. In this paper, we propose to learn syntax-aware entity embedding for\nneural relation extraction. First, we encode the context of entities on a\ndependency tree as sentence-level entity embedding based on tree-GRU. Then, we\nutilize both intra-sentence and inter-sentence attentions to obtain sentence\nset-level entity embedding over all sentences containing the focus entity pair.\nFinally, we combine both sentence embedding and entity embedding for relation\nclassification. We conduct experiments on a widely used real-world dataset and\nthe experimental results show that our model can make full use of all\ninformative instances and achieve state-of-the-art performance of relation\nextraction.", "published": "2018-01-11 01:16:13", "link": "http://arxiv.org/abs/1801.03603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved English to Russian Translation by Neural Suffix Prediction", "abstract": "Neural machine translation (NMT) suffers a performance deficiency when a\nlimited vocabulary fails to cover the source or target side adequately, which\nhappens frequently when dealing with morphologically rich languages. To address\nthis problem, previous work focused on adjusting translation granularity or\nexpanding the vocabulary size. However, morphological information is relatively\nunder-considered in NMT architectures, which may further improve translation\nquality. We propose a novel method, which can not only reduce data sparsity but\nalso model morphology through a simple but effective mechanism. By predicting\nthe stem and suffix separately during decoding, our system achieves an\nimprovement of up to 1.98 BLEU compared with previous work on English to\nRussian translation. Our method is orthogonal to different NMT architectures\nand stably gains improvements on various domains.", "published": "2018-01-11 02:18:06", "link": "http://arxiv.org/abs/1801.03615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Did William Shakespeare and Thomas Kyd Write Edward III?", "abstract": "William Shakespeare is believed to be a significant author in the anonymous\nplay, The Reign of King Edward III, published in 1596. However, recently,\nThomas Kyd, has been suggested as the primary author. Using a neurolinguistics\napproach to authorship identification we use a four-feature technique, RPAS, to\nconvert the 19 scenes in Edward III into a multi-dimensional vector. Three\ncomplementary analytical techniques are applied to cluster the data and reduce\nsingle technique bias before an alternate method, seriation, is used to measure\nthe distances between clusters and test the strength of the connections. We\nfind the multivariate techniques robust and are able to allocate up to 14\nscenes to Thomas Kyd, and further question if scenes long believed to be\nShakespeare's are not his.", "published": "2018-01-11 23:40:39", "link": "http://arxiv.org/abs/1801.04017v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EARL: Joint Entity and Relation Linking for Question Answering over\n  Knowledge Graphs", "abstract": "Many question answering systems over knowledge graphs rely on entity and\nrelation linking components in order to connect the natural language input to\nthe underlying knowledge graph. Traditionally, entity linking and relation\nlinking have been performed either as dependent sequential tasks or as\nindependent parallel tasks. In this paper, we propose a framework called EARL,\nwhich performs entity linking and relation linking as a joint task. EARL\nimplements two different solution strategies for which we provide a comparative\nanalysis in this paper: The first strategy is a formalisation of the joint\nentity and relation linking tasks as an instance of the Generalised Travelling\nSalesman Problem (GTSP). In order to be computationally feasible, we employ\napproximate GTSP solvers. The second strategy uses machine learning in order to\nexploit the connection density between nodes in the knowledge graph. It relies\non three base features and re-ranking steps in order to predict entities and\nrelations. We compare the strategies and evaluate them on a dataset with 5000\nquestions. Both strategies significantly outperform the current\nstate-of-the-art approaches for entity and relation linking.", "published": "2018-01-11 15:40:31", "link": "http://arxiv.org/abs/1801.03825v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Stochastic Learning of Nonstationary Kernels for Natural Language\n  Modeling", "abstract": "Natural language processing often involves computations with semantic or\nsyntactic graphs to facilitate sophisticated reasoning based on structural\nrelationships. While convolution kernels provide a powerful tool for comparing\ngraph structure based on node (word) level relationships, they are difficult to\ncustomize and can be computationally expensive. We propose a generalization of\nconvolution kernels, with a nonstationary model, for better expressibility of\nnatural languages in supervised settings. For a scalable learning of the\nparameters introduced with our model, we propose a novel algorithm that\nleverages stochastic sampling on k-nearest neighbor graphs, along with\napproximations based on locality-sensitive hashing. We demonstrate the\nadvantages of our approach on a challenging real-world (structured inference)\nproblem of automatically extracting biological models from the text of\nscientific papers.", "published": "2018-01-11 18:24:02", "link": "http://arxiv.org/abs/1801.03911v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Conversational AI: The Science Behind the Alexa Prize", "abstract": "Conversational agents are exploding in popularity. However, much work remains\nin the area of social conversation as well as free-form conversation over a\nbroad range of domains and topics. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million-dollar\nuniversity competition where sixteen selected university teams were challenged\nto build conversational agents, known as socialbots, to converse coherently and\nengagingly with humans on popular topics such as Sports, Politics,\nEntertainment, Fashion and Technology for 20 minutes. The Alexa Prize offers\nthe academic community a unique opportunity to perform research with a live\nsystem used by millions of users. The competition provided university teams\nwith real user conversational data at scale, along with the user-provided\nratings and feedback augmented with annotations by the Alexa team. This enabled\nteams to effectively iterate and make improvements throughout the competition\nwhile being evaluated in real-time through live user interactions. To build\ntheir socialbots, university teams combined state-of-the-art techniques with\nnovel strategies in the areas of Natural Language Understanding, Context\nModeling, Dialog Management, Response Generation, and Knowledge Acquisition. To\nsupport the efforts of participating teams, the Alexa Prize team made\nsignificant scientific and engineering investments to build and improve\nConversational Speech Recognition, Topic Tracking, Dialog Evaluation, Voice\nUser Experience, and tools for traffic management and scalability. This paper\noutlines the advances created by the university teams as well as the Alexa\nPrize team to achieve the common goal of solving the problem of Conversational\nAI.", "published": "2018-01-11 01:23:50", "link": "http://arxiv.org/abs/1801.03604v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.MA", "97R40", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Topic-based Evaluation for Conversational Bots", "abstract": "Dialog evaluation is a challenging problem, especially for non task-oriented\ndialogs where conversational success is not well-defined. We propose to\nevaluate dialog quality using topic-based metrics that describe the ability of\na conversational bot to sustain coherent and engaging conversations on a topic,\nand the diversity of topics that a bot can handle. To detect conversation\ntopics per utterance, we adopt Deep Average Networks (DAN) and train a topic\nclassifier on a variety of question and query data categorized into multiple\ntopics. We propose a novel extension to DAN by adding a topic-word attention\ntable that allows the system to jointly capture topic keywords in an utterance\nand perform topic classification. We compare our proposed topic based metrics\nwith the ratings provided by users and show that our metrics both correlate\nwith and complement human judgment. Our analysis is performed on tens of\nthousands of real human-bot dialogs from the Alexa Prize competition and\nhighlights user expectations for conversational bots.", "published": "2018-01-11 03:20:02", "link": "http://arxiv.org/abs/1801.03622v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.MA", "97R40", "I.2.7"], "primary_category": "cs.CL"}
{"title": "On Evaluating and Comparing Open Domain Dialog Systems", "abstract": "Conversational agents are exploding in popularity. However, much work remains\nin the area of non goal-oriented conversations, despite significant growth in\nresearch interest over recent years. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar\nuniversity competition where sixteen selected university teams built\nconversational agents to deliver the best social conversational experience.\nAlexa Prize provided the academic community with the unique opportunity to\nperform research with a live system used by millions of users. The subjectivity\nassociated with evaluating conversations is key element underlying the\nchallenge of building non-goal oriented dialogue systems. In this paper, we\npropose a comprehensive evaluation strategy with multiple metrics designed to\nreduce subjectivity by selecting metrics which correlate well with human\njudgement. The proposed metrics provide granular analysis of the conversational\nagents, which is not captured in human ratings. We show that these metrics can\nbe used as a reasonable proxy for human judgment. We provide a mechanism to\nunify the metrics for selecting the top performing agents, which has also been\napplied throughout the Alexa Prize competition. To our knowledge, to date it is\nthe largest setting for evaluating agents with millions of conversations and\nhundreds of thousands of ratings from users. We believe that this work is a\nstep towards an automatic evaluation process for conversational AIs.", "published": "2018-01-11 03:30:00", "link": "http://arxiv.org/abs/1801.03625v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.MA", "97R40", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Direction of Arrival with One Microphone, a few LEGOs, and Non-Negative\n  Matrix Factorization", "abstract": "Conventional approaches to sound source localization require at least two\nmicrophones. It is known, however, that people with unilateral hearing loss can\nalso localize sounds. Monaural localization is possible thanks to the\nscattering by the head, though it hinges on learning the spectra of the various\nsources. We take inspiration from this human ability to propose algorithms for\naccurate sound source localization using a single microphone embedded in an\narbitrary scattering structure. The structure modifies the frequency response\nof the microphone in a direction-dependent way giving each direction a\nsignature. While knowing those signatures is sufficient to localize sources of\nwhite noise, localizing speech is much more challenging: it is an ill-posed\ninverse problem which we regularize by prior knowledge in the form of learned\nnon-negative dictionaries. We demonstrate a monaural speech localization\nalgorithm based on non-negative matrix factorization that does not depend on\nsophisticated, designed scatterers. In fact, we show experimental results with\nad hoc scatterers made of LEGO bricks. Even with these rudimentary structures\nwe can accurately localize arbitrary speakers; that is, we do not need to learn\nthe dictionary for the particular speaker to be localized. Finally, we discuss\nmulti-source localization and the related limitations of our approach.", "published": "2018-01-11 12:45:04", "link": "http://arxiv.org/abs/1801.03740v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
