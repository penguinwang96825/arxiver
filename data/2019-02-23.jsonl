{"title": "VCWE: Visual Character-Enhanced Word Embeddings", "abstract": "Chinese is a logographic writing system, and the shape of Chinese characters\ncontain rich syntactic and semantic information. In this paper, we propose a\nmodel to learn Chinese word embeddings via three-level composition: (1) a\nconvolutional neural network to extract the intra-character compositionality\nfrom the visual shape of a character; (2) a recurrent neural network with\nself-attention to compose character representation into word embeddings; (3)\nthe Skip-Gram framework to capture non-compositionality directly from the\ncontextual information. Evaluations demonstrate the superior performance of our\nmodel on four tasks: word similarity, sentiment analysis, named entity\nrecognition and part-of-speech tagging.", "published": "2019-02-23 14:25:51", "link": "http://arxiv.org/abs/1902.08795v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Neural Machine Translation with Knowledge Graphs", "abstract": "While neural networks have been used extensively to make substantial progress\nin the machine translation task, they are known for being heavily dependent on\nthe availability of large amounts of training data. Recent efforts have tried\nto alleviate the data sparsity problem by augmenting the training data using\ndifferent strategies, such as back-translation. Along with the data scarcity,\nthe out-of-vocabulary words, mostly entities and terminological expressions,\npose a difficult challenge to Neural Machine Translation systems. In this\npaper, we hypothesize that knowledge graphs enhance the semantic feature\nextraction of neural models, thus optimizing the translation of entities and\nterminological expressions in texts and consequently leading to a better\ntranslation quality. We hence investigate two different strategies for\nincorporating knowledge graphs into neural models without modifying the neural\nnetwork architectures. We also examine the effectiveness of our augmentation\nmethod to recurrent and non-recurrent (self-attentional) neural architectures.\nOur knowledge graph augmented neural translation model, dubbed KG-NMT, achieves\nsignificant and consistent improvements of +3 BLEU, METEOR and chrF3 on average\non the newstest datasets between 2014 and 2018 for WMT English-German\ntranslation task.", "published": "2019-02-23 17:04:54", "link": "http://arxiv.org/abs/1902.08816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Categorization in the Wild: Generalizing Cognitive Models to\n  Naturalistic Data across Languages", "abstract": "Categories such as animal or furniture are acquired at an early age and play\nan important role in processing, organizing, and communicating world knowledge.\nCategories exist across cultures: they allow to efficiently represent the\ncomplexity of the world, and members of a community strongly agree on their\nnature, revealing a shared mental representation. Models of category learning\nand representation, however, are typically tested on data from small-scale\nexperiments involving small sets of concepts with artificially restricted\nfeatures; and experiments predominantly involve participants of selected\ncultural and socio-economical groups (very often involving western native\nspeakers of English such as U.S. college students) . This work investigates\nwhether models of categorization generalize (a) to rich and noisy data\napproximating the environment humans live in; and (b) across languages and\ncultures. We present a Bayesian cognitive model designed to jointly learn\ncategories and their structured representation from natural language text which\nallows us to (a) evaluate performance on a large scale, and (b) apply our model\nto a diverse set of languages. We show that meaningful categories comprising\nhundreds of concepts and richly structured featural representations emerge\nacross languages. Our work illustrates the potential of recent advances in\ncomputational modeling and large scale naturalistic datasets for cognitive\nscience research.", "published": "2019-02-23 19:21:08", "link": "http://arxiv.org/abs/1902.08830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-evaluating ADEM: A Deeper Look at Scoring Dialogue Responses", "abstract": "Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. ADEM(Lowe et al. 2017) formulated the\nautomatic evaluation of dialogue systems as a learning problem and showed that\nsuch a model was able to predict responses which correlate significantly with\nhuman judgements, both at utterance and system level. Their system was shown to\nhave beaten word-overlap metrics such as BLEU with large margins. We start with\nthe question of whether an adversary can game the ADEM model. We design a\nbattery of targeted attacks at the neural network based ADEM evaluation system\nand show that automatic evaluation of dialogue systems still has a long way to\ngo. ADEM can get confused with a variation as simple as reversing the word\norder in the text! We report experiments on several such adversarial scenarios\nthat draw out counterintuitive scores on the dialogue responses. We take a\nsystematic look at the scoring function proposed by ADEM and connect it to\nlinear system theory to predict the shortcomings evident in the system. We also\ndevise an attack that can fool such a system to rate a response generation\nsystem as favorable. Finally, we allude to future research directions of using\nthe adversarial attacks to design a truly automated dialogue evaluation system.", "published": "2019-02-23 19:21:24", "link": "http://arxiv.org/abs/1902.08832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vector of Locally-Aggregated Word Embeddings (VLAWE): A Novel\n  Document-level Representation", "abstract": "In this paper, we propose a novel representation for text documents based on\naggregating word embedding vectors into document embeddings. Our approach is\ninspired by the Vector of Locally-Aggregated Descriptors used for image\nrepresentation, and it works as follows. First, the word embeddings gathered\nfrom a collection of documents are clustered by k-means in order to learn a\ncodebook of semnatically-related word embeddings. Each word embedding is then\nassociated to its nearest cluster centroid (codeword). The Vector of\nLocally-Aggregated Word Embeddings (VLAWE) representation of a document is then\ncomputed by accumulating the differences between each codeword vector and each\nword vector (from the document) associated to the respective codeword. We plug\nthe VLAWE representation, which is learned in an unsupervised manner, into a\nclassifier and show that it is useful for a diverse set of text classification\ntasks. We compare our approach with a broad range of recent state-of-the-art\nmethods, demonstrating the effectiveness of our approach. Furthermore, we\nobtain a considerable improvement on the Movie Review data set, reporting an\naccuracy of 93.3%, which represents an absolute gain of 10% over the\nstate-of-the-art approach. Our code is available at\nhttps://github.com/raduionescu/vlawe-boswe/.", "published": "2019-02-23 21:35:54", "link": "http://arxiv.org/abs/1902.08850v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evidence Sentence Extraction for Machine Reading Comprehension", "abstract": "Remarkable success has been achieved in the last few years on some limited\nmachine reading comprehension (MRC) tasks. However, it is still difficult to\ninterpret the predictions of existing MRC models. In this paper, we focus on\nextracting evidence sentences that can explain or support the answers of\nmultiple-choice MRC tasks, where the majority of answer options cannot be\ndirectly extracted from reference documents.\n  Due to the lack of ground truth evidence sentence labels in most cases, we\napply distant supervision to generate imperfect labels and then use them to\ntrain an evidence sentence extractor. To denoise the noisy labels, we apply a\nrecently proposed deep probabilistic logic learning framework to incorporate\nboth sentence-level and cross-sentence linguistic indicators for indirect\nsupervision. We feed the extracted evidence sentences into existing MRC models\nand evaluate the end-to-end performance on three challenging multiple-choice\nMRC datasets: MultiRC, RACE, and DREAM, achieving comparable or better\nperformance than the same models that take as input the full reference\ndocument. To the best of our knowledge, this is the first work extracting\nevidence sentences for multiple-choice MRC.", "published": "2019-02-23 21:53:48", "link": "http://arxiv.org/abs/1902.08852v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ABI Neural Ensemble Model for Gender Prediction Adapt Bar-Ilan\n  Submission for the CLIN29 Shared Task on Gender Prediction", "abstract": "We present our system for the CLIN29 shared task on cross-genre gender\ndetection for Dutch. We experimented with a multitude of neural models (CNN,\nRNN, LSTM, etc.), more \"traditional\" models (SVM, RF, LogReg, etc.), different\nfeature sets as well as data pre-processing. The final results suggested that\nusing tokenized, non-lowercased data works best for most of the neural models,\nwhile a combination of word clusters, character trigrams and word lists showed\nto be most beneficial for the majority of the more \"traditional\" (that is,\nnon-neural) models, beating features used in previous tasks such as n-grams,\ncharacter n-grams, part-of-speech tags and combinations thereof. In\ncontradiction with the results described in previous comparable shared tasks,\nour neural models performed better than our best traditional approaches with\nour best feature set-up. Our final model consisted of a weighted ensemble model\ncombining the top 25 models. Our final model won both the in-domain gender\nprediction task and the cross-genre challenge, achieving an average accuracy of\n64.93% on the in-domain gender prediction task, and 56.26% on cross-genre\ngender prediction.", "published": "2019-02-23 22:17:08", "link": "http://arxiv.org/abs/1902.08856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog\n  Agents with Latent Variable Models", "abstract": "Defining action spaces for conversational agents and optimizing their\ndecision-making process with reinforcement learning is an enduring challenge.\nCommon practice has been to use handcrafted dialog acts, or the output\nvocabulary, e.g. in neural encoder decoders, as the action spaces. Both have\ntheir own limitations. This paper proposes a novel latent action framework that\ntreats the action spaces of an end-to-end dialog agent as latent variables and\ndevelops unsupervised methods in order to induce its own action space from the\ndata. Comprehensive experiments are conducted examining both continuous and\ndiscrete action types and two different optimization methods based on\nstochastic variational inference. Results show that the proposed latent actions\nachieve superior empirical performance improvement over previous word-level\npolicy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed\nanalysis also provides insights about various latent variable approaches for\npolicy learning and can serve as a foundation for developing better latent\nactions in future research.", "published": "2019-02-23 22:27:45", "link": "http://arxiv.org/abs/1902.08858v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fixed-Size Ordinally Forgetting Encoding Based Word Sense Disambiguation", "abstract": "In this paper, we present our method of using fixed-size ordinally forgetting\nencoding (FOFE) to solve the word sense disambiguation (WSD) problem. FOFE\nenables us to encode variable-length sequence of words into a theoretically\nunique fixed-size representation that can be fed into a feed forward neural\nnetwork (FFNN), while keeping the positional information between words. In our\nmethod, a FOFE-based FFNN is used to train a pseudo language model over\nunlabelled corpus, then the pre-trained language model is capable of\nabstracting the surrounding context of polyseme instances in labelled corpus\ninto context embeddings. Next, we take advantage of these context embeddings\ntowards WSD classification. We conducted experiments on several WSD data sets,\nwhich demonstrates that our proposed method can achieve comparable performance\nto that of the state-of-the-art approach at the expense of much lower\ncomputational cost.", "published": "2019-02-23 00:22:58", "link": "http://arxiv.org/abs/1902.10246v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Leveraging Deep Graph-Based Text Representation for Sentiment Polarity\n  Applications", "abstract": "Over the last few years, machine learning over graph structures has\nmanifested a significant enhancement in text mining applications such as event\ndetection, opinion mining, and news recommendation. One of the primary\nchallenges in this regard is structuring a graph that encodes and encompasses\nthe features of textual data for the effective machine learning algorithm.\nBesides, exploration and exploiting of semantic relations is regarded as a\nprincipal step in text mining applications. However, most of the traditional\ntext mining methods perform somewhat poor in terms of employing such relations.\nIn this paper, we propose a sentence-level graph-based text representation\nwhich includes stop words to consider semantic and term relations. Then, we\nemploy a representation learning approach on the combined graphs of sentences\nto extract the latent and continuous features of the documents. Eventually, the\nlearned features of the documents are fed into a deep neural network for the\nsentiment classification task. The experimental results demonstrate that the\nproposed method substantially outperforms the related sentiment analysis\napproaches based on several benchmark datasets. Furthermore, our method can be\ngeneralized on different datasets without any dependency on pre-trained word\nembeddings.", "published": "2019-02-23 16:38:35", "link": "http://arxiv.org/abs/1902.10247v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "GANSynth: Adversarial Neural Audio Synthesis", "abstract": "Efficient audio synthesis is an inherently difficult machine learning task,\nas human perception is sensitive to both global structure and fine-scale\nwaveform coherence. Autoregressive models, such as WaveNet, model local\nstructure at the expense of global latent structure and slow iterative\nsampling, while Generative Adversarial Networks (GANs), have global latent\nconditioning and efficient parallel sampling, but struggle to generate\nlocally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact\ngenerate high-fidelity and locally-coherent audio by modeling log magnitudes\nand instantaneous frequencies with sufficient frequency resolution in the\nspectral domain. Through extensive empirical investigations on the NSynth\ndataset, we demonstrate that GANs are able to outperform strong WaveNet\nbaselines on automated and human evaluation metrics, and efficiently generate\naudio several orders of magnitude faster than their autoregressive\ncounterparts.", "published": "2019-02-23 00:55:16", "link": "http://arxiv.org/abs/1902.08710v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
