{"title": "Abuse is Contextual, What about NLP? The Role of Context in Abusive\n  Language Annotation and Detection", "abstract": "The datasets most widely used for abusive language detection contain lists of\nmessages, usually tweets, that have been manually judged as abusive or not by\none or more annotators, with the annotation performed at message level. In this\npaper, we investigate what happens when the hateful content of a message is\njudged also based on the context, given that messages are often ambiguous and\nneed to be interpreted in the context of occurrence. We first re-annotate part\nof a widely used dataset for abusive language detection in English in two\nconditions, i.e. with and without context. Then, we compare the performance of\nthree classification algorithms obtained on these two types of dataset, arguing\nthat a context-aware classification is more challenging but also more similar\nto a real application scenario.", "published": "2021-03-27 14:31:52", "link": "http://arxiv.org/abs/2103.14916v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supersense and Sensibility: Proxy Tasks for Semantic Annotation of\n  Prepositions", "abstract": "Prepositional supersense annotation is time-consuming and requires expert\ntraining. Here, we present two sensible methods for obtaining prepositional\nsupersense annotations by eliciting surface substitution and similarity\njudgments. Four pilot studies suggest that both methods have potential for\nproducing prepositional supersense annotations that are comparable in quality\nto expert annotations.", "published": "2021-03-27 18:28:33", "link": "http://arxiv.org/abs/2103.14961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HateBR: A Large Expert Annotated Corpus of Brazilian Instagram Comments\n  for Offensive Language and Hate Speech Detection", "abstract": "Due to the severity of the social media offensive and hateful comments in\nBrazil, and the lack of research in Portuguese, this paper provides the first\nlarge-scale expert annotated corpus of Brazilian Instagram comments for hate\nspeech and offensive language detection. The HateBR corpus was collected from\nthe comment section of Brazilian politicians' accounts on Instagram and\nmanually annotated by specialists, reaching a high inter-annotator agreement.\nThe corpus consists of 7,000 documents annotated according to three different\nlayers: a binary classification (offensive versus non-offensive comments),\noffensiveness-level classification (highly, moderately, and slightly\noffensive), and nine hate speech groups (xenophobia, racism, homophobia,\nsexism, religious intolerance, partyism, apology for the dictatorship,\nantisemitism, and fatphobia). We also implemented baseline experiments for\noffensive language and hate speech detection and compared them with a\nliterature baseline. Results show that the baseline experiments on our corpus\noutperform the current state-of-the-art for the Portuguese language.", "published": "2021-03-27 19:43:16", "link": "http://arxiv.org/abs/2103.14972v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Review of the Video-to-Text Problem", "abstract": "Research in the Vision and Language area encompasses challenging topics that\nseek to connect visual and textual information. When the visual information is\nrelated to videos, this takes us into Video-Text Research, which includes\nseveral challenging tasks such as video question answering, video summarization\nwith natural language, and video-to-text and text-to-video conversion. This\npaper reviews the video-to-text problem, in which the goal is to associate an\ninput video with its textual description. This association can be mainly made\nby retrieving the most relevant descriptions from a corpus or generating a new\none given a context video. These two ways represent essential tasks for\nComputer Vision and Natural Language Processing communities, called text\nretrieval from video task and video captioning/description task. These two\ntasks are substantially more complex than predicting or retrieving a single\nsentence from an image. The spatiotemporal information present in videos\nintroduces diversity and complexity regarding the visual content and the\nstructure of associated language descriptions. This review categorizes and\ndescribes the state-of-the-art techniques for the video-to-text problem. It\ncovers the main video-to-text methods and the ways to evaluate their\nperformance. We analyze twenty-six benchmark datasets, showing their drawbacks\nand strengths for the problem requirements. We also show the progress that\nresearchers have made on each dataset, we cover the challenges in the field,\nand we discuss future research directions.", "published": "2021-03-27 02:12:28", "link": "http://arxiv.org/abs/2103.14785v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Unsupervised Self-Training for Sentiment Analysis of Code-Switched Data", "abstract": "Sentiment analysis is an important task in understanding social media content\nlike customer reviews, Twitter and Facebook feeds etc. In multilingual\ncommunities around the world, a large amount of social media text is\ncharacterized by the presence of Code-Switching. Thus, it has become important\nto build models that can handle code-switched data. However, annotated\ncode-switched data is scarce and there is a need for unsupervised models and\nalgorithms. We propose a general framework called Unsupervised Self-Training\nand show its applications for the specific use case of sentiment analysis of\ncode-switched data. We use the power of pre-trained BERT models for\ninitialization and fine-tune them in an unsupervised manner, only using pseudo\nlabels produced by zero-shot transfer. We test our algorithm on multiple\ncode-switched languages and provide a detailed analysis of the learning\ndynamics of the algorithm with the aim of answering the question - `Does our\nunsupervised model understand the Code-Switched languages or does it just learn\nits representations?'. Our unsupervised models compete well with their\nsupervised counterparts, with their performance reaching within 1-7\\% (weighted\nF1 scores) when compared to supervised models trained for a two class problem.", "published": "2021-03-27 03:23:12", "link": "http://arxiv.org/abs/2103.14797v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LSTM Based Sentiment Analysis for Cryptocurrency Prediction", "abstract": "Recent studies in big data analytics and natural language processing develop\nautomatic techniques in analyzing sentiment in the social media information. In\naddition, the growing user base of social media and the high volume of posts\nalso provide valuable sentiment information to predict the price fluctuation of\nthe cryptocurrency. This research is directed to predicting the volatile price\nmovement of cryptocurrency by analyzing the sentiment in social media and\nfinding the correlation between them. While previous work has been developed to\nanalyze sentiment in English social media posts, we propose a method to\nidentify the sentiment of the Chinese social media posts from the most popular\nChinese social media platform Sina-Weibo. We develop the pipeline to capture\nWeibo posts, describe the creation of the crypto-specific sentiment dictionary,\nand propose a long short-term memory (LSTM) based recurrent neural network\nalong with the historical cryptocurrency price movement to predict the price\ntrend for future time frames. The conducted experiments demonstrate the\nproposed approach outperforms the state of the art auto regressive based model\nby 18.5% in precision and 15.4% in recall.", "published": "2021-03-27 04:08:37", "link": "http://arxiv.org/abs/2103.14804v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "You Can Do Better! If You Elaborate the Reason When Making Prediction", "abstract": "Neural predictive models have achieved remarkable performance improvements in\nvarious natural language processing tasks. However, most neural predictive\nmodels suffer from the lack of explainability of predictions, limiting their\npractical utility. This paper proposes a neural predictive approach to make a\nprediction and generate its corresponding explanation simultaneously. It\nleverages the knowledge entailed in explanations as an additional distillation\nsignal for more efficient learning. We conduct a preliminary study on Chinese\nmedical multiple-choice question answering, English natural language inference,\nand commonsense question answering tasks. The experimental results show that\nthe proposed approach can generate reasonable explanations for its predictions\neven with a small-scale training corpus. The proposed method also achieves\nimproved prediction accuracy on three datasets, which indicates that making\npredictions can benefit from generating the explanation in the decision\nprocess.", "published": "2021-03-27 14:55:19", "link": "http://arxiv.org/abs/2103.14919v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Machine Learning Meets Natural Language Processing -- The story so far", "abstract": "Natural Language Processing (NLP) has evolved significantly over the last\ndecade. This paper highlights the most important milestones of this period\nwhile trying to pinpoint the contribution of each individual model and\nalgorithm to the overall progress. Furthermore, it focuses on issues still\nremaining to be solved, emphasizing the groundbreaking proposals of\nTransformers, BERT, and all the similar attention-based models.", "published": "2021-03-27 16:41:34", "link": "http://arxiv.org/abs/2104.10213v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.5"], "primary_category": "cs.CL"}
{"title": "Explaining the Road Not Taken", "abstract": "It is unclear if existing interpretations of deep neural network models\nrespond effectively to the needs of users. This paper summarizes the common\nforms of explanations (such as feature attribution, decision rules, or probes)\nused in over 200 recent papers about natural language processing (NLP), and\ncompares them against user questions collected in the XAI Question Bank. We\nfound that although users are interested in explanations for the road not taken\n-- namely, why the model chose one result and not a well-defined, seemly\nsimilar legitimate counterpart -- most model interpretations cannot answer\nthese questions.", "published": "2021-03-27 19:47:06", "link": "http://arxiv.org/abs/2103.14973v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On TasNet for Low-Latency Single-Speaker Speech Enhancement", "abstract": "In recent years, speech processing algorithms have seen tremendous progress\nprimarily due to the deep learning renaissance. This is especially true for\nspeech separation where the time-domain audio separation network (TasNet) has\nled to significant improvements. However, for the related task of\nsingle-speaker speech enhancement, which is of obvious importance, it is yet\nunknown, if the TasNet architecture is equally successful. In this paper, we\nshow that TasNet improves state-of-the-art also for speech enhancement, and\nthat the largest gains are achieved for modulated noise sources such as speech.\nFurthermore, we show that TasNet learns an efficient inner-domain\nrepresentation, where target and noise signal components are highly separable.\nThis is especially true for noise in terms of interfering speech signals, which\nmight explain why TasNet performs so well on the separation task. Additionally,\nwe show that TasNet performs poorly for large frame hops and conjecture that\naliasing might be the main cause of this performance drop. Finally, we show\nthat TasNet consistently outperforms a state-of-the-art single-speaker speech\nenhancement system.", "published": "2021-03-27 11:29:59", "link": "http://arxiv.org/abs/2103.14882v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Scalable and Efficient Neural Speech Coding: A Hybrid Design", "abstract": "We present a scalable and efficient neural waveform coding system for speech\ncompression. We formulate the speech coding problem as an autoencoding task,\nwhere a convolutional neural network (CNN) performs encoding and decoding as a\nneural waveform codec (NWC) during its feedforward routine. The proposed NWC\nalso defines quantization and entropy coding as a trainable module, so the\ncoding artifacts and bitrate control are handled during the optimization\nprocess. We achieve efficiency by introducing compact model components to NWC,\nsuch as gated residual networks and depthwise separable convolution.\nFurthermore, the proposed models are with a scalable architecture, cross-module\nresidual learning (CMRL), to cover a wide range of bitrates. To this end, we\nemploy the residual coding concept to concatenate multiple NWC autoencoding\nmodules, where each NWC module performs residual coding to restore any\nreconstruction loss that its preceding modules have created. CMRL can scale\ndown to cover lower bitrates as well, for which it employs linear predictive\ncoding (LPC) module as its first autoencoder. The hybrid design integrates LPC\nand NWC by redefining LPC's quantization as a differentiable process, making\nthe system training an end-to-end manner. The decoder of proposed system is\nwith either one NWC (0.12 million parameters) in low to medium bitrate ranges\n(12 to 20 kbps) or two NWCs in the high bitrate (32 kbps). Although the\ndecoding complexity is not yet as low as that of conventional speech codecs, it\nis significantly reduced from that of other neural speech coders, such as a\nWaveNet-based vocoder. For wide-band speech coding quality, our system yields\ncomparable or superior performance to AMR-WB and Opus on TIMIT test utterances\nat low and medium bitrates. The proposed system can scale up to higher bitrates\nto achieve near transparent performance.", "published": "2021-03-27 00:10:16", "link": "http://arxiv.org/abs/2103.14776v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Feature-based Representation for Violin Bridge Admittances", "abstract": "Frequency Response Functions (FRFs) are one of the cornerstones of musical\nacoustic experimental research. They describe the way in which musical\ninstruments vibrate in a wide range of frequencies and are used to predict and\nunderstand the acoustic differences between them. In the specific case of\nstringed musical instruments such as violins, FRFs evaluated at the bridge are\nknown to capture the overall body vibration. These indicators, also called\nbridge admittances, are widely used in the literature for comparative analyses.\nHowever, due to their complex structure they are rather difficult to\nquantitatively compare and study. In this manuscript we present a way to\nquantify differences between FRFs, in particular violin bridge admittances,\nthat separates the effects in frequency, amplitude and quality factor of the\nfirst resonance peaks characterizing the responses. This approach allows us to\ndefine a distance between FRFs and clusterise measurements according to this\ndistance. We use two case studies, one based on Finite Element Analysis and\nanother exploiting measurements on real violins, to prove the effectiveness of\nsuch representation. In particular, for simulated bridge admittances the\nproposed distance is able to highlight the different impact of consecutive\nsimulation `steps' on specific vibrational properties and, for real violins,\ngives a first insight on similar styles of making, as well as opposite ones.", "published": "2021-03-27 12:53:57", "link": "http://arxiv.org/abs/2103.14895v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
