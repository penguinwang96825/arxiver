{"title": "Paragraph-based complex networks: application to document classification\n  and authenticity verification", "abstract": "With the increasing number of texts made available on the Internet, many\napplications have relied on text mining tools to tackle a diversity of\nproblems. A relevant model to represent texts is the so-called word adjacency\n(co-occurrence) representation, which is known to capture mainly syntactical\nfeatures of texts.In this study, we introduce a novel network representation\nthat considers the semantic similarity between paragraphs. Two main properties\nof paragraph networks are considered: (i) their ability to incorporate\ncharacteristics that can discriminate real from artificial, shuffled\nmanuscripts and (ii) their ability to capture syntactical and semantic textual\nfeatures. Our results revealed that real texts are organized into communities,\nwhich turned out to be an important feature for discriminating them from\nartificial texts. Interestingly, we have also found that, differently from\ntraditional co-occurrence networks, the adopted representation is able to\ncapture semantic features. Additionally, the proposed framework was employed to\nanalyze the Voynich manuscript, which was found to be compatible with texts\nwritten in natural languages. Taken together, our findings suggest that the\nproposed methodology can be combined with traditional network models to improve\ntext classification tasks.", "published": "2018-06-22 01:58:44", "link": "http://arxiv.org/abs/1806.08467v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation", "abstract": "The variational autoencoder (VAE) imposes a probabilistic distribution\n(typically Gaussian) on the latent space and penalizes the Kullback--Leibler\n(KL) divergence between the posterior and prior. In NLP, VAEs are extremely\ndifficult to train due to the problem of KL collapsing to zero. One has to\nimplement various heuristics such as KL weight annealing and word dropout in a\ncarefully engineered manner to successfully train a VAE for text. In this\npaper, we propose to use the Wasserstein autoencoder (WAE) for probabilistic\nsentence generation, where the encoder could be either stochastic or\ndeterministic. We show theoretically and empirically that, in the original WAE,\nthe stochastically encoded Gaussian distribution tends to become a Dirac-delta\nfunction, and we propose a variant of WAE that encourages the stochasticity of\nthe encoder. Experimental results show that the latent space learned by WAE\nexhibits properties of continuity and smoothness as in VAEs, while\nsimultaneously achieving much higher BLEU scores for sentence reconstruction.", "published": "2018-06-22 01:11:40", "link": "http://arxiv.org/abs/1806.08462v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Training of Speaker Identification Models", "abstract": "We propose an approach for training speaker identification models in a weakly\nsupervised manner. We concentrate on the setting where the training data\nconsists of a set of audio recordings and the speaker annotation is provided\nonly at the recording level. The method uses speaker diarization to find unique\nspeakers in each recording, and i-vectors to project the speech of each speaker\nto a fixed-dimensional vector. A neural network is then trained to map\ni-vectors to speakers, using a special objective function that allows to\noptimize the model using recording-level speaker labels. We report experiments\non two different real-world datasets. On the VoxCeleb dataset, the method\nprovides 94.6% accuracy on a closed set speaker identification task, surpassing\nthe baseline performance by a large margin. On an Estonian broadcast news\ndataset, the method provides 66% time-weighted speaker identification recall at\n93% precision.", "published": "2018-06-22 12:15:35", "link": "http://arxiv.org/abs/1806.08621v1", "categories": ["cs.SD", "cs.CL", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Persistent Hidden States and Nonlinear Transformation for Long\n  Short-Term Memory", "abstract": "Recurrent neural networks (RNNs) have been drawing much attention with great\nsuccess in many applications like speech recognition and neural machine\ntranslation. Long short-term memory (LSTM) is one of the most popular RNN units\nin deep learning applications. LSTM transforms the input and the previous\nhidden states to the next states with the affine transformation, multiplication\noperations and a nonlinear activation function, which makes a good data\nrepresentation for a given task. The affine transformation includes rotation\nand reflection, which change the semantic or syntactic information of\ndimensions in the hidden states. However, considering that a model interprets\nthe output sequence of LSTM over the whole input sequence, the dimensions of\nthe states need to keep the same type of semantic or syntactic information\nregardless of the location in the sequence. In this paper, we propose a simple\nvariant of the LSTM unit, persistent recurrent unit (PRU), where each dimension\nof hidden states keeps persistent information across time, so that the space\nkeeps the same meaning over the whole sequence. In addition, to improve the\nnonlinear transformation power, we add a feedforward layer in the PRU\nstructure. In the experiment, we evaluate our proposed methods with three\ndifferent tasks, and the results confirm that our methods have better\nperformance than the conventional LSTM.", "published": "2018-06-22 16:19:46", "link": "http://arxiv.org/abs/1806.08748v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Combination of Domain Knowledge and Deep Learning for Sentiment Analysis", "abstract": "The emerging technique of deep learning has been widely applied in many\ndifferent areas. However, when adopted in a certain specific domain, this\ntechnique should be combined with domain knowledge to improve efficiency and\naccuracy. In particular, when analyzing the applications of deep learning in\nsentiment analysis, we found that the current approaches are suffering from the\nfollowing drawbacks: (i) the existing works have not paid much attention to the\nimportance of different types of sentiment terms, which is an important concept\nin this area; and (ii) the loss function currently employed does not well\nreflect the degree of error of sentiment misclassification. To overcome such\nproblem, we propose to combine domain knowledge with deep learning. Our\nproposal includes using sentiment scores, learnt by quadratic programming, to\naugment training data; and introducing the penalty matrix for enhancing the\nloss function of cross entropy. When experimented, we achieved a significant\nimprovement in classification results.", "published": "2018-06-22 16:39:37", "link": "http://arxiv.org/abs/1806.08760v3", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Using NLP on news headlines to predict index trends", "abstract": "This paper attempts to provide a state of the art in trend prediction using\nnews headlines. We present the research done on predicting DJIA trends using\nNatural Language Processing. We will explain the different algorithms we have\nused as well as the various embedding techniques attempted. We rely on\nstatistical and deep learning models in order to extract information from the\ncorpuses.", "published": "2018-06-22 15:37:35", "link": "http://arxiv.org/abs/1806.09533v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Variational Prosody Model for Mapping the Context-Sensitive Variation\n  of Functional Prosodic Prototypes", "abstract": "The quest for comprehensive generative models of intonation that link\nlinguistic and paralinguistic functions to prosodic forms has been a\nlongstanding challenge of speech communication research. Traditional intonation\nmodels have given way to the overwhelming performance of deep learning (DL)\ntechniques for training general purpose end-to-end mappings using millions of\ntunable parameters. The shift towards black box machine learning models has\nnonetheless posed the reverse problem -- a compelling need to discover\nknowledge, to explain, visualise and interpret. Our work bridges between a\ncomprehensive generative model of intonation and state-of-the-art DL\ntechniques. We build upon the modelling paradigm of the Superposition of\nFunctional Contours (SFC) model and propose a Variational Prosody Model (VPM)\nthat uses a network of variational contour generators to capture the\ncontext-sensitive variation of the constituent elementary prosodic contours. We\nshow that the VPM can give insight into the intrinsic variability of these\nprosodic prototypes through learning a meaningful prosodic latent space\nrepresentation structure. We also show that the VPM is able to capture prosodic\nphenomena that have multiple dimensions of context based variability. Since it\nis based on the principle of superposition, the VPM does not necessitate the\nuse of specially crafted corpora for the analysis, opening up the possibilities\nof using big data for prosody analysis. In a speech synthesis scenario, the\nmodel can be used to generate a dynamic and natural prosody contour that is\ndevoid of averaging effects.", "published": "2018-06-22 14:14:30", "link": "http://arxiv.org/abs/1806.08685v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Evaluating language models of tonal harmony", "abstract": "This study borrows and extends probabilistic language models from natural\nlanguage processing to discover the syntactic properties of tonal harmony.\nLanguage models come in many shapes and sizes, but their central purpose is\nalways the same: to predict the next event in a sequence of letters, words,\nnotes, or chords. However, few studies employing such models have evaluated the\nmost state-of-the-art architectures using a large-scale corpus of Western tonal\nmusic, instead preferring to use relatively small datasets containing chord\nannotations from contemporary genres like jazz, pop, and rock.\n  Using symbolic representations of prominent instrumental genres from the\ncommon-practice period, this study applies a flexible, data-driven encoding\nscheme to (1) evaluate Finite Context (or n-gram) models and Recurrent Neural\nNetworks (RNNs) in a chord prediction task; (2) compare predictive accuracy\nfrom the best-performing models for chord onsets from each of the selected\ndatasets; and (3) explain differences between the two model architectures in a\nregression analysis. We find that Finite Context models using the Prediction by\nPartial Match (PPM) algorithm outperform RNNs, particularly for the piano\ndatasets, with the regression model suggesting that RNNs struggle with\nparticularly rare chord types.", "published": "2018-06-22 15:18:54", "link": "http://arxiv.org/abs/1806.08724v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-task WaveNet: A Multi-task Generative Model for Statistical\n  Parametric Speech Synthesis without Fundamental Frequency Conditions", "abstract": "This paper introduces an improved generative model for statistical parametric\nspeech synthesis (SPSS) based on WaveNet under a multi-task learning framework.\nDifferent from the original WaveNet model, the proposed Multi-task WaveNet\nemploys the frame-level acoustic feature prediction as the secondary task and\nthe external fundamental frequency prediction model for the original WaveNet\ncan be removed. Therefore the improved WaveNet can generate high-quality speech\nwaveforms only conditioned on linguistic features. Multi-task WaveNet can\nproduce more natural and expressive speech by addressing the pitch prediction\nerror accumulation issue and possesses more succinct inference procedures than\nthe original WaveNet. Experimental results prove that the SPSS method proposed\nin this paper can achieve better performance than the state-of-the-art approach\nutilizing the original WaveNet in both objective and subjective preference\ntests.", "published": "2018-06-22 12:12:54", "link": "http://arxiv.org/abs/1806.08619v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A Predictive Model for Music Based on Learned Interval Representations", "abstract": "Connectionist sequence models (e.g., RNNs) applied to musical sequences\nsuffer from two known problems: First, they have strictly \"absolute pitch\nperception\". Therefore, they fail to generalize over musical concepts which are\ncommonly perceived in terms of relative distances between pitches (e.g.,\nmelodies, scale types, modes, cadences, or chord types). Second, they fall\nshort of capturing the concepts of repetition and musical form. In this paper\nwe introduce the recurrent gated autoencoder (RGAE), a recurrent neural network\nwhich learns and operates on interval representations of musical sequences. The\nrelative pitch modeling increases generalization and reduces sparsity in the\ninput data. Furthermore, it can learn sequences of copy-and-shift operations\n(i.e. chromatically transposed copies of musical fragments)---a promising\ncapability for learning musical repetition structure. We show that the RGAE\nimproves the state of the art for general connectionist sequence models in\nlearning to predict monophonic melodies, and that ensembles of relative and\nabsolute music processing models improve the results appreciably. Furthermore,\nwe show that the relative pitch processing of the RGAE naturally facilitates\nthe learning and the generation of sequences of copy-and-shift operations,\nwherefore the RGAE greatly outperforms a common absolute pitch recurrent neural\nnetwork on this task.", "published": "2018-06-22 14:17:04", "link": "http://arxiv.org/abs/1806.08686v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
