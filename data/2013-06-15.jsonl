{"title": "Recurrent Convolutional Neural Networks for Discourse Compositionality", "abstract": "The compositionality of meaning extends beyond the single sentence. Just as\nwords combine to form the meaning of sentences, so do sentences combine to form\nthe meaning of paragraphs, dialogues and general discourse. We introduce both a\nsentence model and a discourse model corresponding to the two levels of\ncompositionality. The sentence model adopts convolution as the central\noperation for composing semantic vectors and is based on a novel hierarchical\nconvolutional neural network. The discourse model extends the sentence model\nand is based on a recurrent neural network that is conditioned in a novel way\nboth on the current sentence and on the current speaker. The discourse model is\nable to capture both the sequentiality of sentences and the interaction between\ndifferent speakers. Without feature engineering or pretraining and with simple\ngreedy decoding, the discourse model coupled to the sentence model obtains\nstate of the art performance on a dialogue act classification experiment.", "published": "2013-06-15 14:52:17", "link": "http://arxiv.org/abs/1306.3584v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
