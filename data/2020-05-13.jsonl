{"title": "Large Scale Multi-Actor Generative Dialog Modeling", "abstract": "Non-goal oriented dialog agents (i.e. chatbots) aim to produce varying and\nengaging conversations with a user; however, they typically exhibit either\ninconsistent personality across conversations or the average personality of all\nusers. This paper addresses these issues by controlling an agent's persona upon\ngeneration via conditioning on prior conversations of a target actor. In doing\nso, we are able to utilize more abstract patterns within a person's speech and\nbetter emulate them in generated responses. This work introduces the Generative\nConversation Control model, an augmented and fine-tuned GPT-2 language model\nthat conditions on past reference conversations to probabilistically model\nmulti-turn conversations in the actor's persona. We introduce an accompanying\ndata collection procedure to obtain 10.3M conversations from 6 months worth of\nReddit comments. We demonstrate that scaling model sizes from 117M to 8.3B\nparameters yields an improvement from 23.14 to 13.14 perplexity on 1.7M held\nout Reddit conversations. Increasing model scale yielded similar improvements\nin human evaluations that measure preference of model samples to the held out\ntarget distribution in terms of realism (31% increased to 37% preference),\nstyle matching (37% to 42%), grammar and content quality (29% to 42%), and\nconversation coherency (32% to 40%). We find that conditionally modeling past\nconversations improves perplexity by 0.47 in automatic evaluations. Through\nhuman trials we identify positive trends between conditional modeling and style\nmatching and outline steps to further improve persona control.", "published": "2020-05-13 01:56:00", "link": "http://arxiv.org/abs/2005.06114v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Screenplay Quality Assessment: Can We Predict Who Gets Nominated?", "abstract": "Deciding which scripts to turn into movies is a costly and time-consuming\nprocess for filmmakers. Thus, building a tool to aid script selection, an\ninitial phase in movie production, can be very beneficial. Toward that goal, in\nthis work, we present a method to evaluate the quality of a screenplay based on\nlinguistic cues. We address this in a two-fold approach: (1) we define the task\nas predicting nominations of scripts at major film awards with the hypothesis\nthat the peer-recognized scripts should have a greater chance to succeed. (2)\nbased on industry opinions and narratology, we extract and integrate\ndomain-specific features into common classification techniques. We face two\nchallenges (1) scripts are much longer than other document datasets (2)\nnominated scripts are limited and thus difficult to collect. However, with\nnarratology-inspired modeling and domain features, our approach offers clear\nimprovements over strong baselines. Our work provides a new approach for future\nwork in screenplay analysis.", "published": "2020-05-13 02:39:56", "link": "http://arxiv.org/abs/2005.06123v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Response-Anticipated Memory for On-Demand Knowledge Integration in\n  Response Generation", "abstract": "Neural conversation models are known to generate appropriate but\nnon-informative responses in general. A scenario where informativeness can be\nsignificantly enhanced is Conversing by Reading (CbR), where conversations take\nplace with respect to a given external document. In previous work, the external\ndocument is utilized by (1) creating a context-aware document memory that\nintegrates information from the document and the conversational context, and\nthen (2) generating responses referring to the memory. In this paper, we\npropose to create the document memory with some anticipated responses in mind.\nThis is achieved using a teacher-student framework. The teacher is given the\nexternal document, the context, and the ground-truth response, and learns how\nto build a response-aware document memory from three sources of information.\nThe student learns to construct a response-anticipated document memory from the\nfirst two sources, and the teacher's insight on memory creation. Empirical\nresults show that our model outperforms the previous state-of-the-art for the\nCbR task.", "published": "2020-05-13 03:09:58", "link": "http://arxiv.org/abs/2005.06128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning with Latent Structure Refinement for Document-Level Relation\n  Extraction", "abstract": "Document-level relation extraction requires integrating information within\nand across multiple sentences of a document and capturing complex interactions\nbetween inter-sentence entities. However, effective aggregation of relevant\ninformation in the document remains a challenging research question. Existing\napproaches construct static document-level graphs based on syntactic trees,\nco-references or heuristics from the unstructured text to model the\ndependencies. Unlike previous methods that may not be able to capture rich\nnon-local interactions for inference, we propose a novel model that empowers\nthe relational reasoning across sentences by automatically inducing the latent\ndocument-level graph. We further develop a refinement strategy, which enables\nthe model to incrementally aggregate relevant information for multi-hop\nreasoning. Specifically, our model achieves an F1 score of 59.05 on a\nlarge-scale document-level dataset (DocRED), significantly improving over the\nprevious results, and also yields new state-of-the-art results on the CDR and\nGDA dataset. Furthermore, extensive analyses show that the model is able to\ndiscover more accurate inter-sentence relations.", "published": "2020-05-13 13:36:09", "link": "http://arxiv.org/abs/2005.06312v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sanskrit Segmentation Revisited", "abstract": "Computationally analyzing Sanskrit texts requires proper segmentation in the\ninitial stages. There have been various tools developed for Sanskrit text\nsegmentation. Of these, G\\'erard Huet's Reader in the Sanskrit Heritage Engine\nanalyzes the input text and segments it based on the word parameters - phases\nlike iic, ifc, Pr, Subst, etc., and sandhi (or transition) that takes place at\nthe end of a word with the initial part of the next word. And it enlists all\nthe possible solutions differentiating them with the help of the phases. The\nphases and their analyses have their use in the domain of sentential parsers.\nIn segmentation, though, they are not used beyond deciding whether the words\nformed with the phases are morphologically valid. This paper tries to modify\nthe above segmenter by ignoring the phase details (except for a few cases), and\nalso proposes a probability function to prioritize the list of solutions to\nbring up the most valid solutions at the top.", "published": "2020-05-13 15:50:03", "link": "http://arxiv.org/abs/2005.06383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Mixture of $h-1$ Heads is Better than $h$ Heads", "abstract": "Multi-head attentive neural architectures have achieved state-of-the-art\nresults on a variety of natural language processing tasks. Evidence has shown\nthat they are overparameterized; attention heads can be pruned without\nsignificant performance loss. In this work, we instead \"reallocate\" them -- the\nmodel learns to activate different heads on different inputs. Drawing\nconnections between multi-head attention and mixture of experts, we propose the\nmixture of attentive experts model (MAE). MAE is trained using a block\ncoordinate descent algorithm that alternates between updating (1) the\nresponsibilities of the experts and (2) their parameters. Experiments on\nmachine translation and language modeling show that MAE outperforms strong\nbaselines on both tasks. Particularly, on the WMT14 English to German\ntranslation dataset, MAE improves over \"transformer-base\" by 0.8 BLEU, with a\ncomparable number of parameters. Our analysis shows that our model learns to\nspecialize different experts to different inputs.", "published": "2020-05-13 19:05:58", "link": "http://arxiv.org/abs/2005.06537v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Validation and Normalization of DCS corpus using Sanskrit Heritage tools\n  to build a tagged Gold Corpus", "abstract": "The Digital Corpus of Sanskrit records around 650,000 sentences along with\ntheir morphological and lexical tagging. But inconsistencies in morphological\nanalysis, and in providing crucial information like the segmented word, urges\nthe need for standardization and validation of this corpus. Automating the\nvalidation process requires efficient analyzers which also provide the missing\ninformation. The Sanskrit Heritage Engine's Reader produces all possible\nsegmentations with morphological and lexical analyses. Aligning these systems\nwould help us in recording the linguistic differences, which can be used to\nupdate these systems to produce standardized results and will also provide a\nGold corpus tagged with complete morphological and lexical information along\nwith the segmented words. Krishna et al. (2017) aligned 115,000 sentences,\nconsidering some of the linguistic differences. As both these systems have\nevolved significantly, the alignment is done again considering all the\nremaining linguistic differences between these systems. This paper describes\nthe modified alignment process in detail and records the additional linguistic\ndifferences observed.\n  Reference: Amrith Krishna, Pavankumar Satuluri, and Pawan Goyal. 2017. A\ndataset for Sanskrit word segmentation. In Proceedings of the Joint SIGHUM\nWorkshop on Computational Linguistics for Cultural Heritage, Social Sciences,\nHumanities and Literature, page 105-114. Association for Computational\nLinguistics, August.", "published": "2020-05-13 19:23:43", "link": "http://arxiv.org/abs/2005.06545v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Dialect Identification in the Wild", "abstract": "We present QADI, an automatically collected dataset of tweets belonging to a\nwide range of country-level Arabic dialects -covering 18 different countries in\nthe Middle East and North Africa region. Our method for building this dataset\nrelies on applying multiple filters to identify users who belong to different\ncountries based on their account descriptions and to eliminate tweets that are\neither written in Modern Standard Arabic or contain inappropriate language. The\nresultant dataset contains 540k tweets from 2,525 users who are evenly\ndistributed across 18 Arab countries. Using intrinsic evaluation, we show that\nthe labels of a set of randomly selected tweets are 91.5% accurate. For\nextrinsic evaluation, we are able to build effective country-level dialect\nidentification on tweets with a macro-averaged F1-score of 60.6% across 18\nclasses.", "published": "2020-05-13 19:46:41", "link": "http://arxiv.org/abs/2005.06557v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-Level Event Role Filler Extraction using Multi-Granularity\n  Contextualized Encoding", "abstract": "Few works in the literature of event extraction have gone beyond individual\nsentences to make extraction decisions. This is problematic when the\ninformation needed to recognize an event argument is spread across multiple\nsentences. We argue that document-level event extraction is a difficult task\nsince it requires a view of a larger context to determine which spans of text\ncorrespond to event role fillers. We first investigate how end-to-end neural\nsequence models (with pre-trained language model representations) perform on\ndocument-level role filler extraction, as well as how the length of context\ncaptured affects the models' performance. To dynamically aggregate information\ncaptured by neural representations learned at different levels of granularity\n(e.g., the sentence- and paragraph-level), we propose a novel multi-granularity\nreader. We evaluate our models on the MUC-4 event extraction dataset, and show\nthat our best system performs substantially better than prior work. We also\nreport findings on the relationship between context length and neural model\nperformance on the task.", "published": "2020-05-13 20:42:17", "link": "http://arxiv.org/abs/2005.06579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PERLEX: A Bilingual Persian-English Gold Dataset for Relation Extraction", "abstract": "Relation extraction is the task of extracting semantic relations between\nentities in a sentence. It is an essential part of some natural language\nprocessing tasks such as information extraction, knowledge extraction, and\nknowledge base population. The main motivations of this research stem from a\nlack of a dataset for relation extraction in the Persian language as well as\nthe necessity of extracting knowledge from the growing big-data in the Persian\nlanguage for different applications. In this paper, we present \"PERLEX\" as the\nfirst Persian dataset for relation extraction, which is an expert-translated\nversion of the \"Semeval-2010-Task-8\" dataset. Moreover, this paper addresses\nPersian relation extraction utilizing state-of-the-art language-agnostic\nalgorithms. We employ six different models for relation extraction on the\nproposed bilingual dataset, including a non-neural model (as the baseline),\nthree neural models, and two deep learning models fed by multilingual-BERT\ncontextual word representations. The experiments result in the maximum f-score\n77.66% (provided by BERTEM-MTB method) as the state-of-the-art of relation\nextraction in the Persian language.", "published": "2020-05-13 21:06:59", "link": "http://arxiv.org/abs/2005.06588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "INFOTABS: Inference on Tables as Semi-structured Data", "abstract": "In this paper, we observe that semi-structured tabulated text is ubiquitous;\nunderstanding them requires not only comprehending the meaning of text\nfragments, but also implicit relationships between them. We argue that such\ndata can prove as a testing ground for understanding how we reason about\ninformation. To study this, we introduce a new dataset called INFOTABS,\ncomprising of human-written textual hypotheses based on premises that are\ntables extracted from Wikipedia info-boxes. Our analysis shows that the\nsemi-structured, multi-domain and heterogeneous nature of the premises admits\ncomplex, multi-faceted reasoning. Experiments reveal that, while human\nannotators agree on the relationships between a table-hypothesis pair, several\nstandard modeling strategies are unsuccessful at the task, suggesting that\nreasoning about tables can pose a difficult modeling challenge.", "published": "2020-05-13 02:07:54", "link": "http://arxiv.org/abs/2005.06117v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Parallel Corpus Filtering via Pre-trained Language Models", "abstract": "Web-crawled data provides a good source of parallel corpora for training\nmachine translation models. It is automatically obtained, but extremely noisy,\nand recent work shows that neural machine translation systems are more\nsensitive to noise than traditional statistical machine translation methods. In\nthis paper, we propose a novel approach to filter out noisy sentence pairs from\nweb-crawled corpora via pre-trained language models. We measure sentence\nparallelism by leveraging the multilingual capability of BERT and use the\nGenerative Pre-training (GPT) language model as a domain filter to balance data\ndomains. We evaluate the proposed method on the WMT 2018 Parallel Corpus\nFiltering shared task, and on our own web-crawled Japanese-Chinese parallel\ncorpus. Our method significantly outperforms baselines and achieves a new\nstate-of-the-art. In an unsupervised setting, our method achieves comparable\nperformance to the top-1 supervised method. We also evaluate on a web-crawled\nJapanese-Chinese parallel corpus that we make publicly available.", "published": "2020-05-13 06:06:23", "link": "http://arxiv.org/abs/2005.06166v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Unstoppable Rise of Computational Linguistics in Deep Learning", "abstract": "In this paper, we trace the history of neural networks applied to natural\nlanguage understanding tasks, and identify key contributions which the nature\nof language has made to the development of neural network architectures. We\nfocus on the importance of variable binding and its instantiation in\nattention-based models, and argue that Transformer is not a sequence model but\nan induced-structure model. This perspective leads to predictions of the\nchallenges facing research in deep learning architectures for natural language\nunderstanding.", "published": "2020-05-13 16:51:02", "link": "http://arxiv.org/abs/2005.06420v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Automatic building of Human-Machine Conversational System to\n  support Maintenance Processes", "abstract": "Companies are dealing with many cognitive changes with the introduction of\nthe Industry 4.0 paradigm. In this constantly changing environment, knowledge\nmanagement is a key factor. Dialog systems, being able to hold a conversation\nwith humans, could support the knowledge management in business environment.\nAlthough, these systems are currently hand-coded and need the intervention of a\nhuman being in writing all the possible questions and answers, and then\nplanning the interactions. This process, besides being time-consuming, is not\nscalable. Conversely, a dialog system, also referred to as chatbot, can be\nbuilt from scratch by simply extracting rules from technical documentation. So,\nthe goal of this research is designing a methodology for automatic building of\nhuman-machine conversational system, able to interact in an industrial\nenvironment. An initial taxonomy, containing entities expected to be found in\nmaintenance manuals, is used to identify the relevant sentences of a manual\nprovided by the company BOBST SA and applying text mining techniques, it is\nautomatically expanded. The final result is a taxonomy network representing the\nentities and their relation, that will be used in future works for managing the\ninteractions of a maintenance chatbot.", "published": "2020-05-13 18:39:00", "link": "http://arxiv.org/abs/2005.06517v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Deep Learning for Political Science", "abstract": "Political science, and social science in general, have traditionally been\nusing computational methods to study areas such as voting behavior, policy\nmaking, international conflict, and international development. More recently,\nincreasingly available quantities of data are being combined with improved\nalgorithms and affordable computational resources to predict, learn, and\ndiscover new insights from data that is large in volume and variety. New\ndevelopments in the areas of machine learning, deep learning, natural language\nprocessing (NLP), and, more generally, artificial intelligence (AI) are opening\nup new opportunities for testing theories and evaluating the impact of\ninterventions and programs in a more dynamic and effective way. Applications\nusing large volumes of structured and unstructured data are becoming common in\ngovernment and industry, and increasingly also in social science research. This\nchapter offers an introduction to such methods drawing examples from political\nscience. Focusing on the areas where the strengths of the methods coincide with\nchallenges in these fields, the chapter first presents an introduction to AI\nand its core technology - machine learning, with its rapidly developing\nsubfield of deep learning. The discussion of deep neural networks is\nillustrated with the NLP tasks that are relevant to political science. The\nlatest advances in deep learning methods for NLP are also reviewed, together\nwith their potential for improving information extraction and pattern\nrecognition from political science texts.", "published": "2020-05-13 19:14:37", "link": "http://arxiv.org/abs/2005.06540v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Rate-Distortion view of human pragmatic reasoning", "abstract": "What computational principles underlie human pragmatic reasoning? A prominent\napproach to pragmatics is the Rational Speech Act (RSA) framework, which\nformulates pragmatic reasoning as probabilistic speakers and listeners\nrecursively reasoning about each other. While RSA enjoys broad empirical\nsupport, it is not yet clear whether the dynamics of such recursive reasoning\nmay be governed by a general optimization principle. Here, we present a novel\nanalysis of the RSA framework that addresses this question. First, we show that\nRSA recursion implements an alternating maximization for optimizing a tradeoff\nbetween expected utility and communicative effort. On that basis, we study the\ndynamics of RSA recursion and disconfirm the conjecture that expected utility\nis guaranteed to improve with recursion depth. Second, we show that RSA can be\ngrounded in Rate-Distortion theory, while maintaining a similar ability to\naccount for human behavior and avoiding a bias of RSA toward random utterance\nproduction. This work furthers the mathematical understanding of RSA models,\nand suggests that general information-theoretic principles may give rise to\nhuman pragmatic reasoning.", "published": "2020-05-13 22:04:27", "link": "http://arxiv.org/abs/2005.06641v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Machine Reading Comprehension: The Role of Contextualized Language\n  Models and Beyond", "abstract": "Machine reading comprehension (MRC) aims to teach machines to read and\ncomprehend human languages, which is a long-standing goal of natural language\nprocessing (NLP). With the burst of deep neural networks and the evolution of\ncontextualized language models (CLMs), the research of MRC has experienced two\nsignificant breakthroughs. MRC and CLM, as a phenomenon, have a great impact on\nthe NLP community. In this survey, we provide a comprehensive and comparative\nreview on MRC covering overall research topics about 1) the origin and\ndevelopment of MRC and CLM, with a particular focus on the role of CLMs; 2) the\nimpact of MRC and CLM to the NLP community; 3) the definition, datasets, and\nevaluation of MRC; 4) general MRC architecture and technical methods in the\nview of two-stage Encoder-Decoder solving architecture from the insights of the\ncognitive process of humans; 5) previous highlights, emerging topics, and our\nempirical analysis, among which we especially focus on what works in different\nperiods of MRC researches. We propose a full-view categorization and new\ntaxonomies on these topics. The primary views we have arrived at are that 1)\nMRC boosts the progress from language processing to understanding; 2) the rapid\nimprovement of MRC systems greatly benefits from the development of CLMs; 3)\nthe theme of MRC is gradually moving from shallow text matching to cognitive\nreasoning.", "published": "2020-05-13 10:58:50", "link": "http://arxiv.org/abs/2005.06249v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mitigating Gender Bias Amplification in Distribution by Posterior\n  Regularization", "abstract": "Advanced machine learning techniques have boosted the performance of natural\nlanguage processing. Nevertheless, recent studies, e.g., Zhao et al. (2017)\nshow that these techniques inadvertently capture the societal bias hidden in\nthe corpus and further amplify it. However, their analysis is conducted only on\nmodels' top predictions. In this paper, we investigate the gender bias\namplification issue from the distribution perspective and demonstrate that the\nbias is amplified in the view of predicted probability distribution over\nlabels. We further propose a bias mitigation approach based on posterior\nregularization. With little performance loss, our method can almost remove the\nbias amplification in the distribution. Our study sheds the light on\nunderstanding the bias amplification.", "published": "2020-05-13 11:07:10", "link": "http://arxiv.org/abs/2005.06251v1", "categories": ["cs.CL", "cs.CV", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards Hate Speech Detection at Large via Deep Generative Modeling", "abstract": "Hate speech detection is a critical problem in social media platforms, being\noften accused for enabling the spread of hatred and igniting physical violence.\nHate speech detection requires overwhelming resources including\nhigh-performance computing for online posts and tweets monitoring as well as\nthousands of human experts for daily screening of suspected posts or tweets.\nRecently, Deep Learning (DL)-based solutions have been proposed for automatic\ndetection of hate speech, using modest-sized training datasets of few thousands\nof hate speech sequences. While these methods perform well on the specific\ndatasets, their ability to detect new hate speech sequences is limited and has\nnot been investigated. Being a data-driven approach, it is well known that DL\nsurpasses other methods whenever a scale-up in train dataset size and diversity\nis achieved. Therefore, we first present a dataset of 1 million realistic hate\nand non-hate sequences, produced by a deep generative language model. We\nfurther utilize the generated dataset to train a well-studied DL-based hate\nspeech detector, and demonstrate consistent and significant performance\nimprovements across five public hate speech datasets. Therefore, the proposed\nsolution enables high sensitivity detection of a very large variety of hate\nspeech sequences, paving the way to a fully automatic solution.", "published": "2020-05-13 15:25:59", "link": "http://arxiv.org/abs/2005.06370v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BIOMRC: A Dataset for Biomedical Machine Reading Comprehension", "abstract": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care\nwas taken to reduce noise, compared to the previous BIOREAD dataset of Pappas\net al. (2018). Experiments show that simple heuristics do not perform well on\nthe new dataset, and that two neural MRC models that had been tested on BIOREAD\nperform much better on BIOMRC, indicating that the new dataset is indeed less\nnoisy or at least that its task is more feasible. Non-expert human performance\nis also higher on the new dataset compared to BIOREAD, and biomedical experts\nperform even better. We also introduce a new BERT-based MRC model, the best\nversion of which substantially outperforms all other methods tested, reaching\nor surpassing the accuracy of biomedical experts in some experiments. We make\nthe new dataset available in three different sizes, also releasing our code,\nand providing a leaderboard.", "published": "2020-05-13 15:38:12", "link": "http://arxiv.org/abs/2005.06376v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "SueNes: A Weakly Supervised Approach to Evaluating Single-Document\n  Summarization via Negative Sampling", "abstract": "Canonical automatic summary evaluation metrics, such as ROUGE, focus on\nlexical similarity which cannot well capture semantics nor linguistic quality\nand require a reference summary which is costly to obtain. Recently, there have\nbeen a growing number of efforts to alleviate either or both of the two\ndrawbacks. In this paper, we present a proof-of-concept study to a weakly\nsupervised summary evaluation approach without the presence of reference\nsummaries. Massive data in existing summarization datasets are transformed for\ntraining by pairing documents with corrupted reference summaries. In\ncross-domain tests, our strategy outperforms baselines with promising\nimprovements, and show a great advantage in gauging linguistic qualities over\nall metrics.", "published": "2020-05-13 15:40:13", "link": "http://arxiv.org/abs/2005.06377v3", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Dense-Caption Matching and Frame-Selection Gating for Temporal\n  Localization in VideoQA", "abstract": "Videos convey rich information. Dynamic spatio-temporal relationships between\npeople/objects, and diverse multimodal events are present in a video clip.\nHence, it is important to develop automated models that can accurately extract\nsuch information from videos. Answering questions on videos is one of the tasks\nwhich can evaluate such AI abilities. In this paper, we propose a video\nquestion answering model which effectively integrates multi-modal input sources\nand finds the temporally relevant information to answer questions.\nSpecifically, we first employ dense image captions to help identify objects and\ntheir detailed salient regions and actions, and hence give the model useful\nextra information (in explicit textual format to allow easier matching) for\nanswering questions. Moreover, our model is also comprised of dual-level\nattention (word/object and frame level), multi-head self/cross-integration for\ndifferent sources (video and dense captions), and gates which pass more\nrelevant information to the classifier. Finally, we also cast the frame\nselection problem as a multi-label classification task and introduce two loss\nfunctions, In-andOut Frame Score Margin (IOFSM) and Balanced Binary\nCross-Entropy (BBCE), to better supervise the model with human importance\nannotations. We evaluate our model on the challenging TVQA dataset, where each\nof our model components provides significant gains, and our overall model\noutperforms the state-of-the-art by a large margin (74.09% versus 70.52%). We\nalso present several word, object, and frame level visualization studies. Our\ncode is publicly available at:\nhttps://github.com/hyounghk/VideoQADenseCapFrameGate-ACL2020", "published": "2020-05-13 16:35:27", "link": "http://arxiv.org/abs/2005.06409v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey on Temporal Reasoning for Temporal Information Extraction from\n  Text (Extended Abstract)", "abstract": "Time is deeply woven into how people perceive, and communicate about the\nworld. Almost unconsciously, we provide our language utterances with temporal\ncues, like verb tenses, and we can hardly produce sentences without such cues.\nExtracting temporal cues from text, and constructing a global temporal view\nabout the order of described events is a major challenge of automatic natural\nlanguage understanding. Temporal reasoning, the process of combining different\ntemporal cues into a coherent temporal view, plays a central role in temporal\ninformation extraction. This article presents a comprehensive survey of the\nresearch from the past decades on temporal reasoning for automatic temporal\ninformation extraction from text, providing a case study on the integration of\nsymbolic reasoning with machine learning-based information extraction systems.", "published": "2020-05-13 18:53:15", "link": "http://arxiv.org/abs/2005.06527v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entity-Enriched Neural Models for Clinical Question Answering", "abstract": "We explore state-of-the-art neural models for question answering on\nelectronic medical records and improve their ability to generalize better on\npreviously unseen (paraphrased) questions at test time. We enable this by\nlearning to predict logical forms as an auxiliary task along with the main task\nof answer span detection. The predicted logical forms also serve as a rationale\nfor the answer. Further, we also incorporate medical entity information in\nthese models via the ERNIE architecture. We train our models on the large-scale\nemrQA dataset and observe that our multi-task entity-enriched models generalize\nto paraphrased questions ~5% better than the baseline BERT model.", "published": "2020-05-13 21:04:29", "link": "http://arxiv.org/abs/2005.06587v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice\n  Conversion", "abstract": "Emotional voice conversion aims to convert the emotion of speech from one\nstate to another while preserving the linguistic content and speaker identity.\nThe prior studies on emotional voice conversion are mostly carried out under\nthe assumption that emotion is speaker-dependent. We consider that there is a\ncommon code between speakers for emotional expression in a spoken language,\ntherefore, a speaker-independent mapping between emotional states is possible.\nIn this paper, we propose a speaker-independent emotional voice conversion\nframework, that can convert anyone's emotion without the need for parallel\ndata. We propose a VAW-GAN based encoder-decoder structure to learn the\nspectrum and prosody mapping. We perform prosody conversion by using continuous\nwavelet transform (CWT) to model the temporal dependencies. We also investigate\nthe use of F0 as an additional input to the decoder to improve emotion\nconversion performance. Experiments show that the proposed speaker-independent\nframework achieves competitive results for both seen and unseen speakers.", "published": "2020-05-13 13:36:34", "link": "http://arxiv.org/abs/2005.07025v3", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DARTS-ASR: Differentiable Architecture Search for Multilingual Speech\n  Recognition and Adaptation", "abstract": "In previous works, only parameter weights of ASR models are optimized under\nfixed-topology architecture. However, the design of successful model\narchitecture has always relied on human experience and intuition. Besides, many\nhyperparameters related to model architecture need to be manually tuned.\nTherefore in this paper, we propose an ASR approach with efficient\ngradient-based architecture search, DARTS-ASR. In order to examine the\ngeneralizability of DARTS-ASR, we apply our approach not only on many languages\nto perform monolingual ASR, but also on a multilingual ASR setting. Following\nprevious works, we conducted experiments on a multilingual dataset, IARPA\nBABEL. The experiment results show that our approach outperformed the baseline\nfixed-topology architecture by 10.2% and 10.0% relative reduction on character\nerror rates under monolingual and multilingual ASR settings respectively.\nFurthermore, we perform some analysis on the searched architectures by\nDARTS-ASR.", "published": "2020-05-13 11:32:27", "link": "http://arxiv.org/abs/2005.07029v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Memory Controlled Sequential Self Attention for Sound Recognition", "abstract": "In this paper we investigate the importance of the extent of memory in\nsequential self attention for sound recognition. We propose to use a memory\ncontrolled sequential self attention mechanism on top of a convolutional\nrecurrent neural network (CRNN) model for polyphonic sound event detection\n(SED). Experiments on the URBAN-SED dataset demonstrate the impact of the\nextent of memory on sound recognition performance with the self attention\ninduced SED model. We extend the proposed idea with a multi-head self attention\nmechanism where each attention head processes the audio embedding with explicit\nattention width values. The proposed use of memory controlled sequential self\nattention offers a way to induce relations among frames of sound event tokens.\nWe show that our memory controlled self attention model achieves an event based\nF -score of 33.92% on the URBAN-SED dataset, outperforming the F -score of\n20.10% reported by the model without self attention.", "published": "2020-05-13 22:29:59", "link": "http://arxiv.org/abs/2005.06650v4", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
