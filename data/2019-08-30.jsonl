{"title": "Dialog Intent Induction with Deep Multi-View Clustering", "abstract": "We introduce the dialog intent induction task and present a novel deep\nmulti-view clustering approach to tackle the problem. Dialog intent induction\naims at discovering user intents from user query utterances in human-human\nconversations such as dialogs between customer support agents and customers.\nMotivated by the intuition that a dialog intent is not only expressed in the\nuser query utterance but also captured in the rest of the dialog, we split a\nconversation into two independent views and exploit multi-view clustering\ntechniques for inducing the dialog intent. In particular, we propose\nalternating-view k-means (AV-KMEANS) for joint multi-view representation\nlearning and clustering analysis. The key innovation is that the instance-view\nrepresentations are updated iteratively by predicting the cluster assignment\nobtained from the alternative view, so that the multi-view representations of\nthe instances lead to similar cluster assignments. Experiments on two public\ndatasets show that AV-KMEANS can induce better dialog intent clusters than\nstate-of-the-art unsupervised representation learning methods and standard\nmulti-view clustering approaches.", "published": "2019-08-30 00:08:06", "link": "http://arxiv.org/abs/1908.11487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension", "abstract": "Multi-choice reading comprehension is a challenging task to select an answer\nfrom a set of candidate options when given passage and question. Previous\napproaches usually only calculate question-aware passage representation and\nignore passage-aware question representation when modeling the relationship\nbetween passage and question, which obviously cannot take the best of\ninformation between passage and question. In this work, we propose dual\nco-matching network (DCMN) which models the relationship among passage,\nquestion and answer options bidirectionally. Besides, inspired by how human\nsolve multi-choice questions, we integrate two reading strategies into our\nmodel: (i) passage sentence selection that finds the most salient supporting\nsentences to answer the question, (ii) answer option interaction that encodes\nthe comparison information between answer options. DCMN integrated with the two\nstrategies (DCMN+) obtains state-of-the-art results on five multi-choice\nreading comprehension datasets which are from different domains: RACE,\nSemEval-2018 Task 11, ROCStories, COIN, MCTest.", "published": "2019-08-30 02:30:28", "link": "http://arxiv.org/abs/1908.11511v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Infer Entities, Properties and their Relations from Clinical\n  Conversations", "abstract": "Recently we proposed the Span Attribute Tagging (SAT) Model (Du et al., 2019)\nto infer clinical entities (e.g., symptoms) and their properties (e.g.,\nduration). It tackles the challenge of large label space and limited training\ndata using a hierarchical two-stage approach that identifies the span of\ninterest in a tagging step and assigns labels to the span in a classification\nstep.\n  We extend the SAT model to jointly infer not only entities and their\nproperties but also relations between them. Most relation extraction models\nrestrict inferring relations between tokens within a few neighboring sentences,\nmainly to avoid high computational complexity. In contrast, our proposed\nRelation-SAT (R-SAT) model is computationally efficient and can infer relations\nover the entire conversation, spanning an average duration of 10 minutes.\n  We evaluate our model on a corpus of clinical conversations. When the\nentities are given, the R-SAT outperforms baselines in identifying relations\nbetween symptoms and their properties by about 32% (0.82 vs 0.62 F-score) and\nby about 50% (0.60 vs 0.41 F-score) on medications and their properties. On the\nmore difficult task of jointly inferring entities and relations, the R-SAT\nmodel achieves a performance of 0.34 and 0.45 for symptoms and medications\nrespectively, which is significantly better than 0.18 and 0.35 for the baseline\nmodel. The contributions of different components of the model are quantified\nusing ablation analysis.", "published": "2019-08-30 05:27:39", "link": "http://arxiv.org/abs/1908.11536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Multi-Action Policy for Task-Oriented Dialogues", "abstract": "Dialogue management (DM) plays a key role in the quality of the interaction\nwith the user in a task-oriented dialogue system. In most existing approaches,\nthe agent predicts only one DM policy action per turn. This significantly\nlimits the expressive power of the conversational agent and introduces unwanted\nturns of interactions that may challenge users' patience. Longer conversations\nalso lead to more errors and the system needs to be more robust to handle them.\nIn this paper, we compare the performance of several models on the task of\npredicting multiple acts for each turn. A novel policy model is proposed based\non a recurrent cell called gated Continue-Act-Slots (gCAS) that overcomes the\nlimitations of the existing models. Experimental results show that gCAS\noutperforms other approaches. The code is available at\nhttps://leishu02.github.io/", "published": "2019-08-30 06:15:35", "link": "http://arxiv.org/abs/1908.11546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detect Camouflaged Spam Content via StoneSkipping: Graph and Text Joint\n  Embedding for Chinese Character Variation Representation", "abstract": "The task of Chinese text spam detection is very challenging due to both glyph\nand phonetic variations of Chinese characters. This paper proposes a novel\nframework to jointly model Chinese variational, semantic, and contextualized\nrepresentations for Chinese text spam detection task. In particular, a\nVariation Family-enhanced Graph Embedding (VFGE) algorithm is designed based on\na Chinese character variation graph. The VFGE can learn both the graph\nembeddings of the Chinese characters (local) and the latent variation families\n(global). Furthermore, an enhanced bidirectional language model, with a\ncombination gate function and an aggregation learning function, is proposed to\nintegrate the graph and text information while capturing the sequential\ninformation. Extensive experiments have been conducted on both SMS and review\ndatasets, to show the proposed method outperforms a series of state-of-the-art\nmodels for Chinese spam detection.", "published": "2019-08-30 06:38:55", "link": "http://arxiv.org/abs/1908.11561v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Online influence, offline violence: Language Use on YouTube surrounding\n  the 'Unite the Right' rally", "abstract": "The media frequently describes the 2017 Charlottesville 'Unite the Right'\nrally as a turning point for the alt-right and white supremacist movements.\nSocial movement theory suggests that the media attention and public discourse\nconcerning the rally may have influenced the alt-right, but this has yet to be\nempirically tested. The current study investigates whether there are\ndifferences in language use between 7,142 alt-right and progressive YouTube\nchannels, in addition to measuring possible changes as a result of the rally.\nTo do so, we create structural topic models and measure bigram proportions in\nvideo transcripts, spanning eight weeks before to eight weeks after the rally.\nWe observe differences in topics between the two groups, with the 'alternative\ninfluencers' for example discussing topics related to race and free speech to\nan increasing and larger extent than progressive channels. We also observe\nstructural breakpoints in the use of bigrams at the time of the rally,\nsuggesting there are changes in language use within the two groups as a result\nof the rally. While most changes relate to mentions of the rally itself, the\nalternative group also shows an increase in promotion of their YouTube\nchannels. Results are discussed in light of social movement theory, followed by\na discussion of potential implications for understanding the alt-right and\ntheir language use on YouTube.", "published": "2019-08-30 08:58:11", "link": "http://arxiv.org/abs/1908.11599v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-domain Aspect Category Transfer and Detection via Traceable\n  Heterogeneous Graph Representation Learning", "abstract": "Aspect category detection is an essential task for sentiment analysis and\nopinion mining. However, the cost of categorical data labeling, e.g., label the\nreview aspect information for a large number of product domains, can be\ninevitable but unaffordable. In this study, we propose a novel problem,\ncross-domain aspect category transfer and detection, which faces three\nchallenges: various feature spaces, different data distributions, and diverse\noutput spaces. To address these problems, we propose an innovative solution,\nTraceable Heterogeneous Graph Representation Learning (THGRL). Unlike prior\ntext-based aspect detection works, THGRL explores latent domain aspect category\nconnections via massive user behavior information on a heterogeneous graph.\nMoreover, an innovative latent variable \"Walker Tracer\" is introduced to\ncharacterize the global semantic/aspect dependencies and capture the\ninformative vertexes on the random walk paths. By using THGRL, we project\ndifferent domains' feature spaces into a common one, while allowing data\ndistributions and output spaces stay differently. Experiment results show that\nthe proposed method outperforms a series of state-of-the-art baseline models.", "published": "2019-08-30 09:30:38", "link": "http://arxiv.org/abs/1908.11610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Domain Shift in Extractive Text Summarization", "abstract": "Although domain shift has been well explored in many NLP applications, it\nstill has received little attention in the domain of extractive text\nsummarization. As a result, the model is under-utilizing the nature of the\ntraining data due to ignoring the difference in the distribution of training\nsets and shows poor generalization on the unseen domain.\n  With the above limitation in mind, in this paper, we first extend the\nconventional definition of the domain from categories into data sources for the\ntext summarization task. Then we re-purpose a multi-domain summarization\ndataset and verify how the gap between different domains influences the\nperformance of neural summarization models.\n  Furthermore, we investigate four learning strategies and examine their\nabilities to deal with the domain shift problem.\n  Experimental results on three different settings show their different\ncharacteristics in our new testbed.\n  Our source code including \\textit{BERT-based}, \\textit{meta-learning} methods\nfor multi-domain summarization learning and the re-purposed dataset\n\\textsc{Multi-SUM} will be available on our project:\n\\url{http://pfliu.com/TransferSum/}.", "published": "2019-08-30 11:40:14", "link": "http://arxiv.org/abs/1908.11664v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Earlier Isn't Always Better: Sub-aspect Analysis on Corpus and System\n  Biases in Summarization", "abstract": "Despite the recent developments on neural summarization systems, the\nunderlying logic behind the improvements from the systems and its\ncorpus-dependency remains largely unexplored. Position of sentences in the\noriginal text, for example, is a well known bias for news summarization.\nFollowing in the spirit of the claim that summarization is a combination of\nsub-functions, we define three sub-aspects of summarization: position,\nimportance, and diversity and conduct an extensive analysis of the biases of\neach sub-aspect with respect to the domain of nine different summarization\ncorpora (e.g., news, academic papers, meeting minutes, movie script, books,\nposts). We find that while position exhibits substantial bias in news articles,\nthis is not the case, for example, with academic papers and meeting minutes.\nFurthermore, our empirical study shows that different types of summarization\nsystems (e.g., neural-based) are composed of different degrees of the\nsub-aspects. Our study provides useful lessons regarding consideration of\nunderlying sub-aspects when collecting a new summarization dataset or\ndeveloping a new system.", "published": "2019-08-30 13:16:18", "link": "http://arxiv.org/abs/1908.11723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Encoders Help You Disambiguate Word Senses in Neural Machine Translation", "abstract": "Neural machine translation (NMT) has achieved new state-of-the-art\nperformance in translating ambiguous words. However, it is still unclear which\ncomponent dominates the process of disambiguation. In this paper, we explore\nthe ability of NMT encoders and decoders to disambiguate word senses by\nevaluating hidden states and investigating the distributions of self-attention.\nWe train a classifier to predict whether a translation is correct given the\nrepresentation of an ambiguous noun. We find that encoder hidden states\noutperform word embeddings significantly which indicates that encoders\nadequately encode relevant information for disambiguation into hidden states.\nDecoders could provide further relevant information for disambiguation.\nMoreover, the attention weights and attention entropy show that self-attention\ncan detect ambiguous nouns and distribute more attention to the context. Note\nthat this is a revised version. The content related to decoder hidden states\nhas been updated.", "published": "2019-08-30 15:00:19", "link": "http://arxiv.org/abs/1908.11771v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answering Conversational Questions on Structured Data without Logical\n  Forms", "abstract": "We present a novel approach to answering sequential questions based on\nstructured objects such as knowledge bases or tables without using a logical\nform as an intermediate representation. We encode tables as graphs using a\ngraph neural network model based on the Transformer architecture. The answers\nare then selected from the encoded graph using a pointer network. This model is\nappropriate for processing conversations around structured data, where the\nattention mechanism that selects the answers to a question can also be used to\nresolve conversational references. We demonstrate the validity of this approach\nwith competitive results on the Sequential Question Answering (SQA) task (Iyyer\net al., 2017).", "published": "2019-08-30 15:26:44", "link": "http://arxiv.org/abs/1908.11787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Learning with Language Modeling for Question Generation", "abstract": "This paper explores the task of answer-aware questions generation. Based on\nthe attention-based pointer generator model, we propose to incorporate an\nauxiliary task of language modeling to help question generation in a\nhierarchical multi-task learning structure. Our joint-learning model enables\nthe encoder to learn a better representation of the input sequence, which will\nguide the decoder to generate more coherent and fluent questions. On both SQuAD\nand MARCO datasets, our multi-task learning model boosts the performance,\nachieving state-of-the-art results. Moreover, human evaluation further proves\nthe high quality of our generated questions.", "published": "2019-08-30 16:10:20", "link": "http://arxiv.org/abs/1908.11813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase\n  Identification", "abstract": "Most existing work on adversarial data generation focuses on English. For\nexample, PAWS (Paraphrase Adversaries from Word Scrambling) consists of\nchallenging English paraphrase identification pairs from Wikipedia and Quora.\nWe remedy this gap with PAWS-X, a new dataset of 23,659 human translated PAWS\nevaluation pairs in six typologically distinct languages: French, Spanish,\nGerman, Chinese, Japanese, and Korean. We provide baseline numbers for three\nmodels with different capacity to capture non-local context and sentence\nstructure, and using different multilingual training and evaluation regimes.\nMultilingual BERT fine-tuned on PAWS English plus machine-translated data\nperforms the best, with a range of 83.1-90.8 accuracy across the non-English\nlanguages and an average accuracy gain of 23% over the next best model. PAWS-X\nshows the effectiveness of deep, multilingual pre-training while also leaving\nconsiderable headroom as a new challenge to drive multilingual research that\nbetter captures structure and contextual information.", "published": "2019-08-30 16:40:00", "link": "http://arxiv.org/abs/1908.11828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in\n  Online Discussion Forums", "abstract": "In contrast to many decades of research on oral code-switching, the study of\nwritten multilingual productions has only recently enjoyed a surge of interest.\nMany open questions remain regarding the sociolinguistic underpinnings of\nwritten code-switching, and progress has been limited by a lack of suitable\nresources. We introduce a novel, large, and diverse dataset of written\ncode-switched productions, curated from topical threads of multiple bilingual\ncommunities on the Reddit discussion platform, and explore questions that were\nmainly addressed in the context of spoken language thus far. We investigate\nwhether findings in oral code-switching concerning content and style, as well\nas speaker proficiency, are carried over into written code-switching in\ndiscussion forums. The released dataset can further facilitate a range of\nresearch and practical activities.", "published": "2019-08-30 17:12:32", "link": "http://arxiv.org/abs/1908.11841v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adapt or Get Left Behind: Domain Adaptation through BERT Language Model\n  Finetuning for Aspect-Target Sentiment Classification", "abstract": "Aspect-Target Sentiment Classification (ATSC) is a subtask of Aspect-Based\nSentiment Analysis (ABSA), which has many applications e.g. in e-commerce,\nwhere data and insights from reviews can be leveraged to create value for\nbusinesses and customers. Recently, deep transfer-learning methods have been\napplied successfully to a myriad of Natural Language Processing (NLP) tasks,\nincluding ATSC. Building on top of the prominent BERT language model, we\napproach ATSC using a two-step procedure: self-supervised domain-specific BERT\nlanguage model finetuning, followed by supervised task-specific finetuning. Our\nfindings on how to best exploit domain-specific language model finetuning\nenable us to produce new state-of-the-art performance on the SemEval 2014 Task\n4 restaurants dataset. In addition, to explore the real-world robustness of our\nmodels, we perform cross-domain evaluation. We show that a cross-domain adapted\nBERT language model performs significantly better than strong baseline models\nlike vanilla BERT-base and XLNet-base. Finally, we conduct a case study to\ninterpret model prediction errors.", "published": "2019-08-30 17:44:30", "link": "http://arxiv.org/abs/1908.11860v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Handling Syntactic Divergence in Low-resource Machine Translation", "abstract": "Despite impressive empirical successes of neural machine translation (NMT) on\nstandard benchmarks, limited parallel data impedes the application of NMT\nmodels to many language pairs. Data augmentation methods such as\nback-translation make it possible to use monolingual data to help alleviate\nthese issues, but back-translation itself fails in extreme low-resource\nscenarios, especially for syntactically divergent languages. In this paper, we\npropose a simple yet effective solution, whereby target-language sentences are\nre-ordered to match the order of the source and used as an additional source of\ntraining-time supervision. Experiments with simulated low-resource\nJapanese-to-English, and real low-resource Uyghur-to-English scenarios find\nsignificant improvements over other semi-supervised alternatives.", "published": "2019-08-30 19:07:56", "link": "http://arxiv.org/abs/1909.00040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequential Learning of Convolutional Features for Effective Text\n  Classification", "abstract": "Text classification has been one of the major problems in natural language\nprocessing. With the advent of deep learning, convolutional neural network\n(CNN) has been a popular solution to this task. However, CNNs which were first\nproposed for images, face many crucial challenges in the context of text\nprocessing, namely in their elementary blocks: convolution filters and max\npooling. These challenges have largely been overlooked by the most existing CNN\nmodels proposed for text classification. In this paper, we present an\nexperimental study on the fundamental blocks of CNNs in text categorization.\nBased on this critique, we propose Sequential Convolutional Attentive Recurrent\nNetwork (SCARN). The proposed SCARN model utilizes both the advantages of\nrecurrent and convolutional structures efficiently in comparison to previously\nproposed recurrent convolutional models. We test our model on different text\nclassification datasets across tasks like sentiment analysis and question\nclassification. Extensive experiments establish that SCARN outperforms other\nrecurrent convolutional architectures with significantly less parameters.\nFurthermore, SCARN achieves better performance compared to equally large\nvarious deep CNN and LSTM architectures.", "published": "2019-08-30 22:10:52", "link": "http://arxiv.org/abs/1909.00080v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically Inferring Gender Associations from Language", "abstract": "In this paper, we pose the question: do people talk about women and men in\ndifferent ways? We introduce two datasets and a novel integration of approaches\nfor automatically inferring gender associations from language, discovering\ncoherent word clusters, and labeling the clusters for the semantic concepts\nthey represent. The datasets allow us to compare how people write about women\nand men in two different settings - one set draws from celebrity news and the\nother from student reviews of computer science professors. We demonstrate that\nthere are large-scale differences in the ways that people talk about women and\nmen and that these differences vary across domains. Human evaluations show that\nour methods significantly outperform strong baselines.", "published": "2019-08-30 23:27:06", "link": "http://arxiv.org/abs/1909.00091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parsing All: Syntax and Semantics, Dependencies and Spans", "abstract": "Both syntactic and semantic structures are key linguistic contextual clues,\nin which parsing the latter has been well shown beneficial from parsing the\nformer. However, few works ever made an attempt to let semantic parsing help\nsyntactic parsing. As linguistic representation formalisms, both syntax and\nsemantics may be represented in either span (constituent/phrase) or dependency,\non both of which joint learning was also seldom explored. In this paper, we\npropose a novel joint model of syntactic and semantic parsing on both span and\ndependency representations, which incorporates syntactic information\neffectively in the encoder of neural network and benefits from two\nrepresentation formalisms in a uniform way. The experiments show that semantics\nand syntax can benefit each other by optimizing joint objectives. Our single\nmodel achieves new state-of-the-art or competitive results on both span and\ndependency semantic parsing on Propbank benchmarks and both dependency and\nconstituent syntactic parsing on Penn Treebank.", "published": "2019-08-30 03:49:19", "link": "http://arxiv.org/abs/1908.11522v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DialogueGCN: A Graph Convolutional Neural Network for Emotion\n  Recognition in Conversation", "abstract": "Emotion recognition in conversation (ERC) has received much attention,\nlately, from researchers due to its potential widespread applications in\ndiverse areas, such as health-care, education, and human resources. In this\npaper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph\nneural network based approach to ERC. We leverage self and inter-speaker\ndependency of the interlocutors to model conversational context for emotion\nrecognition. Through the graph network, DialogueGCN addresses context\npropagation issues present in the current RNN-based methods. We empirically\nshow that this method alleviates such issues, while outperforming the current\nstate of the art on a number of benchmark emotion classification datasets.", "published": "2019-08-30 05:44:24", "link": "http://arxiv.org/abs/1908.11540v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Pointer Net Parsing", "abstract": "Transition-based top-down parsing with pointer networks has achieved\nstate-of-the-art results in multiple parsing tasks, while having a linear time\ncomplexity. However, the decoder of these parsers has a sequential structure,\nwhich does not yield the most appropriate inductive bias for deriving tree\nstructures. In this paper, we propose hierarchical pointer network parsers, and\napply them to dependency and sentence-level discourse parsing tasks. Our\nresults on standard benchmark datasets demonstrate the effectiveness of our\napproach, outperforming existing methods and setting a new state-of-the-art.", "published": "2019-08-30 07:22:43", "link": "http://arxiv.org/abs/1908.11571v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Latent Part-of-Speech Sequences for Neural Machine Translation", "abstract": "Learning target side syntactic structure has been shown to improve Neural\nMachine Translation (NMT). However, incorporating syntax through latent\nvariables introduces additional complexity in inference, as the models need to\nmarginalize over the latent syntactic structures. To avoid this, models often\nresort to greedy search which only allows them to explore a limited portion of\nthe latent space. In this work, we introduce a new latent variable model,\nLaSyn, that captures the co-dependence between syntax and semantics, while\nallowing for effective and efficient inference over the latent space. LaSyn\ndecouples direct dependence between successive latent variables, which allows\nits decoder to exhaustively search through the latent syntactic choices, while\nkeeping decoding speed proportional to the size of the latent variable\nvocabulary. We implement LaSyn by modifying a transformer-based NMT system and\ndesign a neural expectation maximization algorithm that we regularize with\npart-of-speech information as the latent sequences. Evaluations on four\ndifferent MT tasks show that incorporating target side syntax with LaSyn\nimproves both translation quality, and also provides an opportunity to improve\ndiversity.", "published": "2019-08-30 15:21:28", "link": "http://arxiv.org/abs/1908.11782v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Linguistic Versus Latent Relations for Modeling Coherent Flow in\n  Paragraphs", "abstract": "Generating a long, coherent text such as a paragraph requires a high-level\ncontrol of different levels of relations between sentences (e.g., tense,\ncoreference). We call such a logical connection between sentences as a\n(paragraph) flow. In order to produce a coherent flow of text, we explore two\nforms of intersentential relations in a paragraph: one is a human-created\nlinguistical relation that forms a structure (e.g., discourse tree) and the\nother is a relation from latent representation learned from the sentences\nthemselves. Our two proposed models incorporate each form of relations into\ndocument-level language models: the former is a supervised model that jointly\nlearns a language model as well as discourse relation prediction, and the\nlatter is an unsupervised model that is hierarchically conditioned by a\nrecurrent neural network (RNN) over the latent information. Our proposed models\nwith both forms of relations outperform the baselines in partially conditioned\nparagraph generation task. Our codes and data are publicly available.", "published": "2019-08-30 15:30:11", "link": "http://arxiv.org/abs/1908.11790v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptively Sparse Transformers", "abstract": "Attention mechanisms have become ubiquitous in NLP. Recent architectures,\nnotably the Transformer, learn powerful context-aware word representations\nthrough layered, multi-headed attention. The multiple heads learn diverse types\nof word relationships. However, with standard softmax attention, all attention\nheads are dense, assigning a non-zero weight to all context words. In this\nwork, we introduce the adaptively sparse Transformer, wherein attention heads\nhave flexible, context-dependent sparsity patterns. This sparsity is\naccomplished by replacing softmax with $\\alpha$-entmax: a differentiable\ngeneralization of softmax that allows low-scoring words to receive precisely\nzero weight. Moreover, we derive a method to automatically learn the $\\alpha$\nparameter -- which controls the shape and sparsity of $\\alpha$-entmax --\nallowing attention heads to choose between focused or spread-out behavior. Our\nadaptively sparse Transformer improves interpretability and head diversity when\ncompared to softmax Transformers on machine translation datasets. Findings of\nthe quantitative and qualitative analysis of our approach include that heads in\ndifferent layers learn different sparsity preferences and tend to be more\ndiverse in their attention distributions than softmax Transformers.\nFurthermore, at no cost in accuracy, sparsity in attention heads helps to\nuncover different head specializations.", "published": "2019-08-30 18:06:14", "link": "http://arxiv.org/abs/1909.00015v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Bilingual is At Least Monolingual (BALM): A Novel Translation Algorithm\n  that Encodes Monolingual Priors", "abstract": "State-of-the-art machine translation (MT) models do not use knowledge of any\nsingle language's structure; this is the equivalent of asking someone to\ntranslate from English to German while knowing neither language. BALM is a\nframework incorporates monolingual priors into an MT pipeline; by casting input\nand output languages into embedded space using BERT, we can solve machine\ntranslation with much simpler models. We find that English-to-German\ntranslation on the Multi30k dataset can be solved with a simple feedforward\nnetwork under the BALM framework with near-SOTA BLEU scores.", "published": "2019-08-30 03:16:10", "link": "http://arxiv.org/abs/1909.01146v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Single Training Dimension Selection for Word Embedding with PCA", "abstract": "In this paper, we present a fast and reliable method based on PCA to select\nthe number of dimensions for word embeddings. First, we train one embedding\nwith a generous upper bound (e.g. 1,000) of dimensions. Then we transform the\nembeddings using PCA and incrementally remove the lesser dimensions one at a\ntime while recording the embeddings' performance on language tasks. Lastly, we\nselect the number of dimensions while balancing model size and accuracy.\nExperiments using various datasets and language tasks demonstrate that we are\nable to train 10 times fewer sets of embeddings while retaining optimal\nperformance. Researchers interested in training the best-performing embeddings\nfor downstream tasks, such as sentiment analysis, question answering and\nhypernym extraction, as well as those interested in embedding compression\nshould find the method helpful.", "published": "2019-08-30 23:19:41", "link": "http://arxiv.org/abs/1909.01761v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Charge-Based Prison Term Prediction with Deep Gating Network", "abstract": "Judgment prediction for legal cases has attracted much research efforts for\nits practice use, of which the ultimate goal is prison term prediction. While\nexisting work merely predicts the total prison term, in reality a defendant is\noften charged with multiple crimes. In this paper, we argue that charge-based\nprison term prediction (CPTP) not only better fits realistic needs, but also\nmakes the total prison term prediction more accurate and interpretable. We\ncollect the first large-scale structured data for CPTP and evaluate several\ncompetitive baselines. Based on the observation that fine-grained feature\nselection is the key to achieving good performance, we propose the Deep Gating\nNetwork (DGN) for charge-specific feature selection and aggregation.\nExperiments show that DGN achieves the state-of-the-art performance.", "published": "2019-08-30 03:44:10", "link": "http://arxiv.org/abs/1908.11521v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Implicit Deep Latent Variable Models for Text Generation", "abstract": "Deep latent variable models (LVM) such as variational auto-encoder (VAE) have\nrecently played an important role in text generation. One key factor is the\nexploitation of smooth latent structures to guide the generation. However, the\nrepresentation power of VAEs is limited due to two reasons: (1) the Gaussian\nassumption is often made on the variational posteriors; and meanwhile (2) a\nnotorious \"posterior collapse\" issue occurs. In this paper, we advocate\nsample-based representations of variational distributions for natural language,\nleading to implicit latent features, which can provide flexible representation\npower compared with Gaussian-based posteriors. We further develop an LVM to\ndirectly match the aggregated posterior to the prior. It can be viewed as a\nnatural extension of VAEs with a regularization of maximizing mutual\ninformation, mitigating the \"posterior collapse\" issue. We demonstrate the\neffectiveness and versatility of our models in various text generation\nscenarios, including language modeling, unaligned style transfer, and dialog\nresponse generation. The source code to reproduce our experimental results is\navailable on GitHub.", "published": "2019-08-30 04:12:08", "link": "http://arxiv.org/abs/1908.11527v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Initial investigation of an encoder-decoder end-to-end TTS framework\n  using marginalization of monotonic hard latent alignments", "abstract": "End-to-end text-to-speech (TTS) synthesis is a method that directly converts\ninput text to output acoustic features using a single network. A recent advance\nof end-to-end TTS is due to a key technique called attention mechanisms, and\nall successful methods proposed so far have been based on soft attention\nmechanisms. However, although network structures are becoming increasingly\ncomplex, end-to-end TTS systems with soft attention mechanisms may still fail\nto learn and to predict accurate alignment between the input and output. This\nmay be because the soft attention mechanisms are too flexible. Therefore, we\npropose an approach that has more explicit but natural constraints suitable for\nspeech signals to make alignment learning and prediction of end-to-end TTS\nsystems more robust. The proposed system, with the constrained alignment scheme\nborrowed from segment-to-segment neural transduction (SSNT), directly\ncalculates the joint probability of acoustic features and alignment given an\ninput text. The alignment is designed to be hard and monotonically increase by\nconsidering the speech nature, and it is treated as a latent variable and\nmarginalized during training. During prediction, both the alignment and\nacoustic features can be generated from the probabilistic distributions. The\nadvantages of our approach are that we can simplify many modules for the soft\nattention and that we can train the end-to-end TTS model using a single\nlikelihood function. As far as we know, our approach is the first end-to-end\nTTS without a soft attention mechanism.", "published": "2019-08-30 05:00:06", "link": "http://arxiv.org/abs/1908.11535v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "On Laughter and Speech-Laugh, Based on Observations of Child-Robot\n  Interaction", "abstract": "In this article, we study laughter found in child-robot interaction where it\nhad not been prompted intentionally. Different types of laughter and\nspeech-laugh are annotated and processed. In a descriptive part, we report on\nthe position of laughter and speech-laugh in syntax and dialogue structure, and\non communicative functions. In a second part, we report on automatic\nclassification performance and on acoustic characteristics, based on extensive\nfeature selection procedures.", "published": "2019-08-30 08:32:10", "link": "http://arxiv.org/abs/1908.11593v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "68T10"], "primary_category": "cs.CL"}
{"title": "Autoregressive Text Generation Beyond Feedback Loops", "abstract": "Autoregressive state transitions, where predictions are conditioned on past\npredictions, are the predominant choice for both deterministic and stochastic\nsequential models. However, autoregressive feedback exposes the evolution of\nthe hidden state trajectory to potential biases from well-known train-test\ndiscrepancies. In this paper, we combine a latent state space model with a CRF\nobservation model. We argue that such autoregressive observation models form an\ninteresting middle ground that expresses local correlations on the word level\nbut keeps the state evolution non-autoregressive. On unconditional sentence\ngeneration we show performance improvements compared to RNN and GAN baselines\nwhile avoiding some prototypical failure modes of autoregressive models.", "published": "2019-08-30 11:31:07", "link": "http://arxiv.org/abs/1908.11658v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "abstract": "The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.", "published": "2019-08-30 13:12:21", "link": "http://arxiv.org/abs/1908.11722v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Approximating Stacked and Bidirectional Recurrent Architectures with the\n  Delayed Recurrent Neural Network", "abstract": "Recent work has shown that topological enhancements to recurrent neural\nnetworks (RNNs) can increase their expressiveness and representational\ncapacity. Two popular enhancements are stacked RNNs, which increases the\ncapacity for learning non-linear functions, and bidirectional processing, which\nexploits acausal information in a sequence. In this work, we explore the\ndelayed-RNN, which is a single-layer RNN that has a delay between the input and\noutput. We prove that a weight-constrained version of the delayed-RNN is\nequivalent to a stacked-RNN. We also show that the delay gives rise to partial\nacausality, much like bidirectional networks. Synthetic experiments confirm\nthat the delayed-RNN can mimic bidirectional networks, solving some acausal\ntasks similarly, and outperforming them in others. Moreover, we show similar\nperformance to bidirectional networks in a real-world natural language\nprocessing task. These results suggest that delayed-RNNs can approximate\ntopologies including stacked RNNs, bidirectional RNNs, and stacked\nbidirectional RNNs - but with equivalent or faster runtimes for the\ndelayed-RNNs.", "published": "2019-08-30 18:18:04", "link": "http://arxiv.org/abs/1909.00021v2", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML", "62M45", "I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic\n  Text Exchange", "abstract": "In this paper, we present a novel method for measurably adjusting the\nsemantics of text while preserving its sentiment and fluency, a task we call\nsemantic text exchange. This is useful for text data augmentation and the\nsemantic correction of text generated by chatbots and virtual assistants. We\nintroduce a pipeline called SMERTI that combines entity replacement, similarity\nmasking, and text infilling. We measure our pipeline's success by its Semantic\nText Exchange Score (STES): the ability to preserve the original text's\nsentiment and fluency while adjusting semantic content. We propose to use\nmasking (replacement) rate threshold as an adjustable parameter to control the\namount of semantic change in the text. Our experiments demonstrate that SMERTI\ncan outperform baseline models on Yelp reviews, Amazon reviews, and news\nheadlines.", "published": "2019-08-30 23:10:28", "link": "http://arxiv.org/abs/1909.00088v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pre-training A Neural Language Model Improves The Sample Efficiency of\n  an Emergency Room Classification Model", "abstract": "To build a French national electronic injury surveillance system based on\nemergency room visits, we aim to develop a coding system to classify their\ncauses from clinical notes in free-text. Supervised learning techniques have\nshown good results in this area but require a large amount of expert annotated\ndataset which is time consuming and costly to obtain. We hypothesize that the\nNatural Language Processing Transformer model incorporating a generative\nself-supervised pre-training step can significantly reduce the required number\nof annotated samples for supervised fine-tuning. In this preliminary study, we\ntest our hypothesis in the simplified problem of predicting whether a visit is\nthe consequence of a traumatic event or not from free-text clinical notes.\nUsing fully re-trained GPT-2 models (without OpenAI pre-trained weights), we\nassess the gain of applying a self-supervised pre-training phase with unlabeled\nnotes prior to the supervised learning task. Results show that the number of\ndata required to achieve a ginve level of performance (AUC>0.95) was reduced by\na factor of 10 when applying pre-training. Namely, for 16 times more data, the\nfully-supervised model achieved an improvement <1% in AUC. To conclude, it is\npossible to adapt a multi-purpose neural language model such as the GPT-2 to\ncreate a powerful tool for classification of free-text notes with only a small\nnumber of labeled samples.", "published": "2019-08-30 17:25:06", "link": "http://arxiv.org/abs/1909.01136v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Maximizing Mutual Information for Tacotron", "abstract": "End-to-end speech synthesis methods already achieve close-to-human quality\nperformance. However compared to HMM-based and NN-based frame-to-frame\nregression methods, they are prone to some synthesis errors, such as missing or\nrepeating words and incomplete synthesis. We attribute the comparatively high\nutterance error rate to the local information preference of conditional\nautoregressive models, and the ill-posed training objective of the model, which\ndescribes mostly the training status of the autoregressive module, but rarely\nthat of the condition module. Inspired by InfoGAN, we propose to maximize the\nmutual information between the text condition and the predicted acoustic\nfeatures to strengthen the dependency between them for CAR speech synthesis\nmodel, which would alleviate the local information preference issue and reduce\nthe utterance error rate. The training objective of maximizing mutual\ninformation can be considered as a metric of the dependency between the\nautoregressive module and the condition module. Experiment results show that\nour method can reduce the utterance error rate.", "published": "2019-08-30 04:03:14", "link": "http://arxiv.org/abs/1909.01145v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tehran Stock Exchange Prediction Using Sentiment Analysis of Online\n  Textual Opinions", "abstract": "In this paper, we investigate the impact of the social media data in\npredicting the Tehran Stock Exchange (TSE) variables for the first time. We\nconsider the closing price and daily return of three different stocks for this\ninvestigation. We collected our social media data from Sahamyab.com/stocktwits\nfor about three months. To extract information from online comments, we propose\na hybrid sentiment analysis approach that combines lexicon-based and\nlearning-based methods. Since lexicons that are available for the Persian\nlanguage are not practical for sentiment analysis in the stock market domain,\nwe built a particular sentiment lexicon for this domain. After designing and\ncalculating daily sentiment indices using the sentiment of the comments, we\nexamine their impact on the baseline models that only use historical market\ndata and propose new predictor models using multi regression analysis. In\naddition to the sentiments, we also examine the comments volume and the users'\nreliabilities. We conclude that the predictability of various stocks in TSE is\ndifferent depending on their attributes. Moreover, we indicate that for\npredicting the closing price only comments volume and for predicting the daily\nreturn both the volume and the sentiment of the comments could be useful. We\ndemonstrate that Users' Trust coefficients have different behaviors toward the\nthree stocks.", "published": "2019-08-30 13:36:21", "link": "http://arxiv.org/abs/1909.03792v2", "categories": ["q-fin.ST", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Multi-Grained Spatio-temporal Modeling for Lip-reading", "abstract": "Lip-reading aims to recognize speech content from videos via visual analysis\nof speakers' lip movements. This is a challenging task due to the existence of\nhomophemes-words which involve identical or highly similar lip movements, as\nwell as diverse lip appearances and motion patterns among the speakers. To\naddress these challenges, we propose a novel lip-reading model which captures\nnot only the nuance between words but also styles of different speakers, by a\nmulti-grained spatio-temporal modeling of the speaking process. Specifically,\nwe first extract both frame-level fine-grained features and short-term\nmedium-grained features by the visual front-end, which are then combined to\nobtain discriminative representations for words with similar phonemes. Next, a\nbidirectional ConvLSTM augmented with temporal attention aggregates\nspatio-temporal information in the entire input sequence, which is expected to\nbe able to capture the coarse-gained patterns of each word and robust to\nvarious conditions in speaker identity, lighting conditions, and so on. By\nmaking full use of the information from different levels in a unified\nframework, the model is not only able to distinguish words with similar\npronunciations, but also becomes robust to appearance changes. We evaluate our\nmethod on two challenging word-level lip-reading benchmarks and show the\neffectiveness of the proposed method, which also demonstrate the above claims.", "published": "2019-08-30 09:50:20", "link": "http://arxiv.org/abs/1908.11618v2", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Enhancements for Audio-only Diarization Systems", "abstract": "In this paper two different approaches to enhance the performance of the most\nchallenging component of a Speaker Diarization system are presented, i.e. the\nspeaker clustering part. A processing step is proposed enhancing the input\nfeatures with a temporal smoothing process combined with nonlinear filtering.\nWe, also, propose improvements on the Deep Embedded Clustering (DEC) algorithm\n-- a nonlinear feature transformation. The performance of these enhancements is\ncompared with different clustering algorithms, such as the UISRNN, k-Means,\nSpectral clustering and x-Means. The evaluation is held on three different\ntasks, i.e. the AMI, DIHARD and an internal meeting transcription task. The\nproposed approaches assume a known number of speakers and time segmentations\nfor the audio files. Since, we focus only on the clustering component of\ndiarization for this work, the segmentation provided is assumed perfect.\nFinally, we present how supervision, in the form of given speaker profiles, can\nfurther improve the overall diarization performance. The proposed enhancements\nyield substantial relative improvements in all 3 tasks, with 20\\% in AMI and\n19\\% better than the best diarization system for DIHARD task, when the number\nof speakers is known.", "published": "2019-08-30 22:33:06", "link": "http://arxiv.org/abs/1909.00082v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Recursive Visual Sound Separation Using Minus-Plus Net", "abstract": "Sounds provide rich semantics, complementary to visual data, for many tasks.\nHowever, in practice, sounds from multiple sources are often mixed together. In\nthis paper we propose a novel framework, referred to as MinusPlus Network\n(MP-Net), for the task of visual sound separation. MP-Net separates sounds\nrecursively in the order of average energy, removing the separated sound from\nthe mixture at the end of each prediction, until the mixture becomes empty or\ncontains only noise. In this way, MP-Net could be applied to sound mixtures\nwith arbitrary numbers and types of sounds. Moreover, while MP-Net keeps\nremoving sounds with large energy from the mixture, sounds with small energy\ncould emerge and become clearer, so that the separation is more accurate.\nCompared to previous methods, MP-Net obtains state-of-the-art results on two\nlarge scale datasets, across mixtures with different types and numbers of\nsounds.", "published": "2019-08-30 09:05:26", "link": "http://arxiv.org/abs/1908.11602v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
