{"title": "A Review of Features for the Discrimination of Twitter Users:\n  Application to the Prediction of Offline Influence", "abstract": "Many works related to Twitter aim at characterizing its users in some way:\nrole on the service (spammers, bots, organizations, etc.), nature of the user\n(socio-professional category, age, etc.), topics of interest , and others.\nHowever, for a given user classification problem, it is very difficult to\nselect a set of appropriate features, because the many features described in\nthe literature are very heterogeneous, with name overlaps and collisions, and\nnumerous very close variants. In this article, we review a wide range of such\nfeatures. In order to present a clear state-of-the-art description, we unify\ntheir names, definitions and relationships, and we propose a new, neutral,\ntypology. We then illustrate the interest of our review by applying a selection\nof these features to the offline influence detection problem. This task\nconsists in identifying users which are influential in real-life, based on\ntheir Twitter account and related data. We show that most features deemed\nefficient to predict online influence, such as the numbers of retweets and\nfollowers, are not relevant to this problem. However, We propose several\ncontent-based approaches to label Twitter users as Influencers or not. We also\nrank them according to a predicted influence level. Our proposals are evaluated\nover the CLEF RepLab 2014 dataset, and outmatch state-of-the-art methods.", "published": "2015-09-22 13:12:34", "link": "http://arxiv.org/abs/1509.06585v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Compositional Explanation of the Pet Fish Phenomenon", "abstract": "The `pet fish' phenomenon is often cited as a paradigm example of the\n`non-compositionality' of human concept use. We show here how this phenomenon\nis naturally accommodated within a compositional distributional model of\nmeaning. This model describes the meaning of a composite concept by accounting\nfor interaction between its constituents via their grammatical roles. We give\ntwo illustrative examples to show how the qualitative phenomena are exhibited.\nWe go on to apply the model to experimental data, and finally discuss\nextensions of the formalism.", "published": "2015-09-22 13:33:34", "link": "http://arxiv.org/abs/1509.06594v1", "categories": ["cs.AI", "cs.CL", "math.CT"], "primary_category": "cs.AI"}
{"title": "Reasoning about Entailment with Neural Attention", "abstract": "While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset.", "published": "2015-09-22 16:08:24", "link": "http://arxiv.org/abs/1509.06664v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "68T50", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
