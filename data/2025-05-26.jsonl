{"title": "Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models", "abstract": "Benefiting from contrastively trained visual encoders on large-scale natural\nscene images, Large Multimodal Models (LMMs) have achieved remarkable\nperformance across various visual perception tasks. However, the inherent\nlimitations of contrastive learning upon summarized descriptions fundamentally\nrestrict the capabilities of models in meticulous reasoning, particularly in\ncrucial scenarios of geometric problem-solving. To enhance geometric\nunderstanding, we propose a novel hard negative contrastive learning framework\nfor the vision encoder, which combines image-based contrastive learning using\ngeneration-based hard negatives created by perturbing diagram generation code,\nand text-based contrastive learning using rule-based negatives derived from\nmodified geometric descriptions and retrieval-based negatives selected based on\ncaption similarity. We train CLIP using our strong negative learning method,\nnamely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for\ngeometric problem-solving. Experiments show that our trained model, MMGeoLM,\nsignificantly outperforms other open-source models on three geometric reasoning\nbenchmarks. Even with a size of 7B, it can rival powerful closed-source models\nlike GPT-4o. We further study the impact of different negative sample\nconstruction methods and the number of negative samples on the geometric\nreasoning performance of LMM, yielding fruitful conclusions. The code and\ndataset are available at https://github.com/THU-KEG/MMGeoLM.", "published": "2025-05-26 15:55:28", "link": "http://arxiv.org/abs/2505.20152v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SeMe: Training-Free Language Model Merging via Semantic Alignment", "abstract": "Despite the remarkable capabilities of Language Models (LMs) across diverse\ntasks, no single model consistently outperforms others, necessitating efficient\nmethods to combine their strengths without expensive retraining. Existing model\nmerging techniques, such as parameter averaging and task-guided fusion, often\nrely on data-dependent computations or fail to preserve internal knowledge,\nlimiting their robustness and scalability. We introduce SeMe (Semantic-based\nMerging), a novel, data-free, and training-free approach that leverages latent\nsemantic alignment to merge LMs at a fine-grained, layer-wise level. Unlike\nprior work, SeMe not only preserves model behaviors but also explicitly\nstabilizes internal knowledge, addressing a critical gap in LM fusion. Through\nextensive experiments across diverse architectures and tasks, we demonstrate\nthat SeMe outperforms existing methods in both performance and efficiency while\neliminating reliance on external data. Our work establishes a new paradigm for\nknowledge-aware model merging and provides insights into the semantic structure\nof LMs, paving the way for more scalable and interpretable model composition.", "published": "2025-05-26 15:45:56", "link": "http://arxiv.org/abs/2505.20144v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "StructEval: Benchmarking LLMs' Capabilities to Generate Structural Outputs", "abstract": "As Large Language Models (LLMs) become integral to software development\nworkflows, their ability to generate structured outputs has become critically\nimportant. We introduce StructEval, a comprehensive benchmark for evaluating\nLLMs' capabilities in producing both non-renderable (JSON, YAML, CSV) and\nrenderable (HTML, React, SVG) structured formats. Unlike prior benchmarks,\nStructEval systematically evaluates structural fidelity across diverse formats\nthrough two paradigms: 1) generation tasks, producing structured output from\nnatural language prompts, and 2) conversion tasks, translating between\nstructured formats. Our benchmark encompasses 18 formats and 44 types of task,\nwith novel metrics for format adherence and structural correctness. Results\nreveal significant performance gaps, even state-of-the-art models like o1-mini\nachieve only 75.58 average score, with open-source alternatives lagging\napproximately 10 points behind. We find generation tasks more challenging than\nconversion tasks, and producing correct visual content more difficult than\ngenerating text-only structures.", "published": "2025-05-26 15:40:42", "link": "http://arxiv.org/abs/2505.20139v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "AweDist: Attention-aware Embedding Distillation for New Input Token Embeddings", "abstract": "Current language models rely on static vocabularies determined at pretraining\ntime, which can lead to decreased performance and increased computational cost\nfor domains underrepresented in the original vocabulary. New tokens can be\nadded to solve this problem, when coupled with a good initialization for their\nnew embeddings. However, existing embedding initialization methods either\nrequire expensive further training or pretraining of additional modules. In\nthis paper, we propose AweDist and show that by distilling representations\nobtained using the original tokenization, we can quickly learn high-quality\ninput embeddings for new tokens. Experimental results with a wide range of\nopen-weight models show that AweDist is able to outperform even strong\nbaselines.", "published": "2025-05-26 15:35:29", "link": "http://arxiv.org/abs/2505.20133v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers", "abstract": "Large language models (LLMs) have been widely integrated into information\nretrieval to advance traditional techniques. However, effectively enabling LLMs\nto seek accurate knowledge in complex tasks remains a challenge due to the\ncomplexity of multi-hop queries as well as the irrelevant retrieved content. To\naddress these limitations, we propose EXSEARCH, an agentic search framework,\nwhere the LLM learns to retrieve useful information as the reasoning unfolds\nthrough a self-incentivized process. At each step, the LLM decides what to\nretrieve (thinking), triggers an external retriever (search), and extracts\nfine-grained evidence (recording) to support next-step reasoning. To enable LLM\nwith this capability, EXSEARCH adopts a Generalized Expectation-Maximization\nalgorithm. In the E-step, the LLM generates multiple search trajectories and\nassigns an importance weight to each; the M-step trains the LLM on them with a\nre-weighted loss function. This creates a self-incentivized loop, where the LLM\niteratively learns from its own generated data, progressively improving itself\nfor search. We further theoretically analyze this training process,\nestablishing convergence guarantees. Extensive experiments on four\nknowledge-intensive benchmarks show that EXSEARCH substantially outperforms\nbaselines, e.g., +7.8% improvement on exact match score. Motivated by these\npromising results, we introduce EXSEARCH-Zoo, an extension that extends our\nmethod to broader scenarios, to facilitate future work.", "published": "2025-05-26 15:27:55", "link": "http://arxiv.org/abs/2505.20128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent", "abstract": "As large language models (LLMs) become integrated into sensitive workflows,\nconcerns grow over their potential to leak confidential information. We propose\nTrojanStego, a novel threat model in which an adversary fine-tunes an LLM to\nembed sensitive context information into natural-looking outputs via linguistic\nsteganography, without requiring explicit control over inference inputs. We\nintroduce a taxonomy outlining risk factors for compromised LLMs, and use it to\nevaluate the risk profile of the threat. To implement TrojanStego, we propose a\npractical encoding scheme based on vocabulary partitioning learnable by LLMs\nvia fine-tuning. Experimental results show that compromised models reliably\ntransmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over\n97% accuracy using majority voting across three generations. Further, they\nmaintain high utility, can evade human detection, and preserve coherence. These\nresults highlight a new class of LLM data exfiltration attacks that are\npassive, covert, practical, and dangerous.", "published": "2025-05-26 15:20:51", "link": "http://arxiv.org/abs/2505.20118v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition in Historical Italian: The Case of Giacomo Leopardi's Zibaldone", "abstract": "The increased digitization of world's textual heritage poses significant\nchallenges for both computer science and literary studies. Overall, there is an\nurgent need of computational techniques able to adapt to the challenges of\nhistorical texts, such as orthographic and spelling variations, fragmentary\nstructure and digitization errors. The rise of large language models (LLMs) has\nrevolutionized natural language processing, suggesting promising applications\nfor Named Entity Recognition (NER) on historical documents. In spite of this,\nno thorough evaluation has been proposed for Italian texts. This research tries\nto fill the gap by proposing a new challenging dataset for entity extraction\nbased on a corpus of 19th century scholarly notes, i.e. Giacomo Leopardi's\nZibaldone (1898), containing 2,899 references to people, locations and literary\nworks. This dataset was used to carry out reproducible experiments with both\ndomain-specific BERT-based models and state-of-the-art LLMs such as LLaMa3.1.\nResults show that instruction-tuned models encounter multiple difficulties\nhandling historical humanistic texts, while fine-tuned NER models offer more\nrobust performance even with challenging entity types such as bibliographic\nreferences.", "published": "2025-05-26 15:16:48", "link": "http://arxiv.org/abs/2505.20113v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ResSVD: Residual Compensated SVD for Large Language Model Compression", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in a\nwide range of downstream natural language processing tasks. Nevertheless, their\nconsiderable sizes and memory demands hinder practical deployment, underscoring\nthe importance of developing efficient compression strategies. Singular value\ndecomposition (SVD) decomposes a matrix into orthogonal components, enabling\nefficient low-rank approximation. This is particularly suitable for LLM\ncompression, where weight matrices often exhibit significant redundancy.\nHowever, current SVD-based methods neglect the residual matrix from truncation,\nresulting in significant truncation loss. Additionally, compressing all layers\nof the model results in severe performance degradation. To overcome these\nlimitations, we propose ResSVD, a new post-training SVD-based LLM compression\nmethod. Specifically, we leverage the residual matrix generated during the\ntruncation process to reduce truncation loss. Moreover, under a fixed overall\ncompression ratio, we selectively compress the last few layers of the model,\nwhich mitigates error propagation and significantly improves the performance of\ncompressed models.Comprehensive evaluations of ResSVD on diverse LLM families\nand multiple benchmark datasets indicate that ResSVD consistently achieves\nsuperior performance over existing counterpart methods, demonstrating its\npractical effectiveness.", "published": "2025-05-26 15:14:54", "link": "http://arxiv.org/abs/2505.20112v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language-Agnostic Suicidal Risk Detection Using Large Language Models", "abstract": "Suicidal risk detection in adolescents is a critical challenge, yet existing\nmethods rely on language-specific models, limiting scalability and\ngeneralization. This study introduces a novel language-agnostic framework for\nsuicidal risk assessment with large language models (LLMs). We generate Chinese\ntranscripts from speech using an ASR model and then employ LLMs with\nprompt-based queries to extract suicidal risk-related features from these\ntranscripts. The extracted features are retained in both Chinese and English to\nenable cross-linguistic analysis and then used to fine-tune corresponding\npretrained language models independently. Experimental results show that our\nmethod achieves performance comparable to direct fine-tuning with ASR results\nor to models trained solely on Chinese suicidal risk-related features,\ndemonstrating its potential to overcome language constraints and improve the\nrobustness of suicidal risk assessment.", "published": "2025-05-26 15:12:10", "link": "http://arxiv.org/abs/2505.20109v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SCIRGC: Multi-Granularity Citation Recommendation and Citation Sentence Preference Alignment", "abstract": "Citations are crucial in scientific research articles as they highlight the\nconnection between the current study and prior work. However, this process is\noften time-consuming for researchers. In this study, we propose the SciRGC\nframework, which aims to automatically recommend citation articles and generate\ncitation sentences for citation locations within articles. The framework\naddresses two key challenges in academic citation generation: 1) how to\naccurately identify the author's citation intent and find relevant citation\npapers, and 2) how to generate high-quality citation sentences that align with\nhuman preferences. We enhance citation recommendation accuracy in the citation\narticle recommendation module by incorporating citation networks and sentiment\nintent, and generate reasoning-based citation sentences in the citation\nsentence generation module by using the original article abstract, local\ncontext, citation intent, and recommended articles as inputs. Additionally, we\npropose a new evaluation metric to fairly assess the quality of generated\ncitation sentences. Through comparisons with baseline models and ablation\nexperiments, the SciRGC framework not only improves the accuracy and relevance\nof citation recommendations but also ensures the appropriateness of the\ngenerated citation sentences in context, providing a valuable tool for\ninterdisciplinary researchers.", "published": "2025-05-26 15:09:10", "link": "http://arxiv.org/abs/2505.20103v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Adaptive Deep Reasoning: Triggering Deep Thinking When Needed", "abstract": "Large language models (LLMs) have shown impressive capabilities in handling\ncomplex tasks through long-chain reasoning. However, the extensive reasoning\nsteps involved can significantly increase computational costs, posing\nchallenges for real-world deployment. Recent efforts have focused on optimizing\nreasoning efficiency by shortening the Chain-of-Thought (CoT) reasoning\nprocesses through various approaches, such as length-aware prompt engineering,\nsupervised fine-tuning on CoT data with variable lengths, and reinforcement\nlearning with length penalties. Although these methods effectively reduce\nreasoning length, they still necessitate an initial reasoning phase. More\nrecent approaches have attempted to integrate long-chain and short-chain\nreasoning abilities into a single model, yet they still rely on manual control\nto toggle between short and long CoT.In this work, we propose a novel approach\nthat autonomously switches between short and long reasoning chains based on\nproblem complexity. Our method begins with supervised fine-tuning of the base\nmodel to equip both long-chain and short-chain reasoning abilities. We then\nemploy reinforcement learning to further balance short and long CoT generation\nwhile maintaining accuracy through two key strategies: first, integrating\nreinforcement learning with a long-short adaptive group-wise reward strategy to\nassess prompt complexity and provide corresponding rewards; second,\nimplementing a logit-based reasoning mode switching loss to optimize the\nmodel's initial token choice, thereby guiding the selection of the reasoning\ntype.Evaluations on mathematical datasets demonstrate that our model can\ndynamically switch between long-chain and short-chain reasoning modes without\nsubstantially sacrificing performance. This advancement enhances the\npracticality of reasoning in large language models for real-world applications.", "published": "2025-05-26 15:08:51", "link": "http://arxiv.org/abs/2505.20101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities", "abstract": "Large language models (LLMs) have demonstrated remarkable performance on\nquestion-answering (QA) tasks because of their superior capabilities in natural\nlanguage understanding and generation. However, LLM-based QA struggles with\ncomplex QA tasks due to poor reasoning capacity, outdated knowledge, and\nhallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs)\nfor QA to address the above challenges. In this survey, we propose a new\nstructured taxonomy that categorizes the methodology of synthesizing LLMs and\nKGs for QA according to the categories of QA and the KG's role when integrating\nwith LLMs. We systematically survey state-of-the-art advances in synthesizing\nLLMs and KGs for QA and compare and analyze these approaches in terms of\nstrength, limitations, and KG requirements. We then align the approaches with\nQA and discuss how these approaches address the main challenges of different\ncomplex QA. Finally, we summarize the advancements, evaluation metrics, and\nbenchmark datasets and highlight open challenges and opportunities.", "published": "2025-05-26 15:08:23", "link": "http://arxiv.org/abs/2505.20099v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "S2LPP: Small-to-Large Prompt Prediction across LLMs", "abstract": "The performance of pre-trained Large Language Models (LLMs) is often\nsensitive to nuances in prompt templates, requiring careful prompt engineering,\nadding costs in terms of computing and human effort. In this study, we present\nexperiments encompassing multiple LLMs variants of varying sizes aimed at\nprobing their preference with different prompts. Through experiments on\nQuestion Answering, we show prompt preference consistency across LLMs of\ndifferent sizes. We also show that this consistency extends to other tasks,\nsuch as Natural Language Inference. Utilizing this consistency, we propose a\nmethod to use a smaller model to select effective prompt templates for a larger\nmodel. We show that our method substantially reduces the cost of prompt\nengineering while consistently matching performance with optimal prompts among\ncandidates. More importantly, our experiment shows the efficacy of our strategy\nacross fourteen LLMs and its applicability to a broad range of NLP tasks,\nhighlighting its robustness", "published": "2025-05-26 15:07:30", "link": "http://arxiv.org/abs/2505.20097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning", "abstract": "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\neither end-to-end fine-tuning or isolated component enhancements, MA-RAG\norchestrates a collaborative set of specialized AI agents: Planner, Step\nDefiner, Extractor, and QA Agents, to tackle each stage of the RAG pipeline\nwith task-aware reasoning. Ambiguities may arise from underspecified queries,\nsparse or indirect evidence in retrieved documents, or the need to integrate\ninformation scattered across multiple sources. MA-RAG mitigates these\nchallenges by decomposing the problem into subtasks, such as query\ndisambiguation, evidence extraction, and answer synthesis, and dispatching them\nto dedicated agents equipped with chain-of-thought prompting. These agents\ncommunicate intermediate reasoning and progressively refine the retrieval and\nsynthesis process. Our design allows fine-grained control over information flow\nwithout any model fine-tuning. Crucially, agents are invoked on demand,\nenabling a dynamic and efficient workflow that avoids unnecessary computation.\nThis modular and reasoning-driven architecture enables MA-RAG to deliver\nrobust, interpretable results. Experiments on multi-hop and ambiguous QA\nbenchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free\nbaselines and rivals fine-tuned systems, validating the effectiveness of\ncollaborative agent-based reasoning in RAG.", "published": "2025-05-26 15:05:18", "link": "http://arxiv.org/abs/2505.20096v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Domain Explainability of Preferences", "abstract": "Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and\nreward models, are central to aligning and evaluating large language models\n(LLMs). Yet, the underlying concepts that drive these preferences remain poorly\nunderstood. In this work, we propose a fully automated end-to-end method for\ngenerating local and global concept-based explanations of preferences across\nmultiple domains. Our method employs an LLM to discover concepts that\ndifferentiate between chosen and rejected responses and represent them with\nconcept-based vectors. To model the relationships between concepts and\npreferences, we propose a white-box Hierarchical Multi-Domain Regression model\nthat captures both domain-general and domain-specific effects. To evaluate our\nmethod, we curate a dataset spanning eight challenging and diverse domains and\nexplain twelve mechanisms. Our method achieves strong preference prediction\nperformance, outperforming baselines while also being explainable.\nAdditionally, we assess explanations in two novel application-driven settings.\nFirst, guiding LLM outputs with concepts from LaaJ explanations yields\nresponses that those judges consistently prefer. Second, prompting LaaJs with\nconcepts explaining humans improves their preference predictions. Together, our\nwork provides a new paradigm for explainability in the era of LLMs.", "published": "2025-05-26 15:01:56", "link": "http://arxiv.org/abs/2505.20088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models", "abstract": "Reasoning-based language models have demonstrated strong performance across\nvarious domains, with the most notable gains seen in mathematical and coding\ntasks. Recent research has shown that reasoning also offers significant\nbenefits for LLM safety and guardrail applications. In this work, we conduct a\ncomprehensive analysis of training reasoning-based guardrail models for content\nmoderation, with an emphasis on generalization to custom safety policies at\ninference time. Our study focuses on two key dimensions: data efficiency and\ninference efficiency. On the data front, we find that reasoning-based models\nexhibit strong sample efficiency, achieving competitive performance with\nsignificantly fewer training examples than their non-reasoning counterparts.\nThis unlocks the potential to repurpose the remaining data for mining\nhigh-value, difficult samples that further enhance model performance. On the\ninference side, we evaluate practical trade-offs by introducing reasoning\nbudgets, examining the impact of reasoning length on latency and accuracy, and\nexploring dual-mode training to allow runtime control over reasoning behavior.\nOur findings will provide practical insights for researchers and developers to\neffectively and efficiently train and deploy reasoning-based guardrails models\nin real-world systems.", "published": "2025-05-26 15:01:37", "link": "http://arxiv.org/abs/2505.20087v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Inference-time Alignment in Continuous Space", "abstract": "Aligning large language models with human feedback at inference time has\nreceived increasing attention due to its flexibility. Existing methods rely on\ngenerating multiple responses from the base policy for search using a reward\nmodel, which can be considered as searching in a discrete response space.\nHowever, these methods struggle to explore informative candidates when the base\npolicy is weak or the candidate set is small, resulting in limited\neffectiveness. In this paper, to address this problem, we propose Simple Energy\nAdaptation ($\\textbf{SEA}$), a simple yet effective algorithm for\ninference-time alignment. In contrast to expensive search over the discrete\nspace, SEA directly adapts original responses from the base policy toward the\noptimal one via gradient-based sampling in continuous latent space.\nSpecifically, SEA formulates inference as an iterative optimization procedure\non an energy function over actions in the continuous space defined by the\noptimal policy, enabling simple and effective alignment. For instance, despite\nits simplicity, SEA outperforms the second-best baseline with a relative\nimprovement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on\nMATH. Our code is publicly available at https://github.com/yuanyige/SEA", "published": "2025-05-26 14:58:33", "link": "http://arxiv.org/abs/2505.20081v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Incentivizing Reasoning from Weak Supervision", "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nreasoning-intensive tasks, but enhancing their reasoning abilities typically\nrelies on either reinforcement learning (RL) with verifiable signals or\nsupervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT)\ndemonstrations, both of which are expensive. In this paper, we study a novel\nproblem of incentivizing the reasoning capacity of LLMs without expensive\nhigh-quality demonstrations and reinforcement learning. We investigate whether\nthe reasoning capabilities of LLMs can be effectively incentivized via\nsupervision from significantly weaker models. We further analyze when and why\nsuch weak supervision succeeds in eliciting reasoning abilities in stronger\nmodels. Our findings show that supervision from significantly weaker reasoners\ncan substantially improve student reasoning performance, recovering close to\n94% of the gains of expensive RL at a fraction of the cost. Experiments across\ndiverse benchmarks and model architectures demonstrate that weak reasoners can\neffectively incentivize reasoning in stronger student models, consistently\nimproving performance across a wide range of reasoning tasks. Our results\nsuggest that this simple weak-to-strong paradigm is a promising and\ngeneralizable alternative to costly methods for incentivizing strong reasoning\ncapabilities at inference-time in LLMs. The code is publicly available at\nhttps://github.com/yuanyige/W2SR.", "published": "2025-05-26 14:51:29", "link": "http://arxiv.org/abs/2505.20072v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SAEs Are Good for Steering -- If You Select the Right Features", "abstract": "Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to\nlearn a decomposition of a model's latent space. This enables useful\napplications such as steering - influencing the output of a model towards a\ndesired concept - without requiring labeled data. Current methods identify SAE\nfeatures to steer by analyzing the input tokens that activate them. However,\nrecent work has highlighted that activations alone do not fully describe the\neffect of a feature on the model's output. In this work, we draw a distinction\nbetween two types of features: input features, which mainly capture patterns in\nthe model's input, and output features, which have a human-understandable\neffect on the model's output. We propose input and output scores to\ncharacterize and locate these types of features, and show that high values for\nboth scores rarely co-occur in the same features. These findings have practical\nimplications: after filtering out features with low output scores, we obtain\n2-3x improvements when steering with SAEs, making them competitive with\nsupervised methods.", "published": "2025-05-26 14:47:59", "link": "http://arxiv.org/abs/2505.20063v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion", "abstract": "Diffusion models have become the mainstream architecture for text-to-image\ngeneration, achieving remarkable progress in visual quality and prompt\ncontrollability. However, current inference pipelines generally lack\ninterpretable semantic supervision and correction mechanisms throughout the\ndenoising process. Most existing approaches rely solely on post-hoc scoring of\nthe final image, prompt filtering, or heuristic resampling strategies-making\nthem ineffective in providing actionable guidance for correcting the generative\ntrajectory. As a result, models often suffer from object confusion, spatial\nerrors, inaccurate counts, and missing semantic elements, severely compromising\nprompt-image alignment and image quality. To tackle these challenges, we\npropose MLLM Semantic-Corrected Ping-Pong-Ahead Diffusion (PPAD), a novel\nframework that, for the first time, introduces a Multimodal Large Language\nModel (MLLM) as a semantic observer during inference. PPAD performs real-time\nanalysis on intermediate generations, identifies latent semantic\ninconsistencies, and translates feedback into controllable signals that\nactively guide the remaining denoising steps. The framework supports both\ninference-only and training-enhanced settings, and performs semantic correction\nat only extremely few diffusion steps, offering strong generality and\nscalability. Extensive experiments demonstrate PPAD's significant improvements.", "published": "2025-05-26 14:42:35", "link": "http://arxiv.org/abs/2505.20053v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "MVP: Multi-source Voice Pathology detection", "abstract": "Voice disorders significantly impact patient quality of life, yet\nnon-invasive automated diagnosis remains under-explored due to both the\nscarcity of pathological voice data, and the variability in recording sources.\nThis work introduces MVP (Multi-source Voice Pathology detection), a novel\napproach that leverages transformers operating directly on raw voice signals.\nWe explore three fusion strategies to combine sentence reading and sustained\nvowel recordings: waveform concatenation, intermediate feature fusion, and\ndecision-level combination. Empirical validation across the German, Portuguese,\nand Italian languages shows that intermediate feature fusion using transformers\nbest captures the complementary characteristics of both recording types. Our\napproach achieves up to +13% AUC improvement over single-source methods.", "published": "2025-05-26 14:38:35", "link": "http://arxiv.org/abs/2505.20050v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks", "abstract": "Large language models (LLMs) show remarkable promise for democratizing\nautomated reasoning by generating formal specifications. However, a fundamental\ntension exists: LLMs are probabilistic, while formal verification demands\ndeterministic guarantees. This paper addresses this epistemological gap by\ncomprehensively investigating failure modes and uncertainty quantification (UQ)\nin LLM-generated formal artifacts. Our systematic evaluation of five frontier\nLLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization's\ndomain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on\nfactual ones), with known UQ techniques like the entropy of token probabilities\nfailing to identify these errors. We introduce a probabilistic context-free\ngrammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty\ntaxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy\nfor logic, AUROC>0.93). Finally, a lightweight fusion of these signals enables\nselective verification, drastically reducing errors (14-100%) with minimal\nabstention, transforming LLM-driven formalization into a reliable engineering\ndiscipline.", "published": "2025-05-26 14:34:04", "link": "http://arxiv.org/abs/2505.20047v1", "categories": ["cs.CL", "cs.AI", "cs.LO", "cs.SE"], "primary_category": "cs.CL"}
{"title": "REARANK: Reasoning Re-ranking Agent via Reinforcement Learning", "abstract": "We present REARANK, a large language model (LLM)-based listwise reasoning\nreranking agent. REARANK explicitly reasons before reranking, significantly\nimproving both performance and interpretability. Leveraging reinforcement\nlearning and data augmentation, REARANK achieves substantial improvements over\nbaseline models across popular information retrieval benchmarks, notably\nrequiring only 179 annotated samples. Built on top of Qwen2.5-7B, our\nREARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and\nout-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT\nbenchmarks. These results underscore the effectiveness of our approach and\nhighlight how reinforcement learning can enhance LLM reasoning capabilities in\nreranking.", "published": "2025-05-26 14:31:48", "link": "http://arxiv.org/abs/2505.20046v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs", "abstract": "Large language models (LLMs) exhibit impressive fluency, but often produce\ncritical errors known as \"hallucinations\". Uncertainty quantification (UQ)\nmethods are a promising tool for coping with this fundamental shortcoming. Yet,\nexisting UQ methods face challenges such as high computational overhead or\nreliance on supervised learning. Here, we aim to bridge this gap. In\nparticular, we propose RAUQ (Recurrent Attention-based Uncertainty\nQuantification), an unsupervised approach that leverages intrinsic attention\npatterns in transformers to detect hallucinations efficiently. By analyzing\nattention weights, we identified a peculiar pattern: drops in attention to\npreceding tokens are systematically observed during incorrect generations for\ncertain \"uncertainty-aware\" heads. RAUQ automatically selects such heads,\nrecurrently aggregates their attention weights and token-level confidences, and\ncomputes sequence-level uncertainty scores in a single forward pass.\nExperiments across 4 LLMs and 12 question answering, summarization, and\ntranslation tasks demonstrate that RAUQ yields excellent results, outperforming\nstate-of-the-art UQ methods using minimal computational overhead (<1% latency).\nMoreover, it requires no task-specific labels and no careful hyperparameter\ntuning, offering plug-and-play real-time hallucination detection in white-box\nLLMs.", "published": "2025-05-26 14:28:37", "link": "http://arxiv.org/abs/2505.20045v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-modal brain encoding models for multi-modal stimuli", "abstract": "Despite participants engaging in unimodal stimuli, such as watching images or\nsilent videos, recent work has demonstrated that multi-modal Transformer models\ncan predict visual brain activity impressively well, even with incongruent\nmodality representations. This raises the question of how accurately these\nmulti-modal models can predict brain activity when participants are engaged in\nmulti-modal stimuli. As these models grow increasingly popular, their use in\nstudying neural activity provides insights into how our brains respond to such\nmulti-modal naturalistic stimuli, i.e., where it separates and integrates\ninformation across modalities through a hierarchy of early sensory regions to\nhigher cognition. We investigate this question by using multiple unimodal and\ntwo types of multi-modal models-cross-modal and jointly pretrained-to determine\nwhich type of model is more relevant to fMRI brain activity when participants\nare engaged in watching movies. We observe that both types of multi-modal\nmodels show improved alignment in several language and visual regions. This\nstudy also helps in identifying which brain regions process unimodal versus\nmulti-modal information. We further investigate the contribution of each\nmodality to multi-modal alignment by carefully removing unimodal features one\nby one from multi-modal representations, and find that there is additional\ninformation beyond the unimodal embeddings that is processed in the visual and\nlanguage regions. Based on this investigation, we find that while for\ncross-modal models, their brain alignment is partially attributed to the video\nmodality; for jointly pretrained models, it is partially attributed to both the\nvideo and audio modalities. This serves as a strong motivation for the\nneuroscience community to investigate the interpretability of these models for\ndeepening our understanding of multi-modal information processing in brain.", "published": "2025-05-26 14:17:08", "link": "http://arxiv.org/abs/2505.20027v1", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "q-bio.NC"}
{"title": "Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking", "abstract": "Autonomous agents, which perceive environments and take actions to achieve\ngoals, have become increasingly feasible with the advancements in large\nlanguage models (LLMs). However, current powerful agents often depend on\nsophisticated prompt engineering combined with closed-source LLMs like GPT-4.\nAlthough training open-source LLMs using expert trajectories from teacher\nmodels has yielded some improvements in agent capabilities, this approach still\nfaces limitations such as performance plateauing and error propagation. To\nmitigate these challenges, we propose STeP, a novel method for improving\nLLM-based agent training. We synthesize self-reflected trajectories that\ninclude reflections and corrections of error steps, which enhance the\neffectiveness of LLM agents in learning from teacher models, enabling them to\nbecome agents capable of self-reflecting and correcting. We also introduce\npartial masking strategy that prevents the LLM from internalizing incorrect or\nsuboptimal steps. Experiments demonstrate that our method improves agent\nperformance across three representative tasks: ALFWorld, WebShop, and SciWorld.\nFor the open-source model LLaMA2-7B-Chat, when trained using self-reflected\ntrajectories constructed with Qwen1.5-110B-Chat as the teacher model, it\nachieves comprehensive improvements with less training data compared to agents\ntrained exclusively on expert trajectories.", "published": "2025-05-26 14:11:12", "link": "http://arxiv.org/abs/2505.20023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TTPA: Token-level Tool-use Preference Alignment Training Framework with Fine-grained Evaluation", "abstract": "Existing tool-learning methods usually rely on supervised fine-tuning, they\noften overlook fine-grained optimization of internal tool call details, leading\nto limitations in preference alignment and error discrimination. To overcome\nthese challenges, we propose Token-level Tool-use Preference Alignment Training\nFramework (TTPA), a training paradigm for constructing token-level tool-use\npreference datasets that align LLMs with fine-grained preferences using a novel\nerror-oriented scoring mechanism. TTPA first introduces reversed dataset\nconstruction, a method for creating high-quality, multi-turn tool-use datasets\nby reversing the generation flow. Additionally, we propose Token-level\nPreference Sampling (TPS) to capture fine-grained preferences by modeling\ntoken-level differences during generation. To address biases in scoring, we\nintroduce the Error-oriented Scoring Mechanism (ESM), which quantifies\ntool-call errors and can be used as a training signal. Extensive experiments on\nthree diverse benchmark datasets demonstrate that TTPA significantly improves\ntool-using performance while showing strong generalization ability across\nmodels and datasets.", "published": "2025-05-26 14:06:02", "link": "http://arxiv.org/abs/2505.20016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the class of coding optimality of human languages and the origins of Zipf's law", "abstract": "Here we present a new class of optimality for coding systems. Members of that\nclass are separated linearly from optimal coding and thus exhibit Zipf's law,\nnamely a power-law distribution of frequency ranks. Whithin that class, Zipf's\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf's law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are separated by a\nlinear function whose slope is the exponent of Zipf's law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. Our findings provide\nsupport for the hypothesis that Zipf's law originates from compression.", "published": "2025-05-26 14:05:45", "link": "http://arxiv.org/abs/2505.20015v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Does Rationale Quality Matter? Enhancing Mental Disorder Detection via Selective Reasoning Distillation", "abstract": "The detection of mental health problems from social media and the\ninterpretation of these results have been extensively explored. Research has\nshown that incorporating clinical symptom information into a model enhances\ndomain expertise, improving its detection and interpretation performance. While\nlarge language models (LLMs) are shown to be effective for generating\nexplanatory rationales in mental health detection, their substantially large\nparameter size and high computational cost limit their practicality. Reasoning\ndistillation transfers this ability to smaller language models (SLMs), but\ninconsistencies in the relevance and domain alignment of LLM-generated\nrationales pose a challenge. This paper investigates how rationale quality\nimpacts SLM performance in mental health detection and explanation generation.\nWe hypothesize that ensuring high-quality and domain-relevant rationales\nenhances the distillation. To this end, we propose a framework that selects\nrationales based on their alignment with expert clinical reasoning. Experiments\nshow that our quality-focused approach significantly enhances SLM performance\nin both mental disorder detection and rationale generation. This work\nhighlights the importance of rationale quality and offers an insightful\nframework for knowledge transfer in mental health applications.", "published": "2025-05-26 14:05:33", "link": "http://arxiv.org/abs/2505.20014v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback", "abstract": "Web agents powered by Large Language Models (LLMs) show promise for\nnext-generation AI, but their limited reasoning in uncertain, dynamic web\nenvironments hinders robust deployment. In this paper, we identify key\nreasoning skills essential for effective web agents, i.e., reflection &\nlookahead, branching, and rollback, and curate trajectory data that exemplifies\nthese abilities by reconstructing the agent's (inference-time) reasoning\nalgorithms into chain-of-thought rationales. We conduct experiments in the\nagent self-improving benchmark, OpenWebVoyager, and demonstrate that distilling\nsalient reasoning patterns into the backbone LLM via simple fine-tuning can\nsubstantially enhance its performance. Our approach yields significant\nimprovements across multiple benchmarks, including WebVoyager, Mind2web-live,\nand SimpleQA (web search), highlighting the potential of targeted reasoning\nskill enhancement for web agents.", "published": "2025-05-26 14:03:37", "link": "http://arxiv.org/abs/2505.20013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixture of LoRA Experts for Low-Resourced Multi-Accent Automatic Speech Recognition", "abstract": "We aim to improve the robustness of Automatic Speech Recognition (ASR)\nsystems against non-native speech, particularly in low-resourced multi-accent\nsettings. We introduce Mixture of Accent-Specific LoRAs (MAS-LoRA), a\nfine-tuning method that leverages a mixture of Low-Rank Adaptation (LoRA)\nexperts, each specialized in a specific accent. This method can be used when\nthe accent is known or unknown at inference time, without the need to fine-tune\nthe model again. Our experiments, conducted using Whisper on the L2-ARCTIC\ncorpus, demonstrate significant improvements in Word Error Rate compared to\nregular LoRA and full fine-tuning when the accent is unknown. When the accent\nis known, the results further improve. Furthermore, MAS-LoRA shows less\ncatastrophic forgetting than the other fine-tuning methods. To the best of our\nknowledge, this is the first use of a mixture of LoRA experts for non-native\nmulti-accent ASR.", "published": "2025-05-26 13:57:24", "link": "http://arxiv.org/abs/2505.20006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents", "abstract": "Large language models (LLMs) are revolutionizing education, with LLM-based\nagents playing a key role in simulating student behavior. A major challenge in\nstudent simulation is modeling the diverse learning patterns of students at\nvarious cognitive levels. However, current LLMs, typically trained as ``helpful\nassistants'', target at generating perfect responses. As a result, they\nstruggle to simulate students with diverse cognitive abilities, as they often\nproduce overly advanced answers, missing the natural imperfections that\ncharacterize student learning and resulting in unrealistic simulations. To\naddress this issue, we propose a training-free framework for student\nsimulation. We begin by constructing a cognitive prototype for each student\nusing a knowledge graph, which captures their understanding of concepts from\npast learning records. This prototype is then mapped to new tasks to predict\nstudent performance. Next, we simulate student solutions based on these\npredictions and iteratively refine them using a beam search method to better\nreplicate realistic mistakes. To validate our approach, we construct the\n\\texttt{Student\\_100} dataset, consisting of $100$ students working on Python\nprogramming and $5,000$ learning records. Experimental results show that our\nmethod consistently outperforms baseline models, achieving $100\\%$ improvement\nin simulation accuracy.", "published": "2025-05-26 13:48:49", "link": "http://arxiv.org/abs/2505.19997v1", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "How Well Do Large Reasoning Models Translate? A Comprehensive Evaluation for Multi-Domain Machine Translation", "abstract": "Large language models (LLMs) have demonstrated strong performance in\ngeneral-purpose machine translation, but their effectiveness in complex,\ndomain-sensitive translation tasks remains underexplored. Recent advancements\nin Large Reasoning Models (LRMs), raise the question of whether structured\nreasoning can enhance translation quality across diverse domains. In this work,\nwe compare the performance of LRMs with traditional LLMs across 15\nrepresentative domains and four translation directions. Our evaluation\nconsiders various factors, including task difficulty, input length, and\nterminology density. We use a combination of automatic metrics and an enhanced\nMQM-based evaluation hierarchy to assess translation quality. Our findings show\nthat LRMs consistently outperform traditional LLMs in semantically complex\ndomains, especially in long-text and high-difficulty translation scenarios.\nMoreover, domain-adaptive prompting strategies further improve performance by\nbetter leveraging the reasoning capabilities of LRMs. These results highlight\nthe potential of structured reasoning in MDMT tasks and provide valuable\ninsights for optimizing translation systems in domain-sensitive contexts.", "published": "2025-05-26 13:43:37", "link": "http://arxiv.org/abs/2505.19987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeepDialogue: A Multi-Turn Emotionally-Rich Spoken Dialogue Dataset", "abstract": "Recent advances in conversational AI have demonstrated impressive\ncapabilities in single-turn responses, yet multi-turn dialogues remain\nchallenging for even the most sophisticated language models. Current dialogue\ndatasets are limited in their emotional range, domain diversity, turn depth,\nand are predominantly text-only, hindering progress in developing more\nhuman-like conversational systems across modalities. To address these\nlimitations, we present DeepDialogue, a large-scale multimodal dataset\ncontaining 40,150 high-quality multi-turn dialogues spanning 41 domains and\nincorporating 20 distinct emotions with coherent emotional progressions. Our\napproach pairs 9 different language models (4B-72B parameters) to generate\n65,600 initial conversations, which we then evaluate through a combination of\nhuman annotation and LLM-based quality filtering. The resulting dataset reveals\nfundamental insights: smaller models fail to maintain coherence beyond 6\ndialogue turns; concrete domains (e.g., \"cars,\" \"travel\") yield more meaningful\nconversations than abstract ones (e.g., \"philosophy\"); and cross-model\ninteractions produce more coherent dialogues than same-model conversations. A\nkey contribution of DeepDialogue is its speech component, where we synthesize\nemotion-consistent voices for all 40,150 dialogues, creating the first\nlarge-scale open-source multimodal dialogue dataset that faithfully preserves\nemotional context across multi-turn conversations.", "published": "2025-05-26 13:37:10", "link": "http://arxiv.org/abs/2505.19978v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Conversational Lexicography: Querying Lexicographic Data on Knowledge Graphs with SPARQL through Natural Language", "abstract": "Knowledge graphs offer an excellent solution for representing the\nlexical-semantic structures of lexicographic data. However, working with the\nSPARQL query language represents a considerable hurdle for many non-expert\nusers who could benefit from the advantages of this technology. This paper\naddresses the challenge of creating natural language interfaces for\nlexicographic data retrieval on knowledge graphs such as Wikidata. We develop a\nmultidimensional taxonomy capturing the complexity of Wikidata's lexicographic\ndata ontology module through four dimensions and create a template-based\ndataset with over 1.2 million mappings from natural language utterances to\nSPARQL queries. Our experiments with GPT-2 (124M), Phi-1.5 (1.3B), and\nGPT-3.5-Turbo reveal significant differences in model capabilities. While all\nmodels perform well on familiar patterns, only GPT-3.5-Turbo demonstrates\nmeaningful generalization capabilities, suggesting that model size and diverse\npre-training are crucial for adaptability in this domain. However, significant\nchallenges remain in achieving robust generalization, handling diverse\nlinguistic data, and developing scalable solutions that can accommodate the\nfull complexity of lexicographic knowledge representation.", "published": "2025-05-26 13:34:39", "link": "http://arxiv.org/abs/2505.19971v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CP-Router: An Uncertainty-Aware Router Between LLM and LRM", "abstract": "Recent advances in Large Reasoning Models (LRMs) have significantly improved\nlong-chain reasoning capabilities over Large Language Models (LLMs). However,\nLRMs often produce unnecessarily lengthy outputs even for simple queries,\nleading to inefficiencies or even accuracy degradation compared to LLMs. To\novercome this, we propose CP-Router, a training-free and model-agnostic routing\nframework that dynamically selects between an LLM and an LRM, demonstrated with\nmultiple-choice question answering (MCQA) prompts. The routing decision is\nguided by the prediction uncertainty estimates derived via Conformal Prediction\n(CP), which provides rigorous coverage guarantees. To further refine the\nuncertainty differentiation across inputs, we introduce Full and Binary Entropy\n(FBE), a novel entropy-based criterion that adaptively selects the appropriate\nCP threshold. Experiments across diverse MCQA benchmarks, including\nmathematics, logical reasoning, and Chinese chemistry, demonstrate that\nCP-Router efficiently reduces token usage while maintaining or even improving\naccuracy compared to using LRM alone. We also extend CP-Router to diverse model\npairings and open-ended QA, where it continues to demonstrate strong\nperformance, validating its generality and robustness.", "published": "2025-05-26 13:33:31", "link": "http://arxiv.org/abs/2505.19970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Limits of Preference Data for Post-Training", "abstract": "Recent progress in strengthening the capabilities of large language models\nhas stemmed from applying reinforcement learning to domains with automatically\nverifiable outcomes. A key question is whether we can similarly use RL to\noptimize for outcomes in domains where evaluating outcomes inherently requires\nhuman feedback; for example, in tasks like deep research and trip planning,\noutcome evaluation is qualitative and there are many possible degrees of\nsuccess. One attractive and scalable modality for collecting human feedback is\npreference data: ordinal rankings (pairwise or $k$-wise) that indicate, for $k$\ngiven outcomes, which one is preferred. In this work, we study a critical\nroadblock: preference data fundamentally and significantly limits outcome-based\noptimization. Even with idealized preference data (infinite, noiseless, and\nonline), the use of ordinal feedback can prevent obtaining even approximately\noptimal solutions. We formalize this impossibility using voting theory, drawing\nan analogy between how a model chooses to answer a query with how voters choose\na candidate to elect. This indicates that grounded human scoring and\nalgorithmic innovations are necessary for extending the success of RL\npost-training to domains demanding human feedback. We also explore why these\nlimitations have disproportionately impacted RLHF when it comes to eliciting\nreasoning behaviors (e.g., backtracking) versus situations where RLHF has been\nhistorically successful (e.g., instruction-tuning and safety training), finding\nthat the limitations of preference data primarily suppress RLHF's ability to\nelicit robust strategies -- a class that encompasses most reasoning behaviors.", "published": "2025-05-26 13:26:15", "link": "http://arxiv.org/abs/2505.19964v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.LG"}
{"title": "MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models", "abstract": "Long Context Understanding (LCU) is a critical area for exploration in\ncurrent large language models (LLMs). However, due to the inherently lengthy\nnature of long-text data, existing LCU benchmarks for LLMs often result in\nprohibitively high evaluation costs, like testing time and inference expenses.\nThrough extensive experimentation, we discover that existing LCU benchmarks\nexhibit significant redundancy, which means the inefficiency in evaluation. In\nthis paper, we propose a concise data compression method tailored for long-text\ndata with sparse information characteristics. By pruning the well-known LCU\nbenchmark LongBench, we create MiniLongBench. This benchmark includes only 237\ntest samples across six major task categories and 21 distinct tasks. Through\nempirical analysis of over 60 LLMs, MiniLongBench achieves an average\nevaluation cost reduced to only 4.5% of the original while maintaining an\naverage rank correlation coefficient of 0.97 with LongBench results. Therefore,\nour MiniLongBench, as a low-cost benchmark, holds great potential to\nsubstantially drive future research into the LCU capabilities of LLMs. See\nhttps://github.com/MilkThink-Lab/MiniLongBench for our code, data and tutorial.", "published": "2025-05-26 13:21:18", "link": "http://arxiv.org/abs/2505.19959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph", "abstract": "Text-to-SQL, which translates a natural language question into an SQL query,\nhas advanced with in-context learning of Large Language Models (LLMs). However,\nexisting methods show little improvement in performance compared to randomly\nchosen demonstrations, and significant performance drops when smaller LLMs\n(e.g., Llama 3.1-8B) are used. This indicates that these methods heavily rely\non the intrinsic capabilities of hyper-scaled LLMs, rather than effectively\nretrieving useful demonstrations. In this paper, we propose a novel approach\nfor effectively retrieving demonstrations and generating SQL queries. We\nconstruct a Deep Contextual Schema Link Graph, which contains key information\nand semantic relationship between a question and its database schema items.\nThis graph-based structure enables effective representation of Text-to-SQL\nsamples and retrieval of useful demonstrations for in-context learning.\nExperimental results on the Spider benchmark demonstrate the effectiveness of\nour approach, showing consistent improvements in SQL generation performance and\nefficiency across both hyper-scaled LLMs and small LLMs. Our code will be\nreleased.", "published": "2025-05-26 13:19:10", "link": "http://arxiv.org/abs/2505.19956v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "abstract": "Recent advancements in AI agents have demonstrated their growing potential to\ndrive and support scientific discovery. In this work, we introduce MLR-Bench, a\ncomprehensive benchmark for evaluating AI agents on open-ended machine learning\nresearch. MLR-Bench includes three key components: (1) 201 research tasks\nsourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2)\nMLR-Judge, an automated evaluation framework combining LLM-based reviewers with\ncarefully designed review rubrics to assess research quality; and (3)\nMLR-Agent, a modular agent scaffold capable of completing research tasks\nthrough four stages: idea generation, proposal formulation, experimentation,\nand paper writing. Our framework supports both stepwise assessment across these\ndistinct research stages, and end-to-end evaluation of the final research\npaper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced\ncoding agent, finding that while LLMs are effective at generating coherent\nideas and well-structured papers, current coding agents frequently (e.g., in\n80% of the cases) produce fabricated or invalidated experimental\nresults--posing a major barrier to scientific reliability. We validate\nMLR-Judge through human evaluation, showing high agreement with expert\nreviewers, supporting its potential as a scalable tool for research evaluation.\nWe open-source MLR-Bench to help the community benchmark, diagnose, and improve\nAI research agents toward trustworthy and transparent scientific discovery.", "published": "2025-05-26 13:18:37", "link": "http://arxiv.org/abs/2505.19955v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning", "abstract": "The differential diagnosis of neurodegenerative dementias is a challenging\nclinical task, mainly because of the overlap in symptom presentation and the\nsimilarity of patterns observed in structural neuroimaging. To improve\ndiagnostic efficiency and accuracy, deep learning-based methods such as\nConvolutional Neural Networks and Vision Transformers have been proposed for\nthe automatic classification of brain MRIs. However, despite their strong\npredictive performance, these models find limited clinical utility due to their\nopaque decision making. In this work, we propose a framework that integrates\ntwo core components to enhance diagnostic transparency. First, we introduce a\nmodular pipeline for converting 3D T1-weighted brain MRIs into textual\nradiology reports. Second, we explore the potential of modern Large Language\nModels (LLMs) to assist clinicians in the differential diagnosis between\nFrontotemporal dementia subtypes, Alzheimer's disease, and normal aging based\non the generated reports. To bridge the gap between predictive accuracy and\nexplainability, we employ reinforcement learning to incentivize diagnostic\nreasoning in LLMs. Without requiring supervised reasoning traces or\ndistillation from larger models, our approach enables the emergence of\nstructured diagnostic rationales grounded in neuroimaging findings. Unlike\npost-hoc explainability methods that retrospectively justify model decisions,\nour framework generates diagnostic rationales as part of the inference\nprocess-producing causally grounded explanations that inform and guide the\nmodel's decision-making process. In doing so, our framework matches the\ndiagnostic performance of existing deep learning methods while offering\nrationales that support its diagnostic conclusions.", "published": "2025-05-26 13:18:32", "link": "http://arxiv.org/abs/2505.19954v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Can Visual Encoder Learn to See Arrows?", "abstract": "The diagram is a visual representation of a relationship illustrated with\nedges (lines or arrows), which is widely used in industrial and scientific\ncommunication. Although recognizing diagrams is essential for vision language\nmodels (VLMs) to comprehend domain-specific knowledge, recent studies reveal\nthat many VLMs fail to identify edges in images. We hypothesize that these\nfailures stem from an over-reliance on textual and positional biases,\npreventing VLMs from learning explicit edge features. Based on this idea, we\nempirically investigate whether the image encoder in VLMs can learn edge\nrepresentation through training on a diagram dataset in which edges are biased\nneither by textual nor positional information. To this end, we conduct\ncontrastive learning on an artificially generated diagram--caption dataset to\ntrain an image encoder and evaluate its diagram-related features on three\ntasks: probing, image retrieval, and captioning. Our results show that the\nfinetuned model outperforms pretrained CLIP in all tasks and surpasses\nzero-shot GPT-4o and LLaVA-Mistral in the captioning task. These findings\nconfirm that eliminating textual and positional biases fosters accurate edge\nrecognition in VLMs, offering a promising path for advancing diagram\nunderstanding.", "published": "2025-05-26 13:09:31", "link": "http://arxiv.org/abs/2505.19944v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs", "abstract": "Large Language Models (LLMs) are widely used in Spoken Language Understanding\n(SLU). Recent SLU models process audio directly by adapting speech input into\nLLMs for better multimodal learning. A key consideration for these models is\nthe cross-modal alignment between text and audio modalities, which is a\ntelltale sign as to whether or not LLM is able to associate semantic meaning to\naudio segments. While various methods exist for fusing these modalities, there\nis no standard metric to evaluate alignment quality in LLMs. In this work, we\npropose a new metric, ALAS (Automatic Latent Alignment Score). Our study\nexamines the correlation between audio and text representations across\ntransformer layers, for two different tasks (Spoken Question Answering and\nEmotion Recognition). We showcase that our metric behaves as expected across\ndifferent layers and different tasks.", "published": "2025-05-26 13:02:44", "link": "http://arxiv.org/abs/2505.19937v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles", "abstract": "Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at\nadvanced reasoning tasks like math and coding via Reinforcement Learning with\nVerifiable Rewards (RLVR), but still struggle with puzzles solvable by humans\nwithout domain knowledge. We introduce Enigmata, the first comprehensive suite\ntailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks\nacross seven categories, each with 1) a generator that produces unlimited\nexamples with controllable difficulty and 2) a rule-based verifier for\nautomatic evaluation. This generator-verifier design supports scalable,\nmulti-task RL training, fine-grained analysis, and seamless RLVR integration.\nWe further propose Enigmata-Eval, a rigorous benchmark, and develop optimized\nmulti-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata,\nconsistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks\nlike Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes\nwell to out-of-domain puzzle benchmarks and mathematical reasoning, with little\nmulti-tasking trade-off. When trained on larger models like Seed1.5-Thinking\n(20B activated parameters and 200B total parameters), puzzle data from Enigmata\nfurther boosts SoTA performance on advanced math and STEM reasoning tasks such\nas AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization\nbenefits of Enigmata. This work offers a unified, controllable framework for\nadvancing logical reasoning in LLMs. Resources of this work can be found at\nhttps://seed-enigmata.github.io.", "published": "2025-05-26 12:40:31", "link": "http://arxiv.org/abs/2505.19914v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization", "abstract": "We present Adjacent Possible Exploration (APE), a simple yet effective method\nfor adapting large language models to specific tasks using minimal\ncomputational resources. Unlike traditional fine-tuning that requires extensive\ncompute, APE iteratively fine-tunes models on small, carefully selected data\nbatches (200 examples), retaining only improvements. On news summarization, APE\nachieves 40 percent BLEU improvement using just a T4 GPU in 60 minutes,\nmatching or exceeding more complex methods like LoRA while remaining\nconceptually simple. Our approach is particularly valuable for researchers and\npractitioners with limited computational resources. We provide open-source code\nand demonstrate APE's effectiveness through both automatic metrics and human\nevaluation. While inspired by evolutionary theory's \"adjacent possible\", APE's\ncore insight has a very practical application: small, iterative data\nperturbations can efficiently guide LLMs toward task-specific performance\nwithout expensive retraining.", "published": "2025-05-26 12:39:24", "link": "http://arxiv.org/abs/2505.19912v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "abstract": "Large Language Models (LLMs) have extended their impact beyond Natural\nLanguage Processing, substantially fostering the development of\ninterdisciplinary research. Recently, various LLM-based agents have been\ndeveloped to assist scientific discovery progress across multiple aspects and\ndomains. Among these, computer-using agents, capable of interacting with\noperating systems as humans do, are paving the way to automated scientific\nproblem-solving and addressing routines in researchers' workflows. Recognizing\nthe transformative potential of these agents, we introduce ScienceBoard, which\nencompasses two complementary contributions: (i) a realistic, multi-domain\nenvironment featuring dynamic and visually rich scientific workflows with\nintegrated professional software, where agents can autonomously interact via\ndifferent interfaces to accelerate complex research tasks and experiments; and\n(ii) a challenging benchmark of 169 high-quality, rigorously validated\nreal-world tasks curated by humans, spanning scientific-discovery workflows in\ndomains such as biochemistry, astronomy, and geoinformatics. Extensive\nevaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude\n3.7, UI-TARS) show that, despite some promising results, they still fall short\nof reliably assisting scientists in complex workflows, achieving only a 15%\noverall success rate. In-depth analysis further provides valuable insights for\naddressing current agent limitations and more effective design principles,\npaving the way to build more capable agents for scientific discovery. Our code,\nenvironment, and benchmark are at\nhttps://qiushisun.github.io/ScienceBoard-Home/.", "published": "2025-05-26 12:27:27", "link": "http://arxiv.org/abs/2505.19897v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program", "abstract": "Recent trends are emerging in the use of Large Language Models (LLMs) as\nautonomous agents that take actions based on the content of the user text\nprompts. We intend to apply these concepts to the field of Control in space,\nenabling LLMs to play a significant role in the decision-making process for\nautonomous satellite operations. As a first step towards this goal, we have\ndeveloped a pure LLM-based solution for the Kerbal Space Program Differential\nGames (KSPDG) challenge, a public software design competition where\nparticipants create autonomous agents for maneuvering satellites involved in\nnon-cooperative space operations, running on the KSP game engine. Our approach\nleverages prompt engineering, few-shot prompting, and fine-tuning techniques to\ncreate an effective LLM-based agent that ranked 2nd in the competition. To the\nbest of our knowledge, this work pioneers the integration of LLM agents into\nspace research. The project comprises several open repositories to facilitate\nreplication and further research. The codebase is accessible on\n\\href{https://github.com/ARCLab-MIT/kspdg}{GitHub}, while the trained models\nand datasets are available on \\href{https://huggingface.co/OhhTuRnz}{Hugging\nFace}. Additionally, experiment tracking and detailed results can be reviewed\non \\href{https://wandb.ai/carrusk/huggingface}{Weights \\& Biases", "published": "2025-05-26 12:25:35", "link": "http://arxiv.org/abs/2505.19896v1", "categories": ["cs.AI", "astro-ph.IM", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ESLM: Risk-Averse Selective Language Modeling for Efficient Pretraining", "abstract": "Large language model pretraining is compute-intensive, yet many tokens\ncontribute marginally to learning, resulting in inefficiency. We introduce\nEfficient Selective Language Modeling (ESLM), a risk-aware algorithm that\nimproves training efficiency and distributional robustness by performing online\ntoken-level batch selection. ESLM leverages per-token statistics (e.g., entropy\nor loss) and applies value-at-risk thresholding to retain only the most\ninformative tokens per batch. This data-centric mechanism reshapes the training\nloss, prioritizing high-risk tokens and eliminating redundant gradient\ncomputation. We frame ESLM as a bilevel game: the model competes with a masking\nadversary that selects worst-case token subsets under a constrained\nthresholding rule. In the loss-based setting, ESLM recovers conditional\nvalue-at-risk loss minimization, providing a principled connection to\ndistributionally robust optimization. We extend our approach to Ada-ESLM, which\nadaptively tunes the selection confidence during training. Experiments on GPT-2\npretraining show that ESLM significantly reduces training FLOPs while\nmaintaining or improving both perplexity and downstream performance compared to\nbaselines. Our approach also scales across model sizes, pretraining corpora,\nand integrates naturally with knowledge distillation.", "published": "2025-05-26 12:23:26", "link": "http://arxiv.org/abs/2505.19893v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "HS-STAR: Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation", "abstract": "Self-taught reasoners (STaRs) enhance the mathematical reasoning abilities of\nlarge language models (LLMs) by leveraging self-generated responses for\nself-training. Recent studies have incorporated reward models to guide response\nselection or decoding, aiming to obtain higher-quality data. However, they\ntypically allocate a uniform sampling budget across all problems, overlooking\nthe varying utility of problems at different difficulty levels. In this work,\nwe conduct an empirical study and find that problems near the boundary of the\nLLM's reasoning capability offer significantly greater learning utility than\nboth easy and overly difficult ones. To identify and exploit such problems, we\npropose HS-STaR, a Hierarchical Sampling framework for Self-Taught Reasoners.\nGiven a fixed sampling budget, HS-STaR first performs lightweight pre-sampling\nwith a reward-guided difficulty estimation strategy to efficiently identify\nboundary-level problems. Subsequently, it dynamically reallocates the remaining\nbudget toward these high-utility problems during a re-sampling phase,\nmaximizing the generation of valuable training data. Extensive experiments\nacross multiple reasoning benchmarks and backbone LLMs demonstrate that HS-STaR\nsignificantly outperforms other baselines without requiring additional sampling\nbudget.", "published": "2025-05-26 11:50:16", "link": "http://arxiv.org/abs/2505.19866v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "REA-RL: Reflection-Aware Online Reinforcement Learning for Efficient Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) demonstrate strong performance in complex tasks\nbut often face the challenge of overthinking, leading to substantially high\ninference costs. Existing approaches synthesize shorter reasoning responses for\nLRMs to learn, but are inefficient for online usage due to the time-consuming\ndata generation and filtering processes. Meanwhile, online reinforcement\nlearning mainly adopts a length reward to encourage short reasoning responses,\nbut tends to lose the reflection ability and harm the performance. To address\nthese issues, we propose REA-RL, which introduces a small reflection model for\nefficient scaling in online training, offering both parallel sampling and\nsequential revision. Besides, a reflection reward is designed to further\nprevent LRMs from favoring short yet non-reflective responses. Experiments show\nthat both methods maintain or enhance performance while significantly improving\ninference efficiency. Their combination achieves a good balance between\nperformance and efficiency, reducing inference costs by 35% without\ncompromising performance. Further analysis demonstrates that our methods are\neffective by maintaining reflection frequency for hard problems while\nappropriately reducing it for simpler ones without losing reflection ability.\nCodes are available at https://github.com/hexuandeng/REA-RL.", "published": "2025-05-26 11:47:16", "link": "http://arxiv.org/abs/2505.19862v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond Specialization: Benchmarking LLMs for Transliteration of Indian Languages", "abstract": "Transliteration, the process of mapping text from one script to another,\nplays a crucial role in multilingual natural language processing, especially\nwithin linguistically diverse contexts such as India. Despite significant\nadvancements through specialized models like IndicXlit, recent developments in\nlarge language models suggest a potential for general-purpose models to excel\nat this task without explicit task-specific training. The current work\nsystematically evaluates the performance of prominent LLMs, including GPT-4o,\nGPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, a\nstate-of-the-art transliteration model, across ten major Indian languages.\nExperiments utilized standard benchmarks, including Dakshina and Aksharantar\ndatasets, with performance assessed via Top-1 Accuracy and Character Error\nRate. Our findings reveal that while GPT family models generally outperform\nother LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4o\nimproves performance on specific languages notably. An extensive error analysis\nand robustness testing under noisy conditions further elucidate strengths of\nLLMs compared to specialized models, highlighting the efficacy of foundational\nmodels for a wide spectrum of specialized applications with minimal overhead.", "published": "2025-05-26 11:35:51", "link": "http://arxiv.org/abs/2505.19851v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Multilingual Math Reasoning for African Languages", "abstract": "Researchers working on low-resource languages face persistent challenges due\nto limited data availability and restricted access to computational resources.\nAlthough most large language models (LLMs) are predominantly trained in\nhigh-resource languages, adapting them to low-resource contexts, particularly\nAfrican languages, requires specialized techniques. Several strategies have\nemerged for adapting models to low-resource languages in todays LLM landscape,\ndefined by multi-stage pre-training and post-training paradigms. However, the\nmost effective approaches remain uncertain. This work systematically\ninvestigates which adaptation strategies yield the best performance when\nextending existing LLMs to African languages. We conduct extensive experiments\nand ablation studies to evaluate different combinations of data types\n(translated versus synthetically generated), training stages (pre-training\nversus post-training), and other model adaptation configurations. Our\nexperiments focuses on mathematical reasoning tasks, using the Llama 3.1 model\nfamily as our base model.", "published": "2025-05-26 11:35:01", "link": "http://arxiv.org/abs/2505.19848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FoodTaxo: Generating Food Taxonomies with Large Language Models", "abstract": "We investigate the utility of Large Language Models for automated taxonomy\ngeneration and completion specifically applied to taxonomies from the food\ntechnology industry. We explore the extent to which taxonomies can be completed\nfrom a seed taxonomy or generated without a seed from a set of known concepts,\nin an iterative fashion using recent prompting techniques. Experiments on five\ntaxonomies using an open-source LLM (Llama-3), while promising, point to the\ndifficulty of correctly placing inner nodes.", "published": "2025-05-26 11:22:17", "link": "http://arxiv.org/abs/2505.19838v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective", "abstract": "We propose a novel framework for comprehending the reasoning capabilities of\nlarge language models (LLMs) through the perspective of meta-learning. By\nconceptualizing reasoning trajectories as pseudo-gradient descent updates to\nthe LLM's parameters, we identify parallels between LLM reasoning and various\nmeta-learning paradigms. We formalize the training process for reasoning tasks\nas a meta-learning setup, with each question treated as an individual task, and\nreasoning trajectories serving as the inner loop optimization for adapting\nmodel parameters. Once trained on a diverse set of questions, the LLM develops\nfundamental reasoning capabilities that can generalize to previously unseen\nquestions. Extensive empirical evaluations substantiate the strong connection\nbetween LLM reasoning and meta-learning, exploring several issues of\nsignificant interest from a meta-learning standpoint. Our work not only\nenhances the understanding of LLM reasoning but also provides practical\ninsights for improving these models through established meta-learning\ntechniques.", "published": "2025-05-26 10:52:17", "link": "http://arxiv.org/abs/2505.19815v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Consciousness in LLMs: A Systematic Survey of Theories, Implementations, and Frontier Risks", "abstract": "Consciousness stands as one of the most profound and distinguishing features\nof the human mind, fundamentally shaping our understanding of existence and\nagency. As large language models (LLMs) develop at an unprecedented pace,\nquestions concerning intelligence and consciousness have become increasingly\nsignificant. However, discourse on LLM consciousness remains largely unexplored\nterritory. In this paper, we first clarify frequently conflated terminologies\n(e.g., LLM consciousness and LLM awareness). Then, we systematically organize\nand synthesize existing research on LLM consciousness from both theoretical and\nempirical perspectives. Furthermore, we highlight potential frontier risks that\nconscious LLMs might introduce. Finally, we discuss current challenges and\noutline future directions in this emerging field. The references discussed in\nthis paper are organized at\nhttps://github.com/OpenCausaLab/Awesome-LLM-Consciousness.", "published": "2025-05-26 10:40:52", "link": "http://arxiv.org/abs/2505.19806v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation", "abstract": "Nowadays, regulatory compliance has become a cornerstone of corporate\ngovernance, ensuring adherence to systematic legal frameworks. At its core,\nfinancial regulations often comprise highly intricate provisions, layered\nlogical structures, and numerous exceptions, which inevitably result in\nlabor-intensive or comprehension challenges. To mitigate this, recent\nRegulatory Technology (RegTech) and Large Language Models (LLMs) have gained\nsignificant attention in automating the conversion of regulatory text into\nexecutable compliance logic. However, their performance remains suboptimal\nparticularly when applied to Chinese-language financial regulations, due to\nthree key limitations: (1) incomplete domain-specific knowledge representation,\n(2) insufficient hierarchical reasoning capabilities, and (3) failure to\nmaintain temporal and logical coherence. One promising solution is to develop a\ndomain specific and code-oriented datasets for model training. Existing\ndatasets such as LexGLUE, LegalBench, and CODE-ACCORD are often\nEnglish-focused, domain-mismatched, or lack fine-grained granularity for\ncompliance code generation. To fill these gaps, we present Compliance-to-Code,\nthe first large-scale Chinese dataset dedicated to financial regulatory\ncompliance. Covering 1,159 annotated clauses from 361 regulations across ten\ncategories, each clause is modularly structured with four logical\nelements-subject, condition, constraint, and contextual information-along with\nregulation relations. We provide deterministic Python code mappings, detailed\ncode reasoning, and code explanations to facilitate automated auditing. To\ndemonstrate utility, we present FinCheck: a pipeline for regulation\nstructuring, code generation, and report generation.", "published": "2025-05-26 10:38:32", "link": "http://arxiv.org/abs/2505.19804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs", "abstract": "Metadata extraction is essential for cataloging and preserving datasets,\nenabling effective research discovery and reproducibility, especially given the\ncurrent exponential growth in scientific research. While Masader (Alyafeai et\nal.,2021) laid the groundwork for extracting a wide range of metadata\nattributes from Arabic NLP datasets' scholarly articles, it relies heavily on\nmanual annotation. In this paper, we present MOLE, a framework that leverages\nLarge Language Models (LLMs) to automatically extract metadata attributes from\nscientific papers covering datasets of languages other than Arabic. Our\nschema-driven methodology processes entire documents across multiple input\nformats and incorporates robust validation mechanisms for consistent output.\nAdditionally, we introduce a new benchmark to evaluate the research progress on\nthis task. Through systematic analysis of context length, few-shot learning,\nand web browsing integration, we demonstrate that modern LLMs show promising\nresults in automating this task, highlighting the need for further future work\nimprovements to ensure consistent and reliable performance. We release the\ncode: https://github.com/IVUL-KAUST/MOLE and dataset:\nhttps://huggingface.co/datasets/IVUL-KAUST/MOLE for the research community.", "published": "2025-05-26 10:31:26", "link": "http://arxiv.org/abs/2505.19800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Avengers: A Simple Recipe for Uniting Smaller Language Models to Challenge Proprietary Giants", "abstract": "As proprietary giants increasingly dominate the race for ever-larger language\nmodels, a pressing question arises for the open-source community: can smaller\nmodels remain competitive across a broad range of tasks? In this paper, we\npresent the Avengers--a simple recipe that effectively leverages the collective\nintelligence of open-source, smaller language models. Our framework is built\nupon four lightweight operations: (i) embedding: encode queries using a text\nembedding model; (ii) clustering: group queries based on their semantic\nsimilarity; (iii) scoring: scores each model's performance within each cluster;\nand (iv) voting: improve outputs via repeated sampling and voting. At inference\ntime, each query is embedded and assigned to its nearest cluster. The\ntop-performing model(s) within that cluster are selected to generate the\nresponse using the Self-Consistency or its multi-model variant. Remarkably,\nwith 10 open-source models (~7B parameters each), the Avengers collectively\noutperforms GPT-4.1 on 10 out of 15 datasets (spanning mathematics, code,\nlogic, knowledge, and affective tasks). In particular, it surpasses GPT-4.1 on\nmathematics tasks by 18.21% and on code tasks by 7.46%. Furthermore, the\nAvengers delivers superior out-of-distribution generalization, and remains\nrobust across various embedding models, clustering algorithms, ensemble\nstrategies, and values of its sole parameter--the number of clusters. We have\nopen-sourced the code on GitHub: https://github.com/ZhangYiqun018/Avengers", "published": "2025-05-26 10:29:42", "link": "http://arxiv.org/abs/2505.19797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification", "abstract": "Political biases encoded by LLMs might have detrimental effects on downstream\napplications. Existing bias analysis methods rely on small-size intermediate\ntasks (questionnaire answering or political content generation) and rely on the\nLLMs themselves for analysis, thus propagating bias. We propose a new approach\nleveraging the observation that LLM sentiment predictions vary with the target\nentity in the same sentence. We define an entropy-based inconsistency metric to\nencode this prediction variability. We insert 1319 demographically and\npolitically diverse politician names in 450 political sentences and predict\ntarget-oriented sentiment using seven models in six widely spoken languages. We\nobserve inconsistencies in all tested combinations and aggregate them in a\nstatistically robust analysis at different granularity levels. We observe\npositive and negative bias toward left and far-right politicians and positive\ncorrelations between politicians with similar alignment. Bias intensity is\nhigher for Western languages than for others. Larger models exhibit stronger\nand more consistent biases and reduce discrepancies between similar languages.\nWe partially mitigate LLM unreliability in target-oriented sentiment\nclassification (TSC) by replacing politician names with fictional but plausible\ncounterparts.", "published": "2025-05-26 10:01:24", "link": "http://arxiv.org/abs/2505.19776v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs", "abstract": "We investigate long-context vulnerabilities in Large Language Models (LLMs)\nthrough Many-Shot Jailbreaking (MSJ). Our experiments utilize context length of\nup to 128K tokens. Through comprehensive analysis with various many-shot attack\nsettings with different instruction styles, shot density, topic, and format, we\nreveal that context length is the primary factor determining attack\neffectiveness. Critically, we find that successful attacks do not require\ncarefully crafted harmful content. Even repetitive shots or random dummy text\ncan circumvent model safety measures, suggesting fundamental limitations in\nlong-context processing capabilities of LLMs. The safety behavior of\nwell-aligned models becomes increasingly inconsistent with longer contexts.\nThese findings highlight significant safety gaps in context expansion\ncapabilities of LLMs, emphasizing the need for new safety mechanisms.", "published": "2025-05-26 09:57:25", "link": "http://arxiv.org/abs/2505.19773v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Understanding the Performance Gap in Preference Learning: A Dichotomy of RLHF and DPO", "abstract": "We present a fine-grained theoretical analysis of the performance gap between\nreinforcement learning from human feedback (RLHF) and direct preference\noptimization (DPO) under a representation gap. Our study decomposes this gap\ninto two sources: an explicit representation gap under exact optimization and\nan implicit representation gap under finite samples. In the exact optimization\nsetting, we characterize how the relative capacities of the reward and policy\nmodel classes influence the final policy qualities. We show that RLHF, DPO, or\nonline DPO can outperform one another depending on the type of model\nmis-specifications. Notably, online DPO can outperform both RLHF and standard\nDPO when the reward and policy model classes are isomorphic and both\nmis-specified. In the approximate optimization setting, we provide a concrete\nconstruction where the ground-truth reward is implicitly sparse and show that\nRLHF requires significantly fewer samples than DPO to recover an effective\nreward model -- highlighting a statistical advantage of two-stage learning.\nTogether, these results provide a comprehensive understanding of the\nperformance gap between RLHF and DPO under various settings, and offer\npractical insights into when each method is preferred.", "published": "2025-05-26 09:54:02", "link": "http://arxiv.org/abs/2505.19770v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search", "abstract": "Real-world multimodal misinformation often arises from mixed forgery sources,\nrequiring dynamic reasoning and adaptive verification. However, existing\nmethods mainly rely on static pipelines and limited tool usage, limiting their\nability to handle such complexity and diversity. To address this challenge, we\npropose T2Agent, a novel misinformation detection agent that incorporates an\nextensible toolkit with Monte Carlo Tree Search (MCTS). The toolkit consists of\nmodular tools such as web search, forgery detection, and consistency analysis.\nEach tool is described using standardized templates, enabling seamless\nintegration and future expansion. To avoid inefficiency from using all tools\nsimultaneously, a Bayesian optimization-based selector is proposed to identify\na task-relevant subset. This subset then serves as the action space for MCTS to\ndynamically collect evidence and perform multi-source verification. To better\nalign MCTS with the multi-source nature of misinformation detection, T2Agent\nextends traditional MCTS with multi-source verification, which decomposes the\ntask into coordinated subtasks targeting different forgery sources. A dual\nreward mechanism containing a reasoning trajectory score and a confidence score\nis further proposed to encourage a balance between exploration across mixed\nforgery sources and exploitation for more reliable evidence. We conduct\nablation studies to confirm the effectiveness of the tree search mechanism and\ntool usage. Extensive experiments further show that T2Agent consistently\noutperforms existing baselines on challenging mixed-source multimodal\nmisinformation benchmarks, demonstrating its strong potential as a\ntraining-free approach for enhancing detection accuracy. The code will be\nreleased.", "published": "2025-05-26 09:50:55", "link": "http://arxiv.org/abs/2505.19768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SGM: A Framework for Building Specification-Guided Moderation Filters", "abstract": "Aligning large language models (LLMs) with deployment-specific requirements\nis critical but inherently imperfect. Despite extensive training, models remain\nsusceptible to misalignment and adversarial inputs such as jailbreaks. Content\nmoderation filters are commonly used as external safeguards, though they\ntypically focus narrowly on safety. We introduce SGM (Specification-Guided\nModeration), a flexible framework for training moderation filters grounded in\nuser-defined specifications that go beyond standard safety concerns. SGM\nautomates training data generation without relying on human-written examples,\nenabling scalable support for diverse, application-specific alignment goals.\nSGM-trained filters perform on par with state-of-the-art safety filters built\non curated datasets, while supporting fine-grained and user-defined alignment\ncontrol.", "published": "2025-05-26 09:49:43", "link": "http://arxiv.org/abs/2505.19766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CIDRe: A Reference-Free Multi-Aspect Criterion for Code Comment Quality Measurement", "abstract": "Effective generation of structured code comments requires robust quality\nmetrics for dataset curation, yet existing approaches (SIDE, MIDQ, STASIS)\nsuffer from limited code-comment analysis. We propose CIDRe, a\nlanguage-agnostic reference-free quality criterion combining four synergistic\naspects: (1) relevance (code-comment semantic alignment), (2) informativeness\n(functional coverage), (3) completeness (presence of all structure sections),\nand (4) description length (detail sufficiency). We validate our criterion on a\nmanually annotated dataset. Experiments demonstrate CIDRe's superiority over\nexisting metrics, achieving improvement in cross-entropy evaluation. When\napplied to filter comments, the models finetuned on CIDRe-filtered data show\nstatistically significant quality gains in GPT-4o-mini assessments.", "published": "2025-05-26 09:36:57", "link": "http://arxiv.org/abs/2505.19757v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Efficient Reasoning via Chain of Unconscious Thought", "abstract": "Large Reasoning Models (LRMs) achieve promising performance but compromise\ntoken efficiency due to verbose reasoning processes. Unconscious Thought Theory\n(UTT) posits that complex problems can be solved more efficiently through\ninternalized cognitive processes. Inspired by UTT, we propose a new reasoning\nparadigm, termed Chain of Unconscious Thought (CoUT), to improve the token\nefficiency of LRMs by guiding them to mimic human unconscious thought and\ninternalize reasoning processes. Concretely, we first prompt the model to\ninternalize the reasoning by thinking in the hidden layer. Then, we design a\nbag of token-efficient strategies to further help models reduce unnecessary\ntokens yet preserve the performance. Our work reveals that models may possess\nbeneficial unconscious thought, enabling improved efficiency without\nsacrificing performance. Extensive experiments demonstrate the effectiveness of\nCoUT. Remarkably, it surpasses CoT by reducing token usage by 47.62% while\nmaintaining comparable accuracy, as shown in Figure 1. The code of CoUT is\navailable at this link: https://github.com/Rohan-GRH/CoUT", "published": "2025-05-26 09:34:04", "link": "http://arxiv.org/abs/2505.19756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering", "abstract": "The increasing number of academic papers poses significant challenges for\nresearchers to efficiently acquire key details. While retrieval augmented\ngeneration (RAG) shows great promise in large language model (LLM) based\nautomated question answering, previous works often isolate neural and symbolic\nretrieval despite their complementary strengths. Moreover, conventional\nsingle-view chunking neglects the rich structure and layout of PDFs, e.g.,\nsections and tables. In this work, we propose NeuSym-RAG, a hybrid neural\nsymbolic retrieval framework which combines both paradigms in an interactive\nprocess. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG\norganizes semi-structured PDF content into both the relational database and\nvectorstore, enabling LLM agents to iteratively gather context until sufficient\nto generate answers. Experiments on three full PDF-based QA datasets, including\na self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the\nvector-based RAG and various structured baselines, highlighting its capacity to\nunify both retrieval schemes and utilize multiple views. Code and data are\npublicly available at https://github.com/X-LANCE/NeuSym-RAG.", "published": "2025-05-26 09:33:10", "link": "http://arxiv.org/abs/2505.19754v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discrete Markov Bridge", "abstract": "Discrete diffusion has recently emerged as a promising paradigm in discrete\ndata modeling. However, existing methods typically rely on a fixed rate\ntransition matrix during training, which not only limits the expressiveness of\nlatent representations, a fundamental strength of variational methods, but also\nconstrains the overall design space. To address these limitations, we propose\nDiscrete Markov Bridge, a novel framework specifically designed for discrete\nrepresentation learning. Our approach is built upon two key components: Matrix\nLearning and Score Learning. We conduct a rigorous theoretical analysis,\nestablishing formal performance guarantees for Matrix Learning and proving the\nconvergence of the overall framework. Furthermore, we analyze the space\ncomplexity of our method, addressing practical constraints identified in prior\nstudies. Extensive empirical evaluations validate the effectiveness of the\nproposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO)\nof 1.38 on the Text8 dataset, outperforming established baselines. Moreover,\nthe proposed model demonstrates competitive performance on the CIFAR-10\ndataset, achieving results comparable to those obtained by image-specific\ngeneration approaches.", "published": "2025-05-26 09:32:12", "link": "http://arxiv.org/abs/2505.19752v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Token-level Accept or Reject: A Micro Alignment Approach for Large Language Models", "abstract": "With the rapid development of Large Language Models (LLMs), aligning these\nmodels with human preferences and values is critical to ensuring ethical and\nsafe applications. However, existing alignment techniques such as RLHF or DPO\noften require direct fine-tuning on LLMs with billions of parameters, resulting\nin substantial computational costs and inefficiencies. To address this, we\npropose Micro token-level Accept-Reject Aligning (MARA) approach designed to\noperate independently of the language models. MARA simplifies the alignment\nprocess by decomposing sentence-level preference learning into token-level\nbinary classification, where a compact three-layer fully-connected network\ndetermines whether candidate tokens are \"Accepted\" or \"Rejected\" as part of the\nresponse. Extensive experiments across seven different LLMs and three\nopen-source datasets show that MARA achieves significant improvements in\nalignment performance while reducing computational costs.", "published": "2025-05-26 09:24:36", "link": "http://arxiv.org/abs/2505.19743v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic Biomedical Entity Linking", "abstract": "Biomedical entity linking aims to map nonstandard entities to standard\nentities in a knowledge base. Traditional supervised methods perform well but\nrequire extensive annotated data to transfer, limiting their usage in\nlow-resource scenarios. Large language models (LLMs), especially closed-source\nLLMs, can address these but risk stability issues and high economic costs:\nusing these models is restricted by commercial companies and brings significant\neconomic costs when dealing with large amounts of data. To address this, we\npropose ``RPDR'', a framework combining closed-source LLMs and open-source LLMs\nfor re-ranking candidates retrieved by a retriever fine-tuned with a small\namount of data. By prompting a closed-source LLM to generate training data from\nunannotated data and fine-tuning an open-source LLM for re-ranking, we\neffectively distill the knowledge to the open-source LLM that can be deployed\nlocally, thus avoiding the stability issues and the problem of high economic\ncosts. We evaluate RPDR on two datasets, including one real-world dataset and\none publicly available dataset involving two languages: Chinese and English.\nRPDR achieves 0.019 Acc@1 improvement and 0.036 Acc@1 improvement on the Aier\ndataset and the Ask A Patient dataset when the amount of training data is not\nenough. The results demonstrate the superiority and generalizability of the\nproposed framework.", "published": "2025-05-26 09:10:19", "link": "http://arxiv.org/abs/2505.19722v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graceful Forgetting in Generative Language Models", "abstract": "Recently, the pretrain-finetune paradigm has become a cornerstone in various\ndeep learning areas. While in general the pre-trained model would promote both\neffectiveness and efficiency of downstream tasks fine-tuning, studies have\nshown that not all knowledge acquired during pre-training is beneficial. Some\nof the knowledge may actually bring detrimental effects to the fine-tuning\ntasks, which is also known as negative transfer. To address this problem,\ngraceful forgetting has emerged as a promising approach. The core principle of\ngraceful forgetting is to enhance the learning plasticity of the target task by\nselectively discarding irrelevant knowledge. However, this approach remains\nunderexplored in the context of generative language models, and it is often\nchallenging to migrate existing forgetting algorithms to these models due to\narchitecture incompatibility. To bridge this gap, in this paper we propose a\nnovel framework, Learning With Forgetting (LWF), to achieve graceful forgetting\nin generative language models. With Fisher Information Matrix weighting the\nintended parameter updates, LWF computes forgetting confidence to evaluate\nself-generated knowledge regarding the forgetting task, and consequently,\nknowledge with high confidence is periodically unlearned during fine-tuning.\nOur experiments demonstrate that, although thoroughly uncovering the mechanisms\nof knowledge interaction remains challenging in pre-trained language models,\napplying graceful forgetting can contribute to enhanced fine-tuning\nperformance.", "published": "2025-05-26 09:03:57", "link": "http://arxiv.org/abs/2505.19715v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning", "abstract": "Text Image Machine Translation (TIMT)-the task of translating textual content\nembedded in images-is critical for applications in accessibility, cross-lingual\ninformation access, and real-world document understanding. However, TIMT\nremains a complex challenge due to the need for accurate optical character\nrecognition (OCR), robust visual-text reasoning, and high-quality translation,\noften requiring cascading multi-stage pipelines. Recent advances in large-scale\nReinforcement Learning (RL) have improved reasoning in Large Language Models\n(LLMs) and Multimodal LLMs (MLLMs), but their application to end-to-end TIMT is\nstill underexplored. To bridge this gap, we introduce MT$^{3}$, the first\nframework to apply Multi-Task RL to MLLMs for end-to-end TIMT. MT$^{3}$ adopts\na multi-task optimization paradigm targeting three key sub-skills: text\nrecognition, context-aware reasoning, and translation. It is trained using a\nnovel multi-mixed reward mechanism that adapts rule-based RL strategies to\nTIMT's intricacies, offering fine-grained, non-binary feedback across tasks.\nFurthermore, to facilitate the evaluation of TIMT in authentic cross-cultural\nand real-world social media contexts, we introduced XHSPost, the first social\nmedia TIMT benchmark. Our MT$^{3}$-7B-Zero achieves state-of-the-art results on\nthe latest in-domain MIT-10M benchmark, outperforming strong baselines such as\nQwen2.5-VL-72B and InternVL2.5-78B by notable margins across multiple metrics.\nAdditionally, the model shows strong generalization to out-of-distribution\nlanguage pairs and datasets. In-depth analyses reveal how multi-task synergy,\nreinforcement learning initialization, curriculum design, and reward\nformulation contribute to advancing MLLM-driven TIMT.", "published": "2025-05-26 09:02:35", "link": "http://arxiv.org/abs/2505.19714v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Error Typing for Smarter Rewards: Improving Process Reward Models with Error-Aware Hierarchical Supervision", "abstract": "Large Language Models (LLMs) are prone to hallucination, especially during\nmulti-hop and reasoning-intensive tasks such as mathematical problem solving.\nWhile Outcome Reward Models verify only final answers, Process Reward Models\n(PRMs) score each intermediate step to steer generation toward coherent\nsolutions. We introduce PathFinder-PRM, a novel hierarchical, error-aware\ndiscriminative PRM that first classifies math and consistency errors at each\nstep, then combines these fine-grained signals to estimate step correctness. To\ntrain PathFinder-PRM, we construct a 400K-sample dataset by enriching the\nhuman-annotated PRM800K corpus and RLHFlow Mistral traces with\nthree-dimensional step-level labels. On PRMBench, PathFinder-PRM achieves a new\nstate-of-the-art PRMScore of 67.7, outperforming the prior best (65.5) while\nusing 3 times less data. When applied to reward guided greedy search, our model\nyields prm@8 48.3, a +1.5 point gain over the strongest baseline. These results\ndemonstrate that decoupled error detection and reward estimation not only boost\nfine-grained error detection but also substantially improve end-to-end,\nreward-guided mathematical reasoning with greater data efficiency.", "published": "2025-05-26 08:56:36", "link": "http://arxiv.org/abs/2505.19706v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models", "abstract": "The widespread adoption of large language models (LLMs) across industries has\nincreased the demand for high-quality and customizable outputs. However,\ntraditional alignment methods often require retraining large pretrained models,\nmaking it difficult to quickly adapt and optimize LLMs for diverse\napplications. To address this limitation, we propose a novel \\textit{Residual\nAlignment Model} (\\textit{RAM}) that formalizes the alignment process as a type\nof importance sampling. In this framework, the unaligned upstream model serves\nas the proposal distribution, while the alignment process is framed as\nsecondary sampling based on an autoregressive alignment module that acts as an\nestimator of the importance weights. This design enables a natural detachment\nof the alignment module from the target aligned model, improving flexibility\nand scalability. Based on this model, we derive an efficient sequence-level\ntraining strategy for the alignment module, which operates independently of the\nproposal module. Additionally, we develop a resampling algorithm with iterative\ntoken-level decoding to address the common first-token latency issue in\ncomparable methods. Experimental evaluations on two leading open-source LLMs\nacross diverse tasks, including instruction following, domain adaptation, and\npreference optimization, demonstrate that our approach consistently outperforms\nbaseline models.", "published": "2025-05-26 08:53:02", "link": "http://arxiv.org/abs/2505.19700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "abstract": "Planning represents a fundamental capability of intelligent agents, requiring\ncomprehensive environmental understanding, rigorous logical reasoning, and\neffective sequential decision-making. While Large Language Models (LLMs) have\ndemonstrated remarkable performance on certain planning tasks, their broader\napplication in this domain warrants systematic investigation. This paper\npresents a comprehensive review of LLM-based planning. Specifically, this\nsurvey is structured as follows: First, we establish the theoretical\nfoundations by introducing essential definitions and categories about automated\nplanning. Next, we provide a detailed taxonomy and analysis of contemporary\nLLM-based planning methodologies, categorizing them into three principal\napproaches: 1) External Module Augmented Methods that combine LLMs with\nadditional components for planning, 2) Finetuning-based Methods that involve\nusing trajectory data and feedback signals to adjust LLMs in order to improve\ntheir planning abilities, and 3) Searching-based Methods that break down\ncomplex tasks into simpler components, navigate the planning space, or enhance\ndecoding strategies to find the best solutions. Subsequently, we systematically\nsummarize existing evaluation frameworks, including benchmark datasets,\nevaluation metrics and performance comparisons between representative planning\nmethods. Finally, we discuss the underlying mechanisms enabling LLM-based\nplanning and outline promising research directions for this rapidly evolving\nfield. We hope this survey will serve as a valuable resource to inspire\ninnovation and drive progress in this field.", "published": "2025-05-26 08:44:53", "link": "http://arxiv.org/abs/2505.19683v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "KIT's Low-resource Speech Translation Systems for IWSLT2025: System Enhancement with Synthetic Data and Model Regularization", "abstract": "This paper presents KIT's submissions to the IWSLT 2025 low-resource track.\nWe develop both cascaded systems, consisting of Automatic Speech Recognition\n(ASR) and Machine Translation (MT) models, and end-to-end (E2E) Speech\nTranslation (ST) systems for three language pairs: Bemba, North Levantine\nArabic, and Tunisian Arabic into English. Building upon pre-trained models, we\nfine-tune our systems with different strategies to utilize resources\nefficiently. This study further explores system enhancement with synthetic data\nand model regularization. Specifically, we investigate MT-augmented ST by\ngenerating translations from ASR data using MT models. For North Levantine,\nwhich lacks parallel ST training data, a system trained solely on synthetic\ndata slightly surpasses the cascaded system trained on real data. We also\nexplore augmentation using text-to-speech models by generating synthetic speech\nfrom MT data, demonstrating the benefits of synthetic data in improving both\nASR and ST performance for Bemba. Additionally, we apply intra-distillation to\nenhance model performance. Our experiments show that this approach consistently\nimproves results across ASR, MT, and ST tasks, as well as across different\npre-trained models. Finally, we apply Minimum Bayes Risk decoding to combine\nthe cascaded and end-to-end systems, achieving an improvement of approximately\n1.5 BLEU points.", "published": "2025-05-26 08:38:02", "link": "http://arxiv.org/abs/2505.19679v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs", "abstract": "Large Vision-Language Models (LVLMs) are susceptible to hallucinations, where\ngenerated responses seem semantically plausible yet exhibit little or no\nrelevance to the input image. Previous studies reveal that this issue primarily\nstems from LVLMs' over-reliance on language priors while disregarding the\nvisual information during decoding. To alleviate this issue, we introduce a\nnovel Conditional Pointwise Mutual Information (C-PMI) calibrated decoding\nstrategy, which adaptively strengthens the mutual dependency between generated\ntexts and input images to mitigate hallucinations. Unlike existing methods\nsolely focusing on text token sampling, we propose to jointly model the\ncontributions of visual and textual tokens to C-PMI, formulating hallucination\nmitigation as a bi-level optimization problem aimed at maximizing mutual\ninformation. To solve it, we design a token purification mechanism that\ndynamically regulates the decoding process by sampling text tokens remaining\nmaximally relevant to the given image, while simultaneously refining image\ntokens most pertinent to the generated response. Extensive experiments across\nvarious benchmarks reveal that the proposed method significantly reduces\nhallucinations in LVLMs while preserving decoding efficiency.", "published": "2025-05-26 08:36:10", "link": "http://arxiv.org/abs/2505.19678v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement", "abstract": "The traditional process of creating labeled datasets is labor-intensive and\nexpensive. Recent breakthroughs in open-source large language models (LLMs)\nhave opened up a new avenue in generating labeled datasets automatically for\nvarious natural language processing (NLP) tasks, providing an alternative to\nsuch an expensive annotation process. However, the reliability of such\nauto-generated labels remains a significant concern due to inherent\ninaccuracies. When learning from noisy labels, the model's generalization is\nlikely to be harmed as it is prone to overfit to those label noises. While\nprevious studies in learning from noisy labels mainly focus on synthetic noise\nand real-world noise, LLM-generated label noise receives less attention. In\nthis paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to\ncalibrate the classifier's prediction, thus enhancing its robustness towards\nLLM-generated noisy labels. SiDyP retrieves potential true label candidates by\nneighborhood label distribution in text embedding space and iteratively refines\nnoisy candidates using a simplex diffusion model. Our framework can increase\nthe performance of the BERT classifier fine-tuned on both zero-shot and\nfew-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30%\nrespectively. We demonstrate the effectiveness of SiDyP by conducting extensive\nbenchmarking for different LLMs over a variety of NLP tasks. Our code is\navailable on Github.", "published": "2025-05-26 08:31:55", "link": "http://arxiv.org/abs/2505.19675v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations", "abstract": "As the impact of large language models increases, understanding the moral\nvalues they reflect becomes ever more important. Assessing the nature of moral\nvalues as understood by these models via direct prompting is challenging due to\npotential leakage of human norms into model training data, and their\nsensitivity to prompt formulation. Instead, we propose to use word\nassociations, which have been shown to reflect moral reasoning in humans, as\nlow-level underlying representations to obtain a more robust picture of LLMs'\nmoral reasoning. We study moral differences in associations from western\nEnglish-speaking communities and LLMs trained predominantly on English data.\nFirst, we create a large dataset of LLM-generated word associations, resembling\nan existing data set of human word associations. Next, we propose a novel\nmethod to propagate moral values based on seed words derived from Moral\nFoundation Theory through the human and LLM-generated association graphs.\nFinally, we compare the resulting moral conceptualizations, highlighting\ndetailed but systematic differences between moral values emerging from English\nspeakers and LLM associations.", "published": "2025-05-26 08:29:15", "link": "http://arxiv.org/abs/2505.19674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reshaping Representation Space to Balance the Safety and Over-rejection in Large Audio Language Models", "abstract": "Large Audio Language Models (LALMs) have extended the capabilities of Large\nLanguage Models (LLMs) by enabling audio-based human interactions. However,\nrecent research has revealed that LALMs remain vulnerable to harmful queries\ndue to insufficient safety-alignment. Despite advances in defence measures for\ntext and vision LLMs, effective safety-alignment strategies and audio-safety\ndataset specifically targeting LALMs are notably absent. Meanwhile defence\nmeasures based on Supervised Fine-tuning (SFT) struggle to address safety\nimprovement while avoiding over-rejection issues, significantly compromising\nhelpfulness. In this work, we propose an unsupervised safety-fine-tuning\nstrategy as remedy that reshapes model's representation space to enhance\nexisting LALMs safety-alignment while balancing the risk of over-rejection. Our\nexperiments, conducted across three generations of Qwen LALMs, demonstrate that\nour approach significantly improves LALMs safety under three modality input\nconditions (audio-text, text-only, and audio-only) while increasing\nover-rejection rate by only 0.88% on average. Warning: this paper contains\nharmful examples.", "published": "2025-05-26 08:25:25", "link": "http://arxiv.org/abs/2505.19670v1", "categories": ["cs.CL", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation", "abstract": "Legal consultation is essential for safeguarding individual rights and\nensuring access to justice, yet remains costly and inaccessible to many\nindividuals due to the shortage of professionals. While recent advances in\nLarge Language Models (LLMs) offer a promising path toward scalable, low-cost\nlegal assistance, current systems fall short in handling the interactive and\nknowledge-intensive nature of real-world consultations. To address these\nchallenges, we introduce LeCoDe, a real-world multi-turn benchmark dataset\ncomprising 3,696 legal consultation dialogues with 110,008 dialogue turns,\ndesigned to evaluate and improve LLMs' legal consultation capability. With\nLeCoDe, we innovatively collect live-streamed consultations from short-video\nplatforms, providing authentic multi-turn legal consultation dialogues. The\nrigorous annotation by legal experts further enhances the dataset with\nprofessional insights and expertise. Furthermore, we propose a comprehensive\nevaluation framework that assesses LLMs' consultation capabilities in terms of\n(1) clarification capability and (2) professional advice quality. This unified\nframework incorporates 12 metrics across two dimensions. Through extensive\nexperiments on various general and domain-specific LLMs, our results reveal\nsignificant challenges in this task, with even state-of-the-art models like\nGPT-4 achieving only 39.8% recall for clarification and 59% overall score for\nadvice quality, highlighting the complexity of professional consultation\nscenarios. Based on these findings, we further explore several strategies to\nenhance LLMs' legal consultation abilities. Our benchmark contributes to\nadvancing research in legal domain dialogue systems, particularly in simulating\nmore real-world user-expert interactions.", "published": "2025-05-26 08:24:32", "link": "http://arxiv.org/abs/2505.19667v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "GenKI: Enhancing Open-Domain Question Answering with Knowledge Integration and Controllable Generation in Large Language Models", "abstract": "Open-domain question answering (OpenQA) represents a cornerstone in natural\nlanguage processing (NLP), primarily focused on extracting answers from\nunstructured textual data. With the rapid advancements in Large Language Models\n(LLMs), LLM-based OpenQA methods have reaped the benefits of emergent\nunderstanding and answering capabilities enabled by massive parameters compared\nto traditional methods. However, most of these methods encounter two critical\nchallenges: how to integrate knowledge into LLMs effectively and how to\nadaptively generate results with specific answer formats for various task\nsituations. To address these challenges, we propose a novel framework named\nGenKI, which aims to improve the OpenQA performance by exploring Knowledge\nIntegration and controllable Generation on LLMs simultaneously. Specifically,\nwe first train a dense passage retrieval model to retrieve associated knowledge\nfrom a given knowledge base. Subsequently, we introduce a novel knowledge\nintegration model that incorporates the retrieval knowledge into instructions\nduring fine-tuning to intensify the model. Furthermore, to enable controllable\ngeneration in LLMs, we leverage a certain fine-tuned LLM and an ensemble based\non text consistency incorporating all coherence, fluency, and answer format\nassurance. Finally, extensive experiments conducted on the TriviaQA, MSMARCO,\nand CMRC2018 datasets, featuring diverse answer formats, have demonstrated the\neffectiveness of GenKI with comparison of state-of-the-art baselines. Moreover,\nablation studies have disclosed a linear relationship between the frequency of\nretrieved knowledge and the model's ability to recall knowledge accurately\nagainst the ground truth. Our code of GenKI is available at\nhttps://github.com/USTC-StarTeam/GenKI", "published": "2025-05-26 08:18:33", "link": "http://arxiv.org/abs/2505.19660v1", "categories": ["cs.CL", "cs.AI", "68P20", "H.3.4; I.2.6"], "primary_category": "cs.CL"}
{"title": "Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation", "abstract": "Automatic related work generation (RWG) can save people's time and effort\nwhen writing a draft of related work section (RWS) for further revision.\nHowever, existing methods for RWG always suffer from shallow comprehension due\nto taking the limited portions of references papers as input and isolated\nexplanation for each reference due to ineffective capturing the relationships\namong them. To address these issues, we focus on full-text-based RWG task and\npropose a novel multi-agent framework. Our framework consists of three agents:\na selector that decides which section of the papers is going to read next, a\nreader that digests the selected section and updates a shared working memory,\nand a writer that generates RWS based on the final curated memory. To better\ncapture the relationships among references, we also propose two graph-aware\nstrategies for selector, enabling to optimize the reading order with constrains\nof the graph structure. Extensive experiments demonstrate that our framework\nconsistently improves performance across three base models and various input\nconfigurations. The graph-aware selectors outperform alternative selectors,\nachieving state-of-the-art results. The code and data are available at\nhttps://github.com/1190200817/Full_Text_RWG.", "published": "2025-05-26 08:02:34", "link": "http://arxiv.org/abs/2505.19647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond", "abstract": "Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the\npotential of Reinforcement Learning (RL) to enhance reasoning abilities in\nLarge Language Models (LLMs). While open-source replication efforts have\nprimarily focused on mathematical and coding domains, methods and resources for\ndeveloping general reasoning capabilities remain underexplored. This gap is\npartly due to the challenge of collecting diverse and verifiable reasoning data\nsuitable for RL. We hypothesize that logical reasoning is critical for\ndeveloping general reasoning capabilities, as logic forms a fundamental\nbuilding block of reasoning. In this work, we present SynLogic, a data\nsynthesis framework and dataset that generates diverse logical reasoning data\nat scale, encompassing 35 diverse logical reasoning tasks. The SynLogic\napproach enables controlled synthesis of data with adjustable difficulty and\nquantity. Importantly, all examples can be verified by simple rules, making\nthem ideally suited for RL with verifiable rewards. In our experiments, we\nvalidate the effectiveness of RL training on the SynLogic dataset based on 7B\nand 32B models. SynLogic leads to state-of-the-art logical reasoning\nperformance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B\nby 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and\ncoding tasks improves the training efficiency of these domains and\nsignificantly enhances reasoning generalization. Notably, our mixed training\nmodel outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These\nfindings position SynLogic as a valuable resource for advancing the broader\nreasoning capabilities of LLMs. We open-source both the data synthesis pipeline\nand the SynLogic dataset at https://github.com/MiniMax-AI/SynLogic.", "published": "2025-05-26 07:59:36", "link": "http://arxiv.org/abs/2505.19641v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Interleaved Reasoning for Large Language Models via Reinforcement Learning", "abstract": "Long chain-of-thought (CoT) significantly enhances large language models'\n(LLM) reasoning capabilities. However, the extensive reasoning traces lead to\ninefficiencies and an increased time-to-first-token (TTFT). We propose a novel\ntraining paradigm that uses reinforcement learning (RL) to guide reasoning LLMs\nto interleave thinking and answering for multi-hop questions. We observe that\nmodels inherently possess the ability to perform interleaved reasoning, which\ncan be further enhanced through RL. We introduce a simple yet effective\nrule-based reward to incentivize correct intermediate steps, which guides the\npolicy model toward correct reasoning paths by leveraging intermediate signals\ngenerated during interleaved reasoning. Extensive experiments conducted across\nfive diverse datasets and three RL algorithms (PPO, GRPO, and REINFORCE++)\ndemonstrate consistent improvements over traditional think-answer reasoning,\nwithout requiring external tools. Specifically, our approach reduces TTFT by\nover 80% on average and improves up to 19.3% in Pass@1 accuracy. Furthermore,\nour method, trained solely on question answering and logical reasoning\ndatasets, exhibits strong generalization ability to complex reasoning datasets\nsuch as MATH, GPQA, and MMLU. Additionally, we conduct in-depth analysis to\nreveal several valuable insights into conditional reward modeling.", "published": "2025-05-26 07:58:17", "link": "http://arxiv.org/abs/2505.19640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster and Better LLMs via Latency-Aware Test-Time Scaling", "abstract": "Test-Time Scaling (TTS) has proven effective in improving the performance of\nLarge Language Models (LLMs) during inference. However, existing research has\noverlooked the efficiency of TTS from a latency-sensitive perspective. Through\na latency-aware evaluation of representative TTS methods, we demonstrate that a\ncompute-optimal TTS does not always result in the lowest latency in scenarios\nwhere latency is critical. To address this gap and achieve latency-optimal TTS,\nwe propose two key approaches by optimizing the concurrency configurations: (1)\nbranch-wise parallelism, which leverages multiple concurrent inference\nbranches, and (2) sequence-wise parallelism, enabled by speculative decoding.\nBy integrating these two approaches and allocating computational resources\nproperly to each, our latency-optimal TTS enables a 32B model to reach 82.3%\naccuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4%\nwithin 10 seconds. Our work emphasizes the importance of latency-aware TTS and\ndemonstrates its ability to deliver both speed and accuracy in\nlatency-sensitive scenarios.", "published": "2025-05-26 07:51:30", "link": "http://arxiv.org/abs/2505.19634v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models", "abstract": "Word segmentation stands as a cornerstone of Natural Language Processing\n(NLP). Based on the concept of \"comprehend first, segment later\", we propose a\nnew framework to explore the limit of unsupervised word segmentation with Large\nLanguage Models (LLMs) and evaluate the semantic understanding capabilities of\nLLMs based on word segmentation. We employ current mainstream LLMs to perform\nword segmentation across multiple languages to assess LLMs' \"comprehension\".\nOur findings reveal that LLMs are capable of following simple prompts to\nsegment raw text into words. There is a trend suggesting that models with more\nparameters tend to perform better on multiple languages. Additionally, we\nintroduce a novel unsupervised method, termed LLACA ($\\textbf{L}$arge\n$\\textbf{L}$anguage Model-Inspired $\\textbf{A}$ho-$\\textbf{C}$orasick\n$\\textbf{A}$utomaton). Leveraging the advanced pattern recognition capabilities\nof Aho-Corasick automata, LLACA innovatively combines these with the deep\ninsights of well-pretrained LLMs. This approach not only enables the\nconstruction of a dynamic $n$-gram model that adjusts based on contextual\ninformation but also integrates the nuanced understanding of LLMs, offering\nsignificant improvements over traditional methods. Our source code is available\nat https://github.com/hkr04/LLACA", "published": "2025-05-26 07:48:15", "link": "http://arxiv.org/abs/2505.19631v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue", "abstract": "Large language models (LLMs) have demonstrated excellent capabilities in the\nfield of biomedical question answering, but their application in real-world\nclinical consultations still faces core challenges. Existing systems rely on a\none-way information transmission mode where patients must fully describe their\nsymptoms in a single round, leading to nonspecific diagnostic recommendations\nwhen complaints are vague. Traditional multi-turn dialogue methods based on\nsupervised learning are constrained by static data-driven paradigms, lacking\ngeneralizability and struggling to intelligently extract key clinical\ninformation. To address these limitations, we propose DoctorAgent-RL, a\nreinforcement learning (RL)-based multi-agent collaborative framework that\nmodels medical consultations as a dynamic decision-making process under\nuncertainty. The doctor agent continuously optimizes its questioning strategy\nwithin the RL framework through multi-turn interactions with the patient agent,\ndynamically adjusting its information-gathering path based on comprehensive\nrewards from the Consultation Evaluator. This RL fine-tuning mechanism enables\nLLMs to autonomously develop interaction strategies aligned with clinical\nreasoning logic, rather than superficially imitating patterns in existing\ndialogue data. Notably, we constructed MTMedDialog, the first English\nmulti-turn medical consultation dataset capable of simulating patient\ninteractions. Experiments demonstrate that DoctorAgent-RL outperforms existing\nmodels in both multi-turn reasoning capability and final diagnostic\nperformance, demonstrating practical value in assisting clinical consultations.\nhttps://github.com/JarvisUSTC/DoctorAgent-RL", "published": "2025-05-26 07:48:14", "link": "http://arxiv.org/abs/2505.19630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices", "abstract": "Large language models (LLMs) have the potential to revolutionize smart home\nassistants by enhancing their ability to accurately understand user needs and\nrespond appropriately, which is extremely beneficial for building a smarter\nhome environment. While recent studies have explored integrating LLMs into\nsmart home systems, they primarily focus on handling straightforward, valid\nsingle-device operation instructions. However, real-world scenarios are far\nmore complex and often involve users issuing invalid instructions or\ncontrolling multiple devices simultaneously. These have two main challenges:\nLLMs must accurately identify and rectify errors in user instructions and\nexecute multiple user instructions perfectly. To address these challenges and\nadvance the development of LLM-based smart home assistants, we introduce\nHomeBench, the first smart home dataset with valid and invalid instructions\nacross single and multiple devices in this paper. We have experimental results\non 13 distinct LLMs; e.g., GPT-4o achieves only a 0.0% success rate in the\nscenario of invalid multi-device instructions, revealing that the existing\nstate-of-the-art LLMs still cannot perform well in this situation even with the\nhelp of in-context learning, retrieval-augmented generation, and fine-tuning.\nOur code and dataset are publicly available at\nhttps://github.com/BITHLP/HomeBench.", "published": "2025-05-26 07:47:39", "link": "http://arxiv.org/abs/2505.19628v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think Again! The Effect of Test-Time Compute on Preferences, Opinions, and Beliefs of Large Language Models", "abstract": "As Large Language Models (LLMs) become deeply integrated into human life and\nincreasingly influence decision-making, it's crucial to evaluate whether and to\nwhat extent they exhibit subjective preferences, opinions, and beliefs. These\ntendencies may stem from biases within the models, which may shape their\nbehavior, influence the advice and recommendations they offer to users, and\npotentially reinforce certain viewpoints. This paper presents the Preference,\nOpinion, and Belief survey (POBs), a benchmark developed to assess LLMs'\nsubjective inclinations across societal, cultural, ethical, and personal\ndomains. We applied our benchmark to evaluate leading open- and closed-source\nLLMs, measuring desired properties such as reliability, neutrality, and\nconsistency. In addition, we investigated the effect of increasing the\ntest-time compute, through reasoning and self-reflection mechanisms, on those\nmetrics. While effective in other tasks, our results show that these mechanisms\noffer only limited gains in our domain. Furthermore, we reveal that newer model\nversions are becoming less consistent and more biased toward specific\nviewpoints, highlighting a blind spot and a concerning trend. POBS:\nhttps://ibm.github.io/POBS", "published": "2025-05-26 07:41:21", "link": "http://arxiv.org/abs/2505.19621v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Languages in Multilingual Speech Foundation Models Align Both Phonetically and Semantically", "abstract": "Cross-lingual alignment in pretrained language models (LMs) has enabled\nefficient transfer in text-based LMs. Such an alignment has also been observed\nin speech foundation models. However, it remains an open question whether\nfindings and methods from text-based cross-lingual alignment apply to speech.\nBuilding on prior work on spoken translation retrieval, we perform\npronunciation-controlled experiments to observe if cross-lingual alignment can\nindeed occur in such models on a semantic basis, instead of relying on phonetic\nsimilarities. Our findings indicate that even in the absence of phonetic cues,\nspoken translation retrieval accuracy remains relatively stable. We follow up\nwith a controlled experiment on a word-level dataset of cross-lingual synonyms\nand near-homophones, confirming the existence of both phonetic and semantic\nknowledge in the encoder. Finally, we qualitatively examine the transcriptions\nproduced by early exiting the encoder, where we observe that speech translation\nproduces semantic errors that are characterized by phonetic similarities to\ncorresponding words in the source language. We apply this insight from early\nexiting to speech recognition in seven low-resource languages unsupported by\nthe Whisper model, and achieve improved accuracy in all languages examined,\nparticularly for languages with transparent orthographies.", "published": "2025-05-26 07:21:20", "link": "http://arxiv.org/abs/2505.19606v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Machine Translation Models for English-Hindi Language Pairs: A Comparative Analysis", "abstract": "Machine translation has become a critical tool in bridging linguistic gaps,\nespecially between languages as diverse as English and Hindi. This paper\ncomprehensively evaluates various machine translation models for translating\nbetween English and Hindi. We assess the performance of these models using a\ndiverse set of automatic evaluation metrics, both lexical and machine\nlearning-based metrics. Our evaluation leverages an 18000+ corpus of English\nHindi parallel dataset and a custom FAQ dataset comprising questions from\ngovernment websites. The study aims to provide insights into the effectiveness\nof different machine translation approaches in handling both general and\nspecialized language domains. Results indicate varying performance levels\nacross different metrics, highlighting strengths and areas for improvement in\ncurrent translation systems.", "published": "2025-05-26 07:15:06", "link": "http://arxiv.org/abs/2505.19604v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Preference Optimization by Estimating the Ratio of the Data Distribution", "abstract": "Direct preference optimization (DPO) is widely used as a simple and stable\nmethod for aligning large language models (LLMs) with human preferences. This\npaper investigates a generalized DPO loss that enables a policy model to match\nthe target policy from a likelihood ratio estimation perspective. The ratio of\nthe target policy provides a unique identification of the policy distribution\nwithout relying on reward models or partition functions. This allows the\ngeneralized loss to retain both simplicity and theoretical guarantees, which\nprior work such as $f$-PO fails to achieve simultaneously. We propose Bregman\npreference optimization (BPO), a generalized framework for ratio matching that\nprovides a family of objective functions achieving target policy optimality.\nBPO subsumes DPO as a special case and offers tractable forms for all\ninstances, allowing implementation with a few lines of code. We further develop\nscaled Basu's power divergence (SBA), a gradient scaling method that can be\nused for BPO instances. The BPO framework complements other DPO variants and is\napplicable to target policies defined by these variants. In experiments, unlike\nother probabilistic loss extensions such as $f$-DPO or $f$-PO, which exhibit a\ntrade-off between generation fidelity and diversity, instances of BPO improve\nboth win rate and entropy compared with DPO. When applied to\nLlama-3-Instruct-8B, BPO achieves state-of-the-art performance among Llama-3-8B\nbackbones, with a 55.9\\% length-controlled win rate on AlpacaEval2.", "published": "2025-05-26 07:10:53", "link": "http://arxiv.org/abs/2505.19601v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar", "abstract": "Typical methods for evaluating the performance of language models evaluate\ntheir ability to answer questions accurately. These evaluation metrics are\nacceptable for determining the extent to which language models can understand\nand reason about text in a general sense, but fail to capture nuanced\ncapabilities, such as the ability of language models to recognize and obey rare\ngrammar points, particularly in languages other than English. We measure the\nperplexity of language models when confronted with the \"first person psych\npredicate restriction\" grammar point in Japanese. Weblab is the only tested\nopen source model in the 7-10B parameter range which consistently assigns\nhigher perplexity to ungrammatical psych predicate sentences than grammatical\nones. We give evidence that Weblab's uniformly bad tokenization is a possible\nroot cause for its good performance, and show that Llama 3's perplexity on\ngrammatical psych predicate sentences can be reduced by orders of magnitude\n(28x difference) by restricting test sentences to those with uniformly\nwell-behaved tokenizations. We show in further experiments on machine\ntranslation tasks that language models will use alternative grammar patterns in\norder to produce grammatical sentences when tokenization issues prevent the\nmost natural sentence from being output.", "published": "2025-05-26 07:08:47", "link": "http://arxiv.org/abs/2505.19599v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study", "abstract": "Large Audio-Language Models (LALMs) are increasingly deployed in real-world\napplications, yet their robustness against malicious audio injection attacks\nremains underexplored. This study systematically evaluates five leading LALMs\nacross four attack scenarios: Audio Interference Attack, Instruction Following\nAttack, Context Injection Attack, and Judgment Hijacking Attack. Using metrics\nlike Defense Success Rate, Context Robustness Score, and Judgment Robustness\nIndex, their vulnerabilities and resilience were quantitatively assessed.\nExperimental results reveal significant performance disparities among models;\nno single model consistently outperforms others across all attack types. The\nposition of malicious content critically influences attack effectiveness,\nparticularly when placed at the beginning of sequences. A negative correlation\nbetween instruction-following capability and robustness suggests models\nadhering strictly to instructions may be more susceptible, contrasting with\ngreater resistance by safety-aligned models. Additionally, system prompts show\nmixed effectiveness, indicating the need for tailored strategies. This work\nintroduces a benchmark framework and highlights the importance of integrating\nrobustness into training pipelines. Findings emphasize developing multi-modal\ndefenses and architectural designs that decouple capability from susceptibility\nfor secure LALMs deployment.", "published": "2025-05-26 07:08:38", "link": "http://arxiv.org/abs/2505.19598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Agent Collaboration via Evolving Orchestration", "abstract": "Large language models (LLMs) have achieved remarkable results across diverse\ndownstream tasks, but their monolithic nature restricts scalability and\nefficiency in complex problem-solving. While recent research explores\nmulti-agent collaboration among LLMs, most approaches rely on static\norganizational structures that struggle to adapt as task complexity and agent\nnumbers grow, resulting in coordination overhead and inefficiencies. To this\nend, we propose a puppeteer-style paradigm for LLM-based multi-agent\ncollaboration, where a centralized orchestrator (\"puppeteer\") dynamically\ndirects agents (\"puppets\") in response to evolving task states. This\norchestrator is trained via reinforcement learning to adaptively sequence and\nprioritize agents, enabling flexible and evolvable collective reasoning.\nExperiments on closed- and open-domain scenarios show that this method achieves\nsuperior performance with reduced computational costs. Analyses further reveal\nthat the key improvements consistently stem from the emergence of more compact,\ncyclic reasoning structures under the orchestrator's evolution.", "published": "2025-05-26 07:02:17", "link": "http://arxiv.org/abs/2505.19591v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Learning to Reason without External Rewards", "abstract": "Training large language models (LLMs) for complex reasoning via Reinforcement\nLearning with Verifiable Rewards (RLVR) is effective but limited by reliance on\ncostly, domain-specific supervision. We explore Reinforcement Learning from\nInternal Feedback (RLIF), a framework that enables LLMs to learn from intrinsic\nsignals without external rewards or labeled data. We propose Intuitor, an RLIF\nmethod that uses a model's own confidence, termed self-certainty, as its sole\nreward signal. Intuitor replaces external rewards in Group Relative Policy\nOptimization (GRPO) with self-certainty scores, enabling fully unsupervised\nlearning. Experiments demonstrate that Intuitor matches GRPO's performance on\nmathematical benchmarks while achieving superior generalization to\nout-of-domain tasks like code generation, without requiring gold solutions or\ntest cases. Our findings show that intrinsic model signals can drive effective\nlearning across domains, offering a scalable alternative to RLVR for autonomous\nAI systems where verifiable rewards are unavailable. Code is available at\nhttps://github.com/sunblaze-ucb/Intuitor", "published": "2025-05-26 07:01:06", "link": "http://arxiv.org/abs/2505.19590v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization", "abstract": "The Key-Value (KV) cache in generative large language models (LLMs)\nintroduces substantial memory overhead. Existing works mitigate this burden by\noffloading or compressing the KV cache. However, loading the entire cache\nincurs significant latency due to PCIe bandwidth bottlenecks in CPU-GPU\ncommunication, while aggressive compression causes notable performance\ndegradation. We identify that certain layers in the LLM need to maintain global\ninformation and are unsuitable for selective loading. In contrast, other layers\nprimarily focus on a few tokens with dominant activations that potentially\nincur substantial quantization error. This observation leads to a key insight\nthat loading dominant tokens and quantizing all tokens can complement each\nother. Building on this insight, we propose a hybrid compression method,\nTailorKV, which seamlessly integrates quantization and offloading. TailorKV\ndevelops an inference framework along with a hardware-friendly implementation\nthat leverages these complementary characteristics. Extensive long-context\nevaluations exhibit that TailorKV achieves nearly lossless performance under\naggressive compression settings, outperforming the state-of-the-art.\nParticularly, the Llama-3.1-8B with 128k context can be served within a single\nRTX 3090 GPU, reaching 82 ms per token during decoding.", "published": "2025-05-26 07:00:04", "link": "http://arxiv.org/abs/2505.19586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating Prefilling for Long-Context LLMs via Sparse Pattern Sharing", "abstract": "Sparse attention methods exploit the inherent sparsity in attention to speed\nup the prefilling phase of long-context inference, mitigating the quadratic\ncomplexity of full attention computation. While existing sparse attention\nmethods rely on predefined patterns or inaccurate estimations to approximate\nattention behavior, they often fail to fully capture the true dynamics of\nattention, resulting in reduced efficiency and compromised accuracy. Instead,\nwe propose a highly accurate sparse attention mechanism that shares similar yet\nprecise attention patterns across heads, enabling a more realistic capture of\nthe dynamic behavior of attention. Our approach is grounded in two key\nobservations: (1) attention patterns demonstrate strong inter-head similarity,\nand (2) this similarity remains remarkably consistent across diverse inputs. By\nstrategically sharing computed accurate patterns across attention heads, our\nmethod effectively captures actual patterns while requiring full attention\ncomputation for only a small subset of heads. Comprehensive evaluations\ndemonstrate that our approach achieves superior or comparable speedup relative\nto state-of-the-art methods while delivering the best overall accuracy.", "published": "2025-05-26 06:48:53", "link": "http://arxiv.org/abs/2505.19578v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DocMEdit: Towards Document-Level Model Editing", "abstract": "Model editing aims to correct errors and outdated knowledge in the Large\nlanguage models (LLMs) with minimal cost. Prior research has proposed a variety\nof datasets to assess the effectiveness of these model editing methods.\nHowever, most existing datasets only require models to output short phrases or\nsentences, overlooks the widespread existence of document-level tasks in the\nreal world, raising doubts about their practical usability. Aimed at addressing\nthis limitation and promoting the application of model editing in real-world\nscenarios, we propose the task of document-level model editing. To tackle such\nchallenges and enhance model capabilities in practical settings, we introduce\n\\benchmarkname, a dataset focused on document-level model editing,\ncharacterized by document-level inputs and outputs, extrapolative, and multiple\nfacts within a single edit. We propose a series of evaluation metrics and\nexperiments. The results show that the difficulties in document-level model\nediting pose challenges for existing model editing methods.", "published": "2025-05-26 06:37:24", "link": "http://arxiv.org/abs/2505.19572v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Text-to-Table for Reasoning-Intensive Table QA: Pipeline Design and Benchmarking Insights", "abstract": "Reasoning with tabular data holds increasing importance in modern\napplications, yet comprehensive evaluation methodologies for\nreasoning-intensive Table Question Answering (QA) tasks remain nascent.\nExisting research is constrained by two primary bottlenecks: 1) Reliance on\ncostly manually annotated real-world data, which is difficult to cover complex\nreasoning scenarios; 2) The heterogeneity of table structures hinders\nsystematic analysis of the intrinsic mechanisms behind the underperformance of\nLLMs, especially in reasoning-intensive tasks. To address these issues, we\npropose an automated generation pipeline AutoT2T that transforms mathematical\nword problems into table-based reasoning tasks, eliminating the need for manual\nannotation. The pipeline can generate multiple variants of a table for the same\nreasoning problem, including noisy versions to support robustness evaluation.\nBased on this, we construct a new benchmark TabularGSM, which systematically\nspans a range of table complexities and trap problems. Experimental analyses\nthrough AutoT2T and TabularGSM reveal that the tight coupling between reasoning\nand retrieval or identification processes is a key factor underlying the\nfailure of LLMs in complex Table QA tasks. This highlights the necessity for\nmodels to develop synergistic reasoning capabilities in order to perform\neffectively in complex Table QA tasks.", "published": "2025-05-26 06:24:31", "link": "http://arxiv.org/abs/2505.19563v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On the (Non) Injectivity of Piecewise Linear Janossy Pooling", "abstract": "Multiset functions, which are functions that map multisets to vectors, are a\nfundamental tool in the construction of neural networks for multisets and\ngraphs. To guarantee that the vector representation of the multiset is\nfaithful, it is often desirable to have multiset mappings that are both\ninjective and bi-Lipschitz. Currently, there are several constructions of\nmultiset functions achieving both these guarantees, leading to improved\nperformance in some tasks but often also to higher compute time than standard\nconstructions. Accordingly, it is natural to inquire whether simpler multiset\nfunctions achieving the same guarantees are available. In this paper, we make a\nlarge step towards giving a negative answer to this question. We consider the\nfamily of k-ary Janossy pooling, which includes many of the most popular\nmultiset models, and prove that no piecewise linear Janossy pooling function\ncan be injective. On the positive side, we show that when restricted to\nmultisets without multiplicities, even simple deep-sets models suffice for\ninjectivity and bi-Lipschitzness.", "published": "2025-05-26 15:53:09", "link": "http://arxiv.org/abs/2505.20150v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases", "abstract": "This paper focuses on using few-shot learning to improve the accuracy of\nclassifying OCT diagnosis images with major and rare classes. We used the\nGAN-based augmentation strategy as a baseline and introduced several novel\nmethods to further enhance our model. The proposed strategy contains U-GAT-IT\nfor improving the generative part and uses the data balance technique to narrow\ndown the skew of accuracy between all categories. The best model obtained was\nbuilt with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an\noverall accuracy of 97.85%, representing a significant improvement over the\noriginal baseline.", "published": "2025-05-26 15:49:44", "link": "http://arxiv.org/abs/2505.20149v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents", "abstract": "Spatial Planning is a crucial part in the field of spatial intelligence,\nwhich requires the understanding and planning about object arrangements in\nspace perspective. AI agents with the spatial planning ability can better adapt\nto various real-world applications, including robotic manipulation, automatic\nassembly, urban planning etc. Recent works have attempted to construct\nbenchmarks for evaluating the spatial intelligence of Multimodal Large Language\nModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatial\nreasoning based on typical Visual Question-Answering (VQA) forms, which suffers\nfrom the gap between abstract spatial understanding and concrete task\nexecution. In this work, we take a step further to build a comprehensive\nbenchmark called MineAnyBuild, aiming to evaluate the spatial planning ability\nof open-world AI agents in the Minecraft game. Specifically, MineAnyBuild\nrequires an agent to generate executable architecture building plans based on\nthe given multi-modal human instructions. It involves 4,000 curated spatial\nplanning tasks and also provides a paradigm for infinitely expandable data\ncollection by utilizing rich player-generated content. MineAnyBuild evaluates\nspatial planning through four core supporting dimensions: spatial\nunderstanding, spatial reasoning, creativity, and spatial commonsense. Based on\nMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based\nagents, revealing the severe limitations but enormous potential in their\nspatial planning abilities. We believe our MineAnyBuild will open new avenues\nfor the evaluation of spatial intelligence and help promote further development\nfor open-world AI agents capable of spatial planning.", "published": "2025-05-26 15:48:14", "link": "http://arxiv.org/abs/2505.20148v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks", "abstract": "Predictive Coding (PC) offers a biologically plausible alternative to\nbackpropagation for neural network training, yet struggles with deeper\narchitectures. This paper identifies the root cause: an inherent signal decay\nproblem where gradients attenuate exponentially with depth, becoming\ncomputationally negligible due to numerical precision constraints. To address\nthis fundamental limitation, we introduce Error Optimization (EO), a novel\nreparameterization that preserves PC's theoretical properties while eliminating\nsignal decay. By optimizing over prediction errors rather than states, EO\nenables signals to reach all layers simultaneously and without attenuation,\nconverging orders of magnitude faster than standard PC. Experiments across\nmultiple architectures and datasets demonstrate that EO matches\nbackpropagation's performance even for deeper models where conventional PC\nstruggles. Besides practical improvements, our work provides theoretical\ninsight into PC dynamics and establishes a foundation for scaling\nbiologically-inspired learning to deeper architectures on digital hardware and\nbeyond.", "published": "2025-05-26 15:39:16", "link": "http://arxiv.org/abs/2505.20137v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks", "abstract": "Tensorizing a neural network involves reshaping some or all of its dense\nweight matrices into higher-order tensors and approximating them using low-rank\ntensor network decompositions. This technique has shown promise as a model\ncompression strategy for large-scale neural networks. However, despite\nencouraging empirical results, tensorized neural networks (TNNs) remain\nunderutilized in mainstream deep learning. In this position paper, we offer a\nperspective on both the potential and current limitations of TNNs. We argue\nthat TNNs represent a powerful yet underexplored framework for deep\nlearning--one that deserves greater attention from both engineering and\ntheoretical communities. Beyond compression, we highlight the value of TNNs as\na flexible class of architectures with distinctive scaling properties and\nincreased interpretability. A central feature of TNNs is the presence of bond\nindices, which introduce new latent spaces not found in conventional networks.\nThese internal representations may provide deeper insight into the evolution of\nfeatures across layers, potentially advancing the goals of mechanistic\ninterpretability. We conclude by outlining several key research directions\naimed at overcoming the practical barriers to scaling and adopting TNNs in\nmodern deep learning workflows.", "published": "2025-05-26 15:32:28", "link": "http://arxiv.org/abs/2505.20132v1", "categories": ["cs.LG", "cs.AI", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Agentic AI Process Observability: Discovering Behavioral Variability", "abstract": "AI agents that leverage Large Language Models (LLMs) are increasingly\nbecoming core building blocks of modern software systems. A wide range of\nframeworks is now available to support the specification of such applications.\nThese frameworks enable the definition of agent setups using natural language\nprompting, which specifies the roles, goals, and tools assigned to the various\nagents involved. Within such setups, agent behavior is non-deterministic for\nany given input, highlighting the critical need for robust debugging and\nobservability tools. In this work, we explore the use of process and causal\ndiscovery applied to agent execution trajectories as a means of enhancing\ndeveloper observability. This approach aids in monitoring and understanding the\nemergent variability in agent behavior. Additionally, we complement this with\nLLM-based static analysis techniques to distinguish between intended and\nunintended behavioral variability. We argue that such instrumentation is\nessential for giving developers greater control over evolving specifications\nand for identifying aspects of functionality that may require more precise and\nexplicit definitions.", "published": "2025-05-26 15:26:07", "link": "http://arxiv.org/abs/2505.20127v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets", "abstract": "Current labor markets are strongly affected by the economic forces of adverse\nselection, moral hazard, and reputation, each of which arises due to\n$\\textit{incomplete information}$. These economic forces will still be\ninfluential after AI agents are introduced, and thus, agents must use\nmetacognitive and strategic reasoning to perform effectively. Metacognition is\na form of $\\textit{internal reasoning}$ that includes the capabilities for\nself-assessment, task understanding, and evaluation of strategies. Strategic\nreasoning is $\\textit{external reasoning}$ that covers holding beliefs about\nother participants in the labor market (e.g., competitors, colleagues), making\nstrategic decisions, and learning about others over time. Both types of\nreasoning are required by agents as they decide among the many\n$\\textit{actions}$ they can take in labor markets, both within and outside\ntheir jobs. We discuss current research into metacognitive and strategic\nreasoning and the areas requiring further development.", "published": "2025-05-26 15:22:04", "link": "http://arxiv.org/abs/2505.20120v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Spatiotemporal Causal Decoupling Model for Air Quality Forecasting", "abstract": "Due to the profound impact of air pollution on human health, livelihoods, and\neconomic development, air quality forecasting is of paramount significance.\nInitially, we employ the causal graph method to scrutinize the constraints of\nexisting research in comprehensively modeling the causal relationships between\nthe air quality index (AQI) and meteorological features. In order to enhance\nprediction accuracy, we introduce a novel air quality forecasting model,\nAirCade, which incorporates a causal decoupling approach. AirCade leverages a\nspatiotemporal module in conjunction with knowledge embedding techniques to\ncapture the internal dynamics of AQI. Subsequently, a causal decoupling module\nis proposed to disentangle synchronous causality from past AQI and\nmeteorological features, followed by the dissemination of acquired knowledge to\nfuture time steps to enhance performance. Additionally, we introduce a causal\nintervention mechanism to explicitly represent the uncertainty of future\nmeteorological features, thereby bolstering the model's robustness. Our\nevaluation of AirCade on an open-source air quality dataset demonstrates over\n20\\% relative improvement over state-of-the-art models.", "published": "2025-05-26 15:21:57", "link": "http://arxiv.org/abs/2505.20119v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Proxy-Free GFlowNet", "abstract": "Generative Flow Networks (GFlowNets) are a promising class of generative\nmodels designed to sample diverse, high-reward structures by modeling\ndistributions over compositional objects. In many real-world applications,\nobtaining the reward function for such objects is expensive, time-consuming, or\nrequires human input, making it necessary to train GFlowNets from historical\ndatasets. Most existing methods adopt a model-based approach, learning a proxy\nmodel from the dataset to approximate the reward function. However, this\nstrategy inherently ties the quality of the learned policy to the accuracy of\nthe proxy, introducing additional complexity and uncertainty into the training\nprocess. To overcome these limitations, we propose \\textbf{Trajectory-Distilled\nGFlowNet (TD-GFN)}, a \\emph{proxy-free} training framework that eliminates the\nneed for out-of-dataset reward queries. Our method is motivated by the key\nobservation that different edges in the associated directed acyclic graph (DAG)\ncontribute unequally to effective policy learning. TD-GFN leverages inverse\nreinforcement learning to estimate edge-level rewards from the offline dataset,\nwhich are then used to ingeniously prune the DAG and guide backward trajectory\nsampling during training. This approach directs the policy toward high-reward\nregions while reducing the complexity of model fitting. Empirical results\nacross multiple tasks show that TD-GFN trains both efficiently and reliably,\nsignificantly outperforming existing baselines in convergence speed and sample\nquality.", "published": "2025-05-26 15:12:22", "link": "http://arxiv.org/abs/2505.20110v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AdaTP: Attention-Debiased Token Pruning for Video Large Language Models", "abstract": "Video Large Language Models (Video LLMs) have achieved remarkable results in\nvideo understanding tasks. However, they often suffer from heavy computational\noverhead due to the large number of visual tokens generated from multiple video\nframes. Existing visual token compression methods often rely on attention\nscores from language models as guidance. However, these scores exhibit inherent\nbiases: global bias reflects a tendency to focus on the two ends of the visual\ntoken sequence, while local bias leads to an over-concentration on the same\nspatial positions across different frames. To address the issue of attention\nbias, we propose $\\textbf{A}$ttention-$\\textbf{D}$ebi$\\textbf{a}$sed\n$\\textbf{T}$oken $\\textbf{P}$runing for Video Large Language Models\n($\\textbf{AdaTP}$), a novel token pruning pipeline for Video LLMs. AdaTP\nintegrates two dedicated debiasing modules into the pipeline, targeting global\nattention bias and local attention bias, respectively. Without the need for\nadditional training, our method significantly reduces the computational\noverhead of Video LLMs while retaining the performance of vanilla models.\nExtensive evaluation shows that AdaTP achieves state-of-the-art performance in\nvarious commonly used video understanding benchmarks. In particular, on\nLLaVA-OneVision-7B, AdaTP maintains performance without degradation while using\nonly up to $27.3\\%$ FLOPs compared to the vanilla model. Our code will be\nreleased soon.", "published": "2025-05-26 15:08:37", "link": "http://arxiv.org/abs/2505.20100v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale", "abstract": "Can a scientific simulation system be physically consistent, interpretable by\ndesign, and scalable across regimes--all at once? Despite decades of progress,\nthis trifecta remains elusive. Classical methods like Kinetic Monte Carlo\nensure thermodynamic accuracy but scale poorly; learning-based methods offer\nefficiency but often sacrifice physical consistency and interpretability. We\npresent SwarmThinkers, a reinforcement learning framework that recasts\natomic-scale simulation as a physically grounded swarm intelligence system.\nEach diffusing particle is modeled as a local decision-making agent that\nselects transitions via a shared policy network trained under thermodynamic\nconstraints. A reweighting mechanism fuses learned preferences with transition\nrates, preserving statistical fidelity while enabling interpretable, step-wise\ndecision making. Training follows a centralized-training,\ndecentralized-execution paradigm, allowing the policy to generalize across\nsystem sizes, concentrations, and temperatures without retraining. On a\nbenchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers\nis the first system to achieve full-scale, physically consistent simulation on\na single A100 GPU, previously attainable only via OpenKMC on a supercomputer.\nIt delivers up to 4963x (3185x on average) faster computation with 485x lower\nmemory usage. By treating particles as decision-makers, not passive samplers,\nSwarmThinkers marks a paradigm shift in scientific simulation--one that unifies\nphysical consistency, interpretability, and scalability through agent-driven\nintelligence.", "published": "2025-05-26 15:04:37", "link": "http://arxiv.org/abs/2505.20094v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Homophily Enhanced Graph Domain Adaptation", "abstract": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs\nto unlabeled target graphs, addressing the challenge of label scarcity. In this\npaper, we highlight the significance of graph homophily, a pivotal factor for\ngraph domain alignment, which, however, has long been overlooked in existing\napproaches. Specifically, our analysis first reveals that homophily\ndiscrepancies exist in benchmarks. Moreover, we also show that homophily\ndiscrepancies degrade GDA performance from both empirical and theoretical\naspects, which further underscores the importance of homophily alignment in\nGDA. Inspired by this finding, we propose a novel homophily alignment algorithm\nthat employs mixed filters to smooth graph signals, thereby effectively\ncapturing and mitigating homophily discrepancies between graphs. Experimental\nresults on a variety of benchmarks verify the effectiveness of our method.", "published": "2025-05-26 15:02:08", "link": "http://arxiv.org/abs/2505.20089v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Explanation User Interfaces: A Systematic Literature Review", "abstract": "Artificial Intelligence (AI) is one of the major technological advancements\nof this century, bearing incredible potential for users through AI-powered\napplications and tools in numerous domains. Being often black-box (i.e., its\ndecision-making process is unintelligible), developers typically resort to\neXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour\nof AI models to produce systems that are transparent, fair, reliable, and\ntrustworthy. However, presenting explanations to the user is not trivial and is\noften left as a secondary aspect of the system's design process, leading to AI\nsystems that are not useful to end-users. This paper presents a Systematic\nLiterature Review on Explanation User Interfaces (XUIs) to gain a deeper\nunderstanding of the solutions and design guidelines employed in the academic\nliterature to effectively present explanations to users. To improve the\ncontribution and real-world impact of this survey, we also present a framework\nfor Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide\npractitioners and academics in the design and evaluation of XUIs.", "published": "2025-05-26 15:00:17", "link": "http://arxiv.org/abs/2505.20085v1", "categories": ["cs.HC", "cs.AI", "A.1"], "primary_category": "cs.HC"}
{"title": "Curriculum-RLAIF: Curriculum Alignment with Reinforcement Learning from AI Feedback", "abstract": "Reward models trained with conventional Reinforcement Learning from AI\nFeedback (RLAIF) methods suffer from limited generalizability, which hinders\nthe alignment performance of the policy model during reinforcement learning\n(RL). This challenge stems from various issues, including distribution shift,\npreference label noise, and mismatches between overly challenging samples and\nmodel capacity. In this paper, we attempt to enhance the generalizability of\nreward models through a data-centric approach, driven by the insight that these\nissues are inherently intertwined from the perspective of data difficulty. To\naddress this, we propose a novel framework, $\\textit{Curriculum-RLAIF}$, which\nconstructs preference pairs with varying difficulty levels and produces a\ncurriculum that progressively incorporates preference pairs of increasing\ndifficulty for reward model training. Our experimental results suggest that\nreward models trained with Curriculum-RLAIF achieve improved generalizability,\nsignificantly increasing the alignment performance of the policy model by a\nlarge margin without incurring additional inference costs compared to various\nnon-curriculum baselines. Detailed analysis and comparisons with alternative\napproaches, including data selection via external pretrained reward models or\ninternal self-selection mechanisms, as well as other curriculum strategies,\nfurther demonstrate the superiority of our approach in terms of simplicity,\nefficiency, and effectiveness.", "published": "2025-05-26 14:53:08", "link": "http://arxiv.org/abs/2505.20075v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On the Same Page: Dimensions of Perceived Shared Understanding in Human-AI Interaction", "abstract": "Shared understanding plays a key role in the effective communication in and\nperformance of human-human interactions. With the increasingly common\nintegration of AI into human contexts, the future of personal and workplace\ninteractions will likely see human-AI interaction (HAII) in which the\nperception of shared understanding is important. Existing literature has\naddressed the processes and effects of PSU in human-human interactions, but the\nconstrual remains underexplored in HAII. To better understand PSU in HAII, we\nconducted an online survey to collect user reflections on interactions with a\nlarge language model when it sunderstanding of a situation was thought to be\nsimilar to or different from the participant's. Through inductive thematic\nanalysis, we identified eight dimensions comprising PSU in human-AI\ninteractions: Fluency, aligned operation, fluidity, outcome satisfaction,\ncontextual awareness, lack of humanlike abilities, computational limits, and\nsuspicion.", "published": "2025-05-26 14:50:40", "link": "http://arxiv.org/abs/2505.20068v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Community Moderation and the New Epistemology of Fact Checking on Social Media", "abstract": "Social media platforms have traditionally relied on internal moderation teams\nand partnerships with independent fact-checking organizations to identify and\nflag misleading content. Recently, however, platforms including X (formerly\nTwitter) and Meta have shifted towards community-driven content moderation by\nlaunching their own versions of crowd-sourced fact-checking -- Community Notes.\nIf effectively scaled and governed, such crowd-checking initiatives have the\npotential to combat misinformation with increased scale and speed as\nsuccessfully as community-driven efforts once did with spam. Nevertheless,\ngeneral content moderation, especially for misinformation, is inherently more\ncomplex. Public perceptions of truth are often shaped by personal biases,\npolitical leanings, and cultural contexts, complicating consensus on what\nconstitutes misleading content. This suggests that community efforts, while\nvaluable, cannot replace the indispensable role of professional fact-checkers.\nHere we systemically examine the current approaches to misinformation detection\nacross major platforms, explore the emerging role of community-driven\nmoderation, and critically evaluate both the promises and challenges of\ncrowd-checking at scale.", "published": "2025-05-26 14:50:18", "link": "http://arxiv.org/abs/2505.20067v1", "categories": ["cs.SI", "cs.AI", "cs.CY"], "primary_category": "cs.SI"}
{"title": "Automated data curation for self-supervised learning in underwater acoustic analysis", "abstract": "The sustainability of the ocean ecosystem is threatened by increased levels\nof sound pollution, making monitoring crucial to understand its variability and\nimpact. Passive acoustic monitoring (PAM) systems collect a large amount of\nunderwater sound recordings, but the large volume of data makes manual analysis\nimpossible, creating the need for automation. Although machine learning offers\na potential solution, most underwater acoustic recordings are unlabeled.\nSelf-supervised learning models have demonstrated success in learning from\nlarge-scale unlabeled data in various domains like computer vision, Natural\nLanguage Processing, and audio. However, these models require large, diverse,\nand balanced datasets for training in order to generalize well. To address\nthis, a fully automated self-supervised data curation pipeline is proposed to\ncreate a diverse and balanced dataset from raw PAM data. It integrates\nAutomatic Identification System (AIS) data with recordings from various\nhydrophones in the U.S. waters. Using hierarchical k-means clustering, the raw\naudio data is sampled and then combined with AIS samples to create a balanced\nand diverse dataset. The resulting curated dataset enables the development of\nself-supervised learning models, facilitating various tasks such as monitoring\nmarine mammals and assessing sound pollution.", "published": "2025-05-26 14:50:04", "link": "http://arxiv.org/abs/2505.20066v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SafeDPO: A Simple Approach to Direct Preference Optimization with Enhanced Safety", "abstract": "As Large Language Models (LLMs) continue to advance and find applications\nacross a growing number of fields, ensuring the safety of LLMs has become\nincreasingly critical. To address safety concerns, recent studies have proposed\nintegrating safety constraints into Reinforcement Learning from Human Feedback\n(RLHF). However, these approaches tend to be complex, as they encompass\ncomplicated procedures in RLHF along with additional steps required by the\nsafety constraints. Inspired by Direct Preference Optimization (DPO), we\nintroduce a new algorithm called SafeDPO, which is designed to directly\noptimize the safety alignment objective in a single stage of policy learning,\nwithout requiring relaxation. SafeDPO introduces only one additional\nhyperparameter to further enhance safety and requires only minor modifications\nto standard DPO. As a result, it eliminates the need to fit separate reward and\ncost models or to sample from the language model during fine-tuning, while\nstill enhancing the safety of LLMs. Finally, we demonstrate that SafeDPO\nachieves competitive performance compared to state-of-the-art safety alignment\nalgorithms, both in terms of aligning with human preferences and improving\nsafety.", "published": "2025-05-26 14:50:01", "link": "http://arxiv.org/abs/2505.20065v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition", "abstract": "Effective human-AI interaction relies on AI's ability to accurately perceive\nand interpret human emotions. Current benchmarks for vision and vision-language\nmodels are severely limited, offering a narrow emotional spectrum that\noverlooks nuanced states (e.g., bitterness, intoxication) and fails to\ndistinguish subtle differences between related feelings (e.g., shame vs.\nembarrassment). Existing datasets also often use uncontrolled imagery with\noccluded faces and lack demographic diversity, risking significant bias. To\naddress these critical gaps, we introduce EmoNet Face, a comprehensive\nbenchmark suite. EmoNet Face features: (1) A novel 40-category emotion\ntaxonomy, meticulously derived from foundational research to capture finer\ndetails of human emotional experiences. (2) Three large-scale, AI-generated\ndatasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and\ncontrolled demographic balance across ethnicity, age, and gender. (3) Rigorous,\nmulti-expert annotations for training and high-fidelity evaluation. (4) We\nbuild Empathic Insight Face, a model achieving human-expert-level performance\non our benchmark. The publicly released EmoNet Face suite - taxonomy, datasets,\nand model - provides a robust foundation for developing and evaluating AI\nsystems with a deeper understanding of human emotions.", "published": "2025-05-26 14:19:58", "link": "http://arxiv.org/abs/2505.20033v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multiple Descents in Deep Learning as a Sequence of Order-Chaos Transitions", "abstract": "We observe a novel 'multiple-descent' phenomenon during the training process\nof LSTM, in which the test loss goes through long cycles of up and down trend\nmultiple times after the model is overtrained. By carrying out asymptotic\nstability analysis of the models, we found that the cycles in test loss are\nclosely associated with the phase transition process between order and chaos,\nand the local optimal epochs are consistently at the critical transition point\nbetween the two phases. More importantly, the global optimal epoch occurs at\nthe first transition from order to chaos, where the 'width' of the 'edge of\nchaos' is the widest, allowing the best exploration of better weight\nconfigurations for learning.", "published": "2025-05-26 14:18:22", "link": "http://arxiv.org/abs/2505.20030v1", "categories": ["cs.LG", "cs.AI", "nlin.CD", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)", "abstract": "Transformer-based language models, though not explicitly trained to mimic\nbrain recordings, have demonstrated surprising alignment with brain activity.\nProgress in these models-through increased size, instruction-tuning, and\nmultimodality-has led to better representational alignment with neural data.\nRecently, a new class of instruction-tuned multimodal LLMs (MLLMs) have\nemerged, showing remarkable zero-shot capabilities in open-ended multimodal\nvision tasks. However, it is unknown whether MLLMs, when prompted with natural\ninstructions, lead to better brain alignment and effectively capture\ninstruction-specific representations. To address this, we first investigate\nbrain alignment, i.e., measuring the degree of predictivity of neural visual\nactivity using text output response embeddings from MLLMs as participants\nengage in watching natural scenes. Experiments with 10 different instructions\nshow that MLLMs exhibit significantly better brain alignment than vision-only\nmodels and perform comparably to non-instruction-tuned multimodal models like\nCLIP. We also find that while these MLLMs are effective at generating\nhigh-quality responses suitable to the task-specific instructions, not all\ninstructions are relevant for brain alignment. Further, by varying\ninstructions, we make the MLLMs encode instruction-specific visual concepts\nrelated to the input image. This analysis shows that MLLMs effectively capture\ncount-related and recognition-related concepts, demonstrating strong alignment\nwith brain activity. Notably, the majority of the explained variance of the\nbrain encoding models is shared between MLLM embeddings of image captioning and\nother instructions. These results suggest that enhancing MLLMs' ability to\ncapture task-specific information could lead to better differentiation between\nvarious types of instructions, and thereby improving their precision in\npredicting brain responses.", "published": "2025-05-26 14:18:15", "link": "http://arxiv.org/abs/2505.20029v1", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage", "abstract": "We propose Gradient Inversion Transcript (GIT), a novel generative approach\nfor reconstructing training data from leaked gradients. GIT employs a\ngenerative attack model, whose architecture is tailored to align with the\nstructure of the leaked model based on theoretical analysis. Once trained\noffline, GIT can be deployed efficiently and only relies on the leaked\ngradients to reconstruct the input data, rendering it applicable under various\ndistributed learning environments. When used as a prior for other iterative\noptimization-based methods, GIT not only accelerates convergence but also\nenhances the overall reconstruction quality. GIT consistently outperforms\nexisting methods across multiple datasets and demonstrates strong robustness\nunder challenging conditions, including inaccurate gradients, data distribution\nshifts and discrepancies in model parameters.", "published": "2025-05-26 14:17:00", "link": "http://arxiv.org/abs/2505.20026v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving", "abstract": "Due to the powerful vision-language reasoning and generalization abilities,\nmultimodal large language models (MLLMs) have garnered significant attention in\nthe field of end-to-end (E2E) autonomous driving. However, their application to\nclosed-loop systems remains underexplored, and current MLLM-based methods have\nnot shown clear superiority to mainstream E2E imitation learning approaches. In\nthis work, we propose ReasonPlan, a novel MLLM fine-tuning framework designed\nfor closed-loop driving through holistic reasoning with a self-supervised Next\nScene Prediction task and supervised Decision Chain-of-Thought process. This\ndual mechanism encourages the model to align visual representations with\nactionable driving context, while promoting interpretable and causally grounded\ndecision making. We curate a planning-oriented decision reasoning dataset,\nnamely PDR, comprising 210k diverse and high-quality samples. Our method\noutperforms the mainstream E2E imitation learning method by a large margin of\n19% L2 and 16.1 driving score on Bench2Drive benchmark. Furthermore, ReasonPlan\ndemonstrates strong zero-shot generalization on unseen DOS benchmark,\nhighlighting its adaptability in handling zero-shot corner cases. Code and\ndataset will be found in https://github.com/Liuxueyi/ReasonPlan.", "published": "2025-05-26 14:12:38", "link": "http://arxiv.org/abs/2505.20024v1", "categories": ["cs.CV", "cs.AI", "cs.RO", "68T40(Primary), 68T45, 68T50(Secondary)", "I.2.9; I.2.10; I.5.1"], "primary_category": "cs.CV"}
{"title": "Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models", "abstract": "Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal\ncomprehension and reasoning capabilities, yet they often struggle with\ntrivially simple visual tasks. In this work, we focus on the domain of basic 2D\nEuclidean geometry and systematically categorize the fundamental, indivisible\nvisual perception skills, which we refer to as atomic visual skills. We then\nintroduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the\natomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find\nthat they struggle with these tasks, despite being trivial for adult humans.\nOur findings highlight the need for purpose-built datasets to train and\nevaluate VLMs on atomic, rather than composite, visual perception tasks.", "published": "2025-05-26 14:09:24", "link": "http://arxiv.org/abs/2505.20021v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Many Challenges of Human-Like Agents in Virtual Game Environments", "abstract": "Human-like agents are an increasingly important topic in games and beyond.\nBelievable non-player characters enhance the gaming experience by improving\nimmersion and providing entertainment. They also offer players the opportunity\nto engage with AI entities that can function as opponents, teachers, or\ncooperating partners. Additionally, in games where bots are prohibited -- and\neven more so in non-game environments -- there is a need for methods capable of\nidentifying whether digital interactions occur with bots or humans. This leads\nto two fundamental research questions: (1) how to model and implement\nhuman-like AI, and (2) how to measure its degree of human likeness.\n  This article offers two contributions. The first one is a survey of the most\nsignificant challenges in implementing human-like AI in games (or any virtual\nenvironment featuring simulated agents, although this article specifically\nfocuses on games). Thirteen such challenges, both conceptual and technical, are\ndiscussed in detail. The second is an empirical study performed in a tactical\nvideo game that addresses the research question: \"Is it possible to distinguish\nhuman players from bots (AI agents) based on empirical data?\" A\nmachine-learning approach using a custom deep recurrent convolutional neural\nnetwork is presented. We hypothesize that the more challenging it is to create\nhuman-like AI for a given game, the easier it becomes to develop a method for\ndistinguishing humans from AI-driven players.", "published": "2025-05-26 14:00:39", "link": "http://arxiv.org/abs/2505.20011v1", "categories": ["cs.AI", "cs.HC", "cs.MM", "68T01", "I.2; I.6.0; H.1.2"], "primary_category": "cs.AI"}
{"title": "ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications", "abstract": "Diffusion models (DMs) have recently achieved significant success in wireless\ncommunications systems due to their denoising capabilities. The broadcast\nnature of wireless signals makes them susceptible not only to Gaussian noise,\nbut also to unaware interference. This raises the question of whether DMs can\neffectively mitigate interference in wireless semantic communication systems.\nIn this paper, we model the interference cancellation problem as a maximum a\nposteriori (MAP) problem over the joint posterior probability of the signal and\ninterference, and theoretically prove that the solution provides excellent\nestimates for the signal and interference. To solve this problem, we develop an\ninterference cancellation diffusion model (ICDM), which decomposes the joint\nposterior into independent prior probabilities of the signal and interference,\nalong with the channel transition probablity. The log-gradients of these\ndistributions at each time step are learned separately by DMs and accurately\nestimated through deriving. ICDM further integrates these gradients with\nadvanced numerical iteration method, achieving accurate and rapid interference\ncancellation. Extensive experiments demonstrate that ICDM significantly reduces\nthe mean square error (MSE) and enhances perceptual quality compared to schemes\nwithout ICDM. For example, on the CelebA dataset under the Rayleigh fading\nchannel with a signal-to-noise ratio (SNR) of $20$ dB and signal to\ninterference plus noise ratio (SINR) of 0 dB, ICDM reduces the MSE by 4.54 dB\nand improves the learned perceptual image patch similarity (LPIPS) by 2.47 dB.", "published": "2025-05-26 13:41:52", "link": "http://arxiv.org/abs/2505.19983v1", "categories": ["cs.IT", "cs.AI", "cs.CV", "math.IT"], "primary_category": "cs.IT"}
{"title": "DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in Digital Forensics and Incident Response", "abstract": "Digital Forensics and Incident Response (DFIR) involves analyzing digital\nevidence to support legal investigations. Large Language Models (LLMs) offer\nnew opportunities in DFIR tasks such as log analysis and memory forensics, but\ntheir susceptibility to errors and hallucinations raises concerns in\nhigh-stakes contexts. Despite growing interest, there is no comprehensive\nbenchmark to evaluate LLMs across both theoretical and practical DFIR domains.\nTo address this gap, we present DFIR-Metric, a benchmark with three components:\n(1) Knowledge Assessment: a set of 700 expert-reviewed multiple-choice\nquestions sourced from industry-standard certifications and official\ndocumentation; (2) Realistic Forensic Challenges: 150 CTF-style tasks testing\nmulti-step reasoning and evidence correlation; and (3) Practical Analysis: 500\ndisk and memory forensics cases from the NIST Computer Forensics Tool Testing\nProgram (CFTT). We evaluated 14 LLMs using DFIR-Metric, analyzing both their\naccuracy and consistency across trials. We also introduce a new metric, the\nTask Understanding Score (TUS), designed to more effectively evaluate models in\nscenarios where they achieve near-zero accuracy. This benchmark offers a\nrigorous, reproducible foundation for advancing AI in digital forensics. All\nscripts, artifacts, and results are available on the project website at\nhttps://github.com/DFIR-Metric.", "published": "2025-05-26 13:35:37", "link": "http://arxiv.org/abs/2505.19973v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Learning to Select In-Context Demonstration Preferred by Large Language Model", "abstract": "In-context learning (ICL) enables large language models (LLMs) to adapt to\nnew tasks during inference using only a few demonstrations. However, ICL\nperformance is highly dependent on the selection of these demonstrations.\nRecent work explores retrieval-based methods for selecting query-specific\ndemonstrations, but these approaches often rely on surrogate objectives such as\nmetric learning, failing to directly optimize ICL performance. Consequently,\nthey struggle to identify truly beneficial demonstrations. Moreover, their\ndiscriminative retrieval paradigm is ineffective when the candidate pool lacks\nsufficient high-quality demonstrations. To address these challenges, we propose\nGenICL, a novel generative preference learning framework that leverages LLM\nfeedback to directly optimize demonstration selection for ICL. Experiments on\n19 datasets across 11 task categories demonstrate that GenICL achieves superior\nperformance than existing methods in selecting the most effective\ndemonstrations, leading to better ICL performance.", "published": "2025-05-26 13:26:56", "link": "http://arxiv.org/abs/2505.19966v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adaptive Location Hierarchy Learning for Long-Tailed Mobility Prediction", "abstract": "Human mobility prediction is crucial for applications ranging from\nlocation-based recommendations to urban planning, which aims to forecast users'\nnext location visits based on historical trajectories. Despite the severe\nlong-tailed distribution of locations, the problem of long-tailed mobility\nprediction remains largely underexplored. Existing long-tailed learning methods\nprimarily focus on rebalancing the skewed distribution at the data, model, or\nclass level, neglecting to exploit the spatiotemporal semantics of locations.\nTo address this gap, we propose the first plug-and-play framework for\nlong-tailed mobility prediction in an exploitation and exploration manner,\nnamed \\textbf{A}daptive \\textbf{LO}cation \\textbf{H}ier\\textbf{A}rchy learning\n(ALOHA). First, we construct city-tailored location hierarchy based on Large\nLanguage Models (LLMs) by exploiting Maslow's theory of human motivation to\ndesign Chain-of-Thought (CoT) prompts that captures spatiotemporal semantics.\nSecond, we optimize the location hierarchy predictions by Gumbel disturbance\nand node-wise adaptive weights within the hierarchical tree structure.\nExperiments on state-of-the-art models across six datasets demonstrate the\nframework's consistent effectiveness and generalizability, which strikes a well\nbalance between head and tail locations. Weight analysis and ablation studies\nreveal the optimization differences of each component for head and tail\nlocations. Furthermore, in-depth analyses of hierarchical distance and case\nstudy demonstrate the effective semantic guidance from the location hierarchy.\nOur code will be made publicly available.", "published": "2025-05-26 13:26:35", "link": "http://arxiv.org/abs/2505.19965v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Novel Loss-Enhanced Universal Adversarial Patches for Sustainable Speaker Privacy", "abstract": "Deep learning voice models are commonly used nowadays, but the safety\nprocessing of personal data, such as human identity and speech content, remains\nsuspicious. To prevent malicious user identification, speaker anonymization\nmethods were proposed. Current methods, particularly based on universal\nadversarial patch (UAP) applications, have drawbacks such as significant\ndegradation of audio quality, decreased speech recognition quality, low\ntransferability across different voice biometrics models, and performance\ndependence on the input audio length. To mitigate these drawbacks, in this\nwork, we introduce and leverage the novel Exponential Total Variance (TV) loss\nfunction and provide experimental evidence that it positively affects UAP\nstrength and imperceptibility. Moreover, we present a novel scalable UAP\ninsertion procedure and demonstrate its uniformly high performance for various\naudio lengths.", "published": "2025-05-26 13:16:01", "link": "http://arxiv.org/abs/2505.19951v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SaSi: A Self-augmented and Self-interpreted Deep Learning Approach for Few-shot Cryo-ET Particle Detection", "abstract": "Cryo-electron tomography (cryo-ET) has emerged as a powerful technique for\nimaging macromolecular complexes in their near-native states. However, the\nlocalization of 3D particles in cellular environments still presents a\nsignificant challenge due to low signal-to-noise ratios and missing wedge\nartifacts. Deep learning approaches have shown great potential, but they need\nhuge amounts of data, which can be a challenge in cryo-ET scenarios where\nlabeled data is often scarce. In this paper, we propose a novel Self-augmented\nand Self-interpreted (SaSi) deep learning approach towards few-shot particle\ndetection in 3D cryo-ET images. Our method builds upon self-augmentation\ntechniques to further boost data utilization and introduces a self-interpreted\nsegmentation strategy for alleviating dependency on labeled data, hence\nimproving generalization and robustness. As demonstrated by experiments\nconducted on both simulated and real-world cryo-ET datasets, the SaSi approach\nsignificantly outperforms existing state-of-the-art methods for particle\nlocalization. This research increases understanding of how to detect particles\nwith very few labels in cryo-ET and thus sets a new benchmark for few-shot\nlearning in structural biology.", "published": "2025-05-26 13:14:21", "link": "http://arxiv.org/abs/2505.19948v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dynamically Learned Test-Time Model Routing in Language Model Zoos with Service Level Guarantees", "abstract": "Open-weight LLM zoos provide access to numerous high-quality models, but\nselecting the appropriate model for specific tasks remains challenging and\nrequires technical expertise. Most users simply want factually correct, safe,\nand satisfying responses without concerning themselves with model\ntechnicalities, while inference service providers prioritize minimizing\noperating costs. These competing interests are typically mediated through\nservice level agreements (SLAs) that guarantee minimum service quality. We\nintroduce MESS+, a stochastic optimization algorithm for cost-optimal LLM\nrequest routing while providing rigorous SLA compliance guarantees. MESS+\nlearns request satisfaction probabilities of LLMs in real-time as users\ninteract with the system, based on which model selection decisions are made by\nsolving a per-request optimization problem. Our algorithm includes a novel\ncombination of virtual queues and request satisfaction prediction, along with a\ntheoretical analysis of cost optimality and constraint satisfaction. Across a\nwide range of state-of-the-art LLM benchmarks, MESS+ achieves an average of 2x\ncost savings compared to existing LLM routing techniques.", "published": "2025-05-26 13:11:08", "link": "http://arxiv.org/abs/2505.19947v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "I.2; I.2.7; I.2.8"], "primary_category": "cs.LG"}
{"title": "Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making", "abstract": "Large Language Models (LLMs) are increasingly used for decision making in\nembodied agents, yet existing safety evaluations often rely on coarse success\nrates and domain-specific setups, making it difficult to diagnose why and where\nthese models fail. This obscures our understanding of embodied safety and\nlimits the selective deployment of LLMs in high-risk physical environments. We\nintroduce SAFEL, the framework for systematically evaluating the physical\nsafety of LLMs in embodied decision making. SAFEL assesses two key\ncompetencies: (1) rejecting unsafe commands via the Command Refusal Test, and\n(2) generating safe and executable plans via the Plan Safety Test. Critically,\nthe latter is decomposed into functional modules, goal interpretation,\ntransition modeling, action sequencing, enabling fine-grained diagnosis of\nsafety failures. To support this framework, we introduce EMBODYGUARD, a\nPDDL-grounded benchmark containing 942 LLM-generated scenarios covering both\novertly malicious and contextually hazardous instructions. Evaluation across 13\nstate-of-the-art LLMs reveals that while models often reject clearly unsafe\ncommands, they struggle to anticipate and mitigate subtle, situational risks.\nOur results highlight critical limitations in current LLMs and provide a\nfoundation for more targeted, modular improvements in safe embodied reasoning.", "published": "2025-05-26 13:01:14", "link": "http://arxiv.org/abs/2505.19933v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TCP: a Benchmark for Temporal Constraint-Based Planning", "abstract": "Temporal reasoning and planning are essential capabilities for large language\nmodels (LLMs), yet most existing benchmarks evaluate them in isolation and\nunder limited forms of complexity. To address this gap, we introduce the\nTemporal Constraint-based Planning (TCP) benchmark, that jointly assesses both\ncapabilities. Each instance in TCP features a naturalistic dialogue around a\ncollaborative project, where diverse and interdependent temporal constraints\nare explicitly or implicitly expressed, and models must infer an optimal\nschedule that satisfies all constraints. To construct TCP, we first generate\nabstract problem prototypes that are paired with realistic scenarios from\nvarious domains and enriched into dialogues using an LLM. A human quality check\nis performed on a sampled subset to confirm the reliability of our benchmark.\nWe evaluate state-of-the-art LLMs and find that even the strongest models\nstruggle with TCP, highlighting its difficulty and revealing limitations in\nLLMs' temporal constraint-based planning abilities. We analyze underlying\nfailure cases, open source our benchmark, and hope our findings can inspire\nfuture research.", "published": "2025-05-26 12:53:01", "link": "http://arxiv.org/abs/2505.19927v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Responsible Face Recognition Approach for Small and Mid-Scale Systems Through Personalized Neural Networks", "abstract": "Traditional face recognition systems rely on extracting fixed face\nrepresentations, known as templates, to store and verify identities. These\nrepresentations are typically generated by neural networks that often lack\nexplainability and raise concerns regarding fairness and privacy. In this work,\nwe propose a novel model-template (MOTE) approach that replaces vector-based\nface templates with small personalized neural networks. This design enables\nmore responsible face recognition for small and medium-scale systems. During\nenrollment, MOTE creates a dedicated binary classifier for each identity,\ntrained to determine whether an input face matches the enrolled identity. Each\nclassifier is trained using only a single reference sample, along with\nsynthetically balanced samples to allow adjusting fairness at the level of a\nsingle individual during enrollment. Extensive experiments across multiple\ndatasets and recognition systems demonstrate substantial improvements in\nfairness and particularly in privacy. Although the method increases inference\ntime and storage requirements, it presents a strong solution for small- and\nmid-scale applications where fairness and privacy are critical.", "published": "2025-05-26 12:45:01", "link": "http://arxiv.org/abs/2505.19920v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Evaluating AI cyber capabilities with crowdsourced elicitation", "abstract": "As AI systems become increasingly capable, understanding their offensive\ncyber potential is critical for informed governance and responsible deployment.\nHowever, it's hard to accurately bound their capabilities, and some prior\nevaluations dramatically underestimated them. The art of extracting maximum\ntask-specific performance from AIs is called \"AI elicitation\", and today's\nsafety organizations typically conduct it in-house. In this paper, we explore\ncrowdsourcing elicitation efforts as an alternative to in-house elicitation\nwork.\n  We host open-access AI tracks at two Capture The Flag (CTF) competitions: AI\nvs. Humans (400 teams) and Cyber Apocalypse_ (4000 teams). The AI teams achieve\noutstanding performance at both events, ranking top-13% and top-21%\nrespectively for a total of \\$7500 in bounties. This impressive performance\nsuggests that open-market elicitation may offer an effective complement to\nin-house elicitation. We propose elicitation bounties as a practical mechanism\nfor maintaining timely, cost-effective situational awareness of emerging AI\ncapabilities.\n  Another advantage of open elicitations is the option to collect human\nperformance data at scale. Applying METR's methodology, we found that AI agents\ncan reliably solve cyber challenges requiring one hour or less of effort from a\nmedian human CTF participant.", "published": "2025-05-26 12:40:32", "link": "http://arxiv.org/abs/2505.19915v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM", "abstract": "Although LLMs demonstrate proficiency in several text-based reasoning and\nplanning tasks, their implementation in robotics control is constrained by\nsignificant deficiencies: (1) LLM agents are designed to work mainly with\ntextual inputs rather than visual conditions; (2) Current multimodal agents\ntreat LLMs as static planners, which separates their reasoning from environment\ndynamics, resulting in actions that do not take domain-specific knowledge into\naccount; and (3) LLMs are not designed to learn from visual interactions, which\nmakes it harder for them to make better policies for specific domains. In this\npaper, we introduce EMAC+, an Embodied Multimodal Agent that collaboratively\nintegrates LLM and VLM via a bidirectional training paradigm. Unlike existing\nmethods, EMAC+ dynamically refines high-level textual plans generated by an LLM\nusing real-time feedback from a VLM executing low-level visual control tasks.\nWe address critical limitations of previous models by enabling the LLM to\ninternalize visual environment dynamics directly through interactive\nexperience, rather than relying solely on static symbolic mappings. Extensive\nexperimental evaluations on ALFWorld and RT-1 benchmarks demonstrate that EMAC+\nachieves superior task performance, robustness against noisy observations, and\nefficient learning. We also conduct thorough ablation studies and provide\ndetailed analyses of success and failure cases.", "published": "2025-05-26 12:34:16", "link": "http://arxiv.org/abs/2505.19905v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging", "abstract": "While foundation models update slowly due to resource-intensive training\nrequirements, domain-specific models evolve between updates. Model merging aims\nto combine multiple expert models into a single, more capable model, thereby\nreducing storage and serving costs while supporting decentralized model\ndevelopment. Despite its potential, previous studies have primarily focused on\nmerging visual classification models or Large Language Models (LLMs) for code\nand math tasks. Multimodal Large Language Models (MLLMs), which extend the\ncapabilities of LLMs through large-scale multimodal training, have gained\ntraction. However, there lacks a benchmark for model merging research that\nclearly divides the tasks for MLLM training and evaluation. In this paper, (i)\nwe introduce the model merging benchmark for MLLMs, which includes multiple\ntasks such as VQA, Geometry, Chart, OCR, and Grounding, providing both LoRA and\nfull fine-tuning models. Moreover, we explore how model merging can combine\ndifferent modalities (e.g., vision-language, audio-language, and video-language\nmodels), moving toward the Omni-language model. (ii) We implement 10 model\nmerging algorithms on the benchmark. Furthermore, we propose a novel method\nthat removes noise from task vectors and robustly optimizes the merged vector\nbased on a loss defined over task vector interactions, achieving an average\nperformance gain of 2.48%. (iii) We find that model merging offers a promising\nway for building improved MLLMs without requiring data training. Our results\nalso demonstrate that the complementarity among multiple modalities outperforms\nindividual modalities.", "published": "2025-05-26 12:23:14", "link": "http://arxiv.org/abs/2505.19892v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deconstructing Obfuscation: A four-dimensional framework for evaluating Large Language Models assembly code deobfuscation capabilities", "abstract": "Large language models (LLMs) have shown promise in software engineering, yet\ntheir effectiveness for binary analysis remains unexplored. We present the\nfirst comprehensive evaluation of commercial LLMs for assembly code\ndeobfuscation. Testing seven state-of-the-art models against four obfuscation\nscenarios (bogus control flow, instruction substitution, control flow\nflattening, and their combination), we found striking performance\nvariations--from autonomous deobfuscation to complete failure. We propose a\ntheoretical framework based on four dimensions: Reasoning Depth, Pattern\nRecognition, Noise Filtering, and Context Integration, explaining these\nvariations. Our analysis identifies five error patterns: predicate\nmisinterpretation, structural mapping errors, control flow misinterpretation,\narithmetic transformation errors, and constant propagation errors, revealing\nfundamental limitations in LLM code processing.We establish a three-tier\nresistance model: bogus control flow (low resistance), control flow flattening\n(moderate resistance), and instruction substitution/combined techniques (high\nresistance). Universal failure against combined techniques demonstrates that\nsophisticated obfuscation remains effective against advanced LLMs. Our findings\nsuggest a human-AI collaboration paradigm where LLMs reduce expertise barriers\nfor certain reverse engineering tasks while requiring human guidance for\ncomplex deobfuscation. This work provides a foundation for evaluating emerging\ncapabilities and developing resistant obfuscation techniques.x deobfuscation.\nThis work provides a foundation for evaluating emerging capabilities and\ndeveloping resistant obfuscation techniques.", "published": "2025-05-26 12:16:44", "link": "http://arxiv.org/abs/2505.19887v1", "categories": ["cs.SE", "cs.AI", "cs.CR"], "primary_category": "cs.SE"}
{"title": "StyleAR: Customizing Multimodal Autoregressive Model for Style-Aligned Text-to-Image Generation", "abstract": "In the current research landscape, multimodal autoregressive (AR) models have\nshown exceptional capabilities across various domains, including visual\nunderstanding and generation. However, complex tasks such as style-aligned\ntext-to-image generation present significant challenges, particularly in data\nacquisition. In analogy to instruction-following tuning for image editing of AR\nmodels, style-aligned generation requires a reference style image and prompt,\nresulting in a text-image-to-image triplet where the output shares the style\nand semantics of the input. However, acquiring large volumes of such triplet\ndata with specific styles is considerably more challenging than obtaining\nconventional text-to-image data used for training generative models. To address\nthis issue, we propose StyleAR, an innovative approach that combines a\nspecially designed data curation method with our proposed AR models to\neffectively utilize text-to-image binary data for style-aligned text-to-image\ngeneration. Our method synthesizes target stylized data using a reference style\nimage and prompt, but only incorporates the target stylized image as the image\nmodality to create high-quality binary data. To facilitate binary data\ntraining, we introduce a CLIP image encoder with a perceiver resampler that\ntranslates the image input into style tokens aligned with multimodal tokens in\nAR models and implement a style-enhanced token technique to prevent content\nleakage which is a common issue in previous work. Furthermore, we mix raw\nimages drawn from large-scale text-image datasets with stylized images to\nenhance StyleAR's ability to extract richer stylistic features and ensure style\nconsistency. Extensive qualitative and quantitative experiments demonstrate our\nsuperior performance.", "published": "2025-05-26 12:01:15", "link": "http://arxiv.org/abs/2505.19874v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Deep Active Inference Agents for Delayed and Long-Horizon Environments", "abstract": "With the recent success of world-model agents, which extend the core idea of\nmodel-based reinforcement learning by learning a differentiable model for\nsample-efficient control across diverse tasks, active inference (AIF) offers a\ncomplementary, neuroscience-grounded paradigm that unifies perception,\nlearning, and action within a single probabilistic framework powered by a\ngenerative model. Despite this promise, practical AIF agents still rely on\naccurate immediate predictions and exhaustive planning, a limitation that is\nexacerbated in delayed environments requiring plans over long horizons, tens to\nhundreds of steps. Moreover, most existing agents are evaluated on robotic or\nvision benchmarks which, while natural for biological agents, fall short of\nreal-world industrial complexity. We address these limitations with a\ngenerative-policy architecture featuring (i) a multi-step latent transition\nthat lets the generative model predict an entire horizon in a single\nlook-ahead, (ii) an integrated policy network that enables the transition and\nreceives gradients of the expected free energy, (iii) an alternating\noptimization scheme that updates model and policy from a replay buffer, and\n(iv) a single gradient step that plans over long horizons, eliminating\nexhaustive planning from the control loop. We evaluate our agent in an\nenvironment that mimics a realistic industrial scenario with delayed and\nlong-horizon settings. The empirical results confirm the effectiveness of the\nproposed approach, demonstrating the coupled world-model with the AIF formalism\nyields an end-to-end probabilistic controller capable of effective decision\nmaking in delayed, long-horizon settings without handcrafted rewards or\nexpensive planning.", "published": "2025-05-26 11:50:22", "link": "http://arxiv.org/abs/2505.19867v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Two Causally Related Needles in a Video Haystack", "abstract": "Evaluating the video understanding capabilities of Video-Language Models\n(VLMs) remains a significant challenge. We propose a long-context video\nunderstanding benchmark, Causal2Needles, that assesses two crucial abilities\ninsufficiently evaluated by existing benchmarks: (1) the ability to extract\ninformation from two separate locations in a long video and understand them\njointly, and (2) the ability to model the world in terms of cause and effect in\nhuman behaviors. Specifically, Causal2Needles introduces 2-needle questions,\nwhich require extracting information from both the cause and effect\nhuman-behavior events in a long video and the associated narration text. To\nprevent textual bias, these questions comprise two complementary formats: one\nasking to identify the video clip containing the answer, and one asking for the\ntextual description of an unrelated visual detail from that video clip. Our\nexperiments reveal that models excelling in pre-existing benchmarks struggle\nwith 2-needle visual grounding, and the model performance is negatively\ncorrelated with the distance between the two needles. These findings highlight\ncritical limitations in current VLMs.", "published": "2025-05-26 11:37:34", "link": "http://arxiv.org/abs/2505.19853v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning", "abstract": "Sparse-reward reinforcement learning (RL) can model a wide range of highly\ncomplex tasks. Solving sparse-reward tasks is RL's core premise - requiring\nefficient exploration coupled with long-horizon credit assignment - and\novercoming these challenges is key for building self-improving agents with\nsuperhuman ability. We argue that solving complex and high-dimensional tasks\nrequires solving simpler tasks that are relevant to the target task. In\ncontrast, most prior work designs strategies for selecting exploratory tasks\nwith the objective of solving any task, making exploration of challenging\nhigh-dimensional, long-horizon tasks intractable. We find that the sense of\ndirection, necessary for effective exploration, can be extracted from existing\nRL algorithms, without needing any prior information. Based on this finding, we\npropose a method for directed sparse-reward goal-conditioned very long-horizon\nRL (DISCOVER), which selects exploratory goals in the direction of the target\ntask. We connect DISCOVER to principled exploration in bandits, formally\nbounding the time until the target task becomes achievable in terms of the\nagent's initial distance to the target, but independent of the volume of the\nspace of all tasks. Empirically, we perform a thorough evaluation in\nhigh-dimensional environments. We find that the directed goal selection of\nDISCOVER solves exploration problems that are beyond the reach of prior\nstate-of-the-art exploration methods in RL.", "published": "2025-05-26 11:35:07", "link": "http://arxiv.org/abs/2505.19850v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to\nenhance the capabilities of language models by integrating external knowledge.\nDue to the diversity of data sources and the constraints of memory and\ncomputing resources, real-world data is often scattered in multiple devices.\nConventional RAGs that store massive amounts of scattered data centrally face\nincreasing privacy concerns and high computational costs. Additionally, RAG in\na central node raises latency issues when searching over a large-scale\nknowledge base. To address these challenges, we propose a distributed Knowledge\nGraph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where\neach edge device maintains a local knowledge base without the need to share it\nwith the cloud, instead sharing only summaries of its knowledge. Specifically,\nDGRAG has two main phases. In the Distributed Knowledge Construction phase,\nDGRAG organizes local knowledge using knowledge graphs, generating subgraph\nsummaries and storing them in a summary database in the cloud as information\nsharing. In the Collaborative Retrieval and Generation phase, DGRAG first\nperforms knowledge retrieval and answer generation locally, and a gate\nmechanism determines whether the query is beyond the scope of local knowledge\nor processing capabilities. For queries that exceed the local knowledge scope,\nthe cloud retrieves knowledge from the most relevant edges based on the\nsummaries and generates a more precise answer. Experimental results demonstrate\nthe effectiveness of the proposed DGRAG approach in significantly improving the\nquality of question-answering tasks over baseline approaches.", "published": "2025-05-26 11:31:58", "link": "http://arxiv.org/abs/2505.19847v1", "categories": ["cs.AI", "cs.DC"], "primary_category": "cs.AI"}
{"title": "PCDCNet: A Surrogate Model for Air Quality Forecasting with Physical-Chemical Dynamics and Constraints", "abstract": "Air quality forecasting (AQF) is critical for public health and environmental\nmanagement, yet remains challenging due to the complex interplay of emissions,\nmeteorology, and chemical transformations. Traditional numerical models, such\nas CMAQ and WRF-Chem, provide physically grounded simulations but are\ncomputationally expensive and rely on uncertain emission inventories. Deep\nlearning models, while computationally efficient, often struggle with\ngeneralization due to their lack of physical constraints. To bridge this gap,\nwe propose PCDCNet, a surrogate model that integrates numerical modeling\nprinciples with deep learning. PCDCNet explicitly incorporates emissions,\nmeteorological influences, and domain-informed constraints to model pollutant\nformation, transport, and dissipation. By combining graph-based spatial\ntransport modeling, recurrent structures for temporal accumulation, and\nrepresentation enhancement for local interactions, PCDCNet achieves\nstate-of-the-art (SOTA) performance in 72-hour station-level PM2.5 and O3\nforecasting while significantly reducing computational costs. Furthermore, our\nmodel is deployed in an online platform, providing free, real-time air quality\nforecasts, demonstrating its scalability and societal impact. By aligning deep\nlearning with physical consistency, PCDCNet offers a practical and\ninterpretable solution for AQF, enabling informed decision-making for both\npersonal and regulatory applications.", "published": "2025-05-26 11:27:07", "link": "http://arxiv.org/abs/2505.19842v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Revisiting Glorot Initialization for Long-Range Linear Recurrences", "abstract": "Proper initialization is critical for Recurrent Neural Networks (RNNs),\nparticularly in long-range reasoning tasks, where repeated application of the\nsame weight matrix can cause vanishing or exploding signals. A common baseline\nfor linear recurrences is Glorot initialization, designed to ensure stable\nsignal propagation--but derived under the infinite-width, fixed-length\nregime--an unrealistic setting for RNNs processing long sequences. In this\nwork, we show that Glorot initialization is in fact unstable: small positive\ndeviations in the spectral radius are amplified through time and cause the\nhidden state to explode. Our theoretical analysis demonstrates that sequences\nof length $t = O(\\sqrt{n})$, where $n$ is the hidden width, are sufficient to\ninduce instability. To address this, we propose a simple, dimension-aware\nrescaling of Glorot that shifts the spectral radius slightly below one,\npreventing rapid signal explosion or decay. These results suggest that standard\ninitialization schemes may break down in the long-sequence regime, motivating a\nseparate line of theory for stable recurrent initialization.", "published": "2025-05-26 11:04:59", "link": "http://arxiv.org/abs/2505.19827v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Foundation Models for Tabular Data within Systemic Contexts Need Grounding", "abstract": "Current research on tabular foundation models often overlooks the\ncomplexities of large-scale, real-world data by treating tables as isolated\nentities and assuming information completeness, thereby neglecting the vital\noperational context. To address this, we introduce the concept of Semantically\nLinked Tables (SLT), recognizing that tables are inherently connected to both\ndeclarative and procedural operational knowledge. We propose Foundation Models\nfor Semantically Linked Tables (FMSLT), which integrate these components to\nground tabular data within its true operational context. This comprehensive\nrepresentation unlocks the full potential of machine learning for complex,\ninterconnected tabular data across diverse domains. Realizing FMSLTs requires\naccess to operational knowledge that is often unavailable in public datasets,\nhighlighting the need for close collaboration between domain experts and\nresearchers. Our work exposes the limitations of current tabular foundation\nmodels and proposes a new direction centered on FMSLTs, aiming to advance\nrobust, context-aware models for structured data.", "published": "2025-05-26 11:02:51", "link": "http://arxiv.org/abs/2505.19825v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "LAPA-based Dynamic Privacy Optimization for Wireless Federated Learning in Heterogeneous Environments", "abstract": "Federated Learning (FL) is a distributed machine learning paradigm based on\nprotecting data privacy of devices, which however, can still be broken by\ngradient leakage attack via parameter inversion techniques. Differential\nprivacy (DP) technology reduces the risk of private data leakage by adding\nartificial noise to the gradients, but detrimental to the FL utility at the\nsame time, especially in the scenario where the data is Non-Independent\nIdentically Distributed (Non-IID). Based on the impact of heterogeneous data on\naggregation performance, this paper proposes a Lightweight Adaptive Privacy\nAllocation (LAPA) strategy, which assigns personalized privacy budgets to\ndevices in each aggregation round without transmitting any additional\ninformation beyond gradients, ensuring both privacy protection and aggregation\nefficiency. Furthermore, the Deep Deterministic Policy Gradient (DDPG)\nalgorithm is employed to optimize the transmission power, in order to determine\nthe optimal timing at which the adaptively attenuated artificial noise aligns\nwith the communication noise, enabling an effective balance between DP and\nsystem utility. Finally, a reliable aggregation strategy is designed by\nintegrating communication quality and data distribution characteristics, which\nimproves aggregation performance while preserving privacy. Experimental results\ndemonstrate that the personalized noise allocation and dynamic optimization\nstrategy based on LAPA proposed in this paper enhances convergence performance\nwhile satisfying the privacy requirements of FL.", "published": "2025-05-26 11:00:31", "link": "http://arxiv.org/abs/2505.19823v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FinLoRA: Benchmarking LoRA Methods for Fine-Tuning LLMs on Financial Datasets", "abstract": "Low-rank adaptation (LoRA) methods show great potential for scaling\npre-trained general-purpose Large Language Models (LLMs) to hundreds or\nthousands of use scenarios. However, their efficacy in high-stakes domains like\nfinance is rarely explored, e.g., passing CFA exams and analyzing SEC filings.\nIn this paper, we present the open-source FinLoRA project that benchmarks LoRA\nmethods on both general and highly professional financial tasks. First, we\ncurated 19 datasets covering diverse financial applications; in particular, we\ncreated four novel XBRL analysis datasets based on 150 SEC filings. Second, we\nevaluated five LoRA methods and five base LLMs. Finally, we provide extensive\nexperimental results in terms of accuracy, F1, and BERTScore and report\ncomputational cost in terms of time and GPU memory during fine-tuning and\ninference stages. We find that LoRA methods achieved substantial performance\ngains of 36\\% on average over base models. Our FinLoRA project provides an\naffordable and scalable approach to democratize financial intelligence to the\ngeneral public. Datasets, LoRA adapters, code, and documentation are available\nat https://github.com/Open-Finance-Lab/FinLoRA", "published": "2025-05-26 10:58:51", "link": "http://arxiv.org/abs/2505.19819v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees", "abstract": "In many real-world applications of regression, conditional probability\nestimation, and uncertainty quantification, exploiting symmetries rooted in\nphysics or geometry can dramatically improve generalization and sample\nefficiency. While geometric deep learning has made significant empirical\nadvances by incorporating group-theoretic structure, less attention has been\ngiven to statistical learning guarantees. In this paper, we introduce an\nequivariant representation learning framework that simultaneously addresses\nregression, conditional probability estimation, and uncertainty quantification\nwhile providing first-of-its-kind non-asymptotic statistical learning\nguarantees. Grounded in operator and group representation theory, our framework\napproximates the spectral decomposition of the conditional expectation\noperator, building representations that are both equivariant and disentangled\nalong independent symmetry subgroups. Empirical evaluations on synthetic\ndatasets and real-world robotics applications confirm the potential of our\napproach, matching or outperforming existing equivariant baselines in\nregression while additionally providing well-calibrated parametric uncertainty\nestimates.", "published": "2025-05-26 10:47:23", "link": "http://arxiv.org/abs/2505.19809v1", "categories": ["cs.LG", "cs.AI", "cs.RO", "43-06", "I.2.6; I.2.9; I.5.1"], "primary_category": "cs.LG"}
{"title": "The Missing Point in Vision Transformers for Universal Image Segmentation", "abstract": "Image segmentation remains a challenging task in computer vision, demanding\nrobust mask generation and precise classification. Recent mask-based approaches\nyield high-quality masks by capturing global context. However, accurately\nclassifying these masks, especially in the presence of ambiguous boundaries and\nimbalanced class distributions, remains an open challenge. In this work, we\nintroduce ViT-P, a novel two-stage segmentation framework that decouples mask\ngeneration from classification. The first stage employs a proposal generator to\nproduce class-agnostic mask proposals, while the second stage utilizes a\npoint-based classification model built on the Vision Transformer (ViT) to\nrefine predictions by focusing on mask central points. ViT-P serves as a\npre-training-free adapter, allowing the integration of various pre-trained\nvision transformers without modifying their architecture, ensuring adaptability\nto dense prediction tasks. Furthermore, we demonstrate that coarse and bounding\nbox annotations can effectively enhance classification without requiring\nadditional training on fine annotation datasets, reducing annotation costs\nwhile maintaining strong performance. Extensive experiments across COCO,\nADE20K, and Cityscapes datasets validate the effectiveness of ViT-P, achieving\nstate-of-the-art results with 54.0 PQ on ADE20K panoptic segmentation, 87.4\nmIoU on Cityscapes semantic segmentation, and 63.6 mIoU on ADE20K semantic\nsegmentation. The code and pretrained models are available at:\nhttps://github.com/sajjad-sh33/ViT-P}{https://github.com/sajjad-sh33/ViT-P.", "published": "2025-05-26 10:29:13", "link": "http://arxiv.org/abs/2505.19795v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Types of Relations: Defining Analogies with Category Theory", "abstract": "In order to behave intelligently both humans and machines have to represent\ntheir knowledge adequately for how it is used. Humans often use analogies to\ntransfer their knowledge to new domains, or help others with this transfer via\nexplanations. Hence, an important question is: What representation can be used\nto construct, find, and evaluate analogies? In this paper, we study features of\na domain that are important for constructing analogies. We do so by formalizing\nknowledge domains as categories. We use the well-known example of the analogy\nbetween the solar system and the hydrogen atom to demonstrate how to construct\ndomain categories. We also show how functors, pullbacks, and pushouts can be\nused to define an analogy, describe its core and a corresponding blend of the\nunderlying domains.", "published": "2025-05-26 10:22:44", "link": "http://arxiv.org/abs/2505.19792v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Alpay Algebra III: Observer-Coupled Collapse and the Temporal Drift of Identity", "abstract": "This paper introduces a formal framework for modeling observer-dependent\ncollapse dynamics and temporal identity drift within artificial and\nmathematical systems, grounded entirely in the symbolic foundations of Alpay\nAlgebra. Building upon the fixed-point emergence structures developed in Alpay\nAlgebra I and II, this third installment formalizes the observer-coupled\n{\\phi}-collapse process through transfinite categorical flows and\ncurvature-driven identity operators. We define a novel temporal drift mechanism\nas a recursive deformation of identity signatures under entangled observer\ninfluence, constructing categorical invariants that evolve across fold\niterations. The proposed system surpasses conventional identity modeling in\nexplainable AI (XAI) by encoding internal transformation history into a\nsymbolic fixed-point structure, offering provable traceability and temporal\ncoherence. Applications range from AI self-awareness architectures to formal\nlogic systems where identity is not static but dynamically induced by\nobservation. The theoretical results also offer a mathematically rigorous basis\nfor future AI systems with stable self-referential behavior, positioning Alpay\nAlgebra as a next-generation symbolic framework bridging category theory,\nidentity logic, and observer dynamics.", "published": "2025-05-26 10:20:12", "link": "http://arxiv.org/abs/2505.19790v1", "categories": ["math.CT", "cs.AI", "cs.LO", "18C10, 03G30, 68T01, 03B70, 03D80", "F.4.1; I.2.6; I.2.8"], "primary_category": "math.CT"}
{"title": "Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured Multi-Turn Decomposition", "abstract": "Large Reasoning Models (LRMs) are criticized for the excessively lengthy\nChain-of-Thought (CoT) to derive the final answer, suffering from high\nfirst-token and overall latency. Typically, the CoT of LRMs mixes multiple\nthinking units; each unit attempts to produce a candidate answer to the\noriginal query. Hence, a natural idea to improve efficiency is to reduce the\nunit number. Yet, the fact that the thinking units in vanilla CoT cannot be\nexplicitly managed renders doing so challenging. This paper introduces\nMulti-Turn Decomposition (MinD) to decode conventional CoT into a sequence of\nexplicit, structured, and turn-wise interactions to bridge the gap. In MinD,\nthe model provides a multi-turn response to the query, where each turn embraces\na thinking unit and yields a corresponding answer. The subsequent turns can\nreflect, verify, revise, or explore alternative approaches to both the thinking\nand answer parts of earlier ones. This not only makes the answer delivered more\nswiftly, but also enables explicit controls over the iterative reasoning\nprocess (i.e., users may halt or continue at any turn). We follow a supervised\nfine-tuning (SFT) then reinforcement learning (RL) paradigm to realize MinD. We\nfirst rephrase the outputs of an LRM into multi-turn formats by prompting\nanother LLM, and then tune the LRM with such data. Observing that the tuned\nmodel tends to consume even more tokens than the original one (probably due to\nthat the multi-turn formats introduce additional answer tokens), we advocate\nleveraging RL algorithms like GRPO to prioritize correct outputs with fewer\nturns. Trained on the MATH dataset using R1-Distill models, MinD can achieve up\nto ~70% reduction in both output token usage and time to first token (TTFT),\nwhile maintaining competitive performance on reasoning benchmarks such as\nMATH-500, AIME24, AMC23, and GPQA-Diamond.", "published": "2025-05-26 10:18:57", "link": "http://arxiv.org/abs/2505.19788v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MedDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support", "abstract": "Timely and personalized treatment decisions are essential across a wide range\nof healthcare settings where patient responses vary significantly and evolve\nover time. Clinical data used to support these decisions are often irregularly\nsampled, sparse, and noisy. Existing decision support systems commonly rely on\ndiscretization and imputation, which can distort critical temporal dynamics and\ndegrade decision quality. Moreover, they often overlook the clinical\nsignificance of irregular recording frequencies, filtering out patterns in how\nand when data is collected. Reinforcement Learning (RL) is a natural fit for\nclinical decision-making, enabling sequential, long-term optimization in\ndynamic, uncertain environments. However, most existing treatment\nrecommendation systems are model-free and trained solely on offline data,\nmaking them sample-inefficient, sensitive to data quality, and poorly\ngeneralizable across tasks or cohorts. To address these limitations, we propose\nMedDreamer, a two-phase model-based RL framework for personalized treatment\nrecommendation. MedDreamer uses a world model with an Adaptive Feature\nIntegration (AFI) module to effectively model irregular, sparse clinical data.\nThrough latent imagination, it simulates plausible patient trajectories to\nenhance learning, refining its policy using a mix of real and imagined\nexperiences. This enables learning policies that go beyond suboptimal\nhistorical decisions while remaining grounded in clinical data. To our\nknowledge, this is the first application of latent imagination to irregular\nhealthcare data. Evaluations on sepsis and mechanical ventilation (MV)\ntreatment using two large-scale EHR datasets show that MedDreamer outperforms\nboth model-free and model-based baselines in clinical outcomes and off-policy\nmetrics.", "published": "2025-05-26 10:16:39", "link": "http://arxiv.org/abs/2505.19785v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning", "abstract": "Developing scalable and generalizable reward engineering for reinforcement\nlearning (RL) is crucial for creating general-purpose agents, especially in the\nchallenging domain of robotic manipulation. While recent advances in reward\nengineering with Vision-Language Models (VLMs) have shown promise, their sparse\nreward nature significantly limits sample efficiency. This paper introduces\nTeViR, a novel method that leverages a pre-trained text-to-video diffusion\nmodel to generate dense rewards by comparing the predicted image sequence with\ncurrent observations. Experimental results across 11 complex robotic tasks\ndemonstrate that TeViR outperforms traditional methods leveraging sparse\nrewards and other state-of-the-art (SOTA) methods, achieving better sample\nefficiency and performance without ground truth environmental rewards. TeViR's\nability to efficiently guide agents in complex environments highlights its\npotential to advance reinforcement learning applications in robotic\nmanipulation.", "published": "2025-05-26 09:52:25", "link": "http://arxiv.org/abs/2505.19769v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\ndiverse tasks, but optimizing LLM-based agentic systems remains challenging due\nto the vast search space of agent configurations, prompting strategies, and\ncommunication patterns. Existing approaches often rely on heuristic-based\ntuning or exhaustive evaluation, which can be computationally expensive and\nsuboptimal. This paper proposes Agentic Predictor, a lightweight predictor for\nefficient agentic workflow evaluation. Agentic Predictor is equipped with a\nmulti-view workflow encoding technique that leverages multi-view representation\nlearning of agentic systems by incorporating code architecture, textual\nprompts, and interaction graph features. To achieve high predictive accuracy\nwhile significantly reducing the number of required workflow evaluations for\ntraining a predictor, Agentic Predictor employs cross-domain unsupervised\npretraining. By learning to approximate task success rates, Agentic Predictor\nenables fast and accurate selection of optimal agentic workflow configurations\nfor a given task, significantly reducing the need for expensive trial-and-error\nevaluations. Experiments on a carefully curated benchmark spanning three\ndomains show that our predictor outperforms state-of-the-art methods in both\npredictive accuracy and workflow utility, highlighting the potential of\nperformance predictors in streamlining the design of LLM-based agentic\nworkflows.", "published": "2025-05-26 09:46:50", "link": "http://arxiv.org/abs/2505.19764v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Language Model-Enhanced Message Passing for Heterophilic Graph Learning", "abstract": "Traditional graph neural networks (GNNs), which rely on homophily-driven\nmessage passing, struggle with heterophilic graphs where connected nodes\nexhibit dissimilar features and different labels. While existing methods\naddress heterophily through graph structure refinement or adaptation of\nneighbor aggregation functions, they often overlook the semantic potential of\nnode text, rely on suboptimal message representation for propagation and\ncompromise performance on homophilic graphs. To address these limitations, we\npropose a novel language model (LM)-enhanced message passing approach for\nheterophilic graph leaning (LEMP4HG). Specifically, in the context of\ntext-attributed graph, we provide paired node texts for LM to generate their\nconnection analysis, which are encoded and then fused with paired node textual\nembeddings through a gating mechanism. The synthesized messages are\nsemantically enriched and adaptively balanced with both nodes' information,\nwhich mitigates contradictory signals when neighbor aggregation in heterophilic\nregions. Furthermore, we introduce an active learning strategy guided by our\nheuristic MVRD (Modulated Variation of Reliable Distance), selectively\nenhancing node pairs suffer most from message passing, reducing the cost of\nanalysis generation and side effects on homophilic regions. Extensive\nexperiments validate that our approach excels on heterophilic graphs and\nperforms robustly on homophilic ones, with a graph convolutional network (GCN)\nbackbone and a practical budget.", "published": "2025-05-26 09:45:16", "link": "http://arxiv.org/abs/2505.19762v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning", "abstract": "While showing sophisticated reasoning abilities, large language models (LLMs)\nstill struggle with long-horizon decision-making tasks due to deficient\nexploration and long-term credit assignment, especially in sparse-reward\nscenarios. Inspired by the divide-and-conquer principle, we propose an\ninnovative framework **GLIDER** (**G**rounding **L**anguage Models as\nEff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical\n**R**einforcement Learning) that introduces a parameter-efficient and generally\napplicable hierarchy to LLM policies. We develop a scheme where the low-level\ncontroller is supervised with abstract, step-by-step plans that are learned and\ninstructed by the high-level policy. This design decomposes complicated\nproblems into a series of coherent chain-of-thought reasoning sub-tasks,\nproviding flexible temporal abstraction to significantly enhance exploration\nand learning for long-horizon tasks. Furthermore, GLIDER facilitates fast\nonline adaptation to non-stationary environments owing to the strong\ntransferability of its task-agnostic low-level skills. Experiments on\nScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent\nperformance gains, along with enhanced generalization capabilities.", "published": "2025-05-26 09:43:40", "link": "http://arxiv.org/abs/2505.19761v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection", "abstract": "Coding with hardware description languages (HDLs) such as Verilog is a\ntime-intensive and laborious task. With the rapid advancement of large language\nmodels (LLMs), there is increasing interest in applying LLMs to assist with HDL\ncoding. Recent efforts have demonstrated the potential of LLMs in translating\nnatural language to traditional HDL Verilog. Chisel, a next-generation HDL\nbased on Scala, introduces higher-level abstractions, facilitating more\nconcise, maintainable, and scalable hardware designs. However, the potential of\nusing LLMs for Chisel code generation remains largely unexplored. This work\nproposes ReChisel, an LLM-based agentic system designed to enhance the\neffectiveness of Chisel code generation. ReChisel incorporates a reflection\nmechanism to iteratively refine the quality of generated code using feedback\nfrom compilation and simulation processes, and introduces an escape mechanism\nto break free from non-progress loops. Experiments demonstrate that ReChisel\nsignificantly improves the success rate of Chisel code generation, achieving\nperformance comparable to state-of-the-art LLM-based agentic systems for\nVerilog code generation.", "published": "2025-05-26 09:20:07", "link": "http://arxiv.org/abs/2505.19734v1", "categories": ["cs.AI", "cs.AR"], "primary_category": "cs.AI"}
{"title": "OCN: Effectively Utilizing Higher-Order Common Neighbors for Better Link Prediction", "abstract": "Common Neighbors (CNs) and their higher-order variants are important pairwise\nfeatures widely used in state-of-the-art link prediction methods. However,\nexisting methods often struggle with the repetition across different orders of\nCNs and fail to fully leverage their potential. We identify that these\nlimitations stem from two key issues: redundancy and over-smoothing in\nhigh-order common neighbors. To address these challenges, we design\northogonalization to eliminate redundancy between different-order CNs and\nnormalization to mitigate over-smoothing. By combining these two techniques, we\npropose Orthogonal Common Neighbor (OCN), a novel approach that significantly\noutperforms the strongest baselines by an average of 7.7% on popular link\nprediction benchmarks. A thorough theoretical analysis is provided to support\nour method. Ablation studies also verify the effectiveness of our\northogonalization and normalization techniques.", "published": "2025-05-26 09:08:25", "link": "http://arxiv.org/abs/2505.19719v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting", "abstract": "Existing chain-of-thought (CoT) distillation methods can effectively transfer\nreasoning abilities to base models but suffer from two major limitations:\nexcessive verbosity of reasoning traces and inadequate adaptability to problem\ndifficulty. Long reasoning traces significantly increase inference costs, and\nuniform-length solutions prevent base models from learning adaptive reasoning\nstrategies. To address these issues, we propose a difficulty-aware prompting\n(DAP) method to dynamically shorten reasoning traces without performance loss.\nIn our approach, a large teacher model first judges each problem's difficulty\nand then rewrites its reasoning traces to an appropriate shorter length,\nyielding concise yet complete reasoning traces. Leveraging the DAP pipeline, we\ncurate a distilled dataset called LiteCoT consisting of 100K concise reasoning\nexamples, with solutions averaging only 720 tokens (an order of magnitude\nshorter than typical CoTs). Using LiteCoT, we distilled a new family of\nreasoning models called Liter (1.5B, 7B, and 32B) based on the Qwen2.5\narchitecture. Experiments show that a student model fine-tuned on just 100K of\nthese difficulty-pruned CoT samples outperforms a model distilled on 800K\noriginal Long CoT samples, while significantly reducing training and inference\ncosts. Our method also generalizes well: across 11 diverse benchmarks, the\nshorter difficulty-aware CoTs achieve equal or better accuracy than Long\nchains, using far fewer tokens. For example, on the challenging AIME24 exam,\nour approach reaches $74.2\\%$ Pass@1 using only about 5K inference tokens,\nsurpassing other methods that consume many more tokens. Our code and data are\navailable at https://github.com/Evanwu1125/LiteCoT.", "published": "2025-05-26 09:04:44", "link": "http://arxiv.org/abs/2505.19716v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mosaic: Data-Free Knowledge Distillation via Mixture-of-Experts for Heterogeneous Distributed Environments", "abstract": "Federated Learning (FL) is a decentralized machine learning paradigm that\nenables clients to collaboratively train models while preserving data privacy.\nHowever, the coexistence of model and data heterogeneity gives rise to\ninconsistent representations and divergent optimization dynamics across\nclients, ultimately hindering robust global performance. To transcend these\nchallenges, we propose Mosaic, a novel data-free knowledge distillation\nframework tailored for heterogeneous distributed environments. Mosaic first\ntrains local generative models to approximate each client's personalized\ndistribution, enabling synthetic data generation that safeguards privacy\nthrough strict separation from real data. Subsequently, Mosaic forms a\nMixture-of-Experts (MoE) from client models based on their specialized\nknowledge, and distills it into a global model using the generated data. To\nfurther enhance the MoE architecture, Mosaic integrates expert predictions via\na lightweight meta model trained on a few representative prototypes. Extensive\nexperiments on standard image classification benchmarks demonstrate that Mosaic\nconsistently outperforms state-of-the-art approaches under both model and data\nheterogeneity. The source code has been published at\nhttps://github.com/Wings-Of-Disaster/Mosaic.", "published": "2025-05-26 08:52:49", "link": "http://arxiv.org/abs/2505.19699v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning", "abstract": "Recent advances in model-based reinforcement learning (MBRL) have achieved\nsuper-human level performance on the Atari100k benchmark, driven by\nreinforcement learning agents trained on powerful diffusion world models.\nHowever, we identify that the current aggregates mask a major performance\nasymmetry: MBRL agents dramatically outperform humans in some tasks despite\ndrastically underperforming in others, with the former inflating the aggregate\nmetrics. This is especially pronounced in pixel-based agents trained with\ndiffusion world models. In this work, we address the pronounced asymmetry\nobserved in pixel-based agents as an initial attempt to reverse the worrying\nupward trend observed in them. We address the problematic aggregates by\ndelineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal\nimportance on metrics from both sets. Next, we hypothesize this pronounced\nasymmetry is due to the lack of temporally-structured latent space trained with\nthe World Model objective in pixel-based methods. Lastly, to address this\nissue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion\nworld model trained end-to-end with the self-consistency objective. JEDI\noutperforms SOTA models in human-optimal tasks while staying competitive across\nthe Atari100k benchmark, and runs 3 times faster with 43% lower memory than the\nlatest pixel-based diffusion baseline. Overall, our work rethinks what it truly\nmeans to cross human-level performance in Atari100k.", "published": "2025-05-26 08:52:45", "link": "http://arxiv.org/abs/2505.19698v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "EmoSphere-SER: Enhancing Speech Emotion Recognition Through Spherical Representation with Auxiliary Classification", "abstract": "Speech emotion recognition predicts a speaker's emotional state from speech\nsignals using discrete labels or continuous dimensions such as arousal,\nvalence, and dominance (VAD). We propose EmoSphere-SER, a joint model that\nintegrates spherical VAD region classification to guide VAD regression for\nimproved emotion prediction. In our framework, VAD values are transformed into\nspherical coordinates that are divided into multiple spherical regions, and an\nauxiliary classification task predicts which spherical region each point\nbelongs to, guiding the regression process. Additionally, we incorporate a\ndynamic weighting scheme and a style pooling layer with multi-head\nself-attention to capture spectral and temporal dynamics, further boosting\nperformance. This combined training strategy reinforces structured learning and\nimproves prediction consistency. Experimental results show that our approach\nexceeds baseline methods, confirming the validity of the proposed framework.", "published": "2025-05-26 08:50:23", "link": "http://arxiv.org/abs/2505.19693v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models", "abstract": "Uncertainty quantification is essential for assessing the reliability and\ntrustworthiness of modern AI systems. Among existing approaches, verbalized\nuncertainty, where models express their confidence through natural language,\nhas emerged as a lightweight and interpretable solution in large language\nmodels (LLMs). However, its effectiveness in vision-language models (VLMs)\nremains insufficiently studied. In this work, we conduct a comprehensive\nevaluation of verbalized confidence in VLMs, spanning three model categories,\nfour task domains, and three evaluation scenarios. Our results show that\ncurrent VLMs often display notable miscalibration across diverse tasks and\nsettings. Notably, visual reasoning models (i.e., thinking with images)\nconsistently exhibit better calibration, suggesting that modality-specific\nreasoning is critical for reliable uncertainty estimation. To further address\ncalibration challenges, we introduce Visual Confidence-Aware Prompting, a\ntwo-stage prompting strategy that improves confidence alignment in multimodal\nsettings. Overall, our study highlights the inherent miscalibration in VLMs\nacross modalities. More broadly, our findings underscore the fundamental\nimportance of modality alignment and model faithfulness in advancing reliable\nmultimodal systems.", "published": "2025-05-26 17:16:36", "link": "http://arxiv.org/abs/2505.20236v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Federated Learning With Missing Modalities through Feature Imputation Network", "abstract": "Multimodal federated learning holds immense potential for collaboratively\ntraining models from multiple sources without sharing raw data, addressing both\ndata scarcity and privacy concerns, two key challenges in healthcare. A major\nchallenge in training multimodal federated models in healthcare is the presence\nof missing modalities due to multiple reasons, including variations in clinical\npractice, cost and accessibility constraints, retrospective data collection,\nprivacy concerns, and occasional technical or human errors. Previous methods\ntypically rely on publicly available real datasets or synthetic data to\ncompensate for missing modalities. However, obtaining real datasets for every\ndisease is impractical, and training generative models to synthesize missing\nmodalities is computationally expensive and prone to errors due to the high\ndimensionality of medical data. In this paper, we propose a novel, lightweight,\nlow-dimensional feature translator to reconstruct bottleneck features of the\nmissing modalities. Our experiments on three different datasets (MIMIC-CXR, NIH\nOpen-I, and CheXpert), in both homogeneous and heterogeneous settings\nconsistently improve the performance of competitive baselines. The code and\nimplementation details are available at:\nhttps://github.com/bhattarailab/FedFeatGen", "published": "2025-05-26 17:11:03", "link": "http://arxiv.org/abs/2505.20232v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "PathBench: A comprehensive comparison benchmark for pathology foundation models towards precision oncology", "abstract": "The emergence of pathology foundation models has revolutionized computational\nhistopathology, enabling highly accurate, generalized whole-slide image\nanalysis for improved cancer diagnosis, and prognosis assessment. While these\nmodels show remarkable potential across cancer diagnostics and prognostics,\ntheir clinical translation faces critical challenges including variability in\noptimal model across cancer types, potential data leakage in evaluation, and\nlack of standardized benchmarks. Without rigorous, unbiased evaluation, even\nthe most advanced PFMs risk remaining confined to research settings, delaying\ntheir life-saving applications. Existing benchmarking efforts remain limited by\nnarrow cancer-type focus, potential pretraining data overlaps, or incomplete\ntask coverage. We present PathBench, the first comprehensive benchmark\naddressing these gaps through: multi-center in-hourse datasets spanning common\ncancers with rigorous leakage prevention, evaluation across the full clinical\nspectrum from diagnosis to prognosis, and an automated leaderboard system for\ncontinuous model assessment. Our framework incorporates large-scale data,\nenabling objective comparison of PFMs while reflecting real-world clinical\ncomplexity. All evaluation data comes from private medical providers, with\nstrict exclusion of any pretraining usage to avoid data leakage risks. We have\ncollected 15,888 WSIs from 8,549 patients across 10 hospitals, encompassing\nover 64 diagnosis and prognosis tasks. Currently, our evaluation of 19 PFMs\nshows that Virchow2 and H-Optimus-1 are the most effective models overall. This\nwork provides researchers with a robust platform for model development and\noffers clinicians actionable insights into PFM performance across diverse\nclinical scenarios, ultimately accelerating the translation of these\ntransformative technologies into routine pathology practice.", "published": "2025-05-26 16:42:22", "link": "http://arxiv.org/abs/2505.20202v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Long-Context State-Space Video World Models", "abstract": "Video diffusion models have recently shown promise for world modeling through\nautoregressive frame prediction conditioned on actions. However, they struggle\nto maintain long-term memory due to the high computational cost associated with\nprocessing extended sequences in attention layers. To overcome this limitation,\nwe propose a novel architecture leveraging state-space models (SSMs) to extend\ntemporal memory without compromising computational efficiency. Unlike previous\napproaches that retrofit SSMs for non-causal vision tasks, our method fully\nexploits the inherent advantages of SSMs in causal sequence modeling. Central\nto our design is a block-wise SSM scanning scheme, which strategically trades\noff spatial consistency for extended temporal memory, combined with dense local\nattention to ensure coherence between consecutive frames. We evaluate the\nlong-term memory capabilities of our model through spatial retrieval and\nreasoning tasks over extended horizons. Experiments on Memory Maze and\nMinecraft datasets demonstrate that our approach surpasses baselines in\npreserving long-range memory, while maintaining practical inference speeds\nsuitable for interactive applications.", "published": "2025-05-26 16:12:41", "link": "http://arxiv.org/abs/2505.20171v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters", "abstract": "Recent years have witnessed significant progress in audio-driven human\nanimation. However, critical challenges remain in (i) generating highly dynamic\nvideos while preserving character consistency, (ii) achieving precise emotion\nalignment between characters and audio, and (iii) enabling multi-character\naudio-driven animation. To address these challenges, we propose\nHunyuanVideo-Avatar, a multimodal diffusion transformer (MM-DiT)-based model\ncapable of simultaneously generating dynamic, emotion-controllable, and\nmulti-character dialogue videos. Concretely, HunyuanVideo-Avatar introduces\nthree key innovations: (i) A character image injection module is designed to\nreplace the conventional addition-based character conditioning scheme,\neliminating the inherent condition mismatch between training and inference.\nThis ensures the dynamic motion and strong character consistency; (ii) An Audio\nEmotion Module (AEM) is introduced to extract and transfer the emotional cues\nfrom an emotion reference image to the target generated video, enabling\nfine-grained and accurate emotion style control; (iii) A Face-Aware Audio\nAdapter (FAA) is proposed to isolate the audio-driven character with\nlatent-level face mask, enabling independent audio injection via\ncross-attention for multi-character scenarios. These innovations empower\nHunyuanVideo-Avatar to surpass state-of-the-art methods on benchmark datasets\nand a newly proposed wild dataset, generating realistic avatars in dynamic,\nimmersive scenarios.", "published": "2025-05-26 15:57:27", "link": "http://arxiv.org/abs/2505.20156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities", "abstract": "The rapid progress of large language models (LLMs) has catalyzed the\nemergence of multimodal large language models (MLLMs) that unify visual\nunderstanding and image generation within a single framework. However, most\nexisting MLLMs rely on autoregressive (AR) architectures, which impose inherent\nlimitations on future development, such as the raster-scan order in image\ngeneration and restricted reasoning abilities in causal context modeling. In\nthis work, we challenge the dominance of AR-based approaches by introducing\nFUDOKI, a unified multimodal model purely based on discrete flow matching, as\nan alternative to conventional AR paradigms. By leveraging metric-induced\nprobability paths with kinetic optimal velocities, our framework goes beyond\nthe previous masking-based corruption process, enabling iterative refinement\nwith self-correction capability and richer bidirectional context integration\nduring generation. To mitigate the high cost of training from scratch, we\ninitialize FUDOKI from pre-trained AR-based MLLMs and adaptively transition to\nthe discrete flow matching paradigm. Experimental results show that FUDOKI\nachieves performance comparable to state-of-the-art AR-based MLLMs across both\nvisual understanding and image generation tasks, highlighting its potential as\na foundation for next-generation unified multimodal models. Furthermore, we\nshow that applying test-time scaling techniques to FUDOKI yields significant\nperformance gains, further underscoring its promise for future enhancement\nthrough reinforcement learning.", "published": "2025-05-26 15:46:53", "link": "http://arxiv.org/abs/2505.20147v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Agentic 3D Scene Generation with Spatially Contextualized VLMs", "abstract": "Despite recent advances in multimodal content generation enabled by\nvision-language models (VLMs), their ability to reason about and generate\nstructured 3D scenes remains largely underexplored. This limitation constrains\ntheir utility in spatially grounded tasks such as embodied AI, immersive\nsimulations, and interactive 3D applications. We introduce a new paradigm that\nenables VLMs to generate, understand, and edit complex 3D environments by\ninjecting a continually evolving spatial context. Constructed from multimodal\ninput, this context consists of three components: a scene portrait that\nprovides a high-level semantic blueprint, a semantically labeled point cloud\ncapturing object-level geometry, and a scene hypergraph that encodes rich\nspatial relationships, including unary, binary, and higher-order constraints.\nTogether, these components provide the VLM with a structured, geometry-aware\nworking memory that integrates its inherent multimodal reasoning capabilities\nwith structured 3D understanding for effective spatial reasoning. Building on\nthis foundation, we develop an agentic 3D scene generation pipeline in which\nthe VLM iteratively reads from and updates the spatial context. The pipeline\nfeatures high-quality asset generation with geometric restoration, environment\nsetup with automatic verification, and ergonomic adjustment guided by the scene\nhypergraph. Experiments show that our framework can handle diverse and\nchallenging inputs, achieving a level of generalization not observed in prior\nwork. Further results demonstrate that injecting spatial context enables VLMs\nto perform downstream tasks such as interactive scene editing and path\nplanning, suggesting strong potential for spatially intelligent systems in\ncomputer graphics, 3D vision, and embodied applications.", "published": "2025-05-26 15:28:17", "link": "http://arxiv.org/abs/2505.20129v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender", "abstract": "Recent advancements in radiance field rendering, exemplified by Neural\nRadiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have significantly\nprogressed 3D modeling and reconstruction. The use of multiple 360-degree\nomnidirectional images for these tasks is increasingly favored due to\nadvantages in data acquisition and comprehensive scene capture. However, the\ninherent geometric distortions in common omnidirectional representations, such\nas equirectangular projection (particularly severe in polar regions and varying\nwith latitude), pose substantial challenges to achieving high-fidelity 3D\nreconstructions. Current datasets, while valuable, often lack the specific\nfocus, scene composition, and ground truth granularity required to\nsystematically benchmark and drive progress in overcoming these\nomnidirectional-specific challenges. To address this critical gap, we introduce\nOmnidirectional Blender 3D (OB3D), a new synthetic dataset curated for\nadvancing 3D reconstruction from multiple omnidirectional images. OB3D features\ndiverse and complex 3D scenes generated from Blender 3D projects, with a\ndeliberate emphasis on challenging scenarios. The dataset provides\ncomprehensive ground truth, including omnidirectional RGB images, precise\nomnidirectional camera parameters, and pixel-aligned equirectangular maps for\ndepth and normals, alongside evaluation metrics. By offering a controlled yet\nchallenging environment, OB3Daims to facilitate the rigorous evaluation of\nexisting methods and prompt the development of new techniques to enhance the\naccuracy and reliability of 3D reconstruction from omnidirectional images.", "published": "2025-05-26 15:25:29", "link": "http://arxiv.org/abs/2505.20126v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos", "abstract": "Videos are unique in their integration of temporal elements, including\ncamera, scene, action, and attribute, along with their dynamic relationships\nover time. However, existing benchmarks for video understanding often treat\nthese properties separately or narrowly focus on specific aspects, overlooking\nthe holistic nature of video content. To address this, we introduce TUNA, a\ntemporal-oriented benchmark for fine-grained understanding on dense dynamic\nvideos, with two complementary tasks: captioning and QA. Our TUNA features\ndiverse video scenarios and dynamics, assisted by interpretable and robust\nevaluation criteria. We evaluate several leading models on our benchmark,\nproviding fine-grained performance assessments across various dimensions. This\nevaluation reveals key challenges in video temporal understanding, such as\nlimited action description, inadequate multi-subject understanding, and\ninsensitivity to camera motion, offering valuable insights for improving video\nunderstanding models. The data and code are available at\nhttps://friedrichor.github.io/projects/TUNA.", "published": "2025-05-26 15:24:06", "link": "http://arxiv.org/abs/2505.20124v1", "categories": ["cs.CV", "cs.DB", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Understanding Generalization in Diffusion Models via Probability Flow Distance", "abstract": "Diffusion models have emerged as a powerful class of generative models,\ncapable of producing high-quality samples that generalize beyond the training\ndata. However, evaluating this generalization remains challenging: theoretical\nmetrics are often impractical for high-dimensional data, while no practical\nmetrics rigorously measure generalization. In this work, we bridge this gap by\nintroducing probability flow distance ($\\texttt{PFD}$), a theoretically\ngrounded and computationally efficient metric to measure distributional\ngeneralization. Specifically, $\\texttt{PFD}$ quantifies the distance between\ndistributions by comparing their noise-to-data mappings induced by the\nprobability flow ODE. Moreover, by using $\\texttt{PFD}$ under a teacher-student\nevaluation protocol, we empirically uncover several key generalization\nbehaviors in diffusion models, including: (1) scaling behavior from\nmemorization to generalization, (2) early learning and double descent training\ndynamics, and (3) bias-variance decomposition. Beyond these insights, our work\nlays a foundation for future empirical and theoretical studies on\ngeneralization in diffusion models.", "published": "2025-05-26 15:23:50", "link": "http://arxiv.org/abs/2505.20123v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MEBench: A Novel Benchmark for Understanding Mutual Exclusivity Bias in Vision-Language Models", "abstract": "This paper introduces MEBench, a novel benchmark for evaluating mutual\nexclusivity (ME) bias, a cognitive phenomenon observed in children during word\nlearning. Unlike traditional ME tasks, MEBench further incorporates spatial\nreasoning to create more challenging and realistic evaluation settings. We\nassess the performance of state-of-the-art vision-language models (VLMs) on\nthis benchmark using novel evaluation metrics that capture key aspects of\nME-based reasoning. To facilitate controlled experimentation, we also present a\nflexible and scalable data generation pipeline that supports the construction\nof diverse annotated scenes.", "published": "2025-05-26 15:23:18", "link": "http://arxiv.org/abs/2505.20122v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning", "abstract": "Text-to-multiview (T2MV) generation, which produces coherent multiview images\nfrom a single text prompt, remains computationally intensive, while accelerated\nT2MV methods using few-step diffusion models often sacrifice image fidelity and\nview consistency. To address this, we propose a novel reinforcement learning\n(RL) finetuning framework tailored for few-step T2MV diffusion models to\njointly optimize per-view fidelity and cross-view consistency. Specifically, we\nfirst reformulate T2MV denoising across all views as a single unified Markov\ndecision process, enabling multiview-aware policy optimization driven by a\njoint-view reward objective. Next, we introduce ZMV-Sampling, a test-time T2MV\nsampling technique that adds an inversion-denoising pass to reinforce both\nviewpoint and text conditioning, resulting in improved T2MV generation at the\ncost of inference time. To internalize its performance gains into the base\nsampling policy, we develop MV-ZigAL, a novel policy optimization strategy that\nuses reward advantages of ZMV-Sampling over standard sampling as learning\nsignals for policy updates. Finally, noting that the joint-view reward\nobjective under-optimizes per-view fidelity but naively optimizing single-view\nmetrics neglects cross-view alignment, we reframe RL finetuning for T2MV\ndiffusion models as a constrained optimization problem that maximizes per-view\nfidelity subject to an explicit joint-view constraint, thereby enabling more\nefficient and balanced policy updates. By integrating this constrained\noptimization paradigm with MV-ZigAL, we establish our complete RL finetuning\nframework, referred to as MVC-ZigAL, which effectively refines the few-step\nT2MV diffusion baseline in both fidelity and consistency while preserving its\nfew-step efficiency.", "published": "2025-05-26 15:11:26", "link": "http://arxiv.org/abs/2505.20107v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "From Data to Modeling: Fully Open-vocabulary Scene Graph Generation", "abstract": "We present OvSGTR, a novel transformer-based framework for fully\nopen-vocabulary scene graph generation that overcomes the limitations of\ntraditional closed-set models. Conventional methods restrict both object and\nrelationship recognition to a fixed vocabulary, hindering their applicability\nto real-world scenarios where novel concepts frequently emerge. In contrast,\nour approach jointly predicts objects (nodes) and their inter-relationships\n(edges) beyond predefined categories. OvSGTR leverages a DETR-like architecture\nfeaturing a frozen image backbone and text encoder to extract high-quality\nvisual and semantic features, which are then fused via a transformer decoder\nfor end-to-end scene graph prediction. To enrich the model's understanding of\ncomplex visual relations, we propose a relation-aware pre-training strategy\nthat synthesizes scene graph annotations in a weakly supervised manner.\nSpecifically, we investigate three pipelines--scene parser-based, LLM-based,\nand multimodal LLM-based--to generate transferable supervision signals with\nminimal manual annotation. Furthermore, we address the common issue of\ncatastrophic forgetting in open-vocabulary settings by incorporating a\nvisual-concept retention mechanism coupled with a knowledge distillation\nstrategy, ensuring that the model retains rich semantic cues during\nfine-tuning. Extensive experiments on the VG150 benchmark demonstrate that\nOvSGTR achieves state-of-the-art performance across multiple settings,\nincluding closed-set, open-vocabulary object detection-based, relation-based,\nand fully open-vocabulary scenarios. Our results highlight the promise of\nlarge-scale relation-aware pre-training and transformer architectures for\nadvancing scene graph generation towards more generalized and reliable visual\nunderstanding.", "published": "2025-05-26 15:11:23", "link": "http://arxiv.org/abs/2505.20106v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "M3DHMR: Monocular 3D Hand Mesh Recovery", "abstract": "Monocular 3D hand mesh recovery is challenging due to high degrees of freedom\nof hands, 2D-to-3D ambiguity and self-occlusion. Most existing methods are\neither inefficient or less straightforward for predicting the position of 3D\nmesh vertices. Thus, we propose a new pipeline called Monocular 3D Hand Mesh\nRecovery (M3DHMR) to directly estimate the positions of hand mesh vertices.\nM3DHMR provides 2D cues for 3D tasks from a single image and uses a new spiral\ndecoder consist of several Dynamic Spiral Convolution (DSC) Layers and a Region\nof Interest (ROI) Layer. On the one hand, DSC Layers adaptively adjust the\nweights based on the vertex positions and extract the vertex features in both\nspatial and channel dimensions. On the other hand, ROI Layer utilizes the\nphysical information and refines mesh vertices in each predefined hand region\nseparately. Extensive experiments on popular dataset FreiHAND demonstrate that\nM3DHMR significantly outperforms state-of-the-art real-time methods.", "published": "2025-05-26 14:44:47", "link": "http://arxiv.org/abs/2505.20058v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PAMD: Plausibility-Aware Motion Diffusion Model for Long Dance Generation", "abstract": "Computational dance generation is crucial in many areas, such as art,\nhuman-computer interaction, virtual reality, and digital entertainment,\nparticularly for generating coherent and expressive long dance sequences.\nDiffusion-based music-to-dance generation has made significant progress, yet\nexisting methods still struggle to produce physically plausible motions. To\naddress this, we propose Plausibility-Aware Motion Diffusion (PAMD), a\nframework for generating dances that are both musically aligned and physically\nrealistic. The core of PAMD lies in the Plausible Motion Constraint (PMC),\nwhich leverages Neural Distance Fields (NDFs) to model the actual pose manifold\nand guide generated motions toward a physically valid pose manifold. To provide\nmore effective guidance during generation, we incorporate Prior Motion Guidance\n(PMG), which uses standing poses as auxiliary conditions alongside music\nfeatures. To further enhance realism for complex movements, we introduce the\nMotion Refinement with Foot-ground Contact (MRFC) module, which addresses\nfoot-skating artifacts by bridging the gap between the optimization objective\nin linear joint position space and the data representation in nonlinear\nrotation space. Extensive experiments show that PAMD significantly improves\nmusical alignment and enhances the physical plausibility of generated motions.\nThis project page is available at: https://mucunzhuzhu.github.io/PAMD-page/.", "published": "2025-05-26 14:44:09", "link": "http://arxiv.org/abs/2505.20056v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data-Free Class-Incremental Gesture Recognition with Prototype-Guided Pseudo Feature Replay", "abstract": "Gesture recognition is an important research area in the field of computer\nvision. Most gesture recognition efforts focus on close-set scenarios, thereby\nlimiting the capacity to effectively handle unseen or novel gestures. We aim to\naddress class-incremental gesture recognition, which entails the ability to\naccommodate new and previously unseen gestures over time. Specifically, we\nintroduce a Prototype-Guided Pseudo Feature Replay (PGPFR) framework for\ndata-free class-incremental gesture recognition. This framework comprises four\ncomponents: Pseudo Feature Generation with Batch Prototypes (PFGBP),\nVariational Prototype Replay (VPR) for old classes, Truncated Cross-Entropy\n(TCE) for new classes, and Continual Classifier Re-Training (CCRT). To tackle\nthe issue of catastrophic forgetting, the PFGBP dynamically generates a\ndiversity of pseudo features in an online manner, leveraging class prototypes\nof old classes along with batch class prototypes of new classes. Furthermore,\nthe VPR enforces consistency between the classifier's weights and the\nprototypes of old classes, leveraging class prototypes and covariance matrices\nto enhance robustness and generalization capabilities. The TCE mitigates the\nimpact of domain differences of the classifier caused by pseudo features.\nFinally, the CCRT training strategy is designed to prevent overfitting to new\nclasses and ensure the stability of features extracted from old classes.\nExtensive experiments conducted on two widely used gesture recognition\ndatasets, namely SHREC 2017 3D and EgoGesture 3D, demonstrate that our approach\noutperforms existing state-of-the-art methods by 11.8\\% and 12.8\\% in terms of\nmean global accuracy, respectively. The code is available on\nhttps://github.com/sunao-101/PGPFR-3/.", "published": "2025-05-26 14:37:35", "link": "http://arxiv.org/abs/2505.20049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DepthMatch: Semi-Supervised RGB-D Scene Parsing through Depth-Guided Regularization", "abstract": "RGB-D scene parsing methods effectively capture both semantic and geometric\nfeatures of the environment, demonstrating great potential under challenging\nconditions such as extreme weather and low lighting. However, existing RGB-D\nscene parsing methods predominantly rely on supervised training strategies,\nwhich require a large amount of manually annotated pixel-level labels that are\nboth time-consuming and costly. To overcome these limitations, we introduce\nDepthMatch, a semi-supervised learning framework that is specifically designed\nfor RGB-D scene parsing. To make full use of unlabeled data, we propose\ncomplementary patch mix-up augmentation to explore the latent relationships\nbetween texture and spatial features in RGB-D image pairs. We also design a\nlightweight spatial prior injector to replace traditional complex fusion\nmodules, improving the efficiency of heterogeneous feature fusion. Furthermore,\nwe introduce depth-guided boundary loss to enhance the model's boundary\nprediction capabilities. Experimental results demonstrate that DepthMatch\nexhibits high applicability in both indoor and outdoor scenes, achieving\nstate-of-the-art results on the NYUv2 dataset and ranking first on the KITTI\nSemantics benchmark.", "published": "2025-05-26 14:26:31", "link": "http://arxiv.org/abs/2505.20041v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks", "abstract": "Generating high-quality piano audio from video requires precise\nsynchronization between visual cues and musical output, ensuring accurate\nsemantic and temporal alignment.However, existing evaluation datasets do not\nfully capture the intricate synchronization required for piano music\ngeneration. A comprehensive benchmark is essential for two primary reasons: (1)\nexisting metrics fail to reflect the complexity of video-to-piano music\ninteractions, and (2) a dedicated benchmark dataset can provide valuable\ninsights to accelerate progress in high-quality piano music generation. To\naddress these challenges, we introduce the CoP Benchmark Dataset-a fully\nopen-sourced, multimodal benchmark designed specifically for video-guided piano\nmusic generation. The proposed Chain-of-Perform (CoP) benchmark offers several\ncompelling features: (1) detailed multimodal annotations, enabling precise\nsemantic and temporal alignment between video content and piano audio via\nstep-by-step Chain-of-Perform guidance; (2) a versatile evaluation framework\nfor rigorous assessment of both general-purpose and specialized video-to-piano\ngeneration tasks; and (3) full open-sourcing of the dataset, annotations, and\nevaluation protocols. The dataset is publicly available at\nhttps://github.com/acappemin/Video-to-Audio-and-Piano, with a continuously\nupdated leaderboard to promote ongoing research in this domain.", "published": "2025-05-26 14:24:19", "link": "http://arxiv.org/abs/2505.20038v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers", "abstract": "Tactile sensing provides local essential information that is complementary to\nvisual perception, such as texture, compliance, and force. Despite recent\nadvances in visuotactile representation learning, challenges remain in fusing\nthese modalities and generalizing across tasks and environments without heavy\nreliance on pre-trained vision-language models. Moreover, existing methods do\nnot study positional encodings, thereby overlooking the multi-scale spatial\nreasoning needed to capture fine-grained visuotactile correlations. We\nintroduce ViTaPEs, a transformer-based framework that robustly integrates\nvisual and tactile input data to learn task-agnostic representations for\nvisuotactile perception. Our approach exploits a novel multi-scale positional\nencoding scheme to capture intra-modal structures, while simultaneously\nmodeling cross-modal cues. Unlike prior work, we provide provable guarantees in\nvisuotactile fusion, showing that our encodings are injective,\nrigid-motion-equivariant, and information-preserving, validating these\nproperties empirically. Experiments on multiple large-scale real-world datasets\nshow that ViTaPEs not only surpasses state-of-the-art baselines across various\nrecognition tasks but also demonstrates zero-shot generalization to unseen,\nout-of-domain scenarios. We further demonstrate the transfer-learning strength\nof ViTaPEs in a robotic grasping task, where it outperforms state-of-the-art\nbaselines in predicting grasp success. Project page:\nhttps://sites.google.com/view/vitapes", "published": "2025-05-26 14:19:29", "link": "http://arxiv.org/abs/2505.20032v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID", "abstract": "Multi-modal object re-identification (ReID) aims to extract identity features\nacross heterogeneous spectral modalities to enable accurate recognition and\nretrieval in complex real-world scenarios. However, most existing methods rely\non implicit feature fusion structures, making it difficult to model\nfine-grained recognition strategies under varying challenging conditions.\nBenefiting from the powerful semantic understanding capabilities of Multi-modal\nLarge Language Models (MLLMs), the visual appearance of an object can be\neffectively translated into descriptive text. In this paper, we propose a\nreliable multi-modal caption generation method based on attribute confidence,\nwhich significantly reduces the unknown recognition rate of MLLMs in\nmulti-modal semantic generation and improves the quality of generated text.\nAdditionally, we propose a novel ReID framework NEXT, the Multi-grained Mixture\nof Experts via Text-Modulation for Multi-modal Object Re-Identification.\nSpecifically, we decouple the recognition problem into semantic and structural\nexpert branches to separately capture modality-specific appearance and\nintrinsic structure. For semantic recognition, we propose the Text-Modulated\nSemantic-sampling Experts (TMSE), which leverages randomly sampled high-quality\nsemantic texts to modulate expert-specific sampling of multi-modal features and\nmining intra-modality fine-grained semantic cues. Then, to recognize\ncoarse-grained structure features, we propose the Context-Shared\nStructure-aware Experts (CSSE) that focuses on capturing the holistic object\nstructure across modalities and maintains inter-modality structural consistency\nthrough a soft routing mechanism. Finally, we propose the Multi-Modal Feature\nAggregation (MMFA), which adopts a unified feature fusion strategy to simply\nand effectively integrate semantic and structural expert outputs into the final\nidentity representations.", "published": "2025-05-26 13:52:28", "link": "http://arxiv.org/abs/2505.20001v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimizing edge AI models on HPC systems with the edge in the loop", "abstract": "Artificial intelligence and machine learning models deployed on edge devices,\ne.g., for quality control in Additive Manufacturing (AM), are frequently small\nin size. Such models usually have to deliver highly accurate results within a\nshort time frame. Methods that are commonly employed in literature start out\nwith larger trained models and try to reduce their memory and latency footprint\nby structural pruning, knowledge distillation, or quantization. It is, however,\nalso possible to leverage hardware-aware Neural Architecture Search (NAS), an\napproach that seeks to systematically explore the architecture space to find\noptimized configurations. In this study, a hardware-aware NAS workflow is\nintroduced that couples an edge device located in Belgium with a powerful\nHigh-Performance Computing system in Germany, to train possible architecture\ncandidates as fast as possible while performing real-time latency measurements\non the target hardware. The approach is verified on a use case in the AM\ndomain, based on the open RAISE-LPBF dataset, achieving ~8.8 times faster\ninference speed while simultaneously enhancing model quality by a factor of\n~1.35, compared to a human-designed baseline.", "published": "2025-05-26 13:47:36", "link": "http://arxiv.org/abs/2505.19995v1", "categories": ["cs.DC", "cs.CV", "I.2.6; D.1.3; I.2.8; I.5.1"], "primary_category": "cs.DC"}
{"title": "Progressive Scaling Visual Object Tracking", "abstract": "In this work, we propose a progressive scaling training strategy for visual\nobject tracking, systematically analyzing the influence of training data\nvolume, model size, and input resolution on tracking performance. Our empirical\nstudy reveals that while scaling each factor leads to significant improvements\nin tracking accuracy, naive training suffers from suboptimal optimization and\nlimited iterative refinement. To address this issue, we introduce DT-Training,\na progressive scaling framework that integrates small teacher transfer and\ndual-branch alignment to maximize model potential. The resulting scaled tracker\nconsistently outperforms state-of-the-art methods across multiple benchmarks,\ndemonstrating strong generalization and transferability of the proposed method.\nFurthermore, we validate the broader applicability of our approach to\nadditional tasks, underscoring its versatility beyond tracking.", "published": "2025-05-26 13:45:27", "link": "http://arxiv.org/abs/2505.19990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structured Initialization for Vision Transformers", "abstract": "Convolutional Neural Networks (CNNs) inherently encode strong inductive\nbiases, enabling effective generalization on small-scale datasets. In this\npaper, we propose integrating this inductive bias into ViTs, not through an\narchitectural intervention but solely through initialization. The motivation\nhere is to have a ViT that can enjoy strong CNN-like performance when data\nassets are small, but can still scale to ViT-like performance as the data\nexpands. Our approach is motivated by our empirical results that random impulse\nfilters can achieve commensurate performance to learned filters within a CNN.\nWe improve upon current ViT initialization strategies, which typically rely on\nempirical heuristics such as using attention weights from pretrained models or\nfocusing on the distribution of attention weights without enforcing structures.\nEmpirical results demonstrate that our method significantly outperforms\nstandard ViT initialization across numerous small and medium-scale benchmarks,\nincluding Food-101, CIFAR-10, CIFAR-100, STL-10, Flowers, and Pets, while\nmaintaining comparative performance on large-scale datasets such as\nImageNet-1K. Moreover, our initialization strategy can be easily integrated\ninto various transformer-based architectures such as Swin Transformer and\nMLP-Mixer with consistent improvements in performance.", "published": "2025-05-26 13:42:31", "link": "http://arxiv.org/abs/2505.19985v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PHI: Bridging Domain Shift in Long-Term Action Quality Assessment via Progressive Hierarchical Instruction", "abstract": "Long-term Action Quality Assessment (AQA) aims to evaluate the quantitative\nperformance of actions in long videos. However, existing methods face\nchallenges due to domain shifts between the pre-trained large-scale action\nrecognition backbones and the specific AQA task, thereby hindering their\nperformance. This arises since fine-tuning resource-intensive backbones on\nsmall AQA datasets is impractical. We address this by identifying two levels of\ndomain shift: task-level, regarding differences in task objectives, and\nfeature-level, regarding differences in important features. For feature-level\nshifts, which are more detrimental, we propose Progressive Hierarchical\nInstruction (PHI) with two strategies. First, Gap Minimization Flow (GMF)\nleverages flow matching to progressively learn a fast flow path that reduces\nthe domain gap between initial and desired features across shallow to deep\nlayers. Additionally, a temporally-enhanced attention module captures\nlong-range dependencies essential for AQA. Second, List-wise Contrastive\nRegularization (LCR) facilitates coarse-to-fine alignment by comprehensively\ncomparing batch pairs to learn fine-grained cues while mitigating domain shift.\nIntegrating these modules, PHI offers an effective solution. Experiments\ndemonstrate that PHI achieves state-of-the-art performance on three\nrepresentative long-term AQA datasets, proving its superiority in addressing\nthe domain shift for long-term AQA.", "published": "2025-05-26 13:34:46", "link": "http://arxiv.org/abs/2505.19972v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UltraVSR: Achieving Ultra-Realistic Video Super-Resolution with Efficient One-Step Diffusion Space", "abstract": "Diffusion models have shown great potential in generating realistic image\ndetail. However, adapting these models to video super-resolution (VSR) remains\nchallenging due to their inherent stochasticity and lack of temporal modeling.\nIn this paper, we propose UltraVSR, a novel framework that enables\nultra-realistic and temporal-coherent VSR through an efficient one-step\ndiffusion space. A central component of UltraVSR is the Degradation-aware\nRestoration Schedule (DRS), which estimates a degradation factor from the\nlow-resolution input and transforms iterative denoising process into a\nsingle-step reconstruction from from low-resolution to high-resolution videos.\nThis design eliminates randomness from diffusion noise and significantly speeds\nup inference. To ensure temporal consistency, we propose a lightweight yet\neffective Recurrent Temporal Shift (RTS) module, composed of an RTS-convolution\nunit and an RTS-attention unit. By partially shifting feature components along\nthe temporal dimension, these two units collaboratively facilitate effective\nfeature propagation, fusion, and alignment across neighboring frames, without\nrelying on explicit temporal layers. The RTS module is integrated into a\npretrained text-to-image diffusion model and is further enhanced through\nSpatio-temporal Joint Distillation (SJD), which improves temporal coherence\nwhile preserving realistic details. Additionally, we introduce a Temporally\nAsynchronous Inference (TAI) strategy to capture long-range temporal\ndependencies under limited memory constraints. Extensive experiments show that\nUltraVSR achieves state-of-the-art performance, both qualitatively and\nquantitatively, in a single sampling step.", "published": "2025-05-26 13:19:27", "link": "http://arxiv.org/abs/2505.19958v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval", "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images\ngiven a compositional query, consisting of a reference image and a modifying\ntext-without relying on annotated training data. Existing approaches often\ngenerate a synthetic target text using large language models (LLMs) to serve as\nan intermediate anchor between the compositional query and the target image.\nModels are then trained to align the compositional query with the generated\ntext, and separately align images with their corresponding texts using\ncontrastive learning. However, this reliance on intermediate text introduces\nerror propagation, as inaccuracies in query-to-text and text-to-image mappings\naccumulate, ultimately degrading retrieval performance. To address these\nproblems, we propose a novel framework by employing a Multimodal Reasoning\nAgent (MRA) for ZS-CIR. MRA eliminates the dependence on textual intermediaries\nby directly constructing triplets, <reference image, modification text, target\nimage>, using only unlabeled image data. By training on these synthetic\ntriplets, our model learns to capture the relationships between compositional\nqueries and candidate images directly. Extensive experiments on three standard\nCIR benchmarks demonstrate the effectiveness of our approach. On the FashionIQ\ndataset, our method improves Average R@10 by at least 7.5\\% over existing\nbaselines; on CIRR, it boosts R@1 by 9.6\\%; and on CIRCO, it increases mAP@5 by\n9.5\\%.", "published": "2025-05-26 13:17:50", "link": "http://arxiv.org/abs/2505.19952v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Multi-Timescale Motion-Decoupled Spiking Transformer for Audio-Visual Zero-Shot Learning", "abstract": "Audio-visual zero-shot learning (ZSL) has been extensively researched for its\ncapability to classify video data from unseen classes during training.\nNevertheless, current methodologies often struggle with background scene biases\nand inadequate motion detail. This paper proposes a novel dual-stream\nMulti-Timescale Motion-Decoupled Spiking Transformer (MDST++), which decouples\ncontextual semantic information and sparse dynamic motion information. The\nrecurrent joint learning unit is proposed to extract contextual semantic\ninformation and capture joint knowledge across various modalities to understand\nthe environment of actions. By converting RGB images to events, our method\ncaptures motion information more accurately and mitigates background scene\nbiases. Moreover, we introduce a discrepancy analysis block to model audio\nmotion information. To enhance the robustness of SNNs in extracting temporal\nand motion cues, we dynamically adjust the threshold of Leaky\nIntegrate-and-Fire neurons based on global motion and contextual semantic\ninformation. Our experiments validate the effectiveness of MDST++,\ndemonstrating their consistent superiority over state-of-the-art methods on\nmainstream benchmarks. Additionally, incorporating motion and multi-timescale\ninformation significantly improves HM and ZSL accuracy by 26.2\\% and 39.9\\%.", "published": "2025-05-26 13:06:01", "link": "http://arxiv.org/abs/2505.19938v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CA3D: Convolutional-Attentional 3D Nets for Efficient Video Activity Recognition on the Edge", "abstract": "In this paper, we introduce a deep learning solution for video activity\nrecognition that leverages an innovative combination of convolutional layers\nwith a linear-complexity attention mechanism. Moreover, we introduce a novel\nquantization mechanism to further improve the efficiency of our model during\nboth training and inference. Our model maintains a reduced computational cost,\nwhile preserving robust learning and generalization capabilities. Our approach\naddresses the issues related to the high computing requirements of current\nmodels, with the goal of achieving competitive accuracy on consumer and edge\ndevices, enabling smart home and smart healthcare applications where efficiency\nand privacy issues are of concern. We experimentally validate our model on\ndifferent established and publicly available video activity recognition\nbenchmarks, improving accuracy over alternative models at a competitive\ncomputing cost.", "published": "2025-05-26 12:55:27", "link": "http://arxiv.org/abs/2505.19928v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Weather-Magician: Reconstruction and Rendering Framework for 4D Weather Synthesis In Real Time", "abstract": "For tasks such as urban digital twins, VR/AR/game scene design, or creating\nsynthetic films, the traditional industrial approach often involves manually\nmodeling scenes and using various rendering engines to complete the rendering\nprocess. This approach typically requires high labor costs and hardware\ndemands, and can result in poor quality when replicating complex real-world\nscenes. A more efficient approach is to use data from captured real-world\nscenes, then apply reconstruction and rendering algorithms to quickly recreate\nthe authentic scene. However, current algorithms are unable to effectively\nreconstruct and render real-world weather effects. To address this, we propose\na framework based on gaussian splatting, that can reconstruct real scenes and\nrender them under synthesized 4D weather effects. Our work can simulate various\ncommon weather effects by applying Gaussians modeling and rendering techniques.\nIt supports continuous dynamic weather changes and can easily control the\ndetails of the effects. Additionally, our work has low hardware requirements\nand achieves real-time rendering performance. The result demos can be accessed\non our project homepage: weathermagician.github.io", "published": "2025-05-26 12:44:53", "link": "http://arxiv.org/abs/2505.19919v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Attention! You Vision Language Model Could Be Maliciously Manipulated", "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable success in\nunderstanding complex real-world scenarios and supporting data-driven\ndecision-making processes. However, VLMs exhibit significant vulnerability\nagainst adversarial examples, either text or image, which can lead to various\nadversarial outcomes, e.g., jailbreaking, hijacking, and hallucination, etc. In\nthis work, we empirically and theoretically demonstrate that VLMs are\nparticularly susceptible to image-based adversarial examples, where\nimperceptible perturbations can precisely manipulate each output token. To this\nend, we propose a novel attack called Vision-language model Manipulation Attack\n(VMA), which integrates first-order and second-order momentum optimization\ntechniques with a differentiable transformation mechanism to effectively\noptimize the adversarial perturbation. Notably, VMA can be a double-edged\nsword: it can be leveraged to implement various attacks, such as jailbreaking,\nhijacking, privacy breaches, Denial-of-Service, and the generation of sponge\nexamples, etc, while simultaneously enabling the injection of watermarks for\ncopyright protection. Extensive empirical evaluations substantiate the efficacy\nand generalizability of VMA across diverse scenarios and datasets.", "published": "2025-05-26 12:38:58", "link": "http://arxiv.org/abs/2505.19911v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic-I2V: Exploring Image-to-Video Generaion Models via Multimodal LLM", "abstract": "Recent advancements in image-to-video (I2V) generation have shown promising\nperformance in conventional scenarios. However, these methods still encounter\nsignificant challenges when dealing with complex scenes that require a deep\nunderstanding of nuanced motion and intricate object-action relationships. To\naddress these challenges, we present Dynamic-I2V, an innovative framework that\nintegrates Multimodal Large Language Models (MLLMs) to jointly encode visual\nand textual conditions for a diffusion transformer (DiT) architecture. By\nleveraging the advanced multimodal understanding capabilities of MLLMs, our\nmodel significantly improves motion controllability and temporal coherence in\nsynthesized videos. The inherent multimodality of Dynamic-I2V further enables\nflexible support for diverse conditional inputs, extending its applicability to\nvarious downstream generation tasks. Through systematic analysis, we identify a\ncritical limitation in current I2V benchmarks: a significant bias towards\nfavoring low-dynamic videos, stemming from an inadequate balance between motion\ncomplexity and visual quality metrics. To resolve this evaluation gap, we\npropose DIVE - a novel assessment benchmark specifically designed for\ncomprehensive dynamic quality measurement in I2V generation. In conclusion,\nextensive quantitative and qualitative experiments confirm that Dynamic-I2V\nattains state-of-the-art performance in image-to-video generation, particularly\nrevealing significant improvements of 42.5%, 7.9%, and 11.8% in dynamic range,\ncontrollability, and quality, respectively, as assessed by the DIVE metric in\ncomparison to existing methods.", "published": "2025-05-26 12:29:34", "link": "http://arxiv.org/abs/2505.19901v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement", "abstract": "Underwater images are often affected by complex degradations such as light\nabsorption, scattering, color casts, and artifacts, making enhancement critical\nfor effective object detection, recognition, and scene understanding in aquatic\nenvironments. Existing methods, especially diffusion-based approaches,\ntypically rely on synthetic paired datasets due to the scarcity of real\nunderwater references, introducing bias and limiting generalization.\nFurthermore, fine-tuning these models can degrade learned priors, resulting in\nunrealistic enhancements due to domain shifts. To address these challenges, we\npropose UDAN-CLIP, an image-to-image diffusion framework pre-trained on\nsynthetic underwater datasets and enhanced with a customized classifier based\non vision-language model, a spatial attention module, and a novel\nCLIP-Diffusion loss. The classifier preserves natural in-air priors and\nsemantically guides the diffusion process, while the spatial attention module\nfocuses on correcting localized degradations such as haze and low contrast. The\nproposed CLIP-Diffusion loss further strengthens visual-textual alignment and\nhelps maintain semantic consistency during enhancement. The proposed\ncontributions empower our UDAN-CLIP model to perform more effective underwater\nimage enhancement, producing results that are not only visually compelling but\nalso more realistic and detail-preserving. These improvements are consistently\nvalidated through both quantitative metrics and qualitative visual comparisons,\ndemonstrating the model's ability to correct distortions and restore natural\nappearance in challenging underwater conditions.", "published": "2025-05-26 12:24:56", "link": "http://arxiv.org/abs/2505.19895v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniFall: A Unified Staged-to-Wild Benchmark for Human Fall Detection", "abstract": "Current video-based fall detection research mostly relies on small, staged\ndatasets with significant domain biases concerning background, lighting, and\ncamera setup resulting in unknown real-world performance. We introduce\nOmniFall, unifying eight public fall detection datasets (roughly 14 h of\nrecordings, roughly 42 h of multiview data, 101 subjects, 29 camera views)\nunder a consistent ten-class taxonomy with standardized evaluation protocols.\nOur benchmark provides complete video segmentation labels and enables fair\ncross-dataset comparison previously impossible with incompatible annotation\nschemes. For real-world evaluation we curate OOPS-Fall from genuine accident\nvideos and establish a staged-to-wild protocol measuring generalization from\ncontrolled to uncontrolled environments. Experiments with frozen pre-trained\nbackbones such as I3D or VideoMAE reveal significant performance gaps between\nin-distribution and in-the-wild scenarios, highlighting critical challenges in\ndeveloping robust fall detection systems. OmniFall Dataset at\nhttps://huggingface.co/datasets/simplexsigil2/omnifall , Code at\nhttps://github.com/simplexsigil/omnifall-experiments", "published": "2025-05-26 12:19:11", "link": "http://arxiv.org/abs/2505.19889v1", "categories": ["cs.CV", "I.2.10; I.5.4"], "primary_category": "cs.CV"}
{"title": "ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization", "abstract": "The use of multi-view images acquired by a 360-degree camera can reconstruct\na 3D space with a wide area. There are 3D reconstruction methods from\nequirectangular images based on NeRF and 3DGS, as well as Novel View Synthesis\n(NVS) methods. On the other hand, it is necessary to overcome the large\ndistortion caused by the projection model of a 360-degree camera when\nequirectangular images are used. In 3DGS-based methods, the large distortion of\nthe 360-degree camera model generates extremely large 3D Gaussians, resulting\nin poor rendering accuracy. We propose ErpGS, which is Omnidirectional GS based\non 3DGS to realize NVS addressing the problems. ErpGS introduce some rendering\naccuracy improvement techniques: geometric regularization, scale\nregularization, and distortion-aware weights and a mask to suppress the effects\nof obstacles in equirectangular images. Through experiments on public datasets,\nwe demonstrate that ErpGS can render novel view images more accurately than\nconventional methods.", "published": "2025-05-26 12:09:10", "link": "http://arxiv.org/abs/2505.19883v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought", "abstract": "Recent advancements in reasoning capability of Multimodal Large Language\nModels (MLLMs) demonstrate its effectiveness in tackling complex visual tasks.\nHowever, existing MLLM-based Video Anomaly Detection (VAD) methods remain\nlimited to shallow anomaly descriptions without deep reasoning. In this paper,\nwe propose a new task named Video Anomaly Reasoning (VAR), which aims to enable\ndeep analysis and understanding of anomalies in the video by requiring MLLMs to\nthink explicitly before answering. To this end, we propose Vad-R1, an\nend-to-end MLLM-based framework for VAR. Specifically, we design a\nPerception-to-Cognition Chain-of-Thought (P2C-CoT) that simulates the human\nprocess of recognizing anomalies, guiding the MLLM to reason anomaly\nstep-by-step. Based on the structured P2C-CoT, we construct Vad-Reasoning, a\ndedicated dataset for VAR. Furthermore, we propose an improved reinforcement\nlearning algorithm AVA-GRPO, which explicitly incentivizes the anomaly\nreasoning capability of MLLMs through a self-verification mechanism with\nlimited annotations. Experimental results demonstrate that Vad-R1 achieves\nsuperior performance, outperforming both open-source and proprietary models on\nVAD and VAR tasks. Codes and datasets will be released at\nhttps://github.com/wbfwonderful/Vad-R1.", "published": "2025-05-26 12:05:16", "link": "http://arxiv.org/abs/2505.19877v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep Spectral Prior", "abstract": "We introduce Deep Spectral Prior (DSP), a new formulation of Deep Image Prior\n(DIP) that redefines image reconstruction as a frequency-domain alignment\nproblem. Unlike traditional DIP, which relies on pixel-wise loss and early\nstopping to mitigate overfitting, DSP directly matches Fourier coefficients\nbetween the network output and observed measurements. This shift introduces an\nexplicit inductive bias towards spectral coherence, aligning with the known\nfrequency structure of images and the spectral bias of convolutional neural\nnetworks. We provide a rigorous theoretical framework demonstrating that DSP\nacts as an implicit spectral regulariser, suppressing high-frequency noise by\ndesign and eliminating the need for early stopping. Our analysis spans four\ncore dimensions establishing smooth convergence dynamics, local stability, and\nfavourable bias-variance tradeoffs. We further show that DSP naturally projects\nreconstructions onto a frequency-consistent manifold, enhancing\ninterpretability and robustness. These theoretical guarantees are supported by\nempirical results across denoising, inpainting, and super-resolution tasks,\nwhere DSP consistently outperforms classical DIP and other unsupervised\nbaselines.", "published": "2025-05-26 12:00:37", "link": "http://arxiv.org/abs/2505.19873v1", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "Harnessing the Power of Training-Free Techniques in Text-to-2D Generation for Text-to-3D Generation via Score Distillation Sampling", "abstract": "Recent studies show that simple training-free techniques can dramatically\nimprove the quality of text-to-2D generation outputs, e.g. Classifier-Free\nGuidance (CFG) or FreeU. However, these training-free techniques have been\nunderexplored in the lens of Score Distillation Sampling (SDS), which is a\npopular and effective technique to leverage the power of pretrained text-to-2D\ndiffusion models for various tasks. In this paper, we aim to shed light on the\neffect such training-free techniques have on SDS, via a particular application\nof text-to-3D generation via 2D lifting. We present our findings, which show\nthat varying the scales of CFG presents a trade-off between object size and\nsurface smoothness, while varying the scales of FreeU presents a trade-off\nbetween texture details and geometric errors. Based on these findings, we\nprovide insights into how we can effectively harness training-free techniques\nfor SDS, via a strategic scaling of such techniques in a dynamic manner with\nrespect to the timestep or optimization iteration step. We show that using our\nproposed scheme strikes a favorable balance between texture details and surface\nsmoothness in text-to-3D generations, while preserving the size of the output\nand mitigating the occurrence of geometric defects.", "published": "2025-05-26 11:54:07", "link": "http://arxiv.org/abs/2505.19868v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive Learning and Neural Radiance Fields", "abstract": "We introduce FruitNeRF++, a novel fruit-counting approach that combines\ncontrastive learning with neural radiance fields to count fruits from\nunstructured input photographs of orchards. Our work is based on FruitNeRF,\nwhich employs a neural semantic field combined with a fruit-specific clustering\napproach. The requirement for adaptation for each fruit type limits the\napplicability of the method, and makes it difficult to use in practice. To lift\nthis limitation, we design a shape-agnostic multi-fruit counting framework,\nthat complements the RGB and semantic data with instance masks predicted by a\nvision foundation model. The masks are used to encode the identity of each\nfruit as instance embeddings into a neural instance field. By volumetrically\nsampling the neural fields, we extract a point cloud embedded with the instance\nfeatures, which can be clustered in a fruit-agnostic manner to obtain the fruit\ncount. We evaluate our approach using a synthetic dataset containing apples,\nplums, lemons, pears, peaches, and mangoes, as well as a real-world benchmark\napple dataset. Our results demonstrate that FruitNeRF++ is easier to control\nand compares favorably to other state-of-the-art methods.", "published": "2025-05-26 11:48:22", "link": "http://arxiv.org/abs/2505.19863v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking", "abstract": "The real world is dynamic, yet most image fusion methods process static\nframes independently, ignoring temporal correlations in videos and leading to\nflickering and temporal inconsistency. To address this, we propose Unified\nVideo Fusion (UniVF), a novel framework for temporally coherent video fusion\nthat leverages multi-frame learning and optical flow-based feature warping for\ninformative, temporally coherent video fusion. To support its development, we\nalso introduce Video Fusion Benchmark (VF-Bench), the first comprehensive\nbenchmark covering four video fusion tasks: multi-exposure, multi-focus,\ninfrared-visible, and medical fusion. VF-Bench provides high-quality,\nwell-aligned video pairs obtained through synthetic data generation and\nrigorous curation from existing datasets, with a unified evaluation protocol\nthat jointly assesses the spatial quality and temporal consistency of video\nfusion. Extensive experiments show that UniVF achieves state-of-the-art results\nacross all tasks on VF-Bench. Project page: https://vfbench.github.io.", "published": "2025-05-26 11:45:10", "link": "http://arxiv.org/abs/2505.19858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud", "abstract": "Gaussian Splatting (GS) has gained attention as a fast and effective method\nfor novel view synthesis. It has also been applied to 3D reconstruction using\nmulti-view images and can achieve fast and accurate 3D reconstruction. However,\nGS assumes that the input contains a large number of multi-view images, and\ntherefore, the reconstruction accuracy significantly decreases when only a\nlimited number of input images are available. One of the main reasons is the\ninsufficient number of 3D points in the sparse point cloud obtained through\nStructure from Motion (SfM), which results in a poor initialization for\noptimizing the Gaussian primitives. We propose a new 3D reconstruction method,\ncalled Sparse2DGS, to enhance 2DGS in reconstructing objects using only three\nimages. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, along\nwith COLMAP MVS to generate highly accurate and dense 3D point clouds, which\nare then used to initialize 2D Gaussians. Through experiments on the DTU\ndataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes of\nobjects using just three images.", "published": "2025-05-26 11:38:26", "link": "http://arxiv.org/abs/2505.19854v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Pseudo Labels Generation Using SAM and CLIP for Semi-Supervised Semantic Segmentation", "abstract": "Semantic segmentation is a fundamental task in medical image analysis and\nautonomous driving and has a problem with the high cost of annotating the\nlabels required in training. To address this problem, semantic segmentation\nmethods based on semi-supervised learning with a small number of labeled data\nhave been proposed. For example, one approach is to train a semantic\nsegmentation model using images with annotated labels and pseudo labels. In\nthis approach, the accuracy of the semantic segmentation model depends on the\nquality of the pseudo labels, and the quality of the pseudo labels depends on\nthe performance of the model to be trained and the amount of data with\nannotated labels. In this paper, we generate pseudo labels using zero-shot\nannotation with the Segment Anything Model (SAM) and Contrastive Language-Image\nPretraining (CLIP), improve the accuracy of the pseudo labels using the Unified\nDual-Stream Perturbations Approach (UniMatch), and use them as enhanced labels\nto train a semantic segmentation model. The effectiveness of the proposed\nmethod is demonstrated through the experiments using the public datasets:\nPASCAL and MS COCO.", "published": "2025-05-26 11:31:13", "link": "http://arxiv.org/abs/2505.19846v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis", "abstract": "Neural Radiance Fields (NeRF) have transformed novel view synthesis by\nmodeling scene-specific volumetric representations directly from images. While\ngeneralizable NeRF models can generate novel views across unknown scenes by\nlearning latent ray representations, their performance heavily depends on a\nlarge number of multi-view observations. However, with limited input views,\nthese methods experience significant degradation in rendering quality. To\naddress this limitation, we propose GoLF-NRT: a Global and Local feature\nFusion-based Neural Rendering Transformer. GoLF-NRT enhances generalizable\nneural rendering from few input views by leveraging a 3D transformer with\nefficient sparse attention to capture global scene context. In parallel, it\nintegrates local geometric features extracted along the epipolar line, enabling\nhigh-quality scene reconstruction from as few as 1 to 3 input views.\nFurthermore, we introduce an adaptive sampling strategy based on attention\nweights and kernel regression, improving the accuracy of transformer-based\nneural rendering. Extensive experiments on public datasets show that GoLF-NRT\nachieves state-of-the-art performance across varying numbers of input views,\nhighlighting the effectiveness and superiority of our approach. Code is\navailable at https://github.com/KLMAV-CUC/GoLF-NRT.", "published": "2025-05-26 10:50:25", "link": "http://arxiv.org/abs/2505.19813v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Multi-modal Long Context Learning for Training-free Adaptation", "abstract": "Traditional approaches to adapting multi-modal large language models (MLLMs)\nto new tasks have relied heavily on fine-tuning. This paper introduces\nEfficient Multi-Modal Long Context Learning (EMLoC), a novel training-free\nalternative that embeds demonstration examples directly into the model input.\nEMLoC offers a more efficient, flexible, and scalable solution for task\nadaptation. Because extremely lengthy inputs introduce prohibitive\ncomputational and memory overhead, EMLoC contributes a chunk-wise compression\nmechanism combined with layer-wise adaptive pruning. It condenses long-context\nmultimodal inputs into compact, task-specific memory representations. By\nadaptively pruning tokens at each layer under a Jensen-Shannon divergence\nconstraint, our method achieves a dramatic reduction in inference complexity\nwithout sacrificing performance. This approach is the first to seamlessly\nintegrate compression and pruning techniques for multi-modal long-context\nlearning, offering a scalable and efficient solution for real-world\napplications. Extensive experiments on diverse vision-language benchmarks\ndemonstrate that EMLoC achieves performance on par with or superior to naive\nlong-context approaches. Our results highlight the potential of EMLoC as a\ngroundbreaking framework for efficient and flexible adaptation of multi-modal\nmodels in resource-constrained environments. Codes are publicly available at\nhttps://github.com/Zehong-Ma/EMLoC.", "published": "2025-05-26 10:49:44", "link": "http://arxiv.org/abs/2505.19812v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks", "abstract": "The design of convolutional neural architectures that are exactly equivariant\nto continuous translations is an active field of research. It promises to\nbenefit scientific computing, notably by making existing imaging systems more\nphysically accurate. Most efforts focus on the design of downsampling/pooling\nlayers, upsampling layers and activation functions, but little attention is\ndedicated to normalization layers. In this work, we present a novel theoretical\nframework for understanding the equivariance of normalization layers to\ndiscrete shifts and continuous translations. We also determine necessary and\nsufficient conditions for normalization layers to be equivariant in terms of\nthe dimensions they operate on. Using real feature maps from ResNet-18 and\nImageNet, we test those theoretical results empirically and find that they are\nconsistent with our predictions.", "published": "2025-05-26 10:39:36", "link": "http://arxiv.org/abs/2505.19805v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity Estimation", "abstract": "Understanding pain-related facial behaviors is essential for digital\nhealthcare in terms of effective monitoring, assisted diagnostics, and\ntreatment planning, particularly for patients unable to communicate verbally.\nExisting data-driven methods of detecting pain from facial expressions are\nlimited due to interpretability and severity quantification. To this end, we\npropose GraphAU-Pain, leveraging a graph-based framework to model facial Action\nUnits (AUs) and their interrelationships for pain intensity estimation. AUs are\nrepresented as graph nodes, with co-occurrence relationships as edges, enabling\na more expressive depiction of pain-related facial behaviors. By utilizing a\nrelational graph neural network, our framework offers improved interpretability\nand significant performance gains. Experiments conducted on the publicly\navailable UNBC dataset demonstrate the effectiveness of the GraphAU-Pain,\nachieving an F1-score of 66.21% and accuracy of 87.61% in pain intensity\nestimation.", "published": "2025-05-26 10:35:42", "link": "http://arxiv.org/abs/2505.19802v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Regularization-Guided Equivariant Approach for Image Restoration", "abstract": "Equivariant and invariant deep learning models have been developed to exploit\nintrinsic symmetries in data, demonstrating significant effectiveness in\ncertain scenarios. However, these methods often suffer from limited\nrepresentation accuracy and rely on strict symmetry assumptions that may not\nhold in practice. These limitations pose a significant drawback for image\nrestoration tasks, which demands high accuracy and precise symmetry\nrepresentation. To address these challenges, we propose a rotation-equivariant\nregularization strategy that adaptively enforces the appropriate symmetry\nconstraints on the data while preserving the network's representational\naccuracy. Specifically, we introduce EQ-Reg, a regularizer designed to enhance\nrotation equivariance, which innovatively extends the insights of\ndata-augmentation-based and equivariant-based methodologies. This is achieved\nthrough self-supervised learning and the spatial rotation and cyclic channel\nshift of feature maps deduce in the equivariant framework. Our approach firstly\nenables a non-strictly equivariant network suitable for image restoration,\nproviding a simple and adaptive mechanism for adjusting equivariance based on\ntask. Extensive experiments across three low-level tasks demonstrate the\nsuperior accuracy and generalization capability of our method, outperforming\nstate-of-the-art approaches.", "published": "2025-05-26 10:30:26", "link": "http://arxiv.org/abs/2505.19799v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction", "abstract": "Recent advancements in generalizable novel view synthesis have achieved\nimpressive quality through interpolation between nearby views. However,\nrendering high-resolution images remains computationally intensive due to the\nneed for dense sampling of all rays. Recognizing that natural scenes are\ntypically piecewise smooth and sampling all rays is often redundant, we propose\na novel depth-guided bundle sampling strategy to accelerate rendering. By\ngrouping adjacent rays into a bundle and sampling them collectively, a shared\nrepresentation is generated for decoding all rays within the bundle. To further\noptimize efficiency, our adaptive sampling strategy dynamically allocates\nsamples based on depth confidence, concentrating more samples in complex\nregions while reducing them in smoother areas. When applied to ENeRF, our\nmethod achieves up to a 1.27 dB PSNR improvement and a 47% increase in FPS on\nthe DTU dataset. Extensive experiments on synthetic and real-world datasets\ndemonstrate state-of-the-art rendering quality and up to 2x faster rendering\ncompared to existing generalizable methods. Code is available at\nhttps://github.com/KLMAV-CUC/GDB-NeRF.", "published": "2025-05-26 10:23:59", "link": "http://arxiv.org/abs/2505.19793v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models", "abstract": "Using massive datasets, foundation models are large-scale, pre-trained models\nthat perform a wide range of tasks. These models have shown consistently\nimproved results with the introduction of new methods. It is crucial to analyze\nhow these trends impact the medical field and determine whether these\nadvancements can drive meaningful change. This study investigates the\napplication of recent state-of-the-art foundation models, DINOv2, MAE, VMamba,\nCoCa, SAM2, and AIMv2, for medical image classification. We explore their\neffectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for\nskin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest\nradiographs. By fine-tuning these models and evaluating their configurations,\nwe aim to understand the potential of these advancements in medical image\nclassification. The results indicate that these advanced models significantly\nenhance classification outcomes, demonstrating robust performance despite\nlimited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models\noutperformed others, demonstrating that progress in natural domain training has\npositively impacted the medical domain and improved classification outcomes.\nOur code is publicly available at:\nhttps://github.com/sajjad-sh33/Medical-Transfer-Learning.", "published": "2025-05-26 10:04:40", "link": "http://arxiv.org/abs/2505.19779v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "SAIL: Self-supervised Albedo Estimation from Real Images with a Latent Diffusion Model", "abstract": "Intrinsic image decomposition aims at separating an image into its underlying\nalbedo and shading components, isolating the base color from lighting effects\nto enable downstream applications such as virtual relighting and scene editing.\nDespite the rise and success of learning-based approaches, intrinsic image\ndecomposition from real-world images remains a significant challenging task due\nto the scarcity of labeled ground-truth data. Most existing solutions rely on\nsynthetic data as supervised setups, limiting their ability to generalize to\nreal-world scenes. Self-supervised methods, on the other hand, often produce\nalbedo maps that contain reflections and lack consistency under different\nlighting conditions. To address this, we propose SAIL, an approach designed to\nestimate albedo-like representations from single-view real-world images. We\nrepurpose the prior knowledge of a latent diffusion model for unconditioned\nscene relighting as a surrogate objective for albedo estimation. To extract the\nalbedo, we introduce a novel intrinsic image decomposition fully formulated in\nthe latent space. To guide the training of our latent diffusion model, we\nintroduce regularization terms that constrain both the lighting-dependent and\nindependent components of our latent image decomposition. SAIL predicts stable\nalbedo under varying lighting conditions and generalizes to multiple scenes,\nusing only unlabeled multi-illumination data available online.", "published": "2025-05-26 09:31:56", "link": "http://arxiv.org/abs/2505.19751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect", "abstract": "In this technical report, we present our solution to the CVPR 2025 Visual\nAnomaly and Novelty Detection (VAND) 3.0 Workshop Challenge Track 1: Adapt &\nDetect: Robust Anomaly Detection in Real-World Applications. In real-world\nindustrial anomaly detection, it is crucial to accurately identify anomalies\nwith physical complexity, such as transparent or reflective surfaces,\nocclusions, and low-contrast contaminations. The recently proposed MVTec AD 2\ndataset significantly narrows the gap between publicly available benchmarks and\nanomalies found in real-world industrial environments. To address the\nchallenges posed by this dataset--such as complex and varying lighting\nconditions and real anomalies with large scale differences--we propose a fully\ntraining-free anomaly detection and segmentation method based on feature\nextraction using the DINOv2 model named SuperAD. Our method carefully selects a\nsmall number of normal reference images and constructs a memory bank by\nleveraging the strong representational power of DINOv2. Anomalies are then\nsegmented by performing nearest neighbor matching between test image features\nand the memory bank. Our method achieves competitive results on both test sets\nof the MVTec AD 2 dataset.", "published": "2025-05-26 09:29:27", "link": "http://arxiv.org/abs/2505.19750v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation", "abstract": "Accurate identification of acute cellular rejection (ACR) in endomyocardial\nbiopsies is essential for effective management of heart transplant patients.\nHowever, the rarity of high-grade rejection cases (3R) presents a significant\nchallenge for training robust deep learning models. This work addresses the\nclass imbalance problem by leveraging synthetic data generation using StyleGAN\nto augment the limited number of real 3R images. Prior to GAN training,\nhistogram equalization was applied to standardize image appearance and improve\nthe consistency of tissue representation. StyleGAN was trained on available 3R\nbiopsy patches and subsequently used to generate 10,000 realistic synthetic\nimages. These were combined with real 0R samples, that is samples without\nrejection, in various configurations to train ResNet-18 classifiers for binary\nrejection classification.\n  Three classifier variants were evaluated: one trained on real 0R and\nsynthetic 3R images, another using both synthetic and additional real samples,\nand a third trained solely on real data. All models were tested on an\nindependent set of real biopsy images. Results demonstrate that synthetic data\nimproves classification performance, particularly when used in combination with\nreal samples. The highest-performing model, which used both real and synthetic\nimages, achieved strong precision and recall for both classes. These findings\nunderscore the value of hybrid training strategies and highlight the potential\nof GAN-based data augmentation in biomedical image analysis, especially in\ndomains constrained by limited annotated datasets.", "published": "2025-05-26 09:26:36", "link": "http://arxiv.org/abs/2505.19746v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HAODiff: Human-Aware One-Step Diffusion via Dual-Prompt Guidance", "abstract": "Human-centered images often suffer from severe generic degradation during\ntransmission and are prone to human motion blur (HMB), making restoration\nchallenging. Existing research lacks sufficient focus on these issues, as both\nproblems often coexist in practice. To address this, we design a degradation\npipeline that simulates the coexistence of HMB and generic noise, generating\nsynthetic degraded data to train our proposed HAODiff, a human-aware one-step\ndiffusion. Specifically, we propose a triple-branch dual-prompt guidance (DPG),\nwhich leverages high-quality images, residual noise (LQ minus HQ), and HMB\nsegmentation masks as training targets. It produces a positive-negative prompt\npair for classifier-free guidance (CFG) in a single diffusion step. The\nresulting adaptive dual prompts let HAODiff exploit CFG more effectively,\nboosting robustness against diverse degradations. For fair evaluation, we\nintroduce MPII-Test, a benchmark rich in combined noise and HMB cases.\nExtensive experiments show that our HAODiff surpasses existing state-of-the-art\n(SOTA) methods in terms of both quantitative metrics and visual quality on\nsynthetic and real-world datasets, including our introduced MPII-Test. Code is\navailable at: https://github.com/gobunu/HAODiff.", "published": "2025-05-26 09:24:11", "link": "http://arxiv.org/abs/2505.19742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-Sequence Semi-Supervised Learning for Multi-Parametric MRI-Based Visual Pathway Delineation", "abstract": "Accurately delineating the visual pathway (VP) is crucial for understanding\nthe human visual system and diagnosing related disorders. Exploring\nmulti-parametric MR imaging data has been identified as an important way to\ndelineate VP. However, due to the complex cross-sequence relationships,\nexisting methods cannot effectively model the complementary information from\ndifferent MRI sequences. In addition, these existing methods heavily rely on\nlarge training data with labels, which is labor-intensive and time-consuming to\nobtain. In this work, we propose a novel semi-supervised multi-parametric\nfeature decomposition framework for VP delineation. Specifically, a\ncorrelation-constrained feature decomposition (CFD) is designed to handle the\ncomplex cross-sequence relationships by capturing the unique characteristics of\neach MRI sequence and easing the multi-parametric information fusion process.\nFurthermore, a consistency-based sample enhancement (CSE) module is developed\nto address the limited labeled data issue, by generating and promoting\nmeaningful edge information from unlabeled data. We validate our framework\nusing two public datasets, and one in-house Multi-Shell Diffusion MRI (MDM)\ndataset. Experimental results demonstrate the superiority of our approach in\nterms of delineation performance when compared to seven state-of-the-art\napproaches.", "published": "2025-05-26 09:18:58", "link": "http://arxiv.org/abs/2505.19733v1", "categories": ["cs.CV", "cs.CE"], "primary_category": "cs.CV"}
{"title": "MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed Image Retrieval", "abstract": "Existing Zero-Shot Composed Image Retrieval (ZS-CIR) methods typically train\nadapters that convert reference images into pseudo-text tokens, which are\nconcatenated with the modifying text and processed by frozen text encoders in\npretrained VLMs or LLMs. While this design leverages the strengths of large\npretrained models, it only supervises the adapter to produce encoder-compatible\ntokens that loosely preserve visual semantics. Crucially, it does not directly\noptimize the composed query representation to capture the full intent of the\ncomposition or to align with the target semantics, thereby limiting retrieval\nperformance, particularly in cases involving fine-grained or complex visual\ntransformations. To address this problem, we propose MLLM-Guided VLM\nFine-Tuning with Joint Inference (MVFT-JI), a novel approach that leverages a\npretrained multimodal large language model (MLLM) to construct two\ncomplementary training tasks using only unlabeled images: target text retrieval\ntaskand text-to-image retrieval task. By jointly optimizing these tasks, our\nmethod enables the VLM to inherently acquire robust compositional retrieval\ncapabilities, supported by the provided theoretical justifications and\nempirical validation. Furthermore, during inference, we further prompt the MLLM\nto generate target texts from composed queries and compute retrieval scores by\nintegrating similarities between (i) the composed query and candidate images,\nand (ii) the MLLM-generated target text and candidate images. This strategy\neffectively combines the VLM's semantic alignment strengths with the MLLM's\nreasoning capabilities.", "published": "2025-05-26 08:56:59", "link": "http://arxiv.org/abs/2505.19707v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Point-RFT: Improving Multimodal Reasoning with Visually Grounded Reinforcement Finetuning", "abstract": "Recent advances in large language models have significantly improved textual\nreasoning through the effective use of Chain-of-Thought (CoT) and reinforcement\nlearning. However, extending these successes to vision-language tasks remains\nchallenging due to inherent limitations in text-only CoT, such as visual\nhallucinations and insufficient multimodal integration. In this paper, we\nintroduce Point-RFT, a multimodal reasoning framework explicitly designed to\nleverage visually grounded CoT reasoning for visual document understanding. Our\napproach consists of two stages: First, we conduct format finetuning using a\ncurated dataset of 71K diverse visual reasoning problems, each annotated with\ndetailed, step-by-step rationales explicitly grounded to corresponding visual\nelements. Second, we employ reinforcement finetuning targeting visual document\nunderstanding. On ChartQA, our approach improves accuracy from 70.88%\n(format-finetuned baseline) to 90.04%, surpassing the 83.92% accuracy achieved\nby reinforcement finetuning relying solely on text-based CoT. The result shows\nthat our grounded CoT is more effective for multimodal reasoning compared with\nthe text-only CoT. Moreover, Point-RFT exhibits superior generalization\ncapability across several out-of-domain visual document reasoning benchmarks,\nincluding CharXiv, PlotQA, IconQA, TabMWP, etc., and highlights its potential\nin complex real-world scenarios.", "published": "2025-05-26 08:54:14", "link": "http://arxiv.org/abs/2505.19702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modeling Beyond MOS: Quality Assessment Models Must Integrate Context, Reasoning, and Multimodality", "abstract": "This position paper argues that Mean Opinion Score (MOS), while historically\nfoundational, is no longer sufficient as the sole supervisory signal for\nmultimedia quality assessment models. MOS reduces rich, context-sensitive human\njudgments to a single scalar, obscuring semantic failures, user intent, and the\nrationale behind quality decisions. We contend that modern quality assessment\nmodels must integrate three interdependent capabilities: (1) context-awareness,\nto adapt evaluations to task-specific goals and viewing conditions; (2)\nreasoning, to produce interpretable, evidence-grounded justifications for\nquality judgments; and (3) multimodality, to align perceptual and semantic cues\nusing vision-language models. We critique the limitations of current\nMOS-centric benchmarks and propose a roadmap for reform: richer datasets with\ncontextual metadata and expert rationales, and new evaluation metrics that\nassess semantic alignment, reasoning fidelity, and contextual sensitivity. By\nreframing quality assessment as a contextual, explainable, and multimodal\nmodeling task, we aim to catalyze a shift toward more robust, human-aligned,\nand trustworthy evaluation systems.", "published": "2025-05-26 08:52:02", "link": "http://arxiv.org/abs/2505.19696v1", "categories": ["cs.CV", "cs.MM", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition", "abstract": "Visual Emotion Recognition (VER) is a critical yet challenging task aimed at\ninferring emotional states of individuals based on visual cues. However,\nexisting works focus on single domains, e.g., realistic images or stickers,\nlimiting VER models' cross-domain generalizability. To fill this gap, we\nintroduce an Unsupervised Cross-Domain Visual Emotion Recognition (UCDVER)\ntask, which aims to generalize visual emotion recognition from the source\ndomain (e.g., realistic images) to the low-resource target domain (e.g.,\nstickers) in an unsupervised manner. Compared to the conventional unsupervised\ndomain adaptation problems, UCDVER presents two key challenges: a significant\nemotional expression variability and an affective distribution shift. To\nmitigate these issues, we propose the Knowledge-aligned\nCounterfactual-enhancement Diffusion Perception (KCDP) framework. Specifically,\nKCDP leverages a VLM to align emotional representations in a shared knowledge\nspace and guides diffusion models for improved visual affective perception.\nFurthermore, a Counterfactual-Enhanced Language-image Emotional Alignment\n(CLIEA) method generates high-quality pseudo-labels for the target domain.\nExtensive experiments demonstrate that our model surpasses SOTA models in both\nperceptibility and generalization, e.g., gaining 12% improvements over the SOTA\nVER model TGCA-PVT. The project page is at https://yinwen2019.github.io/ucdver.", "published": "2025-05-26 08:50:30", "link": "http://arxiv.org/abs/2505.19694v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DriveCamSim: Generalizable Camera Simulation via Explicit Camera Modeling for Autonomous Driving", "abstract": "Camera sensor simulation serves as a critical role for autonomous driving\n(AD), e.g. evaluating vision-based AD algorithms. While existing approaches\nhave leveraged generative models for controllable image/video generation, they\nremain constrained to generating multi-view video sequences with fixed camera\nviewpoints and video frequency, significantly limiting their downstream\napplications. To address this, we present a generalizable camera simulation\nframework DriveCamSim, whose core innovation lies in the proposed Explicit\nCamera Modeling (ECM) mechanism. Instead of implicit interaction through\nvanilla attention, ECM establishes explicit pixel-wise correspondences across\nmulti-view and multi-frame dimensions, decoupling the model from overfitting to\nthe specific camera configurations (intrinsic/extrinsic parameters, number of\nviews) and temporal sampling rates presented in the training data. For\ncontrollable generation, we identify the issue of information loss inherent in\nexisting conditional encoding and injection pipelines, proposing an\ninformation-preserving control mechanism. This control mechanism not only\nimproves conditional controllability, but also can be extended to be\nidentity-aware to enhance temporal consistency in foreground object rendering.\nWith above designs, our model demonstrates superior performance in both visual\nquality and controllability, as well as generalization capability across\nspatial-level (camera parameters variations) and temporal-level (video frame\nrate variations), enabling flexible user-customizable camera simulation\ntailored to diverse application scenarios. Code will be avaliable at\nhttps://github.com/swc-17/DriveCamSim for facilitating future research.", "published": "2025-05-26 08:50:15", "link": "http://arxiv.org/abs/2505.19692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models", "abstract": "The emergence of Multimodal Large Language Models (MLRMs) has enabled\nsophisticated visual reasoning capabilities by integrating reinforcement\nlearning and Chain-of-Thought (CoT) supervision. However, while these enhanced\nreasoning capabilities improve performance, they also introduce new and\nunderexplored safety risks. In this work, we systematically investigate the\nsecurity implications of advanced visual reasoning in MLRMs. Our analysis\nreveals a fundamental trade-off: as visual reasoning improves, models become\nmore vulnerable to jailbreak attacks. Motivated by this critical finding, we\nintroduce VisCRA (Visual Chain Reasoning Attack), a novel jailbreak framework\nthat exploits the visual reasoning chains to bypass safety mechanisms. VisCRA\ncombines targeted visual attention masking with a two-stage reasoning induction\nstrategy to precisely control harmful outputs. Extensive experiments\ndemonstrate VisCRA's significant effectiveness, achieving high attack success\nrates on leading closed-source MLRMs: 76.48% on Gemini 2.0 Flash Thinking,\n68.56% on QvQ-Max, and 56.60% on GPT-4o. Our findings highlight a critical\ninsight: the very capability that empowers MLRMs -- their visual reasoning --\ncan also serve as an attack vector, posing significant security risks.", "published": "2025-05-26 08:45:06", "link": "http://arxiv.org/abs/2505.19684v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Burst Image Super-Resolution via Multi-Cross Attention Encoding and Multi-Scan State-Space Decoding", "abstract": "Multi-image super-resolution (MISR) can achieve higher image quality than\nsingle-image super-resolution (SISR) by aggregating sub-pixel information from\nmultiple spatially shifted frames. Among MISR tasks, burst super-resolution\n(BurstSR) has gained significant attention due to its wide range of\napplications. Recent methods have increasingly adopted Transformers over\nconvolutional neural networks (CNNs) in super-resolution tasks, due to their\nsuperior ability to capture both local and global context. However, most\nexisting approaches still rely on fixed and narrow attention windows that\nrestrict the perception of features beyond the local field. This limitation\nhampers alignment and feature aggregation, both of which are crucial for\nhigh-quality super-resolution. To address these limitations, we propose a novel\nfeature extractor that incorporates two newly designed attention mechanisms:\noverlapping cross-window attention and cross-frame attention, enabling more\nprecise and efficient extraction of sub-pixel information across multiple\nframes. Furthermore, we introduce a Multi-scan State-Space Module with the\ncross-frame attention mechanism to enhance feature aggregation. Extensive\nexperiments on both synthetic and real-world benchmarks demonstrate the\nsuperiority of our approach. Additional evaluations on ISO 12233 resolution\ntest charts further confirm its enhanced super-resolution performance.", "published": "2025-05-26 08:24:33", "link": "http://arxiv.org/abs/2505.19668v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks", "abstract": "This paper proposes FieldWorkArena, a benchmark for agentic AI targeting\nreal-world field work. With the recent increase in demand for agentic AI, they\nare required to monitor and report safety and health incidents, as well as\nmanufacturing-related incidents, that may occur in real-world work\nenvironments. Existing agentic AI benchmarks have been limited to evaluating\nweb tasks and are insufficient for evaluating agents in real-world work\nenvironments, where complexity increases significantly. In this paper, we\ndefine a new action space that agentic AI should possess for real world work\nenvironment benchmarks and improve the evaluation function from previous\nmethods to assess the performance of agentic AI in diverse real-world tasks.\nThe dataset consists of videos captured on-site and documents actually used in\nfactories and warehouses, and tasks were created based on interviews with\non-site workers and managers. Evaluation results confirmed that performance\nevaluation considering the characteristics of Multimodal LLM (MLLM) such as\nGPT-4o is feasible. Additionally, the effectiveness and limitations of the\nproposed new evaluation method were identified. The complete dataset\n(HuggingFace) and evaluation program (GitHub) can be downloaded from the\nfollowing website:\nhttps://en-documents.research.global.fujitsu.com/fieldworkarena/.", "published": "2025-05-26 08:21:46", "link": "http://arxiv.org/abs/2505.19662v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation", "abstract": "Medical image segmentation models often struggle to generalize across\ndifferent domains due to various reasons. Domain Generalization (DG) methods\novercome this either through representation learning or data augmentation\n(DAug). While representation learning methods seek domain-invariant features,\nthey often rely on ad-hoc techniques and lack formal guarantees. DAug methods,\nwhich enrich model representations through synthetic samples, have shown\ncomparable or superior performance to representation learning approaches. We\npropose LangDAug, a novel $\\textbf{Lang}$evin $\\textbf{D}$ata\n$\\textbf{Aug}$mentation for multi-source domain generalization in 2D medical\nimage segmentation. LangDAug leverages Energy-Based Models (EBMs) trained via\ncontrastive divergence to traverse between source domains, generating\nintermediate samples through Langevin dynamics. Theoretical analysis shows that\nLangDAug induces a regularization effect, and for GLMs, it upper-bounds the\nRademacher complexity by the intrinsic dimensionality of the data manifold.\nThrough extensive experiments on Fundus segmentation and 2D MRI prostate\nsegmentation benchmarks, we show that LangDAug outperforms state-of-the-art\ndomain generalization methods and effectively complements existing\ndomain-randomization approaches. The codebase for our method is available at\nhttps://github.com/backpropagator/LangDAug.", "published": "2025-05-26 08:18:32", "link": "http://arxiv.org/abs/2505.19659v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReDDiT: Rehashing Noise for Discrete Visual Generation", "abstract": "Discrete diffusion models are gaining traction in the visual generative area\nfor their efficiency and compatibility. However, the pioneered attempts still\nfall behind the continuous counterparts, which we attribute to the noise\n(absorbing state) design and sampling heuristics. In this study, we propose the\nrehashing noise framework for discrete diffusion transformer, termed ReDDiT, to\nextend absorbing states and improve expressive capacity of discrete diffusion\nmodels. ReDDiT enriches the potential paths that latent variables can traverse\nduring training with randomized multi-index corruption. The derived rehash\nsampler, which reverses the randomized absorbing paths, guarantees the\ndiversity and low discrepancy of the generation process. These reformulations\nlead to more consistent and competitive generation quality, mitigating the need\nfor heavily tuned randomness. Experiments show that ReDDiT significantly\noutperforms the baseline (reducing gFID from 6.18 to 1.61) and is on par with\nthe continuous counterparts with higher efficiency.", "published": "2025-05-26 08:17:20", "link": "http://arxiv.org/abs/2505.19656v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval", "abstract": "Multimodal information retrieval (MIR) faces inherent challenges due to the\nheterogeneity of data sources and the complexity of cross-modal alignment.\nWhile previous studies have identified modal gaps in feature spaces, a\nsystematic approach to address these challenges remains unexplored. In this\nwork, we introduce UNITE, a universal framework that tackles these challenges\nthrough two critical yet underexplored aspects: data curation and\nmodality-aware training configurations. Our work provides the first\ncomprehensive analysis of how modality-specific data properties influence\ndownstream task performance across diverse scenarios. Moreover, we propose\nModal-Aware Masked Contrastive Learning (MAMCL) to mitigate the competitive\nrelationships among the instances of different modalities. Our framework\nachieves state-of-the-art results on multiple multimodal retrieval benchmarks,\noutperforming existing methods by notable margins. Through extensive\nexperiments, we demonstrate that strategic modality curation and tailored\ntraining protocols are pivotal for robust cross-modal representation learning.\nThis work not only advances MIR performance but also provides a foundational\nblueprint for future research in multimodal systems. Our project is available\nat https://friedrichor.github.io/projects/UNITE.", "published": "2025-05-26 08:09:44", "link": "http://arxiv.org/abs/2505.19650v1", "categories": ["cs.CV", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "HF-VTON: High-Fidelity Virtual Try-On via Consistent Geometric and Semantic Alignment", "abstract": "Virtual try-on technology has become increasingly important in the fashion\nand retail industries, enabling the generation of high-fidelity garment images\nthat adapt seamlessly to target human models. While existing methods have\nachieved notable progress, they still face significant challenges in\nmaintaining consistency across different poses. Specifically, geometric\ndistortions lead to a lack of spatial consistency, mismatches in garment\nstructure and texture across poses result in semantic inconsistency, and the\nloss or distortion of fine-grained details diminishes visual fidelity. To\naddress these challenges, we propose HF-VTON, a novel framework that ensures\nhigh-fidelity virtual try-on performance across diverse poses. HF-VTON consists\nof three key modules: (1) the Appearance-Preserving Warp Alignment Module\n(APWAM), which aligns garments to human poses, addressing geometric\ndeformations and ensuring spatial consistency; (2) the Semantic Representation\nand Comprehension Module (SRCM), which captures fine-grained garment attributes\nand multi-pose data to enhance semantic representation, maintaining structural,\ntextural, and pattern consistency; and (3) the Multimodal Prior-Guided\nAppearance Generation Module (MPAGM), which integrates multimodal features and\nprior knowledge from pre-trained models to optimize appearance generation,\nensuring both semantic and geometric consistency. Additionally, to overcome\ndata limitations in existing benchmarks, we introduce the SAMP-VTONS dataset,\nfeaturing multi-pose pairs and rich textual annotations for a more\ncomprehensive evaluation. Experimental results demonstrate that HF-VTON\noutperforms state-of-the-art methods on both VITON-HD and SAMP-VTONS, excelling\nin visual fidelity, semantic consistency, and detail preservation.", "published": "2025-05-26 07:55:49", "link": "http://arxiv.org/abs/2505.19638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking Large Multimodal Models for Ophthalmic Visual Question Answering with OphthalWeChat", "abstract": "Purpose: To develop a bilingual multimodal visual question answering (VQA)\nbenchmark for evaluating VLMs in ophthalmology. Methods: Ophthalmic image posts\nand associated captions published between January 1, 2016, and December 31,\n2024, were collected from WeChat Official Accounts. Based on these captions,\nbilingual question-answer (QA) pairs in Chinese and English were generated\nusing GPT-4o-mini. QA pairs were categorized into six subsets by question type\nand language: binary (Binary_CN, Binary_EN), single-choice (Single-choice_CN,\nSingle-choice_EN), and open-ended (Open-ended_CN, Open-ended_EN). The benchmark\nwas used to evaluate the performance of three VLMs: GPT-4o, Gemini 2.0 Flash,\nand Qwen2.5-VL-72B-Instruct. Results: The final OphthalWeChat dataset included\n3,469 images and 30,120 QA pairs across 9 ophthalmic subspecialties, 548\nconditions, 29 imaging modalities, and 68 modality combinations. Gemini 2.0\nFlash achieved the highest overall accuracy (0.548), outperforming GPT-4o\n(0.522, P < 0.001) and Qwen2.5-VL-72B-Instruct (0.514, P < 0.001). It also led\nin both Chinese (0.546) and English subsets (0.550). Subset-specific\nperformance showed Gemini 2.0 Flash excelled in Binary_CN (0.687),\nSingle-choice_CN (0.666), and Single-choice_EN (0.646), while GPT-4o ranked\nhighest in Binary_EN (0.717), Open-ended_CN (BLEU-1: 0.301; BERTScore: 0.382),\nand Open-ended_EN (BLEU-1: 0.183; BERTScore: 0.240). Conclusions: This study\npresents the first bilingual VQA benchmark for ophthalmology, distinguished by\nits real-world context and inclusion of multiple examinations per patient. The\ndataset reflects authentic clinical decision-making scenarios and enables\nquantitative evaluation of VLMs, supporting the development of accurate,\nspecialized, and trustworthy AI systems for eye care.", "published": "2025-05-26 07:45:42", "link": "http://arxiv.org/abs/2505.19624v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Rotation-Equivariant Self-Supervised Method in Image Denoising", "abstract": "Self-supervised image denoising methods have garnered significant research\nattention in recent years, for this kind of method reduces the requirement of\nlarge training datasets. Compared to supervised methods, self-supervised\nmethods rely more on the prior embedded in deep networks themselves. As a\nresult, most of the self-supervised methods are designed with Convolution\nNeural Networks (CNNs) architectures, which well capture one of the most\nimportant image prior, translation equivariant prior. Inspired by the great\nsuccess achieved by the introduction of translational equivariance, in this\npaper, we explore the way to further incorporate another important image prior.\nSpecifically, we first apply high-accuracy rotation equivariant convolution to\nself-supervised image denoising. Through rigorous theoretical analysis, we have\nproved that simply replacing all the convolution layers with rotation\nequivariant convolution layers would modify the network into its rotation\nequivariant version. To the best of our knowledge, this is the first time that\nrotation equivariant image prior is introduced to self-supervised image\ndenoising at the network architecture level with a comprehensive theoretical\nanalysis of equivariance errors, which offers a new perspective to the field of\nself-supervised image denoising. Moreover, to further improve the performance,\nwe design a new mask mechanism to fusion the output of rotation equivariant\nnetwork and vanilla CNN-based network, and construct an adaptive rotation\nequivariant framework. Through extensive experiments on three typical methods,\nwe have demonstrated the effectiveness of the proposed method.", "published": "2025-05-26 07:32:52", "link": "http://arxiv.org/abs/2505.19618v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities across tasks, yet they often exhibit difficulty in distinguishing\ntask-relevant from irrelevant signals, particularly in tasks like Visual\nQuestion Answering (VQA), which can lead to susceptibility to misleading or\nspurious inputs. We refer to this broader limitation as the Cross-Modality\nCompetency Problem: the model's inability to fairly evaluate all modalities.\nThis vulnerability becomes more evident in modality-specific tasks such as\nimage classification or pure text question answering, where models are expected\nto rely solely on one modality. In such tasks, spurious information from\nirrelevant modalities often leads to significant performance degradation. We\nrefer to this failure as Modality Interference, which serves as a concrete and\nmeasurable instance of the cross-modality competency problem. We further design\na perturbation-based causal diagnostic experiment to verify and quantify this\nproblem. To mitigate modality interference, we propose a novel framework to\nfine-tune MLLMs, including perturbation-based data augmentations with both\nheuristic perturbations and adversarial perturbations via Projected Gradient\nDescent (PGD), and a consistency regularization strategy applied to model\noutputs with original and perturbed inputs. Experiments on multiple benchmark\ndatasets (image-heavy, text-heavy, and VQA tasks) and multiple model families\nwith different scales demonstrate significant improvements in robustness and\ncross-modality competency, indicating our method's effectiveness in boosting\nunimodal reasoning ability while enhancing performance on multimodal tasks.", "published": "2025-05-26 07:31:32", "link": "http://arxiv.org/abs/2505.19616v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Multiplicity is an Inevitable and Inherent Challenge in Multimodal Learning", "abstract": "Multimodal learning has seen remarkable progress, particularly with the\nemergence of large-scale pre-training across various modalities. However, most\ncurrent approaches are built on the assumption of a deterministic, one-to-one\nalignment between modalities. This oversimplifies real-world multimodal\nrelationships, where their nature is inherently many-to-many. This phenomenon,\nnamed multiplicity, is not a side-effect of noise or annotation error, but an\ninevitable outcome of semantic abstraction, representational asymmetry, and\ntask-dependent ambiguity in multimodal tasks. This position paper argues that\nmultiplicity is a fundamental bottleneck that manifests across all stages of\nthe multimodal learning pipeline: from data construction to training and\nevaluation. This paper examines the causes and consequences of multiplicity,\nand highlights how multiplicity introduces training uncertainty, unreliable\nevaluation, and low dataset quality. This position calls for new research\ndirections on multimodal learning: novel multiplicity-aware learning frameworks\nand dataset construction protocols considering multiplicity.", "published": "2025-05-26 07:30:38", "link": "http://arxiv.org/abs/2505.19614v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "TESSER: Transfer-Enhancing Adversarial Attacks from Vision Transformers via Spectral and Semantic Regularization", "abstract": "Adversarial transferability remains a critical challenge in evaluating the\nrobustness of deep neural networks. In security-critical applications,\ntransferability enables black-box attacks without access to model internals,\nmaking it a key concern for real-world adversarial threat assessment. While\nVision Transformers (ViTs) have demonstrated strong adversarial performance,\nexisting attacks often fail to transfer effectively across architectures,\nespecially from ViTs to Convolutional Neural Networks (CNNs) or hybrid models.\nIn this paper, we introduce \\textbf{TESSER} -- a novel adversarial attack\nframework that enhances transferability via two key strategies: (1)\n\\textit{Feature-Sensitive Gradient Scaling (FSGS)}, which modulates gradients\nbased on token-wise importance derived from intermediate feature activations,\nand (2) \\textit{Spectral Smoothness Regularization (SSR)}, which suppresses\nhigh-frequency noise in perturbations using a differentiable Gaussian prior.\nThese components work in tandem to generate perturbations that are both\nsemantically meaningful and spectrally smooth. Extensive experiments on\nImageNet across 12 diverse architectures demonstrate that TESSER achieves\n+10.9\\% higher attack succes rate (ASR) on CNNs and +7.2\\% on ViTs compared to\nthe state-of-the-art Adaptive Token Tuning (ATT) method. Moreover, TESSER\nsignificantly improves robustness against defended models, achieving 53.55\\%\nASR on adversarially trained CNNs. Qualitative analysis shows strong alignment\nbetween TESSER's perturbations and salient visual regions identified via\nGrad-CAM, while frequency-domain analysis reveals a 12\\% reduction in\nhigh-frequency energy, confirming the effectiveness of spectral regularization.", "published": "2025-05-26 07:30:00", "link": "http://arxiv.org/abs/2505.19613v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Align and Surpass Human Camouflaged Perception: Visual Refocus Reinforcement Fine-Tuning", "abstract": "Current multi-modal models exhibit a notable misalignment with the human\nvisual system when identifying objects that are visually assimilated into the\nbackground. Our observations reveal that these multi-modal models cannot\ndistinguish concealed objects, demonstrating an inability to emulate human\ncognitive processes which effectively utilize foreground-background similarity\nprinciples for visual analysis. To analyze this hidden human-model visual\nthinking discrepancy, we build a visual system that mimicks human visual\ncamouflaged perception to progressively and iteratively `refocus' visual\nconcealed content. The refocus is a progressive guidance mechanism enabling\nmodels to logically localize objects in visual images through stepwise\nreasoning. The localization process of concealed objects requires hierarchical\nattention shifting with dynamic adjustment and refinement of prior cognitive\nknowledge. In this paper, we propose a visual refocus reinforcement framework\nvia the policy optimization algorithm to encourage multi-modal models to think\nand refocus more before answering, and achieve excellent reasoning abilities to\nalign and even surpass human camouflaged perception systems. Our extensive\nexperiments on camouflaged perception successfully demonstrate the emergence of\nrefocus visual phenomena, characterized by multiple reasoning tokens and\ndynamic adjustment of the detection box. Besides, experimental results on both\ncamouflaged object classification and detection tasks exhibit significantly\nsuperior performance compared to Supervised Fine-Tuning (SFT) baselines.", "published": "2025-05-26 07:27:18", "link": "http://arxiv.org/abs/2505.19611v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models", "abstract": "Vision-Language Models (VLMs) exhibit impressive performance, yet the\nintegration of powerful vision encoders has significantly broadened their\nattack surface, rendering them increasingly susceptible to jailbreak attacks.\nHowever, lacking well-defined attack objectives, existing jailbreak methods\noften struggle with gradient-based strategies prone to local optima and lacking\nprecise directional guidance, and typically decouple visual and textual\nmodalities, thereby limiting their effectiveness by neglecting crucial\ncross-modal interactions. Inspired by the Eliciting Latent Knowledge (ELK)\nframework, we posit that VLMs encode safety-relevant information within their\ninternal fusion-layer representations, revealing an implicit safety decision\nboundary in the latent space. This motivates exploiting boundary to steer model\nbehavior. Accordingly, we propose JailBound, a novel latent space jailbreak\nframework comprising two stages: (1) Safety Boundary Probing, which addresses\nthe guidance issue by approximating decision boundary within fusion layer's\nlatent space, thereby identifying optimal perturbation directions towards the\ntarget region; and (2) Safety Boundary Crossing, which overcomes the\nlimitations of decoupled approaches by jointly optimizing adversarial\nperturbations across both image and text inputs. This latter stage employs an\ninnovative mechanism to steer the model's internal state towards\npolicy-violating outputs while maintaining cross-modal semantic consistency.\nExtensive experiments on six diverse VLMs demonstrate JailBound's efficacy,\nachieves 94.32% white-box and 67.28% black-box attack success averagely, which\nare 6.17% and 21.13% higher than SOTA methods, respectively. Our findings\nexpose a overlooked safety risk in VLMs and highlight the urgent need for more\nrobust defenses. Warning: This paper contains potentially sensitive, harmful\nand offensive content.", "published": "2025-05-26 07:23:00", "link": "http://arxiv.org/abs/2505.19610v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rep3D: Re-parameterize Large 3D Kernels with Low-Rank Receptive Modeling for Medical Imaging", "abstract": "In contrast to vision transformers, which model long-range dependencies\nthrough global self-attention, large kernel convolutions provide a more\nefficient and scalable alternative, particularly in high-resolution 3D\nvolumetric settings. However, naively increasing kernel size often leads to\noptimization instability and degradation in performance. Motivated by the\nspatial bias observed in effective receptive fields (ERFs), we hypothesize that\ndifferent kernel elements converge at variable rates during training. To\nsupport this, we derive a theoretical connection between element-wise gradients\nand first-order optimization, showing that structurally re-parameterized\nconvolution blocks inherently induce spatially varying learning rates. Building\non this insight, we introduce Rep3D, a 3D convolutional framework that\nincorporates a learnable spatial prior into large kernel training. A\nlightweight two-stage modulation network generates a receptive-biased scaling\nmask, adaptively re-weighting kernel updates and enabling local-to-global\nconvergence behavior. Rep3D adopts a plain encoder design with large depthwise\nconvolutions, avoiding the architectural complexity of multi-branch\ncompositions. We evaluate Rep3D on five challenging 3D segmentation benchmarks\nand demonstrate consistent improvements over state-of-the-art baselines,\nincluding transformer-based and fixed-prior re-parameterization methods. By\nunifying spatial inductive bias with optimization-aware learning, Rep3D offers\nan interpretable, and scalable solution for 3D medical image analysis. The\nsource code is publicly available at https://github.com/leeh43/Rep3D.", "published": "2025-05-26 07:12:56", "link": "http://arxiv.org/abs/2505.19603v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "WQLCP: Weighted Adaptive Conformal Prediction for Robust Uncertainty Quantification Under Distribution Shifts", "abstract": "Conformal prediction (CP) provides a framework for constructing prediction\nsets with guaranteed coverage, assuming exchangeable data. However, real-world\nscenarios often involve distribution shifts that violate exchangeability,\nleading to unreliable coverage and inflated prediction sets. To address this\nchallenge, we first introduce Reconstruction Loss-Scaled Conformal Prediction\n(RLSCP), which utilizes reconstruction losses derived from a Variational\nAutoencoder (VAE) as an uncertainty metric to scale score functions. While\nRLSCP demonstrates performance improvements, mainly resulting in better\ncoverage, it quantifies quantiles based on a fixed calibration dataset without\nconsidering the discrepancies between test and train datasets in an\nunexchangeable setting. In the next step, we propose Weighted Quantile\nLoss-scaled Conformal Prediction (WQLCP), which refines RLSCP by incorporating\na weighted notion of exchangeability, adjusting the calibration quantile\nthreshold based on weights with respect to the ratio of calibration and test\nloss values. This approach improves the CP-generated prediction set outputs in\nthe presence of distribution shifts. Experiments on large-scale datasets,\nincluding ImageNet variants, demonstrate that WQLCP outperforms existing\nbaselines by consistently maintaining coverage while reducing prediction set\nsizes, providing a robust solution for CP under distribution shifts.", "published": "2025-05-26 07:00:15", "link": "http://arxiv.org/abs/2505.19587v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Beyond Segmentation: Confidence-Aware and Debiased Estimation of Ratio-based Biomarkers", "abstract": "Ratio-based biomarkers -- such as the proportion of necrotic tissue within a\ntumor -- are widely used in clinical practice to support diagnosis, prognosis\nand treatment planning. These biomarkers are typically estimated from soft\nsegmentation outputs by computing region-wise ratios. Despite the high-stakes\nnature of clinical decision making, existing methods provide only point\nestimates, offering no measure of uncertainty. In this work, we propose a\nunified \\textit{confidence-aware} framework for estimating ratio-based\nbiomarkers. We conduct a systematic analysis of error propagation in the\nsegmentation-to-biomarker pipeline and identify model miscalibration as the\ndominant source of uncertainty. To mitigate this, we incorporate a lightweight,\npost-hoc calibration module that can be applied using internal hospital data\nwithout retraining. We leverage a tunable parameter $Q$ to control the\nconfidence level of the derived bounds, allowing adaptation towards clinical\npractice. Extensive experiments show that our method produces statistically\nsound confidence intervals, with tunable confidence levels, enabling more\ntrustworthy application of predictive biomarkers in clinical workflows.", "published": "2025-05-26 06:58:19", "link": "http://arxiv.org/abs/2505.19585v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Guard Me If You Know Me: Protecting Specific Face-Identity from Deepfakes", "abstract": "Securing personal identity against deepfake attacks is increasingly critical\nin the digital age, especially for celebrities and political figures whose\nfaces are easily accessible and frequently targeted. Most existing deepfake\ndetection methods focus on general-purpose scenarios and often ignore the\nvaluable prior knowledge of known facial identities, e.g., \"VIP individuals\"\nwhose authentic facial data are already available. In this paper, we propose\n\\textbf{VIPGuard}, a unified multimodal framework designed to capture\nfine-grained and comprehensive facial representations of a given identity,\ncompare them against potentially fake or similar-looking faces, and reason over\nthese comparisons to make accurate and explainable predictions. Specifically,\nour framework consists of three main stages. First, fine-tune a multimodal\nlarge language model (MLLM) to learn detailed and structural facial attributes.\nSecond, we perform identity-level discriminative learning to enable the model\nto distinguish subtle differences between highly similar faces, including real\nand fake variations. Finally, we introduce user-specific customization, where\nwe model the unique characteristics of the target face identity and perform\nsemantic reasoning via MLLM to enable personalized and explainable deepfake\ndetection. Our framework shows clear advantages over previous detection works,\nwhere traditional detectors mainly rely on low-level visual cues and provide no\nhuman-understandable explanations, while other MLLM-based models often lack a\ndetailed understanding of specific face identities. To facilitate the\nevaluation of our method, we built a comprehensive identity-aware benchmark\ncalled \\textbf{VIPBench} for personalized deepfake detection, involving the\nlatest 7 face-swapping and 7 entire face synthesis techniques for generation.", "published": "2025-05-26 06:55:23", "link": "http://arxiv.org/abs/2505.19582v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VTBench: Comprehensive Benchmark Suite Towards Real-World Virtual Try-on Models", "abstract": "While virtual try-on has achieved significant progress, evaluating these\nmodels towards real-world scenarios remains a challenge. A comprehensive\nbenchmark is essential for three key reasons:(1) Current metrics inadequately\nreflect human perception, particularly in unpaired try-on settings;(2)Most\nexisting test sets are limited to indoor scenarios, lacking complexity for\nreal-world evaluation; and (3) An ideal system should guide future advancements\nin virtual try-on generation. To address these needs, we introduce VTBench, a\nhierarchical benchmark suite that systematically decomposes virtual image\ntry-on into hierarchical, disentangled dimensions, each equipped with tailored\ntest sets and evaluation criteria. VTBench exhibits three key advantages:1)\nMulti-Dimensional Evaluation Framework: The benchmark encompasses five critical\ndimensions for virtual try-on generation (e.g., overall image quality, texture\npreservation, complex background consistency, cross-category size adaptability,\nand hand-occlusion handling). Granular evaluation metrics of corresponding test\nsets pinpoint model capabilities and limitations across diverse, challenging\nscenarios.2) Human Alignment: Human preference annotations are provided for\neach test set, ensuring the benchmark's alignment with perceptual quality\nacross all evaluation dimensions. (3) Valuable Insights: Beyond standard indoor\nsettings, we analyze model performance variations across dimensions and\ninvestigate the disparity between indoor and real-world try-on scenarios. To\nfoster the field of virtual try-on towards challenging real-world scenario,\nVTBench will be open-sourced, including all test sets, evaluation protocols,\ngenerated results, and human annotations.", "published": "2025-05-26 06:37:11", "link": "http://arxiv.org/abs/2505.19571v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What You Perceive Is What You Conceive: A Cognition-Inspired Framework for Open Vocabulary Image Segmentation", "abstract": "Open vocabulary image segmentation tackles the challenge of recognizing\ndynamically adjustable, predefined novel categories at inference time by\nleveraging vision-language alignment. However, existing paradigms typically\nperform class-agnostic region segmentation followed by category matching, which\ndeviates from the human visual system's process of recognizing objects based on\nsemantic concepts, leading to poor alignment between region segmentation and\ntarget concepts. To bridge this gap, we propose a novel Cognition-Inspired\nFramework for open vocabulary image segmentation that emulates the human visual\nrecognition process: first forming a conceptual understanding of an object,\nthen perceiving its spatial extent. The framework consists of three core\ncomponents: (1) A Generative Vision-Language Model (G-VLM) that mimics human\ncognition by generating object concepts to provide semantic guidance for region\nsegmentation. (2) A Concept-Aware Visual Enhancer Module that fuses textual\nconcept features with global visual representations, enabling adaptive visual\nperception based on target concepts. (3) A Cognition-Inspired Decoder that\nintegrates local instance features with G-VLM-provided semantic cues, allowing\nselective classification over a subset of relevant categories. Extensive\nexperiments demonstrate that our framework achieves significant improvements,\nreaching $27.2$ PQ, $17.0$ mAP, and $35.3$ mIoU on A-150. It further attains\n$56.2$, $28.2$, $15.4$, $59.2$, $18.7$, and $95.8$ mIoU on Cityscapes,\nMapillary Vistas, A-847, PC-59, PC-459, and PAS-20, respectively. In addition,\nour framework supports vocabulary-free segmentation, offering enhanced\nflexibility in recognizing unseen categories. Code will be public.", "published": "2025-05-26 06:33:48", "link": "http://arxiv.org/abs/2505.19569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Few-Shot Class-Incremental Learning For Efficient SAR Automatic Target Recognition", "abstract": "Synthetic aperture radar automatic target recognition (SAR-ATR) systems have\nrapidly evolved to tackle incremental recognition challenges in operational\nsettings. Data scarcity remains a major hurdle that conventional SAR-ATR\ntechniques struggle to address. To cope with this challenge, we propose a\nfew-shot class-incremental learning (FSCIL) framework based on a dual-branch\narchitecture that focuses on local feature extraction and leverages the\ndiscrete Fourier transform and global filters to capture long-term spatial\ndependencies. This incorporates a lightweight cross-attention mechanism that\nfuses domain-specific features with global dependencies to ensure robust\nfeature interaction, while maintaining computational efficiency by introducing\nminimal scale-shift parameters. The framework combines focal loss for class\ndistinction under imbalance and center loss for compact intra-class\ndistributions to enhance class separation boundaries. Experimental results on\nthe MSTAR benchmark dataset demonstrate that the proposed framework\nconsistently outperforms state-of-the-art methods in FSCIL SAR-ATR, attesting\nto its effectiveness in real-world scenarios.", "published": "2025-05-26 06:25:30", "link": "http://arxiv.org/abs/2505.19565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple Buffers", "abstract": "Neural fields are now the central focus of research in 3D vision and computer\ngraphics. Existing methods mainly focus on various scene representations, such\nas neural points and 3D Gaussians. However, few works have studied the\nrendering process to enhance the neural fields. In this work, we propose a\nplug-in method named K-Buffers that leverages multiple buffers to improve the\nrendering performance. Our method first renders K buffers from scene\nrepresentations and constructs K pixel-wise feature maps. Then, We introduce a\nK-Feature Fusion Network (KFN) to merge the K pixel-wise feature maps. Finally,\nwe adopt a feature decoder to generate the rendering image. We also introduce\nan acceleration strategy to improve rendering speed and quality. We apply our\nmethod to well-known radiance field baselines, including neural point fields\nand 3D Gaussian Splatting (3DGS). Extensive experiments demonstrate that our\nmethod effectively enhances the rendering performance of neural point fields\nand 3DGS.", "published": "2025-05-26 06:24:48", "link": "http://arxiv.org/abs/2505.19564v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Aggregated Structural Representation with Large Language Models for Human-Centric Layout Generation", "abstract": "Time consumption and the complexity of manual layout design make automated\nlayout generation a critical task, especially for multiple applications across\ndifferent mobile devices. Existing graph-based layout generation approaches\nsuffer from limited generative capability, often resulting in unreasonable and\nincompatible outputs. Meanwhile, vision based generative models tend to\noverlook the original structural information, leading to component\nintersections and overlaps. To address these challenges, we propose an\nAggregation Structural Representation (ASR) module that integrates graph\nnetworks with large language models (LLMs) to preserve structural information\nwhile enhancing generative capability. This novel pipeline utilizes graph\nfeatures as hierarchical prior knowledge, replacing the traditional Vision\nTransformer (ViT) module in multimodal large language models (MLLM) to predict\nfull layout information for the first time. Moreover, the intermediate graph\nmatrix used as input for the LLM is human editable, enabling progressive, human\ncentric design generation. A comprehensive evaluation on the RICO dataset\ndemonstrates the strong performance of ASR, both quantitatively using mean\nIntersection over Union (mIoU), and qualitatively through a crowdsourced user\nstudy. Additionally, sampling on relational features ensures diverse layout\ngeneration, further enhancing the adaptability and creativity of the proposed\napproach.", "published": "2025-05-26 06:17:21", "link": "http://arxiv.org/abs/2505.19554v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds", "abstract": "Test-Time Training (TTT) has emerged as a promising solution to address\ndistribution shifts in 3D point cloud classification. However, existing methods\noften rely on computationally expensive backpropagation during adaptation,\nlimiting their applicability in real-world, time-sensitive scenarios. In this\npaper, we introduce SMART-PC, a skeleton-based framework that enhances\nresilience to corruptions by leveraging the geometric structure of 3D point\nclouds. During pre-training, our method predicts skeletal representations,\nenabling the model to extract robust and meaningful geometric features that are\nless sensitive to corruptions, thereby improving adaptability to test-time\ndistribution shifts. Unlike prior approaches, SMART-PC achieves real-time\nadaptation by eliminating backpropagation and updating only BatchNorm\nstatistics, resulting in a lightweight and efficient framework capable of\nachieving high frame-per-second rates while maintaining superior classification\nperformance. Extensive experiments on benchmark datasets, including\nModelNet40-C, ShapeNet-C, and ScanObjectNN-C, demonstrate that SMART-PC\nachieves state-of-the-art results, outperforming existing methods such as MATE\nin terms of both accuracy and computational efficiency. The implementation is\navailable at: https://github.com/AliBahri94/SMART-PC.", "published": "2025-05-26 06:11:02", "link": "http://arxiv.org/abs/2505.19546v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models", "abstract": "Large vision-language models (LVLMs) excel at multimodal understanding but\nsuffer from high computational costs due to redundant vision tokens. Existing\npruning methods typically rely on single-layer attention scores to rank and\nprune redundant visual tokens to solve this inefficiency. However, as the\ninteraction between tokens and layers is complicated, this raises a basic\nquestion: Is such a simple single-layer criterion sufficient to identify\nredundancy? To answer this question, we rethink the emergence of redundant\nvisual tokens from a fundamental perspective: information flow, which models\nthe interaction between tokens and layers by capturing how information moves\nbetween tokens across layers. We find (1) the CLS token acts as an information\nrelay, which can simplify the complicated flow analysis; (2) the redundancy\nemerges progressively and dynamically via layer-wise attention concentration;\nand (3) relying solely on attention scores from single layers can lead to\ncontradictory redundancy identification. Based on this, we propose FlowCut, an\ninformation-flow-aware pruning framework, mitigating the insufficiency of the\ncurrent criterion for identifying redundant tokens and better aligning with the\nmodel's inherent behaviors. Extensive experiments show that FlowCut achieves\nsuperior results, outperforming SoTA by 1.6% on LLaVA-1.5-7B with 88.9% token\nreduction, and by 4.3% on LLaVA-NeXT-7B with 94.4% reduction, delivering 3.2x\nspeed-up in the prefilling stage. Our code is available at\nhttps://github.com/TungChintao/FlowCut", "published": "2025-05-26 05:54:48", "link": "http://arxiv.org/abs/2505.19536v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "TDVE-Assessor: Benchmarking and Evaluating the Quality of Text-Driven Video Editing with LMMs", "abstract": "Text-driven video editing is rapidly advancing, yet its rigorous evaluation\nremains challenging due to the absence of dedicated video quality assessment\n(VQA) models capable of discerning the nuances of editing quality. To address\nthis critical gap, we introduce TDVE-DB, a large-scale benchmark dataset for\ntext-driven video editing. TDVE-DB consists of 3,857 edited videos generated\nfrom 12 diverse models across 8 editing categories, and is annotated with\n173,565 human subjective ratings along three crucial dimensions, i.e., edited\nvideo quality, editing alignment, and structural consistency. Based on TDVE-DB,\nwe first conduct a comprehensive evaluation for the 12 state-of-the-art editing\nmodels revealing the strengths and weaknesses of current video techniques, and\nthen benchmark existing VQA methods in the context of text-driven video editing\nevaluation. Building on these insights, we propose TDVE-Assessor, a novel VQA\nmodel specifically designed for text-driven video editing assessment.\nTDVE-Assessor integrates both spatial and temporal video features into a large\nlanguage model (LLM) for rich contextual understanding to provide comprehensive\nquality assessment. Extensive experiments demonstrate that TDVE-Assessor\nsubstantially outperforms existing VQA models on TDVE-DB across all three\nevaluation dimensions, setting a new state-of-the-art. Both TDVE-DB and\nTDVE-Assessor will be released upon the publication.", "published": "2025-05-26 05:47:09", "link": "http://arxiv.org/abs/2505.19535v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bounding Width on Graph Classes of Constant Diameter", "abstract": "We determine if the width of a graph class ${\\cal G}$ changes from unbounded\nto bounded if we consider only those graphs from ${\\cal G}$ whose diameter is\nbounded. As parameters we consider treedepth, pathwidth, treewidth and\nclique-width, and as graph classes we consider classes defined by forbidding\nsome specific graph $F$ as a minor, induced subgraph or subgraph, respectively.\nOur main focus is on treedepth for $F$-subgraph-free graphs of diameter at\nmost~$d$ for some fixed integer $d$. We give classifications of boundedness of\ntreedepth for $d\\in \\{4,5,\\ldots\\}$ and partial classifications for $d=2$ and\n$d=3$.", "published": "2025-05-26 12:50:59", "link": "http://arxiv.org/abs/2505.19926v1", "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "Pathographs and some (un)decidability results", "abstract": "We introduce pathographs as a framework to study graph classes defined by\nforbidden structures, including forbidding induced subgraphs, minors, etc.\nPathographs approximately generalize s-graphs of\nL\\'ev\\^eque--Lin--Maffray--Trotignon by the addition of two extra adjacency\nrelations: one between subdivisible edges and vertices called spokes, and one\nbetween pairs of subdivisible edges called rungs. We consider the following\ndecision problem: given a pathograph $\\mathfrak{H}$ and a finite set of\npathographs $\\mathcal{F}$, is there an $\\mathcal{F}$-free realization of\n$\\mathfrak{H}$? This may be regarded as a generalization of the \"graph class\ncontainment problem\": given two graph classes $S$ and $S'$, is it the case that\n$S\\subseteq S'$? We prove the pathograph realization problem is undecidable in\ngeneral, but it is decidable in the case that $\\mathfrak{H}$ has no rungs (but\nmay have spokes), or if $\\mathcal{F}$ is closed under adding edges, spokes, and\nrungs. We also discuss some potential applications to proving decomposition\ntheorems.", "published": "2025-05-26 11:55:58", "link": "http://arxiv.org/abs/2505.19871v1", "categories": ["math.CO", "cs.DM", "cs.DS", "05C85 (Primary) 68Q45, 05C75 (Secondary)"], "primary_category": "math.CO"}
{"title": "Density Decomposition in Dual-Modular Optimization: Markets, Fairness, and Contracts", "abstract": "We study a unified framework for optimization problems defined on\ndual-modular instances, where the input comprises a finite ground set $V$ and\ntwo set functions: a monotone supermodular reward function $\\f$ and a strictly\nmonotone submodular cost function $\\g$. This abstraction captures and\ngeneralizes classical models in economics and combinatorial optimization,\nincluding submodular utility allocation (SUA) markets and combinatorial\ncontracts. At the core of our framework is the notion of density decomposition,\nwhich extends classical results to the dual-modular setting and uncovers\nstructural insights into fairness and optimality.\n  We show that the density decomposition yields a canonical vector of\nreward-to-cost ratios (densities) that simultaneously characterizes market\nequilibria, fair allocations -- via both lexicographic optimality and local\nmaximin conditions -- and best-response strategies in contract design. Our main\nresult proves the equivalence of these fairness notions and guarantees the\nexistence of allocations that realize the decomposition densities.\n  Our technical contributions include the analysis of a broad family of convex\nprograms -- parameterized by divergences such as quadratic, logarithmic, and\nhockey-stick functions -- whose minimizers recover the density decomposition.\nWe prove that any strictly convex divergence yields the same canonical density\nvector, and that locally maximin allocations act as universal minimizers for\nall divergences satisfying the data processing inequality.\n  As an application of our framework, we determine the structure and number of\ncritical values in the combinatorial contracts problem. Additionally, we\ngeneralize a Frank-Wolfe-type iterative method for approximating the\ndual-modular density decomposition, establishing both convergence guarantees\nand practical potential through efficient gradient oracle design.", "published": "2025-05-26 04:27:04", "link": "http://arxiv.org/abs/2505.19499v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "It's High Time: A Survey of Temporal Information Retrieval and Question Answering", "abstract": "Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nInformation Retrieval and Temporal Question Answering, two research areas aimed\nat handling and understanding time-sensitive information. As the amount of\ntime-stamped content from sources like news articles, web archives, and\nknowledge bases increases, systems must address challenges such as detecting\ntemporal intent, normalizing time expressions, ordering events, and reasoning\nover evolving or ambiguous facts. These challenges are critical across many\ndynamic and time-sensitive domains, from news and encyclopedias to science,\nhistory, and social media. We review both traditional approaches and modern\nneural methods, including those that use transformer models and Large Language\nModels (LLMs). We also review recent advances in temporal language modeling,\nmulti-hop reasoning, and retrieval-augmented generation (RAG), alongside\nbenchmark datasets and evaluation strategies that test temporal robustness,\nrecency awareness, and generalization.", "published": "2025-05-26 17:21:26", "link": "http://arxiv.org/abs/2505.20243v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Measure Domain's Gap: A Similar Domain Selection Principle for Multi-Domain Recommendation", "abstract": "Multi-Domain Recommendation (MDR) achieves the desirable recommendation\nperformance by effectively utilizing the transfer information across different\ndomains. Despite the great success, most existing MDR methods adopt a single\nstructure to transfer complex domain-shared knowledge. However, the beneficial\ntransferring information should vary across different domains. When there is\nknowledge conflict between domains or a domain is of poor quality,\nunselectively leveraging information from all domains will lead to a serious\nNegative Transfer Problem (NTP). Therefore, how to effectively model the\ncomplex transfer relationships between domains to avoid NTP is still a\ndirection worth exploring. To address these issues, we propose a simple and\ndynamic Similar Domain Selection Principle (SDSP) for multi-domain\nrecommendation in this paper. SDSP presents the initial exploration of\nselecting suitable domain knowledge for each domain to alleviate NTP.\nSpecifically, we propose a novel prototype-based domain distance measure to\neffectively model the complexity relationship between domains. Thereafter, the\nproposed SDSP can dynamically find similar domains for each domain based on the\nsupervised signals of the domain metrics and the unsupervised distance measure\nfrom the learned domain prototype. We emphasize that SDSP is a lightweight\nmethod that can be incorporated with existing MDR methods for better\nperformance while not introducing excessive time overheads. To the best of our\nknowledge, it is the first solution that can explicitly measure domain-level\ngaps and dynamically select appropriate domains in the MDR field. Extensive\nexperiments on three datasets demonstrate the effectiveness of our proposed\nmethod.", "published": "2025-05-26 17:07:31", "link": "http://arxiv.org/abs/2505.20227v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement", "abstract": "The integration of large language models (LLMs) with function calling has\nemerged as a crucial capability for enhancing their practical utility in\nreal-world applications. However, effectively combining reasoning processes\nwith accurate function execution remains a significant challenge. Traditional\ntraining approaches often struggle to balance the detailed reasoning steps with\nthe precision of function calls, leading to suboptimal performance. To address\nthese limitations, we introduce FunReason, a novel framework that enhances\nLLMs' function calling capabilities through an automated data refinement\nstrategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason\nleverages LLMs' natural reasoning abilities to generate high-quality training\nexamples, focusing on query parseability, reasoning coherence, and function\ncall precision. The SRML approach dynamically balances the contribution of\nreasoning processes and function call accuracy during training, addressing the\ninherent trade-off between these two critical aspects. FunReason achieves\nperformance comparable to GPT-4o while effectively mitigating catastrophic\nforgetting during fine-tuning. FunReason provides a comprehensive solution for\nenhancing LLMs' function calling capabilities by introducing a balanced\ntraining methodology and a data refinement pipeline. For code and dataset,\nplease refer to our repository at GitHub\nhttps://github.com/BingguangHao/FunReason", "published": "2025-05-26 16:38:06", "link": "http://arxiv.org/abs/2505.20192v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Leveraging Descriptions of Emotional Preferences in Recommender Systems", "abstract": "The affective attitude of liking a recommended item reflects just one\ncategory in a wide spectrum of affective phenomena that also includes emotions\nsuch as entranced or intrigued, moods such as cheerful or buoyant, as well as\nmore fine-grained affective states, such as \"pleasantly surprised by the\nconclusion\". In this paper, we introduce a novel recommendation task that can\nleverage a virtually unbounded range of affective states sought explicitly by\nthe user in order to identify items that, upon consumption, are likely to\ninduce those affective states. Correspondingly, we create a large dataset of\nuser preferences containing expressions of fine-grained affective states that\nare mined from book reviews, and propose a Transformer-based architecture that\nleverages such affective expressions as input. We then use the resulting\ndataset of affective states preferences, together with the linked users and\ntheir histories of book readings, ratings, and reviews, to train and evaluate\nmultiple recommendation models on the task of matching recommended items with\naffective preferences. Experiments show that the best results are obtained by\nmodels that can utilize textual descriptions of items and user affective\npreferences.", "published": "2025-05-26 16:33:14", "link": "http://arxiv.org/abs/2505.20190v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Research on feature fusion and multimodal patent text based on graph attention network", "abstract": "Aiming at the problems of cross-modal feature fusion, low efficiency of long\ntext modeling and lack of hierarchical semantic coherence in patent text\nsemantic mining, this study proposes HGM-Net, a deep learning framework that\nintegrates Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention\nNetwork (M-GAT) and Multi-Granularity Sparse Attention (MSA), which builds a\ndynamic mask, contrast and cross-structural similarity constraints on the word,\nsentence and paragraph hierarchies through HCL. Contrast and cross-structural\nsimilarity constraints are constructed at the word and paragraph levels by HCL\nto strengthen the local semantic and global thematic consistency of patent\ntext; M-GAT models patent classification codes, citation relations and text\nsemantics as heterogeneous graph structures, and achieves dynamic fusion of\nmulti-source features by cross-modal gated attention; MSA adopts a hierarchical\nsparsity strategy to optimize the computational efficiency of long text\nmodeling at word, phrase, sentence and paragraph granularity. Experiments show\nthat the framework demonstrates significant advantages over existing deep\nlearning methods in tasks such as patent classification and similarity\nmatching, and provides a solution with both theoretical innovation and\npractical value for solving the problems of patent examination efficiency\nimprovement and technology relevance mining.", "published": "2025-05-26 16:32:43", "link": "http://arxiv.org/abs/2505.20188v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "HIT Model: A Hierarchical Interaction-Enhanced Two-Tower Model for Pre-Ranking Systems", "abstract": "Online display advertising platforms rely on pre-ranking systems to\nefficiently filter and prioritize candidate ads from large corpora, balancing\nrelevance to users with strict computational constraints. The prevailing\ntwo-tower architecture, though highly efficient due to its decoupled design and\npre-caching, suffers from cross-domain interaction and coarse similarity\nmetrics, undermining its capacity to model complex user-ad relationships. In\nthis study, we propose the Hierarchical Interaction-Enhanced Two-Tower (HIT)\nmodel, a new architecture that augments the two-tower paradigm with two key\ncomponents: $\\textit{generators}$ that pre-generate holistic vectors\nincorporating coarse-grained user-ad interactions through a dual-generator\nframework with a cosine-similarity-based generation loss as the training\nobjective, and $\\textit{multi-head representers}$ that project embeddings into\nmultiple latent subspaces to capture fine-grained, multi-faceted user interests\nand multi-dimensional ad attributes. This design enhances modeling\neffectiveness without compromising inference efficiency. Extensive experiments\non public datasets and large-scale online A/B testing on Tencent's advertising\nplatform demonstrate that HIT significantly outperforms several baselines in\nrelevance metrics, yielding a $1.66\\%$ increase in Gross Merchandise Volume and\na $1.55\\%$ improvement in Return on Investment, alongside similar serving\nlatency to the vanilla two-tower models. The HIT model has been successfully\ndeployed in Tencent's online display advertising system, serving billions of\nimpressions daily. The code is available at\nhttps://anonymous.4open.science/r/HIT_model-5C23.", "published": "2025-05-26 11:35:04", "link": "http://arxiv.org/abs/2505.19849v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Light distillation for Incremental Graph Convolution Collaborative Filtering", "abstract": "Recommender systems presently utilize vast amounts of data and play a pivotal\nrole in enhancing user experiences. Graph Convolution Networks (GCNs) have\nsurfaced as highly efficient models within the realm of recommender systems due\nto their ability to capture extensive relational information. The continuously\nexpanding volume of data may render the training of GCNs excessively costly. To\ntackle this problem, incrementally training GCNs as new data blocks come in has\nbecome a vital research direction. Knowledge distillation techniques have been\nexplored as a general paradigm to train GCNs incrementally and alleviate the\ncatastrophic forgetting problem that typically occurs in incremental settings.\nHowever, we argue that current methods based on knowledge distillation\nintroduce additional parameters and have a high model complexity, which results\nin unrealistic training time consumption in an incremental setting and thus\ndifficult to actually deploy in the real world. In this work, we propose a\nlight preference-driven distillation method to distill the preference score of\na user for an item directly from historical interactions, which reduces the\ntraining time consumption in the incremental setting significantly without\nnoticeable loss in performance. The experimental result on two general datasets\nshows that the proposed method can save training time from 1.5x to 9.5x\ncompared to the existing methods and improves Recall@20 by 5.41% and 10.64%\nfrom the fine-tune method.", "published": "2025-05-26 10:47:26", "link": "http://arxiv.org/abs/2505.19810v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "One Model to Rank Them All: Unifying Online Advertising with End-to-End Learning", "abstract": "Modern industrial advertising systems commonly employ Multi-stage Cascading\nArchitectures (MCA) to balance computational efficiency with ranking accuracy.\nHowever, this approach presents two fundamental challenges: (1) performance\ninconsistencies arising from divergent optimization targets and capability\ndifferences between stages, and (2) failure to account for advertisement\nexternalities - the complex interactions between candidate ads during ranking.\nThese limitations ultimately compromise system effectiveness and reduce\nplatform profitability. In this paper, we present UniROM, an end-to-end\ngenerative architecture that Unifies online advertising Ranking as One Model.\nUniROM replaces cascaded stages with a single model to directly generate\noptimal ad sequences from the full candidate ad corpus in location-based\nservices (LBS). The primary challenges associated with this approach stem from\nhigh costs of feature processing and computational bottlenecks in modeling\nexternalities of large-scale candidate pools. To address these challenges,\nUniROM introduces an algorithm and engine co-designed hybrid feature service to\ndecouple user and ad feature processing, reducing latency while preserving\nexpressiveness. To efficiently extract intra- and cross-sequence mutual\ninformation, we propose RecFormer with an innovative cluster-attention\nmechanism as its core architectural component. Furthermore, we propose a\nbi-stage training strategy that integrates pre-training with reinforcement\nlearning-based post-training to meet sophisticated platform and advertising\nobjectives. Extensive offline evaluations on public benchmarks and large-scale\nonline A/B testing on industrial advertising platform have demonstrated the\nsuperior performance of UniROM over state-of-the-art MCAs.", "published": "2025-05-26 09:33:54", "link": "http://arxiv.org/abs/2505.19755v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems", "abstract": "The emergence of agentic recommender systems powered by Large Language Models\n(LLMs) represents a paradigm shift in personalized recommendations, leveraging\nLLMs' advanced reasoning and role-playing capabilities to enable autonomous,\nadaptive decision-making. Unlike traditional recommendation approaches, agentic\nrecommender systems can dynamically gather and interpret user-item interactions\nfrom complex environments, generating robust recommendation strategies that\ngeneralize across diverse scenarios. However, the field currently lacks\nstandardized evaluation protocols to systematically assess these methods. To\naddress this critical gap, we propose: (1) an interactive textual\nrecommendation simulator incorporating rich user and item metadata and three\ntypical evaluation scenarios (classic, evolving-interest, and cold-start\nrecommendation tasks); (2) a unified modular framework for developing and\nstudying agentic recommender systems; and (3) the first comprehensive benchmark\ncomparing 10 classical and agentic recommendation methods. Our findings\ndemonstrate the superiority of agentic systems and establish actionable design\nguidelines for their core components. The benchmark environment has been\nrigorously validated through an open challenge and remains publicly available\nwith a continuously maintained\nleaderboard~\\footnote[2]{https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html},\nfostering ongoing community engagement and reproducible research. The benchmark\nis available at:\n\\hyperlink{https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}.", "published": "2025-05-26 07:45:11", "link": "http://arxiv.org/abs/2505.19623v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval", "abstract": "While significant progress has been made with dual- and bi-encoder dense\nretrievers, they often struggle on queries with logical connectives, a use case\nthat is often overlooked yet important in downstream applications. Current\ndense retrievers struggle with such queries, such that the retrieved results do\nnot respect the logical constraints implied in the queries. To address this\nchallenge, we introduce LogiCoL, a logically-informed contrastive learning\nobjective for dense retrievers. LogiCoL builds upon in-batch supervised\ncontrastive learning, and learns dense retrievers to respect the subset and\nmutually-exclusive set relation between query results via two sets of soft\nconstraints expressed via t-norm in the learning objective. We evaluate the\neffectiveness of LogiCoL on the task of entity retrieval, where the model is\nexpected to retrieve a set of entities in Wikipedia that satisfy the implicit\nlogical constraints in the query. We show that models trained with LogiCoL\nyield improvement both in terms of retrieval performance and logical\nconsistency in the results. We provide detailed analysis and insights to\nuncover why queries with logical connectives are challenging for dense\nretrievers and why LogiCoL is most effective.", "published": "2025-05-26 07:00:32", "link": "http://arxiv.org/abs/2505.19588v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Unlocking the Power of Diffusion Models in Sequential Recommendation: A Simple and Effective Approach", "abstract": "In this paper, we focus on the often-overlooked issue of embedding collapse\nin existing diffusion-based sequential recommendation models and propose ADRec,\nan innovative framework designed to mitigate this problem. Diverging from\nprevious diffusion-based methods, ADRec applies an independent noise process to\neach token and performs diffusion across the entire target sequence during\ntraining. ADRec captures token interdependency through auto-regression while\nmodeling per-token distributions through token-level diffusion. This dual\napproach enables the model to effectively capture both sequence dynamics and\nitem representations, overcoming the limitations of existing methods. To\nfurther mitigate embedding collapse, we propose a three-stage training\nstrategy: (1) pre-training the embedding weights, (2) aligning these weights\nwith the ADRec backbone, and (3) fine-tuning the model. During inference, ADRec\napplies the denoising process only to the last token, ensuring that the\nmeaningful patterns in historical interactions are preserved. Our comprehensive\nempirical evaluation across six datasets underscores the effectiveness of ADRec\nin enhancing both the accuracy and efficiency of diffusion-based sequential\nrecommendation systems.", "published": "2025-05-26 06:05:29", "link": "http://arxiv.org/abs/2505.19544v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Cuff-KT: Tackling Learners' Real-time Learning Pattern Adjustment via Tuning-Free Knowledge State Guided Model Updating", "abstract": "Knowledge Tracing (KT) is a core component of Intelligent Tutoring Systems,\nmodeling learners' knowledge state to predict future performance and provide\npersonalized learning support. Traditional KT models assume that learners'\nlearning abilities remain relatively stable over short periods or change in\npredictable ways based on prior performance. However, in reality, learners'\nabilities change irregularly due to factors like cognitive fatigue, motivation,\nand external stress -- a task introduced, which we refer to as Real-time\nLearning Pattern Adjustment (RLPA). Existing KT models, when faced with RLPA,\nlack sufficient adaptability, because they fail to timely account for the\ndynamic nature of different learners' evolving learning patterns. Current\nstrategies for enhancing adaptability rely on retraining, which leads to\nsignificant overfitting and high time overhead issues. To address this, we\npropose Cuff-KT, comprising a controller and a generator. The controller\nassigns value scores to learners, while the generator generates personalized\nparameters for selected learners. Cuff-KT controllably adapts to data changes\nfast and flexibly without fine-tuning. Experiments on five datasets from\ndifferent subjects demonstrate that Cuff-KT significantly improves the\nperformance of five KT models with different structures under intra- and\ninter-learner shifts, with an average relative increase in AUC of 10% and 4%,\nrespectively, at a negligible time cost, effectively tackling RLPA task. Our\ncode and datasets are fully available at https://github.com/zyy-2001/Cuff-KT.", "published": "2025-05-26 06:04:11", "link": "http://arxiv.org/abs/2505.19543v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients", "abstract": "Existing medical RAG systems mainly leverage knowledge from medical knowledge\nbases, neglecting the crucial role of experiential knowledge derived from\nsimilar patient cases -- a key component of human clinical reasoning. To bridge\nthis gap, we propose DoctorRAG, a RAG framework that emulates doctor-like\nreasoning by integrating both explicit clinical knowledge and implicit\ncase-based experience. DoctorRAG enhances retrieval precision by first\nallocating conceptual tags for queries and knowledge sources, together with a\nhybrid retrieval mechanism from both relevant knowledge and patient. In\naddition, a Med-TextGrad module using multi-agent textual gradients is\nintegrated to ensure that the final output adheres to the retrieved knowledge\nand patient query. Comprehensive experiments on multilingual, multitask\ndatasets demonstrate that DoctorRAG significantly outperforms strong baseline\nRAG models and gains improvements from iterative refinements. Our approach\ngenerates more accurate, relevant, and comprehensive responses, taking a step\ntowards more doctor-like medical reasoning systems.", "published": "2025-05-26 05:56:23", "link": "http://arxiv.org/abs/2505.19538v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.IR", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Hierarchical Tree Search-based User Lifelong Behavior Modeling on Large Language Model", "abstract": "Large Language Models (LLMs) have garnered significant attention in\nRecommendation Systems (RS) due to their extensive world knowledge and robust\nreasoning capabilities. However, a critical challenge lies in enabling LLMs to\neffectively comprehend and extract insights from massive user behaviors.\nCurrent approaches that directly leverage LLMs for user interest learning face\nlimitations in handling long sequential behaviors, effectively extracting\ninterest, and applying interest in practical scenarios. To address these\nissues, we propose a Hierarchical Tree Search-based User Lifelong Behavior\nModeling framework (HiT-LBM). HiT-LBM integrates Chunked User Behavior\nExtraction (CUBE) and Hierarchical Tree Search for Interest (HTS) to capture\ndiverse interests and interest evolution of user. CUBE divides user lifelong\nbehaviors into multiple chunks and learns the interest and interest evolution\nwithin each chunk in a cascading manner. HTS generates candidate interests\nthrough hierarchical expansion and searches for the optimal interest with\nprocess rating model to ensure information gain for each behavior chunk.\nAdditionally, we design Temporal-Ware Interest Fusion (TIF) to integrate\ninterests from multiple behavior chunks, constructing a comprehensive\nrepresentation of user lifelong interests. The representation can be embedded\ninto any recommendation model to enhance performance. Extensive experiments\ndemonstrate the effectiveness of our approach, showing that it surpasses\nstate-of-the-art methods.", "published": "2025-05-26 04:32:57", "link": "http://arxiv.org/abs/2505.19505v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Anveshana: A New Benchmark Dataset for Cross-Lingual Information Retrieval On English Queries and Sanskrit Documents", "abstract": "The study presents a comprehensive benchmark for retrieving Sanskrit\ndocuments using English queries, focusing on the chapters of the\nSrimadbhagavatam. It employs a tripartite approach: Direct Retrieval (DR),\nTranslation-based Retrieval (DT), and Query Translation (QT), utilizing shared\nembedding spaces and advanced translation methods to enhance retrieval systems\nin a RAG framework. The study fine-tunes state-of-the-art models for Sanskrit's\nlinguistic nuances, evaluating models such as BM25, REPLUG, mDPR, ColBERT,\nContriever, and GPT-2. It adapts summarization techniques for Sanskrit\ndocuments to improve QA processing. Evaluation shows DT methods outperform DR\nand QT in handling the cross-lingual challenges of ancient texts, improving\naccessibility and understanding. A dataset of 3,400 English-Sanskrit\nquery-document pairs underpins the study, aiming to preserve Sanskrit\nscriptures and share their philosophical importance widely. Our dataset is\npublicly available at https://huggingface.co/datasets/manojbalaji1/anveshana", "published": "2025-05-26 04:23:21", "link": "http://arxiv.org/abs/2505.19494v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Improving Recommendation Fairness without Sensitive Attributes Using Multi-Persona LLMs", "abstract": "Despite the success of recommender systems in alleviating information\noverload, fairness issues have raised concerns in recent years, potentially\nleading to unequal treatment for certain user groups. While efforts have been\nmade to improve recommendation fairness, they often assume that users'\nsensitive attributes are available during model training. However, collecting\nsensitive information can be difficult, especially on platforms that involve no\npersonal information disclosure. Therefore, we aim to improve recommendation\nfairness without any access to sensitive attributes. However, this is a\nnon-trivial task because uncovering latent sensitive patterns from complicated\nuser behaviors without explicit sensitive attributes can be difficult.\nConsequently, suboptimal estimates of sensitive distributions can hinder the\nfairness training process. To address these challenges, leveraging the\nremarkable reasoning abilities of Large Language Models (LLMs), we propose a\nnovel LLM-enhanced framework for Fair recommendation withOut Sensitive\nAttributes (LLMFOSA). A Multi-Persona Sensitive Information Inference module\nemploys LLMs with distinct personas that mimic diverse human perceptions to\ninfer and distill sensitive information. Furthermore, a Confusion-Aware\nSensitive Representation Learning module incorporates inference results and\nrationales to develop robust sensitive representations, considering the\nmislabeling confusion and collective consensus among agents. The model is then\noptimized by a formulated mutual information objective. Extensive experiments\non two public datasets validate the effectiveness of LLMFOSA in improving\nfairness.", "published": "2025-05-26 03:52:41", "link": "http://arxiv.org/abs/2505.19473v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLMs as Better Recommenders with Natural Language Collaborative Signals: A Self-Assessing Retrieval Approach", "abstract": "Incorporating collaborative information (CI) effectively is crucial for\nleveraging LLMs in recommendation tasks. Existing approaches often encode CI\nusing soft tokens or abstract identifiers, which introduces a semantic\nmisalignment with the LLM's natural language pretraining and hampers knowledge\nintegration. To address this, we propose expressing CI directly in natural\nlanguage to better align with LLMs' semantic space. We achieve this by\nretrieving a curated set of the most relevant user behaviors in natural\nlanguage form. However, identifying informative CI is challenging due to the\ncomplexity of similarity and utility assessment. To tackle this, we introduce a\nSelf-assessing COllaborative REtrieval framework (SCORE) following the\nretrieve-rerank paradigm. First, a Collaborative Retriever (CAR) is developed\nto consider both collaborative patterns and semantic similarity. Then, a\nSelf-assessing Reranker (SARE) leverages LLMs' own reasoning to assess and\nprioritize retrieved behaviors. Finally, the selected behaviors are prepended\nto the LLM prompt as natural-language CI to guide recommendation. Extensive\nexperiments on two public datasets validate the effectiveness of SCORE in\nimproving LLM-based recommendation.", "published": "2025-05-26 03:37:17", "link": "http://arxiv.org/abs/2505.19464v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Study of Symbol Error Probability Constrained Precoding with Zero-Crossing Modulation for Wireless Systems with 1-Bit ADCs", "abstract": "The next generation of wireless communications systems will employ new\nfrequency bands such as those in the upper midband, millimeter-wave and\nsub-terahertz frequency bands. The high energy consumption of analog-to-digital\nconverters resulting from their high resolution constituted a major limitation\nfor future wireless communications systems, which will require low energy\nconsumption and low-complexity devices at the transmitter and at the receiver.\nIn this regard, we present a novel precoding method based on quality of service\nconstraints for a multiuser multiple-input multiple-output downlink system with\n1-bit quantization and oversampling. For this scenario, we consider the\ntime-instance zero-crossing modulation, which conveys the information into the\nzero-crossings of the signals. Unlike prior works the proposed constraint is\ngiven in terms of the symbol error probability related to the minimum distance\nto the decision threshold and is included in the proposed optimization problem\nthat is used in the design of the precoder. Simulation results illustrate the\nperformance of the proposed precoding method evaluated under different\nparameters and scenarios.", "published": "2025-05-26 14:52:44", "link": "http://arxiv.org/abs/2505.20073v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Entropy Characterization of Quantum MDS Codes", "abstract": "An $[[n,k,d]]$ quantum maximum-distance-separable code maps $k$ source qudits\nto $n$ coded qudits such that any $n-(d-1)$ coded qudits may recover all source\nqudits and $n = k + 2 (d-1)$. The entropy of the joint state of the reference\nsystem of $k$ qudits and the $n$ coded qudits is fully characterized - the\njoint state must be pure, i.e., has entropy zero; and any sub-system whose\nnumber of qudits is at most half of $k+n$, the total number of qudits in the\njoint state must be maximally mixed, i.e., has entropy equal to its size.", "published": "2025-05-26 11:03:13", "link": "http://arxiv.org/abs/2505.19826v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Capacity-Optimized Pre-Equalizer Design for Visible Light Communication Systems", "abstract": "Since commercial LEDs are primarily designed for illumination rather than\ndata transmission, their modulation bandwidth is inherently limited to a few\nMHz. This becomes a major bottleneck in the implementation of visible light\ncommunication (VLC) systems necessiating the design of pre-equalizers. While\nstate-of-the-art equalizer designs primarily focus on the data rate increasing\nthrough bandwidth expansion, they often overlook the accompanying degradation\nin signal-to-noise ratio (SNR). Achieving effective bandwidth extension without\nintroducing excessive SNR penalties remains a significant challenge, since the\nchannel capacity is a non-linear function of both parameters. In this paper, we\npresent a fundamental analysis of how the parameters of the LED and\npre-equalization circuits influence the channel capacity in intensity\nmodulation and direct detection (IMDD)-based VLC systems. We derive a\nclosed-form expression for channel capacity model that is an explicitly\nfunction of analog pre-equalizer circuit parameters. Building upon the derived\ncapacity expression, we propose a systematic design methodology for analog\npre-equalizers that effectively balances bandwidth and SNR, thereby maximizing\nthe overall channel capacity across a wide range of channel attenuations. We\npresent extensive numerical results to validate the effectiveness of the\nproposed design and demonstrate the improvements over conventional\nbandwidth-optimized pre-equalizer designs.", "published": "2025-05-26 08:59:29", "link": "http://arxiv.org/abs/2505.19709v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone", "abstract": "This work studies near-field secure communications through transmit\nbeamfocusing. We examine the benefit of having a protected eavesdropper-free\nzone around the legitimate receiver, and we determine the worst-case secrecy\nperformance against a potential eavesdropper located anywhere outside the\nprotected zone. A max-min optimization problem is formulated for the\nbeamfocusing design with and without artificial noise transmission. Despite the\nNP-hardness of the problem, we develop a synchronous gradient descent-ascent\nframework that approximates the global maximin solution. A low-complexity\nsolution is also derived that delivers excellent performance over a wide range\nof operating conditions. We further extend this study to a scenario where it is\nnot possible to physically enforce a protected zone. To this end, we consider\nsecure communications through the creation of a virtual protected zone using a\nfull-duplex legitimate receiver. Numerical results demonstrate that exploiting\neither the physical or virtual receiver-centered protected zone with\nappropriately designed beamfocusing is an effective strategy for achieving\nsecure near-field communications.", "published": "2025-05-26 05:12:00", "link": "http://arxiv.org/abs/2505.19523v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "RedAHD: Reduction-Based End-to-End Automatic Heuristic Design with Large Language Models", "abstract": "Solving NP-hard combinatorial optimization problems (COPs) (e.g., traveling\nsalesman problems (TSPs) and capacitated vehicle routing problems (CVRPs)) in\npractice traditionally involves handcrafting heuristics or specifying a search\nspace for finding effective heuristics. The main challenges from these\napproaches, however, are the sheer amount of domain knowledge and\nimplementation efforts required from human experts. Recently, significant\nprogress has been made to address these challenges, particularly by using large\nlanguage models (LLMs) to design heuristics within some predetermined\ngeneralized algorithmic framework (GAF, e.g., ant colony optimization and\nguided local search) for building key functions/components (e.g., a priori\ninformation on how promising it is to include each edge in a solution for TSP\nand CVRP). Although existing methods leveraging this idea have shown to yield\nimpressive optimization performance, they are not fully end-to-end and still\nrequire considerable manual interventions. In this paper, we propose a novel\nend-to-end framework, named RedAHD, that enables these LLM-based heuristic\ndesign methods to operate without the need of GAFs. More specifically, RedAHD\nemploys LLMs to automate the process of reduction, i.e., transforming the COP\nat hand into similar COPs that are better-understood, from which LLM-based\nheuristic design methods can design effective heuristics for directly solving\nthe transformed COPs and, in turn, indirectly solving the original COP. Our\nexperimental results, evaluated on six COPs, show that RedAHD is capable of\ndesigning heuristics with competitive or improved results over the\nstate-of-the-art methods with minimal human involvement.", "published": "2025-05-26 17:21:16", "link": "http://arxiv.org/abs/2505.20242v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning", "abstract": "Reasoning has substantially improved the performance of large language models\n(LLMs) on complicated tasks. Central to the current reasoning studies, Process\nReward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning\nsteps and guide the reasoning process. However, extending PRMs to multimodal\nlarge language models (MLLMs) introduces challenges. Since multimodal reasoning\ncovers a wider range of tasks compared to text-only scenarios, the resulting\ndistribution shift from the training to testing sets is more severe, leading to\ngreater generalization difficulty. Training a reliable multimodal PRM,\ntherefore, demands large and diverse datasets to ensure sufficient coverage.\nHowever, current multimodal reasoning datasets suffer from a marked quality\nimbalance, which degrades PRM performance and highlights the need for an\neffective data selection strategy. To address the issues, we introduce\nDreamPRM, a domain-reweighted training framework for multimodal PRMs which\nemploys bi-level optimization. In the lower-level optimization, DreamPRM\nperforms fine-tuning on multiple datasets with domain weights, allowing the PRM\nto prioritize high-quality reasoning signals and alleviating the impact of\ndataset quality imbalance. In the upper-level optimization, the PRM is\nevaluated on a separate meta-learning dataset; this feedback updates the domain\nweights through an aggregation loss function, thereby improving the\ngeneralization capability of trained PRM. Extensive experiments on multiple\nmultimodal reasoning benchmarks covering both mathematical and general\nreasoning show that test-time scaling with DreamPRM consistently improves the\nperformance of state-of-the-art MLLMs. Further comparisons reveal that\nDreamPRM's domain-reweighting strategy surpasses other data selection methods\nand yields higher accuracy gains than existing test-time scaling approaches.", "published": "2025-05-26 17:20:17", "link": "http://arxiv.org/abs/2505.20241v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Variational Deep Learning via Implicit Regularization", "abstract": "Modern deep learning models generalize remarkably well in-distribution,\ndespite being overparametrized and trained with little to no explicit\nregularization. Instead, current theory credits implicit regularization imposed\nby the choice of architecture, hyperparameters and optimization procedure.\nHowever, deploying deep learning models out-of-distribution, in sequential\ndecision-making tasks, or in safety-critical domains, necessitates reliable\nuncertainty quantification, not just a point estimate. The machinery of modern\napproximate inference -- Bayesian deep learning -- should answer the need for\nuncertainty quantification, but its effectiveness has been challenged by our\ninability to define useful explicit inductive biases through priors, as well as\nthe associated computational burden. Instead, in this work we demonstrate, both\ntheoretically and empirically, how to regularize a variational deep network\nimplicitly via the optimization procedure, just as for standard deep learning.\nWe fully characterize the inductive bias of (stochastic) gradient descent in\nthe case of an overparametrized linear model as generalized variational\ninference and demonstrate the importance of the choice of parametrization.\nFinally, we show empirically that our approach achieves strong in- and\nout-of-distribution performance without tuning of additional hyperparameters\nand with minimal time and memory overhead over standard deep learning.", "published": "2025-05-26 17:15:57", "link": "http://arxiv.org/abs/2505.20235v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "From What to How: Attributing CLIP's Latent Components Reveals Unexpected Semantic Reliance", "abstract": "Transformer-based CLIP models are widely used for text-image probing and\nfeature extraction, making it relevant to understand the internal mechanisms\nbehind their predictions. While recent works show that Sparse Autoencoders\n(SAEs) yield interpretable latent components, they focus on what these encode\nand miss how they drive predictions. We introduce a scalable framework that\nreveals what latent components activate for, how they align with expected\nsemantics, and how important they are to predictions. To achieve this, we adapt\nattribution patching for instance-wise component attributions in CLIP and\nhighlight key faithfulness limitations of the widely used Logit Lens technique.\nBy combining attributions with semantic alignment scores, we can automatically\nuncover reliance on components that encode semantically unexpected or spurious\nconcepts. Applied across multiple CLIP variants, our method uncovers hundreds\nof surprising components linked to polysemous words, compound nouns, visual\ntypography and dataset artifacts. While text embeddings remain prone to\nsemantic ambiguity, they are more robust to spurious correlations compared to\nlinear classifiers trained on image embeddings. A case study on skin lesion\ndetection highlights how such classifiers can amplify hidden shortcuts,\nunderscoring the need for holistic, mechanistic interpretability. We provide\ncode at https://github.com/maxdreyer/attributing-clip.", "published": "2025-05-26 17:08:02", "link": "http://arxiv.org/abs/2505.20229v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models", "abstract": "Recent large language models such as Gemini-1.5, DeepSeek-V3, and Llama-4\nincreasingly adopt Mixture-of-Experts (MoE) architectures, which offer strong\nefficiency-performance trade-offs by activating only a fraction of the model\nper token. Yet academic researchers still lack a fully open, end-to-end MoE\nplatform for investigating scaling, routing, and expert behavior. We release\nFLAME-MoE, a completely open-source research suite composed of seven\ndecoder-only models, ranging from 38M to 1.7B active parameters, whose\narchitecture--64 experts with top-8 gating and 2 shared experts--closely\nreflects modern production LLMs. All training data pipelines, scripts, logs,\nand checkpoints are publicly available to enable reproducible experimentation.\nAcross six evaluation tasks, FLAME-MoE improves average accuracy by up to 3.4\npoints over dense baselines trained with identical FLOPs. Leveraging full\ntraining trace transparency, we present initial analyses showing that (i)\nexperts increasingly specialize on distinct token subsets, (ii) co-activation\nmatrices remain sparse, reflecting diverse expert usage, and (iii) routing\nbehavior stabilizes early in training. All code, training logs, and model\ncheckpoints are available at https://github.com/cmu-flame/FLAME-MoE.", "published": "2025-05-26 17:06:25", "link": "http://arxiv.org/abs/2505.20225v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects", "abstract": "The rapid evolution of large language models in natural language processing\nhas substantially elevated their semantic understanding and logical reasoning\ncapabilities. Such proficiencies have been leveraged in autonomous driving\nsystems, contributing to significant improvements in system performance. Models\nsuch as OpenAI o1 and DeepSeek-R1, leverage Chain-of-Thought (CoT) reasoning,\nan advanced cognitive method that simulates human thinking processes,\ndemonstrating remarkable reasoning capabilities in complex tasks. By\nstructuring complex driving scenarios within a systematic reasoning framework,\nthis approach has emerged as a prominent research focus in autonomous driving,\nsubstantially improving the system's ability to handle challenging cases. This\npaper investigates how CoT methods improve the reasoning abilities of\nautonomous driving models. Based on a comprehensive literature review, we\npresent a systematic analysis of the motivations, methodologies, challenges,\nand future research directions of CoT in autonomous driving. Furthermore, we\npropose the insight of combining CoT with self-learning to facilitate\nself-evolution in driving systems. To ensure the relevance and timeliness of\nthis study, we have compiled a dynamic repository of literature and open-source\nprojects, diligently updated to incorporate forefront developments. The\nrepository is publicly available at\nhttps://github.com/cuiyx1720/Awesome-CoT4AD.", "published": "2025-05-26 17:06:00", "link": "http://arxiv.org/abs/2505.20223v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Gradient Flow Matching for Learning Update Dynamics in Neural Network Training", "abstract": "Training deep neural networks remains computationally intensive due to the\nitera2 tive nature of gradient-based optimization. We propose Gradient Flow\nMatching (GFM), a continuous-time modeling framework that treats neural network\ntraining as a dynamical system governed by learned optimizer-aware vector\nfields. By leveraging conditional flow matching, GFM captures the underlying\nupdate rules of optimizers such as SGD, Adam, and RMSprop, enabling smooth\nextrapolation of weight trajectories toward convergence. Unlike black-box\nsequence models, GFM incorporates structural knowledge of gradient-based\nupdates into the learning objective, facilitating accurate forecasting of final\nweights from partial training sequences. Empirically, GFM achieves forecasting\naccuracy that is competitive with Transformer-based models and significantly\noutperforms LSTM and other classical baselines. Furthermore, GFM generalizes\nacross neural architectures and initializations, providing a unified framework\nfor studying optimization dynamics and accelerating convergence prediction.", "published": "2025-05-26 17:03:22", "link": "http://arxiv.org/abs/2505.20221v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "New Perspectives on the Polyak Stepsize: Surrogate Functions and Negative Results", "abstract": "The Polyak stepsize has been proven to be a fundamental stepsize in convex\noptimization, giving near optimal gradient descent rates across a wide range of\nassumptions. The universality of the Polyak stepsize has also inspired many\nstochastic variants, with theoretical guarantees and strong empirical\nperformance. Despite the many theoretical results, our understanding of the\nconvergence properties and shortcomings of the Polyak stepsize or its variants\nis both incomplete and fractured across different analyses. We propose a new,\nunified, and simple perspective for the Polyak stepsize and its variants as\ngradient descent on a surrogate loss. We show that each variant is equivalent\nto minimize a surrogate function with stepsizes that adapt to a guaranteed\nlocal curvature. Our general surrogate loss perspective is then used to provide\na unified analysis of existing variants across different assumptions. Moreover,\nwe show a number of negative results proving that the non-convergence results\nin some of the upper bounds is indeed real.", "published": "2025-05-26 17:00:27", "link": "http://arxiv.org/abs/2505.20219v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Fine-grained List-wise Alignment for Generative Medication Recommendation", "abstract": "Accurate and safe medication recommendations are critical for effective\nclinical decision-making, especially in multimorbidity cases. However, existing\nsystems rely on point-wise prediction paradigms that overlook synergistic drug\neffects and potential adverse drug-drug interactions (DDIs). We propose FLAME,\na fine-grained list-wise alignment framework for large language models (LLMs),\nenabling drug-by-drug generation of drug lists. FLAME formulates recommendation\nas a sequential decision process, where each step adds or removes a single\ndrug. To provide fine-grained learning signals, we devise step-wise Group\nRelative Policy Optimization (GRPO) with potential-based reward shaping, which\nexplicitly models DDIs and optimizes the contribution of each drug to the\noverall prescription. Furthermore, FLAME enhances patient modeling by\nintegrating structured clinical knowledge and collaborative information into\nthe representation space of LLMs. Experiments on benchmark datasets demonstrate\nthat FLAME achieves state-of-the-art performance, delivering superior accuracy,\ncontrollable safety-accuracy trade-offs, and strong generalization across\ndiverse clinical scenarios. Our code is available at\nhttps://github.com/cxfann/Flame.", "published": "2025-05-26 16:59:23", "link": "http://arxiv.org/abs/2505.20218v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Parameter-Efficient Fine-Tuning with Column Space Projection", "abstract": "Fine-tuning large language models (LLMs) with minimal computational overhead\nis essential for efficiently adapting them to downstream tasks under resource\nconstraints. Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank\nAdaptation (LoRA), facilitate this by updating only a small subset of\nparameters. However, recent studies show that LoRA diverges from full\nfine-tuning (Full FT) in its learning behavior, particularly in terms of\nspectral properties. Motivated by these findings, we propose PiCa, the first\ntheoretically grounded PEFT method based on the spectral properties of\nfine-tuned weights. PiCa projects gradients onto the low-rank column subspace\nof pre-trained weights and exhibits learning patterns more closely aligned with\nFull FT. Furthermore, we show that combining PiCa with weight sharing\ndrastically reduces the number of trainable parameters without compromising\nperformance, enabling to achieve superior performance than LoRA using 13x fewer\ntrainable parameters. Extensive experiments demonstrate PiCa achieves the\nstate-of-the-art performance compared to existing PEFT methods.", "published": "2025-05-26 16:52:40", "link": "http://arxiv.org/abs/2505.20211v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Temporal Sampling for Forgotten Reasoning in LLMs", "abstract": "Fine-tuning large language models (LLMs) is intended to improve their\nreasoning capabilities, yet we uncover a counterintuitive effect: models often\nforget how to solve problems they previously answered correctly during\ntraining. We term this phenomenon temporal forgetting and show that it is\nwidespread across model sizes, fine-tuning methods (both Reinforcement Learning\nand Supervised Fine-Tuning), and multiple reasoning benchmarks. To address this\ngap, we introduce Temporal Sampling, a simple decoding strategy that draws\noutputs from multiple checkpoints along the training trajectory. This approach\nrecovers forgotten solutions without retraining or ensembling, and leads to\nsubstantial improvements in reasoning performance, gains from 4 to 19 points in\nPass@k and consistent gains in Majority@k across several benchmarks. We further\nextend our method to LoRA-adapted models, demonstrating that storing only\nadapter weights across checkpoints achieves similar benefits with minimal\nstorage cost. By leveraging the temporal diversity inherent in training,\nTemporal Sampling offers a practical, compute-efficient way to surface hidden\nreasoning ability and rethink how we evaluate LLMs.", "published": "2025-05-26 16:39:52", "link": "http://arxiv.org/abs/2505.20196v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Private Geometric Median in Nearly-Linear Time", "abstract": "Estimating the geometric median of a dataset is a robust counterpart to mean\nestimation, and is a fundamental problem in computational geometry. Recently,\n[HSU24] gave an $(\\varepsilon, \\delta)$-differentially private algorithm\nobtaining an $\\alpha$-multiplicative approximation to the geometric median\nobjective, $\\frac 1 n \\sum_{i \\in [n]} \\|\\cdot - \\mathbf{x}_i\\|$, given a\ndataset $\\mathcal{D} := \\{\\mathbf{x}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$.\nTheir algorithm requires $n \\gtrsim \\sqrt d \\cdot \\frac 1 {\\alpha\\varepsilon}$\nsamples, which they prove is information-theoretically optimal. This result is\nsurprising because its error scales with the \\emph{effective radius} of\n$\\mathcal{D}$ (i.e., of a ball capturing most points), rather than the\nworst-case radius. We give an improved algorithm that obtains the same\napproximation quality, also using $n \\gtrsim \\sqrt d \\cdot \\frac 1\n{\\alpha\\epsilon}$ samples, but in time $\\widetilde{O}(nd + \\frac d\n{\\alpha^2})$. Our runtime is nearly-linear, plus the cost of the cheapest\nnon-private first-order method due to [CLM+16]. To achieve our results, we use\nsubsampling and geometric aggregation tools inspired by FriendlyCore [TCK+22]\nto speed up the \"warm start\" component of the [HSU24] algorithm, combined with\na careful custom analysis of DP-SGD's sensitivity for the geometric median\nobjective.", "published": "2025-05-26 16:32:49", "link": "http://arxiv.org/abs/2505.20189v1", "categories": ["cs.DS", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.DS"}
{"title": "No Free Lunch: Non-Asymptotic Analysis of Prediction-Powered Inference", "abstract": "Prediction-Powered Inference (PPI) is a popular strategy for combining\ngold-standard and possibly noisy pseudo-labels to perform statistical\nestimation. Prior work has shown an asymptotic \"free lunch\" for PPI++, an\nadaptive form of PPI, showing that the *asymptotic* variance of PPI++ is always\nless than or equal to the variance obtained from using gold-standard labels\nalone. Notably, this result holds *regardless of the quality of the\npseudo-labels*. In this work, we demystify this result by conducting an exact\nfinite-sample analysis of the estimation error of PPI++ on the mean estimation\nproblem. We give a \"no free lunch\" result, characterizing the settings (and\nsample sizes) where PPI++ has provably worse estimation error than using\ngold-standard labels alone. Specifically, PPI++ will outperform if and only if\nthe correlation between pseudo- and gold-standard is above a certain level that\ndepends on the number of labeled samples ($n$). In some cases our results\nsimplify considerably: For Gaussian data, the correlation must be at least\n$1/\\sqrt{n - 2}$ in order to see improvement, and a similar result holds for\nbinary labels. In experiments, we illustrate that our theoretical findings hold\non real-world datasets, and give insights into trade-offs between single-sample\nand sample-splitting variants of PPI++.", "published": "2025-05-26 16:18:40", "link": "http://arxiv.org/abs/2505.20178v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination", "abstract": "Inspired by recent work on learning with distribution shift, we give a\ngeneral outlier removal algorithm called iterative polynomial filtering and\nshow a number of striking applications for supervised learning with\ncontamination: (1) We show that any function class that can be approximated by\nlow-degree polynomials with respect to a hypercontractive distribution can be\nefficiently learned under bounded contamination (also known as nasty noise).\nThis is a surprising resolution to a longstanding gap between the complexity of\nagnostic learning and learning with contamination, as it was widely believed\nthat low-degree approximators only implied tolerance to label noise. (2) For\nany function class that admits the (stronger) notion of sandwiching\napproximators, we obtain near-optimal learning guarantees even with respect to\nheavy additive contamination, where far more than $1/2$ of the training set may\nbe added adversarially. Prior related work held only for regression and in a\nlist-decodable setting. (3) We obtain the first efficient algorithms for\ntolerant testable learning of functions of halfspaces with respect to any fixed\nlog-concave distribution. Even the non-tolerant case for a single halfspace in\nthis setting had remained open. These results significantly advance our\nunderstanding of efficient supervised learning under contamination, a setting\nthat has been much less studied than its unsupervised counterpart.", "published": "2025-05-26 16:17:48", "link": "http://arxiv.org/abs/2505.20177v1", "categories": ["cs.LG", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "\"KAN you hear me?\" Exploring Kolmogorov-Arnold Networks for Spoken Language Understanding", "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising\nalternative to traditional neural architectures, yet their application to\nspeech processing remains under explored. This work presents the first\ninvestigation of KANs for Spoken Language Understanding (SLU) tasks. We\nexperiment with 2D-CNN models on two datasets, integrating KAN layers in five\ndifferent configurations within the dense block. The best-performing setup,\nwhich places a KAN layer between two linear layers, is directly applied to\ntransformer-based models and evaluated on five SLU datasets with increasing\ncomplexity. Our results show that KAN layers can effectively replace the linear\nlayers, achieving comparable or superior performance in most cases. Finally, we\nprovide insights into how KAN and linear layers on top of transformers\ndifferently attend to input regions of the raw waveforms.", "published": "2025-05-26 16:16:44", "link": "http://arxiv.org/abs/2505.20176v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Theoretical Framework for Grokking: Interpolation followed by Riemannian Norm Minimisation", "abstract": "We study the dynamics of gradient flow with small weight decay on general\ntraining losses $F: \\mathbb{R}^d \\to \\mathbb{R}$. Under mild regularity\nassumptions and assuming convergence of the unregularised gradient flow, we\nshow that the trajectory with weight decay $\\lambda$ exhibits a two-phase\nbehaviour as $\\lambda \\to 0$. During the initial fast phase, the trajectory\nfollows the unregularised gradient flow and converges to a manifold of critical\npoints of $F$. Then, at time of order $1/\\lambda$, the trajectory enters a slow\ndrift phase and follows a Riemannian gradient flow minimising the $\\ell_2$-norm\nof the parameters. This purely optimisation-based phenomenon offers a natural\nexplanation for the \\textit{grokking} effect observed in deep learning, where\nthe training loss rapidly reaches zero while the test loss plateaus for an\nextended period before suddenly improving. We argue that this generalisation\njump can be attributed to the slow norm reduction induced by weight decay, as\nexplained by our analysis. We validate this mechanism empirically on several\nsynthetic regression tasks.", "published": "2025-05-26 16:12:45", "link": "http://arxiv.org/abs/2505.20172v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data", "abstract": "Audio-aware large language models (ALLMs) have recently made great strides in\nunderstanding and processing audio inputs. These models are typically adapted\nfrom text-based large language models (LLMs) through additional training on\naudio-related tasks. However, this adaptation process presents two major\nlimitations. First, ALLMs often suffer from catastrophic forgetting, where\nimportant textual capabilities such as instruction-following are lost after\ntraining on audio data. In some cases, models may even hallucinate sounds that\nare not present in the input audio, raising concerns about their reliability.\nSecond, achieving cross-modal alignment between audio and language typically\nrelies on large collections of task-specific question-answer pairs for\ninstruction tuning, making the process resource-intensive. To address these\nissues, we leverage the backbone LLMs from ALLMs to synthesize general-purpose\ncaption-style alignment data. We refer to this process as bootstrapping\naudio-language alignment via synthetic data generation from backbone LLMs\n(BALSa). Building on BALSa, we introduce LISTEN (Learning to Identify Sounds\nThrough Extended Negative Samples), a contrastive-like training method designed\nto improve ALLMs' ability to distinguish between present and absent sounds. We\nfurther extend BALSa to multi-audio scenarios, where the model either explains\nthe differences between audio inputs or produces a unified caption that\ndescribes them all, thereby enhancing audio-language alignment. Experimental\nresults indicate that our method effectively mitigates audio hallucinations\nwhile reliably maintaining strong performance in audio understanding,\nreasoning, and instruction-following skills. Moreover, incorporating\nmulti-audio training further enhances the model's comprehension and reasoning\ncapabilities. Overall, BALSa offers an efficient and scalable approach to the\ndevelopment of ALLMs.", "published": "2025-05-26 16:08:41", "link": "http://arxiv.org/abs/2505.20166v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning", "abstract": "Effective generalization in language models depends critically on the\ndiversity of their training data. Yet existing diversity metrics often fall\nshort of this goal, relying on surface-level heuristics that are decoupled from\nmodel behavior. This motivates us to ask: What kind of diversity in training\ndata actually drives generalization in language models -- and how can we\nmeasure and amplify it? Through large-scale empirical analyses spanning over\n300 training runs, carefully controlled for data scale and quality, we show\nthat data diversity can be a strong predictor of generalization in LLM\nreasoning -- as measured by average model performance on unseen\nout-of-distribution benchmarks. We introduce G-Vendi, a metric that quantifies\ndiversity via the entropy of model-induced gradients. Despite using a small\noff-the-shelf proxy model for gradients, G-Vendi consistently outperforms\nalternative measures, achieving strong correlation (Spearman's $\\rho \\approx\n0.9$) with out-of-distribution (OOD) performance on both natural language\ninference (NLI) and math reasoning tasks. Building on this insight, we present\nPrismatic Synthesis, a framework for generating diverse synthetic data by\ntargeting underrepresented regions in gradient space. Experimental results show\nthat Prismatic Synthesis consistently improves model performance as we scale\nsynthetic data -- not just on in-distribution test but across unseen,\nout-of-distribution benchmarks -- significantly outperforming state-of-the-art\nmodels that rely on 20 times larger data generator than ours. For example,\nPrismMath-7B, our model distilled from a 32B LLM, outperforms\nR1-Distill-Qwen-7B -- the same base model trained on proprietary data generated\nby 671B R1 -- on 6 out of 7 challenging benchmarks.", "published": "2025-05-26 16:05:10", "link": "http://arxiv.org/abs/2505.20161v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Model Stitching by Functional Latent Alignment", "abstract": "Evaluating functional similarity involves quantifying the degree to which\nindependently trained neural networks learn functionally similar\nrepresentations. Reliably inferring the functional similarity of these networks\nremains an open problem with far-reaching implications for AI. Model stitching\nhas emerged as a promising paradigm, where an optimal affine transformation\naligns two models to solve a task, with the stitched model serving as a proxy\nfor functional similarity. In this work, we draw inspiration from the knowledge\ndistillation literature and propose Functional Latent Alignment (FuLA) as a\nnovel optimality condition for model stitching. We revisit previously explored\nfunctional similarity testbeds and introduce a new one, based on which FuLA\nemerges as an overall more reliable method of functional similarity.\nSpecifically, our experiments in (a) adversarial training, (b) shortcut\ntraining and, (c) cross-layer stitching, reveal that FuLA is less prone to\nartifacts tied to training on task cues while achieving non-trivial alignments\nthat are missed by stitch-level matching.", "published": "2025-05-26 15:44:26", "link": "http://arxiv.org/abs/2505.20142v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Data-Distill-Net: A Data Distillation Approach Tailored for Reply-based Continual Learning", "abstract": "Replay-based continual learning (CL) methods assume that models trained on a\nsmall subset can also effectively minimize the empirical risk of the complete\ndataset. These methods maintain a memory buffer that stores a sampled subset of\ndata from previous tasks to consolidate past knowledge. However, this\nassumption is not guaranteed in practice due to the limited capacity of the\nmemory buffer and the heuristic criteria used for buffer data selection. To\naddress this issue, we propose a new dataset distillation framework tailored\nfor CL, which maintains a learnable memory buffer to distill the global\ninformation from the current task data and accumulated knowledge preserved in\nthe previous memory buffer. Moreover, to avoid the computational overhead and\noverfitting risks associated with parameterizing the entire buffer during\ndistillation, we introduce a lightweight distillation module that can achieve\nglobal information distillation solely by generating learnable soft labels for\nthe memory buffer data. Extensive experiments show that, our method can achieve\ncompetitive results and effectively mitigates forgetting across various\ndatasets. The source code will be publicly available.", "published": "2025-05-26 15:37:10", "link": "http://arxiv.org/abs/2505.20135v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MolEditRL: Structure-Preserving Molecular Editing via Discrete Diffusion and Reinforcement Learning", "abstract": "Molecular editing aims to modify a given molecule to optimize desired\nchemical properties while preserving structural similarity. However, current\napproaches typically rely on string-based or continuous representations, which\nfail to adequately capture the discrete, graph-structured nature of molecules,\nresulting in limited structural fidelity and poor controllability. In this\npaper, we propose MolEditRL, a molecular editing framework that explicitly\nintegrates structural constraints with precise property optimization.\nSpecifically, MolEditRL consists of two stages: (1) a discrete graph diffusion\nmodel pretrained to reconstruct target molecules conditioned on source\nstructures and natural language instructions; (2) an editing-aware\nreinforcement learning fine-tuning stage that further enhances property\nalignment and structural preservation by explicitly optimizing editing\ndecisions under graph constraints. For comprehensive evaluation, we construct\nMolEdit-Instruct, the largest and most property-rich molecular editing dataset,\ncomprising 3 million diverse examples spanning single- and multi-property tasks\nacross 10 chemical attributes. Experimental results demonstrate that MolEditRL\nsignificantly outperforms state-of-the-art methods in both property\noptimization accuracy and structural fidelity, achieving a 74\\% improvement in\nediting success rate while using 98\\% fewer parameters.", "published": "2025-05-26 15:29:08", "link": "http://arxiv.org/abs/2505.20131v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Balancing Interference and Correlation in Spatial Experimental Designs: A Causal Graph Cut Approach", "abstract": "This paper focuses on the design of spatial experiments to optimize the\namount of information derived from the experimental data and enhance the\naccuracy of the resulting causal effect estimator. We propose a surrogate\nfunction for the mean squared error (MSE) of the estimator, which facilitates\nthe use of classical graph cut algorithms to learn the optimal design. Our\nproposal offers three key advances: (1) it accommodates moderate to large\nspatial interference effects; (2) it adapts to different spatial covariance\nfunctions; (3) it is computationally efficient. Theoretical results and\nnumerical experiments based on synthetic environments and a dispatch simulator\nthat models a city-scale ridesharing market, further validate the effectiveness\nof our design. A python implementation of our method is available at\nhttps://github.com/Mamba413/CausalGraphCut.", "published": "2025-05-26 15:29:01", "link": "http://arxiv.org/abs/2505.20130v1", "categories": ["cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Transformer in Protein: A Survey", "abstract": "As protein informatics advances rapidly, the demand for enhanced predictive\naccuracy, structural analysis, and functional understanding has intensified.\nTransformer models, as powerful deep learning architectures, have demonstrated\nunprecedented potential in addressing diverse challenges across protein\nresearch. However, a comprehensive review of Transformer applications in this\nfield remains lacking. This paper bridges this gap by surveying over 100\nstudies, offering an in-depth analysis of practical implementations and\nresearch progress of Transformers in protein-related tasks. Our review\nsystematically covers critical domains, including protein structure prediction,\nfunction prediction, protein-protein interaction analysis, functional\nannotation, and drug discovery/target identification. To contextualize these\nadvancements across various protein domains, we adopt a domain-oriented\nclassification system. We first introduce foundational concepts: the\nTransformer architecture and attention mechanisms, categorize Transformer\nvariants tailored for protein science, and summarize essential protein\nknowledge. For each research domain, we outline its objectives and background,\ncritically evaluate prior methods and their limitations, and highlight\ntransformative contributions enabled by Transformer models. We also curate and\nsummarize pivotal datasets and open-source code resources to facilitate\nreproducibility and benchmarking. Finally, we discuss persistent challenges in\napplying Transformers to protein informatics and propose future research\ndirections. This review aims to provide a consolidated foundation for the\nsynergistic integration of Transformer and protein informatics, fostering\nfurther innovation and expanded applications in the field.", "published": "2025-05-26 15:08:18", "link": "http://arxiv.org/abs/2505.20098v1", "categories": ["cs.LG", "cs.CR", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Spurious Privacy Leakage in Neural Networks", "abstract": "Neural networks are vulnerable to privacy attacks aimed at stealing sensitive\ndata. The risks can be amplified in a real-world scenario, particularly when\nmodels are trained on limited and biased data. In this work, we investigate the\nimpact of spurious correlation bias on privacy vulnerability. We introduce\n\\emph{spurious privacy leakage}, a phenomenon where spurious groups are\nsignificantly more vulnerable to privacy attacks than non-spurious groups. We\nfurther show that group privacy disparity increases in tasks with simpler\nobjectives (e.g. fewer classes) due to the persistence of spurious features.\nSurprisingly, we find that reducing spurious correlation using spurious robust\nmethods does not mitigate spurious privacy leakage. This leads us to introduce\na perspective on privacy disparity based on memorization, where mitigating\nspurious correlation does not mitigate the memorization of spurious data, and\ntherefore, neither the privacy level. Lastly, we compare the privacy of\ndifferent model architectures trained with spurious data, demonstrating that,\ncontrary to prior works, architectural choice can affect privacy outcomes.", "published": "2025-05-26 15:04:39", "link": "http://arxiv.org/abs/2505.20095v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A fast sound power prediction tool for genset noise using machine learning", "abstract": "This paper investigates the application of machine learning regression\nalgorithms Kernel Ridge Regression (KRR), Huber Regressor (HR), and Gaussian\nProcess Regression (GPR) for predicting sound power levels of gensets, offering\nsignificant value for marketing and sales teams during the early bidding\nprocess. When engine sizes and genset enclosure dimensions are tentative, and\nmeasured noise data is unavailable, these algorithms enable reliable noise\nlevel estimation for unbuilt gensets. The study utilizes high fidelity datasets\nfrom over 100 experiments conducted at Cummins Acoustics Technology Center\n(ATC) in a hemi-anechoic chamber, adhering to ISO 3744 standards. By using\nreadily available information from the bidding and initial design stages, KRR\npredicts sound power with an average accuracy of within 5 dBA. While HR and GPR\nshow slightly higher prediction errors, all models effectively capture the\noverall noise trends across various genset configurations. These findings\npresent a promising method for early-stage noise estimation in genset design.", "published": "2025-05-26 14:56:05", "link": "http://arxiv.org/abs/2505.20079v1", "categories": ["physics.app-ph", "cs.LG"], "primary_category": "physics.app-ph"}
{"title": "Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior", "abstract": "Post-hoc interpretability methods typically attribute a model's behavior to\nits components, data, or training trajectory in isolation. This leads to\nexplanations that lack a unified view and may miss key interactions. While\ncombining existing methods or applying them at different training stages offers\nbroader insights, these approaches usually lack theoretical support. In this\nwork, we present ExPLAIND, a unified framework that integrates all three\nperspectives. First, we generalize recent work on gradient path kernels, which\nreformulate models trained by gradient descent as a kernel machine, to more\nrealistic training settings. Empirically, we find that both a CNN and a\nTransformer model are replicated accurately by this reformulation. Second, we\nderive novel parameter- and step-wise influence scores from the kernel feature\nmaps. We show their effectiveness in parameter pruning that is comparable to\nexisting methods, reinforcing their value for model component attribution.\nFinally, jointly interpreting model components and data over the training\nprocess, we leverage ExPLAIND to analyze a Transformer that exhibits Grokking.\nAmong other things, our findings support previously proposed stages of\nGrokking, while refining the final phase as one of alignment of input\nembeddings and final layers around a representation pipeline learned after the\nmemorization phase. Overall, ExPLAIND provides a theoretically grounded,\nunified framework to interpret model behavior and training dynamics.", "published": "2025-05-26 14:53:11", "link": "http://arxiv.org/abs/2505.20076v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Out-Of-Distribution Membership Inference Attack Approach for Cross-Domain Graph Attacks", "abstract": "Graph Neural Network-based methods face privacy leakage risks due to the\nintroduction of topological structures about the targets, which allows\nattackers to bypass the target's prior knowledge of the sensitive attributes\nand realize membership inference attacks (MIA) by observing and analyzing the\ntopology distribution. As privacy concerns grow, the assumption of MIA, which\npresumes that attackers can obtain an auxiliary dataset with the same\ndistribution, is increasingly deviating from reality. In this paper, we\ncategorize the distribution diversity issue in real-world MIA scenarios as an\nOut-Of-Distribution (OOD) problem, and propose a novel Graph OOD Membership\nInference Attack (GOOD-MIA) to achieve cross-domain graph attacks.\nSpecifically, we construct shadow subgraphs with distributions from different\ndomains to model the diversity of real-world data. We then explore the stable\nnode representations that remain unchanged under external influences and\nconsider eliminating redundant information from confounding environments and\nextracting task-relevant key information to more clearly distinguish between\nthe characteristics of training data and unseen data. This OOD-based design\nmakes cross-domain graph attacks possible. Finally, we perform risk\nextrapolation to optimize the attack's domain adaptability during attack\ninference to generalize the attack to other domains. Experimental results\ndemonstrate that GOOD-MIA achieves superior attack performance in datasets\ndesigned for multiple domains.", "published": "2025-05-26 14:52:52", "link": "http://arxiv.org/abs/2505.20074v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion Enhances Protein Representations", "abstract": "Protein language models (PLMs) have emerged as powerful tools to detect\ncomplex patterns of protein sequences. However, the capability of PLMs to fully\ncapture information on protein sequences might be limited by focusing on single\npre-training tasks. Although adding data modalities or supervised objectives\ncan improve the performance of PLMs, pre-training often remains focused on\ndenoising corrupted sequences. To push the boundaries of PLMs, our research\ninvestigated a multi-task pre-training strategy. We developed Ankh3, a model\njointly optimized on two objectives: masked language modeling with multiple\nmasking probabilities and protein sequence completion relying only on protein\nsequences as input. This multi-task pre-training demonstrated that PLMs can\nlearn richer and more generalizable representations solely from protein\nsequences. The results demonstrated improved performance in downstream tasks,\nsuch as secondary structure prediction, fluorescence, GB1 fitness, and contact\nprediction. The integration of multiple tasks gave the model a more\ncomprehensive understanding of protein properties, leading to more robust and\naccurate predictions.", "published": "2025-05-26 14:41:10", "link": "http://arxiv.org/abs/2505.20052v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Catoni-Style Change Point Detection for Regret Minimization in Non-Stationary Heavy-Tailed Bandits", "abstract": "Regret minimization in stochastic non-stationary bandits gained popularity\nover the last decade, as it can model a broad class of real-world problems,\nfrom advertising to recommendation systems. Existing literature relies on\nvarious assumptions about the reward-generating process, such as Bernoulli or\nsubgaussian rewards. However, in settings such as finance and\ntelecommunications, heavy-tailed distributions naturally arise. In this work,\nwe tackle the heavy-tailed piecewise-stationary bandit problem. Heavy-tailed\nbandits, introduced by Bubeck et al., 2013, operate on the minimal assumption\nthat the finite absolute centered moments of maximum order $1+\\epsilon$ are\nuniformly bounded by a constant $v<+\\infty$, for some $\\epsilon \\in (0,1]$. We\nfocus on the most popular non-stationary bandit setting, i.e., the\npiecewise-stationary setting, in which the mean of reward-generating\ndistributions may change at unknown time steps. We provide a novel Catoni-style\nchange-point detection strategy tailored for heavy-tailed distributions that\nrelies on recent advancements in the theory of sequential estimation, which is\nof independent interest. We introduce Robust-CPD-UCB, which combines this\nchange-point detection strategy with optimistic algorithms for bandits,\nproviding its regret upper bound and an impossibility result on the minimum\nattainable regret for any policy. Finally, we validate our approach through\nnumerical experiments on synthetic and real-world datasets.", "published": "2025-05-26 14:40:47", "link": "http://arxiv.org/abs/2505.20051v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synthetic Time Series Forecasting with Transformer Architectures: Extensive Simulation Benchmarks", "abstract": "Time series forecasting plays a critical role in domains such as energy,\nfinance, and healthcare, where accurate predictions inform decision-making\nunder uncertainty. Although Transformer-based models have demonstrated success\nin sequential modeling, their adoption for time series remains limited by\nchallenges such as noise sensitivity, long-range dependencies, and a lack of\ninductive bias for temporal structure. In this work, we present a unified and\nprincipled framework for benchmarking three prominent Transformer forecasting\narchitectures-Autoformer, Informer, and Patchtst-each evaluated through three\narchitectural variants: Minimal, Standard, and Full, representing increasing\nlevels of complexity and modeling capacity.\n  We conduct over 1500 controlled experiments on a suite of ten synthetic\nsignals, spanning five patch lengths and five forecast horizons under both\nclean and noisy conditions. Our analysis reveals consistent patterns across\nmodel families.\n  To advance this landscape further, we introduce the Koopman-enhanced\nTransformer framework, Deep Koopformer, which integrates operator-theoretic\nlatent state modeling to improve stability and interpretability. We demonstrate\nits efficacy on nonlinear and chaotic dynamical systems. Our results highlight\nKoopman based Transformer as a promising hybrid approach for robust,\ninterpretable, and theoretically grounded time series forecasting in noisy and\ncomplex real-world conditions.", "published": "2025-05-26 14:34:05", "link": "http://arxiv.org/abs/2505.20048v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Beyond Simple Concatenation: Fairly Assessing PLM Architectures for Multi-Chain Protein-Protein Interactions Prediction", "abstract": "Protein-protein interactions (PPIs) are fundamental to numerous cellular\nprocesses, and their characterization is vital for understanding disease\nmechanisms and guiding drug discovery. While protein language models (PLMs)\nhave demonstrated remarkable success in predicting protein structure and\nfunction, their application to sequence-based PPI binding affinity prediction\nremains relatively underexplored. This gap is often attributed to the scarcity\nof high-quality, rigorously refined datasets and the reliance on simple\nstrategies for concatenating protein representations. In this work, we address\nthese limitations. First, we introduce a meticulously curated version of the\nPPB-Affinity dataset of a total of 8,207 unique protein-protein interaction\nentries, by resolving annotation inconsistencies and duplicate entries for\nmulti-chain protein interactions. This dataset incorporates a stringent, less\nthan or equal to 30%, sequence identity threshold to ensure robust splitting\ninto training, validation, and test sets, minimizing data leakage. Second, we\npropose and systematically evaluate four architectures for adapting PLMs to PPI\nbinding affinity prediction: embeddings concatenation (EC), sequences\nconcatenation (SC), hierarchical pooling (HP), and pooled attention addition\n(PAD). These architectures were assessed using two training methods: full\nfine-tuning and a lightweight approach employing ConvBERT heads over frozen PLM\nfeatures. Our comprehensive experiments across multiple leading PLMs (ProtT5,\nESM2, Ankh, Ankh2, and ESM3) demonstrated that the HP and PAD architectures\nconsistently outperform conventional concatenation methods, achieving up to 12%\nincrease in terms of Spearman correlation. These results highlight the\nnecessity of sophisticated architectural designs to fully exploit the\ncapabilities of PLMs for nuanced PPI binding affinity prediction.", "published": "2025-05-26 14:23:08", "link": "http://arxiv.org/abs/2505.20036v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Graph Wave Networks", "abstract": "Dynamics modeling has been introduced as a novel paradigm in message passing\n(MP) of graph neural networks (GNNs). Existing methods consider MP between\nnodes as a heat diffusion process, and leverage heat equation to model the\ntemporal evolution of nodes in the embedding space. However, heat equation can\nhardly depict the wave nature of graph signals in graph signal processing.\nBesides, heat equation is essentially a partial differential equation (PDE)\ninvolving a first partial derivative of time, whose numerical solution usually\nhas low stability, and leads to inefficient model training. In this paper, we\nwould like to depict more wave details in MP, since graph signals are\nessentially wave signals that can be seen as a superposition of a series of\nwaves in the form of eigenvector. This motivates us to consider MP as a wave\npropagation process to capture the temporal evolution of wave signals in the\nspace. Based on wave equation in physics, we innovatively develop a graph wave\nequation to leverage the wave propagation on graphs. In details, we demonstrate\nthat the graph wave equation can be connected to traditional spectral GNNs,\nfacilitating the design of graph wave networks based on various Laplacians and\nenhancing the performance of the spectral GNNs. Besides, the graph wave\nequation is particularly a PDE involving a second partial derivative of time,\nwhich has stronger stability on graphs than the heat equation that involves a\nfirst partial derivative of time. Additionally, we theoretically prove that the\nnumerical solution derived from the graph wave equation are constantly stable,\nenabling to significantly enhance model efficiency while ensuring its\nperformance. Extensive experiments show that GWNs achieve SOTA and efficient\nperformance on benchmark datasets, and exhibit outstanding performance in\naddressing challenging graph problems, such as over-smoothing and heterophily.", "published": "2025-05-26 14:20:41", "link": "http://arxiv.org/abs/2505.20034v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ontology- and LLM-based Data Harmonization for Federated Learning in Healthcare", "abstract": "The rise of electronic health records (EHRs) has unlocked new opportunities\nfor medical research, but privacy regulations and data heterogeneity remain key\nbarriers to large-scale machine learning. Federated learning (FL) enables\ncollaborative modeling without sharing raw data, yet faces challenges in\nharmonizing diverse clinical datasets. This paper presents a two-step data\nalignment strategy integrating ontologies and large language models (LLMs) to\nsupport secure, privacy-preserving FL in healthcare, demonstrating its\neffectiveness in a real-world project involving semantic mapping of EHR data.", "published": "2025-05-26 14:09:17", "link": "http://arxiv.org/abs/2505.20020v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Linear Bandits with Non-i.i.d. Noise", "abstract": "We study the linear stochastic bandit problem, relaxing the standard i.i.d.\nassumption on the observation noise. As an alternative to this restrictive\nassumption, we allow the noise terms across rounds to be sub-Gaussian but\ninterdependent, with dependencies that decay over time. To address this\nsetting, we develop new confidence sequences using a recently introduced\nreduction scheme to sequential probability assignment, and use these to derive\na bandit algorithm based on the principle of optimism in the face of\nuncertainty. We provide regret bounds for the resulting algorithm, expressed in\nterms of the decay rate of the strength of dependence between observations.\nAmong other results, we show that our bounds recover the standard rates up to a\nfactor of the mixing time for geometrically mixing observation noise.", "published": "2025-05-26 14:06:23", "link": "http://arxiv.org/abs/2505.20017v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Data-Dependent Regret Bounds for Constrained MABs", "abstract": "This paper initiates the study of data-dependent regret bounds in constrained\nMAB settings. These bounds depend on the sequence of losses that characterize\nthe problem instance. Thus, they can be much smaller than classical\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret bounds, while being equivalent to\nthem in the worst case. Despite this, data-dependent regret bounds have been\ncompletely overlooked in constrained MAB settings. The goal of this paper is to\nanswer the following question: Can data-dependent regret bounds be derived in\nthe presence of constraints? We answer this question affirmatively in\nconstrained MABs with adversarial losses and stochastic constraints.\nSpecifically, our main focus is on the most challenging and natural settings\nwith hard constraints, where the learner must ensure that the constraints are\nalways satisfied with high probability. We design an algorithm with a regret\nbound consisting of two data-dependent terms. The first term captures the\ndifficulty of satisfying the constraints, while the second one encodes the\ncomplexity of learning independently of the presence of constraints. We also\nprove a lower bound showing that these two terms are not artifacts of our\nspecific approach and analysis, but rather the fundamental components that\ninherently characterize the complexities of the problem. Finally, in designing\nour algorithm, we also derive some novel results in the related (and easier)\nsoft constraints settings, which may be of independent interest.", "published": "2025-05-26 14:00:36", "link": "http://arxiv.org/abs/2505.20010v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TabPFN: One Model to Rule Them All?", "abstract": "Hollmann et al. (Nature 637 (2025) 319-326) recently introduced TabPFN, a\ntransformer-based deep learning model for regression and classification on\ntabular data, which they claim \"outperforms all previous methods on datasets\nwith up to 10,000 samples by a wide margin, using substantially less training\ntime.\" Furthermore, they have called TabPFN a \"foundation model\" for tabular\ndata, as it can support \"data generation, density estimation, learning reusable\nembeddings and fine-tuning\". If these statements are well-supported, TabPFN may\nhave the potential to supersede existing modeling approaches on a wide range of\nstatistical tasks, mirroring a similar revolution in other areas of artificial\nintelligence that began with the advent of large language models. In this\npaper, we provide a tailored explanation of how TabPFN works for a statistics\naudience, by emphasizing its interpretation as approximate Bayesian inference.\nWe also provide more evidence of TabPFN's \"foundation model\" capabilities: We\nshow that an out-of-the-box application of TabPFN vastly outperforms\nspecialized state-of-the-art methods for semi-supervised parameter estimation,\nprediction under covariate shift, and heterogeneous treatment effect\nestimation. We further show that TabPFN can outperform LASSO at sparse\nregression and can break a robustness-efficiency trade-off in classification.\nAll experiments can be reproduced using the code provided at\nhttps://github.com/qinglong-tian/tabpfn_study\n(https://github.com/qinglong-tian/tabpfn_study).", "published": "2025-05-26 13:55:29", "link": "http://arxiv.org/abs/2505.20003v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Optimal Multimodal Information Bottleneck Representations", "abstract": "Leveraging high-quality joint representations from multimodal data can\ngreatly enhance model performance in various machine-learning based\napplications. Recent multimodal learning methods, based on the multimodal\ninformation bottleneck (MIB) principle, aim to generate optimal MIB with\nmaximal task-relevant information and minimal superfluous information via\nregularization. However, these methods often set ad hoc regularization weights\nand overlook imbalanced task-relevant information across modalities, limiting\ntheir ability to achieve optimal MIB. To address this gap, we propose a novel\nmultimodal learning framework, Optimal Multimodal Information Bottleneck\n(OMIB), whose optimization objective guarantees the achievability of optimal\nMIB by setting the regularization weight within a theoretically derived bound.\nOMIB further addresses imbalanced task-relevant information by dynamically\nadjusting regularization weights per modality, promoting the inclusion of all\ntask-relevant information. Moreover, we establish a solid\ninformation-theoretical foundation for OMIB's optimization and implement it\nunder the variational approximation framework for computational efficiency.\nFinally, we empirically validate the OMIB's theoretical properties on synthetic\ndata and demonstrate its superiority over the state-of-the-art benchmark\nmethods in various downstream tasks.", "published": "2025-05-26 13:48:07", "link": "http://arxiv.org/abs/2505.19996v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Regret Analysis of Average-Reward Unichain MDPs via an Actor-Critic Approach", "abstract": "Actor-Critic methods are widely used for their scalability, yet existing\ntheoretical guarantees for infinite-horizon average-reward Markov Decision\nProcesses (MDPs) often rely on restrictive ergodicity assumptions. We propose\nNAC-B, a Natural Actor-Critic with Batching, that achieves order-optimal regret\nof $\\tilde{O}(\\sqrt{T})$ in infinite-horizon average-reward MDPs under the\nunichain assumption, which permits both transient states and periodicity. This\nassumption is among the weakest under which the classic policy gradient theorem\nremains valid for average-reward settings. NAC-B employs function approximation\nfor both the actor and the critic, enabling scalability to problems with large\nstate and action spaces. The use of batching in our algorithm helps mitigate\npotential periodicity in the MDP and reduces stochasticity in gradient\nestimates, and our analysis formalizes these benefits through the introduction\nof the constants $C_{\\text{hit}}$ and $C_{\\text{tar}}$, which characterize the\nrate at which empirical averages over Markovian samples converge to the\nstationary distribution.", "published": "2025-05-26 13:43:02", "link": "http://arxiv.org/abs/2505.19986v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Rethinking Probabilistic Circuit Parameter Learning", "abstract": "Probabilistic Circuits (PCs) offer a computationally scalable framework for\ngenerative modeling, supporting exact and efficient inference of a wide range\nof probabilistic queries. While recent advances have significantly improved the\nexpressiveness and scalability of PCs, effectively training their parameters\nremains a challenge. In particular, a widely used optimization method,\nfull-batch Expectation-Maximization (EM), requires processing the entire\ndataset before performing a single update, making it ineffective for large\ndatasets. While empirical extensions to the mini-batch setting have been\nproposed, it remains unclear what objective these algorithms are optimizing,\nmaking it difficult to assess their theoretical soundness. This paper bridges\nthe gap by establishing a novel connection between the general EM objective and\nthe standard full-batch EM algorithm. Building on this, we derive a\ntheoretically grounded generalization to the mini-batch setting and demonstrate\nits effectiveness through preliminary empirical results.", "published": "2025-05-26 13:41:06", "link": "http://arxiv.org/abs/2505.19982v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Differential Privacy Analysis of Decentralized Gossip Averaging under Varying Threat Models", "abstract": "Fully decentralized training of machine learning models offers significant\nadvantages in scalability, robustness, and fault tolerance. However, achieving\ndifferential privacy (DP) in such settings is challenging due to the absence of\na central aggregator and varying trust assumptions among nodes. In this work,\nwe present a novel privacy analysis of decentralized gossip-based averaging\nalgorithms with additive node-level noise, both with and without secure\nsummation over each node's direct neighbors. Our main contribution is a new\nanalytical framework based on a linear systems formulation that accurately\ncharacterizes privacy leakage across these scenarios. This framework\nsignificantly improves upon prior analyses, for example, reducing the R\\'enyi\nDP parameter growth from $O(T^2)$ to $O(T)$, where $T$ is the number of\ntraining rounds. We validate our analysis with numerical results demonstrating\nsuperior DP bounds compared to existing approaches. We further illustrate our\nanalysis with a logistic regression experiment on MNIST image classification in\na fully decentralized setting, demonstrating utility comparable to central\naggregation methods.", "published": "2025-05-26 13:31:43", "link": "http://arxiv.org/abs/2505.19969v1", "categories": ["cs.LG", "cs.CR", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Which Data Attributes Stimulate Math and Code Reasoning? An Investigation via Influence Functions", "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities in math and coding, often bolstered by post-training on the\nchain-of-thoughts (CoTs) generated by stronger models. However, existing\nstrategies for curating such training data predominantly rely on heuristics,\nlimiting generalizability and failing to capture subtleties underlying in data.\nTo address these limitations, we leverage influence functions to systematically\nattribute LLMs' reasoning ability on math and coding to individual training\nexamples, sequences, and tokens, enabling deeper insights into effective data\ncharacteristics. Our Influence-based Reasoning Attribution (Infra) uncovers\nnontrivial cross-domain effects across math and coding tasks: high-difficulty\nmath examples improve both math and code reasoning, while low-difficulty code\ntasks most effectively benefit code reasoning. Based on these findings, we\nintroduce a simple yet effective dataset reweighting strategy by flipping task\ndifficulty, which doubles AIME24 accuracy from 10\\% to 20\\% and boosts\nLiveCodeBench accuracy from 33.8\\% to 35.3\\% for Qwen2.5-7B-Instruct. Moreover,\nour fine-grained attribution reveals that the sequence-level exploratory\nbehaviors enhance reasoning performance in both math and code, and the\ntoken-level influence patterns are distinct for math and code reasoning: the\nformer prefers natural language logic connectors and the latter emphasizes\nstructural syntax.", "published": "2025-05-26 13:15:26", "link": "http://arxiv.org/abs/2505.19949v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Inverse Q-Learning Done Right: Offline Imitation Learning in $Q^\u03c0$-Realizable MDPs", "abstract": "We study the problem of offline imitation learning in Markov decision\nprocesses (MDPs), where the goal is to learn a well-performing policy given a\ndataset of state-action pairs generated by an expert policy. Complementing a\nrecent line of work on this topic that assumes the expert belongs to a\ntractable class of known policies, we approach this problem from a new angle\nand leverage a different type of structural assumption about the environment.\nSpecifically, for the class of linear $Q^\\pi$-realizable MDPs, we introduce a\nnew algorithm called saddle-point offline imitation learning (\\SPOIL), which is\nguaranteed to match the performance of any expert up to an additive error\n$\\varepsilon$ with access to $\\mathcal{O}(\\varepsilon^{-2})$ samples. Moreover,\nwe extend this result to possibly non-linear $Q^\\pi$-realizable MDPs at the\ncost of a worse sample complexity of order $\\mathcal{O}(\\varepsilon^{-4})$.\nFinally, our analysis suggests a new loss function for training critic networks\nfrom expert data in deep imitation learning. Empirical evaluations on standard\nbenchmarks demonstrate that the neural net implementation of \\SPOIL is superior\nto behavior cloning and competitive with state-of-the-art algorithms.", "published": "2025-05-26 13:10:27", "link": "http://arxiv.org/abs/2505.19946v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beyond Freezing: Sparse Tuning Enhances Plasticity in Continual Learning with Pre-Trained Models", "abstract": "Continual Learning with Pre-trained Models holds great promise for efficient\nadaptation across sequential tasks. However, most existing approaches freeze\nPTMs and rely on auxiliary modules like prompts or adapters, limiting model\nplasticity and leading to suboptimal generalization when facing significant\ndistribution shifts. While full fine-tuning can improve adaptability, it risks\ndisrupting crucial pre-trained knowledge. In this paper, we propose Mutual\nInformation-guided Sparse Tuning (MIST), a plug-and-play method that\nselectively updates a small subset of PTM parameters, less than 5%, based on\nsensitivity to mutual information objectives. MIST enables effective\ntask-specific adaptation while preserving generalization. To further reduce\ninterference, we introduce strong sparsity regularization by randomly dropping\ngradients during tuning, resulting in fewer than 0.5% of parameters being\nupdated per step. Applied before standard freeze-based methods, MIST\nconsistently boosts performance across diverse continual learning benchmarks.\nExperiments show that integrating our method into multiple baselines yields\nsignificant performance gains. Our code is available at\nhttps://github.com/zhwhu/MIST.", "published": "2025-05-26 13:09:25", "link": "http://arxiv.org/abs/2505.19943v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Task-Oriented Low-Label Semantic Communication With Self-Supervised Learning", "abstract": "Task-oriented semantic communication enhances transmission efficiency by\nconveying semantic information rather than exact messages. Deep learning\n(DL)-based semantic communication can effectively cultivate the essential\nsemantic knowledge for semantic extraction, transmission, and interpretation by\nleveraging massive labeled samples for downstream task training. In this paper,\nwe propose a self-supervised learning-based semantic communication framework\n(SLSCom) to enhance task inference performance, particularly in scenarios with\nlimited access to labeled samples. Specifically, we develop a task-relevant\nsemantic encoder using unlabeled samples, which can be collected by devices in\nreal-world edge networks. To facilitate task-relevant semantic extraction, we\nintroduce self-supervision for learning contrastive features and formulate the\ninformation bottleneck (IB) problem to balance the tradeoff between the\ninformativeness of the extracted features and task inference performance. Given\nthe computational challenges of the IB problem, we devise a practical and\neffective solution by employing self-supervised classification and\nreconstruction pretext tasks. We further propose efficient joint training\nmethods to enhance end-to-end inference accuracy over wireless channels, even\nwith few labeled samples. We evaluate the proposed framework on image\nclassification tasks over multipath wireless channels. Extensive simulation\nresults demonstrate that SLSCom significantly outperforms conventional digital\ncoding methods and existing DL-based approaches across varying labeled data set\nsizes and SNR conditions, even when the unlabeled samples are irrelevant to the\ndownstream tasks.", "published": "2025-05-26 13:06:18", "link": "http://arxiv.org/abs/2505.19940v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Logic Gate Neural Networks are Good for Verification", "abstract": "Learning-based systems are increasingly deployed across various domains, yet\nthe complexity of traditional neural networks poses significant challenges for\nformal verification. Unlike conventional neural networks, learned Logic Gate\nNetworks (LGNs) replace multiplications with Boolean logic gates, yielding a\nsparse, netlist-like architecture that is inherently more amenable to symbolic\nverification, while still delivering promising performance. In this paper, we\nintroduce a SAT encoding for verifying global robustness and fairness in LGNs.\nWe evaluate our method on five benchmark datasets, including a newly\nconstructed 5-class variant, and find that LGNs are both verification-friendly\nand maintain strong predictive performance.", "published": "2025-05-26 12:59:33", "link": "http://arxiv.org/abs/2505.19932v1", "categories": ["cs.LG", "cs.LO"], "primary_category": "cs.LG"}
{"title": "Cellwise and Casewise Robust Covariance in High Dimensions", "abstract": "The sample covariance matrix is a cornerstone of multivariate statistics, but\nit is highly sensitive to outliers. These can be casewise outliers, such as\ncases belonging to a different population, or cellwise outliers, which are\ndeviating cells (entries) of the data matrix. Recently some robust covariance\nestimators have been developed that can handle both types of outliers, but\ntheir computation is only feasible up to at most 20 dimensions. To remedy this\nwe propose the cellRCov method, a robust covariance estimator that\nsimultaneously handles casewise outliers, cellwise outliers, and missing data.\nIt relies on a decomposition of the covariance on principal and orthogonal\nsubspaces, leveraging recent work on robust PCA. It also employs a ridge-type\nregularization to stabilize the estimated covariance matrix. We establish some\ntheoretical properties of cellRCov, including its casewise and cellwise\ninfluence functions as well as consistency and asymptotic normality. A\nsimulation study demonstrates the superior performance of cellRCov in\ncontaminated and missing data scenarios. Furthermore, its practical utility is\nillustrated in a real-world application to anomaly detection. We also construct\nand illustrate the cellRCCA method for robust and regularized canonical\ncorrelation analysis.", "published": "2025-05-26 12:46:44", "link": "http://arxiv.org/abs/2505.19925v1", "categories": ["stat.ME", "cs.LG"], "primary_category": "stat.ME"}
{"title": "Learning to Trust Bellman Updates: Selective State-Adaptive Regularization for Offline RL", "abstract": "Offline reinforcement learning (RL) aims to learn an effective policy from a\nstatic dataset. To alleviate extrapolation errors, existing studies often\nuniformly regularize the value function or policy updates across all states.\nHowever, due to substantial variations in data quality, the fixed\nregularization strength often leads to a dilemma: Weak regularization strength\nfails to address extrapolation errors and value overestimation, while strong\nregularization strength shifts policy learning toward behavior cloning,\nimpeding potential performance enabled by Bellman updates. To address this\nissue, we propose the selective state-adaptive regularization method for\noffline RL. Specifically, we introduce state-adaptive regularization\ncoefficients to trust state-level Bellman-driven results, while selectively\napplying regularization on high-quality actions, aiming to avoid performance\ndegradation caused by tight constraints on low-quality actions. By establishing\na connection between the representative value regularization method, CQL, and\nexplicit policy constraint methods, we effectively extend selective\nstate-adaptive regularization to these two mainstream offline RL approaches.\nExtensive experiments demonstrate that the proposed method significantly\noutperforms the state-of-the-art approaches in both offline and\noffline-to-online settings on the D4RL benchmark.", "published": "2025-05-26 12:45:54", "link": "http://arxiv.org/abs/2505.19923v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generalized and Personalized Federated Learning with Foundation Models via Orthogonal Transformations", "abstract": "Federated Learning (FL) aims to train models across decentralized clients or\ndevices holding local data without the need for centralized data collection,\nthus enhancing data privacy and security. However, achieving both\ngeneralization and personalization in heterogeneous settings remains a\nsignificant challenge. To address this, we introduce FedOT, a novel approach\nthat leverages black-box foundation models. FedOT shares only a global\ntask-dependent classifier across clients while locally adapting features\nthrough orthogonal transformations. By enforcing orthogonality, FedOT mitigates\ngradient conflicts across diverse clients, preserves semantic integrity, and\nachieves robust performance even in the presence of substantial data\nheterogeneity. The strategy of combining global and local parameters enables a\nmore balanced approach for both generalization and personalization,\noutperforming baseline FL methods across multiple benchmarks. Furthermore, our\nextensive analysis confirms that joint optimization of global classifiers and\nlocal orthogonal transformations yields superior performance and suggests\nbroader applicability.", "published": "2025-05-26 12:18:24", "link": "http://arxiv.org/abs/2505.19888v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Editing as Unlearning: Are Knowledge Editing Methods Strong Baselines for Large Language Model Unlearning?", "abstract": "Large language Model (LLM) unlearning, i.e., selectively removing information\nfrom LLMs, is vital for responsible model deployment. Differently, LLM\nknowledge editing aims to modify LLM knowledge instead of removing it. Though\nediting and unlearning seem to be two distinct tasks, we find there is a tight\nconnection between them. In this paper, we conceptualize unlearning as a\nspecial case of editing where information is modified to a refusal or \"empty\nset\" $\\emptyset$ response, signifying its removal. This paper thus investigates\nif knowledge editing techniques are strong baselines for LLM unlearning. We\nevaluate state-of-the-art (SOTA) editing methods (e.g., ROME, MEMIT, GRACE,\nWISE, and AlphaEdit) against existing unlearning approaches on pretrained and\nfinetuned knowledge. Results show certain editing methods, notably WISE and\nAlphaEdit, are effective unlearning baselines, especially for pretrained\nknowledge, and excel in generating human-aligned refusal answers. To better\nadapt editing methods for unlearning applications, we propose practical recipes\nincluding self-improvement and query merging. The former leverages the LLM's\nown in-context learning ability to craft a more human-aligned unlearning\ntarget, and the latter enables ROME and MEMIT to perform well in unlearning\nlonger sample sequences. We advocate for the unlearning community to adopt SOTA\nediting methods as baselines and explore unlearning from an editing perspective\nfor more holistic LLM memory control.", "published": "2025-05-26 11:39:56", "link": "http://arxiv.org/abs/2505.19855v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Deconvolution in Populational Inverse Problems", "abstract": "This work is focussed on the inversion task of inferring the distribution\nover parameters of interest leading to multiple sets of observations. The\npotential to solve such distributional inversion problems is driven by\nincreasing availability of data, but a major roadblock is blind deconvolution,\narising when the observational noise distribution is unknown. However, when\ndata originates from collections of physical systems, a population, it is\npossible to leverage this information to perform deconvolution. To this end, we\npropose a methodology leveraging large data sets of observations, collected\nfrom different instantiations of the same physical processes, to simultaneously\ndeconvolve the data corrupting noise distribution, and to identify the\ndistribution over model parameters defining the physical processes. A\nparameter-dependent mathematical model of the physical process is employed. A\nloss function characterizing the match between the observed data and the output\nof the mathematical model is defined; it is minimized as a function of the both\nthe parameter inputs to the model of the physics and the parameterized\nobservational noise. This coupled problem is addressed with a modified gradient\ndescent algorithm that leverages specific structure in the noise model.\nFurthermore, a new active learning scheme is proposed, based on adaptive\nempirical measures, to train a surrogate model to be accurate in parameter\nregions of interest; this approach accelerates computation and enables\nautomatic differentiation of black-box, potentially nondifferentiable, code\ncomputing parameter-to-solution maps. The proposed methodology is demonstrated\non porous medium flow, damped elastodynamics, and simplified models of\natmospheric dynamics.", "published": "2025-05-26 11:25:46", "link": "http://arxiv.org/abs/2505.19841v1", "categories": ["stat.ML", "cs.LG", "physics.comp-ph"], "primary_category": "stat.ML"}
{"title": "One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP", "abstract": "Deep Neural Networks (DNNs) have achieved widespread success yet remain prone\nto adversarial attacks. Typically, such attacks either involve frequent queries\nto the target model or rely on surrogate models closely mirroring the target\nmodel -- often trained with subsets of the target model's training data -- to\nachieve high attack success rates through transferability. However, in\nrealistic scenarios where training data is inaccessible and excessive queries\ncan raise alarms, crafting adversarial examples becomes more challenging. In\nthis paper, we present UnivIntruder, a novel attack framework that relies\nsolely on a single, publicly available CLIP model and publicly available\ndatasets. By using textual concepts, UnivIntruder generates universal,\ntransferable, and targeted adversarial perturbations that mislead DNNs into\nmisclassifying inputs into adversary-specified classes defined by textual\nconcepts.\n  Our extensive experiments show that our approach achieves an Attack Success\nRate (ASR) of up to 85% on ImageNet and over 99% on CIFAR-10, significantly\noutperforming existing transfer-based methods. Additionally, we reveal\nreal-world vulnerabilities, showing that even without querying target models,\nUnivIntruder compromises image search engines like Google and Baidu with ASR\nrates up to 84%, and vision language models like GPT-4 and Claude-3.5 with ASR\nrates up to 80%. These findings underscore the practicality of our attack in\nscenarios where traditional avenues are blocked, highlighting the need to\nreevaluate security paradigms in AI applications.", "published": "2025-05-26 11:25:00", "link": "http://arxiv.org/abs/2505.19840v1", "categories": ["cs.CR", "cs.LG", "68T07", "I.2.6"], "primary_category": "cs.CR"}
{"title": "Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals to Applications", "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown great potential as an\nadaptive solution for addressing modern cybersecurity challenges. MARL enables\ndecentralized, adaptive, and collaborative defense strategies and provides an\nautomated mechanism to combat dynamic, coordinated, and sophisticated threats.\nThis survey investigates the current state of research in MARL applications for\nautomated cyber defense (ACD), focusing on intruder detection and lateral\nmovement containment. Additionally, it examines the role of Autonomous\nIntelligent Cyber-defense Agents (AICA) and Cyber Gyms in training and\nvalidating MARL agents. Finally, the paper outlines existing challenges, such\nas scalability and adversarial robustness, and proposes future research\ndirections. This also discusses how MARL integrates in AICA to provide\nadaptive, scalable, and dynamic solutions to counter the increasingly\nsophisticated landscape of cyber threats. It highlights the transformative\npotential of MARL in areas like intrusion detection and lateral movement\ncontainment, and underscores the value of Cyber Gyms for training and\nvalidation of AICA.", "published": "2025-05-26 11:19:43", "link": "http://arxiv.org/abs/2505.19837v1", "categories": ["cs.MA", "cs.GT", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Poison in the Well: Feature Embedding Disruption in Backdoor Attacks", "abstract": "Backdoor attacks embed malicious triggers into training data, enabling\nattackers to manipulate neural network behavior during inference while\nmaintaining high accuracy on benign inputs. However, existing backdoor attacks\nface limitations manifesting in excessive reliance on training data, poor\nstealth, and instability, which hinder their effectiveness in real-world\napplications. Therefore, this paper introduces ShadowPrint, a versatile\nbackdoor attack that targets feature embeddings within neural networks to\nachieve high ASRs and stealthiness. Unlike traditional approaches, ShadowPrint\nreduces reliance on training data access and operates effectively with\nexceedingly low poison rates (as low as 0.01%). It leverages a clustering-based\noptimization strategy to align feature embeddings, ensuring robust performance\nacross diverse scenarios while maintaining stability and stealth. Extensive\nevaluations demonstrate that ShadowPrint achieves superior ASR (up to 100%),\nsteady CA (with decay no more than 1% in most cases), and low DDR (averaging\nbelow 5%) across both clean-label and dirty-label settings, and with poison\nrates ranging from as low as 0.01% to 0.05%, setting a new standard for\nbackdoor attack capabilities and emphasizing the need for advanced defense\nstrategies focused on feature space manipulations.", "published": "2025-05-26 10:59:44", "link": "http://arxiv.org/abs/2505.19821v1", "categories": ["cs.CR", "cs.LG", "I.2.6; I.5.1; D.4.6"], "primary_category": "cs.CR"}
{"title": "InfoCons: Identifying Interpretable Critical Concepts in Point Clouds via Information Theory", "abstract": "Interpretability of point cloud (PC) models becomes imperative given their\ndeployment in safety-critical scenarios such as autonomous vehicles. We focus\non attributing PC model outputs to interpretable critical concepts, defined as\nmeaningful subsets of the input point cloud. To enable human-understandable\ndiagnostics of model failures, an ideal critical subset should be *faithful*\n(preserving points that causally influence predictions) and *conceptually\ncoherent* (forming semantically meaningful structures that align with human\nperception). We propose InfoCons, an explanation framework that applies\ninformation-theoretic principles to decompose the point cloud into 3D concepts,\nenabling the examination of their causal effect on model predictions with\nlearnable priors. We evaluate InfoCons on synthetic datasets for\nclassification, comparing it qualitatively and quantitatively with four\nbaselines. We further demonstrate its scalability and flexibility on two\nreal-world datasets and in two applications that utilize critical scores of PC.", "published": "2025-05-26 10:58:54", "link": "http://arxiv.org/abs/2505.19820v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Density Ratio-Free Doubly Robust Proxy Causal Learning", "abstract": "We study the problem of causal function estimation in the Proxy Causal\nLearning (PCL) framework, where confounders are not observed but proxies for\nthe confounders are available. Two main approaches have been proposed: outcome\nbridge-based and treatment bridge-based methods. In this work, we propose two\nkernel-based doubly robust estimators that combine the strengths of both\napproaches, and naturally handle continuous and high-dimensional variables. Our\nidentification strategy builds on a recent density ratio-free method for\ntreatment bridge-based PCL; furthermore, in contrast to previous approaches, it\ndoes not require indicator functions or kernel smoothing over the treatment\nvariable. These properties make it especially well-suited for continuous or\nhigh-dimensional treatments. By using kernel mean embeddings, we have\nclosed-form solutions and strong consistency guarantees. Our estimators\noutperform existing methods on PCL benchmarks, including a prior doubly robust\nmethod that requires both kernel smoothing and density ratio estimation.", "published": "2025-05-26 10:44:26", "link": "http://arxiv.org/abs/2505.19807v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "What Can RL Bring to VLA Generalization? An Empirical Study", "abstract": "Large Vision-Language Action (VLA) models have shown significant potential\nfor embodied AI. However, their predominant training via supervised fine-tuning\n(SFT) limits generalization due to susceptibility to compounding errors under\ndistribution shifts. Reinforcement learning (RL) offers a path to overcome\nthese limitations by optimizing for task objectives via trial-and-error, yet a\nsystematic understanding of its specific generalization benefits for VLAs\ncompared to SFT is lacking. To address this, our study introduces a\ncomprehensive benchmark for evaluating VLA generalization and systematically\ninvestigates the impact of RL fine-tuning across diverse visual, semantic, and\nexecution dimensions. Our extensive experiments reveal that RL fine-tuning,\nparticularly with PPO, significantly enhances generalization in semantic\nunderstanding and execution robustness over SFT, while maintaining comparable\nvisual robustness. We identify PPO as a more effective RL algorithm for VLAs\nthan LLM-derived methods like DPO and GRPO. We also develop a simple recipe for\nefficient PPO training on VLAs, and demonstrate its practical utility for\nimproving VLA generalization. The project page is at https://rlvla.github.io", "published": "2025-05-26 10:19:26", "link": "http://arxiv.org/abs/2505.19789v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Episode Length Adjustment for Multi-agent Reinforcement Learning", "abstract": "In standard reinforcement learning, an episode is defined as a sequence of\ninteractions between agents and the environment, which terminates upon reaching\na terminal state or a pre-defined episode length. Setting a shorter episode\nlength enables the generation of multiple episodes with the same number of data\nsamples, thereby facilitating an exploration of diverse states. While shorter\nepisodes may limit the collection of long-term interactions, they may offer\nsignificant advantages when properly managed. For example, trajectory\ntruncation in single-agent reinforcement learning has shown how the benefits of\nshorter episodes can be leveraged despite the trade-off of reduced long-term\ninteraction experiences. However, this approach remains underexplored in MARL.\nThis paper proposes a novel MARL approach, Adaptive Episode Length Adjustment\n(AELA), where the episode length is initially limited and gradually increased\nbased on an entropy-based assessment of learning progress. By starting with\nshorter episodes, agents can focus on learning effective strategies for initial\nstates and minimize time spent in dead-end states. The use of entropy as an\nassessment metric prevents premature convergence to suboptimal policies and\nensures balanced training over varying episode lengths. We validate our\napproach using the StarCraft Multi-agent Challenge (SMAC) and a modified\npredator-prey environment, demonstrating significant improvements in both\nconvergence speed and overall performance compared to existing methods. To the\nbest of our knowledge, this is the first study to adaptively adjust episode\nlength in MARL based on learning progress.", "published": "2025-05-26 07:54:58", "link": "http://arxiv.org/abs/2505.19637v1", "categories": ["cs.MA", "I.2.11"], "primary_category": "cs.MA"}
{"title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "abstract": "This study presents the LLM-Agent-Controller, a multi-agent large language\nmodel (LLM) system developed to address a wide range of problems in control\nengineering (Control Theory). The system integrates a central controller agent\nwith multiple specialized auxiliary agents, responsible for tasks such as\ncontroller design, model representation, control analysis, time-domain\nresponse, and simulation. A supervisor oversees high-level decision-making and\nworkflow coordination, enhancing the system's reliability and efficiency. The\nLLM-Agent-Controller incorporates advanced capabilities, including\nRetrieval-Augmented Generation (RAG), Chain-of-Thought reasoning,\nself-criticism and correction, efficient memory handling, and user-friendly\nnatural language communication. It is designed to function without requiring\nusers to have prior knowledge of Control Theory, enabling them to input\nproblems in plain language and receive complete, real-time solutions. To\nevaluate the system, we propose new performance metrics assessing both\nindividual agents and the system as a whole. We test five categories of Control\nTheory problems and benchmark performance across three advanced LLMs.\nAdditionally, we conduct a comprehensive qualitative conversational analysis\ncovering all key services. Results show that the LLM-Agent-Controller\nsuccessfully solved 83% of general tasks, with individual agents achieving an\naverage success rate of 87%. Performance improved with more advanced LLMs. This\nresearch demonstrates the potential of multi-agent LLM architectures to solve\ncomplex, domain-specific problems. By integrating specialized agents,\nsupervisory control, and advanced reasoning, the LLM-Agent-Controller offers a\nscalable, robust, and accessible solution framework that can be extended to\nvarious technical domains.", "published": "2025-05-26 06:30:13", "link": "http://arxiv.org/abs/2505.19567v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "VLMLight: Traffic Signal Control via Vision-Language Meta-Control and Dual-Branch Reasoning", "abstract": "Traffic signal control (TSC) is a core challenge in urban mobility, where\nreal-time decisions must balance efficiency and safety. Existing methods -\nranging from rule-based heuristics to reinforcement learning (RL) - often\nstruggle to generalize to complex, dynamic, and safety-critical scenarios. We\nintroduce VLMLight, a novel TSC framework that integrates vision-language\nmeta-control with dual-branch reasoning. At the core of VLMLight is the first\nimage-based traffic simulator that enables multi-view visual perception at\nintersections, allowing policies to reason over rich cues such as vehicle type,\nmotion, and spatial density. A large language model (LLM) serves as a\nsafety-prioritized meta-controller, selecting between a fast RL policy for\nroutine traffic and a structured reasoning branch for critical cases. In the\nlatter, multiple LLM agents collaborate to assess traffic phases, prioritize\nemergency vehicles, and verify rule compliance. Experiments show that VLMLight\nreduces waiting times for emergency vehicles by up to 65% over RL-only systems,\nwhile preserving real-time performance in standard conditions with less than 1%\ndegradation. VLMLight offers a scalable, interpretable, and safety-aware\nsolution for next-generation traffic signal control.", "published": "2025-05-26 04:12:57", "link": "http://arxiv.org/abs/2505.19486v1", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs", "abstract": "Large language models (LLMs) have shown remarkable performance across diverse\nreasoning and generation tasks, and are increasingly deployed as agents in\ndynamic environments such as code generation and recommendation systems.\nHowever, many real-world applications, such as high-frequency trading and\nreal-time competitive gaming, require decisions under strict latency\nconstraints, where faster responses directly translate into higher rewards.\nDespite the importance of this latency quality trade off, it remains\nunderexplored in the context of LLM based agents. In this work, we present the\nfirst systematic study of this trade off in real time decision making tasks. To\nsupport our investigation, we introduce two new benchmarks: HFTBench, a high\nfrequency trading simulation, and StreetFighter, a competitive gaming platform.\nOur analysis reveals that optimal latency quality balance varies by task, and\nthat sacrificing quality for lower latency can significantly enhance downstream\nperformance. To address this, we propose FPX, an adaptive framework that\ndynamically selects model size and quantization level based on real time\ndemands. Our method achieves the best performance on both benchmarks, improving\nwin rate by up to 80% in Street Fighter and boosting daily yield by up to\n26.52% in trading, underscoring the need for latency aware evaluation and\ndeployment strategies for LLM based agents. These results demonstrate the\ncritical importance of latency aware evaluation and deployment strategies for\nreal world LLM based agents. Our benchmarks are available at Latency Sensitive\nBenchmarks.", "published": "2025-05-26 04:03:48", "link": "http://arxiv.org/abs/2505.19481v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.MA"], "primary_category": "cs.LG"}
{"title": "A structure-preserving multiscale solver for particle-wave interaction in non-uniform magnetized plasmas", "abstract": "Particle-wave interaction is of fundamental interest in plasma physics,\nespecially in the study of runaway electrons in magnetic confinement fusion.\nAnalogous to the concept of photons and phonons, wave packets in plasma can\nalso be treated as quasi-particles, called plasmons. To model the ``mixture\" of\nelectrons and plasmons in plasma, a set of ``collisional\" kinetic equations has\nbeen derived, based on weak turbulence limit and the Wentzel-Kramers-Brillouin\n(WKB) approximation.\n  There are two main challenges in solving the electron-plasmon kinetic system\nnumerically. Firstly, non-uniform plasma density and magnetic field results in\nhigh dimensionality and the presence of multiple time scales. Secondly, a\nphysically reliable numerical solution requires a structure-preserving scheme\nthat enforces the conservation of mass, momentum, and energy.\n  In this paper, we propose a struture-preserving multiscale solver for\nparticle-wave interaction in non-uniform magnetized plasmas. The solver\ncombines a conservative local discontinuous Galerkin (LDG) scheme for the\ninteraction part with a trajectory averaging method for the plasmon Hamiltonian\nflow part. Numerical examples for a non-uniform magnetized plasma in an\ninfinitely long symmetric cylinder are presented. It is verified that the LDG\nscheme rigorously preserves all the conservation laws, and the trajectory\naveraging method significantly reduces the computational cost.", "published": "2025-05-26 16:50:28", "link": "http://arxiv.org/abs/2505.20210v1", "categories": ["math.NA", "cs.NA", "physics.plasm-ph"], "primary_category": "math.NA"}
{"title": "Multirate methods for ordinary differential equations", "abstract": "This survey provides an overview of state-of-the art multirate schemes, which\nexploit the different time scales in the dynamics of a differential equation\nmodel by adapting the computational costs to different activity levels of the\nsystem. We start the discussion with the straightforward approach based on\ninterpolating and extrapolating the slow--fast coupling variables; the\nmultirate Euler scheme, used as a base example, falls into this class. Next we\ndiscuss higher order multirate schemes that generalize classical singlerate\nlinear multistep, Runge-Kutta, and extrapolation methods.", "published": "2025-05-26 14:47:32", "link": "http://arxiv.org/abs/2505.20062v1", "categories": ["math.NA", "cs.NA", "65L05, 65L06, 65L07, 65L020"], "primary_category": "math.NA"}
{"title": "Robust feedback control of collisional plasma dynamics in presence of uncertainties", "abstract": "Magnetic fusion aims to confine high-temperature plasma within a device,\nenabling the fusion of deuterium and tritium nuclei to release energy. Due to\nthe very large temperatures involved, it is essential to isolate the plasma\nfrom the device walls to prevent structural damage and the external magnetic\nfields play a fundamental role in achieving this confinement. In realistic\nsettings, the physical mechanisms governing plasma behavior are highly complex,\ninvolving numerous uncertain parameters and intricate particle interactions,\nsuch as collisions, that significantly affect both confinement efficiency and\noverall stability. In this work, we address particularly these challenges by\nproposing a robust feedback control strategy designed to steer the plasma\ntowards a desired spatial region, despite the presence of uncertainties. From a\nmodeling perspective, we consider a collisional plasma described by a\nVlasov-Poisson-BGK system, which accounts for a self-consistent electric field\nand a strong external magnetic field, while incorporating uncertainty in the\nmodel. A key feature of the proposed control strategy is its independence from\nthe random parameter, making it particularly suitable for practical\napplications. A series of numerical simulations confirms the effectiveness of\nour approach and demonstrates the ability of external magnetic fields to\nsuccessfully confine plasma away from the device boundaries, even in the\npresence of uncertain conditions.", "published": "2025-05-26 13:46:28", "link": "http://arxiv.org/abs/2505.19992v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence rates for Tikhonov regularization on compact sets: application to neural networks", "abstract": "In this work, we consider ill-posed inverse problems in which the forward\noperator is continuous and weakly closed, and the sought solution belongs to a\nweakly closed constraint set. We propose a regularization method based on\nminimizing the Tikhonov functional on a sequence of compact sets which is dense\nin the intersection between the domain of the forward operator and the\nconstraint set. The index of the compact sets can be interpreted as an\nadditional regularization parameter. We prove that the proposed method is a\nregularization, achieving the same convergence rates as classical Tikhonov\nregularization and attaining the optimal convergence rate when the forward\noperator is linear. Moreover, we show that our methodology applies to the case\nwhere the constrained solution space is parametrized by means of neural\nnetworks (NNs), and the constraint is obtained by composing the last layer of\nthe NN with a suitable activation function. In this case the dense compact sets\nare defined by taking a family of bounded weight NNs with increasing weight\nbound. Finally, we present some numerical experiments in the case of\nComputerized Tomography to compare the theoretical behavior of the\nreconstruction error with that obtained in a finite dimensional and\nnon-asymptotic setting. The numerical tests also show that our NN-based\nregularization method is able to provide piece-wise constant solutions and to\npreserve the sharpness of edges, thus achieving lower reconstruction errors\ncompared to the classical Tikhonov approach for the same level of noise in the\ndata.", "published": "2025-05-26 13:02:31", "link": "http://arxiv.org/abs/2505.19936v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Galerkin Alternating Projection Method for Kinetic Equations in the Diffusive Limit", "abstract": "The numerical approximation of high-dimensional evolution equations poses\nsignificant computational challenges, particularly in kinetic theory and\nradiative transfer. In this work, we introduce the Galerkin Alternating\nProjection (GAP) scheme, a novel integrator derived within the Dynamical\nLow-Rank Approximation (DLRA) framework. We perform a rigorous error analysis,\nestablishing local and global accuracy using standard ODE techniques.\nFurthermore, we prove that GAP possesses the Asymptotic-Preserving (AP)\nproperty when applied to the Radiative Transfer Equation (RTE), ensuring\nconsistent behavior across both kinetic and diffusive regimes. In the diffusive\nregime, the K-step of the GAP integrator directly becomes the limit equation.\nIn particular, this means that we can easily obtain schemes that even in the\ndiffusive regime are free of a CFL condition, do not require well prepared\ninitial data, and can have arbitrary order in the diffusive limit (in contrast\nto the semi-implicit and implicit schemes available in the literature).\nNumerical experiments support the theoretical findings and demonstrate the\nrobustness and efficiency of the proposed method.", "published": "2025-05-26 12:56:07", "link": "http://arxiv.org/abs/2505.19929v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of Adaptive Finite Element Algorithms for a Regularized Variational Model of Quasi-Static Brittle Fracture in \"Strain-Limiting\" Elastic Solids", "abstract": "The rigorous convergence analysis of adaptive finite element methods for\nregularized variational models of quasi-static brittle fracture in\nstrain-limiting elastic solids is presented. This work introduces two novel\nadaptive mesh refinement algorithms, based on robust local error indicators,\ndesigned to solve the underlying energy minimization problem efficiently. A\ncomprehensive convergence analysis is provided for minimizer sequences\ngenerated by these distinct adaptive strategies. It is rigorously demonstrated\nthat sequences from the first algorithm converge to a prescribed tolerance.\nNotably, the second algorithm is proven to yield inherently convergent\nsequences without requiring an explicit stopping criterion. The practical\nefficacy of the proposed adaptive framework is validated through extensive\nnumerical simulations, where critical comparisons of energy components (bulk,\nsurface, and total) demonstrate the performance of the two adaptive algorithms\nin the case of an edge crack in a strain-limiting solid subjected to anti-plane\nshear-type loading.", "published": "2025-05-26 10:32:00", "link": "http://arxiv.org/abs/2505.19801v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N22, 65N30, 65N50, 65R10"], "primary_category": "math.NA"}
{"title": "On some coupled local and nonlocal diffusion models", "abstract": "We study problems in which a local model is coupled with a nonlocal one. We\npropose two energies: both of them are based on the same classical weighted\n$H^1$-semi norm to model the local part, while two different weighted\n$H^s$-semi norms, with $s \\in (0,1)$, are used to model the nonlocal part. The\ncorresponding strong formulations are derived. In doing so, one needs to\ndevelop some technical tools, such as suitable integration by parts formulas\nfor operators with variable diffusivity, and one also needs to study the\nmapping properties of the Neumann operators that arise. In contrast to problems\ncoupling purely local models, in which one requires transmission conditions on\nthe interface between the subdomains, the presence of a nonlocal operator may\ngive rise to nonlocal fluxes. These nonlocal fluxes may enter the problem as a\nsource term, thereby changing its structure. Finally, we focus on a specific\nproblem, that we consider most relevant, and study regularity of solutions and\nfinite element discretizations. We provide numerical experiments to illustrate\nthe most salient features of the models.", "published": "2025-05-26 09:47:20", "link": "http://arxiv.org/abs/2505.19765v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Numerical Identification of a Time-Dependent Coefficient in a Time-Fractional Diffusion Equation with Integral Constraints", "abstract": "In this paper, we numerically address the inverse problem of identifying a\ntime-dependent coefficient in the time-fractional diffusion equation. An a\npriori estimate is established to ensure uniqueness and stability of the\nsolution. A fully implicit finite-difference scheme is proposed and rigorously\nanalysed for stability and convergence. An efficient algorithm based on an\nintegral formulation is implemented and verified through numerical experiments,\ndemonstrating accuracy and robustness under noisy data.", "published": "2025-05-26 09:20:45", "link": "http://arxiv.org/abs/2505.19738v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Solving Implicit Inverse Problems with Homotopy-Based Regularization Path", "abstract": "Implicit inverse problems, in which noisy observations of a physical quantity\nare used to infer a nonlinear functional applied to an associated function, are\ninherently ill posed and often exhibit non uniqueness of solutions. Such\nproblems arise in a range of domains, including the identification of systems\ngoverned by Ordinary and Partial Differential Equations (ODEs/PDEs), optimal\ncontrol, and data assimilation. Their solution is complicated by the nonlinear\nnature of the underlying constraints and the instability introduced by noise.\nIn this paper, we propose a homotopy based optimization method for solving such\nproblems. Beginning with a regularized constrained formulation that includes a\nsparsity promoting regularization term, we employ a gradient based algorithm in\nwhich gradients with respect to the model parameters are efficiently computed\nusing the adjoint state method. Nonlinear constraints are handled through a\nNewton Raphson procedure. By solving a sequence of problems with decreasing\nregularization, we trace a solution path that improves stability and enables\nthe exploration of multiple candidate solutions. The method is applied to the\nlatent dynamics discovery problem in simulation, highlighting performance as a\nfunction of ground truth sparsity and semi convergence behavior.", "published": "2025-05-26 07:21:39", "link": "http://arxiv.org/abs/2505.19608v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Reduced-Order Solution for Rarefied Gas Flow by Proper Generalised Decomposition", "abstract": "Modelling rarefied gas flow via the Boltzmann equation plays a vital role in\nmany areas. Due to the high dimensionality of this kinetic equation and the\ncoexistence of multiple characteristic scales in the transport processes,\nconventional solution strategies incur prohibitively high computational costs\nand are inadequate for rapid response for parametric analysis and optimisation\nloops in engineering design simulations. This paper proposes an \\textit{a\npriori} reduced-order method based on the proper generalised decomposition to\nsolve the high-dimensional, parametrised Shakhov kinetic model equation. This\nmethod reduces the original problem into a few low-dimensional problem by\nformulating separated representations for the low-rank solution, as well as\ndata and operators in the equation, thereby overcoming the curse of\ndimensionality. Furthermore, a general solution can be calculated once and for\nall in the whole range of the rarefaction parameter, enabling fast and multiple\nqueries to a specific solution at any point in the parameter space. Numerical\nexamples are presented to demonstrate the capability of the method to simulate\nrarefied gas flow with high accuracy and significant reduction in CPU time and\nmemory requirements.", "published": "2025-05-26 06:17:48", "link": "http://arxiv.org/abs/2505.19555v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Selective focusing of multiple particles in a layered medium", "abstract": "Inverse scattering in layered media has a wide range of applications,\nexamples including geophysical exploration, medical imaging, and remote\nsensing. In this paper, we develop a selective focusing method for identifying\nmultiple unknown buried scatterers in a layered medium. The method is derived\nthrough the asymptotic analysis of the time reversal operator using the layered\nGreen's function and limited aperture measurements. We begin by showing the\nglobal focusing property of the time reversal operator. Then we demonstrate\nthat each small sound-soft particle gives rise to one significant eigenvalue of\nthe time reversal operator, while each sound-hard particle gives three. The\nassociated eigenfunction generates an incident wave focusing selectively on the\ncorresponding unknown particle. Finally, we employ the time reversal method as\nan initial indicator and propose an effective Bayesian inversion scheme to\nreconstruct multiple buried extended scatterers for enhanced resolution.\nNumerical experiments are provided to demonstrate the efficiency.", "published": "2025-05-26 05:12:33", "link": "http://arxiv.org/abs/2505.19524v1", "categories": ["math.NA", "cs.NA", "78A46, 35B40, 35R30, 31A10"], "primary_category": "math.NA"}
{"title": "Hybrid Models for Financial Forecasting: Combining Econometric, Machine Learning, and Deep Learning Models", "abstract": "This research systematically develops and evaluates various hybrid modeling\napproaches by combining traditional econometric models (ARIMA and ARFIMA\nmodels) with machine learning and deep learning techniques (SVM, XGBoost, and\nLSTM models) to forecast financial time series. The empirical analysis is based\non two distinct financial assets: the S&P 500 index and Bitcoin. By\nincorporating over two decades of daily data for the S&P 500 and almost ten\nyears of Bitcoin data, the study provides a comprehensive evaluation of\nforecasting methodologies across different market conditions and periods of\nfinancial distress. Models' training and hyperparameter tuning procedure is\nperformed using a novel three-fold dynamic cross-validation method. The\napplicability of applied models is evaluated using both forecast error metrics\nand trading performance indicators. The obtained findings indicate that the\nproper construction process of hybrid models plays a crucial role in developing\nprofitable trading strategies, outperforming their individual components and\nthe benchmark Buy&Hold strategy. The most effective hybrid model architecture\nwas achieved by combining the econometric ARIMA model with either SVM or LSTM,\nunder the assumption of a non-additive relationship between the linear and\nnonlinear components.", "published": "2025-05-26 07:32:23", "link": "http://arxiv.org/abs/2505.19617v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Minimax Adaptive Online Nonparametric Regression over Besov Spaces", "abstract": "We study online adversarial regression with convex losses against a rich\nclass of continuous yet highly irregular prediction rules, modeled by Besov\nspaces $B_{pq}^s$ with general parameters $1 \\leq p,q \\leq \\infty$ and\nsmoothness $s > d/p$. We introduce an adaptive wavelet-based algorithm that\nperforms sequential prediction without prior knowledge of $(s,p,q)$, and\nestablish minimax-optimal regret bounds against any comparator in $B_{pq}^s$.\nWe further design a locally adaptive extension capable of dynamically tracking\nspatially inhomogeneous smoothness. This adaptive mechanism adjusts the\nresolution of the predictions over both time and space, yielding refined regret\nbounds in terms of local regularity. Consequently, in heterogeneous\nenvironments, our adaptive guarantees can significantly surpass those obtained\nby standard global methods.", "published": "2025-05-26 09:23:11", "link": "http://arxiv.org/abs/2505.19741v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Weighted Leave-One-Out Cross Validation", "abstract": "We present a weighted version of Leave-One-Out (LOO) cross-validation for\nestimating the Integrated Squared Error (ISE) when approximating an unknown\nfunction by a predictor that depends linearly on evaluations of the function\nover a finite collection of sites. The method relies on the construction of the\nbest linear estimator of the squared prediction error at an arbitrary unsampled\nsite based on squared LOO residuals, assuming that the function is a\nrealization of a Gaussian Process (GP). A theoretical analysis of performance\nof the ISE estimator is presented, and robustness with respect to the choice of\nthe GP kernel is investigated first analytically, then through numerical\nexamples. Overall, the estimation of ISE is significantly more precise than\nwith classical, unweighted, LOO cross validation. Application to model\nselection is briefly considered through examples.", "published": "2025-05-26 09:20:34", "link": "http://arxiv.org/abs/2505.19737v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Accelerating Nash Learning from Human Feedback via Mirror Prox", "abstract": "Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on\nreward models, frequently assuming preference structures like the Bradley-Terry\nmodel, which may not accurately capture the complexities of real human\npreferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF)\noffers a more direct alternative by framing the problem as finding a Nash\nequilibrium of a game defined by these preferences. In this work, we introduce\nNash Mirror Prox ($\\mathtt{Nash-MP}$), an online NLHF algorithm that leverages\nthe Mirror Prox optimization scheme to achieve fast and stable convergence to\nthe Nash equilibrium. Our theoretical analysis establishes that Nash-MP\nexhibits last-iterate linear convergence towards the $\\beta$-regularized Nash\nequilibrium. Specifically, we prove that the KL-divergence to the optimal\npolicy decreases at a rate of order $(1+2\\beta)^{-N/2}$, where $N$ is a number\nof preference queries. We further demonstrate last-iterate linear convergence\nfor the exploitability gap and uniformly for the span semi-norm of\nlog-probabilities, with all these rates being independent of the size of the\naction space. Furthermore, we propose and analyze an approximate version of\nNash-MP where proximal steps are estimated using stochastic policy gradients,\nmaking the algorithm closer to applications. Finally, we detail a practical\nimplementation strategy for fine-tuning large language models and present\nexperiments that demonstrate its competitive performance and compatibility with\nexisting methods.", "published": "2025-05-26 09:17:32", "link": "http://arxiv.org/abs/2505.19731v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On the Relation between Rectified Flows and Optimal Transport", "abstract": "This paper investigates the connections between rectified flows, flow\nmatching, and optimal transport. Flow matching is a recent approach to learning\ngenerative models by estimating velocity fields that guide transformations from\na source to a target distribution. Rectified flow matching aims to straighten\nthe learned transport paths, yielding more direct flows between distributions.\nOur first contribution is a set of invariance properties of rectified flows and\nexplicit velocity fields. In addition, we also provide explicit constructions\nand analysis in the Gaussian (not necessarily independent) and Gaussian mixture\nsettings and study the relation to optimal transport. Our second contribution\naddresses recent claims suggesting that rectified flows, when constrained such\nthat the learned velocity field is a gradient, can yield (asymptotically)\nsolutions to optimal transport problems. We study the existence of solutions\nfor this problem and demonstrate that they only relate to optimal transport\nunder assumptions that are significantly stronger than those previously\nacknowledged. In particular, we present several counter-examples that\ninvalidate earlier equivalence results in the literature, and we argue that\nenforcing a gradient constraint on rectified flows is, in general, not a\nreliable method for computing optimal transport maps.", "published": "2025-05-26 09:01:53", "link": "http://arxiv.org/abs/2505.19712v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "When fractional quasi p-norms concentrate", "abstract": "Concentration of distances in high dimension is an important factor for the\ndevelopment and design of stable and reliable data analysis algorithms. In this\npaper, we address the fundamental long-standing question about the\nconcentration of distances in high dimension for fractional quasi $p$-norms,\n$p\\in(0,1)$. The topic has been at the centre of various theoretical and\nempirical controversies. Here we, for the first time, identify conditions when\nfractional quasi $p$-norms concentrate and when they don't. We show that\ncontrary to some earlier suggestions, for broad classes of distributions,\nfractional quasi $p$-norms admit exponential and uniform in $p$ concentration\nbounds. For these distributions, the results effectively rule out previously\nproposed approaches to alleviate concentration by \"optimal\" setting the values\nof $p$ in $(0,1)$. At the same time, we specify conditions and the\ncorresponding families of distributions for which one can still control\nconcentration rates by appropriate choices of $p$. We also show that in an\narbitrarily small vicinity of a distribution from a large class of\ndistributions for which uniform concentration occurs, there are uncountably\nmany other distributions featuring anti-concentration properties. Importantly,\nthis behavior enables devising relevant data encoding or representation schemes\nfavouring or discouraging distance concentration. The results shed new light on\nthis long-standing problem and resolve the tension around the topic in both\ntheory and empirical evidence reported in the literature.", "published": "2025-05-26 07:53:51", "link": "http://arxiv.org/abs/2505.19635v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68T09, 62R07, 94A16"], "primary_category": "cs.LG"}
{"title": "Model Agnostic Differentially Private Causal Inference", "abstract": "Estimating causal effects from observational data is essential in fields such\nas medicine, economics and social sciences, where privacy concerns are\nparamount. We propose a general, model-agnostic framework for differentially\nprivate estimation of average treatment effects (ATE) that avoids strong\nstructural assumptions on the data-generating process or the models used to\nestimate propensity scores and conditional outcomes. In contrast to prior work,\nwhich enforces differential privacy by directly privatizing these nuisance\ncomponents and results in a privacy cost that scales with model complexity, our\napproach decouples nuisance estimation from privacy protection. This separation\nallows the use of flexible, state-of-the-art black-box models, while\ndifferential privacy is achieved by perturbing only predictions and aggregation\nsteps within a fold-splitting scheme with ensemble techniques. We instantiate\nthe framework for three classical estimators -- the G-formula, inverse\npropensity weighting (IPW), and augmented IPW (AIPW) -- and provide formal\nutility and privacy guarantees. Empirical results show that our methods\nmaintain competitive performance under realistic privacy budgets. We further\nextend our framework to support meta-analysis of multiple private ATE\nestimates. Our results bridge a critical gap between causal inference and\nprivacy-preserving data analysis.", "published": "2025-05-26 07:00:37", "link": "http://arxiv.org/abs/2505.19589v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Minimalist Softmax Attention Provably Learns Constrained Boolean Functions", "abstract": "We study the computational limits of learning $k$-bit Boolean functions\n(specifically, $\\mathrm{AND}$, $\\mathrm{OR}$, and their noisy variants), using\na minimalist single-head softmax-attention mechanism, where $k=\\Theta(d)$\nrelevant bits are selected from $d$ inputs. We show that these simple\n$\\mathrm{AND}$ and $\\mathrm{OR}$ functions are unsolvable with a single-head\nsoftmax-attention mechanism alone. However, with teacher forcing, the same\nminimalist attention is capable of solving them. These findings offer two key\ninsights: Architecturally, solving these Boolean tasks requires only minimalist\nattention, without deep Transformer blocks or FFNs. Methodologically, one\ngradient descent update with supervision suffices and replaces the multi-step\nChain-of-Thought (CoT) reasoning scheme of [Kim and Suzuki, ICLR 2025] for\nsolving Boolean problems. Together, the bounds expose a fundamental gap between\nwhat this minimal architecture achieves under ideal supervision and what is\nprovably impossible under standard training.", "published": "2025-05-26 05:33:26", "link": "http://arxiv.org/abs/2505.19531v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Discounted Online Convex Optimization: Uniform Regret Across a Continuous Interval", "abstract": "Reflecting the greater significance of recent history over the distant past\nin non-stationary environments, $\\lambda$-discounted regret has been introduced\nin online convex optimization (OCO) to gracefully forget past data as new\ninformation arrives. When the discount factor $\\lambda$ is given, online\ngradient descent with an appropriate step size achieves an\n$O(1/\\sqrt{1-\\lambda})$ discounted regret. However, the value of $\\lambda$ is\noften not predetermined in real-world scenarios. This gives rise to a\nsignificant open question: is it possible to develop a discounted algorithm\nthat adapts to an unknown discount factor. In this paper, we affirmatively\nanswer this question by providing a novel analysis to demonstrate that smoothed\nOGD (SOGD) achieves a uniform $O(\\sqrt{\\log T/1-\\lambda})$ discounted regret,\nholding for all values of $\\lambda$ across a continuous interval\nsimultaneously. The basic idea is to maintain multiple OGD instances to handle\ndifferent discount factors, and aggregate their outputs sequentially by an\nonline prediction algorithm named as Discounted-Normal-Predictor (DNP)\n(Kapralov and Panigrahy,2010). Our analysis reveals that DNP can combine the\ndecisions of two experts, even when they operate on discounted regret with\ndifferent discount factors.", "published": "2025-05-26 04:20:51", "link": "http://arxiv.org/abs/2505.19491v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Information-theoretic Generalization Analysis for VQ-VAEs: A Role of Latent Variables", "abstract": "Latent variables (LVs) play a crucial role in encoder-decoder models by\nenabling effective data compression, prediction, and generation. Although their\ntheoretical properties, such as generalization, have been extensively studied\nin supervised learning, similar analyses for unsupervised models such as\nvariational autoencoders (VAEs) remain insufficiently underexplored. In this\nwork, we extend information-theoretic generalization analysis to\nvector-quantized (VQ) VAEs with discrete latent spaces, introducing a novel\ndata-dependent prior to rigorously analyze the relationship among LVs,\ngeneralization, and data generation. We derive a novel generalization error\nbound of the reconstruction loss of VQ-VAEs, which depends solely on the\ncomplexity of LVs and the encoder, independent of the decoder. Additionally, we\nprovide the upper bound of the 2-Wasserstein distance between the distributions\nof the true data and the generated data, explaining how the regularization of\nthe LVs contributes to the data generation performance.", "published": "2025-05-26 03:51:44", "link": "http://arxiv.org/abs/2505.19470v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Recurrent Self-Attention Dynamics: An Energy-Agnostic Perspective from Jacobians", "abstract": "The theoretical understanding of self-attention (SA) has been steadily\nprogressing. A prominent line of work studies a class of SA layers that admit\nan energy function decreased by state updates. While it provides valuable\ninsights into inherent biases in signal propagation, it often relies on\nidealized assumptions or additional constraints not necessarily present in\nstandard SA. Thus, to broaden our understanding, this work aims to relax these\nenergy constraints and provide an energy-agnostic characterization of inference\ndynamics by dynamical systems analysis. In more detail, we first consider\nrelaxing the symmetry and single-head constraints traditionally required in\nenergy-based formulations. Next, to investigate more general SA architectures\ncapable of oscillatory dynamics without necessarily admitting an energy\nfunction, we analyze the Jacobian matrix of the state. We reveal that\nnormalization layers effectively normalize the Jacobian's complex eigenvalues,\nforcing the dynamics close to a critical state. This significantly enhances\ninference performance. Furthermore, we utilize the Jacobian perspective to\ndevelop regularization methods for training and a pseudo-energy for monitoring\ninference dynamics.", "published": "2025-05-26 03:24:59", "link": "http://arxiv.org/abs/2505.19458v1", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Uniform convergence of the smooth calibration error and its relationship with functional gradient", "abstract": "Calibration is a critical requirement for reliable probabilistic prediction,\nespecially in high-risk applications. However, the theoretical understanding of\nwhich learning algorithms can simultaneously achieve high accuracy and good\ncalibration remains limited, and many existing studies provide empirical\nvalidation or a theoretical guarantee in restrictive settings. To address this\nissue, in this work, we focus on the smooth calibration error (CE) and provide\na uniform convergence bound, showing that the smooth CE is bounded by the sum\nof the smooth CE over the training dataset and a generalization gap. We further\nprove that the functional gradient of the loss function can effectively control\nthe training smooth CE. Based on this framework, we analyze three\nrepresentative algorithms: gradient boosting trees, kernel boosting, and\ntwo-layer neural networks. For each, we derive conditions under which both\nclassification and calibration performances are simultaneously guaranteed. Our\nresults offer new theoretical insights and practical guidance for designing\nreliable probabilistic models with provable calibration guarantees.", "published": "2025-05-26 01:23:56", "link": "http://arxiv.org/abs/2505.19396v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Efficient Speech Translation through Model Compression and Knowledge Distillation", "abstract": "Efficient deployment of large audio-language models for speech translation\nremains challenging due to their significant computational requirements. In\nthis paper, we address this challenge through our system submissions to the\n\"Model Compression\" track at the International Conference on Spoken Language\nTranslation (IWSLT 2025). We experiment with a combination of approaches\nincluding iterative layer pruning based on layer importance evaluation,\nlow-rank adaptation with 4-bit quantization (QLoRA), and knowledge\ndistillation. In our experiments, we use Qwen2-Audio-7B-Instruct for speech\ntranslation into German and Chinese. Our pruned (student) models achieve up to\na 50% reduction in both model parameters and storage footprint, while retaining\n97-100% of the translation quality of the in-domain (teacher) models.", "published": "2025-05-26 17:17:08", "link": "http://arxiv.org/abs/2505.20237v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "FT-Boosted SV: Towards Noise Robust Speaker Verification for English Speaking Classroom Environments", "abstract": "Creating Speaker Verification (SV) systems for classroom settings that are\nrobust to classroom noises such as babble noise is crucial for the development\nof AI tools that assist educational environments. In this work, we study the\nefficacy of finetuning with augmented children datasets to adapt the x-vector\nand ECAPA-TDNN to classroom environments. We demonstrate that finetuning with\naugmented children's datasets is powerful in that regard and reduces the Equal\nError Rate (EER) of x-vector and ECAPA-TDNN models for both classroom datasets\nand children speech datasets. Notably, this method reduces EER of the\nECAPA-TDNN model on average by half (a 5 % improvement) for classrooms in the\nMPT dataset compared to the ECAPA-TDNN baseline model. The x-vector model shows\nan 8 % average improvement for classrooms in the NCTE dataset compared to its\nbaseline.", "published": "2025-05-26 17:05:42", "link": "http://arxiv.org/abs/2505.20222v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Continuous Learning for Children's ASR: Overcoming Catastrophic Forgetting with Elastic Weight Consolidation and Synaptic Intelligence", "abstract": "In this work, we present the first study addressing automatic speech\nrecognition (ASR) for children in an online learning setting. This is\nparticularly important for both child-centric applications and the privacy\nprotection of minors, where training models with sequentially arriving data is\ncritical. The conventional approach of model fine-tuning often suffers from\ncatastrophic forgetting. To tackle this issue, we explore two established\ntechniques: elastic weight consolidation (EWC) and synaptic intelligence (SI).\nUsing a custom protocol on the MyST corpus, tailored to the online learning\nsetting, we achieve relative word error rate (WER) reductions of 5.21% with EWC\nand 4.36% with SI, compared to the fine-tuning baseline.", "published": "2025-05-26 16:57:42", "link": "http://arxiv.org/abs/2505.20216v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Exploring Generative Error Correction for Dysarthric Speech Recognition", "abstract": "Despite the remarkable progress in end-to-end Automatic Speech Recognition\n(ASR) engines, accurately transcribing dysarthric speech remains a major\nchallenge. In this work, we proposed a two-stage framework for the Speech\nAccessibility Project Challenge at INTERSPEECH 2025, which combines\ncutting-edge speech recognition models with LLM-based generative error\ncorrection (GER). We assess different configurations of model scales and\ntraining strategies, incorporating specific hypothesis selection to improve\ntranscription accuracy. Experiments on the Speech Accessibility Project dataset\ndemonstrate the strength of our approach on structured and spontaneous speech,\nwhile highlighting challenges in single-word recognition. Through comprehensive\nanalysis, we provide insights into the complementary roles of acoustic and\nlinguistic modeling in dysarthric speech recognition", "published": "2025-05-26 16:06:31", "link": "http://arxiv.org/abs/2505.20163v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Improving Speech Emotion Recognition Through Cross Modal Attention Alignment and Balanced Stacking Model", "abstract": "Emotion plays a fundamental role in human interaction, and therefore systems\ncapable of identifying emotions in speech are crucial in the context of\nhuman-computer interaction. Speech emotion recognition (SER) is a challenging\nproblem, particularly in natural speech and when the available data is\nimbalanced across emotions. This paper presents our proposed system in the\ncontext of the 2025 Speech Emotion Recognition in Naturalistic Conditions\nChallenge. Our proposed architecture leverages cross-modality, utilizing\ncross-modal attention to fuse representations from different modalities. To\naddress class imbalance, we employed two training designs: (i) weighted\ncrossentropy loss (WCE); and (ii) WCE with an additional neutralexpressive soft\nmargin loss and balancing. We trained a total of 12 multimodal models, which\nwere ensembled using a balanced stacking model. Our proposed system achieves a\nMacroF1 score of 0.4094 and an accuracy of 0.4128 on 8-class speech emotion\nrecognition.", "published": "2025-05-26 13:58:12", "link": "http://arxiv.org/abs/2505.20007v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Accelerating Flow-Matching-Based Text-to-Speech via Empirically Pruned Step Sampling", "abstract": "Flow-matching-based text-to-speech (TTS) models, such as Voicebox, E2 TTS,\nand F5-TTS, have attracted significant attention in recent years. These models\nrequire multiple sampling steps to reconstruct speech from noise, making\ninference speed a key challenge. Reducing the number of sampling steps can\ngreatly improve inference efficiency. To this end, we introduce Fast F5-TTS, a\ntraining-free approach to accelerate the inference of flow-matching-based TTS\nmodels. By inspecting the sampling trajectory of F5-TTS, we identify redundant\nsteps and propose Empirically Pruned Step Sampling (EPSS), a non-uniform\ntime-step sampling strategy that effectively reduces the number of sampling\nsteps. Our approach achieves a 7-step generation with an inference RTF of 0.030\non an NVIDIA RTX 3090 GPU, making it 4 times faster than the original F5-TTS\nwhile maintaining comparable performance. Furthermore, EPSS performs well on E2\nTTS models, demonstrating its strong generalization ability.", "published": "2025-05-26 12:58:27", "link": "http://arxiv.org/abs/2505.19931v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep learning based spatial aliasing reduction in beamforming for audio capture", "abstract": "Spatial aliasing affects spaced microphone arrays, causing directional\nambiguity above certain frequencies, degrading spatial and spectral accuracy of\nbeamformers. Given the limitations of conventional signal processing and the\nscarcity of deep learning approaches to spatial aliasing mitigation, we propose\na novel approach using a U-Net architecture to predict a signal-dependent\nde-aliasing filter, which reduces aliasing in conventional beamforming for\nspatial capture. Two types of multichannel filters are considered, one which\ntreats the channels independently and a second one that models cross-channel\ndependencies. The proposed approach is evaluated in two common spatial capture\nscenarios: stereo and first-order Ambisonics. The results indicate a very\nsignificant improvement, both objective and perceptual, with respect to\nconventional beamforming. This work shows the potential of deep learning to\nreduce aliasing in beamforming, leading to improvements in multi-microphone\nsetups.", "published": "2025-05-26 10:08:04", "link": "http://arxiv.org/abs/2505.19781v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DuRep: Dual-Mode Speech Representation Learning via ASR-Aware Distillation", "abstract": "Recent advancements in speech encoders have drawn attention due to their\nintegration with Large Language Models for various speech tasks. While most\nresearch has focused on either causal or full-context speech encoders, there's\nlimited exploration to effectively handle both streaming and non-streaming\napplications, while achieving state-of-the-art performance. We introduce DuRep,\na Dual-mode Speech Representation learning setup, which enables a single speech\nencoder to function efficiently in both offline and online modes without\nadditional parameters or mode-specific adjustments, across downstream tasks.\nDuRep-200M, our 200M parameter dual-mode encoder, achieves 12% and 11.6%\nimprovements in streaming and non-streaming modes, over baseline encoders on\nMultilingual ASR. Scaling this approach to 2B parameters, DuRep-2B sets new\nperformance benchmarks across ASR and non-ASR tasks. Our analysis reveals\ninteresting trade-offs between acoustic and semantic information across encoder\nlayers.", "published": "2025-05-26 09:57:59", "link": "http://arxiv.org/abs/2505.19774v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Navigating PESQ: Up-to-Date Versions and Open Implementations", "abstract": "Perceptual Evaluation of Speech Quality (PESQ) is an objective quality\nmeasure that remains widely used despite its withdrawal by the International\nTelecommunication Union (ITU). PESQ has evolved over two decades, with multiple\nversions and publicly available implementations emerging during this time. The\nnumerous versions and their updates can be overwhelming, especially for new\nPESQ users. This work provides practical guidance on the different versions and\nimplementations of PESQ. We show that differences can be significant,\nespecially between PESQ versions. We stress the importance of specifying the\nexact version and implementation that is used to compute PESQ, and possibly to\ndetail how multi-channel signals are handled. These practices would facilitate\nthe interpretation of results and allow comparisons of PESQ scores between\ndifferent studies. We also provide a repository that implements the latest\ncorrections to PESQ, i.e., Corrigendum 2, which is not implemented by any other\nopenly available distribution: https://github.com/audiolabs/PESQ.", "published": "2025-05-26 09:43:09", "link": "http://arxiv.org/abs/2505.19760v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech", "abstract": "Cross-speaker emotion transfer in speech synthesis relies on extracting\nspeaker-independent emotion embeddings for accurate emotion modeling without\nretaining speaker traits. However, existing timbre compression methods fail to\nfully separate speaker and emotion characteristics, causing speaker leakage and\ndegraded synthesis quality. To address this, we propose DiEmo-TTS, a\nself-supervised distillation method to minimize emotional information loss and\npreserve speaker identity. We introduce cluster-driven sampling and information\nperturbation to preserve emotion while removing irrelevant factors. To\nfacilitate this process, we propose an emotion clustering and matching approach\nusing emotional attribute prediction and speaker embeddings, enabling\ngeneralization to unlabeled data. Additionally, we designed a dual conditioning\ntransformer to integrate style features better. Experimental results confirm\nthe effectiveness of our method in learning speaker-irrelevant emotion\nembeddings.", "published": "2025-05-26 08:47:39", "link": "http://arxiv.org/abs/2505.19687v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automated evaluation of children's speech fluency for low-resource languages", "abstract": "Assessment of children's speaking fluency in education is well researched for\nmajority languages, but remains highly challenging for low resource languages.\nThis paper proposes a system to automatically assess fluency by combining a\nfine-tuned multilingual ASR model, an objective metrics extraction stage, and a\ngenerative pre-trained transformer (GPT) network. The objective metrics include\nphonetic and word error rates, speech rate, and speech-pause duration ratio.\nThese are interpreted by a GPT-based classifier guided by a small set of\nhuman-evaluated ground truth examples, to score fluency. We evaluate the\nproposed system on a dataset of children's speech in two low-resource\nlanguages, Tamil and Malay and compare the classification performance against\nRandom Forest and XGBoost, as well as using ChatGPT-4o to predict fluency\ndirectly from speech input. Results demonstrate that the proposed approach\nachieves significantly higher accuracy than multimodal GPT or other methods.", "published": "2025-05-26 08:25:50", "link": "http://arxiv.org/abs/2505.19671v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comprehensive Real-World Assessment of Audio Watermarking Algorithms: Will They Survive Neural Codecs?", "abstract": "We present a framework to foster the evaluation of deep learning-based audio\nwatermarking algorithms, establishing a standardized benchmark and allowing\nsystematic comparisons. To simulate real-world usage, we introduce a\ncomprehensive audio attack pipeline, featuring various distortions such as\ncompression, background noise, and reverberation, and propose a diverse test\ndataset, including speech, environmental sounds, and music recordings. By\nassessing the performance of four existing watermarking algorithms on our\nframework, two main insights stand out: (i) neural compression techniques pose\nthe most significant challenge, even when algorithms are trained with such\ncompressions; and (ii) training with audio attacks generally improves\nrobustness, although it is insufficient in some cases. Furthermore, we find\nthat specific distortions, such as polarity inversion, time stretching, or\nreverb, seriously affect certain algorithms. Our contributions strengthen the\nrobustness and perceptual assessment of audio watermarking algorithms across a\nwide range of applications, while ensuring a fair and consistent evaluation\napproach. The evaluation framework, including the attack pipeline, is\naccessible at github.com/SonyResearch/wm_robustness_eval.", "published": "2025-05-26 08:21:58", "link": "http://arxiv.org/abs/2505.19663v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SACM: SEEG-Audio Contrastive Matching for Chinese Speech Decoding", "abstract": "Speech disorders such as dysarthria and anarthria can severely impair the\npatient's ability to communicate verbally. Speech decoding brain-computer\ninterfaces (BCIs) offer a potential alternative by directly translating speech\nintentions into spoken words, serving as speech neuroprostheses. This paper\nreports an experimental protocol for Mandarin Chinese speech decoding BCIs,\nalong with the corresponding decoding algorithms. Stereo-electroencephalography\n(SEEG) and synchronized audio data were collected from eight drug-resistant\nepilepsy patients as they conducted a word-level reading task. The proposed\nSEEG and Audio Contrastive Matching (SACM), a contrastive learning-based\nframework, achieved decoding accuracies significantly exceeding chance levels\nin both speech detection and speech decoding tasks. Electrode-wise analysis\nrevealed that a single sensorimotor cortex electrode achieved performance\ncomparable to that of the full electrode array. These findings provide valuable\ninsights for developing more accurate online speech decoding BCIs.", "published": "2025-05-26 08:11:01", "link": "http://arxiv.org/abs/2505.19652v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "STOPA: A Database of Systematic VariaTion Of DeePfake Audio for Open-Set Source Tracing and Attribution", "abstract": "A key research area in deepfake speech detection is source tracing -\ndetermining the origin of synthesised utterances. The approaches may involve\nidentifying the acoustic model (AM), vocoder model (VM), or other\ngeneration-specific parameters. However, progress is limited by the lack of a\ndedicated, systematically curated dataset. To address this, we introduce STOPA,\na systematically varied and metadata-rich dataset for deepfake speech source\ntracing, covering 8 AMs, 6 VMs, and diverse parameter settings across 700k\nsamples from 13 distinct synthesisers. Unlike existing datasets, which often\nfeature limited variation or sparse metadata, STOPA provides a systematically\ncontrolled framework covering a broader range of generative factors, such as\nthe choice of the vocoder model, acoustic model, or pretrained weights,\nensuring higher attribution reliability. This control improves attribution\naccuracy, aiding forensic analysis, deepfake detection, and generative model\ntransparency.", "published": "2025-05-26 08:00:30", "link": "http://arxiv.org/abs/2505.19644v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "eess.AS", "68T45, 68T10, 94A08", "I.2.7; I.5.4; K.4.1"], "primary_category": "cs.SD"}
{"title": "Decoding Speaker-Normalized Pitch from EEG for Mandarin Perception", "abstract": "The same speech content produced by different speakers exhibits significant\ndifferences in pitch contour, yet listeners' semantic perception remains\nunaffected. This phenomenon may stem from the brain's perception of pitch\ncontours being independent of individual speakers' pitch ranges. In this work,\nwe recorded electroencephalogram (EEG) while participants listened to Mandarin\nmonosyllables with varying tones, phonemes, and speakers. The CE-ViViT model is\nproposed to decode raw or speaker-normalized pitch contours directly from EEG.\nExperimental results demonstrate that the proposed model can decode pitch\ncontours with modest errors, achieving performance comparable to\nstate-of-the-art EEG regression methods. Moreover, speaker-normalized pitch\ncontours were decoded more accurately, supporting the neural encoding of\nrelative pitch.", "published": "2025-05-26 07:46:48", "link": "http://arxiv.org/abs/2505.19626v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Lightweight Hybrid Dual Channel Speech Enhancement System under Low-SNR Conditions", "abstract": "Although deep learning based multi-channel speech enhancement has achieved\nsignificant advancements, its practical deployment is often limited by\nconstrained computational resources, particularly in low signal-to-noise ratio\n(SNR) conditions. In this paper, we propose a lightweight hybrid dual-channel\nspeech enhancement system that combines independent vector analysis (IVA) with\na modified version of the dual-channel grouped temporal convolutional recurrent\nnetwork (GTCRN). IVA functions as a coarse estimator, providing auxiliary\ninformation for both speech and noise, while the modified GTCRN further refines\nthe speech quality. We investigate several modifications to ensure the\ncomprehensive utilization of both original and auxiliary information.\nExperimental results demonstrate the effectiveness of the proposed system,\nachieving enhanced speech with minimal parameters and low computational\ncomplexity.", "published": "2025-05-26 07:08:02", "link": "http://arxiv.org/abs/2505.19597v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Accelerating Diffusion-based Text-to-Speech Model Training with Dual Modality Alignment", "abstract": "The goal of this paper is to optimize the training process of diffusion-based\ntext-to-speech models. While recent studies have achieved remarkable\nadvancements, their training demands substantial time and computational costs,\nlargely due to the implicit guidance of diffusion models in learning complex\nintermediate representations. To address this, we propose A-DMA, an effective\nstrategy for Accelerating training with Dual Modality Alignment. Our method\nintroduces a novel alignment pipeline leveraging both text and speech\nmodalities: text-guided alignment, which incorporates contextual\nrepresentations, and speech-guided alignment, which refines semantic\nrepresentations. By aligning hidden states with discriminative features, our\ntraining scheme reduces the reliance on diffusion models for learning complex\nrepresentations. Extensive experiments demonstrate that A-DMA doubles the\nconvergence speed while achieving superior performance over baselines. Code and\ndemo samples are available at: https://github.com/ZhikangNiu/A-DMA", "published": "2025-05-26 07:07:16", "link": "http://arxiv.org/abs/2505.19595v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MFA-KWS: Effective Keyword Spotting with Multi-head Frame-asynchronous Decoding", "abstract": "Keyword spotting (KWS) is essential for voice-driven applications, demanding\nboth accuracy and efficiency. Traditional ASR-based KWS methods, such as greedy\nand beam search, explore the entire search space without explicitly\nprioritizing keyword detection, often leading to suboptimal performance. In\nthis paper, we propose an effective keyword-specific KWS framework by\nintroducing a streaming-oriented CTC-Transducer-combined frame-asynchronous\nsystem with multi-head frame-asynchronous decoding (MFA-KWS). Specifically,\nMFA-KWS employs keyword-specific phone-synchronous decoding for CTC and\nreplaces conventional RNN-T with Token-and-Duration Transducer to enhance both\nperformance and efficiency. Furthermore, we explore various score fusion\nstrategies, including single-frame-based and consistency-based methods.\nExtensive experiments demonstrate the superior performance of MFA-KWS, which\nachieves state-of-the-art results on both fixed keyword and arbitrary keywords\ndatasets, such as Snips, MobvoiHotwords, and LibriKWS-20, while exhibiting\nstrong robustness in noisy environments. Among fusion strategies, the\nconsistency-based CDC-Last method delivers the best performance. Additionally,\nMFA-KWS achieves a 47% to 63% speed-up over the frame-synchronous baselines\nacross various datasets. Extensive experimental results confirm that MFA-KWS is\nan effective and efficient KWS framework, making it well-suited for on-device\ndeployment.", "published": "2025-05-26 06:47:43", "link": "http://arxiv.org/abs/2505.19577v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mel-McNet: A Mel-Scale Framework for Online Multichannel Speech Enhancement", "abstract": "Online multichannel speech enhancement has been intensively studied recently.\nThough Mel-scale frequency is more matched with human auditory perception and\ncomputationally efficient than linear frequency, few works are implemented in a\nMel-frequency domain. To this end, this work proposes a Mel-scale framework\n(namely Mel-McNet). It processes spectral and spatial information with two key\ncomponents: an effective STFT-to-Mel module compressing multi-channel STFT\nfeatures into Mel-frequency representations, and a modified McNet backbone\ndirectly operating in the Mel domain to generate enhanced LogMel spectra. The\nspectra can be directly fed to vocoders for waveform reconstruction or ASR\nsystems for transcription. Experiments on CHiME-3 show that Mel-McNet can\nreduce computational complexity by 60% while maintaining comparable enhancement\nand ASR performance to the original McNet. Mel-McNet also outperforms other\nSOTA methods, verifying the potential of Mel-scale speech enhancement.", "published": "2025-05-26 06:47:30", "link": "http://arxiv.org/abs/2505.19576v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Training-Free Multi-Step Audio Source Separation", "abstract": "Audio source separation aims to separate a mixture into target sources.\nPrevious audio source separation systems usually conduct one-step inference,\nwhich does not fully explore the separation ability of models. In this work, we\nreveal that pretrained one-step audio source separation models can be leveraged\nfor multi-step separation without additional training. We propose a simple yet\neffective inference method that iteratively applies separation by optimally\nblending the input mixture with the previous step's separation result. At each\nstep, we determine the optimal blending ratio by maximizing a metric. We prove\nthat our method always yield improvement over one-step inference, provide error\nbounds based on model smoothness and metric robustness, and provide theoretical\nanalysis connecting our method to denoising along linear interpolation paths\nbetween noise and clean distributions, a property we link to denoising\ndiffusion bridge models. Our approach effectively delivers improved separation\nperformance as a \"free lunch\" from existing models. Our empirical results\ndemonstrate that our multi-step separation approach consistently outperforms\none-step inference across both speech enhancement and music source separation\ntasks, and can achieve scaling performance similar to training a larger model,\nusing more data, or in some cases employing a multi-step training objective.\nThese improvements appear not only on the optimization metric during multi-step\ninference, but also extend to nearly all non-optimized metrics (with one\nexception). We also discuss limitations of our approach and directions for\nfuture research.", "published": "2025-05-26 05:40:12", "link": "http://arxiv.org/abs/2505.19534v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimation", "abstract": "Acoustic echo cancellation (AEC) is an important speech signal processing\ntechnology that can remove echoes from microphone signals to enable\nnatural-sounding full-duplex speech communication. While single-channel AEC is\nwidely adopted, multi-channel AEC can leverage spatial cues afforded by\nmultiple microphones to achieve better performance. Existing multi-channel AEC\napproaches typically combine beamforming with deep neural networks (DNN). This\nwork proposes a two-stage algorithm that enhances multi-channel AEC by\nincorporating sound source directional cues. Specifically, a lightweight DNN is\nfirst trained to predict the sound source directions, and then the predicted\ndirectional information, multi-channel microphone signals, and single-channel\nfar-end signal are jointly fed into an AEC network to estimate the near-end\nsignal. Evaluation results show that the proposed algorithm outperforms\nbaseline approaches and exhibits robust generalization across diverse acoustic\nenvironments.", "published": "2025-05-26 04:22:45", "link": "http://arxiv.org/abs/2505.19493v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Room Impulse Response as a Prompt for Acoustic Echo Cancellation", "abstract": "Data-driven acoustic echo cancellation (AEC) methods, predominantly trained\non synthetic or constrained real-world datasets, encounter performance declines\nin unseen echo scenarios, especially in real environments where echo paths are\nnot directly observable. Our proposed method counters this limitation by\nintegrating room impulse response (RIR) as a pivotal training prompt, aiming to\nimprove the generalization of AEC models in such unforeseen conditions. We also\nexplore four RIR prompt fusion methods. Comprehensive evaluations, including\nboth simulated RIR under unknown conditions and recorded RIR in real,\ndemonstrate that the proposed approach significantly improves performance\ncompared to baseline models. These results substantiate the effectiveness of\nour RIR-guided approach in strengthening the model's generalization\ncapabilities.", "published": "2025-05-26 04:02:52", "link": "http://arxiv.org/abs/2505.19480v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FlowSE: Efficient and High-Quality Speech Enhancement via Flow Matching", "abstract": "Generative models have excelled in audio tasks using approaches such as\nlanguage models, diffusion, and flow matching. However, existing generative\napproaches for speech enhancement (SE) face notable challenges: language\nmodel-based methods suffer from quantization loss, leading to compromised\nspeaker similarity and intelligibility, while diffusion models require complex\ntraining and high inference latency. To address these challenges, we propose\nFlowSE, a flow-matching-based model for SE. Flow matching learns a continuous\ntransformation between noisy and clean speech distributions in a single pass,\nsignificantly reducing inference latency while maintaining high-quality\nreconstruction. Specifically, FlowSE trains on noisy mel spectrograms and\noptional character sequences, optimizing a conditional flow matching loss with\nground-truth mel spectrograms as supervision. It implicitly learns speech's\ntemporal-spectral structure and text-speech alignment. During inference, FlowSE\ncan operate with or without textual information, achieving impressive results\nin both scenarios, with further improvements when transcripts are available.\nExtensive experiments demonstrate that FlowSE significantly outperforms\nstate-of-the-art generative methods, establishing a new paradigm for\ngenerative-based SE and demonstrating the potential of flow matching to advance\nthe field. Our code, pre-trained checkpoints, and audio samples are available.", "published": "2025-05-26 03:55:00", "link": "http://arxiv.org/abs/2505.19476v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and Extrapolation", "abstract": "We present VoiceStar, the first zero-shot TTS model that achieves both output\nduration control and extrapolation. VoiceStar is an autoregressive\nencoder-decoder neural codec language model, that leverages a novel\nProgress-Monitoring Rotary Position Embedding (PM-RoPE) and is trained with\nContinuation-Prompt Mixed (CPM) training. PM-RoPE enables the model to better\nalign text and speech tokens, indicates the target duration for the generated\nspeech, and also allows the model to generate speech waveforms much longer in\nduration than those seen during. CPM training also helps to mitigate the\ntraining/inference mismatch, and significantly improves the quality of the\ngenerated speech in terms of speaker similarity and intelligibility. VoiceStar\noutperforms or is on par with current state-of-the-art models on short-form\nbenchmarks such as Librispeech and Seed-TTS, and significantly outperforms\nthese models on long-form/extrapolation benchmarks (20-50s) in terms of\nintelligibility and naturalness. Code and model weights:\nhttps://github.com/jasonppy/VoiceStar", "published": "2025-05-26 03:35:44", "link": "http://arxiv.org/abs/2505.19462v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Beyond Manual Transcripts: The Potential of Automated Speech Recognition Errors in Improving Alzheimer's Disease Detection", "abstract": "Recent breakthroughs in Automatic Speech Recognition (ASR) have enabled fully\nautomated Alzheimer's Disease (AD) detection using ASR transcripts.\nNonetheless, the impact of ASR errors on AD detection remains poorly\nunderstood. This paper fills the gap. We conduct a comprehensive study on AD\ndetection using transcripts from various ASR models and their synthesized\nspeech on the ADReSS dataset. Experimental results reveal that certain ASR\ntranscripts (ASR-synthesized speech) outperform manual transcripts\n(manual-synthesized speech) in detection accuracy, suggesting that ASR errors\nmay provide valuable cues for improving AD detection. Additionally, we propose\na cross-attention-based interpretability model that not only identifies these\ncues but also achieves superior or comparable performance to the baseline.\nFurthermore, we utilize this model to unveil AD-related patterns within\npre-trained embeddings. Our study offers novel insights into the potential of\nASR models for AD detection.", "published": "2025-05-26 03:15:25", "link": "http://arxiv.org/abs/2505.19448v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Leveraging Cascaded Binary Classification and Multimodal Fusion for Dementia Detection through Spontaneous Speech", "abstract": "This paper presents our submission to the PROCESS Challenge 2025, focusing on\nspontaneous speech analysis for early dementia detection. For the three-class\nclassification task (Healthy Control, Mild Cognitive Impairment, and Dementia),\nwe propose a cascaded binary classification framework that fine-tunes\npre-trained language models and incorporates pause encoding to better capture\ndisfluencies. This design streamlines multi-class classification and addresses\nclass imbalance by restructuring the decision process. For the Mini-Mental\nState Examination score regression task, we develop an enhanced multimodal\nfusion system that combines diverse acoustic and linguistic features. Separate\nregression models are trained on individual feature sets, with ensemble\nlearning applied through score averaging. Experimental results on the test set\noutperform the baselines provided by the organizers in both tasks,\ndemonstrating the robustness and effectiveness of our approach.", "published": "2025-05-26 03:08:55", "link": "http://arxiv.org/abs/2505.19446v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "RA-CLAP: Relation-Augmented Emotional Speaking Style Contrastive Language-Audio Pretraining For Speech Retrieval", "abstract": "The Contrastive Language-Audio Pretraining (CLAP) model has demonstrated\nexcellent performance in general audio description-related tasks, such as audio\nretrieval. However, in the emerging field of emotional speaking style\ndescription (ESSD), cross-modal contrastive pretraining remains largely\nunexplored. In this paper, we propose a novel speech retrieval task called\nemotional speaking style retrieval (ESSR), and ESS-CLAP, an emotional speaking\nstyle CLAP model tailored for learning relationship between speech and natural\nlanguage descriptions. In addition, we further propose relation-augmented CLAP\n(RA-CLAP) to address the limitation of traditional methods that assume a strict\nbinary relationship between caption and audio. The model leverages\nself-distillation to learn the potential local matching relationships between\nspeech and descriptions, thereby enhancing generalization ability. The\nexperimental results validate the effectiveness of RA-CLAP, providing valuable\nreference in ESSD.", "published": "2025-05-26 02:54:14", "link": "http://arxiv.org/abs/2505.19437v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stack Less, Repeat More: A Block Reusing Approach for Progressive Speech Enhancement", "abstract": "This paper presents an efficient speech enhancement (SE) approach that reuses\na processing block repeatedly instead of conventional stacking. Rather than\nincreasing the number of blocks for learning deep latent representations,\nrepeating a single block leads to progressive refinement while reducing\nparameter redundancy. We also minimize domain transformation by keeping an\nencoder and decoder shallow and reusing a single sequence modeling block.\nExperimental results show that the number of processing stages is more critical\nto performance than the number of blocks with different weights. Also, we\nobserved that the proposed method gradually refines a noisy input within a\nsingle block. Furthermore, with the block reuse method, we demonstrate that\ndeepening the encoder and decoder can be redundant for learning deep complex\nrepresentation. Therefore, the experimental results confirm that the proposed\nblock reusing enables progressive learning and provides an efficient\nalternative for SE.", "published": "2025-05-26 01:34:53", "link": "http://arxiv.org/abs/2505.19401v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "GSA-TTS : Toward Zero-Shot Speech Synthesis based on Gradual Style Adaptor", "abstract": "We present the gradual style adaptor TTS (GSA-TTS) with a novel style encoder\nthat gradually encodes speaking styles from an acoustic reference for zero-shot\nspeech synthesis. GSA first captures the local style of each semantic sound\nunit. Then the local styles are combined by self-attention to obtain a global\nstyle condition. This semantic and hierarchical encoding strategy provides a\nrobust and rich style representation for an acoustic model. We test GSA-TTS on\nunseen speakers and obtain promising results regarding naturalness, speaker\nsimilarity, and intelligibility. Additionally, we explore the potential of GSA\nin terms of interpretability and controllability, which stems from its\nhierarchical structure.", "published": "2025-05-26 00:58:16", "link": "http://arxiv.org/abs/2505.19384v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Identification of Power System Dynamic Model Parameters using the Fisher Information Matrix", "abstract": "The expected decrease in system inertia and frequency stability motivates the\ndevelopment and maintenance of dynamic system models by Transmission System\nOperators. However, some dynamic model parameters can be unavailable due to\nmarket unbundling, or inaccurate due to aging infrastructure, non-documented\ntuning of controllers, or other factors. In this paper, we propose the use of a\nnumerical approximation of the Fisher Information Matrix (nFIM) for efficient\ninference of dynamic model parameters. Thanks to the proposed numerical\nimplementation, the method is scalable to Electromagnetic Transient (EMT)\nmodels, which can quickly become computationally complex even for small study\nsystems. Case studies show that the nFIM is coherent with parameter variances\nof single- and multi-parameter least-squares estimators when applied to an IEEE\n9-bus dynamic model with artificial measurements.", "published": "2025-05-26 16:41:17", "link": "http://arxiv.org/abs/2505.20200v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On the Robustness of RSMA to Adversarial BD-RIS-Induced Interference", "abstract": "This article investigates the robustness of rate-splitting multiple access\n(RSMA) in multi-user multiple-input multiple-output (MIMO) systems to\ninterference attacks against channel acquisition induced by beyond-diagonal\nRISs (BD-RISs). Two primary attack strategies, random and aligned interference,\nare proposed for fully connected and group-connected BD-RIS architectures.\nValid random reflection coefficients are generated exploiting the Takagi\nfactorization, while potent aligned interference attacks are achieved through\noptimization strategies based on a quadratically constrained quadratic program\n(QCQP) reformulation followed by projections onto the unitary manifold. Our\nnumerical findings reveal that, when perfect channel state information (CSI) is\navailable, RSMA behaves similarly to space-division multiple access (SDMA) and\nthus is highly susceptible to the attack, with BD-RIS inducing severe\nperformance loss and significantly outperforming diagonal RIS. However, under\nimperfect CSI, RSMA consistently demonstrates significantly greater robustness\nthan SDMA, particularly as the system's transmit power increases.", "published": "2025-05-26 15:46:24", "link": "http://arxiv.org/abs/2505.20146v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "OFDMA for Pinching Antenna Systems", "abstract": "Pinching-antenna (PA) systems route millimeter wave (mmWave) signals through\na leaky waveguide and radiate them at \"pinch\" apertures, offering low-cost\nline-of-sight (LoS) coverage. However, when multiple PAs serve multiple users\nsimultaneously, the downlink channel becomes strongly frequency-selective,\ncreating inter-symbol interference (ISI) that existing single-carrier designs\noverlook. This paper models the overall channel as a finite impulse response\n(FIR) filter, characterizes its frequency selectivity, and explicitly accounts\nfor the resulting ISI. To overcome ISI, we introduce an orthogonal\nfrequency-division multiple access (OFDMA)-based framework and formulate a\nmax-min resource-allocation problem to achieve user fairness. A lightweight\ntwo-stage heuristic-greedy subcarrier assignment, followed by per-user\nwater-filling, achieves near-optimal fairness with polynomial complexity.\nSimulation results for an indoor layout demonstrate that the proposed scheme\nnotably increases the minimum user rate compared to time-division\nsingle-carrier baselines and remains robust under moderate LoS blockage.", "published": "2025-05-26 12:29:53", "link": "http://arxiv.org/abs/2505.19902v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Power allocation for cell-free MIMO integrated sensing and communication", "abstract": "In this paper, we investigate integrated sensing and communication (ISAC) in\na cell-free (CF) multiple-input multiple-output (MIMO) network with\nsingle-antenna access points (APs), where each AP functions either as a\ntransmitter for both sensing and communication or as a receiver for\ntarget-reflected signals. We derive closed-form Cramer-Rao lower bounds (CRLBs)\nfor location and velocity estimation under arbitrary power allocation ratios,\nassuming the radar cross-section (RCS) is deterministic and unknown over the\nobservation interval. A power allocation optimization problem is formulated to\nmaximize the communication signal-to-interference-plus-noise ratio (SINR),\nsubject to CRLB-based sensing constraints and per-transmitter power limits. To\nsolve the resulting nonlinear and non-convex problem, we propose a penalty\nfunction and projection-based modified conjugate gradient algorithm with\ninexact line search (PP-MCG-ILS), and an alternative method based on a modified\nsteepest descent approach (PP-MSD-ILS). Additionally, for power minimization in\npure sensing scenarios, we introduce a penalty function-based normalized\nconjugate gradient algorithm (P-NCG-ILS). We analyze the convergence behavior\nand qualitatively compare the computational complexity of the proposed\nalgorithms. Simulation results confirm the accuracy of the derived CRLBs and\ndemonstrate the effectiveness of the proposed power allocation strategies in\nenhancing both sensing and overall ISAC performance.", "published": "2025-05-26 11:30:19", "link": "http://arxiv.org/abs/2505.19845v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bit Error Rate and Performance Analysis of Multi-User OTFS under Nakagami-m Fading for 6G and Beyond Networks", "abstract": "Orthogonal Time-Frequency Space modulation stands out as a promising waveform\nfor 6G and beyond wireless communication systems, offering superior performance\nover conventional methods, particularly in high-mobility scenarios and\ndispersive channel conditions. Error performance analysis remains crucial for\naccurately characterizing the reliability of wireless communication systems\nunder practical constraints. In this paper, we systematically investigate the\nbit error rate performance of OTFS modulation over Nakagami-m fading channels\nin both single-user and multi-user scenarios. In analytical approaches,\nmathematical frameworks are employed for distinct receiver configurations: the\nSingle-input Single-output scenario leverages Erlang probability density\nfunction of squared-Nakagami variables to derive closed-form BER expressions,\nwhile the Single-input Multiple-output case applies moment matching techniques\nwith Gamma approximation to model multiple user interference, subsequently\nyielding Signal-to-interference-plus-noise Ratio characterizations through\nMeijer-G functions. This study examines single-path and multi-path channel\nconditions, evaluating the relationship between path multiplicity and error\nperformance metrics while considering various fading intensities through\nNakagami-m fading parameters. The derived closed-form BER expressions are\nvalidated through maximum likelihood detection based Monte Carlo simulations,\ndemonstrating strong correlation between analytical and numerical results\nacross various SNR regions. Furthermore, comparative benchmark evaluations\nagainst conventional orthogonal frequency division multiplexing with MLD reveal\nthat OTFS consistently achieves superior error performance in high-mobility\nscenarios. In multipath fading environments, OTFS achieves superior diversity\ngain compared to conventional OFDM, which refers to enhanced error performance.", "published": "2025-05-26 11:27:09", "link": "http://arxiv.org/abs/2505.19843v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Accurate Radar-Based Detection of Sleep Apnea Using Overlapping Time-Interval Averaging", "abstract": "Radar-based respiratory measurement is a promising tool for the noncontact\ndetection of sleep apnea. Our team has reported that apnea events can be\naccurately detected using the statistical characteristics of the amplitude of\nrespiratory displacement. However, apnea and hypopnea events are often followed\nby irregular breathing, reducing the detection accuracy. This study proposes a\nnew method to overcome this performance degradation by repeatedly applying the\ndetection method to radar data sets corresponding to multiple overlapping time\nintervals. Averaging the detected classes over multiple time intervals gives an\nanalog value between 0 and 1, which can be interpreted as the probability that\nthere is an apnea event. We show that the proposed method can mitigate the\neffect of irregular breathing that occurs after apnea / hypopnea events, and\nits performance is confirmed by experimental data taken from seven patients.", "published": "2025-05-26 08:53:54", "link": "http://arxiv.org/abs/2505.19701v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Customising Electricity Contracts at Scale with Large Language Models", "abstract": "The electricity system becomes more complex, connecting massive numbers of\nend-users and distributed generators. Adding or removing grid connections\nrequires expert studies to align technical constraints with user requests. In\ntimes of labour shortages, carrying out these studies represents a significant\namount of time that engineers at system operators spend in planning\ndepartments. As time is limited, only standard block connectivity contracts can\nbe offered to end-users, or the requests pile up. Even if offers are made,\nthese often do not perfectly match the user's requirements, leading to\noverpaying or underusing the grid capacity. This paper investigates whether\nend-users can negotiate individual, flexible time-of-use contracts directly\nwith the grid using Large Language Models (LLM) in chats at scale. The\nLLM-based chat has direct access to a model of the grid and studies the grid's\ntechnical constraints just as an expert engineer. The advantage of this system\nis that end-users can directly interact with grid models through natural\nlanguage; no intermediate is needed to service, analyse, study, assess, advise,\nconsult and engineer. This initial study paves the way toward developing this\ntailored LLM system, resulting in possible high-efficiency gains for grid\nplanning and customer management.", "published": "2025-05-26 06:14:09", "link": "http://arxiv.org/abs/2505.19551v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Water Level Sensing via Communication Signals in a Bi-Static System", "abstract": "Accurate water level sensing is essential for flood monitoring, agricultural\nirrigation, and water resource optimization. Traditional methods require\ndedicated sensor deployments, leading to high installation costs, vulnerability\nto interference, and limited resolution. This work proposes PMNs-WaterSense, a\nnovel scheme leveraging Channel State Information (CSI) from existing mobile\nnetworks for water level sensing. Our scheme begins with a CSI-power method to\neliminate phase offsets caused by clock asynchrony in bi-static systems. We\nthen apply multi-domain filtering across the time (Doppler), frequency (delay),\nand spatial (Angle-of-Arrival, AoA) domains to extract phase features that\nfinely capture variations in path length over water. To resolve the $2\\pi$\nphase ambiguity, we introduce a Kalman filter-based unwrapping technique.\nAdditionally, we exploit transceiver geometry to convert path length variations\ninto water level height changes, even with limited antenna configurations. We\nvalidate our framework through controlled experiments with 28 GHz mmWave and\n3.1 GHz LTE signals in real time, achieving average height estimation errors of\n0.025 cm and 0.198 cm, respectively. Moreover, real-world river monitoring with\n2.6 GHz LTE signals achieves an average error of 4.8 cm for a 1-meter water\nlevel change, demonstrating its effectiveness in practical deployments.", "published": "2025-05-26 05:57:45", "link": "http://arxiv.org/abs/2505.19539v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Empirical 3D Channel Modeling for Cellular-Connected UAVs: A Triple-Layer Machine Learning Approach", "abstract": "This work proposes an empirical air to ground (A2G) propagation model\nspecifically designed for cellular connected unmanned aerial vehicles (UAVs).\nAn in depth aerial drive test was carried out within an operating Long Term\nEvolution (LTE) network, gathering thorough measurements of key network\nparameters. Rigid preprocessing and statistical analysis of these data produced\na strong foundation for training a new triple layer machine learning (ML)\nmodel. The proposed ML framework employs a systematic hierarchical approach.\nAccordingly, the first two layers, Stepwise Linear Regression (STW) and\nEnsemble of Bagged Trees (EBT) generate predictions independently, meanwhile,\nthe third layer, Gaussian Process Regression (GPR), explicitly acts as an\naggregation layer, refining these predictions to accurately estimate Key\nPerformance Indicators (KPIs) such as Reference Signal Received Power (RSRP),\nReference Signal Received Quality (RSRQ), Received Signal Strength (RSSI), and\nPath Loss (PL). Compared to traditional single layer ML or computationally\nintensive ray tracing approaches, the proposed triple layer ML framework\nsignificantly improves predictive accuracy and robustness, achieving around 99\npercent accuracy in training and above 90 percent in testing while utilizing a\nminimal but effective feature set log transformed 3D and 2D propagation\ndistances, azimuth, and elevation angles. This streamlined feature selection\nsubstantially reduces computing complexity, thus enhancing scalability across\nvarious operating environments. The proposed frameworks practicality and\nefficacy for real world deployment in UAV integrated cellular networks are\nfurther demonstrated by comparative analyses, which underscore its substantial\nimprovement.", "published": "2025-05-26 04:01:01", "link": "http://arxiv.org/abs/2505.19478v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Foundation Model for Wireless Technology Recognition Using IQ Timeseries", "abstract": "Wireless Technology Recognition (WTR) is essential in modern communication\nsystems, enabling efficient spectrum management and the seamless coexistence of\ndiverse technologies. In real-world conditions, WTR solutions should be able to\nhandle signals from various resources with different sampling rates, capturing\ndevices, and frequency bands. However, traditional WTR methods, which rely on\nenergy detection, Convolutional Neural Network (CNN) models, or Deep Learning\n(DL), lack the robustness and adaptability required to generalize across unseen\nenvironments, different sampling devices, and previously unencountered signal\nclasses. In this work, we introduce a Transformer-based foundation model for\nWTR, trained in an unsupervised manner on large-scale, unlabeled wireless\nsignal datasets. Foundation models are designed to learn general-purpose\nrepresentations that transfer effectively across tasks and domains, allowing\ngeneralization towards new technologies and WTR sampling devices. Our approach\nleverages input patching for computational efficiency and incorporates a\ntwo-stage training pipeline: unsupervised pre-training followed by lightweight\nfine-tuning. This enables the model to generalize to new wireless technologies\nand environments using only a small number of labeled samples. Experimental\nresults demonstrate that our model achieves superior accuracy across varying\nsampling rates and frequency bands while maintaining low computational\ncomplexity, supporting the vision of a reusable wireless foundation model\nadaptable to new technologies with minimal retraining.", "published": "2025-05-26 01:12:34", "link": "http://arxiv.org/abs/2505.19390v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs", "abstract": "Large Language Models (LLMs) deliver state-of-the-art capabilities across\nnumerous tasks, but their immense size and inference costs pose significant\ncomputational challenges for practical deployment. While structured pruning\noffers a promising avenue for model compression, existing methods often\nstruggle with the detrimental effects of aggressive, simultaneous width and\ndepth reductions, leading to substantial performance degradation. This paper\nargues that a critical, often overlooked, aspect in making such aggressive\njoint pruning viable is the strategic re-initialization and adjustment of\nremaining weights to improve the model post-pruning training accuracies. We\nintroduce Pangu Light, a framework for LLM acceleration centered around\nstructured pruning coupled with novel weight re-initialization techniques\ndesigned to address this ``missing piece''. Our framework systematically\ntargets multiple axes, including model width, depth, attention heads, and\nRMSNorm, with its effectiveness rooted in novel re-initialization methods like\nCross-Layer Attention Pruning (CLAP) and Stabilized LayerNorm Pruning (SLNP)\nthat mitigate performance drops by providing the network a better training\nstarting point. Further enhancing efficiency, Pangu Light incorporates\nspecialized optimizations such as absorbing Post-RMSNorm computations and\ntailors its strategies to Ascend NPU characteristics. The Pangu Light models\nconsistently exhibit a superior accuracy-efficiency trade-off, outperforming\nprominent baseline pruning methods like Nemotron and established LLMs like\nQwen3 series. For instance, on Ascend NPUs, Pangu Light-32B's 81.6 average\nscore and 2585 tokens/s throughput exceed Qwen3-32B's 80.9 average score and\n2225 tokens/s.", "published": "2025-05-26 15:57:08", "link": "http://arxiv.org/abs/2505.20155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models", "abstract": "This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA),\na novel parameter-efficient fine-tuning (PEFT) approach for Large Language\nModels (LLMs). UORA achieves state-of-the-art performance and parameter\nefficiency by leveraging a low-rank approximation method to reduce the number\nof trainable parameters. Unlike existing methods such as LoRA and VeRA, UORA\nemploys an interpolation-based reparametrization mechanism that selectively\nreinitializes rows and columns in frozen projection matrices, guided by the\nvector magnitude heuristic. This results in substantially fewer trainable\nparameters compared to LoRA and outperforms VeRA in computation and storage\nefficiency. Comprehensive experiments across various benchmarks demonstrate\nUORA's superiority in achieving competitive fine-tuning performance with\nnegligible computational overhead. We demonstrate its performance on GLUE and\nE2E benchmarks and its effectiveness in instruction-tuning large language\nmodels and image classification models. Our contributions establish a new\nparadigm for scalable and resource-efficient fine-tuning of LLMs.", "published": "2025-05-26 15:56:40", "link": "http://arxiv.org/abs/2505.20154v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applications and Effect Evaluation of Generative Adversarial Networks in Semi-Supervised Learning", "abstract": "In recent years, image classification, as a core task in computer vision,\nrelies on high-quality labelled data, which restricts the wide application of\ndeep learning models in practical scenarios. To alleviate the problem of\ninsufficient labelled samples, semi-supervised learning has gradually become a\nresearch hotspot. In this paper, we construct a semi-supervised image\nclassification model based on Generative Adversarial Networks (GANs), and\nthrough the introduction of the collaborative training mechanism of generators,\ndiscriminators and classifiers, we achieve the effective use of limited\nlabelled data and a large amount of unlabelled data, improve the quality of\nimage generation and classification accuracy, and provide an effective solution\nfor the task of image recognition in complex environments.", "published": "2025-05-26 05:08:16", "link": "http://arxiv.org/abs/2505.19522v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Regularized Personalization of Text-to-Image Diffusion Models without Distributional Drift", "abstract": "Personalization using text-to-image diffusion models involves adapting a\npretrained model to novel subjects with only a few image examples. This task\npresents a fundamental challenge, as the model must not only learn the new\nsubject effectively but also preserve its ability to generate diverse and\ncoherent outputs across a wide range of prompts. In other words, successful\npersonalization requires integrating new concepts without forgetting previously\nlearned generative capabilities. Forgetting denotes unintended distributional\ndrift, where the model's output distribution deviates from that of the original\npretrained model. In this paper, we provide an analysis of this issue and\nidentify a mismatch between standard training objectives and the goals of\npersonalization. To address this, we propose a new training objective based on\na Lipschitz-bounded formulation that explicitly constrains deviation from the\npretrained distribution. Our method provides improved control over\ndistributional drift and performs well even in data-scarce scenarios.\nExperimental results demonstrate that our approach consistently outperforms\nexisting personalization methods, achieving higher CLIP-T, CLIP-I, and DINO\nscores.", "published": "2025-05-26 05:03:59", "link": "http://arxiv.org/abs/2505.19519v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions", "abstract": "Intra-operative data captured during image-guided surgery lacks sub-surface\ninformation, where key regions of interest, such as vessels and tumors, reside.\nImage-to-physical registration enables the fusion of pre-operative information\nand intra-operative data, typically represented as a point cloud. However, this\nregistration process struggles due to partial visibility of the intra-operative\npoint cloud. In this research, we propose a patient-specific point cloud\ncompletion approach to assist with the registration process. Specifically, we\nleverage VN-OccNet to generate a complete liver surface from a partial\nintra-operative point cloud. The network is trained in a patient-specific\nmanner, where simulated deformations from the pre-operative model are used to\ntrain the model. First, we conduct an in-depth analysis of VN-OccNet's\nrotation-equivariant property and its effectiveness in recovering complete\nsurfaces from partial intra-operative surfaces. Next, we integrate the\ncompleted intra-operative surface into the Go-ICP registration algorithm to\ndemonstrate its utility in improving initial rigid registration outcomes. Our\nresults highlight the promise of this patient-specific completion approach in\nmitigating the challenges posed by partial intra-operative visibility. The\nrotation equivariant and surface generation capabilities of VN-OccNet hold\nstrong promise for developing robust registration frameworks for variations of\nthe intra-operative point cloud.", "published": "2025-05-26 05:03:01", "link": "http://arxiv.org/abs/2505.19518v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Machine Translation with Visual Scene Graph Pruning", "abstract": "Multimodal machine translation (MMT) seeks to address the challenges posed by\nlinguistic polysemy and ambiguity in translation tasks by incorporating visual\ninformation. A key bottleneck in current MMT research is the effective\nutilization of visual data. Previous approaches have focused on extracting\nglobal or region-level image features and using attention or gating mechanisms\nfor multimodal information fusion. However, these methods have not adequately\ntackled the issue of visual information redundancy in MMT, nor have they\nproposed effective solutions. In this paper, we introduce a novel\napproach--multimodal machine translation with visual Scene Graph Pruning (PSG),\nwhich leverages language scene graph information to guide the pruning of\nredundant nodes in visual scene graphs, thereby reducing noise in downstream\ntranslation tasks. Through extensive comparative experiments with\nstate-of-the-art methods and ablation studies, we demonstrate the effectiveness\nof the PSG model. Our results also highlight the promising potential of visual\ninformation pruning in advancing the field of MMT.", "published": "2025-05-26 04:35:03", "link": "http://arxiv.org/abs/2505.19507v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Unfolding AlphaFold's Bayesian Roots in Probability Kinematics", "abstract": "We present a novel theoretical interpretation of AlphaFold1. The seminal\nbreakthrough of AlphaFold1 in protein structure prediction by deep learning\nrelied on a learned potential energy function, in contrast to the later\nend-to-end architectures of AlphaFold2 and AlphaFold3. While this potential was\noriginally justified by referring to physical potentials of mean force (PMFs),\nwe reinterpret AlphaFold1's potential as an instance of probability kinematics\n- also known as Jeffrey conditioning - a principled but underrecognised\ngeneralization of conventional Bayesian updating. Probability kinematics\naccommodates uncertain or soft evidence in the form of updated probabilities\nover a partition. This perspective reveals AlphaFold1's potential as a form of\ngeneralized Bayesian updating, rather than a thermodynamic potential. To\nconfirm our probabilistic framework's scope and precision, we analyze a\nsynthetic 2D model in which an angular random walk prior is updated with\nevidence on distances via probability kinematics, mirroring AlphaFold1's\napproach. This theoretical contribution connects AlphaFold1 to a broader class\nof well-justified Bayesian methods, allowing precise quantification, surpassing\nmerely qualitative heuristics based on PMFs. More broadly, given the\nachievements of AlphaFold1, probability kinematics holds considerable promise\nfor probabilistic deep learning, as it allows for the formulation of complex\nmodels from a few simpler components.", "published": "2025-05-26 09:46:07", "link": "http://arxiv.org/abs/2505.19763v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Machine Learning Algorithm for Noise Reduction and Disease-Causing Gene Feature Extraction in Gene Sequencing Data", "abstract": "In this study, we propose a machine learning-based method for noise reduction\nand disease-causing gene feature extraction in gene sequencing DeepSeqDenoise\nalgorithm combines CNN and RNN to effectively remove the sequencing noise, and\nimproves the signal-to-noise ratio by 9.4 dB. We screened 17 key features by\nfeature engineering, and constructed an integrated learning model to predict\ndisease-causing genes with 94.3% accuracy. We successfully identified 57 new\ncandidate disease-causing genes in a cardiovascular disease cohort validation,\nand detected 3 missed variants in clinical applications. The method\nsignificantly outperforms existing tools and provides strong support for\naccurate diagnosis of genetic diseases.", "published": "2025-05-26 09:23:09", "link": "http://arxiv.org/abs/2505.19740v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Structured Tour of Optimization with Finite Differences", "abstract": "Finite-difference methods are widely used for zeroth-order optimization in\nsettings where gradient information is unavailable or expensive to compute.\nThese procedures mimic first-order strategies by approximating gradients\nthrough function evaluations along a set of random directions. From a\ntheoretical perspective, recent studies indicate that imposing structure (such\nas orthogonality) on the chosen directions allows for the derivation of\nconvergence rates comparable to those achieved with unstructured random\ndirections (i.e., directions sampled independently from a distribution).\nEmpirically, although structured directions are expected to enhance\nperformance, they often introduce additional computational costs, which can\nlimit their applicability in high-dimensional settings. In this work, we\nexamine the impact of structured direction selection in finite-difference\nmethods. We review and extend several strategies for constructing structured\ndirection matrices and compare them with unstructured approaches in terms of\ncomputational cost, gradient approximation quality, and convergence behavior.\nOur evaluation spans both synthetic tasks and real-world applications such as\nadversarial perturbation. The results demonstrate that structured directions\ncan be generated with computational costs comparable to unstructured ones while\nsignificantly improving gradient estimation accuracy and optimization\nperformance.", "published": "2025-05-26 09:08:46", "link": "http://arxiv.org/abs/2505.19720v1", "categories": ["math.OC", "cs.LG", "90C56 (Primary) 90C25, 90C26 (Secondary)", "G.1.6"], "primary_category": "math.OC"}
{"title": "Graph Guided Diffusion: Unified Guidance for Conditional Graph Generation", "abstract": "Diffusion models have emerged as powerful generative models for graph\ngeneration, yet their use for conditional graph generation remains a\nfundamental challenge. In particular, guiding diffusion models on graphs under\narbitrary reward signals is difficult: gradient-based methods, while powerful,\nare often unsuitable due to the discrete and combinatorial nature of graphs,\nand non-differentiable rewards further complicate gradient-based guidance. We\npropose Graph Guided Diffusion (GGDiff), a novel guidance framework that\ninterprets conditional diffusion on graphs as a stochastic control problem to\naddress this challenge. GGDiff unifies multiple guidance strategies, including\ngradient-based guidance (for differentiable rewards), control-based guidance\n(using control signals from forward reward evaluations), and zero-order\napproximations (bridging gradient-based and gradient-free optimization). This\ncomprehensive, plug-and-play framework enables zero-shot guidance of\npre-trained diffusion models under both differentiable and non-differentiable\nreward functions, adapting well-established guidance techniques to graph\ngeneration--a direction largely unexplored. Our formulation balances\ncomputational efficiency, reward alignment, and sample quality, enabling\npractical conditional generation across diverse reward types. We demonstrate\nthe efficacy of GGDiff in various tasks, including constraints on graph motifs,\nfairness, and link prediction, achieving superior alignment with target rewards\nwhile maintaining diversity and fidelity.", "published": "2025-05-26 08:45:22", "link": "http://arxiv.org/abs/2505.19685v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Actor-Critics with Tight Risk Certificates", "abstract": "After a period of research, deep actor-critic algorithms have reached a level\nwhere they influence our everyday lives. They serve as the driving force behind\nthe continual improvement of large language models through user-collected\nfeedback. However, their deployment in physical systems is not yet widely\nadopted, mainly because no validation scheme that quantifies their risk of\nmalfunction. We demonstrate that it is possible to develop tight risk\ncertificates for deep actor-critic algorithms that predict generalization\nperformance from validation-time observations. Our key insight centers on the\neffectiveness of minimal evaluation data. Surprisingly, a small feasible of\nevaluation roll-outs collected from a pretrained policy suffices to produce\naccurate risk certificates when combined with a simple adaptation of PAC-Bayes\ntheory. Specifically, we adopt a recently introduced recursive PAC-Bayes\napproach, which splits validation data into portions and recursively builds\nPAC-Bayes bounds on the excess loss of each portion's predictor, using the\npredictor from the previous portion as a data-informed prior. Our empirical\nresults across multiple locomotion tasks and policy expertise levels\ndemonstrate risk certificates that are tight enough to be considered for\npractical use.", "published": "2025-05-26 08:42:53", "link": "http://arxiv.org/abs/2505.19682v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cut out and Replay: A Simple yet Versatile Strategy for Multi-Label Online Continual Learning", "abstract": "Multi-Label Online Continual Learning (MOCL) requires models to learn\ncontinuously from endless multi-label data streams, facing complex challenges\nincluding persistent catastrophic forgetting, potential missing labels, and\nuncontrollable imbalanced class distributions. While existing MOCL methods\nattempt to address these challenges through various techniques, \\textit{they\nall overlook label-specific region identifying and feature learning} - a\nfundamental solution rooted in multi-label learning but challenging to achieve\nin the online setting with incremental and partial supervision. To this end, we\nfirst leverage the inherent structural information of input data to evaluate\nand verify the innate localization capability of different pre-trained models.\nThen, we propose CUTER (CUT-out-and-Experience-Replay), a simple yet versatile\nstrategy that provides fine-grained supervision signals by further identifying,\nstrengthening and cutting out label-specific regions for efficient experience\nreplay. It not only enables models to simultaneously address catastrophic\nforgetting, missing labels, and class imbalance challenges, but also serves as\nan orthogonal solution that seamlessly integrates with existing approaches.\nExtensive experiments on multiple multi-label image benchmarks demonstrate the\nsuperiority of our proposed method. The code is available at\n\\href{https://github.com/wxr99/Cut-Replay}{https://github.com/wxr99/Cut-Replay}", "published": "2025-05-26 08:40:31", "link": "http://arxiv.org/abs/2505.19680v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Streaming Text to Speech Synthesis with Transducer and Auto-Regressive Modeling", "abstract": "Zero-shot streaming text-to-speech is an important research topic in\nhuman-computer interaction. Existing methods primarily use a lookahead\nmechanism, relying on future text to achieve natural streaming speech\nsynthesis, which introduces high processing latency. To address this issue, we\npropose SMLLE, a streaming framework for generating high-quality speech\nframe-by-frame. SMLLE employs a Transducer to convert text into semantic tokens\nin real time while simultaneously obtaining duration alignment information. The\ncombined outputs are then fed into a fully autoregressive (AR) streaming model\nto reconstruct mel-spectrograms. To further stabilize the generation process,\nwe design a Delete < Bos > Mechanism that allows the AR model to access future\ntext introducing as minimal delay as possible. Experimental results suggest\nthat the SMLLE outperforms current streaming TTS methods and achieves\ncomparable performance over sentence-level TTS systems. Samples are available\non https://anonymous.4open.science/w/demo_page-48B7/.", "published": "2025-05-26 08:25:01", "link": "http://arxiv.org/abs/2505.19669v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Energy-based generator matching: A neural sampler for general state space", "abstract": "We propose Energy-based generator matching (EGM), a modality-agnostic\napproach to train generative models from energy functions in the absence of\ndata. Extending the recently proposed generator matching, EGM enables training\nof arbitrary continuous-time Markov processes, e.g., diffusion, flow, and jump,\nand can generate data from continuous, discrete, and a mixture of two\nmodalities. To this end, we propose estimating the generator matching loss\nusing self-normalized importance sampling with an additional bootstrapping\ntrick to reduce variance in the importance weight. We validate EGM on both\ndiscrete and multimodal tasks up to 100 and 20 dimensions, respectively.", "published": "2025-05-26 08:02:29", "link": "http://arxiv.org/abs/2505.19646v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing", "abstract": "Recent advances in retrieval-augmented generation (RAG) furnish large\nlanguage models (LLMs) with iterative retrievals of relevant information to\nhandle complex multi-hop questions. These methods typically alternate between\nLLM reasoning and retrieval to accumulate external information into the LLM's\ncontext. However, the ever-growing context inherently imposes an increasing\nburden on the LLM to perceive connections among critical information pieces,\nwith futile reasoning steps further exacerbating this overload issue. In this\npaper, we present KnowTrace, an elegant RAG framework to (1) mitigate the\ncontext overload and (2) bootstrap higher-quality multi-step reasoning. Instead\nof simply piling the retrieved contents, KnowTrace autonomously traces out\ndesired knowledge triplets to organize a specific knowledge graph relevant to\nthe input question. Such a structured workflow not only empowers the LLM with\nan intelligible context for inference, but also naturally inspires a reflective\nmechanism of knowledge backtracing to identify contributive LLM generations as\nprocess supervision data for self-bootstrapping. Extensive experiments show\nthat KnowTrace consistently surpasses existing methods across three multi-hop\nquestion answering benchmarks, and the bootstrapped version further amplifies\nthe gains.", "published": "2025-05-26 17:22:20", "link": "http://arxiv.org/abs/2505.20245v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent", "abstract": "Recent advances in large language models (LLMs) have led to remarkable\nprogress across domains, yet their capabilities in the humanities, particularly\nhistory, remain underexplored. Historical reasoning poses unique challenges for\nAI, involving multimodal source interpretation, temporal inference, and\ncross-linguistic analysis. While general-purpose agents perform well on many\nexisting benchmarks, they lack the domain-specific expertise required to engage\nwith historical materials and questions. To address this gap, we introduce\nHistBench, a new benchmark of 414 high-quality questions designed to evaluate\nAI's capacity for historical reasoning and authored by more than 40 expert\ncontributors. The tasks span a wide range of historical problems-from factual\nretrieval based on primary sources to interpretive analysis of manuscripts and\nimages, to interdisciplinary challenges involving archaeology, linguistics, or\ncultural history. Furthermore, the benchmark dataset spans 29 ancient and\nmodern languages and covers a wide range of historical periods and world\nregions. Finding the poor performance of LLMs and other agents on HistBench, we\nfurther present HistAgent, a history-specific agent equipped with carefully\ndesigned tools for OCR, translation, archival search, and image understanding\nin History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of\n27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online\nsearch and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%)\nand Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These\nresults highlight the limitations of existing LLMs and generalist agents and\ndemonstrate the advantages of HistAgent for historical reasoning.", "published": "2025-05-26 17:22:20", "link": "http://arxiv.org/abs/2505.20246v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Bridging the Long-Term Gap: A Memory-Active Policy for Multi-Session Task-Oriented Dialogue", "abstract": "Existing Task-Oriented Dialogue (TOD) systems primarily focus on\nsingle-session dialogues, limiting their effectiveness in long-term memory\naugmentation. To address this challenge, we introduce a MS-TOD dataset, the\nfirst multi-session TOD dataset designed to retain long-term memory across\nsessions, enabling fewer turns and more efficient task completion. This defines\na new benchmark task for evaluating long-term memory in multi-session TOD.\nBased on this new dataset, we propose a Memory-Active Policy (MAP) that\nimproves multi-session dialogue efficiency through a two-stage approach. 1)\nMemory-Guided Dialogue Planning retrieves intent-aligned history, identifies\nkey QA units via a memory judger, refines them by removing redundant questions,\nand generates responses based on the reconstructed memory. 2) Proactive\nResponse Strategy detects and correct errors or omissions, ensuring efficient\nand accurate task completion. We evaluate MAP on MS-TOD dataset, focusing on\nresponse quality and effectiveness of the proactive strategy. Experiments on\nMS-TOD demonstrate that MAP significantly improves task success and turn\nefficiency in multi-session scenarios, while maintaining competitive\nperformance on conventional single-session tasks.", "published": "2025-05-26 17:10:43", "link": "http://arxiv.org/abs/2505.20231v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency Parsing is More Parameter-Efficient with Normalization", "abstract": "Dependency parsing is the task of inferring natural language structure, often\napproached by modeling word interactions via attention through biaffine\nscoring. This mechanism works like self-attention in Transformers, where scores\nare calculated for every pair of words in a sentence. However, unlike\nTransformer attention, biaffine scoring does not use normalization prior to\ntaking the softmax of the scores. In this paper, we provide theoretical\nevidence and empirical results revealing that a lack of normalization\nnecessarily results in overparameterized parser models, where the extra\nparameters compensate for the sharp softmax outputs produced by high variance\ninputs to the biaffine scoring function. We argue that biaffine scoring can be\nmade substantially more efficient by performing score normalization. We conduct\nexperiments on six datasets for semantic and syntactic dependency parsing using\na one-hop parser. We train N-layer stacked BiLSTMs and evaluate the parser's\nperformance with and without normalizing biaffine scores. Normalizing allows us\nto beat the state of the art on two datasets, with fewer samples and trainable\nparameters. Code: https://anonymous.4open.science/r/EfficientSDP-70C1", "published": "2025-05-26 16:56:07", "link": "http://arxiv.org/abs/2505.20215v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Improve the Robustness of Closed-Source Models on NLI", "abstract": "Closed-source Large Language Models (LLMs) have become increasingly popular,\nwith impressive performance across a wide range of natural language tasks.\nThese models can be fine-tuned to further improve performance, but this often\nresults in the models learning from dataset-specific heuristics that reduce\ntheir robustness on out-of-distribution (OOD) data. Existing methods to improve\nrobustness either perform poorly, or are non-applicable to closed-source models\nbecause they assume access to model internals, or the ability to change the\nmodel's training procedure. In this work, we investigate strategies to improve\nthe robustness of closed-source LLMs through data-centric methods that do not\nrequire access to model internals. We find that the optimal strategy depends on\nthe complexity of the OOD data. For highly complex OOD datasets, upsampling\nmore challenging training examples can improve robustness by up to 1.5%. For\nless complex OOD datasets, replacing a portion of the training set with\nLLM-generated examples can improve robustness by 3.7%. More broadly, we find\nthat large-scale closed-source autoregressive LLMs are substantially more\nrobust than commonly used encoder models, and are a more appropriate choice of\nbaseline going forward.", "published": "2025-05-26 16:49:31", "link": "http://arxiv.org/abs/2505.20209v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations", "abstract": "Limited access to mental healthcare, extended wait times, and increasing\ncapabilities of Large Language Models (LLMs) has led individuals to turn to\nLLMs for fulfilling their mental health needs. However, examining the\nmulti-turn mental health conversation capabilities of LLMs remains\nunder-explored. Existing evaluation frameworks typically focus on diagnostic\naccuracy and win-rates and often overlook alignment with patient-specific\ngoals, values, and personalities required for meaningful conversations. To\naddress this, we introduce MedAgent, a novel framework for synthetically\ngenerating realistic, multi-turn mental health sensemaking conversations and\nuse it to create the Mental Health Sensemaking Dialogue (MHSD) dataset,\ncomprising over 2,200 patient-LLM conversations. Additionally, we present\nMultiSenseEval, a holistic framework to evaluate the multi-turn conversation\nabilities of LLMs in healthcare settings using human-centric criteria. Our\nfindings reveal that frontier reasoning models yield below-par performance for\npatient-centric communication and struggle at advanced diagnostic capabilities\nwith average score of 31%. Additionally, we observed variation in model\nperformance based on patient's persona and performance drop with increasing\nturns in the conversation. Our work provides a comprehensive synthetic data\ngeneration framework, a dataset and evaluation framework for assessing LLMs in\nmulti-turn mental health conversations.", "published": "2025-05-26 16:42:02", "link": "http://arxiv.org/abs/2505.20201v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking", "abstract": "Classifier-Free Guidance (CFG) significantly enhances controllability in\ngenerative models by interpolating conditional and unconditional predictions.\nHowever, standard CFG often employs a static unconditional input, which can be\nsuboptimal for iterative generation processes where model uncertainty varies\ndynamically. We introduce Adaptive Classifier-Free Guidance (A-CFG), a novel\nmethod that tailors the unconditional input by leveraging the model's\ninstantaneous predictive confidence. At each step of an iterative (masked)\ndiffusion language model, A-CFG identifies tokens in the currently generated\nsequence for which the model exhibits low confidence. These tokens are\ntemporarily re-masked to create a dynamic, localized unconditional input. This\nfocuses CFG's corrective influence precisely on areas of ambiguity, leading to\nmore effective guidance. We integrate A-CFG into a state-of-the-art masked\ndiffusion language model and demonstrate its efficacy. Experiments on diverse\nlanguage generation benchmarks show that A-CFG yields substantial improvements\nover standard CFG, achieving, for instance, a 3.9 point gain on GPQA. Our work\nhighlights the benefit of dynamically adapting guidance mechanisms to model\nuncertainty in iterative generation.", "published": "2025-05-26 16:40:22", "link": "http://arxiv.org/abs/2505.20199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monocle: Hybrid Local-Global In-Context Evaluation for Long-Text Generation with Uncertainty-Based Active Learning", "abstract": "Assessing the quality of long-form, model-generated text is challenging, even\nwith advanced LLM-as-a-Judge methods, due to performance degradation as input\nlength increases. To address this issue, we propose a divide-and-conquer\napproach, which breaks down the comprehensive evaluation task into a series of\nlocalized scoring tasks, followed by a final global assessment. This strategy\nallows for more granular and manageable evaluations, ensuring that each segment\nof the text is assessed in isolation for both coherence and quality, while also\naccounting for the overall structure and consistency of the entire piece.\nMoreover, we introduce a hybrid in-context learning approach that leverages\nhuman annotations to enhance the performance of both local and global\nevaluations. By incorporating human-generated feedback directly into the\nevaluation process, this method allows the model to better align with human\njudgment. Finally, we develop an uncertainty-based active learning algorithm\nthat efficiently selects data samples for human annotation, thereby reducing\nannotation costs in practical scenarios. Experimental results show that the\nproposed evaluation framework outperforms several representative baselines,\nhighlighting the effectiveness of our approach.", "published": "2025-05-26 16:39:41", "link": "http://arxiv.org/abs/2505.20195v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "THiNK: Can Large Language Models Think-aloud?", "abstract": "Assessing higher-order thinking skills in large language models (LLMs)\nremains a fundamental challenge, especially in tasks that go beyond\nsurface-level accuracy. In this work, we propose THiNK (Testing Higher-order\nNotion of Knowledge), a multi-agent, feedback-driven evaluation framework\ngrounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative\ntask of problem generation, critique, and revision, encouraging LLMs to\nthink-aloud through step-by-step reflection and refinement. This enables a\nsystematic evaluation of both lower-order (e.g., remember, understand) and\nhigher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven\nstate-of-the-art LLMs and perform a detailed cognitive analysis of their\noutputs. Results reveal that while models reliably perform lower-order\ncategories well, they struggle with applying knowledge in realistic contexts\nand exhibit limited abstraction. Structured feedback loops significantly\nimprove reasoning performance, particularly in higher-order thinking.\nQualitative evaluations further confirm that THiNK-guided outputs better align\nwith domain logic and problem structure. The code of our framework provides a\nscalable methodology for probing and enhancing LLM reasoning, offering new\ndirections for evaluation grounded in learning science, which is available at\nour GitHub repository.", "published": "2025-05-26 16:27:02", "link": "http://arxiv.org/abs/2505.20184v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visual Abstract Thinking Empowers Multimodal Reasoning", "abstract": "Images usually convey richer detail than text, but often include redundant\ninformation which potentially downgrades multimodal reasoning performance. When\nfaced with lengthy or complex messages, humans tend to employ abstract thinking\nto convert them into simple and concise abstracts. Inspired by this cognitive\nstrategy, we introduce Visual Abstract Thinking (VAT), a novel thinking\nparadigm that prompts Multimodal Large Language Models (MLLMs) with visual\nabstract instead of explicit verbal thoughts or elaborate guidance, permitting\na more concentrated visual reasoning mechanism. Explicit thinking, such as\nChain-of-thought (CoT) or tool-augmented approaches, increases the complexity\nof reasoning process via inserting verbose intermediate steps, external\nknowledge or visual information. In contrast, VAT reduces redundant visual\ninformation and encourages models to focus their reasoning on more essential\nvisual elements. Experimental results show that VAT consistently empowers\ndifferent models, and achieves an average gain of 17% over GPT-4o baseline by\nemploying diverse types of visual abstracts, demonstrating that VAT can enhance\nvisual reasoning abilities for MLLMs regarding conceptual, structural and\nrelational reasoning tasks. VAT is also compatible with CoT in\nknowledge-intensive multimodal reasoning tasks. These findings highlight the\neffectiveness of visual reasoning via abstract thinking and encourage further\nexploration of more diverse reasoning paradigms from the perspective of human\ncognition.", "published": "2025-05-26 16:06:35", "link": "http://arxiv.org/abs/2505.20164v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent", "abstract": "As large language models (LLMs) become integrated into sensitive workflows,\nconcerns grow over their potential to leak confidential information. We propose\nTrojanStego, a novel threat model in which an adversary fine-tunes an LLM to\nembed sensitive context information into natural-looking outputs via linguistic\nsteganography, without requiring explicit control over inference inputs. We\nintroduce a taxonomy outlining risk factors for compromised LLMs, and use it to\nevaluate the risk profile of the threat. To implement TrojanStego, we propose a\npractical encoding scheme based on vocabulary partitioning learnable by LLMs\nvia fine-tuning. Experimental results show that compromised models reliably\ntransmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over\n97% accuracy using majority voting across three generations. Further, they\nmaintain high utility, can evade human detection, and preserve coherence. These\nresults highlight a new class of LLM data exfiltration attacks that are\npassive, covert, practical, and dangerous.", "published": "2025-05-26 15:20:51", "link": "http://arxiv.org/abs/2505.20118v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "SCIRGC: Multi-Granularity Citation Recommendation and Citation Sentence Preference Alignment", "abstract": "Citations are crucial in scientific research articles as they highlight the\nconnection between the current study and prior work. However, this process is\noften time-consuming for researchers. In this study, we propose the SciRGC\nframework, which aims to automatically recommend citation articles and generate\ncitation sentences for citation locations within articles. The framework\naddresses two key challenges in academic citation generation: 1) how to\naccurately identify the author's citation intent and find relevant citation\npapers, and 2) how to generate high-quality citation sentences that align with\nhuman preferences. We enhance citation recommendation accuracy in the citation\narticle recommendation module by incorporating citation networks and sentiment\nintent, and generate reasoning-based citation sentences in the citation\nsentence generation module by using the original article abstract, local\ncontext, citation intent, and recommended articles as inputs. Additionally, we\npropose a new evaluation metric to fairly assess the quality of generated\ncitation sentences. Through comparisons with baseline models and ablation\nexperiments, the SciRGC framework not only improves the accuracy and relevance\nof citation recommendations but also ensures the appropriateness of the\ngenerated citation sentences in context, providing a valuable tool for\ninterdisciplinary researchers.", "published": "2025-05-26 15:09:10", "link": "http://arxiv.org/abs/2505.20103v2", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Adaptive Deep Reasoning: Triggering Deep Thinking When Needed", "abstract": "Large language models (LLMs) have shown impressive capabilities in handling\ncomplex tasks through long-chain reasoning. However, the extensive reasoning\nsteps involved can significantly increase computational costs, posing\nchallenges for real-world deployment. Recent efforts have focused on optimizing\nreasoning efficiency by shortening the Chain-of-Thought (CoT) reasoning\nprocesses through various approaches, such as length-aware prompt engineering,\nsupervised fine-tuning on CoT data with variable lengths, and reinforcement\nlearning with length penalties. Although these methods effectively reduce\nreasoning length, they still necessitate an initial reasoning phase. More\nrecent approaches have attempted to integrate long-chain and short-chain\nreasoning abilities into a single model, yet they still rely on manual control\nto toggle between short and long CoT. In this work, we propose a novel approach\nthat autonomously switches between short and long reasoning chains based on\nproblem complexity. Our method begins with supervised fine-tuning of the base\nmodel to equip both long-chain and short-chain reasoning abilities. We then\nemploy reinforcement learning to further balance short and long CoT generation\nwhile maintaining accuracy through two key strategies: first, integrating\nreinforcement learning with a long-short adaptive group-wise reward strategy to\nassess prompt complexity and provide corresponding rewards; second,\nimplementing a logit-based reasoning mode switching loss to optimize the\nmodel's initial token choice, thereby guiding the selection of the reasoning\ntype. Evaluations on mathematical datasets demonstrate that our model can\ndynamically switch between long-chain and short-chain reasoning modes without\nsubstantially sacrificing performance. This advancement enhances the\npracticality of reasoning in large language models for real-world applications.", "published": "2025-05-26 15:08:51", "link": "http://arxiv.org/abs/2505.20101v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Token-level Accept or Reject: A Micro Alignment Approach for Large Language Models", "abstract": "With the rapid development of Large Language Models (LLMs), aligning these\nmodels with human preferences and values is critical to ensuring ethical and\nsafe applications. However, existing alignment techniques such as RLHF or DPO\noften require direct fine-tuning on LLMs with billions of parameters, resulting\nin substantial computational costs and inefficiencies. To address this, we\npropose Micro token-level Accept-Reject Aligning (MARA) approach designed to\noperate independently of the language models. MARA simplifies the alignment\nprocess by decomposing sentence-level preference learning into token-level\nbinary classification, where a compact three-layer fully-connected network\ndetermines whether candidate tokens are \"Accepted\" or \"Rejected\" as part of the\nresponse. Extensive experiments across seven different LLMs and three\nopen-source datasets show that MARA achieves significant improvements in\nalignment performance while reducing computational costs. The source code and\nimplementation details are publicly available at\nhttps://github.com/IAAR-Shanghai/MARA, and the trained models are released at\nhttps://huggingface.co/IAAR-Shanghai/MARA_AGENTS.", "published": "2025-05-26 09:24:36", "link": "http://arxiv.org/abs/2505.19743v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Mirage of Multimodality: Where Truth is Tested and Honesty Unravels", "abstract": "Reasoning models have recently attracted significant attention, especially\nfor tasks that involve complex inference. Their strengths exemplify the System\nII paradigm (slow, structured thinking), contrasting with the System I (rapid,\nheuristic-driven). Yet, does slower reasoning necessarily lead to greater\ntruthfulness? Our findings suggest otherwise. In this study, we present the\nfirst systematic investigation of distortions associated with System I and\nSystem II reasoning in multimodal contexts. We demonstrate that slower\nreasoning models, when presented with incomplete or misleading visual inputs,\nare more likely to fabricate plausible yet false details to support flawed\nreasoning -- a phenomenon we term the \"Mirage of Multimodality\". To examine\nthis, we constructed a 5,000-sample hierarchical prompt dataset annotated by 50\nhuman participants. These prompts gradually increase in complexity, revealing a\nconsistent pattern: slower reasoning models tend to employ depth-first thinking\n(delving deeper into incorrect premises), whereas faster chat models favor\nbreadth-first inference, exhibiting greater caution under uncertainty. Our\nresults highlight a critical vulnerability of slower reasoning models: although\nhighly effective in structured domains such as mathematics, it becomes brittle\nwhen confronted with ambiguous multimodal inputs.", "published": "2025-05-26 16:55:38", "link": "http://arxiv.org/abs/2505.20214v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Evaluating Large Language Models for Code Review", "abstract": "Context: Code reviews are crucial for software quality. Recent AI advances\nhave allowed large language models (LLMs) to review and fix code; now, there\nare tools that perform these reviews. However, their reliability and accuracy\nhave not yet been systematically evaluated. Objective: This study compares\ndifferent LLMs' performance in detecting code correctness and suggesting\nimprovements. Method: We tested GPT4o and Gemini 2.0 Flash on 492 AI generated\ncode blocks of varying correctness, along with 164 canonical code blocks from\nthe HumanEval benchmark. To simulate the code review task objectively, we\nexpected LLMs to assess code correctness and improve the code if needed. We ran\nexperiments with different configurations and reported on the results. Results:\nWith problem descriptions, GPT4o and Gemini 2.0 Flash correctly classified code\ncorrectness 68.50% and 63.89% of the time, respectively, and corrected the code\n67.83% and 54.26% of the time for the 492 code blocks of varying correctness.\nWithout problem descriptions, performance declined. The results for the 164\ncanonical code blocks differed, suggesting that performance depends on the type\nof code. Conclusion: LLM code reviews can help suggest improvements and assess\ncorrectness, but there is a risk of faulty outputs. We propose a process that\ninvolves humans, called the \"Human in the loop LLM Code Review\" to promote\nknowledge sharing while mitigating the risk of faulty outputs.", "published": "2025-05-26 16:47:29", "link": "http://arxiv.org/abs/2505.20206v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Shutdownable Agents through POST-Agency", "abstract": "Many fear that future artificial agents will resist shutdown. I present an\nidea - the POST-Agents Proposal - for ensuring that doesn't happen. I propose\nthat we train agents to satisfy Preferences Only Between Same-Length\nTrajectories (POST). I then prove that POST - together with other conditions -\nimplies Neutrality+: the agent maximizes expected utility, ignoring the\nprobability distribution over trajectory-lengths. I argue that Neutrality+\nkeeps agents shutdownable and allows them to be useful.", "published": "2025-05-26 16:44:17", "link": "http://arxiv.org/abs/2505.20203v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation", "abstract": "We study cost-efficient collaboration between strong and weak language models\nfor repository-level code generation, where the weak model handles simpler\ntasks at lower cost, and the most challenging tasks are delegated to the strong\nmodel. While many works propose architectures for this task, few analyze\nperformance relative to cost. We evaluate a broad spectrum of collaboration\nstrategies: context-based, pipeline-based, and dynamic, on GitHub issue\nresolution. Our most effective collaborative strategy achieves equivalent\nperformance to the strong model while reducing the cost by 40%. Based on our\nfindings, we offer actionable guidelines for choosing collaboration strategies\nunder varying budget and performance constraints. Our results show that\nstrong-weak collaboration substantially boosts the weak model's performance at\na fraction of the cost, pipeline and context-based methods being most\nefficient. We release the code for our work at\nhttps://github.com/shubhamrgandhi/codegen-strong-weak-collab.", "published": "2025-05-26 16:25:38", "link": "http://arxiv.org/abs/2505.20182v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Program of Equations Thoughts to Solve Algebra Word Problems", "abstract": "Solving algebraic word problems (AWPs) has recently emerged as an important\nnatural language processing task. Recently, large language models (LLMs) have\ndemonstrated powerful mathematical capabilities, and the Chain-of-Thought\ntechnique, which guides LLMs through step-by-step reasoning, has yielded\nimpressive results. However, this reasoning ability is limited by the\ncomputational weaknesses of LLMs themselves, where calculation errors can\naccumulate, leading to incorrect final answers. To address this, we propose\nProgram of Equations Thoughts (POET), which transforms the task of generating\nstep-by-step reasoning answers into a two-stage task of predicting equations\nand generating code, offloading complex computations to a Python interpreter to\navoid calculation errors in LLMs. Furthermore, we propose Zero-shot POET, which\nutilizes a manually designed template to enable LLMs to directly generate\nPython code for one-step solving. Our method achieves accuracies of 95.3% and\n98.0% on the PEN and ALG514 datasets, respectively, setting a new\nstate-of-the-art (SOTA). Zero-shot POET also achieves the SOTA result of 95.5%\non the DRAW-1K dataset.", "published": "2025-05-26 16:12:04", "link": "http://arxiv.org/abs/2505.20170v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Capability-Based Scaling Laws for LLM Red-Teaming", "abstract": "As large language models grow in capability and agency, identifying\nvulnerabilities through red-teaming becomes vital for safe deployment. However,\ntraditional prompt-engineering approaches may prove ineffective once\nred-teaming turns into a weak-to-strong problem, where target models surpass\nred-teamers in capabilities. To study this shift, we frame red-teaming through\nthe lens of the capability gap between attacker and target. We evaluate more\nthan 500 attacker-target pairs using LLM-based jailbreak attacks that mimic\nhuman red-teamers across diverse families, sizes, and capability levels. Three\nstrong trends emerge: (i) more capable models are better attackers, (ii) attack\nsuccess drops sharply once the target's capability exceeds the attacker's, and\n(iii) attack success rates correlate with high performance on social science\nsplits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking\nscaling law that predicts attack success for a fixed target based on\nattacker-target capability gap. These findings suggest that fixed-capability\nattackers (e.g., humans) may become ineffective against future models,\nincreasingly capable open-source models amplify risks for existing systems, and\nmodel providers must accurately measure and control models' persuasive and\nmanipulative abilities to limit their effectiveness as attackers.", "published": "2025-05-26 16:05:41", "link": "http://arxiv.org/abs/2505.20162v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents", "abstract": "Spatial Planning is a crucial part in the field of spatial intelligence,\nwhich requires the understanding and planning about object arrangements in\nspace perspective. AI agents with the spatial planning ability can better adapt\nto various real-world applications, including robotic manipulation, automatic\nassembly, urban planning etc. Recent works have attempted to construct\nbenchmarks for evaluating the spatial intelligence of Multimodal Large Language\nModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatial\nreasoning based on typical Visual Question-Answering (VQA) forms, which suffers\nfrom the gap between abstract spatial understanding and concrete task\nexecution. In this work, we take a step further to build a comprehensive\nbenchmark called MineAnyBuild, aiming to evaluate the spatial planning ability\nof open-world AI agents in the Minecraft game. Specifically, MineAnyBuild\nrequires an agent to generate executable architecture building plans based on\nthe given multi-modal human instructions. It involves 4,000 curated spatial\nplanning tasks and also provides a paradigm for infinitely expandable data\ncollection by utilizing rich player-generated content. MineAnyBuild evaluates\nspatial planning through four core supporting dimensions: spatial\nunderstanding, spatial reasoning, creativity, and spatial commonsense. Based on\nMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based\nagents, revealing the severe limitations but enormous potential in their\nspatial planning abilities. We believe our MineAnyBuild will open new avenues\nfor the evaluation of spatial intelligence and help promote further development\nfor open-world AI agents capable of spatial planning.", "published": "2025-05-26 15:48:14", "link": "http://arxiv.org/abs/2505.20148v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Homophily Enhanced Graph Domain Adaptation", "abstract": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs\nto unlabeled target graphs, addressing the challenge of label scarcity. In this\npaper, we highlight the significance of graph homophily, a pivotal factor for\ngraph domain alignment, which, however, has long been overlooked in existing\napproaches. Specifically, our analysis first reveals that homophily\ndiscrepancies exist in benchmarks. Moreover, we also show that homophily\ndiscrepancies degrade GDA performance from both empirical and theoretical\naspects, which further underscores the importance of homophily alignment in\nGDA. Inspired by this finding, we propose a novel homophily alignment algorithm\nthat employs mixed filters to smooth graph signals, thereby effectively\ncapturing and mitigating homophily discrepancies between graphs. Experimental\nresults on a variety of benchmarks verify the effectiveness of our method.", "published": "2025-05-26 15:02:08", "link": "http://arxiv.org/abs/2505.20089v2", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition", "abstract": "Effective human-AI interaction relies on AI's ability to accurately perceive\nand interpret human emotions. Current benchmarks for vision and vision-language\nmodels are severely limited, offering a narrow emotional spectrum that\noverlooks nuanced states (e.g., bitterness, intoxication) and fails to\ndistinguish subtle differences between related feelings (e.g., shame vs.\nembarrassment). Existing datasets also often use uncontrolled imagery with\noccluded faces and lack demographic diversity, risking significant bias. To\naddress these critical gaps, we introduce EmoNet Face, a comprehensive\nbenchmark suite. EmoNet Face features: (1) A novel 40-category emotion\ntaxonomy, meticulously derived from foundational research to capture finer\ndetails of human emotional experiences. (2) Three large-scale, AI-generated\ndatasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and\ncontrolled demographic balance across ethnicity, age, and gender. (3) Rigorous,\nmulti-expert annotations for training and high-fidelity evaluation. (4) We\nbuilt EmpathicInsight-Face, a model achieving human-expert-level performance on\nour benchmark. The publicly released EmoNet Face suite - taxonomy, datasets,\nand model - provides a robust foundation for developing and evaluating AI\nsystems with a deeper understanding of human emotions.", "published": "2025-05-26 14:19:58", "link": "http://arxiv.org/abs/2505.20033v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Evaluating AI cyber capabilities with crowdsourced elicitation", "abstract": "As AI systems become increasingly capable, understanding their offensive\ncyber potential is critical for informed governance and responsible deployment.\nHowever, it's hard to accurately bound their capabilities, and some prior\nevaluations dramatically underestimated them. The art of extracting maximum\ntask-specific performance from AIs is called \"AI elicitation\", and today's\nsafety organizations typically conduct it in-house. In this paper, we explore\ncrowdsourcing elicitation efforts as an alternative to in-house elicitation\nwork.\n  We host open-access AI tracks at two Capture The Flag (CTF) competitions: AI\nvs. Humans (400 teams) and Cyber Apocalypse (8000 teams). The AI teams achieve\noutstanding performance at both events, ranking top-5% and top-10% respectively\nfor a total of \\$7500 in bounties. This impressive performance suggests that\nopen-market elicitation may offer an effective complement to in-house\nelicitation. We propose elicitation bounties as a practical mechanism for\nmaintaining timely, cost-effective situational awareness of emerging AI\ncapabilities.\n  Another advantage of open elicitations is the option to collect human\nperformance data at scale. Applying METR's methodology, we found that AI agents\ncan reliably solve cyber challenges requiring one hour or less of effort from a\nmedian human CTF participant.", "published": "2025-05-26 12:40:32", "link": "http://arxiv.org/abs/2505.19915v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "PCDCNet: A Surrogate Model for Air Quality Forecasting with Physical-Chemical Dynamics and Constraints", "abstract": "Air quality forecasting (AQF) is critical for public health and environmental\nmanagement, yet remains challenging due to the complex interplay of emissions,\nmeteorology, and chemical transformations. Traditional numerical models, such\nas CMAQ and WRF-Chem, provide physically grounded simulations but are\ncomputationally expensive and rely on uncertain emission inventories. Deep\nlearning models, while computationally efficient, often struggle with\ngeneralization due to their lack of physical constraints. To bridge this gap,\nwe propose PCDCNet, a surrogate model that integrates numerical modeling\nprinciples with deep learning. PCDCNet explicitly incorporates emissions,\nmeteorological influences, and domain-informed constraints to model pollutant\nformation, transport, and dissipation. By combining graph-based spatial\ntransport modeling, recurrent structures for temporal accumulation, and\nrepresentation enhancement for local interactions, PCDCNet achieves\nstate-of-the-art (SOTA) performance in 72-hour station-level PM2.5 and O3\nforecasting while significantly reducing computational costs. Furthermore, our\nmodel is deployed in an online platform, providing free, real-time air quality\nforecasts, demonstrating its scalability and societal impact. By aligning deep\nlearning with physical consistency, PCDCNet offers a practical and\ninterpretable solution for AQF, enabling informed decision-making for both\npersonal and regulatory applications.", "published": "2025-05-26 11:27:07", "link": "http://arxiv.org/abs/2505.19842v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees", "abstract": "In many real-world applications of regression, conditional probability\nestimation, and uncertainty quantification, exploiting symmetries rooted in\nphysics or geometry can dramatically improve generalization and sample\nefficiency. While geometric deep learning has made significant empirical\nadvances by incorporating group-theoretic structure, less attention has been\ngiven to statistical learning guarantees. In this paper, we introduce an\nequivariant representation learning framework that simultaneously addresses\nregression, conditional probability estimation, and uncertainty quantification\nwhile providing first-of-its-kind non-asymptotic statistical learning\nguarantees. Grounded in operator and group representation theory, our framework\napproximates the spectral decomposition of the conditional expectation\noperator, building representations that are both equivariant and disentangled\nalong independent symmetry subgroups. Empirical evaluations on synthetic\ndatasets and real-world robotics applications confirm the potential of our\napproach, matching or outperforming existing equivariant baselines in\nregression while additionally providing well-calibrated parametric uncertainty\nestimates.", "published": "2025-05-26 10:47:23", "link": "http://arxiv.org/abs/2505.19809v2", "categories": ["cs.LG", "cs.AI", "cs.RO", "43-06", "I.2.6; I.2.9; I.5.1"], "primary_category": "cs.LG"}
{"title": "Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM", "abstract": "Recent advancements in image-to-video (I2V) generation have shown promising\nperformance in conventional scenarios. However, these methods still encounter\nsignificant challenges when dealing with complex scenes that require a deep\nunderstanding of nuanced motion and intricate object-action relationships. To\naddress these challenges, we present Dynamic-I2V, an innovative framework that\nintegrates Multimodal Large Language Models (MLLMs) to jointly encode visual\nand textual conditions for a diffusion transformer (DiT) architecture. By\nleveraging the advanced multimodal understanding capabilities of MLLMs, our\nmodel significantly improves motion controllability and temporal coherence in\nsynthesized videos. The inherent multimodality of Dynamic-I2V further enables\nflexible support for diverse conditional inputs, extending its applicability to\nvarious downstream generation tasks. Through systematic analysis, we identify a\ncritical limitation in current I2V benchmarks: a significant bias towards\nfavoring low-dynamic videos, stemming from an inadequate balance between motion\ncomplexity and visual quality metrics. To resolve this evaluation gap, we\npropose DIVE - a novel assessment benchmark specifically designed for\ncomprehensive dynamic quality measurement in I2V generation. In conclusion,\nextensive quantitative and qualitative experiments confirm that Dynamic-I2V\nattains state-of-the-art performance in image-to-video generation, particularly\nrevealing significant improvements of 42.5%, 7.9%, and 11.8% in dynamic range,\ncontrollability, and quality, respectively, as assessed by the DIVE metric in\ncomparison to existing methods.", "published": "2025-05-26 12:29:34", "link": "http://arxiv.org/abs/2505.19901v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAIL: Self-supervised Albedo Estimation from Real Images with a Latent Diffusion Model", "abstract": "Intrinsic image decomposition aims at separating an image into its underlying\nalbedo and shading components, isolating the base color from lighting effects\nto enable downstream applications such as virtual relighting and scene editing.\nDespite the rise and success of learning-based approaches, intrinsic image\ndecomposition from real-world images remains a significant challenging task due\nto the scarcity of labeled ground-truth data. Most existing solutions rely on\nsynthetic data as supervised setups, limiting their ability to generalize to\nreal-world scenes. Self-supervised methods, on the other hand, often produce\nalbedo maps that contain reflections and lack consistency under different\nlighting conditions. To address this, we propose SAIL, an approach designed to\nestimate albedo-like representations from single-view real-world images. We\nrepurpose the prior knowledge of a latent diffusion model for unconditioned\nscene relighting as a surrogate objective for albedo estimation. To extract the\nalbedo, we introduce a novel intrinsic image decomposition fully formulated in\nthe latent space. To guide the training of our latent diffusion model, we\nintroduce regularization terms that constrain both the lighting-dependent and\nindependent components of our latent image decomposition. SAIL predicts stable\nalbedo under varying lighting conditions and generalizes to multiple scenes,\nusing only unlabeled multi-illumination data available online.", "published": "2025-05-26 09:31:56", "link": "http://arxiv.org/abs/2505.19751v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect", "abstract": "In this technical report, we present our solution to the CVPR 2025 Visual\nAnomaly and Novelty Detection (VAND) 3.0 Workshop Challenge Track 1: Adapt &\nDetect: Robust Anomaly Detection in Real-World Applications. In real-world\nindustrial anomaly detection, it is crucial to accurately identify anomalies\nwith physical complexity, such as transparent or reflective surfaces,\nocclusions, and low-contrast contaminations. The recently proposed MVTec AD 2\ndataset significantly narrows the gap between publicly available benchmarks and\nanomalies found in real-world industrial environments. To address the\nchallenges posed by this dataset--such as complex and varying lighting\nconditions and real anomalies with large scale differences--we propose a fully\ntraining-free anomaly detection and segmentation method based on feature\nextraction using the DINOv2 model named SuperAD. Our method carefully selects a\nsmall number of normal reference images and constructs a memory bank by\nleveraging the strong representational power of DINOv2. Anomalies are then\nsegmented by performing nearest neighbor matching between test image features\nand the memory bank. Our method achieves competitive results on both test sets\nof the MVTec AD 2 dataset.", "published": "2025-05-26 09:29:27", "link": "http://arxiv.org/abs/2505.19750v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval", "abstract": "Multimodal information retrieval (MIR) faces inherent challenges due to the\nheterogeneity of data sources and the complexity of cross-modal alignment.\nWhile previous studies have identified modal gaps in feature spaces, a\nsystematic approach to address these challenges remains unexplored. In this\nwork, we introduce UNITE, a universal framework that tackles these challenges\nthrough two critical yet underexplored aspects: data curation and\nmodality-aware training configurations. Our work provides the first\ncomprehensive analysis of how modality-specific data properties influence\ndownstream task performance across diverse scenarios. Moreover, we propose\nModal-Aware Masked Contrastive Learning (MAMCL) to mitigate the competitive\nrelationships among the instances of different modalities. Our framework\nachieves state-of-the-art results on multiple multimodal retrieval benchmarks,\noutperforming existing methods by notable margins. Through extensive\nexperiments, we demonstrate that strategic modality curation and tailored\ntraining protocols are pivotal for robust cross-modal representation learning.\nThis work not only advances MIR performance but also provides a foundational\nblueprint for future research in multimodal systems. Our project is available\nat https://friedrichor.github.io/projects/UNITE.", "published": "2025-05-26 08:09:44", "link": "http://arxiv.org/abs/2505.19650v2", "categories": ["cs.CV", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Transformers in Protein: A Survey", "abstract": "As protein informatics advances rapidly, the demand for enhanced predictive\naccuracy, structural analysis, and functional understanding has intensified.\nTransformer models, as powerful deep learning architectures, have demonstrated\nunprecedented potential in addressing diverse challenges across protein\nresearch. However, a comprehensive review of Transformer applications in this\nfield remains lacking. This paper bridges this gap by surveying over 100\nstudies, offering an in-depth analysis of practical implementations and\nresearch progress of Transformers in protein-related tasks. Our review\nsystematically covers critical domains, including protein structure prediction,\nfunction prediction, protein-protein interaction analysis, functional\nannotation, and drug discovery/target identification. To contextualize these\nadvancements across various protein domains, we adopt a domain-oriented\nclassification system. We first introduce foundational concepts: the\nTransformer architecture and attention mechanisms, categorize Transformer\nvariants tailored for protein science, and summarize essential protein\nknowledge. For each research domain, we outline its objectives and background,\ncritically evaluate prior methods and their limitations, and highlight\ntransformative contributions enabled by Transformer models. We also curate and\nsummarize pivotal datasets and open-source code resources to facilitate\nreproducibility and benchmarking. Finally, we discuss persistent challenges in\napplying Transformers to protein informatics and propose future research\ndirections. This review aims to provide a consolidated foundation for the\nsynergistic integration of Transformer and protein informatics, fostering\nfurther innovation and expanded applications in the field.", "published": "2025-05-26 15:08:18", "link": "http://arxiv.org/abs/2505.20098v2", "categories": ["cs.LG", "cs.CR", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Linear Bandits with Non-i.i.d. Noise", "abstract": "We study the linear stochastic bandit problem, relaxing the standard i.i.d.\nassumption on the observation noise. As an alternative to this restrictive\nassumption, we allow the noise terms across rounds to be sub-Gaussian but\ninterdependent, with dependencies that decay over time. To address this\nsetting, we develop new confidence sequences using a recently introduced\nreduction scheme to sequential probability assignment, and use these to derive\na bandit algorithm based on the principle of optimism in the face of\nuncertainty. We provide regret bounds for the resulting algorithm, expressed in\nterms of the decay rate of the strength of dependence between observations.\nAmong other results, we show that our bounds recover the standard rates up to a\nfactor of the mixing time for geometrically mixing observation noise.", "published": "2025-05-26 14:06:23", "link": "http://arxiv.org/abs/2505.20017v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generalized and Personalized Federated Learning with Foundation Models via Orthogonal Transformations", "abstract": "Federated Learning (FL) aims to train models across decentralized clients or\ndevices holding local data without the need for centralized data collection,\nthus enhancing data privacy and security. However, achieving both\ngeneralization and personalization in heterogeneous settings remains a\nsignificant challenge. To address this, we introduce FedOT, a novel approach\nthat leverages black-box foundation models. FedOT shares only a global\ntask-dependent classifier across clients while locally adapting features\nthrough orthogonal transformations. By enforcing orthogonality, FedOT mitigates\ngradient conflicts across diverse clients, preserves semantic integrity, and\nachieves robust performance even in the presence of substantial data\nheterogeneity. The strategy of combining global and local parameters enables a\nmore balanced approach for both generalization and personalization,\noutperforming baseline FL methods across multiple benchmarks. Furthermore, our\nextensive analysis confirms that joint optimization of global classifiers and\nlocal orthogonal transformations yields superior performance and suggests\nbroader applicability.", "published": "2025-05-26 12:18:24", "link": "http://arxiv.org/abs/2505.19888v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Model Agnostic Differentially Private Causal Inference", "abstract": "Estimating causal effects from observational data is essential in fields such\nas medicine, economics and social sciences, where privacy concerns are\nparamount. We propose a general, model-agnostic framework for differentially\nprivate estimation of average treatment effects (ATE) that avoids strong\nstructural assumptions on the data-generating process or the models used to\nestimate propensity scores and conditional outcomes. In contrast to prior work,\nwhich enforces differential privacy by directly privatizing these nuisance\ncomponents and results in a privacy cost that scales with model complexity, our\napproach decouples nuisance estimation from privacy protection. This separation\nallows the use of flexible, state-of-the-art black-box models, while\ndifferential privacy is achieved by perturbing only predictions and aggregation\nsteps within a fold-splitting scheme with ensemble techniques. We instantiate\nthe framework for three classical estimators -- the G-formula, inverse\npropensity weighting (IPW), and augmented IPW (AIPW) -- and provide formal\nutility and privacy guarantees. Empirical results show that our methods\nmaintain competitive performance under realistic privacy budgets. We further\nextend our framework to support meta-analysis of multiple private ATE\nestimates. Our results bridge a critical gap between causal inference and\nprivacy-preserving data analysis.", "published": "2025-05-26 07:00:37", "link": "http://arxiv.org/abs/2505.19589v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FlowSE: Efficient and High-Quality Speech Enhancement via Flow Matching", "abstract": "Generative models have excelled in audio tasks using approaches such as\nlanguage models, diffusion, and flow matching. However, existing generative\napproaches for speech enhancement (SE) face notable challenges: language\nmodel-based methods suffer from quantization loss, leading to compromised\nspeaker similarity and intelligibility, while diffusion models require complex\ntraining and high inference latency. To address these challenges, we propose\nFlowSE, a flow-matching-based model for SE. Flow matching learns a continuous\ntransformation between noisy and clean speech distributions in a single pass,\nsignificantly reducing inference latency while maintaining high-quality\nreconstruction. Specifically, FlowSE trains on noisy mel spectrograms and\noptional character sequences, optimizing a conditional flow matching loss with\nground-truth mel spectrograms as supervision. It implicitly learns speech's\ntemporal-spectral structure and text-speech alignment. During inference, FlowSE\ncan operate with or without textual information, achieving impressive results\nin both scenarios, with further improvements when transcripts are available.\nExtensive experiments demonstrate that FlowSE significantly outperforms\nstate-of-the-art generative methods, establishing a new paradigm for\ngenerative-based SE and demonstrating the potential of flow matching to advance\nthe field. Our code, pre-trained checkpoints, and audio samples are available.", "published": "2025-05-26 03:55:00", "link": "http://arxiv.org/abs/2505.19476v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Leveraging Cascaded Binary Classification and Multimodal Fusion for Dementia Detection through Spontaneous Speech", "abstract": "This paper presents our submission to the PROCESS Challenge 2025, focusing on\nspontaneous speech analysis for early dementia detection. For the three-class\nclassification task (Healthy Control, Mild Cognitive Impairment, and Dementia),\nwe propose a cascaded binary classification framework that fine-tunes\npre-trained language models and incorporates pause encoding to better capture\ndisfluencies. This design streamlines multi-class classification and addresses\nclass imbalance by restructuring the decision process. For the Mini-Mental\nState Examination score regression task, we develop an enhanced multimodal\nfusion system that combines diverse acoustic and linguistic features. Separate\nregression models are trained on individual feature sets, with ensemble\nlearning applied through score averaging. Experimental results on the test set\noutperform the baselines provided by the organizers in both tasks,\ndemonstrating the robustness and effectiveness of our approach.", "published": "2025-05-26 03:08:55", "link": "http://arxiv.org/abs/2505.19446v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "WikiTermBase: An AI-Augmented Term Base to Standardize Arabic Translation on Wikipedia", "abstract": "Term bases are recognized as one of the most effective components of\ntranslation software in time saving and consistency. In spite of the many\nrecent advances in natural language processing (NLP) and large language models\n(LLMs), major translation platforms have yet to take advantage of these tools\nto improve their term bases and support scalable content for underrepresented\nlanguages, which often struggle with localizing technical terminology. Language\nacademies in the Arab World, for example, have struggled since the 1940s to\nunify the way new scientific terms enter the Arabic language at scale. This\nabstract introduces an open source tool, WikiTermBase, with a systematic\napproach for building a lexicographical database with over 900K terms, which\nwere collected and mapped from a multitude of sources on a semantic and\nmorphological basis. The tool was successfully implemented on Arabic Wikipedia\nto standardize translated English and French terms.", "published": "2025-05-26 11:27:01", "link": "http://arxiv.org/abs/2505.20369v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents", "abstract": "Retrieval-augmented generation (RAG) based large language models (LLMs) are\nwidely used in finance for their excellent performance on knowledge-intensive\ntasks. However, standardized documents (e.g., SEC filing) share similar formats\nsuch as repetitive boilerplate texts, and similar table structures. This\nsimilarity forces traditional RAG methods to misidentify near-duplicate text,\nleading to duplicate retrieval that undermines accuracy and completeness. To\naddress these issues, we propose the Hierarchical Retrieval with Evidence\nCuration (HiREC) framework. Our approach first performs hierarchical retrieval\nto reduce confusion among similar texts. It first retrieve related documents\nand then selects the most relevant passages from the documents. The evidence\ncuration process removes irrelevant passages. When necessary, it automatically\ngenerates complementary queries to collect missing information. To evaluate our\napproach, we construct and release a Large-scale Open-domain Financial (LOFin)\nquestion answering benchmark that includes 145,897 SEC documents and 1,595\nquestion-answer pairs. Our code and data are available at\nhttps://github.com/deep-over/LOFin-bench-HiREC.", "published": "2025-05-26 11:08:23", "link": "http://arxiv.org/abs/2505.20368v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration", "abstract": "The rapid advancement of vision-language models (VLMs) has brought a lot of\nattention to their safety alignment. However, existing methods have primarily\nfocused on model undersafety, where the model responds to hazardous queries,\nwhile neglecting oversafety, where the model refuses to answer safe queries. In\nthis paper, we introduce the concept of $\\textit{safety calibration}$, which\nsystematically addresses both undersafety and oversafety. Specifically, we\npresent $\\textbf{VSCBench}$, a novel dataset of 3,600 image-text pairs that are\nvisually or textually similar but differ in terms of safety, which is designed\nto evaluate safety calibration across image-centric and text-centric scenarios.\nBased on our benchmark, we evaluate safety calibration across eleven widely\nused VLMs. Our extensive experiments revealed major issues with both\nundersafety and oversafety. We further investigated four approaches to improve\nthe model's safety calibration. We found that even though some methods\neffectively calibrated the models' safety problems, these methods also lead to\nthe degradation of models' utility. This trade-off underscores the urgent need\nfor advanced calibration methods, and our benchmark provides a valuable tool\nfor evaluating future approaches. Our code and data are available at\nhttps://github.com/jiahuigeng/VSCBench.git.", "published": "2025-05-26 09:01:46", "link": "http://arxiv.org/abs/2505.20362v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Achievable Rates and Error Exponents for a Class of Mismatched Compound Channels", "abstract": "This paper investigates achievable information rates and error exponents of\nmismatched decoding when the channel belongs to the class of channels that are\nclose to the decoding metric in terms of relative entropy. For both discrete-\nand continuous-alphabet channels, we derive approximations of the worst-case\nachievable information rates and error exponents as a function of the radius of\na small relative entropy ball centered at the decoding metric, allowing the\ncharacterization of the loss incurred due to imperfect channel estimation. We\nprovide a number of examples including symmetric metrics and modulo- additive\nnoise metrics for discrete systems, and nearest neighbor decoding for\ncontinuous-alphabet channels, where we derive the approximation when the\nchannel admits arbitrary statistics and when it is assumed noise-additive with\nunknown finite second-order moment.", "published": "2025-05-26 21:01:48", "link": "http://arxiv.org/abs/2505.20523v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The challenge of hidden gifts in multi-agent reinforcement learning", "abstract": "Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings.", "published": "2025-05-26 23:28:52", "link": "http://arxiv.org/abs/2505.20579v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "xChemAgents: Agentic AI for Explainable Quantum Chemistry", "abstract": "Recent progress in multimodal graph neural networks has demonstrated that\naugmenting atomic XYZ geometries with textual chemical descriptors can enhance\npredictive accuracy across a range of electronic and thermodynamic properties.\nHowever, naively appending large sets of heterogeneous descriptors often\ndegrades performance on tasks sensitive to molecular shape or symmetry, and\nundermines interpretability. xChemAgents proposes a cooperative agent framework\nthat injects physics-aware reasoning into multimodal property prediction.\nxChemAgents comprises two language-model-based agents: a Selector, which\nadaptively identifies a sparse, weighted subset of descriptors relevant to each\ntarget, and provides a natural language rationale; and a Validator, which\nenforces physical constraints such as unit consistency and scaling laws through\niterative dialogue. On standard benchmark datasets, xChemAgents achieves up to\na 22\\% reduction in mean absolute error over strong baselines, while producing\nfaithful, human-interpretable explanations. Experiment results highlight the\npotential of cooperative, self-verifying agents to enhance both accuracy and\ntransparency in foundation-model-driven materials science. The implementation\nand accompanying dataset are available anonymously at\nhttps://github.com/KurbanIntelligenceLab/xChemAgents.", "published": "2025-05-26 23:22:41", "link": "http://arxiv.org/abs/2505.20574v1", "categories": ["cs.MA", "physics.chem-ph", "physics.comp-ph"], "primary_category": "cs.MA"}
{"title": "Reconceptualizing Smart Microscopy: From Data Collection to Knowledge Creation by Multi-Agent Integration", "abstract": "Smart microscopy represents a paradigm shift in biological imaging, moving\nfrom passive observation tools to active collaborators in scientific inquiry.\nEnabled by advances in automation, computational power, and artificial\nintelligence, these systems are now capable of adaptive decision-making and\nreal-time experimental control. Here, we introduce a theoretical framework that\nreconceptualizes smart microscopy as a partner in scientific investigation.\nCentral to our framework is the concept of the 'epistemic-empirical divide' in\ncellular investigation-the gap between what is observable (empirical domain)\nand what must be understood (epistemic domain). We propose six core design\nprinciples: epistemic-empirical awareness, hierarchical context integration, an\nevolution from detection to perception, adaptive measurement frameworks,\nnarrative synthesis capabilities, and cross-contextual reasoning. Together,\nthese principles guide a multi-agent architecture designed to align empirical\nobservation with the goals of scientific understanding. Our framework provides\na roadmap for building microscopy systems that go beyond automation to actively\nsupport hypothesis generation, insight discovery, and theory development,\nredefining the role of scientific instruments in the process of knowledge\ncreation.", "published": "2025-05-26 19:02:14", "link": "http://arxiv.org/abs/2505.20466v1", "categories": ["cs.AI", "cs.HC", "cs.MA", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "A minimax method for the spectral fractional Laplacian and related evolution problems", "abstract": "We present a numerical method for the approximation of the inverse of the\nfractional Laplacian $(-\\Delta)^{s}$, based on its spectral definition, using\nrational functions to approximate the fractional power $A^{-s}$ of a matrix\n$A$, for $0<s<1$. The proposed numerical method is fast and accurate,\nbenefiting from the fact that the matrix $A$ arises from a finite element\napproximation of the Laplacian $-\\Delta$, which makes it applicable to a wide\nrange of domains with potentially irregular shapes. We make use of\nstate-of-the-art software to compute the best rational approximation of a\nfractional power. We analyze the convergence rate of our method and validate\nour findings through a series of numerical experiments with a range of\nexponents $s \\in (0,1)$. Additionally, we apply the proposed numerical method\nto different evolution problems that involve the fractional Laplacian through\nan interaction potential: the fractional porous medium equation and the\nfractional Keller-Segel equation. We then investigate the accuracy of the\nresulting numerical method, focusing in particular on the accurate reproduction\nof qualitative properties of the associated analytical solutions to these\npartial differential equations.", "published": "2025-05-26 22:49:52", "link": "http://arxiv.org/abs/2505.20560v1", "categories": ["math.NA", "cs.NA", "math.AP", "65N30, 65F60, 35K55, 35R11"], "primary_category": "math.NA"}
{"title": "Superfast 1-Norm Estimation", "abstract": "A matrix algorithm is said to be superfast (that is, runs at sublinear cost)\nif it involves much fewer scalars and flops than the input matrix has entries.\nSuch algorithms have been extensively studied and widely applied in modern\ncomputations for matrices with low displacement rank and more recently for\nlow-rank approximation of matrices, even though they are known to fail on\nworst-case inputs in the latter application. We devise novel superfast\nalgorithms that consistently produce accurate 1-norm estimates for real-world\nmatrices and discuss some promising extensions of our surprisingly simple\ntechniques. With further testing and refinement, our algorithms can potentially\nbe adopted in practical computations.", "published": "2025-05-26 21:12:23", "link": "http://arxiv.org/abs/2505.20528v1", "categories": ["math.NA", "cs.NA", "65F35, 65Y20, 68Q25"], "primary_category": "math.NA"}
{"title": "Semi-Explicit Neural DAEs: Learning Long-Horizon Dynamical Systems with Algebraic Constraints", "abstract": "Despite the promise of scientific machine learning (SciML) in combining\ndata-driven techniques with mechanistic modeling, existing approaches for\nincorporating hard constraints in neural differential equations (NDEs) face\nsignificant limitations. Scalability issues and poor numerical properties\nprevent these neural models from being used for modeling physical systems with\ncomplicated conservation laws. We propose Manifold-Projected Neural ODEs\n(PNODEs), a method that explicitly enforces algebraic constraints by projecting\neach ODE step onto the constraint manifold. This framework arises naturally\nfrom semi-explicit differential-algebraic equations (DAEs), and includes both a\nrobust iterative variant and a fast approximation requiring a single Jacobian\nfactorization. We further demonstrate that prior works on relaxation methods\nare special cases of our approach. PNODEs consistently outperform baselines\nacross six benchmark problems achieving a mean constraint violation error below\n$10^{-10}$. Additionally, PNODEs consistently achieve lower runtime compared to\nother methods for a given level of error tolerance. These results show that\nconstraint projection offers a simple strategy for learning physically\nconsistent long-horizon dynamics.", "published": "2025-05-26 20:31:15", "link": "http://arxiv.org/abs/2505.20515v1", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA"], "primary_category": "cs.LG"}
{"title": "Tensor finite elements for smectic liquid crystals", "abstract": "We present a tensor-based finite element scheme for a smectic-A liquid\ncrystal model. We propose a simple C\\'ea-type finite element projection in the\nlinear case and prove its quasi-optimal convergence. Special emphasis is put on\nthe formulation and treatment of appropriate boundary conditions. For the\nnonlinear case we present a formulation in two space dimensions and prove the\nexistence of a solution. We propose a discretization that extends the linear\ncase in Uzawa-fashion to the nonlinear case by an additional Poisson solver.\nNumerical results illustrate the performance and convergence of our schemes.", "published": "2025-05-26 19:55:11", "link": "http://arxiv.org/abs/2505.20493v1", "categories": ["math.NA", "cs.NA", "65N30, 76A15, 49J10, 35B45, 65N12"], "primary_category": "math.NA"}
{"title": "Maxwell \u00e0 la Helmholtz: Electromagnetic scattering by 3D perfect electric conductors via Helmholtz integral operators", "abstract": "This paper introduces a novel class of indirect boundary integral equation\n(BIE) formulations for the solution of electromagnetic scattering problems\ninvolving smooth perfectly electric conductors (PECs) in three-dimensions.\nThese combined-field-type BIE formulations rely exclusively on classical\nHelmholtz boundary operators, resulting in provably well-posed,\nfrequency-robust, Fredholm second-kind BIEs. Notably, we prove that the\nproposed formulations are free from spurious resonances, while retaining the\nversatility of Helmholtz integral operators. The approach is based on the\nequivalence between the Maxwell PEC scattering problem and two independent\nvector Helmholtz boundary value problems for the electric and magnetic fields,\nwith boundary conditions defined in terms of the Dirichlet and Neumann traces\nof the corresponding vector Helmholtz solutions. While certain aspects of this\nequivalence (for the electric field) have been previously exploited in the\nso-called field-only BIE formulations, we here rigorously establish and\ngeneralize the equivalence between Maxwell and Helmholtz problems for both\nfields. Finally, a variety of numerical examples highlights the robustness and\naccuracy of the proposed approach when combined with Density\nInterpolation-based Nystr\\\"om methods and fast linear algebra solvers,\nimplemented in the open-source Julia package Inti.jl.", "published": "2025-05-26 18:34:41", "link": "http://arxiv.org/abs/2505.20440v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "78A40, 65R20, 65N38, 65J10, 45B05"], "primary_category": "math.NA"}
{"title": "Martingale Consumption", "abstract": "We propose martingale consumption as a natural, desirable consumption pattern\nfor any given (proportional) investment strategy. The idea is to always adjust\ncurrent consumption so as to achieve level expected future consumption under\nthe arbitrarily chosen investment strategy. This approach avoids the\nformulation of an optimization objective based on preferences towards risk,\nintertemporal consumption, habit formation etc. We identify general explicit\nsolutions in deterministic-coefficient models. In the general case with random\ncoefficients we establish uniqueness, but the question of existence of a\nsolution is unsettled. With the interest rate as the only random factor we\nderive a PDE for the wealth-to-consumption factor as a function of the state\nvariables, which, however, is non-linear and without known closed-form\nsolutions. We briefly consider the discrete-time case and obtain similar\nresults. Throughout, we compare with well-known optimal strategies for\nclassical CRRA investors with time-additive utility of consumption and find\nthat under suitable time preferences they may in certain cases achieve\nmartingale consumption simultaneously.", "published": "2025-05-26 20:10:07", "link": "http://arxiv.org/abs/2505.20504v1", "categories": ["q-fin.MF", "91B08, 91B16, 91G15, 35A99"], "primary_category": "q-fin.MF"}
{"title": "Balancing Performance and Costs in Best Arm Identification", "abstract": "We consider the problem of identifying the best arm in a multi-armed bandit\nmodel. Despite a wealth of literature in the traditional fixed budget and fixed\nconfidence regimes of the best arm identification problem, it still remains a\nmystery to most practitioners as to how to choose an approach and corresponding\nbudget or confidence parameter. We propose a new formalism to avoid this\ndilemma altogether by minimizing a risk functional which explicitly balances\nthe performance of the recommended arm and the cost incurred by learning this\narm. In this framework, a cost is incurred for each observation during the\nsampling phase, and upon recommending an arm, a performance penalty is incurred\nfor identifying a suboptimal arm. The learner's goal is to minimize the sum of\nthe penalty and cost. This new regime mirrors the priorities of many\npractitioners, e.g. maximizing profit in an A/B testing framework, better than\nclassical fixed budget or confidence settings. We derive theoretical lower\nbounds for the risk of each of two choices for the performance penalty, the\nprobability of misidentification and the simple regret, and propose an\nalgorithm called DBCARE to match these lower bounds up to polylog factors on\nnearly all problem instances. We then demonstrate the performance of DBCARE on\na number of simulated models, comparing to fixed budget and confidence\nalgorithms to show the shortfalls of existing BAI paradigms on this problem.", "published": "2025-05-26 23:33:43", "link": "http://arxiv.org/abs/2505.20583v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning", "abstract": "Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL.", "published": "2025-05-26 22:51:00", "link": "http://arxiv.org/abs/2505.20561v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models", "abstract": "This paper studies the task of estimating heterogeneous treatment effects in\ncausal panel data models, in the presence of covariate effects. We propose a\nnovel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,\nthat employs flexible model structures and powerful neural network\narchitectures to cohesively deal with the underlying heterogeneity and\nnonlinearity of both panel units and covariate effects. The proposed CoDEAL\nintegrates nonlinear covariate effect components (parameterized by a\nfeed-forward neural network) with nonlinear factor structures (modeled by a\nmulti-output autoencoder) to form a heterogeneous causal panel model. The\nnonlinear covariate component offers a flexible framework for capturing the\ncomplex influences of covariates on outcomes. The nonlinear factor analysis\nenables CoDEAL to effectively capture both cross-sectional and temporal\ndependencies inherent in the data panel. This latent structural information is\nsubsequently integrated into a customized matrix completion algorithm, thereby\nfacilitating more accurate imputation of missing counterfactual outcomes.\nMoreover, the use of a multi-output autoencoder explicitly accounts for\nheterogeneity across units and enhances the model interpretability of the\nlatent factors. We establish theoretical guarantees on the convergence of the\nestimated counterfactuals, and demonstrate the compelling performance of the\nproposed method using extensive simulation studies and a real data application.", "published": "2025-05-26 21:45:43", "link": "http://arxiv.org/abs/2505.20536v1", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "primary_category": "stat.ML"}
{"title": "One-shot Robust Federated Learning of Independent Component Analysis", "abstract": "This paper investigates a general robust one-shot aggregation framework for\ndistributed and federated Independent Component Analysis (ICA) problem. We\npropose a geometric median-based aggregation algorithm that leverages $k$-means\nclustering to resolve the permutation ambiguity in local client estimations.\nOur method first performs k-means to partition client-provided estimators into\nclusters and then aggregates estimators within each cluster using the geometric\nmedian. This approach provably remains effective even in highly heterogeneous\nscenarios where at most half of the clients can observe only a minimal number\nof samples. The key theoretical contribution lies in the combined analysis of\nthe geometric median's error bound-aided by sample quantiles-and the maximum\nmisclustering rates of the aforementioned solution of $k$-means. The\neffectiveness of the proposed approach is further supported by simulation\nstudies conducted under various heterogeneous settings.", "published": "2025-05-26 21:37:19", "link": "http://arxiv.org/abs/2505.20532v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning with Expected Signatures: Theory and Applications", "abstract": "The expected signature maps a collection of data streams to a lower\ndimensional representation, with a remarkable property: the resulting feature\ntensor can fully characterize the data generating distribution. This\n\"model-free\" embedding has been successfully leveraged to build multiple\ndomain-agnostic machine learning (ML) algorithms for time series and sequential\ndata. The convergence results proved in this paper bridge the gap between the\nexpected signature's empirical discrete-time estimator and its theoretical\ncontinuous-time value, allowing for a more complete probabilistic\ninterpretation of expected signature-based ML methods. Moreover, when the data\ngenerating process is a martingale, we suggest a simple modification of the\nexpected signature estimator with significantly lower mean squared error and\nempirically demonstrate how it can be effectively applied to improve predictive\nperformance.", "published": "2025-05-26 19:01:20", "link": "http://arxiv.org/abs/2505.20465v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Kernel Quantile Embeddings and Associated Probability Metrics", "abstract": "Embedding probability distributions into reproducing kernel Hilbert spaces\n(RKHS) has enabled powerful nonparametric methods such as the maximum mean\ndiscrepancy (MMD), a statistical distance with strong theoretical and\ncomputational properties. At its core, the MMD relies on kernel mean embeddings\nto represent distributions as mean functions in RKHS. However, it remains\nunclear if the mean function is the only meaningful RKHS representation.\nInspired by generalised quantiles, we introduce the notion of kernel quantile\nembeddings (KQEs). We then use KQEs to construct a family of distances that:\n(i) are probability metrics under weaker kernel conditions than MMD; (ii)\nrecover a kernelised form of the sliced Wasserstein distance; and (iii) can be\nefficiently estimated with near-linear cost. Through hypothesis testing, we\nshow that these distances offer a competitive alternative to MMD and its fast\napproximations.", "published": "2025-05-26 18:27:17", "link": "http://arxiv.org/abs/2505.20433v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?", "abstract": "To reveal when a large language model (LLM) is uncertain about a response,\nuncertainty quantification commonly produces percentage numbers along with the\noutput. But is this all we can do? We argue that in the output space of LLMs,\nthe space of strings, exist strings expressive enough to summarize the\ndistribution over output strings the LLM deems possible. We lay a foundation\nfor this new avenue of uncertainty explication and present SelfReflect, a\ntheoretically-motivated metric to assess how faithfully a string summarizes an\nLLM's internal answer distribution. We show that SelfReflect is able to\ndiscriminate even subtle differences of candidate summary strings and that it\naligns with human judgement, outperforming alternative metrics such as LLM\njudges and embedding comparisons. With SelfReflect, we investigate a number of\nself-summarization methods and find that even state-of-the-art reasoning models\nstruggle to explicate their internal uncertainty. But we find that faithful\nsummarizations can be generated by sampling and summarizing. Our metric enables\nfuture works towards this universal form of LLM uncertainties.", "published": "2025-05-26 17:59:53", "link": "http://arxiv.org/abs/2505.20295v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Lorentz Local Canonicalization: How to Make Any Network Lorentz-Equivariant", "abstract": "Lorentz-equivariant neural networks are becoming the leading architectures\nfor high-energy physics. Current implementations rely on specialized layers,\nlimiting architectural choices. We introduce Lorentz Local Canonicalization\n(LLoCa), a general framework that renders any backbone network exactly\nLorentz-equivariant. Using equivariantly predicted local reference frames, we\nconstruct LLoCa-transformers and graph networks. We adapt a recent approach to\ngeometric message passing to the non-compact Lorentz group, allowing\npropagation of space-time tensorial features. Data augmentation emerges from\nLLoCa as a special choice of reference frame. Our models surpass\nstate-of-the-art accuracy on relevant particle physics tasks, while being\n$4\\times$ faster and using $5$-$100\\times$ fewer FLOPs.", "published": "2025-05-26 17:57:17", "link": "http://arxiv.org/abs/2505.20280v1", "categories": ["stat.ML", "cs.LG", "hep-ph"], "primary_category": "stat.ML"}
{"title": "Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits", "abstract": "Reinforcement learning with outcome-based feedback faces a fundamental\nchallenge: when rewards are only observed at trajectory endpoints, how do we\nassign credit to the right actions? This paper provides the first comprehensive\nanalysis of this problem in online RL with general function approximation. We\ndevelop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm\ncov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the\ncoverability coefficient of the underlying MDP. By leveraging general function\napproximation, our approach works effectively in large or infinite state spaces\nwhere tabular methods fail, requiring only that value functions and reward\nfunctions can be represented by appropriate function classes. Our results also\ncharacterize when outcome-based feedback is statistically separated from\nper-step rewards, revealing an unavoidable exponential separation for certain\nMDPs. For deterministic MDPs, we show how to eliminate the completeness\nassumption, dramatically simplifying the algorithm. We further extend our\napproach to preference-based feedback settings, proving that equivalent\nstatistical efficiency can be achieved even under more limited information.\nTogether, these results constitute a theoretical foundation for understanding\nthe statistical properties of outcome-based reinforcement learning.", "published": "2025-05-26 17:44:08", "link": "http://arxiv.org/abs/2505.20268v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs", "abstract": "Sparse Autoencoders (SAEs) are a prominent tool in mechanistic\ninterpretability (MI) for decomposing neural network activations into\ninterpretable features. However, the aspiration to identify a canonical set of\nfeatures is challenged by the observed inconsistency of learned SAE features\nacross different training runs, undermining the reliability and efficiency of\nMI research. This position paper argues that mechanistic interpretability\nshould prioritize feature consistency in SAEs -- the reliable convergence to\nequivalent feature sets across independent runs. We propose using the Pairwise\nDictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to\noperationalize consistency and demonstrate that high levels are achievable\n(0.80 for TopK SAEs on LLM activations) with appropriate architectural choices.\nOur contributions include detailing the benefits of prioritizing consistency;\nproviding theoretical grounding and synthetic validation using a model\norganism, which verifies PW-MCC as a reliable proxy for ground-truth recovery;\nand extending these findings to real-world LLM data, where high feature\nconsistency strongly correlates with the semantic similarity of learned feature\nexplanations. We call for a community-wide shift towards systematically\nmeasuring feature consistency to foster robust cumulative progress in MI.", "published": "2025-05-26 17:31:36", "link": "http://arxiv.org/abs/2505.20254v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Differentially private ratio statistics", "abstract": "Ratio statistics--such as relative risk and odds ratios--play a central role\nin hypothesis testing, model evaluation, and decision-making across many areas\nof machine learning, including causal inference and fairness analysis. However,\ndespite privacy concerns surrounding many datasets and despite increasing\nadoption of differential privacy, differentially private ratio statistics have\nlargely been neglected by the literature and have only recently received an\ninitial treatment by Lin et al. [1]. This paper attempts to fill this lacuna,\ngiving results that can guide practice in evaluating ratios when the results\nmust be protected by differential privacy. In particular, we show that even a\nsimple algorithm can provide excellent properties concerning privacy, sample\naccuracy, and bias, not just asymptotically but also at quite small sample\nsizes. Additionally, we analyze a differentially private estimator for relative\nrisk, prove its consistency, and develop a method for constructing valid\nconfidence intervals. Our approach bridges a gap in the differential privacy\nliterature and provides a practical solution for ratio estimation in private\nmachine learning pipelines.", "published": "2025-05-26 04:28:27", "link": "http://arxiv.org/abs/2505.20351v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Techniques for Quantum-Computing-Aided Algorithmic Composition: Experiments in Rhythm, Timbre, Harmony, and Space", "abstract": "Quantum computing can be employed in computer-aided music composition to\ncontrol various attributes of the music at different structural levels. This\narticle describes the application of quantum simulation to model compositional\ndecision making, the simulation of quantum particle tracking to produce\nnoise-based timbres, the use of basis state vector rotation to cause changing\nprobabilistic behaviors in granular harmonic textures, and the exploitation of\nquantum measurement error to cause noisy perturbations of spatial soundpaths.\nWe describe the concepts fundamental to these techniques, we provide algorithms\nand software enacting them, and we provide examples demonstrating their\nimplementation in computer-generated music.", "published": "2025-05-26 22:54:28", "link": "http://arxiv.org/abs/2505.20565v1", "categories": ["quant-ph", "cs.ET", "cs.SD", "eess.AS"], "primary_category": "quant-ph"}
{"title": "Effect of laboratory conditions on the perception of virtual stages for music", "abstract": "This manuscript presents initial findings critical for supporting augmented\nacoustics experiments in custom-made hearing booths, addressing a key challenge\nin ensuring perceptual validity and experimental rigor in these highly\nsensitive setups. This validation ensures our proposed methodology is sound,\nguarantees the reliability of future results, and lays the foundational\ngroundwork for subsequent perceptual studies and the development of robust\nguidelines for laboratory design in virtual acoustics research. A preliminary\nstudy on the effect of the acoustical conditions of three different rooms on\nthe perception of virtual stages for music is presented: an anechoic room, a\ncustom-made hearing booth with insufficient sound absorption, and another\ncustom-made hearing booth with achievable sound absorption. The goal of this\nstudy is to assess the impact of these different conditions on the perception\nof virtual stages for music. The results show that the anechoic room and the\nhearing booth with achievable sound absorption have a difference between the\ntotal sound and the virtual sound below the just-noticeable difference, which\nmeans that the virtual sound is not perceived louder than it should. In\ncontrast, the hearing booth with insufficient sound absorption has a difference\nabove the just-noticeable difference, which means that the virtual sound is\nperceived louder than it should. This study provides a preliminary validation\nof the proposed methodology for assessing the acoustical conditions of\ncustom-made hearing booths in stage acoustics experiments. Future work will\ninclude a more comprehensive analysis of the results, including the effect of\ndifferent sound sources.", "published": "2025-05-26 22:25:35", "link": "http://arxiv.org/abs/2505.20552v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ReverbFX: A Dataset of Room Impulse Responses Derived from Reverb Effect Plugins for Singing Voice Dereverberation", "abstract": "We present ReverbFX, a new room impulse response (RIR) dataset designed for\nsinging voice dereverberation research. Unlike existing datasets based on real\nrecorded RIRs, ReverbFX features a diverse collection of RIRs captured from\nvarious reverb audio effect plugins commonly used in music production. We\nconduct comprehensive experiments using the proposed dataset to benchmark the\nchallenge of dereverberation of singing voice recordings affected by artificial\nreverbs. We train two state-of-the-art generative models using ReverbFX and\ndemonstrate that models trained with plugin-derived RIRs outperform those\ntrained on realistic RIRs in artificial reverb scenarios.", "published": "2025-05-26 21:39:17", "link": "http://arxiv.org/abs/2505.20533v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Training Articulatory Inversion Models for Inter-Speaker Consistency", "abstract": "Acoustic-to-Articulatory Inversion (AAI) attempts to model the inverse\nmapping from speech to articulation. Exact articulatory prediction from speech\nalone may be impossible, as speakers can choose different forms of articulation\nseemingly without reference to their vocal tract structure. However, once a\nspeaker has selected an articulatory form, their productions vary minimally.\nRecent works in AAI have proposed adapting Self-Supervised Learning (SSL)\nmodels to single-speaker datasets, claiming that these single-speaker models\nprovide a universal articulatory template. In this paper, we investigate\nwhether SSL-adapted models trained on single and multi-speaker data produce\narticulatory targets which are consistent across speaker identities for English\nand Russian. We do this through the use of a novel evaluation method which\nextracts articulatory targets using minimal pair sets. We also present a\ntraining method which can improve inter-speaker consistency using only speech\ndata.", "published": "2025-05-26 21:19:20", "link": "http://arxiv.org/abs/2505.20529v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis", "abstract": "We introduce ArVoice, a multi-speaker Modern Standard Arabic (MSA) speech\ncorpus with diacritized transcriptions, intended for multi-speaker speech\nsynthesis, and can be useful for other tasks such as speech-based diacritic\nrestoration, voice conversion, and deepfake detection. ArVoice comprises: (1) a\nnew professionally recorded set from six voice talents with diverse\ndemographics, (2) a modified subset of the Arabic Speech Corpus; and (3)\nhigh-quality synthetic speech from two commercial systems. The complete corpus\nconsists of a total of 83.52 hours of speech across 11 voices; around 10 hours\nconsist of human voices from 7 speakers. We train three open-source TTS and two\nvoice conversion systems to illustrate the use cases of the dataset. The corpus\nis available for research use.", "published": "2025-05-26 20:15:15", "link": "http://arxiv.org/abs/2505.20506v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "In-context learning capabilities of Large Language Models to detect suicide risk among adolescents from speech transcripts", "abstract": "Early suicide risk detection in adolescents is critical yet hindered by\nscalability challenges of current assessments. This paper presents our approach\nto the first SpeechWellness Challenge (SW1), which aims to assess suicide risk\nin Chinese adolescents through speech analysis. Due to speech anonymization\nconstraints, we focused on linguistic features, leveraging Large Language\nModels (LLMs) for transcript-based classification. Using DSPy for systematic\nprompt engineering, we developed a robust in-context learning approach that\noutperformed traditional fine-tuning on both linguistic and acoustic markers.\nOur systems achieved third and fourth places among 180+ submissions, with 0.68\naccuracy (F1=0.7) using only transcripts. Ablation analyses showed that\nincreasing prompt example improved performance (p=0.003), with varying effects\nacross model types and sizes. These findings advance automated suicide risk\nassessment and demonstrate LLMs' value in mental health applications.", "published": "2025-05-26 19:52:57", "link": "http://arxiv.org/abs/2505.20491v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust fine-tuning of speech recognition models via model merging: application to disordered speech", "abstract": "Automatic Speech Recognition (ASR) has advanced with Speech Foundation Models\n(SFMs), yet performance degrades on dysarthric speech due to variability and\nlimited data. This study as part of the submission to the Speech Accessibility\nchallenge, explored model merging to improve ASR generalization using Whisper\nas the base SFM. We compared fine-tuning with single-trajectory merging,\ncombining models from one fine-tuning path, and multi-run merging, merging\nindependently trained models. Our best multi-run merging approach achieved a\n12% relative decrease of WER over classic fine-tuning, and a 16.2% relative\ndecrease on long-form audios, a major loss contributor in dysarthric ASR.\nMerging more and more models led to continuous gains, remained effective in\nlow-data regimes, and generalized across model architectures. These results\nhighlight model merging as an easily replicable adaptation method that\nconsistently improves ASR without additional inference cost or hyperparameter\ntuning.", "published": "2025-05-26 19:21:42", "link": "http://arxiv.org/abs/2505.20477v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OpenNIRScap: An Open-Source, Low-Cost Wearable Near-Infrared Spectroscopy-based Brain Interfacing Cap", "abstract": "Functional Near-Infrared Spectroscopy (fNIRS) is a non-invasive, real-time\nmethod for monitoring brain activity by measuring hemodynamic responses in the\ncerebral cortex. However, existing systems are expensive, bulky, and limited to\nclinical or research environments. This paper introduces OpenNIRScap, an\nopen-source, low-cost, and wearable fNIRS system designed to make real-time\nbrain monitoring more accessible in everyday environments. The device features\n24 custom-designed sensor boards with dual-wavelength light emitters and\nphotodiode detectors, a central electrical control unit (ECU) with analog\nmultiplexing, and a real-time data processing pipeline. Bench validation and\npilot tests on volunteers have confirmed the ability of the system to capture\ncognitively evoked hemodynamic responses, supporting its potential as an\naffordable tool for cognitive monitoring and portable neurotechnology\napplications. The hardware, software, and graphical user interface have all\nbeen open-sourced and made publicly available at the following link:\nhttps://github.com/tonykim07/fNIRS.", "published": "2025-05-26 20:20:46", "link": "http://arxiv.org/abs/2505.20509v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CardioPatternFormer: Pattern-Guided Attention for Interpretable ECG Classification with Transformer Architecture", "abstract": "Accurate ECG interpretation is vital, yet complex cardiac data and\n\"black-box\" AI models limit clinical utility. Inspired by Transformer\narchitectures' success in NLP for understanding sequential data, we frame ECG\nas the heart's unique \"language\" of temporal patterns. We present\nCardioPatternFormer, a novel Transformer-based model for interpretable ECG\nclassification. It employs a sophisticated attention mechanism to precisely\nidentify and classify diverse cardiac patterns, excelling at discerning subtle\nanomalies and distinguishing multiple co-occurring conditions. This\npattern-guided attention provides clear insights by highlighting influential\nsignal regions, effectively allowing the \"heart to talk\" through transparent\ninterpretations. CardioPatternFormer demonstrates robust performance on\nchallenging ECGs, including complex multi-pathology cases. Its interpretability\nvia attention maps enables clinicians to understand the model's rationale,\nfostering trust and aiding informed diagnostic decisions. This work offers a\npowerful, transparent solution for advanced ECG analysis, paving the way for\nmore reliable and clinically actionable AI in cardiology.", "published": "2025-05-26 19:36:58", "link": "http://arxiv.org/abs/2505.20481v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "BrainStratify: Coarse-to-Fine Disentanglement of Intracranial Neural Dynamics", "abstract": "Decoding speech directly from neural activity is a central goal in\nbrain-computer interface (BCI) research. In recent years, exciting advances\nhave been made through the growing use of intracranial field potential\nrecordings, such as stereo-ElectroEncephaloGraphy (sEEG) and\nElectroCorticoGraphy (ECoG). These neural signals capture rich population-level\nactivity but present key challenges: (i) task-relevant neural signals are\nsparsely distributed across sEEG electrodes, and (ii) they are often entangled\nwith task-irrelevant neural signals in both sEEG and ECoG. To address these\nchallenges, we introduce a unified Coarse-to-Fine neural disentanglement\nframework, BrainStratify, which includes (i) identifying functional groups\nthrough spatial-context-guided temporal-spatial modeling, and (ii)\ndisentangling distinct neural dynamics within the target functional group using\nDecoupled Product Quantization (DPQ). We evaluate BrainStratify on two\nopen-source sEEG datasets and one (epidural) ECoG dataset, spanning tasks like\nvocal production and speech perception. Extensive experiments show that\nBrainStratify, as a unified framework for decoding speech from intracranial\nneural signals, significantly outperforms previous decoding methods. Overall,\nby combining data-driven stratification with neuroscience-inspired modularity,\nBrainStratify offers a robust and interpretable solution for speech decoding\nfrom intracranial recordings.", "published": "2025-05-26 19:36:39", "link": "http://arxiv.org/abs/2505.20480v1", "categories": ["eess.SP", "cs.CL", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Federated Learning-Distillation Alternation for Resource-Constrained IoT", "abstract": "Federated learning (FL) faces significant challenges in Internet of Things\n(IoT) networks due to device limitations in energy and communication resources,\nespecially when considering the large size of FL models. From an energy\nperspective, the challenge is aggravated if devices rely on energy harvesting\n(EH), as energy availability can vary significantly over time, influencing the\naverage number of participating users in each iteration. Additionally, the\ntransmission of large model updates is more susceptible to interference from\nuncorrelated background traffic in shared wireless environments. As an\nalternative, federated distillation (FD) reduces communication overhead and\nenergy consumption by transmitting local model outputs, which are typically\nmuch smaller than the entire model used in FL. However, this comes at the cost\nof reduced model accuracy. Therefore, in this paper, we propose FL-distillation\nalternation (FLDA). In FLDA, devices alternate between FD and FL phases,\nbalancing model information with lower communication overhead and energy\nconsumption per iteration. We consider a multichannel slotted-ALOHA EH-IoT\nnetwork subject to background traffic/interference. In such a scenario, FLDA\ndemonstrates higher model accuracy than both FL and FD, and achieves faster\nconvergence than FL. Moreover, FLDA achieves target accuracies saving up to 98%\nin energy consumption, while also being less sensitive to interference, both\nrelative to FL.", "published": "2025-05-26 18:52:02", "link": "http://arxiv.org/abs/2505.20456v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems", "abstract": "The emergence of agentic recommender systems powered by Large Language Models\n(LLMs) represents a paradigm shift in personalized recommendations, leveraging\nLLMs' advanced reasoning and role-playing capabilities to enable autonomous,\nadaptive decision-making. Unlike traditional recommendation approaches, agentic\nrecommender systems can dynamically gather and interpret user-item interactions\nfrom complex environments, generating robust recommendation strategies that\ngeneralize across diverse scenarios. However, the field currently lacks\nstandardized evaluation protocols to systematically assess these methods. To\naddress this critical gap, we propose: (1) an interactive textual\nrecommendation simulator incorporating rich user and item metadata and three\ntypical evaluation scenarios (classic, evolving-interest, and cold-start\nrecommendation tasks); (2) a unified modular framework for developing and\nstudying agentic recommender systems; and (3) the first comprehensive benchmark\ncomparing 10 classical and agentic recommendation methods. Our findings\ndemonstrate the superiority of agentic systems and establish actionable design\nguidelines for their core components. The benchmark environment has been\nrigorously validated through an open challenge and remains publicly available\nwith a continuously maintained\nleaderboard~\\footnote[2]{https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html},\nfostering ongoing community engagement and reproducible research. The benchmark\nis available at:\n\\hyperlink{https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}.", "published": "2025-05-26 07:45:11", "link": "http://arxiv.org/abs/2505.19623v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Maxwell \u00e0 la Helmholtz: Electromagnetic scattering by 3D perfect electric conductors via Helmholtz integral operators", "abstract": "This paper introduces a novel class of indirect boundary integral equation\n(BIE) formulations for the solution of electromagnetic scattering problems\ninvolving smooth perfectly electric conductors (PECs) in three-dimensions.\nThese combined-field-type BIE formulations rely exclusively on classical\nHelmholtz boundary operators, resulting in provably well-posed,\nfrequency-robust, Fredholm second-kind BIEs. Notably, we prove that the\nproposed formulations are free from spurious resonances, while retaining the\nversatility of Helmholtz integral operators. The approach is based on the\nequivalence between the Maxwell PEC scattering problem and two independent\nvector Helmholtz boundary value problems for the electric and magnetic fields,\nwith boundary conditions defined in terms of the Dirichlet and Neumann traces\nof the corresponding vector Helmholtz solutions. While certain aspects of this\nequivalence (for the electric field) have been previously exploited in the\nso-called field-only BIE formulations, we here rigorously establish and\ngeneralize the equivalence between Maxwell and Helmholtz problems for both\nfields. Finally, a variety of numerical examples highlights the robustness and\naccuracy of the proposed approach when combined with Density\nInterpolation-based Nystr\\\"om methods and fast linear algebra solvers,\nimplemented in the open-source Julia package Inti$.$jl.", "published": "2025-05-26 18:34:41", "link": "http://arxiv.org/abs/2505.20440v2", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "78A40, 65R20, 65N38, 65J10, 45B05"], "primary_category": "math.NA"}
{"title": "A Comprehensive Real-World Assessment of Audio Watermarking Algorithms: Will They Survive Neural Codecs?", "abstract": "We introduce the Robust Audio Watermarking Benchmark (RAW-Bench), a benchmark\nfor evaluating deep learning-based audio watermarking methods with standardized\nand systematic comparisons. To simulate real-world usage, we introduce a\ncomprehensive audio attack pipeline with various distortions such as\ncompression, background noise, and reverberation, along with a diverse test\ndataset including speech, environmental sounds, and music recordings.\nEvaluating four existing watermarking methods on RAW-bench reveals two main\ninsights: (i) neural compression techniques pose the most significant\nchallenge, even when algorithms are trained with such compressions; and (ii)\ntraining with audio attacks generally improves robustness, although it is\ninsufficient in some cases. Furthermore, we find that specific distortions,\nsuch as polarity inversion, time stretching, or reverb, seriously affect\ncertain methods. The evaluation framework is accessible at\ngithub.com/SonyResearch/raw_bench.", "published": "2025-05-26 08:21:58", "link": "http://arxiv.org/abs/2505.19663v2", "categories": ["cs.SD", "cs.AI", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework", "abstract": "In cloud-native systems, Kubernetes clusters with interdependent services\noften face challenges to their operational resilience due to poor workload\nmanagement issues such as resource blocking, bottlenecks, or continuous pod\ncrashes. These vulnerabilities are further amplified in adversarial scenarios,\nsuch as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal\nPod Autoscaling (HPA) approaches struggle to address such dynamic conditions,\nwhile reinforcement learning-based methods, though more adaptable, typically\noptimize single goals like latency or resource usage, neglecting broader\nfailure scenarios. We propose decomposing the overarching goal of maintaining\noperational resilience into failure-specific sub-goals delegated to\ncollaborative agents, collectively forming an HPA Multi-Agent System (MAS). We\nintroduce an automated, four-phase online framework for HPA MAS design: 1)\nmodeling a digital twin built from cluster traces; 2) training agents in\nsimulation using roles and missions tailored to failure contexts; 3) analyzing\nagent behaviors for explainability; and 4) transferring learned policies to the\nreal cluster. Experimental results demonstrate that the generated HPA MASs\noutperform three state-of-the-art HPA systems in sustaining operational\nresilience under various adversarial conditions in a proposed complex cluster.", "published": "2025-05-26 20:39:31", "link": "http://arxiv.org/abs/2505.21559v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "The challenge of hidden gifts in multi-agent reinforcement learning", "abstract": "Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings.", "published": "2025-05-26 23:28:52", "link": "http://arxiv.org/abs/2505.20579v2", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "It's High Time: A Survey of Temporal Information Retrieval and Question Answering", "abstract": "Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nInformation Retrieval and Temporal Question Answering, two research areas aimed\nat handling and understanding time-sensitive information. As the amount of\ntime-stamped content from sources like news articles, web archives, and\nknowledge bases increases, systems must address challenges such as detecting\ntemporal intent, normalizing time expressions, ordering events, and reasoning\nover evolving or ambiguous facts. These challenges are critical across many\ndynamic and time-sensitive domains, from news and encyclopedias to science,\nhistory, and social media. We review both traditional approaches and modern\nneural methods, including those that use transformer models and Large Language\nModels (LLMs). We also review recent advances in temporal language modeling,\nmulti-hop reasoning, and retrieval-augmented generation (RAG), alongside\nbenchmark datasets and evaluation strategies that test temporal robustness,\nrecency awareness, and generalization.", "published": "2025-05-26 17:21:26", "link": "http://arxiv.org/abs/2505.20243v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents", "abstract": "Retrieval-augmented generation (RAG) based large language models (LLMs) are\nwidely used in finance for their excellent performance on knowledge-intensive\ntasks. However, standardized documents (e.g., SEC filing) share similar formats\nsuch as repetitive boilerplate texts, and similar table structures. This\nsimilarity forces traditional RAG methods to misidentify near-duplicate text,\nleading to duplicate retrieval that undermines accuracy and completeness. To\naddress these issues, we propose the Hierarchical Retrieval with Evidence\nCuration (HiREC) framework. Our approach first performs hierarchical retrieval\nto reduce confusion among similar texts. It first retrieve related documents\nand then selects the most relevant passages from the documents. The evidence\ncuration process removes irrelevant passages. When necessary, it automatically\ngenerates complementary queries to collect missing information. To evaluate our\napproach, we construct and release a Large-scale Open-domain Financial (LOFin)\nquestion answering benchmark that includes 145,897 SEC documents and 1,595\nquestion-answer pairs. Our code and data are available at\nhttps://github.com/deep-over/LOFin-bench-HiREC.", "published": "2025-05-26 11:08:23", "link": "http://arxiv.org/abs/2505.20368v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "EGA-V1: Unifying Online Advertising with End-to-End Learning", "abstract": "Modern industrial advertising systems commonly employ Multi-stage Cascading\nArchitectures (MCA) to balance computational efficiency with ranking accuracy.\nHowever, this approach presents two fundamental challenges: (1) performance\ninconsistencies arising from divergent optimization targets and capability\ndifferences between stages, and (2) failure to account for advertisement\nexternalities - the complex interactions between candidate ads during ranking.\nThese limitations ultimately compromise system effectiveness and reduce\nplatform profitability. In this paper, we present EGA-V1, an end-to-end\ngenerative architecture that unifies online advertising ranking as one model.\nEGA-V1 replaces cascaded stages with a single model to directly generate\noptimal ad sequences from the full candidate ad corpus in location-based\nservices (LBS). The primary challenges associated with this approach stem from\nhigh costs of feature processing and computational bottlenecks in modeling\nexternalities of large-scale candidate pools. To address these challenges,\nEGA-V1 introduces an algorithm and engine co-designed hybrid feature service to\ndecouple user and ad feature processing, reducing latency while preserving\nexpressiveness. To efficiently extract intra- and cross-sequence mutual\ninformation, we propose RecFormer with an innovative cluster-attention\nmechanism as its core architectural component. Furthermore, we propose a\nbi-stage training strategy that integrates pre-training with reinforcement\nlearning-based post-training to meet sophisticated platform and advertising\nobjectives. Extensive offline evaluations on public benchmarks and large-scale\nonline A/B testing on industrial advertising platform have demonstrated the\nsuperior performance of EGA-V1 over state-of-the-art MCAs.", "published": "2025-05-26 09:33:54", "link": "http://arxiv.org/abs/2505.19755v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
