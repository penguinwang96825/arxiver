{"title": "Enhanced Aspect-Based Sentiment Analysis Models with Progressive\n  Self-supervised Attention Learning", "abstract": "In aspect-based sentiment analysis (ABSA), many neural models are equipped\nwith an attention mechanism to quantify the contribution of each context word\nto sentiment prediction. However, such a mechanism suffers from one drawback:\nonly a few frequent words with sentiment polarities are tended to be taken into\nconsideration for final sentiment decision while abundant infrequent sentiment\nwords are ignored by models. To deal with this issue, we propose a progressive\nself-supervised attention learning approach for attentional ABSA models. In\nthis approach, we iteratively perform sentiment prediction on all training\ninstances, and continually learn useful attention supervision information in\nthe meantime. During training, at each iteration, context words with the\nhighest impact on sentiment prediction, identified based on their attention\nweights or gradients, are extracted as words with active/misleading influence\non the correct/incorrect prediction for each instance. Words extracted in this\nway are masked for subsequent iterations. To exploit these extracted words for\nrefining ABSA models, we augment the conventional training objective with a\nregularization term that encourages ABSA models to not only take full advantage\nof the extracted active context words but also decrease the weights of those\nmisleading words. We integrate the proposed approach into three\nstate-of-the-art neural ABSA models. Experiment results and in-depth analyses\nshow that our approach yields better attention results and significantly\nenhances the performance of all three models. We release the source code and\ntrained models at https://github.com/DeepLearnXMU/PSSAttention.", "published": "2021-03-05 02:50:05", "link": "http://arxiv.org/abs/2103.03446v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic and Semantic-driven Learning for Open Information Extraction", "abstract": "One of the biggest bottlenecks in building accurate, high coverage neural\nopen IE systems is the need for large labelled corpora. The diversity of open\ndomain corpora and the variety of natural language expressions further\nexacerbate this problem. In this paper, we propose a syntactic and\nsemantic-driven learning approach, which can learn neural open IE models\nwithout any human-labelled data by leveraging syntactic and semantic knowledge\nas noisier, higher-level supervisions. Specifically, we first employ syntactic\npatterns as data labelling functions and pretrain a base model using the\ngenerated labels. Then we propose a syntactic and semantic-driven reinforcement\nlearning algorithm, which can effectively generalize the base model to open\nsituations with high accuracy. Experimental results show that our approach\nsignificantly outperforms the supervised counterparts, and can even achieve\ncompetitive performance to supervised state-of-the-art (SoA) model", "published": "2021-03-05 02:59:40", "link": "http://arxiv.org/abs/2103.03448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dual Pointer Network for Fast Extraction of Multiple Relations in a\n  Sentence", "abstract": "Relation extraction is a type of information extraction task that recognizes\nsemantic relationships between entities in a sentence. Many previous studies\nhave focused on extracting only one semantic relation between two entities in a\nsingle sentence. However, multiple entities in a sentence are associated\nthrough various relations. To address this issue, we propose a relation\nextraction model based on a dual pointer network with a multi-head attention\nmechanism. The proposed model finds n-to-1 subject-object relations using a\nforward object decoder. Then, it finds 1-to-n subject-object relations using a\nbackward subject decoder. Our experiments confirmed that the proposed model\noutperformed previous models, with an F1-score of 80.8% for the ACE-2005 corpus\nand an F1-score of 78.3% for the NYT corpus.", "published": "2021-03-05 07:36:54", "link": "http://arxiv.org/abs/2103.03509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA", "abstract": "In community-based question answering (CQA) platforms, automatic answer\nranking for a given question is critical for finding potentially popular\nanswers in early times. The mainstream approaches learn to generate answer\nranking scores based on the matching degree between question and answer\nrepresentations as well as the influence of respondents. However, they\nencounter two main limitations: (1) Correlations between answers in the same\nquestion are often overlooked. (2) Question and respondent representations are\nbuilt independently of specific answers before affecting answer\nrepresentations. To address the limitations, we devise a novel graph-based\ntri-attention network, namely GTAN, which has two innovations. First, GTAN\nproposes to construct a graph for each question and learn answer correlations\nfrom each graph through graph neural networks (GNNs). Second, based on the\nrepresentations learned from GNNs, an alternating tri-attention method is\ndeveloped to alternatively build target-aware respondent representations,\nanswer-specific question representations, and context-aware answer\nrepresentations by attention computation. GTAN finally integrates the above\nrepresentations to generate answer ranking scores. Experiments on three\nreal-world CQA datasets demonstrate GTAN significantly outperforms\nstate-of-the-art answer ranking methods, validating the rationality of the\nnetwork architecture.", "published": "2021-03-05 10:40:38", "link": "http://arxiv.org/abs/2103.03583v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Pretrained Multilingual BERT Model for Indonesian\n  Aspect-based Sentiment Analysis", "abstract": "Although previous research on Aspect-based Sentiment Analysis (ABSA) for\nIndonesian reviews in hotel domain has been conducted using CNN and XGBoost,\nits model did not generalize well in test data and high number of OOV words\ncontributed to misclassification cases. Nowadays, most state-of-the-art results\nfor wide array of NLP tasks are achieved by utilizing pretrained language\nrepresentation. In this paper, we intend to incorporate one of the foremost\nlanguage representation model, BERT, to perform ABSA in Indonesian reviews\ndataset. By combining multilingual BERT (m-BERT) with task transformation\nmethod, we manage to achieve significant improvement by 8% on the F1-score\ncompared to the result from our previous study.", "published": "2021-03-05 15:05:51", "link": "http://arxiv.org/abs/2103.03732v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-document Summarization using Semantic Role Labeling and Semantic\n  Graph for Indonesian News Article", "abstract": "In this paper, we proposed a multi-document summarization system using\nsemantic role labeling (SRL) and semantic graph for Indonesian news articles.\nIn order to improve existing summarizer, our system modified summarizer that\nemployed subject, predicate, object, and adverbial (SVOA) extraction for\npredicate argument structure (PAS) extraction. SVOA extraction is replaced with\nSRL model for Indonesian. We also replace the genetic algorithm to identify\nimportant PAS with the decision tree classifier since the summarizer without\ngenetic algorithm gave better performance. The decision tree model is employed\nto identify important PAS. The decision tree model with 10 features achieved\nbetter performance than decision tree with 4 sentence features. Experiments and\nevaluations are conducted to generate 100 words summary and 200 words summary.\nThe evaluation shows the proposed model get 0.313 average ROUGE-2 recall in 100\nwords summary and 0.394 average ROUGE-2 recall in 200 words summary.", "published": "2021-03-05 15:09:25", "link": "http://arxiv.org/abs/2103.03736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Recursive Processing for Neural-Symbolic Affect-Target\n  Associations", "abstract": "Explaining the outcome of deep learning decisions based on affect is\nchallenging but necessary if we expect social companion robots to interact with\nusers on an emotional level. In this paper, we present a commonsense approach\nthat utilizes an interpretable hybrid neural-symbolic system to associate\nextracted targets, noun chunks determined to be associated with the expressed\nemotion, with affective labels from a natural language expression. We leverage\na pre-trained neural network that is well adapted to tree and sub-tree\nprocessing, the Dependency Tree-LSTM, to learn the affect labels of dynamic\ntargets, determined through symbolic rules, in natural language. We find that\nmaking use of the unique properties of the recursive network provides higher\naccuracy and interpretability when compared to other unstructured and\nsequential methods for determining target-affect associations in an\naspect-based sentiment analysis task.", "published": "2021-03-05 15:32:38", "link": "http://arxiv.org/abs/2103.03755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "There Once Was a Really Bad Poet, It Was Automated but You Didn't Know\n  It", "abstract": "Limerick generation exemplifies some of the most difficult challenges faced\nin poetry generation, as the poems must tell a story in only five lines, with\nconstraints on rhyme, stress, and meter. To address these challenges, we\nintroduce LimGen, a novel and fully automated system for limerick generation\nthat outperforms state-of-the-art neural network-based poetry models, as well\nas prior rule-based poetry models. LimGen consists of three important pieces:\nthe Adaptive Multi-Templated Constraint algorithm that constrains our search to\nthe space of realistic poems, the Multi-Templated Beam Search algorithm which\nsearches efficiently through the space, and the probabilistic Storyline\nalgorithm that provides coherent storylines related to a user-provided prompt\nword. The resulting limericks satisfy poetic constraints and have thematically\ncoherent storylines, which are sometimes even funny (when we are lucky).", "published": "2021-03-05 16:03:55", "link": "http://arxiv.org/abs/2103.03775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AnswerQuest: A System for Generating Question-Answer Items from\n  Multi-Paragraph Documents", "abstract": "One strategy for facilitating reading comprehension is to present information\nin a question-and-answer format. We demo a system that integrates the tasks of\nquestion answering (QA) and question generation (QG) in order to produce Q&A\nitems that convey the content of multi-paragraph documents. We report some\nexperiments for QA and QG that yield improvements on both tasks, and assess how\nthey interact to produce a list of Q&A items for a text. The demo is accessible\nat qna.sdl.com.", "published": "2021-03-05 17:36:04", "link": "http://arxiv.org/abs/2103.03820v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overcoming Poor Word Embeddings with Word Definitions", "abstract": "Modern natural language understanding models depend on pretrained subword\nembeddings, but applications may need to reason about words that were never or\nrarely seen during pretraining. We show that examples that depend critically on\na rarer word are more challenging for natural language inference models. Then\nwe explore how a model could learn to use definitions, provided in natural\ntext, to overcome this handicap. Our model's understanding of a definition is\nusually weaker than a well-modeled word embedding, but it recovers most of the\nperformance gap from using a completely untrained word.", "published": "2021-03-05 17:57:54", "link": "http://arxiv.org/abs/2103.03842v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IOT: Instance-wise Layer Reordering for Transformer Structures", "abstract": "With sequentially stacked self-attention, (optional) encoder-decoder\nattention, and feed-forward layers, Transformer achieves big success in natural\nlanguage processing (NLP), and many variants have been proposed. Currently,\nalmost all these models assume that the layer order is fixed and kept the same\nacross data samples. We observe that different data samples actually favor\ndifferent orders of the layers. Based on this observation, in this work, we\nbreak the assumption of the fixed layer order in the Transformer and introduce\ninstance-wise layer reordering into the model structure. Our Instance-wise\nOrdered Transformer (IOT) can model variant functions by reordered layers,\nwhich enables each sample to select the better one to improve the model\nperformance under the constraint of almost the same number of parameters. To\nachieve this, we introduce a light predictor with negligible parameter and\ninference cost to decide the most capable and favorable layer order for any\ninput sequence. Experiments on 3 tasks (neural machine translation, abstractive\nsummarization, and code generation) and 9 datasets demonstrate consistent\nimprovements of our method. We further show that our method can also be applied\nto other architectures beyond Transformer. Our code is released at Github.", "published": "2021-03-05 03:44:42", "link": "http://arxiv.org/abs/2103.03457v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hierarchical Transformer for Multilingual Machine Translation", "abstract": "The choice of parameter sharing strategy in multilingual machine translation\nmodels determines how optimally parameter space is used and hence, directly\ninfluences ultimate translation quality. Inspired by linguistic trees that show\nthe degree of relatedness between different languages, the new general approach\nto parameter sharing in multilingual machine translation was suggested\nrecently. The main idea is to use these expert language hierarchies as a basis\nfor multilingual architecture: the closer two languages are, the more\nparameters they share. In this work, we test this idea using the Transformer\narchitecture and show that despite the success in previous work there are\nproblems inherent to training such hierarchical models. We demonstrate that in\ncase of carefully chosen training strategy the hierarchical architecture can\noutperform bilingual models and multilingual models with full parameter\nsharing.", "published": "2021-03-05 10:51:47", "link": "http://arxiv.org/abs/2103.03589v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Topology-Aware Correlations Between Relations for Inductive Link\n  Prediction in Knowledge Graphs", "abstract": "Inductive link prediction -- where entities during training and inference\nstages can be different -- has been shown to be promising for completing\ncontinuously evolving knowledge graphs. Existing models of inductive reasoning\nmainly focus on predicting missing links by learning logical rules. However,\nmany existing approaches do not take into account semantic correlations between\nrelations, which are commonly seen in real-world knowledge graphs. To address\nthis challenge, we propose a novel inductive reasoning approach, namely TACT,\nwhich can effectively exploit Topology-Aware CorrelaTions between relations in\nan entity-independent manner. TACT is inspired by the observation that the\nsemantic correlation between two relations is highly correlated to their\ntopological structure in knowledge graphs. Specifically, we categorize all\nrelation pairs into several topological patterns, and then propose a Relational\nCorrelation Network (RCN) to learn the importance of the different patterns for\ninductive link prediction. Experiments demonstrate that TACT can effectively\nmodel semantic correlations between relations, and significantly outperforms\nexisting state-of-the-art methods on benchmark datasets for the inductive link\nprediction task.", "published": "2021-03-05 13:00:10", "link": "http://arxiv.org/abs/2103.03642v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Parsing Indonesian Sentence into Abstract Meaning Representation using\n  Machine Learning Approach", "abstract": "Abstract Meaning Representation (AMR) provides many information of a sentence\nsuch as semantic relations, coreferences, and named entity relation in one\nrepresentation. However, research on AMR parsing for Indonesian sentence is\nfairly limited. In this paper, we develop a system that aims to parse an\nIndonesian sentence using a machine learning approach. Based on Zhang et al.\nwork, our system consists of three steps: pair prediction, label prediction,\nand graph construction. Pair prediction uses dependency parsing component to\nget the edges between the words for the AMR. The result of pair prediction is\npassed to the label prediction process which used a supervised learning\nalgorithm to predict the label between the edges of the AMR. We used simple\nsentence dataset that is gathered from articles and news article sentences. Our\nmodel achieved the SMATCH score of 0.820 for simple sentence test data.", "published": "2021-03-05 15:01:59", "link": "http://arxiv.org/abs/2103.03730v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Byte2Speech Models for Scalable Low-resource Speech\n  Synthesis", "abstract": "To scale neural speech synthesis to various real-world languages, we present\na multilingual end-to-end framework that maps byte inputs to spectrograms, thus\nallowing arbitrary input scripts. Besides strong results on 40+ languages, the\nframework demonstrates capabilities to adapt to new languages under extreme\nlow-resource and even few-shot scenarios of merely 40s transcribed recording,\nwithout the need of per-language resources like lexicon, extra corpus,\nauxiliary models, or linguistic expertise, thus ensuring scalability. While it\nretains satisfactory intelligibility and naturalness matching rich-resource\nmodels. Exhaustive comparative and ablation studies are performed to reveal the\npotential of the framework for low-resource languages. Furthermore, we propose\na novel method to extract language-specific sub-networks in a multilingual\nmodel for a better understanding of its mechanism.", "published": "2021-03-05 08:41:45", "link": "http://arxiv.org/abs/2103.03541v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Transfer Learning based Speech Affect Recognition in Urdu", "abstract": "It has been established that Speech Affect Recognition for low resource\nlanguages is a difficult task. Here we present a Transfer learning based Speech\nAffect Recognition approach in which: we pre-train a model for high resource\nlanguage affect recognition task and fine tune the parameters for low resource\nlanguage using Deep Residual Network. Here we use standard four data sets to\ndemonstrate that transfer learning can solve the problem of data scarcity for\nAffect Recognition task. We demonstrate that our approach is efficient by\nachieving 74.7 percent UAR on RAVDESS as source and Urdu data set as a target.\nThrough an ablation study, we have identified that pre-trained model adds most\nof the features information, improvement in results and solves less data\nissues. Using this knowledge, we have also experimented on SAVEE and EMO-DB\ndata set by setting Urdu as target language where only 400 utterances of data\nis available. This approach achieves high Unweighted Average Recall (UAR) when\ncompared with existing algorithms.", "published": "2021-03-05 10:30:58", "link": "http://arxiv.org/abs/2103.03580v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "WordBias: An Interactive Visual Tool for Discovering Intersectional\n  Biases Encoded in Word Embeddings", "abstract": "Intersectional bias is a bias caused by an overlap of multiple social factors\nlike gender, sexuality, race, disability, religion, etc. A recent study has\nshown that word embedding models can be laden with biases against\nintersectional groups like African American females, etc. The first step\ntowards tackling such intersectional biases is to identify them. However,\ndiscovering biases against different intersectional groups remains a\nchallenging task. In this work, we present WordBias, an interactive visual tool\ndesigned to explore biases against intersectional groups encoded in static word\nembeddings. Given a pretrained static word embedding, WordBias computes the\nassociation of each word along different groups based on race, age, etc. and\nthen visualizes them using a novel interactive interface. Using a case study,\nwe demonstrate how WordBias can help uncover biases against intersectional\ngroups like Black Muslim Males, Poor Females, etc. encoded in word embedding.\nIn addition, we also evaluate our tool using qualitative feedback from expert\ninterviews. The source code for this tool can be publicly accessed for\nreproducibility at github.com/bhavyaghai/WordBias.", "published": "2021-03-05 11:04:35", "link": "http://arxiv.org/abs/2103.03598v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Rissanen Data Analysis: Examining Dataset Characteristics via\n  Description Length", "abstract": "We introduce a method to determine if a certain capability helps to achieve\nan accurate model of given data. We view labels as being generated from the\ninputs by a program composed of subroutines with different capabilities, and we\nposit that a subroutine is useful if and only if the minimal program that\ninvokes it is shorter than the one that does not. Since minimum program length\nis uncomputable, we instead estimate the labels' minimum description length\n(MDL) as a proxy, giving us a theoretically-grounded method for analyzing\ndataset characteristics. We call the method Rissanen Data Analysis (RDA) after\nthe father of MDL, and we showcase its applicability on a wide variety of\nsettings in NLP, ranging from evaluating the utility of generating subquestions\nbefore answering a question, to analyzing the value of rationales and\nexplanations, to investigating the importance of different parts of speech, and\nuncovering dataset gender bias.", "published": "2021-03-05 18:58:32", "link": "http://arxiv.org/abs/2103.03872v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Measuring Mathematical Problem Solving With the MATH Dataset", "abstract": "Many intellectual endeavors require mathematical problem solving, but this\nskill remains beyond the capabilities of computers. To measure this ability in\nmachine learning models, we introduce MATH, a new dataset of 12,500 challenging\ncompetition mathematics problems. Each problem in MATH has a full step-by-step\nsolution which can be used to teach models to generate answer derivations and\nexplanations. To facilitate future research and increase accuracy on MATH, we\nalso contribute a large auxiliary pretraining dataset which helps teach models\nthe fundamentals of mathematics. Even though we are able to increase accuracy\non MATH, our results show that accuracy remains relatively low, even with\nenormous Transformer models. Moreover, we find that simply increasing budgets\nand model parameter counts will be impractical for achieving strong\nmathematical reasoning if scaling trends continue. While scaling Transformers\nis automatically solving most other text-based tasks, scaling is not currently\nsolving MATH. To have more traction on mathematical problem solving we will\nlikely need new algorithmic advancements from the broader research community.", "published": "2021-03-05 18:59:39", "link": "http://arxiv.org/abs/2103.03874v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Disambiguating Affective Stimulus Associations for Robot Perception and\n  Dialogue", "abstract": "Effectively recognising and applying emotions to interactions is a highly\ndesirable trait for social robots. Implicitly understanding how subjects\nexperience different kinds of actions and objects in the world is crucial for\nnatural HRI interactions, with the possibility to perform positive actions and\navoid negative actions. In this paper, we utilize the NICO robot's appearance\nand capabilities to give the NICO the ability to model a coherent affective\nassociation between a perceived auditory stimulus and a temporally asynchronous\nemotion expression. This is done by combining evaluations of emotional valence\nfrom vision and language. NICO uses this information to make decisions about\nwhen to extend conversations in order to accrue more affective information if\nthe representation of the association is not coherent. Our primary contribution\nis providing a NICO robot with the ability to learn the affective associations\nbetween a perceived auditory stimulus and an emotional expression. NICO is able\nto do this for both individual subjects and specific stimuli, with the aid of\nan emotion-driven dialogue system that rectifies emotional expression\nincoherences. The robot is then able to use this information to determine a\nsubject's enjoyment of perceived auditory stimuli in a real HRI scenario.", "published": "2021-03-05 20:55:48", "link": "http://arxiv.org/abs/2103.03940v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A Hybrid CNN-BiLSTM Voice Activity Detector", "abstract": "This paper presents a new hybrid architecture for voice activity detection\n(VAD) incorporating both convolutional neural network (CNN) and bidirectional\nlong short-term memory (BiLSTM) layers trained in an end-to-end manner. In\naddition, we focus specifically on optimising the computational efficiency of\nour architecture in order to deliver robust performance in difficult\nin-the-wild noise conditions in a severely under-resourced setting. Nested\nk-fold cross-validation was used to explore the hyperparameter space, and the\ntrade-off between optimal parameters and model size is discussed. The\nperformance effect of a BiLSTM layer compared to a unidirectional LSTM layer\nwas also considered. We compare our systems with three established baselines on\nthe AVA-Speech dataset. We find that significantly smaller models with near\noptimal parameters perform on par with larger models trained with optimal\nparameters. BiLSTM layers were shown to improve accuracy over unidirectional\nlayers by $\\approx$2% absolute on average. With an area under the curve (AUC)\nof 0.951, our system outperforms all baselines, including a much larger ResNet\nsystem, particularly in difficult noise conditions.", "published": "2021-03-05 08:15:36", "link": "http://arxiv.org/abs/2103.03529v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Incorporating Wireless Communication Parameters into the E-Model\n  Algorithm", "abstract": "Telecommunication service providers have to guarantee acceptable speech\nquality during a phone call to avoid a negative impact on the users' quality of\nexperience. Currently, there are different speech quality assessment methods.\nITU-T Recommendation G.107 describes the E-model algorithm, which is a\ncomputational model developed for network planning purposes focused on\nnarrowband (NB) networks. Later, ITU-T Recommendations G.107.1 and G.107.2 were\ndeveloped for wideband (WB) and fullband (FB) networks. These algorithms use\ndifferent impairment factors, each one related to different speech\ncommunication steps. However, the NB, WB, and FB E-model algorithms do not\nconsider wireless techniques used in these networks, such as\nMultiple-Input-Multiple-Output (MIMO) systems, which are used to improve the\ncommunication system robustness in the presence of different types of wireless\nchannel degradation. In this context, the main objective of this study is to\npropose a general methodology to incorporate wireless network parameters into\nthe NB and WB E-model algorithms. To accomplish this goal, MIMO and wireless\nchannel parameters are incorporated into the E-model algorithms, specifically\ninto the $I_{e,eff}$ and $I_{e,eff,WB}$ impairment factors. For performance\nvalidation, subjective tests were carried out, and the proposed methodology\nreached a Pearson correlation coefficient (PCC) and a root mean square error\n(RMSE) of $0.9732$ and $0.2351$, respectively. It is noteworthy that our\nproposed methodology does not affect the rest of the E-model input parameters,\nand it intends to be useful for wireless network planning in speech\ncommunication services.", "published": "2021-03-05 22:45:02", "link": "http://arxiv.org/abs/2103.03970v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Environmental Sound Classification on the Edge: A Pipeline for Deep\n  Acoustic Networks on Extremely Resource-Constrained Devices", "abstract": "Significant efforts are being invested to bring state-of-the-art\nclassification and recognition to edge devices with extreme resource\nconstraints (memory, speed, and lack of GPU support). Here, we demonstrate the\nfirst deep network for acoustic recognition that is small, flexible and\ncompression-friendly yet achieves state-of-the-art performance for raw audio\nclassification. Rather than handcrafting a once-off solution, we present a\ngeneric pipeline that automatically converts a large deep convolutional network\nvia compression and quantization into a network for resource-impoverished edge\ndevices. After introducing ACDNet, which produces above state-of-the-art\naccuracy on ESC-10 (96.65%), ESC-50 (87.10%), UrbanSound8K (84.45%) and\nAudioEvent (92.57%), we describe the compression pipeline and show that it\nallows us to achieve 97.22% size reduction and 97.28% FLOP reduction while\nmaintaining close to state-of-the-art accuracy 96.25%, 83.65%, 78.27% and\n89.69% on these datasets. We describe a successful implementation on a standard\noff-the-shelf microcontroller and, beyond laboratory benchmarks, report\nsuccessful tests on real-world datasets.", "published": "2021-03-05 05:52:31", "link": "http://arxiv.org/abs/2103.03483v4", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Slow-Fast Auditory Streams For Audio Recognition", "abstract": "We propose a two-stream convolutional network for audio recognition, that\noperates on time-frequency spectrogram inputs. Following similar success in\nvisual recognition, we learn Slow-Fast auditory streams with separable\nconvolutions and multi-level lateral connections. The Slow pathway has high\nchannel capacity while the Fast pathway operates at a fine-grained temporal\nresolution. We showcase the importance of our two-stream proposal on two\ndiverse datasets: VGG-Sound and EPIC-KITCHENS-100, and achieve state-of-the-art\nresults on both.", "published": "2021-03-05 07:51:21", "link": "http://arxiv.org/abs/2103.03516v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-latency auditory spatial attention detection based on\n  spectro-spatial features from EEG", "abstract": "Detecting auditory attention based on brain signals enables many everyday\napplications, and serves as part of the solution to the cocktail party effect\nin speech processing. Several studies leverage the correlation between brain\nsignals and auditory stimuli to detect the auditory attention of listeners.\nRecently, studies show that the alpha band (8-13 Hz) EEG signals enable the\nlocalization of auditory stimuli. We believe that it is possible to detect\nauditory spatial attention without the need of auditory stimuli as references.\nIn this work, we use alpha power signals for automatic auditory spatial\nattention detection. To the best of our knowledge, this is the first attempt to\ndetect spatial attention based on alpha power neural signals. We propose a\nspectro-spatial feature extraction technique to detect the auditory spatial\nattention (left/right) based on the topographic specificity of alpha power.\nExperiments show that the proposed neural approach achieves 81.7% and 94.6%\naccuracy for 1-second and 10-second decision windows, respectively. Our\ncomparative results show that this neural approach outperforms other\ncompetitive models by a large margin in all test cases.", "published": "2021-03-05 11:50:50", "link": "http://arxiv.org/abs/2103.03621v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "ODAS: Open embeddeD Audition System", "abstract": "Artificial audition aims at providing hearing capabilities to machines,\ncomputers and robots. Existing frameworks in robot audition offer interesting\nsound source localization, tracking and separation performance, although\ninvolve a significant amount of computations that limit their use on robots\nwith embedded computing capabilities. This paper presents ODAS, the Open\nembeddeD Audition System framework, which includes strategies to reduce the\ncomputational load and perform robot audition tasks on low-cost embedded\ncomputing systems. It presents key features of ODAS, along with cases\nillustrating its uses in different robots and artificial audition applications.", "published": "2021-03-05 22:02:58", "link": "http://arxiv.org/abs/2103.03954v2", "categories": ["eess.AS", "cs.RO", "cs.SD"], "primary_category": "eess.AS"}
