{"title": "Refining Time Series Anomaly Detectors using Large Language Models", "abstract": "Time series anomaly detection (TSAD) is of widespread interest across many\nindustries, including finance, healthcare, and manufacturing. Despite the\ndevelopment of numerous automatic methods for detecting anomalies, human\noversight remains necessary to review and act upon detected anomalies, as well\nas verify their accuracy. We study the use of multimodal large language models\n(LLMs) to partially automate this process. We find that LLMs can effectively\nidentify false alarms by integrating visual inspection of time series plots\nwith text descriptions of the data-generating process. By leveraging the\ncapabilities of LLMs, we aim to reduce the reliance on human effort required to\nmaintain a TSAD system", "published": "2025-03-26 23:41:49", "link": "http://arxiv.org/abs/2503.21833v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Susceptibility of Large Language Models to User-Driven Factors in Medical Queries", "abstract": "Large language models (LLMs) are increasingly used in healthcare, but their\nreliability is heavily influenced by user-driven factors such as question\nphrasing and the completeness of clinical information. In this study, we\nexamined how misinformation framing, source authority, model persona, and\nomission of key clinical details affect the diagnostic accuracy and reliability\nof LLM outputs. We conducted two experiments: one introducing misleading\nexternal opinions with varying assertiveness (perturbation test), and another\nremoving specific categories of patient information (ablation test). Using\npublic datasets (MedQA and Medbullets), we evaluated proprietary models\n(GPT-4o, Claude 3.5 Sonnet, Claude 3.5 Haiku, Gemini 1.5 Pro, Gemini 1.5 Flash)\nand open-source models (LLaMA 3 8B, LLaMA 3 Med42 8B, DeepSeek R1 8B). All\nmodels were vulnerable to user-driven misinformation, with proprietary models\nespecially affected by definitive and authoritative language. Assertive tone\nhad the greatest negative impact on accuracy. In the ablation test, omitting\nphysical exam findings and lab results caused the most significant performance\ndrop. Although proprietary models had higher baseline accuracy, their\nperformance declined sharply under misinformation. These results highlight the\nneed for well-structured prompts and complete clinical context. Users should\navoid authoritative framing of misinformation and provide full clinical\ndetails, especially for complex cases.", "published": "2025-03-26 23:28:21", "link": "http://arxiv.org/abs/2503.22746v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Enhancing Korean Dependency Parsing with Morphosyntactic Features", "abstract": "This paper introduces UniDive for Korean, an integrated framework that\nbridges Universal Dependencies (UD) and Universal Morphology (UniMorph) to\nenhance the representation and processing of Korean {morphosyntax}. Korean's\nrich inflectional morphology and flexible word order pose challenges for\nexisting frameworks, which often treat morphology and syntax separately,\nleading to inconsistencies in linguistic analysis. UniDive unifies syntactic\nand morphological annotations by preserving syntactic dependencies while\nincorporating UniMorph-derived features, improving consistency in annotation.\nWe construct an integrated dataset and apply it to dependency parsing,\ndemonstrating that enriched morphosyntactic features enhance parsing accuracy,\nparticularly in distinguishing grammatical relations influenced by morphology.\nOur experiments, conducted with both encoder-only and decoder-only models,\nconfirm that explicit morphological information contributes to more accurate\nsyntactic analysis.", "published": "2025-03-26 22:27:26", "link": "http://arxiv.org/abs/2503.21029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Predict Associations Among Human Attitudes?", "abstract": "Prior work has shown that large language models (LLMs) can predict human\nattitudes based on other attitudes, but this work has largely focused on\npredictions from highly similar and interrelated attitudes. In contrast, human\nattitudes are often strongly associated even across disparate and dissimilar\ntopics. Using a novel dataset of human responses toward diverse attitude\nstatements, we found that a frontier language model (GPT-4o) was able to\nrecreate the pairwise correlations among individual attitudes and to predict\nindividuals' attitudes from one another. Crucially, in an advance over prior\nwork, we tested GPT-4o's ability to predict in the absence of\nsurface-similarity between attitudes, finding that while surface similarity\nimproves prediction accuracy, the model was still highly-capable of generating\nmeaningful social inferences between dissimilar attitudes. Altogether, our\nfindings indicate that LLMs capture crucial aspects of the deeper, latent\nstructure of human belief systems.", "published": "2025-03-26 21:58:43", "link": "http://arxiv.org/abs/2503.21011v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models for Automated Clinical Abstraction in Pulmonary Embolism Registries: Performance Across Model Sizes, Versions, and Parameters", "abstract": "Pulmonary embolism (PE) is a leading cause of cardiovascular mortality, yet\nour understanding of optimal management remains limited due to heterogeneous\nand inaccessible radiology documentation. The PERT Consortium registry\nstandardizes PE management data but depends on resource-intensive manual\nabstraction. Large language models (LLMs) offer a scalable alternative for\nautomating concept extraction from computed tomography PE (CTPE) reports. This\nstudy evaluated the accuracy of LLMs in extracting PE-related concepts compared\nto a human-curated criterion standard. We retrospectively analyzed MIMIC-IV and\nDuke Health CTPE reports using multiple LLaMA models. Larger models (70B)\noutperformed smaller ones (8B), achieving kappa values of 0.98 (PE detection),\n0.65-0.75 (PE location), 0.48-0.51 (right heart strain), and 0.65-0.70 (image\nartifacts). Moderate temperature tuning (0.2-0.5) improved accuracy, while\nexcessive in-context examples reduced performance. A dual-model review\nframework achieved >80-90% precision. LLMs demonstrate strong potential for\nautomating PE registry abstraction, minimizing manual workload while preserving\naccuracy.", "published": "2025-03-26 21:38:06", "link": "http://arxiv.org/abs/2503.21004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-head Reward Aggregation Guided by Entropy", "abstract": "Aligning large language models (LLMs) with safety guidelines typically\ninvolves reinforcement learning from human feedback (RLHF), relying on\nhuman-generated preference annotations. However, assigning consistent overall\nquality ratings is challenging, prompting recent research to shift towards\ndetailed evaluations based on multiple specific safety criteria. This paper\nuncovers a consistent observation: safety rules characterized by high rating\nentropy are generally less reliable in identifying responses preferred by\nhumans. Leveraging this finding, we introduce ENCORE, a straightforward\nentropy-guided approach that composes multi-head rewards by downweighting rules\nexhibiting high rating entropy. Theoretically, we demonstrate that rules with\nelevated entropy naturally receive minimal weighting in the Bradley-Terry\noptimization framework, justifying our entropy-based penalization. Through\nextensive experiments on RewardBench safety tasks, our method significantly\nsurpasses several competitive baselines, including random weighting, uniform\nweighting, single-head Bradley-Terry models, and LLM-based judging methods. Our\nproposed approach is training-free, broadly applicable to various datasets, and\nmaintains interpretability, offering a practical and effective solution for\nmulti-attribute reward modeling.", "published": "2025-03-26 21:16:48", "link": "http://arxiv.org/abs/2503.20995v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReverBERT: A State Space Model for Efficient Text-Driven Speech Style Transfer", "abstract": "Text-driven speech style transfer aims to mold the intonation, pace, and\ntimbre of a spoken utterance to match stylistic cues from text descriptions.\nWhile existing methods leverage large-scale neural architectures or pre-trained\nlanguage models, the computational costs often remain high. In this paper, we\npresent \\emph{ReverBERT}, an efficient framework for text-driven speech style\ntransfer that draws inspiration from a state space model (SSM) paradigm,\nloosely motivated by the image-based method of Wang and\nLiu~\\cite{wang2024stylemamba}. Unlike image domain techniques, our method\noperates in the speech space and integrates a discrete Fourier transform of\nlatent speech features to enable smooth and continuous style modulation. We\nalso propose a novel \\emph{Transformer-based SSM} layer for bridging textual\nstyle descriptors with acoustic attributes, dramatically reducing inference\ntime while preserving high-quality speech characteristics. Extensive\nexperiments on benchmark speech corpora demonstrate that \\emph{ReverBERT}\nsignificantly outperforms baselines in terms of naturalness, expressiveness,\nand computational efficiency. We release our model and code publicly to foster\nfurther research in text-driven speech style transfer.", "published": "2025-03-26 21:11:17", "link": "http://arxiv.org/abs/2503.20992v1", "categories": ["cs.GR", "cs.CL"], "primary_category": "cs.GR"}
{"title": "Cross-Modal State-Space Graph Reasoning for Structured Summarization", "abstract": "The ability to extract compact, meaningful summaries from large-scale and\nmultimodal data is critical for numerous applications, ranging from video\nanalytics to medical reports. Prior methods in cross-modal summarization have\noften suffered from high computational overheads and limited interpretability.\nIn this paper, we propose a \\textit{Cross-Modal State-Space Graph Reasoning}\n(\\textbf{CSS-GR}) framework that incorporates a state-space model with\ngraph-based message passing, inspired by prior work on efficient state-space\nmodels. Unlike existing approaches relying on purely sequential models, our\nmethod constructs a graph that captures inter- and intra-modal relationships,\nallowing more holistic reasoning over both textual and visual streams. We\ndemonstrate that our approach significantly improves summarization quality and\ninterpretability while maintaining computational efficiency, as validated on\nstandard multimodal summarization benchmarks. We also provide a thorough\nablation study to highlight the contributions of each component.", "published": "2025-03-26 21:06:56", "link": "http://arxiv.org/abs/2503.20988v1", "categories": ["cs.CL", "cs.GR"], "primary_category": "cs.CL"}
{"title": "Patients Speak, AI Listens: LLM-based Analysis of Online Reviews Uncovers Key Drivers for Urgent Care Satisfaction", "abstract": "Investigating the public experience of urgent care facilities is essential\nfor promoting community healthcare development. Traditional survey methods\noften fall short due to limited scope, time, and spatial coverage.\nCrowdsourcing through online reviews or social media offers a valuable approach\nto gaining such insights. With recent advancements in large language models\n(LLMs), extracting nuanced perceptions from reviews has become feasible. This\nstudy collects Google Maps reviews across the DMV and Florida areas and\nconducts prompt engineering with the GPT model to analyze the aspect-based\nsentiment of urgent care. We first analyze the geospatial patterns of various\naspects, including interpersonal factors, operational efficiency, technical\nquality, finances, and facilities. Next, we determine Census Block\nGroup(CBG)-level characteristics underpinning differences in public perception,\nincluding population density, median income, GINI Index, rent-to-income ratio,\nhousehold below poverty rate, no insurance rate, and unemployment rate. Our\nresults show that interpersonal factors and operational efficiency emerge as\nthe strongest determinants of patient satisfaction in urgent care, while\ntechnical quality, finances, and facilities show no significant independent\neffects when adjusted for in multivariate models. Among socioeconomic and\ndemographic factors, only population density demonstrates a significant but\nmodest association with patient ratings, while the remaining factors exhibit no\nsignificant correlations. Overall, this study highlights the potential of\ncrowdsourcing to uncover the key factors that matter to residents and provide\nvaluable insights for stakeholders to improve public satisfaction with urgent\ncare.", "published": "2025-03-26 20:45:01", "link": "http://arxiv.org/abs/2503.20981v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "ScreenLLM: Stateful Screen Schema for Efficient Action Understanding and Prediction", "abstract": "Graphical User Interface (GUI) agents are autonomous systems that interpret\nand generate actions, enabling intelligent user assistance and automation.\nEffective training of these agent presents unique challenges, such as sparsity\nin supervision signals, scalability for large datasets, and the need for\nnuanced user understanding. We propose stateful screen schema, an efficient\nrepresentation of GUI interactions that captures key user actions and\nintentions over time. Building on this foundation, we introduce ScreenLLM, a\nset of multimodal large language models (MLLMs) tailored for advanced UI\nunderstanding and action prediction. Extensive experiments on both open-source\nand proprietary models show that ScreenLLM accurately models user behavior and\npredicts actions. Our work lays the foundation for scalable, robust, and\nintelligent GUI agents that enhance user interaction in diverse software\nenvironments.", "published": "2025-03-26 20:41:24", "link": "http://arxiv.org/abs/2503.20978v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Modal Framing Analysis of News", "abstract": "Automated frame analysis of political communication is a popular task in\ncomputational social science that is used to study how authors select aspects\nof a topic to frame its reception. So far, such studies have been narrow, in\nthat they use a fixed set of pre-defined frames and focus only on the text,\nignoring the visual contexts in which those texts appear. Especially for\nframing in the news, this leaves out valuable information about editorial\nchoices, which include not just the written article but also accompanying\nphotographs. To overcome such limitations, we present a method for conducting\nmulti-modal, multi-label framing analysis at scale using large\n(vision-)language models. Grounding our work in framing theory, we extract\nlatent meaning embedded in images used to convey a certain point and contrast\nthat to the text by comparing the respective frames used. We also identify\nhighly partisan framing of topics with issue-specific frame analysis found in\nprior qualitative work. We demonstrate a method for doing scalable integrative\nframing analysis of both text and image in news, providing a more complete\npicture for understanding media bias.", "published": "2025-03-26 19:51:33", "link": "http://arxiv.org/abs/2503.20960v2", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sociotechnical Effects of Machine Translation", "abstract": "While the previous chapters have shown how machine translation (MT) can be\nuseful, in this chapter we discuss some of the side-effects and risks that are\nassociated, and how they might be mitigated. With the move to neural MT and\napproaches using Large Language Models (LLMs), there is an associated impact on\nclimate change, as the models built by multinational corporations are massive.\nThey are hugely expensive to train, consume large amounts of electricity, and\noutput huge volumes of kgCO2 to boot. However, smaller models which still\nperform to a high level of quality can be built with much lower carbon\nfootprints, and tuning pre-trained models saves on the requirement to train\nfrom scratch. We also discuss the possible detrimental effects of MT on\ntranslators and other users. The topics of copyright and ownership of data are\ndiscussed, as well as ethical considerations on data and MT use. Finally, we\nshow how if done properly, using MT in crisis scenarios can save lives, and we\nprovide a method of how this might be done.", "published": "2025-03-26 19:49:46", "link": "http://arxiv.org/abs/2503.20959v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Clean & Clear: Feasibility of Safe LLM Clinical Guidance", "abstract": "Background:\n  Clinical guidelines are central to safe evidence-based medicine in modern\nhealthcare, providing diagnostic criteria, treatment options and monitoring\nadvice for a wide range of illnesses. LLM-empowered chatbots have shown great\npromise in Healthcare Q&A tasks, offering the potential to provide quick and\naccurate responses to medical inquiries.\n  Our main objective was the development and preliminary assessment of an\nLLM-empowered chatbot software capable of reliably answering clinical guideline\nquestions using University College London Hospital (UCLH) clinical guidelines.\n  Methods: We used the open-weight Llama-3.1-8B LLM to extract relevant\ninformation from the UCLH guidelines to answer questions. Our approach\nhighlights the safety and reliability of referencing information over its\ninterpretation and response generation. Seven doctors from the ward assessed\nthe chatbot's performance by comparing its answers to the gold standard.\n  Results: Our chatbot demonstrates promising performance in terms of\nrelevance, with ~73% of its responses rated as very relevant, showcasing a\nstrong understanding of the clinical context. Importantly, our chatbot achieves\na recall of 0.98 for extracted guideline lines, substantially minimising the\nrisk of missing critical information. Approximately 78% of responses were rated\nsatisfactory in terms of completeness. A small portion (~14.5%) contained minor\nunnecessary information, indicating occasional lapses in precision. The\nchatbot' showed high efficiency, with an average completion time of 10 seconds,\ncompared to 30 seconds for human respondents. Evaluation of clinical reasoning\nshowed that 72% of the chatbot's responses were without flaws. Our chatbot\ndemonstrates significant potential to speed up and improve the process of\naccessing locally relevant clinical information for healthcare professionals.", "published": "2025-03-26 19:36:43", "link": "http://arxiv.org/abs/2503.20953v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Integrated Layered Attention (AILA)", "abstract": "We propose Adaptive Integrated Layered Attention (AILA), a neural network\narchitecture that combines dense skip connections with different mechanisms for\nadaptive feature reuse across network layers. We evaluate AILA on three\nchallenging tasks: price forecasting for various commodities and indices (S&P\n500, Gold, US dollar Futures, Coffee, Wheat), image recognition using the\nCIFAR-10 dataset, and sentiment analysis on the IMDB movie review dataset. In\nall cases, AILA matches strong deep learning baselines (LSTMs, Transformers,\nand ResNets), achieving it at a fraction of the training and inference time.\nNotably, we implement and test two versions of the model - AILA-Architecture 1,\nwhich uses simple linear layers as the connection mechanism between layers, and\nAILA-Architecture 2, which implements an attention mechanism to selectively\nfocus on outputs from previous layers. Both architectures are applied in a\nsingle-task learning setting, with each model trained separately for individual\ntasks. Results confirm that AILA's adaptive inter-layer connections yield\nrobust gains by flexibly reusing pertinent features at multiple network depths.\nThe AILA approach thus presents an extension to existing architectures,\nimproving long-range sequence modeling, image recognition with optimised\ncomputational speed, and SOTA classification performance in practice.", "published": "2025-03-26 19:32:31", "link": "http://arxiv.org/abs/2503.22742v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Hacia la interpretabilidad de la detecci\u00f3n anticipada de riesgos de depresi\u00f3n utilizando grandes modelos de lenguaje", "abstract": "Early Detection of Risks (EDR) on the Web involves identifying at-risk users\nas early as possible. Although Large Language Models (LLMs) have proven to\nsolve various linguistic tasks efficiently, assessing their reasoning ability\nin specific domains is crucial. In this work, we propose a method for solving\ndepression-related EDR using LLMs on Spanish texts, with responses that can be\ninterpreted by humans. We define a reasoning criterion to analyze users through\na specialist, apply in-context learning to the Gemini model, and evaluate its\nperformance both quantitatively and qualitatively. The results show that\naccurate predictions can be obtained, supported by explanatory reasoning,\nproviding a deeper understanding of the solution. Our approach offers new\nperspectives for addressing EDR problems by leveraging the power of LLMs.", "published": "2025-03-26 19:14:21", "link": "http://arxiv.org/abs/2503.20939v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GatedxLSTM: A Multimodal Affective Computing Approach for Emotion Recognition in Conversations", "abstract": "Affective Computing (AC) is essential for advancing Artificial General\nIntelligence (AGI), with emotion recognition serving as a key component.\nHowever, human emotions are inherently dynamic, influenced not only by an\nindividual's expressions but also by interactions with others, and\nsingle-modality approaches often fail to capture their full dynamics.\nMultimodal Emotion Recognition (MER) leverages multiple signals but\ntraditionally relies on utterance-level analysis, overlooking the dynamic\nnature of emotions in conversations. Emotion Recognition in Conversation (ERC)\naddresses this limitation, yet existing methods struggle to align multimodal\nfeatures and explain why emotions evolve within dialogues. To bridge this gap,\nwe propose GatedxLSTM, a novel speech-text multimodal ERC model that explicitly\nconsiders voice and transcripts of both the speaker and their conversational\npartner(s) to identify the most influential sentences driving emotional shifts.\nBy integrating Contrastive Language-Audio Pretraining (CLAP) for improved\ncross-modal alignment and employing a gating mechanism to emphasise emotionally\nimpactful utterances, GatedxLSTM enhances both interpretability and\nperformance. Additionally, the Dialogical Emotion Decoder (DED) refines emotion\npredictions by modelling contextual dependencies. Experiments on the IEMOCAP\ndataset demonstrate that GatedxLSTM achieves state-of-the-art (SOTA)\nperformance among open-source methods in four-class emotion classification.\nThese results validate its effectiveness for ERC applications and provide an\ninterpretability analysis from a psychological perspective.", "published": "2025-03-26 18:46:18", "link": "http://arxiv.org/abs/2503.20919v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "D4R -- Exploring and Querying Relational Graphs Using Natural Language and Large Language Models -- the Case of Historical Documents", "abstract": "D4R is a digital platform designed to assist non-technical users,\nparticularly historians, in exploring textual documents through advanced\ngraphical tools for text analysis and knowledge extraction. By leveraging a\nlarge language model, D4R translates natural language questions into Cypher\nqueries, enabling the retrieval of data from a Neo4J database. A user-friendly\ngraphical interface allows for intuitive interaction, enabling users to\nnavigate and analyse complex relational data extracted from unstructured\ntextual documents. Originally designed to bridge the gap between AI\ntechnologies and historical research, D4R's capabilities extend to various\nother domains. A demonstration video and a live software demo are available.", "published": "2025-03-26 18:41:42", "link": "http://arxiv.org/abs/2503.20914v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "H.3; H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "VinaBench: Benchmark for Faithful and Consistent Visual Narratives", "abstract": "Visual narrative generation transforms textual narratives into sequences of\nimages illustrating the content of the text. However, generating visual\nnarratives that are faithful to the input text and self-consistent across\ngenerated images remains an open challenge, due to the lack of knowledge\nconstraints used for planning the stories. In this work, we propose a new\nbenchmark, VinaBench, to address this challenge. Our benchmark annotates the\nunderlying commonsense and discourse constraints in visual narrative samples,\noffering systematic scaffolds for learning the implicit strategies of visual\nstorytelling. Based on the incorporated narrative constraints, we further\npropose novel metrics to closely evaluate the consistency of generated\nnarrative images and the alignment of generations with the input textual\nnarrative. Our results across three generative vision models demonstrate that\nlearning with VinaBench's knowledge constraints effectively improves the\nfaithfulness and cohesion of generated visual narratives.", "published": "2025-03-26 18:00:03", "link": "http://arxiv.org/abs/2503.20871v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Mobile-MMLU: A Mobile Intelligence Language Understanding Benchmark", "abstract": "Rapid advancements in large language models (LLMs) have increased interest in\ndeploying them on mobile devices for on-device AI applications. Mobile users\ninteract differently with LLMs compared to desktop users, creating unique\nexpectations and data biases. Current benchmark datasets primarily target at\nserver and desktop environments, and there is a notable lack of extensive\ndatasets specifically designed for mobile contexts. Additionally, mobile\ndevices face strict limitations in storage and computing resources,\nconstraining model size and capabilities, thus requiring optimized efficiency\nand prioritized knowledge. To address these challenges, we introduce\nMobile-MMLU, a large-scale benchmark dataset tailored for mobile intelligence.\nIt consists of 16,186 questions across 80 mobile-related fields, designed to\nevaluate LLM performance in realistic mobile scenarios. A challenging subset,\nMobile-MMLU-Pro, provides advanced evaluation similar in size to MMLU-Pro but\nsignificantly more difficult than our standard full set. Both benchmarks use\nmultiple-choice, order-invariant questions focused on practical mobile\ninteractions, such as recipe suggestions, travel planning, and essential daily\ntasks. The dataset emphasizes critical mobile-specific metrics like inference\nlatency, energy consumption, memory usage, and response quality, offering\ncomprehensive insights into model performance under mobile constraints.\nMoreover, it prioritizes privacy and adaptability, assessing models' ability to\nperform on-device processing, maintain user privacy, and adapt to personalized\nusage patterns. Mobile-MMLU family offers a standardized framework for\ndeveloping and comparing mobile-optimized LLMs, enabling advancements in\nproductivity and decision-making within mobile computing environments. Our code\nand data are available at: https://github.com/VILA-Lab/Mobile-MMLU.", "published": "2025-03-26 17:59:56", "link": "http://arxiv.org/abs/2503.20786v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding R1-Zero-Like Training: A Critical Perspective", "abstract": "DeepSeek-R1-Zero has shown that reinforcement learning (RL) at scale can\ndirectly enhance the reasoning capabilities of LLMs without supervised\nfine-tuning. In this work, we critically examine R1-Zero-like training by\nanalyzing its two core components: base models and RL. We investigate a wide\nrange of base models, including DeepSeek-V3-Base, to understand how pretraining\ncharacteristics influence RL performance. Our analysis reveals that\nDeepSeek-V3-Base already exhibit ''Aha moment'', while Qwen2.5 base models\ndemonstrate strong reasoning capabilities even without prompt templates,\nsuggesting potential pretraining biases. Additionally, we identify an\noptimization bias in Group Relative Policy Optimization (GRPO), which\nartificially increases response length (especially for incorrect outputs)\nduring training. To address this, we introduce Dr. GRPO, an unbiased\noptimization method that improves token efficiency while maintaining reasoning\nperformance. Leveraging these insights, we present a minimalist R1-Zero recipe\nthat achieves 43.3% accuracy on AIME 2024 with a 7B base model, establishing a\nnew state-of-the-art. Our code is available at\nhttps://github.com/sail-sg/understand-r1-zero.", "published": "2025-03-26 17:59:14", "link": "http://arxiv.org/abs/2503.20783v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search", "abstract": "We introduce MCTS-RAG, a novel approach that enhances the reasoning\ncapabilities of small language models on knowledge-intensive tasks by\nleveraging retrieval-augmented generation (RAG) to provide relevant context and\nMonte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamically\nintegrates retrieval and reasoning through an iterative decision-making\nprocess. Unlike standard RAG methods, which typically retrieve information\nindependently from reasoning and thus integrate knowledge suboptimally, or\nconventional MCTS reasoning, which depends solely on internal model knowledge\nwithout external facts, MCTS-RAG combines structured reasoning with adaptive\nretrieval. This integrated approach enhances decision-making, reduces\nhallucinations, and ensures improved factual accuracy and response consistency.\nThe experimental results on multiple reasoning and knowledge-intensive datasets\ndatasets (i.e., ComplexWebQA, GPQA, and FoolMeTwice) show that our method\nenables small-scale LMs to achieve performance comparable to frontier LLMs like\nGPT-4o by effectively scaling inference-time compute, setting a new standard\nfor reasoning in small-scale models.", "published": "2025-03-26 17:46:08", "link": "http://arxiv.org/abs/2503.20757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems", "abstract": "Recent advancements in Large Multimodal Models (LMMs) have shown promise in\nAutonomous Driving Systems (ADS). However, their direct application to ADS is\nhindered by challenges such as misunderstanding of traffic knowledge, complex\nroad conditions, and diverse states of vehicle. To address these challenges, we\npropose the use of Knowledge Editing, which enables targeted modifications to a\nmodel's behavior without the need for full retraining. Meanwhile, we introduce\nADS-Edit, a multimodal knowledge editing dataset specifically designed for ADS,\nwhich includes various real-world scenarios, multiple data types, and\ncomprehensive evaluation metrics. We conduct comprehensive experiments and\nderive several interesting conclusions. We hope that our work will contribute\nto the further advancement of knowledge editing applications in the field of\nautonomous driving. Code and data are available in\nhttps://github.com/zjunlp/EasyEdit.", "published": "2025-03-26 17:45:29", "link": "http://arxiv.org/abs/2503.20756v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Beyond Believability: Accurate Human Behavior Simulation with Fine-Tuned LLMs", "abstract": "Recent research shows that LLMs can simulate ``believable'' human behaviors\nto power LLM agents via prompt-only methods. In this work, we focus on\nevaluating and improving LLM's objective ``accuracy'' rather than the\nsubjective ``believability'' in the web action generation task, leveraging a\nlarge-scale, real-world dataset collected from online shopping human actions.\nWe present the first comprehensive quantitative evaluation of state-of-the-art\nLLMs (e.g., DeepSeek-R1, Llama, and Claude) on the task of web action\ngeneration. Our results show that fine-tuning LLMs on real-world behavioral\ndata substantially improves their ability to generate actions compared to\nprompt-only methods. Furthermore, incorporating synthesized reasoning traces\ninto model training leads to additional performance gains, demonstrating the\nvalue of explicit rationale in behavior modeling. This work establishes a new\nbenchmark for evaluating LLMs in behavior simulation and offers actionable\ninsights into how real-world action data and reasoning augmentation can enhance\nthe fidelity of LLM agents.", "published": "2025-03-26 17:33:27", "link": "http://arxiv.org/abs/2503.20749v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Both Direct and Indirect Evidence Contribute to Dative Alternation Preferences in Language Models", "abstract": "Language models (LMs) tend to show human-like preferences on a number of\nsyntactic phenomena, but the extent to which these are attributable to direct\nexposure to the phenomena or more general properties of language is unclear. We\nexplore this with the English dative alternation (DO: \"gave Y the X\" vs. PO:\n\"gave the X to Y\"), using a controlled rearing paradigm wherein we iteratively\ntrain small LMs on systematically manipulated input. We focus on properties\nthat affect the choice of alternant: length and animacy. Both properties are\ndirectly present in datives but also reflect more global tendencies for shorter\nelements to precede longer ones and animates to precede inanimates. First, by\nmanipulating and ablating datives for these biases in the input, we show that\ndirect evidence of length and animacy matters, but easy-first preferences\npersist even without such evidence. Then, using LMs trained on systematically\nperturbed datasets to manipulate global length effects (re-linearizing\nsentences globally while preserving dependency structure), we find that dative\npreferences can emerge from indirect evidence. We conclude that LMs' emergent\nsyntactic preferences come from a mix of direct and indirect sources.", "published": "2025-03-26 17:32:41", "link": "http://arxiv.org/abs/2503.20850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ontology-based Semantic Similarity Measures for Clustering Medical Concepts in Drug Safety", "abstract": "Semantic similarity measures (SSMs) are widely used in biomedical research\nbut remain underutilized in pharmacovigilance. This study evaluates six\nontology-based SSMs for clustering MedDRA Preferred Terms (PTs) in drug safety\ndata. Using the Unified Medical Language System (UMLS), we assess each method's\nability to group PTs around medically meaningful centroids. A high-throughput\nframework was developed with a Java API and Python and R interfaces support\nlarge-scale similarity computations. Results show that while path-based methods\nperform moderately with F1 scores of 0.36 for WUPALMER and 0.28 for LCH,\nintrinsic information content (IC)-based measures, especially INTRINSIC-LIN and\nSOKAL, consistently yield better clustering accuracy (F1 score of 0.403).\nValidated against expert review and standard MedDRA queries (SMQs), our\nfindings highlight the promise of IC-based SSMs in enhancing pharmacovigilance\nworkflows by improving early signal detection and reducing manual review.", "published": "2025-03-26 17:19:00", "link": "http://arxiv.org/abs/2503.20737v1", "categories": ["cs.CL", "I.2.4; G.3; H.3.3"], "primary_category": "cs.CL"}
{"title": "From Annotation to Adaptation: Metrics, Synthetic Data, and Aspect Extraction for Aspect-Based Sentiment Analysis with Large Language Models", "abstract": "This study examines the performance of Large Language Models (LLMs) in\nAspect-Based Sentiment Analysis (ABSA), with a focus on implicit aspect\nextraction in a novel domain. Using a synthetic sports feedback dataset, we\nevaluate open-weight LLMs' ability to extract aspect-polarity pairs and propose\na metric to facilitate the evaluation of aspect extraction with generative\nmodels. Our findings highlight both the potential and limitations of LLMs in\nthe ABSA task.", "published": "2025-03-26 16:52:40", "link": "http://arxiv.org/abs/2503.20715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniEDU: A Unified Language and Vision Assistant for Education Applications", "abstract": "Education materials for K-12 students often consist of multiple modalities,\nsuch as text and images, posing challenges for models to fully understand\nnuanced information in these materials. In this paper, we propose a unified\nlanguage and vision assistant UniEDU designed for various educational\napplications, including knowledge recommendation, knowledge tracing, time cost\nprediction, and user answer prediction, all within a single model. Unlike\nconventional task-specific models, UniEDU offers a unified solution that excels\nacross multiple educational tasks while maintaining strong generalization\ncapabilities. Its adaptability makes it well-suited for real-world deployment\nin diverse learning environments. Furthermore, UniEDU is optimized for\nindustry-scale deployment by significantly reducing computational\noverhead-achieving approximately a 300\\% increase in efficiency-while\nmaintaining competitive performance with minimal degradation compared to fully\nfine-tuned models. This work represents a significant step toward creating\nversatile AI systems tailored to the evolving demands of education.", "published": "2025-03-26 16:33:04", "link": "http://arxiv.org/abs/2503.20701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vision as LoRA", "abstract": "We introduce Vision as LoRA (VoRA), a novel paradigm for transforming an LLM\ninto an MLLM. Unlike prevalent MLLM architectures that rely on external vision\nmodules for vision encoding, VoRA internalizes visual capabilities by\nintegrating vision-specific LoRA layers directly into the LLM. This design\nallows the added parameters to be seamlessly merged into the LLM during\ninference, eliminating structural complexity and minimizing computational\noverhead. Moreover, inheriting the LLM's ability of handling flexible context,\nVoRA can process inputs at arbitrary resolutions.\n  To further strengthen VoRA's visual capabilities, we introduce a block-wise\ndistillation method that transfers visual priors from a pre-trained ViT into\nthe LoRA layers, effectively accelerating training by injecting visual\nknowledge. Additionally, we apply bi-directional attention masks to better\ncapture the context information of an image. We successfully demonstrate that\nwith additional pre-training data, VoRA can perform comparably with\nconventional encode-based MLLMs. All training data, codes, and model weights\nwill be released at https://github.com/Hon-Wong/VoRA.", "published": "2025-03-26 16:15:42", "link": "http://arxiv.org/abs/2503.20680v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generating Synthetic Data with Formal Privacy Guarantees: State of the Art and the Road Ahead", "abstract": "Privacy-preserving synthetic data offers a promising solution to harness\nsegregated data in high-stakes domains where information is compartmentalized\nfor regulatory, privacy, or institutional reasons. This survey provides a\ncomprehensive framework for understanding the landscape of privacy-preserving\nsynthetic data, presenting the theoretical foundations of generative models and\ndifferential privacy followed by a review of state-of-the-art methods across\ntabular data, images, and text. Our synthesis of evaluation approaches\nhighlights the fundamental trade-off between utility for down-stream tasks and\nprivacy guarantees, while identifying critical research gaps: the lack of\nrealistic benchmarks representing specialized domains and insufficient\nempirical evaluations required to contextualise formal guarantees.\n  Through empirical analysis of four leading methods on five real-world\ndatasets from specialized domains, we demonstrate significant performance\ndegradation under realistic privacy constraints ($\\epsilon \\leq 4$), revealing\na substantial gap between results reported on general domain benchmarks and\nperformance on domain-specific data. %Our findings highlight key challenges\nincluding unaccounted privacy leakage, insufficient empirical verification of\nformal guarantees, and a critical deficit of realistic benchmarks. These\nchallenges underscore the need for robust evaluation frameworks, standardized\nbenchmarks for specialized domains, and improved techniques to address the\nunique requirements of privacy-sensitive fields such that this technology can\ndeliver on its considerable potential.", "published": "2025-03-26 16:06:33", "link": "http://arxiv.org/abs/2503.20846v1", "categories": ["cs.CR", "cs.CL", "cs.CV"], "primary_category": "cs.CR"}
{"title": "TAMA: A Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews", "abstract": "Thematic analysis (TA) is a widely used qualitative approach for uncovering\nlatent meanings in unstructured text data. TA provides valuable insights in\nhealthcare but is resource-intensive. Large Language Models (LLMs) have been\nintroduced to perform TA, yet their applications in healthcare remain\nunexplored. Here, we propose TAMA: A Human-AI Collaborative Thematic Analysis\nframework using Multi-Agent LLMs for clinical interviews. We leverage the\nscalability and coherence of multi-agent systems through structured\nconversations between agents and coordinate the expertise of cardiac experts in\nTA. Using interview transcripts from parents of children with Anomalous Aortic\nOrigin of a Coronary Artery (AAOCA), a rare congenital heart disease, we\ndemonstrate that TAMA outperforms existing LLM-assisted TA approaches,\nachieving higher thematic hit rate, coverage, and distinctiveness. TAMA\ndemonstrates strong potential for automated TA in clinical settings by\nleveraging multi-agent LLM systems with human-in-the-loop integration by\nenhancing quality while significantly reducing manual workload.", "published": "2025-03-26 15:58:16", "link": "http://arxiv.org/abs/2503.20666v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "TN-Eval: Rubric and Evaluation Protocols for Measuring the Quality of Behavioral Therapy Notes", "abstract": "Behavioral therapy notes are important for both legal compliance and patient\ncare. Unlike progress notes in physical health, quality standards for\nbehavioral therapy notes remain underdeveloped. To address this gap, we\ncollaborated with licensed therapists to design a comprehensive rubric for\nevaluating therapy notes across key dimensions: completeness, conciseness, and\nfaithfulness. Further, we extend a public dataset of behavioral health\nconversations with therapist-written notes and LLM-generated notes, and apply\nour evaluation framework to measure their quality. We find that: (1) A\nrubric-based manual evaluation protocol offers more reliable and interpretable\nresults than traditional Likert-scale annotations. (2) LLMs can mimic human\nevaluators in assessing completeness and conciseness but struggle with\nfaithfulness. (3) Therapist-written notes often lack completeness and\nconciseness, while LLM-generated notes contain hallucination. Surprisingly, in\na blind test, therapists prefer and judge LLM-generated notes to be superior to\ntherapist-written notes.", "published": "2025-03-26 15:40:40", "link": "http://arxiv.org/abs/2503.20648v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging", "abstract": "The transition from System 1 to System 2 reasoning in large language models\n(LLMs) has marked significant advancements in handling complex tasks through\ndeliberate, iterative thinking. However, this progress often comes at the cost\nof efficiency, as models tend to overthink, generating redundant reasoning\nsteps without proportional improvements in output quality. Long-to-Short (L2S)\nreasoning has emerged as a promising solution to this challenge, aiming to\nbalance reasoning depth with practical efficiency. While existing approaches,\nsuch as supervised fine-tuning (SFT), reinforcement learning (RL), and prompt\nengineering, have shown potential, they are either computationally expensive or\nunstable. Model merging, on the other hand, offers a cost-effective and robust\nalternative by integrating the quick-thinking capabilities of System 1 models\nwith the methodical reasoning of System 2 models. In this work, we present a\ncomprehensive empirical study on model merging for L2S reasoning, exploring\ndiverse methodologies, including task-vector-based, SVD-based, and\nactivation-informed merging. Our experiments reveal that model merging can\nreduce average response length by up to 55% while preserving or even improving\nbaseline performance. We also identify a strong correlation between model scale\nand merging efficacy with extensive evaluations on 1.5B/7B/14B/32B models.\nFurthermore, we investigate the merged model's ability to self-critique and\nself-correct, as well as its adaptive response length based on task complexity.\nOur findings highlight model merging as a highly efficient and effective\nparadigm for L2S reasoning, offering a practical solution to the overthinking\nproblem while maintaining the robustness of System 2 reasoning. This work can\nbe found on Github https://github.com/hahahawu/Long-to-Short-via-Model-Merging.", "published": "2025-03-26 15:34:37", "link": "http://arxiv.org/abs/2503.20641v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PVLens: Enhancing Pharmacovigilance Through Automated Label Extraction", "abstract": "Reliable drug safety reference databases are essential for pharmacovigilance,\nyet existing resources like SIDER are outdated and static. We introduce PVLens,\nan automated system that extracts labeled safety information from FDA\nStructured Product Labels (SPLs) and maps terms to MedDRA. PVLens integrates\nautomation with expert oversight through a web-based review tool. In validation\nagainst 97 drug labels, PVLens achieved an F1 score of 0.882, with high recall\n(0.983) and moderate precision (0.799). By offering a scalable, more accurate\nand continuously updated alternative to SIDER, PVLens enhances real-time\npharamcovigilance with improved accuracy and contemporaneous insights.", "published": "2025-03-26 15:33:26", "link": "http://arxiv.org/abs/2503.20639v2", "categories": ["cs.CL", "cs.LG", "J.3; H.3.1; D.2.12"], "primary_category": "cs.CL"}
{"title": "Collaborative Storytelling and LLM: A Linguistic Analysis of Automatically-Generated Role-Playing Game Sessions", "abstract": "Role-playing games (RPG) are games in which players interact with one another\nto create narratives. The role of players in the RPG is largely based on the\ninteraction between players and their characters. This emerging form of shared\nnarrative, primarily oral, is receiving increasing attention. In particular,\nmany authors investigated the use of an LLM as an actor in the game. In this\npaper, we aim to discover to what extent the language of Large Language Models\n(LLMs) exhibit oral or written features when asked to generate an RPG session\nwithout human interference. We will conduct a linguistic analysis of the\nlexical and syntactic features of the generated texts and compare the results\nwith analyses of conversations, transcripts of human RPG sessions, and books.\nWe found that LLMs exhibit a pattern that is distinct from all other text\ncategories, including oral conversations, human RPG sessions and books. Our\nanalysis has shown how training influences the way LLMs express themselves and\nprovides important indications of the narrative capabilities of these tools.", "published": "2025-03-26 15:10:47", "link": "http://arxiv.org/abs/2503.20623v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training in translation tools and technologies: Findings of the EMT survey 2023", "abstract": "This article reports on the third iteration of a survey of computerized tools\nand technologies taught as part of postgraduate translation training\nprogrammes. While the survey was carried out under the aegis of the EMT\nNetwork, more than half of responses are from outside that network. The results\nshow the responsiveness of programmes to innovations in translation technology,\nwith increased compulsory inclusion of machine translation, post-editing, and\nquality evaluation, and a rapid response to the release of generative tools.\nThe flexibility required during the Covid-19 pandemic has also led to some\nlasting changes to programmes. While the range of tools being taught has\ncontinued to expand, programmes seem to be consolidating their core offering\naround cloud-based software with cost-free academic access. There has also been\nan increase in the embedding of professional contexts and workflows associated\nwith translation technology. Generic file management and data security skills\nhave increased in perceived importance, and legal and ethical issues related to\ntranslation data have also become more prominent. In terms of course delivery\nthe shift away from conventional labs identified in EMT2017 has accelerated\nmarkedly, no doubt partly driven by the pandemic, accompanied by a dramatic\nexpansion in the use of students' personal devices.", "published": "2025-03-26 14:49:14", "link": "http://arxiv.org/abs/2503.22735v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Synthetic Data Augmentation for Cross-domain Implicit Discourse Relation Recognition", "abstract": "Implicit discourse relation recognition (IDRR) -- the task of identifying the\nimplicit coherence relation between two text spans -- requires deep semantic\nunderstanding. Recent studies have shown that zero- or few-shot approaches\nsignificantly lag behind supervised models, but LLMs may be useful for\nsynthetic data augmentation, where LLMs generate a second argument following a\nspecified coherence relation. We applied this approach in a cross-domain\nsetting, generating discourse continuations using unlabelled target-domain data\nto adapt a base model which was trained on source-domain labelled data.\nEvaluations conducted on a large-scale test set revealed that different\nvariations of the approach did not result in any significant improvements. We\nconclude that LLMs often fail to generate useful samples for IDRR, and\nemphasize the importance of considering both statistical significance and\ncomparability when evaluating IDRR models.", "published": "2025-03-26 14:41:04", "link": "http://arxiv.org/abs/2503.20588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models", "abstract": "In this work, we explore the potential of large language models (LLMs) for\ngenerating functional test scripts, which necessitates understanding the\ndynamically evolving code structure of the target software. To achieve this, we\npropose a case-based reasoning (CBR) system utilizing a 4R cycle (i.e.,\nretrieve, reuse, revise, and retain), which maintains and leverages a case bank\nof test intent descriptions and corresponding test scripts to facilitate LLMs\nfor test script generation. To improve user experience further, we introduce\nRe4, an optimization method for the CBR system, comprising reranking-based\nretrieval finetuning and reinforced reuse finetuning. Specifically, we first\nidentify positive examples with high semantic and script similarity, providing\nreliable pseudo-labels for finetuning the retriever model without costly\nlabeling. Then, we apply supervised finetuning, followed by a reinforcement\nlearning finetuning stage, to align LLMs with our production scenarios,\nensuring the faithful reuse of retrieved cases. Extensive experimental results\non two product development units from Huawei Datacom demonstrate the\nsuperiority of the proposed CBR+Re4. Notably, we also show that the proposed\nRe4 method can help alleviate the repetitive generation issues with LLMs.", "published": "2025-03-26 14:23:59", "link": "http://arxiv.org/abs/2503.20576v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Low-resource Information Extraction with the European Clinical Case Corpus", "abstract": "We present E3C-3.0, a multilingual dataset in the medical domain, comprising\nclinical cases annotated with diseases and test-result relations. The dataset\nincludes both native texts in five languages (English, French, Italian, Spanish\nand Basque) and texts translated and projected from the English source into\nfive target languages (Greek, Italian, Polish, Slovak, and Slovenian). A\nsemi-automatic approach has been implemented, including automatic annotation\nprojection based on Large Language Models (LLMs) and human revision. We present\nseveral experiments showing that current state-of-the-art LLMs can benefit from\nbeing fine-tuned on the E3C-3.0 dataset. We also show that transfer learning in\ndifferent languages is very effective, mitigating the scarcity of data.\nFinally, we compare performance both on native data and on projected data. We\nrelease the data at\nhttps://huggingface.co/collections/NLP-FBK/e3c-projected-676a7d6221608d60e4e9fd89 .", "published": "2025-03-26 14:07:40", "link": "http://arxiv.org/abs/2503.20568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Retrieval-Based Approach to Medical Procedure Matching in Romanian", "abstract": "Accurately mapping medical procedure names from healthcare providers to\nstandardized terminology used by insurance companies is a crucial yet complex\ntask. Inconsistencies in naming conventions lead to missclasified procedures,\ncausing administrative inefficiencies and insurance claim problems in private\nhealthcare settings. Many companies still use human resources for manual\nmapping, while there is a clear opportunity for automation. This paper proposes\na retrieval-based architecture leveraging sentence embeddings for medical name\nmatching in the Romanian healthcare system. This challenge is significantly\nmore difficult in underrepresented languages such as Romanian, where existing\npretrained language models lack domain-specific adaptation to medical text. We\nevaluate multiple embedding models, including Romanian, multilingual, and\nmedical-domain-specific representations, to identify the most effective\nsolution for this task. Our findings contribute to the broader field of medical\nNLP for low-resource languages such as Romanian.", "published": "2025-03-26 13:54:16", "link": "http://arxiv.org/abs/2503.20556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerate Parallelizable Reasoning via Parallel Decoding within One Sequence", "abstract": "Recent advances in reasoning models have demonstrated significant\nimprovements in accuracy, particularly for complex tasks such as mathematical\nreasoning, by employing detailed and comprehensive reasoning processes.\nHowever, generating these lengthy reasoning sequences is computationally\nexpensive and time-consuming. To address this inefficiency, we leverage the\ninherent parallelizability of certain tasks to accelerate the reasoning\nprocess. Specifically, when multiple parallel reasoning branches exist, we\ndecode multiple tokens per step using a specialized attention mask, processing\nthem within a single sequence, avoiding additional memory usage. Experimental\nresults show that our method achieves over 100% speedup in decoding time while\nmaintaining the answer quality.", "published": "2025-03-26 13:28:57", "link": "http://arxiv.org/abs/2503.20533v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StableToolBench-MirrorAPI: Modeling Tool Environments as Mirrors of 7,000+ Real-World APIs", "abstract": "The rapid advancement of large language models (LLMs) has spurred significant\ninterest in tool learning, where LLMs are augmented with external tools to\ntackle complex tasks. However, existing tool environments face challenges in\nbalancing stability, scalability, and realness, particularly for benchmarking\npurposes. To address this problem, we propose MirrorAPI, a novel framework that\ntrains specialized LLMs to accurately simulate real API responses, effectively\nacting as \"mirrors\" to tool environments. Using a comprehensive dataset of\nrequest-response pairs from 7,000+ APIs, we employ supervised fine-tuning and\nchain-of-thought reasoning to enhance simulation fidelity. MirrorAPI achieves\nsuperior accuracy and stability compared to state-of-the-art methods, as\ndemonstrated by its performance on the newly constructed MirrorAPI-Bench and\nits integration into StableToolBench.", "published": "2025-03-26 13:13:03", "link": "http://arxiv.org/abs/2503.20527v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Effect of Robotic Embodiment and Empathetic Tone of LLMs on Empathy Elicitation", "abstract": "This study investigates the elicitation of empathy toward a third party\nthrough interaction with social agents. Participants engaged with either a\nphysical robot or a voice-enabled chatbot, both driven by a large language\nmodel (LLM) programmed to exhibit either an empathetic tone or remain neutral.\nThe interaction is focused on a fictional character, Katie Banks, who is in a\nchallenging situation and in need of financial donations. The willingness to\nhelp Katie, measured by the number of hours participants were willing to\nvolunteer, along with their perceptions of the agent, were assessed for 60\nparticipants. Results indicate that neither robotic embodiment nor empathetic\ntone significantly influenced participants' willingness to volunteer. While the\nLLM effectively simulated human empathy, fostering genuine empathetic responses\nin participants proved challenging.", "published": "2025-03-26 13:00:05", "link": "http://arxiv.org/abs/2503.20518v1", "categories": ["cs.HC", "cs.CL", "cs.RO", "I.2.9, I.2.7, H.5.2"], "primary_category": "cs.HC"}
{"title": "Explainable ICD Coding via Entity Linking", "abstract": "Clinical coding is a critical task in healthcare, although traditional\nmethods for automating clinical coding may not provide sufficient explicit\nevidence for coders in production environments. This evidence is crucial, as\nmedical coders have to make sure there exists at least one explicit passage in\nthe input health record that justifies the attribution of a code. We therefore\npropose to reframe the task as an entity linking problem, in which each\ndocument is annotated with its set of codes and respective textual evidence,\nenabling better human-machine collaboration. By leveraging parameter-efficient\nfine-tuning of Large Language Models (LLMs), together with constrained\ndecoding, we introduce three approaches to solve this problem that prove\neffective at disambiguating clinical mentions and that perform well in few-shot\nscenarios.", "published": "2025-03-26 12:49:35", "link": "http://arxiv.org/abs/2503.20508v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Depression Detection via Question-wise Modality Fusion", "abstract": "Depression is a highly prevalent and disabling condition that incurs\nsubstantial personal and societal costs. Current depression diagnosis involves\ndetermining the depression severity of a person through self-reported\nquestionnaires or interviews conducted by clinicians. This often leads to\ndelayed treatment and involves substantial human resources. Thus, several works\ntry to automate the process using multimodal data. However, they usually\noverlook the following: i) The variable contribution of each modality for each\nquestion in the questionnaire and ii) Using ordinal classification for the\ntask. This results in sub-optimal fusion and training methods. In this work, we\npropose a novel Question-wise Modality Fusion (QuestMF) framework trained with\na novel Imbalanced Ordinal Log-Loss (ImbOLL) function to tackle these issues.\nThe performance of our framework is comparable to the current state-of-the-art\nmodels on the E-DAIC dataset and enhances interpretability by predicting scores\nfor each question. This will help clinicians identify an individual's symptoms,\nallowing them to customise their interventions accordingly. We also make the\ncode for the QuestMF framework publicly available.", "published": "2025-03-26 12:34:34", "link": "http://arxiv.org/abs/2503.20496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Beyond Limits: Advances and Open Problems for LLMs", "abstract": "Recent generative reasoning breakthroughs have transformed how large language\nmodels (LLMs) tackle complex problems by dynamically retrieving and refining\ninformation while generating coherent, multi-step thought processes. Techniques\nsuch as inference-time scaling, reinforcement learning, supervised fine-tuning,\nand distillation have been successfully applied to models like DeepSeek-R1,\nOpenAI's o1 & o3, GPT-4o, Qwen-32B, and various Llama variants, resulting in\nenhanced reasoning capabilities. In this paper, we provide a comprehensive\nanalysis of the top 27 LLM models released between 2023 and 2025 (including\nmodels such as Mistral AI Small 3 24B, DeepSeek-R1, Search-o1, QwQ-32B, and\nphi-4). Then, we present an extensive overview of training methodologies that\nspans general training approaches, mixture-of-experts (MoE) and architectural\ninnovations, retrieval-augmented generation (RAG), chain-of-thought and\nself-improvement techniques, as well as test-time compute scaling,\ndistillation, and reinforcement learning (RL) methods. Finally, we discuss the\nkey challenges in advancing LLM capabilities, including improving multi-step\nreasoning without human supervision, overcoming limitations in chained tasks,\nbalancing structured prompts with flexibility, and enhancing long-context\nretrieval and external tool integration.", "published": "2025-03-26 12:29:40", "link": "http://arxiv.org/abs/2503.22732v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VPO: Aligning Text-to-Video Generation Models with Prompt Optimization", "abstract": "Video generation models have achieved remarkable progress in text-to-video\ntasks. These models are typically trained on text-video pairs with highly\ndetailed and carefully crafted descriptions, while real-world user inputs\nduring inference are often concise, vague, or poorly structured. This gap makes\nprompt optimization crucial for generating high-quality videos. Current methods\noften rely on large language models (LLMs) to refine prompts through in-context\nlearning, but suffer from several limitations: they may distort user intent,\nomit critical details, or introduce safety risks. Moreover, they optimize\nprompts without considering the impact on the final video quality, which can\nlead to suboptimal results. To address these issues, we introduce VPO, a\nprincipled framework that optimizes prompts based on three core principles:\nharmlessness, accuracy, and helpfulness. The generated prompts faithfully\npreserve user intents and, more importantly, enhance the safety and quality of\ngenerated videos. To achieve this, VPO employs a two-stage optimization\napproach. First, we construct and refine a supervised fine-tuning (SFT) dataset\nbased on principles of safety and alignment. Second, we introduce both\ntext-level and video-level feedback to further optimize the SFT model with\npreference learning. Our extensive experiments demonstrate that VPO\nsignificantly improves safety, alignment, and video quality compared to\nbaseline methods. Moreover, VPO shows strong generalization across video\ngeneration models. Furthermore, we demonstrate that VPO could outperform and be\ncombined with RLHF methods on video generation models, underscoring the\neffectiveness of VPO in aligning video generation models. Our code and data are\npublicly available at https://github.com/thu-coai/VPO.", "published": "2025-03-26 12:28:20", "link": "http://arxiv.org/abs/2503.20491v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TempTest: Local Normalization Distortion and the Detection of Machine-generated Text", "abstract": "Existing methods for the zero-shot detection of machine-generated text are\ndominated by three statistical quantities: log-likelihood, log-rank, and\nentropy. As language models mimic the distribution of human text ever closer,\nthis will limit our ability to build effective detection algorithms. To combat\nthis, we introduce a method for detecting machine-generated text that is\nentirely agnostic of the generating language model. This is achieved by\ntargeting a defect in the way that decoding strategies, such as temperature or\ntop-k sampling, normalize conditional probability measures. This method can be\nrigorously theoretically justified, is easily explainable, and is conceptually\ndistinct from existing methods for detecting machine-generated text. We\nevaluate our detector in the white and black box settings across various\nlanguage models, datasets, and passage lengths. We also study the effect of\nparaphrasing attacks on our detector and the extent to which it is biased\nagainst non-native speakers. In each of these settings, the performance of our\ntest is at least comparable to that of other state-of-the-art text detectors,\nand in some cases, we strongly outperform these baselines.", "published": "2025-03-26 10:56:59", "link": "http://arxiv.org/abs/2503.20421v1", "categories": ["cs.CL", "cs.LG", "math.DS"], "primary_category": "cs.CL"}
{"title": "CFunModel: A \"Funny\" Language Model Capable of Chinese Humor Generation and Processing", "abstract": "Humor plays a significant role in daily language communication. With the\nrapid development of large language models (LLMs), natural language processing\nhas made significant strides in understanding and generating various genres of\ntexts. However, most LLMs exhibit poor performance in generating and processing\nChinese humor. In this study, we introduce a comprehensive Chinese\nhumor-related dataset, the Chinese Fun Set (CFunSet). This dataset aggregates\nexisting Chinese humor datasets and includes over 20,000 jokes collected from\nTieba-JokeBar, a Chinese online platform known for joke sharing. The resulting\ncorpus comprises more than 160,000 entries. Leveraging CFunSet, we developed\nthe Chinese Fun Model (CFunModel), the first large language model designed to\nhandle various Chinese humor-related tasks including Crosstalk Response\nSelection, Humor Recognition, Joke Generation, etc. Experimental results\ndemonstrate that CFunModel outperforms popular large language models in these\ntasks. Our CFunSet is available at\nhttps://huggingface.co/datasets/ZhenghanYU/CFunSet and CFunModel is available\nat https://huggingface.co/ZhenghanYU/CFunModel. A demostration video of our\nwork is available at https://youtu.be/MOsISOJ66Ms.", "published": "2025-03-26 10:44:51", "link": "http://arxiv.org/abs/2503.20417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VideoGEM: Training-free Action Grounding in Videos", "abstract": "Vision-language foundation models have shown impressive capabilities across\nvarious zero-shot tasks, including training-free localization and grounding,\nprimarily focusing on localizing objects in images. However, leveraging those\ncapabilities to localize actions and events in videos is challenging, as\nactions have less physical outline and are usually described by higher-level\nconcepts. In this work, we propose VideoGEM, the first training-free spatial\naction grounding method based on pretrained image- and video-language\nbackbones. Namely, we adapt the self-self attention formulation of GEM to\nspatial activity grounding. We observe that high-level semantic concepts, such\nas actions, usually emerge in the higher layers of the image- and\nvideo-language models. We, therefore, propose a layer weighting in the\nself-attention path to prioritize higher layers. Additionally, we introduce a\ndynamic weighting method to automatically tune layer weights to capture each\nlayer`s relevance to a specific prompt. Finally, we introduce a prompt\ndecomposition, processing action, verb, and object prompts separately,\nresulting in a better spatial localization of actions. We evaluate the proposed\napproach on three image- and video-language backbones, CLIP, OpenCLIP, and\nViCLIP, and on four video grounding datasets, V-HICO, DALY,\nYouCook-Interactions, and GroundingYouTube, showing that the proposed\ntraining-free approach is able to outperform current trained state-of-the-art\napproaches for spatial video grounding.", "published": "2025-03-26 09:20:30", "link": "http://arxiv.org/abs/2503.20348v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Iterative Prompting with Persuasion Skills in Jailbreaking Large Language Models", "abstract": "Large language models (LLMs) are designed to align with human values in their\nresponses. This study exploits LLMs with an iterative prompting technique where\neach prompt is systematically modified and refined across multiple iterations\nto enhance its effectiveness in jailbreaking attacks progressively. This\ntechnique involves analyzing the response patterns of LLMs, including GPT-3.5,\nGPT-4, LLaMa2, Vicuna, and ChatGLM, allowing us to adjust and optimize prompts\nto evade the LLMs' ethical and security constraints. Persuasion strategies\nenhance prompt effectiveness while maintaining consistency with malicious\nintent. Our results show that the attack success rates (ASR) increase as the\nattacking prompts become more refined with the highest ASR of 90% for GPT4 and\nChatGLM and the lowest ASR of 68% for LLaMa2. Our technique outperforms\nbaseline techniques (PAIR and PAP) in ASR and shows comparable performance with\nGCG and ArtPrompt.", "published": "2025-03-26 08:40:46", "link": "http://arxiv.org/abs/2503.20320v1", "categories": ["cs.CL", "cs.AI", "cs.ET"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition in Context", "abstract": "We present the Named Entity Recognition system developed by the Edit Dunhuang\nteam for the EvaHan2025 competition. Our approach integrates three core\ncomponents: (1) Pindola, a modern transformer-based bidirectional encoder\npretrained on a large corpus of Classical Chinese texts; (2) a retrieval module\nthat fetches relevant external context for each target sequence; and (3) a\ngenerative reasoning step that summarizes retrieved context in Classical\nChinese for more robust entity disambiguation. Using this approach, we achieve\nan average F1 score of 85.58, improving upon the competition baseline by nearly\n5 points.", "published": "2025-03-26 08:37:19", "link": "http://arxiv.org/abs/2503.20836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications", "abstract": "Misgendering is the act of referring to someone by a gender that does not\nmatch their chosen identity. It marginalizes and undermines a person's sense of\nself, causing significant harm. English-based approaches have clear-cut\napproaches to avoiding misgendering, such as the use of the pronoun ``they''.\nHowever, other languages pose unique challenges due to both grammatical and\ncultural constructs. In this work we develop methodologies to assess and\nmitigate misgendering across 42 languages and dialects using a\nparticipatory-design approach to design effective and appropriate guardrails\nacross all languages. We test these guardrails in a standard large language\nmodel-based application (meeting transcript summarization), where both the data\ngeneration and the annotation steps followed a human-in-the-loop approach. We\nfind that the proposed guardrails are very effective in reducing misgendering\nrates across all languages in the summaries generated, and without incurring\nloss of quality. Our human-in-the-loop approach demonstrates a method to\nfeasibly scale inclusive and responsible AI-based solutions across multiple\nlanguages and cultures.", "published": "2025-03-26 08:01:35", "link": "http://arxiv.org/abs/2503.20302v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comprehensive Manuscript Assessment with Text Summarization Using 69707 articles", "abstract": "Rapid and efficient assessment of the future impact of research articles is a\nsignificant concern for both authors and reviewers. The most common standard\nfor measuring the impact of academic papers is the number of citations. In\nrecent years, numerous efforts have been undertaken to predict citation counts\nwithin various citation windows. However, most of these studies focus solely on\na specific academic field or require early citation counts for prediction,\nrendering them impractical for the early-stage evaluation of papers. In this\nwork, we harness Scopus to curate a significantly comprehensive and large-scale\ndataset of information from 69707 scientific articles sourced from 99 journals\nspanning multiple disciplines. We propose a deep learning methodology for the\nimpact-based classification tasks, which leverages semantic features extracted\nfrom the manuscripts and paper metadata. To summarize the semantic features,\nsuch as titles and abstracts, we employ a Transformer-based language model to\nencode semantic features and design a text fusion layer to capture shared\ninformation between titles and abstracts. We specifically focus on the\nfollowing impact-based prediction tasks using information of scientific\nmanuscripts in pre-publication stage: (1) The impact of journals in which the\nmanuscripts will be published. (2) The future impact of manuscripts themselves.\nExtensive experiments on our datasets demonstrate the superiority of our\nproposed model for impact-based prediction tasks. We also demonstrate\npotentials in generating manuscript's feedback and improvement suggestions.", "published": "2025-03-26 07:56:15", "link": "http://arxiv.org/abs/2503.20835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions", "abstract": "This paper explores a novel perspective to speech quality assessment by\nleveraging natural language descriptions, offering richer, more nuanced\ninsights than traditional numerical scoring methods. Natural language feedback\nprovides instructive recommendations and detailed evaluations, yet existing\ndatasets lack the comprehensive annotations needed for this approach. To bridge\nthis gap, we introduce QualiSpeech, a comprehensive low-level speech quality\nassessment dataset encompassing 11 key aspects and detailed natural language\ncomments that include reasoning and contextual insights. Additionally, we\npropose the QualiSpeech Benchmark to evaluate the low-level speech\nunderstanding capabilities of auditory large language models (LLMs).\nExperimental results demonstrate that finetuned auditory LLMs can reliably\ngenerate detailed descriptions of noise and distortion, effectively identifying\ntheir types and temporal characteristics. The results further highlight the\npotential for incorporating reasoning to enhance the accuracy and reliability\nof quality assessments. The dataset will be released at\nhttps://huggingface.co/datasets/tsinghua-ee/QualiSpeech.", "published": "2025-03-26 07:32:20", "link": "http://arxiv.org/abs/2503.20290v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "sudo rm -rf agentic_security", "abstract": "Large Language Models (LLMs) are increasingly deployed as computer-use\nagents, autonomously performing tasks within real desktop or web environments.\nWhile this evolution greatly expands practical use cases for humans, it also\ncreates serious security exposures. We present SUDO (Screen-based Universal\nDetox2Tox Offense), a novel attack framework that systematically bypasses\nrefusal trained safeguards in commercial computer-use agents, such as Claude\nComputer Use. The core mechanism, Detox2Tox, transforms harmful requests (that\nagents initially reject) into seemingly benign requests via detoxification,\nsecures detailed instructions from advanced vision language models (VLMs), and\nthen reintroduces malicious content via toxification just before execution.\nUnlike conventional jailbreaks, SUDO iteratively refines its attacks based on a\nbuilt-in refusal feedback, making it increasingly effective against robust\npolicy filters. In extensive tests spanning 50 real-world tasks and multiple\nstate-of-the-art VLMs, SUDO achieves a stark attack success rate of 24% (with\nno refinement), and up to 41% (by its iterative refinement) in Claude Computer\nUse. By revealing these vulnerabilities and demonstrating the ease with which\nthey can be exploited in real-world computing environments, this paper\nhighlights an immediate need for robust, context-aware safeguards. WARNING:\nThis paper includes harmful or offensive model outputs Our code is available\nat: https://github.com/AIM-Intelligence/SUDO.git", "published": "2025-03-26 07:08:15", "link": "http://arxiv.org/abs/2503.20279v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "ViLBench: A Suite for Vision-Language Process Reward Modeling", "abstract": "Process-supervised reward models serve as a fine-grained function that\nprovides detailed step-wise feedback to model responses, facilitating effective\nselection of reasoning trajectories for complex tasks. Despite its advantages,\nevaluation on PRMs remains less explored, especially in the multimodal domain.\nTo address this gap, this paper first benchmarks current vision large language\nmodels (VLLMs) as two types of reward models: output reward models (ORMs) and\nprocess reward models (PRMs) on multiple vision-language benchmarks, which\nreveal that neither ORM nor PRM consistently outperforms across all tasks, and\nsuperior VLLMs do not necessarily yield better rewarding performance. To\nfurther advance evaluation, we introduce ViLBench, a vision-language benchmark\ndesigned to require intensive process reward signals. Notably, OpenAI's GPT-4o\nwith Chain-of-Thought (CoT) achieves only 27.3% accuracy, indicating the\nbenchmark's challenge for current VLLMs. Lastly, we preliminarily showcase a\npromising pathway towards bridging the gap between general VLLMs and reward\nmodels -- by collecting 73.6K vision-language process reward data using an\nenhanced tree-search algorithm, our 3B model is able to achieve an average\nimprovement of 3.3% over standard CoT and up to 2.5% compared to its untrained\ncounterpart on ViLBench by selecting OpenAI o1's generations. We release the\nimplementations at https://ucsc-vlaa.github.io/ViLBench with our code, model,\nand data.", "published": "2025-03-26 06:38:31", "link": "http://arxiv.org/abs/2503.20271v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Large-Scale Vision-Language Dataset Derived from Open Scientific Literature to Advance Biomedical Generalist AI", "abstract": "Despite the excitement behind biomedical artificial intelligence (AI), access\nto high-quality, diverse, and large-scale data - the foundation for modern AI\nsystems - is still a bottleneck to unlocking its full potential. To address\nthis gap, we introduce Biomedica, an open-source dataset derived from the\nPubMed Central Open Access subset, containing over 6 million scientific\narticles and 24 million image-text pairs, along with 27 metadata fields\n(including expert human annotations). To overcome the challenges of accessing\nour large-scale dataset, we provide scalable streaming and search APIs through\na web server, facilitating seamless integration with AI systems. We demonstrate\nthe utility of the Biomedica dataset by building embedding models, chat-style\nmodels, and retrieval-augmented chat agents. Notably, all our AI models surpass\nprevious open systems in their respective categories, underscoring the critical\nrole of diverse, high-quality, and large-scale biomedical data.", "published": "2025-03-26 05:56:46", "link": "http://arxiv.org/abs/2503.22727v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimizing Safe and Aligned Language Generation: A Multi-Objective GRPO Approach", "abstract": "Aligning large language models (LLMs) with human values and safety\nconstraints is challenging, especially when objectives like helpfulness,\ntruthfulness, and avoidance of harm conflict. Reinforcement Learning from Human\nFeedback (RLHF) has achieved notable success in steering models, but is complex\nand can be unstable. Recent approaches such as Direct Preference Optimization\n(DPO) simplify preference-based fine-tuning but may introduce bias or trade-off\ncertain objectives~\\cite{dpo}. In this work, we propose a Group Relative Policy\nOptimization (GRPO) framework with a multi-label reward regression model to\nachieve safe and aligned language generation. The GRPO algorithm optimizes a\npolicy by comparing groups of sampled responses, eliminating the need for a\nseparate value critic and improving training efficiency~\\cite{grpo}. We train a\nreward model to predict multiple alignment scores (e.g., safety, helpfulness,\netc.), which are combined into a single reward signal. We provide a theoretical\nderivation for using this learned multi-aspect reward within GRPO and discuss\nits advantages and limitations. Empirically, our approach improves all the\nsafety and quality metrics evaluated in language generation tasks on model\nscales (0.5B, 7B, and 14B parameters), demonstrating a robust balance of\nobjectives. We compare GRPO to PPO-based RLHF and DPO, highlighting that GRPO\nachieves alignment with significantly lower computational cost and explicit\nmulti-objective handling. \\textbf{We will open-source all trained models at\nhttps://huggingface.co/hydroxai.", "published": "2025-03-26 05:50:33", "link": "http://arxiv.org/abs/2503.21819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "abstract": "In online advertising systems, publishers often face a trade-off in\ninformation disclosure strategies: while disclosing more information can\nenhance efficiency by enabling optimal allocation of ad impressions, it may\nlose revenue potential by decreasing uncertainty among competing advertisers.\nSimilar to other challenges in market design, understanding this trade-off is\nconstrained by limited access to real-world data, leading researchers and\npractitioners to turn to simulation frameworks. The recent emergence of large\nlanguage models (LLMs) offers a novel approach to simulations, providing\nhuman-like reasoning and adaptability without necessarily relying on explicit\nassumptions about agent behavior modeling. Despite their potential, existing\nframeworks have yet to integrate LLM-based agents for studying information\nasymmetry and signaling strategies, particularly in the context of auctions. To\naddress this gap, we introduce InfoBid, a flexible simulation framework that\nleverages LLM agents to examine the effects of information disclosure\nstrategies in multi-agent auction settings. Using GPT-4o, we implemented\nsimulations of second-price auctions with diverse information schemas. The\nresults reveal key insights into how signaling influences strategic behavior\nand auction outcomes, which align with both economic and social learning\ntheories. Through InfoBid, we hope to foster the use of LLMs as proxies for\nhuman economic and social agents in empirical studies, enhancing our\nunderstanding of their capabilities and limitations. This work bridges the gap\nbetween theoretical market designs and practical applications, advancing\nresearch in market simulations, information design, and agent-based reasoning\nwhile offering a valuable tool for exploring the dynamics of digital economies.", "published": "2025-03-26 04:46:57", "link": "http://arxiv.org/abs/2503.22726v1", "categories": ["cs.GT", "cs.CL", "cs.HC", "cs.MA", "econ.GN", "q-fin.EC"], "primary_category": "cs.GT"}
{"title": "TeleLoRA: Teleporting Model-Specific Alignment Across LLMs", "abstract": "Mitigating Trojans in Large Language Models (LLMs) is one of many tasks where\nalignment data is LLM specific, as different LLMs have different Trojan\ntriggers and trigger behaviors to be removed. In this paper, we introduce\nTeleLoRA (Teleporting Low-Rank Adaptation), a novel framework that synergizes\nmodel-specific alignment data across multiple LLMs to enable zero-shot Trojan\nmitigation on unseen LLMs without alignment data. TeleLoRA learns a unified\ngenerator of LoRA adapter weights by leveraging local activation information\nacross multiple LLMs. This generator is designed to be permutation symmetric to\ngeneralize across models with different architectures and sizes. We optimize\nthe model design for memory efficiency, making it feasible to learn with\nlarge-scale LLMs with minimal computational resources. Experiments on LLM\nTrojan mitigation benchmarks demonstrate that TeleLoRA effectively reduces\nattack success rates while preserving the benign performance of the models.", "published": "2025-03-26 04:46:31", "link": "http://arxiv.org/abs/2503.20228v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Advancements in Natural Language Processing: Exploring Transformer-Based Architectures for Text Understanding", "abstract": "Natural Language Processing (NLP) has witnessed a transformative leap with\nthe advent of transformer-based architectures, which have significantly\nenhanced the ability of machines to understand and generate human-like text.\nThis paper explores the advancements in transformer models, such as BERT and\nGPT, focusing on their superior performance in text understanding tasks\ncompared to traditional methods like recurrent neural networks (RNNs). By\nanalyzing statistical properties through visual representations-including\nprobability density functions of text length distributions and feature space\nclassifications-the study highlights the models' proficiency in handling\nlong-range dependencies, adapting to conditional shifts, and extracting\nfeatures for classification, even with overlapping classes. Drawing on recent\n2024 research, including enhancements in multi-hop knowledge graph reasoning\nand context-aware chat interactions, the paper outlines a methodology involving\ndata preparation, model selection, pretraining, fine-tuning, and evaluation.\nThe results demonstrate state-of-the-art performance on benchmarks like GLUE\nand SQuAD, with F1 scores exceeding 90%, though challenges such as high\ncomputational costs persist. This work underscores the pivotal role of\ntransformers in modern NLP and suggests future directions, including efficiency\noptimization and multimodal integration, to further advance language-based AI\nsystems.", "published": "2025-03-26 04:45:33", "link": "http://arxiv.org/abs/2503.20227v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Qwen2.5-Omni Technical Report", "abstract": "In this report, we present Qwen2.5-Omni, an end-to-end multimodal model\ndesigned to perceive diverse modalities, including text, images, audio, and\nvideo, while simultaneously generating text and natural speech responses in a\nstreaming manner. To enable the streaming of multimodal information inputs,\nboth audio and visual encoders utilize a block-wise processing approach. To\nsynchronize the timestamps of video inputs with audio, we organize the audio\nand video sequentially in an interleaved manner and propose a novel position\nembedding approach, named TMRoPE(Time-aligned Multimodal RoPE). To concurrently\ngenerate text and speech while avoiding interference between the two\nmodalities, we propose \\textbf{Thinker-Talker} architecture. In this framework,\nThinker functions as a large language model tasked with text generation, while\nTalker is a dual-track autoregressive model that directly utilizes the hidden\nrepresentations from the Thinker to produce audio tokens as output. Both the\nThinker and Talker models are designed to be trained and inferred in an\nend-to-end manner. For decoding audio tokens in a streaming manner, we\nintroduce a sliding-window DiT that restricts the receptive field, aiming to\nreduce the initial package delay. Qwen2.5-Omni is comparable with the similarly\nsized Qwen2.5-VL and outperforms Qwen2-Audio. Furthermore, Qwen2.5-Omni\nachieves state-of-the-art performance on multimodal benchmarks like Omni-Bench.\nNotably, Qwen2.5-Omni's performance in end-to-end speech instruction following\nis comparable to its capabilities with text inputs, as evidenced by benchmarks\nsuch as MMLU and GSM8K. As for speech generation, Qwen2.5-Omni's streaming\nTalker outperforms most existing streaming and non-streaming alternatives in\nrobustness and naturalness.", "published": "2025-03-26 04:17:55", "link": "http://arxiv.org/abs/2503.20215v1", "categories": ["cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages", "abstract": "This report introduces Dolphin, a large-scale multilingual automatic speech\nrecognition (ASR) model that extends the Whisper architecture to support a\nwider range of languages. Our approach integrates in-house proprietary and\nopen-source datasets to refine and optimize Dolphin's performance. The model is\nspecifically designed to achieve notable recognition accuracy for 40 Eastern\nlanguages across East Asia, South Asia, Southeast Asia, and the Middle East,\nwhile also supporting 22 Chinese dialects. Experimental evaluations show that\nDolphin significantly outperforms current state-of-the-art open-source models\nacross various languages. To promote reproducibility and community-driven\ninnovation, we are making our trained models and inference source code publicly\navailable.", "published": "2025-03-26 04:14:03", "link": "http://arxiv.org/abs/2503.20212v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SARGes: Semantically Aligned Reliable Gesture Generation via Intent Chain", "abstract": "Co-speech gesture generation enhances human-computer interaction realism\nthrough speech-synchronized gesture synthesis. However, generating semantically\nmeaningful gestures remains a challenging problem. We propose SARGes, a novel\nframework that leverages large language models (LLMs) to parse speech content\nand generate reliable semantic gesture labels, which subsequently guide the\nsynthesis of meaningful co-speech gestures.First, we constructed a\ncomprehensive co-speech gesture ethogram and developed an LLM-based intent\nchain reasoning mechanism that systematically parses and decomposes gesture\nsemantics into structured inference steps following ethogram criteria,\neffectively guiding LLMs to generate context-aware gesture labels.\nSubsequently, we constructed an intent chain-annotated text-to-gesture label\ndataset and trained a lightweight gesture label generation model, which then\nguides the generation of credible and semantically coherent co-speech gestures.\nExperimental results demonstrate that SARGes achieves highly\nsemantically-aligned gesture labeling (50.2% accuracy) with efficient\nsingle-pass inference (0.4 seconds). The proposed method provides an\ninterpretable intent reasoning pathway for semantic gesture synthesis.", "published": "2025-03-26 03:55:41", "link": "http://arxiv.org/abs/2503.20202v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Open Deep Search: Democratizing Search with Open-source Reasoning Agents", "abstract": "We introduce Open Deep Search (ODS) to close the increasing gap between the\nproprietary search AI solutions, such as Perplexity's Sonar Reasoning Pro and\nOpenAI's GPT-4o Search Preview, and their open-source counterparts. The main\ninnovation introduced in ODS is to augment the reasoning capabilities of the\nlatest open-source LLMs with reasoning agents that can judiciously use web\nsearch tools to answer queries. Concretely, ODS consists of two components that\nwork with a base LLM chosen by the user: Open Search Tool and Open Reasoning\nAgent. Open Reasoning Agent interprets the given task and completes it by\norchestrating a sequence of actions that includes calling tools, one of which\nis the Open Search Tool. Open Search Tool is a novel web search tool that\noutperforms proprietary counterparts. Together with powerful open-source\nreasoning LLMs, such as DeepSeek-R1, ODS nearly matches and sometimes surpasses\nthe existing state-of-the-art baselines on two benchmarks: SimpleQA and FRAMES.\nFor example, on the FRAMES evaluation benchmark, ODS improves the best existing\nbaseline of the recently released GPT-4o Search Preview by 9.7% in accuracy.\nODS is a general framework for seamlessly augmenting any LLMs -- for example,\nDeepSeek-R1 that achieves 82.4% on SimpleQA and 30.1% on FRAMES -- with search\nand reasoning capabilities to achieve state-of-the-art performance: 88.3% on\nSimpleQA and 75.3% on FRAMES.", "published": "2025-03-26 03:51:32", "link": "http://arxiv.org/abs/2503.20201v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization", "abstract": "Recent advances in large language models have highlighted the critical need\nfor precise control over model outputs through predefined constraints. While\nexisting methods attempt to achieve this through either direct\ninstruction-response synthesis or preferential response optimization, they\noften struggle with constraint understanding and adaptation. This limitation\nbecomes particularly evident when handling fine-grained constraints, leading to\neither hallucination or brittle performance. We introduce Generative\nAdversarial Policy Optimization (GAPO), a novel framework that combines\nGAN-based training dynamics with an encoder-only reward model to progressively\nlearn and adapt to increasingly complex constraints. GAPO leverages adversarial\ntraining to automatically generate training samples of varying difficulty while\nutilizing the encoder-only architecture to better capture prompt-response\nrelationships. Extensive experiments demonstrate GAPO's superior performance\nacross multiple benchmarks, particularly in scenarios requiring fine-grained\nconstraint handling, where it significantly outperforms existing methods like\nPPO, DPO, and KTO. Our results suggest that GAPO's unique approach to\npreferential prompt learning offers a more robust and effective solution for\ncontrolling LLM outputs. Code is avaliable in\nhttps://github.com/MikeGu721/GAPO.", "published": "2025-03-26 03:37:52", "link": "http://arxiv.org/abs/2503.20194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Implicit Sentiments: Enhancing Reliability and Validity in Psychological Trait Evaluation of LLMs", "abstract": "Recent advancements in Large Language Models (LLMs) have led to their\nincreasing integration into human life. With the transition from mere tools to\nhuman-like assistants, understanding their psychological aspects-such as\nemotional tendencies and personalities-becomes essential for ensuring their\ntrustworthiness. However, current psychological evaluations of LLMs, often\nbased on human psychological assessments like the BFI, face significant\nlimitations. The results from these approaches often lack reliability and have\nlimited validity when predicting LLM behavior in real-world scenarios. In this\nwork, we introduce a novel evaluation instrument specifically designed for\nLLMs, called Core Sentiment Inventory (CSI). CSI is a bilingual tool, covering\nboth English and Chinese, that implicitly evaluates models' sentiment\ntendencies, providing an insightful psychological portrait of LLM across three\ndimensions: optimism, pessimism, and neutrality. Through extensive experiments,\nwe demonstrate that: 1) CSI effectively captures nuanced emotional patterns,\nrevealing significant variation in LLMs across languages and contexts; 2)\nCompared to current approaches, CSI significantly improves reliability,\nyielding more consistent results; and 3) The correlation between CSI scores and\nthe sentiment of LLM's real-world outputs exceeds 0.85, demonstrating its\nstrong validity in predicting LLM behavior. We make CSI public available via:\nhttps://github.com/dependentsign/CSI.", "published": "2025-03-26 03:14:31", "link": "http://arxiv.org/abs/2503.20182v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ProtoBERT-LoRA: Parameter-Efficient Prototypical Finetuning for Immunotherapy Study Identification", "abstract": "Identifying immune checkpoint inhibitor (ICI) studies in genomic repositories\nlike Gene Expression Omnibus (GEO) is vital for cancer research yet remains\nchallenging due to semantic ambiguity, extreme class imbalance, and limited\nlabeled data in low-resource settings. We present ProtoBERT-LoRA, a hybrid\nframework that combines PubMedBERT with prototypical networks and Low-Rank\nAdaptation (LoRA) for efficient fine-tuning. The model enforces class-separable\nembeddings via episodic prototype training while preserving biomedical domain\nknowledge. Our dataset was divided as: Training (20 positive, 20 negative),\nPrototype Set (10 positive, 10 negative), Validation (20 positive, 200\nnegative), and Test (71 positive, 765 negative). Evaluated on test dataset,\nProtoBERT-LoRA achieved F1-score of 0.624 (precision: 0.481, recall: 0.887),\noutperforming the rule-based system, machine learning baselines and finetuned\nPubMedBERT. Application to 44,287 unlabeled studies reduced manual review\nefforts by 82%. Ablation studies confirmed that combining prototypes with LoRA\nimproved performance by 29% over stand-alone LoRA.", "published": "2025-03-26 03:09:11", "link": "http://arxiv.org/abs/2503.20179v1", "categories": ["cs.CL", "cs.IR", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "The Art of Tool Interface Design", "abstract": "We present an agentic framework, Thinker, which achieves state of art\nperformance in challenging reasoning tasks for realistic customer service\nscenarios that involve complex business logic and human interactions via long\nhorizons. On the $\\tau$-bench retail dataset, Thinker achieves 82.6\\% success\nrate with GPT-4o (version 2024-06-01) (baseline: 68.3\\%), and 81.9\\% success\nrate with Llama-3.1 405B (baseline: 49.6\\%), without any fine-tuning. Thinker\neffectively closes the gap in reasoning capabilities between the base models by\nintroducing proper structure.\n  The key features of the Thinker framework are: (1) State-Machine Augmented\nGeneration (SMAG), which represents business logic as state machines and the\nLLM uses state machines as tools. (2) Delegation of tasks from the main\nreasoning loop to LLM-powered tools. (3) Adaptive context management.\n  Our prompting-only solution achieves signficant gains, while still\nmaintaining a standard agentic architecture with a ReAct style reasoning loop.\nThe key is to innovate on the tool interface design, as exemplified by SMAG and\nthe LLM-powered tools.", "published": "2025-03-26 23:02:00", "link": "http://arxiv.org/abs/2503.21036v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Improving User Behavior Prediction: Leveraging Annotator Metadata in Supervised Machine Learning Models", "abstract": "Supervised machine-learning models often underperform in predicting user\nbehaviors from conversational text, hindered by poor crowdsourced label quality\nand low NLP task accuracy. We introduce the Metadata-Sensitive\nWeighted-Encoding Ensemble Model (MSWEEM), which integrates annotator\nmeta-features like fatigue and speeding. First, our results show MSWEEM\noutperforms standard ensembles by 14\\% on held-out data and 12\\% on an\nalternative dataset. Second, we find that incorporating signals of annotator\nbehavior, such as speed and fatigue, significantly boosts model performance.\nThird, we find that annotators with higher qualifications, such as Master's,\ndeliver more consistent and faster annotations. Given the increasing\nuncertainty over annotation quality, our experiments show that understanding\nannotator patterns is crucial for enhancing model accuracy in user behavior\nprediction.", "published": "2025-03-26 21:30:48", "link": "http://arxiv.org/abs/2503.21000v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FinAudio: A Benchmark for Audio Large Language Models in Financial Applications", "abstract": "Audio Large Language Models (AudioLLMs) have received widespread attention\nand have significantly improved performance on audio tasks such as\nconversation, audio understanding, and automatic speech recognition (ASR).\nDespite these advancements, there is an absence of a benchmark for assessing\nAudioLLMs in financial scenarios, where audio data, such as earnings conference\ncalls and CEO speeches, are crucial resources for financial analysis and\ninvestment decisions. In this paper, we introduce \\textsc{FinAudio}, the first\nbenchmark designed to evaluate the capacity of AudioLLMs in the financial\ndomain. We first define three tasks based on the unique characteristics of the\nfinancial domain: 1) ASR for short financial audio, 2) ASR for long financial\naudio, and 3) summarization of long financial audio. Then, we curate two short\nand two long audio datasets, respectively, and develop a novel dataset for\nfinancial audio summarization, comprising the \\textsc{FinAudio} benchmark.\nThen, we evaluate seven prevalent AudioLLMs on \\textsc{FinAudio}. Our\nevaluation reveals the limitations of existing AudioLLMs in the financial\ndomain and offers insights for improving AudioLLMs. All datasets and codes will\nbe released.", "published": "2025-03-26 21:07:51", "link": "http://arxiv.org/abs/2503.20990v1", "categories": ["cs.CE", "cs.AI", "cs.MM"], "primary_category": "cs.CE"}
{"title": "Competitive Multi-armed Bandit Games for Resource Sharing", "abstract": "In modern resource-sharing systems, multiple agents access limited resources\nwith unknown stochastic conditions to perform tasks. When multiple agents\naccess the same resource (arm) simultaneously, they compete for successful\nusage, leading to contention and reduced rewards. This motivates our study of\ncompetitive multi-armed bandit (CMAB) games. In this paper, we study a new\nN-player K-arm competitive MAB game, where non-myopic players (agents) compete\nwith each other to form diverse private estimations of unknown arms over time.\nTheir possible collisions on same arms and time-varying nature of arm rewards\nmake the policy analysis more involved than existing studies for myopic\nplayers. We explicitly analyze the threshold-based structures of social optimum\nand existing selfish policy, showing that the latter causes prolonged\nconvergence time $\\Omega(\\frac{K}{\\eta^2}\\ln({\\frac{KN}{\\delta}}))$, while\nsocially optimal policy with coordinated communication reduces it to\n$\\mathcal{O}(\\frac{K}{N\\eta^2}\\ln{(\\frac{K}{\\delta})})$. Based on the\ncomparison, we prove that the competition among selfish players for the best\narm can result in an infinite price of anarchy (PoA), indicating an arbitrarily\nlarge efficiency loss compared to social optimum. We further prove that no\ninformational (non-monetary) mechanism (including Bayesian persuasion) can\nreduce the infinite PoA, as the strategic misreporting by non-myopic players\nundermines such approaches. To address this, we propose a Combined\nInformational and Side-Payment (CISP) mechanism, which provides socially\noptimal arm recommendations with proper informational and monetary incentives\nto players according to their time-varying private beliefs. Our CISP mechanism\nkeeps ex-post budget balanced for social planner and ensures truthful reporting\nfrom players, achieving the minimum PoA=1 and same convergence time as social\noptimum.", "published": "2025-03-26 20:35:18", "link": "http://arxiv.org/abs/2503.20975v1", "categories": ["cs.GT", "cs.AI"], "primary_category": "cs.GT"}
{"title": "TS-Inverse: A Gradient Inversion Attack Tailored for Federated Time Series Forecasting Models", "abstract": "Federated learning (FL) for time series forecasting (TSF) enables clients\nwith privacy-sensitive time series (TS) data to collaboratively learn accurate\nforecasting models, for example, in energy load prediction. Unfortunately,\nprivacy risks in FL persist, as servers can potentially reconstruct clients'\ntraining data through gradient inversion attacks (GIA). Although GIA is\ndemonstrated for image classification tasks, little is known about time series\nregression tasks. In this paper, we first conduct an extensive empirical study\non inverting TS data across 4 TSF models and 4 datasets, identifying the unique\nchallenges of reconstructing both observations and targets of TS data. We then\npropose TS-Inverse, a novel GIA that improves the inversion of TS data by (i)\nlearning a gradient inversion model that outputs quantile predictions, (ii) a\nunique loss function that incorporates periodicity and trend regularization,\nand (iii) regularization according to the quantile predictions. Our evaluations\ndemonstrate a remarkable performance of TS-Inverse, achieving at least a 2x-10x\nimprovement in terms of the sMAPE metric over existing GIA methods on TS data.\nCode repository: https://github.com/Capsar/ts-inverse", "published": "2025-03-26 19:35:49", "link": "http://arxiv.org/abs/2503.20952v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DEMENTIA-PLAN: An Agent-Based Framework for Multi-Knowledge Graph Retrieval-Augmented Generation in Dementia Care", "abstract": "Mild-stage dementia patients primarily experience two critical symptoms:\nsevere memory loss and emotional instability. To address these challenges, we\npropose DEMENTIA-PLAN, an innovative retrieval-augmented generation framework\nthat leverages large language models to enhance conversational support. Our\nmodel employs a multiple knowledge graph architecture, integrating various\ndimensional knowledge representations including daily routine graphs and life\nmemory graphs. Through this multi-graph architecture, DEMENTIA-PLAN\ncomprehensively addresses both immediate care needs and facilitates deeper\nemotional resonance through personal memories, helping stabilize patient mood\nwhile providing reliable memory support. Our notable innovation is the\nself-reflection planning agent, which systematically coordinates knowledge\nretrieval and semantic integration across multiple knowledge graphs, while\nscoring retrieved content from daily routine and life memory graphs to\ndynamically adjust their retrieval weights for optimized response generation.\nDEMENTIA-PLAN represents a significant advancement in the clinical application\nof large language models for dementia care, bridging the gap between AI tools\nand caregivers interventions.", "published": "2025-03-26 19:34:04", "link": "http://arxiv.org/abs/2503.20950v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos", "abstract": "Physical agility is a necessary skill in competitive table tennis, but by no\nmeans sufficient. Champions excel in this fast-paced and highly dynamic\nenvironment by anticipating their opponent's intent - buying themselves the\nnecessary time to react. In this work, we take one step towards designing such\nan anticipatory agent. Previous works have developed systems capable of\nreal-time table tennis gameplay, though they often do not leverage\nanticipation. Among the works that forecast opponent actions, their approaches\nare limited by dataset size and variety. Our paper contributes (1) a scalable\nsystem for reconstructing monocular video of table tennis matches in 3D and (2)\nan uncertainty-aware controller that anticipates opponent actions. We\ndemonstrate in simulation that our policy improves the ball return rate against\nhigh-speed hits from 49.9% to 59.0% as compared to a baseline non-anticipatory\npolicy.", "published": "2025-03-26 19:11:22", "link": "http://arxiv.org/abs/2503.20936v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Prototype Guided Backdoor Defense", "abstract": "Deep learning models are susceptible to {\\em backdoor attacks} involving\nmalicious attackers perturbing a small subset of training data with a {\\em\ntrigger} to causes misclassifications. Various triggers have been used,\nincluding semantic triggers that are easily realizable without requiring the\nattacker to manipulate the image. The emergence of generative AI has eased the\ngeneration of varied poisoned samples. Robustness across types of triggers is\ncrucial to effective defense. We propose Prototype Guided Backdoor Defense\n(PGBD), a robust post-hoc defense that scales across different trigger types,\nincluding previously unsolved semantic triggers. PGBD exploits displacements in\nthe geometric spaces of activations to penalize movements toward the trigger.\nThis is done using a novel sanitization loss of a post-hoc fine-tuning step.\nThe geometric approach scales easily to all types of attacks. PGBD achieves\nbetter performance across all settings. We also present the first defense\nagainst a new semantic attack on celebrity face images. Project page:\n\\hyperlink{https://venkatadithya9.github.io/pgbd.github.io/}{this https URL}.", "published": "2025-03-26 18:58:53", "link": "http://arxiv.org/abs/2503.20925v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CSPO: Cross-Market Synergistic Stock Price Movement Forecasting with Pseudo-volatility Optimization", "abstract": "The stock market, as a cornerstone of the financial markets, places\nforecasting stock price movements at the forefront of challenges in\nquantitative finance. Emerging learning-based approaches have made significant\nprogress in capturing the intricate and ever-evolving data patterns of modern\nmarkets. With the rapid expansion of the stock market, it presents two\ncharacteristics, i.e., stock exogeneity and volatility heterogeneity, that\nheighten the complexity of price forecasting. Specifically, while stock\nexogeneity reflects the influence of external market factors on price\nmovements, volatility heterogeneity showcases the varying difficulty in\nmovement forecasting against price fluctuations. In this work, we introduce the\nframework of Cross-market Synergy with Pseudo-volatility Optimization (CSPO).\nSpecifically, CSPO implements an effective deep neural architecture to leverage\nexternal futures knowledge. This enriches stock embeddings with cross-market\ninsights and thus enhances the CSPO's predictive capability. Furthermore, CSPO\nincorporates pseudo-volatility to model stock-specific forecasting confidence,\nenabling a dynamic adaptation of its optimization process to improve accuracy\nand robustness. Our extensive experiments, encompassing industrial evaluation\nand public benchmarking, highlight CSPO's superior performance over existing\nmethods and effectiveness of all proposed modules contained therein.", "published": "2025-03-26 18:58:15", "link": "http://arxiv.org/abs/2503.22740v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Assessing Generative Models for Structured Data", "abstract": "Synthetic tabular data generation has emerged as a promising method to\naddress limited data availability and privacy concerns. With the sharp increase\nin the performance of large language models in recent years, researchers have\nbeen interested in applying these models to the generation of tabular data.\nHowever, little is known about the quality of the generated tabular data from\nlarge language models. The predominant method for assessing the quality of\nsynthetic tabular data is the train-synthetic-test-real approach, where the\nartificial examples are compared to the original by how well machine learning\nmodels, trained separately on the real and synthetic sets, perform in some\ndownstream tasks. This method does not directly measure how closely the\ndistribution of generated data approximates that of the original. This paper\nintroduces rigorous methods for directly assessing synthetic tabular data\nagainst real data by looking at inter-column dependencies within the data. We\nfind that large language models (GPT-2), both when queried via few-shot\nprompting and when fine-tuned, and GAN (CTGAN) models do not produce data with\ndependencies that mirror the original real data. Results from this study can\ninform future practice in synthetic data generation to improve data quality.", "published": "2025-03-26 18:19:05", "link": "http://arxiv.org/abs/2503.20903v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Robust Federated Learning Against Poisoning Attacks: A GAN-Based Defense Framework", "abstract": "Federated Learning (FL) enables collaborative model training across\ndecentralized devices without sharing raw data, but it remains vulnerable to\npoisoning attacks that compromise model integrity. Existing defenses often rely\non external datasets or predefined heuristics (e.g. number of malicious\nclients), limiting their effectiveness and scalability. To address these\nlimitations, we propose a privacy-preserving defense framework that leverages a\nConditional Generative Adversarial Network (cGAN) to generate synthetic data at\nthe server for authenticating client updates, eliminating the need for external\ndatasets. Our framework is scalable, adaptive, and seamlessly integrates into\nFL workflows. Extensive experiments on benchmark datasets demonstrate its\nrobust performance against a variety of poisoning attacks, achieving high True\nPositive Rate (TPR) and True Negative Rate (TNR) of malicious and benign\nclients, respectively, while maintaining model accuracy. The proposed framework\noffers a practical and effective solution for securing federated learning\nsystems.", "published": "2025-03-26 18:00:56", "link": "http://arxiv.org/abs/2503.20884v1", "categories": ["cs.CR", "cs.AI", "cs.DC"], "primary_category": "cs.CR"}
{"title": "Unified Multimodal Discrete Diffusion", "abstract": "Multimodal generative models that can understand and generate across multiple\nmodalities are dominated by autoregressive (AR) approaches, which process\ntokens sequentially from left to right, or top to bottom. These models jointly\nhandle images, text, video, and audio for various tasks such as image\ncaptioning, question answering, and image generation. In this work, we explore\ndiscrete diffusion models as a unified generative formulation in the joint text\nand image domain, building upon their recent success in text generation.\nDiscrete diffusion models offer several advantages over AR models, including\nimproved control over quality versus diversity of generated samples, the\nability to perform joint multimodal inpainting (across both text and image\ndomains), and greater controllability in generation through guidance.\nLeveraging these benefits, we present the first Unified Multimodal Discrete\nDiffusion (UniDisc) model which is capable of jointly understanding and\ngenerating text and images for a variety of downstream tasks. We compare\nUniDisc to multimodal AR models, performing a scaling analysis and\ndemonstrating that UniDisc outperforms them in terms of both performance and\ninference-time compute, enhanced controllability, editability, inpainting, and\nflexible trade-off between inference time and generation quality. Code and\nadditional visualizations are available at https://unidisc.github.io.", "published": "2025-03-26 17:59:51", "link": "http://arxiv.org/abs/2503.20853v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Exploration of Multi-Element Collaborative Research and Application for Modern Power System Based on Generative Large Models", "abstract": "The transition to intelligent, low-carbon power systems necessitates advanced\noptimization strategies for managing renewable energy integration, energy\nstorage, and carbon emissions. Generative Large Models (GLMs) provide a\ndata-driven approach to enhancing forecasting, scheduling, and market\noperations by processing multi-source data and capturing complex system\ndynamics. This paper explores the role of GLMs in optimizing load-side\nmanagement, energy storage utilization, and electricity carbon, with a focus on\nSmart Wide-area Hybrid Energy Systems with Storage and Carbon (SGLSC). By\nleveraging spatiotemporal modeling and reinforcement learning, GLMs enable\ndynamic energy scheduling, improve grid stability, enhance carbon trading\nstrategies, and strengthen resilience against extreme weather events. The\nproposed framework highlights the transformative potential of GLMs in achieving\nefficient, adaptive, and low-carbon power system operations.", "published": "2025-03-26 17:58:49", "link": "http://arxiv.org/abs/2504.02855v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning", "abstract": "Visual reasoning abilities play a crucial role in understanding complex\nmultimodal data, advancing both domain-specific applications and artificial\ngeneral intelligence (AGI). Existing methods improve VLM reasoning via\nChain-of-Thought (CoT) supervised fine-tuning, using meticulously annotated\ntraining data to enhance visual reasoning capabilities. However, this training\nparadigm may lead to overfitting and cognitive rigidity, restricting the\nmodel's ability to transfer visual reasoning skills across domains and limiting\nits real-world applicability. To address these limitations, we propose\nReason-RFT, a novel reinforcement fine-tuning framework that significantly\nenhances generalization capabilities in visual reasoning tasks. Reason-RFT\nintroduces a two-phase training framework for visual reasoning: (1) Supervised\nFine-Tuning (SFT) with curated Chain-of-Thought (CoT) data activates the\nreasoning potential of Vision-Language Models (VLMs), followed by (2) Group\nRelative Policy Optimization (GRPO)-based reinforcement learning that generates\nmultiple reasoning-response pairs, significantly enhancing generalization in\nvisual reasoning tasks. To evaluate Reason-RFT's visual reasoning capabilities,\nwe reconstructed a comprehensive dataset spanning visual counting, structure\nperception, and spatial transformation. Experimental results demonstrate\nReasoning-RFT's three key advantages: (1) Performance Enhancement: achieving\nstate-of-the-art results across multiple tasks, outperforming most mainstream\nopen-source and proprietary models; (2) Generalization Superiority:\nconsistently maintaining robust performance across diverse tasks and domains,\noutperforming alternative training paradigms; (3) Data Efficiency: excelling in\nfew-shot learning scenarios while surpassing full-dataset SFT baselines.\nProject website: https://tanhuajie.github.io/ReasonRFT", "published": "2025-03-26 17:38:06", "link": "http://arxiv.org/abs/2503.20752v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Optimal Scaling Laws for Efficiency Gains in a Theoretical Transformer-Augmented Sectional MoE Framework", "abstract": "This paper introduces a theoretical framework for a Transformer-augmented,\nsectional Mixture-of-Experts (MoE) architecture that aims to enhance\ncomputational efficiency while preserving model scalability. Unlike\nconventional MoE models, which route entire token embeddings to selected\nexperts, our approach portions the embedding dimension itself -- assigning\nsegments of each token's representation to dedicated experts. To combat losses\nin token representation, we utilize a pre-expert transformer layer to recompute\nattention across tokens and reduce the sequence length dimensionality. We\nextend our theory by deriving optimal scaling laws that a non-linear\nrelationship between the number of experts and factors such as model\ndimensionality, sequence length, and system overhead. These formulations yield\nclosed-form and numerically-solvable expressions for identifying the optimal\nexpert count under given architectural and hardware constraints. As a result,\nour framework not only provides theoretical bounds for computing efficiency\nwith varying frameworks but also guides practical design choices for scaling\nlarge models effectively. While empirical validation is pending, we present a\ncomprehensive experimental road map to evaluate the framework's efficiency,\nscalability, and practicality in future work.", "published": "2025-03-26 17:33:38", "link": "http://arxiv.org/abs/2503.20750v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching", "abstract": "We introduce relative and absolute position matching (RAPM), a diffusion\ndistillation method resulting in high quality generation that can be trained\nefficiently on a single GPU. Recent diffusion distillation research has\nachieved excellent results for high-resolution text-to-image generation with\nmethods such as phased consistency models (PCM) and improved distribution\nmatching distillation (DMD2). However, these methods generally require many\nGPUs (e.g.~8-64) and significant batchsizes (e.g.~128-2048) during training,\nresulting in memory and compute requirements that are beyond the resources of\nsome researchers. RAPM provides effective single-GPU diffusion distillation\ntraining with a batchsize of 1. The new method attempts to mimic the sampling\ntrajectories of the teacher model by matching the relative and absolute\npositions. The design of relative positions is inspired by PCM. Two\ndiscriminators are introduced accordingly in RAPM, one for matching relative\npositions and the other for absolute positions. Experimental results on\nStableDiffusion (SD) V1.5 and SDXL indicate that RAPM with 4 timesteps produces\ncomparable FID scores as the best method with 1 timestep under very limited\ncomputational resources.", "published": "2025-03-26 17:29:08", "link": "http://arxiv.org/abs/2503.20744v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Quantum Neural Network Restatement of Markov Jump Process", "abstract": "Despite the many challenges in exploratory data analysis, artificial neural\nnetworks have motivated strong interests in scientists and researchers both in\ntheoretical as well as practical applications. Among sources of such popularity\nof artificial neural networks the ability of modeling non-linear dynamical\nsystems, generalization, and adaptation possibilities should be mentioned.\nDespite this, there is still significant debate about the role of various\nunderlying stochastic processes in stabilizing a unique structure for data\nlearning and prediction. One of such obstacles to the theoretical and numerical\nstudy of machine intelligent systems is the curse of dimensionality and the\nsampling from high-dimensional probability distributions. In general, this\ncurse prevents efficient description of states, providing a significant\ncomplexity barrier for the system to be efficiently described and studied. In\nthis strand of research, direct treatment and description of such abstract\nnotions of learning theory in terms of quantum information be one of the most\nfavorable candidates. Hence, the subject matter of these articles is devoted to\nproblems of design, adaptation and the formulations of computationally hard\nproblems in terms of quantum mechanical systems. In order to characterize the\nmicroscopic description of such dynamics in the language of inferential\nstatistics, covariance matrix estimation of d-dimensional Gaussian densities\nand Bayesian interpretation of eigenvalue problem for dynamical systems is\nassessed.", "published": "2025-03-26 17:25:11", "link": "http://arxiv.org/abs/2503.20742v2", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Emotion Detection and Music Recommendation System", "abstract": "As artificial intelligence becomes more and more ingrained in daily life, we\npresent a novel system that uses deep learning for music recommendation and\nemotion-based detection. Through the use of facial recognition and the DeepFace\nframework, our method analyses human emotions in real-time and then plays music\nthat reflects the mood it has discovered. The system uses a webcam to take\npictures, analyses the most common facial expression, and then pulls a playlist\nfrom local storage that corresponds to the mood it has detected. An engaging\nand customised experience is ensured by allowing users to manually change the\nsong selection via a dropdown menu or navigation buttons. By continuously\nlooping over the playlist, the technology guarantees continuity. The objective\nof our system is to improve emotional well-being through music therapy by\noffering a responsive and automated music-selection experience.", "published": "2025-03-26 17:22:06", "link": "http://arxiv.org/abs/2503.20739v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Cyborg Data: Merging Human with AI Generated Training Data", "abstract": "Automated scoring (AS) systems used in large-scale assessment have\ntraditionally used small statistical models that require a large quantity of\nhand-scored data to make accurate predictions, which can be time-consuming and\ncostly. Generative Large Language Models are trained on many tasks and have\nshown impressive abilities to generalize to new tasks with little to no data.\nWhile these models require substantially more computational power to make\npredictions, they still require some fine-tuning to meet operational standards.\nEvidence suggests that these models can exceed human-human levels of agreement\neven when fine-tuned on small amounts of data. With this in mind, we propose a\nmodel distillation pipeline in which a large generative model, a Teacher,\nteaches a much smaller model, a Student. The Teacher, trained on a small subset\nof the training data, is used to provide scores on the remaining training data,\nwhich is then used to train the Student. We call the resulting dataset \"Cyborg\nData\", as it combines human and machine-scored responses. Our findings show\nthat Student models trained on \"Cyborg Data\" show performance comparable to\ntraining on the entire dataset, while only requiring 10% of the original\nhand-scored data.", "published": "2025-03-26 16:38:20", "link": "http://arxiv.org/abs/2503.22736v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph-Enhanced Model-Free Reinforcement Learning Agents for Efficient Power Grid Topological Control", "abstract": "The increasing complexity of power grid management, driven by the emergence\nof prosumers and the demand for cleaner energy solutions, has needed innovative\napproaches to ensure stability and efficiency. This paper presents a novel\napproach within the model-free framework of reinforcement learning, aimed at\noptimizing power network operations without prior expert knowledge. We\nintroduce a masked topological action space, enabling agents to explore diverse\nstrategies for cost reduction while maintaining reliable service using the\nstate logic as a guide for choosing proper actions. Through extensive\nexperimentation across 20 different scenarios in a simulated 5-substation\nenvironment, we demonstrate that our approach achieves a consistent reduction\nin power losses, while ensuring grid stability against potential blackouts. The\nresults underscore the effectiveness of combining dynamic observation\nformalization with opponent-based training, showing a viable way for autonomous\nmanagement solutions in modern energy systems or even for building a\nfoundational model for this field.", "published": "2025-03-26 16:20:30", "link": "http://arxiv.org/abs/2503.20688v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Flip Learning: Weakly Supervised Erase to Segment Nodules in Breast Ultrasound", "abstract": "Accurate segmentation of nodules in both 2D breast ultrasound (BUS) and 3D\nautomated breast ultrasound (ABUS) is crucial for clinical diagnosis and\ntreatment planning. Therefore, developing an automated system for nodule\nsegmentation can enhance user independence and expedite clinical analysis.\nUnlike fully-supervised learning, weakly-supervised segmentation (WSS) can\nstreamline the laborious and intricate annotation process. However, current WSS\nmethods face challenges in achieving precise nodule segmentation, as many of\nthem depend on inaccurate activation maps or inefficient pseudo-mask generation\nalgorithms. In this study, we introduce a novel multi-agent reinforcement\nlearning-based WSS framework called Flip Learning, which relies solely on 2D/3D\nboxes for accurate segmentation. Specifically, multiple agents are employed to\nerase the target from the box to facilitate classification tag flipping, with\nthe erased region serving as the predicted segmentation mask. The key\ncontributions of this research are as follows: (1) Adoption of a\nsuperpixel/supervoxel-based approach to encode the standardized environment,\ncapturing boundary priors and expediting the learning process. (2) Introduction\nof three meticulously designed rewards, comprising a classification score\nreward and two intensity distribution rewards, to steer the agents' erasing\nprocess precisely, thereby avoiding both under- and over-segmentation. (3)\nImplementation of a progressive curriculum learning strategy to enable agents\nto interact with the environment in a progressively challenging manner, thereby\nenhancing learning efficiency. Extensively validated on the large in-house BUS\nand ABUS datasets, our Flip Learning method outperforms state-of-the-art WSS\nmethods and foundation models, and achieves comparable performance as\nfully-supervised learning algorithms.", "published": "2025-03-26 16:20:02", "link": "http://arxiv.org/abs/2503.20685v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Inductive Link Prediction on N-ary Relational Facts via Semantic Hypergraph Reasoning", "abstract": "N-ary relational facts represent semantic correlations among more than two\nentities. While recent studies have developed link prediction (LP) methods to\ninfer missing relations for knowledge graphs (KGs) containing n-ary relational\nfacts, they are generally limited to transductive settings. Fully inductive\nsettings, where predictions are made on previously unseen entities, remain a\nsignificant challenge. As existing methods are mainly entity embedding-based,\nthey struggle to capture entity-independent logical rules. To fill in this gap,\nwe propose an n-ary subgraph reasoning framework for fully inductive link\nprediction (ILP) on n-ary relational facts. This framework reasons over local\nsubgraphs and has a strong inductive inference ability to capture n-ary\npatterns. Specifically, we introduce a novel graph structure, the n-ary\nsemantic hypergraph, to facilitate subgraph extraction. Moreover, we develop a\nsubgraph aggregating network, NS-HART, to effectively mine complex semantic\ncorrelations within subgraphs. Theoretically, we provide a thorough analysis\nfrom the score function optimization perspective to shed light on NS-HART's\neffectiveness for n-ary ILP tasks. Empirically, we conduct extensive\nexperiments on a series of inductive benchmarks, including transfer reasoning\n(with and without entity features) and pairwise subgraph reasoning. The results\nhighlight the superiority of the n-ary subgraph reasoning framework and the\nexceptional inductive ability of NS-HART. The source code of this paper has\nbeen made publicly available at\nhttps://github.com/yin-gz/Nary-Inductive-SubGraph.", "published": "2025-03-26 16:09:54", "link": "http://arxiv.org/abs/2503.20676v1", "categories": ["cs.AI", "cs.LG", "I.2.4"], "primary_category": "cs.AI"}
{"title": "The Backfiring Effect of Weak AI Safety Regulation", "abstract": "Recent policy proposals aim to improve the safety of general-purpose AI, but\nthere is little understanding of the efficacy of different regulatory\napproaches to AI safety. We present a strategic model that explores the\ninteractions between the regulator, the general-purpose AI technology creators,\nand domain specialists--those who adapt the AI for specific applications. Our\nanalysis examines how different regulatory measures, targeting different parts\nof the development chain, affect the outcome of the development process. In\nparticular, we assume AI technology is described by two key attributes: safety\nand performance. The regulator first sets a minimum safety standard that\napplies to one or both players, with strict penalties for non-compliance. The\ngeneral-purpose creator then develops the technology, establishing its initial\nsafety and performance levels. Next, domain specialists refine the AI for their\nspecific use cases, and the resulting revenue is distributed between the\nspecialist and generalist through an ex-ante bargaining process. Our analysis\nof this game reveals two key insights: First, weak safety regulation imposed\nonly on the domain specialists can backfire. While it might seem logical to\nregulate use cases (as opposed to the general-purpose technology), our analysis\nshows that weak regulations targeting domain specialists alone can\nunintentionally reduce safety. This effect persists across a wide range of\nsettings. Second, in sharp contrast to the previous finding, we observe that\nstronger, well-placed regulation can in fact benefit all players subjected to\nit. When regulators impose appropriate safety standards on both AI creators and\ndomain specialists, the regulation functions as a commitment mechanism, leading\nto safety and performance gains, surpassing what is achieved under no\nregulation or regulating one player only.", "published": "2025-03-26 16:08:22", "link": "http://arxiv.org/abs/2503.20848v1", "categories": ["cs.GT", "cs.AI", "cs.CY", "econ.TH"], "primary_category": "cs.GT"}
{"title": "Probabilistic Forecasting for Network Resource Analysis in Integrated Terrestrial and Non-Terrestrial Networks", "abstract": "Efficient resource management is critical for Non-Terrestrial Networks (NTNs)\nto provide consistent, high-quality service in remote and under-served regions.\nWhile traditional single-point prediction methods, such as Long-Short Term\nMemory (LSTM), have been used in terrestrial networks, they often fall short in\nNTNs due to the complexity of satellite dynamics, signal latency and coverage\nvariability. Probabilistic forecasting, which quantifies the uncertainties of\nthe predictions, is a robust alternative. In this paper, we evaluate the\napplication of probabilistic forecasting techniques, in particular SFF, to NTN\nresource allocation scenarios. Our results show their effectiveness in\npredicting bandwidth and capacity requirements in different NTN segments of\nprobabilistic forecasting compared to single-point prediction techniques such\nas LSTM. The results show the potential of black probabilistic forecasting\nmodels to provide accurate and reliable predictions and to quantify their\nuncertainty, making them indispensable for optimizing NTN resource allocation.\nAt the end of the paper, we also present application scenarios and a\nstandardization roadmap for the use of probabilistic forecasting in integrated\nTerrestrial Network (TN)-NTN environments.", "published": "2025-03-26 15:54:46", "link": "http://arxiv.org/abs/2503.20658v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "eess.SP"}
{"title": "AccidentSim: Generating Physically Realistic Vehicle Collision Videos from Real-World Accident Reports", "abstract": "Collecting real-world vehicle accident videos for autonomous driving research\nis challenging due to their rarity and complexity. While existing driving video\ngeneration methods may produce visually realistic videos, they often fail to\ndeliver physically realistic simulations because they lack the capability to\ngenerate accurate post-collision trajectories. In this paper, we introduce\nAccidentSim, a novel framework that generates physically realistic vehicle\ncollision videos by extracting and utilizing the physical clues and contextual\ninformation available in real-world vehicle accident reports. Specifically,\nAccidentSim leverages a reliable physical simulator to replicate post-collision\nvehicle trajectories from the physical and contextual information in the\naccident reports and to build a vehicle collision trajectory dataset. This\ndataset is then used to fine-tune a language model, enabling it to respond to\nuser prompts and predict physically consistent post-collision trajectories\nacross various driving scenarios based on user descriptions. Finally, we employ\nNeural Radiance Fields (NeRF) to render high-quality backgrounds, merging them\nwith the foreground vehicles that exhibit physically realistic trajectories to\ngenerate vehicle collision videos. Experimental results demonstrate that the\nvideos produced by AccidentSim excel in both visual and physical authenticity.", "published": "2025-03-26 15:50:42", "link": "http://arxiv.org/abs/2503.20654v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Procedural Knowledge Ontology (PKO)", "abstract": "Processes, workflows and guidelines are core to ensure the correct\nfunctioning of industrial companies: for the successful operations of factory\nlines, machinery or services, often industry operators rely on their past\nexperience and know-how. The effect is that this Procedural Knowledge (PK)\nremains tacit and, as such, difficult to exploit efficiently and effectively.\nThis paper presents PKO, the Procedural Knowledge Ontology, which enables the\nexplicit modeling of procedures and their executions, by reusing and extending\nexisting ontologies. PKO is built on requirements collected from three\nheterogeneous industrial use cases and can be exploited by any AI and\ndata-driven tools that rely on a shared and interoperable representation to\nsupport the governance of PK throughout its life cycle. We describe its\nstructure and design methodology, and outline its relevance, quality, and\nimpact by discussing applications leveraging PKO for PK elicitation and\nexploitation.", "published": "2025-03-26 15:28:30", "link": "http://arxiv.org/abs/2503.20634v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "$\u03b2$-GNN: A Robust Ensemble Approach Against Graph Structure Perturbation", "abstract": "Graph Neural Networks (GNNs) are playing an increasingly important role in\nthe efficient operation and security of computing systems, with applications in\nworkload scheduling, anomaly detection, and resource management. However, their\nvulnerability to network perturbations poses a significant challenge. We\npropose $\\beta$-GNN, a model enhancing GNN robustness without sacrificing clean\ndata performance. $\\beta$-GNN uses a weighted ensemble, combining any GNN with\na multi-layer perceptron. A learned dynamic weight, $\\beta$, modulates the\nGNN's contribution. This $\\beta$ not only weights GNN influence but also\nindicates data perturbation levels, enabling proactive mitigation. Experimental\nresults on diverse datasets show $\\beta$-GNN's superior adversarial accuracy\nand attack severity quantification. Crucially, $\\beta$-GNN avoids perturbation\nassumptions, preserving clean data structure and performance.", "published": "2025-03-26 15:24:07", "link": "http://arxiv.org/abs/2503.20630v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Robust Deep Reinforcement Learning in Robotics via Adaptive Gradient-Masked Adversarial Attacks", "abstract": "Deep reinforcement learning (DRL) has emerged as a promising approach for\nrobotic control, but its realworld deployment remains challenging due to its\nvulnerability to environmental perturbations. Existing white-box adversarial\nattack methods, adapted from supervised learning, fail to effectively target\nDRL agents as they overlook temporal dynamics and indiscriminately perturb all\nstate dimensions, limiting their impact on long-term rewards. To address these\nchallenges, we propose the Adaptive Gradient-Masked Reinforcement (AGMR)\nAttack, a white-box attack method that combines DRL with a gradient-based soft\nmasking mechanism to dynamically identify critical state dimensions and\noptimize adversarial policies. AGMR selectively allocates perturbations to the\nmost impactful state features and incorporates a dynamic adjustment mechanism\nto balance exploration and exploitation during training. Extensive experiments\ndemonstrate that AGMR outperforms state-of-the-art adversarial attack methods\nin degrading the performance of the victim agent and enhances the victim\nagent's robustness through adversarial defense mechanisms.", "published": "2025-03-26 15:08:58", "link": "http://arxiv.org/abs/2503.20844v1", "categories": ["cs.LG", "cs.AI", "cs.NI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "State-Aware Perturbation Optimization for Robust Deep Reinforcement Learning", "abstract": "Recently, deep reinforcement learning (DRL) has emerged as a promising\napproach for robotic control. However, the deployment of DRL in real-world\nrobots is hindered by its sensitivity to environmental perturbations. While\nexisting whitebox adversarial attacks rely on local gradient information and\napply uniform perturbations across all states to evaluate DRL robustness, they\nfail to account for temporal dynamics and state-specific vulnerabilities. To\ncombat the above challenge, we first conduct a theoretical analysis of\nwhite-box attacks in DRL by establishing the adversarial victim-dynamics Markov\ndecision process (AVD-MDP), to derive the necessary and sufficient conditions\nfor a successful attack. Based on this, we propose a selective state-aware\nreinforcement adversarial attack method, named STAR, to optimize perturbation\nstealthiness and state visitation dispersion. STAR first employs a soft\nmask-based state-targeting mechanism to minimize redundant perturbations,\nenhancing stealthiness and attack effectiveness. Then, it incorporates an\ninformation-theoretic optimization objective to maximize mutual information\nbetween perturbations, environmental states, and victim actions, ensuring a\ndispersed state-visitation distribution that steers the victim agent into\nvulnerable states for maximum return reduction. Extensive experiments\ndemonstrate that STAR outperforms state-of-the-art benchmarks.", "published": "2025-03-26 15:00:07", "link": "http://arxiv.org/abs/2503.20613v1", "categories": ["cs.LG", "cs.AI", "cs.NI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "A decision-theoretic approach to dealing with uncertainty in quantum mechanics", "abstract": "We provide a decision-theoretic framework for dealing with uncertainty in\nquantum mechanics. This uncertainty is two-fold: on the one hand there may be\nuncertainty about the state the quantum system is in, and on the other hand, as\nis essential to quantum mechanical uncertainty, even if the quantum state is\nknown, measurements may still produce an uncertain outcome. In our framework,\nmeasurements therefore play the role of acts with an uncertain outcome and our\nsimple decision-theoretic postulates ensure that Born's rule is encapsulated in\nthe utility functions associated with such acts. This approach allows us to\nuncouple (precise) probability theory from quantum mechanics, in the sense that\nit leaves room for a more general, so-called imprecise probabilities approach.\nWe discuss the mathematical implications of our findings, which allow us to\ngive a decision-theoretic foundation to recent seminal work by Benavoli,\nFacchini and Zaffalon, and we compare our approach to earlier and different\napproaches by Deutsch and Wallace.", "published": "2025-03-26 14:53:06", "link": "http://arxiv.org/abs/2503.20607v1", "categories": ["quant-ph", "cs.AI", "math.PR"], "primary_category": "quant-ph"}
{"title": "Anti Robot Speciesism", "abstract": "Humanoid robots are a form of embodied artificial intelligence (AI) that\nlooks and acts more and more like humans. Powered by generative AI and advances\nin robotics, humanoid robots can speak and interact with humans rather\nnaturally but are still easily recognizable as robots. But how will we treat\nhumanoids when they seem indistinguishable from humans in appearance and mind?\nWe find a tendency (called \"anti-robot\" speciesism) to deny such robots\nhumanlike capabilities, driven by motivations to accord members of the human\nspecies preferential treatment. Six experiments show that robots are denied\nhumanlike attributes, simply because they are not biological beings and because\nhumans want to avoid feelings of cognitive dissonance when utilizing such\nrobots for unsavory tasks. Thus, people do not rationally attribute\ncapabilities to perfectly humanlike robots but deny them capabilities as it\nsuits them.", "published": "2025-03-26 13:56:30", "link": "http://arxiv.org/abs/2503.20842v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving", "abstract": "Generative models offer a scalable and flexible paradigm for simulating\ncomplex environments, yet current approaches fall short in addressing the\ndomain-specific requirements of autonomous driving - such as multi-agent\ninteractions, fine-grained control, and multi-camera consistency. We introduce\nGAIA-2, Generative AI for Autonomy, a latent diffusion world model that unifies\nthese capabilities within a single generative framework. GAIA-2 supports\ncontrollable video generation conditioned on a rich set of structured inputs:\nego-vehicle dynamics, agent configurations, environmental factors, and road\nsemantics. It generates high-resolution, spatiotemporally consistent\nmulti-camera videos across geographically diverse driving environments (UK, US,\nGermany). The model integrates both structured conditioning and external latent\nembeddings (e.g., from a proprietary driving model) to facilitate flexible and\nsemantically grounded scene synthesis. Through this integration, GAIA-2 enables\nscalable simulation of both common and rare driving scenarios, advancing the\nuse of generative world models as a core tool in the development of autonomous\nsystems. Videos are available at https://wayve.ai/thinking/gaia-2.", "published": "2025-03-26 13:11:35", "link": "http://arxiv.org/abs/2503.20523v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Design and Evaluation of Neural Network-Based Receiver Architectures for Reliable Communication", "abstract": "Neural network-based receivers leverage deep learning to optimize signal\ndetection and decoding, significantly improving bit-error rate (BER) and\nblock-error rate (BLER) in challenging environments. This study evaluates\nvarious architectures and compares their BER and BLER performance across\ndifferent noise levels. Two novel models, the Dual Attention Transformer (DAT)\nand the Residual Dual Non-Local Attention Network (RDNLA), integrate\nself-attention and residual learning to enhance signal reconstruction. These\nmodels bypass conventional channel estimation and equalization by directly\npredicting log-likelihood ratios (LLRs) from received signals, with noise\nvariance as an additional input. Simulations show that DAT and RDNLA outperform\ntraditional and other neural receiver models under varying signal-to-noise\nratios (SNR), while their computational efficiency supports their feasibility\nfor next-generation communication systems.", "published": "2025-03-26 12:39:56", "link": "http://arxiv.org/abs/2503.20500v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Towards Efficient and General-Purpose Few-Shot Misclassification Detection for Vision-Language Models", "abstract": "Reliable prediction by classifiers is crucial for their deployment in high\nsecurity and dynamically changing situations. However, modern neural networks\noften exhibit overconfidence for misclassified predictions, highlighting the\nneed for confidence estimation to detect errors. Despite the achievements\nobtained by existing methods on small-scale datasets, they all require training\nfrom scratch and there are no efficient and effective misclassification\ndetection (MisD) methods, hindering practical application towards large-scale\nand ever-changing datasets. In this paper, we pave the way to exploit vision\nlanguage model (VLM) leveraging text information to establish an efficient and\ngeneral-purpose misclassification detection framework. By harnessing the power\nof VLM, we construct FSMisD, a Few-Shot prompt learning framework for MisD to\nrefrain from training from scratch and therefore improve tuning efficiency. To\nenhance misclassification detection ability, we use adaptive pseudo sample\ngeneration and a novel negative loss to mitigate the issue of overconfidence by\npushing category prompts away from pseudo features. We conduct comprehensive\nexperiments with prompt learning methods and validate the generalization\nability across various datasets with domain shift. Significant and consistent\nimprovement demonstrates the effectiveness, efficiency and generalizability of\nour approach.", "published": "2025-03-26 12:31:04", "link": "http://arxiv.org/abs/2503.20492v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Underwater Image Enhancement by Convolutional Spiking Neural Networks", "abstract": "Underwater image enhancement (UIE) is fundamental for marine applications,\nincluding autonomous vision-based navigation. Deep learning methods using\nconvolutional neural networks (CNN) and vision transformers advanced UIE\nperformance. Recently, spiking neural networks (SNN) have gained attention for\ntheir lightweight design, energy efficiency, and scalability. This paper\nintroduces UIE-SNN, the first SNN-based UIE algorithm to improve visibility of\nunderwater images. UIE-SNN is a 19- layered convolutional spiking\nencoder-decoder framework with skip connections, directly trained using\nsurrogate gradient-based backpropagation through time (BPTT) strategy. We\nexplore and validate the influence of training datasets on energy reduction, a\nunique advantage of UIE-SNN architecture, in contrast to the conventional\nlearning-based architectures, where energy consumption is model-dependent.\nUIE-SNN optimizes the loss function in latent space representation to\nreconstruct clear underwater images. Our algorithm performs on par with its\nnon-spiking counterpart methods in terms of PSNR and structural similarity\nindex (SSIM) at reduced timesteps ($T=5$) and energy consumption of $85\\%$. The\nalgorithm is trained on two publicly available benchmark datasets, UIEB and\nEUVP, and tested on unseen images from UIEB, EUVP, LSUI, U45, and our custom\nUIE dataset. The UIE-SNN algorithm achieves PSNR of \\(17.7801~dB\\) and SSIM of\n\\(0.7454\\) on UIEB, and PSNR of \\(23.1725~dB\\) and SSIM of \\(0.7890\\) on EUVP.\nUIE-SNN achieves this algorithmic performance with fewer operators (\\(147.49\\)\nGSOPs) and energy (\\(0.1327~J\\)) compared to its non-spiking counterpart\n(GFLOPs = \\(218.88\\) and Energy=\\(1.0068~J\\)). Compared with existing SOTA UIE\nmethods, UIE-SNN achieves an average of \\(6.5\\times\\) improvement in energy\nefficiency. The source code is available at\n\\href{https://github.com/vidya-rejul/UIE-SNN.git}{UIE-SNN}.", "published": "2025-03-26 12:15:38", "link": "http://arxiv.org/abs/2503.20485v1", "categories": ["eess.IV", "cs.AI", "cs.PF"], "primary_category": "eess.IV"}
{"title": "Contrastive Learning Guided Latent Diffusion Model for Image-to-Image Translation", "abstract": "The diffusion model has demonstrated superior performance in synthesizing\ndiverse and high-quality images for text-guided image translation. However,\nthere remains room for improvement in both the formulation of text prompts and\nthe preservation of reference image content. First, variations in target text\nprompts can significantly influence the quality of the generated images, and it\nis often challenging for users to craft an optimal prompt that fully captures\nthe content of the input image. Second, while existing models can introduce\ndesired modifications to specific regions of the reference image, they\nfrequently induce unintended alterations in areas that should remain unchanged.\nTo address these challenges, we propose pix2pix-zeroCon, a zero-shot\ndiffusion-based method that eliminates the need for additional training by\nleveraging patch-wise contrastive loss. Specifically, we automatically\ndetermine the editing direction in the text embedding space based on the\nreference image and target prompts. Furthermore, to ensure precise content and\nstructural preservation in the edited image, we introduce cross-attention\nguiding loss and patch-wise contrastive loss between the generated and original\nimage embeddings within a pre-trained diffusion model. Notably, our approach\nrequires no additional training and operates directly on a pre-trained\ntext-to-image diffusion model. Extensive experiments demonstrate that our\nmethod surpasses existing models in image-to-image translation, achieving\nenhanced fidelity and controllability.", "published": "2025-03-26 12:15:25", "link": "http://arxiv.org/abs/2503.20484v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A multi-agentic framework for real-time, autonomous freeform metasurface design", "abstract": "Innovation in nanophotonics currently relies on human experts who synergize\nspecialized knowledge in photonics and coding with simulation and optimization\nalgorithms, entailing design cycles that are time-consuming, computationally\ndemanding, and frequently suboptimal. We introduce MetaChat, a multi-agentic\ndesign framework that can translate semantically described photonic design\ngoals into high-performance, freeform device layouts in an automated, nearly\nreal-time manner. Multi-step reasoning is enabled by our Agentic Iterative\nMonologue (AIM) paradigm, which coherently interfaces agents with code-based\ntools, other specialized agents, and human designers. Design acceleration is\nfacilitated by Feature-wise Linear Modulation-conditioned Maxwell surrogate\nsolvers that support the generalized evaluation of metasurface structures. We\nuse freeform dielectric metasurfaces as a model system and demonstrate with\nMetaChat the design of multi-objective, multi-wavelength metasurfaces orders of\nmagnitude faster than conventional methods. These concepts present a scientific\ncomputing blueprint for utilizing specialist design agents, surrogate solvers,\nand human interactions to drive multi-physics innovation and discovery.", "published": "2025-03-26 12:10:45", "link": "http://arxiv.org/abs/2503.20479v1", "categories": ["physics.app-ph", "cs.AI", "cs.MA", "physics.comp-ph"], "primary_category": "physics.app-ph"}
{"title": "From Trial to Triumph: Advancing Long Video Understanding via Visual Context Sample Scaling and Self-reward Alignment", "abstract": "Multi-modal Large language models (MLLMs) show remarkable ability in video\nunderstanding. Nevertheless, understanding long videos remains challenging as\nthe models can only process a finite number of frames in a single inference,\npotentially omitting crucial visual information. To address the challenge, we\npropose generating multiple predictions through visual context sampling,\nfollowed by a scoring mechanism to select the final prediction. Specifically,\nwe devise a bin-wise sampling strategy that enables MLLMs to generate diverse\nanswers based on various combinations of keyframes, thereby enriching the\nvisual context. To determine the final prediction from the sampled answers, we\nemploy a self-reward by linearly combining three scores: (1) a frequency score\nindicating the prevalence of each option, (2) a marginal confidence score\nreflecting the inter-intra sample certainty of MLLM predictions, and (3) a\nreasoning score for different question types, including clue-guided answering\nfor global questions and temporal self-refocusing for local questions. The\nfrequency score ensures robustness through majority correctness, the\nconfidence-aligned score reflects prediction certainty, and the typed-reasoning\nscore addresses cases with sparse key visual information using tailored\nstrategies. Experiments show that this approach covers the correct answer for a\nhigh percentage of long video questions, on seven datasets show that our method\nimproves the performance of three MLLMs.", "published": "2025-03-26 11:53:03", "link": "http://arxiv.org/abs/2503.20472v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Attention Xception UNet (AXUNet): A Novel Combination of CNN and Self-Attention for Brain Tumor Segmentation", "abstract": "Accurate segmentation of glioma brain tumors is crucial for diagnosis and\ntreatment planning. Deep learning techniques offer promising solutions, but\noptimal model architectures remain under investigation. We used the BraTS 2021\ndataset, selecting T1 with contrast enhancement (T1CE), T2, and\nFluid-Attenuated Inversion Recovery (FLAIR) sequences for model development.\nThe proposed Attention Xception UNet (AXUNet) architecture integrates an\nXception backbone with dot-product self-attention modules, inspired by\nstate-of-the-art (SOTA) large language models such as Google Bard and OpenAI\nChatGPT, within a UNet-shaped model. We compared AXUNet with SOTA models.\nComparative evaluation on the test set demonstrated improved results over\nbaseline models. Inception-UNet and Xception-UNet achieved mean Dice scores of\n90.88 and 93.24, respectively. Attention ResUNet (AResUNet) attained a mean\nDice score of 92.80, with the highest score of 84.92 for enhancing tumor (ET)\namong all models. Attention Gate UNet (AGUNet) yielded a mean Dice score of\n90.38. AXUNet outperformed all models with a mean Dice score of 93.73. It\ndemonstrated superior Dice scores across whole tumor (WT) and tumor core (TC)\nregions, achieving 92.59 for WT, 86.81 for TC, and 84.89 for ET. The\nintegration of the Xception backbone and dot-product self-attention mechanisms\nin AXUNet showcases enhanced performance in capturing spatial and contextual\ninformation. The findings underscore the potential utility of AXUNet in\nfacilitating precise tumor delineation.", "published": "2025-03-26 11:22:17", "link": "http://arxiv.org/abs/2503.20446v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Evaluating Facial Expression Recognition Datasets for Deep Learning: A Benchmark Study with Novel Similarity Metrics", "abstract": "This study investigates the key characteristics and suitability of widely\nused Facial Expression Recognition (FER) datasets for training deep learning\nmodels. In the field of affective computing, FER is essential for interpreting\nhuman emotions, yet the performance of FER systems is highly contingent on the\nquality and diversity of the underlying datasets. To address this issue, we\ncompiled and analyzed 24 FER datasets, including those targeting specific age\ngroups such as children, adults, and the elderly, and processed them through a\ncomprehensive normalization pipeline. In addition, we enriched the datasets\nwith automatic annotations for age and gender, enabling a more nuanced\nevaluation of their demographic properties. To further assess dataset efficacy,\nwe introduce three novel metricsLocal, Global, and Paired Similarity, which\nquantitatively measure dataset difficulty, generalization capability, and\ncross-dataset transferability. Benchmark experiments using state-of-the-art\nneural networks reveal that large-scale, automatically collected datasets\n(e.g., AffectNet, FER2013) tend to generalize better, despite issues with\nlabeling noise and demographic biases, whereas controlled datasets offer higher\nannotation quality but limited variability. Our findings provide actionable\nrecommendations for dataset selection and design, advancing the development of\nmore robust, fair, and effective FER systems.", "published": "2025-03-26 11:01:00", "link": "http://arxiv.org/abs/2503.20428v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation", "abstract": "Navigating in environments alongside humans requires agents to reason under\nuncertainty and account for the beliefs and intentions of those around them.\nUnder a sequential decision-making framework, egocentric navigation can\nnaturally be represented as a Markov Decision Process (MDP). However, social\nnavigation additionally requires reasoning about the hidden beliefs of others,\ninherently leading to a Partially Observable Markov Decision Process (POMDP),\nwhere agents lack direct access to others' mental states. Inspired by Theory of\nMind and Epistemic Planning, we propose (1) a neuro-symbolic model-based\nreinforcement learning architecture for social navigation, addressing the\nchallenge of belief tracking in partially observable environments; and (2) a\nperspective-shift operator for belief estimation, leveraging recent work on\nInfluence-based Abstractions (IBA) in structured multi-agent settings.", "published": "2025-03-26 10:59:08", "link": "http://arxiv.org/abs/2503.20425v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Including local feature interactions in deep non-negative matrix factorization networks improves performance", "abstract": "The brain uses positive signals as a means of signaling. Forward interactions\nin the early visual cortex are also positive, realized by excitatory synapses.\nOnly local interactions also include inhibition. Non-negative matrix\nfactorization (NMF) captures the biological constraint of positive long-range\ninteractions and can be implemented with stochastic spikes. While NMF can serve\nas an abstract formalization of early neural processing in the visual system,\nthe performance of deep convolutional networks with NMF modules does not match\nthat of CNNs of similar size. However, when the local NMF modules are each\nfollowed by a module that mixes the NMF's positive activities, the performances\non the benchmark data exceed that of vanilla deep convolutional networks of\nsimilar size. This setting can be considered a biologically more plausible\nemulation of the processing in cortical (hyper-)columns with the potential to\nimprove the performance of deep networks.", "published": "2025-03-26 10:21:38", "link": "http://arxiv.org/abs/2503.20398v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FastFT: Accelerating Reinforced Feature Transformation via Advanced Exploration Strategies", "abstract": "Feature Transformation is crucial for classic machine learning that aims to\ngenerate feature combinations to enhance the performance of downstream tasks\nfrom a data-centric perspective. Current methodologies, such as manual\nexpert-driven processes, iterative-feedback techniques, and\nexploration-generative tactics, have shown promise in automating such data\nengineering workflow by minimizing human involvement. However, three challenges\nremain in those frameworks: (1) It predominantly depends on downstream task\nperformance metrics, as assessment is time-consuming, especially for large\ndatasets. (2) The diversity of feature combinations will hardly be guaranteed\nafter random exploration ends. (3) Rare significant transformations lead to\nsparse valuable feedback that hinders the learning processes or leads to less\neffective results. In response to these challenges, we introduce FastFT, an\ninnovative framework that leverages a trio of advanced strategies.We first\ndecouple the feature transformation evaluation from the outcomes of the\ngenerated datasets via the performance predictor. To address the issue of\nreward sparsity, we developed a method to evaluate the novelty of generated\ntransformation sequences. Incorporating this novelty into the reward function\naccelerates the model's exploration of effective transformations, thereby\nimproving the search productivity. Additionally, we combine novelty and\nperformance to create a prioritized memory buffer, ensuring that essential\nexperiences are effectively revisited during exploration. Our extensive\nexperimental evaluations validate the performance, efficiency, and traceability\nof our proposed framework, showcasing its superiority in handling complex\nfeature transformation tasks.", "published": "2025-03-26 10:17:41", "link": "http://arxiv.org/abs/2503.20394v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation", "abstract": "Multimodal Large Language Models (MLLMs) excel in understanding complex\nlanguage and visual data, enabling generalist robotic systems to interpret\ninstructions and perform embodied tasks. Nevertheless, their real-world\ndeployment is hindered by substantial computational and storage demands. Recent\ninsights into the homogeneous patterns in the LLM layer have inspired\nsparsification techniques to address these challenges, such as early exit and\ntoken pruning. However, these methods often neglect the critical role of the\nfinal layers that encode the semantic information most relevant to downstream\nrobotic tasks. Aligning with the recent breakthrough of the Shallow Brain\nHypothesis (SBH) in neuroscience and the mixture of experts in model\nsparsification, we conceptualize each LLM layer as an expert and propose a\nMixture-of-Layers Vision-Language-Action model (MoLe-VLA, or simply MoLe)\narchitecture for dynamic LLM layer activation. We introduce a Spatial-Temporal\nAware Router (STAR) for MoLe to selectively activate only parts of the layers\nbased on the robot's current state, mimicking the brain's distinct signal\npathways specialized for cognition and causal reasoning. Additionally, to\ncompensate for the cognitive ability of LLMs lost in MoLe, we devise a\nCognition Self-Knowledge Distillation (CogKD) framework. CogKD enhances the\nunderstanding of task demands and improves the generation of task-relevant\naction sequences by leveraging cognitive features. Extensive experiments\nconducted in both RLBench simulation and real-world environments demonstrate\nthe superiority of MoLe-VLA in both efficiency and performance. Specifically,\nMoLe-VLA achieves an 8% improvement in the mean success rate across ten tasks\nwhile reducing computational costs by up to x5.6 compared to standard LLMs.", "published": "2025-03-26 10:05:38", "link": "http://arxiv.org/abs/2503.20384v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Wasserstein Distributionally Robust Bayesian Optimization with Continuous Context", "abstract": "We address the challenge of sequential data-driven decision-making under\ncontext distributional uncertainty. This problem arises in numerous real-world\nscenarios where the learner optimizes black-box objective functions in the\npresence of uncontrollable contextual variables. We consider the setting where\nthe context distribution is uncertain but known to lie within an ambiguity set\ndefined as a ball in the Wasserstein distance. We propose a novel algorithm for\nWasserstein Distributionally Robust Bayesian Optimization that can handle\ncontinuous context distributions while maintaining computational tractability.\nOur theoretical analysis combines recent results in self-normalized\nconcentration in Hilbert spaces and finite-sample bounds for distributionally\nrobust optimization to establish sublinear regret bounds that match\nstate-of-the-art results. Through extensive comparisons with existing\napproaches on both synthetic and real-world problems, we demonstrate the\nsimplicity, effectiveness, and practical applicability of our proposed method.", "published": "2025-03-26 09:11:17", "link": "http://arxiv.org/abs/2503.20341v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Ancestral Mamba: Enhancing Selective Discriminant Space Model with Online Visual Prototype Learning for Efficient and Robust Discriminant Approach", "abstract": "In the realm of computer graphics, the ability to learn continuously from\nnon-stationary data streams while adapting to new visual patterns and\nmitigating catastrophic forgetting is of paramount importance. Existing\napproaches often struggle to capture and represent the essential\ncharacteristics of evolving visual concepts, hindering their applicability to\ndynamic graphics tasks. In this paper, we propose Ancestral Mamba, a novel\napproach that integrates online prototype learning into a selective\ndiscriminant space model for efficient and robust online continual learning.\nThe key components of our approach include Ancestral Prototype Adaptation\n(APA), which continuously refines and builds upon learned visual prototypes,\nand Mamba Feedback (MF), which provides targeted feedback to adapt to\nchallenging visual patterns. APA enables the model to continuously adapt its\nprototypes, building upon ancestral knowledge to tackle new challenges, while\nMF acts as a targeted feedback mechanism, focusing on challenging classes and\nrefining their representations. Extensive experiments on graphics-oriented\ndatasets, such as CIFAR-10 and CIFAR-100, demonstrate the superior performance\nof Ancestral Mamba compared to state-of-the-art baselines, achieving\nsignificant improvements in accuracy and forgetting mitigation.", "published": "2025-03-26 08:36:05", "link": "http://arxiv.org/abs/2503.22729v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Context-Aware Weakly Supervised Image Manipulation Localization with SAM Refinement", "abstract": "Malicious image manipulation poses societal risks, increasing the importance\nof effective image manipulation detection methods. Recent approaches in image\nmanipulation detection have largely been driven by fully supervised approaches,\nwhich require labor-intensive pixel-level annotations. Thus, it is essential to\nexplore weakly supervised image manipulation localization methods that only\nrequire image-level binary labels for training. However, existing weakly\nsupervised image manipulation methods overlook the importance of edge\ninformation for accurate localization, leading to suboptimal localization\nperformance. To address this, we propose a Context-Aware Boundary Localization\n(CABL) module to aggregate boundary features and learn context-inconsistency\nfor localizing manipulated areas. Furthermore, by leveraging Class Activation\nMapping (CAM) and Segment Anything Model (SAM), we introduce the CAM-Guided SAM\nRefinement (CGSR) module to generate more accurate manipulation localization\nmaps. By integrating two modules, we present a novel weakly supervised\nframework based on a dual-branch Transformer-CNN architecture. Our method\nachieves outstanding localization performance across multiple datasets.", "published": "2025-03-26 07:35:09", "link": "http://arxiv.org/abs/2503.20294v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CryoSAMU: Enhancing 3D Cryo-EM Density Maps of Protein Structures at Intermediate Resolution with Structure-Aware Multimodal U-Nets", "abstract": "Enhancing cryogenic electron microscopy (cryo-EM) 3D density maps at\nintermediate resolution (4-8 {\\AA}) is crucial in protein structure\ndetermination. Recent advances in deep learning have led to the development of\nautomated approaches for enhancing experimental cryo-EM density maps. Yet,\nthese methods are not optimized for intermediate-resolution maps and rely on\nmap density features alone. To address this, we propose CryoSAMU, a novel\nmethod designed to enhance 3D cryo-EM density maps of protein structures using\nstructure-aware multimodal U-Nets and trained on curated\nintermediate-resolution density maps. We comprehensively evaluate CryoSAMU\nacross various metrics and demonstrate its competitive performance compared to\nstate-of-the-art methods. Notably, CryoSAMU achieves significantly faster\nprocessing speed, showing promise for future practical applications. Our code\nis available at https://github.com/chenwei-zhang/CryoSAMU.", "published": "2025-03-26 07:33:36", "link": "http://arxiv.org/abs/2503.20291v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "q-bio.BM"], "primary_category": "cs.CV"}
{"title": "Model-Based Offline Reinforcement Learning with Adversarial Data Augmentation", "abstract": "Model-based offline Reinforcement Learning (RL) constructs environment models\nfrom offline datasets to perform conservative policy optimization. Existing\napproaches focus on learning state transitions through ensemble models,\nrollouting conservative estimation to mitigate extrapolation errors. However,\nthe static data makes it challenging to develop a robust policy, and offline\nagents cannot access the environment to gather new data. To address these\nchallenges, we introduce Model-based Offline Reinforcement learning with\nAdversariaL data augmentation (MORAL). In MORAL, we replace the fixed horizon\nrollout by employing adversaria data augmentation to execute alternating\nsampling with ensemble models to enrich training data. Specifically, this\nadversarial process dynamically selects ensemble models against policy for\nbiased sampling, mitigating the optimistic estimation of fixed models, thus\nrobustly expanding the training data for policy optimization. Moreover, a\ndifferential factor is integrated into the adversarial process for\nregularization, ensuring error minimization in extrapolations. This\ndata-augmented optimization adapts to diverse offline tasks without rollout\nhorizon tuning, showing remarkable applicability. Extensive experiments on D4RL\nbenchmark demonstrate that MORAL outperforms other model-based offline RL\nmethods in terms of policy learning and sample efficiency.", "published": "2025-03-26 07:24:34", "link": "http://arxiv.org/abs/2503.20285v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Faster Parameter-Efficient Tuning with Token Redundancy Reduction", "abstract": "Parameter-efficient tuning (PET) aims to transfer pre-trained foundation\nmodels to downstream tasks by learning a small number of parameters. Compared\nto traditional fine-tuning, which updates the entire model, PET significantly\nreduces storage and transfer costs for each task regardless of exponentially\nincreasing pre-trained model capacity. However, most PET methods inherit the\ninference latency of their large backbone models and often introduce additional\ncomputational overhead due to additional modules (e.g. adapters), limiting\ntheir practicality for compute-intensive applications. In this paper, we\npropose Faster Parameter-Efficient Tuning (FPET), a novel approach that\nenhances inference speed and training efficiency while maintaining high storage\nefficiency. Specifically, we introduce a plug-and-play token redundancy\nreduction module delicately designed for PET. This module refines tokens from\nthe self-attention layer using an adapter to learn the accurate similarity\nbetween tokens and cuts off the tokens through a fully-differentiable token\nmerging strategy, which uses a straight-through estimator for optimal token\nreduction. Experimental results prove that our FPET achieves faster inference\nand higher memory efficiency than the pre-trained backbone while keeping\ncompetitive performance on par with state-of-the-art PET methods.", "published": "2025-03-26 07:15:08", "link": "http://arxiv.org/abs/2503.20282v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Are We There Yet? Unraveling the State-of-the-Art Graph Network Intrusion Detection Systems", "abstract": "Network Intrusion Detection Systems (NIDS) are vital for ensuring enterprise\nsecurity. Recently, Graph-based NIDS (GIDS) have attracted considerable\nattention because of their capability to effectively capture the complex\nrelationships within the graph structures of data communications. Despite their\npromise, the reproducibility and replicability of these GIDS remain largely\nunexplored, posing challenges for developing reliable and robust detection\nsystems. This study bridges this gap by designing a systematic approach to\nevaluate state-of-the-art GIDS, which includes critically assessing, extending,\nand clarifying the findings of these systems. We further assess the robustness\nof GIDS under adversarial attacks. Evaluations were conducted on three public\ndatasets as well as a newly collected large-scale enterprise dataset. Our\nfindings reveal significant performance discrepancies, highlighting challenges\nrelated to dataset scale, model inputs, and implementation settings. We\ndemonstrate difficulties in reproducing and replicating results, particularly\nconcerning false positive rates and robustness against adversarial attacks.\nThis work provides valuable insights and recommendations for future research,\nemphasizing the importance of rigorous reproduction and replication studies in\ndeveloping robust and generalizable GIDS solutions.", "published": "2025-03-26 07:11:57", "link": "http://arxiv.org/abs/2503.20281v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Advancing Vulnerability Classification with BERT: A Multi-Objective Learning Model", "abstract": "The rapid increase in cybersecurity vulnerabilities necessitates automated\ntools for analyzing and classifying vulnerability reports. This paper presents\na novel Vulnerability Report Classifier that leverages the BERT (Bidirectional\nEncoder Representations from Transformers) model to perform multi-label\nclassification of Common Vulnerabilities and Exposures (CVE) reports from the\nNational Vulnerability Database (NVD). The classifier predicts both the\nseverity (Low, Medium, High, Critical) and vulnerability types (e.g., Buffer\nOverflow, XSS) from textual descriptions. We introduce a custom training\npipeline using a combined loss function-Cross-Entropy for severity and Binary\nCross-Entropy with Logits for types-integrated into a Hugging Face Trainer\nsubclass. Experiments on recent NVD data demonstrate promising results, with\ndecreasing evaluation loss across epochs. The system is deployed via a REST API\nand a Streamlit UI, enabling real-time vulnerability analysis. This work\ncontributes a scalable, open-source solution for cybersecurity practitioners to\nautomate vulnerability triage.", "published": "2025-03-26 06:04:45", "link": "http://arxiv.org/abs/2503.20831v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Mamba-3D as Masked Autoencoders for Accurate and Data-Efficient Analysis of Medical Ultrasound Videos", "abstract": "Ultrasound videos are an important form of clinical imaging data, and deep\nlearning-based automated analysis can improve diagnostic accuracy and clinical\nefficiency. However, the scarcity of labeled data and the inherent challenges\nof video analysis have impeded the advancement of related methods. In this\nwork, we introduce E-ViM$^3$, a data-efficient Vision Mamba network that\npreserves the 3D structure of video data, enhancing long-range dependencies and\ninductive biases to better model space-time correlations. With our design of\nEnclosure Global Tokens (EGT), the model captures and aggregates global\nfeatures more effectively than competing methods. To further improve data\nefficiency, we employ masked video modeling for self-supervised pre-training,\nwith the proposed Spatial-Temporal Chained (STC) masking strategy designed to\nadapt to various video scenarios. Experiments demonstrate that E-ViM$^3$\nperforms as the state-of-the-art in two high-level semantic analysis tasks\nacross four datasets of varying sizes: EchoNet-Dynamic, CAMUS, MICCAI-BUV, and\nWHBUS. Furthermore, our model achieves competitive performance with limited\nlabels, highlighting its potential impact on real-world clinical applications.", "published": "2025-03-26 05:54:13", "link": "http://arxiv.org/abs/2503.20258v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LogicQA: Logical Anomaly Detection with Vision Language Model Generated Questions", "abstract": "Anomaly Detection (AD) focuses on detecting samples that differ from the\nstandard pattern, making it a vital tool in process control. Logical anomalies\nmay appear visually normal yet violate predefined constraints on object\npresence, arrangement, or quantity, depending on reasoning and explainability.\nWe introduce LogicQA, a framework that enhances AD by providing industrial\noperators with explanations for logical anomalies. LogicQA compiles\nautomatically generated questions into a checklist and collects responses to\nidentify violations of logical constraints. LogicQA is training-free,\nannotation-free, and operates in a few-shot setting. We achieve\nstate-of-the-art (SOTA) Logical AD performance on public benchmarks, MVTec LOCO\nAD, with an AUROC of 87.6 percent and an F1-max of 87.0 percent along with the\nexplanations of anomalies. Also, our approach has shown outstanding performance\non semiconductor SEM corporate data, further validating its effectiveness in\nindustrial applications.", "published": "2025-03-26 05:38:45", "link": "http://arxiv.org/abs/2503.20252v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ESSR: An 8K@30FPS Super-Resolution Accelerator With Edge Selective Network", "abstract": "Deep learning-based super-resolution (SR) is challenging to implement in\nresource-constrained edge devices for resolutions beyond full HD due to its\nhigh computational complexity and memory bandwidth requirements. This paper\nintroduces an 8K@30FPS SR accelerator with edge-selective dynamic input\nprocessing. Dynamic processing chooses the appropriate subnets for different\npatches based on simple input edge criteria, achieving a 50\\% MAC reduction\nwith only a 0.1dB PSNR decrease. The quality of reconstruction images is\nguaranteed and maximized its potential with \\textit{resource adaptive model\nswitching} even under resource constraints. In conjunction with\nhardware-specific refinements, the model size is reduced by 84\\% to 51K, but\nwith a decrease of less than 0.6dB PSNR. Additionally, to support dynamic\nprocessing with high utilization, this design incorporates a\n\\textit{configurable group of layer mapping} that synergizes with the\n\\textit{structure-friendly fusion block}, resulting in 77\\% hardware\nutilization and up to 79\\% reduction in feature SRAM access. The\nimplementation, using the TSMC 28nm process, can achieve 8K@30FPS throughput at\n800MHz with a gate count of 2749K, 0.2075W power consumption, and 4797Mpixels/J\nenergy efficiency, exceeding previous work.", "published": "2025-03-26 05:27:23", "link": "http://arxiv.org/abs/2503.20245v1", "categories": ["cs.AR", "cs.AI", "cs.MM", "eess.IV"], "primary_category": "cs.AR"}
{"title": "LGR: LLM-Guided Ranking of Frontiers for Object Goal Navigation", "abstract": "Object Goal Navigation (OGN) is a fundamental task for robots and AI, with\nkey applications such as mobile robot image databases (MRID). In particular,\nmapless OGN is essential in scenarios involving unknown or dynamic\nenvironments. This study aims to enhance recent modular mapless OGN systems by\nleveraging the commonsense reasoning capabilities of large language models\n(LLMs). Specifically, we address the challenge of determining the visiting\norder in frontier-based exploration by framing it as a frontier ranking\nproblem. Our approach is grounded in recent findings that, while LLMs cannot\ndetermine the absolute value of a frontier, they excel at evaluating the\nrelative value between multiple frontiers viewed within a single image using\nthe view image as context. We dynamically manage the frontier list by adding\nand removing elements, using an LLM as a ranking model. The ranking results are\nrepresented as reciprocal rank vectors, which are ideal for multi-view,\nmulti-query information fusion. We validate the effectiveness of our method\nthrough evaluations in Habitat-Sim.", "published": "2025-03-26 05:15:26", "link": "http://arxiv.org/abs/2503.20241v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Dynamic Learning and Productivity for Data Analysts: A Bayesian Hidden Markov Model Perspective", "abstract": "Data analysts are essential in organizations, transforming raw data into\ninsights that drive decision-making and strategy. This study explores how\nanalysts' productivity evolves on a collaborative platform, focusing on two key\nlearning activities: writing queries and viewing peer queries. While\ntraditional research often assumes static models, where performance improves\nsteadily with cumulative learning, such models fail to capture the dynamic\nnature of real-world learning. To address this, we propose a Hidden Markov\nModel (HMM) that tracks how analysts transition between distinct learning\nstates based on their participation in these activities.\n  Using an industry dataset with 2,001 analysts and 79,797 queries, this study\nidentifies three learning states: novice, intermediate, and advanced.\nProductivity increases as analysts advance to higher states, reflecting the\ncumulative benefits of learning. Writing queries benefits analysts across all\nstates, with the largest gains observed for novices. Viewing peer queries\nsupports novices but may hinder analysts in higher states due to cognitive\noverload or inefficiencies. Transitions between states are also uneven, with\nprogression from intermediate to advanced being particularly challenging. This\nstudy advances understanding of into dynamic learning behavior of knowledge\nworker and offers practical implications for designing systems, optimizing\ntraining, enabling personalized learning, and fostering effective knowledge\nsharing.", "published": "2025-03-26 04:57:03", "link": "http://arxiv.org/abs/2503.20233v1", "categories": ["cs.SI", "cs.AI", "cs.CE", "cs.HC"], "primary_category": "cs.SI"}
{"title": "Dynamics of Algorithmic Content Amplification on TikTok", "abstract": "Intelligent algorithms increasingly shape the content we encounter and engage\nwith online. TikTok's For You feed exemplifies extreme algorithm-driven\ncuration, tailoring the stream of video content almost exclusively based on\nusers' explicit and implicit interactions with the platform. Despite growing\nattention, the dynamics of content amplification on TikTok remain largely\nunquantified. How quickly, and to what extent, does TikTok's algorithm amplify\ncontent aligned with users' interests? To address these questions, we conduct a\nsock-puppet audit, deploying bots with different interests to engage with\nTikTok's \"For You\" feed. Our findings reveal that content aligned with the\nbots' interests undergoes strong amplification, with rapid reinforcement\ntypically occurring within the first 200 videos watched. While amplification is\nconsistently observed across all interests, its intensity varies by interest,\nindicating the emergence of topic-specific biases. Time series analyses and\nMarkov models uncover distinct phases of recommendation dynamics, including\npersistent content reinforcement and a gradual decline in content diversity\nover time. Although TikTok's algorithm preserves some content diversity, we\nfind a strong negative correlation between amplification and exploration: as\nthe amplification of interest-aligned content increases, engagement with unseen\nhashtags declines. These findings contribute to discussions on\nsocio-algorithmic feedback loops in the digital age and the trade-offs between\npersonalization and content diversity.", "published": "2025-03-26 04:54:24", "link": "http://arxiv.org/abs/2503.20231v1", "categories": ["physics.soc-ph", "cs.AI", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "TraNCE: Transformative Non-linear Concept Explainer for CNNs", "abstract": "Convolutional neural networks (CNNs) have succeeded remarkably in various\ncomputer vision tasks. However, they are not intrinsically explainable. While\nthe feature-level understanding of CNNs reveals where the models looked,\nconcept-based explainability methods provide insights into what the models saw.\nHowever, their assumption of linear reconstructability of image activations\nfails to capture the intricate relationships within these activations. Their\nFidelity-only approach to evaluating global explanations also presents a new\nconcern. For the first time, we address these limitations with the novel\nTransformative Nonlinear Concept Explainer (TraNCE) for CNNs. Unlike linear\nreconstruction assumptions made by existing methods, TraNCE captures the\nintricate relationships within the activations. This study presents three\noriginal contributions to the CNN explainability literature: (i) An automatic\nconcept discovery mechanism based on variational autoencoders (VAEs). This\ntransformative concept discovery process enhances the identification of\nmeaningful concepts from image activations. (ii) A visualization module that\nleverages the Bessel function to create a smooth transition between\nprototypical image pixels, revealing not only what the CNN saw but also what\nthe CNN avoided, thereby mitigating the challenges of concept duplication as\ndocumented in previous works. (iii) A new metric, the Faith score, integrates\nboth Coherence and Fidelity for a comprehensive evaluation of explainer\nfaithfulness and consistency.", "published": "2025-03-26 04:49:46", "link": "http://arxiv.org/abs/2503.20230v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning Adaptive Dexterous Grasping from Single Demonstrations", "abstract": "How can robots learn dexterous grasping skills efficiently and apply them\nadaptively based on user instructions? This work tackles two key challenges:\nefficient skill acquisition from limited human demonstrations and\ncontext-driven skill selection. We introduce AdaDexGrasp, a framework that\nlearns a library of grasping skills from a single human demonstration per skill\nand selects the most suitable one using a vision-language model (VLM). To\nimprove sample efficiency, we propose a trajectory following reward that guides\nreinforcement learning (RL) toward states close to a human demonstration while\nallowing flexibility in exploration. To learn beyond the single demonstration,\nwe employ curriculum learning, progressively increasing object pose variations\nto enhance robustness. At deployment, a VLM retrieves the appropriate skill\nbased on user instructions, bridging low-level learned skills with high-level\nintent. We evaluate AdaDexGrasp in both simulation and real-world settings,\nshowing that our approach significantly improves RL efficiency and enables\nlearning human-like grasp strategies across varied object configurations.\nFinally, we demonstrate zero-shot transfer of our learned policies to a\nreal-world PSYONIC Ability Hand, with a 90% success rate across objects,\nsignificantly outperforming the baseline.", "published": "2025-03-26 04:05:50", "link": "http://arxiv.org/abs/2503.20208v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Generalized Phase Pressure Control Enhanced Reinforcement Learning for Traffic Signal Control", "abstract": "Appropriate traffic state representation is crucial for learning traffic\nsignal control policies. However, most of the current traffic state\nrepresentations are heuristically designed, with insufficient theoretical\nsupport. In this paper, we (1) develop a flexible, efficient, and theoretically\ngrounded method, namely generalized phase pressure (G2P) control, which takes\nonly simple lane features into consideration to decide which phase to be\nactuated; 2) extend the pressure control theory to a general form for\nmulti-homogeneous-lane road networks based on queueing theory; (3) design a new\ntraffic state representation based on the generalized phase state features from\nG2P control; and 4) develop a reinforcement learning (RL)-based algorithm\ntemplate named G2P-XLight, and two RL algorithms, G2P-MPLight and G2P-CoLight,\nby combining the generalized phase state representation with MPLight and\nCoLight, two well-performed RL methods for learning traffic signal control\npolicies. Extensive experiments conducted on multiple real-world datasets\ndemonstrate that G2P control outperforms the state-of-the-art (SOTA) heuristic\nmethod in the transportation field and other recent human-designed heuristic\nmethods; and that the newly proposed G2P-XLight significantly outperforms SOTA\nlearning-based approaches. Our code is available online.", "published": "2025-03-26 04:03:12", "link": "http://arxiv.org/abs/2503.20205v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Assessing SAM for Tree Crown Instance Segmentation from Drone Imagery", "abstract": "The potential of tree planting as a natural climate solution is often\nundermined by inadequate monitoring of tree planting projects. Current\nmonitoring methods involve measuring trees by hand for each species, requiring\nextensive cost, time, and labour. Advances in drone remote sensing and computer\nvision offer great potential for mapping and characterizing trees from aerial\nimagery, and large pre-trained vision models, such as the Segment Anything\nModel (SAM), may be a particularly compelling choice given limited labeled\ndata. In this work, we compare SAM methods for the task of automatic tree crown\ninstance segmentation in high resolution drone imagery of young tree\nplantations. We explore the potential of SAM for this task, and find that\nmethods using SAM out-of-the-box do not outperform a custom Mask R-CNN, even\nwith well-designed prompts, but that there is potential for methods which tune\nSAM further. We also show that predictions can be improved by adding Digital\nSurface Model (DSM) information as an input.", "published": "2025-03-26 03:45:36", "link": "http://arxiv.org/abs/2503.20199v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Zero-Shot LLMs in Human-in-the-Loop RL: Replacing Human Feedback for Reward Shaping", "abstract": "Reinforcement learning often faces challenges with reward misalignment, where\nagents optimize for given rewards but fail to exhibit the desired behaviors.\nThis occurs when the reward function incentivizes proxy behaviors that diverge\nfrom the true objective. While human-in-the-loop (HIL) methods can help, they\nmay exacerbate the problem, as humans are prone to biases that lead to\ninconsistent, subjective, or misaligned feedback, complicating the learning\nprocess. To address these issues, we propose two key contributions. First, we\nextend the use of zero-shot, off-the-shelf large language models (LLMs) for\nreward shaping beyond natural language processing (NLP) to continuous control\ntasks. By leveraging LLMs as direct feedback providers, we replace surrogate\nmodels trained on human feedback, which often suffer from the bias inherent in\nthe feedback data it is trained on. Second, we introduce a hybrid framework\n(LLM-HFBF) that enables LLMs to identify and correct biases in human feedback\nwhile incorporating this feedback into the reward shaping process. The LLM-HFBF\nframework creates a more balanced and reliable system by addressing both the\nlimitations of LLMs (e.g., lack of domain-specific knowledge) and human\nsupervision (e.g., inherent biases). By enabling human feedback bias flagging\nand correction, our approach improves reinforcement learning performance and\nreduces reliance on potentially biased human guidance. Empirical experiments\nshow that biased human feedback significantly reduces performance, with average\nepisodic reward (AER) dropping from 28.472 in (unbiased approaches) to 7.039\n(biased with conservative bias). In contrast, LLM-based approaches maintain a\nmatching AER like unbiased feedback, even in custom edge case scenarios.", "published": "2025-03-26 03:17:12", "link": "http://arxiv.org/abs/2503.22723v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Offline Reinforcement Learning with Discrete Diffusion Skills", "abstract": "Skills have been introduced to offline reinforcement learning (RL) as\ntemporal abstractions to tackle complex, long-horizon tasks, promoting\nconsistent behavior and enabling meaningful exploration. While skills in\noffline RL are predominantly modeled within a continuous latent space, the\npotential of discrete skill spaces remains largely underexplored. In this\npaper, we propose a compact discrete skill space for offline RL tasks supported\nby state-of-the-art transformer-based encoder and diffusion-based decoder.\nCoupled with a high-level policy trained via offline RL techniques, our method\nestablishes a hierarchical RL framework where the trained diffusion decoder\nplays a pivotal role. Empirical evaluations show that the proposed algorithm,\nDiscrete Diffusion Skill (DDS), is a powerful offline RL method. DDS performs\ncompetitively on Locomotion and Kitchen tasks and excels on long-horizon tasks,\nachieving at least a 12 percent improvement on AntMaze-v2 benchmarks compared\nto existing offline RL approaches. Furthermore, DDS offers improved\ninterpretability, training stability, and online exploration compared to\nprevious skill-based methods.", "published": "2025-03-26 03:04:42", "link": "http://arxiv.org/abs/2503.20176v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Debiasing Kernel-Based Generative Models", "abstract": "We propose a novel two-stage framework of generative models named Debiasing\nKernel-Based Generative Models (DKGM) with the insights from kernel density\nestimation (KDE) and stochastic approximation. In the first stage of DKGM, we\nemploy KDE to bypass the obstacles in estimating the density of data without\nlosing too much image quality. One characteristic of KDE is oversmoothing,\nwhich makes the generated image blurry. Therefore, in the second stage, we\nformulate the process of reducing the blurriness of images as a statistical\ndebiasing problem and develop a novel iterative algorithm to improve image\nquality, which is inspired by the stochastic approximation. Extensive\nexperiments illustrate that the image quality of DKGM on CIFAR10 is comparable\nto state-of-the-art models such as diffusion models and GAN models. The\nperformance of DKGM on CelebA 128x128 and LSUN (Church) 128x128 is also\ncompetitive. We conduct extra experiments to exploit how the bandwidth in KDE\naffects the sample diversity and debiasing effect of DKGM. The connections\nbetween DKGM and score-based models are also discussed.", "published": "2025-03-26 01:48:34", "link": "http://arxiv.org/abs/2503.20825v1", "categories": ["stat.ML", "cs.AI"], "primary_category": "stat.ML"}
{"title": "Exploiting Temporal State Space Sharing for Video Semantic Segmentation", "abstract": "Video semantic segmentation (VSS) plays a vital role in understanding the\ntemporal evolution of scenes. Traditional methods often segment videos\nframe-by-frame or in a short temporal window, leading to limited temporal\ncontext, redundant computations, and heavy memory requirements. To this end, we\nintroduce a Temporal Video State Space Sharing (TV3S) architecture to leverage\nMamba state space models for temporal feature sharing. Our model features a\nselective gating mechanism that efficiently propagates relevant information\nacross video frames, eliminating the need for a memory-heavy feature pool. By\nprocessing spatial patches independently and incorporating shifted operation,\nTV3S supports highly parallel computation in both training and inference\nstages, which reduces the delay in sequential state space processing and\nimproves the scalability for long video sequences. Moreover, TV3S incorporates\ninformation from prior frames during inference, achieving long-range temporal\ncoherence and superior adaptability to extended sequences. Evaluations on the\nVSPW and Cityscapes datasets reveal that our approach outperforms current\nstate-of-the-art methods, establishing a new standard for VSS with consistent\nresults across long video sequences. By achieving a good balance between\naccuracy and efficiency, TV3S shows a significant advancement in spatiotemporal\nmodeling, paving the way for efficient video analysis. The code is publicly\navailable at https://github.com/Ashesham/TV3S.git.", "published": "2025-03-26 01:47:42", "link": "http://arxiv.org/abs/2503.20824v1", "categories": ["eess.IV", "cs.AI", "cs.LG"], "primary_category": "eess.IV"}
{"title": "ATP: Adaptive Threshold Pruning for Efficient Data Encoding in Quantum Neural Networks", "abstract": "Quantum Neural Networks (QNNs) offer promising capabilities for complex data\ntasks, but are often constrained by limited qubit resources and high\nentanglement, which can hinder scalability and efficiency. In this paper, we\nintroduce Adaptive Threshold Pruning (ATP), an encoding method that reduces\nentanglement and optimizes data complexity for efficient computations in QNNs.\nATP dynamically prunes non-essential features in the data based on adaptive\nthresholds, effectively reducing quantum circuit requirements while preserving\nhigh performance. Extensive experiments across multiple datasets demonstrate\nthat ATP reduces entanglement entropy and improves adversarial robustness when\ncombined with adversarial training methods like FGSM. Our results highlight\nATPs ability to balance computational efficiency and model resilience,\nachieving significant performance improvements with fewer resources, which will\nhelp make QNNs more feasible in practical, resource-constrained settings.", "published": "2025-03-26 01:14:26", "link": "http://arxiv.org/abs/2503.21815v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Look Before Leap: Look-Ahead Planning with Uncertainty in Reinforcement Learning", "abstract": "Model-based reinforcement learning (MBRL) has demonstrated superior sample\nefficiency compared to model-free reinforcement learning (MFRL). However, the\npresence of inaccurate models can introduce biases during policy learning,\nresulting in misleading trajectories. The challenge lies in obtaining accurate\nmodels due to limited diverse training data, particularly in regions with\nlimited visits (uncertain regions). Existing approaches passively quantify\nuncertainty after sample generation, failing to actively collect uncertain\nsamples that could enhance state coverage and improve model accuracy. Moreover,\nMBRL often faces difficulties in making accurate multi-step predictions,\nthereby impacting overall performance. To address these limitations, we propose\na novel framework for uncertainty-aware policy optimization with model-based\nexploratory planning. In the model-based planning phase, we introduce an\nuncertainty-aware k-step lookahead planning approach to guide action selection\nat each step. This process involves a trade-off analysis between model\nuncertainty and value function approximation error, effectively enhancing\npolicy performance. In the policy optimization phase, we leverage an\nuncertainty-driven exploratory policy to actively collect diverse training\nsamples, resulting in improved model accuracy and overall performance of the RL\nagent. Our approach offers flexibility and applicability to tasks with varying\nstate/action spaces and reward structures. We validate its effectiveness\nthrough experiments on challenging robotic manipulation tasks and Atari games,\nsurpassing state-of-the-art methods with fewer interactions, thereby leading to\nsignificant performance improvements.", "published": "2025-03-26 01:07:35", "link": "http://arxiv.org/abs/2503.20139v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Unlocking the Value of Decentralized Data: A Federated Dual Learning Approach for Model Aggregation", "abstract": "Artificial Intelligence (AI) technologies have revolutionized numerous\nfields, yet their applications often rely on costly and time-consuming data\ncollection processes. Federated Learning (FL) offers a promising alternative by\nenabling AI models to be trained on decentralized data where data is scattered\nacross clients (distributed nodes). However, existing FL approaches struggle to\nmatch the performance of centralized training due to challenges such as\nheterogeneous data distribution and communication delays, limiting their\npotential for breakthroughs. We observe that many real-world use cases involve\nhybrid data regimes, in which a server (center node) has access to some data\nwhile a large amount of data is distributed across associated clients. To\nimprove the utilization of decentralized data under this regime, address data\nheterogeneity issue, and facilitate asynchronous communication between the\nserver and clients, we propose a dual learning approach that leverages\ncentralized data at the server to guide the merging of model updates from\nclients. Our method accommodates scenarios where server data is out-of-domain\nrelative to decentralized client data, making it applicable to a wide range of\nuse cases. We provide theoretical analysis demonstrating the faster convergence\nof our method compared to existing methods. Furthermore, experimental results\nacross various scenarios show that our approach significantly outperforms\nexisting technologies, highlighting its potential to unlock the value of large\namounts of decentralized data.", "published": "2025-03-26 01:00:35", "link": "http://arxiv.org/abs/2503.20138v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Synthetic Video Enhances Physical Fidelity in Video Synthesis", "abstract": "We investigate how to enhance the physical fidelity of video generation\nmodels by leveraging synthetic videos derived from computer graphics pipelines.\nThese rendered videos respect real-world physics, such as maintaining 3D\nconsistency, and serve as a valuable resource that can potentially improve\nvideo generation models. To harness this potential, we propose a solution that\ncurates and integrates synthetic data while introducing a method to transfer\nits physical realism to the model, significantly reducing unwanted artifacts.\nThrough experiments on three representative tasks emphasizing physical\nconsistency, we demonstrate its efficacy in enhancing physical fidelity. While\nour model still lacks a deep understanding of physics, our work offers one of\nthe first empirical demonstrations that synthetic video enhances physical\nfidelity in video synthesis. Website: https://kevinz8866.github.io/simulation/", "published": "2025-03-26 00:45:07", "link": "http://arxiv.org/abs/2503.20822v1", "categories": ["eess.IV", "cs.AI", "cs.GR"], "primary_category": "eess.IV"}
{"title": "Can We Make Code Green? Understanding Trade-Offs in LLMs vs. Human Code Optimizations", "abstract": "The rapid technological evolution has accelerated software development for\nvarious domains and use cases, contributing to a growing share of global carbon\nemissions. While recent large language models (LLMs) claim to assist developers\nin optimizing code for performance and energy efficiency, their efficacy in\nreal-world scenarios remains under exploration. In this work, we explore the\neffectiveness of LLMs in reducing the environmental footprint of real-world\nprojects, focusing on software written in Matlab-widely used in both academia\nand industry for scientific and engineering applications. We analyze\nenergy-focused optimization on 400 scripts across 100 top GitHub repositories.\nWe examine potential 2,176 optimizations recommended by leading LLMs, such as\nGPT-3, GPT-4, Llama, and Mixtral, and a senior Matlab developer, on energy\nconsumption, memory usage, execution time consumption, and code correctness.\nThe developer serves as a real-world baseline for comparing typical human and\nLLM-generated optimizations.\n  Mapping these optimizations to 13 high-level themes, we found that LLMs\npropose a broad spectrum of improvements--beyond energy efficiency--including\nimproving code readability and maintainability, memory management, error\nhandling while the developer overlooked some parallel processing, error\nhandling etc. However, our statistical tests reveal that the energy-focused\noptimizations unexpectedly negatively impacted memory usage, with no clear\nbenefits regarding execution time or energy consumption. Our qualitative\nanalysis of energy-time trade-offs revealed that some themes, such as\nvectorization preallocation, were among the common themes shaping these\ntrade-offs. With LLMs becoming ubiquitous in modern software development, our\nstudy serves as a call to action: prioritizing the evaluation of common coding\npractices to identify the green ones.", "published": "2025-03-26 00:27:29", "link": "http://arxiv.org/abs/2503.20126v1", "categories": ["cs.SE", "cs.AI", "cs.PF"], "primary_category": "cs.SE"}
{"title": "Synthesizing world models for bilevel planning", "abstract": "Modern reinforcement learning (RL) systems have demonstrated remarkable\ncapabilities in complex environments, such as video games. However, they still\nfall short of achieving human-like sample efficiency and adaptability when\nlearning new domains. Theory-based reinforcement learning (TBRL) is an\nalgorithmic framework specifically designed to address this gap. Modeled on\ncognitive theories, TBRL leverages structured, causal world models - \"theories\"\n- as forward simulators for use in planning, generalization and exploration.\nAlthough current TBRL systems provide compelling explanations of how humans\nlearn to play video games, they face several technical limitations: their\ntheory languages are restrictive, and their planning algorithms are not\nscalable. To address these challenges, we introduce TheoryCoder, an\ninstantiation of TBRL that exploits hierarchical representations of theories\nand efficient program synthesis methods for more powerful learning and\nplanning. TheoryCoder equips agents with general-purpose abstractions (e.g.,\n\"move to\"), which are then grounded in a particular environment by learning a\nlow-level transition model (a Python program synthesized from observations by a\nlarge language model). A bilevel planning algorithm can exploit this\nhierarchical structure to solve large domains. We demonstrate that this\napproach can be successfully applied to diverse and challenging grid-world\ngames, where approaches based on directly synthesizing a policy perform poorly.\nAblation studies demonstrate the benefits of using hierarchical abstractions.", "published": "2025-03-26 00:10:01", "link": "http://arxiv.org/abs/2503.20124v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On the order of the shortest solution sequences for the pebble motion problems", "abstract": "Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of\nvertices in a longest path of $G$ such that every vertex on the path is a cut\nvertex of $G$, and every intermediate vertex of the path is a degree-two vertex\nof $G$. Let $k$ be the number of vertices of such a longest path of $T$ that\nevery vertex of the path is a cut vertex and that every intermediate vertex of\nthe path is a degree-two vertex of $T$. Let $P=\\{1,\\ldots,n\\}$ be a set of\npebbles with $n+k < N$. A configuration of $P$ on $G$ is defined as a function\n$f$ from $V(G)$ to $\\{0, 1, \\ldots, n \\}$ with $|f^{-1}(i)| = 1$ for $1 \\le i\n\\le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \\le\ni \\le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A move is defined as\nshifting a pebble from a vertex to some unoccupied neighbor. The pebble motion\nproblem on the pair $(G,P)$ is to decide whether a given configuration of\npebbles is reachable from another by executing a sequence of moves. In this\npaper, we show that the length of the shortest solution sequence of the pebble\nmotion problem on the pair $(G,P)$ is in $O(Nn + n^2 \\log(\\min\\{n,k\\}))$ if $G$\nis a $N$-vertex tree, and it is in $O(N^2 + \\frac{n^3}{N-n} + n^2\n\\log(\\min\\{n,N-n\\}))$ if $G$ is a connected general $N$-vertex graph. We\nprovide an algorithm that can obtain a solution sequence of lengths that\nsatisfy these orders, with the same computational complexity as the order of\nthe length.\n  Keywords: pebble motion, motion planning, multi-agent path finding,\n$15$-puzzle, tree", "published": "2025-03-26 13:46:44", "link": "http://arxiv.org/abs/2503.20550v2", "categories": ["math.CO", "cs.CC", "cs.DM"], "primary_category": "math.CO"}
{"title": "Local obstructions in sequences revisited", "abstract": "In this article, we consider some simple combinatorial game and a winning\nstrategy in this game. This game is then used to prove several known results\nabout non-repetitive sequences and approximations with denominators from a\nlacunary sequence. In this way we simplify the proofs, improve the bounds and\nget for free the computable versions that required a separate treatment.", "published": "2025-03-26 13:16:12", "link": "http://arxiv.org/abs/2503.20529v1", "categories": ["math.CO", "cs.DM", "math.NT"], "primary_category": "math.CO"}
{"title": "Beyond Worst-Case Subset Sum: An Adaptive, Structure-Aware Solver with Sub-$2^{n/2}$ Enumeration", "abstract": "The Subset Sum problem, which asks whether a set of $n$ integers has a subset\nsumming to a target $t$, is a fundamental NP-complete problem in cryptography\nand combinatorial optimization. The classical meet-in-the-middle (MIM)\nalgorithm of Horowitz--Sahni runs in\n$\\widetilde{\\mathcal{O}}\\bigl(2^{n/2}\\bigr)$, still the best-known\ndeterministic bound. Yet many instances exhibit abundant collisions in partial\nsums, so actual hardness often depends on the number of unique sums ($U$).\n  We present a structure-aware, adaptive solver that enumerates only distinct\nsums, pruning duplicates on the fly, thus running in\n$\\widetilde{\\mathcal{O}}(U)$ when $U \\ll 2^n$. Its core is a unique-subset-sums\nenumerator combined with a double meet-in-the-middle strategy and lightweight\ndynamic programming, avoiding the classical MIM's expensive merge. We also\nintroduce combinatorial tree compression to guarantee strictly sub-$2^{n/2}$\nenumeration even on unstructured inputs, shaving a nontrivial constant from the\nexponent.\n  Our solver supports anytime and online modes, producing partial solutions\nearly and adapting to newly added elements. Theoretical analysis and\nexperiments show that for structured instances -- e.g. with small doubling\nconstants, high additive energy, or significant redundancy -- our method can\nfar outperform classical approaches, often nearing dynamic-programming\nefficiency. Even in the worst case, it remains within\n$\\widetilde{\\mathcal{O}}\\bigl(2^{n/2}\\bigr)$, and its compression-based pruning\nyields a real constant-factor speedup over naive MIM. We conclude by discussing\nhow this instance-specific adaptivity refines the Subset Sum complexity\nlandscape and suggesting future adaptive-exponential directions.", "published": "2025-03-26 02:32:13", "link": "http://arxiv.org/abs/2503.20162v1", "categories": ["cs.DS", "cs.CC", "cs.DM"], "primary_category": "cs.DS"}
{"title": "MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion", "abstract": "Videos inherently contain multiple modalities, including visual events, text\noverlays, sounds, and speech, all of which are important for retrieval.\nHowever, state-of-the-art multimodal language models like VAST and LanguageBind\nare built on vision-language models (VLMs), and thus overly prioritize visual\nsignals. Retrieval benchmarks further reinforce this bias by focusing on visual\nqueries and neglecting other modalities. We create a search system MMMORRF that\nextracts text and features from both visual and audio modalities and integrates\nthem with a novel modality-aware weighted reciprocal rank fusion. MMMORRF is\nboth effective and efficient, demonstrating practicality in searching videos\nbased on users' information needs instead of visual descriptive queries. We\nevaluate MMMORRF on MultiVENT 2.0 and TVR, two multimodal benchmarks designed\nfor more targeted information needs, and find that it improves nDCG@20 by 81%\nover leading multimodal encoders and 37% over single-modality retrieval,\ndemonstrating the value of integrating diverse modalities.", "published": "2025-03-26 16:28:04", "link": "http://arxiv.org/abs/2503.20698v2", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "RALLRec+: Retrieval Augmented Large Language Model Recommendation with Reasoning", "abstract": "Large Language Models (LLMs) have been integrated into recommender systems to\nenhance user behavior comprehension. The Retrieval Augmented Generation (RAG)\ntechnique is further incorporated into these systems to retrieve more relevant\nitems and improve system performance. However, existing RAG methods have two\nshortcomings. \\textit{(i)} In the \\textit{retrieval} stage, they rely primarily\non textual semantics and often fail to incorporate the most relevant items,\nthus constraining system effectiveness. \\textit{(ii)} In the\n\\textit{generation} stage, they lack explicit chain-of-thought reasoning,\nfurther limiting their potential.\n  In this paper, we propose Representation learning and \\textbf{R}easoning\nempowered retrieval-\\textbf{A}ugmented \\textbf{L}arge \\textbf{L}anguage model\n\\textbf{Rec}ommendation (RALLRec+). Specifically, for the retrieval stage, we\nprompt LLMs to generate detailed item descriptions and perform joint\nrepresentation learning, combining textual and collaborative signals extracted\nfrom the LLM and recommendation models, respectively. To account for the\ntime-varying nature of user interests, we propose a simple yet effective\nreranking method to capture preference dynamics. For the generation phase, we\nfirst evaluate reasoning LLMs on recommendation tasks, uncovering valuable\ninsights. Then we introduce knowledge-injected prompting and consistency-based\nmerging approach to integrate reasoning LLMs with general-purpose LLMs,\nenhancing overall performance. Extensive experiments on three real world\ndatasets validate our method's effectiveness.", "published": "2025-03-26 11:03:34", "link": "http://arxiv.org/abs/2503.20430v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Dewey Long Context Embedding Model: A Technical Report", "abstract": "This technical report presents the training methodology and evaluation\nresults of the open-source dewey_en_beta embedding model. The increasing demand\nfor retrieval-augmented generation (RAG) systems and the expanding context\nwindow capabilities of large language models (LLMs) have created critical\nchallenges for conventional embedding models. Current approaches often struggle\nto maintain semantic coherence when processing documents exceeding typical\nsequence length limitations, significantly impacting retrieval performance in\nknowledge-intensive applications. This paper presents dewey_en_beta, a novel\ntext embedding model that achieves excellent performance on MTEB (Eng, v2) and\nLongEmbed benchmark while supporting 128K token sequences. Our technical\ncontribution centers on chunk alignment training, an innovative methodology\nthat enables the simultaneous generation of localized chunk embeddings and\nglobal document-level representations through distillation. Information\nregarding the model release can be found at\nhttps://huggingface.co/infgrad/dewey_en_beta.", "published": "2025-03-26 09:55:00", "link": "http://arxiv.org/abs/2503.20376v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Learnable Sequence Augmenter for Triplet Contrastive Learning in Sequential Recommendation", "abstract": "Most existing contrastive learning-based sequential recommendation (SR)\nmethods rely on random operations (e.g., crop, reorder, and substitute) to\ngenerate augmented sequences. These methods often struggle to create positive\nsample pairs that closely resemble the representations of the raw sequences,\npotentially disrupting item correlations by deleting key items or introducing\nnoisy iterac, which misguides the contrastive learning process.\n  To address this limitation, we propose Learnable sequence Augmentor for\ntriplet Contrastive Learning in sequential Recommendation (LACLRec).\nSpecifically, the self-supervised learning-based augmenter can automatically\ndelete noisy items from sequences and insert new items that better capture item\ntransition patterns, generating a higher-quality augmented sequence.\nSubsequently, we randomly generate another augmented sequence and design a\nranking-based triplet contrastive loss to differentiate the similarities\nbetween the raw sequence, the augmented sequence from augmenter, and the\nrandomly augmented sequence, providing more fine-grained contrastive signals.\nExtensive experiments on three real-world datasets demonstrate that both the\nsequence augmenter and the triplet contrast contribute to improving\nrecommendation accuracy. LACLRec significantly outperforms the baseline model\nCL4SRec, and demonstrates superior performance compared to several\nstate-of-the-art sequential recommendation algorithms.", "published": "2025-03-26 04:56:29", "link": "http://arxiv.org/abs/2503.20232v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "BeLightRec: A lightweight recommender system enhanced with BERT", "abstract": "The trend of data mining using deep learning models on graph neural networks\nhas proven effective in identifying object features through signal encoders and\ndecoders, particularly in recommendation systems utilizing collaborative\nfiltering methods. Collaborative filtering exploits similarities between users\nand items from historical data. However, it overlooks distinctive information,\nsuch as item names and descriptions. The semantic data of items should be\nfurther mined using models in the natural language processing field. Thus,\nitems can be compared using text classification, similarity assessments, or\nidentifying analogous sentence pairs. This research proposes combining two\nsources of item similarity signals: one from collaborative filtering and one\nfrom the semantic similarity measure between item names and descriptions. These\nsignals are integrated into a graph convolutional neural network to optimize\nmodel weights, thereby providing accurate recommendations. Experiments are also\ndesigned to evaluate the contribution of each signal group to the\nrecommendation results.", "published": "2025-03-26 04:03:20", "link": "http://arxiv.org/abs/2503.20206v1", "categories": ["cs.IR", "H.m"], "primary_category": "cs.IR"}
{"title": "Covert Entanglement Generation and Secrecy", "abstract": "We determine the covert capacity for entanglement generation over a noisy\nquantum channel. While secrecy guarantees that the transmitted information\nremains inaccessible to an adversary, covert communication ensures that the\ntransmission itself remains undetectable. The entanglement dimension follows a\nsquare root law (SRL) in the covert setting, i.e., $O(\\sqrt{n})$ EPR pairs can\nbe distributed covertly and reliably over n channel uses. We begin with covert\ncommunication of classical information under a secrecy constraint. We then\nleverage this result to construct a coding scheme for covert entanglement\ngeneration. Consequently, we establish achievability of the same covert\nentanglement generation rate as the classical information rate without secrecy,\nalbeit with a larger key.", "published": "2025-03-26 21:34:18", "link": "http://arxiv.org/abs/2503.21002v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Semantic Communications via Features Identification", "abstract": "The development of the new generation of wireless technologies (6G) has led\nto an increased interest in semantic communication. Thanks also to recent\ndevelopments in artificial intelligence and communication technologies,\nresearchers in this field have defined new communication paradigms that go\nbeyond those of syntactic communication to post-Shannon and semantic\ncommunication. However, there is still need to define a clear and practical\nframework for semantic communication, as well as an effective structure of\nsemantic elements that can be used in it. The aim of this work is to bridge the\ngap between two post-Shannon communication paradigms, and to define a robust\nand effective semantic communication strategy that focuses on a dedicated\nsemantic element that can be easily derived from any type of message. Our work\nwill take form as an innovative communication method called identification via\nsemantic features, which aims at exploiting the ambiguities present in semantic\nmessages, allowing for their identification instead of reproducing them bit by\nbit. Our approach has been tested through numerical simulations using a\ncombination of machine learning and data analysis. The proposed communication\nmethod showed promising results, demonstrating a clear and significant gain\nover traditional syntactic communication paradigms.", "published": "2025-03-26 17:00:03", "link": "http://arxiv.org/abs/2503.20720v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Power Minimization for NOMA-assisted Pinching Antenna Systems With Multiple Waveguides", "abstract": "The integration of pinching antenna systems with non-orthogonal multiple\naccess (NOMA) has emerged as a promising technique for future 6G applications.\nThis paper is the first to investigate power minimization for NOMA-assisted\npinching antenna systems utilizing multiple dielectric waveguides. We formulate\na total power minimization problem constrained by each user's minimum data\nrequirements, addressing a classical challenge. To efficiently solve the\nnon-convex optimization problem, we propose an iterative algorithm.\nFurthermore, we demonstrate that the interference function of this algorithm is\nstandard, ensuring convergence to a unique fixed point. Numerical simulations\nvalidate that our developed algorithm converges within a few steps and\nsignificantly outperforms benchmark strategies across various data rate\nrequirements. The results also indicate that the minimum transmit power, as a\nfunction of the interval between the waveguides, exhibits an approximately\noscillatory decay with a negative trend.", "published": "2025-03-26 09:01:02", "link": "http://arxiv.org/abs/2503.20336v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Phase-Only Zero-Forcing for Secure Wireless Communication in Multi-User Systems", "abstract": "Artificial noise (AN) transmission is a physical layer security technique in\nmulti-antenna wireless communication systems. Synthetic noise is broadcast to\nall receivers except designated legitimate users via beamforming in the\nlegitimate users' null space. We consider AN transmission employing a single RF\nchain and analog beamforming, where beamforming vectors maintain constant\nmagnitude while allowing arbitrary phases. Our primary objective is to design a\nconstant-magnitude vector capable of nullifying multiple users' channel vectors\nsimultaneously. To tackle this zero-forcing problem, we propose a novel\nsuccessive partition zero-forcing (SPZF) scheme, which transforms the\nmulti-user zero-forcing task into optimizing channel partitioning to minimize\noutage probability. The SPZF scheme can be generalized to any number of users,\nbut our analysis focuses on the two-user case. Theoretical analysis reveals\nthat our proposed SPZF scheme can attain arbitrarily low outage probability in\nthe limit of large number of transmit antenna. We present three partition\nalgorithms (random, iterative, and genetic) to minimize the outage probability.\nThe outage probabilities and secrecy rates of the three partition algorithms\nare compared via numerical simulations. We find that the more advanced\npartition algorithms (iterative and genetic) achieve higher secrecy rates than\nthe random algorithm, particularly under conditions of high signal-to-noise\nratio (SNR), large number of eavesdroppers, or small number of transmit\nantennas.", "published": "2025-03-26 04:29:23", "link": "http://arxiv.org/abs/2503.20223v1", "categories": ["cs.IT", "math.IT", "68P30", "E.4; H.1.1"], "primary_category": "cs.IT"}
{"title": "Mutual Information-Empowered Task-Oriented Communication: Principles, Applications and Challenges", "abstract": "Mutual information (MI)-based guidelines have recently proven to be effective\nfor designing task-oriented communication systems, where the ultimate goal is\nto extract and transmit task-relevant information for downstream task. This\npaper provides a comprehensive overview of MI-empowered task-oriented\ncommunication, highlighting how MI-based methods can serve as a unifying design\nframework in various task-oriented communication scenarios. We begin with the\nroadmap of MI for designing task-oriented communication systems, and then\nintroduce the roles and applications of MI to guide feature encoding,\ntransmission optimization, and efficient training with two case studies. We\nfurther elaborate the limitations and challenges of MI-based methods. Finally,\nwe identify several open issues in MI-based task-oriented communication to\ninspire future research.", "published": "2025-03-26 03:39:53", "link": "http://arxiv.org/abs/2503.20195v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "New constructions of MDS symbol-pair codes via simple-root cyclic codes", "abstract": "In modern storage technologies, symbol-pair codes have emerged as a crucial\nframework for addressing errors in channels where symbols are read in\noverlapping pairs to guard against pair errors. A symbol-pair code that meets\nthe Singleton-type bound is called a maximum distance separable (MDS)\nsymbol-pair code. MDS symbol-pair codes are optimal in the sense that they have\nthe highest pair error-correcting capability. In this paper, we focus on new\nconstructions of MDS symbol-pair codes using simple-root cyclic codes.\nSpecifically, three new infinite families of $(n, d_P)_q$-MDS symbol-pair codes\nare obtained: (1) $(n=4q+4,d_P=7)_q$ for $q\\equiv 1\\pmod 4$; (2)\n$(n=4q-4,d_P=8)_q$ for $q\\equiv 3\\pmod 4$; (3) $(n=2q+2,d_P=9)_q$ for $q$ being\nan odd prime power. The first two constructions are based on analyzing the\nsolutions of certain equations over finite fields. The third construction\narises from the decomposition of cyclic codes, where we utilize the orthogonal\nrelationships between component codes and their duals to rigorously exclude the\npresence of specific codewords. It is worth noting that for the pair distance\n$d_P=7$ or $8$, our $q$-ary MDS symbol-pair codes achieve the longest known\ncode length when $q$ is not a prime. Furthermore, for $d_P=9$, our codes attain\nthe longest code length regardless of whether $q$ is prime or not.", "published": "2025-03-26 00:57:51", "link": "http://arxiv.org/abs/2503.20137v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?", "abstract": "Many multi-agent socio-technical systems rely on aggregating heterogeneous\nagents' costs into a social cost function (SCF) to coordinate resource\nallocation in domains like energy grids, water allocation, or traffic\nmanagement. The choice of SCF often entails implicit assumptions and may lead\nto undesirable outcomes if not rigorously justified. In this paper, we\ndemonstrate that what determines which SCF ought to be used is the degree to\nwhich individual costs can be compared across agents and which axioms the\naggregation shall fulfill. Drawing on the results from social choice theory, we\nprovide guidance on how this process can be used in control applications. We\ndemonstrate which assumptions about interpersonal utility comparability --\nranging from ordinal level comparability to full cardinal comparability --\ntogether with a choice of desirable axioms, inform the selection of a correct\nSCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then\ndemonstrate how the proposed framework can be applied for principled\nallocations of water and transportation resources.", "published": "2025-03-26 17:53:57", "link": "http://arxiv.org/abs/2503.20772v1", "categories": ["math.OC", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "Distributed Linear Quadratic Gaussian for Multi-Robot Coordination with Localization Uncertainty", "abstract": "This paper addresses the problem of distributed coordination control for\nmulti-robot systems (MRSs) in the presence of localization uncertainty using a\nLinear Quadratic Gaussian (LQG) approach. We introduce a stochastic LQG control\nstrategy that ensures the coordination of mobile robots while optimizing a\nperformance criterion. The proposed control framework accounts for the inherent\nuncertainty in localization measurements, enabling robust decision-making and\ncoordination. We analyze the stability of the system under the proposed control\nprotocol, deriving conditions for the convergence of the multi-robot network.\nThe effectiveness of the proposed approach is demonstrated through experimental\nvalidation using Robotrium simulation experiments, showcasing the practical\napplicability of the control strategy in real-world scenarios with localization\nuncertainty.", "published": "2025-03-26 17:10:07", "link": "http://arxiv.org/abs/2504.03126v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Multi-Robot Coordination Under Physical Limitations", "abstract": "Multi-robot coordination is fundamental to various applications, including\nautonomous exploration, search and rescue, and cooperative transportation. This\npaper presents an optimal consensus framework for multi-robot systems (MRSs)\nthat ensures efficient rendezvous while minimizing energy consumption and\naddressing actuator constraints. A critical challenge in real-world deployments\nis actuator limitations, particularly wheel velocity saturation, which can\nsignificantly degrade control performance. To address this issue, we\nincorporate Pontryagin Minimum Principle (PMP) into the control design,\nfacilitating constrained optimization while ensuring system stability and\nfeasibility. The resulting optimal control policy effectively balances\ncoordination efficiency and energy consumption, even in the presence of\nactuation constraints. The proposed framework is validated through extensive\nnumerical simulations and real-world experiments conducted using a team of\nRobotarium mobile robots. The experimental results confirm that our control\nstrategies achieve reliable and efficient coordinated rendezvous while\naddressing real-world challenges such as communication delays, sensor noise,\nand packet loss.", "published": "2025-03-26 17:06:53", "link": "http://arxiv.org/abs/2503.20723v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement Learning for Connected Autonomous Vehicles", "abstract": "Deep Reinforcement Learning (DRL) holds significant promise for achieving\nhuman-like Autonomous Vehicle (AV) capabilities, but suffers from low sample\nefficiency and challenges in reward design. Model-Based Reinforcement Learning\n(MBRL) offers improved sample efficiency and generalizability compared to\nModel-Free Reinforcement Learning (MFRL) in various multi-agent decision-making\nscenarios. Nevertheless, MBRL faces critical difficulties in estimating\nuncertainty during the model learning phase, thereby limiting its scalability\nand applicability in real-world scenarios. Additionally, most Connected\nAutonomous Vehicle (CAV) studies focus on single-agent decision-making, while\nexisting multi-agent MBRL solutions lack computationally tractable algorithms\nwith Probably Approximately Correct (PAC) guarantees, an essential factor for\nensuring policy reliability with limited training data. To address these\nchallenges, we propose MA-PMBRL, a novel Multi-Agent Pessimistic Model-Based\nReinforcement Learning framework for CAVs, incorporating a max-min optimization\napproach to enhance robustness and decision-making. To mitigate the inherent\nsubjectivity of uncertainty estimation in MBRL and avoid incurring catastrophic\nfailures in AV, MA-PMBRL employs a pessimistic optimization framework combined\nwith Projected Gradient Descent (PGD) for both model and policy learning.\nMA-PMBRL also employs general function approximations under partial dataset\ncoverage to enhance learning efficiency and system-level performance. By\nbounding the suboptimality of the resulting policy under mild theoretical\nassumptions, we successfully establish PAC guarantees for MA-PMBRL,\ndemonstrating that the proposed framework represents a significant step toward\nscalable, efficient, and reliable multi-agent decision-making for CAVs.", "published": "2025-03-26 11:49:02", "link": "http://arxiv.org/abs/2503.20462v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "CTS-CBS: A New Approach for Multi-Agent Collaborative Task Sequencing and Path Finding", "abstract": "This paper addresses a generalization problem of Multi-Agent Pathfinding\n(MAPF), called Collaborative Task Sequencing - Multi-Agent Pathfinding\n(CTS-MAPF), where agents must plan collision-free paths and visit a series of\nintermediate task locations in a specific order before reaching their final\ndestinations. To address this problem, we propose a new approach, Collaborative\nTask Sequencing - Conflict-Based Search (CTS-CBS), which conducts a two-level\nsearch. In the high level, it generates a search forest, where each tree\ncorresponds to a joint task sequence derived from the jTSP solution. In the low\nlevel, CTS-CBS performs constrained single-agent path planning to generate\npaths for each agent while adhering to high-level constraints. We also provide\nheoretical guarantees of its completeness and optimality (or sub-optimality\nwith a bounded parameter). To evaluate the performance of CTS-CBS, we create\ntwo datasets, CTS-MAPF and MG-MAPF, and conduct comprehensive experiments. The\nresults show that CTS-CBS adaptations for MG-MAPF outperform baseline\nalgorithms in terms of success rate (up to 20 times larger) and runtime (up to\n100 times faster), with less than a 10% sacrifice in solution quality.\nFurthermore, CTS-CBS offers flexibility by allowing users to adjust the\nsub-optimality bound omega to balance between solution quality and efficiency.\nFinally, practical robot tests demonstrate the algorithm's applicability in\nreal-world scenarios.", "published": "2025-03-26 08:47:43", "link": "http://arxiv.org/abs/2503.20324v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "ConicCurv: A curvature estimation algorithm for planar polygons", "abstract": "ConicCurv is a new derivative-free algorithm to estimate the curvature of a\nplane curve from a sample of data points. It is based on a known tangent\nestimator method grounded on classic results of Projective Geometry and\nB\\'ezier rational conic curves. The curvature values estimated by ConicCurv are\ninvariant to Euclidean changes of coordinates and reproduce the exact curvature\nvalues if the data are sampled from a conic.\n  We show that ConicCurv< has convergence order $3$ and, if the sample points\nare uniformly arc-length distributed, the convergence order is $4$. The\nperformance of ConicCurv is compared with some of the most frequently used\nalgorithms to estimate curvatures and its performance is illustrated in the\ncalculation of the elastic energy of subdivision curves and the location of\nL-curves corners.", "published": "2025-03-26 19:14:15", "link": "http://arxiv.org/abs/2503.20938v1", "categories": ["math.NA", "cs.NA", "53Z50, 53A15, 68W25, 65D15, 65F22"], "primary_category": "math.NA"}
{"title": "Centroidal Voronoi Refinement in the Geometric Refinement Transform: Symmetry, Stability, and Optimal Reconstruction", "abstract": "We extend the Geometric Refinement Transform (GRT) by introducing centroidal\nVoronoi tessellations (CVTs) into the refinement process, enhancing symmetry,\nreconstruction accuracy, and numerical stability. By applying Lloyds algorithm\nat each refinement level, we minimize centroidal energy and generate Voronoi\nregions that better align with the functions underlying structure. This\napproach reduces geometric distortion, suppresses reconstruction error, and\nprovides a natural framework for adaptive refinement. We analyze convergence\nproperties, quantify the reduction in reconstruction error using Taylor-based\nestimates and Lipschitz continuous functions, and propose perturbation\nstrategies to escape symmetry-preserving local minima. The resulting transform\noffers improved accuracy for applications in medical imaging, signal\nprocessing, and physics simulations, while preserving the theoretical\ncompleteness and stability guarantees of the original GRT framework.", "published": "2025-03-26 19:02:49", "link": "http://arxiv.org/abs/2503.20930v1", "categories": ["math.NA", "cs.NA", "42C40, 52C17, 65D15, 65N50, 94A08"], "primary_category": "math.NA"}
{"title": "The MINI mixed virtual element for the Stokes equation", "abstract": "We present and discuss a generalization of the popular MINI mixed finite\nelement for the 2D Stokes equation by means of conforming virtual elements on\npolygonal meshes. We prove optimal error estimates for both velocity and\npressure. Theoretical results are confirmed by several numerical tests\nperformed with different choices of polynomial accuracy and meshes.", "published": "2025-03-26 18:55:06", "link": "http://arxiv.org/abs/2503.20921v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N30"], "primary_category": "math.NA"}
{"title": "Variants of thick-restart Lanczos for the Bethe-Salpeter eigenvalue problem", "abstract": "The non-Hermitian Bethe-Salpeter eigenvalue problem is a structured\neigenproblem, with real eigenvalues coming in pairs $\\{\\lambda,-\\lambda\\}$\nwhere the corresponding pair of eigenvectors are closely related, and\nfurthermore the left eigenvectors can be trivially obtained from the right\nones. We exploit these properties to devise three variants of\nstructure-preserving Lanczos eigensolvers to compute a subset of eigenvalues\n(those of either smallest or largest magnitude) together with their\ncorresponding right and left eigenvectors. For this to be effective in real\napplications, we need to incorporate a thick-restart technique in a way that\nthe overall computation preserves the problem structure. The new methods are\nvalidated in an implementation within the SLEPc library using several test\nmatrices, some of them coming from the Yambo materials science code.", "published": "2025-03-26 18:53:45", "link": "http://arxiv.org/abs/2503.20920v1", "categories": ["math.NA", "cs.NA", "65F15, 15A18, 65F50"], "primary_category": "math.NA"}
{"title": "On computing the zeros of a class of Sobolev orthogonal polynomials", "abstract": "A fast and weakly stable method for computing the zeros of a particular class\nof hypergeometric polynomials is presented. The studied hypergeometric\npolynomials satisfy a higher order differential equation and generalize\nLaguerre polynomials. The theoretical study of the asymptotic distribution of\nthe spectrum of these polynomials is an active research topic. In this article\nwe do not contribute to the theory, but provide a practical method to\ncontribute to further and better understanding of the asymptotic behavior. The\npolynomials under consideration fit into the class of Sobolev orthogonal\npolynomials, satisfying a four--term recurrence relation. This allows computing\nthe roots via a generalized eigenvalue problem. After condition enhancing\nsimilarity transformations, the problem is transformed into the computation of\nthe eigenvalues of a comrade matrix, which is a symmetric tridiagonal modified\nby a rank--one matrix. The eigenvalues are then retrieved by relying on an\nexisting structured rank based fast algorithm. Numerical examples are reported\nstudying the accuracy, stability and conforming the efficiency for various\nparameter settings of the proposed approach.", "published": "2025-03-26 14:07:04", "link": "http://arxiv.org/abs/2503.20567v1", "categories": ["math.NA", "cs.NA", "33C20, 65F15, 65F35"], "primary_category": "math.NA"}
{"title": "Local sensitivity analysis for Bayesian inverse problems", "abstract": "We present an extension of local sensitivity analysis, also referred to as\nthe perturbation approach for uncertainty quantification, to Bayesian inverse\nproblems. More precisely, we show how moments of random variables with respect\nto the posterior distribution can be approximated efficiently by asymptotic\nexpansions. This is under the assumption that the measurement operators and\nprediction functions are sufficiently smooth and their corresponding stochastic\nmoments with respect to the prior distribution exist. Numerical experiments are\npresented to the illustrate the theoretical results.", "published": "2025-03-26 13:12:28", "link": "http://arxiv.org/abs/2503.20526v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Consistent splitting SAV schemes for finite element approximations of incompressible flows", "abstract": "Consistent splitting schemes are among the most accurate pressure segregation\nmethods, incurring no splitting errors or spurious boundary conditions.\nNevertheless, their theoretical properties are not yet fully understood,\nespecially when finite elements are used for the spatial discretisation. This\nwork proposes a simple scalar auxiliary variable (SAV) technique that, when\ncombined with standard finite elements in space, guarantees unconditional\nstability for first- and second-order consistent splitting schemes. The\nframework is implicit-explicit (IMEX) and only requires solving linear\ntransport equations and a pressure Poisson problem per time step. Furthermore,\npressure stability is attained with respect to a stronger norm than in\nclassical projection schemes, which allows eliminating the inf-sup\ncompatibility requirement on the velocity-pressure pairs. The accuracy of the\nnew framework is assessed through numerical examples.", "published": "2025-03-26 11:56:16", "link": "http://arxiv.org/abs/2503.20474v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Which variables of a numerical problem cause ill-conditioning?", "abstract": "We study a broad class of numerical problems that can be defined as the\nsolution of a system of (nonlinear) equations for a subset of the dependent\nvariables. Given a system of the form $F(x,y,z) = c$ with multivariate input\n$x$ and dependent variables $y$ and $z$, we define and give concrete\nexpressions for the condition number of solving for a value of $y$ such that\n$F(x,y,z) = c$ for some unspecified $z$. This condition number can be used to\ndetermine which of the dependent variables of a numerical problem are the most\nill-conditioned. We show how this can be used to explain the condition number\nof the problem of solving for all dependent variables, even if the solution is\nnot unique. The concepts are illustrated with Tucker decomposition of tensors\nas an example problem.", "published": "2025-03-26 11:11:06", "link": "http://arxiv.org/abs/2503.20437v1", "categories": ["math.NA", "cs.NA", "15A12, 15A23, 49Q12, 53B20, 15A69, 65F35"], "primary_category": "math.NA"}
{"title": "Second order divergence constraint preserving schemes for two-fluid relativistic plasma flow equations", "abstract": "Two-fluid relativistic plasma flow equations combine the equations of\nrelativistic hydrodynamics with Maxwell's equations for electromagnetic fields,\nwhich involve divergence constraints for the magnetic and electric fields. When\ndeveloping numerical schemes for the model, the divergence constraints are\nignored, or Maxwell's equations are reformulated as Perfectly Hyperbolic\nMaxwell's (PHM) equations by introducing additional equations for correction\npotentials. In the latter case, the divergence constraints are preserved only\nas the limiting case.\n  In this article, we present second-order numerical schemes that preserve the\ndivergence constraint for electric and magnetic fields at the discrete level.\nThe schemes are based on using a multidimensional Riemann solver at the\nvertices of the cells to define the numerical fluxes on the edges. The\nsecond-order accuracy is obtained by reconstructing the electromagnetic fields\nat the corners using a MinMod limiter. The discretization of Maxwell's\nequations can be combined with any consistent and stable discretization of the\nfluid parts. In particular, we consider entropy-stable schemes for the fluid\npart. The resulting schemes are second-order accurate, entropy stable, and\npreserve the divergence constraints of the electromagnetic fields. We use\nexplicit and IMEX-based time discretizations. We then test these schemes using\nseveral one- and two-dimensional test cases. We also compare the divergence\nconstraint errors of the proposed schemes with schemes having no divergence\nconstraints treatment and schemes based on the PHM-based divergence cleaning.", "published": "2025-03-26 09:49:08", "link": "http://arxiv.org/abs/2503.20372v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Semi-Lagrangian scheme for Hamilton-Jacobi-Bellman equations with Dirichlet boundary conditions", "abstract": "We study the numerical approximation of time-dependent, possibly degenerate,\nsecond-order Hamilton-Jacobi-Bellman equations in bounded domains with\nnonhomogeneous Dirichlet boundary conditions. It is well known that convergence\ntowards the exact solution of the equation, considered here in the viscosity\nsense, holds if the scheme is monotone, consistent, and stable. While standard\nfinite difference schemes are, in general, not monotone, the so-called\nsemi-Lagrangian schemes are monotone by construction. On the other hand, these\nschemes make use of a wide stencil and, when the equation is set in a bounded\ndomain, this typically causes an overstepping of the boundary and hence the\nloss of consistency. We propose here a semi-Lagrangian scheme defined on an\nunstructured mesh, with a suitable treatment at grid points near the boundary\nto preserve consistency, and show its convergence for problems where the\nviscosity solution can even be discontinuous. We illustrate the numerical\nconvergence in several tests, including degenerate and first-order equations.", "published": "2025-03-26 07:18:22", "link": "http://arxiv.org/abs/2503.20283v1", "categories": ["math.NA", "cs.NA", "math.OC", "49L25, 65M12, 35D40, 35K55"], "primary_category": "math.NA"}
{"title": "Relative portfolio optimization via a value at risk based constraint", "abstract": "In this paper, we consider $n$ agents who invest in a general financial\nmarket that is free of arbitrage and complete. The aim of each investor is to\nmaximize her expected utility while ensuring, with a specified probability,\nthat her terminal wealth exceeds a benchmark defined by her competitors'\nperformance. This setup introduces an interdependence between agents, leading\nto a search for Nash equilibria. In the case of two agents and CRRA utility, we\nare able to derive all Nash equilibria in terms of terminal wealth. For $n>2$\nagents and logarithmic utility we distinguish two cases. In the first case, the\nprobabilities in the constraint are small and we can characterize all Nash\nequilibria. In the second case, the probabilities are larger and we look for\nNash equilibria in a certain set. We also discuss the impact of the competition\nusing some numerical examples. As a by-product, we solve some portfolio\noptimization problems with probability constraints.", "published": "2025-03-26 09:06:29", "link": "http://arxiv.org/abs/2503.20340v1", "categories": ["math.OC", "q-fin.MF", "q-fin.PM"], "primary_category": "math.OC"}
{"title": "Graph-Based Uncertainty-Aware Self-Training with Stochastic Node Labeling", "abstract": "Self-training has become a popular semi-supervised learning technique for\nleveraging unlabeled data. However, the over-confidence of pseudo-labels\nremains a key challenge. In this paper, we propose a novel \\emph{graph-based\nuncertainty-aware self-training} (GUST) framework to combat over-confidence in\nnode classification. Drawing inspiration from the uncertainty integration idea\nintroduced by Wang \\emph{et al.}~\\cite{wang2024uncertainty}, our method largely\ndiverges from previous self-training approaches by focusing on \\emph{stochastic\nnode labeling} grounded in the graph topology. Specifically, we deploy a\nBayesian-inspired module to estimate node-level uncertainty, incorporate these\nestimates into the pseudo-label generation process via an\nexpectation-maximization (EM)-like step, and iteratively update both node\nembeddings and adjacency-based transformations. Experimental results on several\nbenchmark graph datasets demonstrate that our GUST framework achieves\nstate-of-the-art performance, especially in settings where labeled data is\nextremely sparse.", "published": "2025-03-26 21:54:19", "link": "http://arxiv.org/abs/2503.22745v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Uncertainty-Aware Graph Self-Training with Expectation-Maximization Regularization", "abstract": "In this paper, we propose a novel \\emph{uncertainty-aware graph\nself-training} approach for semi-supervised node classification. Our method\nintroduces an Expectation-Maximization (EM) regularization scheme to\nincorporate an uncertainty mechanism during pseudo-label generation and model\nretraining. Unlike conventional graph self-training pipelines that rely on\nfixed pseudo-labels, our approach iteratively refines label confidences with an\nEM-inspired uncertainty measure. This ensures that the predictive model focuses\non reliable graph regions while gradually incorporating ambiguous nodes.\nInspired by prior work on uncertainty-aware self-training\ntechniques~\\cite{wang2024uncertainty}, our framework is designed to handle\nnoisy graph structures and feature spaces more effectively. Through extensive\nexperiments on several benchmark graph datasets, we demonstrate that our method\noutperforms strong baselines by a margin of up to 2.5\\% in accuracy while\nmaintaining lower variance in performance across multiple runs.", "published": "2025-03-26 21:52:21", "link": "http://arxiv.org/abs/2503.22744v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep Learning for Forensic Identification of Source", "abstract": "We used contrastive neural networks to learn useful similarity scores between\nthe 144 cartridge casings in the NBIDE dataset, under the common-but-unknown\nsource paradigm. The common-but-unknown source problem is a problem archetype\nin forensics where the question is whether two objects share a common source\n(e.g. were two cartridge casings fired from the same firearm). Similarity\nscores are often used to interpret evidence under this paradigm. We directly\ncompared our results to a state-of-the-art algorithm, Congruent Matching Cells\n(CMC). When trained on the E3 dataset of 2967 cartridge casings, contrastive\nlearning achieved an ROC AUC of 0.892. The CMC algorithm achieved 0.867. We\nalso conducted an ablation study where we varied the neural network\narchitecture; specifically, the network's width or depth. The ablation study\nshowed that contrastive network performance results are somewhat robust to the\nnetwork architecture. This work was in part motivated by the use of similarity\nscores attained via contrastive learning for standard evidence interpretation\nmethods such as score-based likelihood ratios.", "published": "2025-03-26 21:13:08", "link": "http://arxiv.org/abs/2503.20994v1", "categories": ["cs.LG", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reliable algorithm selection for machine learning-guided design", "abstract": "Algorithms for machine learning-guided design, or design algorithms, use\nmachine learning-based predictions to propose novel objects with desired\nproperty values. Given a new design task -- for example, to design novel\nproteins with high binding affinity to a therapeutic target -- one must choose\na design algorithm and specify any hyperparameters and predictive and/or\ngenerative models involved. How can these decisions be made such that the\nresulting designs are successful? This paper proposes a method for design\nalgorithm selection, which aims to select design algorithms that will produce a\ndistribution of design labels satisfying a user-specified success criterion --\nfor example, that at least ten percent of designs' labels exceed a threshold.\nIt does so by combining designs' predicted property values with held-out\nlabeled data to reliably forecast characteristics of the label distributions\nproduced by different design algorithms, building upon techniques from\nprediction-powered inference. The method is guaranteed with high probability to\nreturn design algorithms that yield successful label distributions (or the null\nset if none exist), if the density ratios between the design and labeled data\ndistributions are known. We demonstrate the method's effectiveness in simulated\nprotein and RNA design tasks, in settings with either known or estimated\ndensity ratios.", "published": "2025-03-26 17:52:19", "link": "http://arxiv.org/abs/2503.20767v1", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Continual learning via probabilistic exchangeable sequence modelling", "abstract": "Continual learning (CL) refers to the ability to continuously learn and\naccumulate new knowledge while retaining useful information from past\nexperiences. Although numerous CL methods have been proposed in recent years,\nit is not straightforward to deploy them directly to real-world decision-making\nproblems due to their computational cost and lack of uncertainty\nquantification. To address these issues, we propose CL-BRUNO, a probabilistic,\nNeural Process-based CL model that performs scalable and tractable Bayesian\nupdate and prediction. Our proposed approach uses deep-generative models to\ncreate a unified probabilistic framework capable of handling different types of\nCL problems such as task- and class-incremental learning, allowing users to\nintegrate information across different CL scenarios using a single model. Our\napproach is able to prevent catastrophic forgetting through distributional and\nfunctional regularisation without the need of retaining any previously seen\nsamples, making it appealing to applications where data privacy or storage\ncapacity is of concern. Experiments show that CL-BRUNO outperforms existing\nmethods on both natural image and biomedical data sets, confirming its\neffectiveness in real-world applications.", "published": "2025-03-26 17:08:20", "link": "http://arxiv.org/abs/2503.20725v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Diffusion Counterfactuals for Image Regressors", "abstract": "Counterfactual explanations have been successfully applied to create human\ninterpretable explanations for various black-box models. They are handy for\ntasks in the image domain, where the quality of the explanations benefits from\nrecent advances in generative models. Although counterfactual explanations have\nbeen widely applied to classification models, their application to regression\ntasks remains underexplored. We present two methods to create counterfactual\nexplanations for image regression tasks using diffusion-based generative models\nto address challenges in sparsity and quality: 1) one based on a Denoising\nDiffusion Probabilistic Model that operates directly in pixel-space and 2)\nanother based on a Diffusion Autoencoder operating in latent space. Both\nproduce realistic, semantic, and smooth counterfactuals on CelebA-HQ and a\nsynthetic data set, providing easily interpretable insights into the\ndecision-making process of the regression model and reveal spurious\ncorrelations. We find that for regression counterfactuals, changes in features\ndepend on the region of the predicted value. Large semantic changes are needed\nfor significant changes in predicted values, making it harder to find sparse\ncounterfactuals than with classifiers. Moreover, pixel space counterfactuals\nare more sparse while latent space counterfactuals are of higher quality and\nallow bigger semantic changes.", "published": "2025-03-26 14:42:46", "link": "http://arxiv.org/abs/2503.20595v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Theoretical Framework for Prompt Engineering: Approximating Smooth Functions with Transformer Prompts", "abstract": "Prompt engineering has emerged as a powerful technique for guiding large\nlanguage models (LLMs) toward desired responses, significantly enhancing their\nperformance across diverse tasks. Beyond their role as static predictors, LLMs\nincreasingly function as intelligent agents, capable of reasoning,\ndecision-making, and adapting dynamically to complex environments. However, the\ntheoretical underpinnings of prompt engineering remain largely unexplored. In\nthis paper, we introduce a formal framework demonstrating that transformer\nmodels, when provided with carefully designed prompts, can act as a\nconfigurable computational system by emulating a ``virtual'' neural network\nduring inference. Specifically, input prompts effectively translate into the\ncorresponding network configuration, enabling LLMs to adjust their internal\ncomputations dynamically. Building on this construction, we establish an\napproximation theory for $\\beta$-times differentiable functions, proving that\ntransformers can approximate such functions with arbitrary precision when\nguided by appropriately structured prompts. Moreover, our framework provides\ntheoretical justification for several empirically successful prompt engineering\ntechniques, including the use of longer, structured prompts, filtering\nirrelevant information, enhancing prompt token diversity, and leveraging\nmulti-agent interactions. By framing LLMs as adaptable agents rather than\nstatic models, our findings underscore their potential for autonomous reasoning\nand problem-solving, paving the way for more robust and theoretically grounded\nadvancements in prompt engineering and AI agent design.", "published": "2025-03-26 13:58:02", "link": "http://arxiv.org/abs/2503.20561v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Regression-Based Estimation of Causal Effects in the Presence of Selection Bias and Confounding", "abstract": "We consider the problem of estimating the expected causal effect $E[Y|do(X)]$\nfor a target variable $Y$ when treatment $X$ is set by intervention, focusing\non continuous random variables. In settings without selection bias or\nconfounding, $E[Y|do(X)] = E[Y|X]$, which can be estimated using standard\nregression methods. However, regression fails when systematic missingness\ninduced by selection bias, or confounding distorts the data. Boeken et al.\n[2023] show that when training data is subject to selection, proxy variables\nunaffected by this process can, under certain constraints, be used to correct\nfor selection bias to estimate $E[Y|X]$, and hence $E[Y|do(X)]$, reliably. When\ndata is additionally affected by confounding, however, this equality is no\nlonger valid.\n  Building on these results, we consider a more general setting and propose a\nframework that incorporates both selection bias and confounding. Specifically,\nwe derive theoretical conditions ensuring identifiability and recoverability of\ncausal effects under access to external data and proxy variables. We further\nintroduce a two-step regression estimator (TSR), capable of exploiting proxy\nvariables to adjust for selection bias while accounting for confounding. We\nshow that TSR coincides with prior work if confounding is absent, but achieves\na lower variance. Extensive simulation studies validate TSR's correctness for\nscenarios which may include both selection bias and confounding with proxy\nvariables.", "published": "2025-03-26 13:43:37", "link": "http://arxiv.org/abs/2503.20546v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Riemannian Optimization on Relaxed Indicator Matrix Manifold", "abstract": "The indicator matrix plays an important role in machine learning, but\noptimizing it is an NP-hard problem. We propose a new relaxation of the\nindicator matrix and prove that this relaxation forms a manifold, which we call\nthe Relaxed Indicator Matrix Manifold (RIM manifold). Based on Riemannian\ngeometry, we develop a Riemannian toolbox for optimization on the RIM manifold.\nSpecifically, we provide several methods of Retraction, including a fast\nRetraction method to obtain geodesics. We point out that the RIM manifold is a\ngeneralization of the double stochastic manifold, and it is much faster than\nexisting methods on the double stochastic manifold, which has a complexity of\n\\( \\mathcal{O}(n^3) \\), while RIM manifold optimization is \\( \\mathcal{O}(n) \\)\nand often yields better results. We conducted extensive experiments, including\nimage denoising, with millions of variables to support our conclusion, and\napplied the RIM manifold to Ratio Cut, achieving clustering results that\noutperform the state-of-the-art methods. Our Code in\n\\href{https://github.com/Yuan-Jinghui/Riemannian-Optimization-on-Relaxed-Indicator-Matrix-Manifold}{https://github.com/Yuan-Jinghui/Riemannian-Optimization-on-Relaxed-Indicator-Matrix-Manifold}.", "published": "2025-03-26 12:45:52", "link": "http://arxiv.org/abs/2503.20505v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Automated and Risk-Aware Engine Control Calibration Using Constrained Bayesian Optimization", "abstract": "Decarbonization of the transport sector sets increasingly strict demands to\nmaximize thermal efficiency and minimize greenhouse gas emissions of Internal\nCombustion Engines. This has led to complex engines with a surge in the number\nof corresponding tunable parameters in actuator set points and control\nsettings. Automated calibration is therefore essential to keep development time\nand costs at acceptable levels. In this work, an innovative self-learning\ncalibration method is presented based on in-cylinder pressure curve shaping.\nThis method combines Principal Component Decomposition with constrained\nBayesian Optimization. To realize maximal thermal engine efficiency, the\noptimization problem aims at minimizing the difference between the actual\nin-cylinder pressure curve and an Idealized Thermodynamic Cycle. By\ncontinuously updating a Gaussian Process Regression model of the pressure's\nPrincipal Components weights using measurements of the actual operating\nconditions, the mean in-cylinder pressure curve as well as its uncertainty\nbounds are learned. This information drives the optimization of calibration\nparameters, which are automatically adapted while dealing with the risks and\nuncertainties associated with operational safety and combustion stability. This\ndata-driven method does not require prior knowledge of the system. The proposed\nmethod is successfully demonstrated in simulation using a Reactivity Controlled\nCompression Ignition engine model. The difference between the Gross Indicated\nEfficiency of the optimal solution found and the true optimum is 0.017%. For\nthis complex engine, the optimal solution was found after 64.4s, which is\nrelatively fast compared to conventional calibration methods.", "published": "2025-03-26 12:32:53", "link": "http://arxiv.org/abs/2503.20493v1", "categories": ["eess.SY", "cs.SY", "stat.ML"], "primary_category": "eess.SY"}
{"title": "Data-driven Seasonal Climate Predictions via Variational Inference and Transformers", "abstract": "Most operational climate services providers base their seasonal predictions\non initialised general circulation models (GCMs) or statistical techniques that\nfit past observations. GCMs require substantial computational resources, which\nlimits their capacity. In contrast, statistical methods often lack robustness\ndue to short historical records. Recent works propose machine learning methods\ntrained on climate model output, leveraging larger sample sizes and simulated\nscenarios. Yet, many of these studies focus on prediction tasks that might be\nrestricted in spatial extent or temporal coverage, opening a gap with existing\noperational predictions. Thus, the present study evaluates the effectiveness of\na methodology that combines variational inference with transformer models to\npredict fields of seasonal anomalies. The predictions cover all four seasons\nand are initialised one month before the start of each season. The model was\ntrained on climate model output from CMIP6 and tested using ERA5 reanalysis\ndata. We analyse the method's performance in predicting interannual anomalies\nbeyond the climate change-induced trend. We also test the proposed methodology\nin a regional context with a use case focused on Europe. While climate change\ntrends dominate the skill of temperature predictions, the method presents\nadditional skill over the climatological forecast in regions influenced by\nknown teleconnections. We reach similar conclusions based on the validation of\nprecipitation predictions. Despite underperforming SEAS5 in most tropics, our\nmodel offers added value in numerous extratropical inland regions. This work\ndemonstrates the effectiveness of training generative models on climate model\noutput for seasonal predictions, providing skilful predictions beyond the\ninduced climate change trend at time scales and lead times relevant for user\napplications.", "published": "2025-03-26 11:51:23", "link": "http://arxiv.org/abs/2503.20466v2", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "primary_category": "physics.ao-ph"}
{"title": "Learning Data-Driven Uncertainty Set Partitions for Robust and Adaptive Energy Forecasting with Missing Data", "abstract": "Short-term forecasting models typically assume the availability of input data\n(features) when they are deployed and in use. However, equipment failures,\ndisruptions, cyberattacks, may lead to missing features when such models are\nused operationally, which could negatively affect forecast accuracy, and result\nin suboptimal operational decisions. In this paper, we use adaptive robust\noptimization and adversarial machine learning to develop forecasting models\nthat seamlessly handle missing data operationally. We propose linear- and\nneural network-based forecasting models with parameters that adapt to available\nfeatures, combining linear adaptation with a novel algorithm for learning\ndata-driven uncertainty set partitions. The proposed adaptive models do not\nrely on identifying historical missing data patterns and are suitable for\nreal-time operations under stringent time constraints. Extensive numerical\nexperiments on short-term wind power forecasting considering horizons from 15\nminutes to 4 hours ahead illustrate that our proposed adaptive models are on\npar with imputation when data are missing for very short periods (e.g., when\nonly the latest measurement is missing) whereas they significantly outperform\nimputation when data are missing for longer periods. We further provide\ninsights by showcasing how linear adaptation and data-driven partitions (even\nwith a few subsets) approach the performance of the optimal, yet impractical,\nmethod of retraining for every possible realization of missing data.", "published": "2025-03-26 10:38:56", "link": "http://arxiv.org/abs/2503.20410v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An $(\u03b5,\u03b4)$-accurate level set estimation with a stopping criterion", "abstract": "The level set estimation problem seeks to identify regions within a set of\ncandidate points where an unknown and costly to evaluate function's value\nexceeds a specified threshold, providing an efficient alternative to exhaustive\nevaluations of function values. Traditional methods often use sequential\noptimization strategies to find $\\epsilon$-accurate solutions, which permit a\nmargin around the threshold contour but frequently lack effective stopping\ncriteria, leading to excessive exploration and inefficiencies. This paper\nintroduces an acquisition strategy for level set estimation that incorporates a\nstopping criterion, ensuring the algorithm halts when further exploration is\nunlikely to yield improvements, thereby reducing unnecessary function\nevaluations. We theoretically prove that our method satisfies\n$\\epsilon$-accuracy with a confidence level of $1 - \\delta$, addressing a key\ngap in existing approaches. Furthermore, we show that this also leads to\nguarantees on the lower bounds of performance metrics such as F-score.\nNumerical experiments demonstrate that the proposed acquisition function\nachieves comparable precision to existing methods while confirming that the\nstopping criterion effectively terminates the algorithm once adequate\nexploration is completed.", "published": "2025-03-26 06:41:07", "link": "http://arxiv.org/abs/2503.20272v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Revisit Time Series Classification Benchmark: The Impact of Temporal Information for Classification", "abstract": "Time series classification is usually regarded as a distinct task from\ntabular data classification due to the importance of temporal information.\nHowever, in this paper, by performing permutation tests that disrupt temporal\ninformation on the UCR time series classification archive, the most widely used\nbenchmark for time series classification, we identify a significant proportion\nof datasets where temporal information has little to no impact on\nclassification. Many of these datasets are tabular in nature or rely mainly on\ntabular features, leading to potentially biased evaluations of time series\nclassifiers focused on temporal information. To address this, we propose UCR\nAugmented, a benchmark based on the UCR time series classification archive\ndesigned to evaluate classifiers' ability to extract and utilize temporal\ninformation. Testing classifiers from seven categories on this benchmark\nrevealed notable shifts in performance rankings. Some previously overlooked\napproaches perform well, while others see their performance decline\nsignificantly when temporal information is crucial. UCR Augmented provides a\nmore robust framework for assessing time series classifiers, ensuring fairer\nevaluations. Our code is available at\nhttps://github.com/YunruiZhang/Revisit-Time-Series-Classification-Benchmark.", "published": "2025-03-26 06:13:41", "link": "http://arxiv.org/abs/2503.20264v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nonparametric MLE for Gaussian Location Mixtures: Certified Computation and Generic Behavior", "abstract": "We study the nonparametric maximum likelihood estimator $\\widehat{\\pi}$ for\nGaussian location mixtures in one dimension. It has been known since (Lindsay,\n1983) that given an $n$-point dataset, this estimator always returns a mixture\nwith at most $n$ components, and more recently (Wu-Polyanskiy, 2020) gave a\nsharp $O(\\log n)$ bound for subgaussian data. In this work we study\ncomputational aspects of $\\widehat{\\pi}$. We provide an algorithm which for\nsmall enough $\\varepsilon>0$ computes an $\\varepsilon$-approximation of\n$\\widehat\\pi$ in Wasserstein distance in time $K+Cnk^2\\log\\log(1/\\varepsilon)$.\nHere $K$ is data-dependent but independent of $\\varepsilon$, while $C$ is an\nabsolute constant and $k=|supp(\\widehat{\\pi})|\\leq n$ is the number of atoms in\n$\\widehat\\pi$. We also certifiably compute the exact value of\n$|supp(\\widehat\\pi)|$ in finite time. These guarantees hold almost surely\nwhenever the dataset $(x_1,\\dots,x_n)\\in [-cn^{1/4},cn^{1/4}]$ consists of\nindependent points from a probability distribution with a density (relative to\nLebesgue measure). We also show the distribution of $\\widehat\\pi$ conditioned\nto be $k$-atomic admits a density on the associated $2k-1$ dimensional\nparameter space for all $k\\leq \\sqrt{n}/3$, and almost sure locally linear\nconvergence of the EM algorithm. One key tool is a classical Fourier analytic\nestimate for non-degenerate curves.", "published": "2025-03-26 03:36:36", "link": "http://arxiv.org/abs/2503.20193v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "On the Robustness of Kernel Ridge Regression Using the Cauchy Loss Function", "abstract": "Robust regression aims to develop methods for estimating an unknown\nregression function in the presence of outliers, heavy-tailed distributions, or\ncontaminated data, which can severely impact performance. Most existing\ntheoretical results in robust regression assume that the noise has a finite\nabsolute mean, an assumption violated by certain distributions, such as Cauchy\nand some Pareto noise. In this paper, we introduce a generalized Cauchy noise\nframework that accommodates all noise distributions with finite moments of any\norder, even when the absolute mean is infinite. Within this framework, we study\nthe \\textit{kernel Cauchy ridge regressor} (\\textit{KCRR}), which minimizes a\nregularized empirical Cauchy risk to achieve robustness. To derive the\n$L_2$-risk bound for KCRR, we establish a connection between the excess Cauchy\nrisk and $L_2$-risk for sufficiently large scale parameters of the Cauchy loss,\nwhich reveals that these two risks are equivalent. Furthermore, under the\nassumption that the regression function satisfies H\\\"older smoothness, we\nderive excess Cauchy risk bounds for KCRR, showing improved performance as the\nscale parameter decreases. By considering the twofold effect of the scale\nparameter on the excess Cauchy risk and its equivalence with the $L_2$-risk, we\nestablish the almost minimax-optimal convergence rate for KCRR in terms of\n$L_2$-risk, highlighting the robustness of the Cauchy loss in handling various\ntypes of noise. Finally, we validate the effectiveness of KCRR through\nexperiments on both synthetic and real-world datasets under diverse noise\ncorruption scenarios.", "published": "2025-03-26 00:00:53", "link": "http://arxiv.org/abs/2503.20120v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Improving Speech Recognition Accuracy Using Custom Language Models with the Vosk Toolkit", "abstract": "Although speech recognition algorithms have developed quickly in recent\nyears, achieving high transcription accuracy across diverse audio formats and\nacoustic environments remains a major challenge. This work explores how\nincorporating custom language models with the open-source Vosk Toolkit can\nimprove speech-to-text accuracy in varied settings. Unlike many conventional\nsystems limited to specific audio types, this approach supports multiple audio\nformats such as WAV, MP3, FLAC, and OGG by using Python modules for\npreprocessing and format conversion.\n  A Python-based transcription pipeline was developed to process input audio,\nperform speech recognition using Vosk's KaldiRecognizer, and export the output\nto a DOCX file. Results showed that custom models reduced word error rates,\nespecially in domain-specific scenarios involving technical terminology, varied\naccents, or background noise. This work presents a cost-effective, offline\nsolution for high-accuracy transcription and opens up future opportunities for\nautomation and real-time applications.", "published": "2025-03-26 22:20:48", "link": "http://arxiv.org/abs/2503.21025v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "I.2.7; H.5.2"], "primary_category": "cs.SD"}
{"title": "Text-Driven Voice Conversion via Latent State-Space Modeling", "abstract": "Text-driven voice conversion allows customization of speaker characteristics\nand prosodic elements using textual descriptions. However, most existing\nmethods rely heavily on direct text-to-speech training, limiting their\nflexibility in controlling nuanced style elements or timbral features. In this\npaper, we propose a novel \\textbf{Latent State-Space} approach for text-driven\nvoice conversion (\\textbf{LSS-VC}). Our method treats each utterance as an\nevolving dynamical system in a continuous latent space. Drawing inspiration\nfrom mamba, which introduced a state-space model for efficient text-driven\n\\emph{image} style transfer, we adapt a loosely related methodology for\n\\emph{voice} style transformation. Specifically, we learn a voice latent\nmanifold where style and content can be manipulated independently by textual\nstyle prompts. We propose an adaptive cross-modal fusion mechanism to inject\nstyle information into the voice latent representation, enabling interpretable\nand fine-grained control over speaker identity, speaking rate, and emphasis.\nExtensive experiments show that our approach significantly outperforms recent\nbaselines in both subjective and objective quality metrics, while offering\nsmoother transitions between styles, reduced artifacts, and more precise\ntext-based style control.", "published": "2025-03-26 21:30:29", "link": "http://arxiv.org/abs/2503.20999v1", "categories": ["cs.SD", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising", "abstract": "In this paper, we introduce zero-shot audio-video editing, a novel task that\nrequires transforming original audio-visual content to align with a specified\ntextual prompt without additional model training. To evaluate this task, we\ncurate a benchmark dataset, AvED-Bench, designed explicitly for zero-shot\naudio-video editing. AvED-Bench includes 110 videos, each with a 10-second\nduration, spanning 11 categories from VGGSound. It offers diverse prompts and\nscenarios that require precise alignment between auditory and visual elements,\nenabling robust evaluation. We identify limitations in existing zero-shot audio\nand video editing methods, particularly in synchronization and coherence\nbetween modalities, which often result in inconsistent outcomes. To address\nthese challenges, we propose AvED, a zero-shot cross-modal delta denoising\nframework that leverages audio-video interactions to achieve synchronized and\ncoherent edits. AvED demonstrates superior results on both AvED-Bench and the\nrecent OAVE dataset to validate its generalization capabilities. Results are\navailable at https://genjib.github.io/project_page/AVED/index.html", "published": "2025-03-26 17:59:04", "link": "http://arxiv.org/abs/2503.20782v1", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Benchmarking Machine Learning Methods for Distributed Acoustic Sensing", "abstract": "Distributed acoustic sensing (DAS) technology represents an innovative\nfiber-optic-based sensing methodology that enables real-time acoustic signal\nmonitoring through the detection of minute perturbations along optical fibers.\nThis sensing approach offers compelling advantages, including extensive\nmeasurement ranges, exceptional spatial resolution, and an expansive dynamic\nmeasurement spectrum.\n  The integration of machine learning (ML) paradigms presents transformative\npotential for DAS technology, encompassing critical domains such as data\naugmentation, sophisticated preprocessing techniques, and advanced acoustic\nevent classification and recognition. By leveraging ML algorithms, DAS systems\ncan transition from traditional data processing methodologies to more automated\nand intelligent analytical frameworks.\n  The computational intelligence afforded by ML-enhanced DAS technologies\nfacilitates unprecedented monitoring capabilities across diverse critical\ninfrastructure sectors. Particularly noteworthy are the technology's\napplications in transportation infrastructure, energy management systems, and\nNatural disaster monitoring frameworks, where the precision of data acquisition\nand the reliability of intelligent decision-making mechanisms are paramount.\n  This research critically examines the comparative performance characteristics\nof classical machine learning methodologies and state-of-the-art deep learning\nmodels in the context of DAS data recognition and interpretation, offering\ncomprehensive insights into the evolving landscape of intelligent sensing\ntechnologies.", "published": "2025-03-26 16:17:22", "link": "http://arxiv.org/abs/2503.20681v1", "categories": ["eess.AS", "cs.CV", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System", "abstract": "In this work, we propose a high-quality streaming foundation text-to-speech\nsystem, FireRedTTS-1S, upgraded from the streamable version of FireRedTTS.\nFireRedTTS-1S achieves streaming generation via two steps: text-to-semantic\ndecoding and semantic-to-acoustic decoding. In text-to-semantic decoding, a\nsemantic-aware speech tokenizer converts the speech signal into semantic\ntokens, which can be synthesized from the text via a semantic language model in\nan auto-regressive manner. Meanwhile, the semantic-to-acoustic decoding module\nsimultaneously translates generated semantic tokens into the speech signal in a\nstreaming way via a super-resolution causal audio codec and a multi-stream\nacoustic language model. This design enables us to produce high-quality speech\naudio in zero-shot settings while presenting a real-time generation process\nwith low latency under 150ms. In experiments on zero-shot voice cloning, the\nobjective results validate FireRedTTS-1S as a high-quality foundation model\nwith comparable intelligibility and speaker similarity over industrial baseline\nsystems. Furthermore, the subjective score of FireRedTTS-1S highlights its\nimpressive synthesis performance, achieving comparable quality to the\nground-truth recordings. These results validate FireRedTTS-1S as a high-quality\nstreaming foundation TTS system.", "published": "2025-03-26 12:39:06", "link": "http://arxiv.org/abs/2503.20499v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hierarchical Label Propagation: A Model-Size-Dependent Performance Booster for AudioSet Tagging", "abstract": "AudioSet is one of the most used and largest datasets in audio tagging,\ncontaining about 2 million audio samples that are manually labeled with 527\nevent categories organized into an ontology. However, the annotations contain\ninconsistencies, particularly where categories that should be labeled as\npositive according to the ontology are frequently mislabeled as negative. To\naddress this issue, we apply Hierarchical Label Propagation (HLP), which\npropagates labels up the ontology hierarchy, resulting in a mean increase in\npositive labels per audio clip from 1.98 to 2.39 and affecting 109 out of the\n527 classes. Our results demonstrate that HLP provides performance benefits\nacross various model architectures, including convolutional neural networks\n(PANN's CNN6 and ConvNeXT) and transformers (PaSST), with smaller models\nshowing more improvements. Finally, on FSD50K, another widely used dataset,\nmodels trained on AudioSet with HLP consistently outperformed those trained\nwithout HLP. Our source code will be made available on GitHub.", "published": "2025-03-26 08:45:43", "link": "http://arxiv.org/abs/2503.21826v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dual Audio-Centric Modality Coupling for Talking Head Generation", "abstract": "The generation of audio-driven talking head videos is a key challenge in\ncomputer vision and graphics, with applications in virtual avatars and digital\nmedia. Traditional approaches often struggle with capturing the complex\ninteraction between audio and facial dynamics, leading to lip synchronization\nand visual quality issues. In this paper, we propose a novel NeRF-based\nframework, Dual Audio-Centric Modality Coupling (DAMC), which effectively\nintegrates content and dynamic features from audio inputs. By leveraging a dual\nencoder structure, DAMC captures semantic content through the Content-Aware\nEncoder and ensures precise visual synchronization through the Dynamic-Sync\nEncoder. These features are fused using a Cross-Synchronized Fusion Module\n(CSFM), enhancing content representation and lip synchronization. Extensive\nexperiments show that our method outperforms existing state-of-the-art\napproaches in key metrics such as lip synchronization accuracy and image\nquality, demonstrating robust generalization across various audio inputs,\nincluding synthetic speech from text-to-speech (TTS) systems. Our results\nprovide a promising solution for high-quality, audio-driven talking head\ngeneration and present a scalable approach for creating realistic talking\nheads.", "published": "2025-03-26 06:46:51", "link": "http://arxiv.org/abs/2503.22728v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RIS-Enabled Self-Localization with FMCW Radar", "abstract": "In the upcoming vehicular networks, reconfigurable intelligent surfaces\n(RISs) are considered as a key enabler of user self-localization without the\nintervention of the access points (APs). In this paper, we investigate the\nfeasibility of RIS-enabled self-localization with no APs. We first develop a\ndigital signal processing (DSP) unit for estimating the geometric parameters\nsuch as the angle, distance, and velocity and for RIS-enabled\nself-localization. Second, we set up an experimental testbed consisting of a\nTexas Instrument frequency modulated continuous wave (FMCW) radar for the user\nand SilversIMA module for the RIS. Our results confirm the validity of the\ndeveloped DSP unit and demonstrate the feasibility of RIS-enabled\nself-localization.", "published": "2025-03-26 22:11:52", "link": "http://arxiv.org/abs/2503.21021v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Filtered Multi-Tone Spread Spectrum with Overlapping Subbands", "abstract": "A new form of the filter bank multi-carrier spread spectrum (FBMC-SS)\nwaveform is presented. This new waveform modifies the filtered multi-tone\nspread spectrum (FMT-SS) system, and is intended to whiten the power spectral\ndensity (PSD) of the transmit signal. In the conventional FMT-SS, subcarrier\nbands are non-overlapping, leaving a spectral null between the adjacent\nsubcarrier bands. To make FMT-SS more appealing for a broader set of\napplications than those studied in the past, we propose adding additional\nsubcarriers centered at these nulls and thoroughly explore the impact of the\nadded subcarriers on the system performance. This modified form of FMT-SS is\nreferred to as overlapped FMT-SS (OFMT-SS). We explore the conditions required\nfor maximally flattening the PSD of the synthesized OFMT-SS signal and for\ncancelling the interference caused by overlapping subbands. We also explore the\nchoices of spreading gains that result in a low peak-to-average power ratio\n(PAPR) for a number of different scenarios. Further reduction of the PAPR of\nthe synthesized signal through clipping methods is also explored. Additionally,\nwe propose methods of multi-coding for increasing the data rate of the OFMT-SS\nwaveform, while minimally impacting its PAPR.", "published": "2025-03-26 20:09:54", "link": "http://arxiv.org/abs/2503.20966v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Low-complexity Structured Neural Network Approach to Intelligently Realize Wideband Multi-beam Beamformers", "abstract": "True-time-delay (TTD) beamformers can produce wideband, squint-free beams in\nboth analog and digital signal domains, unlike frequency-dependent FFT beams.\nOur previous work showed that TTD beamformers can be efficiently realized using\nthe elements of delay Vandermonde matrix (DVM), answering the longstanding\nbeam-squint problem. Thus, building on our work on classical algorithms based\non DVM, we propose neural network (NN) architecture to realize wideband\nmulti-beam beamformers using structure-imposed weight matrices and submatrices.\nThe structure and sparsity of the weight matrices and submatrices are shown to\nreduce the space and computational complexities of the NN greatly. The proposed\nnetwork architecture has O(pLM logM) complexity compared to a conventional\nfully connected L-layers network with O(M2L) complexity, where M is the number\nof nodes in each layer of the network, p is the number of submatrices per\nlayer, and M >> p. We will show numerical simulations in the 24 GHz to 32 GHz\nrange to demonstrate the numerical feasibility of realizing wideband multi-beam\nbeamformers using the proposed neural architecture. We also show the complexity\nreduction of the proposed NN and compare that with fully connected NNs, to show\nthe efficiency of the proposed architecture without sacrificing accuracy. The\naccuracy of the proposed NN architecture was shown using the mean squared\nerror, which is based on an objective function of the weight matrices and\nbeamformed signals of antenna arrays, while also normalizing nodes. The\nproposed NN architecture shows a low-complexity NN realizing wideband\nmulti-beam beamformers in real-time for low-complexity intelligent systems.", "published": "2025-03-26 16:25:32", "link": "http://arxiv.org/abs/2503.20694v1", "categories": ["cs.LG", "eess.SP", "I.5.1; I.5.2; G.1.3"], "primary_category": "cs.LG"}
{"title": "Impact of Network-Controlled Repeaters in Integrated Sensing and Communication Systems", "abstract": "Integrating sensing capabilities into existing massive MIMO communication\nnetworks has become crucial, stemming from a need for a more interconnected\nsociety. Improved coverage and performance can be obtained by incorporating new\nnetwork components, such as reconfigurable intelligent surfaces or\nnetwork-controlled repeaters (NCR). Integrating such components into modern\nnetworks brings a number of challenges. Thus, this paper contributes with the\nanalysis of NCR impact in integrated sensing and communication networks.\nParticularly, the Cram\\'er-Rao bound for a range estimator is derived where the\ninterference from the repeater is taken into consideration. Additionally, a\njoint procedure for determining the repeater amplification factor, along with\nthe precoders of the transmitting access point, is proposed.", "published": "2025-03-26 15:07:04", "link": "http://arxiv.org/abs/2503.20617v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Towards Practical Emotion Recognition: An Unsupervised Source-Free Approach for EEG Domain Adaptation", "abstract": "Emotion recognition is crucial for advancing mental health, healthcare, and\ntechnologies like brain-computer interfaces (BCIs). However, EEG-based emotion\nrecognition models face challenges in cross-domain applications due to the high\ncost of labeled data and variations in EEG signals from individual differences\nand recording conditions. Unsupervised domain adaptation methods typically\nrequire access to source domain data, which may not always be feasible in\nreal-world scenarios due to privacy and computational constraints. Source-free\nunsupervised domain adaptation (SF-UDA) has recently emerged as a solution,\nenabling target domain adaptation without source data, but its application in\nemotion recognition remains unexplored. We propose a novel SF-UDA approach for\nEEG-based emotion classification across domains, introducing a multi-stage\nframework that enhances model adaptability without requiring source data. Our\napproach incorporates Dual-Loss Adaptive Regularization (DLAR) to minimize\nprediction discrepancies on confident samples and align predictions with\nexpected pseudo-labels. Additionally, we introduce Localized Consistency\nLearning (LCL), which enforces local consistency by promoting similar\npredictions from reliable neighbors. These techniques together address domain\nshift and reduce the impact of noisy pseudo-labels, a key challenge in\ntraditional SF-UDA models. Experiments on two widely used datasets, DEAP and\nSEED, demonstrate the effectiveness of our method. Our approach significantly\noutperforms state-of-the-art methods, achieving 65.84% accuracy when trained on\nDEAP and tested on SEED, and 58.99% accuracy in the reverse scenario. It excels\nat detecting both positive and negative emotions, making it well-suited for\npractical emotion recognition applications.", "published": "2025-03-26 14:29:20", "link": "http://arxiv.org/abs/2504.03707v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "A multi-scale lithium-ion battery capacity prediction using mixture of experts and patch-based MLP", "abstract": "Lithium-ion battery health management has become increasingly important as\nthe application of batteries expands. Precise forecasting of capacity\ndegradation is critical for ensuring the healthy usage of batteries. In this\npaper, we innovatively propose MSPMLP, a multi-scale capacity prediction model\nutilizing the mixture of experts (MoE) architecture and patch-based multi-layer\nperceptron (MLP) blocks, to capture both the long-term degradation trend and\nlocal capacity regeneration phenomena. Specifically, we utilize patch-based MLP\nblocks with varying patch sizes to extract multi-scale features from the\ncapacity sequence. Leveraging the MoE architecture, the model adaptively\nintegrates the extracted features, thereby enhancing its capacity and\nexpressiveness. Finally, the future battery capacity is predicted based on the\nintegrated features, achieving high prediction accuracy and generalization.\nExperimental results on the public NASA dataset indicate that MSPMLP achieves a\nmean absolute error (MAE) of 0.0078, improving by 41.8\\% compared to existing\nmethods. These findings highlight that MSPMLP, owing to its multi-scale\nmodeling capability and generalizability, provides a promising solution to the\nbattery capacity prediction challenges caused by capacity regeneration\nphenomena and complex usage conditions. The code of this work is provided at\nhttps://github.com/LeiYuzhu/CapacityPredict.", "published": "2025-03-26 13:59:48", "link": "http://arxiv.org/abs/2504.03706v1", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Channel impulse response peak clustering using neural networks", "abstract": "This paper introduces an approach to process channel sounder data acquired\nfrom Channel Impulse Response (CIR) of 60GHz and 80GHz channel sounder systems,\nthrough the integration of Long Short-Term Memory (LSTM) Neural Network (NN)\nand Fully Connected Neural Network (FCNN). The primary goal is to enhance and\nautomate cluster detection within peaks from noised CIR data. The study\ninitially compares the performance of LSTM NN and FCNN across different input\nsequence lengths. Notably, LSTM surpasses FCNN due to its incorporation of\nmemory cells, which prove beneficial for handling longer series.Additionally,\nthe paper investigates the robustness of LSTM NN through various architectural\nconfigurations. The findings suggest that robust neural networks tend to\nclosely mimic the input function, whereas smaller neural networks are better at\ngeneralizing trends in time series data, which is desirable for anomaly\ndetection, where function peaks are regarded as anomalies.Finally, the selected\nLSTM NN is compared with traditional signal filters, including Butterworth,\nSavitzky-Golay, Bessel/Thomson, and median filters. Visual observations\nindicate that the most effective methods for peak detection within channel\nimpulse response data are either the LSTM NN or median filter, as they yield\nsimilar results.", "published": "2025-03-26 12:12:01", "link": "http://arxiv.org/abs/2503.20838v1", "categories": ["eess.SP", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring", "abstract": "Semiconductor devices, especially MOSFETs (Metal-oxide-semiconductor\nfield-effect transistor), are crucial in power electronics, but their\nreliability is affected by aging processes influenced by cycling and\ntemperature. The primary aging mechanism in discrete semiconductors and power\nmodules is the bond wire lift-off, caused by crack growth due to thermal\nfatigue. The process is empirically characterized by exponential growth and an\nabrupt end of life, making long-term aging forecasts challenging. This research\npresents a comprehensive comparative assessment of different forecasting\nmethods for MOSFET failure forecasting applications. Classical tracking,\nstatistical forecasting and Neural Network (NN) based forecasting models are\nimplemented along with novel Temporal Fusion Transformers (TFTs). A\ncomprehensive comparison is performed assessing their MOSFET ageing forecasting\nability for different forecasting horizons. For short-term predictions, all\nalgorithms result in acceptable results, with the best results produced by\nclassical NN forecasting models at the expense of higher computations. For\nlong-term forecasting, only the TFT is able to produce valid outcomes owing to\nthe ability to integrate covariates from the expected future conditions.\nAdditionally, TFT attention points identify key ageing turning points, which\nindicate new failure modes or accelerated ageing phases.", "published": "2025-03-26 10:24:20", "link": "http://arxiv.org/abs/2503.20403v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "UnReference: analysis of the effect of spoofing on RTK reference stations for connected rovers", "abstract": "Global Navigation Satellite Systems (GNSS) provide standalone precise\nnavigation for a wide gamut of applications. Nevertheless, applications or\nsystems such as unmanned vehicles (aerial or ground vehicles and surface\nvessels) generally require a much higher level of accuracy than those provided\nby standalone receivers. The most effective and economical way of achieving\ncentimeter-level accuracy is to rely on corrections provided by fixed\n\\emph{reference station} receivers to improve the satellite ranging\nmeasurements. Differential GNSS (DGNSS) and Real Time Kinematics (RTK) provide\ncentimeter-level accuracy by distributing online correction streams to\nconnected nearby mobile receivers typically termed \\emph{rovers}. However, due\nto their static nature, reference stations are prime targets for GNSS attacks,\nboth simplistic jamming and advanced spoofing, with different levels of\nadversarial control and complexity. Jamming the reference station would deny\ncorrections and thus accuracy to the rovers. Spoofing the reference station\nwould force it to distribute misleading corrections. As a result, all connected\nrovers using those corrections will be equally influenced by the adversary\nindependently of their actual trajectory. We evaluate a battery of tests\ngenerated with an RF simulator to test the robustness of a common DGNSS/RTK\nprocessing library and receivers. We test both jamming and synchronized\nspoofing to demonstrate that adversarial action on the rover using reference\nspoofing is both effective and convenient from an adversarial perspective.\nAdditionally, we discuss possible strategies based on existing countermeasures\n(self-validation of the PNT solution and monitoring of own clock drift) that\nthe rover and the reference station can adopt to avoid using or distributing\nbogus corrections.", "published": "2025-03-26 09:40:19", "link": "http://arxiv.org/abs/2503.20364v1", "categories": ["cs.CR", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Comparative analysis of clustering methods for power delay profile in MMW bands and in-vehicle scenarios", "abstract": "The spatial statistics of radio wave propagation in specific environments and\nscenarios, as well as being able to recognize important signal components, are\nprerequisites for dependable connectivity. There are several reasons why\nin-vehicle communication is unique, including safety considerations and\nvehicle-to-vehicle/infrastructure communication.The paper examines the\ncharacteristics of clustering power delay profiles to investigate in-vehicle\ncommunication. It has been demonstrated that the Saleh-Valenzuela channel model\ncan also be adapted for in-vehicle communication, and that the signal is\nreceived in clusters with exponential decay. A measurement campaign was\nconducted, capturing the power delay profile inside the vehicle cabin, and the\nreweighted l1 minimization method was compared with the traditional k-means\nclustering techniques.", "published": "2025-03-26 09:36:24", "link": "http://arxiv.org/abs/2503.20358v1", "categories": ["eess.SP", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "GNSS jammer localization and identification with airborne commercial GNSS receivers", "abstract": "Global Navigation Satellite Systems (GNSS) are fundamental in ubiquitously\nproviding position and time to a wide gamut of systems. Jamming remains a\nrealistic threat in many deployment settings, civilian and tactical.\nSpecifically, in Unmanned Aerial Vehicles (UAVs) sustained denial raises safety\ncritical concerns. This work presents a strategy that allows detection,\nlocalization, and classification both in the frequency and time domain of\ninterference signals harmful to navigation. A high-performance Vertical Take\nOff and Landing (VTOL) UAV with a single antenna and a commercial GNSS receiver\nis used to geolocate and characterize RF emitters at long range, to infer the\nnavigation impairment. Raw IQ baseband snapshots from the GNSS receiver make\nthe application of spectral correlation methods possible without extra\nsoftware-defined radio payload, paving the way to spectrum identification and\nmonitoring in airborne platforms, aiming at RF situational awareness. Live\ntesting at Jammertest, in Norway, with portable, commercially available GNSS\nmulti-band jammers demonstrates the ability to detect, localize, and\ncharacterize harmful interference. Our system pinpointed the position with an\nerror of a few meters of the transmitter and the extent of the affected area at\nlong range, without entering the denied zone. Additionally, further spectral\ncontent extraction is used to accurately identify the jammer frequency,\nbandwidth, and modulation scheme based on spectral correlation techniques.", "published": "2025-03-26 09:23:08", "link": "http://arxiv.org/abs/2503.20352v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Phase-Center-Constrained Beamforming for Minimizing Phase-Center Displacement", "abstract": "Accurate knowledge and control of the phase center in antenna arrays is\nessential for high-precision applications such as Global Navigation Satellite\nSystems (GNSS), where even small displacements can introduce significant\nlocalization errors. Traditional beamforming techniques applied to array\nantennas often neglect the variation of the phase center, resulting in unwanted\nspatial shifts, and in consequence, localization errors. In this work, we\npropose a novel beamforming algorithm, called Phase-Center-Constrained\nBeamforming (PCCB), which explicitly minimizes the displacement of the phase\ncenter (Phase Center Offset, PCO) while preserving a chosen directional gain.\nWe formulate the problem as a constrained optimization problem and incorporate\nregularization terms that enforce energy compactness and beampattern fidelity.\nThe resulting PCCB approach allows for directional gain control and\ninterference nulling while significantly reducing PCO displacement.\nExperimental validation using a simulated GNSS antenna array demonstrates that\nour PCCB approach achieves a fivefold reduction in PCO shift compared to the\nPCO shifts obtained when using conventional beamforming. A stability analysis\nacross multiple random initializations confirms the robustness of our method\nand highlights the benefit of repeated optimization. These results indicate\nthat our PCCB approach can serve as a practical and effective solution for\ndecreasing phase center variability.", "published": "2025-03-26 08:58:33", "link": "http://arxiv.org/abs/2503.20333v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Derivation and analysis of power offset in fiber-longitudinal power profile estimation using pre-FEC hard-decision data", "abstract": "Utilizing the precise reference waveform regenerated by post-forward error\ncorrection (FEC) data, the fiber-longitudinal power profile estimation based on\nthe minimum-mean-square-error method (MMSE-PPE) has been validated as an\neffective tool for absolute power monitoring. However, when post-FEC data is\nunavailable, it becomes necessary to rely on pre-FEC hard-decision data, which\ninevitably introduces hard-decision errors. These hard-decision errors will\nresult in a power offset that undermines the accuracy of absolute power\nmonitoring. In this paper, we present the first analytical expression for power\noffset in MMSE-PPE when using pre-FEC hard-decision data, achieved by\nintroducing a virtual hard-decision nonlinear perturbation term. Based on this\nanalytical expression, we also establish the first nonlinear relationship\nbetween the power offset and the symbol error rate (SER) of M-ary quadrature\namplitude modulation (M-QAM) formats based on Gaussian assumptions. Verified in\na numerical 130-GBaud single-wavelength coherent optical fiber transmission\nsystem, the correctness of the analytical expression of power offset has been\nconfirmed with 4-QAM, 16-QAM, and 64-QAM formats under different SER\nsituations. Furthermore, the nonlinear relationship between the power offset\nand SER of $M$-QAM formats has also been thoroughly validated under both linear\nscale (measured in mW) and logarithmic scale (measured in dB). These\ntheoretical insights offer significant contributions to the design of potential\npower offset mitigation strategies in MMSE-PPE, thereby enhancing its real-time\napplication.", "published": "2025-03-26 08:45:16", "link": "http://arxiv.org/abs/2503.20323v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimal One- and Two-Sided Multi-Level ASK for Noncoherent SIMO Systems Over Correlated Rician Fading", "abstract": "This paper analyzes the performance of a single-input multiple-output (SIMO)\nwireless communication system employing one- and two-sided amplitude shift\nkeying (ASK) modulation schemes for data transmission and operating under\ncorrelated Rician fading channels. The receiver deploys an optimal noncoherent\nmaximum likelihood detector, which exploits statistical knowledge of the\nchannel state information for signal decoding. An optimal receiver structure is\nderived, from which series-form and closed-form expressions for the union bound\non the symbol error probability (SEP) are obtained for general and massive SIMO\nsystems, respectively. Furthermore, an optimization framework to derive the\noptimal one- and two-sided ASK modulation schemes is proposed, which focuses on\nminimizing SEP performance under an average transmit energy constraint. The\nconducted numerical investigations for various system parameters demonstrate\nthat the proposed noncoherent SIMO system with the designed optimal ASK\nmodulation schemes achieves superior error performance compared to traditional\nequispaced ASK modulation. It is also shown that, when the proposed system\nemploys traditional two-sided ASK modulation, superior error performance from\nthe case of using one-sided ASK is obtained.", "published": "2025-03-26 07:34:24", "link": "http://arxiv.org/abs/2503.20293v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Impact of the Pilot Design for OFDM Based Bi-static Integrated Sensing and Communication System", "abstract": "A bistatic milimeter-wave (mmWave) ISAC system utilizing OFDM signaling is\nconsidered. For a single-target scnenario, closed-form expressions for the\nCramer-Rao bounds (CRBs) of range and velocity estimation are derived for a\ngiven pilot pattern. The analysis shows that when the target's range and\nvelocity remain within the maximum unambiguous limits, allocating pilot symbols\nmore frequently in time improves position estimation, while increasing their\ndensity in frequency enhances velocity estimation. Numerical results further\nvalidate that the least squares (LS) channel estimation approach closely\nfollows CRB predictions, particularly in the high-SNR regime.", "published": "2025-03-26 07:31:41", "link": "http://arxiv.org/abs/2503.20288v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field THz Bending Beamforming: A Convex Optimization Perspective", "abstract": "Terahertz (THz) communication systems suffer severe blockage issues, which\nmay significantly degrade the communication coverage and quality. Bending\nbeams, capable of adjusting their propagation direction to bypass obstacles,\nhave recently emerged as a promising solution to resolve this issue by\nengineering the propagation trajectory of the beam. However, traditional\nbending beam generation methods rely heavily on the specific geometric\nproperties of the propagation trajectory and can only achieve sub-optimal\nperformance. In this paper, we propose a new and general bending beamforming\nmethod by adopting the convex optimization techniques. In particular, we\nformulate the bending beamforming design as a max-min optimization problem,\naiming to optimize the analog or digital transmit beamforming vector to\nmaximize the minimum received signal power among all positions along the\nbending beam trajectory. However, the resulting problem is non-convex and\ndifficult to be solved optimally. To tackle this difficulty, we apply the\nsuccessive convex approximation (SCA) technique to obtain a high-quality\nsuboptimal solution. Numerical results show that our proposed bending\nbeamforming method outperforms the traditional method and shows robustness to\nthe obstacle in the environment.", "published": "2025-03-26 06:47:52", "link": "http://arxiv.org/abs/2503.20274v4", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sequential Task Assignment and Resource Allocation in V2X-Enabled Mobile Edge Computing", "abstract": "Nowadays, the convergence of Mobile Edge Computing (MEC) and vehicular\nnetworks has emerged as a vital facilitator for the ever-increasing intelligent\nonboard applications. This paper introduces a multi-tier task offloading\nmechanism for MEC-enabled vehicular networks leveraging vehicle-to-everything\n(V2X) communications. The study focuses on applications with sequential\nsubtasks and explores two tiers of collaboration. In the vehicle tier, we\ndesign a needing vehicle (NV)-helping vehicle (HV) matching scheme and\ninter-vehicle collaborative computation is studied, with joint optimization of\ntask offloading decision, communication, and computation resource allocation to\nminimize energy consumption and meet latency requirements. In the roadside unit\n(RSU) tier, collaboration among RSUs is investigated to address multi-access\nissues of bandwidth and computation resources for multiple vehicles. A two-step\nmethod is proposed to solve the subchannel allocation problem. Detailed\nexperiments are conducted to demonstrate the effectiveness of the proposed\nmethod and assess the impact of different parameters on system energy\nconsumption.", "published": "2025-03-26 05:48:51", "link": "http://arxiv.org/abs/2503.20256v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Hybrid FSO and RF Lunar Wireless Power Transfer", "abstract": "This study focuses on the feasibility analyses of the hybrid FSO and RF-based\nWPT system used in the realistic Cislunar environment, which is established by\nusing STK HPOP software in which many external forces are incorporated. In our\nproposed multi-hop scheme, a solar-powered satellite (SPS) beams the laser\npower to the low lunar orbit (LLO) satellite in the first hop, then the\nharvested power is used as a relay power for RF-based WPT to two critical lunar\nregions, which are lunar south pole (LSP) (0{\\deg}E,90{\\deg}S) and Malapert\nMountain (0{\\deg}E,86{\\deg}S), owing to the multi-point coverage feature of RF\nsystems. The end-to-end system is analyzed for two cases, i) the perfect\nalignment, and ii) the misalignment fading due to the random mechanical\nvibrations in the optical inter-satellite link. It is found that the harvested\npower is maximized when the distance between the SPS and LLO satellite is\nminimized and it is calculated as 331.94 kW, however, when the random\nmisalignment fading is considered, the mean of the harvested power reduces to\n309.49 kW for the same distance. In the next hop, the power harvested by the\nsolar array on the LLO satellite is consumed entirely as the relay power.\nIdentical parabolic antennas are considered during the RF-based WPT system\nbetween the LLO satellite and the LSP, which utilizes a full-tracking module,\nand between the LLO satellite and the Malapert Mountain region, which uses a\nhalf-tracking module that executes the tracking on the receiver dish only. In\nthe perfectly aligned hybrid WPT system, 19.80 W and 573.7 mW of maximum\nharvested powers are yielded at the LSP and Mountain Malapert, respectively. On\nthe other hand, when the misalignment fading in the end-to-end system is\nconsidered, the mean of the maximum harvested powers degrades to 18.41 W and\n534.4 mW for the former and latter hybrid WPT links.", "published": "2025-03-26 00:16:27", "link": "http://arxiv.org/abs/2503.20125v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
