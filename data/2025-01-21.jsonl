{"title": "An Optimal Transport approach to arbitrage correction: Application to volatility Stress-Tests", "abstract": "We present a method based on optimal transport to remove arbitrage\nopportunities within a finite set of option prices. The method is notably\nintended for regulatory stress-tests, which impose to apply important local\ndistortions to implied volatility surfaces. The resulting stressed option\nprices are naturally associated to a family of signed marginal measures: we\nformulate the process of removing arbitrage as a projection onto the subset of\nmartingale measures with respect to a Wasserstein metric in the space of signed\nmeasures. We show how this projection problem can be recast as an optimal\ntransport problem; in view of the numerical solution, we apply an entropic\nregularization technique. For the regularized problem, we derive a strong\nduality formula, show convergence results as the regularization parameter\napproaches zero, and formulate a multi-constrained Sinkhorn algorithm, where\neach iteration involves, at worse, finding the root of an explicit scalar\nfunction. The convergence of this algorithm is also established. We compare our\nmethod with the existing approach by [Cohen, Reisinger and Wang, Appl.\\ Math.\\\nFin.\\ 2020] across various scenarios and test cases.", "published": "2025-01-21 15:03:34", "link": "http://arxiv.org/abs/2501.12195v1", "categories": ["q-fin.MF", "91G80, 49Q22"], "primary_category": "q-fin.MF"}
{"title": "Challenges in Expanding Portuguese Resources: A View from Open\n  Information Extraction", "abstract": "Open Information Extraction (Open IE) is the task of extracting structured\ninformation from textual documents, independent of domain. While traditional\nOpen IE methods were based on unsupervised approaches, recently, with the\nemergence of robust annotated datasets, new data-based approaches have been\ndeveloped to achieve better results. These innovations, however, have focused\nmainly on the English language due to a lack of datasets and the difficulty of\nconstructing such resources for other languages. In this work, we present a\nhigh-quality manually annotated corpus for Open Information Extraction in the\nPortuguese language, based on a rigorous methodology grounded in established\nsemantic theories. We discuss the challenges encountered in the annotation\nprocess, propose a set of structural and contextual annotation rules, and\nvalidate our corpus by evaluating the performance of state-of-the-art Open IE\nsystems. Our resource addresses the lack of datasets for Open IE in Portuguese\nand can support the development and evaluation of new methods and systems in\nthis area.", "published": "2025-01-21 03:08:37", "link": "http://arxiv.org/abs/2501.11851v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and\n  Reasoning of Evidence-Based Medicine", "abstract": "In recent years, Large Language Models (LLMs) have exhibited remarkable\ncapabilities in clinical scenarios. However, despite their potential, existing\nworks face challenges when applying LLMs to medical settings. Strategies\nrelying on training with medical datasets are highly cost-intensive and may\nsuffer from outdated training data. Leveraging external knowledge bases is a\nsuitable alternative, yet it faces obstacles such as limited retrieval\nprecision and poor effectiveness in answer extraction. These issues\ncollectively prevent LLMs from demonstrating the expected level of proficiency\nin mastering medical expertise. To address these challenges, we introduce\nMed-R^2, a novel LLM physician framework that adheres to the Evidence-Based\nMedicine (EBM) process, efficiently integrating retrieval mechanisms as well as\nthe selection and reasoning processes of evidence, thereby enhancing the\nproblem-solving capabilities of LLMs in healthcare scenarios and fostering a\ntrustworthy LLM physician. Our comprehensive experiments indicate that Med-R^2\nachieves a 14.87\\% improvement over vanilla RAG methods and even a 3.59\\%\nenhancement compared to fine-tuning strategies, without incurring additional\ntraining costs.", "published": "2025-01-21 04:40:43", "link": "http://arxiv.org/abs/2501.11885v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HERITAGE: An End-to-End Web Platform for Processing Korean Historical\n  Documents in Hanja", "abstract": "While Korean historical documents are invaluable cultural heritage,\nunderstanding those documents requires in-depth Hanja expertise. Hanja is an\nancient language used in Korea before the 20th century, whose characters were\nborrowed from old Chinese but had evolved in Korea for centuries. Modern\nKoreans and Chinese cannot understand Korean historical documents without\nsubstantial additional help, and while previous efforts have produced some\nKorean and English translations, this requires in-depth expertise, and so most\nof the documents are not translated into any modern language. To address this\ngap, we present HERITAGE, the first open-source Hanja NLP toolkit to assist in\nunderstanding and translating the unexplored Korean historical documents\nwritten in Hanja. HERITAGE is a web-based platform providing model predictions\nof three critical tasks in historical document understanding via Hanja language\nmodels: punctuation restoration, named entity recognition, and machine\ntranslation (MT). HERITAGE also provides an interactive glossary, which\nprovides the character-level reading of the Hanja characters in modern Korean,\nas well as character-level English definition. HERITAGE serves two purposes.\nFirst, anyone interested in these documents can get a general understanding\nfrom the model predictions and the interactive glossary, especially MT outputs\nin Korean and English. Second, since the model outputs are not perfect, Hanja\nexperts can revise them to produce better annotations and translations. This\nwould boost the translation efficiency and potentially lead to most of the\nhistorical documents being translated into modern languages, lowering the\nbarrier on unexplored Korean historical documents.", "published": "2025-01-21 07:49:51", "link": "http://arxiv.org/abs/2501.11951v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proverbs Run in Pairs: Evaluating Proverb Translation Capability of\n  Large Language Model", "abstract": "Despite achieving remarkable performance, machine translation (MT) research\nremains underexplored in terms of translating cultural elements in languages,\nsuch as idioms, proverbs, and colloquial expressions. This paper investigates\nthe capability of state-of-the-art neural machine translation (NMT) and large\nlanguage models (LLMs) in translating proverbs, which are deeply rooted in\ncultural contexts. We construct a translation dataset of standalone proverbs\nand proverbs in conversation for four language pairs. Our experiments show that\nthe studied models can achieve good translation between languages with similar\ncultural backgrounds, and LLMs generally outperform NMT models in proverb\ntranslation. Furthermore, we find that current automatic evaluation metrics\nsuch as BLEU, CHRF++ and COMET are inadequate for reliably assessing the\nquality of proverb translation, highlighting the need for more culturally aware\nevaluation metrics.", "published": "2025-01-21 07:54:22", "link": "http://arxiv.org/abs/2501.11953v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Attention Framework for Fake News Detection with Large Language\n  Models", "abstract": "With the rapid growth of online information, the spread of fake news has\nbecome a serious social challenge. In this study, we propose a novel detection\nframework based on Large Language Models (LLMs) to identify and classify fake\nnews by integrating textual statistical features and deep semantic features.\nOur approach utilizes the contextual understanding capability of the large\nlanguage model for text analysis and introduces a hybrid attention mechanism to\nfocus on feature combinations that are particularly important for fake news\nidentification. Extensive experiments on the WELFake news dataset show that our\nmodel significantly outperforms existing methods, with a 1.5\\% improvement in\nF1 score. In addition, we assess the interpretability of the model through\nattention heat maps and SHAP values, providing actionable insights for content\nreview strategies. Our framework provides a scalable and efficient solution to\ndeal with the spread of fake news and helps build a more reliable online\ninformation ecosystem.", "published": "2025-01-21 08:26:20", "link": "http://arxiv.org/abs/2501.11967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reference-free Evaluation Metrics for Text Generation: A Survey", "abstract": "A number of automatic evaluation metrics have been proposed for natural\nlanguage generation systems. The most common approach to automatic evaluation\nis the use of a reference-based metric that compares the model's output with\ngold-standard references written by humans. However, it is expensive to create\nsuch references, and for some tasks, such as response generation in dialogue,\ncreating references is not a simple matter. Therefore, various reference-free\nmetrics have been developed in recent years. In this survey, which intends to\ncover the full breadth of all NLG tasks, we investigate the most commonly used\napproaches, their application, and their other uses beyond evaluating models.\nThe survey concludes by highlighting some promising directions for future\nresearch.", "published": "2025-01-21 10:05:48", "link": "http://arxiv.org/abs/2501.12011v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow\n  Thinking", "abstract": "Medical language models (MLMs) have become pivotal in advancing medical\nnatural language processing. However, prior models that rely on pre-training or\nsupervised fine-tuning often exhibit low data efficiency and limited\npracticality in real-world clinical applications. While OpenAI's o1 highlights\ntest-time scaling in mathematics, attempts to replicate this approach in\nmedicine typically distill responses from GPT-series models to open-source\nmodels, focusing primarily on multiple-choice tasks. This strategy, though\nstraightforward, neglects critical concerns like data privacy and realistic\ndeployment in clinical settings. In this work, we present a deployable,\nsmall-scale medical reasoning system, MedS3, designed for long-chain reasoning\nin clinical tasks using a self-evolution paradigm. Starting with a seed dataset\nof around 8,000 instances spanning five domains and 16 datasets, we prompt a\nbase policy model to perform Monte Carlo Tree Search (MCTS) to construct\nrule-verifiable reasoning chains. Each reasoning step is assigned an evolution\nrollout value, allowing verified trajectories to train the policy model and the\nprocess reward model (PRM). During inference, the policy model generates\nmultiple responses, and the reward model selects the one with a newly proposed\nPRM-guided Vote-Sum (P-VS) strategy. Experiments on eleven evaluation datasets\ndemonstrate that MedS3 outperforms not only the prior strongest medical model\nby 6.59, but also 32B-level general reasoning models by 8.71 points. Code and\ndata are available at https://github.com/pixas/MedSSS.", "published": "2025-01-21 11:24:55", "link": "http://arxiv.org/abs/2501.12051v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extend Adversarial Policy Against Neural Machine Translation via Unknown\n  Token", "abstract": "Generating adversarial examples contributes to mainstream neural machine\ntranslation~(NMT) robustness. However, popular adversarial policies are apt for\nfixed tokenization, hindering its efficacy for common character perturbations\ninvolving versatile tokenization. Based on existing adversarial generation via\nreinforcement learning~(RL), we propose the `DexChar policy' that introduces\ncharacter perturbations for the existing mainstream adversarial policy based on\ntoken substitution. Furthermore, we improve the self-supervised matching that\nprovides feedback in RL to cater to the semantic constraints required during\ntraining adversaries. Experiments show that our method is compatible with the\nscenario where baseline adversaries fail, and can generate high-efficiency\nadversarial examples for analysis and optimization of the system.", "published": "2025-01-21 14:43:04", "link": "http://arxiv.org/abs/2501.12183v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Approaches to Sentiment Analysis Using Datasets in Major\n  European and Arabic Languages", "abstract": "This study explores transformer-based models such as BERT, mBERT, and XLM-R\nfor multi-lingual sentiment analysis across diverse linguistic structures. Key\ncontributions include the identification of XLM-R superior adaptability in\nmorphologically complex languages, achieving accuracy levels above 88%. The\nwork highlights fine-tuning strategies and emphasizes their significance for\nimproving sentiment classification in underrepresented languages.", "published": "2025-01-21 23:11:16", "link": "http://arxiv.org/abs/2501.12540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fact-Preserved Personalized News Headline Generation", "abstract": "Personalized news headline generation, aiming at generating user-specific\nheadlines based on readers' preferences, burgeons a recent flourishing research\ndirection. Existing studies generally inject a user interest embedding into an\nencoderdecoder headline generator to make the output personalized, while the\nfactual consistency of headlines is inadequate to be verified. In this paper,\nwe propose a framework Fact-Preserved Personalized News Headline Generation\n(short for FPG), to prompt a tradeoff between personalization and consistency.\nIn FPG, the similarity between the candidate news to be exposed and the\nhistorical clicked news is used to give different levels of attention to key\nfacts in the candidate news, and the similarity scores help to learn a\nfact-aware global user embedding. Besides, an additional training procedure\nbased on contrastive learning is devised to further enhance the factual\nconsistency of generated headlines. Extensive experiments conducted on a\nreal-world benchmark PENS validate the superiority of FPG, especially on the\ntradeoff between personalization and factual consistency.", "published": "2025-01-21 02:14:07", "link": "http://arxiv.org/abs/2501.11828v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is your LLM trapped in a Mental Set? Investigative study on how mental\n  sets affect the reasoning capabilities of LLMs", "abstract": "In this paper, we present an investigative study on how Mental Sets influence\nthe reasoning capabilities of LLMs. LLMs have excelled in diverse natural\nlanguage processing (NLP) tasks, driven by advancements in parameter-efficient\nfine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).\nFor complex reasoning tasks, selecting the right model for PEFT or ICL is\ncritical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.\nHowever, current evaluation methods, based on metrics like F1 Score or\nreasoning chain assessments by larger models, overlook a key dimension:\nadaptability to unfamiliar situations and overcoming entrenched thinking\npatterns. In cognitive psychology, Mental Set refers to the tendency to persist\nwith previously successful strategies, even when they become inefficient - a\nchallenge for problem solving and reasoning. We compare the performance of LLM\nmodels like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the\npresence of mental sets. To the best of our knowledge, this is the first study\nto integrate cognitive psychology concepts into the evaluation of LLMs for\ncomplex reasoning tasks, providing deeper insights into their adaptability and\nproblem-solving efficacy.", "published": "2025-01-21 02:29:15", "link": "http://arxiv.org/abs/2501.11833v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents", "abstract": "Multimodal Large Language Models (MLLMs) have shown significant advancements,\nproviding a promising future for embodied agents. Existing benchmarks for\nevaluating MLLMs primarily utilize static images or videos, limiting\nassessments to non-interactive scenarios. Meanwhile, existing embodied AI\nbenchmarks are task-specific and not diverse enough, which do not adequately\nevaluate the embodied capabilities of MLLMs. To address this, we propose\nEmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs\nwith embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied\n3D scenes, each of which is rigorously selected and annotated. It covers a\nbroad spectrum of existing embodied AI tasks with significantly enhanced\ndiversity, all within a unified simulation and evaluation framework tailored\nfor MLLMs. The tasks are organized into five categories: navigation, object\ninteraction, social interaction, attribute question answering, and spatial\nquestion answering to assess different capabilities of the agents. We evaluated\nthe state-of-the-art MLLMs on EmbodiedEval and found that they have a\nsignificant shortfall compared to human level on embodied tasks. Our analysis\ndemonstrates the limitations of existing MLLMs in embodied capabilities,\nproviding insights for their future development. We open-source all evaluation\ndata and simulation framework at https://github.com/thunlp/EmbodiedEval.", "published": "2025-01-21 03:22:10", "link": "http://arxiv.org/abs/2501.11858v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Demons in the Detail: On Implementing Load Balancing Loss for Training\n  Specialized Mixture-of-Expert Models", "abstract": "This paper revisits the implementation of\n$\\textbf{L}$oad-$\\textbf{b}$alancing $\\textbf{L}$oss (LBL) when training\nMixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as $N_E\n\\sum_{i=1}^{N_E} f_i p_i$, where $N_E$ is the total number of experts, $f_i$\nrepresents the frequency of expert $i$ being selected, and $p_i$ denotes the\naverage gating score of the expert $i$. Existing MoE training frameworks\nusually employ the parallel training strategy so that $f_i$ and the LBL are\ncalculated within a $\\textbf{micro-batch}$ and then averaged across parallel\ngroups. In essence, a micro-batch for training billion-scale LLMs normally\ncontains very few sequences. So, the micro-batch LBL is almost at the sequence\nlevel, and the router is pushed to distribute the token evenly within each\nsequence. Under this strict constraint, even tokens from a domain-specific\nsequence ($\\textit{e.g.}$, code) are uniformly routed to all experts, thereby\ninhibiting expert specialization. In this work, we propose calculating LBL\nusing a $\\textbf{global-batch}$ to loose this constraint. Because a\nglobal-batch contains much more diverse sequences than a micro-batch, which\nwill encourage load balance at the corpus level. Specifically, we introduce an\nextra communication step to synchronize $f_i$ across micro-batches and then use\nit to calculate the LBL. Through experiments on training MoEs-based LLMs (up to\n$\\textbf{42.8B}$ total parameters and $\\textbf{400B}$ tokens), we surprisingly\nfind that the global-batch LBL strategy yields excellent performance gains in\nboth pre-training perplexity and downstream tasks. Our analysis reveals that\nthe global-batch LBL also greatly improves the domain specialization of MoE\nexperts.", "published": "2025-01-21 04:04:39", "link": "http://arxiv.org/abs/2501.11873v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From Drafts to Answers: Unlocking LLM Potential via Aggregation\n  Fine-Tuning", "abstract": "Scaling data and model size has been proven effective for boosting the\nperformance of large language models. In addition to training-time scaling,\nrecent studies have revealed that increasing test-time computational resources\ncan further improve performance. In this work, we introduce Aggregation\nFine-Tuning (AFT), a supervised finetuning paradigm where the model learns to\nsynthesize multiple draft responses, referred to as proposals, into a single,\nrefined answer, termed aggregation. At inference time, a propose-and-aggregate\nstrategy further boosts performance by iteratively generating proposals and\naggregating them. Empirical evaluations on benchmark datasets show that\nAFT-trained models substantially outperform standard SFT. Notably, an AFT\nmodel, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC\nwin rate on AlpacaEval 2, surpassing significantly larger LLMs such as\nLlama3.1-405B-Instruct and GPT4. By combining sequential refinement and\nparallel sampling, the propose-and-aggregate framework scales inference-time\ncomputation in a flexible manner. Overall, These findings position AFT as a\npromising approach to unlocking additional capabilities of LLMs without\nresorting to increasing data volume or model size.", "published": "2025-01-21 04:11:59", "link": "http://arxiv.org/abs/2501.11877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Panoramic Interests: Stylistic-Content Aware Personalized Headline\n  Generation", "abstract": "Personalized news headline generation aims to provide users with\nattention-grabbing headlines that are tailored to their preferences. Prevailing\nmethods focus on user-oriented content preferences, but most of them overlook\nthe fact that diverse stylistic preferences are integral to users' panoramic\ninterests, leading to suboptimal personalization. In view of this, we propose a\nnovel Stylistic-Content Aware Personalized Headline Generation (SCAPE)\nframework. SCAPE extracts both content and stylistic features from headlines\nwith the aid of large language model (LLM) collaboration. It further adaptively\nintegrates users' long- and short-term interests through a contrastive\nlearning-based hierarchical fusion network. By incorporating the panoramic\ninterests into the headline generator, SCAPE reflects users' stylistic-content\npreferences during the generation process. Extensive experiments on the\nreal-world dataset PENS demonstrate the superiority of SCAPE over baselines.", "published": "2025-01-21 05:30:20", "link": "http://arxiv.org/abs/2501.11900v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble\n  for Robust Detection of AI-Generated Text across English and Multilingual\n  Contexts", "abstract": "This paper presents a system developed for Task 1 of the COLING 2025 Workshop\non Detecting AI-Generated Content, focusing on the binary classification of\nmachine-generated versus human-written text. Our approach utilizes an ensemble\nof models, with weights assigned according to each model's inverse perplexity,\nto enhance classification accuracy. For the English text detection task, we\ncombined RoBERTa-base, RoBERTa-base with the OpenAI detector, and\nBERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out\nof 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and\nBERT-base-multilingual-case for the multilingual text detection task, employing\nthe same inverse perplexity weighting technique. This resulted in a Macro\nF1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate\nthe effectiveness of inverse perplexity weighting in improving the robustness\nof machine-generated text detection across both monolingual and multilingual\nsettings, highlighting the potential of ensemble methods for this challenging\ntask.", "published": "2025-01-21 06:32:32", "link": "http://arxiv.org/abs/2501.11914v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of\n  AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned\n  Transformer Models", "abstract": "This paper presents our approach for Task 3 of the GenAI content detection\nworkshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT)\nDetection. We propose an ensemble of fine-tuned transformer models, enhanced by\ninverse perplexity weighting, to improve classification accuracy across diverse\ntext domains. For Subtask A (Non-Adversarial MGT Detection), we combined a\nfine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base\nmodel, achieving an aggregate TPR score of 0.826, ranking 10th out of 23\ndetectors. In Subtask B (Adversarial MGT Detection), our fine-tuned\nRoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22\ndetectors. Our results demonstrate the effectiveness of inverse\nperplexity-based weighting for enhancing generalization and performance in both\nnon-adversarial and adversarial MGT detection, highlighting the potential for\ntransformer models in cross-domain AI-generated content detection.", "published": "2025-01-21 06:46:55", "link": "http://arxiv.org/abs/2501.11918v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly\n  Detection", "abstract": "Text anomaly detection is crucial for identifying spam, misinformation, and\noffensive language in natural language processing tasks. Despite the growing\nadoption of embedding-based methods, their effectiveness and generalizability\nacross diverse application scenarios remain under-explored. To address this, we\npresent TAD-Bench, a comprehensive benchmark designed to systematically\nevaluate embedding-based approaches for text anomaly detection. TAD-Bench\nintegrates multiple datasets spanning different domains, combining\nstate-of-the-art embeddings from large language models with a variety of\nanomaly detection algorithms. Through extensive experiments, we analyze the\ninterplay between embeddings and detection methods, uncovering their strengths,\nweaknesses, and applicability to different tasks. These findings offer new\nperspectives on building more robust, efficient, and generalizable anomaly\ndetection systems for real-world applications.", "published": "2025-01-21 08:13:10", "link": "http://arxiv.org/abs/2501.11960v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Graph Structures and Large Language Models for End-to-End\n  Synthetic Task-Oriented Dialogues", "abstract": "Training task-oriented dialogue systems is both costly and time-consuming,\ndue to the need for high-quality datasets encompassing diverse intents.\nTraditional methods depend on extensive human annotation, while recent\nadvancements leverage large language models (LLMs) to generate synthetic data.\nHowever, these approaches often require custom prompts or code, limiting\naccessibility for non-technical users. We introduce GraphTOD, an end-to-end\nframework that simplifies the generation of task-oriented dialogues. Users can\ncreate dialogues by specifying transition graphs in JSON format. Our evaluation\ndemonstrates that GraphTOD generates high-quality dialogues across various\ndomains, significantly lowering the cost and complexity of dataset creation.", "published": "2025-01-21 08:51:12", "link": "http://arxiv.org/abs/2501.11977v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can open source large language models be used for tumor documentation in\n  Germany? -- An evaluation on urological doctors' notes", "abstract": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.", "published": "2025-01-21 12:56:47", "link": "http://arxiv.org/abs/2501.12106v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PAINT: Paying Attention to INformed Tokens to Mitigate Hallucination in\n  Large Vision-Language Model", "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable\ncapabilities in understanding and describing visual content, achieving\nstate-of-the-art performance across various vision-language tasks. However,\nthese models often generate descriptions containing objects or details that are\nabsent in the input image, a phenomenon commonly known as hallucination. Our\nwork investigates the key reasons behind this issue by analyzing the pattern of\nself-attention in transformer layers. We find that hallucinations often arise\nfrom the progressive weakening of attention weight to visual tokens in the\ndeeper layers of the LLM. Some previous works naively boost the attention of\nall visual tokens to mitigate this issue, resulting in suboptimal hallucination\nreduction. To address this, we identify two critical sets of visual tokens that\nfacilitate the transfer of visual information from the vision encoder to the\nLLM. Local tokens encode grounded information about objects present in an\nimage, while summary tokens capture the overall aggregated representation of\nthe image. Importantly, these two sets of tokens require different levels of\nweight enhancement. To this end, we propose \\textbf{PAINT} (\\textbf{P}aying\n\\textbf{A}ttention to \\textbf{IN}formed \\textbf{T}okens), a plug-and-play\nframework that intervenes in the self-attention mechanism of the LLM,\nselectively boosting the attention weights of local and summary tokens with\nexperimentally learned margins. Evaluation on the MSCOCO image captioning\ndataset demonstrate that our approach reduces hallucination rates by up to\n62.3\\% compared to baseline models while maintaining accuracy. Code is\navailable at\n\\href{https://github.com/hasanar1f/PAINT}{https://github.com/hasanar1f/PAINT}", "published": "2025-01-21 15:22:31", "link": "http://arxiv.org/abs/2501.12206v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and\n  Refinement", "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in\nenhancing the conversational capabilities of Large Language Models (LLMs).\nHowever, as LLMs become more advanced, the availability of high-quality\nhuman-annotated SFT data has become a significant bottleneck, necessitating a\ngreater reliance on synthetic training data. In this work, we introduce Condor,\na novel two-stage synthetic data generation framework that incorporates World\nKnowledge Tree and Self-Reflection Refinement to produce high-quality SFT data\nat scale. Our experimental results demonstrate that a base model fine-tuned on\nonly 20K Condor-generated samples achieves superior performance compared to\ncounterparts. The additional refinement stage in Condor further enables\niterative self-improvement for LLMs at various scales (up to 72B), validating\nthe effectiveness of our approach. Furthermore, our investigation into the\nscaling for synthetic data in post-training reveals substantial unexplored\npotential for performance improvements, opening promising avenues for future\nresearch.", "published": "2025-01-21 16:44:12", "link": "http://arxiv.org/abs/2501.12273v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with\n  XLM-Roberta Sentence Embeddings and Deep Neural Regression", "abstract": "This paper presents results of our system for CoMeDi Shared Task, focusing on\nSubtask 2: Disagreement Ranking. Our system leverages sentence embeddings\ngenerated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep\nneural regression model incorporating batch normalization and dropout for\nimproved generalization. By predicting the mean of pairwise judgment\ndifferences between annotators, our method explicitly targets disagreement\nranking, diverging from traditional \"gold label\" aggregation approaches. We\noptimized our system with a customized architecture and training procedure,\nachieving competitive performance in Spearman correlation against mean\ndisagreement labels. Our results highlight the importance of robust embeddings,\neffective model architecture, and careful handling of judgment differences for\nranking disagreement in multilingual contexts. These findings provide insights\ninto the use of contextualized representations for ordinal judgment tasks and\nopen avenues for further refinement of disagreement prediction models.", "published": "2025-01-21 18:10:43", "link": "http://arxiv.org/abs/2501.12336v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward\n  Model", "abstract": "Despite the promising performance of Large Vision Language Models (LVLMs) in\nvisual understanding, they occasionally generate incorrect outputs. While\nreward models (RMs) with reinforcement learning or test-time scaling offer the\npotential for improving generation quality, a critical gap remains: publicly\navailable multi-modal RMs for LVLMs are scarce, and the implementation details\nof proprietary models are often unclear. We bridge this gap with\nInternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective\nmulti-modal reward model that aligns LVLMs with human preferences. To ensure\nthe robustness and versatility of IXC-2.5-Reward, we set up a high-quality\nmulti-modal preference corpus spanning text, image, and video inputs across\ndiverse domains, such as instruction following, general understanding,\ntext-rich documents, mathematical reasoning, and video understanding.\nIXC-2.5-Reward achieves excellent results on the latest multi-modal reward\nmodel benchmark and shows competitive performance on text-only reward model\nbenchmarks. We further demonstrate three key applications of IXC-2.5-Reward:\n(1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward\nwith Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows\nconsistent improvements in instruction following and multi-modal open-ended\ndialogue; (2) Selecting the best response from candidate responses for\ntest-time scaling; and (3) Filtering outlier or noisy samples from existing\nimage and video instruction tuning training data. To ensure reproducibility and\nfacilitate further research, we have open-sourced all model weights and\ntraining recipes at https://github.com/InternLM/InternLM-XComposer", "published": "2025-01-21 18:47:32", "link": "http://arxiv.org/abs/2501.12368v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Journey Matters: Average Parameter Count over Pre-training Unifies\n  Sparse and Dense Scaling Laws", "abstract": "Pruning eliminates unnecessary parameters in neural networks; it offers a\npromising solution to the growing computational demands of large language\nmodels (LLMs). While many focus on post-training pruning, sparse\npre-training--which combines pruning and pre-training into a single\nphase--provides a simpler alternative. In this work, we present the first\nsystematic exploration of optimal sparse pre-training configurations for LLMs\nthrough an examination of 80 unique pruning schedules across different sparsity\nlevels and training durations. We find that initiating pruning at 25% of total\ntraining compute and concluding at 75% achieves near-optimal final evaluation\nloss. These findings provide valuable insights for efficient and effective\nsparse pre-training of LLMs. Furthermore, we propose a new scaling law that\nmodifies the Chinchilla scaling law to use the average parameter count over\npre-training. Through empirical and theoretical validation, we demonstrate that\nthis modified scaling law accurately models evaluation loss for both sparsely\nand densely pre-trained LLMs, unifying scaling laws across pre-training\nparadigms. Our findings indicate that while sparse pre-training achieves the\nsame final model quality as dense pre-training for equivalent compute budgets,\nit provides substantial benefits through reduced model size, enabling\nsignificant potential computational savings during inference.", "published": "2025-01-21 20:23:22", "link": "http://arxiv.org/abs/2501.12486v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Privacy in the Early Detection of Sexual Predators Through\n  Federated Learning and Differential Privacy", "abstract": "The increased screen time and isolation caused by the COVID-19 pandemic have\nled to a significant surge in cases of online grooming, which is the use of\nstrategies by predators to lure children into sexual exploitation. Previous\nefforts to detect grooming in industry and academia have involved accessing and\nmonitoring private conversations through centrally-trained models or sending\nprivate conversations to a global server. In this work, we implement a\nprivacy-preserving pipeline for the early detection of sexual predators. We\nleverage federated learning and differential privacy in order to create safer\nonline spaces for children while respecting their privacy. We investigate\nvarious privacy-preserving implementations and discuss their benefits and\nshortcomings. Our extensive evaluation using real-world data proves that\nprivacy and utility can coexist with only a slight reduction in utility.", "published": "2025-01-21 23:01:21", "link": "http://arxiv.org/abs/2501.12537v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Academic case reports lack diversity: Assessing the presence and\n  diversity of sociodemographic and behavioral factors related to Post COVID-19\n  Condition", "abstract": "Understanding the prevalence, disparities, and symptom variations of Post\nCOVID-19 Condition (PCC) for vulnerable populations is crucial to improving\ncare and addressing intersecting inequities. This study aims to develop a\ncomprehensive framework for integrating social determinants of health (SDOH)\ninto PCC research by leveraging NLP techniques to analyze disparities and\nvariations in SDOH representation within PCC case reports. Following\nconstruction of a PCC Case Report Corpus, comprising over 7,000 case reports\nfrom the LitCOVID repository, a subset of 709 reports were annotated with 26\ncore SDOH-related entity types using pre-trained named entity recognition (NER)\nmodels, human review, and data augmentation to improve quality, diversity and\nrepresentation of entity types. An NLP pipeline integrating NER, natural\nlanguage inference (NLI), trigram and frequency analyses was developed to\nextract and analyze these entities. Both encoder-only transformer models and\nRNN-based models were assessed for the NER objective.\n  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models\nin generalizability to distinct sentence structures and greater class sparsity.\nExploratory analysis revealed variability in entity richness, with prevalent\nentities like condition, age, and access to care, and underrepresentation of\nsensitive categories like race and housing status. Trigram analysis highlighted\nfrequent co-occurrences among entities, including age, gender, and condition.\nThe NLI objective (entailment and contradiction analysis) showed attributes\nlike \"Experienced violence or abuse\" and \"Has medical insurance\" had high\nentailment rates (82.4%-80.3%), while attributes such as \"Is\nfemale-identifying,\" \"Is married,\" and \"Has a terminal condition\" exhibited\nhigh contradiction rates (70.8%-98.5%).", "published": "2025-01-21 23:05:12", "link": "http://arxiv.org/abs/2501.12538v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compositional Instruction Following with Language Models and\n  Reinforcement Learning", "abstract": "Combining reinforcement learning with language grounding is challenging as\nthe agent needs to explore the environment while simultaneously learning\nmultiple language-conditioned tasks. To address this, we introduce a novel\nmethod: the compositionally-enabled reinforcement learning language agent\n(CERLLA). Our method reduces the sample complexity of tasks specified with\nlanguage by leveraging compositional policy representations and a semantic\nparser trained using reinforcement learning and in-context learning. We\nevaluate our approach in an environment requiring function approximation and\ndemonstrate compositional generalization to novel tasks. Our method\nsignificantly outperforms the previous best non-compositional baseline in terms\nof sample complexity on 162 tasks designed to test compositional\ngeneralization. Our model attains a higher success rate and learns in fewer\nsteps than the non-compositional baseline. It reaches a success rate equal to\nan oracle policy's upper-bound performance of 92%. With the same number of\nenvironment steps, the baseline only reaches a success rate of 80%.", "published": "2025-01-21 23:06:34", "link": "http://arxiv.org/abs/2501.12539v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Human-like conceptual representations emerge from language prediction", "abstract": "People acquire concepts through rich physical and social experiences and use\nthem to understand the world. In contrast, large language models (LLMs),\ntrained exclusively through next-token prediction over language data, exhibit\nremarkably human-like behaviors. Are these models developing concepts akin to\nhumans, and if so, how are such concepts represented and organized? To address\nthese questions, we reframed the classic reverse dictionary task to simulate\nhuman concept inference in context and investigated the emergence of human-like\nconceptual representations within LLMs. Our results demonstrate that LLMs can\nflexibly derive concepts from linguistic descriptions in relation to contextual\ncues about other concepts. The derived representations converged towards a\nshared, context-independent structure that effectively predicted human behavior\nacross key psychological phenomena, including computation of similarities,\ncategories and semantic scales. Moreover, these representations aligned well\nwith neural activity patterns in the human brain, even in response to visual\nrather than linguistic stimuli, providing evidence for biological plausibility.\nThese findings establish that structured, human-like conceptual representations\ncan naturally emerge from language prediction without real-world grounding.\nMore broadly, our work positions LLMs as promising computational tools for\nunderstanding complex human cognition and paves the way for better alignment\nbetween artificial and human intelligence.", "published": "2025-01-21 23:54:17", "link": "http://arxiv.org/abs/2501.12547v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Verification-guided Chain of Thoughts", "abstract": "Previous works have demonstrated the effectiveness of Chain-of-Thought (COT)\nprompts and verifiers in guiding Large Language Models (LLMs) through the space\nof reasoning. However, most such studies either use a fine-tuned verifier or\nrely on manually handcrafted few-shot examples. In contrast, in this paper, we\nfocus on LLM-based self-verification of self-generated reasoning steps via COT\nprompts in a completely zero-shot regime. To explore this setting, we design a\nnew zero-shot prompt, which we call COT STEP, to aid zero-shot decomposition of\nreasoning steps and design two new zero-shot prompts for LLM-based verifiers.\nWe evaluate the verifiers' ability to classify the correctness of reasoning\nchains and explore different ways to use verifier scores in guiding reasoning\nfor various mathematical and commonsense reasoning tasks with different LLMs.", "published": "2025-01-21 03:52:54", "link": "http://arxiv.org/abs/2501.13122v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Debate Helps Weak-to-Strong Generalization", "abstract": "Common methods for aligning already-capable models with desired behavior rely\non the ability of humans to provide supervision. However, future superhuman\nmodels will surpass the capability of humans. Therefore, humans will only be\nable to weakly supervise superhuman models. This expected deficiency of human\nevaluation would weaken the safety of future AI systems. Scalable oversight and\nweak-to-strong generalization are two complementary approaches to tackle this\nissue. In this paper, we attempt to combine the strengths of these two\napproaches to further improve alignment. Specifically, we investigate ways of\nimproving human supervision with a strong pretrained model and then supervise\nthe strong model with enhanced weak human supervision. To make iterative\nempirical progress, we consider an analogy: can we use a strong model to\nimprove weak model supervision and then use it to supervise the strong model?\nWe empirically test it by finetuning a small weak model on ground truth labels\nwith the additional help from a large strong model, and then finetuning the\nstrong model on labels generated by the weak model. We find that debate can\nassist a weak model in extracting trustworthy information from an untrustworthy\nstrong model, which provides leverage as context on samples when training a\nweak model. We also show that an ensemble of weak models helps exploit long\narguments generated by strong model debaters and obtain a more robust\nsupervision estimate. Extensive experiments on the OpenAI weak-to-strong NLP\nbenchmarks show that the combination approach leads to better alignment, which\nindicates that debate has the potential to help weak-to-strong generalization.", "published": "2025-01-21 05:36:13", "link": "http://arxiv.org/abs/2501.13124v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Preference Curriculum: LLMs Should Always Be Pretrained on Their\n  Preferred Data", "abstract": "Large language models (LLMs) generally utilize a consistent data distribution\nthroughout the pretraining process. However, as the model's capability\nimproves, it is intuitive that its data preferences dynamically change,\nindicating the need for pretraining with different data at various training\nstages. To achieve it, we propose the Perplexity Difference (PD) based\nPreference Curriculum learning (PDPC) framework, which always perceives and\nuses the data preferred by LLMs to train and boost them. First, we introduce\nthe PD metric to quantify the difference in how challenging a sample is for\nweak versus strong models. Samples with high PD are more challenging for weak\nmodels to learn and are more suitable to be arranged in the later stage of\npretraining. Second, we propose the preference function to approximate and\npredict the data preference of the LLM at any training step, so as to complete\nthe arrangement of the dataset offline and ensure continuous training without\ninterruption. Experimental results on 1.3B and 3B models demonstrate that PDPC\nsignificantly surpasses baselines. Notably, the 3B model trained on 1T tokens\nachieves an increased average accuracy of over 8.1% across MMLU and CMMLU.", "published": "2025-01-21 13:12:13", "link": "http://arxiv.org/abs/2501.13126v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking Generative AI for Scoring Medical Student Interviews in\n  Objective Structured Clinical Examinations (OSCEs)", "abstract": "Introduction. Objective Structured Clinical Examinations (OSCEs) are widely\nused to assess medical students' communication skills, but scoring\ninterview-based assessments is time-consuming and potentially subject to human\nbias. This study explored the potential of large language models (LLMs) to\nautomate OSCE evaluations using the Master Interview Rating Scale (MIRS).\n  Methods. We compared the performance of four state-of-the-art LLMs (GPT-4o,\nClaude 3.5, Llama 3.1, and Gemini 1.5 Pro) in evaluating OSCE transcripts\nacross all 28 items of the MIRS under the conditions of zero-shot,\nchain-of-thought (CoT), few-shot, and multi-step prompting. The models were\nbenchmarked against a dataset of 10 OSCE cases with 174 expert consensus scores\navailable. Model performance was measured using three accuracy metrics (exact,\noff-by-one, thresholded).\n  Results. Averaging across all MIRS items and OSCE cases, LLMs performed with\nlow exact accuracy (0.27 to 0.44), and moderate to high off-by-one accuracy\n(0.67 to 0.87) and thresholded accuracy (0.75 to 0.88). A zero temperature\nparameter ensured high intra-rater reliability ($\\alpha = 0.98$ for GPT-4o).\nCoT, few-shot, and multi-step techniques proved valuable when tailored to\nspecific assessment items. The performance was consistent across MIRS items\nindependent of encounter phases and communication domains.\n  Conclusion. We demonstrated the feasibility of AI-assisted OSCE evaluation\nand provided benchmarking of multiple LLMs across multiple prompt techniques.\nOur work provides a baseline performance assessment for LLMs that lays a\nfoundation for future research in automated assessment of clinical\ncommunication skills.", "published": "2025-01-21 04:05:45", "link": "http://arxiv.org/abs/2501.13957v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Network-informed Prompt Engineering against Organized Astroturf\n  Campaigns under Extreme Class Imbalance", "abstract": "Detecting organized political campaigns is of paramount importance in\nfighting against disinformation on social media. Existing approaches for the\nidentification of such organized actions employ techniques mostly from network\nscience, graph machine learning and natural language processing. Their ultimate\ngoal is to analyze the relationships and interactions (e.g. re-posting) among\nusers and the textual similarities of their posts. Despite their effectiveness\nin recognizing astroturf campaigns, these methods face significant challenges,\nnotably the class imbalance in available training datasets. To mitigate this\nissue, recent methods usually resort to data augmentation or increasing the\nnumber of positive samples, which may not always be feasible or sufficient in\nreal-world settings. Following a different path, in this paper, we propose a\nnovel framework for identifying astroturf campaigns based solely on large\nlanguage models (LLMs), introducing a Balanced Retrieval-Augmented Generation\n(Balanced RAG) component. Our approach first gives both textual information\nconcerning the posts (in our case tweets) and the user interactions of the\nsocial network as input to a language model. Then, through prompt engineering\nand the proposed Balanced RAG method, it effectively detects coordinated\ndisinformation campaigns on X (Twitter). The proposed framework does not\nrequire any training or fine-tuning of the language model. Instead, by\nstrategically harnessing the strengths of prompt engineering and Balanced RAG,\nit facilitates LLMs to overcome the effects of class imbalance and effectively\nidentify coordinated political campaigns. The experimental results demonstrate\nthat by incorporating the proposed prompt engineering and Balanced RAG methods,\nour framework outperforms the traditional graph-based baselines, achieving\n2x-3x improvements in terms of precision, recall and F1 scores.", "published": "2025-01-21 03:07:21", "link": "http://arxiv.org/abs/2501.11849v3", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Cross-Entropy Attacks to Language Models via Rare Event Simulation", "abstract": "Black-box textual adversarial attacks are challenging due to the lack of\nmodel information and the discrete, non-differentiable nature of text. Existing\nmethods often lack versatility for attacking different models, suffer from\nlimited attacking performance due to the inefficient optimization with word\nsaliency ranking, and frequently sacrifice semantic integrity to achieve better\nattack outcomes. This paper introduces a novel approach to textual adversarial\nattacks, which we call Cross-Entropy Attacks (CEA), that uses Cross-Entropy\noptimization to address the above issues. Our CEA approach defines adversarial\nobjectives for both soft-label and hard-label settings and employs CE\noptimization to identify optimal replacements. Through extensive experiments on\ndocument classification and language translation problems, we demonstrate that\nour attack method excels in terms of attacking performance, imperceptibility,\nand sentence quality.", "published": "2025-01-21 03:08:59", "link": "http://arxiv.org/abs/2501.11852v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular\n  Value Decomposition", "abstract": "Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of\ntrainable parameters. However, they often suffer from scalability issues and\ndifferences between their learning pattern and full fine-tuning. To overcome\nthese limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation\n(EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude\nand directional components. By freezing low-rank matrices, initializing them by\nsingular value decomposition, and introducing a small trainable matrix between\nthem, EDoRA achieves substantial reduction in trainable parameters while\nmaintaining learning capacity. Experimental results on the GLUE benchmark\ndemonstrate that EDoRA achieves competitive or superior performance compared to\nstate-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable\nparameters. This makes EDoRA a highly efficient solution for adapting LLMs to\ndiverse tasks under memory-constrained settings. Code is available at\nhttps://github.com/Hamid-Nasiri/EDoRA .", "published": "2025-01-21 11:42:09", "link": "http://arxiv.org/abs/2501.12067v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Improving Influence-based Instruction Tuning Data Selection for Balanced\n  Learning of Diverse Capabilities", "abstract": "Selecting appropriate training data is crucial for effective instruction\nfine-tuning of large language models (LLMs), which aims to (1) elicit strong\ncapabilities, and (2) achieve balanced performance across a diverse range of\ntasks. Influence-based methods show promise in achieving (1) by estimating the\ncontribution of each training example to the model's predictions, but often\nstruggle with (2). Our systematic investigation reveals that this\nunderperformance can be attributed to an inherent bias where certain tasks\nintrinsically have greater influence than others. As a result, data selection\nis often biased towards these tasks, not only hurting the model's performance\non others but also, counterintuitively, harms performance on these\nhigh-influence tasks themselves.\n  As a remedy, we propose BIDS, a Balanced and Influential Data Selection\nalgorithm. BIDS first normalizes influence scores of the training data, and\nthen iteratively balances data selection by choosing the training example with\nthe highest influence on the most underrepresented task. Experiments with both\nLlama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities\nshow that BIDS consistently outperforms both state-of-the-art influence-based\nalgorithms and other non-influence-based selection frameworks. Surprisingly,\ntraining on a 15% subset selected by BIDS can even outperform full-dataset\ntraining with a much more balanced performance. Our analysis further highlights\nthe importance of both instance-level normalization and iterative optimization\nof selected data for balanced learning of diverse capabilities.", "published": "2025-01-21 14:00:43", "link": "http://arxiv.org/abs/2501.12147v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative\n  Decoding", "abstract": "This paper introduces AdaServe, the first LLM serving system to support SLO\ncustomization through fine-grained speculative decoding. AdaServe leverages the\nlogits of a draft model to predict the speculative accuracy of tokens and\nemploys a theoretically optimal algorithm to construct token trees for\nverification. To accommodate diverse SLO requirements without compromising\nthroughput, AdaServe employs a speculation-and-selection scheme that first\nconstructs candidate token trees for each request and then dynamically selects\ntokens to meet individual SLO constraints while optimizing throughput.\nComprehensive evaluations demonstrate that AdaServe achieves up to 73% higher\nSLO attainment and 74% higher goodput compared to state-of-the-art systems.\nThese results underscore AdaServe's potential to enhance the efficiency and\nadaptability of LLM deployments across varied application scenarios.", "published": "2025-01-21 14:15:01", "link": "http://arxiv.org/abs/2501.12162v1", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InsTALL: Context-aware Instructional Task Assistance with Multi-modal\n  Large Language Models", "abstract": "The improved competence of generative models can help building multi-modal\nvirtual assistants that leverage modalities beyond language. By observing\nhumans performing multi-step tasks, one can build assistants that have\nsituational awareness of actions and tasks being performed, enabling them to\ncater assistance based on this understanding. In this paper, we develop a\nContext-aware Instructional Task Assistant with Multi-modal Large Language\nModels (InsTALL) that leverages an online visual stream (e.g. a user's screen\nshare or video recording) and responds in real-time to user queries related to\nthe task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal\nmodel on task videos and paired textual data, and 2) automatically extracts\ntask graph from video data and leverages it at training and inference time. We\nshow InsTALL achieves state-of-the-art performance across proposed sub-tasks\nconsidered for multimodal activity understanding -- task recognition (TR),\naction recognition (AR), next action prediction (AP), and plan prediction (PP)\n-- and outperforms existing baselines on two novel sub-tasks related to\nautomatic error identification.", "published": "2025-01-21 15:55:06", "link": "http://arxiv.org/abs/2501.12231v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FOCUS: First Order Concentrated Updating Scheme", "abstract": "Large language models (LLMs) demonstrate remarkable performance, and\nimproving their pre-training process appears to be key to enhancing their\ncapabilities further. Based on the documented success of Adam, learning rate\ndecay, and weight decay, we hypothesize that the pre-training loss landscape\nfeatures a narrowing valley structure. Through experiments with synthetic loss\nfunctions, we discover that when gradient query noise is high relative to the\nvalley's sharpness, Adam's performance falls behind that of Signum because Adam\nreduces the effective step size too drastically. This observation led us to\ndevelop FOCUS, an optimizer that enhances Signum by incorporating attraction\ntoward moving averaged parameters, allowing it to handle noise better while\nmaintaining larger step sizes. In training GPT-2, FOCUS proves to be more\nstable than Signum and faster than Adam. These results suggest that gradient\nnoise may be an underappreciated limiting factor in LLM training, and FOCUS\noffers promising solutions.", "published": "2025-01-21 16:03:42", "link": "http://arxiv.org/abs/2501.12243v1", "categories": ["cs.LG", "cs.CL", "math.OC"], "primary_category": "cs.LG"}
{"title": "CBVLM: Training-free Explainable Concept-based Large Vision Language\n  Models for Medical Image Classification", "abstract": "The main challenges limiting the adoption of deep learning-based solutions in\nmedical workflows are the availability of annotated data and the lack of\ninterpretability of such systems. Concept Bottleneck Models (CBMs) tackle the\nlatter by constraining the final disease prediction on a set of predefined and\nhuman-interpretable concepts. However, the increased interpretability achieved\nthrough these concept-based explanations implies a higher annotation burden.\nMoreover, if a new concept needs to be added, the whole system needs to be\nretrained. Inspired by the remarkable performance shown by Large\nVision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet\neffective, methodology, CBVLM, which tackles both of the aforementioned\nchallenges. First, for each concept, we prompt the LVLM to answer if the\nconcept is present in the input image. Then, we ask the LVLM to classify the\nimage based on the previous concept predictions. Moreover, in both stages, we\nincorporate a retrieval module responsible for selecting the best examples for\nin-context learning. By grounding the final diagnosis on the predicted\nconcepts, we ensure explainability, and by leveraging the few-shot capabilities\nof LVLMs, we drastically lower the annotation cost. We validate our approach\nwith extensive experiments across four medical datasets and twelve LVLMs (both\ngeneric and medical) and show that CBVLM consistently outperforms CBMs and\ntask-specific supervised methods without requiring any training and using just\na few annotated examples. More information on our project page:\nhttps://cristianopatricio.github.io/CBVLM/.", "published": "2025-01-21 16:38:04", "link": "http://arxiv.org/abs/2501.12266v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents", "abstract": "This paper introduces UI-TARS, a native GUI agent model that solely perceives\nthe screenshots as input and performs human-like interactions (e.g., keyboard\nand mouse operations). Unlike prevailing agent frameworks that depend on\nheavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts\nand workflows, UI-TARS is an end-to-end model that outperforms these\nsophisticated frameworks. Experiments demonstrate its superior performance:\nUI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating\nperception, grounding, and GUI task execution. Notably, in the OSWorld\nbenchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15\nsteps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,\nUI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several\nkey innovations: (1) Enhanced Perception: leveraging a large-scale dataset of\nGUI screenshots for context-aware understanding of UI elements and precise\ncaptioning; (2) Unified Action Modeling, which standardizes actions into a\nunified space across platforms and achieves precise grounding and interaction\nthrough large-scale action traces; (3) System-2 Reasoning, which incorporates\ndeliberate reasoning into multi-step decision making, involving multiple\nreasoning patterns such as task decomposition, reflection thinking, milestone\nrecognition, etc. (4) Iterative Training with Reflective Online Traces, which\naddresses the data bottleneck by automatically collecting, filtering, and\nreflectively refining new interaction traces on hundreds of virtual machines.\nThrough iterative training and reflection tuning, UI-TARS continuously learns\nfrom its mistakes and adapts to unforeseen situations with minimal human\nintervention. We also analyze the evolution path of GUI agents to guide the\nfurther development of this domain.", "published": "2025-01-21 17:48:10", "link": "http://arxiv.org/abs/2501.12326v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Automatic Labelling with Open-source LLMs using Dynamic Label Schema\n  Integration", "abstract": "Acquiring labelled training data remains a costly task in real world machine\nlearning projects to meet quantity and quality requirements. Recently Large\nLanguage Models (LLMs), notably GPT-4, have shown great promises in labelling\ndata with high accuracy. However, privacy and cost concerns prevent the\nubiquitous use of GPT-4. In this work, we explore effectively leveraging\nopen-source models for automatic labelling. We identify integrating label\nschema as a promising technology but found that naively using the label\ndescription for classification leads to poor performance on high cardinality\ntasks. To address this, we propose Retrieval Augmented Classification (RAC) for\nwhich LLM performs inferences for one label at a time using corresponding label\nschema; we start with the most related label and iterates until a label is\nchosen by the LLM. We show that our method, which dynamically integrates label\ndescription, leads to performance improvements in labelling tasks. We further\nshow that by focusing only on the most promising labels, RAC can trade off\nbetween label quality and coverage - a property we leverage to automatically\nlabel our internal datasets.", "published": "2025-01-21 18:06:54", "link": "http://arxiv.org/abs/2501.12332v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding", "abstract": "We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark\nfor evaluating foundation models in video understanding. MMVU includes 3,000\nexpert-annotated questions spanning 27 subjects across four core disciplines:\nScience, Healthcare, Humanities & Social Sciences, and Engineering. Compared to\nprior benchmarks, MMVU features three key advancements. First, it challenges\nmodels to apply domain-specific knowledge and perform expert-level reasoning to\nanalyze specialized-domain videos, moving beyond the basic visual perception\ntypically assessed in current video benchmarks. Second, each example is\nannotated by human experts from scratch. We implement strict data quality\ncontrols to ensure the high quality of the dataset. Finally, each example is\nenriched with expert-annotated reasoning rationals and relevant domain\nknowledge, facilitating in-depth analysis. We conduct an extensive evaluation\nof 32 frontier multimodal foundation models on MMVU. The latest\nSystem-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest\nperformance among the tested models. However, they still fall short of matching\nhuman expertise. Through in-depth error analyses and case studies, we offer\nactionable insights for future advancements in expert-level,\nknowledge-intensive video understanding for specialized domains.", "published": "2025-01-21 18:56:18", "link": "http://arxiv.org/abs/2501.12380v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Modality Interactive Mixture-of-Experts for Fake News Detection", "abstract": "The proliferation of fake news on social media platforms disproportionately\nimpacts vulnerable populations, eroding trust, exacerbating inequality, and\namplifying harmful narratives. Detecting fake news in multimodal contexts --\nwhere deceptive content combines text and images -- is particularly challenging\ndue to the nuanced interplay between modalities. Existing multimodal fake news\ndetection methods often emphasize cross-modal consistency but ignore the\ncomplex interactions between text and visual elements, which may complement,\ncontradict, or independently influence the predicted veracity of a post. To\naddress these challenges, we present Modality Interactive Mixture-of-Experts\nfor Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Experts\nframework designed to enhance multimodal fake news detection by explicitly\nmodeling modality interactions through an interaction gating mechanism. Our\napproach models modality interactions by evaluating two key aspects of modality\ninteractions: unimodal prediction agreement and semantic alignment. The\nhierarchical structure of MIMoE-FND allows for distinct learning pathways\ntailored to different fusion scenarios, adapting to the unique characteristics\nof each modality interaction. By tailoring fusion strategies to diverse\nmodality interaction scenarios, MIMoE-FND provides a more robust and nuanced\napproach to multimodal fake news detection. We evaluate our approach on three\nreal-world benchmarks spanning two languages, demonstrating its superior\nperformance compared to state-of-the-art methods. By enhancing the accuracy and\ninterpretability of fake news detection, MIMoE-FND offers a promising tool to\nmitigate the spread of misinformation, with the potential to better safeguard\nvulnerable communities against its harmful effects.", "published": "2025-01-21 16:49:00", "link": "http://arxiv.org/abs/2501.12431v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.4"], "primary_category": "cs.LG"}
{"title": "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel\n  Tool Invocation", "abstract": "Although current Large Language Models (LLMs) exhibit impressive\ncapabilities, performing complex real-world tasks still requires tool learning.\nMainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to\ninteract with external environments, but they are limited in perceptual scope\nand lack adequate task-planning capability. To address these limitations, other\nstudies introduce the first Search-based Decision Tree (DFSDT), which still\nsuffers from the high computational cost. In this paper, we introduce a novel\nparallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).\nFirst, we transform traditional tree-based tool search paths into Directed\nAcyclic Graph (DAG) structure, generating a high-quality parallel tool\ninvocation dataset. The DTA-Llama is then trained on the dataset to learn to\niteratively divide the current task into several parallel tool invocation\nsub-tasks and aggregate the invocation results to decide the next actions.\nFurthermore, we introduce an efficient inference framework inspired by the\nProcess/Threads mechanism when applying the DTA-Llama to practical tasks.\nExperimental results show that our approach substantially enhances task\nperformance while reducing token consumption and inference time. Llama2-7B,\nusing our method, is comparable to the official parallel function calling\nmethod of GPT-3.5. The relevant code, dataset, and model weights are available\nat https://corn0205.github.io/", "published": "2025-01-21 16:49:08", "link": "http://arxiv.org/abs/2501.12432v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Owls are wise and foxes are unfaithful: Uncovering animal stereotypes in\n  vision-language models", "abstract": "Animal stereotypes are deeply embedded in human culture and language. They\noften shape our perceptions and expectations of various species. Our study\ninvestigates how animal stereotypes manifest in vision-language models during\nthe task of image generation. Through targeted prompts, we explore whether\nDALL-E perpetuates stereotypical representations of animals, such as \"owls as\nwise,\" \"foxes as unfaithful,\" etc. Our findings reveal significant stereotyped\ninstances where the model consistently generates images aligned with cultural\nbiases. The current work is the first of its kind to examine animal\nstereotyping in vision-language models systematically and to highlight a\ncritical yet underexplored dimension of bias in AI-generated visual content.", "published": "2025-01-21 18:41:28", "link": "http://arxiv.org/abs/2501.12433v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Episodic Memories Generation and Evaluation Benchmark for Large Language\n  Models", "abstract": "Episodic memory -- the ability to recall specific events grounded in time and\nspace -- is a cornerstone of human cognition, enabling not only coherent\nstorytelling, but also planning and decision-making. Despite their remarkable\ncapabilities, Large Language Models (LLMs) lack a robust mechanism for episodic\nmemory: we argue that integrating episodic memory capabilities into LLM is\nessential for advancing AI towards human-like cognition, increasing their\npotential to reason consistently and ground their output in real-world episodic\nevents, hence avoiding confabulations. To address this challenge, we introduce\na comprehensive framework to model and evaluate LLM episodic memory\ncapabilities. Drawing inspiration from cognitive science, we develop a\nstructured approach to represent episodic events, encapsulating temporal and\nspatial contexts, involved entities, and detailed descriptions. We synthesize a\nunique episodic memory benchmark, free from contamination, and release open\nsource code and datasets to assess LLM performance across various recall and\nepisodic reasoning tasks. Our evaluation of state-of-the-art models, including\nGPT-4 and Claude variants, Llama 3.1, and o1-mini, reveals that even the most\nadvanced LLMs struggle with episodic memory tasks, particularly when dealing\nwith multiple related events or complex spatio-temporal relationships -- even\nin contexts as short as 10k-100k tokens.", "published": "2025-01-21 02:16:13", "link": "http://arxiv.org/abs/2501.13121v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Plausible Distractors for Multiple-Choice Questions via\n  Student Choice Prediction", "abstract": "In designing multiple-choice questions (MCQs) in education, creating\nplausible distractors is crucial for identifying students' misconceptions and\ngaps in knowledge and accurately assessing their understanding. However, prior\nstudies on distractor generation have not paid sufficient attention to\nenhancing the difficulty of distractors, resulting in reduced effectiveness of\nMCQs. This study presents a pipeline for training a model to generate\ndistractors that are more likely to be selected by students. First, we train a\npairwise ranker to reason about students' misconceptions and assess the\nrelative plausibility of two distractors. Using this model, we create a dataset\nof pairwise distractor ranks and then train a distractor generator via Direct\nPreference Optimization (DPO) to generate more plausible distractors.\nExperiments on computer science subjects (Python, DB, MLDL) demonstrate that\nour pairwise ranker effectively identifies students' potential\nmisunderstandings and achieves ranking accuracy comparable to human experts.\nFurthermore, our distractor generator outperforms several baselines in\ngenerating plausible distractors and produces questions with a higher item\ndiscrimination index (DI).", "published": "2025-01-21 10:20:39", "link": "http://arxiv.org/abs/2501.13125v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey of Graph Retrieval-Augmented Generation for Customized Large\n  Language Models", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in a\nwide range of tasks, yet their application to specialized domains remains\nchallenging due to the need for deep expertise. Retrieval-augmented generation\n(RAG) has emerged as a promising solution to customize LLMs for professional\nfields by seamlessly integrating external knowledge bases, enabling real-time\naccess to domain-specific expertise during inference. Despite its potential,\ntraditional RAG systems, based on flat text retrieval, face three critical\nchallenges: (i) complex query understanding in professional contexts, (ii)\ndifficulties in knowledge integration across distributed sources, and (iii)\nsystem efficiency bottlenecks at scale. This survey presents a systematic\nanalysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new\nparadigm that revolutionizes domain-specific LLM applications. GraphRAG\naddresses traditional RAG limitations through three key innovations: (i)\ngraph-structured knowledge representation that explicitly captures entity\nrelationships and domain hierarchies, (ii) efficient graph-based retrieval\ntechniques that enable context-preserving knowledge retrieval with multihop\nreasoning ability, and (iii) structure-aware knowledge integration algorithms\nthat leverage retrieved knowledge for accurate and logical coherent generation\nof LLMs. In this survey, we systematically analyze the technical foundations of\nGraphRAG and examine current implementations across various professional\ndomains, identifying key technical challenges and promising research\ndirections. All the related resources of GraphRAG, including research papers,\nopen-source data, and projects, are collected for the community in\n\\textcolor{blue}{\\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.", "published": "2025-01-21 06:25:21", "link": "http://arxiv.org/abs/2501.13958v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Assisting Mathematical Formalization with A Learning-based Premise\n  Retriever", "abstract": "Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.", "published": "2025-01-21 06:32:25", "link": "http://arxiv.org/abs/2501.13959v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Benchmarking Randomized Optimization Algorithms on Binary, Permutation,\n  and Combinatorial Problem Landscapes", "abstract": "In this paper, we evaluate the performance of four randomized optimization\nalgorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic\nAlgorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering),\nacross three distinct types of problems: binary, permutation, and\ncombinatorial. We systematically compare these algorithms using a set of\nbenchmark fitness functions that highlight the specific challenges and\nrequirements of each problem category. Our study analyzes each algorithm's\neffectiveness based on key performance metrics, including solution quality,\nconvergence speed, computational cost, and robustness. Results show that while\nMIMIC and GA excel in producing high-quality solutions for binary and\ncombinatorial problems, their computational demands vary significantly. RHC and\nSA, while computationally less expensive, demonstrate limited performance in\ncomplex problem landscapes. The findings offer valuable insights into the\ntrade-offs between different optimization strategies and provide practical\nguidance for selecting the appropriate algorithm based on the type of problems,\naccuracy requirements, and computational constraints.", "published": "2025-01-21 23:13:01", "link": "http://arxiv.org/abs/2501.17170v1", "categories": ["cs.NE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Transferable Adversarial Attacks on Audio Deepfake Detection", "abstract": "Audio deepfakes pose significant threats, including impersonation, fraud, and\nreputation damage. To address these risks, audio deepfake detection (ADD)\ntechniques have been developed, demonstrating success on benchmarks like\nASVspoof2019. However, their resilience against transferable adversarial\nattacks remains largely unexplored. In this paper, we introduce a transferable\nGAN-based adversarial attack framework to evaluate the effectiveness of\nstate-of-the-art (SOTA) ADD systems. By leveraging an ensemble of surrogate ADD\nmodels and a discriminator, the proposed approach generates transferable\nadversarial attacks that better reflect real-world scenarios. Unlike previous\nmethods, the proposed framework incorporates a self-supervised audio model to\nensure transcription and perceptual integrity, resulting in high-quality\nadversarial attacks. Experimental results on benchmark dataset reveal that SOTA\nADD systems exhibit significant vulnerabilities, with accuracies dropping from\n98% to 26%, 92% to 54%, and 94% to 84% in white-box, gray-box, and black-box\nscenarios, respectively. When tested in other data sets, performance drops of\n91% to 46%, and 94% to 67% were observed against the In-the-Wild and WaveFake\ndata sets, respectively. These results highlight the significant\nvulnerabilities of existing ADD systems and emphasize the need to enhance their\nrobustness against advanced adversarial threats to ensure security and\nreliability.", "published": "2025-01-21 05:46:47", "link": "http://arxiv.org/abs/2501.11902v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rate-Aware Learned Speech Compression", "abstract": "The rapid rise of real-time communication and large language models has\nsignificantly increased the importance of speech compression. Deep\nlearning-based neural speech codecs have outperformed traditional signal-level\nspeech codecs in terms of rate-distortion (RD) performance. Typically, these\nneural codecs employ an encoder-quantizer-decoder architecture, where audio is\nfirst converted into latent code feature representations and then into discrete\ntokens. However, this architecture exhibits insufficient RD performance due to\ntwo main drawbacks: (1) the inadequate performance of the quantizer,\nchallenging training processes, and issues such as codebook collapse; (2) the\nlimited representational capacity of the encoder and decoder, making it\ndifficult to meet feature representation requirements across various bitrates.\nIn this paper, we propose a rate-aware learned speech compression scheme that\nreplaces the quantizer with an advanced channel-wise entropy model to improve\nRD performance, simplify training, and avoid codebook collapse. We employ\nmulti-scale convolution and linear attention mixture blocks to enhance the\nrepresentational capacity and flexibility of the encoder and decoder.\nExperimental results demonstrate that the proposed method achieves\nstate-of-the-art RD performance, obtaining 53.51% BD-Rate bitrate saving in\naverage, and achieves 0.26 BD-VisQol and 0.44 BD-PESQ gains.", "published": "2025-01-21 09:46:43", "link": "http://arxiv.org/abs/2501.11999v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speech Enhancement with Overlapped-Frame Information Fusion and Causal\n  Self-Attention", "abstract": "For time-frequency (TF) domain speech enhancement (SE) methods, the\noverlap-and-add operation in the inverse TF transformation inevitably leads to\nan algorithmic delay equal to the window size. However, typical causal SE\nsystems fail to utilize the future speech information within this inherent\ndelay, thereby limiting SE performance. In this paper, we propose an\noverlapped-frame information fusion scheme. At each frame index, we construct\nseveral pseudo overlapped-frames, fuse them with the original speech frame, and\nthen send the fused results to the SE model. Additionally, we introduce a\ncausal time-frequency-channel attention (TFCA) block to boost the\nrepresentation capability of the neural network. This block parallelly\nprocesses the intermediate feature maps through self-attention-based operations\nin the time, frequency, and channel dimensions. Experiments demonstrate the\nsuperiority of these improvements, and the proposed SE system outperforms the\ncurrent advanced methods.", "published": "2025-01-21 09:55:08", "link": "http://arxiv.org/abs/2501.12004v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DOTA-ME-CS: Daily Oriented Text Audio-Mandarin English-Code Switching\n  Dataset", "abstract": "Code-switching, the alternation between two or more languages within\ncommunication, poses great challenges for Automatic Speech Recognition (ASR)\nsystems. Existing models and datasets are limited in their ability to\neffectively handle these challenges. To address this gap and foster progress in\ncode-switching ASR research, we introduce the DOTA-ME-CS: Daily oriented text\naudio Mandarin-English code-switching dataset, which consists of 18.54 hours of\naudio data, including 9,300 recordings from 34 participants. To enhance the\ndataset's diversity, we apply artificial intelligence (AI) techniques such as\nAI timbre synthesis, speed variation, and noise addition, thereby increasing\nthe complexity and scalability of the task. The dataset is carefully curated to\nensure both diversity and quality, providing a robust resource for researchers\naddressing the intricacies of bilingual speech recognition with detailed data\nanalysis. We further demonstrate the dataset's potential in future research.\nThe DOTA-ME-CS dataset, along with accompanying code, will be made publicly\navailable.", "published": "2025-01-21 13:34:03", "link": "http://arxiv.org/abs/2501.12122v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Domain Adaptation Framework for Speech Recognition Systems with Only\n  Synthetic data", "abstract": "We introduce DAS (Domain Adaptation with Synthetic data), a novel domain\nadaptation framework for pre-trained ASR model, designed to efficiently adapt\nto various language-defined domains without requiring any real data. In\nparticular, DAS first prompts large language models (LLMs) to generate\ndomain-specific texts before converting these texts to speech via\ntext-to-speech technology. The synthetic data is used to fine-tune Whisper with\nLow-Rank Adapters (LoRAs) for targeted domains such as music, weather, and\nsports. We introduce a novel one-pass decoding strategy that merges predictions\nfrom multiple LoRA adapters efficiently during the auto-regressive text\ngeneration process. Experimental results show significant improvements,\nreducing the Word Error Rate (WER) by 10% to 17% across all target domains\ncompared to the original model, with minimal performance regression in\nout-of-domain settings (e.g., -1% on Librispeech test sets). We also\ndemonstrate that DAS operates efficiently during inference, introducing an\nadditional 9% increase in Real Time Factor (RTF) compared to the original model\nwhen inferring with three LoRA adapters.", "published": "2025-01-21 21:06:11", "link": "http://arxiv.org/abs/2501.12501v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "30+ Years of Source Separation Research: Achievements and Future\n  Challenges", "abstract": "Source separation (SS) of acoustic signals is a research field that emerged\nin the mid-1990s and has flourished ever since. On the occasion of ICASSP's\n50th anniversary, we review the major contributions and advancements in the\npast three decades in the speech, audio, and music SS research field. We will\ncover both single- and multi-channel SS approaches. We will also look back on\nkey efforts to foster a culture of scientific evaluation in the research field,\nincluding challenges, performance metrics, and datasets. We will conclude by\ndiscussing current trends and future research directions.", "published": "2025-01-21 02:48:00", "link": "http://arxiv.org/abs/2501.11837v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Representation Learning with Parameterised Quantum Circuits for\n  Advancing Speech Emotion Recognition", "abstract": "Speech Emotion Recognition (SER) is a complex and challenging task in\nhuman-computer interaction due to the intricate dependencies of features and\nthe overlapping nature of emotional expressions conveyed through speech.\nAlthough traditional deep learning methods have shown effectiveness, they often\nstruggle to capture subtle emotional variations and overlapping states. This\npaper introduces a hybrid classical-quantum framework that integrates\nParameterised Quantum Circuits (PQCs) with conventional Convolutional Neural\nNetwork (CNN) architectures. By leveraging quantum properties such as\nsuperposition and entanglement, the proposed model enhances feature\nrepresentation and captures complex dependencies more effectively than\nclassical methods. Experimental evaluations conducted on benchmark datasets,\nincluding IEMOCAP, RECOLA, and MSP-Improv, demonstrate that the hybrid model\nachieves higher accuracy in both binary and multi-class emotion classification\nwhile significantly reducing the number of trainable parameters. While a few\nexisting studies have explored the feasibility of using Quantum Circuits to\nreduce model complexity, none have successfully shown how they can enhance\naccuracy. This study is the first to demonstrate that Quantum Circuits has the\npotential to improve the accuracy of SER. The findings highlight the promise of\nQML to transform SER, suggesting a promising direction for future research and\npractical applications in emotion-aware systems.", "published": "2025-01-21 11:23:38", "link": "http://arxiv.org/abs/2501.12050v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "An End-to-End Approach for Korean Wakeword Systems with Speaker\n  Authentication", "abstract": "Wakeword detection plays a critical role in enabling AI assistants to listen\nto user voices and interact effectively. However, for languages other than\nEnglish, there is a significant lack of pre-trained wakeword models.\nAdditionally, systems that merely determine the presence of a wakeword can pose\nserious privacy concerns. In this paper, we propose an end-to-end approach that\ntrains wakewords for Non-English languages, particulary Korean, and uses this\nto develop a Voice Authentication model to protect user privacy. Our\nimplementation employs an open-source platform OpenWakeWord, which performs\nwakeword detection using an FCN (Fully-Connected Network) architecture. Once a\nwakeword is detected, our custom-developed code calculates cosine similarity\nfor robust user authentication. Experimental results demonstrate the\neffectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate\n(EER) each in the Wakeword Detection and the Voice Authentication. These\nfindings highlight the model's potential in providing secure and accurate\nwakeword detection and authentication for Korean users.", "published": "2025-01-21 15:02:31", "link": "http://arxiv.org/abs/2501.12194v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "I.2.7; I.5.4"], "primary_category": "cs.SD"}
{"title": "Audio Texture Manipulation by Exemplar-Based Analogy", "abstract": "Audio texture manipulation involves modifying the perceptual characteristics\nof a sound to achieve specific transformations, such as adding, removing, or\nreplacing auditory elements. In this paper, we propose an exemplar-based\nanalogy model for audio texture manipulation. Instead of conditioning on\ntext-based instructions, our method uses paired speech examples, where one clip\nrepresents the original sound and another illustrates the desired\ntransformation. The model learns to apply the same transformation to new input,\nallowing for the manipulation of sound textures. We construct a quadruplet\ndataset representing various editing tasks, and train a latent diffusion model\nin a self-supervised manner. We show through quantitative evaluations and\nperceptual studies that our model outperforms text-conditioned baselines and\ngeneralizes to real-world, out-of-distribution, and non-speech scenarios.\nProject page: https://berkeley-speech-group.github.io/audio-texture-analogy/", "published": "2025-01-21 18:58:38", "link": "http://arxiv.org/abs/2501.12385v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
