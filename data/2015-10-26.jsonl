{"title": "Edge-Linear First-Order Dependency Parsing with Undirected Minimum\n  Spanning Tree Inference", "abstract": "The run time complexity of state-of-the-art inference algorithms in\ngraph-based dependency parsing is super-linear in the number of input words\n(n). Recently, pruning algorithms for these models have shown to cut a large\nportion of the graph edges, with minimal damage to the resulting parse trees.\nSolving the inference problem in run time complexity determined solely by the\nnumber of edges (m) is hence of obvious importance.\n  We propose such an inference algorithm for first-order models, which encodes\nthe problem as a minimum spanning tree (MST) problem in an undirected graph.\nThis allows us to utilize state-of-the-art undirected MST algorithms whose run\ntime is O(m) at expectation and with a very high probability. A directed parse\ntree is then inferred from the undirected MST and is subsequently improved with\nrespect to the directed parsing model through local greedy updates, both steps\nrunning in O(n) time. In experiments with 18 languages, a variant of the\nfirst-order MSTParser (McDonald et al., 2005b) that employs our algorithm\nperforms very similarly to the original parser that runs an O(n^2) directed MST\ninference.", "published": "2015-10-26 13:56:25", "link": "http://arxiv.org/abs/1510.07482v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parser for Abstract Meaning Representation using Learning to Search", "abstract": "We develop a novel technique to parse English sentences into Abstract Meaning\nRepresentation (AMR) using SEARN, a Learning to Search approach, by modeling\nthe concept and the relation learning in a unified framework. We evaluate our\nparser on multiple datasets from varied domains and show an absolute\nimprovement of 2% to 6% over the state-of-the-art. Additionally we show that\nusing the most frequent concept gives us a baseline that is stronger than the\nstate-of-the-art for concept prediction. We plan to release our parser for\npublic use.", "published": "2015-10-26 18:34:16", "link": "http://arxiv.org/abs/1510.07586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to merge three different methods for information filtering ?", "abstract": "Twitter is now a gold marketing tool for entities concerned with online\nreputation. To automatically monitor online reputation of entities , systems\nhave to deal with ambiguous entity names, polarity detection and topic\ndetection. We propose three approaches to tackle the first issue: monitoring\nTwitter in order to find relevant tweets about a given entity. Evaluated within\nthe framework of the RepLab-2013 Filtering task, each of them has been shown\ncompetitive with state-of-the-art approaches. Mainly we investigate on how much\nmerging strategies may impact performances on a filtering task according to the\nevaluation measure.", "published": "2015-10-26 07:17:36", "link": "http://arxiv.org/abs/1510.07385v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Object Oriented Analysis using Natural Language Processing concepts: A\n  Review", "abstract": "The Software Development Life Cycle (SDLC) starts with eliciting requirements\nof the customers in the form of Software Requirement Specification (SRS). SRS\ndocument needed for software development is mostly written in Natural\nLanguage(NL) convenient for the client. From the SRS document only, the class\nname, its attributes and the functions incorporated in the body of the class\nare traced based on pre-knowledge of analyst. The paper intends to present a\nreview on Object Oriented (OO) analysis using Natural Language Processing (NLP)\ntechniques. This analysis can be manual where domain expert helps to generate\nthe required diagram or automated system, where the system generates the\nrequired diagram, from the input in the form of SRS.", "published": "2015-10-26 11:12:59", "link": "http://arxiv.org/abs/1510.07439v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Empirical Study on Deep Learning Models for Question Answering", "abstract": "In this paper we explore deep learning models with memory component or\nattention mechanism for question answering task. We combine and compare three\nmodels, Neural Machine Translation, Neural Turing Machine, and Memory Networks\nfor a simulated QA data set. This paper is the first one that uses Neural\nMachine Translation and Neural Turing Machines for solving QA tasks. Our\nresults suggest that the combination of attention and memory have potential to\nsolve certain QA problem.", "published": "2015-10-26 16:03:27", "link": "http://arxiv.org/abs/1510.07526v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
