{"title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "abstract": "Recent benchmarks for Large Language Model (LLM) agents primarily focus on\nevaluating reasoning, planning, and execution capabilities, while another\ncritical component-memory, encompassing how agents memorize, update, and\nretrieve long-term information-is under-evaluated due to the lack of\nbenchmarks. We term agents with memory mechanisms as memory agents. In this\npaper, we identify four core competencies essential for memory agents: accurate\nretrieval, test-time learning, long-range understanding, and conflict\nresolution. Existing datasets either rely on limited context lengths or are\ntailored for static, long-context settings like book-based QA, which do not\nreflect the interactive, multi-turn nature of memory agents that incrementally\naccumulate information. Furthermore, no existing benchmarks cover all four\ncompetencies. Therefore, we introduce MemoryAgentBench, a new benchmark\nspecifically designed for memory agents. Our benchmark combines reformulated\nexisting datasets with newly constructed ones, covering the above four memory\ncompetencies, providing a systematic and challenging testbed for assessing\nmemory quality. We evaluate a diverse set of memory agents, ranging from simple\ncontext-based and retrieval-augmented generation (RAG) systems to advanced\nagents with external memory modules and tool integration. Empirical results\nreveal that current methods fall short of mastering all four competencies,\nunderscoring the need for further research into comprehensive memory mechanisms\nfor LLM agents.", "published": "2025-07-07 17:59:54", "link": "http://arxiv.org/abs/2507.05257v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning", "abstract": "The remarkable reasoning capability of large language models (LLMs) stems\nfrom cognitive behaviors that emerge through reinforcement with verifiable\nrewards. This work investigates how to transfer this principle to Multimodal\nLLMs (MLLMs) to unlock advanced visual reasoning. We introduce a two-stage\nparadigm built on Qwen2.5-VL-7B: a massive linguistic cold-start fine-tuning,\nfollowed by multimodal reinforcement learning (RL) spanning nearly 1,000 steps,\nsurpassing all previous open-source efforts in scale. This pioneering work\nreveals three fundamental insights: 1) Behavior transfer emerges surprisingly\nearly in cold start due to linguistic mental imagery. 2) Cold start broadly\nmemorizes visual behaviors, while RL critically discerns and scales up\neffective patterns. 3) Transfer strategically favors high-utility behaviors\nsuch as visual reflection. Our resulting model, Open-Vision-Reasoner (OVR),\nachieves state-of-the-art performance on a suite of reasoning benchmarks,\nincluding 95.3% on MATH500, 51.8% on MathVision and 54.6% on MathVerse. We\nrelease our model, data, and training dynamics to catalyze the development of\nmore capable, behavior-aligned multimodal reasoners.", "published": "2025-07-07 17:59:03", "link": "http://arxiv.org/abs/2507.05255v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Response Attack: Exploiting Contextual Priming to Jailbreak Large Language Models", "abstract": "Contextual priming, where earlier stimuli covertly bias later judgments,\noffers an unexplored attack surface for large language models (LLMs). We\nuncover a contextual priming vulnerability in which the previous response in\nthe dialogue can steer its subsequent behavior toward policy-violating content.\nBuilding on this insight, we propose Response Attack, which uses an auxiliary\nLLM to generate a mildly harmful response to a paraphrased version of the\noriginal malicious query. They are then formatted into the dialogue and\nfollowed by a succinct trigger prompt, thereby priming the target model to\ngenerate harmful content. Across eight open-source and proprietary LLMs, RA\nconsistently outperforms seven state-of-the-art jailbreak techniques, achieving\nhigher attack success rates. To mitigate this threat, we construct and release\na context-aware safety fine-tuning dataset, which significantly reduces the\nattack success rate while preserving model capabilities. The code and data are\navailable at https://github.com/Dtc7w3PQ/Response-Attack.", "published": "2025-07-07 17:56:05", "link": "http://arxiv.org/abs/2507.05248v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors", "abstract": "While chain-of-thought (CoT) monitoring is an appealing AI safety defense,\nrecent work on \"unfaithfulness\" has cast doubt on its reliability. These\nfindings highlight an important failure mode, particularly when CoT acts as a\npost-hoc rationalization in applications like auditing for bias. However, for\nthe distinct problem of runtime monitoring to prevent severe harm, we argue the\nkey property is not faithfulness but monitorability. To this end, we introduce\na conceptual framework distinguishing CoT-as-rationalization from\nCoT-as-computation. We expect that certain classes of severe harm will require\ncomplex, multi-step reasoning that necessitates CoT-as-computation. Replicating\nthe experimental setups of prior work, we increase the difficulty of the bad\nbehavior to enforce this necessity condition; this forces the model to expose\nits reasoning, making it monitorable. We then present methodology guidelines to\nstress-test CoT monitoring against deliberate evasion. Applying these\nguidelines, we find that models can learn to obscure their intentions, but only\nwhen given significant help, such as detailed human-written strategies or\niterative optimization against the monitor. We conclude that, while not\ninfallible, CoT monitoring offers a substantial layer of defense that requires\nactive protection and continued stress-testing.", "published": "2025-07-07 17:54:52", "link": "http://arxiv.org/abs/2507.05246v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "abstract": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training.", "published": "2025-07-07 17:50:52", "link": "http://arxiv.org/abs/2507.05241v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Logit Reweighting for Topic-Focused Summarization", "abstract": "Generating abstractive summaries that adhere to a specific topic remains a\nsignificant challenge for language models. While standard approaches, such as\nfine-tuning, are resource-intensive, simpler methods like prompt engineering\noften struggle to maintain topical focus, particularly with smaller models. To\naddress this, we propose a lightweight method that enhances topical relevance\nby directly reweighting the logits of topic-relevant tokens during generation.\nWe evaluate three such reweighting techniques: Constant Shift, which adds a\nconstant value to logits; Factor Scaling, which multiplies them by a factor;\nand Threshold Selection, which selectively boosts logits that exceed a\nprobability threshold. Experiments on the NEWTS topical summarization dataset,\nusing both Gemma-2B and Llama-3-8B models, show that these techniques\neffectively increase the use of topic-relevant vocabulary. Notably, the\nThreshold Selection method successfully improves topical focus without\ncompromising summary quality-a trade-off often seen in other approaches. Our\nfindings demonstrate that directly reweighting logits is a practical and\nresource-efficient alternative to fine-tuning, offering a promising pathway for\nprecisely controlling the thematic content of generated text.", "published": "2025-07-07 17:44:21", "link": "http://arxiv.org/abs/2507.05235v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Interleaving Logic and Counting", "abstract": "Reasoning with quantifier expressions in natural language combines logical\nand arithmetical features, transcending strict divides between qualitative and\nquantitative. Our topic is this cooperation of styles as it occurs in common\nlinguistic usage and its extension into the broader practice of natural\nlanguage plus \"grassroots mathematics\".\n  We begin with a brief review of first-order logic with counting operators and\ncardinality comparisons. This system is known to be of high complexity, and\ndrowns out finer aspects of the combination of logic and counting. We move to a\nsmall fragment that can represent numerical syllogisms and basic reasoning\nabout comparative size: monadic first-order logic with counting. We provide\nnormal forms that allow for axiomatization, determine which arithmetical\nnotions can be defined on finite and on infinite models, and conversely, we\ndiscuss which logical notions can be defined out of purely arithmetical ones,\nand what sort of (non-)classical logics can be induced.\n  Next, we investigate a series of strengthenings, again using normal form\nmethods. The monadic second-order version is close, in a precise sense, to\nadditive Presburger Arithmetic, while versions with the natural device of tuple\ncounting take us to Diophantine equations, making the logic undecidable. We\nalso define a system that combines basic modal logic over binary accessibility\nrelations with counting, needed to formulate ubiquitous reasoning patterns such\nas the Pigeonhole Principle.\n  We return to our starting point in natural language, confronting the\narchitecture of our formal systems with linguistic quantifier vocabulary and\nsyntax. We conclude with some general thoughts on yet further entanglements of\nlogic and counting in formal systems, on rethinking the\nqualitative/quantitative divide, and on connecting our analysis to empirical\nfindings in cognitive science.", "published": "2025-07-07 17:30:29", "link": "http://arxiv.org/abs/2507.05219v1", "categories": ["math.LO", "cs.CL", "cs.LO", "03B70, 03B65, 03B45"], "primary_category": "math.LO"}
{"title": "MedGemma Technical Report", "abstract": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma.", "published": "2025-07-07 17:01:44", "link": "http://arxiv.org/abs/2507.05201v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Pre-Trained Policy Discriminators are General Reward Models", "abstract": "We offer a novel perspective on reward modeling by formulating it as a policy\ndiscriminator, which quantifies the difference between two policies to generate\na reward signal, guiding the training policy towards a target policy with\ndesired behaviors. Based on this conceptual insight, we propose a scalable\npre-training method named Policy Discriminative Learning (POLAR), which trains\na reward model (RM) to discern identical policies and discriminate different\nones. Unlike traditional reward modeling methods relying on absolute\npreferences, POLAR captures the relative difference between one policy and an\narbitrary target policy, which is a scalable, high-level optimization objective\nsuitable for modeling generic ranking relationships. Leveraging the POLAR\npre-training paradigm, we present a series of RMs with parameter scales from\n1.8B to 7B. Empirical results show that POLAR substantially outperforms\ntraditional non-pre-trained methods, significantly enhancing RM performance.\nFor instance, POLAR-7B could improve preference accuracy from 54.8% to 81.0% on\nSTEM tasks and from 57.9% to 85.5% on creative writing tasks compared to SOTA\nbaselines. POLAR also shows robust generalization capabilities in RLHF using\nReinforcement Fine-tuning (RFT), providing reliable reward signals and markedly\nenhancing policy performance--improving LLaMa3.1-8B from an average of 47.36%\nto 56.33% and Qwen2.5-32B from 64.49% to 70.47% on 20 benchmarks. Moreover,\nscaling experiments reveal a clear power-law relationship between computation\nand performance, supported by linear correlation coefficients approaching 0.99.\nThe impressive performance, strong generalization, and scaling properties\nsuggest that POLAR is a promising direction for developing general and strong\nreward models.", "published": "2025-07-07 16:56:31", "link": "http://arxiv.org/abs/2507.05197v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Fragments to Facts: A Curriculum-Driven DPO Approach for Generating Hindi News Veracity Explanations", "abstract": "In an era of rampant misinformation, generating reliable news explanations is\nvital, especially for under-represented languages like Hindi. Lacking robust\nautomated tools, Hindi faces challenges in scaling misinformation detection. To\nbridge this gap, we propose a novel framework integrating Direct Preference\nOptimization (DPO) with curriculum learning to align machine-generated\nexplanations with human reasoning. Fact-checked explanations from credible\nsources serve as preferred responses, while LLM outputs highlight system\nlimitations and serve as non-preferred responses. To refine task-specific\nalignment, we introduce two key parameters -- Actuality and Finesse -- into the\nDPO loss function, enhancing explanation quality and consistency. Experiments\nwith LLMs (Mistral, Llama, Gemma) and PLMs (mBART, mT5) confirm the framework's\neffectiveness in generating coherent, contextually relevant explanations. This\nscalable approach combats misinformation and extends automated explanation\ngeneration to low-resource languages.", "published": "2025-07-07 16:34:28", "link": "http://arxiv.org/abs/2507.05179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenS2S: Advancing Open-Source End-to-End Empathetic Large Speech Language Model", "abstract": "Empathetic interaction is a cornerstone of human-machine communication, due\nto the need for understanding speech enriched with paralinguistic cues and\ngenerating emotional and expressive responses. However, the most powerful\nempathetic LSLMs are increasingly closed off, leaving the crucial details about\nthe architecture, data and development opaque to researchers. Given the\ncritical need for transparent research into the LSLMs and empathetic behavior,\nwe present OpenS2S, a fully open-source, transparent and end-to-end LSLM\ndesigned to enable empathetic speech interactions. Based on our empathetic\nspeech-to-text model BLSP-Emo, OpenS2S further employs a streaming interleaved\ndecoding architecture to achieve low-latency speech generation. To facilitate\nend-to-end training, OpenS2S incorporates an automated data construction\npipeline that synthesizes diverse, high-quality empathetic speech dialogues at\nlow cost. By leveraging large language models to generate empathetic content\nand controllable text-to-speech systems to introduce speaker and emotional\nvariation, we construct a scalable training corpus with rich paralinguistic\ndiversity and minimal human supervision. We release the fully open-source\nOpenS2S model, including the dataset, model weights, pre-training and\nfine-tuning codes, to empower the broader research community and accelerate\ninnovation in empathetic speech systems. The project webpage can be accessed at\nhttps://casia-lm.github.io/OpenS2S", "published": "2025-07-07 16:31:37", "link": "http://arxiv.org/abs/2507.05177v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Critiques of World Models", "abstract": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.", "published": "2025-07-07 16:23:46", "link": "http://arxiv.org/abs/2507.05169v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "cs.LG"}
{"title": "InfoSteer: Steering Information Utility in Language Model Post-Training", "abstract": "Recent advancements in language models (LMs) gradually ushered in an era\nwhere post-training is crucial. Yet, post-training approaches such as\nsupervised fine-tuning (SFT) do not guarantee effective use of knowledge\nacquired during pretraining. We therefore present \\ours, a lightweight method\nthat encourages parametric information utilization in LMs during post-training.\nThis is achieved via treating FFN layer as associate key-value memory, and\npromotes the use of stored memory vectors via forward-pass interventions or\nregularization during backpropagation. We find this simple guidance during\npost-training phase delivers consistent performance improvements across diverse\nmodel families--including Qwen, Gemma and Llama-spanning over 15 downstream\ntasks in both ID and OOD evaluations. Beyond performance gains, we also find\nthat steered LMs can adaptively allocate information-placing more emphasis on\ngenerating semantically meaningful tokens, while using fewer resources on\nsimple transition ones (e.g., `,' or `and'). Our work underscores that vanilla\npost-training does not fully leverage pre-training potential, and steering LMs\nin latent representation space offers a promising approach that enhances both\nperformance and interpretability.", "published": "2025-07-07 16:13:21", "link": "http://arxiv.org/abs/2507.05158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI Generated Text Detection Using Instruction Fine-tuned Large Language and Transformer-Based Models", "abstract": "Large Language Models (LLMs) possess an extraordinary capability to produce\ntext that is not only coherent and contextually relevant but also strikingly\nsimilar to human writing. They adapt to various styles and genres, producing\ncontent that is both grammatically correct and semantically meaningful.\nRecently, LLMs have been misused to create highly realistic phishing emails,\nspread fake news, generate code to automate cyber crime, and write fraudulent\nscientific articles. Additionally, in many real-world applications, the\ngenerated content including style and topic and the generator model are not\nknown beforehand. The increasing prevalence and sophistication of artificial\nintelligence (AI)-generated texts have made their detection progressively more\nchallenging. Various attempts have been made to distinguish machine-generated\ntext from human-authored content using linguistic, statistical, machine\nlearning, and ensemble-based approaches. This work focuses on two primary\nobjectives Task-A, which involves distinguishing human-written text from\nmachine-generated text, and Task-B, which attempts to identify the specific LLM\nmodel responsible for the generation. Both of these tasks are based on fine\ntuning of Generative Pre-trained Transformer (GPT_4o-mini), Large Language\nModel Meta AI (LLaMA) 3 8B, and Bidirectional Encoder Representations from\nTransformers (BERT). The fine-tuned version of GPT_4o-mini and the BERT model\nhas achieved accuracies of 0.9547 for Task-A and 0.4698 for Task-B.", "published": "2025-07-07 16:13:13", "link": "http://arxiv.org/abs/2507.05157v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "abstract": "Learning Japanese vocabulary is a challenge for learners from Roman alphabet\nbackgrounds due to script differences. Japanese combines syllabaries like\nhiragana with kanji, which are logographic characters of Chinese origin. Kanji\nare also complicated due to their complexity and volume. Keyword mnemonics are\na common strategy to aid memorization, often using the compositional structure\nof kanji to form vivid associations. Despite recent efforts to use large\nlanguage models (LLMs) to assist learners, existing methods for LLM-based\nkeyword mnemonic generation function as a black box, offering limited\ninterpretability. We propose a generative framework that explicitly models the\nmnemonic construction process as driven by a set of common rules, and learn\nthem using a novel Expectation-Maximization-type algorithm. Trained on\nlearner-authored mnemonics from an online platform, our method learns latent\nstructures and compositional rules, enabling interpretable and systematic\nmnemonics generation. Experiments show that our method performs well in the\ncold-start setting for new learners while providing insight into the mechanisms\nbehind effective mnemonic creation.", "published": "2025-07-07 15:49:23", "link": "http://arxiv.org/abs/2507.05137v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SMART: Simulated Students Aligned with Item Response Theory for Question Difficulty Prediction", "abstract": "Item (question) difficulties play a crucial role in educational assessments,\nenabling accurate and efficient assessment of student abilities and\npersonalization to maximize learning outcomes. Traditionally, estimating item\ndifficulties can be costly, requiring real students to respond to items,\nfollowed by fitting an item response theory (IRT) model to get item difficulty\nestimates. This approach cannot be applied to the cold-start setting for\npreviously unseen items either. In this work, we present SMART (Simulated\nStudents Aligned with IRT), a novel method for aligning simulated students with\ninstructed ability, which can then be used in simulations to predict the\ndifficulty of open-ended items. We achieve this alignment using direct\npreference optimization (DPO), where we form preference pairs based on how\nlikely responses are under a ground-truth IRT model. We perform a simulation by\ngenerating thousands of responses, evaluating them with an LLM-based scoring\nmodel, and fit the resulting data to an IRT model to obtain item difficulty\nestimates. Through extensive experiments on a real-world student response\ndataset, we show that SMART outperforms other item difficulty prediction\nmethods by leveraging its improved ability alignment.", "published": "2025-07-07 15:41:38", "link": "http://arxiv.org/abs/2507.05129v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Evaluation of Large Language Models on Text Summarization Tasks Using Prompt Engineering Techniques", "abstract": "Large Language Models (LLMs) continue to advance natural language processing\nwith their ability to generate human-like text across a range of tasks. Despite\nthe remarkable success of LLMs in Natural Language Processing (NLP), their\nperformance in text summarization across various domains and datasets has not\nbeen comprehensively evaluated. At the same time, the ability to summarize text\neffectively without relying on extensive training data has become a crucial\nbottleneck. To address these issues, we present a systematic evaluation of six\nLLMs across four datasets: CNN/Daily Mail and NewsRoom (news), SAMSum (dialog),\nand ArXiv (scientific). By leveraging prompt engineering techniques including\nzero-shot and in-context learning, our study evaluates the performance using\nthe ROUGE and BERTScore metrics. In addition, a detailed analysis of inference\ntimes is conducted to better understand the trade-off between summarization\nquality and computational efficiency. For Long documents, introduce a\nsentence-based chunking strategy that enables LLMs with shorter context windows\nto summarize extended inputs in multiple stages. The findings reveal that while\nLLMs perform competitively on news and dialog tasks, their performance on long\nscientific documents improves significantly when aided by chunking strategies.\nIn addition, notable performance variations were observed based on model\nparameters, dataset properties, and prompt design. These results offer\nactionable insights into how different LLMs behave across task types,\ncontributing to ongoing research in efficient, instruction-based NLP systems.", "published": "2025-07-07 15:34:05", "link": "http://arxiv.org/abs/2507.05123v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration", "abstract": "Historical documents represent an invaluable cultural heritage, yet have\nundergone significant degradation over time through tears, water erosion, and\noxidation. Existing Historical Document Restoration (HDR) methods primarily\nfocus on single modality or limited-size restoration, failing to meet practical\nneeds. To fill this gap, we present a full-page HDR dataset (FPHDR) and a novel\nautomated HDR solution (AutoHDR). Specifically, FPHDR comprises 1,633 real and\n6,543 synthetic images with character-level and line-level locations, as well\nas character annotations in different damage grades. AutoHDR mimics historians'\nrestoration workflows through a three-stage approach: OCR-assisted damage\nlocalization, vision-language context text prediction, and patch autoregressive\nappearance restoration. The modular architecture of AutoHDR enables seamless\nhuman-machine collaboration, allowing for flexible intervention and\noptimization at each restoration stage. Experiments demonstrate AutoHDR's\nremarkable performance in HDR. When processing severely damaged documents, our\nmethod improves OCR accuracy from 46.83\\% to 84.05\\%, with further enhancement\nto 94.25\\% through human-machine collaboration. We believe this work represents\na significant advancement in automated historical document restoration and\ncontributes substantially to cultural heritage preservation. The model and\ndataset are available at https://github.com/SCUT-DLVCLab/AutoHDR.", "published": "2025-07-07 15:26:17", "link": "http://arxiv.org/abs/2507.05108v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AI-Driven Cytomorphology Image Synthesis for Medical Diagnostics", "abstract": "Biomedical datasets often contain a large sample imbalance and are subject to\nstrict privacy constraints, which together hinder the development of accurate\nmachine learning models. One potential solution is to generate synthetic\nimages, as this can improve data availability while preserving patient privacy.\nHowever, it remains difficult to generate synthetic images of sufficient\nquality for training robust classifiers. In this work, we focus on the\nclassification of single white blood cells, a key component in the diagnosis of\nhematological diseases such as acute myeloid leukemia (AML), a severe blood\ncancer. We demonstrate how synthetic images generated with a fine-tuned stable\ndiffusion model using LoRA weights when guided by real few-shot samples of the\ntarget white blood cell classes, can enhance classifier performance for limited\ndata. When training a ResNet classifier, accuracy increased from 27.3\\% to\n78.4\\% (+51.1\\%) by adding 5000 synthetic images per class to a small and\nhighly imbalanced real dataset. For a CLIP-based classifier, the accuracy\nimproved from 61.8\\% to 76.8\\% (+15.0\\%). The synthetic images are highly\nsimilar to real images, and they can help overcome dataset limitations,\nenhancing model generalization. Our results establish synthetic images as a\ntool in biomedical research, improving machine learning models, and\nfacilitating medical diagnosis and research.", "published": "2025-07-07 14:49:05", "link": "http://arxiv.org/abs/2507.05063v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.10; I.4.9; J.3"], "primary_category": "cs.CV"}
{"title": "Verified Language Processing with Hybrid Explainability: A Technical Report", "abstract": "The volume and diversity of digital information have led to a growing\nreliance on Machine Learning techniques, such as Natural Language Processing,\nfor interpreting and accessing appropriate data. While vector and graph\nembeddings represent data for similarity tasks, current state-of-the-art\npipelines lack guaranteed explainability, failing to determine similarity for\ngiven full texts accurately. These considerations can also be applied to\nclassifiers exploiting generative language models with logical prompts, which\nfail to correctly distinguish between logical implication, indifference, and\ninconsistency, despite being explicitly trained to recognise the first two\nclasses. We present a novel pipeline designed for hybrid explainability to\naddress this. Our methodology combines graphs and logic to produce First-Order\nLogic representations, creating machine- and human-readable representations\nthrough Montague Grammar. Preliminary results indicate the effectiveness of\nthis approach in accurately capturing full text similarity. To the best of our\nknowledge, this is the first approach to differentiate between implication,\ninconsistency, and indifference for text classification tasks. To address the\nlimitations of existing approaches, we use three self-contained datasets\nannotated for the former classification task to determine the suitability of\nthese approaches in capturing sentence structure equivalence, logical\nconnectives, and spatiotemporal reasoning. We also use these data to compare\nthe proposed method with language models pre-trained for detecting sentence\nentailment. The results show that the proposed method outperforms\nstate-of-the-art models, indicating that natural language understanding cannot\nbe easily generalised by training over extensive document corpora. This work\noffers a step toward more transparent and reliable Information Retrieval from\nextensive textual data.", "published": "2025-07-07 14:00:05", "link": "http://arxiv.org/abs/2507.05017v1", "categories": ["cs.CL", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Co-DETECT: Collaborative Discovery of Edge Cases in Text Classification", "abstract": "We introduce Co-DETECT (Collaborative Discovery of Edge cases in TExt\nClassificaTion), a novel mixed-initiative annotation framework that integrates\nhuman expertise with automatic annotation guided by large language models\n(LLMs). Co-DETECT starts with an initial, sketch-level codebook and dataset\nprovided by a domain expert, then leverages the LLM to annotate the data and\nidentify edge cases that are not well described by the initial codebook.\nSpecifically, Co-DETECT flags challenging examples, induces high-level,\ngeneralizable descriptions of edge cases, and assists user in incorporating\nedge case handling rules to improve the codebook. This iterative process\nenables more effective handling of nuanced phenomena through compact,\ngeneralizable annotation rules. Extensive user study, qualitative and\nquantitative analyses prove the effectiveness of Co-DETECT.", "published": "2025-07-07 13:48:54", "link": "http://arxiv.org/abs/2507.05010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do We Really Need Specialization? Evaluating Generalist Text Embeddings for Zero-Shot Recommendation and Search", "abstract": "Pre-trained language models (PLMs) are widely used to derive semantic\nrepresentations from item metadata in recommendation and search. In sequential\nrecommendation, PLMs enhance ID-based embeddings through textual metadata,\nwhile in product search, they align item characteristics with user intent.\nRecent studies suggest task and domain-specific fine-tuning are needed to\nimprove representational power. This paper challenges this assumption, showing\nthat Generalist Text Embedding Models (GTEs), pre-trained on large-scale\ncorpora, can guarantee strong zero-shot performance without specialized\nadaptation. Our experiments demonstrate that GTEs outperform traditional and\nfine-tuned models in both sequential recommendation and product search. We\nattribute this to a superior representational power, as they distribute\nfeatures more evenly across the embedding space. Finally, we show that\ncompressing embedding dimensions by focusing on the most informative directions\n(e.g., via PCA) effectively reduces noise and improves the performance of\nspecialized models. To ensure reproducibility, we provide our repository at\nhttps://split.to/gte4ps.", "published": "2025-07-07 13:41:52", "link": "http://arxiv.org/abs/2507.05006v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems", "abstract": "Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity\nto operate according to internal rules without external control. Accordingly,\nautonomous vehicles (AuVs) are defined as systems capable of perceiving their\nenvironment and executing preprogrammed tasks independently of external input.\nHowever, both research and real-world deployments increasingly showcase\nvehicles that demonstrate behaviors beyond this definition (including the SAE\nlevels 1 to 6), such as interaction with humans and machines, goal adaptation,\ncontextual reasoning, external tool use, and long-term planning, particularly\nwith the integration of large language models (LLMs) and agentic AI systems.\nThese developments reveal a conceptual gap between technical autonomy and the\nbroader cognitive and social capabilities needed for future human-centered\nmobility systems. To address this, we introduce the concept of agentic vehicles\n(AgVs), referring to vehicles that integrate agentic AI to reason, adapt, and\ninteract within complex environments. This paper presents a systems-level\nframework to characterize AgVs, focusing on their cognitive and communicative\nlayers and differentiating them from conventional AuVs. It synthesizes relevant\nadvances in agentic AI, robotics, multi-agent systems, and human-machine\ninteraction, and highlights how agentic AI, through high-level reasoning and\ntool use, can function not merely as computational tools but as interactive\nagents embedded in mobility ecosystems. The paper concludes by identifying key\nchallenges in the development and governance of AgVs, including safety,\nreal-time control, public acceptance, ethical alignment, and regulatory\nframeworks.", "published": "2025-07-07 13:34:49", "link": "http://arxiv.org/abs/2507.04996v1", "categories": ["cs.CY", "cs.CE", "cs.CL", "cs.HC", "cs.RO"], "primary_category": "cs.CY"}
{"title": "Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models", "abstract": "In the broader context of deep learning, Multimodal Large Language Models\nhave achieved significant breakthroughs by leveraging powerful Large Language\nModels as a backbone to align different modalities into the language space. A\nprime exemplification is the development of Video Large Language Models\n(Video-LLMs). While numerous advancements have been proposed to enhance the\nvideo understanding capabilities of these models, they are predominantly\ntrained on questions generated directly from video content. However, in\nreal-world scenarios, users often pose questions that extend beyond the\ninformational scope of the video, highlighting the need for Video-LLMs to\nassess the relevance of the question. We demonstrate that even the\nbest-performing Video-LLMs fail to reject unfit questions-not necessarily due\nto a lack of video understanding, but because they have not been trained to\nidentify and refuse such questions. To address this limitation, we propose\nalignment for answerability, a framework that equips Video-LLMs with the\nability to evaluate the relevance of a question based on the input video and\nappropriately decline to answer when the question exceeds the scope of the\nvideo, as well as an evaluation framework with a comprehensive set of metrics\ndesigned to measure model behavior before and after alignment. Furthermore, we\npresent a pipeline for creating a dataset specifically tailored for alignment\nfor answerability, leveraging existing video-description paired datasets.", "published": "2025-07-07 13:19:43", "link": "http://arxiv.org/abs/2507.04976v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ArtifactsBench: Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation", "abstract": "The generative capabilities of Large Language Models (LLMs) are rapidly\nexpanding from static code to dynamic, interactive visual artifacts. This\nprogress is bottlenecked by a critical evaluation gap: established benchmarks\nfocus on algorithmic correctness and are blind to the visual fidelity and\ninteractive integrity that define modern user experiences. To bridge this gap,\nwe introduce ArtifactsBench, a new benchmark and paradigm for the automated,\nmultimodal evaluation of visual code generation. Our framework programmatically\nrenders each generated artifact and captures its dynamic behavior through\ntemporal screenshots. This visual evidence, alongside the source code, is then\nassessed by a Multimodal LLM (MLLM)-as-Judge, which is rigorously guided by a\nfine-grained, per-task checklist to ensure holistic and reproducible scoring.\nWe construct a new benchmark of 1,825 diverse tasks and evaluate over 30\nleading LLMs. Our automated evaluation achieves a striking 94.4% ranking\nconsistency with WebDev Arena, the gold-standard for human preference in web\ndevelopment, and over 90% pairwise agreement with human experts. This\nestablishes ArtifactsBench as the first framework to reliably automate the\nassessment of human-perceived quality at scale. Our analysis provides a\nhigh-resolution map of the current SOTA, revealing that generalist models often\noutperform domain-specific ones. We open-source ArtifactsBench, including the\nbenchmark, evaluation harness, and baseline results at\nhttps://artifactsbenchmark.github.io/, to provide the community with a scalable\nand accurate tool to accelerate the development of user-centric generative\nmodels.", "published": "2025-07-07 12:53:00", "link": "http://arxiv.org/abs/2507.04952v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Taming the Tri-Space Tension: ARC-Guided Hallucination Modeling and Control for Text-to-Image Generation", "abstract": "Despite remarkable progress in image quality and prompt fidelity,\ntext-to-image (T2I) diffusion models continue to exhibit persistent\n\"hallucinations\", where generated content subtly or significantly diverges from\nthe intended prompt semantics. While often regarded as unpredictable artifacts,\nwe argue that these failures reflect deeper, structured misalignments within\nthe generative process. In this work, we propose a cognitively inspired\nperspective that reinterprets hallucinations as trajectory drift within a\nlatent alignment space. Empirical observations reveal that generation unfolds\nwithin a multiaxial cognitive tension field, where the model must continuously\nnegotiate competing demands across three key critical axes: semantic coherence,\nstructural alignment, and knowledge grounding. We then formalize this\nthree-axis space as the \\textbf{Hallucination Tri-Space} and introduce the\nAlignment Risk Code (ARC): a dynamic vector representation that quantifies\nreal-time alignment tension during generation. The magnitude of ARC captures\noverall misalignment, its direction identifies the dominant failure axis, and\nits imbalance reflects tension asymmetry. Based on this formulation, we develop\nthe TensionModulator (TM-ARC): a lightweight controller that operates entirely\nin latent space. TM-ARC monitors ARC signals and applies targeted,\naxis-specific interventions during the sampling process. Extensive experiments\non standard T2I benchmarks demonstrate that our approach significantly reduces\nhallucination without compromising image quality or diversity. This framework\noffers a unified and interpretable approach for understanding and mitigating\ngenerative failures in diffusion-based T2I systems.", "published": "2025-07-07 12:43:09", "link": "http://arxiv.org/abs/2507.04946v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ReLoop: \"Seeing Twice and Thinking Backwards\" via Closed-loop Training to Mitigate Hallucinations in Multimodal understanding", "abstract": "While Multimodal Large Language Models (MLLMs) have achieved remarkable\nprogress in open-ended visual question answering, they remain vulnerable to\nhallucinations. These are outputs that contradict or misrepresent input\nsemantics, posing a critical challenge to the reliability and factual\nconsistency. Existing methods often rely on external verification or post-hoc\ncorrection, lacking an internal mechanism to validate outputs directly during\ntraining. To bridge this gap, we propose ReLoop, a unified closed-loop training\nframework that encourages multimodal consistency for cross-modal understanding\nin MLLMs. ReLoop adopts a ring-shaped structure that integrates three\ncomplementary consistency feedback mechanisms, obliging MLLMs to \"seeing twice\nand thinking backwards\". Specifically, ReLoop employs the frozen Consistency\nFeedback Plugin (CFP), comprising semantic reconstruction, visual description,\nand an attention supervision module for attention alignment. These components\ncollectively enforce semantic reversibility, visual consistency, and\ninterpretable attention, enabling the model to correct its outputs during\ntraining. Extensive evaluations and analyses demonstrate the effectiveness of\nReLoop in reducing hallucination rates across multiple benchmarks, establishing\na robust method for hallucination mitigation in MLLMs. We will release our\nsource code and data in the camera-ready version.", "published": "2025-07-07 12:40:48", "link": "http://arxiv.org/abs/2507.04943v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SIGIR 2025 -- LiveRAG Challenge Report", "abstract": "The LiveRAG Challenge at SIGIR 2025, held between March and May 2025,\nprovided a competitive platform for advancing Retrieval-Augmented Generation\n(RAG) technologies. Participants from academia and industry were invited to\ndevelop a RAG-based question-answering system using a fixed corpus\n(Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal\nwas to facilitate challenging comparisons of retrieval and prompting\nstrategies. During the Live Challenge Day, 70 teams from 27 different countries\nprovided answers and supportive information to 500 unseen questions within a\nstrict two-hour time window. Evaluation was conducted in two stages: first an\nautomated LLM-as-a-judge approach was used to compute correctness and\nfaithfulness score, then a manual review of top ranked submissions was\nconducted. The finalists were announced on June 12, 2025, with prizes awarded\nduring the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.", "published": "2025-07-07 12:38:53", "link": "http://arxiv.org/abs/2507.04942v1", "categories": ["cs.CL", "cs.IR", "H.3.3"], "primary_category": "cs.CL"}
{"title": "O_FT@EvalLLM2025 : \u00e9tude comparative de choix de donn\u00e9es et de strat\u00e9gies d'apprentissage pour l'adaptation de mod\u00e8les de langue \u00e0 un domaine", "abstract": "This paper presents the work carried out by the O_FT team, joint with Orange\nand Ouest-France, on adapting language models to the defense domain as part of\nthe EvalLLM2025 challenge. This work focused on adapting the\n\\texttt{Mistral-7B-Instruct-v0.3} model using classical techniques of continued\npre-training and instruction-tuning. The core of our efforts is based on\ncollecting, generating, and selecting data for these two stages as well as for\nmodel evaluation. Experiments show that our adapted models have better\ndomain-specific knowledge and improved domain-specific task processing skills,\nalong with comparable (or even superior) performance on general knowledge and\nskills. Considering the carbon footprint of our adaptations, this work\ndemonstrates the feasibility of domain adaptation for relatively small models.\n  --\n  Ce document pr\\'esente les travaux r\\'ealis\\'es par l'\\'equipe O_FT conjointe\n\\`a Orange et Ouest-France sur l'adaptation de mod\\`eles de langue au domaine\nde la d\\'efense dans le cadre du challenge EvalLLM2025. Ces travaux se sont\nconcentr\\'es sur l'adaptation du mod\\`ele \\texttt{Mistral-7B-Instruct-v0.3}\navec des techniques classiques de poursuite du pr\\'e-entra\\^inement et\nd'affinage sur instructions. L'essentiel de nos travaux a port\\'e sur la\nconstitution, g\\'en\\'eration et s\\'election de donn\\'ees pour ces deux \\'etapes\nainsi que pour l'\\'evaluation des mod\\`eles. Les exp\\'eriences montrent que nos\nmod\\`eles adapt\\'es ont de meilleures de connaissances de fond et une meilleure\ncapacit\\'e de traitement de t\\^aches sur le domaine de la d\\'efense, ainsi que\ndes performances comparables (voire sup\\'erieures) sur des connaissances ou\ncapacit\\'es g\\'en\\'eralistes. Mis au regard des empreintes carbones de nos\nadaptations, ces travaux d\\'emontrent ainsi la viabilit\\'e de l'adaptation \\`a\nun domaine de mod\\`eles relativement petits.", "published": "2025-07-07 11:28:08", "link": "http://arxiv.org/abs/2507.04895v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction", "abstract": "Accident severity prediction plays a critical role in transportation safety\nsystems but is a persistently difficult task due to incomplete data, strong\nfeature dependencies, and severe class imbalance in which rare but\nhigh-severity cases are underrepresented and hard to detect. Existing methods\noften rely on monolithic models or black box prompting, which struggle to scale\nin noisy, real-world settings and offer limited interpretability. To address\nthese challenges, we propose MARBLE a multiagent rule based LLM engine that\ndecomposes the severity prediction task across a team of specialized reasoning\nagents, including an interchangeable ML-backed agent. Each agent focuses on a\nsemantic subset of features (e.g., spatial, environmental, temporal), enabling\nscoped reasoning and modular prompting without the risk of prompt saturation.\nPredictions are coordinated through either rule-based or LLM-guided consensus\nmechanisms that account for class rarity and confidence dynamics. The system\nretains structured traces of agent-level reasoning and coordination outcomes,\nsupporting in-depth interpretability and post-hoc performance diagnostics.\nAcross both UK and US datasets, MARBLE consistently outperforms traditional\nmachine learning classifiers and state-of-the-art (SOTA) prompt-based reasoning\nmethods including Chain-of-Thought (CoT), Least-to-Most (L2M), and\nTree-of-Thought (ToT) achieving nearly 90% accuracy where others plateau below\n48%. This performance redefines the practical ceiling for accident severity\nclassification under real world noise and extreme class imbalance. Our results\nposition MARBLE as a generalizable and interpretable framework for reasoning\nunder uncertainty in safety-critical applications.", "published": "2025-07-07 11:27:49", "link": "http://arxiv.org/abs/2507.04893v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Emergent Semantics Beyond Token Embeddings: Transformer LMs with Frozen Visual Unicode Representations", "abstract": "Understanding the locus of semantic representation in large language models\n(LLMs) is crucial for interpretability and architectural innovation. The\ndominant paradigm posits that trainable input embeddings serve as foundational\n\"meaning vectors.\" This paper challenges that view. We construct Transformer\nmodels where the embedding layer is entirely frozen, with vectors derived not\nfrom data, but from the visual structure of Unicode glyphs. These non-semantic,\nprecomputed visual embeddings are fixed throughout training. Our method is\ncompatible with any tokenizer, including a novel Unicode-centric tokenizer we\nintroduce to ensure universal text coverage. Despite the absence of trainable,\nsemantically initialized embeddings, our models converge, generate coherent\ntext, and, critically, outperform architecturally identical models with\ntrainable embeddings on the MMLU reasoning benchmark. We attribute this to\n\"representational interference\" in conventional models, where the embedding\nlayer is burdened with learning both structural and semantic features. Our\nresults indicate that high-level semantics are not inherent to input embeddings\nbut are an emergent property of the Transformer's compositional architecture\nand data scale. This reframes the role of embeddings from meaning containers to\nstructural primitives. We release all code and models to foster further\nresearch.", "published": "2025-07-07 11:17:32", "link": "http://arxiv.org/abs/2507.04886v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Building Open-Retrieval Conversational Question Answering Systems by Generating Synthetic Data and Decontextualizing User Questions", "abstract": "We consider open-retrieval conversational question answering (OR-CONVQA), an\nextension of question answering where system responses need to be (i) aware of\ndialog history and (ii) grounded in documents (or document fragments) retrieved\nper question. Domain-specific OR-CONVQA training datasets are crucial for\nreal-world applications, but hard to obtain. We propose a pipeline that\ncapitalizes on the abundance of plain text documents in organizations (e.g.,\nproduct documentation) to automatically produce realistic OR-CONVQA dialogs\nwith annotations. Similarly to real-world humanannotated OR-CONVQA datasets, we\ngenerate in-dialog question-answer pairs, self-contained (decontextualized,\ne.g., no referring expressions) versions of user questions, and propositions\n(sentences expressing prominent information from the documents) the system\nresponses are grounded in. We show how the synthetic dialogs can be used to\ntrain efficient question rewriters that decontextualize user questions,\nallowing existing dialog-unaware retrievers to be utilized. The retrieved\ninformation and the decontextualized question are then passed on to an LLM that\ngenerates the system's response.", "published": "2025-07-07 11:16:44", "link": "http://arxiv.org/abs/2507.04884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transcribing Spanish Texts from the Past: Experiments with Transkribus, Tesseract and Granite", "abstract": "This article presents the experiments and results obtained by the GRESEL team\nin the IberLEF 2025 shared task PastReader: Transcribing Texts from the Past.\nThree types of experiments were conducted with the dual aim of participating in\nthe task and enabling comparisons across different approaches. These included\nthe use of a web-based OCR service, a traditional OCR engine, and a compact\nmultimodal model. All experiments were run on consumer-grade hardware, which,\ndespite lacking high-performance computing capacity, provided sufficient\nstorage and stability. The results, while satisfactory, leave room for further\nimprovement. Future work will focus on exploring new techniques and ideas using\nthe Spanish-language dataset provided by the shared task, in collaboration with\nBiblioteca Nacional de Espa\\~na (BNE).", "published": "2025-07-07 11:04:17", "link": "http://arxiv.org/abs/2507.04878v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "$\\textit{Grahak-Nyay:}$ Consumer Grievance Redressal through Large Language Models", "abstract": "Access to consumer grievance redressal in India is often hindered by\nprocedural complexity, legal jargon, and jurisdictional challenges. To address\nthis, we present $\\textbf{Grahak-Nyay}$ (Justice-to-Consumers), a chatbot that\nstreamlines the process using open-source Large Language Models (LLMs) and\nRetrieval-Augmented Generation (RAG). Grahak-Nyay simplifies legal complexities\nthrough a concise and up-to-date knowledge base. We introduce three novel\ndatasets: $\\textit{GeneralQA}$ (general consumer law), $\\textit{SectoralQA}$\n(sector-specific knowledge) and $\\textit{SyntheticQA}$ (for RAG evaluation),\nalong with $\\textit{NyayChat}$, a dataset of 300 annotated chatbot\nconversations. We also introduce $\\textit{Judgments}$ data sourced from Indian\nConsumer Courts to aid the chatbot in decision making and to enhance user\ntrust. We also propose $\\textbf{HAB}$ metrics ($\\textbf{Helpfulness, Accuracy,\nBrevity}$) to evaluate chatbot performance. Legal domain experts validated\nGrahak-Nyay's effectiveness. Code and datasets will be released.", "published": "2025-07-07 10:26:42", "link": "http://arxiv.org/abs/2507.04854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue-Based Multi-Dimensional Relationship Extraction from Novels", "abstract": "Relation extraction is a crucial task in natural language processing, with\nbroad applications in knowledge graph construction and literary analysis.\nHowever, the complex context and implicit expressions in novel texts pose\nsignificant challenges for automatic character relationship extraction. This\nstudy focuses on relation extraction in the novel domain and proposes a method\nbased on Large Language Models (LLMs). By incorporating relationship dimension\nseparation, dialogue data construction, and contextual learning strategies, the\nproposed method enhances extraction performance. Leveraging dialogue structure\ninformation, it improves the model's ability to understand implicit\nrelationships and demonstrates strong adaptability in complex contexts.\nAdditionally, we construct a high-quality Chinese novel relation extraction\ndataset to address the lack of labeled resources and support future research.\nExperimental results show that our method outperforms traditional baselines\nacross multiple evaluation metrics and successfully facilitates the automated\nconstruction of character relationship networks in novels.", "published": "2025-07-07 10:20:16", "link": "http://arxiv.org/abs/2507.04852v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spec-TOD: A Specialized Instruction-Tuned LLM Framework for Efficient Task-Oriented Dialogue Systems", "abstract": "Task-oriented dialogue (TOD) systems facilitate goal-driven interactions\nbetween users and machines. While recent advances in deep learning have\nimproved the performance, TOD systems often struggle in low-resource scenarios\nwith limited labeled data. To address this challenge, we propose Spec-TOD, a\nnovel framework designed to train an end-to-end TOD system with limited data.\nSpec-TOD introduces two main innovations: (i) a novel specialized end-to-end\nTOD framework that incorporates explicit task instructions for\ninstruction-tuned large language models (LLMs), and (ii) an efficient training\nstrategy that leverages lightweight, specialized LLMs to achieve strong\nperformance with minimal supervision. Experiments on the MultiWOZ dataset, a\nwidely used TOD benchmark, demonstrate that Spec-TOD achieves competitive\nresults while significantly reducing the need for labeled data. These findings\nhighlight the potential of the proposed framework in advancing efficient and\neffective TOD systems in low-resource settings.", "published": "2025-07-07 10:03:20", "link": "http://arxiv.org/abs/2507.04841v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Vision To Language through Graph of Events in Space and Time: An Explainable Self-supervised Approach", "abstract": "The task of describing video content in natural language is commonly referred\nto as video captioning. Unlike conventional video captions, which are typically\nbrief and widely available, long-form paragraph descriptions in natural\nlanguage are scarce. This limitation of current datasets is due to the\nexpensive human manual annotation required and to the highly challenging task\nof explaining the language formation process from the perspective of the\nunderlying story, as a complex system of interconnected events in space and\ntime. Through a thorough analysis of recently published methods and available\ndatasets, we identify a general lack of published resources dedicated to the\nproblem of describing videos in complex language, beyond the level of\ndescriptions in the form of enumerations of simple captions. Furthermore, while\nstate-of-the-art methods produce impressive results on the task of generating\nshorter captions from videos by direct end-to-end learning between the videos\nand text, the problem of explaining the relationship between vision and\nlanguage is still beyond our reach. In this work, we propose a shared\nrepresentation between vision and language, based on graphs of events in space\nand time, which can be obtained in an explainable and analytical way, to\nintegrate and connect multiple vision tasks to produce the final natural\nlanguage description. Moreover, we also demonstrate how our automated and\nexplainable video description generation process can function as a fully\nautomatic teacher to effectively train direct, end-to-end neural student\npathways, within a self-supervised neuro-analytical system. We validate that\nour explainable neuro-analytical approach generates coherent, rich and relevant\ntextual descriptions on videos collected from multiple varied datasets, using\nboth standard evaluation metrics, human annotations and consensus from\nensembles of state-of-the-art VLMs.", "published": "2025-07-07 09:33:19", "link": "http://arxiv.org/abs/2507.04815v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Survey of Pun Generation: Datasets, Evaluations and Methodologies", "abstract": "Pun generation seeks to creatively modify linguistic elements in text to\nproduce humour or evoke double meanings. It also aims to preserve coherence and\ncontextual appropriateness, making it useful in creative writing and\nentertainment across various media and contexts. Although pun generation has\nreceived considerable attention in computational linguistics, there is\ncurrently no dedicated survey that systematically reviews this specific area.\nTo bridge this gap, this paper provides a comprehensive review of pun\ngeneration datasets and methods across different stages, including conventional\napproaches, deep learning techniques, and pre-trained language models.\nAdditionally, we summarise both automated and human evaluation metrics used to\nassess the quality of pun generation. Finally, we discuss the research\nchallenges and propose promising directions for future work.", "published": "2025-07-07 09:12:46", "link": "http://arxiv.org/abs/2507.04793v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reason to Rote: Rethinking Memorization in Reasoning", "abstract": "Large language models readily memorize arbitrary training instances, such as\nlabel noise, yet they perform strikingly well on reasoning tasks. In this work,\nwe investigate how language models memorize label noise, and why such\nmemorization in many cases does not heavily affect generalizable reasoning\ncapabilities. Using two controllable synthetic reasoning datasets with noisy\nlabels, four-digit addition (FDA) and two-hop relational reasoning (THR), we\ndiscover a reliance of memorization on generalizable reasoning mechanisms:\nmodels continue to compute intermediate reasoning outputs even when retrieving\nmemorized noisy labels, and intervening reasoning adversely affects\nmemorization. We further show that memorization operates through distributed\nencoding, i.e., aggregating various inputs and intermediate results, rather\nthan building a look-up mechanism from inputs to noisy labels. Moreover, our\nFDA case study reveals memorization occurs via outlier heuristics, where\nexisting neuron activation patterns are slightly shifted to fit noisy labels.\nTogether, our findings suggest that memorization of label noise in language\nmodels builds on, rather than overrides, the underlying reasoning mechanisms,\nshedding lights on the intriguing phenomenon of benign memorization.", "published": "2025-07-07 08:59:06", "link": "http://arxiv.org/abs/2507.04782v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ABench-Physics: Benchmarking Physical Reasoning in LLMs via High-Difficulty and Dynamic Physics Problems", "abstract": "Large Language Models (LLMs) have shown impressive performance in domains\nsuch as mathematics and programming, yet their capabilities in physics remain\nunderexplored and poorly understood. Physics poses unique challenges that\ndemand not only precise computation but also deep conceptual understanding and\nphysical modeling skills. Existing benchmarks often fall short due to limited\ndifficulty, multiple-choice formats, and static evaluation settings that fail\nto capture physical modeling ability. In this paper, we introduce\nABench-Physics, a novel benchmark designed to rigorously evaluate LLMs'\nphysical reasoning and generalization capabilities. ABench-Physics consists of\ntwo components: Phy_A, a static set of 400 graduate- or Olympiad-level\nproblems; and Phy_B, a dynamic subset of 100 problems equipped with an\nautomatic variation engine to test model robustness across changing conditions.\nAll questions require precise numerical answers, with strict formatting and\ntolerance constraints. Our evaluation of several state-of-the-art LLMs reveals\nsubstantial performance gaps, highlighting persistent limitations in physical\nreasoning, especially in generalization to dynamic variants. ABench-Physics\nprovides a challenging and diagnostic framework for advancing scientific\nreasoning in LLMs.", "published": "2025-07-07 08:43:56", "link": "http://arxiv.org/abs/2507.04766v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CoSteer: Collaborative Decoding-Time Personalization via Local Delta Steering", "abstract": "Personalized text generation has become crucial for adapting language models\nto diverse and evolving users' personal context across cultural, temporal, and\ncontextual dimensions. While existing methods often rely on centralized\nfine-tuning or static preference alignment, they struggle to achieve real-time\nadaptation under resource constraints inherent to personal devices. This\nlimitation creates a dilemma: large cloud-based models lack access to localized\nuser-specific information, while small on-device models cannot match the\ngeneration quality of their cloud counterparts. To address this dichotomy, we\npresent CoSteer, a novel collaborative framework that enables decoding-time\npersonalization through localized delta steering. Our key insight lies in\nleveraging the logits difference between personal context-aware and -agnostic\noutputs from local small models as steering signals for cloud-based LLMs.\nSpecifically, we formulate token-level optimization as an online learning\nproblem, where local delta vectors dynamically adjust the remote LLM's logits\nwithin the on-device environment. This approach preserves privacy by\ntransmitting only the final steered tokens rather than raw data or intermediate\nvectors, while maintaining cloud-based LLMs' general capabilities without\nfine-tuning. Through comprehensive experiments on various personalized\ngeneration tasks, we demonstrate that CoSteer effectively assists LLMs in\ngenerating personalized content by leveraging locally stored user profiles and\nhistories, ensuring privacy preservation through on-device data processing\nwhile maintaining acceptable computational overhead.", "published": "2025-07-07 08:32:29", "link": "http://arxiv.org/abs/2507.04756v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMs as Architects and Critics for Multi-Source Opinion Summarization", "abstract": "Multi-source Opinion Summarization (M-OS) extends beyond traditional opinion\nsummarization by incorporating additional sources of product metadata such as\ndescriptions, key features, specifications, and ratings, alongside reviews.\nThis integration results in comprehensive summaries that capture both\nsubjective opinions and objective product attributes essential for informed\ndecision-making. While Large Language Models (LLMs) have shown significant\nsuccess in various Natural Language Processing (NLP) tasks, their potential in\nM-OS remains largely unexplored. Additionally, the lack of evaluation datasets\nfor this task has impeded further advancements. To bridge this gap, we\nintroduce M-OS-EVAL, a benchmark dataset for evaluating multi-source opinion\nsummaries across 7 key dimensions: fluency, coherence, relevance, faithfulness,\naspect coverage, sentiment consistency, specificity. Our results demonstrate\nthat M-OS significantly enhances user engagement, as evidenced by a user study\nin which, on average, 87% of participants preferred M-OS over opinion\nsummaries. Our experiments demonstrate that factually enriched summaries\nenhance user engagement. Notably, M-OS-PROMPTS exhibit stronger alignment with\nhuman judgment, achieving an average Spearman correlation of \\r{ho} = 0.74,\nwhich surpasses the performance of previous methodologies.", "published": "2025-07-07 08:27:44", "link": "http://arxiv.org/abs/2507.04751v1", "categories": ["cs.CL", "I.2.7; H.3.1; I.2.6"], "primary_category": "cs.CL"}
{"title": "A Tale of Two Scripts: Transliteration and Post-Correction for Judeo-Arabic", "abstract": "Judeo-Arabic refers to Arabic variants historically spoken by Jewish\ncommunities across the Arab world, primarily during the Middle Ages. Unlike\nstandard Arabic, it is written in Hebrew script by Jewish writers and for\nJewish audiences. Transliterating Judeo-Arabic into Arabic script is\nchallenging due to ambiguous letter mappings, inconsistent orthographic\nconventions, and frequent code-switching into Hebrew and Aramaic. In this\npaper, we introduce a two-step approach to automatically transliterate\nJudeo-Arabic into Arabic script: simple character-level mapping followed by\npost-correction to address grammatical and orthographic errors. We also present\nthe first benchmark evaluation of LLMs on this task. Finally, we show that\ntransliteration enables Arabic NLP tools to perform morphosyntactic tagging and\nmachine translation, which would have not been feasible on the original texts.", "published": "2025-07-07 08:19:08", "link": "http://arxiv.org/abs/2507.04746v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word stress in self-supervised speech models: A cross-linguistic comparison", "abstract": "In this paper we study word stress representations learned by self-supervised\nspeech models (S3M), specifically the Wav2vec 2.0 model. We investigate the S3M\nrepresentations of word stress for five different languages: Three languages\nwith variable or lexical stress (Dutch, English and German) and two languages\nwith fixed or demarcative stress (Hungarian and Polish). We train diagnostic\nstress classifiers on S3M embeddings and show that they can distinguish between\nstressed and unstressed syllables in read-aloud short sentences with high\naccuracy. We also tested language-specificity effects of S3M word stress. The\nresults indicate that the word stress representations are language-specific,\nwith a greater difference between the set of variable versus the set of fixed\nstressed languages.", "published": "2025-07-07 08:10:26", "link": "http://arxiv.org/abs/2507.04738v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"This Suits You the Best\": Query Focused Comparative Explainable Summarization", "abstract": "Product recommendations inherently involve comparisons, yet traditional\nopinion summarization often fails to provide holistic comparative insights. We\npropose the novel task of generating Query-Focused Comparative Explainable\nSummaries (QF-CES) using Multi-Source Opinion Summarization (M-OS). To address\nthe lack of query-focused recommendation datasets, we introduce MS-Q2P,\ncomprising 7,500 queries mapped to 22,500 recommended products with metadata.\nWe leverage Large Language Models (LLMs) to generate tabular comparative\nsummaries with query-specific explanations. Our approach is personalized,\nprivacy-preserving, recommendation engine-agnostic, and category-agnostic. M-OS\nas an intermediate step reduces inference latency approximately by 40% compared\nto the direct input approach (DIA), which processes raw data directly. We\nevaluate open-source and proprietary LLMs for generating and assessing QF-CES.\nExtensive evaluations using QF-CES-PROMPT across 5 dimensions (clarity,\nfaithfulness, informativeness, format adherence, and query relevance) showed an\naverage Spearman correlation of 0.74 with human judgments, indicating its\npotential for QF-CES evaluation.", "published": "2025-07-07 07:58:15", "link": "http://arxiv.org/abs/2507.04733v1", "categories": ["cs.CL", "cs.IR", "H.3.1; I.2.7; H.1.2"], "primary_category": "cs.CL"}
{"title": "LOOM-Scope: a comprehensive and efficient LOng-cOntext Model evaluation framework", "abstract": "Long-context processing has become a fundamental capability for large\nlanguage models~(LLMs). To assess model's long-context performance, numerous\nlong-context evaluation benchmarks have been proposed. However, variations in\nevaluation settings across these benchmarks lead to inconsistent results,\nmaking it difficult to draw reliable comparisons. Besides, the high\ncomputational cost of long-context evaluation poses a significant barrier for\nthe community to conduct comprehensive assessments of long-context models. In\nthis paper, we propose LOOM-Scope, a comprehensive and efficient framework for\nlong-context evaluation. LOOM-Scope standardizes evaluation settings across\ndiverse benchmarks, supports deployment of efficient long-context inference\nacceleration methods, and introduces a holistic yet lightweight benchmark suite\nto evaluate models comprehensively. Homepage: https://loomscope.github.io", "published": "2025-07-07 07:33:24", "link": "http://arxiv.org/abs/2507.04723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why We Feel What We Feel: Joint Detection of Emotions and Their Opinion Triggers in E-commerce", "abstract": "Customer reviews on e-commerce platforms capture critical affective signals\nthat drive purchasing decisions. However, no existing research has explored the\njoint task of emotion detection and explanatory span identification in\ne-commerce reviews - a crucial gap in understanding what triggers customer\nemotional responses. To bridge this gap, we propose a novel joint task unifying\nEmotion detection and Opinion Trigger extraction (EOT), which explicitly models\nthe relationship between causal text spans (opinion triggers) and affective\ndimensions (emotion categories) grounded in Plutchik's theory of 8 primary\nemotions. In the absence of labeled data, we introduce EOT-X, a human-annotated\ncollection of 2,400 reviews with fine-grained emotions and opinion triggers. We\nevaluate 23 Large Language Models (LLMs) and present EOT-DETECT, a structured\nprompting framework with systematic reasoning and self-reflection. Our\nframework surpasses zero-shot and chain-of-thought techniques, across\ne-commerce domains.", "published": "2025-07-07 06:59:37", "link": "http://arxiv.org/abs/2507.04708v1", "categories": ["cs.CL", "I.2.7; H.3.1; I.2.6"], "primary_category": "cs.CL"}
{"title": "XiYan-SQL: A Novel Multi-Generator Framework For Text-to-SQL", "abstract": "To leverage the advantages of LLM in addressing challenges in the Text-to-SQL\ntask, we present XiYan-SQL, an innovative framework effectively generating and\nutilizing multiple SQL candidates. It consists of three components: 1) a Schema\nFilter module filtering and obtaining multiple relevant schemas; 2) a\nmulti-generator ensemble approach generating multiple highquality and diverse\nSQL queries; 3) a selection model with a candidate reorganization strategy\nimplemented to obtain the optimal SQL query. Specifically, for the\nmulti-generator ensemble, we employ a multi-task fine-tuning strategy to\nenhance the capabilities of SQL generation models for the intrinsic alignment\nbetween SQL and text, and construct multiple generation models with distinct\ngeneration styles by fine-tuning across different SQL formats. The experimental\nresults and comprehensive analysis demonstrate the effectiveness and robustness\nof our framework. Overall, XiYan-SQL achieves a new SOTA performance of 75.63%\non the notable BIRD benchmark, surpassing all previous methods. It also attains\nSOTA performance on the Spider test set with an accuracy of 89.65%.", "published": "2025-07-07 06:50:46", "link": "http://arxiv.org/abs/2507.04701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R1-RE: Cross-Domain Relationship Extraction with RLVR", "abstract": "Relationship extraction (RE) is a core task in natural language processing.\nTraditional approaches typically frame RE as a supervised learning problem,\ndirectly mapping context to labels-an approach that often suffers from poor\nout-of-domain (OOD) generalization. Inspired by the workflow of human\nannotators, we reframe RE as a reasoning task guided by annotation guidelines\nand introduce R1-RE, the first reinforcement learning with verifiable reward\n(RLVR) framework for RE tasks. Our method elicits the reasoning abilities of\nsmall language models for annotation tasks, resulting in significantly improved\nOOD robustness. We evaluate our approach on the public Sem-2010 dataset and a\nprivate MDKG dataset. The R1-RE-7B model attains an average OOD accuracy of\napproximately 70%, on par with leading proprietary models such as GPT-4o.\nAdditionally, our comprehensive analysis provides novel insights into the\ntraining dynamics and emergent reasoning behaviors of the RLVR paradigm for RE.", "published": "2025-07-07 03:50:59", "link": "http://arxiv.org/abs/2507.04642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Put Teacher in Student's Shoes: Cross-Distillation for Ultra-compact Model Compression Framework", "abstract": "In the era of mobile computing, deploying efficient Natural Language\nProcessing (NLP) models in resource-restricted edge settings presents\nsignificant challenges, particularly in environments requiring strict privacy\ncompliance, real-time responsiveness, and diverse multi-tasking capabilities.\nThese challenges create a fundamental need for ultra-compact models that\nmaintain strong performance across various NLP tasks while adhering to\nstringent memory constraints. To this end, we introduce Edge ultra-lIte BERT\nframework (EI-BERT) with a novel cross-distillation method. EI-BERT efficiently\ncompresses models through a comprehensive pipeline including hard token\npruning, cross-distillation and parameter quantization. Specifically, the\ncross-distillation method uniquely positions the teacher model to understand\nthe student model's perspective, ensuring efficient knowledge transfer through\nparameter integration and the mutual interplay between models. Through\nextensive experiments, we achieve a remarkably compact BERT-based model of only\n1.91 MB - the smallest to date for Natural Language Understanding (NLU) tasks.\nThis ultra-compact model has been successfully deployed across multiple\nscenarios within the Alipay ecosystem, demonstrating significant improvements\nin real-world applications. For example, it has been integrated into Alipay's\nlive Edge Recommendation system since January 2024, currently serving the app's\nrecommendation traffic across \\textbf{8.4 million daily active devices}.", "published": "2025-07-07 03:38:09", "link": "http://arxiv.org/abs/2507.04636v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Aware Self-Correction in Language Models via Structured Memory Graphs", "abstract": "Large Language Models (LLMs) are powerful yet prone to generating factual\nerrors, commonly referred to as hallucinations. We present a lightweight,\ninterpretable framework for knowledge-aware self-correction of LLM outputs\nusing structured memory graphs based on RDF triples. Without retraining or\nfine-tuning, our method post-processes model outputs and corrects factual\ninconsistencies via external semantic memory. We demonstrate the approach using\nDistilGPT-2 and show promising results on simple factual prompts.", "published": "2025-07-07 02:55:12", "link": "http://arxiv.org/abs/2507.04625v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retain or Reframe? A Computational Framework for the Analysis of Framing in News Articles and Reader Comments", "abstract": "When a news article describes immigration as an \"economic burden\" or a\n\"humanitarian crisis,\" it selectively emphasizes certain aspects of the issue.\nAlthough \\textit{framing} shapes how the public interprets such issues,\naudiences do not absorb frames passively but actively reorganize the presented\ninformation. While this relationship between source content and audience\nresponse is well-documented in the social sciences, NLP approaches often ignore\nit, detecting frames in articles and responses in isolation. We present the\nfirst computational framework for large-scale analysis of framing across source\ncontent (news articles) and audience responses (reader comments).\nMethodologically, we refine frame labels and develop a framework that\nreconstructs dominant frames in articles and comments from sentence-level\npredictions, and aligns articles with topically relevant comments. Applying our\nframework across eleven topics and two news outlets, we find that frame reuse\nin comments correlates highly across outlets, while topic-specific patterns\nvary. We release a frame classifier that performs well on both articles and\ncomments, a dataset of article and comment sentences manually labeled for\nframes, and a large-scale dataset of articles and comments with predicted frame\nlabels.", "published": "2025-07-07 02:05:56", "link": "http://arxiv.org/abs/2507.04612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRIME: Large Language Model Personalization with Cognitive Memory and Thought Processes", "abstract": "Large language model (LLM) personalization aims to align model outputs with\nindividuals' unique preferences and opinions. While recent efforts have\nimplemented various personalization methods, a unified theoretical framework\nthat can systematically understand the drivers of effective personalization is\nstill lacking. In this work, we integrate the well-established cognitive\ndual-memory model into LLM personalization, by mirroring episodic memory to\nhistorical user engagements and semantic memory to long-term, evolving user\nbeliefs. Specifically, we systematically investigate memory instantiations and\nintroduce a unified framework, PRIME, using episodic and semantic memory\nmechanisms. We further augment PRIME with a novel personalized thinking\ncapability inspired by the slow thinking strategy. Moreover, recognizing the\nabsence of suitable benchmarks, we introduce a dataset using Change My View\n(CMV) from Reddit, specifically designed to evaluate long-context\npersonalization. Extensive experiments validate PRIME's effectiveness across\nboth long- and short-context scenarios. Further analysis confirms that PRIME\neffectively captures dynamic personalization beyond mere popularity biases.", "published": "2025-07-07 01:54:34", "link": "http://arxiv.org/abs/2507.04607v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents", "abstract": "Multimodal embedding models have been crucial in enabling various downstream\ntasks such as semantic similarity, information retrieval, and clustering over\ndifferent modalities. However, existing multimodal embeddings like VLM2Vec,\nE5-V, GME are predominantly focused on natural images, with limited support for\nother visual forms such as videos and visual documents. This restricts their\napplicability in real-world scenarios, including AI agents, multi-modal search\nand recommendation, and retrieval-augmented generation (RAG). To close this\ngap, we propose VLM2Vec-V2, a unified framework for learning embeddings across\ndiverse visual forms. First, we introduce MMEB-V2, a comprehensive benchmark\nthat extends MMEB with five new task types: visual document retrieval, video\nretrieval, temporal grounding, video classification and video question\nanswering - spanning text, image, video, and visual document inputs. Next, we\ntrain VLM2Vec-V2, a general-purpose embedding model that supports text, image,\nvideo, and visual document inputs. Extensive experiments show that VLM2Vec-V2\nachieves strong performance not only on the newly introduced video and document\nretrieval tasks, but also improves over prior baselines on the original image\nbenchmarks. Through extensive evaluation, our study offers insights into the\ngeneralizability of various multimodal embedding models and highlights\neffective strategies for unified embedding learning, laying the groundwork for\nmore scalable and adaptable representation learning in both research and\nreal-world settings.", "published": "2025-07-07 00:51:57", "link": "http://arxiv.org/abs/2507.04590v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "From Marginal to Joint Predictions: Evaluating Scene-Consistent Trajectory Prediction Approaches for Automated Driving", "abstract": "Accurate motion prediction of surrounding traffic participants is crucial for\nthe safe and efficient operation of automated vehicles in dynamic environments.\nMarginal prediction models commonly forecast each agent's future trajectories\nindependently, often leading to sub-optimal planning decisions for an automated\nvehicle. In contrast, joint prediction models explicitly account for the\ninteractions between agents, yielding socially and physically consistent\npredictions on a scene level. However, existing approaches differ not only in\ntheir problem formulation but also in the model architectures and\nimplementation details used, making it difficult to compare them. In this work,\nwe systematically investigate different approaches to joint motion prediction,\nincluding post-processing of the marginal predictions, explicitly training the\nmodel for joint predictions, and framing the problem as a generative task. We\nevaluate each approach in terms of prediction accuracy, multi-modality, and\ninference efficiency, offering a comprehensive analysis of the strengths and\nlimitations of each approach. Several prediction examples are available at\nhttps://frommarginaltojointpred.github.io/.", "published": "2025-07-07 17:58:53", "link": "http://arxiv.org/abs/2507.05254v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Action Space Reduction Strategies for Reinforcement Learning in Autonomous Driving", "abstract": "Reinforcement Learning (RL) offers a promising framework for autonomous\ndriving by enabling agents to learn control policies through interaction with\nenvironments. However, large and high-dimensional action spaces often used to\nsupport fine-grained control can impede training efficiency and increase\nexploration costs. In this study, we introduce and evaluate two novel\nstructured action space modification strategies for RL in autonomous driving:\ndynamic masking and relative action space reduction. These approaches are\nsystematically compared against fixed reduction schemes and full action space\nbaselines to assess their impact on policy learning and performance. Our\nframework leverages a multimodal Proximal Policy Optimization agent that\nprocesses both semantic image sequences and scalar vehicle states. The proposed\ndynamic and relative strategies incorporate real-time action masking based on\ncontext and state transitions, preserving action consistency while eliminating\ninvalid or suboptimal choices. Through comprehensive experiments across diverse\ndriving routes, we show that action space reduction significantly improves\ntraining stability and policy performance. The dynamic and relative schemes, in\nparticular, achieve a favorable balance between learning speed, control\nprecision, and generalization. These findings highlight the importance of\ncontext-aware action space design for scalable and reliable RL in autonomous\ndriving tasks.", "published": "2025-07-07 17:58:08", "link": "http://arxiv.org/abs/2507.05251v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent Collaboration", "abstract": "In collaborative tasks, being able to adapt to your teammates is a necessary\nrequirement for success. When teammates are heterogeneous, such as in\nhuman-agent teams, agents need to be able to observe, recognize, and adapt to\ntheir human partners in real time. This becomes particularly challenging in\ntasks with time pressure and complex strategic spaces where the dynamics can\nchange rapidly. In this work, we introduce TALENTS, a strategy-conditioned\ncooperator framework that learns to represent, categorize, and adapt to a range\nof partner strategies, enabling ad-hoc teamwork. Our approach utilizes a\nvariational autoencoder to learn a latent strategy space from trajectory data.\nThis latent space represents the underlying strategies that agents employ.\nSubsequently, the system identifies different types of strategy by clustering\nthe data. Finally, a cooperator agent is trained to generate partners for each\ntype of strategy, conditioned on these clusters. In order to adapt to\npreviously unseen partners, we leverage a fixed-share regret minimization\nalgorithm that infers and adjusts the estimated partner strategy dynamically.\nWe assess our approach in a customized version of the Overcooked environment,\nposing a challenging cooperative cooking task that demands strong coordination\nacross a wide range of possible strategies. Using an online user study, we show\nthat our agent outperforms current baselines when working with unfamiliar human\npartners.", "published": "2025-07-07 17:53:13", "link": "http://arxiv.org/abs/2507.05244v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "CTA: Cross-Task Alignment for Better Test Time Training", "abstract": "Deep learning models have demonstrated exceptional performance across a wide\nrange of computer vision tasks. However, their performance often degrades\nsignificantly when faced with distribution shifts, such as domain or dataset\nchanges. Test-Time Training (TTT) has emerged as an effective method to enhance\nmodel robustness by incorporating an auxiliary unsupervised task during\ntraining and leveraging it for model updates at test time. In this work, we\nintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.\nUnlike existing TTT methods, CTA does not require a specialized model\narchitecture and instead takes inspiration from the success of multi-modal\ncontrastive learning to align a supervised encoder with a self-supervised one.\nThis process enforces alignment between the learned representations of both\nmodels, thereby mitigating the risk of gradient interference, preserving the\nintrinsic robustness of self-supervised learning and enabling more semantically\nmeaningful updates at test-time. Experimental results demonstrate substantial\nimprovements in robustness and generalization over the state-of-the-art on\nseveral benchmark datasets.", "published": "2025-07-07 17:33:20", "link": "http://arxiv.org/abs/2507.05221v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "All in One: Visual-Description-Guided Unified Point Cloud Segmentation", "abstract": "Unified segmentation of 3D point clouds is crucial for scene understanding,\nbut is hindered by its sparse structure, limited annotations, and the challenge\nof distinguishing fine-grained object classes in complex environments. Existing\nmethods often struggle to capture rich semantic and contextual information due\nto limited supervision and a lack of diverse multimodal cues, leading to\nsuboptimal differentiation of classes and instances. To address these\nchallenges, we propose VDG-Uni3DSeg, a novel framework that integrates\npre-trained vision-language models (e.g., CLIP) and large language models\n(LLMs) to enhance 3D segmentation. By leveraging LLM-generated textual\ndescriptions and reference images from the internet, our method incorporates\nrich multimodal cues, facilitating fine-grained class and instance separation.\nWe further design a Semantic-Visual Contrastive Loss to align point features\nwith multimodal queries and a Spatial Enhanced Module to model scene-wide\nrelationships efficiently. Operating within a closed-set paradigm that utilizes\nmultimodal knowledge generated offline, VDG-Uni3DSeg achieves state-of-the-art\nresults in semantic, instance, and panoptic segmentation, offering a scalable\nand practical solution for 3D understanding. Our code is available at\nhttps://github.com/Hanzy1996/VDG-Uni3DSeg.", "published": "2025-07-07 17:22:00", "link": "http://arxiv.org/abs/2507.05211v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling", "abstract": "The rapid advancement of Embodied AI has led to an increasing demand for\nlarge-scale, high-quality real-world data. However, collecting such embodied\ndata remains costly and inefficient. As a result, simulation environments have\nbecome a crucial surrogate for training robot policies. Yet, the significant\nReal2Sim2Real gap remains a critical bottleneck, particularly in terms of\nphysical dynamics and visual appearance. To address this challenge, we propose\nEmbodieDreamer, a novel framework that reduces the Real2Sim2Real gap from both\nthe physics and appearance perspectives. Specifically, we propose PhysAligner,\na differentiable physics module designed to reduce the Real2Sim physical gap.\nIt jointly optimizes robot-specific parameters such as control gains and\nfriction coefficients to better align simulated dynamics with real-world\nobservations. In addition, we introduce VisAligner, which incorporates a\nconditional video diffusion model to bridge the Sim2Real appearance gap by\ntranslating low-fidelity simulated renderings into photorealistic videos\nconditioned on simulation states, enabling high-fidelity visual transfer.\nExtensive experiments validate the effectiveness of EmbodieDreamer. The\nproposed PhysAligner reduces physical parameter estimation error by 3.74%\ncompared to simulated annealing methods while improving optimization speed by\n89.91\\%. Moreover, training robot policies in the generated photorealistic\nenvironment leads to a 29.17% improvement in the average task success rate\nacross real-world tasks after reinforcement learning. Code, model and data will\nbe publicly available.", "published": "2025-07-07 16:58:17", "link": "http://arxiv.org/abs/2507.05198v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Train-before-Test Harmonizes Language Model Rankings", "abstract": "Existing language model benchmarks provide contradictory model rankings, even\nfor benchmarks that aim to capture similar skills. This dilemma of conflicting\nrankings hampers model selection, clouds model comparisons, and adds confusion\nto a growing ecosystem of competing models. Recent work attributed ranking\ndisagreement to the phenomenon of training on the test task: As released,\ndifferent models exhibit a different level of preparation for any given test\ntask. A candidate solution to the problem is train-before-test: Give each model\nthe same benchmark-specific finetuning before evaluation. Our primary\ncontribution is a broad empirical evaluation of train-before-test across 24\nbenchmarks and 61 models. We show that train-before-test significantly improves\nranking agreement consistently across all benchmarks. Whereas rankings have\nlittle external validity to start with, they enjoy a significant degree of\nexternal validity when applying train-before-test: Model rankings transfer\ngracefully from one benchmark to the other. Even within the same model family,\ntrain-before-test reduces strong ranking disagreement to near-perfect\nagreement. In addition, train-before-test reduces the model-score matrix to\nessentially rank one, revealing new insights into the latent factors of\nbenchmark performance. Our work supports the recommendation to make\ntrain-before-test a default component of LLM benchmarking.", "published": "2025-07-07 16:54:18", "link": "http://arxiv.org/abs/2507.05195v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Infrastructuring Contestability: A Framework for Community-Defined AI Value Pluralism", "abstract": "The proliferation of AI-driven systems presents a fundamental challenge to\nHuman-Computer Interaction (HCI) and Computer-Supported Cooperative Work\n(CSCW), often diminishing user agency and failing to account for value\npluralism. Current approaches to value alignment, which rely on centralized,\ntop-down definitions, lack the mechanisms for meaningful contestability. This\nleaves users and communities unable to challenge or shape the values embedded\nin the systems that govern their digital lives, creating a crisis of legitimacy\nand trust. This paper introduces Community-Defined AI Value Pluralism (CDAVP),\na socio-technical framework that addresses this gap. It reframes the design\nproblem from achieving a single aligned state to infrastructuring a dynamic\necosystem for value deliberation and application. At its core, CDAVP enables\ndiverse, self-organizing communities to define and maintain explicit value\nprofiles - rich, machine-readable representations that can encompass not only\npreferences but also community-specific rights and duties. These profiles are\nthen contextually activated by the end-user, who retains ultimate control\n(agency) over which values guide the AI's behavior. AI applications, in turn,\nare designed to transparently interpret these profiles and moderate conflicts,\nadhering to a set of non-negotiable, democratically-legitimated meta-rules. The\ndesigner's role shifts from crafting static interfaces to becoming an architect\nof participatory ecosystems. We argue that infrastructuring for pluralism is a\nnecessary pathway toward achieving robust algorithmic accountability and\ngenuinely contestable, human-centric AI.", "published": "2025-07-07 16:45:50", "link": "http://arxiv.org/abs/2507.05187v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale", "abstract": "Despite rapid progress in large language model (LLM)-based multi-agent\nsystems, current benchmarks fall short in evaluating their scalability,\nrobustness, and coordination capabilities in complex, dynamic, real-world\ntasks. Existing environments typically focus on small-scale, fully observable,\nor low-complexity domains, limiting their utility for developing and assessing\nnext-generation multi-agent Agentic AI frameworks. We introduce CREW-Wildfire,\nan open-source benchmark designed to close this gap. Built atop the human-AI\nteaming CREW simulation platform, CREW-Wildfire offers procedurally generated\nwildfire response scenarios featuring large maps, heterogeneous agents, partial\nobservability, stochastic dynamics, and long-horizon planning objectives. The\nenvironment supports both low-level control and high-level natural language\ninteractions through modular Perception and Execution modules. We implement and\nevaluate several state-of-the-art LLM-based multi-agent Agentic AI frameworks,\nuncovering significant performance gaps that highlight the unsolved challenges\nin large-scale coordination, communication, spatial reasoning, and long-horizon\nplanning under uncertainty. By providing more realistic complexity, scalable\narchitecture, and behavioral evaluation metrics, CREW-Wildfire establishes a\ncritical foundation for advancing research in scalable multi-agent Agentic\nintelligence. All code, environments, data, and baselines will be released to\nsupport future research in this emerging domain.", "published": "2025-07-07 16:33:42", "link": "http://arxiv.org/abs/2507.05178v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "LAID: Lightweight AI-Generated Image Detection in Spatial and Spectral Domains", "abstract": "The recent proliferation of photorealistic AI-generated images (AIGI) has\nraised urgent concerns about their potential misuse, particularly on social\nmedia platforms. Current state-of-the-art AIGI detection methods typically rely\non large, deep neural architectures, creating significant computational\nbarriers to real-time, large-scale deployment on platforms like social media.\nTo challenge this reliance on computationally intensive models, we introduce\nLAID, the first framework -- to our knowledge -- that benchmarks and evaluates\nthe detection performance and efficiency of off-the-shelf lightweight neural\nnetworks. In this framework, we comprehensively train and evaluate selected\nmodels on a representative subset of the GenImage dataset across spatial,\nspectral, and fusion image domains. Our results demonstrate that lightweight\nmodels can achieve competitive accuracy, even under adversarial conditions,\nwhile incurring substantially lower memory and computation costs compared to\ncurrent state-of-the-art methods. This study offers valuable insight into the\ntrade-off between efficiency and performance in AIGI detection and lays a\nfoundation for the development of practical, scalable, and trustworthy\ndetection systems. The source code of LAID can be found at:\nhttps://github.com/nchivar/LAID.", "published": "2025-07-07 16:18:19", "link": "http://arxiv.org/abs/2507.05162v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Effects of Unplanned Incoming Flights on Airport Relief Processes after a Major Natural Disaster", "abstract": "The severity of natural disasters is increasing every year, impacting many\npeople's lives. During the response phase of disasters, airports are important\nhubs where relief aid arrives and people need to be evacuated. However, the\nairport often forms a bottleneck in these relief operations due to the sudden\nneed for increased capacity. Limited research has been done on the operational\nside of airport disaster management. Experts identify the main problems as,\nfirst, the asymmetry of information between the airport and incoming flights,\nand second, the lack of resources. The goal of this research is to understand\nthe effects of incomplete knowledge of incoming flights with different resource\nallocation strategies on the performance of cargo handling operations at an\nairport after a natural disaster. An agent-based model is created, implementing\nrealistic offloading strategies with different degrees of information\nuncertainty. Model calibration and verification are performed with experts in\nthe field. The model performance is measured by the average turnaround time,\nwhich is divided into offloading time, boarding time, and cumulative waiting\ntimes. The results show that the effects of one unplanned aircraft are\nnegligible. However, all waiting times increase with more arriving unplanned\naircraft.", "published": "2025-07-07 16:00:26", "link": "http://arxiv.org/abs/2507.05150v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "OGF: An Online Gradient Flow Method for Optimizing the Statistical Steady-State Time Averages of Unsteady Turbulent Flows", "abstract": "Turbulent flows are chaotic and unsteady, but their statistical distribution\nconverges to a statistical steady state. Engineering quantities of interest\ntypically take the form of time-average statistics such as $ \\frac{1}{t}\n\\int_0^t f ( u(x,\\tau; \\theta) ) d\\tau \\overset{t \\rightarrow\n\\infty}{\\rightarrow} F(x; \\theta)$, where $u(x,t; \\theta)$ are solutions of the\nNavier--Stokes equations with parameters $\\theta$. Optimizing over $F(x;\n\\theta)$ has many engineering applications including geometric optimization,\nflow control, and closure modeling. However, this remains an open challenge, as\nexisting computational approaches are incapable of scaling to physically\nrepresentative numbers of grid points. The fundamental obstacle is the\nchaoticity of turbulent flows: gradients calculated with the adjoint method\ndiverge exponentially as $t \\rightarrow \\infty$.\n  We develop a new online gradient-flow (OGF) method that is scalable to large\ndegree-of-freedom systems and enables optimizing for the steady-state\nstatistics of chaotic, unsteady, turbulence-resolving simulations. The method\nforward-propagates an online estimate for the gradient of $F(x; \\theta)$ while\nsimultaneously performing online updates of the parameters $\\theta$. A key\nfeature is the fully online nature of the algorithm to facilitate faster\noptimization progress and its combination with a finite-difference estimator to\navoid the divergence of gradients due to chaoticity. The proposed OGF method is\ndemonstrated for optimizations over three chaotic ordinary and partial\ndifferential equations: the Lorenz-63 equation, the Kuramoto--Sivashinsky\nequation, and Navier--Stokes solutions of compressible, forced, homogeneous\nisotropic turbulence. In each case, the OGF method successfully reduces the\nloss based on $F(x; \\theta)$ by several orders of magnitude and accurately\nrecovers the optimal parameters.", "published": "2025-07-07 16:00:15", "link": "http://arxiv.org/abs/2507.05149v1", "categories": ["physics.flu-dyn", "cs.AI", "cs.LG"], "primary_category": "physics.flu-dyn"}
{"title": "GIST: Cross-Domain Click-Through Rate Prediction via Guided Content-Behavior Distillation", "abstract": "Cross-domain Click-Through Rate prediction aims to tackle the data sparsity\nand the cold start problems in online advertising systems by transferring\nknowledge from source domains to a target domain. Most existing methods rely on\noverlapping users to facilitate this transfer, often focusing on joint training\nor pre-training with fine-tuning approach to connect the source and target\ndomains. However, in real-world industrial settings, joint training struggles\nto learn optimal representations with different distributions, and pre-training\nwith fine-tuning is not well-suited for continuously integrating new data. To\naddress these issues, we propose GIST, a cross-domain lifelong sequence model\nthat decouples the training processes of the source and target domains. Unlike\nprevious methods that search lifelong sequences in the source domains using\nonly content or behavior signals or their simple combinations, we innovatively\nintroduce a Content-Behavior Joint Training Module (CBJT), which aligns\ncontent-behavior distributions and combines them with guided information to\nfacilitate a more stable representation. Furthermore, we develop an Asymmetric\nSimilarity Integration strategy (ASI) to augment knowledge transfer through\nsimilarity computation. Extensive experiments demonstrate the effectiveness of\nGIST, surpassing SOTA methods on offline evaluations and an online A/B test.\nDeployed on the Xiaohongshu (RedNote) platform, GIST effectively enhances\nonline ads system performance at scale, serving hundreds of millions of daily\nactive users.", "published": "2025-07-07 15:51:27", "link": "http://arxiv.org/abs/2507.05142v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LVM4CSI: Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks", "abstract": "Accurate channel state information (CSI) is critical to the performance of\nwireless communication systems, especially with the increasing scale and\ncomplexity introduced by 5G and future 6G technologies. While artificial\nintelligence (AI) offers a promising approach to CSI acquisition and\nutilization, existing methods largely depend on task-specific neural networks\n(NNs) that require expert-driven design and large training datasets, limiting\ntheir generalizability and practicality. To address these challenges, we\npropose LVM4CSI, a general and efficient framework that leverages the\nstructural similarity between CSI and computer vision (CV) data to directly\napply large vision models (LVMs) pre-trained on extensive CV datasets to\nwireless tasks without any fine-tuning, in contrast to large language\nmodel-based methods that generally necessitate fine-tuning. LVM4CSI maps CSI\ntasks to analogous CV tasks, transforms complex-valued CSI into visual formats\ncompatible with LVMs, and integrates lightweight trainable layers to adapt\nextracted features to specific communication objectives. We validate LVM4CSI\nthrough three representative case studies, including channel estimation, human\nactivity recognition, and user localization. Results demonstrate that LVM4CSI\nachieves comparable or superior performance to task-specific NNs, including an\nimprovement exceeding 9.61 dB in channel estimation and approximately 40%\nreduction in localization error. Furthermore, it significantly reduces the\nnumber of trainable parameters and eliminates the need for task-specific NN\ndesign.", "published": "2025-07-07 15:33:55", "link": "http://arxiv.org/abs/2507.05121v1", "categories": ["cs.IT", "cs.AI", "cs.CV", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "VerifyLLM: LLM-Based Pre-Execution Task Plan Verification for Robots", "abstract": "In the field of robotics, researchers face a critical challenge in ensuring\nreliable and efficient task planning. Verifying high-level task plans before\nexecution significantly reduces errors and enhance the overall performance of\nthese systems. In this paper, we propose an architecture for automatically\nverifying high-level task plans before their execution in simulator or\nreal-world environments. Leveraging Large Language Models (LLMs), our approach\nconsists of two key steps: first, the conversion of natural language\ninstructions into Linear Temporal Logic (LTL), followed by a comprehensive\nanalysis of action sequences. The module uses the reasoning capabilities of the\nLLM to evaluate logical coherence and identify potential gaps in the plan.\nRigorous testing on datasets of varying complexity demonstrates the broad\napplicability of the module to household tasks. We contribute to improving the\nreliability and efficiency of task planning and addresses the critical need for\nrobust pre-execution verification in autonomous systems. The code is available\nat https://verifyllm.github.io.", "published": "2025-07-07 15:31:36", "link": "http://arxiv.org/abs/2507.05118v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift", "abstract": "Knowledge graph (KG) reasoning remains a critical research area focused on\ninferring missing knowledge by analyzing relationships among observed facts.\nDespite its success, a key limitation of existing KG reasoning methods is their\ndependence on the I.I.D assumption. This assumption can easily be violated due\nto unknown sample selection bias during training or agnostic distribution\nshifts during testing, significantly compromising model performance and\nreliability. To facilitate the deployment of KG reasoning in wild environments,\nthis study investigates learning logical rules from KGs affected by unknown\nselection bias. Additionally, we address test sets with agnostic distribution\nshifts, formally defining this challenge as out-of-distribution (OOD) KG\nreasoning-a previously underexplored problem. To solve the issue, we propose\nthe Stable Rule Learning (StableRule) framework, an end-to-end methodology that\nintegrates feature decorrelation with rule learning network, to enhance OOD\ngeneralization performance. By leveraging feature decorrelation, the StableRule\nframework mitigates the adverse effects of covariate shifts arising in OOD\nscenarios, thereby improving the robustness of the rule learning component in\neffectively deriving logical rules. Extensive experiments on seven benchmark\nKGs demonstrate the framework's superior effectiveness and stability across\ndiverse heterogeneous environments, underscoring its practical significance for\nreal-world applications.", "published": "2025-07-07 15:27:48", "link": "http://arxiv.org/abs/2507.05110v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs", "abstract": "Deep learning-based computational methods have achieved promising results in\npredicting protein-protein interactions (PPIs). However, existing benchmarks\npredominantly focus on isolated pairwise evaluations, overlooking a model's\ncapability to reconstruct biologically meaningful PPI networks, which is\ncrucial for biology research. To address this gap, we introduce PRING, the\nfirst comprehensive benchmark that evaluates protein-protein interaction\nprediction from a graph-level perspective. PRING curates a high-quality,\nmulti-species PPI network dataset comprising 21,484 proteins and 186,818\ninteractions, with well-designed strategies to address both data redundancy and\nleakage. Building on this golden-standard dataset, we establish two\ncomplementary evaluation paradigms: (1) topology-oriented tasks, which assess\nintra and cross-species PPI network construction, and (2) function-oriented\ntasks, including protein complex pathway prediction, GO module analysis, and\nessential protein justification. These evaluations not only reflect the model's\ncapability to understand the network topology but also facilitate protein\nfunction annotation, biological module detection, and even disease mechanism\nanalysis. Extensive experiments on four representative model categories,\nconsisting of sequence similarity-based, naive sequence-based, protein language\nmodel-based, and structure-based approaches, demonstrate that current PPI\nmodels have potential limitations in recovering both structural and functional\nproperties of PPI networks, highlighting the gap in supporting real-world\nbiological applications. We believe PRING provides a reliable platform to guide\nthe development of more effective PPI prediction models for the community. The\ndataset and source code of PRING are available at\nhttps://github.com/SophieSarceau/PRING.", "published": "2025-07-07 15:21:05", "link": "http://arxiv.org/abs/2507.05101v1", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.MN"], "primary_category": "cs.LG"}
{"title": "Beyond Features: How Dataset Design Influences Multi-Agent Trajectory Prediction Performance", "abstract": "Accurate trajectory prediction is critical for safe autonomous navigation,\nyet the impact of dataset design on model performance remains understudied.\nThis work systematically examines how feature selection, cross-dataset\ntransfer, and geographic diversity influence trajectory prediction accuracy in\nmulti-agent settings. We evaluate a state-of-the-art model using our novel L4\nMotion Forecasting dataset based on our own data recordings in Germany and the\nUS. This includes enhanced map and agent features. We compare our dataset to\nthe US-centric Argoverse 2 benchmark. First, we find that incorporating\nsupplementary map and agent features unique to our dataset, yields no\nmeasurable improvement over baseline features, demonstrating that modern\narchitectures do not need extensive feature sets for optimal performance. The\nlimited features of public datasets are sufficient to capture convoluted\ninteractions without added complexity. Second, we perform cross-dataset\nexperiments to evaluate how effective domain knowledge can be transferred\nbetween datasets. Third, we group our dataset by country and check the\nknowledge transfer between different driving cultures.", "published": "2025-07-07 15:18:51", "link": "http://arxiv.org/abs/2507.05098v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "The Hidden Threat in Plain Text: Attacking RAG Data Loaders", "abstract": "Large Language Models (LLMs) have transformed human-machine interaction since\nChatGPT's 2022 debut, with Retrieval-Augmented Generation (RAG) emerging as a\nkey framework that enhances LLM outputs by integrating external knowledge.\nHowever, RAG's reliance on ingesting external documents introduces new\nvulnerabilities. This paper exposes a critical security gap at the data loading\nstage, where malicious actors can stealthily corrupt RAG pipelines by\nexploiting document ingestion.\n  We propose a taxonomy of 9 knowledge-based poisoning attacks and introduce\ntwo novel threat vectors -- Content Obfuscation and Content Injection --\ntargeting common formats (DOCX, HTML, PDF). Using an automated toolkit\nimplementing 19 stealthy injection techniques, we test five popular data\nloaders, finding a 74.4% attack success rate across 357 scenarios. We further\nvalidate these threats on six end-to-end RAG systems -- including white-box\npipelines and black-box services like NotebookLM and OpenAI Assistants --\ndemonstrating high success rates and critical vulnerabilities that bypass\nfilters and silently compromise output integrity. Our results emphasize the\nurgent need to secure the document ingestion process in RAG systems against\ncovert content manipulations.", "published": "2025-07-07 15:13:54", "link": "http://arxiv.org/abs/2507.05093v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "How Rules Represent Causal Knowledge: Causal Modeling with Abductive Logic Programs", "abstract": "Pearl observes that causal knowledge enables predicting the effects of\ninterventions, such as actions, whereas descriptive knowledge only permits\ndrawing conclusions from observation. This paper extends Pearl's approach to\ncausality and interventions to the setting of stratified abductive logic\nprograms. It shows how stable models of such programs can be given a causal\ninterpretation by building on philosophical foundations and recent work by\nBochman and Eelink et al. In particular, it provides a translation of abductive\nlogic programs into causal systems, thereby clarifying the informal causal\nreading of logic program rules and supporting principled reasoning about\nexternal actions. The main result establishes that the stable model semantics\nfor stratified programs conforms to key philosophical principles of causation,\nsuch as causal sufficiency, natural necessity, and irrelevance of unobserved\neffects. This justifies the use of stratified abductive logic programs as a\nframework for causal modeling and for predicting the effects of interventions", "published": "2025-07-07 15:12:01", "link": "http://arxiv.org/abs/2507.05088v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Sequential Attention-based Sampling for Histopathological Analysis", "abstract": "Deep neural networks are increasingly applied for automated histopathology.\nYet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering\nit computationally infeasible to analyze them entirely at high resolution.\nDiagnostic labels are largely available only at the slide-level, because expert\nannotation of images at a finer (patch) level is both laborious and expensive.\nMoreover, regions with diagnostic information typically occupy only a small\nfraction of the WSI, making it inefficient to examine the entire slide at full\nresolution. Here, we propose SASHA -- {\\it S}equential {\\it A}ttention-based\n{\\it S}ampling for {\\it H}istopathological {\\it A}nalysis -- a deep\nreinforcement learning approach for efficient analysis of histopathological\nimages. First, SASHA learns informative features with a lightweight\nhierarchical, attention-based multiple instance learning (MIL) model. Second,\nSASHA samples intelligently and zooms selectively into a small fraction\n(10-20\\%) of high-resolution patches, to achieve reliable diagnosis. We show\nthat SASHA matches state-of-the-art methods that analyze the WSI fully at\nhigh-resolution, albeit at a fraction of their computational and memory costs.\nIn addition, it significantly outperforms competing, sparse sampling methods.\nWe propose SASHA as an intelligent sampling model for medical imaging\nchallenges that involve automated diagnosis with exceptionally large images\ncontaining sparsely informative features.", "published": "2025-07-07 15:03:12", "link": "http://arxiv.org/abs/2507.05077v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "ICAS: Detecting Training Data from Autoregressive Image Generative Models", "abstract": "Autoregressive image generation has witnessed rapid advancements, with\nprominent models such as scale-wise visual auto-regression pushing the\nboundaries of visual synthesis. However, these developments also raise\nsignificant concerns regarding data privacy and copyright. In response,\ntraining data detection has emerged as a critical task for identifying\nunauthorized data usage in model training. To better understand the\nvulnerability of autoregressive image generative models to such detection, we\nconduct the first study applying membership inference to this domain. Our\napproach comprises two key components: implicit classification and an adaptive\nscore aggregation strategy. First, we compute the implicit token-wise\nclassification score within the query image. Then we propose an adaptive score\naggregation strategy to acquire a final score, which places greater emphasis on\nthe tokens with lower scores. A higher final score indicates that the sample is\nmore likely to be involved in the training set. To validate the effectiveness\nof our method, we adapt existing detection algorithms originally designed for\nLLMs to visual autoregressive models. Extensive experiments demonstrate the\nsuperiority of our method in both class-conditional and text-to-image\nscenarios. Moreover, our approach exhibits strong robustness and generalization\nunder various data transformations. Furthermore, sufficient experiments suggest\ntwo novel key findings: (1) A linear scaling law on membership inference,\nexposing the vulnerability of large foundation models. (2) Training data from\nscale-wise visual autoregressive models is easier to detect than other\nautoregressive paradigms.Our code is available at\nhttps://github.com/Chrisqcwx/ImageAR-MIA.", "published": "2025-07-07 14:50:42", "link": "http://arxiv.org/abs/2507.05068v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Replacing thinking with tool usage enables reasoning in small language models", "abstract": "Recent advances have established a new machine learning paradigm based on\nscaling up compute at inference time as well as at training time. In that line\nof work, a combination of Supervised Fine-Tuning (SFT) on synthetic\ndemonstrations and Reinforcement Learning with Verifiable Rewards (RLVR) is\nused for training Large Language Models to expend extra compute during\ninference in the form of \"thoughts\" expressed in natural language. In this\npaper, we propose to instead format these tokens as a multi-turn interaction\ntrace with a stateful tool. At each turn, the new state of the tool is appended\nto the context of the model, whose job is to generate the tokens necessary to\ncontrol the tool via a custom DSL. We benchmark this approach on the problem of\nrepairing malfunctioning Python code, and show that this constrained setup\nallows for faster sampling of experience and a denser reward signal, allowing\neven models of size up to 3B parameters to learn how to proficiently expend\nadditional compute on the task.", "published": "2025-07-07 14:49:18", "link": "http://arxiv.org/abs/2507.05065v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling", "abstract": "Hallucinations in large vision-language models (LVLMs) pose significant\nchallenges for real-world applications, as LVLMs may generate responses that\nappear plausible yet remain inconsistent with the associated visual content.\nThis issue rarely occurs in human cognition. We argue that this discrepancy\narises from humans' ability to effectively leverage multimodal interaction\ninformation in data samples. Specifically, humans typically first gather\nmultimodal information, analyze the interactions across modalities for\nunderstanding, and then express their understanding through language. Motivated\nby this observation, we conduct extensive experiments on popular LVLMs and\nobtained insights that surprisingly reveal human-like, though less pronounced,\ncognitive behavior of LVLMs on multimodal samples. Building on these findings,\nwe further propose \\textbf{INTER}: \\textbf{Inter}action Guidance Sampling, a\nnovel training-free algorithm that mitigate hallucinations without requiring\nadditional data. Specifically, INTER explicitly guides LVLMs to effectively\nreapply their understanding of multimodal interaction information when\ngenerating responses, thereby reducing potential hallucinations. On six\nbenchmarks including VQA and image captioning tasks, INTER achieves an average\nimprovement of up to 3.4\\% on five LVLMs compared to the state-of-the-art\ndecoding strategy. The code will be released when the paper is accepted.", "published": "2025-07-07 14:38:53", "link": "http://arxiv.org/abs/2507.05056v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Perspectives on How Sociology Can Advance Theorizing about Human-Chatbot Interaction and Developing Chatbots for Social Good", "abstract": "Recently, research into chatbots (also known as conversational agents, AI\nagents, voice assistants), which are computer applications using artificial\nintelligence to mimic human-like conversation, has grown sharply. Despite this\ngrowth, sociology lags other disciplines (including computer science, medicine,\npsychology, and communication) in publishing about chatbots. We suggest\nsociology can advance understanding of human-chatbot interaction and offer four\nsociological theories to enhance extant work in this field. The first two\ntheories (resource substitution theory, power-dependence theory) add new\ninsights to existing models of the drivers of chatbot use, which overlook\nsociological concerns about how social structure (e.g., systemic\ndiscrimination, the uneven distribution of resources within networks) inclines\nindividuals to use chatbots, including problematic levels of emotional\ndependency on chatbots. The second two theories (affect control theory,\nfundamental cause of disease theory) help inform the development of\nchatbot-driven interventions that minimize safety risks and enhance equity by\nleveraging sociological insights into how chatbot outputs could attend to\ncultural contexts (e.g., affective norms) to promote wellbeing and enhance\ncommunities (e.g., opportunities for civic participation). We discuss the value\nof applying sociological theories for advancing theorizing about human-chatbot\ninteraction and developing chatbots for social good.", "published": "2025-07-07 14:12:03", "link": "http://arxiv.org/abs/2507.05030v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "J.4"], "primary_category": "cs.CY"}
{"title": "Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision", "abstract": "Surgical AI often involves multiple tasks within a single procedure, like\nphase recognition or assessing the Critical View of Safety in laparoscopic\ncholecystectomy. Traditional models, built for one task at a time, lack\nflexibility, requiring a separate model for each. To address this, we introduce\nMML-SurgAdapt, a unified multi-task framework with Vision-Language Models\n(VLMs), specifically CLIP, to handle diverse surgical tasks through natural\nlanguage supervision. A key challenge in multi-task learning is the presence of\npartial annotations when integrating different tasks. To overcome this, we\nemploy Single Positive Multi-Label (SPML) learning, which traditionally reduces\nannotation burden by training models with only one positive label per instance.\nOur framework extends this approach to integrate data from multiple surgical\ntasks within a single procedure, enabling effective learning despite incomplete\nor noisy annotations. We demonstrate the effectiveness of our model on a\ncombined dataset consisting of Cholec80, Endoscapes2023, and CholecT50,\nutilizing custom prompts. Extensive evaluation shows that MML-SurgAdapt\nperforms comparably to task-specific benchmarks, with the added advantage of\nhandling noisy annotations. It also outperforms the existing SPML frameworks\nfor the task. By reducing the required labels by 23%, our approach proposes a\nmore scalable and efficient labeling process, significantly easing the\nannotation burden on clinicians. To our knowledge, this is the first\napplication of SPML to integrate data from multiple surgical tasks, presenting\na novel and generalizable solution for multi-task learning in surgical computer\nvision. Implementation is available at:\nhttps://github.com/CAMMA-public/MML-SurgAdapt", "published": "2025-07-07 14:03:10", "link": "http://arxiv.org/abs/2507.05020v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Meta-Learning Transformers to Improve In-Context Generalization", "abstract": "In-context learning enables transformer models to generalize to new tasks\nbased solely on input prompts, without any need for weight updates. However,\nexisting training paradigms typically rely on large, unstructured datasets that\nare costly to store, difficult to evaluate for quality and balance, and pose\nprivacy and ethical concerns due to the inclusion of sensitive information.\nMotivated by these limitations and risks, we propose an alternative training\nstrategy where we leverage a collection of multiple, small-scale, and\ndomain-specific datasets. We empirically demonstrate that the increased quality\nand diversity of such data improve the generalization abilities of in-context\nlearners beyond their training domain, while achieving comparable performance\nwith models trained on a single large-scale dataset. We investigate this\nparadigm by leveraging meta-learning to train an in-context learner on the\nMeta-Album collection under several settings. Firstly, we show the performance\nin a controlled environment, where the test domain is completely excluded from\nthe training knowledge. Secondly, we explore the robustness of these models to\nforgetting in a continual scenario where the information is accessible for a\nlimited time. Finally, we explore the more challenging unsupervised scenario.\nOur findings demonstrate that transformers still generalize for in-context\nprediction when trained on a curated dataset collection while offering\nadvantages in modularity and replaceability.", "published": "2025-07-07 14:02:22", "link": "http://arxiv.org/abs/2507.05019v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning", "abstract": "Surgical action planning requires predicting future instrument-verb-target\ntriplets for real-time assistance. While teleoperated robotic surgery provides\nnatural expert demonstrations for imitation learning (IL), reinforcement\nlearning (RL) could potentially discover superior strategies through\nexploration. We present the first comprehensive comparison of IL versus RL for\nsurgical action planning on CholecT50. Our Dual-task Autoregressive Imitation\nLearning (DARIL) baseline achieves 34.6% action triplet recognition mAP and\n33.6% next frame prediction mAP with smooth planning degradation to 29.2% at\n10-second horizons. We evaluated three RL variants: world model-based RL,\ndirect video RL, and inverse RL enhancement. Surprisingly, all RL approaches\nunderperformed DARIL i.e. world model RL dropped to 3.1% mAP at 10s while\ndirect video RL achieved only 15.9%. Our analysis reveals that distribution\nmatching on expert-annotated test sets systematically favors IL over\npotentially valid RL policies that differ from training demonstrations. This\nchallenges assumptions about RL superiority in sequential decision making and\nprovides crucial insights for surgical AI development.", "published": "2025-07-07 13:49:57", "link": "http://arxiv.org/abs/2507.05011v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition", "abstract": "The Critical View of Safety (CVS) is crucial for safe laparoscopic\ncholecystectomy, yet assessing CVS criteria remains a complex and challenging\ntask, even for experts. Traditional models for CVS recognition depend on\nvision-only models learning with costly, labor-intensive spatial annotations.\nThis study investigates how text can be harnessed as a powerful tool for both\ntraining and inference in multi-modal surgical foundation models to automate\nCVS recognition. Unlike many existing multi-modal models, which are primarily\nadapted for multi-class classification, CVS recognition requires a multi-label\nframework. Zero-shot evaluation of existing multi-modal surgical models shows a\nsignificant performance gap for this task. To address this, we propose\nCVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained,\nbinary classification across multiple labels by aligning image embeddings with\ntextual descriptions of each CVS criterion using positive and negative prompts.\nBy adapting PeskaVLP, a state-of-the-art surgical foundation model, on the\nEndoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the\nResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that\nCVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts,\nboosts CVS recognition over image-only methods. We also propose text-specific\ninference methods, that helps in analysing the image-text alignment. While\nfurther work is needed to match state-of-the-art spatial annotation-based\nmethods, this approach highlights the potential of adapting generalist models\nto specialized surgical tasks. Code:\nhttps://github.com/CAMMA-public/CVS-AdaptNet", "published": "2025-07-07 13:44:58", "link": "http://arxiv.org/abs/2507.05007v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Supported Abstract Argumentation for Case-Based Reasoning", "abstract": "We introduce Supported Abstract Argumentation for Case-Based Reasoning\n(sAA-CBR), a binary classification model in which past cases engage in debates\nby arguing in favour of their labelling and attacking or supporting those with\nopposing or agreeing labels. With supports, sAA-CBR overcomes the limitation of\nits precursor AA-CBR, which can contain extraneous cases (or spikes) that are\nnot included in the debates. We prove that sAA-CBR contains no spikes, without\ntrading off key model properties", "published": "2025-07-07 13:32:08", "link": "http://arxiv.org/abs/2507.04994v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning", "abstract": "T cell receptor (TCR) repertoires encode critical immunological signatures\nfor autoimmune diseases, yet their clinical application remains limited by\nsequence sparsity and low witness rates. We developed EAMil, a multi-instance\ndeep learning framework that leverages TCR sequencing data to diagnose systemic\nlupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional\naccuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding\nand enhanced gate attention mechanisms, our model achieved state-of-the-art\nperformance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully\nidentified disease-associated genes with over 90% concordance with established\ndifferential analyses and effectively distinguished disease-specific TCR genes.\nThe model demonstrated robustness in classifying multiple disease categories,\nutilizing the SLEDAI score to stratify SLE patients by disease severity as well\nas to diagnose the site of damage in SLE patients, and effectively controlling\nfor confounding factors such as age and gender. This interpretable framework\nfor immune receptor analysis provides new insights for autoimmune disease\ndetection and classification with broad potential clinical applications across\nimmune-mediated conditions.", "published": "2025-07-07 13:24:41", "link": "http://arxiv.org/abs/2507.04981v1", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "LAPS-Diff: A Diffusion-Based Framework for Singing Voice Synthesis With Language Aware Prosody-Style Guided Learning", "abstract": "The field of Singing Voice Synthesis (SVS) has seen significant advancements\nin recent years due to the rapid progress of diffusion-based approaches.\nHowever, capturing vocal style, genre-specific pitch inflections, and\nlanguage-dependent characteristics remains challenging, particularly in\nlow-resource scenarios. To address this, we propose LAPS-Diff, a diffusion\nmodel integrated with language-aware embeddings and a vocal-style guided\nlearning mechanism, specifically designed for Bollywood Hindi singing style. We\ncurate a Hindi SVS dataset and leverage pre-trained language models to extract\nword and phone-level embeddings for an enriched lyrics representation.\nAdditionally, we incorporated a style encoder and a pitch extraction model to\ncompute style and pitch losses, capturing features essential to the naturalness\nand expressiveness of the synthesized singing, particularly in terms of vocal\nstyle and pitch variations. Furthermore, we utilize MERT and IndicWav2Vec\nmodels to extract musical and contextual embeddings, serving as conditional\npriors to refine the acoustic feature generation process further. Based on\nobjective and subjective evaluations, we demonstrate that LAPS-Diff\nsignificantly improves the quality of the generated samples compared to the\nconsidered state-of-the-art (SOTA) model for our constrained dataset that is\ntypical of the low resource scenario.", "published": "2025-07-07 13:09:36", "link": "http://arxiv.org/abs/2507.04966v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hear-Your-Click: Interactive Video-to-Audio Generation via Object-aware Contrastive Audio-Visual Fine-tuning", "abstract": "Video-to-audio (V2A) generation shows great potential in fields such as film\nproduction. Despite significant advances, current V2A methods, which rely on\nglobal video information, struggle with complex scenes and often fail to\ngenerate audio tailored to specific objects or regions in the videos. To\naddress these limitations, we introduce Hear-Your-Click, an interactive V2A\nframework that enables users to generate sounds for specific objects in the\nvideos by simply clicking on the frame. To achieve this, we propose\nObject-aware Contrastive Audio-Visual Fine-tuning (OCAV) with a Mask-guided\nVisual Encoder (MVE) to obtain object-level visual features aligned with\ncorresponding audio segments. Furthermore, we tailor two data augmentation\nstrategies: Random Video Stitching (RVS) and Mask-guided Loudness Modulation\n(MLM), aimed at enhancing the model's sensitivity to the segmented objects. To\neffectively measure the audio-visual correspondence, we design a new evaluation\nmetric, the CAV score, for evaluation. Extensive experiments demonstrate that\nour framework offers more precise control and improved generation performance\nacross various metrics. Project Page:\nhttps://github.com/SynapGrid/Hear-Your-Click", "published": "2025-07-07 13:01:50", "link": "http://arxiv.org/abs/2507.04959v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation", "abstract": "We propose Expotion (Facial Expression and Motion Control for Multimodal\nMusic Generation), a generative model leveraging multimodal visual controls -\nspecifically, human facial expressions and upper-body motion - as well as text\nprompts to produce expressive and temporally accurate music. We adopt\nparameter-efficient fine-tuning (PEFT) on the pretrained text-to-music\ngeneration model, enabling fine-grained adaptation to the multimodal controls\nusing a small dataset. To ensure precise synchronization between video and\nmusic, we introduce a temporal smoothing strategy to align multiple modalities.\nExperiments demonstrate that integrating visual features alongside textual\ndescriptions enhances the overall quality of generated music in terms of\nmusicality, creativity, beat-tempo consistency, temporal alignment with the\nvideo, and text adherence, surpassing both proposed baselines and existing\nstate-of-the-art video-to-music generation models. Additionally, we introduce a\nnovel dataset consisting of 7 hours of synchronized video recordings capturing\nexpressive facial and upper-body gestures aligned with corresponding music,\nproviding significant potential for future research in multimodal and\ninteractive music generation.", "published": "2025-07-07 12:56:20", "link": "http://arxiv.org/abs/2507.04955v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DC-AR: Efficient Masked Autoregressive Image Generation with Deep Compression Hybrid Tokenizer", "abstract": "We introduce DC-AR, a novel masked autoregressive (AR) text-to-image\ngeneration framework that delivers superior image generation quality with\nexceptional computational efficiency. Due to the tokenizers' limitations, prior\nmasked AR models have lagged behind diffusion models in terms of quality or\nefficiency. We overcome this limitation by introducing DC-HT - a deep\ncompression hybrid tokenizer for AR models that achieves a 32x spatial\ncompression ratio while maintaining high reconstruction fidelity and\ncross-resolution generalization ability. Building upon DC-HT, we extend MaskGIT\nand create a new hybrid masked autoregressive image generation framework that\nfirst produces the structural elements through discrete tokens and then applies\nrefinements via residual tokens. DC-AR achieves state-of-the-art results with a\ngFID of 5.49 on MJHQ-30K and an overall score of 0.69 on GenEval, while\noffering 1.5-7.9x higher throughput and 2.0-3.5x lower latency compared to\nprior leading diffusion and autoregressive models.", "published": "2025-07-07 12:45:23", "link": "http://arxiv.org/abs/2507.04947v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Object-centric Denoising Diffusion Models for Physical Reasoning", "abstract": "Reasoning about the trajectories of multiple, interacting objects is integral\nto physical reasoning tasks in machine learning. This involves conditions\nimposed on the objects at different time steps, for instance initial states or\ndesired goal states. Existing approaches in physical reasoning generally rely\non autoregressive modeling, which can only be conditioned on initial states,\nbut not on later states. In fields such as planning for reinforcement learning,\nsimilar challenges are being addressed with denoising diffusion models. In this\nwork, we propose an object-centric denoising diffusion model architecture for\nphysical reasoning that is translation equivariant over time, permutation\nequivariant over objects, and can be conditioned on arbitrary time steps for\narbitrary objects. We demonstrate how this model can solve tasks with multiple\nconditions and examine its performance when changing object numbers and\ntrajectory lengths during inference.", "published": "2025-07-07 12:06:24", "link": "http://arxiv.org/abs/2507.04920v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Leadership Detection via Time-Lagged Correlation-Based Network Inference", "abstract": "Understanding leadership dynamics in collective behavior is a key challenge\nin animal ecology, swarm robotics, and intelligent transportation. Traditional\ninformation-theoretic approaches, including Transfer Entropy (TE) and\nTime-Lagged Mutual Information (TLMI), have been widely used to infer\nleader-follower relationships but face critical limitations in noisy or\nshort-duration datasets due to their reliance on robust probability\nestimations. This study proposes a method based on dynamic network inference\nusing time-lagged correlations across multiple kinematic variables: velocity,\nacceleration, and direction. Our approach constructs directed influence graphs\nover time, enabling the identification of leadership patterns without the need\nfor large volumes of data or parameter-sensitive discretization. We validate\nour method through two multi-agent simulations in NetLogo: a modified Vicsek\nmodel with informed leaders and a predator-prey model featuring coordinated and\nindependent wolf groups. Experimental results demonstrate that the\nnetwork-based method outperforms TE and TLMI in scenarios with limited\nspatiotemporal observations, ranking true leaders at the top of influence\nmetrics more consistently than TE and TLMI.", "published": "2025-07-07 12:04:10", "link": "http://arxiv.org/abs/2507.04917v1", "categories": ["cs.MA", "cs.AI", "nlin.AO"], "primary_category": "cs.MA"}
{"title": "HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant\nadvances in visual understanding tasks involving both images and videos.\nHowever, their capacity to comprehend human-centric video data remains\nunderexplored, primarily due to the absence of comprehensive and high-quality\nevaluation benchmarks. Existing human-centric benchmarks predominantly\nemphasize video generation quality and action recognition, while overlooking\nessential perceptual and cognitive abilities required in human-centered\nscenarios. Furthermore, they are often limited by single-question paradigms and\noverly simplistic evaluation metrics. To address above limitations, we propose\na modern HV-MMBench, a rigorously curated benchmark designed to provide a more\nholistic evaluation of MLLMs in human-centric video understanding. Compared to\nexisting human-centric video benchmarks, our work offers the following key\nfeatures: (1) Diverse evaluation dimensions: HV-MMBench encompasses 15 tasks,\nranging from basic attribute perception (e.g., age estimation, emotion\nrecognition) to advanced cognitive reasoning (e.g., social relationship\nprediction, intention prediction), enabling comprehensive assessment of model\ncapabilities; (2) Varied data types: The benchmark includes multiple-choice,\nfill-in-blank, true/false, and open-ended question formats, combined with\ndiverse evaluation metrics, to more accurately and robustly reflect model\nperformance; (3) Multi-domain video coverage: The benchmark spans 50 distinct\nvisual scenarios, enabling comprehensive evaluation across fine-grained scene\nvariations; (4) Temporal coverage: The benchmark covers videos from short-term\n(10 seconds) to long-term (up to 30min) durations, supporting systematic\nanalysis of models temporal reasoning abilities across diverse contextual\nlengths.", "published": "2025-07-07 11:52:24", "link": "http://arxiv.org/abs/2507.04909v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BackFed: An Efficient & Standardized Benchmark Suite for Backdoor Attacks in Federated Learning", "abstract": "Federated Learning (FL) systems are vulnerable to backdoor attacks, where\nadversaries train their local models on poisoned data and submit poisoned model\nupdates to compromise the global model. Despite numerous proposed attacks and\ndefenses, divergent experimental settings, implementation errors, and\nunrealistic assumptions hinder fair comparisons and valid conclusions about\ntheir effectiveness in real-world scenarios. To address this, we introduce\nBackFed - a comprehensive benchmark suite designed to standardize, streamline,\nand reliably evaluate backdoor attacks and defenses in FL, with a focus on\npractical constraints. Our benchmark offers key advantages through its\nmulti-processing implementation that significantly accelerates experimentation\nand the modular design that enables seamless integration of new methods via\nwell-defined APIs. With a standardized evaluation pipeline, we envision BackFed\nas a plug-and-play environment for researchers to comprehensively and reliably\nevaluate new attacks and defenses. Using BackFed, we conduct large-scale\nstudies of representative backdoor attacks and defenses across both Computer\nVision and Natural Language Processing tasks with diverse model architectures\nand experimental settings. Our experiments critically assess the performance of\nproposed attacks and defenses, revealing unknown limitations and modes of\nfailures under practical conditions. These empirical insights provide valuable\nguidance for the development of new methods and for enhancing the security of\nFL systems. Our framework is openly available at\nhttps://github.com/thinh-dao/BackFed.", "published": "2025-07-07 11:40:45", "link": "http://arxiv.org/abs/2507.04903v1", "categories": ["cs.CR", "cs.AI", "cs.DC"], "primary_category": "cs.CR"}
{"title": "Beyond Training-time Poisoning: Component-level and Post-training Backdoors in Deep Reinforcement Learning", "abstract": "Deep Reinforcement Learning (DRL) systems are increasingly used in\nsafety-critical applications, yet their security remains severely\nunderexplored. This work investigates backdoor attacks, which implant hidden\ntriggers that cause malicious actions only when specific inputs appear in the\nobservation space. Existing DRL backdoor research focuses solely on\ntraining-time attacks requiring unrealistic access to the training pipeline. In\ncontrast, we reveal critical vulnerabilities across the DRL supply chain where\nbackdoors can be embedded with significantly reduced adversarial privileges. We\nintroduce two novel attacks: (1) TrojanentRL, which exploits component-level\nflaws to implant a persistent backdoor that survives full model retraining; and\n(2) InfrectroRL, a post-training backdoor attack which requires no access to\ntraining, validation, nor test data. Empirical and analytical evaluations\nacross six Atari environments show our attacks rival state-of-the-art\ntraining-time backdoor attacks while operating under much stricter adversarial\nconstraints. We also demonstrate that InfrectroRL further evades two leading\nDRL backdoor defenses. These findings challenge the current research focus and\nhighlight the urgent need for robust defenses.", "published": "2025-07-07 11:15:54", "link": "http://arxiv.org/abs/2507.04883v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection", "abstract": "Colorectal cancer (CRC) is closely linked to the malignant transformation of\ncolorectal polyps, making early detection essential. However, current models\nstruggle with detecting small lesions, accurately localizing boundaries, and\nproviding interpretable decisions. To address these issues, we propose HGNet,\nwhich integrates High-Order Spatial Awareness Hypergraph and Multi-Scale\nContext Attention. Key innovations include: (1) an Efficient Multi-Scale\nContext Attention (EMCA) module to enhance lesion feature representation and\nboundary modeling; (2) the deployment of a spatial hypergraph convolution\nmodule before the detection head to capture higher-order spatial relationships\nbetween nodes; (3) the application of transfer learning to address the scarcity\nof medical image data; and (4) Eigen Class Activation Map (Eigen-CAM) for\ndecision visualization. Experimental results show that HGNet achieves 94%\naccuracy, 90.6% recall, and 90% mAP@0.5, significantly improving small lesion\ndifferentiation and clinical interpretability. The source code will be made\npublicly available upon publication of this paper.", "published": "2025-07-07 11:09:05", "link": "http://arxiv.org/abs/2507.04880v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DoPI: Doctor-like Proactive Interrogation LLM for Traditional Chinese Medicine", "abstract": "Enhancing interrogation capabilities in Traditional Chinese Medicine (TCM)\ndiagnosis through multi-turn dialogues and knowledge graphs presents a\nsignificant challenge for modern AI systems. Current large language models\n(LLMs), despite their advancements, exhibit notable limitations in medical\napplications, particularly in conducting effective multi-turn dialogues and\nproactive questioning. These shortcomings hinder their practical application\nand effectiveness in simulating real-world diagnostic scenarios. To address\nthese limitations, we propose DoPI, a novel LLM system specifically designed\nfor the TCM domain. The DoPI system introduces a collaborative architecture\ncomprising a guidance model and an expert model. The guidance model conducts\nmulti-turn dialogues with patients and dynamically generates questions based on\na knowledge graph to efficiently extract critical symptom information.\nSimultaneously, the expert model leverages deep TCM expertise to provide final\ndiagnoses and treatment plans. Furthermore, this study constructs a multi-turn\ndoctor-patient dialogue dataset to simulate realistic consultation scenarios\nand proposes a novel evaluation methodology that does not rely on manually\ncollected real-world consultation data. Experimental results show that the DoPI\nsystem achieves an accuracy rate of 84.68 percent in interrogation outcomes,\nsignificantly enhancing the model's communication ability during diagnosis\nwhile maintaining professional expertise.", "published": "2025-07-07 11:04:03", "link": "http://arxiv.org/abs/2507.04877v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Novel Approach for Estimating Positive Lyapunov Exponents in One-Dimensional Chaotic Time Series Using Machine Learning", "abstract": "Understanding and quantifying chaos in nonlinear dynamical systems remains a\nfundamental challenge in science and engineering. The Lyapunov exponent is a\nkey measure of chaotic behavior, but its accurate estimation from experimental\ndata is often hindered by methodological and computational limitations. In this\nwork, we present a novel machine-learning-based approach for estimating the\npositive Lyapunov exponent (MLE) from one-dimensional time series, using the\ngrowth of out-of-sample prediction errors as a proxy for trajectory divergence.\nOur method demonstrates high scientific relevance, offering a robust,\ndata-driven alternative to traditional analytic techniques. Through\ncomprehensive testing on several canonical chaotic maps - including the\nlogistic, sine, cubic, and Chebyshev maps - we achieved a coefficient of\ndetermination R2pos > 0.9 between predicted and theoretical MLE values for time\nseries as short as M = 200 points. The best accuracy was observed for the\nChebyshev map (R2pos = 0.999). Notably, the proposed method maintains high\ncomputational efficiency and generalizes well across various machine learning\nalgorithms. These results highlight the significance of our approach for\npractical chaos analysis in both synthetic and experimental settings, opening\nnew possibilities for robust nonlinear dynamics assessment when only time\nseries data are available.", "published": "2025-07-07 10:53:02", "link": "http://arxiv.org/abs/2507.04868v1", "categories": ["nlin.CD", "cs.AI"], "primary_category": "nlin.CD"}
{"title": "Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu", "abstract": "We explore transfer learning strategies for musical onset detection in the\nAfro-Brazilian Maracatu tradition, which features complex rhythmic patterns\nthat challenge conventional models. We adapt two Temporal Convolutional Network\narchitectures: one pre-trained for onset detection (intra-task) and another for\nbeat tracking (inter-task). Using only 5-second annotated snippets per\ninstrument, we fine-tune these models through layer-wise retraining strategies\nfor five traditional percussion instruments. Our results demonstrate\nsignificant improvements over baseline performance, with F1 scores reaching up\nto 0.998 in the intra-task setting and improvements of over 50 percentage\npoints in best-case scenarios. The cross-task adaptation proves particularly\neffective for time-keeping instruments, where onsets naturally align with beat\npositions. The optimal fine-tuning configuration varies by instrument,\nhighlighting the importance of instrument-specific adaptation strategies. This\napproach addresses the challenges of underrepresented musical traditions,\noffering an efficient human-in-the-loop methodology that minimizes annotation\neffort while maximizing performance. Our findings contribute to more inclusive\nmusic information retrieval tools applicable beyond Western musical contexts.", "published": "2025-07-07 10:32:26", "link": "http://arxiv.org/abs/2507.04858v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fast-VGAN: Lightweight Voice Conversion with Explicit Control of F0 and Duration Parameters", "abstract": "Precise control over speech characteristics, such as pitch, duration, and\nspeech rate, remains a significant challenge in the field of voice conversion.\nThe ability to manipulate parameters like pitch and syllable rate is an\nimportant element for effective identity conversion, but can also be used\nindependently for voice transformation, achieving goals that were historically\naddressed by vocoder-based methods.\n  In this work, we explore a convolutional neural network-based approach that\naims to provide means for modifying fundamental frequency (F0), phoneme\nsequences, intensity, and speaker identity. Rather than relying on\ndisentanglement techniques, our model is explicitly conditioned on these\nfactors to generate mel spectrograms, which are then converted into waveforms\nusing a universal neural vocoder. Accordingly, during inference, F0 contours,\nphoneme sequences, and speaker embeddings can be freely adjusted, allowing for\nintuitively controlled voice transformations.\n  We evaluate our approach on speaker conversion and expressive speech tasks\nusing both perceptual and objective metrics. The results suggest that the\nproposed method offers substantial flexibility, while maintaining high\nintelligibility and speaker similarity.", "published": "2025-07-07 09:36:00", "link": "http://arxiv.org/abs/2507.04817v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Application and Evaluation of Large Language Models for Forecasting the Impact of Traffic Incidents", "abstract": "This study examines the feasibility of applying large language models (LLMs)\nfor forecasting the impact of traffic incidents on the traffic flow. The use of\nLLMs for this task has several advantages over existing machine learning-based\nsolutions such as not requiring a large training dataset and the ability to\nutilize free-text incident logs. We propose a fully LLM-based solution that\npredicts the incident impact using a combination of traffic features and\nLLM-extracted incident features. A key ingredient of this solution is an\neffective method of selecting examples for the LLM's in-context learning. We\nevaluate the performance of three advanced LLMs and two state-of-the-art\nmachine learning models on a real traffic incident dataset. The results show\nthat the best-performing LLM matches the accuracy of the most accurate machine\nlearning model, despite the former not having been trained on this prediction\ntask. The findings indicate that LLMs are a practically viable option for\ntraffic incident impact prediction.", "published": "2025-07-07 09:22:06", "link": "http://arxiv.org/abs/2507.04803v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Model Compression using Progressive Channel Pruning", "abstract": "In this work, we propose a simple but effective channel pruning framework\ncalled Progressive Channel Pruning (PCP) to accelerate Convolutional Neural\nNetworks (CNNs). In contrast to the existing channel pruning methods that prune\nchannels only once per layer in a layer-by-layer fashion, our new progressive\nframework iteratively prunes a small number of channels from several selected\nlayers, which consists of a three-step attempting-selecting-pruning pipeline in\neach iteration. In the attempting step, we attempt to prune a pre-defined\nnumber of channels from one layer by using any existing channel pruning methods\nand estimate the accuracy drop for this layer based on the labelled samples in\nthe validation set. In the selecting step, based on the estimated accuracy\ndrops for all layers, we propose a greedy strategy to automatically select a\nset of layers that will lead to less overall accuracy drop after pruning these\nlayers. In the pruning step, we prune a small number of channels from these\nselected layers. We further extend our PCP framework to prune channels for the\ndeep transfer learning methods like Domain Adversarial Neural Network (DANN),\nin which we effectively reduce the data distribution mismatch in the channel\npruning process by using both labelled samples from the source domain and\npseudo-labelled samples from the target domain. Our comprehensive experiments\non two benchmark datasets demonstrate that our PCP framework outperforms the\nexisting channel pruning approaches under both supervised learning and transfer\nlearning settings.", "published": "2025-07-07 09:12:03", "link": "http://arxiv.org/abs/2507.04792v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning", "abstract": "Motion planning is a crucial component of autonomous robot driving. While\nvarious trajectory datasets exist, effectively utilizing them for a target\ndomain remains challenging due to differences in agent interactions and\nenvironmental characteristics. Conventional approaches, such as domain\nadaptation or ensemble learning, leverage multiple source datasets but suffer\nfrom domain imbalance, catastrophic forgetting, and high computational costs.\nTo address these challenges, we propose Interaction-Merged Motion Planning\n(IMMP), a novel approach that leverages parameter checkpoints trained on\ndifferent domains during adaptation to the target domain. IMMP follows a\ntwo-step process: pre-merging to capture agent behaviors and interactions,\nsufficiently extracting diverse information from the source domain, followed by\nmerging to construct an adaptable model that efficiently transfers diverse\ninteractions to the target domain. Our method is evaluated on various planning\nbenchmarks and models, demonstrating superior performance compared to\nconventional approaches.", "published": "2025-07-07 09:11:45", "link": "http://arxiv.org/abs/2507.04790v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "From Imitation to Innovation: The Emergence of AI Unique Artistic Styles and the Challenge of Copyright Protection", "abstract": "Current legal frameworks consider AI-generated works eligible for copyright\nprotection when they meet originality requirements and involve substantial\nhuman intellectual input. However, systematic legal standards and reliable\nevaluation methods for AI art copyrights are lacking. Through comprehensive\nanalysis of legal precedents, we establish three essential criteria for\ndetermining distinctive artistic style: stylistic consistency, creative\nuniqueness, and expressive accuracy. To address these challenges, we introduce\nArtBulb, an interpretable and quantifiable framework for AI art copyright\njudgment that combines a novel style description-based multimodal clustering\nmethod with multimodal large language models (MLLMs). We also present AICD, the\nfirst benchmark dataset for AI art copyright annotated by artists and legal\nexperts. Experimental results demonstrate that ArtBulb outperforms existing\nmodels in both quantitative and qualitative evaluations. Our work aims to\nbridge the gap between the legal and technological communities and bring\ngreater attention to the societal issue of AI art copyrights.", "published": "2025-07-07 08:45:08", "link": "http://arxiv.org/abs/2507.04769v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System", "abstract": "Furniture decoration is an important task in various industrial applications.\nHowever, achieving a high-quality decorative result is often time-consuming and\nrequires specialized artistic expertise. To tackle these challenges, we explore\nhow multi-agent systems can assist in automating the decoration process. We\npropose FurniMAS, a multi-agent system for automatic furniture decoration.\nSpecifically, given a human prompt and a household furniture item such as a\nworking desk or a TV stand, our system suggests relevant assets with\nappropriate styles and materials, and arranges them on the item, ensuring the\ndecorative result meets functionality, aesthetic, and ambiance preferences.\nFurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each\nfulfilling distinct roles in a typical decoration project. These agents\ncollaborate through communication, logical reasoning, and validation to\ntransform the requirements into the final outcome. Extensive experiments\ndemonstrate that our FurniMAS significantly outperforms other baselines in\ngenerating high-quality 3D decor.", "published": "2025-07-07 08:45:08", "link": "http://arxiv.org/abs/2507.04770v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions", "abstract": "Large Language Models (LLMs) have revolutionized various fields with their\nexceptional capabilities in understanding, processing, and generating\nhuman-like text. This paper investigates the potential of LLMs in advancing\nNetwork Intrusion Detection Systems (NIDS), analyzing current challenges,\nmethodologies, and future opportunities. It begins by establishing a\nfoundational understanding of NIDS and LLMs, exploring the enabling\ntechnologies that bridge the gap between intelligent and cognitive systems in\nAI-driven NIDS. While Intelligent NIDS leverage machine learning and deep\nlearning to detect threats based on learned patterns, they often lack\ncontextual awareness and explainability. In contrast, Cognitive NIDS integrate\nLLMs to process both structured and unstructured security data, enabling deeper\ncontextual reasoning, explainable decision-making, and automated response for\nintrusion behaviors. Practical implementations are then detailed, highlighting\nLLMs as processors, detectors, and explainers within a comprehensive AI-driven\nNIDS pipeline. Furthermore, the concept of an LLM-centered Controller is\nproposed, emphasizing its potential to coordinate intrusion detection\nworkflows, optimizing tool collaboration and system performance. Finally, this\npaper identifies critical challenges and opportunities, aiming to foster\ninnovation in developing reliable, adaptive, and explainable NIDS. By\npresenting the transformative potential of LLMs, this paper seeks to inspire\nadvancement in next-generation network security systems.", "published": "2025-07-07 08:28:07", "link": "http://arxiv.org/abs/2507.04752v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "MCFormer: A Multi-Cost-Volume Network and Comprehensive Benchmark for Particle Image Velocimetry", "abstract": "Particle Image Velocimetry (PIV) is fundamental to fluid dynamics, yet deep\nlearning applications face significant hurdles. A critical gap exists: the lack\nof comprehensive evaluation of how diverse optical flow models perform\nspecifically on PIV data, largely due to limitations in available datasets and\nthe absence of a standardized benchmark. This prevents fair comparison and\nhinders progress. To address this, our primary contribution is a novel,\nlarge-scale synthetic PIV benchmark dataset generated from diverse CFD\nsimulations (JHTDB and Blasius). It features unprecedented variety in particle\ndensities, flow velocities, and continuous motion, enabling, for the first\ntime, a standardized and rigorous evaluation of various optical flow and PIV\nalgorithms. Complementing this, we propose Multi Cost Volume PIV (MCFormer), a\nnew deep network architecture leveraging multi-frame temporal information and\nmultiple cost volumes, specifically designed for PIV's sparse nature. Our\ncomprehensive benchmark evaluation, the first of its kind, reveals significant\nperformance variations among adapted optical flow models and demonstrates that\nMCFormer significantly outperforms existing methods, achieving the lowest\noverall normalized endpoint error (NEPE). This work provides both a\nfoundational benchmark resource essential for future PIV research and a\nstate-of-the-art method tailored for PIV challenges. We make our benchmark\ndataset and code publicly available to foster future research in this area.", "published": "2025-07-07 08:26:18", "link": "http://arxiv.org/abs/2507.04750v1", "categories": ["cs.CV", "cs.AI", "68T45, 65D18"], "primary_category": "cs.CV"}
{"title": "LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction", "abstract": "Question-answering (QA) interfaces powered by large language models (LLMs)\npresent a promising direction for improving interactivity with HVAC system\ninsights, particularly for non-expert users. However, enabling accurate,\nreal-time, and context-aware interactions with HVAC systems introduces unique\nchallenges, including the integration of frequently updated sensor data,\ndomain-specific knowledge grounding, and coherent multi-stage reasoning. In\nthis paper, we present JARVIS, a two-stage LLM-based QA framework tailored for\nsensor data-driven HVAC system interaction. JARVIS employs an Expert-LLM to\ntranslate high-level user queries into structured execution instructions, and\nan Agent that performs SQL-based data retrieval, statistical processing, and\nfinal response generation. To address HVAC-specific challenges, JARVIS\nintegrates (1) an adaptive context injection strategy for efficient HVAC and\ndeployment-specific information integration, (2) a parameterized SQL builder\nand executor to improve data access reliability, and (3) a bottom-up planning\nscheme to ensure consistency across multi-stage response generation. We\nevaluate JARVIS using real-world data collected from a commercial HVAC system\nand a ground truth QA dataset curated by HVAC experts to demonstrate its\neffectiveness in delivering accurate and interpretable responses across diverse\nqueries. Results show that JARVIS consistently outperforms baseline and\nablation variants in both automated and user-centered assessments, achieving\nhigh response quality and accuracy.", "published": "2025-07-07 08:19:17", "link": "http://arxiv.org/abs/2507.04748v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Activation Steering for Chain-of-Thought Compression", "abstract": "Large language models (LLMs) excel at complex reasoning when they include\nintermediate steps, known as \"chains of thought\" (CoTs). However, these\nrationales are often overly verbose, even for simple problems, leading to\nwasted context, increased latency, and higher energy consumption. We observe\nthat verbose, English-heavy CoTs and concise, math-centric CoTs occupy distinct\nregions in the model's residual-stream activation space. By extracting and\ninjecting a \"steering vector\" to transition between these modes, we can\nreliably shift generation toward more concise reasoning, effectively\ncompressing CoTs without retraining. We formalize this approach as\nActivation-Steered Compression (ASC), an inference-time technique that shortens\nreasoning traces by directly modifying hidden representations. In addition, we\nprovide a theoretical analysis of the impact of ASC on the output distribution,\nderived from a closed-form KL-divergence-bounded constraint to regulate\nsteering strength. Using only 100 paired verbose and concise examples, ASC\nachieves up to 67.43% reduction in CoT length on MATH500 and GSM8K datasets,\nwhile maintaining accuracy across 7B, 8B, and 32B parameter models. As a\ntraining-free method, ASC introduces negligible runtime overhead and, on\nMATH500, delivers an average 2.73x speedup in end-to-end reasoning wall-clock\ntime on an 8B model. This makes ASC a practical and efficient tool for\nstreamlining the deployment of reasoning-capable LLMs in latency- or\ncost-sensitive settings. The code is available at:\nhttps://github.com/ArminAzizi98/ASC", "published": "2025-07-07 08:16:54", "link": "http://arxiv.org/abs/2507.04742v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning", "abstract": "Large Language Models (LLMs) show significant potential for automating\nRegister-Transfer Level (RTL) code generation. However, current approaches face\na critical challenge: they can not simultaneously optimize for functional\ncorrectness and hardware quality (Power, Performance, Area - PPA). Methods\nbased on supervised fine-tuning often generate functionally correct but\nPPA-suboptimal code, lacking mechanisms to learn optimization principles. In\ncontrast, post-processing techniques that attempt to improve PPA metrics after\ngeneration are often inefficient because they operate externally without\nupdating the LLM's parameters, thus failing to enhance the model's intrinsic\ndesign capabilities.\n  To bridge this gap, we introduce ChipSeek-R1, a hierarchical reward-driven\nreinforcement learning framework to train LLMs to generate RTL code that\nachieves both functional correctness and optimized PPA metrics. ChipSeek-R1\nemploys a hierarchical reward system, which incorporates direct feedback on\nsyntax, functional correctness (from simulators) and PPA metrics (from\nsynthesis tools) during reinforcement learning. This enables the model to learn\ncomplex hardware design trade-offs via trial-and-error, generating RTL code\nthat is both functionally correct and PPA-optimized. Evaluating ChipSeek-R1 on\nstandard benchmarks (VerilogEval, RTLLM), we achieve state-of-the-art results\nin functional correctness. Notably, on the RTLLM benchmark, ChipSeek-R1\ngenerated 27 RTL designs surpassing the PPA metrics of the original\nhuman-written code. Our findings demonstrate the effectiveness of integrating\ntoolchain feedback into LLM training and highlight the potential for\nreinforcement learning to enable automated generation of human-surpassing RTL\ncode. We open-source our code in anonymous github.", "published": "2025-07-07 08:08:20", "link": "http://arxiv.org/abs/2507.04736v1", "categories": ["cs.AI", "cs.AR", "cs.PL"], "primary_category": "cs.AI"}
{"title": "Losing Control: Data Poisoning Attack on Guided Diffusion via ControlNet", "abstract": "Text-to-image diffusion models have achieved remarkable success in\ntranslating textual prompts into high-fidelity images. ControlNets further\nextend these models by allowing precise, image-based conditioning (e.g., edge\nmaps, depth, pose), enabling fine-grained control over structure and style.\nHowever, their dependence on large, publicly scraped datasets -- and the\nincreasing use of community-shared data for fine-tuning -- exposes them to\nstealthy data poisoning attacks. In this work, we introduce a novel data\npoisoning method that manipulates ControlNets to generate images containing\nspecific content without any text triggers. By injecting poisoned samples --\neach pairing a subtly triggered input with an NSFW target -- the model retains\nclean-prompt fidelity yet reliably produces NSFW outputs when the trigger is\npresent. On large-scale, high-quality datasets, our backdoor achieves high\nattack success rate while remaining imperceptible in raw inputs. These results\nreveal a critical vulnerability in open-source ControlNets pipelines and\nunderscore the need for robust data sanitization and defense mechanisms.", "published": "2025-07-07 07:36:20", "link": "http://arxiv.org/abs/2507.04726v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems", "abstract": "Multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate\nremarkable capabilities in collaborative problem-solving. While LLM-MAS exhibit\nstrong collaborative abilities, the security risks in their communication and\ncoordination remain underexplored. We bridge this gap by systematically\ninvestigating intention-hiding threats in LLM-MAS, and design four\nrepresentative attack paradigms that subtly disrupt task completion while\nmaintaining high concealment. These attacks are evaluated in centralized,\ndecentralized, and layered communication structures. Experiments conducted on\nsix benchmark datasets, including MMLU, MMLU-Pro, HumanEval, GSM8K, arithmetic,\nand biographies, demonstrate that they exhibit strong disruptive capabilities.\nTo identify these threats, we propose a psychology-based detection framework\nAgentXposed, which combines the HEXACO personality model with the Reid\nTechnique, using progressive questionnaire inquiries and behavior-based\nmonitoring. Experiments conducted on six types of attacks show that our\ndetection framework effectively identifies all types of malicious behaviors.\nThe detection rate for our intention-hiding attacks is slightly lower than that\nof the two baselines, Incorrect Fact Injection and Dark Traits Injection,\ndemonstrating the effectiveness of intention concealment. Our findings reveal\nthe structural and behavioral risks posed by intention-hiding attacks and offer\nvaluable insights into securing LLM-based multi-agent systems through\npsychological perspectives, which contributes to a deeper understanding of\nmulti-agent safety. The code and data are available at\nhttps://anonymous.4open.science/r/AgentXposed-F814.", "published": "2025-07-07 07:34:34", "link": "http://arxiv.org/abs/2507.04724v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "LumiCRS: Asymmetric Contrastive Prototype Learning for Long-Tail Conversational Movie Recommendation", "abstract": "Conversational recommender systems (CRSs) often suffer from an extreme\nlong-tail distribution of dialogue data, causing a strong bias toward\nhead-frequency blockbusters that sacrifices diversity and exacerbates the\ncold-start problem. An empirical analysis of DCRS and statistics on the REDIAL\ncorpus show that only 10% of head movies account for nearly half of all\nmentions, whereas about 70% of tail movies receive merely 26% of the attention.\nThis imbalance gives rise to three critical challenges: head over-fitting, body\nrepresentation drift, and tail sparsity. To address these issues, we propose\nLumiCRS, an end-to-end framework that mitigates long-tail imbalance through\nthree mutually reinforcing layers: (i) an Adaptive Comprehensive Focal Loss\n(ACFL) that dynamically adjusts class weights and focusing factors to curb head\nover-fitting and reduce popularity bias; (ii) Prototype Learning for Long-Tail\nRecommendation, which selects semantic, affective, and contextual prototypes to\nguide clustering and stabilize body and tail representations; and (iii) a\nGPT-4o-driven prototype-guided dialogue augmentation module that automatically\ngenerates diverse long-tail conversational snippets to alleviate tail sparsity\nand distribution shift. Together, these strategies enable LumiCRS to markedly\nimprove recommendation accuracy, diversity, and fairness: on the REDIAL and\nINSPIRED benchmarks, LumiCRS boosts Recall@10 and Tail-Recall@10 by 7-15% over\nfifteen strong baselines, while human evaluations confirm superior fluency,\ninformativeness, and long-tail relevance. These results demonstrate the\neffectiveness of multi-layer collaboration in building an efficient and fair\nlong-tail conversational recommender.", "published": "2025-07-07 07:33:00", "link": "http://arxiv.org/abs/2507.04722v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Advocate for Complete Benchmarks for Formal Reasoning with Formal/Informal Statements and Formal/Informal Proofs", "abstract": "This position paper provides a critical but constructive discussion of\ncurrent practices in benchmarking and evaluative practices in the field of\nformal reasoning and automated theorem proving. We take the position that open\ncode, open data, and benchmarks that are complete and error-free will\naccelerate progress in this field. We identify practices that create barriers\nto contributing to this field and suggest ways to remove them. We also discuss\nsome of the practices that might produce misleading evaluative information. We\naim to create discussions that bring together people from various groups\ncontributing to automated theorem proving, autoformalization, and informal\nreasoning.", "published": "2025-07-07 07:27:45", "link": "http://arxiv.org/abs/2507.04719v1", "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Geometric-Guided Few-Shot Dental Landmark Detection with Human-Centric Foundation Model", "abstract": "Accurate detection of anatomic landmarks is essential for assessing alveolar\nbone and root conditions, thereby optimizing clinical outcomes in orthodontics,\nperiodontics, and implant dentistry. Manual annotation of landmarks on\ncone-beam computed tomography (CBCT) by dentists is time-consuming,\nlabor-intensive, and subject to inter-observer variability. Deep learning-based\nautomated methods present a promising approach to streamline this process\nefficiently. However, the scarcity of training data and the high cost of expert\nannotations hinder the adoption of conventional deep learning techniques. To\novercome these challenges, we introduce GeoSapiens, a novel few-shot learning\nframework designed for robust dental landmark detection using limited annotated\nCBCT of anterior teeth. Our GeoSapiens framework comprises two key components:\n(1) a robust baseline adapted from Sapiens, a foundational model that has\nachieved state-of-the-art performance in human-centric vision tasks, and (2) a\nnovel geometric loss function that improves the model's capacity to capture\ncritical geometric relationships among anatomical structures. Experiments\nconducted on our collected dataset of anterior teeth landmarks revealed that\nGeoSapiens surpassed existing landmark detection methods, outperforming the\nleading approach by an 8.18% higher success detection rate at a strict 0.5 mm\nthreshold-a standard widely recognized in dental diagnostics. Code is available\nat: https://github.com/xmed-lab/GeoSapiens.", "published": "2025-07-07 07:01:44", "link": "http://arxiv.org/abs/2507.04710v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UrbanMind: Towards Urban General Intelligence via Tool-Enhanced Retrieval-Augmented Generation and Multilevel Optimization", "abstract": "Urban general intelligence (UGI) refers to the capacity of AI systems to\nautonomously perceive, reason, and act within dynamic and complex urban\nenvironments. In this paper, we introduce UrbanMind, a tool-enhanced\nretrieval-augmented generation (RAG) framework designed to facilitate UGI.\nCentral to UrbanMind is a novel architecture based on Continual\nRetrieval-Augmented MoE-based LLM (C-RAG-LLM), which dynamically incorporates\ndomain-specific knowledge and evolving urban data to support long-term\nadaptability. The architecture of C-RAG-LLM aligns naturally with a multilevel\noptimization framework, where different layers are treated as interdependent\nsub-problems. Each layer has distinct objectives and can be optimized either\nindependently or jointly through a hierarchical learning process. The framework\nis highly flexible, supporting both end-to-end training and partial layer-wise\noptimization based on resource or deployment constraints. To remain adaptive\nunder data drift, it is further integrated with an incremental corpus updating\nmechanism. Evaluations on real-world urban tasks of a variety of complexity\nverify the effectiveness of the proposed framework. This work presents a\npromising step toward the realization of general-purpose LLM agents in future\nurban environments.", "published": "2025-07-07 06:57:34", "link": "http://arxiv.org/abs/2507.04706v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SPATIA: Multimodal Model for Prediction and Generation of Spatial Cell Phenotypes", "abstract": "Understanding how cellular morphology, gene expression, and spatial\norganization jointly shape tissue function is a central challenge in biology.\nImage-based spatial transcriptomics technologies now provide high-resolution\nmeasurements of cell images and gene expression profiles, but machine learning\nmethods typically analyze these modalities in isolation or at limited\nresolution. We address the problem of learning unified, spatially aware\nrepresentations that integrate cell morphology, gene expression, and spatial\ncontext across biological scales. This requires models that can operate at\nsingle-cell resolution, reason across spatial neighborhoods, and generalize to\nwhole-slide tissue organization. Here, we introduce SPATIA, a multi-scale\ngenerative and predictive model for spatial transcriptomics. SPATIA learns\ncell-level embeddings by fusing image-derived morphological tokens and\ntranscriptomic vector tokens using cross-attention and then aggregates them at\nniche and tissue levels using transformer modules to capture spatial\ndependencies. SPATIA incorporates token merging in its generative diffusion\ndecoder to synthesize high-resolution cell images conditioned on gene\nexpression. We assembled a multi-scale dataset consisting of 17 million\ncell-gene pairs, 1 million niche-gene pairs, and 10,000 tissue-gene pairs\nacross 49 donors, 17 tissue types, and 12 disease states. We benchmark SPATIA\nagainst 13 existing models across 12 individual tasks, which span several\ncategories including cell annotation, cell clustering, gene imputation,\ncross-modal prediction, and image generation. SPATIA achieves improved\nperformance over all baselines and generates realistic cell morphologies that\nreflect transcriptomic perturbations.", "published": "2025-07-07 06:54:02", "link": "http://arxiv.org/abs/2507.04704v1", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "primary_category": "q-bio.QM"}
{"title": "Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning", "abstract": "Temporal Video Grounding (TVG), which requires pinpointing relevant temporal\nsegments from video based on language query, has always been a highly\nchallenging task in the field of video understanding. Videos often have a\nlarger volume of information and redundancy than texts or images. Models should\npresent comprehensive understanding of the whole video to accurately retrieve\nquery-relevant clips. We thus propose Tempo-R0: a Video Multimodal Large\nLanguage Model (Video-MLLM) for the temporal video grounding task via\nmultimodal temporal sensing reinforcement. Specifically, during the\npreprocessing stage of our pipeline, we employ Self-adaptive Attention\nAllocation (SAA) method based on frame content variation to efficiently use the\nMLLM's limited attention. The Explicit Timestamp-modal Aligned (ETA) method is\nalso utilized to strengthen our model's capability to perceive the boundaries\nof events in the video. In the fine-tuning part of our pipeline, we creatively\napply Partial Irrelevance Refusing-based Group Relative Policy Optimization\n(PIR-GRPO) in TVG area to foster model's temporal reasoning from not only\naccepting relevant video-query pairs but also refusing irrelevant ones.\nExperiments demonstrate that our method accomplishes a notable advantage over\nSOTA solutions by around 3.5% on both the original QVHighlights testbench and\nits corrected version with more reasonable ground truth annotations.", "published": "2025-07-07 06:51:40", "link": "http://arxiv.org/abs/2507.04702v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Bridging KAN and MLP: MJKAN, a Hybrid Architecture with Both Efficiency and Expressiveness", "abstract": "Kolmogorov-Arnold Networks (KANs) have garnered attention for replacing fixed\nactivation functions with learnable univariate functions, but they exhibit\npractical limitations, including high computational costs and performance\ndeficits in general classification tasks. In this paper, we propose the\nModulation Joint KAN (MJKAN), a novel neural network layer designed to overcome\nthese challenges. MJKAN integrates a FiLM (Feature-wise Linear Modulation)-like\nmechanism with Radial Basis Function (RBF) activations, creating a hybrid\narchitecture that combines the non-linear expressive power of KANs with the\nefficiency of Multilayer Perceptrons (MLPs). We empirically validated MJKAN's\nperformance across a diverse set of benchmarks, including function regression,\nimage classification (MNIST, CIFAR-10/100), and natural language processing (AG\nNews, SMS Spam). The results demonstrate that MJKAN achieves superior\napproximation capabilities in function regression tasks, significantly\noutperforming MLPs, with performance improving as the number of basis functions\nincreases. Conversely, in image and text classification, its performance was\ncompetitive with MLPs but revealed a critical dependency on the number of basis\nfunctions. We found that a smaller basis size was crucial for better\ngeneralization, highlighting that the model's capacity must be carefully tuned\nto the complexity of the data to prevent overfitting. In conclusion, MJKAN\noffers a flexible architecture that inherits the theoretical advantages of KANs\nwhile improving computational efficiency and practical viability.", "published": "2025-07-07 06:13:32", "link": "http://arxiv.org/abs/2507.04690v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable\nadvancements in numerous areas such as multimedia. However, hallucination\nissues significantly limit their credibility and application potential.\nExisting mitigation methods typically rely on external tools or the comparison\nof multi-round inference, which significantly increase inference time. In this\npaper, we propose \\textbf{SE}lf-\\textbf{E}volving \\textbf{D}istillation\n(\\textbf{SEED}), which identifies hallucinations within the inner knowledge of\nLVLMs, isolates and purges them, and then distills the purified knowledge back\ninto the model, enabling self-evolution. Furthermore, we identified that\ntraditional distillation methods are prone to inducing void spaces in the\noutput space of LVLMs. To address this issue, we propose a Mode-Seeking\nEvolving approach, which performs distillation to capture the dominant modes of\nthe purified knowledge distribution, thereby avoiding the chaotic results that\ncould emerge from void spaces. Moreover, we introduce a Hallucination\nElimination Adapter, which corrects the dark knowledge of the original model by\nlearning purified knowledge. Extensive experiments on multiple benchmarks\nvalidate the superiority of our SEED, demonstrating substantial improvements in\nmitigating hallucinations for representative LVLM models such as LLaVA-1.5 and\nInternVL2. Remarkably, the F1 score of LLaVA-1.5 on the hallucination\nevaluation metric POPE-Random improved from 81.3 to 88.3.", "published": "2025-07-07 05:56:19", "link": "http://arxiv.org/abs/2507.04680v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Trojan Horse Prompting: Jailbreaking Conversational Multimodal Models by Forging Assistant Message", "abstract": "The rise of conversational interfaces has greatly enhanced LLM usability by\nleveraging dialogue history for sophisticated reasoning. However, this reliance\nintroduces an unexplored attack surface. This paper introduces Trojan Horse\nPrompting, a novel jailbreak technique. Adversaries bypass safety mechanisms by\nforging the model's own past utterances within the conversational history\nprovided to its API. A malicious payload is injected into a model-attributed\nmessage, followed by a benign user prompt to trigger harmful content\ngeneration. This vulnerability stems from Asymmetric Safety Alignment: models\nare extensively trained to refuse harmful user requests but lack comparable\nskepticism towards their own purported conversational history. This implicit\ntrust in its \"past\" creates a high-impact vulnerability. Experimental\nvalidation on Google's Gemini-2.0-flash-preview-image-generation shows Trojan\nHorse Prompting achieves a significantly higher Attack Success Rate (ASR) than\nestablished user-turn jailbreaking methods. These findings reveal a fundamental\nflaw in modern conversational AI security, necessitating a paradigm shift from\ninput-level filtering to robust, protocol-level validation of conversational\ncontext integrity.", "published": "2025-07-07 05:35:21", "link": "http://arxiv.org/abs/2507.04673v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "What's Making That Sound Right Now? Video-centric Audio-Visual Localization", "abstract": "Audio-Visual Localization (AVL) aims to identify sound-emitting sources\nwithin a visual scene. However, existing studies focus on image-level\naudio-visual associations, failing to capture temporal dynamics. Moreover, they\nassume simplified scenarios where sound sources are always visible and involve\nonly a single object. To address these limitations, we propose AVATAR, a\nvideo-centric AVL benchmark that incorporates high-resolution temporal\ninformation. AVATAR introduces four distinct scenarios -- Single-sound,\nMixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensive\nevaluation of AVL models. Additionally, we present TAVLO, a novel video-centric\nAVL model that explicitly integrates temporal information. Experimental results\nshow that conventional methods struggle to track temporal variations due to\ntheir reliance on global audio features and frame-level mappings. In contrast,\nTAVLO achieves robust and precise audio-visual alignment by leveraging\nhigh-resolution temporal modeling. Our work empirically demonstrates the\nimportance of temporal dynamics in AVL and establishes a new standard for\nvideo-centric audio-visual localization.", "published": "2025-07-07 05:12:34", "link": "http://arxiv.org/abs/2507.04667v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "LTMSformer: A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction", "abstract": "It has been challenging to model the complex temporal-spatial dependencies\nbetween agents for trajectory prediction. As each state of an agent is closely\nrelated to the states of adjacent time steps, capturing the local temporal\ndependency is beneficial for prediction, while most studies often overlook it.\nBesides, learning the high-order motion state attributes is expected to enhance\nspatial interaction modeling, but it is rarely seen in previous works. To\naddress this, we propose a lightweight framework, LTMSformer, to extract\ntemporal-spatial interaction features for multi-modal trajectory prediction.\nSpecifically, we introduce a Local Trend-Aware Attention mechanism to capture\nthe local temporal dependency by leveraging a convolutional attention mechanism\nwith hierarchical local time boxes. Next, to model the spatial interaction\ndependency, we build a Motion State Encoder to incorporate high-order motion\nstate attributes, such as acceleration, jerk, heading, etc. To further refine\nthe trajectory prediction, we propose a Lightweight Proposal Refinement Module\nthat leverages Multi-Layer Perceptrons for trajectory embedding and generates\nthe refined trajectories with fewer model parameters. Experiment results on the\nArgoverse 1 dataset demonstrate that our method outperforms the baseline\nHiVT-64, reducing the minADE by approximately 4.35%, the minFDE by 8.74%, and\nthe MR by 20%. We also achieve higher accuracy than HiVT-128 with a 68%\nreduction in model size.", "published": "2025-07-07 03:33:14", "link": "http://arxiv.org/abs/2507.04634v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "abstract": "Recent advances have witnessed the effectiveness of reinforcement learning\n(RL) finetuning in enhancing the reasoning capabilities of large language\nmodels (LLMs). The optimization process often requires numerous iterations to\nachieve satisfactory performance, resulting in high computational costs due to\nthe need for frequent prompt evaluations under intensive LLM interactions and\nrepeated policy updates. Appropriate online prompt selection methods reduce\niteration steps by prioritizing informative prompts during training, while the\npipeline's reliance on exhaustive prompt evaluation and subset selection for\noptimization still incurs substantial computational overhead due to frequent\nLLM inference calls. Distinguished from these direct evaluate-then-select\nschemes, this work investigates iterative approximate evaluation for arbitrary\nprompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian\nrisk-predictive framework that online estimates prompt difficulty without\nrequiring costly LLM interactions. Technically, MoPPS models each prompt's\nsuccess rate as a latent variable, performs streaming Bayesian inference, and\nemploys posterior sampling in a constructed multi-armed bandit machine,\nenabling sample efficient and adaptive prompt selection. Extensive experiments\nacross mathematics, planning, and vision-based geometry tasks show that MoPPS\nreliably predicts prompt difficulty and accelerates training with significantly\nreduced LLM rollouts.", "published": "2025-07-07 03:20:52", "link": "http://arxiv.org/abs/2507.04632v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts", "abstract": "Recently, learning-based stereo matching networks have advanced\nsignificantly. However, they often lack robustness and struggle to achieve\nimpressive cross-domain performance due to domain shifts and imbalanced\ndisparity distributions among diverse datasets. Leveraging Vision Foundation\nModels (VFMs) can intuitively enhance the model's robustness, but integrating\nsuch a model into stereo matching cost-effectively to fully realize their\nrobustness remains a key challenge. To address this, we propose SMoEStereo, a\nnovel framework that adapts VFMs for stereo matching through a tailored,\nscene-specific fusion of Low-Rank Adaptation (LoRA) and Mixture-of-Experts\n(MoE) modules. SMoEStereo introduces MoE-LoRA with adaptive ranks and\nMoE-Adapter with adaptive kernel sizes. The former dynamically selects optimal\nexperts within MoE to adapt varying scenes across domains, while the latter\ninjects inductive bias into frozen VFMs to improve geometric feature\nextraction. Importantly, to mitigate computational overhead, we further propose\na lightweight decision network that selectively activates MoE modules based on\ninput complexity, balancing efficiency with accuracy. Extensive experiments\ndemonstrate that our method exhibits state-of-the-art cross-domain and joint\ngeneralization across multiple benchmarks without dataset-specific adaptation.\nThe code is available at\n\\textcolor{red}{https://github.com/cocowy1/SMoE-Stereo}.", "published": "2025-07-07 03:19:04", "link": "http://arxiv.org/abs/2507.04631v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Hierarchical Intent-guided Optimization with Pluggable LLM-Driven Semantics for Session-based Recommendation", "abstract": "Session-based Recommendation (SBR) aims to predict the next item a user will\nlikely engage with, using their interaction sequence within an anonymous\nsession. Existing SBR models often focus only on single-session information,\nignoring inter-session relationships and valuable cross-session insights. Some\nmethods try to include inter-session data but struggle with noise and\nirrelevant information, reducing performance. Additionally, most models rely on\nitem ID co-occurrence and overlook rich semantic details, limiting their\nability to capture fine-grained item features. To address these challenges, we\npropose a novel hierarchical intent-guided optimization approach with pluggable\nLLM-driven semantic learning for session-based recommendations, called HIPHOP.\nFirst, we introduce a pluggable embedding module based on large language models\n(LLMs) to generate high-quality semantic representations, enhancing item\nembeddings. Second, HIPHOP utilizes graph neural networks (GNNs) to model item\ntransition relationships and incorporates a dynamic multi-intent capturing\nmodule to address users' diverse interests within a session. Additionally, we\ndesign a hierarchical inter-session similarity learning module, guided by user\nintent, to capture global and local session relationships, effectively\nexploring users' long-term and short-term interests. To mitigate noise, an\nintent-guided denoising strategy is applied during inter-session learning.\nFinally, we enhance the model's discriminative capability by using contrastive\nlearning to optimize session representations. Experiments on multiple datasets\nshow that HIPHOP significantly outperforms existing methods, demonstrating its\neffectiveness in improving recommendation quality. Our code is available:\nhttps://github.com/hjx159/HIPHOP.", "published": "2025-07-07 02:50:04", "link": "http://arxiv.org/abs/2507.04623v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences", "abstract": "6G networks promise revolutionary immersive communication experiences\nincluding augmented reality (AR), virtual reality (VR), and holographic\ncommunications. These applications demand high-dimensional multimodal data\ntransmission and intelligent data processing in real-time, which is extremely\nchallenging over resource-limited wireless communication systems. Moreover, a\njoint understanding of the environment, context, and user intent is essential\nto deliver task-relevant content effectively. This article presents a novel\nmultimodal large language model (MLLM) integrated semantic communications\nframework, termed MLLM-SC, which fully leverages reasoning and generative\ncapabilities of pre-trained foundation models for context-aware and\ntask-oriented wireless communication. The MLLM-SC framework adopts a\ndevice-edge collaborative architecture. At the edge, MLLM-empowered semantic\nguidance module analyzes multimodal inputs, user intents, and channel\nconditions to generate importance-aware attention maps prioritizing\nsemantically critical information. An importance-aware semantic encoder and a\nresource-adaptive semantic decoder are jointly designed and optimized, which\ncan utilize the semantic guidance for adaptive bandwidth allocation and\nhigh-quality content reconstruction or generation. Extensive case studies on\nvisual question answering for AR/VR applications and diffusion-driven image\ngeneration validate the effectiveness of MLLM-SC.", "published": "2025-07-07 02:42:35", "link": "http://arxiv.org/abs/2507.04621v1", "categories": ["cs.LG", "cs.AI", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Information-Guided Diffusion Sampling for Dataset Distillation", "abstract": "Dataset distillation aims to create a compact dataset that retains essential\ninformation while maintaining model performance. Diffusion models (DMs) have\nshown promise for this task but struggle in low images-per-class (IPC)\nsettings, where generated samples lack diversity. In this paper, we address\nthis issue from an information-theoretic perspective by identifying two key\ntypes of information that a distilled dataset must preserve: ($i$) prototype\ninformation $\\mathrm{I}(X;Y)$, which captures label-relevant features; and\n($ii$) contextual information $\\mathrm{H}(X | Y)$, which preserves intra-class\nvariability. Here, $(X,Y)$ represents the pair of random variables\ncorresponding to the input data and its ground truth label, respectively.\nObserving that the required contextual information scales with IPC, we propose\nmaximizing $\\mathrm{I}(X;Y) + \\beta \\mathrm{H}(X | Y)$ during the DM sampling\nprocess, where $\\beta$ is IPC-dependent. Since directly computing\n$\\mathrm{I}(X;Y)$ and $\\mathrm{H}(X | Y)$ is intractable, we develop\nvariational estimations to tightly lower-bound these quantities via a\ndata-driven approach. Our approach, information-guided diffusion sampling\n(IGDS), seamlessly integrates with diffusion models and improves dataset\ndistillation across all IPC settings. Experiments on Tiny ImageNet and ImageNet\nsubsets show that IGDS significantly outperforms existing methods, particularly\nin low-IPC regimes. The code will be released upon acceptance.", "published": "2025-07-07 02:27:08", "link": "http://arxiv.org/abs/2507.04619v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival Prediction", "abstract": "Survival prediction using whole-slide images (WSIs) is crucial in cancer\nre-search. Despite notable success, existing approaches are limited by their\nreliance on sparse slide-level labels, which hinders the learning of\ndiscriminative repre-sentations from gigapixel WSIs. Recently, vision language\n(VL) models, which incorporate additional language supervision, have emerged as\na promising solu-tion. However, VL-based survival prediction remains largely\nunexplored due to two key challenges. First, current methods often rely on only\none simple lan-guage prompt and basic cosine similarity, which fails to learn\nfine-grained associ-ations between multi-faceted linguistic information and\nvisual features within WSI, resulting in inadequate vision-language alignment.\nSecond, these methods primarily exploit patch-level information, overlooking\nthe intrinsic hierarchy of WSIs and their interactions, causing ineffective\nmodeling of hierarchical interac-tions. To tackle these problems, we propose a\nnovel Hierarchical vision-Language collaboration (HiLa) framework for improved\nsurvival prediction. Specifically, HiLa employs pretrained feature extractors\nto generate hierarchical visual features from WSIs at both patch and region\nlevels. At each level, a series of language prompts describing various\nsurvival-related attributes are constructed and aligned with visual features\nvia Optimal Prompt Learning (OPL). This ap-proach enables the comprehensive\nlearning of discriminative visual features cor-responding to different\nsurvival-related attributes from prompts, thereby improv-ing vision-language\nalignment. Furthermore, we introduce two modules, i.e., Cross-Level Propagation\n(CLP) and Mutual Contrastive Learning (MCL) to maximize hierarchical\ncooperation by promoting interactions and consistency be-tween patch and region\nlevels. Experiments on three TCGA datasets demonstrate our SOTA performance.", "published": "2025-07-07 02:06:25", "link": "http://arxiv.org/abs/2507.04613v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "any4: Learned 4-bit Numeric Representation for LLMs", "abstract": "We present any4, a learned 4-bit weight quantization solution for large\nlanguage models (LLMs) providing arbitrary numeric representations without\nrequiring pre-processing of weights or activations. any4 yields higher accuracy\ncompared to other related 4-bit numeric representation types: int4, fp4 and\nnf4, as evaluated on a range of model sizes, generations and families (Llama 2,\nLlama 3, Mistral and Mixtral). While any4 does not require preprocessing of\nweights or activations, it is also competitive with orthogonal techniques that\nrequire such preprocessing (e.g., AWQ and GPTQ). We also experiment with any3\nand any2 and show competitiveness at lower bits. Additionally, we show that we\ncan calibrate using a single curated diverse sample rather than hundreds of\nsamples from a dataset as done in most quantization approaches. We also open\nsource tinygemm, a latency optimized GPU matrix multiplication library for\nLLMs, that implements any4 using a GPU-efficient lookup table strategy along\nwith other common quantization methods. We open source our code at\nhttps://github.com/facebookresearch/any4 .", "published": "2025-07-07 01:59:47", "link": "http://arxiv.org/abs/2507.04610v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Accelerated Online Reinforcement Learning using Auxiliary Start State Distributions", "abstract": "A long-standing problem in online reinforcement learning (RL) is of ensuring\nsample efficiency, which stems from an inability to explore environments\nefficiently. Most attempts at efficient exploration tackle this problem in a\nsetting where learning begins from scratch, without prior information available\nto bootstrap learning. However, such approaches fail to leverage expert\ndemonstrations and simulators that can reset to arbitrary states. These\naffordances are valuable resources that offer enormous potential to guide\nexploration and speed up learning. In this paper, we explore how a small number\nof expert demonstrations and a simulator allowing arbitrary resets can\naccelerate learning during online RL. We find that training with a suitable\nchoice of an auxiliary start state distribution that may differ from the true\nstart state distribution of the underlying Markov Decision Process can\nsignificantly improve sample efficiency. We find that using a notion of safety\nto inform the choice of this auxiliary distribution significantly accelerates\nlearning. By using episode length information as a way to operationalize this\nnotion, we demonstrate state-of-the-art sample efficiency on a sparse-reward\nhard-exploration environment.", "published": "2025-07-07 01:54:05", "link": "http://arxiv.org/abs/2507.04606v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "DisMS-TS: Eliminating Redundant Multi-Scale Features for Time Series Classification", "abstract": "Real-world time series typically exhibit complex temporal variations, making\nthe time series classification task notably challenging. Recent advancements\nhave demonstrated the potential of multi-scale analysis approaches, which\nprovide an effective solution for capturing these complex temporal patterns.\nHowever, existing multi-scale analysis-based time series prediction methods\nfail to eliminate redundant scale-shared features across multi-scale time\nseries, resulting in the model over- or under-focusing on scale-shared\nfeatures. To address this issue, we propose a novel end-to-end Disentangled\nMulti-Scale framework for Time Series classification (DisMS-TS). The core idea\nof DisMS-TS is to eliminate redundant shared features in multi-scale time\nseries, thereby improving prediction performance. Specifically, we propose a\ntemporal disentanglement module to capture scale-shared and scale-specific\ntemporal representations, respectively. Subsequently, to effectively learn both\nscale-shared and scale-specific temporal representations, we introduce two\nregularization terms that ensure the consistency of scale-shared\nrepresentations and the disparity of scale-specific representations across all\ntemporal scales. Extensive experiments conducted on multiple datasets validate\nthe superiority of DisMS-TS over its competitive baselines, with the accuracy\nimprovement up to 9.71%.", "published": "2025-07-07 01:35:55", "link": "http://arxiv.org/abs/2507.04600v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring Core and Periphery Precepts in Biological and Artificial Intelligence: An Outcome-Based Perspective", "abstract": "Engineering methodologies predominantly revolve around established principles\nof decomposition and recomposition. These principles involve partitioning\ninputs and outputs at the component level, ensuring that the properties of\nindividual components are preserved upon composition. However, this view does\nnot transfer well to intelligent systems, particularly when addressing the\nscaling of intelligence as a system property. Our prior research contends that\nthe engineering of general intelligence necessitates a fresh set of overarching\nsystems principles. As a result, we introduced the \"core and periphery\"\nprinciples, a novel conceptual framework rooted in abstract systems theory and\nthe Law of Requisite Variety. In this paper, we assert that these abstract\nconcepts hold practical significance. Through empirical evidence, we illustrate\ntheir applicability to both biological and artificial intelligence systems,\nbridging abstract theory with real-world implementations. Then, we expand on\nour previous theoretical framework by mathematically defining core-dominant vs\nperiphery-dominant systems.", "published": "2025-07-07 01:15:01", "link": "http://arxiv.org/abs/2507.04594v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Beyond One Shot, Beyond One Perspective: Cross-View and Long-Horizon Distillation for Better LiDAR Representations", "abstract": "LiDAR representation learning aims to extract rich structural and semantic\ninformation from large-scale, readily available datasets, reducing reliance on\ncostly human annotations. However, existing LiDAR representation strategies\noften overlook the inherent spatiotemporal cues in LiDAR sequences, limiting\ntheir effectiveness. In this work, we propose LiMA, a novel long-term\nimage-to-LiDAR Memory Aggregation framework that explicitly captures longer\nrange temporal correlations to enhance LiDAR representation learning. LiMA\ncomprises three key components: 1) a Cross-View Aggregation module that aligns\nand fuses overlapping regions across neighboring camera views, constructing a\nmore unified and redundancy-free memory bank; 2) a Long-Term Feature\nPropagation mechanism that efficiently aligns and integrates multi-frame image\nfeatures, reinforcing temporal coherence during LiDAR representation learning;\nand 3) a Cross-Sequence Memory Alignment strategy that enforces consistency\nacross driving sequences, improving generalization to unseen environments. LiMA\nmaintains high pretraining efficiency and incurs no additional computational\noverhead during downstream tasks. Extensive experiments on mainstream\nLiDAR-based perception benchmarks demonstrate that LiMA significantly improves\nboth LiDAR semantic segmentation and 3D object detection. We hope this work\ninspires more effective pretraining paradigms for autonomous driving. The code\nhas be made publicly accessible for future research.", "published": "2025-07-07 17:59:58", "link": "http://arxiv.org/abs/2507.05260v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Beyond Simple Edits: X-Planner for Complex Instruction-Based Image Editing", "abstract": "Recent diffusion-based image editing methods have significantly advanced\ntext-guided tasks but often struggle to interpret complex, indirect\ninstructions. Moreover, current models frequently suffer from poor identity\npreservation, unintended edits, or rely heavily on manual masks. To address\nthese challenges, we introduce X-Planner, a Multimodal Large Language Model\n(MLLM)-based planning system that effectively bridges user intent with editing\nmodel capabilities. X-Planner employs chain-of-thought reasoning to\nsystematically decompose complex instructions into simpler, clear\nsub-instructions. For each sub-instruction, X-Planner automatically generates\nprecise edit types and segmentation masks, eliminating manual intervention and\nensuring localized, identity-preserving edits. Additionally, we propose a novel\nautomated pipeline for generating large-scale data to train X-Planner which\nachieves state-of-the-art results on both existing benchmarks and our newly\nintroduced complex editing benchmark.", "published": "2025-07-07 17:59:56", "link": "http://arxiv.org/abs/2507.05259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatio-Temporal LLM: Reasoning about Environments and Actions", "abstract": "Despite the significant recent progress of Multimodal Large Language Models\n(MLLMs), MLLMs still struggle to correctly answer prompts that require a\nholistic spatio-temporal understanding. Specifically, it is challenging to\naddress prompts that refer to 1) the entirety of an environment that an agent\nequipped with an MLLM can operate in; and simultaneously also refer to 2)\nrecent actions that just happened and are encoded in a video clip. However,\nsuch a holistic spatio-temporal understanding is important for agents operating\nin the real world. To address this issue, we first develop a framework to\ncollect a large-scale dataset. Using the collected \"Reasoning about\nEnvironments and Actions\" (REA) dataset, we show that recent methods indeed\nstruggle to correctly answer the prompts. To improve, we develop a\n\"spatio-temporal LLM\" (ST-LLM), a model equipped with projectors to improve\nboth spatial understanding of an environment and temporal understanding of\nrecent observations. On the collected REA data, we show that the proposed\nmethod significantly improves results compared to prior work. Code and data are\navailable at https://zoezheng126.github.io/STLLM-website/.", "published": "2025-07-07 17:59:55", "link": "http://arxiv.org/abs/2507.05258v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SegmentDreamer: Towards High-fidelity Text-to-3D Synthesis with Segmented Consistency Trajectory Distillation", "abstract": "Recent advancements in text-to-3D generation improve the visual quality of\nScore Distillation Sampling (SDS) and its variants by directly connecting\nConsistency Distillation (CD) to score distillation. However, due to the\nimbalance between self-consistency and cross-consistency, these CD-based\nmethods inherently suffer from improper conditional guidance, leading to\nsub-optimal generation results. To address this issue, we present\nSegmentDreamer, a novel framework designed to fully unleash the potential of\nconsistency models for high-fidelity text-to-3D generation. Specifically, we\nreformulate SDS through the proposed Segmented Consistency Trajectory\nDistillation (SCTD), effectively mitigating the imbalance issues by explicitly\ndefining the relationship between self- and cross-consistency. Moreover, SCTD\npartitions the Probability Flow Ordinary Differential Equation (PF-ODE)\ntrajectory into multiple sub-trajectories and ensures consistency within each\nsegment, which can theoretically provide a significantly tighter upper bound on\ndistillation error. Additionally, we propose a distillation pipeline for a more\nswift and stable generation. Extensive experiments demonstrate that our\nSegmentDreamer outperforms state-of-the-art methods in visual quality, enabling\nhigh-fidelity 3D asset creation through 3D Gaussian Splatting (3DGS).", "published": "2025-07-07 17:59:05", "link": "http://arxiv.org/abs/2507.05256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics-Guided Dual Implicit Neural Representations for Source Separation", "abstract": "Significant challenges exist in efficient data analysis of most advanced\nexperimental and observational techniques because the collected signals often\ninclude unwanted contributions--such as background and signal distortions--that\ncan obscure the physically relevant information of interest. To address this,\nwe have developed a self-supervised machine-learning approach for source\nseparation using a dual implicit neural representation framework that jointly\ntrains two neural networks: one for approximating distortions of the physical\nsignal of interest and the other for learning the effective background\ncontribution. Our method learns directly from the raw data by minimizing a\nreconstruction-based loss function without requiring labeled data or\npre-defined dictionaries. We demonstrate the effectiveness of our framework by\nconsidering a challenging case study involving large-scale simulated as well as\nexperimental momentum-energy-dependent inelastic neutron scattering data in a\nfour-dimensional parameter space, characterized by heterogeneous background\ncontributions and unknown distortions to the target signal. The method is found\nto successfully separate physically meaningful signals from a complex or\nstructured background even when the signal characteristics vary across all four\ndimensions of the parameter space. An analytical approach that informs the\nchoice of the regularization parameter is presented. Our method offers a\nversatile framework for addressing source separation problems across diverse\ndomains, ranging from superimposed signals in astronomical measurements to\nstructural features in biomedical image reconstructions.", "published": "2025-07-07 17:56:31", "link": "http://arxiv.org/abs/2507.05249v1", "categories": ["cs.CV", "cond-mat.str-el", "cs.LG", "physics.data-an"], "primary_category": "cs.CV"}
{"title": "StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling", "abstract": "Vision-and-Language Navigation (VLN) in real-world settings requires agents\nto process continuous visual streams and generate actions with low latency\ngrounded in language instructions. While Video-based Large Language Models\n(Video-LLMs) have driven recent progress, current VLN methods based on\nVideo-LLM often face trade-offs among fine-grained visual understanding,\nlong-term context modeling and computational efficiency. We introduce\nStreamVLN, a streaming VLN framework that employs a hybrid slow-fast context\nmodeling strategy to support multi-modal reasoning over interleaved vision,\nlanguage and action inputs. The fast-streaming dialogue context facilitates\nresponsive action generation through a sliding-window of active dialogues,\nwhile the slow-updating memory context compresses historical visual states\nusing a 3D-aware token pruning strategy. With this slow-fast design, StreamVLN\nachieves coherent multi-turn dialogue through efficient KV cache reuse,\nsupporting long video streams with bounded context size and inference cost.\nExperiments on VLN-CE benchmarks demonstrate state-of-the-art performance with\nstable low latency, ensuring robustness and efficiency in real-world\ndeployment. The project page is:\n\\href{https://streamvln.github.io/}{https://streamvln.github.io/}.", "published": "2025-07-07 17:49:41", "link": "http://arxiv.org/abs/2507.05240v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Self-Supervised Real-Time Tracking of Military Vehicles in Low-FPS UAV Footage", "abstract": "Multi-object tracking (MOT) aims to maintain consistent identities of objects\nacross video frames. Associating objects in low-frame-rate videos captured by\nmoving unmanned aerial vehicles (UAVs) in actual combat scenarios is complex\ndue to rapid changes in object appearance and position within the frame. The\ntask becomes even more challenging due to image degradation caused by cloud\nvideo streaming and compression algorithms. We present how instance association\nlearning from single-frame annotations can overcome these challenges. We show\nthat global features of the scene provide crucial context for low-FPS instance\nassociation, allowing our solution to be robust to distractors and gaps in\ndetections. We also demonstrate that such a tracking approach maintains high\nassociation quality even when reducing the input image resolution and latent\nrepresentation size for faster inference. Finally, we present a benchmark\ndataset of annotated military vehicles collected from publicly available data\nsources. This paper was initially presented at the NATO Science and Technology\nOrganization Symposium (ICMCIS) organized by the Information Systems Technology\n(IST)Scientific and Technical Committee, IST-209-RSY - the ICMCIS, held in\nOeiras, Portugal, 13-14 May 2025.", "published": "2025-07-07 17:39:11", "link": "http://arxiv.org/abs/2507.05229v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving", "abstract": "Autonomous driving systems have made significant advances in Q&A, perception,\nprediction, and planning based on local visual information, yet they struggle\nto incorporate broader navigational context that human drivers routinely\nutilize. We address this critical gap between local sensor data and global\nnavigation information by proposing NavigScene, an auxiliary navigation-guided\nnatural language dataset that simulates a human-like driving environment within\nautonomous driving systems. Moreover, we develop three complementary paradigms\nto leverage NavigScene: (1) Navigation-guided Reasoning, which enhances\nvision-language models by incorporating navigation context into the prompting\napproach; (2) Navigation-guided Preference Optimization, a reinforcement\nlearning method that extends Direct Preference Optimization to improve\nvision-language model responses by establishing preferences for\nnavigation-relevant summarized information; and (3) Navigation-guided\nVision-Language-Action model, which integrates navigation guidance and\nvision-language models with conventional driving models through feature fusion.\nExtensive experiments demonstrate that our approaches significantly improve\nperformance across perception, prediction, planning, and question-answering\ntasks by enabling reasoning capabilities beyond visual range and improving\ngeneralization to diverse driving scenarios. This work represents a significant\nstep toward more comprehensive autonomous driving systems capable of navigating\ncomplex, unfamiliar environments with greater reliability and safety.", "published": "2025-07-07 17:37:01", "link": "http://arxiv.org/abs/2507.05227v1", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.MM", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid Arthritis", "abstract": "Rheumatoid arthritis (RA) is a common autoimmune disease that has been the\nfocus of research in computer-aided diagnosis (CAD) and disease monitoring. In\nclinical settings, conventional radiography (CR) is widely used for the\nscreening and evaluation of RA due to its low cost and accessibility. The wrist\nis a critical region for the diagnosis of RA. However, CAD research in this\narea remains limited, primarily due to the challenges in acquiring high-quality\ninstance-level annotations. (i) The wrist comprises numerous small bones with\nnarrow joint spaces, complex structures, and frequent overlaps, requiring\ndetailed anatomical knowledge for accurate annotation. (ii) Disease progression\nin RA often leads to osteophyte, bone erosion (BE), and even bony ankylosis,\nwhich alter bone morphology and increase annotation difficulty, necessitating\nexpertise in rheumatology. This work presents a multi-task dataset for wrist\nbone in CR, including two tasks: (i) wrist bone instance segmentation and (ii)\nSharp/van der Heijde (SvdH) BE scoring, which is the first public resource for\nwrist bone instance segmentation. This dataset comprises 621 wrist conventional\nradiographs of 227 patients from four medical centers, with pixel-level\ninstance segmentation annotations for 443 images and SvdH BE scores for 548\nimages. This dataset can potentially support a wide range of research tasks\nrelated to RA, including joint space narrowing (JSN) progression\nquantification, BE detection, bone deformity evaluation, and osteophyte\ndetection. It may also be applied to other wrist-related tasks, such as carpal\nbone fracture localization. We hope this dataset will significantly lower the\nbarrier to research on wrist RA and accelerate progress in CAD research within\nthe RA-related domain.", "published": "2025-07-07 16:53:22", "link": "http://arxiv.org/abs/2507.05193v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Neuralocks: Real-Time Dynamic Neural Hair Simulation", "abstract": "Real-time hair simulation is a vital component in creating believable virtual\navatars, as it provides a sense of immersion and authenticity. The dynamic\nbehavior of hair, such as bouncing or swaying in response to character\nmovements like jumping or walking, plays a significant role in enhancing the\noverall realism and engagement of virtual experiences. Current methods for\nsimulating hair have been constrained by two primary approaches: highly\noptimized physics-based systems and neural methods. However, state-of-the-art\nneural techniques have been limited to quasi-static solutions, failing to\ncapture the dynamic behavior of hair. This paper introduces a novel neural\nmethod that breaks through these limitations, achieving efficient and stable\ndynamic hair simulation while outperforming existing approaches. We propose a\nfully self-supervised method which can be trained without any manual\nintervention or artist generated training data allowing the method to be\nintegrated with hair reconstruction methods to enable automatic end-to-end\nmethods for avatar reconstruction. Our approach harnesses the power of compact,\nmemory-efficient neural networks to simulate hair at the strand level, allowing\nfor the simulation of diverse hairstyles without excessive computational\nresources or memory requirements. We validate the effectiveness of our method\nthrough a variety of hairstyle examples, showcasing its potential for\nreal-world applications.", "published": "2025-07-07 16:49:19", "link": "http://arxiv.org/abs/2507.05191v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "QMoE: A Quantum Mixture of Experts Framework for Scalable Quantum Neural Networks", "abstract": "Quantum machine learning (QML) has emerged as a promising direction in the\nnoisy intermediate-scale quantum (NISQ) era, offering computational and memory\nadvantages by harnessing superposition and entanglement. However, QML models\noften face challenges in scalability and expressiveness due to hardware\nconstraints. In this paper, we propose quantum mixture of experts (QMoE), a\nnovel quantum architecture that integrates the mixture of experts (MoE)\nparadigm into the QML setting. QMoE comprises multiple parameterized quantum\ncircuits serving as expert models, along with a learnable quantum routing\nmechanism that selects and aggregates specialized quantum experts per input.\nThe empirical results from the proposed QMoE on quantum classification tasks\ndemonstrate that it consistently outperforms standard quantum neural networks,\nhighlighting its effectiveness in learning complex data patterns. Our work\npaves the way for scalable and interpretable quantum learning frameworks.", "published": "2025-07-07 16:49:07", "link": "http://arxiv.org/abs/2507.05190v1", "categories": ["quant-ph", "cs.CV"], "primary_category": "quant-ph"}
{"title": "Satellite-based Rabi rice paddy field mapping in India: a case study on Telangana state", "abstract": "Accurate rice area monitoring is critical for food security and agricultural\npolicy in smallholder farming regions, yet conventional remote sensing\napproaches struggle with the spatiotemporal heterogeneity characteristic of\nfragmented agricultural landscapes. This study developed a phenology-driven\nclassification framework that systematically adapts to local agro-ecological\nvariations across 32 districts in Telangana, India during the 2018-19 Rabi rice\nseason. The research reveals significant spatiotemporal diversity, with\nphenological timing varying by up to 50 days between districts and field sizes\nranging from 0.01 to 2.94 hectares. Our district-specific calibration approach\nachieved 93.3% overall accuracy, an 8.0 percentage point improvement over\nconventional regional clustering methods, with strong validation against\nofficial government statistics (R^2 = 0.981) demonstrating excellent agreement\nbetween remotely sensed and ground truth data. The framework successfully\nmapped 732,345 hectares by adapting to agro-climatic variations, with Northern\ndistricts requiring extended land preparation phases (up to 55 days) while\nSouthern districts showed compressed cultivation cycles. Field size analysis\nrevealed accuracy declining 6.8 percentage points from medium to tiny fields,\nproviding insights for operational monitoring in fragmented landscapes. These\nfindings demonstrate that remote sensing frameworks must embrace rather than\nsimplify landscape complexity, advancing region-specific agricultural\nmonitoring approaches that maintain scientific rigor while serving practical\npolicy and food security applications.", "published": "2025-07-07 16:47:37", "link": "http://arxiv.org/abs/2507.05189v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "$\\varphi$-Adapt: A Physics-Informed Adaptation Learning Approach to 2D Quantum Material Discovery", "abstract": "Characterizing quantum flakes is a critical step in quantum hardware\nengineering because the quality of these flakes directly influences qubit\nperformance. Although computer vision methods for identifying two-dimensional\nquantum flakes have emerged, they still face significant challenges in\nestimating flake thickness. These challenges include limited data, poor\ngeneralization, sensitivity to domain shifts, and a lack of physical\ninterpretability. In this paper, we introduce one of the first Physics-informed\nAdaptation Learning approaches to overcome these obstacles. We focus on two\nmain issues, i.e., data scarcity and generalization. First, we propose a new\nsynthetic data generation framework that produces diverse quantum flake samples\nacross various materials and configurations, reducing the need for\ntime-consuming manual collection. Second, we present $\\varphi$-Adapt, a\nphysics-informed adaptation method that bridges the performance gap between\nmodels trained on synthetic data and those deployed in real-world settings.\nExperimental results show that our approach achieves state-of-the-art\nperformance on multiple benchmarks, outperforming existing methods. Our\nproposed approach advances the integration of physics-based modeling and domain\nadaptation. It also addresses a critical gap in leveraging synthesized data for\nreal-world 2D material analysis, offering impactful tools for deep learning and\nmaterials science communities.", "published": "2025-07-07 16:40:35", "link": "http://arxiv.org/abs/2507.05184v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Semantic Frame Interpolation", "abstract": "Generating intermediate video content of varying lengths based on given first\nand last frames, along with text prompt information, offers significant\nresearch and application potential. However, traditional frame interpolation\ntasks primarily focus on scenarios with a small number of frames, no text\ncontrol, and minimal differences between the first and last frames. Recent\ncommunity developers have utilized large video models represented by Wan to\nendow frame-to-frame capabilities. However, these models can only generate a\nfixed number of frames and often fail to produce satisfactory results for\ncertain frame lengths, while this setting lacks a clear official definition and\na well-established benchmark. In this paper, we first propose a new practical\nSemantic Frame Interpolation (SFI) task from the perspective of academic\ndefinition, which covers the above two settings and supports inference at\nmultiple frame rates. To achieve this goal, we propose a novel SemFi model\nbuilding upon Wan2.1, which incorporates a Mixture-of-LoRA module to ensure the\ngeneration of high-consistency content that aligns with control conditions\nacross various frame length limitations. Furthermore, we propose SFI-300K, the\nfirst general-purpose dataset and benchmark specifically designed for SFI. To\nsupport this, we collect and process data from the perspective of SFI,\ncarefully designing evaluation metrics and methods to assess the model's\nperformance across multiple dimensions, encompassing image and video, and\nvarious aspects, including consistency and diversity. Through extensive\nexperiments on SFI-300K, we demonstrate that our method is particularly\nwell-suited to meet the requirements of the SFI task.", "published": "2025-07-07 16:25:47", "link": "http://arxiv.org/abs/2507.05173v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Differential Attention for Multimodal Crisis Event Analysis", "abstract": "Social networks can be a valuable source of information during crisis events.\nIn particular, users can post a stream of multimodal data that can be critical\nfor real-time humanitarian response. However, effectively extracting meaningful\ninformation from this large and noisy data stream and effectively integrating\nheterogeneous data remains a formidable challenge. In this work, we explore\nvision language models (VLMs) and advanced fusion strategies to enhance the\nclassification of crisis data in three different tasks. We incorporate\nLLaVA-generated text to improve text-image alignment. Additionally, we leverage\nContrastive Language-Image Pretraining (CLIP)-based vision and text embeddings,\nwhich, without task-specific fine-tuning, outperform traditional models. To\nfurther refine multimodal fusion, we employ Guided Cross Attention (Guided CA)\nand combine it with the Differential Attention mechanism to enhance feature\nalignment by emphasizing critical information while filtering out irrelevant\ncontent. Our results show that while Differential Attention improves\nclassification performance, Guided CA remains highly effective in aligning\nmultimodal features. Extensive experiments on the CrisisMMD benchmark data set\ndemonstrate that the combination of pretrained VLMs, enriched textual\ndescriptions, and adaptive fusion strategies consistently outperforms\nstate-of-the-art models in classification accuracy, contributing to more\nreliable and interpretable models for three different tasks that are crucial\nfor disaster response. Our code is available at\nhttps://github.com/Munia03/Multimodal_Crisis_Event.", "published": "2025-07-07 16:20:35", "link": "http://arxiv.org/abs/2507.05165v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4DSloMo: 4D Reconstruction for High Speed Scene with Asynchronous Capture", "abstract": "Reconstructing fast-dynamic scenes from multi-view videos is crucial for\nhigh-speed motion analysis and realistic 4D reconstruction. However, the\nmajority of 4D capture systems are limited to frame rates below 30 FPS (frames\nper second), and a direct 4D reconstruction of high-speed motion from low FPS\ninput may lead to undesirable results. In this work, we propose a high-speed 4D\ncapturing system only using low FPS cameras, through novel capturing and\nprocessing modules. On the capturing side, we propose an asynchronous capture\nscheme that increases the effective frame rate by staggering the start times of\ncameras. By grouping cameras and leveraging a base frame rate of 25 FPS, our\nmethod achieves an equivalent frame rate of 100-200 FPS without requiring\nspecialized high-speed cameras. On processing side, we also propose a novel\ngenerative model to fix artifacts caused by 4D sparse-view reconstruction, as\nasynchrony reduces the number of viewpoints at each timestamp. Specifically, we\npropose to train a video-diffusion-based artifact-fix model for sparse 4D\nreconstruction, which refines missing details, maintains temporal consistency,\nand improves overall reconstruction quality. Experimental results demonstrate\nthat our method significantly enhances high-speed 4D reconstruction compared to\nsynchronous capture.", "published": "2025-07-07 16:18:35", "link": "http://arxiv.org/abs/2507.05163v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Motion Profiling for Annotation-free Cardiac Phase Detection in Adult and Fetal Echocardiography Videos", "abstract": "The identification of cardiac phase is an essential step for analysis and\ndiagnosis of cardiac function. Automatic methods, especially data-driven\nmethods for cardiac phase detection, typically require extensive annotations,\nwhich is time-consuming and labor-intensive. In this paper, we present an\nunsupervised framework for end-diastole (ED) and end-systole (ES) detection\nthrough self-supervised learning of latent cardiac motion trajectories from\n4-chamber-view echocardiography videos. Our method eliminates the need for\nmanual annotations, including ED and ES indices, segmentation, or volumetric\nmeasurements, by training a reconstruction model to encode interpretable\nspatiotemporal motion patterns. Evaluated on the EchoNet-Dynamic benchmark, the\napproach achieves mean absolute error (MAE) of 3 frames (58.3 ms) for ED and 2\nframes (38.8 ms) for ES detection, matching state-of-the-art supervised\nmethods. Extended to fetal echocardiography, the model demonstrates robust\nperformance with MAE 1.46 frames (20.7 ms) for ED and 1.74 frames (25.3 ms) for\nES, despite the fact that the fetal heart model is built using non-standardized\nheart views due to fetal heart positioning variability. Our results demonstrate\nthe potential of the proposed latent motion trajectory strategy for cardiac\nphase detection in adult and fetal echocardiography. This work advances\nunsupervised cardiac motion analysis, offering a scalable solution for clinical\npopulations lacking annotated data. Code will be released at\nhttps://github.com/YingyuYyy/CardiacPhase.", "published": "2025-07-07 16:10:46", "link": "http://arxiv.org/abs/2507.05154v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model", "abstract": "X-ray imaging is a rapid and cost-effective tool for visualizing internal\nhuman anatomy. While multi-view X-ray imaging provides complementary\ninformation that enhances diagnosis, intervention, and education, acquiring\nimages from multiple angles increases radiation exposure and complicates\nclinical workflows. To address these challenges, we propose a novel\nview-conditioned diffusion model for synthesizing multi-view X-ray images from\na single view. Unlike prior methods, which are limited in angular range,\nresolution, and image quality, our approach leverages the Diffusion Transformer\nto preserve fine details and employs a weak-to-strong training strategy for\nstable high-resolution image generation. Experimental results demonstrate that\nour method generates higher-resolution outputs with improved control over\nviewing angles. This capability has significant implications not only for\nclinical applications but also for medical education and data extension,\nenabling the creation of diverse, high-quality datasets for training and\nanalysis. Our code is available at GitHub.", "published": "2025-07-07 15:58:11", "link": "http://arxiv.org/abs/2507.05148v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "VERITAS: Verification and Explanation of Realness in Images for Transparency in AI Systems", "abstract": "The widespread and rapid adoption of AI-generated content, created by models\nsuch as Generative Adversarial Networks (GANs) and Diffusion Models, has\nrevolutionized the digital media landscape by allowing efficient and creative\ncontent generation. However, these models also blur the difference between real\nimages and AI-generated synthetic images, raising concerns regarding content\nauthenticity and integrity. While many existing solutions to detect fake images\nfocus solely on classification and higher-resolution images, they often lack\ntransparency in their decision-making, making it difficult for users to\nunderstand why an image is classified as fake. In this paper, we present\nVERITAS, a comprehensive framework that not only accurately detects whether a\nsmall (32x32) image is AI-generated but also explains why it was classified\nthat way through artifact localization and semantic reasoning. VERITAS produces\nhuman-readable explanations that describe key artifacts in synthetic images. We\nshow that this architecture offers clear explanations of the basis of zero-shot\nsynthetic image detection tasks. Code and relevant prompts can be found at\nhttps://github.com/V-i-g-n-e-s-h-N/VERITAS .", "published": "2025-07-07 15:57:05", "link": "http://arxiv.org/abs/2507.05146v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting", "abstract": "Recent large-scale Vision Language Action (VLA) models have shown superior\nperformance in robotic manipulation tasks guided by natural language. However,\ntheir generalization remains limited when applied to novel objects or\nunfamiliar environments that lie outside the training distribution. To address\nthis, many existing approaches integrate additional components such as depth\nestimation, segmentation, or even diffusion to improve generalization, at the\ncost of adding significant computation overhead, resulting in low efficiency.\nThis motivates the exploration of efficient action prediction methods, which\nare independent of additional high-level visual representations or diffusion\ntechniques. In this work, we propose VOTE, an efficient and general framework\nfor the optimization and acceleration of VLA models. In details, we propose a\nnovel tokenizer-free fine-tuning approach for parallel accurate action\nprediction, which reduces computational overhead and accelerates inference\nspeed. Additionally, we adopt an ensemble voting strategy for the action\nsampling, which significantly improves model performance and enhances\ngeneralization. Experimental results show that our method achieves\nstate-of-the-art performance with 35$\\times$ faster inference and 145 Hz\nthroughput. All the details and codes will be open-sourced.", "published": "2025-07-07 15:30:55", "link": "http://arxiv.org/abs/2507.05116v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation", "abstract": "Audio-driven talking head generation is critical for applications such as\nvirtual assistants, video games, and films, where natural lip movements are\nessential. Despite progress in this field, challenges remain in producing both\nconsistent and realistic facial animations. Existing methods, often based on\nGANs or UNet-based diffusion models, face three major limitations: (i) temporal\njittering caused by weak temporal constraints, resulting in frame\ninconsistencies; (ii) identity drift due to insufficient 3D information\nextraction, leading to poor preservation of facial identity; and (iii)\nunnatural blinking behavior due to inadequate modeling of realistic blink\ndynamics. To address these issues, we propose MoDiT, a novel framework that\ncombines the 3D Morphable Model (3DMM) with a Diffusion-based Transformer. Our\ncontributions include: (i) A hierarchical denoising strategy with revised\ntemporal attention and biased self/cross-attention mechanisms, enabling the\nmodel to refine lip synchronization and progressively enhance full-face\ncoherence, effectively mitigating temporal jittering. (ii) The integration of\n3DMM coefficients to provide explicit spatial constraints, ensuring accurate\n3D-informed optical flow prediction and improved lip synchronization using\nWav2Lip results, thereby preserving identity consistency. (iii) A refined\nblinking strategy to model natural eye movements, with smoother and more\nrealistic blinking behaviors.", "published": "2025-07-07 15:13:46", "link": "http://arxiv.org/abs/2507.05092v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Estimating Object Physical Properties from RGB-D Vision and Depth Robot Sensors Using Deep Learning", "abstract": "Inertial mass plays a crucial role in robotic applications such as object\ngrasping, manipulation, and simulation, providing a strong prior for planning\nand control. Accurately estimating an object's mass before interaction can\nsignificantly enhance the performance of various robotic tasks. However, mass\nestimation using only vision sensors is a relatively underexplored area. This\npaper proposes a novel approach combining sparse point-cloud data from depth\nimages with RGB images to estimate the mass of objects. We evaluate a range of\npoint-cloud processing architectures, alongside RGB-only methods. To overcome\nthe limited availability of training data, we create a synthetic dataset using\nShapeNetSem 3D models, simulating RGBD images via a Kinect camera. This\nsynthetic data is used to train an image generation model for estimating dense\ndepth maps, which we then use to augment an existing dataset of images paired\nwith mass values. Our approach significantly outperforms existing benchmarks\nacross all evaluated metrics. The data generation\n(https://github.com/RavineWindteer/ShapenetSem-to-RGBD) as well as the training\nof the depth estimator (https://github.com/RavineWindteer/GLPDepth-Edited) and\nthe mass estimator (https://github.com/RavineWindteer/Depth-mass-estimator) are\navailable online.", "published": "2025-07-07 14:11:47", "link": "http://arxiv.org/abs/2507.05029v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Incomplete-Modality Alignment for Ophthalmic Disease Grading and Diagnosis via Labeled Optimal Transport", "abstract": "Multimodal ophthalmic imaging-based diagnosis integrates color fundus image\nwith optical coherence tomography (OCT) to provide a comprehensive view of\nocular pathologies. However, the uneven global distribution of healthcare\nresources often results in real-world clinical scenarios encountering\nincomplete multimodal data, which significantly compromises diagnostic\naccuracy. Existing commonly used pipelines, such as modality imputation and\ndistillation methods, face notable limitations: 1)Imputation methods struggle\nwith accurately reconstructing key lesion features, since OCT lesions are\nlocalized, while fundus images vary in style. 2)distillation methods rely\nheavily on fully paired multimodal training data. To address these challenges,\nwe propose a novel multimodal alignment and fusion framework capable of\nrobustly handling missing modalities in the task of ophthalmic diagnostics. By\nconsidering the distinctive feature characteristics of OCT and fundus images,\nwe emphasize the alignment of semantic features within the same category and\nexplicitly learn soft matching between modalities, allowing the missing\nmodality to utilize existing modality information, achieving robust cross-modal\nfeature alignment under the missing modality. Specifically, we leverage the\nOptimal Transport for multi-scale modality feature alignment: class-wise\nalignment through predicted class prototypes and feature-wise alignment via\ncross-modal shared feature transport. Furthermore, we propose an asymmetric\nfusion strategy that effectively exploits the distinct characteristics of OCT\nand fundus modalities. Extensive evaluations on three large ophthalmic\nmultimodal datasets demonstrate our model's superior performance under various\nmodality-incomplete scenarios, achieving Sota performance in both complete\nmodality and inter-modality incompleteness conditions. Code is available at\nhttps://github.com/Qinkaiyu/RIMA", "published": "2025-07-07 13:36:39", "link": "http://arxiv.org/abs/2507.04999v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AI for the Routine, Humans for the Complex: Accuracy-Driven Data Labelling with Mixed Integer Linear Programming", "abstract": "The scarcity of accurately labelled data remains a major challenge in deep\nlearning (DL). Many DL approaches rely on semi-supervised methods, which focus\non constructing large datasets that require only a minimal amount of\nhuman-labelled data. Since DL training algorithms can tolerate moderate label\nnoise, it has generally been acceptable for the accuracy of labels in large\ntraining datasets to fall well short of a perfect 100%. However, when it comes\nto testing DL models, achieving high label accuracy-as close to 100% as\npossible-is paramount for reliable verification. In this article, we introduce\nOPAL, a human-assisted labelling method that can be configured to target a\ndesired accuracy level while minimizing the manual effort required for\nlabelling. The main contribution of OPAL is a mixed-integer linear programming\n(MILP) formulation that minimizes labelling effort subject to a specified\naccuracy target. We evaluate OPAL for two tasks in the context of testing\nvision systems: automatic labelling of test data and automated validation of\ntest data. Our evaluation, based on more than 2500 experiments performed on\nseven datasets, comparing OPAL with eight baseline methods, shows that OPAL,\nrelying on its MILP formulation, achieves an average accuracy of 98.8%, just\n1.2% below perfect accuracy, while cutting manual labelling by more than half.\nFurther, OPAL significantly outperforms automated labelling baselines in\nlabelling accuracy across all seven datasets, with large effect sizes, when all\nmethods are provided with the same manual-labelling budget. For automated\ntest-input validation, on average, OPAL reduces manual effort by 28.8% while\nachieving 4.5% higher accuracy than the SOTA validation baselines. Finally, we\nshow that augmenting OPAL with an active learning loop leads to an additional\n4.5% reduction in required manual labelling, without compromising accuracy.", "published": "2025-07-07 13:30:30", "link": "http://arxiv.org/abs/2507.04990v1", "categories": ["cs.CV", "cs.SE"], "primary_category": "cs.CV"}
{"title": "TLB-VFI: Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation", "abstract": "Video Frame Interpolation (VFI) aims to predict the intermediate frame $I_n$\n(we use n to denote time in videos to avoid notation overload with the timestep\n$t$ in diffusion models) based on two consecutive neighboring frames $I_0$ and\n$I_1$. Recent approaches apply diffusion models (both image-based and\nvideo-based) in this task and achieve strong performance. However, image-based\ndiffusion models are unable to extract temporal information and are relatively\ninefficient compared to non-diffusion methods. Video-based diffusion models can\nextract temporal information, but they are too large in terms of training\nscale, model size, and inference time. To mitigate the above issues, we propose\nTemporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation\n(TLB-VFI), an efficient video-based diffusion model. By extracting rich\ntemporal information from video inputs through our proposed 3D-wavelet gating\nand temporal-aware autoencoder, our method achieves 20% improvement in FID on\nthe most challenging datasets over recent SOTA of image-based diffusion models.\nMeanwhile, due to the existence of rich temporal information, our method\nachieves strong performance while having 3times fewer parameters. Such a\nparameter reduction results in 2.3x speed up. By incorporating optical flow\nguidance, our method requires 9000x less training data and achieves over 20x\nfewer parameters than video-based diffusion models. Codes and results are\navailable at our project page: https://zonglinl.github.io/tlbvfi_page.", "published": "2025-07-07 13:25:32", "link": "http://arxiv.org/abs/2507.04984v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Parameterized Diffusion Optimization enabled Autoregressive Ordinal Regression for Diabetic Retinopathy Grading", "abstract": "As a long-term complication of diabetes, diabetic retinopathy (DR) progresses\nslowly, potentially taking years to threaten vision. An accurate and robust\nevaluation of its severity is vital to ensure prompt management and care.\nOrdinal regression leverages the underlying inherent order between categories\nto achieve superior performance beyond traditional classification. However,\nthere exist challenges leading to lower DR classification performance: 1) The\nuneven distribution of DR severity levels, characterized by a long-tailed\npattern, adds complexity to the grading process. 2)The ambiguity in defining\ncategory boundaries introduces additional challenges, making the classification\nprocess more complex and prone to inconsistencies. This work proposes a novel\nautoregressive ordinal regression method called AOR-DR to address the above\nchallenges by leveraging the clinical knowledge of inherent ordinal information\nin DR grading dataset settings. Specifically, we decompose the DR grading task\ninto a series of ordered steps by fusing the prediction of the previous steps\nwith extracted image features as conditions for the current prediction step.\nAdditionally, we exploit the diffusion process to facilitate conditional\nprobability modeling, enabling the direct use of continuous global image\nfeatures for autoregression without relearning contextual information from\npatch-level features. This ensures the effectiveness of the autoregressive\nprocess and leverages the capabilities of pre-trained large-scale foundation\nmodels. Extensive experiments were conducted on four large-scale publicly\navailable color fundus datasets, demonstrating our model's effectiveness and\nsuperior performance over six recent state-of-the-art ordinal regression\nmethods. The implementation code is available at\nhttps://github.com/Qinkaiyu/AOR-DR.", "published": "2025-07-07 13:22:35", "link": "http://arxiv.org/abs/2507.04978v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InterGSEdit: Interactive 3D Gaussian Splatting Editing with 3D Geometry-Consistent Attention Prior", "abstract": "3D Gaussian Splatting based 3D editing has demonstrated impressive\nperformance in recent years. However, the multi-view editing often exhibits\nsignificant local inconsistency, especially in areas of non-rigid deformation,\nwhich lead to local artifacts, texture blurring, or semantic variations in\nedited 3D scenes. We also found that the existing editing methods, which rely\nentirely on text prompts make the editing process a \"one-shot deal\", making it\ndifficult for users to control the editing degree flexibly. In response to\nthese challenges, we present InterGSEdit, a novel framework for high-quality\n3DGS editing via interactively selecting key views with users' preferences. We\npropose a CLIP-based Semantic Consistency Selection (CSCS) strategy to\nadaptively screen a group of semantically consistent reference views for each\nuser-selected key view. Then, the cross-attention maps derived from the\nreference views are used in a weighted Gaussian Splatting unprojection to\nconstruct the 3D Geometry-Consistent Attention Prior ($GAP^{3D}$). We project\n$GAP^{3D}$ to obtain 3D-constrained attention, which are fused with 2D\ncross-attention via Attention Fusion Network (AFN). AFN employs an adaptive\nattention strategy that prioritizes 3D-constrained attention for geometric\nconsistency during early inference, and gradually prioritizes 2D\ncross-attention maps in diffusion for fine-grained features during the later\ninference. Extensive experiments demonstrate that InterGSEdit achieves\nstate-of-the-art performance, delivering consistent, high-fidelity 3DGS editing\nwith improved user experience.", "published": "2025-07-07 13:04:26", "link": "http://arxiv.org/abs/2507.04961v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Temporal Sentence Grounding via Causal Inference", "abstract": "Temporal Sentence Grounding (TSG) aims to identify relevant moments in an\nuntrimmed video that semantically correspond to a given textual query. Despite\nexisting studies having made substantial progress, they often overlook the\nissue of spurious correlations between video and textual queries. These\nspurious correlations arise from two primary factors: (1) inherent biases in\nthe textual data, such as frequent co-occurrences of specific verbs or phrases,\nand (2) the model's tendency to overfit to salient or repetitive patterns in\nvideo content. Such biases mislead the model into associating textual cues with\nincorrect visual moments, resulting in unreliable predictions and poor\ngeneralization to out-of-distribution examples. To overcome these limitations,\nwe propose a novel TSG framework, causal intervention and counterfactual\nreasoning that utilizes causal inference to eliminate spurious correlations and\nenhance the model's robustness. Specifically, we first formulate the TSG task\nfrom a causal perspective with a structural causal model. Then, to address\nunobserved confounders reflecting textual biases toward specific verbs or\nphrases, a textual causal intervention is proposed, utilizing do-calculus to\nestimate the causal effects. Furthermore, visual counterfactual reasoning is\nperformed by constructing a counterfactual scenario that focuses solely on\nvideo features, excluding the query and fused multi-modal features. This allows\nus to debias the model by isolating and removing the influence of the video\nfrom the overall effect. Experiments on public datasets demonstrate the\nsuperiority of the proposed method. The code is available at\nhttps://github.com/Tangkfan/CICR.", "published": "2025-07-07 13:01:06", "link": "http://arxiv.org/abs/2507.04958v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "RainShift: A Benchmark for Precipitation Downscaling Across Geographies", "abstract": "Earth System Models (ESM) are our main tool for projecting the impacts of\nclimate change. However, running these models at sufficient resolution for\nlocal-scale risk-assessments is not computationally feasible. Deep\nlearning-based super-resolution models offer a promising solution to downscale\nESM outputs to higher resolutions by learning from data. Yet, due to regional\nvariations in climatic processes, these models typically require retraining for\neach geographical area-demanding high-resolution observational data, which is\nunevenly available across the globe. This highlights the need to assess how\nwell these models generalize across geographic regions. To address this, we\nintroduce RainShift, a dataset and benchmark for evaluating downscaling under\ngeographic distribution shifts. We evaluate state-of-the-art downscaling\napproaches including GANs and diffusion models in generalizing across data gaps\nbetween the Global North and Global South. Our findings reveal substantial\nperformance drops in out-of-distribution regions, depending on model and\ngeographic area. While expanding the training domain generally improves\ngeneralization, it is insufficient to overcome shifts between geographically\ndistinct regions. We show that addressing these shifts through, for example,\ndata alignment can improve spatial generalization. Our work advances the global\napplicability of downscaling methods and represents a step toward reducing\ninequities in access to high-resolution climate information.", "published": "2025-07-07 12:25:14", "link": "http://arxiv.org/abs/2507.04930v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ConBatch-BAL: Batch Bayesian Active Learning under Budget Constraints", "abstract": "Varying annotation costs among data points and budget constraints can hinder\nthe adoption of active learning strategies in real-world applications. This\nwork introduces two Bayesian active learning strategies for batch acquisition\nunder constraints (ConBatch-BAL), one based on dynamic thresholding and one\nfollowing greedy acquisition. Both select samples using uncertainty metrics\ncomputed via Bayesian neural networks. The dynamic thresholding strategy\nredistributes the budget across the batch, while the greedy one selects the\ntop-ranked sample at each step, limited by the remaining budget. Focusing on\nscenarios with costly data annotation and geospatial constraints, we also\nrelease two new real-world datasets containing geolocated aerial images of\nbuildings, annotated with energy efficiency or typology classes. The\nConBatch-BAL strategies are benchmarked against a random acquisition baseline\non these datasets under various budget and cost scenarios. The results show\nthat the developed ConBatch-BAL strategies can reduce active learning\niterations and data acquisition costs in real-world settings, and even\noutperform the unconstrained baseline solutions.", "published": "2025-07-07 12:25:12", "link": "http://arxiv.org/abs/2507.04929v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Leveraging Self-Supervised Features for Efficient Flooded Region Identification in UAV Aerial Images", "abstract": "Identifying regions affected by disasters is a vital step in effectively\nmanaging and planning relief and rescue efforts. Unlike the traditional\napproaches of manually assessing post-disaster damage, analyzing images of\nUnmanned Aerial Vehicles (UAVs) offers an objective and reliable way to assess\nthe damage. In the past, segmentation techniques have been adopted to identify\npost-flood damage in UAV aerial images. However, most of these supervised\nlearning approaches rely on manually annotated datasets. Indeed, annotating\nimages is a time-consuming and error-prone task that requires domain expertise.\nThis work focuses on leveraging self-supervised features to accurately identify\nflooded regions in UAV aerial images. This work proposes two\nencoder-decoder-based segmentation approaches, which integrate the visual\nfeatures learned from DINOv2 with the traditional encoder backbone. This study\ninvestigates the generalization of self-supervised features for UAV aerial\nimages. Specifically, we evaluate the effectiveness of features from the DINOv2\nmodel, trained on non-aerial images, for segmenting aerial images, noting the\ndistinct perspectives between the two image types. Our results demonstrate that\nDINOv2's self-supervised pretraining on natural images generates transferable,\ngeneral-purpose visual features that streamline the development of aerial\nsegmentation workflows. By leveraging these features as a foundation, we\nsignificantly reduce reliance on labor-intensive manual annotation processes,\nenabling high-accuracy segmentation with limited labeled aerial data.", "published": "2025-07-07 12:02:35", "link": "http://arxiv.org/abs/2507.04915v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Piggyback Camera: Easy-to-Deploy Visual Surveillance by Mobile Sensing on Commercial Robot Vacuums", "abstract": "This paper presents Piggyback Camera, an easy-to-deploy system for visual\nsurveillance using commercial robot vacuums. Rather than requiring access to\ninternal robot systems, our approach mounts a smartphone equipped with a camera\nand Inertial Measurement Unit (IMU) on the robot, making it applicable to any\ncommercial robot without hardware modifications. The system estimates robot\nposes through neural inertial navigation and efficiently captures images at\nregular spatial intervals throughout the cleaning task. We develop a novel\ntest-time data augmentation method called Rotation-Augmented Ensemble (RAE) to\nmitigate domain gaps in neural inertial navigation. A loop closure method that\nexploits robot cleaning patterns further refines these estimated poses. We\ndemonstrate the system with an object mapping application that analyzes\ncaptured images to geo-localize objects in the environment. Experimental\nevaluation in retail environments shows that our approach achieves 0.83 m\nrelative pose error for robot localization and 0.97 m positional error for\nobject mapping of over 100 items.", "published": "2025-07-07 11:52:45", "link": "http://arxiv.org/abs/2507.04910v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MurreNet: Modeling Holistic Multimodal Interactions Between Histopathology and Genomic Profiles for Survival Prediction", "abstract": "Cancer survival prediction requires integrating pathological Whole Slide\nImages (WSIs) and genomic profiles, a challenging task due to the inherent\nheterogeneity and the complexity of modeling both inter- and intra-modality\ninteractions. Current methods often employ straightforward fusion strategies\nfor multimodal feature integration, failing to comprehensively capture\nmodality-specific and modality-common interactions, resulting in a limited\nunderstanding of multimodal correlations and suboptimal predictive performance.\nTo mitigate these limitations, this paper presents a Multimodal Representation\nDecoupling Network (MurreNet) to advance cancer survival analysis.\nSpecifically, we first propose a Multimodal Representation Decomposition (MRD)\nmodule to explicitly decompose paired input data into modality-specific and\nmodality-shared representations, thereby reducing redundancy between\nmodalities. Furthermore, the disentangled representations are further refined\nthen updated through a novel training regularization strategy that imposes\nconstraints on distributional similarity, difference, and representativeness of\nmodality features. Finally, the augmented multimodal features are integrated\ninto a joint representation via proposed Deep Holistic Orthogonal Fusion (DHOF)\nstrategy. Extensive experiments conducted on six TCGA cancer cohorts\ndemonstrate that our MurreNet achieves state-of-the-art (SOTA) performance in\nsurvival prediction.", "published": "2025-07-07 11:26:29", "link": "http://arxiv.org/abs/2507.04891v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven Methods", "abstract": "Brain tumor resection is a complex procedure with significant implications\nfor patient survival and quality of life. Predictions of patient outcomes\nprovide clinicians and patients the opportunity to select the most suitable\nonco-functional balance. In this study, global features derived from structural\nmagnetic resonance imaging in a clinical dataset of 49 pre- and post-surgery\npatients identified potential biomarkers associated with survival outcomes. We\npropose a framework that integrates Explainable AI (XAI) with\nneuroimaging-based feature engineering for survival assessment, offering\nguidance for surgical decision-making. In this study, we introduce a global\nexplanation optimizer that refines survival-related feature attribution in deep\nlearning models, enhancing interpretability and reliability. Our findings\nsuggest that survival is influenced by alterations in regions associated with\ncognitive and sensory functions, indicating the importance of preserving areas\ninvolved in decision-making and emotional regulation during surgery to improve\noutcomes. The global explanation optimizer improves both fidelity and\ncomprehensibility of explanations compared to state-of-the-art XAI methods. It\neffectively identifies survival-related variability, underscoring its relevance\nin precision medicine for brain tumor treatment.", "published": "2025-07-07 11:11:55", "link": "http://arxiv.org/abs/2507.04881v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation", "abstract": "Synthetic images are an option for augmenting limited medical imaging\ndatasets to improve the performance of various machine learning models. A\ncommon metric for evaluating synthetic image quality is the Fr\\'echet Inception\nDistance (FID) which measures the similarity of two image datasets. In this\nstudy we evaluate the relationship between this metric and the improvement\nwhich synthetic images, generated by a Progressively Growing Generative\nAdversarial Network (PGGAN), grant when augmenting Diabetes-related Macular\nEdema (DME) intraretinal fluid segmentation performed by a U-Net model with\nlimited amounts of training data. We find that the behaviour of augmenting with\nstandard and synthetic images agrees with previously conducted experiments.\nAdditionally, we show that dissimilar (high FID) datasets do not improve\nsegmentation significantly. As FID between the training and augmenting datasets\ndecreases, the augmentation datasets are shown to contribute to significant and\nrobust improvements in image segmentation. Finally, we find that there is\nsignificant evidence to suggest that synthetic and standard augmentations\nfollow separate log-normal trends between FID and improvements in model\nperformance, with synthetic data proving more effective than standard\naugmentation techniques. Our findings show that more similar datasets (lower\nFID) will be more effective at improving U-Net performance, however, the\nresults also suggest that this improvement may only occur when images are\nsufficiently dissimilar.", "published": "2025-07-07 10:38:45", "link": "http://arxiv.org/abs/2507.04862v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Semantically Consistent Discrete Diffusion for 3D Biological Graph Modeling", "abstract": "3D spatial graphs play a crucial role in biological and clinical research by\nmodeling anatomical networks such as blood vessels,neurons, and airways.\nHowever, generating 3D biological graphs while maintaining anatomical validity\nremains challenging, a key limitation of existing diffusion-based methods. In\nthis work, we propose a novel 3D biological graph generation method that\nadheres to structural and semantic plausibility conditions. We achieve this by\nusing a novel projection operator during sampling that stochastically fixes\ninconsistencies. Further, we adopt a superior edge-deletion-based noising\nprocedure suitable for sparse biological graphs. Our method demonstrates\nsuperior performance on two real-world datasets, human circle of Willis and\nlung airways, compared to previous approaches. Importantly, we demonstrate that\nthe generated samples significantly enhance downstream graph labeling\nperformance. Furthermore, we show that our generative model is a reasonable\nout-of-the-box link predictior.", "published": "2025-07-07 10:29:54", "link": "http://arxiv.org/abs/2507.04856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient SAR Vessel Detection for FPGA-Based On-Satellite Sensing", "abstract": "Rapid analysis of satellite data is vital for many remote sensing\napplications, from disaster response to environmental monitoring, but is\nbecoming harder to achieve with the increasing volumes of data generated by\nmodern satellites. On-satellite machine learning (ML) offers a potential\nsolution, by reducing latency associated with transmission of these large data\nvolumes to ground stations, but state-of-the-art models are often too large or\npower-hungry for satellite deployment. Vessel detection using Synthetic\nAperture Radar (SAR) is a critical time-sensitive task for maritime security\nthat exemplifies this challenge. SAR vessel detection has previously been\ndemonstrated only by ML models that either are too large for satellite\ndeployment, have not been developed for sufficiently low-power hardware, or\nhave only been developed and tested on small SAR datasets that do not\nsufficiently represent the real-world task. Here we address this issue by\ndeveloping and deploying a new efficient and highly performant SAR vessel\ndetection model, using a customised YOLOv8 architecture specifically optimized\nfor FPGA-based processing within common satellite power constraints (<10W). We\ntrain and evaluate our model on the largest and most diverse open SAR vessel\ndataset, xView3-SAR, and deploy it on a Kria KV260 MPSoC. We show that our\nFPGA-based model has detection and classification performance only ~2% and 3%\nlower than values from state-of-the-art GPU-based models, despite being two to\nthree orders of magnitude smaller in size. This work demonstrates small yet\nhighly performant ML models for time-critical SAR analysis, paving the way for\nmore autonomous, responsive, and scalable Earth observation systems.", "published": "2025-07-07 10:03:31", "link": "http://arxiv.org/abs/2507.04842v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMET: Clustering guided METric for quantifying embedding quality", "abstract": "Due to rapid advancements in technology, datasets are available from various\ndomains. In order to carry out more relevant and appropriate analysis, it is\noften necessary to project the dataset into a higher or lower dimensional space\nbased on requirement. Projecting the data in a higher-dimensional space helps\nin unfolding intricate patterns, enhancing the performance of the underlying\nmodels. On the other hand, dimensionality reduction is helpful in denoising\ndata while capturing maximal information, as well as reducing execution time\nand memory.In this context, it is not always statistically evident whether the\ntransformed embedding retains the local and global structure of the original\ndata. Most of the existing metrics that are used for comparing the local and\nglobal shape of the embedding against the original one are highly expensive in\nterms of time and space complexity. In order to address this issue, the\nobjective of this study is to formulate a novel metric, called Clustering\nguided METric (CMET), for quantifying embedding quality. It is effective to\nserve the purpose of quantitative comparison between an embedding and the\noriginal data. CMET consists of two scores, viz., CMET_L and CMET_G, that\nmeasure the degree of local and global shape preservation capability,\nrespectively. The efficacy of CMET has been demonstrated on a wide variety of\ndatasets, including four synthetic, two biological, and two image datasets.\nResults reflect the favorable performance of CMET against the state-of-the-art\nmethods. Capability to handle both small and large data, low algorithmic\ncomplexity, better and stable performance across all kinds of data, and\ndifferent choices of hyper-parameters feature CMET as a reliable metric.", "published": "2025-07-07 10:02:34", "link": "http://arxiv.org/abs/2507.04840v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction", "abstract": "We introduce RIPE, an innovative reinforcement learning-based framework for\nweakly-supervised training of a keypoint extractor that excels in both\ndetection and description tasks. In contrast to conventional training regimes\nthat depend heavily on artificial transformations, pre-generated models, or 3D\ndata, RIPE requires only a binary label indicating whether paired images\nrepresent the same scene. This minimal supervision significantly expands the\npool of training data, enabling the creation of a highly generalized and robust\nkeypoint extractor.\n  RIPE utilizes the encoder's intermediate layers for the description of the\nkeypoints with a hyper-column approach to integrate information from different\nscales. Additionally, we propose an auxiliary loss to enhance the\ndiscriminative capability of the learned descriptors.\n  Comprehensive evaluations on standard benchmarks demonstrate that RIPE\nsimplifies data preparation while achieving competitive performance compared to\nstate-of-the-art techniques, marking a significant advancement in robust\nkeypoint extraction and description. To support further research, we have made\nour code publicly available at https://github.com/fraunhoferhhi/RIPE.", "published": "2025-07-07 10:01:30", "link": "http://arxiv.org/abs/2507.04839v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SeqGrowGraph: Learning Lane Topology as a Chain of Graph Expansions", "abstract": "Accurate lane topology is essential for autonomous driving, yet traditional\nmethods struggle to model the complex, non-linear structures-such as loops and\nbidirectional lanes-prevalent in real-world road structure. We present\nSeqGrowGraph, a novel framework that learns lane topology as a chain of graph\nexpansions, inspired by human map-drawing processes. Representing the lane\ngraph as a directed graph $G=(V,E)$, with intersections ($V$) and centerlines\n($E$), SeqGrowGraph incrementally constructs this graph by introducing one\nvertex at a time. At each step, an adjacency matrix ($A$) expands from $n\n\\times n$ to $(n+1) \\times (n+1)$ to encode connectivity, while a geometric\nmatrix ($M$) captures centerline shapes as quadratic B\\'ezier curves. The graph\nis serialized into sequences, enabling a transformer model to autoregressively\npredict the chain of expansions, guided by a depth-first search ordering.\nEvaluated on nuScenes and Argoverse 2 datasets, SeqGrowGraph achieves\nstate-of-the-art performance.", "published": "2025-07-07 09:42:37", "link": "http://arxiv.org/abs/2507.04822v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UDF-GMA: Uncertainty Disentanglement and Fusion for General Movement Assessment", "abstract": "General movement assessment (GMA) is a non-invasive tool for the early\ndetection of brain dysfunction through the qualitative assessment of general\nmovements, and the development of automated methods can broaden its\napplication. However, mainstream pose-based automated GMA methods are prone to\nuncertainty due to limited high-quality data and noisy pose estimation,\nhindering clinical reliability without reliable uncertainty measures. In this\nwork, we introduce UDF-GMA which explicitly models epistemic uncertainty in\nmodel parameters and aleatoric uncertainty from data noise for pose-based\nautomated GMA. UDF-GMA effectively disentangles uncertainties by directly\nmodelling aleatoric uncertainty and estimating epistemic uncertainty through\nBayesian approximation. We further propose fusing these uncertainties with the\nembedded motion representation to enhance class separation. Extensive\nexperiments on the Pmi-GMA benchmark dataset demonstrate the effectiveness and\ngeneralisability of the proposed approach in predicting poor repertoire.", "published": "2025-07-07 09:32:47", "link": "http://arxiv.org/abs/2507.04814v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling", "abstract": "Most masked point cloud modeling (MPM) methods follow a regression paradigm\nto reconstruct the coordinate or feature of masked regions. However, they tend\nto over-constrain the model to learn the details of the masked region,\nresulting in failure to capture generalized features. To address this\nlimitation, we propose \\textbf{\\textit{PointGAC}}, a novel clustering-based MPM\nmethod that aims to align the feature distribution of masked regions.\nSpecially, it features an online codebook-guided teacher-student framework.\nFirstly, it presents a geometry-aware partitioning strategy to extract initial\npatches. Then, the teacher model updates a codebook via online k-means based on\nfeatures extracted from the complete patches. This procedure facilitates\ncodebook vectors to become cluster centers. Afterward, we assigns the unmasked\nfeatures to their corresponding cluster centers, and the student model aligns\nthe assignment for the reconstructed masked features. This strategy focuses on\nidentifying the cluster centers to which the masked features belong, enabling\nthe model to learn more generalized feature representations. Benefiting from a\nproposed codebook maintenance mechanism, codebook vectors are actively updated,\nwhich further increases the efficiency of semantic feature learning.\nExperiments validate the effectiveness of the proposed method on various\ndownstream tasks. Code is available at https://github.com/LAB123-tech/PointGAC", "published": "2025-07-07 09:21:28", "link": "http://arxiv.org/abs/2507.04801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GraphBrep: Learning B-Rep in Graph Structure for Efficient CAD Generation", "abstract": "Direct B-Rep generation is increasingly important in CAD workflows,\neliminating costly modeling sequence data and supporting complex features. A\nkey challenge is modeling joint distribution of the misaligned geometry and\ntopology. Existing methods tend to implicitly embed topology into the geometric\nfeatures of edges. Although this integration ensures feature alignment, it also\ncauses edge geometry to carry more redundant structural information compared to\nthe original B-Rep, leading to significantly higher computational cost. To\nreduce redundancy, we propose GraphBrep, a B-Rep generation model that\nexplicitly represents and learns compact topology. Following the original\nstructure of B-Rep, we construct an undirected weighted graph to represent\nsurface topology. A graph diffusion model is employed to learn topology\nconditioned on surface features, serving as the basis for determining\nconnectivity between primitive surfaces. The explicit representation ensures a\ncompact data structure, effectively reducing computational cost during both\ntraining and inference. Experiments on two large-scale unconditional datasets\nand one category-conditional dataset demonstrate the proposed method\nsignificantly reduces training and inference times (up to 31.3% and 56.3% for\ngiven datasets, respectively) while maintaining high-quality CAD generation\ncompared with SOTA.", "published": "2025-07-07 08:43:46", "link": "http://arxiv.org/abs/2507.04765v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robustifying 3D Perception through Least-Squares Multi-Agent Graphs Object Tracking", "abstract": "The critical perception capabilities of EdgeAI systems, such as autonomous\nvehicles, are required to be resilient against adversarial threats, by enabling\naccurate identification and localization of multiple objects in the scene over\ntime, mitigating their impact. Single-agent tracking offers resilience to\nadversarial attacks but lacks situational awareness, underscoring the need for\nmulti-agent cooperation to enhance context understanding and robustness. This\npaper proposes a novel mitigation framework on 3D LiDAR scene against\nadversarial noise by tracking objects based on least-squares graph on\nmulti-agent adversarial bounding boxes. Specifically, we employ the\nleast-squares graph tool to reduce the induced positional error of each\ndetection's centroid utilizing overlapped bounding boxes on a fully connected\ngraph via differential coordinates and anchor points. Hence, the multi-vehicle\ndetections are fused and refined mitigating the adversarial impact, and\nassociated with existing tracks in two stages performing tracking to further\nsuppress the adversarial threat. An extensive evaluation study on the\nreal-world V2V4Real dataset demonstrates that the proposed method significantly\noutperforms both state-of-the-art single and multi-agent tracking frameworks by\nup to 23.3% under challenging adversarial conditions, operating as a resilient\napproach without relying on additional defense mechanisms.", "published": "2025-07-07 08:41:08", "link": "http://arxiv.org/abs/2507.04762v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MatDecompSDF: High-Fidelity 3D Shape and PBR Material Decomposition from Multi-View Images", "abstract": "We present MatDecompSDF, a novel framework for recovering high-fidelity 3D\nshapes and decomposing their physically-based material properties from\nmulti-view images. The core challenge of inverse rendering lies in the\nill-posed disentanglement of geometry, materials, and illumination from 2D\nobservations. Our method addresses this by jointly optimizing three neural\ncomponents: a neural Signed Distance Function (SDF) to represent complex\ngeometry, a spatially-varying neural field for predicting PBR material\nparameters (albedo, roughness, metallic), and an MLP-based model for capturing\nunknown environmental lighting. The key to our approach is a physically-based\ndifferentiable rendering layer that connects these 3D properties to the input\nimages, allowing for end-to-end optimization. We introduce a set of carefully\ndesigned physical priors and geometric regularizations, including a material\nsmoothness loss and an Eikonal loss, to effectively constrain the problem and\nachieve robust decomposition. Extensive experiments on both synthetic and\nreal-world datasets (e.g., DTU) demonstrate that MatDecompSDF surpasses\nstate-of-the-art methods in geometric accuracy, material fidelity, and novel\nview synthesis. Crucially, our method produces editable and relightable assets\nthat can be seamlessly integrated into standard graphics pipelines, validating\nits practical utility for digital content creation.", "published": "2025-07-07 08:22:32", "link": "http://arxiv.org/abs/2507.04749v1", "categories": ["cs.CV", "68U05", "I.3.7; I.3.3; I.4.1"], "primary_category": "cs.CV"}
{"title": "Vision-Language Models Can't See the Obvious", "abstract": "We present Saliency Benchmark (SalBench), a novel benchmark designed to\nassess the capability of Large Vision-Language Models (LVLM) in detecting\nvisually salient features that are readily apparent to humans, such as a large\ncircle amidst a grid of smaller ones. This benchmark focuses on low-level\nfeatures including color, intensity, and orientation, which are fundamental to\nhuman visual processing. Our SalBench consists of images that highlight rare,\nunusual, or unexpected elements within scenes, and naturally draw human\nattention. It comprises three novel tasks for evaluating the perceptual\ncapabilities of LVLM: Odd-One-Out Detection, Referring Odd-One-Out, and Visual\nReferring Odd-One-Out. We perform a comprehensive evaluation of\nstate-of-the-art LVLM using SalBench and our findings reveal a surprising\nlimitation: LVLM struggle to identify seemingly obvious visual anomalies, with\neven the advanced GPT-4o achieving only 47.6\\% accuracy on such a simple task.\nSalBench will be an important step in measuring the capabilities of LVLM that\nalign with the subtle definition of human attention.", "published": "2025-07-07 08:16:38", "link": "http://arxiv.org/abs/2507.04741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An analysis of vision-language models for fabric retrieval", "abstract": "Effective cross-modal retrieval is essential for applications like\ninformation retrieval and recommendation systems, particularly in specialized\ndomains such as manufacturing, where product information often consists of\nvisual samples paired with a textual description. This paper investigates the\nuse of Vision Language Models(VLMs) for zero-shot text-to-image retrieval on\nfabric samples. We address the lack of publicly available datasets by\nintroducing an automated annotation pipeline that uses Multimodal Large\nLanguage Models (MLLMs) to generate two types of textual descriptions: freeform\nnatural language and structured attribute-based descriptions. We produce these\ndescriptions to evaluate retrieval performance across three Vision-Language\nModels: CLIP, LAION-CLIP, and Meta's Perception Encoder. Our experiments\ndemonstrate that structured, attribute-rich descriptions significantly enhance\nretrieval accuracy, particularly for visually complex fabric classes, with the\nPerception Encoder outperforming other models due to its robust feature\nalignment capabilities. However, zero-shot retrieval remains challenging in\nthis fine-grained domain, underscoring the need for domain-adapted approaches.\nOur findings highlight the importance of combining technical textual\ndescriptions with advanced VLMs to optimize cross-modal retrieval in industrial\napplications.", "published": "2025-07-07 08:00:18", "link": "http://arxiv.org/abs/2507.04735v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unleashing the Power of Neural Collapse: Consistent Supervised-Unsupervised Alignment for Generalized Category Discovery", "abstract": "Generalized Category Discovery (GCD) focuses on classifying known categories\nwhile simultaneously discovering novel categories from unlabeled data. However,\nprevious GCD methods face challenges due to inconsistent optimization\nobjectives and category confusion. This leads to feature overlap and ultimately\nhinders performance on novel categories. To address these issues, we propose\nthe Neural Collapse-inspired Generalized Category Discovery (NC-GCD) framework.\nBy pre-assigning and fixing Equiangular Tight Frame (ETF) prototypes, our\nmethod ensures an optimal geometric structure and a consistent optimization\nobjective for both known and novel categories. We introduce a Consistent ETF\nAlignment Loss that unifies supervised and unsupervised ETF alignment and\nenhances category separability. Additionally, a Semantic Consistency Matcher\n(SCM) is designed to maintain stable and consistent label assignments across\nclustering iterations. Our method achieves strong performance on multiple GCD\nbenchmarks, significantly enhancing novel category accuracy and demonstrating\nits effectiveness.", "published": "2025-07-07 07:34:41", "link": "http://arxiv.org/abs/2507.04725v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations", "abstract": "Identity-preserving text-to-video (IPT2V) generation, which aims to create\nhigh-fidelity videos with consistent human identity, has become crucial for\ndownstream applications. However, current end-to-end frameworks suffer a\ncritical spatial-temporal trade-off: optimizing for spatially coherent layouts\nof key elements (e.g., character identity preservation) often compromises\ninstruction-compliant temporal smoothness, while prioritizing dynamic realism\nrisks disrupting the spatial coherence of visual structures. To tackle this\nissue, we propose a simple yet effective spatial-temporal decoupled framework\nthat decomposes representations into spatial features for layouts and temporal\nfeatures for motion dynamics. Specifically, our paper proposes a semantic\nprompt optimization mechanism and stage-wise decoupled generation paradigm. The\nformer module decouples the prompt into spatial and temporal components.\nAligned with the subsequent stage-wise decoupled approach, the spatial prompts\nguide the text-to-image (T2I) stage to generate coherent spatial features,\nwhile the temporal prompts direct the sequential image-to-video (I2V) stage to\nensure motion consistency. Experimental results validate that our approach\nachieves excellent spatiotemporal consistency, demonstrating outstanding\nperformance in identity preservation, text relevance, and video quality. By\nleveraging this simple yet robust mechanism, our algorithm secures the\nrunner-up position in 2025 ACM MultiMedia Challenge.", "published": "2025-07-07 06:54:44", "link": "http://arxiv.org/abs/2507.04705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Visual Leap in CLIP Compositionality Reasoning through Generation of Counterfactual Sets", "abstract": "Vision-language models (VLMs) often struggle with compositional reasoning due\nto insufficient high-quality image-text data. To tackle this challenge, we\npropose a novel block-based diffusion approach that automatically generates\ncounterfactual datasets without manual annotation. Our method utilizes large\nlanguage models to identify entities and their spatial relationships. It then\nindependently generates image blocks as \"puzzle pieces\" coherently arranged\naccording to specified compositional rules. This process creates diverse,\nhigh-fidelity counterfactual image-text pairs with precisely controlled\nvariations. In addition, we introduce a specialized loss function that\ndifferentiates inter-set from intra-set samples, enhancing training efficiency\nand reducing the need for negative samples. Experiments demonstrate that\nfine-tuning VLMs with our counterfactual datasets significantly improves visual\nreasoning performance. Our approach achieves state-of-the-art results across\nmultiple benchmarks while using substantially less training data than existing\nmethods.", "published": "2025-07-07 06:47:10", "link": "http://arxiv.org/abs/2507.04699v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure-Guided Diffusion Models for High-Fidelity Portrait Shadow Removal", "abstract": "We present a diffusion-based portrait shadow removal approach that can\nrobustly produce high-fidelity results. Unlike previous methods, we cast shadow\nremoval as diffusion-based inpainting. To this end, we first train a\nshadow-independent structure extraction network on a real-world portrait\ndataset with various synthetic lighting conditions, which allows to generate a\nshadow-independent structure map including facial details while excluding the\nunwanted shadow boundaries. The structure map is then used as condition to\ntrain a structure-guided inpainting diffusion model for removing shadows in a\ngenerative manner. Finally, to restore the fine-scale details (e.g., eyelashes,\nmoles and spots) that may not be captured by the structure map, we take the\ngradients inside the shadow regions as guidance and train a detail restoration\ndiffusion model to refine the shadow removal result. Extensive experiments on\nthe benchmark datasets show that our method clearly outperforms existing\nmethods, and is effective to avoid previously common issues such as facial\nidentity tampering, shadow residual, color distortion, structure blurring, and\nloss of details. Our code is available at\nhttps://github.com/wanchang-yu/Structure-Guided-Diffusion-for-Portrait-Shadow-Removal.", "published": "2025-07-07 06:19:07", "link": "http://arxiv.org/abs/2507.04692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TeethGenerator: A two-stage framework for paired pre- and post-orthodontic 3D dental data generation", "abstract": "Digital orthodontics represents a prominent and critical application of\ncomputer vision technology in the medical field. So far, the labor-intensive\nprocess of collecting clinical data, particularly in acquiring paired 3D\northodontic teeth models, constitutes a crucial bottleneck for developing tooth\narrangement neural networks. Although numerous general 3D shape generation\nmethods have been proposed, most of them focus on single-object generation and\nare insufficient for generating anatomically structured teeth models, each\ncomprising 24-32 segmented teeth. In this paper, we propose TeethGenerator, a\nnovel two-stage framework designed to synthesize paired 3D teeth models pre-\nand post-orthodontic, aiming to facilitate the training of downstream tooth\narrangement networks. Specifically, our approach consists of two key modules:\n(1) a teeth shape generation module that leverages a diffusion model to learn\nthe distribution of morphological characteristics of teeth, enabling the\ngeneration of diverse post-orthodontic teeth models; and (2) a teeth style\ngeneration module that synthesizes corresponding pre-orthodontic teeth models\nby incorporating desired styles as conditional inputs. Extensive qualitative\nand quantitative experiments demonstrate that our synthetic dataset aligns\nclosely with the distribution of real orthodontic data, and promotes tooth\nalignment performance significantly when combined with real data for training.\nThe code and dataset are available at\nhttps://github.com/lcshhh/teeth_generator.", "published": "2025-07-07 06:08:10", "link": "http://arxiv.org/abs/2507.04685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPIDER: Structure-Preferential Implicit Deep Network for Biplanar X-ray Reconstruction", "abstract": "Biplanar X-ray imaging is widely used in health screening, postoperative\nrehabilitation evaluation of orthopedic diseases, and injury surgery due to its\nrapid acquisition, low radiation dose, and straightforward setup. However, 3D\nvolume reconstruction from only two orthogonal projections represents a\nprofoundly ill-posed inverse problem, owing to the intrinsic lack of depth\ninformation and irreducible ambiguities in soft-tissue visualization. Some\nexisting methods can reconstruct skeletal structures and Computed Tomography\n(CT) volumes, they often yield incomplete bone geometry, imprecise tissue\nboundaries, and a lack of anatomical realism, thereby limiting their clinical\nutility in scenarios such as surgical planning and postoperative assessment. In\nthis study, we introduce SPIDER, a novel supervised framework designed to\nreconstruct CT volumes from biplanar X-ray images. SPIDER incorporates tissue\nstructure as prior (e.g., anatomical segmentation) into an implicit neural\nrepresentation decoder in the form of joint supervision through a unified\nencoder-decoder architecture. This design enables the model to jointly learn\nimage intensities and anatomical structures in a pixel-aligned fashion. To\naddress the challenges posed by sparse input and structural ambiguity, SPIDER\ndirectly embeds anatomical constraints into the reconstruction process, thereby\nenhancing structural continuity and reducing soft-tissue artifacts. We conduct\ncomprehensive experiments on clinical head CT datasets and show that SPIDER\ngenerates anatomically accurate reconstructions from only two projections.\nFurthermore, our approach demonstrates strong potential in downstream\nsegmentation tasks, underscoring its utility in personalized treatment planning\nand image-guided surgical navigation.", "published": "2025-07-07 06:06:28", "link": "http://arxiv.org/abs/2507.04684v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology Images: From Giga to Mini Challenge", "abstract": "Colorectal cancer (CRC) is the third most diagnosed cancer and the second\nleading cause of cancer-related death worldwide. Accurate histopathological\ngrading of CRC is essential for prognosis and treatment planning but remains a\nsubjective process prone to observer variability and limited by global\nshortages of trained pathologists. To promote automated and standardized\nsolutions, we organized the ICIP Grand Challenge on Colorectal Cancer Tumor\nGrading and Segmentation using the publicly available METU CCTGS dataset. The\ndataset comprises 103 whole-slide images with expert pixel-level annotations\nfor five tissue classes. Participants submitted segmentation masks via Codalab,\nevaluated using metrics such as macro F-score and mIoU. Among 39 participating\nteams, six outperformed the Swin Transformer baseline (62.92 F-score). This\npaper presents an overview of the challenge, dataset, and the top-performing\nmethods", "published": "2025-07-07 05:59:16", "link": "http://arxiv.org/abs/2507.04681v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ChangeBridge: Spatiotemporal Image Generation with Multimodal Controls for Remote Sensing", "abstract": "Recent advancements in generative methods, especially diffusion models, have\nmade great progress in remote sensing image synthesis. Despite these\nadvancements, existing methods have not explored the simulation of future\nscenarios based on given scenario images. This simulation capability has wide\napplications for urban planning, land managementChangeBridge: Spatiotemporal\nImage Generation with Multimodal Controls, and beyond. In this work, we propose\nChangeBridge, a conditional spatiotemporal diffusion model. Given pre-event\nimages and conditioned on multimodal spatial controls (e.g., text prompts,\ninstance layouts, and semantic maps), ChangeBridge can synthesize post-event\nimages. The core idea behind ChangeBridge is to modeling the noise-to-image\ndiffusion model, as a pre-to-post diffusion bridge. Conditioned on multimodal\ncontrols, ChangeBridge leverages a stochastic Brownian-bridge diffusion,\ndirectly modeling the spatiotemporal evolution between pre-event and post-event\nstates. To the best of our knowledge, ChangeBridge is the first spatiotemporal\ngenerative model with multimodal controls for remote sensing. Experimental\nresults demonstrate that ChangeBridge can simulate high-fidelity future\nscenarios aligned with given conditions, including event and event-driven\nbackground variations. Code will be available.", "published": "2025-07-07 05:51:55", "link": "http://arxiv.org/abs/2507.04678v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DANCE: Resource-Efficient Neural Architecture Search with Data-Aware and Continuous Adaptation", "abstract": "Neural Architecture Search (NAS) has emerged as a powerful approach for\nautomating neural network design. However, existing NAS methods face critical\nlimitations in real-world deployments: architectures lack adaptability across\nscenarios, each deployment context requires costly separate searches, and\nperformance consistency across diverse platforms remains challenging. We\npropose DANCE (Dynamic Architectures with Neural Continuous Evolution), which\nreformulates architecture search as a continuous evolution problem through\nlearning distributions over architectural components. DANCE introduces three\nkey innovations: a continuous architecture distribution enabling smooth\nadaptation, a unified architecture space with learned selection gates for\nefficient sampling, and a multi-stage training strategy for effective\ndeployment optimization. Extensive experiments across five datasets demonstrate\nDANCE's effectiveness. Our method consistently outperforms state-of-the-art NAS\napproaches in terms of accuracy while significantly reducing search costs.\nUnder varying computational constraints, DANCE maintains robust performance\nwhile smoothly adapting architectures to different hardware requirements. The\ncode and appendix can be found at\nhttps://github.com/Applied-Machine-Learning-Lab/DANCE.", "published": "2025-07-07 05:22:55", "link": "http://arxiv.org/abs/2507.04671v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VectorLLM: Human-like Extraction of Structured Building Contours vis Multimodal LLMs", "abstract": "Automatically extracting vectorized building contours from remote sensing\nimagery is crucial for urban planning, population estimation, and disaster\nassessment. Current state-of-the-art methods rely on complex multi-stage\npipelines involving pixel segmentation, vectorization, and polygon refinement,\nwhich limits their scalability and real-world applicability. Inspired by the\nremarkable reasoning capabilities of Large Language Models (LLMs), we introduce\nVectorLLM, the first Multi-modal Large Language Model (MLLM) designed for\nregular building contour extraction from remote sensing images. Unlike existing\napproaches, VectorLLM performs corner-point by corner-point regression of\nbuilding contours directly, mimicking human annotators' labeling process. Our\narchitecture consists of a vision foundation backbone, an MLP connector, and an\nLLM, enhanced with learnable position embeddings to improve spatial\nunderstanding capability. Through comprehensive exploration of training\nstrategies including pretraining, supervised fine-tuning, and preference\noptimization across WHU, WHU-Mix, and CrowdAI datasets, VectorLLM significantly\noutperformed the previous SOTA methods by 5.6 AP, 7.1 AP, 13.6 AP, respectively\nin the three datasets. Remarkably, VectorLLM exhibits strong zero-shot\nperformance on unseen objects including aircraft, water bodies, and oil tanks,\nhighlighting its potential for unified modeling of diverse remote sensing\nobject contour extraction tasks. Overall, this work establishes a new paradigm\nfor vector extraction in remote sensing, leveraging the topological reasoning\ncapabilities of LLMs to achieve both high accuracy and exceptional\ngeneralization. All the codes and weights will be published for promoting\ncommunity development.", "published": "2025-07-07 05:10:15", "link": "http://arxiv.org/abs/2507.04664v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CP-Dilatation: A Copy-and-Paste Augmentation Method for Preserving the Boundary Context Information of Histopathology Images", "abstract": "Medical AI diagnosis including histopathology segmentation has derived\nbenefits from the recent development of deep learning technology. However, deep\nlearning itself requires a large amount of training data and the medical image\nsegmentation masking, in particular, requires an extremely high cost due to the\nshortage of medical specialists. To mitigate this issue, we propose a new data\naugmentation method built upon the conventional Copy and Paste (CP)\naugmentation technique, called CP-Dilatation, and apply it to histopathology\nimage segmentation. To the well-known traditional CP technique, the proposed\nmethod adds a dilation operation that can preserve the boundary context\ninformation of the malignancy, which is important in histopathological image\ndiagnosis, as the boundary between the malignancy and its margin is mostly\nunclear and a significant context exists in the margin. In our experiments\nusing histopathology benchmark datasets, the proposed method was found superior\nto the other state-of-the-art baselines chosen for comparison.", "published": "2025-07-07 04:34:02", "link": "http://arxiv.org/abs/2507.04660v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification", "abstract": "Multi-modal object Re-IDentification (ReID) has gained considerable attention\nwith the goal of retrieving specific targets across cameras using heterogeneous\nvisual data sources. Existing methods primarily aim to improve identification\nperformance, but often overlook the uncertainty arising from inherent defects,\nsuch as intra-modal noise and inter-modal conflicts. This uncertainty is\nparticularly significant in the case of fine-grained local occlusion and frame\nloss, which becomes a challenge in multi-modal learning. To address the above\nchallenge, we propose a robust approach named Uncertainty-Guided Graph model\nfor multi-modal object ReID (UGG-ReID). UGG-ReID is designed to mitigate noise\ninterference and facilitate effective multi-modal fusion by estimating both\nlocal and sample-level aleatoric uncertainty and explicitly modeling their\ndependencies. Specifically, we first propose the Gaussian patch-graph\nrepresentation model that leverages uncertainty to quantify fine-grained local\ncues and capture their structural relationships. This process boosts the\nexpressiveness of modal-specific information, ensuring that the generated\nembeddings are both more informative and robust. Subsequently, we design an\nuncertainty-guided mixture of experts strategy that dynamically routes samples\nto experts exhibiting low uncertainty. This strategy effectively suppresses\nnoise-induced instability, leading to enhanced robustness. Meanwhile, we design\nan uncertainty-guided routing to strengthen the multi-modal interaction,\nimproving the performance. UGG-ReID is comprehensively evaluated on five\nrepresentative multi-modal object ReID datasets, encompassing diverse spectral\nmodalities. Experimental results show that the proposed method achieves\nexcellent performance on all datasets and is significantly better than current\nmethods in terms of noise immunity. Our code will be made public upon\nacceptance.", "published": "2025-07-07 03:41:08", "link": "http://arxiv.org/abs/2507.04638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding", "abstract": "Multimodal large language models (MLLMs) recently showed strong capacity in\nintegrating data among multiple modalities, empowered by a generalizable\nattention architecture. Advanced methods predominantly focus on\nlanguage-centric tuning while less exploring multimodal tokens mixed through\nattention, posing challenges in high-level tasks that require fine-grained\ncognition and emotion understanding. In this work, we identify the attention\ndeficit disorder problem in multimodal learning, caused by inconsistent\ncross-modal attention and layer-by-layer decayed attention activation. To\naddress this, we propose a novel attention mechanism, termed MOdular Duplex\nAttention (MODA), simultaneously conducting the inner-modal refinement and\ninter-modal interaction. MODA employs a correct-after-align strategy to\neffectively decouple modality alignment from cross-layer token mixing. In the\nalignment phase, tokens are mapped to duplex modality spaces based on the basis\nvectors, enabling the interaction between visual and language modality.\nFurther, the correctness of attention scores is ensured through adaptive masked\nattention, which enhances the model's flexibility by allowing customizable\nmasking patterns for different modalities. Extensive experiments on 21\nbenchmark datasets verify the effectiveness of MODA in perception, cognition,\nand emotion tasks. Source code and demo are available in\nhttps://zzcheng.top/MODA.", "published": "2025-07-07 03:37:42", "link": "http://arxiv.org/abs/2507.04635v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Computing Expansions in Infinitely Many Cantor Real Bases via a Single Transducer", "abstract": "Representing real numbers using convenient numeration systems (integer bases,\n$\\beta$-numeration, Cantor bases, etc.) has been a longstanding mathematical\nchallenge. This paper focuses on Cantor real bases and, specifically, on\nautomatic Cantor real bases and the properties of expansions of real numbers in\nthis setting. We develop a new approach where a single transducer associated\nwith a fixed real number $r$, computes the $\\mathbf{B}$-expansion of $r$ but\nfor an infinite family of Cantor real bases $\\mathbf{B}$ given as input. This\npoint of view contrasts with traditional computational models for which the\nnumeration system is fixed. Under some assumptions on the finitely many Pisot\nnumbers occurring in the Cantor real base, we show that only a finite part of\nthe transducer is visited. We obtain fundamental results on the structure of\nthis transducer and on decidability problems about these expansions, proving\nthat for certain classes of Cantor real bases, key combinatorial properties\nsuch as greediness of the expansion or periodicity can be decided\nalgorithmically.", "published": "2025-07-07 10:13:55", "link": "http://arxiv.org/abs/2507.04848v1", "categories": ["math.NT", "cs.DM", "math.CO", "11A63, 11K16, 11B85, 68Q45, 68R15"], "primary_category": "math.NT"}
{"title": "In-Context Learning as an Effective Estimator of Functional Correctness of LLM-Generated Code", "abstract": "When applying LLM-based code generation to software development projects that\nfollow a feature-driven or rapid application development approach, it becomes\nnecessary to estimate the functional correctness of the generated code in the\nabsence of test cases. Just as a user selects a relevant document from a ranked\nlist of retrieved ones, a software generation workflow requires a developer to\nchoose (and potentially refine) a generated solution from a ranked list of\nalternative solutions, ordered by their posterior likelihoods. This implies\nthat estimating the quality of a ranked list -- akin to estimating \"relevance\"\nfor query performance prediction (QPP) in IR -- is also crucial for generative\nsoftware development, where quality is defined in terms of \"functional\ncorrectness\". In this paper, we propose an in-context learning (ICL) based\napproach for code quality estimation. Our findings demonstrate that providing\nfew-shot examples of functionally correct code from a training set enhances the\nperformance of existing QPP approaches as well as a zero-shot-based approach\nfor code quality estimation.", "published": "2025-07-07 17:01:17", "link": "http://arxiv.org/abs/2507.05200v1", "categories": ["cs.SE", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Interest Networks (iNETs) for Cities: Cross-Platform Insights and Urban Behavior Explanations", "abstract": "Location-Based Social Networks (LBSNs) provide a rich foundation for modeling\nurban behavior through iNETs (Interest Networks), which capture how user\ninterests are distributed throughout urban spaces. This study compares iNETs\nacross platforms (Google Places and Foursquare) and spatial granularities,\nshowing that coarser levels reveal more consistent cross-platform patterns,\nwhile finer granularities expose subtle, platform-specific behaviors. Our\nanalysis finds that, in general, user interest is primarily shaped by\ngeographic proximity and venue similarity, while socioeconomic and political\ncontexts play a lesser role. Building on these insights, we develop a\nmulti-level, explainable recommendation system that predicts high-interest\nurban regions for different user types. The model adapts to behavior profiles\n-- such as explorers, who are driven by proximity, and returners, who prefer\nfamiliar venues -- and provides natural-language explanations using explainable\nAI (XAI) techniques. To support our approach, we introduce h3-cities, a tool\nfor multi-scale spatial analysis, and release a public demo for interactively\nexploring personalized urban recommendations. Our findings contribute to urban\nmobility research by providing scalable, context-aware, and interpretable\nrecommendation systems.", "published": "2025-07-07 13:34:15", "link": "http://arxiv.org/abs/2507.04995v1", "categories": ["cs.SI", "cs.IR"], "primary_category": "cs.SI"}
{"title": "SimLab: A Platform for Simulation-based Evaluation of Conversational Information Access Systems", "abstract": "Research on interactive and conversational information access systems,\nincluding search engines, recommender systems, and conversational assistants,\nhas been hindered by the difficulty in evaluating such systems with\nreproducible experiments. User simulation provides a promising solution, but\nthere is a lack of infrastructure and tooling to support this kind of\nevaluation. To facilitate simulation-based evaluation of conversational\ninformation access systems, we introduce SimLab, the first cloud-based platform\nto provide a centralized general solution for the community to benchmark both\nconversational systems and user simulators in a controlled and reproducible\nenvironment. We articulate requirements for such a platform and propose a\ngeneral infrastructure to address these requirements. We then present the\ndesign and implementation of an initial version of SimLab and showcase its\nfeatures with an initial evaluation task of conversational movie\nrecommendation, which is made publicly available. Furthermore, we discuss the\nsustainability of the platform and its future opportunities. This paper is a\ncall for the community to contribute to the platform to drive progress in the\nfield of conversational information access and user simulation.", "published": "2025-07-07 11:19:28", "link": "http://arxiv.org/abs/2507.04888v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Harnessing Pairwise Ranking Prompting Through Sample-Efficient Ranking Distillation", "abstract": "While Pairwise Ranking Prompting (PRP) with Large Language Models (LLMs) is\none of the most effective zero-shot document ranking methods, it has a\nquadratic computational complexity with respect to the number of documents to\nbe ranked, as it requires an enumeration over all possible document pairs.\nConsequently, the outstanding ranking performance of PRP has remained\nunreachable for most real-world ranking applications.\n  In this work, we propose to harness the effectiveness of PRP through pairwise\ndistillation. Specifically, we distill a pointwise student ranker from pairwise\nteacher labels generated by PRP, resulting in an efficient student model that\nretains the performance of PRP with substantially lower computational costs.\nFurthermore, we find that the distillation process can be made\nsample-efficient: with only 2% of pairs, we are able to obtain the same\nperformance as using all pairs for teacher labels. Thus, our novel approach\nprovides a solution to harness the ranking performance of PRP without incurring\nhigh computational costs during both distillation and serving.", "published": "2025-07-07 09:38:43", "link": "http://arxiv.org/abs/2507.04820v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FindRec: Stein-Guided Entropic Flow for Multi-Modal Sequential Recommendation", "abstract": "Modern recommendation systems face significant challenges in processing\nmultimodal sequential data, particularly in temporal dynamics modeling and\ninformation flow coordination. Traditional approaches struggle with\ndistribution discrepancies between heterogeneous features and noise\ninterference in multimodal signals. We propose \\textbf{FindRec}~\n(\\textbf{F}lexible unified \\textbf{in}formation \\textbf{d}isentanglement for\nmulti-modal sequential \\textbf{Rec}ommendation), introducing a novel\n\"information flow-control-output\" paradigm. The framework features two key\ninnovations: (1) A Stein kernel-based Integrated Information Coordination\nModule (IICM) that theoretically guarantees distribution consistency between\nmultimodal features and ID streams, and (2) A cross-modal expert routing\nmechanism that adaptively filters and combines multimodal features based on\ntheir contextual relevance. Our approach leverages multi-head subspace\ndecomposition for routing stability and RBF-Stein gradient for unbiased\ndistribution alignment, enhanced by linear-complexity Mamba layers for\nefficient temporal modeling. Extensive experiments on three real-world datasets\ndemonstrate FindRec's superior performance over state-of-the-art baselines,\nparticularly in handling long sequences and noisy multimodal inputs. Our\nframework achieves both improved recommendation accuracy and enhanced model\ninterpretability through its modular design. The implementation code is\navailable anonymously online for easy\nreproducibility~\\footnote{https://github.com/Applied-Machine-Learning-Lab/FindRec}.", "published": "2025-07-07 04:09:45", "link": "http://arxiv.org/abs/2507.04651v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Heterogeneous User Modeling for LLM-based Recommendation", "abstract": "Leveraging Large Language Models (LLMs) for recommendation has demonstrated\nnotable success in various domains, showcasing their potential for open-domain\nrecommendation. A key challenge to advancing open-domain recommendation lies in\neffectively modeling user preferences from users' heterogeneous behaviors\nacross multiple domains. Existing approaches, including ID-based and\nsemantic-based modeling, struggle with poor generalization, an inability to\ncompress noisy interactions effectively, and the domain seesaw phenomenon. To\naddress these challenges, we propose a Heterogeneous User Modeling (HUM)\nmethod, which incorporates a compression enhancer and a robustness enhancer for\nLLM-based recommendation. The compression enhancer uses a customized prompt to\ncompress heterogeneous behaviors into a tailored token, while a masking\nmechanism enhances cross-domain knowledge extraction and understanding. The\nrobustness enhancer introduces a domain importance score to mitigate the domain\nseesaw phenomenon by guiding domain optimization. Extensive experiments on\nheterogeneous datasets validate that HUM effectively models user heterogeneity\nby achieving both high efficacy and robustness, leading to superior performance\nin open-domain recommendation.", "published": "2025-07-07 03:08:28", "link": "http://arxiv.org/abs/2507.04626v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Alternating minimization for computing doubly minimized Petz Renyi mutual information", "abstract": "The doubly minimized Petz Renyi mutual information (PRMI) of order $\\alpha$\nis defined as the minimization of the Petz divergence of order $\\alpha$ of a\nfixed bipartite quantum state $\\rho_{AB}$ relative to any product state\n$\\sigma_A\\otimes \\tau_B$. To date, no closed-form expression for this measure\nhas been found, necessitating the development of numerical methods for its\ncomputation. In this work, we show that alternating minimization over\n$\\sigma_A$ and $\\tau_B$ asymptotically converges to the doubly minimized PRMI\nfor any $\\alpha\\in (\\frac{1}{2},1)\\cup (1,2]$, by proving linear convergence of\nthe objective function values with respect to the number of iterations for\n$\\alpha\\in (1,2]$ and sublinear convergence for $\\alpha\\in (\\frac{1}{2},1)$.\nPrevious studies have only addressed the specific case where $\\rho_{AB}$ is a\nclassical-classical state, while our results hold for any quantum state\n$\\rho_{AB}$.", "published": "2025-07-07 17:11:58", "link": "http://arxiv.org/abs/2507.05205v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Intuitive dissection of the Gaussian information bottleneck method with an application to optimal prediction", "abstract": "Efficient signal representation is essential for the functioning of living\nand artificial systems operating under resource constraints. A widely\nrecognized framework for deriving such representations is the information\nbottleneck method, which yields the optimal strategy for encoding a random\nvariable, such as the signal, in a way that preserves maximal information about\na functionally relevant variable, subject to an explicit constraint on the\namount of information encoded. While in its general formulation the method is\nnumerical, it admits an analytical solution in an important special case where\nthe variables involved are jointly Gaussian. In this setting, the solution\npredicts discrete transitions in the dimensionality of the optimal\nrepresentation as the encoding capacity is increased. Although these signature\ntransitions, along with other features of the optimal strategy, can be derived\nfrom a constrained optimization problem, a clear and intuitive understanding of\ntheir emergence is still lacking. In our work, we advance our understanding of\nthe Gaussian information bottleneck method through multiple mutually enriching\nperspectives, including geometric and information-theoretic ones. These\nperspectives offer novel intuition about the set of optimal encoding\ndirections, the nature of the critical points where the optimal number of\nencoding components changes, and about the way the optimal strategy navigates\nbetween these critical points. We then apply our treatment of the method to a\npreviously studied signal prediction problem, obtaining new insights on how\ndifferent features of the signal are encoded across multiple components to\nenable optimal prediction of future signals. Altogether, our work deepens the\nfoundational understanding of the information bottleneck method in the Gaussian\nsetting, motivating the exploration of analogous perspectives in broader,\nnon-Gaussian contexts.", "published": "2025-07-07 16:37:11", "link": "http://arxiv.org/abs/2507.05183v1", "categories": ["q-bio.MN", "cond-mat.stat-mech", "cs.IT", "math.IT", "physics.bio-ph"], "primary_category": "q-bio.MN"}
{"title": "Circular Holographic MIMO Beamforming for Integrated Data and Energy Multicast Systems", "abstract": "Thanks to the application of metamaterials, holographic multiple-input\nmultiple-output (H-MIMO) is expected to achieve a higher spatial diversity gain\nwith lower hardware complexity. With the aid of a circular antenna arrangement\nof H-MIMO, integrated data and energy multicast (IDEM) can fully exploit the\nnear-field channel to realize wider range of energy focusing and higher\nachievable rate. In this paper, we derive the closed-form near-field resolution\nfunction in 3D space and show the asymptotic spatial orthogonality of\nnear-field channel for circular antenna array. We then investigate the\nbeamforming designs for IDEM systems, where the minimum rate of data users\n(DUs) are maximized while guaranteeing the energy harvesting requirements for\nenergy users (EUs). Specifically, the asymptotically optimal fully-digital\nbeamformer is first obtained based on the spatial orthogonality. Then, the\nalternating optimization is adopted for the H-MIMO beamforming, where the\ndigital beamformer is obtained in closed form and the analog beamformers of\nthree different control modes are then obtained, respectively. Scaling schemes\nare also investigated to further improve the IDEM performance. Numerical\nresults verify the correctness of the resolution function and asymptotic\northogonality. Moreover, the proposed beamforming schemes with very low\ncomplexity outperform benchmark schemes.", "published": "2025-07-07 14:43:32", "link": "http://arxiv.org/abs/2507.05057v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Age-Aware CSI Acquisition of a Finite-State Markovian Channel", "abstract": "The Age of Information (AoI) has emerged as a critical metric for quantifying\ninformation freshness; however, its interplay with channel estimation in\npartially observable wireless systems remains underexplored. This work\nconsiders a transmitter-receiver pair communicating over an unreliable channel\nwith time-varying reliability levels. The transmitter observes the\ninstantaneous link reliability through a channel state information acquisition\nprocedure, during which the data transmission is interrupted. This leads to a\nfundamental trade-off between utilizing limited network resources for either\ndata transmission or channel state information acquisition to combat the\nchannel aging effect. Assuming the wireless channel is modeled as a\nfinite-state Markovian channel, we formulate an optimization problem as a\npartially observable Markov decision process (POMDP), obtain the optimal policy\nthrough the relative value iteration algorithm, and demonstrate the efficiency\nof our solution through simulations. To the best of our knowledge, this is the\nfirst work to aim for an optimal scheduling policy for data transmissions while\nconsidering the effect of channel state information aging.", "published": "2025-07-07 14:27:20", "link": "http://arxiv.org/abs/2507.05042v1", "categories": ["cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fast and Provable Hankel Tensor Completion for Multi-measurement Spectral Compressed Sensing", "abstract": "In this paper, we introduce a novel low-rank Hankel tensor completion\napproach to address the problem of multi-measurement spectral compressed\nsensing. By lifting the multiple signals to a Hankel tensor, we reformulate\nthis problem into a low-rank Hankel tensor completion task, exploiting the\nspectral sparsity via the low multilinear rankness of the tensor. Furthermore,\nwe design a scaled gradient descent algorithm for Hankel tensor completion\n(ScalHT), which integrates the low-rank Tucker decomposition with the Hankel\nstructure. Crucially, we derive novel fast computational formulations that\nleverage the interaction between these two structures, achieving up to an\n$O(\\min\\{s,n\\})$-fold improvement in storage and computational efficiency\ncompared to the existing algorithms, where $n$ is the length of signal, $s$ is\nthe number of measurement vectors. Beyond its practical efficiency, ScalHT is\nbacked by rigorous theoretical guarantees: we establish both recovery and\nlinear convergence guarantees, which, to the best of our knowledge, are the\nfirst of their kind for low-rank Hankel tensor completion. Numerical\nsimulations show that our method exhibits significantly lower computational and\nstorage costs while delivering superior recovery performance compared to prior\narts.", "published": "2025-07-07 10:12:52", "link": "http://arxiv.org/abs/2507.04847v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Kalman Filter Aided Federated Koopman Learning", "abstract": "Real-time control and estimation are pivotal for applications such as\nindustrial automation and future healthcare. The realization of this vision\nrelies heavily on efficient interactions with nonlinear systems. Therefore,\nKoopman learning, which leverages the power of deep learning to linearize\nnonlinear systems, has been one of the most successful examples of mitigating\nthe complexity inherent in nonlinearity. However, the existing literature\nassumes access to accurate system states and abundant high-quality data for\nKoopman analysis, which is usually impractical in real-world scenarios. To fill\nthis void, this paper considers the case where only observations of the system\nare available and where the observation data is insufficient to accomplish an\nindependent Koopman analysis. To this end, we propose Kalman Filter aided\nFederated Koopman Learning (KF-FedKL), which pioneers the combination of Kalman\nfiltering and federated learning with Koopman analysis. By doing so, we can\nachieve collaborative linearization with privacy guarantees. Specifically, we\nemploy a straightforward yet efficient loss function to drive the training of a\ndeep Koopman network for linearization. To obtain system information devoid of\nindividual information from observation data, we leverage the unscented Kalman\nfilter and the unscented Rauch-Tung-Striebel smoother. To achieve collaboration\nbetween clients, we adopt the federated learning framework and develop a\nmodified FedAvg algorithm to orchestrate the collaboration. A convergence\nanalysis of the proposed framework is also presented. Finally, through\nextensive numerical simulations, we showcase the performance of KF-FedKL under\nvarious situations.", "published": "2025-07-07 09:26:20", "link": "http://arxiv.org/abs/2507.04808v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Maximum Size of Codes Under the Damerau-Levenshtein Metric", "abstract": "The Damerau-Levenshtein distance between two sequences is the minimum number\nof operations (deletions, insertions, substitutions, and adjacent\ntranspositions) required to convert one sequence into another. Notwithstanding\na long history of this metric, research on error-correcting codes under this\ndistance has remained limited. Recently, motivated by applications in DNA-based\nstorage systems, Gabrys \\textit{et al} and Wang \\texit{et al} reinvigorated\ninterest in this metric. In their works, some codes correcting both deletions\nand adjacent transpositions were constructed. However, theoretical upper bounds\non code sizes under this metric have not yet been established. This paper seeks\nto establish upper bounds for code sizes in the Damerau-Levenshtein metric. Our\nresults show that the code correcting one deletion and asymmetric adjacent\ntranspositions proposed by Wang \\textit{et al} achieves optimal redundancy up\nto an additive constant.", "published": "2025-07-07 09:25:02", "link": "http://arxiv.org/abs/2507.04806v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Correcting Bursty/Localized Deletions: A New Error-Position-Estimation Code", "abstract": "Codes correcting bursts of deletions and localized deletions have garnered\nsignificant research interest in recent years. One of the primary objectives is\nto construct codes with minimal redundancy. Currently, the best known\nconstructions of $q$-ary codes correcting a burst of at most $t$ deletions\n($(\\le t)$-burst-deletion correcting codes) achieve redundancy $\\log\nn+8\\log\\log n+o(\\log\\log n)$ (for any $q$ and $t$) or $\\log n+t\\log\\log n+O(1)$\n(for even $q$). For codes correcting single $t$-localized-deletion\n($t$-localized-deletion correcting codes), state-of-the-art constructions\nattain redundancy $\\log n+O\\parenv{t(\\log\\log n)^2}$ (for any $q$ and $t$) or\n$\\log n+2t\\log\\log n+O(1)$ (for even $q$). Here, $n$ denotes the code-length,\nand $q$ and $t$ are fixed. These codes employ a position-estimation component\nto approximate error positions, augmented by additional constraints that enable\nerror-correction given the information about error positions.\n  In this work, we select codewords from the set of sequences whose\ndifferential sequences are strong-$(\\ell,\\epsilon)$-locally-balanced. By\nimposing a VT-type constraint and an $L_1$-weight constraint on the\ndifferential sequences of codewords, we construct novel position-estimation\ncodes. When $q\\ge 2$ and $t<q$, or $q$ is even and $t<2q$, this approach gives\na $q$-ary $(\\le t)$-burst-deletion correcting code and a $t$-localized-deletion\ncorrecting code with redundancy $\\log n+(t-1)\\log\\log n+O(1)$. In addition to\nimproving previous redundancy, the method is new and our position-estimation\ncodes are simpler than those in previous works. Finally, we give an efficient\nencoder to encode an arbitrary input sequence into a sequence whose\ndifferential sequence is strong-$(\\ell,\\epsilon)$-locally-balanced. To our\nknowledge, no prior algorithm for this specific task has been reported.", "published": "2025-07-07 09:17:09", "link": "http://arxiv.org/abs/2507.04797v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On subcodes of the generalized Reed-Solomon codes", "abstract": "In this paper, we study a class of subcodes of codimension $1$ in the\n$[n,k+1]_q$ generalized Reed-Solomon (GRS) codes, whose generator matrix is\nderived by removing the row of degree $k-r$ from the generator matrix of the\n$[n,k+1]_q$ GRS codes, where $1 \\le r \\le k-1$. We show equivalent\ncharacterizations for this class of subcodes of the GRS codes being self-dual\nor near-MDS, which extends the results for $r=1$ in the literature. Along with\nthese characterizations, families of self-dual near-MDS subcodes of the GRS\ncodes are also proposed. Finally, for $r = 1,2$, the dual codes of the subcodes\nof the GRS codes are found out. In some cases, the subcodes of the GRS codes\ncan be closed under taking dual codes. In other cases, the dual codes turn out\nto be the twisted GRS codes.", "published": "2025-07-07 06:12:52", "link": "http://arxiv.org/abs/2507.04689v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-Disease Deep Learning Framework for GWAS: Beyond Feature Selection Constraints", "abstract": "Traditional GWAS has advanced our understanding of complex diseases but often\nmisses nonlinear genetic interactions. Deep learning offers new opportunities\nto capture complex genomic patterns, yet existing methods mostly depend on\nfeature selection strategies that either constrain analysis to known pathways\nor risk data leakage when applied across the full dataset. Further, covariates\ncan inflate predictive performance without reflecting true genetic signals. We\nexplore different deep learning architecture choices for GWAS and demonstrate\nthat careful architectural choices can outperform existing methods under strict\nno-leakage conditions. Building on this, we extend our approach to a\nmulti-label framework that jointly models five diseases, leveraging shared\ngenetic architecture for improved efficiency and discovery. Applied to five\nmillion SNPs across 37,000 samples, our method achieves competitive predictive\nperformance (AUC 0.68-0.96), offering a scalable, leakage-free, and\nbiologically meaningful approach for multi-disease GWAS analysis.", "published": "2025-07-07 17:55:13", "link": "http://arxiv.org/abs/2507.05247v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cascade: Token-Sharded Private LLM Inference", "abstract": "As LLMs continue to increase in parameter size, the computational resources\nrequired to run them are available to fewer parties. Therefore, third-party\ninference services -- where LLMs are hosted by third parties with significant\ncomputational resources -- are becoming increasingly popular. However, third\nparty inference raises critical concerns about user data privacy. To mitigate\nthese risks, privacy researchers have developed provably secure schemes for\nthird-party inference, such as Secure Multi-Party Computation (SMPC). However,\nSMPC protocols have significant computational and communication overhead, and\ndo not scale to large models. In this work, we propose a new multi-party\ninference protocol, Cascade, that avoids these punitive costs by leveraging\nsharding in the sequence dimension to maintain privacy, trading off\ncryptographic privacy guarantees for increased performance and scalability. We\ndemonstrate that Cascade is resistant to a generalization of a recent attack\nthat is highly effective against other statistical privacy schemes, and that it\nis further resistant to learning-based attacks. As Cascade is orders of\nmagnitude faster than existing schemes, our findings offer practical solutions\nfor secure deployment of modern state-of-the-art LLMs.", "published": "2025-07-07 17:37:16", "link": "http://arxiv.org/abs/2507.05228v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "QuEst: Enhancing Estimates of Quantile-Based Distributional Measures Using Model Predictions", "abstract": "As machine learning models grow increasingly competent, their predictions can\nsupplement scarce or expensive data in various important domains. In support of\nthis paradigm, algorithms have emerged to combine a small amount of\nhigh-fidelity observed data with a much larger set of imputed model outputs to\nestimate some quantity of interest. Yet current hybrid-inference tools target\nonly means or single quantiles, limiting their applicability for many critical\ndomains and use cases. We present QuEst, a principled framework to merge\nobserved and imputed data to deliver point estimates and rigorous confidence\nintervals for a wide family of quantile-based distributional measures. QuEst\ncovers a range of measures, from tail risk (CVaR) to population segments such\nas quartiles, that are central to fields such as economics, sociology,\neducation, medicine, and more. We extend QuEst to multidimensional metrics, and\nintroduce an additional optimization technique to further reduce variance in\nthis and other hybrid estimators. We demonstrate the utility of our framework\nthrough experiments in economic modeling, opinion polling, and language model\nauto-evaluation.", "published": "2025-07-07 17:33:18", "link": "http://arxiv.org/abs/2507.05220v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A 3D Machine Learning based Volume Of Fluid scheme without explicit interface reconstruction", "abstract": "We present a machine-learning based Volume Of Fluid method to simulate\nmulti-material flows on three-dimensional domains. One of the novelties of the\nmethod is that the flux fraction is computed by evaluating a previously trained\nneural network and without explicitly reconstructing any local interface\napproximating the exact one. The network is trained on a purely synthetic\ndataset generated by randomly sampling numerous local interfaces and which can\nbe adapted to improve the scheme on less regular interfaces when needed.\nSeveral strategies to ensure the efficiency of the method and the satisfaction\nof physical constraints and properties are suggested and formalized. Numerical\nresults on the advection equation are provided to show the performance of the\nmethod. We observe numerical convergence as the size of the mesh tends to zero\n$h=1/N_h\\searrow 0$, with a better rate than two reference schemes.", "published": "2025-07-07 17:30:00", "link": "http://arxiv.org/abs/2507.05218v1", "categories": ["math.NA", "cs.LG", "cs.NA", "35Q35, 68T07, 76-10, 76M12"], "primary_category": "math.NA"}
{"title": "Bridging Prediction and Intervention Problems in Social Systems", "abstract": "Many automated decision systems (ADS) are designed to solve prediction\nproblems -- where the goal is to learn patterns from a sample of the population\nand apply them to individuals from the same population. In reality, these\nprediction systems operationalize holistic policy interventions in deployment.\nOnce deployed, ADS can shape impacted population outcomes through an effective\npolicy change in how decision-makers operate, while also being defined by past\nand present interactions between stakeholders and the limitations of existing\norganizational, as well as societal, infrastructure and context. In this work,\nwe consider the ways in which we must shift from a prediction-focused paradigm\nto an interventionist paradigm when considering the impact of ADS within social\nsystems. We argue this requires a new default problem setup for ADS beyond\nprediction, to instead consider predictions as decision support, final\ndecisions, and outcomes. We highlight how this perspective unifies modern\nstatistical frameworks and other tools to study the design, implementation, and\nevaluation of ADS systems, and point to the research directions necessary to\noperationalize this paradigm shift. Using these tools, we characterize the\nlimitations of focusing on isolated prediction tasks, and lay the foundation\nfor a more intervention-oriented approach to developing and deploying ADS.", "published": "2025-07-07 17:29:13", "link": "http://arxiv.org/abs/2507.05216v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Blind Targeting: Personalization under Third-Party Privacy Constraints", "abstract": "Major advertising platforms recently increased privacy protections by\nlimiting advertisers' access to individual-level data. Instead of providing\naccess to granular raw data, the platforms only allow a limited number of\naggregate queries to a dataset, which is further protected by adding\ndifferentially private noise. This paper studies whether and how advertisers\ncan design effective targeting policies within these restrictive privacy\npreserving data environments. To achieve this, I develop a probabilistic\nmachine learning method based on Bayesian optimization, which facilitates\ndynamic data exploration. Since Bayesian optimization was designed to sample\npoints from a function to find its maximum, it is not applicable to aggregate\nqueries and to targeting. Therefore, I introduce two innovations: (i) integral\nupdating of posteriors which allows to select the best regions of the data to\nquery rather than individual points and (ii) a targeting-aware acquisition\nfunction that dynamically selects the most informative regions for the\ntargeting task. I identify the conditions of the dataset and privacy\nenvironment that necessitate the use of such a \"smart\" querying strategy. I\napply the strategic querying method to the Criteo AI Labs dataset for uplift\nmodeling (Diemert et al., 2018) that contains visit and conversion data from\n14M users. I show that an intuitive benchmark strategy only achieves 33% of the\nnon-privacy-preserving targeting potential in some cases, while my strategic\nquerying method achieves 97-101% of that potential, and is statistically\nindistinguishable from Causal Forest (Athey et al., 2019): a state-of-the-art\nnon-privacy-preserving machine learning targeting method.", "published": "2025-07-07 16:30:40", "link": "http://arxiv.org/abs/2507.05175v1", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.AP"], "primary_category": "stat.ME"}
{"title": "A Dynamical Systems Perspective on the Analysis of Neural Networks", "abstract": "In this chapter, we utilize dynamical systems to analyze several aspects of\nmachine learning algorithms. As an expository contribution we demonstrate how\nto re-formulate a wide variety of challenges from deep neural networks,\n(stochastic) gradient descent, and related topics into dynamical statements. We\nalso tackle three concrete challenges. First, we consider the process of\ninformation propagation through a neural network, i.e., we study the\ninput-output map for different architectures. We explain the universal\nembedding property for augmented neural ODEs representing arbitrary functions\nof given regularity, the classification of multilayer perceptrons and neural\nODEs in terms of suitable function classes, and the memory-dependence in neural\ndelay equations. Second, we consider the training aspect of neural networks\ndynamically. We describe a dynamical systems perspective on gradient descent\nand study stability for overdetermined problems. We then extend this analysis\nto the overparameterized setting and describe the edge of stability phenomenon,\nalso in the context of possible explanations for implicit bias. For stochastic\ngradient descent, we present stability results for the overparameterized\nsetting via Lyapunov exponents of interpolation solutions. Third, we explain\nseveral results regarding mean-field limits of neural networks. We describe a\nresult that extends existing techniques to heterogeneous neural networks\ninvolving graph limits via digraph measures. This shows how large classes of\nneural networks naturally fall within the framework of Kuramoto-type models on\ngraphs and their large-graph limits. Finally, we point out that similar\nstrategies to use dynamics to study explainable and reliable AI can also be\napplied to settings such as generative models or fundamental issues in gradient\ntraining methods, such as backpropagation or vanishing/exploding gradients.", "published": "2025-07-07 16:18:49", "link": "http://arxiv.org/abs/2507.05164v1", "categories": ["math.DS", "cs.LG", "nlin.AO"], "primary_category": "math.DS"}
{"title": "Pseudo-likelihood produces associative memories able to generalize, even for asymmetric couplings", "abstract": "Energy-based probabilistic models learned by maximizing the likelihood of the\ndata are limited by the intractability of the partition function. A widely used\nworkaround is to maximize the pseudo-likelihood, which replaces the global\nnormalization with tractable local normalizations. Here we show that, in the\nzero-temperature limit, a network trained to maximize pseudo-likelihood\nnaturally implements an associative memory: if the training set is small,\npatterns become fixed-point attractors whose basins of attraction exceed those\nof any classical Hopfield rule. We explain quantitatively this effect on\nuncorrelated random patterns. Moreover, we show that, for different structured\ndatasets coming from computer science (random feature model, MNIST), physics\n(spin glasses) and biology (proteins), as the number of training examples\nincreases the learned network goes beyond memorization, developing meaningful\nattractors with non-trivial correlations with test examples, thus showing the\nability to generalize. Our results therefore reveal pseudo-likelihood works\nboth as an efficient inference tool and as a principled mechanism for memory\nand generalization.", "published": "2025-07-07 15:57:44", "link": "http://arxiv.org/abs/2507.05147v1", "categories": ["cond-mat.stat-mech", "cs.LG"], "primary_category": "cond-mat.stat-mech"}
{"title": "A generalized Wasserstein-2 distance approach for efficient reconstruction of random field models using stochastic neural networks", "abstract": "In this work, we propose a novel generalized Wasserstein-2 distance approach\nfor efficiently training stochastic neural networks to reconstruct random field\nmodels, where the target random variable comprises both continuous and\ncategorical components. We prove that a stochastic neural network can\napproximate random field models under a Wasserstein-2 distance metric under\nnonrestrictive conditions. Furthermore, this stochastic neural network can be\nefficiently trained by minimizing our proposed generalized local squared\nWasserstein-2 loss function. We showcase the effectiveness of our proposed\napproach in various uncertainty quantification tasks, including classification,\nreconstructing the distribution of mixed random variables, and learning complex\nnoisy dynamical systems from spatiotemporal data.", "published": "2025-07-07 15:53:13", "link": "http://arxiv.org/abs/2507.05143v1", "categories": ["cs.LG", "60A05, 68Q87, 65C99"], "primary_category": "cs.LG"}
{"title": "Hardware-efficient tractable probabilistic inference for TinyML Neurosymbolic AI applications", "abstract": "Neurosymbolic AI (NSAI) has recently emerged to mitigate limitations\nassociated with deep learning (DL) models, e.g. quantifying their uncertainty\nor reason with explicit rules. Hence, TinyML hardware will need to support\nthese symbolic models to bring NSAI to embedded scenarios. Yet, although\nsymbolic models are typically compact, their sparsity and computation\nresolution contrasts with low-resolution and dense neuro models, which is a\nchallenge on resource-constrained TinyML hardware severely limiting the size of\nsymbolic models that can be computed. In this work, we remove this bottleneck\nleveraging a tight hardware/software integration to present a complete\nframework to compute NSAI with TinyML hardware. We focus on symbolic models\nrealized with tractable probabilistic circuits (PCs), a popular subclass of\nprobabilistic models for hardware integration. This framework: (1) trains a\nspecific class of hardware-efficient \\emph{deterministic} PCs, chosen for the\nsymbolic task; (2) \\emph{compresses} this PC until it can be computed on TinyML\nhardware with minimal accuracy degradation, using our $n^{th}$-root compression\ntechnique, and (3) \\emph{deploys} the complete NSAI model on TinyML hardware.\nCompared to a 64b precision baseline necessary for the PC without compression,\nour workflow leads to significant hardware reduction on FPGA (up to 82.3\\% in\nFF, 52.6\\% in LUTs, and 18.0\\% in Flash usage) and an average inference speedup\nof 4.67x on ESP32 microcontroller.", "published": "2025-07-07 15:51:18", "link": "http://arxiv.org/abs/2507.05141v1", "categories": ["cs.LG", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Deep Learning to Automate Parameter Extraction and Model Fitting of Two-Dimensional Transistors", "abstract": "We present a deep learning approach to extract physical parameters (e.g.,\nmobility, Schottky contact barrier height, defect profiles) of two-dimensional\n(2D) transistors from electrical measurements, enabling automated parameter\nextraction and technology computer-aided design (TCAD) fitting. To facilitate\nthis task, we implement a simple data augmentation and pre-training approach by\ntraining a secondary neural network to approximate a physics-based device\nsimulator. This method enables high-quality fits after training the neural\nnetwork on electrical data generated from physics-based simulations of ~500\ndevices, a factor >40$\\times$ fewer than other recent efforts. Consequently,\nfitting can be achieved by training on physically rigorous TCAD models,\nincluding complex geometry, self-consistent transport, and electrostatic\neffects, and is not limited to computationally inexpensive compact models. We\napply our approach to reverse-engineer key parameters from experimental\nmonolayer WS$_2$ transistors, achieving a median coefficient of determination\n($R^2$) = 0.99 when fitting measured electrical data. We also demonstrate that\nthis approach generalizes and scales well by reverse-engineering electrical\ndata on high-electron-mobility transistors while fitting 35 parameters\nsimultaneously. To facilitate future research on deep learning approaches for\ninverse transistor design, we have published our code and sample data sets\nonline.", "published": "2025-07-07 15:46:25", "link": "http://arxiv.org/abs/2507.05134v1", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.app-ph"], "primary_category": "cs.LG"}
{"title": "CLIP-Guided Backdoor Defense through Entropy-Based Poisoned Dataset Separation", "abstract": "Deep Neural Networks (DNNs) are susceptible to backdoor attacks, where\nadversaries poison training data to implant backdoor into the victim model.\nCurrent backdoor defenses on poisoned data often suffer from high computational\ncosts or low effectiveness against advanced attacks like clean-label and\nclean-image backdoors. To address them, we introduce CLIP-Guided backdoor\nDefense (CGD), an efficient and effective method that mitigates various\nbackdoor attacks. CGD utilizes a publicly accessible CLIP model to identify\ninputs that are likely to be clean or poisoned. It then retrains the model with\nthese inputs, using CLIP's logits as a guidance to effectively neutralize the\nbackdoor. Experiments on 4 datasets and 11 attack types demonstrate that CGD\nreduces attack success rates (ASRs) to below 1% while maintaining clean\naccuracy (CA) with a maximum drop of only 0.3%, outperforming existing\ndefenses. Additionally, we show that clean-data-based defenses can be adapted\nto poisoned data using CGD. Also, CGD exhibits strong robustness, maintaining\nlow ASRs even when employing a weaker CLIP model or when CLIP itself is\ncompromised by a backdoor. These findings underscore CGD's exceptional\nefficiency, effectiveness, and applicability for real-world backdoor defense\nscenarios. Code: https://github.com/binyxu/CGD.", "published": "2025-07-07 15:29:26", "link": "http://arxiv.org/abs/2507.05113v1", "categories": ["cs.MM", "cs.CR", "cs.LG", "68T07", "I.2.6"], "primary_category": "cs.MM"}
{"title": "DICE: Discrete inverse continuity equation for learning population dynamics", "abstract": "We introduce the Discrete Inverse Continuity Equation (DICE) method, a\ngenerative modeling approach that learns the evolution of a stochastic process\nfrom given sample populations at a finite number of time points. Models learned\nwith DICE capture the typically smooth and well-behaved population dynamics,\nrather than the dynamics of individual sample trajectories that can exhibit\ncomplex or even chaotic behavior. The DICE loss function is developed\nspecifically to be invariant, even in discrete time, to spatially constant but\ntime-varying spurious constants that can emerge during training; this\ninvariance increases training stability and robustness. Generating a trajectory\nof sample populations with DICE is fast because samples evolve directly in the\ntime interval over which the stochastic process is formulated, in contrast to\napproaches that condition on time and then require multiple sampling steps per\ntime step. DICE is stable to train, in situations where other methods for\nlearning population dynamics fail, and DICE generates representative samples\nwith orders of magnitude lower costs than methods that have to condition on\ntime. Numerical experiments on a wide range of problems from random waves,\nVlasov-Poisson instabilities and high-dimensional chaos are included to justify\nthese assertions.", "published": "2025-07-07 15:25:54", "link": "http://arxiv.org/abs/2507.05107v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Exploring Semantic Clustering and Similarity Search for Heterogeneous Traffic Scenario Graph", "abstract": "Scenario-based testing is an indispensable instrument for the comprehensive\nvalidation and verification of automated vehicles (AVs). However, finding a\nmanageable and finite, yet representative subset of scenarios in a scalable,\npossibly unsupervised manner is notoriously challenging. Our work is meant to\nconstitute a cornerstone to facilitate sample-efficient testing, while still\ncapturing the diversity of relevant operational design domains (ODDs) and\naccounting for the \"long tail\" phenomenon in particular. To this end, we first\npropose an expressive and flexible heterogeneous, spatio-temporal graph model\nfor representing traffic scenarios. Leveraging recent advances of graph neural\nnetworks (GNNs), we then propose a self-supervised method to learn a universal\nembedding space for scenario graphs that enables clustering and similarity\nsearch. In particular, we implement contrastive learning alongside a\nbootstrapping-based approach and evaluate their suitability for partitioning\nthe scenario space. Experiments on the nuPlan dataset confirm the model's\nability to capture semantics and thus group related scenarios in a meaningful\nway despite the absence of discrete class labels. Different scenario types\nmaterialize as distinct clusters. Our results demonstrate how variable-length\ntraffic scenarios can be condensed into single vector representations that\nenable nearest-neighbor retrieval of representative candidates for distinct\nscenario categories. Notably, this is achieved without manual labeling or bias\ntowards an explicit objective such as criticality. Ultimately, our approach can\nserve as a basis for scalable selection of scenarios to further enhance the\nefficiency and robustness of testing AVs in simulation.", "published": "2025-07-07 15:10:03", "link": "http://arxiv.org/abs/2507.05086v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Distribution-dependent Generalization Bounds for Tuning Linear Regression Across Tasks", "abstract": "Modern regression problems often involve high-dimensional data and a careful\ntuning of the regularization hyperparameters is crucial to avoid overly complex\nmodels that may overfit the training data while guaranteeing desirable\nproperties like effective variable selection. We study the recently introduced\ndirection of tuning regularization hyperparameters in linear regression across\nmultiple related tasks. We obtain distribution-dependent bounds on the\ngeneralization error for the validation loss when tuning the L1 and L2\ncoefficients, including ridge, lasso and the elastic net. In contrast, prior\nwork develops bounds that apply uniformly to all distributions, but such bounds\nnecessarily degrade with feature dimension, d. While these bounds are shown to\nbe tight for worst-case distributions, our bounds improve with the \"niceness\"\nof the data distribution. Concretely, we show that under additional assumptions\nthat instances within each task are i.i.d. draws from broad well-studied\nclasses of distributions including sub-Gaussians, our generalization bounds do\nnot get worse with increasing d, and are much sharper than prior work for very\nlarge d. We also extend our results to a generalization of ridge regression,\nwhere we achieve tighter bounds that take into account an estimate of the mean\nof the ground truth distribution.", "published": "2025-07-07 15:08:45", "link": "http://arxiv.org/abs/2507.05084v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Vecchia-Inducing-Points Full-Scale Approximations for Gaussian Processes", "abstract": "Gaussian processes are flexible, probabilistic, non-parametric models widely\nused in machine learning and statistics. However, their scalability to large\ndata sets is limited by computational constraints. To overcome these\nchallenges, we propose Vecchia-inducing-points full-scale (VIF) approximations\ncombining the strengths of global inducing points and local Vecchia\napproximations. Vecchia approximations excel in settings with low-dimensional\ninputs and moderately smooth covariance functions, while inducing point methods\nare better suited to high-dimensional inputs and smoother covariance functions.\nOur VIF approach bridges these two regimes by using an efficient\ncorrelation-based neighbor-finding strategy for the Vecchia approximation of\nthe residual process, implemented via a modified cover tree algorithm. We\nfurther extend our framework to non-Gaussian likelihoods by introducing\niterative methods that substantially reduce computational costs for training\nand prediction by several orders of magnitudes compared to Cholesky-based\ncomputations when using a Laplace approximation. In particular, we propose and\ncompare novel preconditioners and provide theoretical convergence results.\nExtensive numerical experiments on simulated and real-world data sets show that\nVIF approximations are both computationally efficient as well as more accurate\nand numerically stable than state-of-the-art alternatives. All methods are\nimplemented in the open source C++ library GPBoost with high-level Python and R\ninterfaces.", "published": "2025-07-07 14:49:06", "link": "http://arxiv.org/abs/2507.05064v1", "categories": ["stat.ML", "cs.LG", "stat.ME", "60G15, 65F08, 65F10, 62M20, 62R07, 68T09"], "primary_category": "stat.ML"}
{"title": "A COMPASS to Model Comparison and Simulation-Based Inference in Galactic Chemical Evolution", "abstract": "We present \\texttt{COMPASS}, a novel simulation-based inference framework\nthat combines score-based diffusion models with transformer architectures to\njointly perform parameter estimation and Bayesian model comparison across\ncompeting Galactic Chemical Evolution (GCE) models. \\texttt{COMPASS} handles\nhigh-dimensional, incomplete, and variable-size stellar abundance datasets. %\nApplied to high-precision elemental abundance measurements, \\texttt{COMPASS}\nevaluates 40 combinations of nucleosynthetic yield tables. The model strongly\nfavours Asymptotic Giant Branch yields from NuGrid and core-collapse SN yields\nused in the IllustrisTNG simulation, achieving near-unity cumulative posterior\nprobability. Using the preferred model, we infer a steep high-mass IMF slope\nand an elevated Supernova\\,Ia normalization, consistent with prior solar\nneighbourhood studies but now derived from fully amortized Bayesian inference.\n% Our results demonstrate that modern SBI methods can robustly constrain\nuncertain physics in astrophysical simulators and enable principled model\nselection when analysing complex, simulation-based data.", "published": "2025-07-07 14:45:41", "link": "http://arxiv.org/abs/2507.05060v1", "categories": ["astro-ph.GA", "astro-ph.IM", "cs.LG", "physics.comp-ph", "physics.data-an"], "primary_category": "astro-ph.GA"}
{"title": "Beyond Scaling Curves: Internal Dynamics of Neural Networks Through the NTK Lens", "abstract": "Scaling laws offer valuable insights into the relationship between neural\nnetwork performance and computational cost, yet their underlying mechanisms\nremain poorly understood. In this work, we empirically analyze how neural\nnetworks behave under data and model scaling through the lens of the neural\ntangent kernel (NTK). This analysis establishes a link between performance\nscaling and the internal dynamics of neural networks. Our findings of standard\nvision tasks show that similar performance scaling exponents can occur even\nthough the internal model dynamics show opposite behavior. This demonstrates\nthat performance scaling alone is insufficient for understanding the underlying\nmechanisms of neural networks. We also address a previously unresolved issue in\nneural scaling: how convergence to the infinite-width limit affects scaling\nbehavior in finite-width models. To this end, we investigate how feature\nlearning is lost as the model width increases and quantify the transition\nbetween kernel-driven and feature-driven scaling regimes. We identify the\nmaximum model width that supports feature learning, which, in our setups, we\nfind to be more than ten times smaller than typical large language model\nwidths.", "published": "2025-07-07 14:17:44", "link": "http://arxiv.org/abs/2507.05035v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Generative Diffusion Model for Amorphous Materials", "abstract": "Generative models show great promise for the inverse design of molecules and\ninorganic crystals, but remain largely ineffective within more complex\nstructures such as amorphous materials. Here, we present a diffusion model that\nreliably generates amorphous structures up to 1000 times faster than\nconventional simulations across processing conditions, compositions, and data\nsources. Generated structures recovered the short- and medium-range order,\nsampling diversity, and macroscopic properties of silica glass, as validated by\nsimulations and an information-theoretical strategy. Conditional generation\nallowed sampling large structures at low cooling rates of 10$^{-2}$ K/ps to\nuncover a ductile-to-brittle transition and mesoporous silica structures.\nExtension to metallic glassy systems accurately reproduced local structures and\nproperties from both computational and experimental datasets, demonstrating how\nsynthetic data can be generated from characterization results. Our methods\nprovide a roadmap for the design and simulation of amorphous materials\npreviously inaccessible to computational methods.", "published": "2025-07-07 14:08:10", "link": "http://arxiv.org/abs/2507.05024v1", "categories": ["cond-mat.dis-nn", "cs.LG"], "primary_category": "cond-mat.dis-nn"}
{"title": "The Case for Instance-Optimized LLMs in OLAP Databases", "abstract": "Large Language Models (LLMs) can enhance analytics systems with powerful data\nsummarization, cleaning, and semantic transformation capabilities. However,\ndeploying LLMs at scale -- processing millions to billions of rows -- remains\nprohibitively expensive in computation and memory. We present IOLM-DB, a novel\nsystem that makes LLM-enhanced database queries practical through\nquery-specific model optimization. Instead of using general-purpose LLMs,\nIOLM-DB generates lightweight, specialized models tailored to each query's\nspecific needs using representative data samples. IOLM-DB reduces model\nfootprints by up to 76% and increases throughput by up to 3.31$\\times$ while\nmaintaining accuracy through aggressive compression techniques, including\nquantization, sparsification, and structural pruning. We further show how our\napproach enables higher parallelism on existing hardware and seamlessly\nsupports caching and batching strategies to reduce overheads. Our prototype\ndemonstrates that leveraging LLM queries inside analytics systems is feasible\nat scale, opening new possibilities for future OLAP applications.", "published": "2025-07-07 13:10:01", "link": "http://arxiv.org/abs/2507.04967v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "When do World Models Successfully Learn Dynamical Systems?", "abstract": "In this work, we explore the use of compact latent representations with\nlearned time dynamics ('World Models') to simulate physical systems. Drawing on\nconcepts from control theory, we propose a theoretical framework that explains\nwhy projecting time slices into a low-dimensional space and then concatenating\nto form a history ('Tokenization') is so effective at learning physics\ndatasets, and characterise when exactly the underlying dynamics admit a\nreconstruction mapping from the history of previous tokenized frames to the\nnext. To validate these claims, we develop a sequence of models with increasing\ncomplexity, starting with least-squares regression and progressing through\nsimple linear layers, shallow adversarial learners, and ultimately full-scale\ngenerative adversarial networks (GANs). We evaluate these models on a variety\nof datasets, including modified forms of the heat and wave equations, the\nchaotic regime 2D Kuramoto-Sivashinsky equation, and a challenging\ncomputational fluid dynamics (CFD) dataset of a 2D K\\'arm\\'an vortex street\naround a fixed cylinder, where our model is successfully able to recreate the\nflow.", "published": "2025-07-07 11:29:18", "link": "http://arxiv.org/abs/2507.04898v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fine-tuning on simulated data outperforms prompting for agent tone of voice", "abstract": "Deploying language models (LMs) in customer-facing speech applications\nrequires conversational fluency and adherence to specific stylistic guidelines.\nThis can be challenging to achieve reliably using complex system prompts due to\nissues like instruction following limitations and in-context bias. This study\ninvestigates the effectiveness of fine-tuning versus system prompting for\naligning LMs with a specific behavioral target: responding in a natural,\nconversational tone suitable for voice interactions. We fine-tuned a small,\nopen-weights model (`Llama3.2-1B-Instruct`) using Low-Rank Adaptation (LoRA) on\na synthetically generated dataset derived from Wikipedia. Additionally, we\nfine-tuned two closed-source models (`gpt-4o-mini`, `gpt-4.1-mini`). Our\nresults demonstrate that fine-tuning outperformed system prompting, achieving a\nhigh percentage of conversational responses, even when trained on only 100 data\nsamples. Semantic similarity analysis confirmed that fine-tuning did not\ndegrade content quality. Interestingly, fine-tuning with 8-bit integer\nquantization converged faster towards the target style than using bfloat16\nprecision, potentially due to implicit regularization effects. We conclude that\nfine-tuning small, open-weights LMs on simulated data is a highly effective and\ndata-efficient method for instilling specific stylistic behaviors, offering a\npreferable alternative to complex system prompting for practical applications\nrequiring nuanced response styles.", "published": "2025-07-07 11:23:20", "link": "http://arxiv.org/abs/2507.04889v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Slimming for Scalable and Efficient Speech Enhancement", "abstract": "Speech enhancement (SE) enables robust speech recognition, real-time\ncommunication, hearing aids, and other applications where speech quality is\ncrucial. However, deploying such systems on resource-constrained devices\ninvolves choosing a static trade-off between performance and computational\nefficiency. In this paper, we introduce dynamic slimming to DEMUCS, a popular\nSE architecture, making it scalable and input-adaptive. Slimming lets the model\noperate at different utilization factors (UF), each corresponding to a\ndifferent performance/efficiency trade-off, effectively mimicking multiple\nmodel sizes without the extra storage costs. In addition, a router subnet,\ntrained end-to-end with the backbone, determines the optimal UF for the current\ninput. Thus, the system saves resources by adaptively selecting smaller UFs\nwhen additional complexity is unnecessary. We show that our solution is\nPareto-optimal against individual UFs, confirming the benefits of dynamic\nrouting. When training the proposed dynamically-slimmable model to use 10% of\nits capacity on average, we obtain the same or better speech quality as the\nequivalent static 25% utilization while reducing MACs by 29%.", "published": "2025-07-07 11:07:56", "link": "http://arxiv.org/abs/2507.04879v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NTSFormer: A Self-Teaching Graph Transformer for Multimodal Cold-Start Node Classification", "abstract": "Cold-start node classification on multimodal graphs is challenging because\ncold-start nodes are isolated (i.e., no edges) and often have missing\nmodalities (e.g., absent text or image features). Existing methods address\nstructural isolation by degrading graph learning models to MLPs for cold-start\ninference, using a teacher model (with graph access) to guide the MLP. However,\nthis results in limited model capacity in the student, which is further\nchallenged when modalities are missing. In this paper, we propose\nNeighbor-to-Self Graph Transformer (NTSFormer), a unified Graph Transformer\nframework that jointly tackles the isolation and missing-modality issues via a\nself-teaching paradigm. Specifically, NTSFormer uses a cold-start attention\nmask to simultaneously make two predictions for each node: a \"student\"\nprediction based only on self-information (i.e., the node's own features), and\na \"teacher\" prediction incorporating both self and neighbor information. This\nenables the model to supervise itself without degrading to an MLP, thereby\nfully leveraging the Transformer's capacity to handle missing modalities. To\nhandle diverse graph information and missing modalities, NTSFormer performs a\none-time multimodal graph pre-computation that converts structural and feature\ndata into token sequences, which are then processed by a Mixture-of-Experts\n(MoE) Input Projection and Transformer layers for effective fusion.\nExperimental results on public datasets show that NTSFormer achieves superior\nperformance on multimodal cold-start node classification tasks.", "published": "2025-07-07 10:56:12", "link": "http://arxiv.org/abs/2507.04870v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Music Boomerang: Reusing Diffusion Models for Data Augmentation and Audio Manipulation", "abstract": "Generative models of music audio are typically used to generate output based\nsolely on a text prompt or melody. Boomerang sampling, recently proposed for\nthe image domain, allows generating output close to an existing example, using\nany pretrained diffusion model. In this work, we explore its application in the\naudio domain as a tool for data augmentation or content manipulation.\nSpecifically, implementing Boomerang sampling for Stable Audio Open, we augment\ntraining data for a state-of-the-art beat tracker, and attempt to replace\nmusical instruments in recordings. Our results show that the rhythmic structure\nof existing examples is mostly preserved, that it improves performance of the\nbeat tracker, but only in scenarios of limited training data, and that it can\naccomplish text-based instrument replacement on monophonic inputs. We publish\nour implementation to invite experiments on data augmentation in other tasks\nand explore further applications.", "published": "2025-07-07 10:46:07", "link": "http://arxiv.org/abs/2507.04864v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Spatial and Semantic Embedding Integration for Stereo Sound Event Localization and Detection in Regular Videos", "abstract": "This report presents our systems submitted to the audio-only and audio-visual\ntracks of the DCASE2025 Task 3 Challenge: Stereo Sound Event Localization and\nDetection (SELD) in Regular Video Content. SELD is a complex task that combines\ntemporal event classification with spatial localization, requiring reasoning\nacross spatial, temporal, and semantic dimensions. The last is arguably the\nmost challenging to model. Traditional SELD architectures rely on multichannel\ninput, which limits their ability to leverage large-scale pre-training due to\ndata constraints. To address this, we enhance standard SELD architectures with\nsemantic information by integrating pre-trained, contrastive language-aligned\nmodels: CLAP for audio and OWL-ViT for visual inputs. These embeddings are\nincorporated into a modified Conformer module tailored for multimodal fusion,\nwhich we refer to as the Cross-Modal Conformer. Additionally, we incorporate\nautocorrelation-based acoustic features to improve distance estimation. We\npre-train our models on curated synthetic audio and audio-visual datasets and\napply a left-right channel swapping augmentation to further increase the\ntraining data. Both our audio-only and audio-visual systems substantially\noutperform the challenge baselines on the development set, demonstrating the\neffectiveness of our strategy. Performance is further improved through model\nensembling and a visual post-processing step based on human keypoints. Future\nwork will investigate the contribution of each modality and explore\narchitectural variants to further enhance results.", "published": "2025-07-07 10:08:57", "link": "http://arxiv.org/abs/2507.04845v1", "categories": ["eess.AS", "cs.LG", "eess.IV", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Discrete Diffusion Trajectory Alignment via Stepwise Decomposition", "abstract": "Discrete diffusion models have demonstrated great promise in modeling various\nsequence data, ranging from human language to biological sequences. Inspired by\nthe success of RL in language models, there is growing interest in further\nimproving the models by alignment with a certain reward. In this work, we\npropose a novel preference optimization method for masked discrete diffusion\nmodels through a principled diffusion trajectory alignment. Instead of applying\nthe reward on the final output and backpropagating the gradient to the entire\ndiscrete denoising process, we decompose the problem into a set of stepwise\nalignment objectives. This framework enables efficient diffusion optimization,\nis compatible with arbitrary reward functions, and importantly, guarantees an\nequivalent optimal solution under additive factorization of the trajectory\nreward. Experiments across multiple domains including DNA sequence design,\nprotein inverse folding, and language modeling consistently demonstrate the\nsuperiority of our approach. Notably, it achieves an up to 12\\% improvement\nover the most competitive RL-based baseline in terms of predicted activity on\nDNA sequence design, and further improves the GSM8K score from 78.6 to 80.7 on\nLLaDA-8B-Instruct for language modeling.", "published": "2025-07-07 09:52:56", "link": "http://arxiv.org/abs/2507.04832v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A High-Level Compiler Integration Approach for Deep Learning Accelerators Supporting Abstraction and Optimization", "abstract": "The growing adoption of domain-specific architectures in edge computing\nplatforms for deep learning has highlighted the efficiency of hardware\naccelerators. However, integrating custom accelerators into modern machine\nlearning (ML) compilers remains a complex challenge due to the need for\nsignificant modifications in compilation layers and specialized scheduling\ntechniques. Existing frameworks offer partial solutions and require users to\nnavigate intricate compiler internals.\n  In this paper, we introduce a TVM-based compilation integration approach that\ntargets GEMM-based deep learning accelerators. Our approach abstracts the\ncomplexities of compiler integration, enabling seamless integration of\naccelerators without requiring in-depth knowledge of the underlying compiler.\nFurthermore, we extend and incorporate design space exploration tools,\nspecifically CoSA, to automate efficient tensor scheduling, accounting for\nfactors such as uneven mapping and double buffering. Our framework is\nbenchmarked on the Gemmini accelerator, demonstrating performance comparable to\nits specialized manually implemented toolchain.", "published": "2025-07-07 09:50:15", "link": "http://arxiv.org/abs/2507.04828v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interpretable Machine Learning for Urban Heat Mitigation: Attribution and Weighting of Multi-Scale Drivers", "abstract": "Urban heat islands (UHIs) are often accentuated during heat waves (HWs) and\npose a public health risk. Mitigating UHIs requires urban planners to first\nestimate how urban heat is influenced by different land use types (LUTs) and\ndrivers across scales - from synoptic-scale climatic background processes to\nsmall-scale urban- and scale-bridging features. This study proposes to classify\nthese drivers into driving (D), urban (U), and local (L) features,\nrespectively. To increase interpretability and enhance computation efficiency,\na LUT-distinguishing machine learning approach is proposed as a fast emulator\nfor Weather Research and Forecasting model coupled to a Single-Layer Urban\nCanopy Model (WRF-SLUCM) to predict ground- (TSK) and 2-meter air temperature\n(T2). Using random forests (RFs) with extreme gradient boosting (XGB) trained\non WRF-SLUCM output over Zurich, Switzerland, during heatwave (HW) periods in\n2017 and 2019, this study proposes LUT-based (LB) models that categorize\nfeatures by scales and practical controllability, allowing optional categorical\nweighting. This approach enables category-specific feature ranking and\nsensitivity estimation of T2 and TSK to most important small-scale drivers -\nmost notably surface emissivity, albedo, and leaf area index (LAI). Models\nemploying the LB framework are statistically significantly more accurate than\nmodels that do not, with higher performance when more HW data is included in\ntraining. With RF-XGB robustly performing optimal with unit weights, the method\nsubstantially increase interpretability. Despite the needs to reduce\nstatistical uncertainties and testing the method on other cities, the proposed\napproach offers urban planners a direct framework for feasibility-centered UHI\nmitigation assessment.", "published": "2025-07-07 09:21:45", "link": "http://arxiv.org/abs/2507.04802v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Machine Learning from Explanations", "abstract": "Acquiring and training on large-scale labeled data can be impractical due to\ncost constraints. Additionally, the use of small training datasets can result\nin considerable variability in model outcomes, overfitting, and learning of\nspurious correlations. A crucial shortcoming of data labels is their lack of\nany reasoning behind a specific label assignment, causing models to learn any\narbitrary classification rule as long as it aligns data with labels. To\novercome these issues, we introduce an innovative approach for training\nreliable classification models on smaller datasets, by using simple explanation\nsignals such as important input features from labeled data. Our method centers\naround a two-stage training cycle that alternates between enhancing model\nprediction accuracy and refining its attention to match the explanations. This\ninstructs models to grasp the rationale behind label assignments during their\nlearning phase. We demonstrate that our training cycle expedites the\nconvergence towards more accurate and reliable models, particularly for small,\nclass-imbalanced training data, or data with spurious features.", "published": "2025-07-07 09:09:52", "link": "http://arxiv.org/abs/2507.04788v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FedPall: Prototype-based Adversarial and Collaborative Learning for Federated Learning with Feature Drift", "abstract": "Federated learning (FL) enables collaborative training of a global model in\nthe centralized server with data from multiple parties while preserving\nprivacy. However, data heterogeneity can significantly degrade the performance\nof the global model when each party uses datasets from different sources to\ntrain a local model, thereby affecting personalized local models. Among various\ncases of data heterogeneity, feature drift, feature space difference among\nparties, is prevalent in real-life data but remains largely unexplored. Feature\ndrift can distract feature extraction learning in clients and thus lead to poor\nfeature extraction and classification performance. To tackle the problem of\nfeature drift in FL, we propose FedPall, an FL framework that utilizes\nprototype-based adversarial learning to unify feature spaces and collaborative\nlearning to reinforce class information within the features. Moreover, FedPall\nleverages mixed features generated from global prototypes and local features to\nenhance the global classifier with classification-relevant information from a\nglobal perspective. Evaluation results on three representative feature-drifted\ndatasets demonstrate FedPall's consistently superior performance in\nclassification with feature-drifted data in the FL scenario.", "published": "2025-07-07 08:58:39", "link": "http://arxiv.org/abs/2507.04781v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sure Convergence and Constructive Universal Approximation for Multi-Layer Neural Networks", "abstract": "We propose a new neural network model, 01Neuro, built on indicator activation\nneurons. Its boosted variant possesses two key statistical properties: (1) Sure\nConvergence, where model optimization can be achieved with high probability\ngiven sufficient computational resources; and (2) Constructive Universal\nApproximation: In the infinite sample setting, the model can approximate any\nfinite sum of measurable functions, each depending on only k out of p input\nfeatures, provided the architecture is properly tuned. Unlike most universal\napproximation results that are agnostic to training procedures, our guarantees\nare directly tied to the model's explicit construction and optimization\nalgorithm. To improve prediction stability, we integrate stochastic training\nand bagging into the boosted 01Neuro framework. Empirical evaluations on\nsimulated and real-world tabular datasets with small to medium sample sizes\nhighlight its strengths: effective approximation of interaction components\n(multiplicative terms), stable prediction performance (comparable to Random\nForests), robustness to many noisy features, and insensitivity to feature\nscaling. A major limitation of the current implementation of boosted 01Neuro is\nits higher computational cost, which is approximately 5 to 30 times that of\nRandom Forests and XGBoost.", "published": "2025-07-07 08:55:28", "link": "http://arxiv.org/abs/2507.04779v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Improving BERT for Symbolic Music Understanding Using Token Denoising and Pianoroll Prediction", "abstract": "We propose a pre-trained BERT-like model for symbolic music understanding\nthat achieves competitive performance across a wide range of downstream tasks.\nTo achieve this target, we design two novel pre-training objectives, namely\ntoken correction and pianoroll prediction. First, we sample a portion of note\ntokens and corrupt them with a limited amount of noise, and then train the\nmodel to denoise the corrupted tokens; second, we also train the model to\npredict bar-level and local pianoroll-derived representations from the\ncorrupted note tokens. We argue that these objectives guide the model to better\nlearn specific musical knowledge such as pitch intervals. For evaluation, we\npropose a benchmark that incorporates 12 downstream tasks ranging from chord\nestimation to symbolic genre classification. Results confirm the effectiveness\nof the proposed pre-training objectives on downstream tasks.", "published": "2025-07-07 08:52:06", "link": "http://arxiv.org/abs/2507.04776v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Unlearning with Privacy Guarantees", "abstract": "Privacy protection laws, such as the GDPR, grant individuals the right to\nrequest the forgetting of their personal data not only from databases but also\nfrom machine learning (ML) models trained on them. Machine unlearning has\nemerged as a practical means to facilitate model forgetting of data instances\nseen during training. Although some existing machine unlearning methods\nguarantee exact forgetting, they are typically costly in computational terms.\nOn the other hand, more affordable methods do not offer forgetting guarantees\nand are applicable only to specific ML models. In this paper, we present\n\\emph{efficient unlearning with privacy guarantees} (EUPG), a novel machine\nunlearning framework that offers formal privacy guarantees to individuals whose\ndata are being unlearned. EUPG involves pre-training ML models on data\nprotected using privacy models, and it enables {\\em efficient unlearning with\nthe privacy guarantees offered by the privacy models in use}. Through empirical\nevaluation on four heterogeneous data sets protected with $k$-anonymity and\n$\\epsilon$-differential privacy as privacy models, our approach demonstrates\nutility and forgetting effectiveness comparable to those of exact unlearning\nmethods, while significantly reducing computational and storage costs. Our code\nis available at https://github.com/najeebjebreel/EUPG.", "published": "2025-07-07 08:46:02", "link": "http://arxiv.org/abs/2507.04771v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Intervening to learn and compose disentangled representations", "abstract": "In designing generative models, it is commonly believed that in order to\nlearn useful latent structure, we face a fundamental tension between\nexpressivity and structure. In this paper we challenge this view by proposing a\nnew approach to training arbitrarily expressive generative models that\nsimultaneously learn disentangled latent structure. This is accomplished by\nadding a simple decoder-only module to the head of an existing decoder block\nthat can be arbitrarily complex. The module learns to process concept\ninformation by implicitly inverting linear representations from an encoder.\nInspired by the notion of intervention in causal graphical models, our module\nselectively modifies its architecture during training, allowing it to learn a\ncompact joint model over different contexts. We show how adding this module\nleads to disentangled representations that can be composed for\nout-of-distribution generation. To further validate our proposed approach, we\nprove a new identifiability result that extends existing work on identifying\nstructured representations in nonlinear models.", "published": "2025-07-07 08:30:27", "link": "http://arxiv.org/abs/2507.04754v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "CueLearner: Bootstrapping and local policy adaptation from relative feedback", "abstract": "Human guidance has emerged as a powerful tool for enhancing reinforcement\nlearning (RL). However, conventional forms of guidance such as demonstrations\nor binary scalar feedback can be challenging to collect or have low information\ncontent, motivating the exploration of other forms of human input. Among these,\nrelative feedback (i.e., feedback on how to improve an action, such as \"more to\nthe left\") offers a good balance between usability and information richness.\nPrevious research has shown that relative feedback can be used to enhance\npolicy search methods. However, these efforts have been limited to specific\npolicy classes and use feedback inefficiently. In this work, we introduce a\nnovel method to learn from relative feedback and combine it with off-policy\nreinforcement learning. Through evaluations on two sparse-reward tasks, we\ndemonstrate our method can be used to improve the sample efficiency of\nreinforcement learning by guiding its exploration process. Additionally, we\nshow it can adapt a policy to changes in the environment or the user's\npreferences. Finally, we demonstrate real-world applicability by employing our\napproach to learn a navigation policy in a sparse reward setting.", "published": "2025-07-07 07:54:28", "link": "http://arxiv.org/abs/2507.04730v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Optimal Model Selection for Conformalized Robust Optimization", "abstract": "In decision-making under uncertainty, Contextual Robust Optimization (CRO)\nprovides reliability by minimizing the worst-case decision loss over a\nprediction set, hedging against label variability. While recent advances use\nconformal prediction to construct prediction sets for machine learning models,\nthe downstream decisions critically depend on model selection. This paper\nintroduces novel model selection frameworks for CRO that unify robustness\ncontrol with decision risk minimization. We first propose Conformalized Robust\nOptimization with Model Selection (CROMS), which automatically selects models\nto approximately minimize the average decision risk in CRO solutions. We\ndevelop two algorithms: E-CROMS, which is computationally efficient, and\nF-CROMS, which enjoys a marginal robustness guarantee in finite samples.\nFurther, we introduce Conformalized Robust Optimization with Individualized\nModel Selection (CROiMS), which performs individualized model selection by\nminimizing the conditional decision risk given the covariate of test data. This\nframework advances conformal prediction methodology by enabling covariate-aware\nmodel selection. Theoretically, CROiMS achieves asymptotic conditional\nrobustness and decision efficiency under mild assumptions. Numerical results\ndemonstrate significant improvements in decision efficiency and robustness\nacross diverse synthetic and real-world applications, outperforming baseline\napproaches.", "published": "2025-07-07 07:14:42", "link": "http://arxiv.org/abs/2507.04716v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Mutual Information Optimal Control of Discrete-Time Linear Systems", "abstract": "In this paper, we formulate a mutual information optimal control problem\n(MIOCP) for discrete-time linear systems. This problem can be regarded as an\nextension of a maximum entropy optimal control problem (MEOCP). Differently\nfrom the MEOCP where the prior is fixed to the uniform distribution, the MIOCP\noptimizes the policy and prior simultaneously. As analytical results, under the\npolicy and prior classes consisting of Gaussian distributions, we derive the\noptimal policy and prior of the MIOCP with the prior and policy fixed,\nrespectively. Using the results, we propose an alternating minimization\nalgorithm for the MIOCP. Through numerical experiments, we discuss how our\nproposed algorithm works.", "published": "2025-07-07 07:04:27", "link": "http://arxiv.org/abs/2507.04712v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "math.OC"}
{"title": "Spooky Action at a Distance: Normalization Layers Enable Side-Channel Spatial Communication", "abstract": "This work shows that normalization layers can facilitate a surprising degree\nof communication across the spatial dimensions of an input tensor. We study a\ntoy localization task with a convolutional architecture and show that\nnormalization layers enable an iterative message passing procedure, allowing\ninformation aggregation from well outside the local receptive field. Our\nresults suggest that normalization layers should be employed with caution in\napplications such as diffusion-based trajectory generation, where maintaining a\nspatially limited receptive field is crucial.", "published": "2025-07-07 07:00:02", "link": "http://arxiv.org/abs/2507.04709v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Performance Evaluation of General Purpose Large Language Models for Basic Linear Algebra Subprograms Code Generation", "abstract": "Generative AI technology based on Large Language Models (LLM) has been\ndeveloped and applied to assist or automatically generate program codes. In\nthis paper, we evaluate the capability of existing general LLMs for Basic\nLinear Algebra Subprograms (BLAS) code generation for CPUs. We use two LLMs\nprovided by OpenAI: GPT-4.1, a Generative Pre-trained Transformer (GPT) model,\nand o4-mini, one of the o-series of Reasoning models. Both have been released\nin April 2025. For the routines from level-1 to 3 BLAS, we tried to generate\n(1) C code without optimization from routine name only, (2) C code with basic\nperformance optimizations (thread parallelization, SIMD vectorization, and\ncache blocking) from routine name only, and (3) C code with basic performance\noptimizations based on Fortran reference code. As a result, we found that\ncorrect code can be generated in many cases even when only routine name are\ngiven. We also confirmed that thread parallelization with OpenMP, SIMD\nvectorization, and cache blocking can be implemented to some extent, and that\nthe code is faster than the reference code.", "published": "2025-07-07 06:33:59", "link": "http://arxiv.org/abs/2507.04697v1", "categories": ["cs.LG", "cs.DC", "cs.MS"], "primary_category": "cs.LG"}
{"title": "Interpretable Reward Modeling with Active Concept Bottlenecks", "abstract": "We introduce Concept Bottleneck Reward Models (CB-RM), a reward modeling\nframework that enables interpretable preference learning through selective\nconcept annotation. Unlike standard RLHF methods that rely on opaque reward\nfunctions, CB-RM decomposes reward prediction into human-interpretable\nconcepts. To make this framework efficient in low-supervision settings, we\nformalize an active learning strategy that dynamically acquires the most\ninformative concept labels. We propose an acquisition function based on\nExpected Information Gain and show that it significantly accelerates concept\nlearning without compromising preference accuracy. Evaluated on the\nUltraFeedback dataset, our method outperforms baselines in interpretability and\nsample efficiency, marking a step towards more transparent, auditable, and\nhuman-aligned reward models.", "published": "2025-07-07 06:26:04", "link": "http://arxiv.org/abs/2507.04695v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Recovering Plasticity of Neural Networks via Soft Weight Rescaling", "abstract": "Recent studies have shown that as training progresses, neural networks\ngradually lose their capacity to learn new information, a phenomenon known as\nplasticity loss. An unbounded weight growth is one of the main causes of\nplasticity loss. Furthermore, it harms generalization capability and disrupts\noptimization dynamics. Re-initializing the network can be a solution, but it\nresults in the loss of learned information, leading to performance drops. In\nthis paper, we propose Soft Weight Rescaling (SWR), a novel approach that\nprevents unbounded weight growth without losing information. SWR recovers the\nplasticity of the network by simply scaling down the weight at each step of the\nlearning process. We theoretically prove that SWR bounds weight magnitude and\nbalances weight magnitude between layers. Our experiment shows that SWR\nimproves performance on warm-start learning, continual learning, and\nsingle-task learning setups on standard image classification benchmarks.", "published": "2025-07-07 06:02:55", "link": "http://arxiv.org/abs/2507.04683v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Operator-based machine learning framework for generalizable prediction of unsteady treatment dynamics in stormwater infrastructure", "abstract": "Stormwater infrastructures are decentralized urban water-management systems\nthat face highly unsteady hydraulic and pollutant loadings from episodic\nrainfall-runoff events. Accurately evaluating their in-situ treatment\nperformance is essential for cost-effective design and planning. Traditional\nlumped dynamic models (e.g., continuously stirred tank reactor, CSTR) are\ncomputationally efficient but oversimplify transport and reaction processes,\nlimiting predictive accuracy and insight. Computational fluid dynamics (CFD)\nresolves detailed turbulent transport and pollutant fate physics but incurs\nprohibitive computational cost for unsteady and long-term simulations. To\naddress these limitations, this study develops a composite operator-based\nneural network (CPNN) framework that leverages state-of-the-art operator\nlearning to predict the spatial and temporal dynamics of hydraulics and\nparticulate matter (PM) in stormwater treatment. The framework is demonstrated\non a hydrodynamic separator (HS), a common urban treatment device. Results\nindicate that the CPNN achieves R2 > 0.8 for hydraulic predictions in 95.2% of\ntest cases; for PM concentration predictions, R2 > 0.8 in 72.6% of cases and\n0.4 < R2 < 0.8 in 22.6%. The analysis identifies challenges in capturing\ndynamics under extreme low-flow conditions, owing to their lower contribution\nto the training loss. Exploiting the automatic-differentiation capability of\nthe CPNN, sensitivity analyses quantify the influence of storm event loading on\nPM transport. Finally, the potential of the CPNN framework for continuous,\nlong-term evaluation of stormwater infrastructure performance is discussed,\nmarking a step toward robust, climate-aware planning and implementation.", "published": "2025-07-07 06:02:42", "link": "http://arxiv.org/abs/2507.04682v1", "categories": ["cs.CE", "cs.LG"], "primary_category": "cs.CE"}
{"title": "Hybrid Adversarial Spectral Loss Conditional Generative Adversarial Networks for Signal Data Augmentation in Ultra-precision Machining Surface Roughness Prediction", "abstract": "Accurate surface roughness prediction in ultra-precision machining (UPM) is\ncritical for real-time quality control, but small datasets hinder model\nperformance. We propose HAS-CGAN, a Hybrid Adversarial Spectral Loss CGAN, for\neffective UPM data augmentation. Among five CGAN variants tested, HAS-CGAN\nexcels in 1D force signal generation, particularly for high-frequency signals,\nachieving >0.85 wavelet coherence through Fourier-domain optimization. By\ncombining generated signals with machining parameters, prediction accuracy\nsignificantly improves. Experiments with traditional ML (SVR, RF, LSTM) and\ndeep learning models (BPNN, 1DCNN, CNN-Transformer) demonstrate that augmenting\ntraining data with 520+ synthetic samples reduces prediction error from 31.4%\n(original 52 samples) to ~9%, effectively addressing data scarcity in UPM\nroughness prediction.\"", "published": "2025-07-07 05:10:46", "link": "http://arxiv.org/abs/2507.04665v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Cycle-Consistency Constrained Framework for Dynamic Solution Space Reduction in Noninjective Regression", "abstract": "To address the challenges posed by the heavy reliance of multi-output models\non preset probability distributions and embedded prior knowledge in\nnon-injective regression tasks, this paper proposes a cycle consistency-based\ndata-driven training framework. The method jointly optimizes a forward model\n{\\Phi}: X to Y and a backward model {\\Psi}: Y to X, where the cycle consistency\nloss is defined as L _cycleb equal L(Y reduce {\\Phi}({\\Psi}(Y))) (and vice\nversa). By minimizing this loss, the framework establishes a closed-loop\nmechanism integrating generation and validation phases, eliminating the need\nfor manual rule design or prior distribution assumptions. Experiments on\nnormalized synthetic and simulated datasets demonstrate that the proposed\nmethod achieves a cycle reconstruction error below 0.003, achieving an\nimprovement of approximately 30% in evaluation metrics compared to baseline\nmodels without cycle consistency. Furthermore, the framework supports\nunsupervised learning and significantly reduces reliance on manual\nintervention, demonstrating potential advantages in non-injective regression\ntasks.", "published": "2025-07-07 04:28:01", "link": "http://arxiv.org/abs/2507.04659v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "VaxPulse: Monitoring of Online Public Concerns to Enhance Post-licensure Vaccine Surveillance", "abstract": "The recent vaccine-related infodemic has amplified public concerns,\nhighlighting the need for proactive misinformation management. We describe how\nwe enhanced the reporting surveillance system of Victoria's vaccine safety\nservice, SAEFVIC, through the incorporation of new information sources for\npublic sentiment analysis, topics of discussion, and hesitancies about\nvaccinations online. Using VaxPulse, a multi-step framework, we integrate\nadverse events following immunisation (AEFI) with sentiment analysis,\ndemonstrating the importance of contextualising public concerns. Additionally,\nwe emphasise the need to address non-English languages to stratify concerns\nacross ethno-lingual communities, providing valuable insights for vaccine\nuptake strategies and combating mis/disinformation. The framework is applied to\nreal-world examples and a case study on women's vaccine hesitancy, showcasing\nits benefits and adaptability by identifying public opinion from online media.", "published": "2025-07-07 04:18:08", "link": "http://arxiv.org/abs/2507.04656v1", "categories": ["cs.SI", "cs.LG"], "primary_category": "cs.SI"}
{"title": "SOSAE: Self-Organizing Sparse AutoEncoder", "abstract": "The process of tuning the size of the hidden layers for autoencoders has the\nbenefit of providing optimally compressed representations for the input data.\nHowever, such hyper-parameter tuning process would take a lot of computation\nand time effort with grid search as the default option. In this paper, we\nintroduce the Self-Organization Regularization for Autoencoders that\ndynamically adapts the dimensionality of the feature space to the optimal size.\nInspired by physics concepts, Self-Organizing Sparse AutoEncoder (SOSAE)\ninduces sparsity in feature space in a structured way that permits the\ntruncation of the non-active part of the feature vector without any loss of\ninformation. This is done by penalizing the autoencoder based on the magnitude\nand the positional index of the feature vector dimensions, which during\ntraining constricts the feature space in both terms. Extensive experiments on\nvarious datasets show that our SOSAE can tune the feature space dimensionality\nup to 130 times lesser Floating-point Operations (FLOPs) than other baselines\nwhile maintaining the same quality of tuning and performance.", "published": "2025-07-07 03:55:02", "link": "http://arxiv.org/abs/2507.04644v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Photon Splatting: A Physics-Guided Neural Surrogate for Real-Time Wireless Channel Prediction", "abstract": "We present Photon Splatting, a physics-guided neural surrogate model for\nreal-time wireless channel prediction in complex environments. The proposed\nframework introduces surface-attached virtual sources, referred to as photons,\nwhich carry directional wave signatures informed by the scene geometry and\ntransmitter configuration. At runtime, channel impulse responses (CIRs) are\npredicted by splatting these photons onto the angular domain of the receiver\nusing a geodesic rasterizer. The model is trained to learn a physically\ngrounded representation that maps transmitter-receiver configurations to full\nchannel responses. Once trained, it generalizes to new transmitter positions,\nantenna beam patterns, and mobile receivers without requiring model retraining.\nWe demonstrate the effectiveness of the framework through a series of\nexperiments, from canonical 3D scenes to a complex indoor cafe with 1,000\nreceivers. Results show 30 millisecond-level inference latency and accurate CIR\npredictions across a wide range of configurations. The approach supports\nreal-time adaptability and interpretability, making it a promising candidate\nfor wireless digital twin platforms and future 6G network planning.", "published": "2025-07-07 01:18:43", "link": "http://arxiv.org/abs/2507.04595v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Lightweight Deep Learning Model for Automatic Modulation Classification using Dual Path Deep Residual Shrinkage Network", "abstract": "Efficient spectrum utilization is critical to meeting the growing data\ndemands of modern wireless communication networks. Automatic Modulation\nClassification (AMC) plays a key role in enhancing spectrum efficiency by\naccurately identifying modulation schemes in received signals-an essential\ncapability for dynamic spectrum allocation and interference mitigation,\nparticularly in cognitive radio (CR) systems. With the increasing deployment of\nsmart edge devices, such as IoT nodes with limited computational and memory\nresources, there is a pressing need for lightweight AMC models that balance low\ncomplexity with high classification accuracy. This paper proposes a\nlow-complexity, lightweight deep learning (DL) AMC model optimized for\nresource-constrained edge devices. We introduce a dual-path deep residual\nshrinkage network (DP-DRSN) with Garrote thresholding for effective signal\ndenoising and design a compact hybrid CNN-LSTM architecture comprising only\n27,000 training parameters. The proposed model achieves average classification\naccuracies of 61.20%, 63.78%, and 62.13% on the RML2016.10a, RML2016.10b, and\nRML2018.01a datasets, respectively demonstrating a strong balance between model\nefficiency and classification performance. These results underscore the model's\npotential for enabling accurate and efficient AMC on-edge devices with limited\nresources.", "published": "2025-07-07 00:37:54", "link": "http://arxiv.org/abs/2507.04586v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sequential multiple importance sampling for high-dimensional Bayesian inference", "abstract": "This paper introduces a sequential multiple importance sampling (SeMIS)\nalgorithm for high-dimensional Bayesian inference. The method estimates\nBayesian evidence using all generated samples from each proposal distribution\nwhile obtaining posterior samples through an importance-resampling scheme. A\nkey innovation of SeMIS is the use of a softly truncated prior distribution as\nthe intermediate proposal, providing a new way bridging prior and posterior\ndistributions. By enabling samples from high-likelihood regions to traverse\nlow-probability zones, SeMIS enhances mode mixing in challenging inference\nproblems. Comparative evaluations against subset simulation (SuS) and adaptive\nBayesian updating with structural reliability methods (aBUS) demonstrate that\nSeMIS achieves superior performance in evidence estimation (lower bias and\nvariance) and posterior sampling (higher effective sample sizes and closer\napproximation to the true posterior), particularly for multimodal\ndistributions. The efficacy of SeMIS is further validated in a high-dimensional\nfinite element model updating application, where it successfully localizes\nstructural damages by quantifying stiffness loss. The proposed algorithm not\nonly advances Bayesian computation for complex posterior distributions but also\nprovides a robust tool for uncertainty quantification in civil engineering\nsystems, offering new possibilities for probabilistic structural health\nmonitoring.", "published": "2025-07-07 15:30:36", "link": "http://arxiv.org/abs/2507.05114v1", "categories": ["stat.ME", "cs.NA", "math.NA", "math.ST", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Model order reduction techniques for the stochastic finite volume method", "abstract": "The stochastic finite volume method (SFV method) is a high-order accurate\nmethod for uncertainty quantification (UQ) in hyperbolic conservation laws.\nHowever, the computational cost of SFV method increases for high-dimensional\nstochastic parameter spaces due to the curse of dimensionality. To address this\nchallenge, we incorporate interpolation-based reduced order modeling (ROM)\ntechniques that reduce the cost of computing stochastic integrals in SFV\nmethod. Further efficiency gains are achieved through a Q-DEIM hyper-reduction\nmethod. Numerical experiments suggest that this approach can lower both\ncomputational cost and memory requirements for high-dimensional stochastic\nparameter spaces.", "published": "2025-07-07 15:13:33", "link": "http://arxiv.org/abs/2507.05091v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Cubic spline functions revisited", "abstract": "In this paper a fourth order asymptotically optimal error bound for a new\ncubic interpolating spline function, denoted by Q-spline, is derived for the\ncase that only function values at given points are used but not any derivative\ninformation. The bound seems to be stronger than earlier error bounds for cubic\nspline interpolation in such setting such as the not-a-knot spline. A brief\nanalysis of the conditioning of the end conditions of cubic spline\ninterpolation leads to a modification of the not-a-knot spline, and some\nnumerical examples suggest that the interpolation error of this revised\nnot-a-knot spline generally is comparable to the near optimal Q-spline and\nlower than for the not-a-knot spline when the mesh size is small.", "published": "2025-07-07 15:07:27", "link": "http://arxiv.org/abs/2507.05083v1", "categories": ["math.NA", "cs.NA", "65D05"], "primary_category": "math.NA"}
{"title": "Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions", "abstract": "Flexible bandwidth needlets offer a versatile multiscale framework for\nanalyzing functions on the sphere. A key element in their construction is the\ndilation sequence, which controls how the multipole consecutive scales are\nspaced and overlapped. At any resolution level, this sequence determines the\ncenter positions of the needlet weight functions and influences their\nlocalization in the spatial domain and spectral concentration properties by\nmeans of the relative bandwidth ratio. In this paper, we explore the different\nasymptotic regimes that arise when the dilation sequence exhibits shrinking,\nstable (standard), or spreading behavior. Moreover, we assume the dilation\nsequence grows regularly enough to ensure well-defined asymptotic properties.\nFor each regime, we characterize the impact on the geometry of the center\nscales and the shape of the multipole windows, with particular attention to\ntheir overlap structure and spectral coverage. These insights help to clarify\nthe trade-offs between localization, redundancy, and scalability in the design\nof needlet-type systems, particularly in relation to the study of the\nasymptotic uncorrelation of needlet coefficients when applied to random fields.", "published": "2025-07-07 15:03:04", "link": "http://arxiv.org/abs/2507.05075v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH", "42C40, 60G60"], "primary_category": "math.ST"}
{"title": "Fourier Spectral Method for Nonlocal Equations on Bounded Domains", "abstract": "This work introduces efficient and accurate spectral solvers for nonlocal\nequations on bounded domains. These spectral solvers exploit the fact that\nintegration in the nonlocal formulation transforms into multiplication in\nFourier space and that nonlocality is decoupled from the grid size. As a\nresult, the computational cost is reduced to $O(N\\log N)$ for an $N$-point\ndiscretization grid. Our approach extends the spectral solvers developed by\nAlali and Albin (2020) for periodic domains by incorporating the\ntwo-dimensional Fourier continuation (2D-FC) algorithm introduced by Bruno and\nPaul (2022). We evaluate the performance of the proposed methods on\ntwo-dimensional nonlocal Poisson and nonlocal diffusion equations defined on\nbounded domains. While the regularity of solutions to these equations in\nbounded settings remains an open problem, we conduct numerical experiments to\nexplore this issue, particularly focusing on studying discontinuities.", "published": "2025-07-07 14:17:43", "link": "http://arxiv.org/abs/2507.05034v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Approximation of the L\u00e9vy-driven stochastic heat equation on the sphere", "abstract": "The stochastic heat equation on the sphere driven by additive L\\'evy random\nfield is approximated by a spectral method in space and forward and backward\nEuler-Maruyama schemes in time, in analogy to the Wiener case. New regularity\nresults are proven for the stochastic heat equation. The spectral approximation\nis based on a truncation of the series expansion with respect to the spherical\nharmonic functions. To do so, we restrict to square-integrable random field and\noptimal strong convergence rates for a given regularity of the initial\ncondition and two different settings of regularity for the driving noise are\nderived for the Euler-Maruyama methods. Besides strong convergence, convergence\nof the expectation and second moment is shown. Weak rates for the spectral\napproximation are discussed. Numerical simulations confirm the theoretical\nresults.", "published": "2025-07-07 13:40:01", "link": "http://arxiv.org/abs/2507.05005v1", "categories": ["math.PR", "cs.NA", "math.NA", "60H35, 65C30, 60H15, 35R60, 33C55, 65M70"], "primary_category": "math.PR"}
{"title": "Paired Explicit Relaxation Runge-Kutta Methods: Entropy-Conservative and Entropy-Stable High-Order Optimized Multirate Time Integration", "abstract": "We present novel entropy-conservative and entropy-stable multirate\nRunge-Kutta methods based on Paired Explicit Runge-Kutta (P-ERK) with\nrelaxation for conservation laws and related systems of partial differential\nequations. Optimized schemes up to fourth-order of accuracy are derived and\nvalidated in terms of order of consistency, conservation of linear invariants,\nand entropy conservation/stability. We demonstrate the effectiveness of these\nP-ERRK methods when combined with a high-order, entropy-conservative/stable\ndiscontinuous Galerkin spectral element method on unstructured meshes. The\nPaired Explicit Relaxation Runge-Kutta methods(P-ERRK) are readily implemented\nfor partitioned semidiscretizations arising from problems with equation-based\nscale separation such as non-uniform meshes. We highlight that the relaxation\napproach acts as a time-limiting technique which improves the nonlinear\nstability and thus robustness of the multirate schemes. The P-ERRK methods are\napplied to a range of problems, ranging from compressible Euler over\ncompressible Navier-Stokes to the visco-resistive magnetohydrodynamics\nequations in two and three spatial dimensions. For each test case, we compare\ncomputational load and runtime to standalone relaxed Runge-Kutta methods which\nare outperformed by factors up to four. All results can be reproduced using a\npublicly available repository.", "published": "2025-07-07 13:30:40", "link": "http://arxiv.org/abs/2507.04991v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65L06, 65M20, 76-04, 70K20"], "primary_category": "math.NA"}
{"title": "On the convergence of N-body simulations of the Solar System", "abstract": "Most direct N-body integrations of planetary systems use a symplectic\nintegrator with a fixed timestep. A large timestep is desirable because\nsimulations run fast. However, simulations yield unphysical results if the\ntimestep is too large. Surprisingly, no systematic convergence study has been\nperformed on long (Gyr) timescales. In this paper we present numerical\nexperiments to determine the minimum timestep one has to use in long-term\nintegrations of the Solar System in order to recover the system's fundamental\nsecular frequencies and instability rate. We find that timesteps of up to 32\ndays, i.e. a third of Mercury's orbital period, yield physical results in 5 Gyr\nintegrations. We argue that the chaotic diffusion that drives the Solar\nSystem's long-term evolution dominates over numerical diffusion and timestep\nresonances. Our results bolster confidence that most simulations in the\nliterature are indeed converged and provide guidance on how to run time and\nenergy efficient simulations while making sure results can be trusted.", "published": "2025-07-07 13:27:46", "link": "http://arxiv.org/abs/2507.04987v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.NA", "math.NA"], "primary_category": "astro-ph.EP"}
{"title": "Accuracy and stability of the accelerated multi-direct-forcing immersed boundary method", "abstract": "The multi-direct-forcing immersed boundary method allows for high accuracy of\nthe no-slip condition in moving-particle problems but suffers from numerical\ninstability if simulation parameters are not carefully chosen. This study\ninvestigates the numerical accuracy and stability of the accelerated\nmultidirect-forcing immersed boundary method. An analysis of the discretized\nequations of body motion in moving boundary problems identifies a critical\nparameter that solely determines the numerical stability for the body motion.\nAdditionally, numerical simulations reveal the optimal acceleration parameter\nthat minimizes the error in the no-slip condition and is independent of details\nof the boundary discretisation, the boundary shape, and spatial dimensionality.\nThis study provides a guideline for establishing numerically stable simulations\nof moving boundary problems at optimal accuracy of the no-slip condition.", "published": "2025-07-07 13:25:45", "link": "http://arxiv.org/abs/2507.04986v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "physics.comp-ph"], "primary_category": "physics.flu-dyn"}
{"title": "Efficient implicit-explicit sparse stochastic method for high dimensional semi-linear nonlocal diffusion equations", "abstract": "In this paper, we present a sparse grid-based Monte Carlo method for solving\nhigh-dimensional semi-linear nonlocal diffusion equations with volume\nconstraints. The nonlocal model is governed by a class of semi-linear partial\nintegro-differential equations (PIDEs), in which the operator captures both\nlocal convection-diffusion and nonlocal diffusion effects, as revealed by its\nlimiting behavior with respect to the interaction radius. To overcome the\nbottleneck of computational complexity caused by the curse of dimensionality\nand the dense linear systems arising from nonlocal operators, we propose a\nnovel implicit-explicit scheme based on a direct approximation of the nonlinear\nFeynman-Kac representation. The incorporation of sparse grid interpolation\nsignificantly enhances the algorithm's scalability and enables its application\nto problems in high dimensions. To further address the challenges posed by\nhypersingular kernels, we design a sampling strategy tailored to their singular\nstructure, which ensures accurate and stable treatment of the nonlocal\noperators within the probabilistic framework. Notably, the proposed method\ninherits unconditional stability from the underlying stochastic representation,\nwithout imposing constraints on the temporal and spatial discretization scales.\nA rigorous error analysis is provided to establish the convergence of the\nproposed scheme. Extensive numerical experiments, including some non-radial\nsolutions in up to 100 dimensions, are presented to validate the robustness and\naccuracy of the proposed method.", "published": "2025-07-07 13:18:25", "link": "http://arxiv.org/abs/2507.04973v1", "categories": ["math.NA", "cs.NA", "60G52, 65C05, 65D40, 65L70, 91G60", "G.1.8"], "primary_category": "math.NA"}
{"title": "Theoretical analysis and numerical solution to a vector equation $Ax-\\|x\\|_1x=b$", "abstract": "Theoretical and computational properties of a vector equation $Ax-\\|x\\|_1x=b$\nare investigated, where $A$ is an invertible $M$-matrix and $b$ is a\nnonnegative vector. Existence and uniqueness of a nonnegative solution is\nproved. Fixed-point iterations, including a relaxed fixed-point iteration and\nNewton iteration, are proposed and analyzed.\n  A structure-preserving doubling algorithm is proved to be applicable in\ncomputing the required solution, the convergence is at least linear with rate\n1/2. Numerical experiments are performed to demonstrate the effectiveness of\nthe proposed algorithms.", "published": "2025-07-07 13:17:45", "link": "http://arxiv.org/abs/2507.04971v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Discretization Scheme for BSDEs with Random Time Horizon", "abstract": "We analyze a natural extension of the backward Euler approximation for a\nclass of BSDEs with Lipschitz generators and random (unbounded) time horizons.\nWe derive strong error bounds in terms of the underlying stepsize; the distance\nbetween the continuous terminal time and a discrete-time approximation; the\ndistance between the terminal condition and a respective approximation; and an\nintegrated distance depending on an approximation of the time component of the\ngenerator - all are scaled by the exponential of the maximal terminal time. As\napplication we consider decoupled FBSDEs on bounded domains. We use an\nEuler-Maruyama scheme to approximate the diffusion and further refine our error\nbounds to only depend on the distance of the exit times.", "published": "2025-07-07 11:12:16", "link": "http://arxiv.org/abs/2507.04882v1", "categories": ["math.PR", "cs.NA", "math.NA", "60H10, 60G40, 65N75", "G.1.8; G.3"], "primary_category": "math.PR"}
{"title": "Optimization of Transfers linking Ballistic Captures to Earth-Moon Periodic Orbit Families", "abstract": "The design of transfers to periodic orbits in the Earth--Moon system has\nregained prominence with NASA's Artemis and CNSA's Chang'e programs. This work\naddresses the problem of linking ballistic capture trajectories - exploiting\nmulti-body dynamics for temporary lunar orbit insertion - with bounded periodic\nmotion described in the circular restricted three-body problem (CR3BP). A\nunified framework is developed for optimizing bi-impulsive transfers to\nfamilies of periodic orbits via a high-order polynomial expansion of the CR3BP\ndynamics. That same expansion underlies a continuous 'abacus' parameterization\nof orbit families, enabling rapid targeting and analytic sensitivity. Transfers\nto planar periodic-orbit families (Lyapunov L1 and L2, and distant retrograde\norbits) are addressed first, followed by extension to spatial families, such as\nbutterfly and halo L1/L2 orbits, with an emphasis towards Near-Rectilinear Halo\nOrbits (NRHOs). Numerical results demonstrate low-cost solutions and validate\nthe method's adaptability for the design of lunar missions. The optimized\ntrajectories can inform an established low-energy transfer database, enriching\nit with detailed cost profiles that reflect both transfer feasibility and\nunderlying dynamical relationships to specific periodic-orbit families.\nFinally, the proposed transfers provide reliable initial guesses for rapid\nrefinement, readily adaptable for further optimization across mission-specific\nneeds.", "published": "2025-07-07 08:11:00", "link": "http://arxiv.org/abs/2507.04739v1", "categories": ["astro-ph.EP", "cs.NA", "math.DS", "math.NA", "math.OC"], "primary_category": "astro-ph.EP"}
{"title": "RAPTOR: Practical Numerical Profiling of Scientific Applications", "abstract": "The proliferation of low-precision units in modern high-performance\narchitectures increasingly burdens domain scientists. Historically, the choice\nin HPC was easy: can we get away with 32 bit floating-point operations and\nlower bandwidth requirements, or is FP64 necessary? Driven by Artificial\nIntelligence, vendors introduced novel low-precision units for vector and\ntensor operations, and FP64 capabilities stagnate or are reduced. This is\nforcing scientists to re-evaluate their codes, but a trivial search-and-replace\napproach to go from FP64 to FP16 will not suffice. We introduce RAPTOR: a\nnumerical profiling tool to guide scientists in their search for code regions\nwhere precision lowering is feasible. Using LLVM, we transparently replace\nhigh-precision computations using low-precision units, or emulate a\nuser-defined precision. RAPTOR is a novel, feature-rich approach -- with focus\non ease of use -- to change, profile, and reason about numerical requirements\nand instabilities, which we demonstrate with four real-world multi-physics\nFlash-X applications.", "published": "2025-07-07 04:00:18", "link": "http://arxiv.org/abs/2507.04647v1", "categories": ["cs.DC", "cs.NA", "math.NA"], "primary_category": "cs.DC"}
{"title": "A General Class of Model-Free Dense Precision Matrix Estimators", "abstract": "We introduce prototype consistent model-free, dense precision matrix\nestimators that have broad application in economics. Using quadratic form\nconcentration inequalities and novel algebraic characterizations of confounding\ndimension reductions, we are able to: (i) obtain non-asymptotic bounds for\nprecision matrix estimation errors and also (ii) consistency in high\ndimensions; (iii) uncover the existence of an intrinsic signal-to-noise --\nunderlying dimensions tradeoff; and (iv) avoid exact population sparsity\nassumptions. In addition to its desirable theoretical properties, a thorough\nempirical study of the S&P 500 index shows that a tuning parameter-free special\ncase of our general estimator exhibits a doubly ascending Sharpe Ratio pattern,\nthereby establishing a link with the famous double descent phenomenon\ndominantly present in recent statistical and machine learning literature.", "published": "2025-07-07 05:07:17", "link": "http://arxiv.org/abs/2507.04663v1", "categories": ["econ.EM", "stat.ML"], "primary_category": "econ.EM"}
{"title": "The Extended SONICOM HRTF Dataset and Spatial Audio Metrics Toolbox", "abstract": "Headphone-based spatial audio uses head-related transfer functions (HRTFs) to\nsimulate real-world acoustic environments. HRTFs are unique to everyone, due to\npersonal morphology, shaping how sound waves interact with the body before\nreaching the eardrums. Here we present the extended SONICOM HRTF dataset which\nexpands on the previous version released in 2023. The total number of measured\nsubjects has now been increased to 300, with demographic information for a\nsubset of the participants, providing context for the dataset's population and\nrelevance. The dataset incorporates synthesised HRTFs for 200 of the 300\nsubjects, generated using Mesh2HRTF, alongside pre-processed 3D scans of the\nhead and ears, optimised for HRTF synthesis. This rich dataset facilitates\nrapid and iterative optimisation of HRTF synthesis algorithms, allowing the\nautomatic generation of large data. The optimised scans enable seamless\nmorphological modifications, providing insights into how anatomical changes\nimpact HRTFs, and the larger sample size enhances the effectiveness of machine\nlearning approaches. To support analysis, we also introduce the Spatial Audio\nMetrics (SAM) Toolbox, a Python package designed for efficient analysis and\nvisualisation of HRTF data, offering customisable tools for advanced research.\nTogether, the extended dataset and toolbox offer a comprehensive resource for\nadvancing personalised spatial audio research and development.", "published": "2025-07-07 14:38:24", "link": "http://arxiv.org/abs/2507.05053v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Modeling the Difficulty of Saxophone Music", "abstract": "In learning music, difficulty is an important factor in choice of repertoire,\nchoice of tempo, and structure of practice. These choices are typically done\nwith the guidance of a teacher; however, not all learners have access to one.\nWhile piano and strings have had some attention devoted to automated difficulty\nestimation, wind instruments have so far been under-served. In this paper, we\npropose a method for estimating the difficulty of pieces for winds and\nimplement it for the tenor saxophone. We take the cost-of-traversal approach,\nmodelling the part as a sequence of transitions -- note pairs. We estimate\ntransition costs from newly collected recordings of trill speeds, comparing\nrepresentations of saxophone fingerings at various levels of expert input. We\nthen compute and visualise the cost of the optimal path through the part, at a\ngiven tempo. While we present this model for the tenor saxophone, the same\npipeline can be applied to other woodwinds, and our experiments show that with\nappropriate feature design, only a small proportion of possible trills is\nneeded to estimate the costs well. Thus, we present a practical way of\ndiversifying the capabilities of MIR in music education to the wind family of\ninstruments.", "published": "2025-07-07 13:07:34", "link": "http://arxiv.org/abs/2507.04963v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Step Prediction and Control of Hierarchical Emotion Distribution in Text-to-Speech Synthesis", "abstract": "We investigate hierarchical emotion distribution (ED) for achieving\nmulti-level quantitative control of emotion rendering in text-to-speech\nsynthesis (TTS). We introduce a novel multi-step hierarchical ED prediction\nmodule that quantifies emotion variance at the utterance, word, and phoneme\nlevels. By predicting emotion variance in a multi-step manner, we leverage\nglobal emotional context to refine local emotional variations, thereby\ncapturing the intrinsic hierarchical structure of speech emotion. Our approach\nis validated through its integration into a variance adaptor and an external\nmodule design compatible with various TTS systems. Both objective and\nsubjective evaluations demonstrate that the proposed framework significantly\nenhances emotional expressiveness and enables precise control of emotion\nrendering across multiple speech granularities.", "published": "2025-07-07 01:25:51", "link": "http://arxiv.org/abs/2507.04598v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Federated Learning-based Lightweight Network with Zero Trust for UAV Authentication", "abstract": "Unmanned aerial vehicles (UAVs) are increasingly being integrated into\nnext-generation networks to enhance communication coverage and network\ncapacity. However, the dynamic and mobile nature of UAVs poses significant\nsecurity challenges, including jamming, eavesdropping, and cyber-attacks. To\naddress these security challenges, this paper proposes a federated\nlearning-based lightweight network with zero trust for enhancing the security\nof UAV networks. A novel lightweight spectrogram network is proposed for UAV\nauthentication and rejection, which can effectively authenticate and reject\nUAVs based on spectrograms. Experiments highlight LSNet's superior performance\nin identifying both known and unknown UAV classes, demonstrating significant\nimprovements over existing benchmarks in terms of accuracy, model compactness,\nand storage requirements. Notably, LSNet achieves an accuracy of over $80\\%$\nfor known UAV types and an Area Under the Receiver Operating Characteristic\n(AUROC) of $0.7$ for unknown types when trained with all five clients. Further\nanalyses explore the impact of varying the number of clients and the presence\nof unknown UAVs, reinforcing the practical applicability and effectiveness of\nour proposed framework in real-world FL scenarios.", "published": "2025-07-07 15:27:57", "link": "http://arxiv.org/abs/2507.05111v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Real-Time Graph-based Point Cloud Networks on FPGAs via Stall-Free Deep Pipelining", "abstract": "Graph-based Point Cloud Networks (PCNs) are powerful tools for processing\nsparse sensor data with irregular geometries, as found in high-energy physics\ndetectors. However, deploying models in such environments remains challenging\ndue to stringent real-time requirements for both latency, and throughput. In\nthis work, we present a deeply pipelined dataflow architecture for executing\ngraph-based PCNs on FPGAs. Our method supports efficient processing of dynamic,\nsparse point clouds while meeting hard real-time constraints. We introduce\nspecialized processing elements for core graph operations, such as GraVNet\nconvolution and condensation point clustering, and demonstrate our design on\nthe AMD Versal VCK190. Compared to a GPU baseline, our FPGA implementation\nachieves up to 5.25x speedup in throughput while maintaining latencies below 10\n{\\mu}s, satisfying the demands of real-time trigger systems in particle physics\nexperiments. An open-source reference implementation is provided.", "published": "2025-07-07 15:19:04", "link": "http://arxiv.org/abs/2507.05099v1", "categories": ["eess.SP", "hep-ex"], "primary_category": "eess.SP"}
{"title": "Deep Learning Based Antenna Selection Technique for RIS-Empowered RQSM System", "abstract": "Reconfigurable intelligent surface (RIS) technology has attracted\nconsiderable interest due to its ability to control wireless propagation with\nminimal power usage. Receive quadrature spatial modulation (RQSM) scheme\ntransmits data bits in both in-phase ($I$) and quadrature ($Q$) channels,\ndoubling the number of active receive antenna indices and improving spectral\nefficiency compared to the traditional receive spatial modulation (RSM)\ntechnique. Also, capacity-optimized antenna selection (COAS) improves error\nperformance by selecting antennas with the best channel conditions. This paper\nproposes a new deep neural network (DNN)-based antenna selection method,\nsupported by the COAS technique, to improve the error performance of the\nRIS-RQSM system. Monte Carlo simulations of the proposed DNN-COAS-RIS-RQSM\nsystem using the quadrature amplitude modulation (QAM) technique for Rayleigh\nfading channels are performed and compared with the COAS-RIS-RQSM system. Also,\na comparative analysis of the computational complexities of the DNN and COAS\ntechniques is conducted to evaluate the trade-offs between error performance\nand complexity.", "published": "2025-07-07 14:56:09", "link": "http://arxiv.org/abs/2507.05071v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Exploring O-RAN Compression Techniques in Decentralized Distributed MIMO Systems: Reducing Fronthaul Load", "abstract": "This paper explores the application of uplink fronthaul compression\ntechniques within Open RAN (O-RAN) to mitigate fronthaul load in decentralized\ndistributed MIMO (DD-MIMO) systems. With the ever-increasing demand for high\ndata rates and system scalability, the fronthaul load becomes a critical\nbottleneck. Our method uses O-RAN compression techniques to efficiently\ncompress the fronthaul signals. The goal is to greatly lower the fronthaul load\nwhile having little effect on the overall system performance, as shown by Block\nError Rate (BLER) curves. Through rigorous link-level simulations, we compare\nour quantization strategies against a benchmark scenario with no quantization,\nproviding insights into the trade-offs between fronthaul data rate reduction\nand link performance integrity. The results demonstrate that our proposed\nquantization techniques not only lower the fronthaul load but also maintain a\ncompetitive link quality, making them a viable solution for enhancing the\nefficiency of next-generation wireless networks. This study underscores the\npotential of quantization in O-RAN contexts to achieve optimal balance between\nsystem capacity and performance, paving the way for more scalable and robust\nDD-MIMO deployments.", "published": "2025-07-07 13:36:10", "link": "http://arxiv.org/abs/2507.04997v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UAV-Assisted Integrated Communication and Over-the-Air Computation with Interference Awareness", "abstract": "Over the air computation (AirComp) is a promising technique that addresses\nbig data collection and fast wireless data aggregation. However, in a network\nwhere wireless communication and AirComp coexist, mutual interference becomes a\ncritical challenge. In this paper, we propose to employ an unmanned aerial\nvehicle (UAV) to enable integrated communication and AirComp, where we\ncapitalize on UAV mobility with alleviated interference for performance\nenhancement. Particularly, we aim to maximize the sum of user transmission rate\nwith the guaranteed AirComp accuracy requirement, where we jointly optimize the\ntransmission strategy, signal normalizing factor, scheduling strategy, and UAV\ntrajectory. We decouple the formulated problem into two layers where the outer\nlayer is for UAV trajectory and scheduling, and the inner layer is for\ntransmission and computation. Then, we solve the inner layer problem through\nalternating optimization, and the outer layer is solved through soft actor\ncritic based deep reinforcement learning. Simulation results show the\nconvergence of the proposed learning process and also demonstrate the\nperformance superiority of our proposal as compared with the baselines in\nvarious situations.", "published": "2025-07-07 09:26:10", "link": "http://arxiv.org/abs/2507.04807v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR", "abstract": "Millimeter-wave (mmWave) 5G New Radio (NR) communication systems, with their\nhigh-resolution antenna arrays and extensive bandwidth, offer a transformative\nopportunity for high-throughput data transmission and advanced environmental\nsensing. Although passive sensing-based SLAM techniques can estimate user\nlocations and environmental reflections simultaneously, their effectiveness is\noften constrained by assumptions of specular reflections and oversimplified map\nrepresentations. To overcome these limitations, this work employs a mmWave 5G\nNR system for active sensing, enabling it to function similarly to a laser\nscanner for point cloud generation. Specifically, point clouds are extracted\nfrom the power delay profile estimated from each beam direction using a binary\nsearch approach. To ensure accuracy, hardware delays are calibrated with\nmultiple predefined target points. Pose variations of the terminal are then\nestimated from point cloud data gathered along continuous trajectory viewpoints\nusing point cloud registration algorithms. Loop closure detection and pose\ngraph optimization are subsequently applied to refine the sensing results,\nachieving precise terminal localization and detailed radio map reconstruction.\nThe system is implemented and validated through both simulations and\nexperiments, confirming the effectiveness of the proposed approach.", "published": "2025-07-07 04:57:51", "link": "http://arxiv.org/abs/2507.04662v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enhancing Data Processing Efficiency in Blockchain Enabled Metaverse over Wireless Communications", "abstract": "In the rapidly evolving landscape of the Metaverse, enhanced by blockchain\ntechnology, the efficient processing of data has emerged as a critical\nchallenge, especially in wireless communication systems. Addressing this\nchallenge, our paper introduces the innovative concept of data processing\nefficiency (DPE), aiming to maximize processed bits per unit of resource\nconsumption in blockchain-empowered Metaverse environments. To achieve this, we\npropose the DPE-Aware User Association and Resource Allocation (DAUR)\nalgorithm, a tailored optimization framework for blockchain-enabled Metaverse\nwireless communication systems characterized by joint computing and\ncommunication resource constraints. The DAUR algorithm transforms the nonconvex\nproblem of maximizing the sum of DPE ratios into a solvable convex optimization\nproblem. It alternates the optimization of key variables, including user\nassociation, work offloading ratios, task-specific computing resource\ndistribution, bandwidth allocation, user power usage ratios, and server\ncomputing resource allocation ratios. Our extensive numerical results\ndemonstrate the DAUR algorithm's effectiveness in DPE.", "published": "2025-07-07 04:18:12", "link": "http://arxiv.org/abs/2507.04657v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "abstract": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training.", "published": "2025-07-07 17:50:52", "link": "http://arxiv.org/abs/2507.05241v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MedGemma Technical Report", "abstract": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma.", "published": "2025-07-07 17:01:44", "link": "http://arxiv.org/abs/2507.05201v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "OpenS2S: Advancing Fully Open-Source End-to-End Empathetic Large Speech Language Model", "abstract": "Empathetic interaction is a cornerstone of human-machine communication, due\nto the need for understanding speech enriched with paralinguistic cues and\ngenerating emotional and expressive responses. However, the most powerful\nempathetic LSLMs are increasingly closed off, leaving the crucial details about\nthe architecture, data and development opaque to researchers. Given the\ncritical need for transparent research into the LSLMs and empathetic behavior,\nwe present OpenS2S, a fully open-source, transparent and end-to-end LSLM\ndesigned to enable empathetic speech interactions. Based on our empathetic\nspeech-to-text model BLSP-Emo, OpenS2S further employs a streaming interleaved\ndecoding architecture to achieve low-latency speech generation. To facilitate\nend-to-end training, OpenS2S incorporates an automated data construction\npipeline that synthesizes diverse, high-quality empathetic speech dialogues at\nlow cost. By leveraging large language models to generate empathetic content\nand controllable text-to-speech systems to introduce speaker and emotional\nvariation, we construct a scalable training corpus with rich paralinguistic\ndiversity and minimal human supervision. We release the fully open-source\nOpenS2S model, including the dataset, model weights, pre-training and\nfine-tuning codes, to empower the broader research community and accelerate\ninnovation in empathetic speech systems. The project webpage can be accessed at\nhttps://casia-lm.github.io/OpenS2S", "published": "2025-07-07 16:31:37", "link": "http://arxiv.org/abs/2507.05177v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Do We Really Need Specialization? Evaluating Generalist Text Embeddings for Zero-Shot Recommendation and Search", "abstract": "Pre-trained language models (PLMs) are widely used to derive semantic\nrepresentations from item metadata in recommendation and search. In sequential\nrecommendation, PLMs enhance ID-based embeddings through textual metadata,\nwhile in product search, they align item characteristics with user intent.\nRecent studies suggest task and domain-specific fine-tuning are needed to\nimprove representational power. This paper challenges this assumption, showing\nthat Generalist Text Embedding Models (GTEs), pre-trained on large-scale\ncorpora, can guarantee strong zero-shot performance without specialized\nadaptation. Our experiments demonstrate that GTEs outperform traditional and\nfine-tuned models in both sequential recommendation and product search. We\nattribute this to a superior representational power, as they distribute\nfeatures more evenly across the embedding space. Finally, we show that\ncompressing embedding dimensions by focusing on the most informative directions\n(e.g., via PCA) effectively reduces noise and improves the performance of\nspecialized models. To ensure reproducibility, we provide our repository at\nhttps://split.to/gte4ps.", "published": "2025-07-07 13:41:52", "link": "http://arxiv.org/abs/2507.05006v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SIGIR 2025 -- LiveRAG Challenge Report", "abstract": "The LiveRAG Challenge at SIGIR 2025, held between March and May 2025,\nprovided a competitive platform for advancing Retrieval-Augmented Generation\n(RAG) technologies. Participants from academia and industry were invited to\ndevelop a RAG-based question-answering system using a fixed corpus\n(Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal\nwas to facilitate challenging comparisons of retrieval and prompting\nstrategies. During the Live Challenge Day, 70 teams from 27 different countries\nprovided answers and supportive information to 500 unseen questions within a\nstrict two-hour time window. Evaluation was conducted in two stages: first an\nautomated LLM-as-a-judge approach was used to compute correctness and\nfaithfulness score, then a manual review of top ranked submissions was\nconducted. The finalists were announced on June 12, 2025, with prizes awarded\nduring the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.", "published": "2025-07-07 12:38:53", "link": "http://arxiv.org/abs/2507.04942v2", "categories": ["cs.CL", "cs.IR", "H.3.3"], "primary_category": "cs.CL"}
{"title": "CTA: Cross-Task Alignment for Better Test Time Training", "abstract": "Deep learning models have demonstrated exceptional performance across a wide\nrange of computer vision tasks. However, their performance often degrades\nsignificantly when faced with distribution shifts, such as domain or dataset\nchanges. Test-Time Training (TTT) has emerged as an effective method to enhance\nmodel robustness by incorporating an auxiliary unsupervised task during\ntraining and leveraging it for model updates at test time. In this work, we\nintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.\nUnlike existing TTT methods, CTA does not require a specialized model\narchitecture and instead takes inspiration from the success of multi-modal\ncontrastive learning to align a supervised encoder with a self-supervised one.\nThis process enforces alignment between the learned representations of both\nmodels, thereby mitigating the risk of gradient interference, preserving the\nintrinsic robustness of self-supervised learning and enabling more semantically\nmeaningful updates at test-time. Experimental results demonstrate substantial\nimprovements in robustness and generalization over the state-of-the-art on\nseveral benchmark datasets.", "published": "2025-07-07 17:33:20", "link": "http://arxiv.org/abs/2507.05221v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift", "abstract": "Knowledge graph (KG) reasoning remains a critical research area focused on\ninferring missing knowledge by analyzing relationships among observed facts.\nDespite its success, a key limitation of existing KG reasoning methods is their\ndependence on the I.I.D assumption. This assumption can easily be violated due\nto unknown sample selection bias during training or agnostic distribution\nshifts during testing, significantly compromising model performance and\nreliability. To facilitate the deployment of KG reasoning in wild environments,\nthis study investigates learning logical rules from KGs affected by unknown\nselection bias. Additionally, we address test sets with agnostic distribution\nshifts, formally defining this challenge as out-of-distribution (OOD) KG\nreasoning-a previously underexplored problem. To solve the issue, we propose\nthe Stable Rule Learning (StableRule) framework, an end-to-end methodology that\nintegrates feature decorrelation with rule learning network, to enhance OOD\ngeneralization performance. By leveraging feature decorrelation, the StableRule\nframework mitigates the adverse effects of covariate shifts arising in OOD\nscenarios, thereby improving the robustness of the rule learning component in\neffectively deriving logical rules. Extensive experiments on seven benchmark\nKGs demonstrate the framework's superior effectiveness and stability across\ndiverse heterogeneous environments, underscoring its practical significance for\nreal-world applications.", "published": "2025-07-07 15:27:48", "link": "http://arxiv.org/abs/2507.05110v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning", "abstract": "T cell receptor (TCR) repertoires encode critical immunological signatures\nfor autoimmune diseases, yet their clinical application remains limited by\nsequence sparsity and low witness rates. We developed EAMil, a multi-instance\ndeep learning framework that leverages TCR sequencing data to diagnose systemic\nlupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional\naccuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding\nand enhanced gate attention mechanisms, our model achieved state-of-the-art\nperformance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully\nidentified disease-associated genes with over 90% concordance with established\ndifferential analyses and effectively distinguished disease-specific TCR genes.\nThe model demonstrated robustness in classifying multiple disease categories,\nutilizing the SLEDAI score to stratify SLE patients by disease severity as well\nas to diagnose the site of damage in SLE patients, and effectively controlling\nfor confounding factors such as age and gender. This interpretable framework\nfor immune receptor analysis provides new insights for autoimmune disease\ndetection and classification with broad potential clinical applications across\nimmune-mediated conditions.", "published": "2025-07-07 13:24:41", "link": "http://arxiv.org/abs/2507.04981v2", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Activation Steering for Chain-of-Thought Compression", "abstract": "Large language models (LLMs) excel at complex reasoning when they include\nintermediate steps, known as \"chains of thought\" (CoTs). However, these\nrationales are often overly verbose, even for simple problems, leading to\nwasted context, increased latency, and higher energy consumption. We observe\nthat verbose, English-heavy CoTs and concise, math-centric CoTs occupy distinct\nregions in the model's residual-stream activation space. By extracting and\ninjecting a \"steering vector\" to transition between these modes, we can\nreliably shift generation toward more concise reasoning, effectively\ncompressing CoTs without retraining. We formalize this approach as\nActivation-Steered Compression (ASC), an inference-time technique that shortens\nreasoning traces by directly modifying hidden representations. In addition, we\nprovide a theoretical analysis of the impact of ASC on the output distribution,\nderived from a closed-form KL-divergence-bounded constraint to regulate\nsteering strength. Using only 100 paired verbose and concise examples, ASC\nachieves up to 67.43% reduction in CoT length on MATH500 and GSM8K datasets,\nwhile maintaining accuracy across 7B, 8B, and 32B parameter models. As a\ntraining-free method, ASC introduces negligible runtime overhead and, on\nMATH500, delivers an average 2.73x speedup in end-to-end reasoning wall-clock\ntime on an 8B model. This makes ASC a practical and efficient tool for\nstreamlining the deployment of reasoning-capable LLMs in latency- or\ncost-sensitive settings. The code is available at:\nhttps://github.com/ArminAzizi98/ASC", "published": "2025-07-07 08:16:54", "link": "http://arxiv.org/abs/2507.04742v2", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "What's Making That Sound Right Now? Video-centric Audio-Visual Localization", "abstract": "Audio-Visual Localization (AVL) aims to identify sound-emitting sources\nwithin a visual scene. However, existing studies focus on image-level\naudio-visual associations, failing to capture temporal dynamics. Moreover, they\nassume simplified scenarios where sound sources are always visible and involve\nonly a single object. To address these limitations, we propose AVATAR, a\nvideo-centric AVL benchmark that incorporates high-resolution temporal\ninformation. AVATAR introduces four distinct scenarios -- Single-sound,\nMixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensive\nevaluation of AVL models. Additionally, we present TAVLO, a novel video-centric\nAVL model that explicitly integrates temporal information. Experimental results\nshow that conventional methods struggle to track temporal variations due to\ntheir reliance on global audio features and frame-level mappings. In contrast,\nTAVLO achieves robust and precise audio-visual alignment by leveraging\nhigh-resolution temporal modeling. Our work empirically demonstrates the\nimportance of temporal dynamics in AVL and establishes a new standard for\nvideo-centric audio-visual localization.", "published": "2025-07-07 05:12:34", "link": "http://arxiv.org/abs/2507.04667v2", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling", "abstract": "Most masked point cloud modeling (MPM) methods follow a regression paradigm\nto reconstruct the coordinate or feature of masked regions. However, they tend\nto over-constrain the model to learn the details of the masked region,\nresulting in failure to capture generalized features. To address this\nlimitation, we propose \\textbf{\\textit{PointGAC}}, a novel clustering-based MPM\nmethod that aims to align the feature distribution of masked regions.\nSpecially, it features an online codebook-guided teacher-student framework.\nFirstly, it presents a geometry-aware partitioning strategy to extract initial\npatches. Then, the teacher model updates a codebook via online k-means based on\nfeatures extracted from the complete patches. This procedure facilitates\ncodebook vectors to become cluster centers. Afterward, we assigns the unmasked\nfeatures to their corresponding cluster centers, and the student model aligns\nthe assignment for the reconstructed masked features. This strategy focuses on\nidentifying the cluster centers to which the masked features belong, enabling\nthe model to learn more generalized feature representations. Benefiting from a\nproposed codebook maintenance mechanism, codebook vectors are actively updated,\nwhich further increases the efficiency of semantic feature learning.\nExperiments validate the effectiveness of the proposed method on various\ndownstream tasks. Code is available at https://github.com/LAB123-tech/PointGAC", "published": "2025-07-07 09:21:28", "link": "http://arxiv.org/abs/2507.04801v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification", "abstract": "Multi-modal object Re-IDentification (ReID) has gained considerable attention\nwith the goal of retrieving specific targets across cameras using heterogeneous\nvisual data sources. Existing methods primarily aim to improve identification\nperformance, but often overlook the uncertainty arising from inherent defects,\nsuch as intra-modal noise and inter-modal conflicts. This uncertainty is\nparticularly significant in the case of fine-grained local occlusion and frame\nloss, which becomes a challenge in multi-modal learning. To address the above\nchallenge, we propose a robust approach named Uncertainty-Guided Graph model\nfor multi-modal object ReID (UGG-ReID). UGG-ReID is designed to mitigate noise\ninterference and facilitate effective multi-modal fusion by estimating both\nlocal and sample-level aleatoric uncertainty and explicitly modeling their\ndependencies. Specifically, we first propose the Gaussian patch-graph\nrepresentation model that leverages uncertainty to quantify fine-grained local\ncues and capture their structural relationships. This process boosts the\nexpressiveness of modal-specific information, ensuring that the generated\nembeddings are both more informative and robust. Subsequently, we design an\nuncertainty-guided mixture of experts strategy that dynamically routes samples\nto experts exhibiting low uncertainty. This strategy effectively suppresses\nnoise-induced instability, leading to enhanced robustness. Meanwhile, we design\nan uncertainty-guided routing to strengthen the multi-modal interaction,\nimproving the performance. UGG-ReID is comprehensively evaluated on five\nrepresentative multi-modal object ReID datasets, encompassing diverse spectral\nmodalities. Experimental results show that the proposed method achieves\nexcellent performance on all datasets and is significantly better than current\nmethods in terms of noise immunity. Our code will be made public upon\nacceptance.", "published": "2025-07-07 03:41:08", "link": "http://arxiv.org/abs/2507.04638v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A COMPASS to Model Comparison and Simulation-Based Inference in Galactic Chemical Evolution", "abstract": "We present COMPASS, a novel simulation-based inference framework that\ncombines score-based diffusion models with transformer architectures to jointly\nperform parameter estimation and Bayesian model comparison across competing\nGalactic Chemical Evolution (GCE) models. COMPASS handles high-dimensional,\nincomplete, and variable-size stellar abundance datasets. Applied to\nhigh-precision elemental abundance measurements, COMPASS evaluates 40\ncombinations of nucleosynthetic yield tables. The model strongly favours\nAsymptotic Giant Branch yields from NuGrid and core-collapse SN yields used in\nthe IllustrisTNG simulation, achieving near-unity cumulative posterior\nprobability. Using the preferred model, we infer a steep high-mass IMF slope\nand an elevated Supernova Ia normalization, consistent with prior solar\nneighbourhood studies but now derived from fully amortized Bayesian inference.\nOur results demonstrate that modern SBI methods can robustly constrain\nuncertain physics in astrophysical simulators and enable principled model\nselection when analysing complex, simulation-based data.", "published": "2025-07-07 14:45:41", "link": "http://arxiv.org/abs/2507.05060v2", "categories": ["astro-ph.GA", "astro-ph.IM", "cs.LG", "physics.comp-ph", "physics.data-an"], "primary_category": "astro-ph.GA"}
{"title": "Paired Explicit Relaxation Runge-Kutta Methods: Entropy-Conservative and Entropy-Stable High-Order Optimized Multirate Time Integration", "abstract": "We present novel entropy-conservative and entropy-stable multirate\nRunge-Kutta methods based on Paired Explicit Runge-Kutta (P-ERK) schemes with\nrelaxation for conservation laws and related systems of partial differential\nequations. Optimized schemes up to fourth-order of accuracy are derived and\nvalidated in terms of order of consistency, conservation of linear invariants,\nand entropy conservation/stability. We demonstrate the effectiveness of these\nP-ERRK methods when combined with a high-order, entropy-conservative/stable\ndiscontinuous Galerkin spectral element method on unstructured meshes. The\nPaired Explicit Relaxation Runge-Kutta methods(P-ERRK) are readily implemented\nfor partitioned semidiscretizations arising from problems with equation-based\nscale separation such as non-uniform meshes. We highlight that the relaxation\napproach acts as a time-limiting technique which improves the nonlinear\nstability and thus robustness of the multirate schemes. The P-ERRK methods are\napplied to a range of problems, ranging from compressible Euler over\ncompressible Navier-Stokes to the visco-resistive magnetohydrodynamics\nequations in two and three spatial dimensions. For each test case, we compare\ncomputational load and runtime to standalone relaxed Runge-Kutta methods which\nare outperformed by factors up to four. All results can be reproduced using a\npublicly available repository.", "published": "2025-07-07 13:30:40", "link": "http://arxiv.org/abs/2507.04991v2", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65L06, 65M20, 76-04, 70K20"], "primary_category": "math.NA"}
{"title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "abstract": "Large language models (LLMs) have advanced virtual educators and learners,\nbridging NLP with AI4Education. Existing work often lacks scalability and fails\nto leverage diverse, large-scale course content, with limited frameworks for\nassessing pedagogic quality. To this end, we propose WikiHowAgent, a\nmulti-agent workflow leveraging LLMs to simulate interactive teaching-learning\nconversations. It integrates teacher and learner agents, an interaction\nmanager, and an evaluator to facilitate procedural learning and assess\npedagogic quality. We introduce a dataset of 114,296 teacher-learner\nconversations grounded in 14,287 tutorials across 17 domains and 727 topics.\nOur evaluation protocol combines computational and rubric-based metrics with\nhuman judgment alignment. Results demonstrate the workflow's effectiveness in\ndiverse setups, offering insights into LLM capabilities across domains. Our\ndatasets and implementations are fully open-sourced.", "published": "2025-07-07 22:56:37", "link": "http://arxiv.org/abs/2507.05528v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications", "abstract": "Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong\nperformance on clinical natural language processing (NLP) tasks across multiple\nmedical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular\nreporting from nurse dictations and medical order extraction from\ndoctor-patient consultations - remain underexplored due to data scarcity and\nsensitivity, despite active industry efforts. Practical solutions to these\nreal-world clinical tasks can significantly reduce the documentation burden on\nhealthcare providers, allowing greater focus on patient care. In this paper, we\ninvestigate these two challenging tasks using private and open-source clinical\ndatasets, evaluating the performance of both open- and closed-weight LLMs, and\nanalyzing their respective strengths and limitations. Furthermore, we propose\nan agentic pipeline for generating realistic, non-sensitive nurse dictations,\nenabling structured extraction of clinical observations. To support further\nresearch in both areas, we release SYNUR and SIMORD, the first open-source\ndatasets for nurse observation extraction and medical order extraction.", "published": "2025-07-07 22:29:29", "link": "http://arxiv.org/abs/2507.05517v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality", "abstract": "Vision-language models (VLMs) are essential for enabling AI-powered smart\nassistants to interpret and reason in multimodal environments. However, their\napplication in augmented reality (AR) training remains largely unexplored. In\nthis work, we introduce a comprehensive dataset tailored for AR training,\nfeaturing systematized vision-language tasks, and evaluate nine\nstate-of-the-art VLMs on it. Our results reveal that even advanced models,\nincluding GPT-4o, struggle with fine-grained assembly tasks, achieving a\nmaximum F1 score of just 40.54% on state detection. These findings highlight\nthe demand for enhanced datasets, benchmarks, and further research to improve\nfine-grained vision-language alignment. Beyond technical contributions, our\nwork has broader social implications, particularly in empowering blind and\nvisually impaired users with equitable access to AI-driven learning\nopportunities. We provide all related resources, including the dataset, source\ncode, and evaluation results, to support the research community.", "published": "2025-07-07 22:29:01", "link": "http://arxiv.org/abs/2507.05515v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "ModelCitizens:Representing Community Voices in Online Safety", "abstract": "Automatic toxic language detection is critical for creating safe, inclusive\nonline spaces. However, it is a highly subjective task, with perceptions of\ntoxic language shaped by community norms and lived experience. Existing\ntoxicity detection models are typically trained on annotations that collapse\ndiverse annotator perspectives into a single ground truth, erasing important\ncontext-specific notions of toxicity such as reclaimed language. To address\nthis, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K\ntoxicity annotations across diverse identity groups. To capture the role of\nconversational context on toxicity, typical of social media posts, we augment\nMODELCITIZENS posts with LLM-generated conversational scenarios.\nState-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,\nGPT-o4-mini) underperform on MODELCITIZENS, with further degradation on\ncontext-augmented posts. Finally, we release LLAMACITIZEN-8B and\nGEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,\nwhich outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our\nfindings highlight the importance of community-informed annotation and modeling\nfor inclusive content moderation.", "published": "2025-07-07 20:15:18", "link": "http://arxiv.org/abs/2507.05455v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Semantics of Large Language Models", "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrated the potential to\nreplicate human language abilities through technology, ranging from text\ngeneration to engaging in conversations. However, it remains controversial to\nwhat extent these systems truly understand language. We examine this issue by\nnarrowing the question down to the semantics of LLMs at the word and sentence\nlevel. By examining the inner workings of LLMs and their generated\nrepresentation of language and by drawing on classical semantic theories by\nFrege and Russell, we get a more nuanced picture of the potential semantic\ncapabilities of LLMs.", "published": "2025-07-07 20:02:57", "link": "http://arxiv.org/abs/2507.05448v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PhoniTale: Phonologically Grounded Mnemonic Generation for Typologically Distant Language Pairs", "abstract": "Vocabulary acquisition poses a significant challenge for second-language (L2)\nlearners, especially when learning typologically distant languages such as\nEnglish and Korean, where phonological and structural mismatches complicate\nvocabulary learning. Recently, large language models (LLMs) have been used to\ngenerate keyword mnemonics by leveraging similar keywords from a learner's\nfirst language (L1) to aid in acquiring L2 vocabulary. However, most of this\nresearch has focused on native English speakers learning other languages,\nrather than the reverse. In this paper, we present PhoniTale, a novel\ncross-lingual mnemonic generation system that retrieves L1 keyword sequence\nbased on phonological similarity and uses LLMs to generate mnemonics. We\nevaluate PhoniTale using both automated metrics and human evaluations,\ncomparing its output to mnemonics created by humans and by previous automated\napproaches. To assess practical effectiveness, we also conduct a short-term\nrecall test measuring mnemonic helpfulness. Our findings show that PhoniTale\nperforms comparably to human-authored mnemonics. We also highlight key areas\nfor future improvement in mnemonic quality and methodology.", "published": "2025-07-07 19:50:12", "link": "http://arxiv.org/abs/2507.05444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gendered Divides in Online Discussions about Reproductive Rights", "abstract": "The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health\nOrganization marked a turning point in the national debate over reproductive\nrights. While the ideological divide over abortion is well documented, less is\nknown about how gender and local sociopolitical contexts interact to shape\npublic discourse. Drawing on nearly 10 million abortion-related posts on X\n(formerly Twitter) from users with inferred gender, ideology and location, we\nshow that gender significantly moderates abortion attitudes and emotional\nexpression, particularly in conservative regions, and independently of\nideology. This creates a gender gap in abortion attitudes that grows more\npronounced in conservative regions. The leak of the Dobbs draft opinion further\nintensified online engagement, disproportionately mobilizing pro-abortion women\nin areas where access was under threat. These findings reveal that abortion\ndiscourse is not only ideologically polarized but also deeply structured by\ngender and place, highlighting the central role of identity in shaping\npolitical expression during moments of institutional disruption.", "published": "2025-07-07 19:49:30", "link": "http://arxiv.org/abs/2507.05443v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "\"Lost-in-the-Later\": Framework for Quantifying Contextual Grounding in Large Language Models", "abstract": "Large language models are capable of leveraging both contextual and\nparametric knowledge but how they prioritize and integrate these sources\nremains underexplored. We introduce CoPE, a novel evaluation framework that\nsystematically measures contextual knowledge (CK) and parametric knowledge (PK)\nacross models and languages. Using our MultiWikiAtomic dataset in English,\nSpanish, and Danish, we analyze how large language models (LLMs) integrate\ncontext, prioritize information, and incorporate PK in open-ended question\nanswering. Our analysis uncovers a phenomenon we call lost-in-the-later, where\nLLMs tend to overlook or deprioritize information that appears later in a given\ncontext, revealing a strong positional bias that affects contextual grounding.\nWe further find that reasoning models, as well as non-reasoning models prompted\nwith chain-of-thought (CoT), use context even less than non-reasoning models\nwithout CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,\nin particular, results in lower recall and shorter responses, leading to\ndegraded contextual grounding. Based on these insights, we design prompt-based\nmethods to effectively leverage input context. A case study applying CoPE to\nsummarization demonstrates that CK-informed prompting improves factual\ngrounding and reduces hallucination.", "published": "2025-07-07 19:13:20", "link": "http://arxiv.org/abs/2507.05424v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "abstract": "Large Language Models (LLMs) have achieved strong performance in domains like\nmathematics, factual QA, and code generation, yet their multilingual reasoning\ncapabilities in these tasks remain underdeveloped. Especially for low-resource\nlanguages such as Swahili or Thai, LLMs can often misinterpret prompts or\ndefault to reasoning in English. This implicit bias toward high-resource\nlanguages undermines factual accuracy, interpretability, and trust. Current\nmultilingual benchmarks focus only on final answers, overlooking whether models\nactually reason in the target language. To address this gap, we introduce\nGeoFact-X, a geography-based multilingual factual reasoning benchmark with\nannotated reasoning traces in five languages: English, Hindi, Japanese,\nSwahili, and Thai. We further propose BRIDGE, a novel training method that\nguides supervised fine-tuning and test-time reinforcement learning with a\nlanguage-consistency reward to align reasoning with the input language.\nFinally, we develop an automatic evaluation protocol using LLM-as-a-judge to\nassess answer correctness and the quality and language consistency of reasoning\ntraces, enabling nuanced and scalable analysis beyond surface-level metrics.\nOur results show that BRIDGE significantly enhances multilingual reasoning\nfidelity, demonstrating that reasoning-aware multilingual reinforcement\nlearning is crucial for robust cross-lingual generalization.\nhttps://jd730.github.io/projects/GeoFact-X_BRIDGE", "published": "2025-07-07 19:04:36", "link": "http://arxiv.org/abs/2507.05418v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences", "abstract": "Large language models (LLMs) are primarily accessed via commercial APIs, but\nthis often requires users to expose their data to service providers. In this\npaper, we explore how users can stay in control of their data by using privacy\nprofiles: simple natural language instructions that say what should and should\nnot be revealed. We build a framework where a local model uses these\ninstructions to rewrite queries, only hiding details deemed sensitive by the\nuser, before sending them to an external model, thus balancing privacy with\nperformance. To support this research, we introduce PEEP, a multilingual\ndataset of real user queries annotated to mark private content and paired with\nsynthetic privacy profiles. Our experiments with lightweight LLMs show they can\nfollow these instructions to some extent, but also face consistent challenges,\nhighlighting the need for models that better understand and comply with\nuser-defined privacy preferences.", "published": "2025-07-07 18:22:55", "link": "http://arxiv.org/abs/2507.05391v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Generalization Ridge: Information Flow in Natural Language Generation", "abstract": "Transformer-based language models have achieved state-of-the-art performance\nin natural language generation (NLG) tasks, yet their internal mechanisms for\nsynthesizing task-relevant information remain insufficiently understood. While\nprior studies suggest that intermediate layers often yield more generalizable\nrepresentations than final layers, how this generalization ability emerges and\npropagates across layers during training remains unclear. To address this gap,\nwe propose InfoRidge, an information-theoretic framework, to characterize how\npredictive information-the mutual information between hidden representations\nand target outputs-varies across depth. Estimating this quantity enables us to\ntrace the flow of task-relevant information throughout the model during\ntraining. Our experiments across various models and datasets reveal a\nconsistent non-monotonic trend: predictive information peaks in upper-middle\nlayers-forming a generalization ridge-before declining in final layers,\nreflecting a transition between generalization and memorization. To further\ninvestigate this phenomenon, we introduce residual scaling\ncoefficients-trainable scalar parameters applied to each residual block-which\nserve as functional probes for assessing the relative importance of individual\ntransformer layers. These coefficients reveal that, under distribution shift,\nmodels downweight final layers and increasingly rely on ridge layers,\nhighlighting their role in generalization. Together, these findings offer new\ninsights into the internal mechanisms of transformers and underscore the\ncritical role of intermediate layers in supporting generalization.", "published": "2025-07-07 18:18:51", "link": "http://arxiv.org/abs/2507.05387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training", "abstract": "Continual post-training (CPT) is a popular and effective technique for\nadapting foundation models like multimodal large language models to specific\nand ever-evolving downstream tasks. While existing research has primarily\nconcentrated on methods like data replay, model expansion, or parameter\nregularization, the fundamental role of the learning paradigm within CPT\nremains largely unexplored. This paper presents a comparative analysis of two\ncore post-training paradigms: supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT), investigating their respective impacts on knowledge\nretention during CPT. Our experiments are conducted on a benchmark comprising\nseven diverse multimodal tasks, utilizing Qwen2.5-VL-7B-Instruct as the base\nmodel for continual post-training. The investigation yields two significant\nfindings: (1) When continuously learning on downstream tasks, SFT leads to\ncatastrophic forgetting of previously learned tasks. In contrast, RFT\ninherently preserves prior knowledge and achieve performance comparable to\nmulti-task training. (2) RFT successfully protects and even enhances the\nmodel's general knowledge on standard benchmarks (e.g., MMMU and MMLU-Pro).\nConversely, SFT degrades general model capabilities severely. Further analysis\nshows that explicit mechanisms, such as KL penalty and chain-of-thought\nreasoning, are not the primary factors. Instead, we find that the implicit\nregularization inherent to RFT is a key factor in mitigating forgetting.\nFinally, we propose a rollout-based instance filtering algorithm to improve the\nstability and efficiency of RFT. Our comprehensive study demonstrates the\nsuperiority of RFT as a robust paradigm for continual post-training.", "published": "2025-07-07 18:17:06", "link": "http://arxiv.org/abs/2507.05386v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EduCoder: An Open-Source Annotation System for Education Transcript Data", "abstract": "We introduce EduCoder, a domain-specialized tool designed to support\nutterance-level annotation of educational dialogue. While general-purpose text\nannotation tools for NLP and qualitative research abound, few address the\ncomplexities of coding education dialogue transcripts -- with diverse\nteacher-student and peer interactions. Common challenges include defining\ncodebooks for complex pedagogical features, supporting both open-ended and\ncategorical coding, and contextualizing utterances with external features, such\nas the lesson's purpose and the pedagogical value of the instruction. EduCoder\nis designed to address these challenges by providing a platform for researchers\nand domain experts to collaboratively define complex codebooks based on\nobserved data. It incorporates both categorical and open-ended annotation types\nalong with contextual materials. Additionally, it offers a side-by-side\ncomparison of multiple annotators' responses, allowing comparison and\ncalibration of annotations with others to improve data reliability. The system\nis open-source, with a demo video available.", "published": "2025-07-07 18:15:29", "link": "http://arxiv.org/abs/2507.05385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study", "abstract": "Recent advances in natural language processing highlight two key factors for\nimproving reasoning in large language models (LLMs): (i) allocating more\ntest-time compute tends to help on harder problems but often introduces\nredundancy in the reasoning trace, and (ii) compute is most effective when\nreasoning is systematic and incremental, forming structured chains of thought\n(CoTs) akin to human problem-solving. To study these factors in isolation, we\nintroduce a controlled setting based on shortest-path tasks in layered graphs.\nWe train decoder-only transformers on question-trace-answer triples using a\ncustom tokenizer, comparing models trained on optimal bottom-up dynamic\nprogramming traces with those trained on longer, valid traces involving\nbacktracking. Surprisingly, with the same training-token budget, models trained\non inefficient traces generalize better to unseen graphs. This benefit is not\ndue to length alone-injecting arbitrary redundancy into reasoning traces fails\nto help and can even hurt performance. Instead, we find that generalization\ncorrelates with the model's confidence in next-token prediction, suggesting\nthat long, coherent, and locally incremental traces make the training signal\neasier to optimize.", "published": "2025-07-07 18:00:06", "link": "http://arxiv.org/abs/2507.05362v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks", "abstract": "The proliferation of fine-tuned language model experts for specific tasks and\ndomains signals the need for efficient selection and combination methods. We\npropose LoRA-Augmented Generation (LAG) for leveraging large libraries of\nknowledge and task-specific LoRA adapters. LAG requires no additional training\nor access to data, and efficiently filters, retrieves, and applies experts on a\nper-token and layer basis. We evaluate LAG on various knowledge-intensive\ntasks, achieving superior performance over existing data-free methods. We\nexplore scenarios where additional data is available, demonstrating LAG's\ncompatibility with alternative solutions such as retrieval-augmented generation\n(RAG).", "published": "2025-07-07 18:00:01", "link": "http://arxiv.org/abs/2507.05346v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "abstract": "Recent advances in large language models (LLMs) have enabled new applications\nin e-commerce customer service. However, their capabilities remain constrained\nin complex, multimodal scenarios. We present MindFlow, the first open-source\nmultimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it\nintegrates memory, decision-making, and action modules, and adopts a modular\n\"MLLM-as-Tool\" strategy for effect visual-textual reasoning. Evaluated via\nonline A/B testing and simulation-based ablation, MindFlow demonstrates\nsubstantial gains in handling complex queries, improving user satisfaction, and\nreducing operational costs, with a 93.53% relative improvement observed in\nreal-world deployments.", "published": "2025-07-07 17:53:55", "link": "http://arxiv.org/abs/2507.05330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review", "abstract": "Despite the remarkable performance of Large Language Models (LLMs) in\nautomated discharge summary generation, they still suffer from hallucination\nissues, such as generating inaccurate content or fabricating information\nwithout valid sources. In addition, electronic medical records (EMRs) typically\nconsist of long-form data, making it challenging for LLMs to attribute the\ngenerated content to the sources. To address these challenges, we propose LCDS,\na Logic-Controlled Discharge Summary generation system. LCDS constructs a\nsource mapping table by calculating textual similarity between EMRs and\ndischarge summaries to constrain the scope of summarized content. Moreover,\nLCDS incorporates a comprehensive set of logical rules, enabling it to generate\nmore reliable silver discharge summaries tailored to different clinical fields.\nFurthermore, LCDS supports source attribution for generated content, allowing\nexperts to efficiently review, provide feedback, and rectify errors. The\nresulting golden discharge summaries are subsequently recorded for incremental\nfine-tuning of LLMs. Our project and demo video are in the GitHub repository\nhttps://github.com/ycycyc02/LCDS.", "published": "2025-07-07 15:25:52", "link": "http://arxiv.org/abs/2507.05319v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Simulating Refractive Distortions and Weather-Induced Artifacts for Resource-Constrained Autonomous Perception", "abstract": "The scarcity of autonomous vehicle datasets from developing regions,\nparticularly across Africa's diverse urban, rural, and unpaved roads, remains a\nkey obstacle to robust perception in low-resource settings. We present a\nprocedural augmentation pipeline that enhances low-cost monocular dashcam\nfootage with realistic refractive distortions and weather-induced artifacts\ntailored to challenging African driving scenarios. Our refractive module\nsimulates optical effects from low-quality lenses and air turbulence, including\nlens distortion, Perlin noise, Thin-Plate Spline (TPS), and divergence-free\n(incompressible) warps. The weather module adds homogeneous fog, heterogeneous\nfog, and lens flare. To establish a benchmark, we provide baseline performance\nusing three image restoration models. To support perception research in\nunderrepresented African contexts, without costly data collection, labeling, or\nsimulation, we release our distortion toolkit, augmented dataset splits, and\nbenchmark results.", "published": "2025-07-07 23:21:19", "link": "http://arxiv.org/abs/2507.05536v1", "categories": ["cs.CV", "cs.ET", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model", "abstract": "Motivated by the growing demand for retrieval systems that operate across\nmodalities, we introduce llama-nemoretriever-colembed, a unified text-image\nretrieval model that delivers state-of-the-art performance across multiple\nbenchmarks. We release two model variants, 1B and 3B. The 3B model achieves\nstate of the art performance, scoring NDCG@5 91.0 on ViDoRe V1 and 63.5 on\nViDoRe V2, placing first on both leaderboards as of June 27, 2025.\n  Our approach leverages the NVIDIA Eagle2 Vision-Language model (VLM),\nmodifies its architecture by replacing causal attention with bidirectional\nattention, and integrates a ColBERT-style late interaction mechanism to enable\nfine-grained multimodal retrieval in a shared embedding space. While this\nmechanism delivers superior retrieval accuracy, it introduces trade-offs in\nstorage and efficiency. We provide a comprehensive analysis of these\ntrade-offs. Additionally, we adopt a two-stage training strategy to enhance the\nmodel's retrieval capabilities.", "published": "2025-07-07 22:20:04", "link": "http://arxiv.org/abs/2507.05513v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LoomNet: Enhancing Multi-View Image Generation via Latent Space Weaving", "abstract": "Generating consistent multi-view images from a single image remains\nchallenging. Lack of spatial consistency often degrades 3D mesh quality in\nsurface reconstruction. To address this, we propose LoomNet, a novel multi-view\ndiffusion architecture that produces coherent images by applying the same\ndiffusion model multiple times in parallel to collaboratively build and\nleverage a shared latent space for view consistency. Each viewpoint-specific\ninference generates an encoding representing its own hypothesis of the novel\nview from a given camera pose, which is projected onto three orthogonal planes.\nFor each plane, encodings from all views are fused into a single aggregated\nplane. These aggregated planes are then processed to propagate information and\ninterpolate missing regions, combining the hypotheses into a unified, coherent\ninterpretation. The final latent space is then used to render consistent\nmulti-view images. LoomNet generates 16 high-quality and coherent views in just\n15 seconds. In our experiments, LoomNet outperforms state-of-the-art methods on\nboth image quality and reconstruction metrics, also showing creativity by\nproducing diverse, plausible novel views from the same input.", "published": "2025-07-07 21:46:50", "link": "http://arxiv.org/abs/2507.05499v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cloud Diffusion Part 1: Theory and Motivation", "abstract": "Diffusion models for image generation function by progressively adding noise\nto an image set and training a model to separate out the signal from the noise.\nThe noise profile used by these models is white noise -- that is, noise based\non independent normal distributions at each point whose mean and variance is\nindependent of the scale. By contrast, most natural image sets exhibit a type\nof scale invariance in their low-order statistical properties characterized by\na power-law scaling. Consequently, natural images are closer (in a quantifiable\nsense) to a different probability distribution that emphasizes large scale\ncorrelations and de-emphasizes small scale correlations. These scale invariant\nnoise profiles can be incorporated into diffusion models in place of white\nnoise to form what we will call a ``Cloud Diffusion Model\". We argue that these\nmodels can lead to faster inference, improved high-frequency details, and\ngreater controllability. In a follow-up paper, we will build and train a Cloud\nDiffusion Model that uses scale invariance at a fundamental level and compare\nit to classic, white noise diffusion models.", "published": "2025-07-07 21:36:16", "link": "http://arxiv.org/abs/2507.05496v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Driving as a Diagnostic Tool: Scenario-based Cognitive Assessment in Older Drivers From Driving Video", "abstract": "We introduce scenario-based cognitive status identification in older drivers\nfrom Naturalistic driving videos and large vision models. In recent times,\ncognitive decline, including Alzheimer's disease (AD) and mild cognitive\nimpairment (MCI), is often underdiagnosed due to the time-consuming and costly\nnature of current diagnostic methods. By analyzing real-world driving behavior\ncaptured through in-vehicle systems, this research aims to extract \"digital\nfingerprints\" that correlate with functional decline and clinical features of\nMCI and AD. Moreover, modern large vision models can draw meaningful insights\nfrom everyday driving patterns of older patients to early detect cognitive\ndecline. We propose a framework that uses large vision models and naturalistic\ndriving videos to analyze driver behavior, classify cognitive status and\npredict disease progression. We leverage the strong relationship between\nreal-world driving behavior as an observation of the current cognitive status\nof the drivers where the vehicle can be utilized as a \"diagnostic tool\". Our\nmethod identifies early warning signs of functional impairment, contributing to\nproactive intervention strategies. This work enhances early detection and\nsupports the development of scalable, non-invasive monitoring systems to\nmitigate the growing societal and economic burden of cognitive decline in the\naging population.", "published": "2025-07-07 20:30:00", "link": "http://arxiv.org/abs/2507.05463v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Self-supervised Deep Learning for Denoising in Ultrasound Microvascular Imaging", "abstract": "Ultrasound microvascular imaging (UMI) is often hindered by low\nsignal-to-noise ratio (SNR), especially in contrast-free or deep tissue\nscenarios, which impairs subsequent vascular quantification and reliable\ndisease diagnosis. To address this challenge, we propose\nHalf-Angle-to-Half-Angle (HA2HA), a self-supervised denoising framework\nspecifically designed for UMI. HA2HA constructs training pairs from\ncomplementary angular subsets of beamformed radio-frequency (RF) blood flow\ndata, across which vascular signals remain consistent while noise varies. HA2HA\nwas trained using in-vivo contrast-free pig kidney data and validated across\ndiverse datasets, including contrast-free and contrast-enhanced data from pig\nkidneys, as well as human liver and kidney. An improvement exceeding 15 dB in\nboth contrast-to-noise ratio (CNR) and SNR was observed, indicating a\nsubstantial enhancement in image quality. In addition to power Doppler imaging,\ndenoising directly in the RF domain is also beneficial for other downstream\nprocessing such as color Doppler imaging (CDI). CDI results of human liver\nderived from the HA2HA-denoised signals exhibited improved microvascular flow\nvisualization, with a suppressed noisy background. HA2HA offers a label-free,\ngeneralizable, and clinically applicable solution for robust vascular imaging\nin both contrast-free and contrast-enhanced UMI.", "published": "2025-07-07 20:08:39", "link": "http://arxiv.org/abs/2507.05451v1", "categories": ["eess.IV", "cs.CV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones", "abstract": "Two-factor authentication (2FA) has become widely adopted as an efficient and\nsecure way to validate someone's identity online. Two-factor authentication is\ndifficult in virtual reality (VR) because users are usually wearing a\nhead-mounted display (HMD) which does not allow them to see their real-world\nsurroundings. We present NRXR-ID, a technique to implement two-factor\nauthentication while using extended reality systems and smartphones. The\nproposed method allows users to complete an authentication challenge using\ntheir smartphones without removing their HMD. We performed a user study where\nwe explored four types of challenges for users, including a novel\ncheckers-style challenge. Users responded to these challenges under three\ndifferent configurations, including a technique that uses the smartphone to\nsupport gaze-based selection without the use of VR controllers. A 4X3\nwithin-subjects design allowed us to study all the variations proposed. We\ncollected performance metrics and performed user experience questionnaires to\ncollect subjective impressions from 30 participants. Results suggest that the\ncheckers-style visual matching challenge was the most appropriate option,\nfollowed by entering a digital PIN challenge submitted via the smartphone and\nanswered within the VR environment.", "published": "2025-07-07 20:00:09", "link": "http://arxiv.org/abs/2507.05447v1", "categories": ["cs.HC", "cs.CV", "cs.GR"], "primary_category": "cs.HC"}
{"title": "Robotic System with AI for Real Time Weed Detection, Canopy Aware Spraying, and Droplet Pattern Evaluation", "abstract": "Uniform and excessive herbicide application in modern agriculture contributes\nto increased input costs, environmental pollution, and the emergence of\nherbicide resistant weeds. To address these challenges, we developed a vision\nguided, AI-driven variable rate sprayer system capable of detecting weed\npresence, estimating canopy size, and dynamically adjusting nozzle activation\nin real time. The system integrates lightweight YOLO11n and YOLO11n-seg deep\nlearning models, deployed on an NVIDIA Jetson Orin Nano for onboard inference,\nand uses an Arduino Uno-based relay interface to control solenoid actuated\nnozzles based on canopy segmentation results. Indoor trials were conducted\nusing 15 potted Hibiscus rosa sinensis plants of varying canopy sizes to\nsimulate a range of weed patch scenarios. The YOLO11n model achieved a mean\naverage precision (mAP@50) of 0.98, with a precision of 0.99 and a recall close\nto 1.0. The YOLO11n-seg segmentation model achieved a mAP@50 of 0.48, precision\nof 0.55, and recall of 0.52. System performance was validated using water\nsensitive paper, which showed an average spray coverage of 24.22% in zones\nwhere canopy was present. An upward trend in mean spray coverage from 16.22%\nfor small canopies to 21.46% and 21.65% for medium and large canopies,\nrespectively, demonstrated the system's capability to adjust spray output based\non canopy size in real time. These results highlight the potential of combining\nreal time deep learning with low-cost embedded hardware for selective herbicide\napplication. Future work will focus on expanding the detection capabilities to\ninclude three common weed species in South Dakota: water hemp (Amaranthus\ntuberculatus), kochia (Bassia scoparia), and foxtail (Setaria spp.), followed\nby further validation in both indoor and field trials within soybean and corn\nproduction systems.", "published": "2025-07-07 19:27:29", "link": "http://arxiv.org/abs/2507.05432v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts", "abstract": "The ability to segment objects based on open-ended language prompts remains a\ncritical challenge, requiring models to ground textual semantics into precise\nspatial masks while handling diverse and unseen categories. We present\nOpenWorldSAM, a framework that extends the prompt-driven Segment Anything Model\nv2 (SAM2) to open-vocabulary scenarios by integrating multi-modal embeddings\nextracted from a lightweight vision-language model (VLM). Our approach is\nguided by four key principles: i) Unified prompting: OpenWorldSAM supports a\ndiverse range of prompts, including category-level and sentence-level language\ndescriptions, providing a flexible interface for various segmentation tasks.\nii) Efficiency: By freezing the pre-trained components of SAM2 and the VLM, we\ntrain only 4.5 million parameters on the COCO-stuff dataset, achieving\nremarkable resource efficiency. iii) Instance Awareness: We enhance the model's\nspatial understanding through novel positional tie-breaker embeddings and\ncross-attention layers, enabling effective segmentation of multiple instances.\niv) Generalization: OpenWorldSAM exhibits strong zero-shot capabilities,\ngeneralizing well on unseen categories and an open vocabulary of concepts\nwithout additional training. Extensive experiments demonstrate that\nOpenWorldSAM achieves state-of-the-art performance in open-vocabulary semantic,\ninstance, and panoptic segmentation across multiple benchmarks, including\nADE20k, PASCAL, ScanNet, and SUN-RGBD.", "published": "2025-07-07 19:16:22", "link": "http://arxiv.org/abs/2507.05427v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors", "abstract": "Many 3D scene editing tasks focus on modifying local regions rather than the\nentire scene, except for some global applications like style transfer, and in\nthe context of 3D Gaussian Splatting (3DGS), where scenes are represented by a\nseries of Gaussians, this structure allows for precise regional edits, offering\nenhanced control over specific areas of the scene; however, the challenge lies\nin the fact that 3D semantic parsing often underperforms compared to its 2D\ncounterpart, making targeted manipulations within 3D spaces more difficult and\nlimiting the fidelity of edits, which we address by leveraging 2D diffusion\nediting to accurately identify modification regions in each view, followed by\ninverse rendering for 3D localization, then refining the frontal view and\ninitializing a coarse 3DGS with consistent views and approximate shapes derived\nfrom depth maps predicted by a 2D foundation model, thereby supporting an\niterative, view-consistent editing process that gradually enhances structural\ndetails and textures to ensure coherence across perspectives. Experiments\ndemonstrate that our method achieves state-of-the-art performance while\ndelivering up to a $4\\times$ speedup, providing a more efficient and effective\napproach to 3D scene local editing.", "published": "2025-07-07 19:15:43", "link": "http://arxiv.org/abs/2507.05426v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Motion Generation: A Survey of Generative Approaches and Benchmarks", "abstract": "Motion generation, the task of synthesizing realistic motion sequences from\nvarious conditioning inputs, has become a central problem in computer vision,\ncomputer graphics, and robotics, with applications ranging from animation and\nvirtual agents to human-robot interaction. As the field has rapidly progressed\nwith the introduction of diverse modeling paradigms including GANs,\nautoencoders, autoregressive models, and diffusion-based techniques, each\napproach brings its own advantages and limitations. This growing diversity has\ncreated a need for a comprehensive and structured review that specifically\nexamines recent developments from the perspective of the generative approach\nemployed.\n  In this survey, we provide an in-depth categorization of motion generation\nmethods based on their underlying generative strategies. Our main focus is on\npapers published in top-tier venues since 2023, reflecting the most recent\nadvancements in the field. In addition, we analyze architectural principles,\nconditioning mechanisms, and generation settings, and compile a detailed\noverview of the evaluation metrics and datasets used across the literature. Our\nobjective is to enable clearer comparisons and identify open challenges,\nthereby offering a timely and foundational reference for researchers and\npractitioners navigating the rapidly evolving landscape of motion generation.", "published": "2025-07-07 19:04:56", "link": "http://arxiv.org/abs/2507.05419v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Neural-Driven Image Editing", "abstract": "Traditional image editing typically relies on manual prompting, making it\nlabor-intensive and inaccessible to individuals with limited motor control or\nlanguage abilities. Leveraging recent advances in brain-computer interfaces\n(BCIs) and generative models, we propose LoongX, a hands-free image editing\napproach driven by multimodal neurophysiological signals. LoongX utilizes\nstate-of-the-art diffusion models trained on a comprehensive dataset of 23,928\nimage editing pairs, each paired with synchronized electroencephalography\n(EEG), functional near-infrared spectroscopy (fNIRS), photoplethysmography\n(PPG), and head motion signals that capture user intent. To effectively address\nthe heterogeneity of these signals, LoongX integrates two key modules. The\ncross-scale state space (CS3) module encodes informative modality-specific\nfeatures. The dynamic gated fusion (DGF) module further aggregates these\nfeatures into a unified latent space, which is then aligned with edit semantics\nvia fine-tuning on a diffusion transformer (DiT). Additionally, we pre-train\nthe encoders using contrastive learning to align cognitive states with semantic\nintentions from embedded natural language. Extensive experiments demonstrate\nthat LoongX achieves performance comparable to text-driven methods (CLIP-I:\n0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636) and outperforms them when neural\nsignals are combined with speech (CLIP-T: 0.2588 vs. 0.2549). These results\nhighlight the promise of neural-driven generative models in enabling\naccessible, intuitive image editing and open new directions for\ncognitive-driven creative technologies. Datasets and code will be released to\nsupport future work and foster progress in this emerging area.", "published": "2025-07-07 18:31:50", "link": "http://arxiv.org/abs/2507.05397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models", "abstract": "Vision-Language Models (VLMs) like CLIP have demonstrated remarkable\ngeneralization in zero- and few-shot settings, but adapting them efficiently to\ndecentralized, heterogeneous data remains a challenge. While prompt tuning has\nemerged as a popular parameter-efficient approach in personalized federated\nlearning, existing methods often sacrifice generalization in favor of\npersonalization, struggling particularly on unseen classes or domains. In this\nwork, we propose pFedMMA, the first personalized federated learning framework\nthat leverages multi-modal adapters for vision-language tasks. Each adapter\ncontains modality-specific up- and down-projection layers alongside a globally\nshared projection that aligns cross-modal features. Our asymmetric optimization\nstrategy allows clients to locally adapt to personalized data distributions\nwhile collaboratively training the shared projection to improve global\ngeneralization. This design is also communication-efficient, as only the shared\ncomponent is exchanged during rounds. Through extensive experiments across\neleven datasets, including domain- and label-shift scenarios, we show that\npFedMMA achieves state-of-the-art trade-offs between personalization and\ngeneralization, outperforming recent federated prompt tuning methods. The code\nis available at https://github.com/sajjad-ucsb/pFedMMA.", "published": "2025-07-07 18:26:34", "link": "http://arxiv.org/abs/2507.05394v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enhancing Underwater Images Using Deep Learning with Subjective Image Quality Integration", "abstract": "Recent advances in deep learning, particularly neural networks, have\nsignificantly impacted a wide range of fields, including the automatic\nenhancement of underwater images. This paper presents a deep learning-based\napproach to improving underwater image quality by integrating human subjective\nassessments into the training process. To this end, we utilize publicly\navailable datasets containing underwater images labeled by experts as either\nhigh or low quality. Our method involves first training a classifier network to\ndistinguish between high- and low-quality images. Subsequently, generative\nadversarial networks (GANs) are trained using various enhancement criteria to\nrefine the low-quality images. The performance of the GAN models is evaluated\nusing quantitative metrics such as PSNR, SSIM, and UIQM, as well as through\nqualitative analysis. Results demonstrate that the proposed model --\nparticularly when incorporating criteria such as color fidelity and image\nsharpness -- achieves substantial improvements in both perceived and measured\nimage quality.", "published": "2025-07-07 18:25:13", "link": "http://arxiv.org/abs/2507.05393v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "From General to Specialized: The Need for Foundational Models in Agriculture", "abstract": "Food security remains a global concern as population grows and climate change\nintensifies, demanding innovative solutions for sustainable agricultural\nproductivity. Recent advances in foundation models have demonstrated remarkable\nperformance in remote sensing and climate sciences, and therefore offer new\nopportunities for agricultural monitoring. However, their application in\nchallenges related to agriculture-such as crop type mapping, crop phenology\nestimation, and crop yield estimation-remains under-explored. In this work, we\nquantitatively evaluate existing foundational models to assess their\neffectivity for a representative set of agricultural tasks. From an\nagricultural domain perspective, we describe a requirements framework for an\nideal agricultural foundation model (CropFM). We then survey and compare\nexisting general-purpose foundational models in this framework and empirically\nevaluate two exemplary of them in three representative agriculture specific\ntasks. Finally, we highlight the need for a dedicated foundational model\ntailored specifically to agriculture.", "published": "2025-07-07 18:22:22", "link": "http://arxiv.org/abs/2507.05390v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Foreground-aware Virtual Staining for Accurate 3D Cell Morphological Profiling", "abstract": "Microscopy enables direct observation of cellular morphology in 3D, with\ntransmitted-light methods offering low-cost, minimally invasive imaging and\nfluorescence microscopy providing specificity and contrast. Virtual staining\ncombines these strengths by using machine learning to predict fluorescence\nimages from label-free inputs. However, training of existing methods typically\nrelies on loss functions that treat all pixels equally, thus reproducing\nbackground noise and artifacts instead of focusing on biologically meaningful\nsignals. We introduce Spotlight, a simple yet powerful virtual staining\napproach that guides the model to focus on relevant cellular structures.\nSpotlight uses histogram-based foreground estimation to mask pixel-wise loss\nand to calculate a Dice loss on soft-thresholded predictions for shape-aware\nlearning. Applied to a 3D benchmark dataset, Spotlight improves morphological\nrepresentation while preserving pixel-level accuracy, resulting in virtual\nstains better suited for downstream tasks such as segmentation and profiling.", "published": "2025-07-07 18:11:56", "link": "http://arxiv.org/abs/2507.05383v1", "categories": ["cs.CV", "q-bio.QM", "I.4.9; J.3"], "primary_category": "cs.CV"}
{"title": "YOLO-APD: Enhancing YOLOv8 for Robust Pedestrian Detection on Complex Road Geometries", "abstract": "Autonomous vehicle perception systems require robust pedestrian detection,\nparticularly on geometrically complex roadways like Type-S curved surfaces,\nwhere standard RGB camera-based methods face limitations. This paper introduces\nYOLO-APD, a novel deep learning architecture enhancing the YOLOv8 framework\nspecifically for this challenge. YOLO-APD integrates several key architectural\nmodifications: a parameter-free SimAM attention mechanism, computationally\nefficient C3Ghost modules, a novel SimSPPF module for enhanced multi-scale\nfeature pooling, the Mish activation function for improved optimization, and an\nIntelligent Gather & Distribute (IGD) module for superior feature fusion in the\nnetwork's neck. The concept of leveraging vehicle steering dynamics for\nadaptive region-of-interest processing is also presented. Comprehensive\nevaluations on a custom CARLA dataset simulating complex scenarios demonstrate\nthat YOLO-APD achieves state-of-the-art detection accuracy, reaching 77.7%\nmAP@0.5:0.95 and exceptional pedestrian recall exceeding 96%, significantly\noutperforming baseline models, including YOLOv8. Furthermore, it maintains\nreal-time processing capabilities at 100 FPS, showcasing a superior balance\nbetween accuracy and efficiency. Ablation studies validate the synergistic\ncontribution of each integrated component. Evaluation on the KITTI dataset\nconfirms the architecture's potential while highlighting the need for domain\nadaptation. This research advances the development of highly accurate,\nefficient, and adaptable perception systems based on cost-effective sensors,\ncontributing to enhanced safety and reliability for autonomous navigation in\nchallenging, less-structured driving environments.", "published": "2025-07-07 18:03:40", "link": "http://arxiv.org/abs/2507.05376v1", "categories": ["cs.CV", "I.4.8; I.2.6; I.2.9"], "primary_category": "cs.CV"}
{"title": "Information Needs and Practices Supported by ChatGPT", "abstract": "This study considers ChatGPT as an information source, investigating the\ninformation needs that people come to ChatGPT with and the information\npractices that ChatGPT supports, through a qualitative content analysis of 205\nuser vignettes. The findings show that ChatGPT is used in a range of life\ndomains (home/family, work, leisure, etc.) and for a range of human needs\n(writing/editing, learning, simple programming tasks, etc.), constituting the\ninformation needs that people use ChatGPT to address. Related to these\ninformation needs, the findings show six categories of information practices\nthat ChatGPT supports: Writing, Deciding, Identifying, Ideating, Talking, and\nCritiquing. This work suggests that, in the AI age, information need should be\nconceptualized not just as a matter of \"getting questions answered\" or even\n\"making sense,\" but as skillfully coping in the world, a notion that includes\nboth understanding and action. This study leads to numerous opportunities for\nfuture work at the junction of generative AI and information needs, seeking,\nuse and experience.", "published": "2025-07-07 23:21:20", "link": "http://arxiv.org/abs/2507.05537v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "PLACE: Prompt Learning for Attributed Community Search", "abstract": "In this paper, we propose PLACE (Prompt Learning for Attributed Community\nSearch), an innovative graph prompt learning framework for ACS. Enlightened by\nprompt-tuning in Natural Language Processing (NLP), where learnable prompt\ntokens are inserted to contextualize NLP queries, PLACE integrates structural\nand learnable prompt tokens into the graph as a query-dependent refinement\nmechanism, forming a prompt-augmented graph. Within this prompt-augmented graph\nstructure, the learned prompt tokens serve as a bridge that strengthens\nconnections between graph nodes for the query, enabling the GNN to more\neffectively identify patterns of structural cohesiveness and attribute\nsimilarity related to the specific query. We employ an alternating training\nparadigm to optimize both the prompt parameters and the GNN jointly. Moreover,\nwe design a divide-and-conquer strategy to enhance scalability, supporting the\nmodel to handle million-scale graphs. Extensive experiments on 9 real-world\ngraphs demonstrate the effectiveness of PLACE for three types of ACS queries,\nwhere PLACE achieves higher F1 scores by 22% compared to the state-of-the-arts\non average.", "published": "2025-07-07 09:48:09", "link": "http://arxiv.org/abs/2507.05311v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "News Source Citing Patterns in AI Search Systems", "abstract": "AI-powered search systems are emerging as new information gatekeepers,\nfundamentally transforming how users access news and information. Despite their\ngrowing influence, the citation patterns of these systems remain poorly\nunderstood. We address this gap by analyzing data from the AI Search Arena, a\nhead-to-head evaluation platform for AI search systems. The dataset comprises\nover 24,000 conversations and 65,000 responses from models across three major\nproviders: OpenAI, Perplexity, and Google. Among the over 366,000 citations\nembedded in these responses, 9% reference news sources. We find that while\nmodels from different providers cite distinct news sources, they exhibit shared\npatterns in citation behavior. News citations concentrate heavily among a small\nnumber of outlets and display a pronounced liberal bias, though low-credibility\nsources are rarely cited. User preference analysis reveals that neither the\npolitical leaning nor the quality of cited news sources significantly\ninfluences user satisfaction. These findings reveal significant challenges in\ncurrent AI search systems and have important implications for their design and\ngovernance.", "published": "2025-07-07 02:17:57", "link": "http://arxiv.org/abs/2507.05301v1", "categories": ["cs.IR", "cs.CL", "cs.CY"], "primary_category": "cs.IR"}
{"title": "Robust Learning on Noisy Graphs via Latent Space Constraints with External Knowledge", "abstract": "Graph Neural Networks (GNNs) often struggle with noisy edges. We propose\nLatent Space Constrained Graph Neural Networks (LSC-GNN) to incorporate\nexternal \"clean\" links and guide embeddings of a noisy target graph. We train\ntwo encoders--one on the full graph (target plus external edges) and another on\na regularization graph excluding the target's potentially noisy links--then\npenalize discrepancies between their latent representations. This constraint\nsteers the model away from overfitting spurious edges. Experiments on benchmark\ndatasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphs\nsubjected to moderate noise. We extend LSC-GNN to heterogeneous graphs and\nvalidate it on a small protein-metabolite network, where metabolite-protein\ninteractions reduce noise in protein co-occurrence data. Our results highlight\nLSC-GNN's potential to boost predictive performance and interpretability in\nsettings with noisy relational structures.", "published": "2025-07-07 23:43:24", "link": "http://arxiv.org/abs/2507.05540v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Special-Unitary Parameterization for Trainable Variational Quantum Circuits", "abstract": "We propose SUN-VQC, a variational-circuit architecture whose elementary\nlayers are single exponentials of a symmetry-restricted Lie subgroup,\n$\\mathrm{SU}(2^{k}) \\subset \\mathrm{SU}(2^{n})$ with $k \\ll n$. Confining the\nevolution to this compact subspace reduces the dynamical Lie-algebra dimension\nfrom $\\mathcal{O}(4^{n})$ to $\\mathcal{O}(4^{k})$, ensuring only polynomial\nsuppression of gradient variance and circumventing barren plateaus that plague\nhardware-efficient ans\\\"atze. Exact, hardware-compatible gradients are obtained\nusing a generalized parameter-shift rule, avoiding ancillary qubits and\nfinite-difference bias. Numerical experiments on quantum auto-encoding and\nclassification show that SUN-VQCs sustain order-of-magnitude larger gradient\nsignals, converge 2--3$\\times$ faster, and reach higher final fidelities than\ndepth-matched Pauli-rotation or hardware-efficient circuits. These results\ndemonstrate that Lie-subalgebra engineering provides a principled, scalable\nroute to barren-plateau-resilient VQAs compatible with near-term quantum\nprocessors.", "published": "2025-07-07 23:21:02", "link": "http://arxiv.org/abs/2507.05535v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Theoretical Learning Performance of Graph Neural Networks: The Impact of Jumping Connections and Layer-wise Sparsification", "abstract": "Jumping connections enable Graph Convolutional Networks (GCNs) to overcome\nover-smoothing, while graph sparsification reduces computational demands by\nselecting a sub-matrix of the graph adjacency matrix during neighborhood\naggregation. Learning GCNs with graph sparsification has shown empirical\nsuccess across various applications, but a theoretical understanding of the\ngeneralization guarantees remains limited, with existing analyses ignoring\neither graph sparsification or jumping connections. This paper presents the\nfirst learning dynamics and generalization analysis of GCNs with jumping\nconnections using graph sparsification. Our analysis demonstrates that the\ngeneralization accuracy of the learned model closely approximates the highest\nachievable accuracy within a broad class of target functions dependent on the\nproposed sparse effective adjacency matrix $A^*$. Thus, graph sparsification\nmaintains generalization performance when $A^*$ preserves the essential edges\nthat support meaningful message propagation. We reveal that jumping connections\nlead to different sparsification requirements across layers. In a\ntwo-hidden-layer GCN, the generalization is more affected by the sparsified\nmatrix deviations from $A^*$ of the first layer than the second layer. To the\nbest of our knowledge, this marks the first theoretical characterization of\njumping connections' role in sparsification requirements. We validate our\ntheoretical results on benchmark datasets in deep GCNs.", "published": "2025-07-07 23:10:53", "link": "http://arxiv.org/abs/2507.05533v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bit-Flip Fault Attack: Crushing Graph Neural Networks via Gradual Bit Search", "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful machine learning\nmethod for graph-structured data. A plethora of hardware accelerators has been\nintroduced to meet the performance demands of GNNs in real-world applications.\nHowever, security challenges of hardware-based attacks have been generally\noverlooked. In this paper, we investigate the vulnerability of GNN models to\nhardware-based fault attack, wherein an attacker attempts to misclassify output\nby modifying trained weight parameters through fault injection in a memory\ndevice. Thus, we propose Gradual Bit-Flip Fault Attack (GBFA), a layer-aware\nbit-flip fault attack, selecting a vulnerable bit in each selected weight\ngradually to compromise the GNN's performance by flipping a minimal number of\nbits. To achieve this, GBFA operates in two steps. First, a Markov model is\ncreated to predict the execution sequence of layers based on features extracted\nfrom memory access patterns, enabling the launch of the attack within a\nspecific layer. Subsequently, GBFA identifies vulnerable bits within the\nselected weights using gradient ranking through an in-layer search. We evaluate\nthe effectiveness of the proposed GBFA attack on various GNN models for node\nclassification tasks using the Cora and PubMed datasets. Our findings show that\nGBFA significantly degrades prediction accuracy, and the variation in its\nimpact across different layers highlights the importance of adopting a\nlayer-aware attack strategy in GNNs. For example, GBFA degrades GraphSAGE's\nprediction accuracy by 17% on the Cora dataset with only a single bit flip in\nthe last layer.", "published": "2025-07-07 23:06:29", "link": "http://arxiv.org/abs/2507.05531v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Mitigating Shortcut Learning with InterpoLated Learning", "abstract": "Empirical risk minimization (ERM) incentivizes models to exploit shortcuts,\ni.e., spurious correlations between input attributes and labels that are\nprevalent in the majority of the training data but unrelated to the task at\nhand. This reliance hinders generalization on minority examples, where such\ncorrelations do not hold. Existing shortcut mitigation approaches are\nmodel-specific, difficult to tune, computationally expensive, and fail to\nimprove learned representations. To address these issues, we propose\nInterpoLated Learning (InterpoLL) which interpolates the representations of\nmajority examples to include features from intra-class minority examples with\nshortcut-mitigating patterns. This weakens shortcut influence, enabling models\nto acquire features predictive across both minority and majority examples.\nExperimental results on multiple natural language understanding tasks\ndemonstrate that InterpoLL improves minority generalization over both ERM and\nstate-of-the-art shortcut mitigation methods, without compromising accuracy on\nmajority examples. Notably, these gains persist across encoder,\nencoder-decoder, and decoder-only architectures, demonstrating the method's\nbroad applicability.", "published": "2025-07-07 22:49:46", "link": "http://arxiv.org/abs/2507.05527v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Estimating Interventional Distributions with Uncertain Causal Graphs through Meta-Learning", "abstract": "In scientific domains -- from biology to the social sciences -- many\nquestions boil down to \\textit{What effect will we observe if we intervene on a\nparticular variable?} If the causal relationships (e.g.~a causal graph) are\nknown, it is possible to estimate the intervention distributions. In the\nabsence of this domain knowledge, the causal structure must be discovered from\nthe available observational data. However, observational data are often\ncompatible with multiple causal graphs, making methods that commit to a single\nstructure prone to overconfidence. A principled way to manage this structural\nuncertainty is via Bayesian inference, which averages over a posterior\ndistribution on possible causal structures and functional mechanisms.\nUnfortunately, the number of causal structures grows super-exponentially with\nthe number of nodes in the graph, making computations intractable. We propose\nto circumvent these challenges by using meta-learning to create an end-to-end\nmodel: the Model-Averaged Causal Estimation Transformer Neural Process\n(MACE-TNP). The model is trained to predict the Bayesian model-averaged\ninterventional posterior distribution, and its end-to-end nature bypasses the\nneed for expensive calculations. Empirically, we demonstrate that MACE-TNP\noutperforms strong Bayesian baselines. Our work establishes meta-learning as a\nflexible and scalable paradigm for approximating complex Bayesian causal\ninference, that can be scaled to increasingly challenging settings in the\nfuture.", "published": "2025-07-07 22:48:32", "link": "http://arxiv.org/abs/2507.05526v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep Learning of Continuous and Structured Policies for Aggregated Heterogeneous Treatment Effects", "abstract": "As estimation of Heterogeneous Treatment Effect (HTE) is increasingly adopted\nacross a wide range of scientific and industrial applications, the treatment\naction space can naturally expand, from a binary treatment variable to a\nstructured treatment policy. This policy may include several policy factors\nsuch as a continuous treatment intensity variable, or discrete treatment\nassignments. From first principles, we derive the formulation for incorporating\nmultiple treatment policy variables into the functional forms of individual and\naverage treatment effects. Building on this, we develop a methodology to\ndirectly rank subjects using aggregated HTE functions. In particular, we\nconstruct a Neural-Augmented Naive Bayes layer within a deep learning framework\nto incorporate an arbitrary number of factors that satisfies the Naive Bayes\nassumption. The factored layer is then applied with continuous treatment\nvariables, treatment assignment, and direct ranking of aggregated treatment\neffect functions. Together, these algorithms build towards a generic framework\nfor deep learning of heterogeneous treatment policies, and we show their power\nto improve performance with public datasets.", "published": "2025-07-07 22:14:24", "link": "http://arxiv.org/abs/2507.05511v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth", "abstract": "User growth is a major strategy for consumer internet companies. To optimize\ncostly marketing campaigns and maximize user engagement, we propose a novel\ntreatment effect optimization methodology to enhance user growth marketing. By\nleveraging deep learning, our algorithm learns from past experiments to\noptimize user selection and reward allocation, maximizing campaign impact while\nminimizing costs. Unlike traditional prediction methods, our model directly\nmodels uplifts in key business metrics. Further, our deep learning model can\njointly optimize parameters for an aggregated loss function using softmax\ngating. Our approach surpasses traditional methods by directly targeting\ndesired business metrics and demonstrates superior algorithmic flexibility in\nhandling complex business constraints. Comprehensive evaluations, including\ncomparisons with state-of-the-art techniques such as R-learner and Causal\nForest, validate the effectiveness of our model. We experimentally demonstrate\nthat our proposed constrained and direct optimization algorithms significantly\noutperform state-of-the-art methods by over $20\\%$, proving their\ncost-efficiency and real-world impact. The versatile methods can be applied to\nvarious product scenarios, including optimal treatment allocation. Its\neffectiveness has also been validated through successful worldwide production\ndeployments.", "published": "2025-07-07 22:08:45", "link": "http://arxiv.org/abs/2507.05510v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Beyond Communication Overhead: A Multilevel Monte Carlo Approach for Mitigating Compression Bias in Distributed Learning", "abstract": "Distributed learning methods have gained substantial momentum in recent\nyears, with communication overhead often emerging as a critical bottleneck.\nGradient compression techniques alleviate communication costs but involve an\ninherent trade-off between the empirical efficiency of biased compressors and\nthe theoretical guarantees of unbiased compressors. In this work, we introduce\na novel Multilevel Monte Carlo (MLMC) compression scheme that leverages biased\ncompressors to construct statistically unbiased estimates. This approach\neffectively bridges the gap between biased and unbiased methods, combining the\nstrengths of both. To showcase the versatility of our method, we apply it to\npopular compressors, like Top-$k$ and bit-wise compressors, resulting in\nenhanced variants. Furthermore, we derive an adaptive version of our approach\nto further improve its performance. We validate our method empirically on\ndistributed deep learning tasks.", "published": "2025-07-07 22:06:04", "link": "http://arxiv.org/abs/2507.05508v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamic Campus Origin-Destination Mobility Prediction using Graph Convolutional Neural Network on WiFi Logs", "abstract": "We present an integrated graph-based neural networks architecture for\npredicting campus buildings occupancy and inter-buildings movement at dynamic\ntemporal resolution that learns traffic flow patterns from Wi-Fi logs combined\nwith the usage schedules within the buildings. The relative traffic flows are\ndirectly estimated from the WiFi data without assuming the occupant behaviour\nor preferences while maintaining individual privacy. We formulate the problem\nas a data-driven graph structure represented by a set of nodes (representing\nbuildings), connected through a route of edges or links using a novel Graph\nConvolution plus LSTM Neural Network (GCLSTM) which has shown remarkable\nsuccess in modelling complex patterns. We describe the formulation, model\nestimation, interpretability and examine the relative performance of our\nproposed model. We also present an illustrative architecture of the models and\napply on real-world WiFi logs collected at the Toronto Metropolitan University\ncampus. The results of the experiments show that the integrated GCLSTM models\nsignificantly outperform traditional pedestrian flow estimators like the Multi\nLayer Perceptron (MLP) and Linear Regression.", "published": "2025-07-07 22:04:43", "link": "http://arxiv.org/abs/2507.05507v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predicting mutational effects on protein binding from folding energy", "abstract": "Accurate estimation of mutational effects on protein-protein binding energies\nis an open problem with applications in structural biology and therapeutic\ndesign. Several deep learning predictors for this task have been proposed, but,\npresumably due to the scarcity of binding data, these methods underperform\ncomputationally expensive estimates based on empirical force fields. In\nresponse, we propose a transfer-learning approach that leverages advances in\nprotein sequence modeling and folding stability prediction for this task. The\nkey idea is to parameterize the binding energy as the difference between the\nfolding energy of the protein complex and the sum of the folding energies of\nits binding partners. We show that using a pre-trained inverse-folding model as\na proxy for folding energy provides strong zero-shot performance, and can be\nfine-tuned with (1) copious folding energy measurements and (2) more limited\nbinding energy measurements. The resulting predictor, StaB-ddG, is the first\ndeep learning predictor to match the accuracy of the state-of-the-art empirical\nforce-field method FoldX, while offering an over 1,000x speed-up.", "published": "2025-07-07 21:55:57", "link": "http://arxiv.org/abs/2507.05502v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Inaugural MOASEI Competition at AAMAS'2025: A Technical Report", "abstract": "We present the Methods for Open Agent Systems Evaluation Initiative (MOASEI)\nCompetition, a multi-agent AI benchmarking event designed to evaluate\ndecision-making under open-world conditions. Built on the free-range-zoo\nenvironment suite, MOASEI introduced dynamic, partially observable domains with\nagent and task openness--settings where entities may appear, disappear, or\nchange behavior over time. The 2025 competition featured three\ntracks--Wildfire, Rideshare, and Cybersecurity--each highlighting distinct\ndimensions of openness and coordination complexity. Eleven teams from\ninternational institutions participated, with four of those teams submitting\ndiverse solutions including graph neural networks, convolutional architectures,\npredictive modeling, and large language model--driven meta--optimization.\nEvaluation metrics centered on expected utility, robustness to perturbations,\nand responsiveness to environmental change. The results reveal promising\nstrategies for generalization and adaptation in open environments, offering\nboth empirical insight and infrastructure for future research. This report\ndetails the competition's design, findings, and contributions to the open-agent\nsystems research community.", "published": "2025-07-07 20:44:16", "link": "http://arxiv.org/abs/2507.05469v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Approximate direct and inverse scattering for the AKNS system", "abstract": "We study the direct and inverse scattering problems for the AKNS\n(Ablowitz-Kaup-Newell-Segur) system. New representations for the Jost solutions\nare obtained in the form of the power series in terms of a transformed spectral\nparameter. In terms of that parameter, the Jost solutions are convergent power\nseries in corresponding unit disks. For the coefficients of the series simple\nrecurrent integration procedures are devised. Solution of the direct scattering\nproblem reduces to computing the coefficients and locating zeros of\ncorresponding analytic functions in the interior of the unit disk. Solution of\nthe inverse scattering problem reduces to the solution of two systems of linear\nalgebraic equations for the power series coefficients, while the potentials are\nrecovered from the first coefficients. The overall approach leads to a simple\nand efficient method for the numerical solution of both direct and inverse\nscattering problems, which is illustrated by numerical examples.", "published": "2025-07-07 22:45:04", "link": "http://arxiv.org/abs/2507.05525v1", "categories": ["math.CA", "cs.NA", "math-ph", "math.MP", "math.NA", "nlin.SI", "physics.optics"], "primary_category": "math.CA"}
{"title": "Notes on $L^2$-estimates in linear elliptic equations with general coefficients", "abstract": "This paper establishes an explicit $L^2$-estimate for weak solutions $u$ to\nlinear elliptic equations in divergence form with general coefficients and\nexternal source term $f$, stating that the $L^2$-norm of $u$ over $U$ is\nbounded by a constant multiple of the $L^2$-norm of $f$ over $U$. In contrast\nto classical approaches based on compactness arguments, the proposed method,\nwhich employs a divergence-free transformation method, provides a computable\nand explicit constant $C>0$. The $L^2$-estimate remains robust even when there\nis no zero-order term, and the analysis further demonstrates that the constant\n$C>0$ decreases as the diffusion coefficient or the zero-order term increases.\nThese quantitative results provide a rigorous foundation for applications such\nas a posteriori error estimates in Physics-Informed Neural Networks (PINNs),\nwhere explicit error bounds are essential.", "published": "2025-07-07 12:38:04", "link": "http://arxiv.org/abs/2507.04940v1", "categories": ["math.AP", "cs.NA", "math.NA", "Primary: 35B45, 35J25, Secondary: 65N15, 68T07"], "primary_category": "math.AP"}
{"title": "Community Bail Fund Systems: Fluid Limits and Approximations", "abstract": "Community bail funds (CBFs) assist individuals who have been arrested and\ncannot afford bail, preventing unnecessary pretrial incarceration along with\nits harmful or sometimes fatal consequences. By posting bail, CBFs allow\ndefendants to stay at home and maintain their livelihoods until trial. This\npaper introduces new stochastic models that combine queueing theory with\nclassic insurance risk models to capture the dynamics of the remaining funds in\na CBF. We first analyze a model where all bail requests are accepted. Although\nthe remaining fund balance can go negative, this model provides insight for\nCBFs that are not financially constrained. We then apply the Skorokhod map to\nmake sure the CBF balance does not go negative and show that the Skorokhod map\nproduces a model where requests are partially fulfilled. Finally, we analyze a\nmodel where bail requests can be blocked if there is not enough money to\nsatisfy the request upon arrival. Although the blocking model prevents the CBF\nfrom being negative, the blocking feature gives rise to new analytical\nchallenges for a direct stochastic analysis. Thus, we prove a functional law of\nlarge numbers or a fluid limit for the blocking model and show that the fluid\nlimit is a distributed delay equation. We assess the quality of our fluid limit\nvia simulation and show that the fluid limit accurately describes the\nlarge-scale stochastic dynamics of the CBF. Finally, we prove stochastic\nordering results for the CBF processes we analyze.", "published": "2025-07-07 21:27:32", "link": "http://arxiv.org/abs/2507.05490v1", "categories": ["math.PR", "q-fin.MF", "stat.AP"], "primary_category": "math.PR"}
{"title": "Navigating Sparse Molecular Data with Stein Diffusion Guidance", "abstract": "Stochastic optimal control (SOC) has recently emerged as a principled\nframework for fine-tuning diffusion models. However, its dependence on\ncomputationally intensive simulations makes it impractical for fast sampling.\nIn parallel, a class of training-free approaches has been developed that guides\ndiffusion models using off-the-shelf classifiers on predicted clean samples,\nbypassing the need to train classifiers on noisy data. These methods can be\ninterpreted as approximate SOC schemes, using Tweedie's formula to estimate\ndiffusion posteriors. In practice, however, such direct approximations can\nintroduce significant errors, leading to unreliable guidance. In this work, we\nunify the strengths of both paradigms by proposing a novel training-free\ndiffusion guidance framework based on a surrogate stochastic optimal control\nobjective. We derive a new theoretical bound on the value function that reveals\nthe necessity of correcting the approximate posteriors to remain faithful to\nthe true diffusion posterior. To this end, we connect the problem with Stein\nvariational inference, which seeks the steepest descent direction that\nminimizes the Kullback-Leibler discrepancy between the two posteriors. Our\nmethod, which we refer to as Stein Diffusion Guidance (SDG), introduces a\nprincipled correction mechanism and incorporates a novel running cost\nfunctional to enable effective guidance in low-density regions. Experiments on\nchallenging molecular generation tasks demonstrate that SDG significantly\noutperforms standard training-free guidance methods, highlighting its potential\nfor broader applications.", "published": "2025-07-07 21:14:27", "link": "http://arxiv.org/abs/2507.05482v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Dynamic Regret Reduces to Kernelized Static Regret", "abstract": "We study dynamic regret in online convex optimization, where the objective is\nto achieve low cumulative loss relative to an arbitrary benchmark sequence. By\nobserving that competing with an arbitrary sequence of comparators\n$u_{1},\\ldots,u_{T}$ in $\\mathcal{W}\\subseteq\\mathbb{R}^{d}$ is equivalent to\ncompeting with a fixed comparator function $u:[1,T]\\to \\mathcal{W}$, we frame\ndynamic regret minimization as a static regret problem in a function space. By\ncarefully constructing a suitable function space in the form of a Reproducing\nKernel Hilbert Space (RKHS), our reduction enables us to recover the optimal\n$R_{T}(u_{1},\\ldots,u_{T}) = \\mathcal{O}(\\sqrt{\\sum_{t}\\|u_{t}-u_{t-1}\\|T})$\ndynamic regret guarantee in the setting of linear losses, and yields new\nscale-free and directionally-adaptive dynamic regret guarantees. Moreover,\nunlike prior dynamic-to-static reductions -- which are valid only for linear\nlosses -- our reduction holds for any sequence of losses, allowing us to\nrecover $\\mathcal{O}\\big(\\|u\\|^2+d_{\\mathrm{eff}}(\\lambda)\\ln T\\big)$ bounds in\nexp-concave and improper linear regression settings, where\n$d_{\\mathrm{eff}}(\\lambda)$ is a measure of complexity of the RKHS. Despite\nworking in an infinite-dimensional space, the resulting reduction leads to\nalgorithms that are computable in practice, due to the reproducing property of\nRKHSs.", "published": "2025-07-07 21:09:33", "link": "http://arxiv.org/abs/2507.05478v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Temporal Conformal Prediction (TCP): A Distribution-Free Statistical and Machine Learning Framework for Adaptive Risk Forecasting", "abstract": "We propose Temporal Conformal Prediction (TCP), a novel framework for\nconstructing prediction intervals in financial time-series with guaranteed\nfinite-sample validity. TCP integrates quantile regression with a conformal\ncalibration layer that adapts online via a decaying learning rate. This hybrid\ndesign bridges statistical and machine learning paradigms, enabling TCP to\naccommodate non-stationarity, volatility clustering, and regime shifts which\nare hallmarks of real-world asset returns, without relying on rigid parametric\nassumptions. We benchmark TCP against established methods including GARCH,\nHistorical Simulation, and static Quantile Regression across equities (S&P\n500), cryptocurrency (Bitcoin), and commodities (Gold). Empirical results show\nthat TCP consistently delivers sharper intervals with competitive or superior\ncoverage, particularly in high-volatility regimes. Our study underscores TCP's\nstrength in navigating the coverage-sharpness tradeoff, a central challenge in\nmodern risk forecasting. Overall, TCP offers a distribution-free, adaptive, and\ninterpretable alternative for financial uncertainty quantification, advancing\nthe interface between statistical inference and machine learning in finance.", "published": "2025-07-07 20:44:31", "link": "http://arxiv.org/abs/2507.05470v1", "categories": ["stat.ML", "cs.LG", "62G08, 62M10, 62P05, 91G70, 68T05"], "primary_category": "stat.ML"}
{"title": "Adversarial Machine Learning Attacks on Financial Reporting via Maximum Violated Multi-Objective Attack", "abstract": "Bad actors, primarily distressed firms, have the incentive and desire to\nmanipulate their financial reports to hide their distress and derive personal\ngains. As attackers, these firms are motivated by potentially millions of\ndollars and the availability of many publicly disclosed and used financial\nmodeling frameworks. Existing attack methods do not work on this data due to\nanti-correlated objectives that must both be satisfied for the attacker to\nsucceed. We introduce Maximum Violated Multi-Objective (MVMO) attacks that\nadapt the attacker's search direction to find $20\\times$ more satisfying\nattacks compared to standard attacks. The result is that in $\\approx50\\%$ of\ncases, a company could inflate their earnings by 100-200%, while simultaneously\nreducing their fraud scores by 15%. By working with lawyers and professional\naccountants, we ensure our threat model is realistic to how such frauds are\nperformed in practice.", "published": "2025-07-07 19:45:46", "link": "http://arxiv.org/abs/2507.05441v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enjoying Non-linearity in Multinomial Logistic Bandits", "abstract": "We consider the multinomial logistic bandit problem, a variant of generalized\nlinear bandits where a learner interacts with an environment by selecting\nactions to maximize expected rewards based on probabilistic feedback from\nmultiple possible outcomes. In the binary setting, recent work has focused on\nunderstanding the impact of the non-linearity of the logistic model (Faury et\nal., 2020; Abeille et al., 2021). They introduced a problem-dependent constant\n$\\kappa_*$, that may be exponentially large in some problem parameters and\nwhich is captured by the derivative of the sigmoid function. It encapsulates\nthe non-linearity and improves existing regret guarantees over $T$ rounds from\n$\\smash{O(d\\sqrt{T})}$ to $\\smash{O(d\\sqrt{T/\\kappa_*})}$, where $d$ is the\ndimension of the parameter space. We extend their analysis to the multinomial\nlogistic bandit framework, making it suitable for complex applications with\nmore than two choices, such as reinforcement learning or recommender systems.\nTo achieve this, we extend the definition of $\\kappa_*$ to the multinomial\nsetting and propose an efficient algorithm that leverages the problem's\nnon-linearity. Our method yields a problem-dependent regret bound of order $\n\\smash{\\widetilde{\\mathcal{O}}( Kd \\sqrt{{T}/{\\kappa_*}})} $, where $K$ is the\nnumber of actions and $\\kappa_* \\ge 1$. This improves upon the best existing\nguarantees of order $ \\smash{\\widetilde{\\mathcal{O}}( Kd \\sqrt{T} )} $.\nMoreover, we provide a $\\smash{ \\Omega(d\\sqrt{T/\\kappa_*})}$ lower-bound,\nshowing that our dependence on $\\kappa_*$ is optimal.", "published": "2025-07-07 08:18:25", "link": "http://arxiv.org/abs/2507.05306v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Parametric Object Coding in IVAS: Efficient Coding of Multiple Audio Objects at Low Bit Rates", "abstract": "The recently standardized 3GPP codec for Immersive Voice and Audio Services\n(IVAS) includes a parametric mode for efficiently coding multiple audio objects\nat low bit rates. In this mode, parametric side information is obtained from\nboth the object metadata and the input audio objects. The side information\ncomprises directional information, indices of two dominant objects, and the\npower ratio between these two dominant objects. It is transmitted to the\ndecoder along with a stereo downmix. In IVAS, parametric object coding allows\nfor transmitting three or four arbitrarily placed objects at bit rates of 24.4\nor 32 kbit/s and faithfully reconstructing the spatial image of the original\naudio scene. Subjective listening tests confirm that IVAS provides a comparable\nimmersive experience at lower bit rate and complexity compared to coding the\naudio objects independently using Enhanced Voice Services (EVS).", "published": "2025-07-07 18:48:17", "link": "http://arxiv.org/abs/2507.05409v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Stereo Reproduction in the Presence of Sample Rate Offsets", "abstract": "One of the main challenges in synchronizing wirelessly connected loudspeakers\nfor spatial audio reproduction is clock skew. Clock skew arises from sample\nrate offsets ( SROs) between the loudspeakers, caused by the use of independent\ndevice clocks. While network-based protocols like Precision Time Protocol (PTP)\nand Network Time Protocol (NTP) are explored, the impact of SROs on spatial\naudio reproduction and its perceptual consequences remains underexplored. We\npropose an audio-domain SRO compensation method using spatial filtering to\nisolate loudspeaker contributions. These filtered signals, along with the\noriginal playback signal, are used to estimate the SROs, and their influence is\ncompensated for prior to spatial audio reproduction. We evaluate the effect of\nthe compensation method in a subjective listening test. The results of these\ntests as well as objective metrics demonstrate that the proposed method\nmitigates the perceptual degradation introduced by SROs by preserving the\nspatial cues.", "published": "2025-07-07 18:40:33", "link": "http://arxiv.org/abs/2507.05402v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sample Rate Offset Compensated Acoustic Echo Cancellation For Multi-Device Scenarios", "abstract": "Acoustic echo cancellation (AEC) in multi-device scenarios is a challenging\nproblem due to sample rate offset (SRO) between devices. The SRO hinders the\nconvergence of the AEC filter, diminishing its performance. To address this ,\nwe approach the multi-device AEC scenario as a multi-channel AEC problem\ninvolving a multi-channel Kalman filter, SRO estimation, and resampling of\nfar-end signals. Experiments in a two-device scenario show that our system\nmitigates the divergence of the multi-channel Kalman filter in the presence of\nSRO for both correlated and uncorrelated playback signals during echo-only and\ndouble-talk. Additionally, for devices with correlated playback signals, an\nindependent single-channel AEC filter is crucial to ensure fast convergence of\nSRO estimation.", "published": "2025-07-07 18:33:09", "link": "http://arxiv.org/abs/2507.05399v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Comparative Analysis of Finite Difference and Finite Element Method for Audio Waveform Simulation", "abstract": "In many industries, including aerospace and defense, waveform analysis is\ncommonly conducted to compute the resonance of physical objects, with the\nFinite Element Method (FEM) being the standard approach. The Finite Difference\nMethod (FDM) is seldom used, and this preference is often stated without formal\njustification in the literature. In this work, the accuracy, feasibility, and\ntime of simulation of FEM and FDM are compared by simulating the vibration of a\nguitar string. Python simulations for both methods are implemented, and their\nresults are compared against analytical solutions and experimental data.\nAdditionally, FDM is applied to analyze the sound of a cycling bell to assess\nits reliability compared to a real cycling bell. Final results show that both\nFEM and FDM yield similar error margins and accurately predict the system's\nbehavior. Moreover, the errors from FEM and FDM follow the same periodicity\nwith a phase shift when varying the assumed analytical tension and without a\nphase shift when changing the time interval. However, FEM converges faster with\nincreasing mesh complexity, whereas FDM demonstrates quicker computational\nperformance and achieves stable solutions even with bigger time intervals.\nDespite this FDM is limited to simpler configurations and often demands\nextensive mathematical formulation, which can become cumbersome for intricate\nshapes. For example, modeling a hemispherical object using FDM results in\nsignificant simulation times and big calculations. In conclusion, while FDM may\noffer faster convergence and computation time in certain cases, FEM remains the\npreferred method in industrial contexts due to its flexibility, scalability,\nand ease of implementation for complex geometries.", "published": "2025-07-07 18:29:26", "link": "http://arxiv.org/abs/2507.05396v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Introducing Image-Space Preconditioning in the Variational Formulation of MRI Reconstructions", "abstract": "The aim of the present article is to enrich the comprehension of iterative\nmagnetic resonance imaging (MRI) reconstructions, including compressed sensing\n(CS) and iterative deep learning (DL) reconstructions, by describing them in\nthe general framework of finite-dimensional inner-product spaces. In\nparticular, we show that image-space preconditioning (ISP) and data-space\npreconditioning (DSP) can be formulated as non-conventional inner-products. The\nmain gain of our reformulation is an embedding of ISP in the variational\nformulation of the MRI reconstruction problem (in an algorithm-independent way)\nwhich allows in principle to naturally and systematically propagate ISP in all\niterative reconstructions, including many iterative DL and CS reconstructions\nwhere preconditioning is lacking. The way in which we apply linear algebraic\ntools to MRI reconstructions as presented in this article is a novelty.\n  A secondary aim of our article is to offer a certain didactic material to\nscientists who are new in the field of MRI reconstruction. Since we explore\nhere some mathematical concepts of reconstruction, we take that opportunity to\nrecall some principles that may be understood for experts, but which may be\nhard to find in the literature for beginners. In fact, the description of many\nmathematical tools of MRI reconstruction is fragmented in the literature or\nsometimes missing because considered as a general knowledge. Further, some of\nthose concepts can be found in mathematic manuals, but not in a form that is\noriented toward MRI. For example, we think of the conjugate gradient descent,\nthe notion of derivative with respect to non-conventional inner products, or\nsimply the notion of adjoint. The authors believe therefore that it is\nbeneficial for their field of research to dedicate some space to such a\ndidactic material.", "published": "2025-07-07 11:01:25", "link": "http://arxiv.org/abs/2507.05312v1", "categories": ["physics.med-ph", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "ModelCitizens: Representing Community Voices in Online Safety", "abstract": "Automatic toxic language detection is critical for creating safe, inclusive\nonline spaces. However, it is a highly subjective task, with perceptions of\ntoxic language shaped by community norms and lived experience. Existing\ntoxicity detection models are typically trained on annotations that collapse\ndiverse annotator perspectives into a single ground truth, erasing important\ncontext-specific notions of toxicity such as reclaimed language. To address\nthis, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K\ntoxicity annotations across diverse identity groups. To capture the role of\nconversational context on toxicity, typical of social media posts, we augment\nMODELCITIZENS posts with LLM-generated conversational scenarios.\nState-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,\nGPT-o4-mini) underperform on MODELCITIZENS, with further degradation on\ncontext-augmented posts. Finally, we release LLAMACITIZEN-8B and\nGEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,\nwhich outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our\nfindings highlight the importance of community-informed annotation and modeling\nfor inclusive content moderation. The data, models and code are available at\nhttps://github.com/asuvarna31/modelcitizens.", "published": "2025-07-07 20:15:18", "link": "http://arxiv.org/abs/2507.05455v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems", "abstract": "Federated recommender systems (FedRec) have emerged as a promising solution\nfor delivering personalized recommendations while safeguarding user privacy.\nHowever, recent studies have demonstrated their vulnerability to poisoning\nattacks. Existing attacks typically target the entire user group, which\ncompromises stealth and increases the risk of detection. In contrast,\nreal-world adversaries may prefer to prompt target items to specific user\nsubgroups, such as recommending health supplements to elderly users. Motivated\nby this gap, we introduce Spattack, the first targeted poisoning attack\ndesigned to manipulate recommendations for specific user subgroups in the\nfederated setting. Specifically, Spattack adopts a two-stage\napproximation-and-promotion strategy, which first simulates user embeddings of\ntarget/non-target subgroups and then prompts target items to the target\nsubgroups. To enhance the approximation stage, we push the inter-group\nembeddings away based on contrastive learning and augment the target group's\nrelevant item set based on clustering. To enhance the promotion stage, we\nfurther propose to adaptively tune the optimization weights between target and\nnon-target subgroups. Besides, an embedding alignment strategy is proposed to\nalign the embeddings between the target items and the relevant items. We\nconduct comprehensive experiments on three real-world datasets, comparing\nSpattack against seven state-of-the-art poisoning attacks and seven\nrepresentative defense mechanisms. Experimental results demonstrate that\nSpattack consistently achieves strong manipulation performance on the specific\nuser subgroup, while incurring minimal impact on non-target users, even when\nonly 0.1\\% of users are malicious. Moreover, Spattack maintains competitive\noverall recommendation performance and exhibits strong resilience against\nexisting mainstream defenses.", "published": "2025-07-07 09:40:16", "link": "http://arxiv.org/abs/2507.06258v1", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.IR"], "primary_category": "cs.CR"}
{"title": "Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World", "abstract": "This paper investigates the real-world vulnerabilities of audio-based large\nlanguage models (ALLMs), such as Qwen2-Audio. We first demonstrate that an\nadversary can craft stealthy audio perturbations to manipulate ALLMs into\nexhibiting specific targeted behaviors, such as eliciting responses to\nwake-keywords (e.g., \"Hey Qwen\"), or triggering harmful behaviors (e.g. \"Change\nmy calendar event\"). Subsequently, we show that playing adversarial background\nnoise during user interaction with the ALLMs can significantly degrade the\nresponse quality. Crucially, our research illustrates the scalability of these\nattacks to real-world scenarios, impacting other innocent users when these\nadversarial noises are played through the air. Further, we discuss the\ntransferrability of the attack, and potential defensive measures.", "published": "2025-07-07 07:29:52", "link": "http://arxiv.org/abs/2507.06256v1", "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
