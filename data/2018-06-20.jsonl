{"title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "abstract": "The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.", "published": "2018-06-20 12:13:53", "link": "http://arxiv.org/abs/1806.07687v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Tagging with Foundational Ontology Classes: Extending the\n  WordNet-DOLCE Mapping to Verbs", "abstract": "Semantic annotation is fundamental to deal with large-scale lexical\ninformation, mapping the information to an enumerable set of categories over\nwhich rules and algorithms can be applied, and foundational ontology classes\ncan be used as a formal set of categories for such tasks. A previous alignment\nbetween WordNet noun synsets and DOLCE provided a starting point for\nontology-based annotation, but in NLP tasks verbs are also of substantial\nimportance. This work presents an extension to the WordNet-DOLCE noun mapping,\naligning verbs according to their links to nouns denoting perdurants,\ntransferring to the verb the DOLCE class assigned to the noun that best\nrepresents that verb's occurrence. To evaluate the usefulness of this resource,\nwe implemented a foundational ontology-based semantic annotation framework,\nthat assigns a high-level foundational category to each word or phrase in a\ntext, and compared it to a similar annotation tool, obtaining an increase of\n9.05% in accuracy.", "published": "2018-06-20 12:56:54", "link": "http://arxiv.org/abs/1806.07699v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Categorization of Semantic Roles for Dictionary Definitions", "abstract": "Understanding the semantic relationships between terms is a fundamental task\nin natural language processing applications. While structured resources that\ncan express those relationships in a formal way, such as ontologies, are still\nscarce, a large number of linguistic resources gathering dictionary definitions\nis becoming available, but understanding the semantic structure of natural\nlanguage definitions is fundamental to make them useful in semantic\ninterpretation tasks. Based on an analysis of a subset of WordNet's glosses, we\npropose a set of semantic roles that compose the semantic structure of a\ndictionary definition, and show how they are related to the definition's\nsyntactic configuration, identifying patterns that can be used in the\ndevelopment of information extraction frameworks and semantic models.", "published": "2018-06-20 13:14:12", "link": "http://arxiv.org/abs/1806.07711v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Relation Classification: Task Formalisation and Refinement", "abstract": "The identification of semantic relations between terms within texts is a\nfundamental task in Natural Language Processing which can support applications\nrequiring a lightweight semantic interpretation model. Currently, semantic\nrelation classification concentrates on relations which are evaluated over\nopen-domain data. This work provides a critique on the set of abstract\nrelations used for semantic relation classification with regard to their\nability to express relationships between terms which are found in a\ndomain-specific corpora. Based on this analysis, this work proposes an\nalternative semantic relation model based on reusing and extending the set of\nabstract relations present in the DOLCE ontology. The resulting set of\nrelations is well grounded, allows to capture a wide range of relations and\ncould thus be used as a foundation for automatic classification of semantic\nrelations.", "published": "2018-06-20 13:30:51", "link": "http://arxiv.org/abs/1806.07721v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building a Knowledge Graph from Natural Language Definitions for\n  Interpretable Text Entailment Recognition", "abstract": "Natural language definitions of terms can serve as a rich source of\nknowledge, but structuring them into a comprehensible semantic model is\nessential to enable them to be used in semantic interpretation tasks. We\npropose a method and provide a set of tools for automatically building a graph\nworld knowledge base from natural language definitions. Adopting a conceptual\nmodel composed of a set of semantic roles for dictionary definitions, we\ntrained a classifier for automatically labeling definitions, preparing the data\nto be later converted to a graph representation. WordNetGraph, a knowledge\ngraph built out of noun and verb WordNet definitions according to this\nmethodology, was successfully used in an interpretable text entailment\nrecognition approach which uses paths in this graph to provide clear\njustifications for entailment decisions.", "published": "2018-06-20 13:50:46", "link": "http://arxiv.org/abs/1806.07731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Opinion Dynamics Modeling for Movie Review Transcripts Classification\n  with Hidden Conditional Random Fields", "abstract": "In this paper, the main goal is to detect a movie reviewer's opinion using\nhidden conditional random fields. This model allows us to capture the dynamics\nof the reviewer's opinion in the transcripts of long unsegmented audio reviews\nthat are analyzed by our system. High level linguistic features are computed at\nthe level of inter-pausal segments. The features include syntactic features, a\nstatistical word embedding model and subjectivity lexicons. The proposed system\nis evaluated on the ICT-MMMO corpus. We obtain a F1-score of 82\\%, which is\nbetter than logistic regression and recurrent neural network approaches. We\nalso offer a discussion that sheds some light on the capacity of our system to\nadapt the word embedding model learned from general written texts data to\nspoken movie reviews and thus model the dynamics of the opinion.", "published": "2018-06-20 15:14:10", "link": "http://arxiv.org/abs/1806.07787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Layer Ensembling Techniques for Multilingual Intent Classification", "abstract": "In this paper we determine how multi-layer ensembling improves performance on\nmultilingual intent classification. We develop a novel multi-layer ensembling\napproach that ensembles both different model initializations and different\nmodel architectures. We also introduce a new banking domain dataset and compare\nresults against the standard ATIS dataset and the Chinese SMP2017 dataset to\ndetermine ensembling performance in multilingual and multi-domain contexts. We\nrun ensemble experiments across all three datasets, and conclude that\nensembling provides significant performance increases, and that multi-layer\nensembling is a no-risk way to improve performance on intent classification. We\nalso find that a diverse ensemble of simple models can reach perform comparable\nto much more sophisticated state-of-the-art models. Our best F 1 scores on\nATIS, Banking, and SMP are 97.54%, 91.79%, and 93.55% respectively, which\ncompare well with the state-of-the-art on ATIS and best submission to the\nSMP2017 competition. The total ensembling performance increases we achieve are\n0.23%, 1.96%, and 4.04% F 1 respectively.", "published": "2018-06-20 18:17:40", "link": "http://arxiv.org/abs/1806.07914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RSDD-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses", "abstract": "Self-reported diagnosis statements have been widely employed in studying\nlanguage related to mental health in social media. However, existing research\nhas largely ignored the temporality of mental health diagnoses. In this work,\nwe introduce RSDD-Time: a new dataset of 598 manually annotated self-reported\ndepression diagnosis posts from Reddit that include temporal information about\nthe diagnosis. Annotations include whether a mental health condition is present\nand how recently the diagnosis happened. Furthermore, we include exact temporal\nspans that relate to the date of diagnosis. This information is valuable for\nvarious computational methods to examine mental health through social media\nbecause one's mental health state is not static. We also test several baseline\nclassification and extraction approaches, which suggest that extracting\ntemporal information from self-reported diagnosis statements is challenging.", "published": "2018-06-20 18:18:52", "link": "http://arxiv.org/abs/1806.07916v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ontology Alignment in the Biomedical Domain Using Entity Definitions and\n  Context", "abstract": "Ontology alignment is the task of identifying semantically equivalent\nentities from two given ontologies. Different ontologies have different\nrepresentations of the same entity, resulting in a need to de-duplicate\nentities when merging ontologies. We propose a method for enriching entities in\nan ontology with external definition and context information, and use this\nadditional information for ontology alignment. We develop a neural architecture\ncapable of encoding the additional information when available, and show that\nthe addition of external data results in an F1-score of 0.69 on the Ontology\nAlignment Evaluation Initiative (OAEI) largebio SNOMED-NCI subtask, comparable\nwith the entity-level matchers in a SOTA system.", "published": "2018-06-20 20:29:24", "link": "http://arxiv.org/abs/1806.07976v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TxPI-u: A Resource for Personality Identification of Undergraduates", "abstract": "Resources such as labeled corpora are necessary to train automatic models\nwithin the natural language processing (NLP) field. Historically, a large\nnumber of resources regarding a broad number of problems are available mostly\nin English. One of such problems is known as Personality Identification where\nbased on a psychological model (e.g. The Big Five Model), the goal is to find\nthe traits of a subject's personality given, for instance, a text written by\nthe same subject. In this paper we introduce a new corpus in Spanish called\nTexts for Personality Identification (TxPI). This corpus will help to develop\nmodels to automatically assign a personality trait to an author of a text\ndocument. Our corpus, TxPI-u, contains information of 416 Mexican undergraduate\nstudents with some demographics information such as, age, gender, and the\nacademic program they are enrolled. Finally, as an additional contribution, we\npresent a set of baselines to provide a comparison scheme for further research.", "published": "2018-06-20 20:31:47", "link": "http://arxiv.org/abs/1806.07977v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Supervised Approach To The Interpretation Of Imperative To-Do Lists", "abstract": "To-do lists are a popular medium for personal information management. As\nto-do tasks are increasingly tracked in electronic form with mobile and desktop\norganizers, so does the potential for software support for the corresponding\ntasks by means of intelligent agents. While there has been work in the area of\npersonal assistants for to-do tasks, no work has focused on classifying user\nintention and information extraction as we do. We show that our methods perform\nwell across two corpora that span sub-domains, one of which we released.", "published": "2018-06-20 21:46:49", "link": "http://arxiv.org/abs/1806.07999v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Injecting Relational Structural Representation in Neural Networks for\n  Question Similarity", "abstract": "Effectively using full syntactic parsing information in Neural Networks (NNs)\nto solve relational tasks, e.g., question similarity, is still an open problem.\nIn this paper, we propose to inject structural representations in NNs by (i)\nlearning an SVM model using Tree Kernels (TKs) on relatively few pairs of\nquestions (few thousands) as gold standard (GS) training data is typically\nscarce, (ii) predicting labels on a very large corpus of question pairs, and\n(iii) pre-training NNs on such large corpus. The results on Quora and SemEval\nquestion similarity datasets show that NNs trained with our approach can learn\nmore accurate models, especially after fine tuning on GS.", "published": "2018-06-20 22:09:50", "link": "http://arxiv.org/abs/1806.08009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StructVAE: Tree-structured Latent Variable Models for Semi-supervised\n  Semantic Parsing", "abstract": "Semantic parsing is the task of transducing natural language (NL) utterances\ninto formal meaning representations (MRs), commonly represented as tree\nstructures. Annotating NL utterances with their corresponding MRs is expensive\nand time-consuming, and thus the limited availability of labeled data often\nbecomes the bottleneck of data-driven, supervised models. We introduce\nStructVAE, a variational auto-encoding model for semisupervised semantic\nparsing, which learns both from limited amounts of parallel data, and\nreadily-available unlabeled NL utterances. StructVAE models latent MRs not\nobserved in the unlabeled data as tree-structured latent variables. Experiments\non semantic parsing on the ATIS domain and Python code generation show that\nwith extra unlabeled data, StructVAE outperforms strong supervised models.", "published": "2018-06-20 16:29:01", "link": "http://arxiv.org/abs/1806.07832v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extracting News Events from Microblogs", "abstract": "Twitter stream has become a large source of information for many people, but\nthe magnitude of tweets and the noisy nature of its content have made\nharvesting the knowledge from Twitter a challenging task for researchers for a\nlong time. Aiming at overcoming some of the main challenges of extracting the\nhidden information from tweet streams, this work proposes a new approach for\nreal-time detection of news events from the Twitter stream. We divide our\napproach into three steps. The first step is to use a neural network or deep\nlearning to detect news-relevant tweets from the stream. The second step is to\napply a novel streaming data clustering algorithm to the detected news tweets\nto form news events. The third and final step is to rank the detected events\nbased on the size of the event clusters and growth speed of the tweet\nfrequencies. We evaluate the proposed system on a large, publicly available\ncorpus of annotated news events from Twitter. As part of the evaluation, we\ncompare our approach with a related state-of-the-art solution. Overall, our\nexperiments and user-based evaluation show that our approach on detecting\ncurrent (real) news events delivers a state-of-the-art performance.", "published": "2018-06-20 06:54:17", "link": "http://arxiv.org/abs/1806.07573v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Using Neural Network for Identifying Clickbaits in Online News Media", "abstract": "Online news media sometimes use misleading headlines to lure users to open\nthe news article. These catchy headlines that attract users but disappointed\nthem at the end, are called Clickbaits. Because of the importance of automatic\nclickbait detection in online medias, lots of machine learning methods were\nproposed and employed to find the clickbait headlines. In this research, a\nmodel using deep learning methods is proposed to find the clickbaits in\nClickbait Challenge 2017's dataset. The proposed model gained the first rank in\nthe Clickbait Challenge 2017 in terms of Mean Squared Error. Also, data\nanalytics and visualization techniques are employed to explore and discover the\nprovided dataset to get more insight from the data.", "published": "2018-06-20 13:21:53", "link": "http://arxiv.org/abs/1806.07713v1", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Corpus Replication Task", "abstract": "In the field of Natural Language Processing (NLP), we revisit the well-known\nword embedding algorithm word2vec. Word embeddings identify words by vectors\nsuch that the words' distributional similarity is captured. Unexpectedly,\nbesides semantic similarity even relational similarity has been shown to be\ncaptured in word embeddings generated by word2vec, whence two questions arise.\nFirstly, which kind of relations are representable in continuous space and\nsecondly, how are relations built. In order to tackle these questions we\npropose a bottom-up point of view. We call generating input text for which\nword2vec outputs target relations solving the Corpus Replication Task. Deeming\ngeneralizations of this approach to any set of relations possible, we expect\nsolving of the Corpus Replication Task to provide partial answers to the\nquestions.", "published": "2018-06-20 20:37:28", "link": "http://arxiv.org/abs/1806.07978v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Jack the Reader - A Machine Reading Framework", "abstract": "Many Machine Reading and Natural Language Understanding tasks require reading\nsupporting text in order to answer questions. For example, in Question\nAnswering, the supporting text can be newswire or Wikipedia articles; in\nNatural Language Inference, premises can be seen as the supporting text and\nhypotheses as questions. Providing a set of useful primitives operating in a\nsingle framework of related tasks would allow for expressive modelling, and\neasier model comparison and replication. To that end, we present Jack the\nReader (Jack), a framework for Machine Reading that allows for quick model\nprototyping by component reuse, evaluation of new models on existing datasets\nas well as integrating new datasets and applying them on a growing set of\nimplemented baseline models. Jack is currently supporting (but not limited to)\nthree tasks: Question Answering, Natural Language Inference, and Link\nPrediction. It is developed with the aim of increasing research efficiency and\ncode reuse.", "published": "2018-06-20 00:30:29", "link": "http://arxiv.org/abs/1806.08727v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing\n(NLP) tasks individually. However, general NLP models cannot emerge within a\nparadigm that focuses on the particularities of a single metric, dataset, and\ntask. We introduce the Natural Language Decathlon (decaNLP), a challenge that\nspans ten tasks: question answering, machine translation, summarization,\nnatural language inference, sentiment analysis, semantic role labeling,\nzero-shot relation extraction, goal-oriented dialogue, semantic parsing, and\ncommonsense pronoun resolution. We cast all tasks as question answering over a\ncontext. Furthermore, we present a new Multitask Question Answering Network\n(MQAN) jointly learns all tasks in decaNLP without any task-specific modules or\nparameters in the multitask setting. MQAN shows improvements in transfer\nlearning for machine translation and named entity recognition, domain\nadaptation for sentiment analysis and natural language inference, and zero-shot\ncapabilities for text classification. We demonstrate that the MQAN's\nmulti-pointer-generator decoder is key to this success and performance further\nimproves with an anti-curriculum training strategy. Though designed for\ndecaNLP, MQAN also achieves state of the art results on the WikiSQL semantic\nparsing task in the single-task setting. We also release code for procuring and\nprocessing data, training and evaluating models, and reproducing all\nexperiments for decaNLP.", "published": "2018-06-20 16:39:26", "link": "http://arxiv.org/abs/1806.08730v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Synthesizing Diverse, High-Quality Audio Textures", "abstract": "Texture synthesis techniques based on matching the Gram matrix of feature\nactivations in neural networks have achieved spectacular success in the image\ndomain. In this paper we extend these techniques to the audio domain. We\ndemonstrate that synthesizing diverse audio textures is challenging, and argue\nthat this is because audio data is relatively low-dimensional. We therefore\nintroduce two new terms to the original Grammian loss: an autocorrelation term\nthat preserves rhythm, and a diversity term that encourages the optimization\nprocedure to synthesize unique textures. We quantitatively study the impact of\nour design choices on the quality of the synthesized audio by introducing an\naudio analogue to the Inception loss which we term the VGGish loss. We show\nthat there is a trade-off between the diversity and quality of the synthesized\naudio using this technique. We additionally perform a number of experiments to\nqualitatively study how these design choices impact the quality of the\nsynthesized audio. Finally we describe the implications of these results for\nthe problem of audio style transfer.", "published": "2018-06-20 21:51:32", "link": "http://arxiv.org/abs/1806.08002v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quaternion Convolutional Neural Networks for End-to-End Automatic Speech\n  Recognition", "abstract": "Recently, the connectionist temporal classification (CTC) model coupled with\nrecurrent (RNN) or convolutional neural networks (CNN), made it easier to train\nspeech recognition systems in an end-to-end fashion. However in real-valued\nmodels, time frame components such as mel-filter-bank energies and the cepstral\ncoefficients obtained from them, together with their first and second order\nderivatives, are processed as individual elements, while a natural alternative\nis to process such components as composed entities. We propose to group such\nelements in the form of quaternions and to process these quaternions using the\nestablished quaternion algebra. Quaternion numbers and quaternion neural\nnetworks have shown their efficiency to process multidimensional inputs as\nentities, to encode internal dependencies, and to solve many tasks with less\nlearning parameters than real-valued models. This paper proposes to integrate\nmultiple feature views in quaternion-valued convolutional neural network\n(QCNN), to be used for sequence-to-sequence mapping with the CTC model.\nPromising results are reported using simple QCNNs in phoneme recognition\nexperiments with the TIMIT corpus. More precisely, QCNNs obtain a lower phoneme\nerror rate (PER) with less learning parameters than a competing model based on\nreal-valued CNNs.", "published": "2018-06-20 15:16:43", "link": "http://arxiv.org/abs/1806.07789v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
