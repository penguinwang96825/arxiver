{"title": "TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit", "abstract": "Recent advances in Large Language Models (LLM) have led to a new class of\nautonomous agents, renewing and expanding interest in the area. LLM-powered\nMultiagent Systems (MAS) have thus emerged, both for assistive and simulation\npurposes, yet tools for realistic human behavior simulation -- with its\ndistinctive challenges and opportunities -- remain underdeveloped. Existing MAS\nlibraries and tools lack fine-grained persona specifications, population\nsampling facilities, experimentation support, and integrated validation, among\nother key capabilities, limiting their utility for behavioral studies, social\nsimulation, and related applications. To address these deficiencies, in this\nwork we introduce TinyTroupe, a simulation toolkit enabling detailed persona\ndefinitions (e.g., nationality, age, occupation, personality, beliefs,\nbehaviors) and programmatic control via numerous LLM-driven mechanisms. This\nallows for the concise formulation of behavioral problems of practical\ninterest, either at the individual or group level, and provides effective means\nfor their solution. TinyTroupe's components are presented using representative\nworking examples, such as brainstorming and market research sessions, thereby\nsimultaneously clarifying their purpose and demonstrating their usefulness.\nQuantitative and qualitative evaluations of selected aspects are also provided,\nhighlighting possibilities, limitations, and trade-offs. The approach, though\nrealized as a specific Python implementation, is meant as a novel conceptual\ncontribution, which can be partially or fully incorporated in other contexts.\nThe library is available as open source at\nhttps://github.com/microsoft/tinytroupe.", "published": "2025-07-13 21:00:27", "link": "http://arxiv.org/abs/2507.09788v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.HC", "I.2.11; I.6.5; I.6.7"], "primary_category": "cs.MA"}
{"title": "Te Ahorr\u00e9 Un Click: A Revised Definition of Clickbait and Detection in Spanish News", "abstract": "We revise the definition of clickbait, which lacks current consensus, and\nargue that the creation of a curiosity gap is the key concept that\ndistinguishes clickbait from other related phenomena such as sensationalism and\nheadlines that do not deliver what they promise or diverge from the article.\nTherefore, we propose a new definition: clickbait is a technique for generating\nheadlines and teasers that deliberately omit part of the information with the\ngoal of raising the readers' curiosity, capturing their attention and enticing\nthem to click. We introduce a new approach to clickbait detection datasets\ncreation, by refining the concept limits and annotations criteria, minimizing\nthe subjectivity in the decision as much as possible. Following it, we created\nand release TA1C (for Te Ahorr\\'e Un Click, Spanish for Saved You A Click), the\nfirst open source dataset for clickbait detection in Spanish. It consists of\n3,500 tweets coming from 18 well known media sources, manually annotated and\nreaching a 0.825 Fleiss' K inter annotator agreement. We implement strong\nbaselines that achieve 0.84 in F1-score.", "published": "2025-07-13 20:19:08", "link": "http://arxiv.org/abs/2507.09777v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions", "abstract": "Hacker forums provide critical early warning signals for emerging\ncybersecurity threats, but extracting actionable intelligence from their\nunstructured and noisy content remains a significant challenge. This paper\npresents an unsupervised framework that automatically detects, clusters, and\nprioritizes security events discussed across hacker forum posts. Our approach\nleverages Transformer-based embeddings fine-tuned with contrastive learning to\ngroup related discussions into distinct security event clusters, identifying\nincidents like zero-day disclosures or malware releases without relying on\npredefined keywords. The framework incorporates a daily ranking mechanism that\nprioritizes identified events using quantifiable metrics reflecting timeliness,\nsource credibility, information completeness, and relevance. Experimental\nevaluation on real-world hacker forum data demonstrates that our method\neffectively reduces noise and surfaces high-priority threats, enabling security\nanalysts to mount proactive responses. By transforming disparate hacker forum\ndiscussions into structured, actionable intelligence, our work addresses\nfundamental challenges in automated threat detection and analysis.", "published": "2025-07-13 19:40:36", "link": "http://arxiv.org/abs/2507.09762v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Your Pretrained Model Tells the Difficulty Itself: A Self-Adaptive Curriculum Learning Paradigm for Natural Language Understanding", "abstract": "Curriculum learning is a widely adopted training strategy in natural language\nprocessing (NLP), where models are exposed to examples organized by increasing\ndifficulty to enhance learning efficiency and performance. However, most\nexisting approaches rely on manually defined difficulty metrics -- such as text\nlength -- which may not accurately reflect the model's own perspective. To\novercome this limitation, we present a self-adaptive curriculum learning\nparadigm that prioritizes fine-tuning examples based on difficulty scores\npredicted by pre-trained language models (PLMs) themselves. Building on these\nscores, we explore various training strategies that differ in the ordering of\nexamples for the fine-tuning: from easy-to-hard, hard-to-easy, to mixed\nsampling. We evaluate our method on four natural language understanding (NLU)\ndatasets covering both binary and multi-class classification tasks.\nExperimental results show that our approach leads to faster convergence and\nimproved performance compared to standard random sampling.", "published": "2025-07-13 19:36:17", "link": "http://arxiv.org/abs/2507.09758v1", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but they exhibit problems with\nlogical consistency in the output they generate. How can we harness LLMs'\nbroad-coverage parametric knowledge in formal reasoning despite their\ninconsistency? We present a method for directly integrating an LLM into the\ninterpretation function of the formal semantics for a paraconsistent logic. We\nprovide experimental evidence for the feasibility of the method by evaluating\nthe function using datasets created from several short-form factuality\nbenchmarks. Unlike prior work, our method offers a theoretical framework for\nneuro-symbolic reasoning that leverages an LLM's knowledge while preserving the\nunderlying logic's soundness and completeness properties.", "published": "2025-07-13 19:05:43", "link": "http://arxiv.org/abs/2507.09751v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Large Language Models Encode Semantics in Low-Dimensional Linear Subspaces", "abstract": "Understanding the latent space geometry of large language models (LLMs) is\nkey to interpreting their behavior and improving alignment. \\baturay{However,\nit remains unclear to what extent LLMs internally organize representations\nrelated to semantic understanding. To investigate this, we conduct a\nlarge-scale empirical study of hidden states in transformer-based LLMs,\nanalyzing 11 decoder-only models across 6 scientific topics and 12 layers each.\nWe find that high-level semantic information consistently lies in\nlow-dimensional subspaces that form linearly separable representations across\ndistinct domains. This separability becomes more pronounced in deeper layers\nand under prompts that trigger structured reasoning or alignment\nbehaviors$\\unicode{x2013}$even when surface content is unchanged. This geometry\nenables simple yet effective causal interventions in hidden space; for example,\nreasoning patterns like chain-of-thought can be captured by a single vector\ndirection. Together, these findings support the development of geometry-aware\ntools that operate directly on latent representations to detect and mitigate\nharmful or adversarial content, using methods such as transport-based defenses\nthat leverage this separability. As a proof of concept, we demonstrate this\npotential by training a simple MLP classifier as a lightweight latent-space\nguardrail, which detects adversarial and malicious prompts with high precision.", "published": "2025-07-13 17:03:25", "link": "http://arxiv.org/abs/2507.09709v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MCEval: A Dynamic Framework for Fair Multilingual Cultural Evaluation of LLMs", "abstract": "Large language models exhibit cultural biases and limited cross-cultural\nunderstanding capabilities, particularly when serving diverse global user\npopulations. We propose MCEval, a novel multilingual evaluation framework that\nemploys dynamic cultural question construction and enables causal analysis\nthrough Counterfactual Rephrasing and Confounder Rephrasing. Our comprehensive\nevaluation spans 13 cultures and 13 languages, systematically assessing both\ncultural awareness and cultural bias across different linguistic scenarios. The\nframework provides 39,897 cultural awareness instances and 17,940 cultural bias\ninstances. Experimental results reveal performance disparities across different\nlinguistic scenarios, demonstrating that optimal cultural performance is not\nonly linked to training data distribution, but also is related to\nlanguage-culture alignment. The evaluation results also expose the fairness\nissue, where approaches appearing successful in the English scenario create\nsubstantial disadvantages. MCEval represents the first comprehensive\nmultilingual cultural evaluation framework that provides deeper insights into\nLLMs' cultural understanding.", "published": "2025-07-13 16:24:35", "link": "http://arxiv.org/abs/2507.09701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey", "abstract": "Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have\ndemonstrated impressive performance on complex reasoning tasks like mathematics\nand programming with long Chain-of-Thought (CoT) reasoning sequences\n(slow-thinking), compared with traditional large language models\n(fast-thinking). However, these reasoning models also face a huge challenge\nthat generating unnecessarily lengthy and redundant reasoning chains even for\ntrivial questions. This phenomenon leads to a significant waste of inference\nresources, increases the response time for simple queries, and hinders the\npractical application of LRMs in real-world products. To this end, it is\ncrucial to shorten lengthy reasoning chains and learn adaptive reasoning\nbetween fast and slow thinking based on input difficulty. In this survey, we\nprovide a comprehensive overview of recent progress in concise and adaptive\nthinking for efficient reasoning of LRMs, including methodologies, benchmarks,\nand challenges for future exploration. We hope this survey can help researchers\nquickly understand the landscape of this field and inspire novel adaptive\nthinking ideas to facilitate better usage of LRMs.", "published": "2025-07-13 14:51:59", "link": "http://arxiv.org/abs/2507.09662v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Can Group Relative Policy Optimization Improve Thai Legal Reasoning and Question Answering?", "abstract": "The Retrieval-Augmented Generation (RAG) systems' performance on Thai legal\nquestion answering is still limited, especially for questions requiring\nextensive, complex legal reasoning. To address these limitations, we introduce\nan approach aligning LLMs toward improved law citation accuracy and better\nresponse quality using Group-Relative Policy Optimization (GRPO). Our approach\nleverages BGE-M3 embeddings as a cost-efficient semantic-similarity reward,\nsignificantly reducing computational expenses up to 2.5x compared to large\nlanguage model judges. Experiments on the NitiBench benchmark demonstrate\nsubstantial improvements: GRPO achieves up to 90% citation-F1 gains from the\nbase model and a 31% increase in joint quality metrics over instruction tuning.\nCrucially, our method shows enhanced robustness on complex legal reasoning\ntasks compared to instruction tuning, providing an effective and\nresource-efficient solution for enhancing Thai legal LLMs.", "published": "2025-07-13 14:05:48", "link": "http://arxiv.org/abs/2507.09638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Exploration of Knowledge Editing for Arabic", "abstract": "While Knowledge Editing (KE) has been widely explored in English, its\nbehavior in morphologically rich languages like Arabic remains underexamined.\nIn this work, we present the first study of Arabic KE. We evaluate four methods\n(ROME, MEMIT, ICE, and LTE) on Arabic translations of the ZsRE and Counterfact\nbenchmarks, analyzing both multilingual and cross-lingual settings. Our\nexperiments on Llama-2-7B-chat show show that parameter-based methods struggle\nwith cross-lingual generalization, while instruction-tuned methods perform more\nrobustly. We extend Learning-To-Edit (LTE) to a multilingual setting and show\nthat joint Arabic-English training improves both editability and transfer. We\nrelease Arabic KE benchmarks and multilingual training for LTE data to support\nfuture research.", "published": "2025-07-13 13:49:52", "link": "http://arxiv.org/abs/2507.09629v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpreadPy: A Python tool for modelling spreading activation and superdiffusion in cognitive multiplex networks", "abstract": "We introduce SpreadPy as a Python library for simulating spreading activation\nin cognitive single-layer and multiplex networks. Our tool is designed to\nperform numerical simulations testing structure-function relationships in\ncognitive processes. By comparing simulation results with grounded theories in\nknowledge modelling, SpreadPy enables systematic investigations of how\nactivation dynamics reflect cognitive, psychological and clinical phenomena. We\ndemonstrate the library's utility through three case studies: (1) Spreading\nactivation on associative knowledge networks distinguishes students with high\nversus low math anxiety, revealing anxiety-related structural differences in\nconceptual organization; (2) Simulations of a creativity task show that\nactivation trajectories vary with task difficulty, exposing how cognitive load\nmodulates lexical access; (3) In individuals with aphasia, simulated activation\npatterns on lexical networks correlate with empirical error types (semantic vs.\nphonological) during picture-naming tasks, linking network structure to\nclinical impairments. SpreadPy's flexible framework allows researchers to model\nthese processes using empirically derived or theoretical networks, providing\nmechanistic insights into individual differences and cognitive impairments. The\nlibrary is openly available, supporting reproducible research in psychology,\nneuroscience, and education research.", "published": "2025-07-13 13:49:29", "link": "http://arxiv.org/abs/2507.09628v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance", "abstract": "General-purpose sentence embedding models often struggle to capture\nspecialized financial semantics, especially in low-resource languages like\nKorean, due to domain-specific jargon, temporal meaning shifts, and misaligned\nbilingual vocabularies. To address these gaps, we introduce NMIXX (Neural\neMbeddings for Cross-lingual eXploration of Finance), a suite of cross-lingual\nembedding models fine-tuned with 18.8K high-confidence triplets that pair\nin-domain paraphrases, hard negatives derived from a semantic-shift typology,\nand exact Korean-English translations. Concurrently, we release KorFinSTS, a\n1,921-pair Korean financial STS benchmark spanning news, disclosures, research\nreports, and regulations, designed to expose nuances that general benchmarks\nmiss.\n  When evaluated against seven open-license baselines, NMIXX's multilingual\nbge-m3 variant achieves Spearman's rho gains of +0.10 on English FinSTS and\n+0.22 on KorFinSTS, outperforming its pre-adaptation checkpoint and surpassing\nother models by the largest margin, while revealing a modest trade-off in\ngeneral STS performance. Our analysis further shows that models with richer\nKorean token coverage adapt more effectively, underscoring the importance of\ntokenizer design in low-resource, cross-lingual settings. By making both models\nand the benchmark publicly available, we provide the community with robust\ntools for domain-adapted, multilingual representation learning in finance.", "published": "2025-07-13 12:14:57", "link": "http://arxiv.org/abs/2507.09601v1", "categories": ["cs.CL", "cs.AI", "q-fin.CP"], "primary_category": "cs.CL"}
{"title": "MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models", "abstract": "Recent text-to-image models produce high-quality results but still struggle\nwith precise visual control, balancing multimodal inputs, and requiring\nextensive training for complex multimodal image generation. To address these\nlimitations, we propose MENTOR, a novel autoregressive (AR) framework for\nefficient Multimodal-conditioned Tuning for Autoregressive multimodal image\ngeneration. MENTOR combines an AR image generator with a two-stage training\nparadigm, enabling fine-grained, token-level alignment between multimodal\ninputs and image outputs without relying on auxiliary adapters or\ncross-attention modules. The two-stage training consists of: (1) a multimodal\nalignment stage that establishes robust pixel- and semantic-level alignment,\nfollowed by (2) a multimodal instruction tuning stage that balances the\nintegration of multimodal inputs and enhances generation controllability.\nDespite modest model size, suboptimal base components, and limited training\nresources, MENTOR achieves strong performance on the DreamBench++ benchmark,\noutperforming competitive baselines in concept preservation and prompt\nfollowing. Additionally, our method delivers superior image reconstruction\nfidelity, broad task adaptability, and improved training efficiency compared to\ndiffusion-based methods. Dataset, code, and models are available at:\nhttps://github.com/HaozheZhao/MENTOR", "published": "2025-07-13 10:52:59", "link": "http://arxiv.org/abs/2507.09574v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adapting Definition Modeling for New Languages: A Case Study on Belarusian", "abstract": "Definition modeling, the task of generating new definitions for words in\ncontext, holds great prospect as a means to assist the work of lexicographers\nin documenting a broader variety of lects and languages, yet much remains to be\ndone in order to assess how we can leverage pre-existing models for as-of-yet\nunsupported languages. In this work, we focus on adapting existing models to\nBelarusian, for which we propose a novel dataset of 43,150 definitions. Our\nexperiments demonstrate that adapting a definition modeling systems requires\nminimal amounts of data, but that there currently are gaps in what automatic\nmetrics do capture.", "published": "2025-07-13 08:35:23", "link": "http://arxiv.org/abs/2507.09536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Important is `Perfect' English for Machine Translation Prompts?", "abstract": "Large language models (LLMs) have achieved top results in recent machine\ntranslation evaluations, but they are also known to be sensitive to errors and\nperturbations in their prompts. We systematically evaluate how both humanly\nplausible and synthetic errors in user prompts affect LLMs' performance on two\nrelated tasks: Machine translation and machine translation evaluation. We\nprovide both a quantitative analysis and qualitative insights into how the\nmodels respond to increasing noise in the user prompt.\n  The prompt quality strongly affects the translation performance: With many\nerrors, even a good prompt can underperform a minimal or poor prompt without\nerrors. However, different noise types impact translation quality differently,\nwith character-level and combined noisers degrading performance more than\nphrasal perturbations. Qualitative analysis reveals that lower prompt quality\nlargely leads to poorer instruction following, rather than directly affecting\ntranslation quality itself. Further, LLMs can still translate in scenarios with\noverwhelming random noise that would make the prompt illegible to humans.", "published": "2025-07-13 06:33:12", "link": "http://arxiv.org/abs/2507.09509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models", "abstract": "Long-context language models (LCLMs) have exhibited impressive capabilities\nin long-context understanding tasks. Among these, long-context referencing -- a\ncrucial task that requires LCLMs to attribute items of interest to specific\nparts of long-context data -- remains underexplored. To bridge this gap, this\npaper proposes Referencing Evaluation for Long-context Language Models\n(Ref-Long), a novel benchmark designed to assess the long-context referencing\ncapability of LCLMs. Specifically, Ref-Long requires LCLMs to identify the\nindexes of documents that reference a specific key, emphasizing contextual\nrelationships between the key and the documents over simple retrieval. Based on\nthe task design, we construct three subsets ranging from synthetic to realistic\nscenarios to form the Ref-Long benchmark. Experimental results of 13 LCLMs\nreveal significant shortcomings in long-context referencing, even among\nadvanced models like GPT-4o. To further investigate these challenges, we\nconduct comprehensive analyses, including human evaluations, task format\nadjustments, fine-tuning experiments, and error analyses, leading to several\nkey insights. Our data and code can be found in https://github.\ncom/wujunjie1998/Ref-Long.", "published": "2025-07-13 06:17:53", "link": "http://arxiv.org/abs/2507.09506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities", "abstract": "Modern enterprise environments demand intelligent systems capable of handling\ncomplex, dynamic, and multi-faceted tasks with high levels of autonomy and\nadaptability. However, traditional single-purpose AI systems often lack\nsufficient coordination, memory reuse, and task decomposition capabilities,\nlimiting their scalability in realistic settings. To address these challenges,\nwe present \\textbf{GoalfyMax}, a protocol-driven framework for end-to-end\nmulti-agent collaboration. GoalfyMax introduces a standardized Agent-to-Agent\n(A2A) communication layer built on the Model Context Protocol (MCP), allowing\nindependent agents to coordinate through asynchronous, protocol-compliant\ninteractions. It incorporates the Experience Pack (XP) architecture, a layered\nmemory system that preserves both task rationales and execution traces,\nenabling structured knowledge retention and continual learning. Moreover, our\nsystem integrates advanced features including multi-turn contextual dialogue,\nlong-short term memory modules, and dynamic safety validation, supporting\nrobust, real-time strategy adaptation. Empirical results on complex task\norchestration benchmarks and case study demonstrate that GoalfyMax achieves\nsuperior adaptability, coordination, and experience reuse compared to baseline\nframeworks. These findings highlight its potential as a scalable, future-ready\nfoundation for multi-agent intelligent systems.", "published": "2025-07-13 05:13:52", "link": "http://arxiv.org/abs/2507.09497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Balanced Training Data Augmentation for Aspect-Based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) is a crucial fine-grained task in\nsocial media scenarios to identify the sentiment polarity of specific aspect\nterms in a sentence. Although many existing studies leverage large language\nmodels (LLMs) to perform ABSA due to their strong context understanding\ncapabilities, they still face challenges to learn the context information in\nthe running text because of the short text, as well as the small and unbalanced\nlabeled training data, where most data are labeled with positive sentiment.\nData augmentation (DA) is a feasible strategy for providing richer contextual\ninformation, especially when using LLMs to create synthetic training data, but\nfaces challenges in ensuring a high quality of the augmented data.In this\npaper, we propose an LLM-based ABSA approach with training data\naugmentation.Specifically, an LLM is prompted to generate augmented training\ndata based on the original training data, so as to construct a new training\ndata with larger size and balanced label distributions to better train an ABSA\nmodel. Meanwhile, in order to improve the quality of the augmented data, we\npropose a reinforcement learning approach to optimize the data augmentation.\nLLM.Experiment results and further analyses on English benchmark datasets for\nABSA demonstrate the effectiveness of our approach, where superior performance\nis observed over strong baselines and most existing studies.", "published": "2025-07-13 04:07:07", "link": "http://arxiv.org/abs/2507.09485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning", "abstract": "Human emotions are complex, with sarcasm being a subtle and distinctive form.\nDespite progress in sarcasm research, sarcasm generation remains underexplored,\nprimarily due to the overreliance on textual modalities and the neglect of\nvisual cues, as well as the mismatch between image content and sarcastic intent\nin existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasm\ngeneration dataset with 4,970 samples, each containing an image, a sarcastic\ntext, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generation\nframework that integrates Proximal Policy Optimization (PPO) and contrastive\nlearning. PPO utilizes reward scores from DIP to steer the generation of\nsarcastic texts, while contrastive learning encourages the model to favor\noutputs with higher reward scores. These strategies improve overall generation\nquality and produce texts with more pronounced sarcastic intent. We evaluate\nViSP across five metric sets and find it surpasses all baselines, including\nlarge language models, underscoring their limitations in sarcasm generation.\nFurthermore, we analyze the distributions of Sarcasm Scores and Factual\nIncongruity for both M2SaG and the texts generated by ViSP. The generated texts\nexhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity\n(0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcastic\ncontent than the original dataset. % The dataset and code will be publicly\navailable. Our dataset and code will be released at\n\\textit{https://github.com/wclapply/ViSP}.", "published": "2025-07-13 04:03:05", "link": "http://arxiv.org/abs/2507.09482v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs on Sequential API Call Through Automated Test Generation", "abstract": "By integrating tools from external APIs, Large Language Models (LLMs) have\nexpanded their promising capabilities in a diverse spectrum of complex\nreal-world tasks. However, testing, evaluation, and analysis of LLM tool use\nremain in their early stages. Most existing benchmarks rely on manually\ncollected test cases, many of which cannot be automatically checked for\nsemantic correctness and instead depend on static methods such as string\nmatching. Additionally, these benchmarks often overlook the complex\ninteractions that occur between sequential API calls, which are common in\nreal-world applications. To fill the gap, in this paper, we introduce StateGen,\nan automated framework designed to generate diverse coding tasks involving\nsequential API interactions. StateGen combines state-machine-based API\nconstraint solving and validation, energy-based sampling, and control-flow\ninjection to generate executable programs. These programs are then translated\ninto human-like natural language task descriptions through a collaboration of\ntwo LLM agents. Utilizing StateGen, we construct StateEval, a benchmark\nencompassing 120 verified test cases spanning across three representative\nscenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental\nresults confirm that StateGen can effectively generate challenging and\nrealistic API-oriented tasks, highlighting areas for improvement in current\nLLMs incorporating APIs.", "published": "2025-07-13 03:52:51", "link": "http://arxiv.org/abs/2507.09481v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs", "abstract": "Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language\nModels (LLMs) by injecting external knowledge, yet it falls short on problems\nthat demand multi-step inference; conversely, purely reasoning-oriented\napproaches often hallucinate or mis-ground facts. This survey synthesizes both\nstrands under a unified reasoning-retrieval perspective. We first map how\nadvanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then,\nwe show how retrieved knowledge of different type supply missing premises and\nexpand context for complex inference (RAG-Enhanced Reasoning). Finally, we\nspotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs\niteratively interleave search and reasoning to achieve state-of-the-art\nperformance across knowledge-intensive benchmarks. We categorize methods,\ndatasets, and open challenges, and outline research avenues toward deeper\nRAG-Reasoning systems that are more effective, multimodally-adaptive,\ntrustworthy, and human-centric. The collection is available at\nhttps://github.com/DavidZWZ/Awesome-RAG-Reasoning.", "published": "2025-07-13 03:29:41", "link": "http://arxiv.org/abs/2507.09477v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The CoNLL-2013 Shared Task on Grammatical Error Correction", "abstract": "The CoNLL-2013 shared task was devoted to grammatical error correction. In\nthis paper, we give the task definition, present the data sets, and describe\nthe evaluation metric and scorer used in the shared task. We also give an\noverview of the various approaches adopted by the participating teams, and\npresent the evaluation results.", "published": "2025-07-13 03:21:05", "link": "http://arxiv.org/abs/2507.09474v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models", "abstract": "This study explores the optimization of the DRAGON Longformer base model for\nclinical text classification, specifically targeting the binary classification\nof medical case descriptions. A dataset of 500 clinical cases containing\nstructured medical observations was used, with 400 cases for training and 100\nfor validation. Enhancements to the pre-trained\njoeranbosma/dragon-longformer-base-mixed-domain model included hyperparameter\ntuning, domain-specific preprocessing, and architectural adjustments. Key\nmodifications involved increasing sequence length from 512 to 1024 tokens,\nadjusting learning rates from 1e-05 to 5e-06, extending training epochs from 5\nto 8, and incorporating specialized medical terminology. The optimized model\nachieved notable performance gains: accuracy improved from 72.0% to 85.2%,\nprecision from 68.0% to 84.1%, recall from 75.0% to 86.3%, and F1-score from\n71.0% to 85.2%. Statistical analysis confirmed the significance of these\nimprovements (p < .001). The model demonstrated enhanced capability in\ninterpreting medical terminology, anatomical measurements, and clinical\nobservations. These findings contribute to domain-specific language model\nresearch and offer practical implications for clinical natural language\nprocessing applications. The optimized model's strong performance across\ndiverse medical conditions underscores its potential for broad use in\nhealthcare settings.", "published": "2025-07-13 03:10:19", "link": "http://arxiv.org/abs/2507.09470v1", "categories": ["cs.CL", "cs.AI", "68T07"], "primary_category": "cs.CL"}
{"title": "Hierarchical Abstraction Enables Human-Like 3D Object Recognition in Deep Learning Models", "abstract": "Both humans and deep learning models can recognize objects from 3D shapes\ndepicted with sparse visual information, such as a set of points randomly\nsampled from the surfaces of 3D objects (termed a point cloud). Although deep\nlearning models achieve human-like performance in recognizing objects from 3D\nshapes, it remains unclear whether these models develop 3D shape\nrepresentations similar to those used by human vision for object recognition.\nWe hypothesize that training with 3D shapes enables models to form\nrepresentations of local geometric structures in 3D shapes. However, their\nrepresentations of global 3D object shapes may be limited. We conducted two\nhuman experiments systematically manipulating point density and object\norientation (Experiment 1), and local geometric structure (Experiment 2).\nHumans consistently performed well across all experimental conditions. We\ncompared two types of deep learning models, one based on a convolutional neural\nnetwork (DGCNN) and the other on visual transformers (point transformer), with\nhuman performance. We found that the point transformer model provided a better\naccount of human performance than the convolution-based model. The advantage\nmainly results from the mechanism in the point transformer model that supports\nhierarchical abstraction of 3D shapes.", "published": "2025-07-13 23:54:45", "link": "http://arxiv.org/abs/2507.09830v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VRU-Accident: A Vision-Language Benchmark for Video Question Answering and Dense Captioning for Accident Scene Understanding", "abstract": "Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and\ncyclists, is a critical challenge for autonomous driving systems, as crashes\ninvolving VRUs often result in severe or fatal consequences. While multimodal\nlarge language models (MLLMs) have shown promise in enhancing scene\nunderstanding and decision making in autonomous vehicles, there is currently no\nstandardized benchmark to quantitatively evaluate their reasoning abilities in\ncomplex, safety-critical scenarios involving VRUs. To address this gap, we\npresent VRU-Accident, a large-scale vision-language benchmark designed to\nevaluate MLLMs in high-risk traffic scenarios involving VRUs. VRU-Accident\ncomprises 1K real-world dashcam accident videos, annotated with 6K\nmultiple-choice question-answer pairs across six safety-critical categories\n(with 24K candidate options and 3.4K unique answer choices), as well as 1K\ndense scene descriptions. Unlike prior works, our benchmark focuses explicitly\non VRU-vehicle accidents, providing rich, fine-grained annotations that capture\nboth spatial-temporal dynamics and causal semantics of accidents. To assess the\ncurrent landscape of MLLMs, we conduct a comprehensive evaluation of 17\nstate-of-the-art models on the multiple-choice VQA task and on the dense\ncaptioning task. Our findings reveal that while MLLMs perform reasonably well\non visually grounded attributes, they face significant challenges in reasoning\nand describing accident causes, types, and preventability.", "published": "2025-07-13 22:14:35", "link": "http://arxiv.org/abs/2507.09815v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection", "abstract": "Recent advancements in Vision-Language Models like CLIP have enabled\nzero-shot OOD detection by leveraging both image and textual label information.\nAmong these, negative label-based methods such as NegLabel and CSP have shown\npromising results by utilizing a lexicon of words to define negative labels for\ndistinguishing OOD samples. However, these methods suffer from detecting\nin-distribution samples as OOD due to negative labels that are subcategories of\nin-distribution labels or proper nouns. They also face limitations in handling\nimages that match multiple in-distribution and negative labels. We propose\nNegRefine, a novel negative label refinement framework for zero-shot OOD\ndetection. By introducing a filtering mechanism to exclude subcategory labels\nand proper nouns from the negative label set and incorporating a\nmulti-matching-aware scoring function that dynamically adjusts the\ncontributions of multiple labels matching an image, NegRefine ensures a more\nrobust separation between in-distribution and OOD samples. We evaluate\nNegRefine on large-scale benchmarks, including ImageNet-1K. Source code is\navailable at https://github.com/ah-ansari/NegRefine.", "published": "2025-07-13 21:15:30", "link": "http://arxiv.org/abs/2507.09795v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design", "abstract": "Computer-aided design (CAD) is the digital construction of 2D and 3D objects,\nand is central to a wide range of engineering and manufacturing applications\nlike automobile and aviation. Despite its importance, CAD modeling remains\nlargely a time-intensive, manual task. Recent works have attempted to automate\nthis process with small transformer-based models and handcrafted CAD sequence\nrepresentations. However, there has been little effort to leverage the\npotential of large language models (LLMs) for sequential CAD design. In this\nwork, we introduce a new large-scale dataset of more than 170k CAD models\nannotated with high-quality, human-like descriptions generated with our\npipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs\nto generate CAD sequences represented in a JSON-based format from natural\nlanguage descriptions, demonstrating the viability and effectiveness of this\napproach for text-conditioned CAD generation. Because simple metrics often fail\nto reflect the quality of generated objects, we introduce geometric and\ntopological metrics based on sphericity, mean curvature, and Euler\ncharacteristic to provide richer structural insights. Our experiments and\nablation studies on both synthetic and human-annotated data demonstrate that\nCADmium is able to automate CAD design, drastically speeding up the design of\nnew objects. The dataset, code, and fine-tuned models are available online.", "published": "2025-07-13 21:11:53", "link": "http://arxiv.org/abs/2507.09792v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Pairwise Alignment & Compatibility for Arbitrarily Irregular Image Fragments", "abstract": "Pairwise compatibility calculation is at the core of most\nfragments-reconstruction algorithms, in particular those designed to solve\ndifferent types of the jigsaw puzzle problem. However, most existing approaches\nfail, or aren't designed to deal with fragments of realistic geometric\nproperties one encounters in real-life puzzles. And in all other cases,\ncompatibility methods rely strongly on the restricted shapes of the fragments.\nIn this paper, we propose an efficient hybrid (geometric and pictorial)\napproach for computing the optimal alignment for pairs of fragments, without\nany assumptions about their shapes, dimensions, or pictorial content. We\nintroduce a new image fragments dataset generated via a novel method for image\nfragmentation and a formal erosion model that mimics real-world archaeological\nerosion, along with evaluation metrics for the compatibility task. We then\nembed our proposed compatibility into an archaeological puzzle-solving\nframework and demonstrate state-of-the-art neighborhood-level precision and\nrecall on the RePAIR 2D dataset, directly reflecting compatibility performance\nimprovements.", "published": "2025-07-13 19:49:42", "link": "http://arxiv.org/abs/2507.09767v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AI-Enhanced Pediatric Pneumonia Detection: A CNN-Based Approach Using Data Augmentation and Generative Adversarial Networks (GANs)", "abstract": "Pneumonia is a leading cause of mortality in children under five, requiring\naccurate chest X-ray diagnosis. This study presents a machine learning-based\nPediatric Chest Pneumonia Classification System to assist healthcare\nprofessionals in diagnosing pneumonia from chest X-ray images. The CNN-based\nmodel was trained on 5,863 labeled chest X-ray images from children aged 0-5\nyears from the Guangzhou Women and Children's Medical Center. To address\nlimited data, we applied augmentation techniques (rotation, zooming, shear,\nhorizontal flipping) and employed GANs to generate synthetic images, addressing\nclass imbalance. The system achieved optimal performance using combined\noriginal, augmented, and GAN-generated data, evaluated through accuracy and F1\nscore metrics. The final model was deployed via a Flask web application,\nenabling real-time classification with probability estimates. Results\ndemonstrate the potential of deep learning and GANs in improving diagnostic\naccuracy and efficiency for pediatric pneumonia classification, particularly\nvaluable in resource-limited clinical settings\nhttps://github.com/AbdulManaf12/Pediatric-Chest-Pneumonia-Classification", "published": "2025-07-13 19:38:49", "link": "http://arxiv.org/abs/2507.09759v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Advancing Text-to-3D Generation with Linearized Lookahead Variational Score Distillation", "abstract": "Text-to-3D generation based on score distillation of pre-trained 2D diffusion\nmodels has gained increasing interest, with variational score distillation\n(VSD) as a remarkable example. VSD proves that vanilla score distillation can\nbe improved by introducing an extra score-based model, which characterizes the\ndistribution of images rendered from 3D models, to correct the distillation\ngradient. Despite the theoretical foundations, VSD, in practice, is likely to\nsuffer from slow and sometimes ill-posed convergence. In this paper, we perform\nan in-depth investigation of the interplay between the introduced score model\nand the 3D model, and find that there exists a mismatching problem between LoRA\nand 3D distributions in practical implementation. We can simply adjust their\noptimization order to improve the generation quality. By doing so, the score\nmodel looks ahead to the current 3D state and hence yields more reasonable\ncorrections. Nevertheless, naive lookahead VSD may suffer from unstable\ntraining in practice due to the potential over-fitting. To address this, we\npropose to use a linearized variant of the model for score distillation, giving\nrise to the Linearized Lookahead Variational Score Distillation ($L^2$-VSD).\n$L^2$-VSD can be realized efficiently with forward-mode autodiff\nfunctionalities of existing deep learning libraries. Extensive experiments\nvalidate the efficacy of $L^2$-VSD, revealing its clear superiority over prior\nscore distillation-based methods. We also show that our method can be\nseamlessly incorporated into any other VSD-based text-to-3D framework.", "published": "2025-07-13 18:57:45", "link": "http://arxiv.org/abs/2507.09748v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Universal Physics Simulation: A Foundational Diffusion Approach", "abstract": "We present the first foundational AI model for universal physics simulation\nthat learns physical laws directly from boundary-condition data without\nrequiring a priori equation encoding. Traditional physics-informed neural\nnetworks (PINNs) and finite-difference methods necessitate explicit\nmathematical formulation of governing equations, fundamentally limiting their\ngeneralizability and discovery potential. Our sketch-guided diffusion\ntransformer approach reimagines computational physics by treating simulation as\na conditional generation problem, where spatial boundary conditions guide the\nsynthesis of physically accurate steady-state solutions.\n  By leveraging enhanced diffusion transformer architectures with novel spatial\nrelationship encoding, our model achieves direct boundary-to-equilibrium\nmapping and is generalizable to diverse physics domains. Unlike sequential\ntime-stepping methods that accumulate errors over iterations, our approach\nbypasses temporal integration entirely, directly generating steady-state\nsolutions with SSIM > 0.8 while maintaining sub-pixel boundary accuracy. Our\ndata-informed approach enables physics discovery through learned\nrepresentations analyzable via Layer-wise Relevance Propagation (LRP),\nrevealing emergent physical relationships without predetermined mathematical\nconstraints. This work represents a paradigm shift from AI-accelerated physics\nto AI-discovered physics, establishing the first truly universal physics\nsimulation framework.", "published": "2025-07-13 18:12:34", "link": "http://arxiv.org/abs/2507.09733v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07, 65M06, 78M34", "I.2.6; I.4.8; J.2"], "primary_category": "cs.LG"}
{"title": "Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging", "abstract": "Medical Imagings are considered one of the crucial diagnostic tools for\ndifferent bones-related diseases, especially bones fractures. This paper\ninvestigates the robustness of pre-trained deep learning models for classifying\nbone fractures in X-ray images and seeks to address global healthcare disparity\nthrough the lens of technology. Three deep learning models have been tested\nunder varying simulated equipment quality conditions. ResNet50, VGG16 and\nEfficientNetv2 are the three pre-trained architectures which are compared.\nThese models were used to perform bone fracture classification as images were\nprogressively degraded using noise. This paper specifically empirically studies\nhow the noise can affect the bone fractures detection and how the pre-trained\nmodels performance can be changes due to the noise that affect the quality of\nthe X-ray images. This paper aims to help replicate real world challenges\nexperienced by medical imaging technicians across the world. Thus, this paper\nestablishes a methodological framework for assessing AI model degradation using\ntransfer learning and controlled noise augmentation. The findings provide\npractical insight into how robust and generalizable different pre-trained deep\nlearning powered computer vision models can be when used in different contexts.", "published": "2025-07-13 18:07:34", "link": "http://arxiv.org/abs/2507.09731v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Visual Homing in Outdoor Robots Using Mushroom Body Circuits and Learning Walks", "abstract": "Ants achieve robust visual homing with minimal sensory input and only a few\nlearning walks, inspiring biomimetic solutions for autonomous navigation. While\nMushroom Body (MB) models have been used in robotic route following, they have\nnot yet been applied to visual homing. We present the first real-world\nimplementation of a lateralized MB architecture for visual homing onboard a\ncompact autonomous car-like robot. We test whether the sign of the angular path\nintegration (PI) signal can categorize panoramic views, acquired during\nlearning walks and encoded in the MB, into \"goal on the left\" and \"goal on the\nright\" memory banks, enabling robust homing in natural outdoor settings. We\nvalidate this approach through four incremental experiments: (1) simulation\nshowing attractor-like nest dynamics; (2) real-world homing after decoupled\nlearning walks, producing nest search behavior; (3) homing after random walks\nusing noisy PI emulated with GPS-RTK; and (4) precise stopping-at-the-goal\nbehavior enabled by a fifth MB Output Neuron (MBON) encoding goal-views to\ncontrol velocity. This mimics the accurate homing behavior of ants and\nfunctionally resembles waypoint-based position control in robotics, despite\nrelying solely on visual input. Operating at 8 Hz on a Raspberry Pi 4 with\n32x32 pixel views and a memory footprint under 9 kB, our system offers a\nbiologically grounded, resource-efficient solution for autonomous visual\nhoming.", "published": "2025-07-13 17:54:01", "link": "http://arxiv.org/abs/2507.09725v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Token Compression Meets Compact Vision Transformers: A Survey and Comparative Evaluation for Edge AI", "abstract": "Token compression techniques have recently emerged as powerful tools for\naccelerating Vision Transformer (ViT) inference in computer vision. Due to the\nquadratic computational complexity with respect to the token sequence length,\nthese methods aim to remove less informative tokens before the attention layers\nto improve inference throughput. While numerous studies have explored various\naccuracy-efficiency trade-offs on large-scale ViTs, two critical gaps remain.\nFirst, there is a lack of unified survey that systematically categorizes and\ncompares token compression approaches based on their core strategies (e.g.,\npruning, merging, or hybrid) and deployment settings (e.g., fine-tuning vs.\nplug-in). Second, most benchmarks are limited to standard ViT models (e.g.,\nViT-B, ViT-L), leaving open the question of whether such methods remain\neffective when applied to structurally compressed transformers, which are\nincreasingly deployed on resource-constrained edge devices. To address these\ngaps, we present the first systematic taxonomy and comparative study of token\ncompression methods, and we evaluate representative techniques on both standard\nand compact ViT architectures. Our experiments reveal that while token\ncompression methods are effective for general-purpose ViTs, they often\nunderperform when directly applied to compact designs. These findings not only\nprovide practical insights but also pave the way for future research on\nadapting token optimization techniques to compact transformer-based networks\nfor edge AI and AI agent applications.", "published": "2025-07-13 16:26:05", "link": "http://arxiv.org/abs/2507.09702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ExpStar: Towards Automatic Commentary Generation for Multi-discipline Scientific Experiments", "abstract": "Experiment commentary is crucial in describing the experimental procedures,\ndelving into underlying scientific principles, and incorporating\ncontent-related safety guidelines. In practice, human teachers rely heavily on\nsubject-specific expertise and invest significant time preparing such\ncommentary. To address this challenge, we introduce the task of automatic\ncommentary generation across multi-discipline scientific experiments. While\nrecent progress in large multimodal models (LMMs) has demonstrated promising\ncapabilities in video understanding and reasoning, their ability to generate\nfine-grained and insightful experiment commentary remains largely\nunderexplored. In this paper, we make the following contributions: (i) We\nconstruct \\textit{ExpInstruct}, the first dataset tailored for experiment\ncommentary generation, featuring over 7\\textit{K} step-level commentaries\nacross 21 scientific subjects from 3 core disciplines (\\ie, science, healthcare\nand engineering). Each sample includes procedural descriptions along with\npotential scientific principles (\\eg, chemical equations and physical laws) and\nsafety guidelines. (ii) We propose ExpStar, an automatic experiment commentary\ngeneration model that leverages a retrieval-augmented mechanism to adaptively\naccess, evaluate, and utilize external knowledge. (iii) Extensive experiments\nshow that our ExpStar substantially outperforms 14 leading LMMs, which\nhighlights the superiority of our dataset and model. We believe that ExpStar\nholds great potential for advancing AI-assisted scientific experiment\ninstruction.", "published": "2025-07-13 16:09:58", "link": "http://arxiv.org/abs/2507.09693v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Divide and Conquer Algorithm for Deciding Group Cellular Automata Dynamics", "abstract": "We prove that many dynamical properties of group cellular automata (i.e.,\ncellular automata defined on any finite group and with global rule which is an\nendomorphism), including surjectivity, injectivity, sensitivity to initial\nconditions, strong transitivity, positive expansivity, and topological entropy,\ncan be decided by decomposing them into a set of much simpler group cellular\nautomata. To be more specific, we provide a novel algorithmic technique\nallowing one to decompose the group cellular automaton to be studied into a\nfinite number of group cellular automata, some of them defined on abelian\ngroups, while others, if any, defined on products of simple non-abelian\nisomorphic groups.\n  It is worth noting that the groups resulting from the decomposition only\ndepend on the original group and therefore they are completely independent of\nboth the automaton and the property under investigation. As a result, they do\nnot inherit any aspect of the complexity of the automaton under investigation.\n  We prove that the group cellular automata obtained by the decomposition\npreserve dynamical properties and turn out to be much easier to analyze if\ncompared to the original cellular automaton. As a consequence of these results,\nwe show that injectivity, surjectivity and sensitivity to initial conditions\nare decidable properties and that no strongly transitive, and therefore no\npositively expansive, group cellular automata defined on non-abelian groups\nexist. Moreover, we prove that the topological entropy of a group cellular\nautomaton can be computed, provided we know how to compute the topological\nentropy for group cellular automata defined on products of simple non-abelian\nisomorphic groups and on abelian groups.", "published": "2025-07-13 19:39:47", "link": "http://arxiv.org/abs/2507.09761v1", "categories": ["cs.FL", "cs.DM"], "primary_category": "cs.FL"}
{"title": "Breaking the Symmetries of Amenable Graphs", "abstract": "In this paper, we consider two ways of breaking a graph's symmetry:\ndistinguishing labelings and fixing sets. A distinguishing labeling $\\phi$ of\n$G$ colors the vertices of $G$ so that the only automorphism of the labeled\ngraph $(G, \\phi)$ is the identity map. The distinguishing number of $G$,\n$D(G)$, is the fewest number of colors needed to create a distinguishing\nlabeling of $G$. A subset $S$ of vertices is a fixing set of $G$ if the only\nautomorphism of $G$ that fixes every element in $S$ is the identity map. The\nfixing number of $G$, $Fix(G)$, is the size of a smallest fixing set. A fixing\nset $S$ of $G$ can be translated into a distinguishing labeling $\\phi_S$ by\nassigning distinct colors to the vertices in $S$ and assigning another color\n(e.g., the ``null\" color) to the vertices not in $S$.\n  Color refinement is a well-known efficient heuristic for graph isomorphism. A\ngraph $G$ is amenable if, for any graph $H$, color refinement correctly\ndetermines whether $G$ and $H$ are isomorphic or not. Using the\ncharacterization of amenable graphs by Arvind et al. as a starting point, we\nshow that both $D(G)$ and $Fix(G)$ can be computed in $O((|V(G)|+|E(G)|) \\log\n|V(G)|)$ time when $G$ is an amenable graph.", "published": "2025-07-13 17:06:55", "link": "http://arxiv.org/abs/2507.09710v1", "categories": ["math.CO", "cs.DM", "05", "G.2.1; G.2.2"], "primary_category": "math.CO"}
{"title": "Nearly Tight Sample Complexity for Matroid Online Contention Resolution", "abstract": "Due to their numerous applications, in particular in Mechanism Design,\nProphet Inequalities have experienced a surge of interest. They describe\ncompetitive ratios for basic stopping time problems where random variables get\nrevealed sequentially. A key drawback in the classical setting is the\nassumption of full distributional knowledge of the involved random variables,\nwhich is often unrealistic. A natural way to address this is via sample-based\napproaches, where only a limited number of samples from the distribution of\neach random variable is available. Recently, Fu, Lu, Gavin Tang, Wu, Wu, and\nZhang (2024) showed that sample-based Online Contention Resolution Schemes\n(OCRS) are a powerful tool to obtain sample-based Prophet Inequalities. They\npresented the first sample-based OCRS for matroid constraints, which is a\nheavily studied constraint family in this context, as it captures many\ninteresting settings. This allowed them to get the first sample-based Matroid\nProphet Inequality, using $O(\\log^4 n)$ many samples (per random variable),\nwhere $n$ is the number of random variables, while obtaining a constant\ncompetitiveness of $\\frac{1}{4}-\\varepsilon$.\n  We present a nearly optimal sample-based OCRS for matroid constraints, which\nuses only $O(\\log \\rho \\cdot \\log^2\\log\\rho)$ many samples, almost matching a\nknown lower bound of $\\Omega(\\log \\rho)$, where $\\rho \\leq n$ is the rank of\nthe matroid. Through the above-mentioned connection to Prophet Inequalities,\nthis yields a sample-based Matroid Prophet Inequality using only $O(\\log n +\n\\log\\rho \\cdot \\log^2\\log\\rho)$ many samples, and matching the competitiveness\nof $\\frac{1}{4}-\\varepsilon$, which is the best known competitiveness for the\nconsidered almighty adversary setting even when the distributions are fully\nknown.", "published": "2025-07-13 06:18:48", "link": "http://arxiv.org/abs/2507.09507v1", "categories": ["cs.DS", "cs.DM", "cs.GT", "68W27 (Primary) 91A68, 68R05 (Secondary)", "F.2.2; G.2.1"], "primary_category": "cs.DS"}
{"title": "Generative Cognitive Diagnosis", "abstract": "Cognitive diagnosis (CD) models latent cognitive states of human learners by\nanalyzing their response patterns on diagnostic tests, serving as a crucial\nmachine learning technique for educational assessment and evaluation.\nTraditional cognitive diagnosis models typically follow a transductive\nprediction paradigm that optimizes parameters to fit response scores and\nextract learner abilities. These approaches face significant limitations as\nthey cannot perform instant diagnosis for new learners without computationally\nexpensive retraining and produce diagnostic outputs with limited reliability.\nIn this study, we introduces a novel generative diagnosis paradigm that\nfundamentally shifts CD from predictive to generative modeling, enabling\ninductive inference of cognitive states without parameter re-optimization. We\npropose two simple yet effective instantiations of this paradigm: Generative\nItem Response Theory (G-IRT) and Generative Neural Cognitive Diagnosis Model\n(G-NCDM), which achieve excellent performance improvements over traditional\nmethods. The generative approach disentangles cognitive state inference from\nresponse prediction through a well-designed generation process that\nincorporates identifiability and monotonicity conditions. Extensive experiments\non real-world datasets demonstrate the effectiveness of our methodology in\naddressing scalability and reliability challenges, especially $\\times 100$\nspeedup for the diagnosis of new learners. Our framework opens new avenues for\ncognitive diagnosis applications in artificial intelligence, particularly for\nintelligent model evaluation and intelligent education systems. The code is\navailable at https://github.com/CSLiJT/Generative-CD.git.", "published": "2025-07-13 23:55:05", "link": "http://arxiv.org/abs/2507.09831v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Identifying Offline Metrics that Predict Online Impact: A Pragmatic Strategy for Real-World Recommender Systems", "abstract": "A critical challenge in recommender systems is to establish reliable\nrelationships between offline and online metrics that predict real-world\nperformance. Motivated by recent advances in Pareto front approximation, we\nintroduce a pragmatic strategy for identifying offline metrics that align with\nonline impact. A key advantage of this approach is its ability to\nsimultaneously serve multiple test groups, each with distinct offline\nperformance metrics, in an online experiment controlled by a single model. The\nmethod is model-agnostic for systems with a neural network backbone, enabling\nbroad applicability across architectures and domains. We validate the strategy\nthrough a large-scale online experiment in the field of session-based\nrecommender systems on the OTTO e-commerce platform. The online experiment\nidentifies significant alignments between offline metrics and real-word\nclick-through rate, post-click conversion rate and units sold. Our strategy\nprovides industry practitioners with a valuable tool for understanding\noffline-to-online metric relationships and making informed, data-driven\ndecisions.", "published": "2025-07-13 10:24:41", "link": "http://arxiv.org/abs/2507.09566v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Criteria-Based LLM Relevance Judgments", "abstract": "Relevance judgments are crucial for evaluating information retrieval systems,\nbut traditional human-annotated labels are time-consuming and expensive. As a\nresult, many researchers turn to automatic alternatives to accelerate method\ndevelopment. Among these, Large Language Models (LLMs) provide a scalable\nsolution by generating relevance labels directly through prompting. However,\nprompting an LLM for a relevance label without constraints often results in not\nonly incorrect predictions but also outputs that are difficult for humans to\ninterpret. We propose the Multi-Criteria framework for LLM-based relevance\njudgments, decomposing the notion of relevance into multiple criteria--such as\nexactness, coverage, topicality, and contextual fit--to improve the robustness\nand interpretability of retrieval evaluations compared to direct grading\nmethods. We validate this approach on three datasets: the TREC Deep Learning\ntracks from 2019 and 2020, as well as LLMJudge (based on TREC DL 2023). Our\nresults demonstrate that Multi-Criteria judgments enhance the system\nranking/leaderboard performance. Moreover, we highlight the strengths and\nlimitations of this approach relative to direct grading approaches, offering\ninsights that can guide the development of future automatic evaluation\nframeworks in information retrieval.", "published": "2025-07-13 04:21:21", "link": "http://arxiv.org/abs/2507.09488v1", "categories": ["cs.IR", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Does UMBRELA Work on Other LLMs?", "abstract": "We reproduce the UMBRELA LLM Judge evaluation framework across a range of\nlarge language models (LLMs) to assess its generalizability beyond the original\nstudy. Our investigation evaluates how LLM choice affects relevance assessment\naccuracy, focusing on leaderboard rank correlation and per-label agreement\nmetrics. Results demonstrate that UMBRELA with DeepSeek V3 obtains very\ncomparable performance to GPT-4o (used in original work). For LLaMA-3.3-70B we\nobtain slightly lower performance, which further degrades with smaller LLMs.", "published": "2025-07-13 04:05:25", "link": "http://arxiv.org/abs/2507.09483v1", "categories": ["cs.IR", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in Multivariate Time Series", "abstract": "Understanding causal relationships in multivariate time series (MTS) is\nessential for effective decision-making in fields such as finance and\nmarketing, where complex dependencies and lagged effects challenge conventional\nanalytical approaches. We introduce Dynamic Sparse Causal-Attention Temporal\nNetworks for Interpretable Causality Discovery in MTS (DyCAST-Net), a novel\narchitecture designed to enhance causal discovery by integrating dilated\ntemporal convolutions and dynamic sparse attention mechanisms. DyCAST-Net\neffectively captures multiscale temporal dependencies through dilated\nconvolutions while leveraging an adaptive thresholding strategy in its\nattention mechanism to eliminate spurious connections, ensuring both accuracy\nand interpretability. A statistical shuffle test validation further strengthens\nrobustness by filtering false positives and improving causal inference\nreliability. Extensive evaluations on financial and marketing datasets\ndemonstrate that DyCAST-Net consistently outperforms existing models such as\nTCDF, GCFormer, and CausalFormer. The model provides a more precise estimation\nof causal delays and significantly reduces false discoveries, particularly in\nnoisy environments. Moreover, attention heatmaps offer interpretable insights,\nuncovering hidden causal patterns such as the mediated effects of advertising\non consumer behavior and the influence of macroeconomic indicators on financial\nmarkets. Case studies illustrate DyCAST-Net's ability to detect latent\nmediators and lagged causal factors, making it particularly effective in\nhigh-dimensional, dynamic settings. The model's architecture enhanced by\nRMSNorm stabilization and causal masking ensures scalability and adaptability\nacross diverse application domains", "published": "2025-07-13 01:03:27", "link": "http://arxiv.org/abs/2507.09439v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Majority Logic Decoding of Affine Grassmann Codes Over Nonbinary Fields", "abstract": "In this article, we consider the decoding problem of affine Grassmann codes\nover nonbinary fields. We use matrices of different ranks to construct a large\nset consisting of parity checks of affine Grassmann codes, which are orthogonal\nwith respect to a fixed coordinate. By leveraging the automorphism groups of\nthese codes, we generate a set of orthogonal parity checks for each coordinate.\nUsing these parity checks, we perform majority logic decoding to correct a\nlarge number of errors in affine Grassmann codes. The order of error correction\ncapability and the complexity of this decoder for affine Grassmann codes are\nthe same as those of the majority logic decoder for Grassmann codes proposed in\n[BS21].", "published": "2025-07-13 18:37:54", "link": "http://arxiv.org/abs/2507.09741v1", "categories": ["cs.IT", "math.IT", "14M15, 14G50, 94B27, 94B35"], "primary_category": "cs.IT"}
{"title": "RDD Function: A Tradeoff Between Rate and Distortion-in-Distortion", "abstract": "In this paper, we propose a novel function named Rate\nDistortion-in-Distortion (RDD) function as an extension of the classical\nrate-distortion (RD) function, where the expected distortion constraint is\nreplaced by the Gromov-type distortion. This distortion, integral to the\nGromov-Wasserstein (GW) distance, effectively defines the similarity in spaces\nof different dimensions without a direct metric between them. While our RDD\nfunction qualifies as an informational RD function, encoding theorems\nsubstantiate its status as an operational RD function, thereby underscoring its\npotential applicability in real-world source coding. Due to the high\ncomputational complexity associated with Gromov-type distortion, the RDD\nfunction cannot be solved analytically. Consequently, we develop an alternating\nmirror descent algorithm that significantly reduces computational complexity by\nemploying decomposition, linearization, and relaxation techniques. Simulations\non classical sources and different grids demonstrate the effectiveness of our\nalgorithm. By examining the distinctions and connections between the RDD\nfunction and the RD function, we anticipate that RDD function will play a novel\nrole in foreseeable future scenarios.", "published": "2025-07-13 17:15:21", "link": "http://arxiv.org/abs/2507.09712v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Metric complexity is a Bryant--Tupper diversity", "abstract": "The metric complexity (sometimes called Leinster--Cobbold maximum diversity)\nof a compact metric space is a recently introduced isometry-invariant of\ncompact metric spaces which generalizes the notion of cardinality, and can be\nthought of as a metric-sensitive analogue of maximum entropy. On the other\nhand, the notion of diversity introduced by Bryant and Tupper is an assignment\nof a real number to every finite subset of a fixed set, which generalizes the\nnotion of a metric. We establish a connection between these concepts by showing\nthat the former quantity naturally produces an example of the latter. Moreover,\nin contrast to several examples in the literature, the diversity that arises\nfrom metric complexity is Minkowski-superlinear for compact subsets of the real\nline.", "published": "2025-07-13 16:16:14", "link": "http://arxiv.org/abs/2507.09698v1", "categories": ["math.MG", "cs.IT", "math.IT", "51F99, 94A17, 54E35"], "primary_category": "math.MG"}
{"title": "Lightweight Deep Learning-Based Channel Estimation for RIS-Aided Extremely Large-Scale MIMO Systems on Resource-Limited Edge Devices", "abstract": "Next-generation wireless technologies such as 6G aim to meet demanding\nrequirements such as ultra-high data rates, low latency, and enhanced\nconnectivity. Extremely Large-Scale MIMO (XL-MIMO) and Reconfigurable\nIntelligent Surface (RIS) are key enablers, with XL-MIMO boosting spectral and\nenergy efficiency through numerous antennas, and RIS offering dynamic control\nover the wireless environment via passive reflective elements. However,\nrealizing their full potential depends on accurate Channel State Information\n(CSI). Recent advances in deep learning have facilitated efficient cascaded\nchannel estimation. However, the scalability and practical deployment of\nexisting estimation models in XL-MIMO systems remain limited. The growing\nnumber of antennas and RIS elements introduces a significant barrier to\nreal-time and efficient channel estimation, drastically increasing data volume,\nescalating computational complexity, requiring advanced hardware, and resulting\nin substantial energy consumption. To address these challenges, we propose a\nlightweight deep learning framework for efficient cascaded channel estimation\nin XL-MIMO systems, designed to minimize computational complexity and make it\nsuitable for deployment on resource-constrained edge devices. Using spatial\ncorrelations in the channel, we introduce a patch-based training mechanism that\nreduces the dimensionality of input to patch-level representations while\npreserving essential information, allowing scalable training for large-scale\nsystems. Simulation results under diverse conditions demonstrate that our\nframework significantly improves estimation accuracy and reduces computational\ncomplexity, regardless of the increasing number of antennas and RIS elements in\nXL-MIMO systems.", "published": "2025-07-13 13:42:42", "link": "http://arxiv.org/abs/2507.09627v1", "categories": ["cs.IT", "cs.CV", "cs.LG", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Wi-Fi: Twenty-Five Years and Counting", "abstract": "Today, Wi-Fi is over 25 years old. Yet, despite sharing the same branding\nname, today's Wi-Fi boasts entirely new capabilities that were not even on the\nroadmap 25 years ago. This article aims to provide a holistic and comprehensive\ntechnical and historical tutorial on Wi-Fi, beginning with IEEE 802.11b (Wi-Fi\n1) and looking forward to IEEE 802.11bn (Wi-Fi 8). This is the first tutorial\narticle to span these eight generations. Rather than a generation-by-generation\nexposition, we describe the key mechanisms that have advanced Wi-Fi. We begin\nby discussing spectrum allocation and coexistence, and detailing the IEEE\n802.11 standardization cycle. Second, we provide an overview of the physical\nlayer and describe key elements that have enabled data rates to increase by\nover 1,000x. Third, we describe how Wi-Fi Medium Access Control has been\nenhanced from the original Distributed Coordination Function to now include\ncapabilities spanning from frame aggregation to wideband spectrum access.\nFourth, we describe how Wi-Fi 5 first broke the one-user-at-a-time paradigm and\nintroduced multi-user access. Fifth, given the increasing use of mobile,\nbattery-powered devices, we describe Wi-Fi's energy-saving mechanisms over the\ngenerations. Sixth, we discuss how Wi-Fi was enhanced to seamlessly aggregate\nspectrum across 2.4 GHz, 5 GHz, and 6 GHz bands to improve throughput,\nreliability, and latency. Finally, we describe how Wi-Fi enables nearby Access\nPoints to coordinate in order to improve performance and efficiency. In the\nAppendix, we further discuss Wi-Fi developments beyond 802.11bn, including\nintegrated mmWave operations, sensing, security and privacy extensions, and the\nadoption of AI/ML.", "published": "2025-07-13 12:35:08", "link": "http://arxiv.org/abs/2507.09613v1", "categories": ["cs.NI", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.NI"}
{"title": "Introducing Meta-Fiber into Stacked Intelligent Metasurfaces for MIMO Communications: A Low-Complexity Design with only Two Layers", "abstract": "Stacked intelligent metasurfaces (SIMs), which integrate multiple\nprogrammable metasurface layers, have recently emerged as a promising\ntechnology for advanced wave-domain signal processing. SIMs benefit from\nflexible spatial degree-of-freedom (DoF) while reducing the requirement for\ncostly radio-frequency (RF) chains. However, current state-of-the-art SIM\ndesigns face challenges such as complex phase shift optimization and energy\nattenuation from multiple layers. To address these aspects, we propose\nincorporating meta-fibers into SIMs, with the aim of reducing the number of\nlayers and enhancing the energy efficiency. First, we introduce a\nmeta-fiber-connected 2-layer SIM that exhibits the same flexible signal\nprocessing capabilities as conventional multi-layer structures, and explains\nthe operating principle. Subsequently, we formulate and solve the optimization\nproblem of minimizing the mean square error (MSE) between the SIM channel and\nthe desired channel matrices. Specifically, by designing the phase shifts of\nthe meta-atoms associated with the transmitting-SIM and receiving-SIM, a\nnon-interference system with parallel subchannels is established. In order to\nreduce the computational complexity, a closed-form expression for each phase\nshift at each iteration of an alternating optimization (AO) algorithm is\nproposed. We show that the proposed algorithm is applicable to conventional\nmulti-layer SIMs. The channel capacity bound and computational complexity are\nanalyzed to provide design insights. Finally, numerical results are\nillustrated, demonstrating that the proposed two-layer SIM with meta-fiber\nachieves over a 25% improvement in channel capacity while reducing the total\nnumber of meta-atoms by 59% as compared with a conventional seven-layer SIM.", "published": "2025-07-13 10:56:33", "link": "http://arxiv.org/abs/2507.09575v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Negotiating Comfort: Simulating Personality-Driven LLM Agents in Shared Residential Social Networks", "abstract": "We use generative agents powered by large language models (LLMs) to simulate\na social network in a shared residential building, driving the temperature\ndecisions for a central heating system. Agents, divided into Family Members and\nRepresentatives, consider personal preferences, personal traits, connections,\nand weather conditions. Daily simulations involve family-level consensus\nfollowed by building-wide decisions among representatives. We tested three\npersonality traits distributions (positive, mixed, and negative) and found that\npositive traits correlate with higher happiness and stronger friendships.\nTemperature preferences, assertiveness, and selflessness have a significant\nimpact on happiness and decisions. This work demonstrates how LLM-driven agents\ncan help simulate nuanced human behavior where complex real-life human\nsimulations are difficult to set.", "published": "2025-07-13 14:43:45", "link": "http://arxiv.org/abs/2507.09657v1", "categories": ["cs.SI", "cs.MA"], "primary_category": "cs.SI"}
{"title": "Physics-informed neural networks for high-dimensional solutions and snaking bifurcations in nonlinear lattices", "abstract": "This paper introduces a framework based on physics-informed neural networks\n(PINNs) for addressing key challenges in nonlinear lattices, including solution\napproximation, bifurcation diagram construction, and linear stability analysis.\nWe first employ PINNs to approximate solutions of nonlinear systems arising\nfrom lattice models, using the Levenberg-Marquardt algorithm to optimize\nnetwork weights for greater accuracy. To enhance computational efficiency in\nhigh-dimensional settings, we integrate a stochastic sampling strategy. We then\nextend the method by coupling PINNs with a continuation approach to compute\nsnaking bifurcation diagrams, incorporating an auxiliary equation to\neffectively track successive solution branches. For linear stability analysis,\nwe adapt PINNs to compute eigenvectors, introducing output constraints to\nenforce positivity, in line with Sturm-Liouville theory. Numerical experiments\nare conducted on the discrete Allen-Cahn equation with cubic and quintic\nnonlinearities in one to five spatial dimensions. The results demonstrate that\nthe proposed approach achieves accuracy comparable to, or better than,\ntraditional numerical methods, especially in high-dimensional regimes where\ncomputational resources are a limiting factor. These findings highlight the\npotential of neural networks as scalable and efficient tools for the study of\ncomplex nonlinear lattice systems.", "published": "2025-07-13 20:41:55", "link": "http://arxiv.org/abs/2507.09782v1", "categories": ["math.NA", "cs.LG", "cs.NA", "cs.NE", "math.OC"], "primary_category": "math.NA"}
{"title": "Designing quantum chemistry algorithms with Just-In-Time compilation", "abstract": "We introduce just-in-time (JIT) compilation to the integral kernels for\nGaussian-type orbitals (GTOs) to enhance the efficiency of electron repulsion\nintegral computations. For Coulomb and exchange (JK) matrices, JIT-based\nalgorithms yield a 2x speedup for the small 6-31G* basis set on an NVIDIA\nA100-80G GPU. By incorporating a novel algorithm designed for orbitals with\nhigh angular momentum, the efficiency of JK evaluations with the large\ndef2-TZVPP basis set is improved by up to 4x. The core CUDA implementation is\ncompact, comprising only ~1,000 lines of code, including support for\nsingle-precision arithmetic. Furthermore, the single-precision implementation\nachieves a 3x speedup over the previous state-of-the-art.", "published": "2025-07-13 20:06:32", "link": "http://arxiv.org/abs/2507.09772v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "physics.comp-ph"}
{"title": "Energy Dissipation Rate Guided Adaptive Sampling for Physics-Informed Neural Networks: Resolving Surface-Bulk Dynamics in Allen-Cahn Systems", "abstract": "We introduce the Energy Dissipation Rate guided Adaptive Sampling (EDRAS)\nstrategy, a novel method that substantially enhances the performance of\nPhysics-Informed Neural Networks (PINNs) in solving thermodynamically\nconsistent partial differential equations (PDEs) over arbitrary domains. EDRAS\nleverages the local energy dissipation rate density as a guiding metric to\nidentify and adaptively re-sample critical collocation points from both the\ninterior and boundary of the computational domain. This dynamical sampling\napproach improves the accuracy of residual-based PINNs by aligning the training\nprocess with the underlying physical structure of the system. In this study, we\ndemonstrate the effectiveness of EDRAS using the Allen-Cahn phase field model\nin irregular geometries, achieving up to a sixfold reduction in the relative\nmean square error compared to traditional residual-based adaptive refinement\n(RAR) methods. Moreover, we compare EDRAS with other residual-based adaptive\nsampling approaches and show that EDRAS is not only computationally more\nefficient but also more likely to identify high-impact collocation points.\nThrough numerical solutions of the Allen-Cahn equation with both static\n(Neumann) and dynamic boundary conditions in 2D disk- and ellipse-shaped\ndomains solved using PINN coupled with EDRAS, we gain significant insights into\nhow dynamic boundary conditions influence bulk phase evolution and\nthermodynamic behavior. The proposed approach offers an effective, physically\ninformed enhancement to PINN frameworks for solving thermodynamically\nconsistent models, making PINN a robust and versatile computational tool for\ninvestigating complex thermodynamic processes in arbitrary geometries.", "published": "2025-07-13 19:34:58", "link": "http://arxiv.org/abs/2507.09757v1", "categories": ["math.NA", "cs.LG", "cs.NA", "35K57, 68T07"], "primary_category": "math.NA"}
{"title": "Efficient FRW Transitions via Stochastic Finite Differences for Handling Non-Stratified Dielectrics", "abstract": "The accuracy of floating-random-walk (FRW) based capacitance extraction\nstands only when the recursive FRW transitions are sampled unbiasedly according\nto surrounding dielectrics. Advanced technology profiles, featuring complicated\nnon-stratified dielectrics, challenge the accuracy of existing FRW transition\nschemes that approximate dielectrics with stratified or eight-octant patterns.\nIn this work, we propose an algorithm named MicroWalk, enabling accurate FRW\ntransitions for arbitrary dielectrics while keeping high efficiency. It is\nprovably unbiased and equivalent to using transition probabilities solved by\nfinite difference method, but at orders of magnitude lower cost (802$\\times$\nfaster). An enhanced 3-D capacitance solver is developed with a hybrid strategy\nfor complicated dielectrics, combining MicroWalk with the special treatment for\nthe first transition cube and the analytical algorithm for stratified cubes.\nExperiments on real-world structures show that our solver achieves a\nsignificant accuracy advantage over existing FRW solvers, while preserving high\nefficiency.", "published": "2025-07-13 18:07:32", "link": "http://arxiv.org/abs/2507.09730v1", "categories": ["cs.AR", "cs.NA", "math.NA"], "primary_category": "cs.AR"}
{"title": "Pyramid transforms via nonstationary subdivision schemes", "abstract": "Pyramid transforms are constructive methods for analyzing sequences in a\nmultiscale fashion. Traditionally, these transforms rely on stationary\nupsampling and downsampling operations. In this paper, we propose employing\nnonstationary subdivision schemes as upsampling operators that vary according\nto the refinement level. These schemes offer greater flexibility, enabling the\ndevelopment of advanced multiscale transforms, including geometric multiscale\nanalysis. We establish the fundamental properties of these nonstationary\noperators and demonstrate their effectiveness in capturing and analyzing\ngeometric features. In particular, we present applications to highlight their\nutility in detecting geometric structures in planar objects.", "published": "2025-07-13 15:03:46", "link": "http://arxiv.org/abs/2507.09668v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Bayesian dictionary learning estimation of cell membrane permeability from surface pH data", "abstract": "Gas transport across cell membrane is a very important process in\nbiochemistry which is essential for many crucial tasks, including cell\nrespiration pH regulation in the cell. In the late 1990's, the suggestion that\ngasses are transported via preferred gas channels embedded into the cell\nmembrane challenged the century old Overton's theory that gases pass through\nthe lipid cell membrane by diffusing across the concentration gradient. Since\nexperimental evidence alone does not provide enough evidence to favor one of\nthe proposed mechanisms, mathematical models have been introduced to provide a\ncontext for the interpretation of laboratory measurement. Following up on\nprevious work where the membrane permeability was estimated using particle\nfilter, in this article we propose an algorithm based on dictionary learning\nfor estimating cell membrane permeability. Computed examples illustrate that\nthe novel approach, which can be applied when the properties of the membrane do\nnot change in the course of the data collection process, is computationally\nmuch more efficient than particle filter.", "published": "2025-07-13 14:34:31", "link": "http://arxiv.org/abs/2507.09651v1", "categories": ["math.NA", "cs.NA", "q-bio.QM"], "primary_category": "math.NA"}
{"title": "Discrete Differential Principle for Continuous Smooth Function Representation", "abstract": "Taylor's formula holds significant importance in function representation,\nsuch as solving differential difference equations, ordinary differential\nequations, partial differential equations, and further promotes applications in\nvisual perception, complex control, fluid mechanics, weather forecasting and\nthermodynamics. However, the Taylor's formula suffers from the curse of\ndimensionality and error propagation during derivative computation in discrete\nsituations. In this paper, we propose a new discrete differential operator to\nestimate derivatives and to represent continuous smooth function locally using\nthe Vandermonde coefficient matrix derived from truncated Taylor series. Our\nmethod simultaneously computes all derivatives of orders less than the number\nof sample points, inherently mitigating error propagation. Utilizing\nequidistant uniform sampling, it achieves high-order accuracy while alleviating\nthe curse of dimensionality. We mathematically establish rigorous error bounds\nfor both derivative estimation and function representation, demonstrating\ntighter bounds for lower-order derivatives. We extend our method to the\ntwo-dimensional case, enabling its use for multivariate derivative\ncalculations. Experiments demonstrate the effectiveness and superiority of the\nproposed method compared to the finite forward difference method for derivative\nestimation and cubic spline and linear interpolation for function\nrepresentation. Consequently, our technique offers broad applicability across\ndomains such as vision representation, feature extraction, fluid mechanics, and\ncross-media imaging.", "published": "2025-07-13 03:43:23", "link": "http://arxiv.org/abs/2507.09480v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "A modified tamed scheme for stochastic differential equations with superlinear drifts", "abstract": "Explicit discretizations of stochastic differential equations often encounter\ninstability when the coefficients are not globally Lipschitz. The truncated\nschemes and tamed schemes have been proposed to handle this difficulty, but\ntruncated schemes involve analyzing of the stopping times while the tamed\nschemes suffer from the reduced order of accuracy. We propose a modified tamed\nscheme by introducing an additional cut-off function in the taming, which\nenjoys the convenience for error analysis and preserving the original order of\nexplicit discretization. While the strategy could be applied to any explicit\ndiscretization, we perform rigorous analysis of the modified tamed scheme for\nthe Euler discretization as an example. Then, we apply the modified tamed\nscheme to the stochastic gradient Langevin dynamics for sampling with\nsuper-linear drift, and obtain a uniform-in-time near-sharp error estimate\nunder relative entropy.", "published": "2025-07-13 03:21:39", "link": "http://arxiv.org/abs/2507.09475v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Enhancing Trading Performance Through Sentiment Analysis with Large Language Models: Evidence from the S&P 500", "abstract": "This study integrates real-time sentiment analysis from financial news, GPT-2\nand FinBERT, with technical indicators and time-series models like ARIMA and\nETS to optimize S&P 500 trading strategies. By merging sentiment data with\nmomentum and trend-based metrics, including a benchmark buy-and-hold and\nsentiment-based approach, is evaluated through assets values and returns.\nResults show that combining sentiment-driven insights with traditional models\nimproves trading performance, offering a more dynamic approach to stock trading\nthat adapts to market changes in volatile environments.", "published": "2025-07-13 18:30:57", "link": "http://arxiv.org/abs/2507.09739v1", "categories": ["q-fin.CP", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Mapping Crisis-Driven Market Dynamics: A Transfer Entropy and Kramers-Moyal Approach to Financial Networks", "abstract": "Financial markets are dynamic, interconnected systems where local shocks can\ntrigger widespread instability, challenging portfolio managers and\npolicymakers. Traditional correlation analysis often miss the directionality\nand temporal dynamics of information flow. To address this, we present a\nunified framework integrating Transfer Entropy (TE) and the N-dimensional\nKramers-Moyal (KM) expansion to map static and time-resolved coupling among\nfour major indices: Nasdaq Composite (^IXIC), WTI crude oil (WTI), gold (GC=F),\nand the US Dollar Index (DX-Y.NYB). TE captures directional information flow.\nKM models non-linear stochastic dynamics, revealing interactions often\noverlooked by linear methods. Using daily data from August 11, 2014, to\nSeptember 8, 2024, we compute returns, confirm non-stationary using a conduct\nsliding-window TE and KM analyses. We find that during the COVID-19 pandemic\n(March-June 2020) and the Russia-Ukraine crisis (Feb-Apr 2022), average TE\nincreases by 35% and 28%, respectively, indicating heightened directional flow.\nDrift coefficients highlight gold-dollar interactions as a persistent\nsafe-haven channel, while oil-equity linkages show regime shifts, weakening\nunder stress and rebounding quickly. Our results expose the shortcomings of\nlinear measures and underscore the value of combining information-theoretic and\nstochastic drift methods. This approach offers actionable insights for adaptive\nhedging and informs macro-prudential policy by revealing the evolving\narchitecture of systemic risk.", "published": "2025-07-13 09:54:26", "link": "http://arxiv.org/abs/2507.09554v1", "categories": ["q-fin.ST", "physics.soc-ph"], "primary_category": "q-fin.ST"}
{"title": "Boltzmann Price: Toward Understanding the Fair Price in High-Frequency Markets", "abstract": "In this paper, we introduce a parametrized family of prices derived from the\nMaximum Entropy Principle. The price is obtained from the distribution that\nminimizes bias, given the bid and ask volume imbalance at the top of the order\nbook. Under specific parameter choices, it closely approximates the mid-price\nor the weighted mid-price. Using probabilities of bid and ask states, we\npropose a model of price dynamics in which both drift and volatility are driven\nby volume imbalance. Compared to standard models like Bachelier or Geometric\nBrownian Motion with constant volatility, our model can generate higher\nkurtosis and heavy-tailed distributions. Additionally, the drift term naturally\nemerges as a consequence of the order book imbalance. We validate the model\nthrough simulation and demonstrate its fit to historical equity data. The model\nprovides a theoretical framework, integrating price, volume imbalance, and\nspread.", "published": "2025-07-13 18:17:48", "link": "http://arxiv.org/abs/2507.09734v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization", "abstract": "Bayesian optimization is a powerful tool for optimizing an\nexpensive-to-evaluate black-box function. In particular, the effectiveness of\nexpected improvement (EI) has been demonstrated in a wide range of\napplications. However, theoretical analyses of EI are limited compared with\nother theoretically established algorithms. This paper analyzes a randomized\nvariant of EI, which evaluates the EI from the maximum of the posterior sample\npath. We show that this posterior sampling-based random EI achieves the\nsublinear Bayesian cumulative regret bounds under the assumption that the\nblack-box function follows a Gaussian process. Finally, we demonstrate the\neffectiveness of the proposed method through numerical experiments.", "published": "2025-07-13 23:37:31", "link": "http://arxiv.org/abs/2507.09828v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Discovering Governing Equations in the Presence of Uncertainty", "abstract": "In the study of complex dynamical systems, understanding and accurately\nmodeling the underlying physical processes is crucial for predicting system\nbehavior and designing effective interventions. Yet real-world systems exhibit\npronounced input (or system) variability and are observed through noisy,\nlimited data conditions that confound traditional discovery methods that assume\nfixed-coefficient deterministic models. In this work, we theorize that\naccounting for system variability together with measurement noise is the key to\nconsistently discover the governing equations underlying dynamical systems. As\nsuch, we introduce a stochastic inverse physics-discovery (SIP) framework that\ntreats the unknown coefficients as random variables and infers their posterior\ndistribution by minimizing the Kullback-Leibler divergence between the\npush-forward of the posterior samples and the empirical data distribution.\nBenchmarks on four canonical problems -- the Lotka-Volterra predator-prey\nsystem (multi- and single-trajectory), the historical Hudson Bay lynx-hare\ndata, the chaotic Lorenz attractor, and fluid infiltration in porous media\nusing low- and high-viscosity liquids -- show that SIP consistently identifies\nthe correct equations and lowers coefficient root-mean-square error by an\naverage of 82\\% relative to the Sparse Identification of Nonlinear Dynamics\n(SINDy) approach and its Bayesian variant. The resulting posterior\ndistributions yield 95\\% credible intervals that closely track the observed\ntrajectories, providing interpretable models with quantified uncertainty. SIP\nthus provides a robust, data-efficient approach for consistent physics\ndiscovery in noisy, variable, and data-limited settings.", "published": "2025-07-13 18:31:25", "link": "http://arxiv.org/abs/2507.09740v1", "categories": ["stat.ML", "cs.LG", "math.DS", "physics.data-an"], "primary_category": "stat.ML"}
{"title": "Signed Graph Learning: Algorithms and Theory", "abstract": "Real-world data is often represented through the relationships between data\nsamples, forming a graph structure. In many applications, it is necessary to\nlearn this graph structure from the observed data. Current graph learning\nresearch has primarily focused on unsigned graphs, which consist only of\npositive edges. However, many biological and social systems are better\ndescribed by signed graphs that account for both positive and negative\ninteractions, capturing similarity and dissimilarity between samples. In this\npaper, we develop a method for learning signed graphs from a set of smooth\nsigned graph signals. Specifically, we employ the net Laplacian as a graph\nshift operator (GSO) to define smooth signed graph signals as the outputs of a\nlow-pass signed graph filter defined by the net Laplacian. The signed graph is\nthen learned by formulating a non-convex optimization problem where the total\nvariation of the observed signals is minimized with respect to the net\nLaplacian. The proposed problem is solved using alternating direction method of\nmultipliers (ADMM) and a fast algorithm reducing the per-ADMM iteration\ncomplexity from quadratic to linear in the number of nodes is introduced.\nFurthermore, theoretical proofs of convergence for the algorithm and a bound on\nthe estimation error of the learned net Laplacian as a function of sample size,\nnumber of nodes, and graph topology are provided. Finally, the proposed method\nis evaluated on simulated data and gene regulatory network inference problem\nand compared to existing signed graph learning methods.", "published": "2025-07-13 17:33:26", "link": "http://arxiv.org/abs/2507.09717v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Phase transition of the Sinkhorn-Knopp algorithm", "abstract": "The matrix scaling problem, particularly the Sinkhorn-Knopp algorithm, has\nbeen studied for over 60 years. In practice, the algorithm often yields\nhigh-quality approximations within just a few iterations. Theoretically,\nhowever, the best-known upper bound places it in the class of\npseudopolynomial-time approximation algorithms. Meanwhile, the lower-bound\nlandscape remains largely unexplored. Two fundamental questions persist: what\naccounts for the algorithm's strong empirical performance, and can a tight\nbound on its iteration count be established?\n  For an $n\\times n$ matrix, its normalized version is obtained by dividing\neach entry by its largest entry. We say that a normalized matrix has a density\n$\\gamma$ if there exists a constant $\\rho > 0$ such that one row or column has\nexactly $\\lceil \\gamma n \\rceil$ entries with values at least $\\rho$, and every\nother row and column has at least $\\lceil \\gamma n \\rceil$ such entries.\n  For the upper bound, we show that the Sinkhorn-Knopp algorithm produces a\nnearly doubly stochastic matrix in $O(\\log n - \\log \\varepsilon)$ iterations\nand $\\widetilde{O}(n^2)$ time for all nonnegative square matrices whose\nnormalized version has a density $\\gamma > 1/2$. Such matrices cover both the\nalgorithm's principal practical inputs and its typical theoretical regime, and\nthe $\\widetilde{O}(n^2)$ runtime is optimal.\n  For the lower bound, we establish a tight bound of\n$\\widetilde{\\Omega}\\left(n^{1/2}/\\varepsilon\\right)$ iterations for positive\nmatrices under the $\\ell_2$-norm error measure. Moreover, for every $\\gamma <\n1/2$, there exists a matrix with density $\\gamma$ for which the algorithm\nrequires $\\Omega\\left(n^{1/2}/\\varepsilon\\right)$ iterations.\n  In summary, our results reveal a sharp phase transition in the Sinkhorn-Knopp\nalgorithm at the density threshold $\\gamma = 1/2$.", "published": "2025-07-13 17:07:51", "link": "http://arxiv.org/abs/2507.09711v1", "categories": ["cs.DS", "cs.LG", "stat.ML"], "primary_category": "cs.DS"}
{"title": "Frequency-aware Surrogate Modeling With SMT Kernels For Advanced Data Forecasting", "abstract": "This paper introduces a comprehensive open-source framework for developing\ncorrelation kernels, with a particular focus on user-defined and composition of\nkernels for surrogate modeling. By advancing kernel-based modeling techniques,\nwe incorporate frequency-aware elements that effectively capture complex\nmechanical behaviors and timefrequency dynamics intrinsic to aircraft systems.\nTraditional kernel functions, often limited to exponential-based methods, are\nextended to include a wider range of kernels such as exponential squared sine\nand rational quadratic kernels, along with their respective firstand\nsecond-order derivatives. The proposed methodologies are first validated on a\nsinus cardinal test case and then applied to forecasting Mauna-Loa Carbon\nDioxide (CO 2 ) concentrations and airline passenger traffic. All these\nadvancements are integrated into the open-source Surrogate Modeling Toolbox\n(SMT 2.0), providing a versatile platform for both standard and customizable\nkernel configurations. Furthermore, the framework enables the combination of\nvarious kernels to leverage their unique strengths into composite models\ntailored to specific problems. The resulting framework offers a flexible\ntoolset for engineers and researchers, paving the way for numerous future\napplications in metamodeling for complex, frequency-sensitive domains.", "published": "2025-07-13 16:10:46", "link": "http://arxiv.org/abs/2507.09694v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Algorithm for Identifying Interpretable Subgroups With Elevated Treatment Effects", "abstract": "We introduce an algorithm for identifying interpretable subgroups with\nelevated treatment effects, given an estimate of individual or conditional\naverage treatment effects (CATE). Subgroups are characterized by ``rule sets''\n-- easy-to-understand statements of the form (Condition A AND Condition B) OR\n(Condition C) -- which can capture high-order interactions while retaining\ninterpretability. Our method complements existing approaches for estimating the\nCATE, which often produce high dimensional and uninterpretable results, by\nsummarizing and extracting critical information from fitted models to aid\ndecision making, policy implementation, and scientific understanding. We\npropose an objective function that trades-off subgroup size and effect size,\nand varying the hyperparameter that controls this trade-off results in a\n``frontier'' of Pareto optimal rule sets, none of which dominates the others\nacross all criteria. Valid inference is achievable through sample splitting. We\ndemonstrate the utility and limitations of our method using simulated and\nempirical examples.", "published": "2025-07-13 05:01:48", "link": "http://arxiv.org/abs/2507.09494v1", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints", "abstract": "Motivated by applications such as cloud platforms allocating GPUs to users or\ngovernments deploying mobile health units across competing regions, we study\nthe dynamic allocation of a reusable resource to strategic agents with private\nvaluations. Our objective is to simultaneously (i) maximize social welfare,\n(ii) satisfy multi-dimensional long-term cost constraints, and (iii)\nincentivize truthful reporting. We begin by numerically evaluating primal-dual\nmethods widely used in constrained online optimization and find them to be\nhighly fragile in strategic settings -- agents can easily manipulate their\nreports to distort future dual updates for future gain.\n  To address this vulnerability, we develop an incentive-aware framework that\nmakes primal-dual methods robust to strategic behavior. Our design combines\nepoch-based lazy updates -- where dual variables remain fixed within each epoch\n-- with randomized exploration rounds that extract approximately truthful\nsignals for learning. Leveraging carefully designed online learning subroutines\nthat can be of independent interest for dual updates, our mechanism achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ social welfare regret, satisfies all cost\nconstraints, and ensures incentive alignment. This matches the performance of\nnon-strategic allocation approaches while being robust to strategic agents.", "published": "2025-07-13 03:18:02", "link": "http://arxiv.org/abs/2507.09473v1", "categories": ["cs.GT", "cs.LG", "stat.ML"], "primary_category": "cs.GT"}
{"title": "Fourier Basis Mapping: A Time-Frequency Learning Framework for Time Series Forecasting", "abstract": "The integration of Fourier transform and deep learning opens new avenues for\ntime series forecasting. We reconsider the Fourier transform from a basis\nfunctions perspective. Specifically, the real and imaginary parts of the\nfrequency components can be regarded as the coefficients of cosine and sine\nbasis functions at tiered frequency levels, respectively. We find that existing\nFourier-based methods face inconsistent starting cycles and inconsistent series\nlength issues. They fail to interpret frequency components precisely and\noverlook temporal information. Accordingly, the novel Fourier Basis Mapping\n(FBM) method addresses these issues by integrating time-frequency features\nthrough Fourier basis expansion and mapping in the time-frequency space. Our\napproach extracts explicit frequency features while preserving temporal\ncharacteristics. FBM supports plug-and-play integration with various types of\nneural networks by only adjusting the first initial projection layer for better\nperformance. First, we propose FBM-L, FBM-NL, and FBM-NP to enhance linear,\nMLP-based, and Transformer-based models, respectively, demonstrating the\neffectiveness of time-frequency features. Next, we propose a synergetic model\narchitecture, termed FBM-S, which decomposes the seasonal, trend, and\ninteraction effects into three separate blocks, each designed to model\ntime-frequency features in a specialized manner. Finally, we introduce several\ntechniques tailored for time-frequency features, including interaction masking,\ncentralization, patching, rolling window projection, and multi-scale\ndown-sampling. The results are validated on diverse real-world datasets for\nboth long-term and short-term forecasting tasks with SOTA performance.", "published": "2025-07-13 01:45:27", "link": "http://arxiv.org/abs/2507.09445v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Low-Rank Adaptation of Deep Prior Neural Networks For Room Impulse Response Reconstruction", "abstract": "The Deep Prior framework has emerged as a powerful generative tool which can\nbe used for reconstructing sound fields in an environment from few sparse\npressure measurements. It employs a neural network that is trained solely on a\nlimited set of available data and acts as an implicit prior which guides the\nsolution of the underlying optimization problem. However, a significant\nlimitation of the Deep Prior approach is its inability to generalize to new\nacoustic configurations, such as changes in the position of a sound source. As\na consequence, the network must be retrained from scratch for every new setup,\nwhich is both computationally intensive and time-consuming. To address this, we\ninvestigate transfer learning in Deep Prior via Low-Rank Adaptation (LoRA),\nwhich enables efficient fine-tuning of a pre-trained neural network by\nintroducing a low-rank decomposition of trainable parameters, thus allowing the\nnetwork to adapt to new measurement sets with minimal computational overhead.\nWe embed LoRA into a MultiResUNet-based Deep Prior model and compare its\nadaptation performance against full fine-tuning of all parameters as well as\nclassical retraining, particularly in scenarios where only a limited number of\nmicrophones are used. The results indicate that fine-tuning, whether done\ncompletely or via LoRA, is especially advantageous when the source location is\nthe sole changing parameter, preserving high physical fidelity, and\nhighlighting the value of transfer learning for acoustics applications.", "published": "2025-07-13 21:51:32", "link": "http://arxiv.org/abs/2507.09806v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Knowing When to Quit: Probabilistic Early Exits for Speech Separation", "abstract": "In recent years, deep learning-based single-channel speech separation has\nimproved considerably, in large part driven by increasingly compute- and\nparameter-efficient neural network architectures. Most such architectures are,\nhowever, designed with a fixed compute and parameter budget, and consequently\ncannot scale to varying compute demands or resources, which limits their use in\nembedded and heterogeneous devices such as mobile phones and hearables. To\nenable such use-cases we design a neural network architecture for speech\nseparation capable of early-exit, and we propose an uncertainty-aware\nprobabilistic framework to jointly model the clean speech signal and error\nvariance which we use to derive probabilistic early-exit conditions in terms of\ndesired signal-to-noise ratios. We evaluate our methods on both speech\nseparation and enhancement tasks, and we show that a single early-exit model\ncan be competitive with state-of-the-art models trained at many compute and\nparameter budgets. Our framework enables fine-grained dynamic compute-scaling\nof speech separation networks while achieving state-of-the-art performance and\ninterpretable exit conditions.", "published": "2025-07-13 19:52:34", "link": "http://arxiv.org/abs/2507.09768v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "MB-RIRs: a Synthetic Room Impulse Response Dataset with Frequency-Dependent Absorption Coefficients", "abstract": "We investigate the effects of four strategies for improving the ecological\nvalidity of synthetic room impulse response (RIR) datasets for monoaural Speech\nEnhancement (SE). We implement three features on top of the traditional image\nsource method-based (ISM) shoebox RIRs: multiband absorption coefficients,\nsource directivity and receiver directivity. We additionally consider\nmesh-based RIRs from the SoundSpaces dataset. We then train a DeepFilternet3\nmodel for each RIR dataset and evaluate the performance on a test set of real\nRIRs both objectively and subjectively. We find that RIRs which use\nfrequency-dependent acoustic absorption coefficients (MB-RIRs) can obtain\n+0.51dB of SDR and a +8.9 MUSHRA score when evaluated on real RIRs. The MB-RIRs\ndataset is publicly available for free download.", "published": "2025-07-13 19:00:26", "link": "http://arxiv.org/abs/2507.09750v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "THAI Speech Emotion Recognition (THAI-SER) corpus", "abstract": "We present the first sizeable corpus of Thai speech emotion recognition,\nTHAI-SER, containing 41 hours and 36 minutes (27,854 utterances) from 100\nrecordings made in different recording environments: Zoom and two studio\nsetups. The recordings contain both scripted and improvised sessions, acted by\n200 professional actors (112 females and 88 males, aged 18 to 55) and were\ndirected by professional directors. There are five primary emotions: neutral,\nangry, happy, sad, and frustrated, assigned to the actors when recording\nutterances. The utterances are annotated with an emotional category using\ncrowdsourcing. To control the annotation process's quality, we also design an\nextensive filtering and quality control scheme to ensure that the majority\nagreement score remains above 0.71. We evaluate our annotated corpus using two\nmetrics: inter-annotator reliability and human recognition accuracy.\nInter-annotator reliability score was calculated using Krippendorff's alpha,\nwhere our corpus, after filtering, achieved an alpha score of 0.692, higher\nthan a recommendation of 0.667. For human recognition accuracy, our corpus\nscored up to 0.772 post-filtering. We also provide the results of the model\ntrained on the corpus evaluated on both in-corpus and cross-corpus setups. The\ncorpus is publicly available under a Creative Commons BY-SA 4.0, as well as our\ncodes for the experiments.", "published": "2025-07-13 12:52:31", "link": "http://arxiv.org/abs/2507.09618v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ensemble Confidence Calibration for Sound Event Detection in Open-environment", "abstract": "Sound event detection (SED) has made strong progress in controlled\nenvironments with clear event categories. However, real-world applications\noften take place in open environments. In such cases, current methods often\nproduce predictions with too much confidence and lack proper ways to measure\nuncertainty. This limits their ability to adapt and perform well in new\nsituations. To solve this problem, we are the first to use ensemble methods in\nSED to improve robustness against out-of-domain (OOD) inputs. We propose a\nconfidence calibration method called Energy-based Open-World Softmax\n(EOW-Softmax), which helps the system better handle uncertainty in unknown\nscenes. We further apply EOW-Softmax to sound occurrence and overlap detection\n(SOD) by adjusting the prediction. In this way, the model becomes more\nadaptable while keeping its ability to detect overlapping events. Experiments\nshow that our method improves performance in open environments. It reduces\noverconfidence and increases the ability to handle OOD situations.", "published": "2025-07-13 12:23:02", "link": "http://arxiv.org/abs/2507.09606v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Stereo Sound Event Detection with BiMamba and Pretrained PSELDnet", "abstract": "Pre-training methods have greatly improved the performance of sound event\nlocalization and detection (SELD). However, existing Transformer-based models\nstill face high computational cost. To solve this problem, we present a stereo\nSELD system using a pre-trained PSELDnet and a bidirectional Mamba sequence\nmodel. Specifically, we replace the Conformer module with a BiMamba module. We\nalso use asymmetric convolutions to better capture the time and frequency\nrelationships in the audio signal. Test results on the DCASE2025 Task 3\ndevelopment dataset show that our method performs better than both the baseline\nand the original PSELDnet with a Conformer decoder. In addition, the proposed\nmodel costs fewer computing resources than the baselines. These results show\nthat the BiMamba architecture is effective for solving key challenges in SELD\ntasks. The source code is publicly accessible at https://github.com/\nalexandergwm/DCASE2025 TASK3 Stereo PSELD Mamba.", "published": "2025-07-13 10:38:24", "link": "http://arxiv.org/abs/2507.09570v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SC-TSE: Speaker Consistency-Aware Target Speaker Extraction", "abstract": "Target Speaker Extraction (TSE) uses a reference cue to extract the target\nspeech from a mixture. In TSE systems relying on audio cues, the speaker\nembedding from the enrolled speech is crucial to performance. However, these\nembeddings may suffer from speaker identity confusion. Unlike previous studies\nthat focus on improving speaker embedding extraction, we improve TSE\nperformance from the perspective of speaker consistency. In this paper, we\npropose a speaker consistency-aware target speaker extraction method that\nincorporates a centroid-based speaker consistency loss. This approach enhances\nTSE performance by ensuring speaker consistency between the enrolled and\nextracted speech. In addition, we integrate conditional loss suppression into\nthe training process. The experimental results validate the effectiveness of\nour proposed methods in advancing the TSE performance. A speech demo is\navailable online.\\footnote{https://sc-tse.netlify.app/", "published": "2025-07-13 06:35:13", "link": "http://arxiv.org/abs/2507.09510v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The DKU System for Multi-Speaker Automatic Speech Recognition in MLC-SLM Challenge", "abstract": "We present the DKU system for Task 2 of the MLC-SLM Challenge, which aims to\nperform multi-speaker automatic speech recognition directly from raw audio\nwithout Oracle speaker labels or time boundaries. Our approach builds upon a\ndiarization-aware framework integrating speaker embeddings and temporal\nutterance boundaries into a Qwen2.5-based large language model (LLM). Then, we\nenhance the system's multilingual performance by fine-tuning language-specific\nadapters and LoRA modules within the LLM decoder. Finally, our system achieves\nthe tcpWER of 23.56\\% and 18.08\\% on the development and test sets of the\nMLC-SLM dataset, substantially outperforming the official baseline.", "published": "2025-07-13 05:30:39", "link": "http://arxiv.org/abs/2507.09499v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing", "abstract": "Analog in-memory computing (AIMC) is an energy-efficient alternative to\ndigital architectures for accelerating machine learning and signal processing\nworkloads. However, its energy efficiency is limited by the high energy cost of\nthe column analog-to-digital converters (ADCs). Reducing the ADC precision is\nan effective approach to lowering its energy cost. However, doing so also\nreduces the AIMC's computational accuracy thereby making it critical to\nidentify the minimum precision required to meet a target accuracy. Prior works\noverestimate the ADC precision requirements by modeling quantization error as\ninput-independent noise, maximizing the signal-to-quantization-noise ratio\n(SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address\nthese limitations by developing analytical expressions for estimating the\ncompute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and\npropose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a\ncircuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we\nshow that for a 256-dimensional binary dot product, CACTUS reduces the ADC\nprecision requirements by 3b while achieving 6dB higher CSNR over prior\nmethods. We also delineate operating conditions under which our proposed\nCSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.", "published": "2025-07-13 20:13:20", "link": "http://arxiv.org/abs/2507.09776v1", "categories": ["eess.SP", "cs.AR"], "primary_category": "eess.SP"}
{"title": "A New Wireless Image Transmission System Using Code Index Modulation and Image Enhancement for High-Rate Next Generation Networks", "abstract": "With the development of wireless network technologies, the wireless image\ntransmission area has become prominent. The need for high resolution, data\ntraffic density, widespread use of multimedia applications, and the importance\nof high rate and reliable image transmission in medical and military fields\nnecessitate the design of novel and high-performance wireless image\ntransmission systems. This paper proposes a code index modulation (CIM)-based\nimage transmission (CIM-IT) system that utilizes spreading code index and\nquadrature amplitude modulation (QAM) symbol for image transmission over a\nwireless channel. The proposed CIM-IT system maps bits to each pixel value of\nthe image to be transmitted and transmits these bits over a wireless channel\nusing a single-input and multiple-output system comprising code index\nmodulation and QAM techniques. At the receiver, the active spreading code index\nand the selected QAM symbol are estimated using a despreading-based maximum\nlikelihood detector, and the corresponding bits are obtained. The image\nconveyed from the transmitter is then reconstructed at the receiver side using\nthe pixel values corresponding to the bits. The obtained noisy image is\nenhanced using important enhancement filters. In addition, an advanced filter\nis proposed to improve the transmitted degraded image with optimum results.\nFurthermore, error performance, spectral efficiency, energy efficiency, and\nthroughputof the CIM-IT system are performed and the results are compared with\ntraditional wireless communication techniques.", "published": "2025-07-13 17:16:13", "link": "http://arxiv.org/abs/2507.09713v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Novel Physics-Aware Attention-Based Machine Learning Approach for Mutual Coupling Modeling", "abstract": "This article presents a physics-aware convolutional long short-term memory\n(PC-LSTM) network for efficient and accurate extraction of mutual impedance\nmatrices in dipole antenna arrays. By reinterpreting the Green's function\nthrough a physics-aware neural network and embedding it into an adaptive loss\nfunction, the proposed machine learning-based approach achieves enhanced\nphysical interpretability in mutual coupling modeling. Also, an attention\nmechanism is carefully designed to calibrate complex-valued features by fusing\nthe real and imaginary parts of the Green's function matrix. These fused\nrepresentations are then processed by a convolutional long short-term memory\nnetwork, and the impedance matrix of the linear antenna array can be finally\nderived. Validation against five benchmarks underscores the efficacy of the\nproposed approach, demonstrating accurate impedance extraction with up to a 7x\nspeedup compared to CST Microwave Studio, making it a fast alternative to\nfull-wave simulations for mutual coupling characterization.", "published": "2025-07-13 10:09:27", "link": "http://arxiv.org/abs/2507.09561v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reframing SAR Target Recognition as Visual Reasoning: A Chain-of-Thought Dataset with Multimodal LLMs", "abstract": "In the context of Synthetic Aperture Radar (SAR) image recognition,\ntraditional methods often struggle with the intrinsic limitations of SAR data,\nsuch as weak texture, high noise, and ambiguous object boundaries. This work\nexplores a novel perspective by reformulating SAR target recognition as a\nmultimodal reasoning task. We leverage multimodal large language models\n(MLLMs), specifically GPT-4o, to perform target classification based on SAR\nimagery, guided by candidate categories and enhanced with Chain-of-Thought\n(CoT) reasoning. A new dataset is constructed based on the FAIR-CSAR benchmark,\ncomprising raw SAR images, structured target annotations, candidate label sets,\nand GPT-generated CoT reasoning chains. Experimental results show that the\nMLLMs are capable of generating logically coherent and interpretable inferences\nin most scenarios. Our analysis highlights both the strengths and current\nlimitations of MLLMs in interpreting SAR imagery, and we provide detailed\ninsights into model behavior through failure case analysis. This work\ndemonstrates the feasibility of incorporating MLLMs into SAR analysis pipelines\nand establishes a foundation for future research in SAR-oriented visual\nreasoning.", "published": "2025-07-13 08:32:32", "link": "http://arxiv.org/abs/2507.09535v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An Enregy Efficient Design of Hybrid NOMA Based on Hybrid SIC with Power Adaptation", "abstract": "Recently, hybrid non-orthogonal multiple access (H-NOMA) technology, which\neffectively utilizes both NOMA and orthogonal multiple access (OMA)\ntechnologies through flexible resource allocation in a single transmission, has\ndemonstrated immense potential for enhancing the performance of wireless\ncommunication systems. To further release the potential of HNOMA, this paper\nproposes a novel design of H-NOMA which jointly incorporates hybrid successive\ninterference cancellation (HSIC) and power adaptation (PA) in the NOMA\ntransmission phase. To reveal the potential of the proposed HSIC-PA aided\nH-NOMA scheme, closed-form expression for the probability of the event that\nH-NOMA can achieve a higher data rate than pure OMA by consuming less energy is\nrigorously derived. Furthermore, the asymptotic analysis demonstrates that the\nprobability of the proposed H-NOMA scheme approaches 1 in the high\nsignal-to-noise ratio (SNR) regime without any constraints on either users'\ntarget rates or transmit power ratios. This represents a significant\nimprovement over conventional H-NOMA schemes, which require specific\nrestrictive conditions to achieve probability 1 at high SNRs as shown in\nexisting work. The above observation indicates that with less energy\nconsumption, the proposed HSIC-PA aided H-NOMA can achieve a higher data rate\nthan pure OMA with probability 1 at high SNRs, and hence a higher energy\nefficiency. Finally, numerical results are provided to verify the accuracy of\nthe analysis and also demonstrate the superior performance of the proposed\nH-NOMA scheme.", "published": "2025-07-13 02:52:49", "link": "http://arxiv.org/abs/2507.09458v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
