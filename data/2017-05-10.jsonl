{"title": "A Survey of Deep Learning Methods for Relation Extraction", "abstract": "Relation Extraction is an important sub-task of Information Extraction which\nhas the potential of employing deep learning (DL) models with the creation of\nlarge datasets using distant supervision. In this review, we compare the\ncontributions and pitfalls of the various DL models that have been used for the\ntask, to help guide the path ahead.", "published": "2017-05-10 08:05:44", "link": "http://arxiv.org/abs/1705.03645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysing Data-To-Text Generation Benchmarks", "abstract": "Recently, several data-sets associating data to text have been created to\ntrain data-to-text surface realisers. It is unclear however to what extent the\nsurface realisation task exercised by these data-sets is linguistically\nchallenging. Do these data-sets provide enough variety to encourage the\ndevelopment of generic, high-quality data-to-text surface realisers ? In this\npaper, we argue that these data-sets have important drawbacks. We back up our\nclaim using statistics, metrics and manual evaluation. We conclude by eliciting\na set of criteria for the creation of a data-to-text benchmark which could help\nbetter support the development, evaluation and comparison of linguistically\nsophisticated data-to-text surface realisers.", "published": "2017-05-10 14:42:54", "link": "http://arxiv.org/abs/1705.03802v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Minimal Span-Based Neural Constituency Parser", "abstract": "In this work, we present a minimal neural model for constituency parsing\nbased on independent scoring of labels and spans. We show that this model is\nnot only compatible with classical dynamic programming techniques, but also\nadmits a novel greedy top-down inference algorithm based on recursive\npartitioning of the input. We demonstrate empirically that both prediction\nschemes are competitive with recent work, and when combined with basic\nextensions to the scoring model are capable of achieving state-of-the-art\nsingle-model performance on the Penn Treebank (91.79 F1) and strong performance\non the French Treebank (82.23 F1).", "published": "2017-05-10 18:44:15", "link": "http://arxiv.org/abs/1705.03919v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Biomedical Information Extraction Primer for NLP Researchers", "abstract": "Biomedical Information Extraction is an exciting field at the crossroads of\nNatural Language Processing, Biology and Medicine. It encompasses a variety of\ndifferent tasks that require application of state-of-the-art NLP techniques,\nsuch as NER and Relation Extraction. This paper provides an overview of the\nproblems in the field and discusses some of the techniques used for solving\nthem.", "published": "2017-05-10 10:00:00", "link": "http://arxiv.org/abs/1705.05437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Distant Supervision Methods using PGMs", "abstract": "Relation Extraction refers to the task of populating a database with tuples\nof the form $r(e_1, e_2)$, where $r$ is a relation and $e_1$, $e_2$ are\nentities. Distant supervision is one such technique which tries to\nautomatically generate training examples based on an existing KB such as\nFreebase. This paper is a survey of some of the techniques in distant\nsupervision which primarily rely on Probabilistic Graphical Models (PGMs).", "published": "2017-05-10 13:19:38", "link": "http://arxiv.org/abs/1705.03751v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Flexible and Creative Chinese Poetry Generation Using Neural Memory", "abstract": "It has been shown that Chinese poems can be successfully generated by\nsequence-to-sequence neural models, particularly with the attention mechanism.\nA potential problem of this approach, however, is that neural models can only\nlearn abstract rules, while poem generation is a highly creative process that\ninvolves not only rules but also innovations for which pure statistical models\nare not appropriate in principle. This work proposes a memory-augmented neural\nmodel for Chinese poem generation, where the neural model and the augmented\nmemory work together to balance the requirements of linguistic accordance and\naesthetic innovation, leading to innovative generations that are still\nrule-compliant. In addition, it is found that the memory mechanism provides\ninteresting flexibility that can be used to generate poems with different\nstyles.", "published": "2017-05-10 13:55:53", "link": "http://arxiv.org/abs/1705.03773v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Inferring and Executing Programs for Visual Reasoning", "abstract": "Existing methods for visual reasoning attempt to directly map inputs to\noutputs using black-box architectures without explicitly modeling the\nunderlying reasoning processes. As a result, these black-box models often learn\nto exploit biases in the data rather than learning to perform visual reasoning.\nInspired by module networks, this paper proposes a model for visual reasoning\nthat consists of a program generator that constructs an explicit representation\nof the reasoning process to be performed, and an execution engine that executes\nthe resulting program to produce an answer. Both the program generator and the\nexecution engine are implemented by neural networks, and are trained using a\ncombination of backpropagation and REINFORCE. Using the CLEVR benchmark for\nvisual reasoning, we show that our model significantly outperforms strong\nbaselines and generalizes better in a variety of settings.", "published": "2017-05-10 07:08:23", "link": "http://arxiv.org/abs/1705.03633v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Deep Speaker Feature Learning for Text-independent Speaker Verification", "abstract": "Recently deep neural networks (DNNs) have been used to learn speaker\nfeatures. However, the quality of the learned features is not sufficiently\ngood, so a complex back-end model, either neural or probabilistic, has to be\nused to address the residual uncertainty when applied to speaker verification,\njust as with raw features. This paper presents a convolutional time-delay deep\nneural network structure (CT-DNN) for speaker feature learning. Our\nexperimental results on the Fisher database demonstrated that this CT-DNN can\nproduce high-quality speaker features: even with a single feature (0.3 seconds\nincluding the context), the EER can be as low as 7.68%. This effectively\nconfirmed that the speaker trait is largely a deterministic short-time property\nrather than a long-time distributional pattern, and therefore can be extracted\nfrom just dozens of frames.", "published": "2017-05-10 09:30:42", "link": "http://arxiv.org/abs/1705.03670v1", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Survey of Visual Question Answering: Datasets and Techniques", "abstract": "Visual question answering (or VQA) is a new and exciting problem that\ncombines natural language processing and computer vision techniques. We present\na survey of the various datasets and models that have been used to tackle this\ntask. The first part of the survey details the various datasets for VQA and\ncompares them along some common factors. The second part of this survey details\nthe different approaches for VQA, classified into four types: non-deep learning\nmodels, deep learning models without attention, deep learning models with\nattention, and other models which do not fit into the first three. Finally, we\ncompare the performances of these approaches and provide some directions for\nfuture work.", "published": "2017-05-10 17:30:17", "link": "http://arxiv.org/abs/1705.03865v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
