{"title": "Financial News-Driven LLM Reinforcement Learning for Portfolio Management", "abstract": "Reinforcement learning (RL) has emerged as a transformative approach for\nfinancial trading, enabling dynamic strategy optimization in complex markets.\nThis study explores the integration of sentiment analysis, derived from large\nlanguage models (LLMs), into RL frameworks to enhance trading performance.\nExperiments were conducted on single-stock trading with Apple Inc. (AAPL) and\nportfolio trading with the ING Corporate Leaders Trust Series B (LEXCX). The\nsentiment-enhanced RL models demonstrated superior net worth and cumulative\nprofit compared to RL models without sentiment and, in the portfolio\nexperiment, outperformed the actual LEXCX portfolio's buy-and-hold strategy.\nThese results highlight the potential of incorporating qualitative market\nsignals to improve decision-making, bridging the gap between quantitative and\nqualitative approaches in financial trading.", "published": "2024-11-17 12:46:01", "link": "http://arxiv.org/abs/2411.11059v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "IVE: Enhanced Probabilistic Forecasting of Intraday Volume Ratio with Transformers", "abstract": "This paper presents a new approach to volume ratio prediction in financial\nmarkets, specifically targeting the execution of Volume-Weighted Average Price\n(VWAP) strategies. Recognizing the importance of accurate volume profile\nforecasting, our research leverages the Transformer architecture to predict\nintraday volume ratio at a one-minute scale. We diverge from prior models that\nuse log-transformed volume or turnover rates, instead opting for a prediction\nmodel that accounts for the intraday volume ratio's high variability,\nstabilized via log-normal transformation. Our input data incorporates not only\nthe statistical properties of volume but also external volume-related features,\nabsolute time information, and stock-specific characteristics to enhance\nprediction accuracy. The model structure includes an encoder-decoder\nTransformer architecture with a distribution head for greedy sampling,\noptimizing performance on high-liquidity stocks across both Korean and American\nmarkets. We extend the capabilities of our model beyond point prediction by\nintroducing probabilistic forecasting that captures the mean and standard\ndeviation of volume ratios, enabling the anticipation of significant intraday\nvolume spikes. Furthermore, an agent with a simple trading logic demonstrates\nthe practical application of our model through live trading tests in the Korean\nmarket, outperforming VWAP benchmarks over a period of two and a half months.\nOur findings underscore the potential of Transformer-based probabilistic models\nfor volume ratio prediction and pave the way for future research advancements\nin this domain.", "published": "2024-11-17 04:07:26", "link": "http://arxiv.org/abs/2411.10956v2", "categories": ["q-fin.CP", "cs.CE"], "primary_category": "q-fin.CP"}
{"title": "Analyzing Pok\u00e9mon and Mario Streamers' Twitch Chat with LLM-based User\n  Embeddings", "abstract": "We present a novel digital humanities method for representing our Twitch\nchatters as user embeddings created by a large language model (LLM). We cluster\nthese embeddings automatically using affinity propagation and further narrow\nthis clustering down through manual analysis. We analyze the chat of one stream\nby each Twitch streamer: SmallAnt, DougDoug and PointCrow. Our findings suggest\nthat each streamer has their own type of chatters, however two categories\nemerge for all of the streamers: supportive viewers and emoji and reaction\nsenders. Repetitive message spammers is a shared chatter category for two of\nthe streamers.", "published": "2024-11-17 02:08:03", "link": "http://arxiv.org/abs/2411.10934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Multimodal LLMs: the Mechanistic Interpretability of Llava\n  in Visual Question Answering", "abstract": "Understanding the mechanisms behind Large Language Models (LLMs) is crucial\nfor designing improved models and strategies. While recent studies have yielded\nvaluable insights into the mechanisms of textual LLMs, the mechanisms of\nMulti-modal Large Language Models (MLLMs) remain underexplored. In this paper,\nwe apply mechanistic interpretability methods to analyze the visual question\nanswering (VQA) mechanisms in the first MLLM, Llava. We compare the mechanisms\nbetween VQA and textual QA (TQA) in color answering tasks and find that: a) VQA\nexhibits a mechanism similar to the in-context learning mechanism observed in\nTQA; b) the visual features exhibit significant interpretability when\nprojecting the visual embeddings into the embedding space; and c) Llava\nenhances the existing capabilities of the corresponding textual LLM Vicuna\nduring visual instruction tuning. Based on these findings, we develop an\ninterpretability tool to help users and researchers identify important visual\nlocations for final predictions, aiding in the understanding of visual\nhallucination. Our method demonstrates faster and more effective results\ncompared to existing interpretability approaches. Code:\n\\url{https://github.com/zepingyu0512/llava-mechanism}", "published": "2024-11-17 03:32:50", "link": "http://arxiv.org/abs/2411.10950v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialectal Toxicity Detection: Evaluating LLM-as-a-Judge Consistency\n  Across Language Varieties", "abstract": "There has been little systematic study on how dialectal differences affect\ntoxicity detection by modern LLMs. Furthermore, although using LLMs as\nevaluators (\"LLM-as-a-judge\") is a growing research area, their sensitivity to\ndialectal nuances is still underexplored and requires more focused attention.\nIn this paper, we address these gaps through a comprehensive toxicity\nevaluation of LLMs across diverse dialects. We create a multi-dialect dataset\nthrough synthetic transformations and human-assisted translations, covering 10\nlanguage clusters and 60 varieties. We then evaluated three LLMs on their\nability to assess toxicity across multilingual, dialectal, and LLM-human\nconsistency. Our findings show that LLMs are sensitive in handling both\nmultilingual and dialectal variations. However, if we have to rank the\nconsistency, the weakest area is LLM-human agreement, followed by dialectal\nconsistency. Code repository:\n\\url{https://github.com/ffaisal93/dialect_toxicity_llm_judge}", "published": "2024-11-17 03:53:24", "link": "http://arxiv.org/abs/2411.10954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Topic-aware Comparable Corpus of Chinese Variations", "abstract": "This study aims to fill the gap by constructing a topic-aware comparable\ncorpus of Mainland Chinese Mandarin and Taiwanese Mandarin from the social\nmedia in Mainland China and Taiwan, respectively. Using Dcard for Taiwanese\nMandarin and Sina Weibo for Mainland Chinese, we create a comparable corpus\nthat updates regularly and reflects modern language use on social media.", "published": "2024-11-17 04:06:12", "link": "http://arxiv.org/abs/2411.10955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FastDraft: How to Train Your Draft", "abstract": "Speculative Decoding has gained popularity as an effective technique for\naccelerating the auto-regressive inference process of Large Language Models\n(LLMs). However, Speculative Decoding entirely relies on the availability of\nefficient draft models, which are often lacking for many existing language\nmodels due to a stringent constraint of vocabulary incompatibility. In this\nwork we introduce FastDraft, a novel and efficient approach for pre-training\nand aligning a draft model to any large language model by incorporating\nefficient pre-training, followed by fine-tuning over synthetic datasets\ngenerated by the target model. We demonstrate FastDraft by training two highly\nparameter efficient drafts for the popular Phi-3-mini and Llama-3.1-8B models.\nUsing FastDraft, we were able to produce a draft with approximately 10 billion\ntokens on a single server with 8 Intel$^\\circledR$ Gaudi$^\\circledR$ 2\naccelerators in under 24 hours. Our results show that the draft model achieves\nimpressive results in key metrics of acceptance rate, block efficiency and up\nto 3x memory bound speed up when evaluated on code completion and up to 2x in\nsummarization, text completion and instruction tasks. We validate our\ntheoretical findings through benchmarking on the latest Intel$^\\circledR$\nCore$^{\\tiny \\text{TM}}$ Ultra, achieving a wall-clock time speedup of up to\n2x, indicating a significant reduction in runtime. Due to its high quality,\nFastDraft unlocks large language models inference on AI-PC and other\nedge-devices.", "published": "2024-11-17 12:32:44", "link": "http://arxiv.org/abs/2411.11055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Large Language Models: A Systematic Survey", "abstract": "This paper provides a comprehensive survey of the latest research on\nmultilingual large language models (MLLMs). MLLMs not only are able to\nunderstand and generate language across linguistic boundaries, but also\nrepresent an important advancement in artificial intelligence. We first discuss\nthe architecture and pre-training objectives of MLLMs, highlighting the key\ncomponents and methodologies that contribute to their multilingual\ncapabilities. We then discuss the construction of multilingual pre-training and\nalignment datasets, underscoring the importance of data quality and diversity\nin enhancing MLLM performance. An important focus of this survey is on the\nevaluation of MLLMs. We present a detailed taxonomy and roadmap covering the\nassessment of MLLMs' cross-lingual knowledge, reasoning, alignment with human\nvalues, safety, interpretability and specialized applications. Specifically, we\nextensively discuss multilingual evaluation benchmarks and datasets, and\nexplore the use of LLMs themselves as multilingual evaluators. To enhance MLLMs\nfrom black to white boxes, we also address the interpretability of multilingual\ncapabilities, cross-lingual transfer and language bias within these models.\nFinally, we provide a comprehensive review of real-world applications of MLLMs\nacross diverse domains, including biology, medicine, computer science,\nmathematics and law. We showcase how these models have driven innovation and\nimprovements in these specialized fields while also highlighting the challenges\nand opportunities in deploying MLLMs within diverse language communities and\napplication scenarios. We listed the paper related in this survey and publicly\navailable at https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers.", "published": "2024-11-17 13:21:26", "link": "http://arxiv.org/abs/2411.11072v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Promises and Pitfalls of LLM Annotations in Dataset Labeling: a Case\n  Study on Media Bias Detection", "abstract": "High annotation costs from hiring or crowdsourcing complicate the creation of\nlarge, high-quality datasets needed for training reliable text classifiers.\nRecent research suggests using Large Language Models (LLMs) to automate the\nannotation process, reducing these costs while maintaining data quality. LLMs\nhave shown promising results in annotating downstream tasks like hate speech\ndetection and political framing. Building on the success in these areas, this\nstudy investigates whether LLMs are viable for annotating the complex task of\nmedia bias detection and whether a downstream media bias classifier can be\ntrained on such data. We create annolexical, the first large-scale dataset for\nmedia bias classification with over 48000 synthetically annotated examples. Our\nclassifier, fine-tuned on this dataset, surpasses all of the annotator LLMs by\n5-9 percent in Matthews Correlation Coefficient (MCC) and performs close to or\noutperforms the model trained on human-labeled data when evaluated on two media\nbias benchmark datasets (BABE and BASIL). This study demonstrates how our\napproach significantly reduces the cost of dataset creation in the media bias\ndomain and, by extension, the development of classifiers, while our subsequent\nbehavioral stress-testing reveals some of its current limitations and\ntrade-offs.", "published": "2024-11-17 14:14:36", "link": "http://arxiv.org/abs/2411.11081v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learn from Downstream and Be Yourself in Multimodal Large Language Model\n  Fine-Tuning", "abstract": "Multimodal Large Language Model (MLLM) have demonstrated strong\ngeneralization capabilities across diverse distributions and tasks, largely due\nto extensive pre-training datasets. Fine-tuning MLLM has become a common\npractice to improve performance on specific downstream tasks. However, during\nfine-tuning, MLLM often faces the risk of forgetting knowledge acquired during\npre-training, which can result in a decline in generalization abilities. To\nbalance the trade-off between generalization and specialization, we propose\nmeasuring the parameter importance for both pre-trained and fine-tuning\ndistributions, based on frozen pre-trained weight magnitude and accumulated\nfine-tuning gradient values. We further apply an importance-aware weight\nallocation strategy, selectively updating relatively important parameters for\ndownstream tasks. We conduct empirical evaluations on both image captioning and\nvisual question-answering tasks using various MLLM architectures. The\ncomprehensive experimental analysis demonstrates the effectiveness of the\nproposed solution, highlighting the efficiency of the crucial modules in\nenhancing downstream specialization performance while mitigating generalization\ndegradation in MLLM Fine-Tuning.", "published": "2024-11-17 01:16:37", "link": "http://arxiv.org/abs/2411.10928v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memory-Augmented Multimodal LLMs for Surgical VQA via Self-Contained\n  Inquiry", "abstract": "Comprehensively understanding surgical scenes in Surgical Visual Question\nAnswering (Surgical VQA) requires reasoning over multiple objects. Previous\napproaches address this task using cross-modal fusion strategies to enhance\nreasoning ability. However, these methods often struggle with limited scene\nunderstanding and question comprehension, and some rely on external resources\n(e.g., pre-extracted object features), which can introduce errors and\ngeneralize poorly across diverse surgical environments. To address these\nchallenges, we propose SCAN, a simple yet effective memory-augmented framework\nthat leverages Multimodal LLMs to improve surgical context comprehension via\nSelf-Contained Inquiry. SCAN operates autonomously, generating two types of\nmemory for context augmentation: Direct Memory (DM), which provides multiple\ncandidates (or hints) to the final answer, and Indirect Memory (IM), which\nconsists of self-contained question-hint pairs to capture broader scene\ncontext. DM directly assists in answering the question, while IM enhances\nunderstanding of the surgical scene beyond the immediate query. Reasoning over\nthese object-aware memories enables the model to accurately interpret images\nand respond to questions. Extensive experiments on three publicly available\nSurgical VQA datasets demonstrate that SCAN achieves state-of-the-art\nperformance, offering improved accuracy and robustness across various surgical\nscenarios.", "published": "2024-11-17 02:23:45", "link": "http://arxiv.org/abs/2411.10937v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BianCang: A Traditional Chinese Medicine Large Language Model", "abstract": "The rise of large language models (LLMs) has driven significant progress in\nmedical applications, including traditional Chinese medicine (TCM). However,\ncurrent medical LLMs struggle with TCM diagnosis and syndrome differentiation\ndue to substantial differences between TCM and modern medical theory, and the\nscarcity of specialized, high-quality corpora. This paper addresses these\nchallenges by proposing BianCang, a TCM-specific LLM, using a two-stage\ntraining process that first injects domain-specific knowledge and then aligns\nit through targeted stimulation. To enhance diagnostic and differentiation\ncapabilities, we constructed pre-training corpora, instruction-aligned datasets\nbased on real hospital records, and the ChP-TCM dataset derived from the\nPharmacopoeia of the People's Republic of China. We compiled extensive TCM and\nmedical corpora for continuous pre-training and supervised fine-tuning,\nbuilding a comprehensive dataset to refine the model's understanding of TCM.\nEvaluations across 11 test sets involving 29 models and 4 tasks demonstrate the\neffectiveness of BianCang, offering valuable insights for future research.\nCode, datasets, and models are available at\nhttps://github.com/QLU-NLP/BianCang.", "published": "2024-11-17 10:17:01", "link": "http://arxiv.org/abs/2411.11027v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree\n  Search for Code Generation", "abstract": "Large language models demonstrate exceptional performance in simple code\ngeneration tasks but still face challenges in tackling complex problems. These\nchallenges may stem from insufficient reasoning and problem decomposition\ncapabilities. To address this issue, we propose a reasoning-augmented data\ngeneration process, SRA-MCTS, which guides the model to autonomously generate\nhigh-quality intermediate reasoning paths. This creates a positive feedback\nloop, enabling continuous improvement. Our method operates entirely through the\nmodel itself without requiring additional supervision. By synthesizing natural\nlanguage reasoning paths and translating them into executable code, the\napproach ensures analytical accuracy and enhances the success rate in solving\ncomplex tasks. Experimental results show that, even without additional\nsupervisory signals, our method achieves performance improvements across\ndifferent model scales, demonstrating the significant potential of\nself-improvement in small models. Furthermore, the method remains robust when\ntraditional Chain-of-Thought (CoT) approaches exhibit performance degradation,\nwith notable improvements observed in diversity metrics such as pass@10. We\nencourage further exploration of reasoning processes within training data to\nenhance the ability of language models to address complex problems. Our code\nand data are public at https://github.com/DIRECT-BIT/SRA-MCTS.", "published": "2024-11-17 12:31:04", "link": "http://arxiv.org/abs/2411.11053v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Human-Like Processing: Large Language Models Perform Equivalently\n  on Forward and Backward Scientific Text", "abstract": "The impressive performance of large language models (LLMs) has led to their\nconsideration as models of human language processing. Instead, we suggest that\nthe success of LLMs arises from the flexibility of the transformer learning\narchitecture. To evaluate this conjecture, we trained LLMs on scientific texts\nthat were either in a forward or backward format. Despite backward text being\ninconsistent with the structure of human languages, we found that LLMs\nperformed equally well in either format on a neuroscience benchmark, eclipsing\nhuman expert performance for both forward and backward orders. Our results are\nconsistent with the success of transformers across diverse domains, such as\nweather prediction and protein design. This widespread success is attributable\nto LLM's ability to extract predictive patterns from any sufficiently\nstructured input. Given their generality, we suggest caution in interpreting\nLLM's success in linguistic tasks as evidence for human-like mechanisms.", "published": "2024-11-17 12:48:24", "link": "http://arxiv.org/abs/2411.11061v1", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "AddrLLM: Address Rewriting via Large Language Model on Nationwide\n  Logistics Data", "abstract": "Textual description of a physical location, commonly known as an address,\nplays an important role in location-based services(LBS) such as on-demand\ndelivery and navigation. However, the prevalence of abnormal addresses, those\ncontaining inaccuracies that fail to pinpoint a location, have led to\nsignificant costs. Address rewriting has emerged as a solution to rectify these\nabnormal addresses. Despite the critical need, existing address rewriting\nmethods are limited, typically tailored to correct specific error types, or\nfrequently require retraining to process new address data effectively. In this\nstudy, we introduce AddrLLM, an innovative framework for address rewriting that\nis built upon a retrieval augmented large language model. AddrLLM overcomes\naforementioned limitations through a meticulously designed Supervised\nFine-Tuning module, an Address-centric Retrieval Augmented Generation module\nand a Bias-free Objective Alignment module. To the best of our knowledge, this\nstudy pioneers the application of LLM-based address rewriting approach to solve\nthe issue of abnormal addresses. Through comprehensive offline testing with\nreal-world data on a national scale and subsequent online deployment, AddrLLM\nhas demonstrated superior performance in integration with existing logistics\nsystem. It has significantly decreased the rate of parcel re-routing by\napproximately 43\\%, underscoring its exceptional efficacy in real-world\napplications.", "published": "2024-11-17 07:32:46", "link": "http://arxiv.org/abs/2411.13584v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inter-linguistic Phonetic Composition (IPC): A Theoretical and\n  Computational Approach to Enhance Second Language Pronunciation", "abstract": "Learners of a second language (L2) often unconsciously substitute unfamiliar\nL2 phonemes with similar phonemes from their native language (L1), even though\nnative speakers of the L2 perceive these sounds as distinct and\nnon-interchangeable. This phonemic substitution leads to deviations from the\nstandard phonological patterns of the L2, creating challenges for learners in\nacquiring accurate L2 pronunciation. To address this, we propose\nInter-linguistic Phonetic Composition (IPC), a novel computational method\ndesigned to minimize incorrect phonological transfer by reconstructing L2\nphonemes as composite sounds derived from multiple L1 phonemes. Tests with two\nautomatic speech recognition models demonstrated that when L2 speakers produced\nIPC-generated composite sounds, the recognition rate of target L2 phonemes\nimproved by 20% compared to when their pronunciation was influenced by original\nphonological transfer patterns. The improvement was observed within a\nrelatively shorter time frame, demonstrating rapid acquisition of the composite\nsound.", "published": "2024-11-17 01:15:58", "link": "http://arxiv.org/abs/2411.10927v2", "categories": ["cs.CL", "cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.CL"}
{"title": "LL\u00e4Mmlein: Compact and Competitive German-Only Language Models from\n  Scratch", "abstract": "We create two German-only decoder models, LL\\\"aMmlein 120M and 1B,\ntransparently from scratch and publish them, along with the training data, for\nthe German NLP research community to use. The model training involved several\nkey steps, including extensive data preprocessing, the creation of a custom\nGerman tokenizer, the training itself, as well as the evaluation of the final\nmodels on various benchmarks. Throughout the training process, multiple\ncheckpoints were saved and analyzed using the SuperGLEBer benchmark to monitor\nthe models' learning dynamics. Compared to state-of-the-art models on the\nSuperGLEBer benchmark, both LL\\\"aMmlein models performed competitively,\nconsistently matching or surpassing models with similar parameter sizes. The\nresults show that the models' quality scales with size as expected, but\nperformance improvements on some tasks plateaued early, offering valuable\ninsights into resource allocation for future model development.", "published": "2024-11-17 20:44:34", "link": "http://arxiv.org/abs/2411.11171v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Capturing Sparks of Abstraction for the ARC Challenge", "abstract": "Excellent progress has been made recently in solving ARC Challenge problems.\nHowever, it seems that new techniques may be required to push beyond 60%\naccuracy. Even commercial Large Language Models (LLMs) struggle to 'understand'\nmany of the problems (when given the input and output grids), which makes\ndiscovering solutions by LLM-lead program search somewhat futile.\n  In this work, LLM 'understanding' is attempted from a stronger starting\nposition : An LLM is given complete solutions to tasks in code, and then asked\nto explain how the task is being solved at various levels of abstraction.\nSpecifically, the LLM was given code solutions implemented in arc-dsl-llm (an\nLLM-legible version of Hodel's arc-dsl to obtain: (a) commented code; (b) code\nrefactored into reusable functional chunks; (c) problem solution steps; and (d)\nhigh-level problem-solving tactics.\n  We demonstrate that 'Sparks of Abstraction' can be extracted from the LLM\noutput - in a form that could be used in downstream tasks with Local LLMs\neligible to enter the ARC Prize.\n  Both the arc-dsl-llm DSL framework (with the re-engineered solutions) and the\nGemini LLM-generated data (along with the generation code) are made Open\nSource.", "published": "2024-11-17 23:40:00", "link": "http://arxiv.org/abs/2411.11206v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AIGS: Generating Science from AI-Powered Automated Falsification", "abstract": "Rapid development of artificial intelligence has drastically accelerated the\ndevelopment of scientific discovery. Trained with large-scale observation data,\ndeep neural networks extract the underlying patterns in an end-to-end manner\nand assist human researchers with highly-precised predictions in unseen\nscenarios. The recent rise of Large Language Models (LLMs) and the empowered\nautonomous agents enable scientists to gain help through interaction in\ndifferent stages of their research, including but not limited to literature\nreview, research ideation, idea implementation, and academic writing. However,\nAI researchers instantiated by foundation model empowered agents with\nfull-process autonomy are still in their infancy. In this paper, we study\n$\\textbf{AI-Generated Science}$ (AIGS), where agents independently and\nautonomously complete the entire research process and discover scientific laws.\nBy revisiting the definition of scientific research, we argue that\n$\\textit{falsification}$ is the essence of both human research process and the\ndesign of an AIGS system. Through the lens of falsification, prior systems\nattempting towards AI-Generated Science either lack the part in their design,\nor rely heavily on existing verification engines that narrow the use in\nspecialized domains. In this work, we propose Baby-AIGS as a baby-step\ndemonstration of a full-process AIGS system, which is a multi-agent system with\nagents in roles representing key research process. By introducing\nFalsificationAgent, which identify and then verify possible scientific\ndiscoveries, we empower the system with explicit falsification. Experiments on\nthree tasks preliminarily show that Baby-AIGS could produce meaningful\nscientific discoveries, though not on par with experienced human researchers.\nFinally, we discuss on the limitations of current Baby-AIGS, actionable\ninsights, and related ethical issues in detail.", "published": "2024-11-17 13:40:35", "link": "http://arxiv.org/abs/2411.11910v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SEFD: Semantic-Enhanced Framework for Detecting LLM-Generated Text", "abstract": "The widespread adoption of large language models (LLMs) has created an urgent\nneed for robust tools to detect LLM-generated text, especially in light of\n\\textit{paraphrasing} techniques that often evade existing detection methods.\nTo address this challenge, we present a novel semantic-enhanced framework for\ndetecting LLM-generated text (SEFD) that leverages a retrieval-based mechanism\nto fully utilize text semantics. Our framework improves upon existing detection\nmethods by systematically integrating retrieval-based techniques with\ntraditional detectors, employing a carefully curated retrieval mechanism that\nstrikes a balance between comprehensive coverage and computational efficiency.\nWe showcase the effectiveness of our approach in sequential text scenarios\ncommon in real-world applications, such as online forums and Q\\&A platforms.\nThrough comprehensive experiments across various LLM-generated texts and\ndetection methods, we demonstrate that our framework substantially enhances\ndetection accuracy in paraphrasing scenarios while maintaining robustness for\nstandard LLM-generated content.", "published": "2024-11-17 20:13:30", "link": "http://arxiv.org/abs/2411.12764v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Leveraging AI and NLP for Bank Marketing: A Systematic Review and Gap\n  Analysis", "abstract": "This paper explores the growing impact of AI and NLP in bank marketing,\nhighlighting their evolving roles in enhancing marketing strategies, improving\ncustomer engagement, and creating value within this sector. While AI and NLP\nhave been widely studied in general marketing, there is a notable gap in\nunderstanding their specific applications and potential within the banking\nsector. This research addresses this specific gap by providing a systematic\nreview and strategic analysis of AI and NLP applications in bank marketing,\nfocusing on their integration across the customer journey and operational\nexcellence. Employing the PRISMA methodology, this study systematically reviews\nexisting literature to assess the current landscape of AI and NLP in bank\nmarketing. Additionally, it incorporates semantic mapping using Sentence\nTransformers and UMAP for strategic gap analysis to identify underexplored\nareas and opportunities for future research.\n  The systematic review reveals limited research specifically focused on NLP\napplications in bank marketing. The strategic gap analysis identifies key areas\nwhere NLP can further enhance marketing strategies, including customer-centric\napplications like acquisition, retention, and personalized engagement, offering\nvaluable insights for both academic research and practical implementation. This\nresearch contributes to the field of bank marketing by mapping the current\nstate of AI and NLP applications and identifying strategic gaps. The findings\nprovide actionable insights for developing NLP-driven growth and innovation\nframeworks and highlight the role of NLP in improving operational efficiency\nand regulatory compliance. This work has broader implications for enhancing\ncustomer experience, profitability, and innovation in the banking industry.", "published": "2024-11-17 14:44:12", "link": "http://arxiv.org/abs/2411.14463v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "Improving Tool Retrieval by Leveraging Large Language Models for Query\n  Generation", "abstract": "Using tools by Large Language Models (LLMs) is a promising avenue to extend\ntheir reach beyond language or conversational settings. The number of tools can\nscale to thousands as they enable accessing sensory information, fetching\nupdated factual knowledge, or taking actions in the real world. In such\nsettings, in-context learning by providing a short list of relevant tools in\nthe prompt is a viable approach. To retrieve relevant tools, various approaches\nhave been suggested, ranging from simple frequency-based matching to dense\nembedding-based semantic retrieval. However, such approaches lack the\ncontextual and common-sense understanding required to retrieve the right tools\nfor complex user requests. Rather than increasing the complexity of the\nretrieval component itself, we propose leveraging LLM understanding to generate\na retrieval query. Then, the generated query is embedded and used to find the\nmost relevant tools via a nearest-neighbor search. We investigate three\napproaches for query generation: zero-shot prompting, supervised fine-tuning on\ntool descriptions, and alignment learning by iteratively optimizing a reward\nmetric measuring retrieval performance. By conducting extensive experiments on\na dataset covering complex and multi-tool scenarios, we show that leveraging\nLLMs for query generation improves the retrieval for in-domain (seen tools) and\nout-of-domain (unseen tools) settings.", "published": "2024-11-17 03:02:09", "link": "http://arxiv.org/abs/2412.03573v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Leveraging Large Language Models for Generating Labeled Mineral Site\n  Record Linkage Data", "abstract": "Record linkage integrates diverse data sources by identifying records that\nrefer to the same entity. In the context of mineral site records, accurate\nrecord linkage is crucial for identifying and mapping mineral deposits.\nProperly linking records that refer to the same mineral deposit helps define\nthe spatial coverage of mineral areas, benefiting resource identification and\nsite data archiving. Mineral site record linkage falls under the spatial record\nlinkage category since the records contain information about the physical\nlocations and non-spatial attributes in a tabular format. The task is\nparticularly challenging due to the heterogeneity and vast scale of the data.\nWhile prior research employs pre-trained discriminative language models (PLMs)\non spatial entity linkage, they often require substantial amounts of curated\nground-truth data for fine-tuning. Gathering and creating ground truth data is\nboth time-consuming and costly. Therefore, such approaches are not always\nfeasible in real-world scenarios where gold-standard data are unavailable.\nAlthough large generative language models (LLMs) have shown promising results\nin various natural language processing tasks, including record linkage, their\nhigh inference time and resource demand present challenges. We propose a method\nthat leverages an LLM to generate training data and fine-tune a PLM to address\nthe training data gap while preserving the efficiency of PLMs. Our approach\nachieves over 45\\% improvement in F1 score for record linkage compared to\ntraditional PLM-based methods using ground truth data while reducing the\ninference time by nearly 18 times compared to relying on LLMs. Additionally, we\noffer an automated pipeline that eliminates the need for human intervention,\nhighlighting this approach's potential to overcome record linkage challenges.", "published": "2024-11-17 18:26:56", "link": "http://arxiv.org/abs/2412.03575v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Debiasing Watermarks for Large Language Models via Maximal Coupling", "abstract": "Watermarking language models is essential for distinguishing between human\nand machine-generated text and thus maintaining the integrity and\ntrustworthiness of digital communication. We present a novel green/red list\nwatermarking approach that partitions the token set into ``green'' and ``red''\nlists, subtly increasing the generation probability for green tokens. To\ncorrect token distribution bias, our method employs maximal coupling, using a\nuniform coin flip to decide whether to apply bias correction, with the result\nembedded as a pseudorandom watermark signal. Theoretical analysis confirms this\napproach's unbiased nature and robust detection capabilities. Experimental\nresults show that it outperforms prior techniques by preserving text quality\nwhile maintaining high detectability, and it demonstrates resilience to\ntargeted modifications aimed at improving text quality. This research provides\na promising watermarking solution for language models, balancing effective\ndetection with minimal impact on text quality.", "published": "2024-11-17 23:36:37", "link": "http://arxiv.org/abs/2411.11203v1", "categories": ["stat.ML", "cs.CL", "cs.CR", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Pitch-and-Spectrum-Aware Singing Quality Assessment with Bias Correction\n  and Model Fusion", "abstract": "We participated in track 2 of the VoiceMOS Challenge 2024, which aimed to\npredict the mean opinion score (MOS) of singing samples. Our submission secured\nthe first place among all participating teams, excluding the official baseline.\nIn this paper, we further improve our submission and propose a novel\nPitch-and-Spectrum-aware Singing Quality Assessment (PS-SQA) method. The PS-SQA\nis designed based on the self-supervised-learning (SSL) MOS predictor,\nincorporating singing pitch and spectral information, which are extracted using\npitch histogram and non-quantized neural codec, respectively. Additionally, the\nPS-SQA introduces a bias correction strategy to address prediction biases\ncaused by low-resource training samples, and employs model fusion technology to\nfurther enhance prediction accuracy. Experimental results confirm that our\nproposed PS-SQA significantly outperforms all competing systems across all\nsystem-level metrics, confirming its strong sing quality assessment\ncapabilities.", "published": "2024-11-17 16:53:39", "link": "http://arxiv.org/abs/2411.11123v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
