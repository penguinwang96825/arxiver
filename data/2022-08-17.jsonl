{"title": "Choquet regularization for reinforcement learning", "abstract": "We propose \\emph{Choquet regularizers} to measure and manage the level of exploration for reinforcement learning (RL), and reformulate the continuous-time entropy-regularized RL problem of Wang et al. (2020, JMLR, 21(198)) in which we replace the differential entropy used for regularization with a Choquet regularizer. We derive the Hamilton--Jacobi--Bellman equation of the problem, and solve it explicitly in the linear--quadratic (LQ) case via maximizing statically a mean--variance constrained Choquet regularizer. Under the LQ setting, we derive explicit optimal distributions for several specific Choquet regularizers, and conversely identify the Choquet regularizers that generate a number of broadly used exploratory samplers such as $\u03b5$-greedy, exponential, uniform and Gaussian.", "published": "2022-08-17 19:32:24", "link": "http://arxiv.org/abs/2208.08497v1", "categories": ["stat.ML", "cs.LG", "q-fin.MF"], "primary_category": "stat.ML"}
