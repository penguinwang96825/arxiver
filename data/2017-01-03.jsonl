{"title": "Shortcut Sequence Tagging", "abstract": "Deep stacked RNNs are usually hard to train. Adding shortcut connections\nacross different layers is a common way to ease the training of stacked\nnetworks. However, extra shortcuts make the recurrent step more complicated. To\nsimply the stacked architecture, we propose a framework called shortcut block,\nwhich is a marriage of the gating mechanism and shortcuts, while discarding the\nself-connected part in LSTM cell. We present extensive empirical experiments\nshowing that this design makes training easy and improves generalization. We\npropose various shortcut block topologies and compositions to explore its\neffectiveness. Based on this architecture, we obtain a 6% relatively\nimprovement over the state-of-the-art on CCGbank supertagging dataset. We also\nget comparable results on POS tagging task.", "published": "2017-01-03 04:15:51", "link": "http://arxiv.org/abs/1701.00576v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On (Commercial) Benefits of Automatic Text Summarization Systems in the\n  News Domain: A Case of Media Monitoring and Media Response Analysis", "abstract": "In this work, we present the results of a systematic study to investigate the\n(commercial) benefits of automatic text summarization systems in a real world\nscenario. More specifically, we define a use case in the context of media\nmonitoring and media response analysis and claim that even using a simple\nquery-based extractive approach can dramatically save the processing time of\nthe employees without significantly reducing the quality of their work.", "published": "2017-01-03 15:49:35", "link": "http://arxiv.org/abs/1701.00728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fuzzy Based Implicit Sentiment Analysis on Quantitative Sentences", "abstract": "With the rapid growth of social media on the web, emotional polarity\ncomputation has become a flourishing frontier in the text mining community.\nHowever, it is challenging to understand the latest trends and summarize the\nstate or general opinions about products due to the big diversity and size of\nsocial media data and this creates the need of automated and real time opinion\nextraction and mining. On the other hand, the bulk of current research has been\ndevoted to study the subjective sentences which contain opinion keywords and\nlimited work has been reported for objective statements that imply sentiment.\nIn this paper, fuzzy based knowledge engineering model has been developed for\nsentiment classification of special group of such sentences including the\nchange or deviation from desired range or value. Drug reviews are the rich\nsource of such statements. Therefore, in this research, some experiments were\ncarried out on patient's reviews on several different cholesterol lowering\ndrugs to determine their sentiment polarity. The main conclusion through this\nstudy is, in order to increase the accuracy level of existing drug opinion\nmining systems, objective sentences which imply opinion should be taken into\naccount. Our experimental results demonstrate that our proposed model obtains\nover 72 percent F1 value.", "published": "2017-01-03 19:41:24", "link": "http://arxiv.org/abs/1701.00798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Attention based Text-Dependent Speaker Verification", "abstract": "A new type of End-to-End system for text-dependent speaker verification is\npresented in this paper. Previously, using the phonetically\ndiscriminative/speaker discriminative DNNs as feature extractors for speaker\nverification has shown promising results. The extracted frame-level (DNN\nbottleneck, posterior or d-vector) features are equally weighted and aggregated\nto compute an utterance-level speaker representation (d-vector or i-vector). In\nthis work we use speaker discriminative CNNs to extract the noise-robust\nframe-level features. These features are smartly combined to form an\nutterance-level speaker vector through an attention mechanism. The proposed\nattention model takes the speaker discriminative information and the phonetic\ninformation to learn the weights. The whole system, including the CNN and\nattention model, is joint optimized using an end-to-end criterion. The training\nalgorithm imitates exactly the evaluation process --- directly mapping a test\nutterance and a few target speaker utterances into a single verification score.\nThe algorithm can automatically select the most similar impostor for each\ntarget speaker to train the network. We demonstrated the effectiveness of the\nproposed end-to-end system on Windows $10$ \"Hey Cortana\" speaker verification\ntask.", "published": "2017-01-03 01:15:53", "link": "http://arxiv.org/abs/1701.00562v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Pyndri: a Python Interface to the Indri Search Engine", "abstract": "We introduce pyndri, a Python interface to the Indri search engine. Pyndri\nallows to access Indri indexes from Python at two levels: (1) dictionary and\ntokenized document collection, (2) evaluating queries on the index. We hope\nthat with the release of pyndri, we will stimulate reproducible, open and\nfast-paced IR research.", "published": "2017-01-03 17:17:34", "link": "http://arxiv.org/abs/1701.00749v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Unsupervised neural and Bayesian models for zero-resource speech\n  processing", "abstract": "In settings where only unlabelled speech data is available, zero-resource\nspeech technology needs to be developed without transcriptions, pronunciation\ndictionaries, or language modelling text. There are two central problems in\nzero-resource speech processing: (i) finding frame-level feature\nrepresentations which make it easier to discriminate between linguistic units\n(phones or words), and (ii) segmenting and clustering unlabelled speech into\nmeaningful units. In this thesis, we argue that a combination of top-down and\nbottom-up modelling is advantageous in tackling these two problems.\n  To address the problem of frame-level representation learning, we present the\ncorrespondence autoencoder (cAE), a neural network trained with weak top-down\nsupervision from an unsupervised term discovery system. By combining this\ntop-down supervision with unsupervised bottom-up initialization, the cAE yields\nmuch more discriminative features than previous approaches. We then present our\nunsupervised segmental Bayesian model that segments and clusters unlabelled\nspeech into hypothesized words. By imposing a consistent top-down segmentation\nwhile also using bottom-up knowledge from detected syllable boundaries, our\nsystem outperforms several others on multi-speaker conversational English and\nXitsonga speech data. Finally, we show that the clusters discovered by the\nsegmental Bayesian model can be made less speaker- and gender-specific by using\nfeatures from the cAE instead of traditional acoustic features.\n  In summary, the different models and systems presented in this thesis show\nthat both top-down and bottom-up modelling can improve representation learning,\nsegmentation and clustering of unlabelled speech data.", "published": "2017-01-03 22:26:10", "link": "http://arxiv.org/abs/1701.00851v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ambiguity and Incomplete Information in Categorical Models of Language", "abstract": "We investigate notions of ambiguity and partial information in categorical\ndistributional models of natural language. Probabilistic ambiguity has\npreviously been studied using Selinger's CPM construction. This construction\nworks well for models built upon vector spaces, as has been shown in quantum\ncomputational applications. Unfortunately, it doesn't seem to provide a\nsatisfactory method for introducing mixing in other compact closed categories\nsuch as the category of sets and binary relations. We therefore lack a uniform\nstrategy for extending a category to model imprecise linguistic information.\n  In this work we adopt a different approach. We analyze different forms of\nambiguous and incomplete information, both with and without quantitative\nprobabilistic data. Each scheme then corresponds to a suitable enrichment of\nthe category in which we model language. We view different monads as\nencapsulating the informational behaviour of interest, by analogy with their\nuse in modelling side effects in computation. Previous results of Jacobs then\nallow us to systematically construct suitable bases for enrichment.\n  We show that we can freely enrich arbitrary dagger compact closed categories\nin order to capture all the phenomena of interest, whilst retaining the\nimportant dagger compact closed structure. This allows us to construct a model\nwith real convex combination of binary relations that makes non-trivial use of\nthe scalars. Finally we relate our various different enrichments, showing that\nfinite subconvex algebra enrichment covers all the effects under consideration.", "published": "2017-01-03 11:16:07", "link": "http://arxiv.org/abs/1701.00660v1", "categories": ["cs.LO", "cs.CL", "math.CT"], "primary_category": "cs.LO"}
