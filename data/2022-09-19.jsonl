{"title": "LED down the rabbit hole: exploring the potential of global attention\n  for biomedical multi-document summarisation", "abstract": "In this paper we report on our submission to the Multidocument Summarisation\nfor Literature Review (MSLR) shared task. Specifically, we adapt PRIMERA (Xiao\net al., 2022) to the biomedical domain by placing global attention on important\nbiomedical entities in several ways. We analyse the outputs of the 23 resulting\nmodels, and report patterns in the results related to the presence of\nadditional global attention, number of training steps, and the input\nconfiguration.", "published": "2022-09-19 01:13:42", "link": "http://arxiv.org/abs/2209.08698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Autoregressive Entity Generation for End-to-End Task-Oriented Dialog", "abstract": "Task-oriented dialog (TOD) systems often require interaction with an external\nknowledge base to retrieve necessary entity (e.g., restaurant) information to\nsupport the response generation. Most current end-to-end TOD systems either\nretrieve the KB information explicitly or embed it into model parameters for\nimplicit access.~While the former approach demands scanning the KB at each turn\nof response generation, which is inefficient when the KB scales up, the latter\napproach shows higher flexibility and efficiency. In either approach, the\nsystems may generate a response with conflicting entity information. To address\nthis issue, we propose to generate the entity autoregressively first and\nleverage it to guide the response generation in an end-to-end system. To ensure\nentity consistency, we impose a trie constraint on entity generation. We also\nintroduce a logit concatenation strategy to facilitate gradient backpropagation\nfor end-to-end training. Experiments on MultiWOZ 2.1 single and CAMREST show\nthat our system can generate more high-quality and entity-consistent responses.", "published": "2022-09-19 01:49:29", "link": "http://arxiv.org/abs/2209.08708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Decoupled Retrieval Representation for Nearest Neighbour Neural\n  Machine Translation", "abstract": "K-Nearest Neighbor Neural Machine Translation (kNN-MT) successfully\nincorporates external corpus by retrieving word-level representations at test\ntime. Generally, kNN-MT borrows the off-the-shelf context representation in the\ntranslation task, e.g., the output of the last decoder layer, as the query\nvector of the retrieval task. In this work, we highlight that coupling the\nrepresentations of these two tasks is sub-optimal for fine-grained retrieval.\nTo alleviate it, we leverage supervised contrastive learning to learn the\ndistinctive retrieval representation derived from the original context\nrepresentation. We also propose a fast and effective approach to constructing\nhard negative samples. Experimental results on five domains show that our\napproach improves the retrieval accuracy and BLEU score compared to vanilla\nkNN-MT.", "published": "2022-09-19 03:19:38", "link": "http://arxiv.org/abs/2209.08738v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Adapt Pre-trained Vision-and-Language Models to a Text-only\n  Input?", "abstract": "Current language models have been criticised for learning language from text\nalone without connection between words and their meaning. Consequently,\nmultimodal training has been proposed as a way for creating models with better\nlanguage understanding by providing the lacking connection. We focus on\npre-trained multimodal vision-and-language (VL) models for which there already\nare some results on their language understanding capabilities. An unresolved\nissue with evaluating the linguistic skills of these models, however, is that\nthere is no established method for adapting them to text-only input without\nout-of-distribution uncertainty. To find the best approach, we investigate and\ncompare seven possible methods for adapting three different pre-trained VL\nmodels to text-only input. Our evaluations on both GLUE and Visual Property\nNorms (VPN) show that care should be put into adapting VL models to zero-shot\ntext-only tasks, while the models are less sensitive to how we adapt them to\nnon-zero-shot tasks. We also find that the adaptation methods perform\ndifferently for different models and that unimodal model counterparts perform\non par with the VL models regardless of adaptation, indicating that current VL\nmodels do not necessarily gain better language understanding from their\nmultimodal training.", "published": "2022-09-19 13:00:12", "link": "http://arxiv.org/abs/2209.08982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic-based Pre-training for Dialogue Understanding", "abstract": "Pre-trained language models have made great progress on dialogue tasks.\nHowever, these models are typically trained on surface dialogue text, thus are\nproven to be weak in understanding the main semantic meaning of a dialogue\ncontext. We investigate Abstract Meaning Representation (AMR) as explicit\nsemantic knowledge for pre-training models to capture the core semantic\ninformation in dialogues during pre-training. In particular, we propose a\nsemantic-based pre-training framework that extends the standard pre-training\nframework (Devlin et al., 2019) by three tasks for learning 1) core semantic\nunits, 2) semantic relations and 3) the overall semantic representation\naccording to AMR graphs. Experiments on the understanding of both chit-chats\nand task-oriented dialogues show the superiority of our model. To our\nknowledge, we are the first to leverage a deep semantic representation for\ndialogue pre-training.", "published": "2022-09-19 16:06:57", "link": "http://arxiv.org/abs/2209.09146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The first neural machine translation system for the Erzya language", "abstract": "We present the first neural machine translation system for translation\nbetween the endangered Erzya language and Russian and the dataset collected by\nus to train and evaluate it. The BLEU scores are 17 and 19 for translation to\nErzya and Russian respectively, and more than half of the translations are\nrated as acceptable by native speakers. We also adapt our model to translate\nbetween Erzya and 10 other languages, but without additional parallel data, the\nquality on these directions remains low. We release the translation models\nalong with the collected text corpus, a new language identification model, and\na multilingual sentence encoder adapted for the Erzya language. These resources\nwill be available at https://github.com/slone-nlp/myv-nmt.", "published": "2022-09-19 22:21:37", "link": "http://arxiv.org/abs/2209.09368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Snapshot into the Possibility of Video Game Machine Translation", "abstract": "We present in this article what we believe to be one of the first attempts at\nvideo game machine translation. Our study shows that models trained only with\nlimited in-domain data surpass publicly available systems by a significant\nmargin, and a subsequent human evaluation reveals interesting findings in the\nfinal translation. The first part of the article introduces some of the\nchallenges of video game translation, some of the existing literature, as well\nas the systems and data sets used in this experiment. The last sections discuss\nour analysis of the resulting translation and the potential benefits of such an\nautomated system. One such finding highlights the model's ability to learn\ntypical rules and patterns of video game translations from English into French.\nOur conclusions therefore indicate that the specific case of video game machine\ntranslation could prove very much useful given the encouraging results, the\nhighly repetitive nature of the work, and the often poor working conditions\nthat translators face in this field. As with other use cases of MT in cultural\nsectors, however, we believe this is heavily dependent on the proper\nimplementation of the tool, which should be used interactively by human\ntranslators to stimulate creativity instead of raw post-editing for the sake of\nproductivity.", "published": "2022-09-19 08:16:59", "link": "http://arxiv.org/abs/2209.08827v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Improving Fake News Detection of Influential Domain via Domain- and\n  Instance-Level Transfer", "abstract": "Both real and fake news in various domains, such as politics, health, and\nentertainment are spread via online social media every day, necessitating fake\nnews detection for multiple domains. Among them, fake news in specific domains\nlike politics and health has more serious potential negative impacts on the\nreal world (e.g., the infodemic led by COVID-19 misinformation). Previous\nstudies focus on multi-domain fake news detection, by equally mining and\nmodeling the correlation between domains. However, these multi-domain methods\nsuffer from a seesaw problem: the performance of some domains is often improved\nat the cost of hurting the performance of other domains, which could lead to an\nunsatisfying performance in specific domains. To address this issue, we propose\na Domain- and Instance-level Transfer Framework for Fake News Detection\n(DITFEND), which could improve the performance of specific target domains. To\ntransfer coarse-grained domain-level knowledge, we train a general model with\ndata of all domains from the meta-learning perspective. To transfer\nfine-grained instance-level knowledge and adapt the general model to a target\ndomain, we train a language model on the target domain to evaluate the\ntransferability of each data instance in source domains and re-weigh each\ninstance's contribution. Offline experiments on two datasets demonstrate the\neffectiveness of DITFEND. Online experiments show that DITFEND brings\nadditional improvements over the base models in a real-world scenario.", "published": "2022-09-19 10:21:13", "link": "http://arxiv.org/abs/2209.08902v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping STI ecosystems via Open Data: overcoming the limitations of\n  conflicting taxonomies. A case study for Climate Change Research in Denmark", "abstract": "Science, Technology and Innovation (STI) decision-makers often need to have a\nclear vision of what is researched and by whom to design effective policies.\nSuch a vision is provided by effective and comprehensive mappings of the\nresearch activities carried out within their institutional boundaries. A major\nchallenge to be faced in this context is the difficulty in accessing the\nrelevant data and in combining information coming from different sources:\nindeed, traditionally, STI data has been confined within closed data sources\nand, when available, it is categorised with different taxonomies. Here, we\npresent a proof-of-concept study of the use of Open Resources to map the\nresearch landscape on the Sustainable Development Goal (SDG) 13-Climate Action,\nfor an entire country, Denmark, and we map it on the 25 ERC panels.", "published": "2022-09-19 10:59:39", "link": "http://arxiv.org/abs/2209.08920v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Will It Blend? Mixing Training Paradigms & Prompting for Argument\n  Quality Prediction", "abstract": "This paper describes our contributions to the Shared Task of the 9th Workshop\non Argument Mining (2022). Our approach uses Large Language Models for the task\nof Argument Quality Prediction. We perform prompt engineering using GPT-3, and\nalso investigate the training paradigms multi-task learning, contrastive\nlearning, and intermediate-task training. We find that a mixed prediction setup\noutperforms single models. Prompting GPT-3 works best for predicting argument\nvalidity, and argument novelty is best estimated by a model trained using all\nthree training paradigms.", "published": "2022-09-19 12:34:46", "link": "http://arxiv.org/abs/2209.08966v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ALEXSIS-PT: A New Resource for Portuguese Lexical Simplification", "abstract": "Lexical simplification (LS) is the task of automatically replacing complex\nwords for easier ones making texts more accessible to various target\npopulations (e.g. individuals with low literacy, individuals with learning\ndisabilities, second language learners). To train and test models, LS systems\nusually require corpora that feature complex words in context along with their\ncandidate substitutions. To continue improving the performance of LS systems we\nintroduce ALEXSIS-PT, a novel multi-candidate dataset for Brazilian Portuguese\nLS containing 9,605 candidate substitutions for 387 complex words. ALEXSIS-PT\nhas been compiled following the ALEXSIS protocol for Spanish opening exciting\nnew avenues for cross-lingual models. ALEXSIS-PT is the first LS\nmulti-candidate dataset that contains Brazilian newspaper articles. We\nevaluated four models for substitute generation on this dataset, namely\nmDistilBERT, mBERT, XLM-R, and BERTimbau. BERTimbau achieved the highest\nperformance across all evaluation metrics.", "published": "2022-09-19 14:10:21", "link": "http://arxiv.org/abs/2209.09034v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Overview of the SV-Ident 2022 Shared Task on Survey Variable\n  Identification in Social Science Publications", "abstract": "In this paper, we provide an overview of the SV-Ident shared task as part of\nthe 3rd Workshop on Scholarly Document Processing (SDP) at COLING 2022. In the\nshared task, participants were provided with a sentence and a vocabulary of\nvariables, and asked to identify which variables, if any, are mentioned in\nindividual sentences from scholarly documents in full text. Two teams made a\ntotal of 9 submissions to the shared task leaderboard. While none of the teams\nimprove on the baseline systems, we still draw insights from their submissions.\nFurthermore, we provide a detailed evaluation. Data and baselines for our\nshared task are freely available at https://github.com/vadis-project/sv-ident", "published": "2022-09-19 14:54:41", "link": "http://arxiv.org/abs/2209.09062v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SAMP: A Model Inference Toolkit of Post-Training Quantization for Text\n  Processing via Self-Adaptive Mixed-Precision", "abstract": "The latest industrial inference engines, such as FasterTransformer and\nTurboTransformers, have verified that half-precision floating point (FP16) and\n8-bit integer (INT8) quantization can greatly improve model inference speed.\nHowever, the existing INT8 quantization methods are too complicated, and\nimproper usage will lead to model performance damage greatly. In this paper, we\ndevelop a toolkit for users to easily quantize their models for inference, in\nwhich Self-Adaptive Mixed-Precision (SAMP) is proposed to automatically control\nquantization rate by a mixed-precision architecture to balance model accuracy\nand efficiency. Experimental results show that our SAMP toolkit has a higher\nspeedup than PyTorch and FasterTransformer while ensuring the required\naccuracy. In addition, SAMP is based on a modular design, decoupling the\ntokenizer, embedding, encoder and target layers, which allows users to handle\nvarious downstream tasks and can be seamlessly integrated into PyTorch.", "published": "2022-09-19 15:53:10", "link": "http://arxiv.org/abs/2209.09130v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Quantifying How Hateful Communities Radicalize Online Users", "abstract": "While online social media offers a way for ignored or stifled voices to be\nheard, it also allows users a platform to spread hateful speech. Such speech\nusually originates in fringe communities, yet it can spill over into mainstream\nchannels. In this paper, we measure the impact of joining fringe hateful\ncommunities in terms of hate speech propagated to the rest of the social\nnetwork. We leverage data from Reddit to assess the effect of joining one type\nof echo chamber: a digital community of like-minded users exhibiting hateful\nbehavior. We measure members' usage of hate speech outside the studied\ncommunity before and after they become active participants. Using Interrupted\nTime Series (ITS) analysis as a causal inference method, we gauge the spillover\neffect, in which hateful language from within a certain community can spread\noutside that community by using the level of out-of-community hate word usage\nas a proxy for learned hate. We investigate four different Reddit\nsub-communities (subreddits) covering three areas of hate speech: racism,\nmisogyny and fat-shaming. In all three cases we find an increase in hate speech\noutside the originating community, implying that joining such community leads\nto a spread of hate speech throughout the platform. Moreover, users are found\nto pick up this new hateful speech for months after initially joining the\ncommunity. We show that the harmful speech does not remain contained within the\ncommunity. Our results provide new evidence of the harmful effects of echo\nchambers and the potential benefit of moderating them to reduce adoption of\nhateful speech.", "published": "2022-09-19 01:13:29", "link": "http://arxiv.org/abs/2209.08697v2", "categories": ["cs.SI", "cs.CL", "cs.LG", "stat.AP"], "primary_category": "cs.SI"}
{"title": "Joint Language Semantic and Structure Embedding for Knowledge Graph\n  Completion", "abstract": "The task of completing knowledge triplets has broad downstream applications.\nBoth structural and semantic information plays an important role in knowledge\ngraph completion. Unlike previous approaches that rely on either the structures\nor semantics of the knowledge graphs, we propose to jointly embed the semantics\nin the natural language description of the knowledge triplets with their\nstructure information. Our method embeds knowledge graphs for the completion\ntask via fine-tuning pre-trained language models with respect to a\nprobabilistic structured loss, where the forward pass of the language models\ncaptures semantics and the loss reconstructs structures. Our extensive\nexperiments on a variety of knowledge graph benchmarks have demonstrated the\nstate-of-the-art performance of our method. We also show that our method can\nsignificantly improve the performance in a low-resource regime, thanks to the\nbetter use of semantics. The code and datasets are available at\nhttps://github.com/pkusjh/LASS.", "published": "2022-09-19 02:41:02", "link": "http://arxiv.org/abs/2209.08721v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing Spurious Correlations in Popular Event-Based Rumor Detection\n  Benchmarks", "abstract": "As social media becomes a hotbed for the spread of misinformation, the\ncrucial task of rumor detection has witnessed promising advances fostered by\nopen-source benchmark datasets. Despite being widely used, we find that these\ndatasets suffer from spurious correlations, which are ignored by existing\nstudies and lead to severe overestimation of existing rumor detection\nperformance. The spurious correlations stem from three causes: (1) event-based\ndata collection and labeling schemes assign the same veracity label to multiple\nhighly similar posts from the same underlying event; (2) merging multiple data\nsources spuriously relates source identities to veracity labels; and (3)\nlabeling bias. In this paper, we closely investigate three of the most popular\nrumor detection benchmark datasets (i.e., Twitter15, Twitter16 and PHEME), and\npropose event-separated rumor detection as a solution to eliminate spurious\ncues. Under the event-separated setting, we observe that the accuracy of\nexisting state-of-the-art models drops significantly by over 40%, becoming only\ncomparable to a simple neural classifier. To better address this task, we\npropose Publisher Style Aggregation (PSA), a generalizable approach that\naggregates publisher posting records to learn writing style and veracity\nstance. Extensive experiments demonstrate that our method outperforms existing\nbaselines in terms of effectiveness, efficiency and generalizability.", "published": "2022-09-19 07:11:36", "link": "http://arxiv.org/abs/2209.08799v1", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "NL2INTERFACE: Interactive Visualization Interface Generation from\n  Natural Language Queries", "abstract": "We develop NL2INTERFACE to explore the potential of generating usable\ninteractive multi-visualization interfaces from natural language queries. With\nNL2INTERFACE, users can directly write natural language queries to\nautomatically generate a fully interactive multi-visualization interface\nwithout any extra effort of learning a tool or programming language. Further,\nusers can interact with the interfaces to easily transform the data and quickly\nsee the results in the visualizations.", "published": "2022-09-19 08:31:50", "link": "http://arxiv.org/abs/2209.08834v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.DB", "H.5.2; H.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "EcoFormer: Energy-Saving Attention with Linear Complexity", "abstract": "Transformer is a transformative framework that models sequential data and has\nachieved remarkable performance on a wide range of tasks, but with high\ncomputational and energy cost. To improve its efficiency, a popular choice is\nto compress the models via binarization which constrains the floating-point\nvalues into binary ones to save resource consumption owing to cheap bitwise\noperations significantly. However, existing binarization methods only aim at\nminimizing the information loss for the input distribution statistically, while\nignoring the pairwise similarity modeling at the core of the attention. To this\nend, we propose a new binarization paradigm customized to high-dimensional\nsoftmax attention via kernelized hashing, called EcoFormer, to map the original\nqueries and keys into low-dimensional binary codes in Hamming space. The\nkernelized hash functions are learned to match the ground-truth similarity\nrelations extracted from the attention map in a self-supervised way. Based on\nthe equivalence between the inner product of binary codes and the Hamming\ndistance as well as the associative property of matrix multiplication, we can\napproximate the attention in linear complexity by expressing it as a\ndot-product of binary codes. Moreover, the compact binary representations of\nqueries and keys enable us to replace most of the expensive multiply-accumulate\noperations in attention with simple accumulations to save considerable on-chip\nenergy footprint on edge devices. Extensive experiments on both vision and\nlanguage tasks show that EcoFormer consistently achieves comparable performance\nwith standard attentions while consuming much fewer resources. For example,\nbased on PVTv2-B0 and ImageNet-1K, Ecoformer achieves a 73% on-chip energy\nfootprint reduction with only a 0.33% performance drop compared to the standard\nattention. Code is available at https://github.com/ziplab/EcoFormer.", "published": "2022-09-19 13:28:32", "link": "http://arxiv.org/abs/2209.09004v3", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Mapping Climate Change Research via Open Repositories & AI: advantages\n  and limitations for an evidence-based R&D policy-making", "abstract": "In the last few years, several initiatives have been starting to offer access\nto research outputs data and metadata in an open fashion. The platforms\ndeveloped by those initiatives are opening up scientific production to the\nwider public and they can be an invaluable asset for evidence-based\npolicy-making in Science, Technology and Innovation (STI). These resources can\nindeed facilitate knowledge discovery and help identify available R&D assets\nand relevant actors within specific research niches of interest. Ideally, to\ngain a comprehensive view of entire STI ecosystems, the information provided by\neach of these resources should be combined and analysed accordingly. To ensure\nso, at least a certain degree of interoperability should be guaranteed across\ndata sources, so that data could be better aggregated and complemented and that\nevidence provided towards policy-making is more complete and reliable. Here, we\nstudy whether this is the case for the case of mapping Climate Action research\nin the whole Denmark STI ecosystem, by using 4 popular open access STI data\nsources, namely OpenAire, Open Alex, CORDIS and Kohesio.", "published": "2022-09-19 12:56:30", "link": "http://arxiv.org/abs/2209.09246v1", "categories": ["cs.DL", "cs.CL", "cs.CY"], "primary_category": "cs.DL"}
{"title": "SJTU-AISPEECH System for VoxCeleb Speaker Recognition Challenge 2022", "abstract": "This report describes the SJTU-AISPEECH system for the Voxceleb Speaker\nRecognition Challenge 2022. For track1, we implemented two kinds of systems,\nthe online system and the offline system. Different ResNet-based backbones and\nloss functions are explored. Our final fusion system achieved 3rd place in\ntrack1. For track3, we implemented statistic adaptation and jointly training\nbased domain adaptation. In the jointly training based domain adaptation, we\njointly trained the source and target domain dataset with different training\nobjectives to do the domain adaptation. We explored two different training\nobjectives for target domain data, self-supervised learning based angular\nproto-typical loss and semi-supervised learning based classification loss with\nestimated pseudo labels. Besides, we used the dynamic loss-gate and label\ncorrection (DLG-LC) strategy to improve the quality of pseudo labels when the\ntarget domain objective is a classification loss. Our final fusion system\nachieved 4th place (very close to 3rd place, relatively less than 1%) in\ntrack3.", "published": "2022-09-19 15:06:42", "link": "http://arxiv.org/abs/2209.09076v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Playing Technique Detection by Fusing Note Onset Information in Guzheng\n  Performance", "abstract": "The Guzheng is a kind of traditional Chinese instruments with diverse playing\ntechniques. Instrument playing techniques (IPT) play an important role in\nmusical performance. However, most of the existing works for IPT detection show\nlow efficiency for variable-length audio and provide no assurance in the\ngeneralization as they rely on a single sound bank for training and testing. In\nthis study, we propose an end-to-end Guzheng playing technique detection system\nusing Fully Convolutional Networks that can be applied to variable-length\naudio. Because each Guzheng playing technique is applied to a note, a dedicated\nonset detector is trained to divide an audio into several notes and its\npredictions are fused with frame-wise IPT predictions. During fusion, we add\nthe IPT predictions frame by frame inside each note and get the IPT with the\nhighest probability within each note as the final output of that note. We\ncreate a new dataset named GZ_IsoTech from multiple sound banks and real-world\nrecordings for Guzheng performance analysis. Our approach achieves 87.97% in\nframe-level accuracy and 80.76% in note-level F1-score, outperforming existing\nworks by a large margin, which indicates the effectiveness of our proposed\nmethod in IPT detection.", "published": "2022-09-19 06:02:37", "link": "http://arxiv.org/abs/2209.08774v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AutoLV: Automatic Lecture Video Generator", "abstract": "We propose an end-to-end lecture video generation system that can generate\nrealistic and complete lecture videos directly from annotated slides,\ninstructor's reference voice and instructor's reference portrait video. Our\nsystem is primarily composed of a speech synthesis module with few-shot speaker\nadaptation and an adversarial learning-based talking-head generation module. It\nis capable of not only reducing instructors' workload but also changing the\nlanguage and accent which can help the students follow the lecture more easily\nand enable a wider dissemination of lecture contents. Our experimental results\nshow that the proposed model outperforms other current approaches in terms of\nauthenticity, naturalness and accuracy. Here is a video demonstration of how\nour system works, and the outcomes of the evaluation and comparison:\nhttps://youtu.be/cY6TYkI0cog.", "published": "2022-09-19 07:00:14", "link": "http://arxiv.org/abs/2209.08795v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "The Royalflush System for VoxCeleb Speaker Recognition Challenge 2022", "abstract": "In this technical report, we describe the Royalflush submissions for the\nVoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22). Our submissions\ncontain track 1, which is for supervised speaker verification and track 3,\nwhich is for semi-supervised speaker verification. For track 1, we develop a\npowerful U-Net-based speaker embedding extractor with a symmetric architecture.\nThe proposed system achieves 2.06% in EER and 0.1293 in MinDCF on the\nvalidation set. Compared with the state-of-the-art ECAPA-TDNN, it obtains a\nrelative improvement of 20.7% in EER and 22.70% in MinDCF. For track 3, we\nemploy the joint training of source domain supervision and target domain\nself-supervision to get a speaker embedding extractor. The subsequent\nclustering process can obtain target domain pseudo-speaker labels. We adapt the\nspeaker embedding extractor using all source and target domain data in a\nsupervised manner, where it can fully leverage both domain information.\nMoreover, clustering and supervised domain adaptation can be repeated until the\nperformance converges on the validation set. Our final submission is a fusion\nof 10 models and achieves 7.75% EER and 0.3517 MinDCF on the validation set.", "published": "2022-09-19 13:35:36", "link": "http://arxiv.org/abs/2209.09010v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Scaling and compressing melodies using geometric similarity measures", "abstract": "Melodic similarity measurement is of key importance in music information\nretrieval. In this paper, we use geometric matching techniques to measure the\nsimilarity between two melodies. We represent music as sets of points or sets\nof horizontal line segments in the Euclidean plane and propose efficient\nalgorithms for optimization problems inspired in two operations on melodies;\nlinear scaling and audio compression. In the scaling problem, an incoming query\nmelody is scaled forward until the similarity measure between the query and a\nreference melody is minimized. The compression problem asks for a subset of\nnotes of a given melody such that the matching cost between the selected notes\nand the reference melody is minimized.", "published": "2022-09-19 08:48:23", "link": "http://arxiv.org/abs/2209.09621v1", "categories": ["cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
