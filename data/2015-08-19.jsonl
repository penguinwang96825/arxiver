{"title": "Exploring Metaphorical Senses and Word Representations for Identifying\n  Metonyms", "abstract": "A metonym is a word with a figurative meaning, similar to a metaphor. Because\nmetonyms are closely related to metaphors, we apply features that are used\nsuccessfully for metaphor recognition to the task of detecting metonyms. On the\nACL SemEval 2007 Task 8 data with gold standard metonym annotations, our system\nachieved 86.45% accuracy on the location metonyms. Our code can be found on\nGitHub.", "published": "2015-08-19 03:26:05", "link": "http://arxiv.org/abs/1508.04515v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Recognizing Extended Spatiotemporal Expressions by Actively Trained\n  Average Perceptron Ensembles", "abstract": "Precise geocoding and time normalization for text requires that location and\ntime phrases be identified. Many state-of-the-art geoparsers and temporal\nparsers suffer from low recall. Categories commonly missed by parsers are:\nnouns used in a non- spatiotemporal sense, adjectival and adverbial phrases,\nprepositional phrases, and numerical phrases. We collected and annotated data\nset by querying commercial web searches API with such spatiotemporal\nexpressions as were missed by state-of-the- art parsers. Due to the high cost\nof sentence annotation, active learning was used to label training data, and a\nnew strategy was designed to better select training examples to reduce labeling\ncost. For the learning algorithm, we applied an average perceptron trained\nFeaturized Hidden Markov Model (FHMM). Five FHMM instances were used to create\nan ensemble, with the output phrase selected by voting. Our ensemble model was\ntested on a range of sequential labeling tasks, and has shown competitive\nperformance. Our contributions include (1) an new dataset annotated with named\nentities and expanded spatiotemporal expressions; (2) a comparison of inference\nalgorithms for ensemble models showing the superior accuracy of Belief\nPropagation over Viterbi Decoding; (3) a new example re-weighting method for\nactive ensemble learning that 'memorizes' the latest examples trained; (4) a\nspatiotemporal parser that jointly recognizes expanded spatiotemporal\nexpressions as well as named entities.", "published": "2015-08-19 04:17:47", "link": "http://arxiv.org/abs/1508.04525v1", "categories": ["cs.CL", "cs.LG", "D.3.3"], "primary_category": "cs.CL"}
{"title": "Fast, Flexible Models for Discovering Topic Correlation across\n  Weakly-Related Collections", "abstract": "Weak topic correlation across document collections with different numbers of\ntopics in individual collections presents challenges for existing\ncross-collection topic models. This paper introduces two probabilistic topic\nmodels, Correlated LDA (C-LDA) and Correlated HDP (C-HDP). These address\nproblems that can arise when analyzing large, asymmetric, and potentially\nweakly-related collections. Topic correlations in weakly-related collections\ntypically lie in the tail of the topic distribution, where they would be\noverlooked by models unable to fit large numbers of topics. To efficiently\nmodel this long tail for large-scale analysis, our models implement a parallel\nsampling algorithm based on the Metropolis-Hastings and alias methods (Yuan et\nal., 2015). The models are first evaluated on synthetic data, generated to\nsimulate various collection-level asymmetries. We then present a case study of\nmodeling over 300k documents in collections of sciences and humanities research\nfrom JSTOR.", "published": "2015-08-19 08:30:37", "link": "http://arxiv.org/abs/1508.04562v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
