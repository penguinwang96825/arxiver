{"title": "WANLI: Worker and AI Collaboration for Natural Language Inference\n  Dataset Creation", "abstract": "A recurring challenge of crowdsourcing NLP datasets at scale is that human\nwriters often rely on repetitive patterns when crafting examples, leading to a\nlack of linguistic diversity. We introduce a novel approach for dataset\ncreation based on worker and AI collaboration, which brings together the\ngenerative strength of language models and the evaluative strength of humans.\nStarting with an existing dataset, MultiNLI for natural language inference\n(NLI), our approach uses dataset cartography to automatically identify examples\nthat demonstrate challenging reasoning patterns, and instructs GPT-3 to compose\nnew examples with similar patterns. Machine generated examples are then\nautomatically filtered, and finally revised and labeled by human crowdworkers.\nThe resulting dataset, WANLI, consists of 107,885 NLI examples and presents\nunique empirical strengths over existing NLI datasets. Remarkably, training a\nmodel on WANLI improves performance on eight out-of-domain test sets we\nconsider, including by 11% on HANS and 9% on Adversarial NLI, compared to\ntraining on the 4x larger MultiNLI. Moreover, it continues to be more effective\nthan MultiNLI augmented with other NLI datasets. Our results demonstrate the\npromise of leveraging natural language generation techniques and re-imagining\nthe role of humans in the dataset creation process.", "published": "2022-01-16 03:13:49", "link": "http://arxiv.org/abs/2201.05955v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding\n  with Text-to-Text Language Models", "abstract": "Structured knowledge grounding (SKG) leverages structured knowledge to\ncomplete user requests, such as semantic parsing over databases and question\nanswering over knowledge bases. Since the inputs and outputs of SKG tasks are\nheterogeneous, they have been studied separately by different communities,\nwhich limits systematic and compatible research on SKG. In this paper, we\novercome this limitation by proposing the UnifiedSKG framework, which unifies\n21 SKG tasks into a text-to-text format, aiming to promote systematic SKG\nresearch, instead of being exclusive to a single task, domain, or dataset. We\nuse UnifiedSKG to benchmark T5 with different sizes and show that T5, with\nsimple modifications when necessary, achieves state-of-the-art performance on\nalmost all of the 21 tasks. We further demonstrate that multi-task\nprefix-tuning improves the performance on most tasks, largely improving the\noverall performance. UnifiedSKG also facilitates the investigation of zero-shot\nand few-shot learning, and we show that T0, GPT-3, and Codex struggle in\nzero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a\nseries of controlled experiments on structured knowledge encoding variants\nacross SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is\nopen-sourced at https://github.com/hkunlp/unifiedskg.", "published": "2022-01-16 04:36:18", "link": "http://arxiv.org/abs/2201.05966v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SNCSE: Contrastive Learning for Unsupervised Sentence Embedding with\n  Soft Negative Samples", "abstract": "Unsupervised sentence embedding aims to obtain the most appropriate embedding\nfor a sentence to reflect its semantic. Contrastive learning has been\nattracting developing attention. For a sentence, current models utilize diverse\ndata augmentation methods to generate positive samples, while consider other\nindependent sentences as negative samples. Then they adopt InfoNCE loss to pull\nthe embeddings of positive pairs gathered, and push those of negative pairs\nscattered. Although these models have made great progress on sentence\nembedding, we argue that they may suffer from feature suppression. The models\nfail to distinguish and decouple textual similarity and semantic similarity.\nAnd they may overestimate the semantic similarity of any pairs with similar\ntextual regardless of the actual semantic difference between them. This is\nbecause positive pairs in unsupervised contrastive learning come with similar\nand even the same textual through data augmentation. To alleviate feature\nsuppression, we propose contrastive learning for unsupervised sentence\nembedding with soft negative samples (SNCSE). Soft negative samples share\nhighly similar textual but have surely and apparently different semantic with\nthe original samples. Specifically, we take the negation of original sentences\nas soft negative samples, and propose Bidirectional Margin Loss (BML) to\nintroduce them into traditional contrastive learning framework, which merely\ninvolves positive and negative samples. Our experimental results show that\nSNCSE can obtain state-of-the-art performance on semantic textual similarity\n(STS) task with average Spearman's correlation coefficient of 78.97% on\nBERTbase and 79.23% on RoBERTabase. Besides, we adopt rank-based error analysis\nmethod to detect the weakness of SNCSE for future study.", "published": "2022-01-16 06:15:43", "link": "http://arxiv.org/abs/2201.05979v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Double Retrieval and Ranking for Accurate Question Answering", "abstract": "Recent work has shown that an answer verification step introduced in\nTransformer-based answer selection models can significantly improve the state\nof the art in Question Answering. This step is performed by aggregating the\nembeddings of top $k$ answer candidates to support the verification of a target\nanswer. Although the approach is intuitive and sound still shows two\nlimitations: (i) the supporting candidates are ranked only according to the\nrelevancy with the question and not with the answer, and (ii) the support\nprovided by the other answer candidates is suboptimal as these are retrieved\nindependently of the target answer. In this paper, we address both drawbacks by\nproposing (i) a double reranking model, which, for each target answer, selects\nthe best support; and (ii) a second neural retrieval stage designed to encode\nquestion and answer pair as the query, which finds more specific verification\ninformation. The results on three well-known datasets for AS2 show consistent\nand significant improvement of the state of the art.", "published": "2022-01-16 06:20:07", "link": "http://arxiv.org/abs/2201.05981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In Situ Answer Sentence Selection at Web-scale", "abstract": "Current answer sentence selection (AS2) applied in open-domain question\nanswering (ODQA) selects answers by ranking a large set of possible candidates,\ni.e., sentences, extracted from the retrieved text. In this paper, we present\nPassage-based Extracting Answer Sentence In-place (PEASI), a novel design for\nAS2 optimized for Web-scale setting, that, instead, computes such answer\nwithout processing each candidate individually. Specifically, we design a\nTransformer-based framework that jointly (i) reranks passages retrieved for a\nquestion and (ii) identifies a probable answer from the top passages in place.\nWe train PEASI in a multi-task learning framework that encourages feature\nsharing between the components: passage reranker and passage-based answer\nsentence extractor. To facilitate our development, we construct a new\nWeb-sourced large-scale QA dataset consisting of 800,000+ labeled\npassages/sentences for 60,000+ questions. The experiments show that our\nproposed design effectively outperforms the current state-of-the-art setting\nfor AS2, i.e., a point-wise model for ranking sentences independently, by 6.51%\nin accuracy, from 48.86% to 55.37%. In addition, PEASI is exceptionally\nefficient in computing answer sentences, requiring only ~20% inferences\ncompared to the standard setting, i.e., reranking all possible candidates. We\nbelieve the release of PEASI, both the dataset and our proposed design, can\ncontribute to advancing the research and development in deploying question\nanswering services at Web scale.", "published": "2022-01-16 06:36:00", "link": "http://arxiv.org/abs/2201.05984v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memory-assisted prompt editing to improve GPT-3 after deployment", "abstract": "Large LMs such as GPT-3 are powerful, but can commit mistakes that are\nobvious to humans. For example, GPT-3 would mistakenly interpret \"What word is\nsimilar to good?\" to mean a homophone, while the user intended a synonym. Our\ngoal is to effectively correct such errors via user interactions with the\nsystem but without retraining, which will be prohibitively costly. We pair\nGPT-3 with a growing memory of recorded cases where the model misunderstood the\nuser's intents, along with user feedback for clarification. Such a memory\nallows our system to produce enhanced prompts for any new query based on the\nuser feedback for error correction on similar cases in the past. On four tasks\n(two lexical tasks, two advanced ethical reasoning tasks), we show how a\n(simulated) user can interactively teach a deployed GPT-3, substantially\nincreasing its accuracy over the queries with different kinds of\nmisunderstandings by the GPT-3. Our approach is a step towards the low-cost\nutility enhancement for very large pre-trained LMs. Code, data, and\ninstructions to implement MEMPROMPT for a new task at\nhttps://www.memprompt.com/.", "published": "2022-01-16 10:11:37", "link": "http://arxiv.org/abs/2201.06009v7", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Ninth Advances in Cognitive Systems (ACS) Conference", "abstract": "ACS is an annual meeting for research on the initial goals of artificial\nintelligence and cognitive science, which aimed to explain the mind in\ncomputational terms and to reproduce the entire range of human cognitive\nabilities in computational artifacts. Many researchers remain committed to this\noriginal vision, and Advances in Cognitive Systems provides a place to present\nrecent results and pose new challenges for the field. The meetings bring\ntogether researchers with interests in human-level intelligence, complex\ncognition, integrated intelligent systems, cognitive architectures, and related\ntopics.", "published": "2022-01-16 20:57:08", "link": "http://arxiv.org/abs/2201.06134v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COLD: A Benchmark for Chinese Offensive Language Detection", "abstract": "Offensive language detection is increasingly crucial for maintaining a\ncivilized social media platform and deploying pre-trained language models.\nHowever, this task in Chinese is still under exploration due to the scarcity of\nreliable datasets. To this end, we propose a benchmark --COLD for Chinese\noffensive language analysis, including a Chinese Offensive Language Dataset\n--COLDATASET and a baseline detector --COLDETECTOR which is trained on the\ndataset. We show that the COLD benchmark contributes to Chinese offensive\nlanguage detection which is challenging for existing resources. We then deploy\nthe COLDETECTOR and conduct detailed analyses on popular Chinese pre-trained\nlanguage models. We first analyze the offensiveness of existing generative\nmodels and show that these models inevitably expose varying degrees of\noffensive issues. Furthermore, we investigate the factors that influence the\noffensive generations, and we find that anti-bias contents and keywords\nreferring to certain groups or revealing negative attitudes trigger offensive\noutputs easier.", "published": "2022-01-16 11:47:23", "link": "http://arxiv.org/abs/2201.06025v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Deduction through Search over Statement Compositions", "abstract": "In settings from fact-checking to question answering, we frequently want to\nknow whether a collection of evidence (premises) entails a hypothesis. Existing\nmethods primarily focus on the end-to-end discriminative version of this task,\nbut less work has treated the generative version in which a model searches over\nthe space of statements entailed by the premises to constructively derive the\nhypothesis. We propose a system for doing this kind of deductive reasoning in\nnatural language by decomposing the task into separate steps coordinated by a\nsearch procedure, producing a tree of intermediate conclusions that faithfully\nreflects the system's reasoning process. Our experiments on the EntailmentBank\ndataset (Dalvi et al., 2021) demonstrate that the proposed system can\nsuccessfully prove true statements while rejecting false ones. Moreover, it\nproduces natural language explanations with a 17% absolute higher step validity\nthan those produced by an end-to-end T5 model.", "published": "2022-01-16 12:05:48", "link": "http://arxiv.org/abs/2201.06028v2", "categories": ["cs.CL", "cs.AI", "I.2.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Temporal Relation Extraction with a Graph-Based Deep Biaffine Attention\n  Model", "abstract": "Temporal information extraction plays a critical role in natural language\nunderstanding. Previous systems have incorporated advanced neural language\nmodels and have successfully enhanced the accuracy of temporal information\nextraction tasks. However, these systems have two major shortcomings. First,\nthey fail to make use of the two-sided nature of temporal relations in\nprediction. Second, they involve non-parallelizable pipelines in inference\nprocess that bring little performance gain. To this end, we propose a novel\ntemporal information extraction model based on deep biaffine attention to\nextract temporal relationships between events in unstructured text efficiently\nand accurately. Our model is performant because we perform relation extraction\ntasks directly instead of considering event annotation as a prerequisite of\nrelation extraction. Moreover, our architecture uses Multilayer Perceptrons\n(MLP) with biaffine attention to predict arcs and relation labels separately,\nimproving relation detecting accuracy by exploiting the two-sided nature of\ntemporal relationships. We experimentally demonstrate that our model achieves\nstate-of-the-art performance in temporal relation extraction.", "published": "2022-01-16 19:40:08", "link": "http://arxiv.org/abs/2201.06125v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Examples to Rules: Neural Guided Rule Synthesis for Information\n  Extraction", "abstract": "While deep learning approaches to information extraction have had many\nsuccesses, they can be difficult to augment or maintain as needs shift.\nRule-based methods, on the other hand, can be more easily modified. However,\ncrafting rules requires expertise in linguistics and the domain of interest,\nmaking it infeasible for most users. Here we attempt to combine the advantages\nof these two directions while mitigating their drawbacks. We adapt recent\nadvances from the adjacent field of program synthesis to information\nextraction, synthesizing rules from provided examples. We use a\ntransformer-based architecture to guide an enumerative search, and show that\nthis reduces the number of steps that need to be explored before a rule is\nfound. Further, we show that without training the synthesis algorithm on the\nspecific domain, our synthesized rules achieve state-of-the-art performance on\nthe 1-shot scenario of a task that focuses on few-shot learning for relation\nclassification, and competitive performance in the 5-shot scenario.", "published": "2022-01-16 19:27:18", "link": "http://arxiv.org/abs/2202.00475v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparison of COVID-19 Prediction Performances of Normalization Methods\n  on Cough Acoustics Sounds", "abstract": "The disease called the new coronavirus (COVID19) is a new viral respiratory\ndisease that first appeared on January 13, 2020 in Wuhan, China. Some of the\nsymptoms of this disease are fever, cough, shortness of breath and difficulty\nin breathing. In more serious cases, death may occur as a result of infection.\nCOVID19 emerged as a pandemic that affected the whole world in a little while.\nThe most important issue in the fight against the epidemic is the early\ndiagnosis and follow-up of COVID19 (+) patients. Therefore, in addition to the\nRT-PCR test, medical imaging methods are also used when identifying COVID 19\n(+) patients. In this study, an alternative approach was proposed using cough\ndata, one of the most prominent symptoms of COVID19 (+) patients. The\nperformances of z-normalization and min-max normalization methods were\ninvestigated on these data. All features were obtained using discrete wavelet\ntransform method. Support vector machines (SVM) was used as classifier\nalgorithm. The highest performances of accuracy and F1-score were obtained as\n100% and 100% using the min-max normalization, respectively. On the other hand,\nthe highest accuracy and highest F1-score performances were obtained as 99.2 %\nand 99.0 % using the z-normalization, respectively. In light of the results, it\nis clear that cough acoustic data will contribute significantly to controlling\nCOVID19 cases.", "published": "2022-01-16 16:16:49", "link": "http://arxiv.org/abs/2201.06078v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Modeling the Repetition-based Recovering of Acoustic and Visual Sources\n  with Dendritic Neurons", "abstract": "In natural auditory environments, acoustic signals originate from the\ntemporal superimposition of different sound sources. The problem of inferring\nindividual sources from ambiguous mixtures of sounds is known as blind source\ndecomposition. Experiments on humans have demonstrated that the auditory system\ncan identify sound sources as repeating patterns embedded in the acoustic\ninput. Source repetition produces temporal regularities that can be detected\nand used for segregation. Specifically, listeners can identify sounds occurring\nmore than once across different mixtures, but not sounds heard only in a single\nmixture. However, whether such a behaviour can be computationally modelled has\nnot yet been explored. Here, we propose a biologically inspired computational\nmodel to perform blind source separation on sequences of mixtures of acoustic\nstimuli. Our method relies on a somatodendritic neuron model trained with a\nHebbian-like learning rule which can detect spatio-temporal patterns recurring\nin synaptic inputs. We show that the segregation capabilities of our model are\nreminiscent of the features of human performance in a variety of experimental\nsettings involving synthesized sounds with naturalistic properties.\nFurthermore, we extend the study to investigate the properties of segregation\non task settings not yet explored with human subjects, namely natural sounds\nand images. Overall, our work suggests that somatodendritic neuron models offer\na promising neuro-inspired learning strategy to account for the characteristics\nof the brain segregation capabilities as well as to make predictions on yet\nuntested experimental settings.", "published": "2022-01-16 19:35:59", "link": "http://arxiv.org/abs/2201.06123v1", "categories": ["cs.SD", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
