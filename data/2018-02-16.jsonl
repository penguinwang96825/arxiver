{"title": "Learning beyond datasets: Knowledge Graph Augmented Neural Networks for\n  Natural language Processing", "abstract": "Machine Learning has been the quintessential solution for many AI problems,\nbut learning is still heavily dependent on the specific training data. Some\nlearning models can be incorporated with a prior knowledge in the Bayesian set\nup, but these learning models do not have the ability to access any organised\nworld knowledge on demand. In this work, we propose to enhance learning models\nwith world knowledge in the form of Knowledge Graph (KG) fact triples for\nNatural Language Processing (NLP) tasks. Our aim is to develop a deep learning\nmodel that can extract relevant prior support facts from knowledge graphs\ndepending on the task using attention mechanism. We introduce a\nconvolution-based model for learning representations of knowledge graph entity\nand relation clusters in order to reduce the attention space. We show that the\nproposed method is highly scalable to the amount of prior information that has\nto be processed and can be applied to any generic NLP task. Using this method\nwe show significant improvement in performance for text classification with\nNews20, DBPedia datasets and natural language inference with Stanford Natural\nLanguage Inference (SNLI) dataset. We also demonstrate that a deep learning\nmodel can be trained well with substantially less amount of labeled training\ndata, when it has access to organised world knowledge in the form of knowledge\ngraph.", "published": "2018-02-16 13:38:00", "link": "http://arxiv.org/abs/1802.05930v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instance-based Inductive Deep Transfer Learning by Cross-Dataset\n  Querying with Locality Sensitive Hashing", "abstract": "Supervised learning models are typically trained on a single dataset and the\nperformance of these models rely heavily on the size of the dataset, i.e.,\namount of data available with the ground truth. Learning algorithms try to\ngeneralize solely based on the data that is presented with during the training.\nIn this work, we propose an inductive transfer learning method that can augment\nlearning models by infusing similar instances from different learning tasks in\nthe Natural Language Processing (NLP) domain. We propose to use instance\nrepresentations from a source dataset, \\textit{without inheriting anything}\nfrom the source learning model. Representations of the instances of\n\\textit{source} \\& \\textit{target} datasets are learned, retrieval of relevant\nsource instances is performed using soft-attention mechanism and\n\\textit{locality sensitive hashing}, and then, augmented into the model during\ntraining on the target dataset. Our approach simultaneously exploits the local\n\\textit{instance level information} as well as the macro statistical viewpoint\nof the dataset. Using this approach we have shown significant improvements for\nthree major news classification datasets over the baseline. Experimental\nevaluations also show that the proposed approach reduces dependency on labeled\ndata by a significant margin for comparable performance. With our proposed\ncross dataset learning procedure we show that one can achieve\ncompetitive/better performance than learning from a single dataset.", "published": "2018-02-16 13:59:15", "link": "http://arxiv.org/abs/1802.05934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fluency Over Adequacy: A Pilot Study in Measuring User Trust in\n  Imperfect MT", "abstract": "Although measuring intrinsic quality has been a key factor in the advancement\nof Machine Translation (MT), successfully deploying MT requires considering not\njust intrinsic quality but also the user experience, including aspects such as\ntrust. This work introduces a method of studying how users modulate their trust\nin an MT system after seeing errorful (disfluent or inadequate) output amidst\ngood (fluent and adequate) output. We conduct a survey to determine how users\nrespond to good translations compared to translations that are either adequate\nbut not fluent, or fluent but not adequate. In this pilot study, users\nresponded strongly to disfluent translations, but were, surprisingly, much less\nconcerned with adequacy.", "published": "2018-02-16 17:34:32", "link": "http://arxiv.org/abs/1802.06041v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bayesian Models for Unit Discovery on a Very Low Resource Language", "abstract": "Developing speech technologies for low-resource languages has become a very\nactive research field over the last decade. Among others, Bayesian models have\nshown some promising results on artificial examples but still lack of in situ\nexperiments. Our work applies state-of-the-art Bayesian models to unsupervised\nAcoustic Unit Discovery (AUD) in a real low-resource language scenario. We also\nshow that Bayesian models can naturally integrate information from other\nresourceful languages by means of informative prior leading to more consistent\ndiscovered units. Finally, discovered acoustic units are used, either as the\n1-best sequence or as a lattice, to perform word segmentation. Word\nsegmentation results show that this Bayesian approach clearly outperforms a\nSegmental-DTW baseline on the same corpus.", "published": "2018-02-16 17:58:43", "link": "http://arxiv.org/abs/1802.06053v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangling Aspect and Opinion Words in Target-based Sentiment\n  Analysis using Lifelong Learning", "abstract": "Given a target name, which can be a product aspect or entity, identifying its\naspect words and opinion words in a given corpus is a fine-grained task in\ntarget-based sentiment analysis (TSA). This task is challenging, especially\nwhen we have no labeled data and we want to perform it for any given domain. To\naddress it, we propose a general two-stage approach. Stage one extracts/groups\nthe target-related words (call t-words) for a given target. This is relatively\neasy as we can apply an existing semantics-based learning technique. Stage two\nseparates the aspect and opinion words from the grouped t-words, which is\nchallenging because we often do not have enough word-level aspect and opinion\nlabels. In this work, we formulate this problem in a PU learning setting and\nincorporate the idea of lifelong learning to solve it. Experimental results\nshow the effectiveness of our approach.", "published": "2018-02-16 02:00:10", "link": "http://arxiv.org/abs/1802.05818v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Generative Model for Joint Alignment and Word Representation", "abstract": "This work exploits translation data as a source of semantically relevant\nlearning signal for models of word representation. In particular, we exploit\nequivalence through translation as a form of distributed context and jointly\nlearn how to embed and align with a deep generative model. Our EmbedAlign model\nembeds words in their complete observed context and learns by marginalisation\nof latent lexical alignments. Besides, it embeds words as posterior probability\ndensities, rather than point estimates, which allows us to compare words in\ncontext using a measure of overlap between distributions (e.g. KL divergence).\nWe investigate our model's performance on a range of lexical semantics tasks\nachieving competitive results on several standard benchmarks including natural\nlanguage inference, paraphrasing, and text similarity.", "published": "2018-02-16 10:11:39", "link": "http://arxiv.org/abs/1802.05883v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Articulatory information and Multiview Features for Large Vocabulary\n  Continuous Speech Recognition", "abstract": "This paper explores the use of multi-view features and their discriminative\ntransforms in a convolutional deep neural network (CNN) architecture for a\ncontinuous large vocabulary speech recognition task. Mel-filterbank energies\nand perceptually motivated forced damped oscillator coefficient (DOC) features\nare used after feature-space maximum-likelihood linear regression (fMLLR)\ntransforms, which are combined and fed as a multi-view feature to a single CNN\nacoustic model. Use of multi-view feature representation demonstrated\nsignificant reduction in word error rates (WERs) compared to the use of\nindividual features by themselves. In addition, when articulatory information\nwas used as an additional input to a fused deep neural network (DNN) and CNN\nacoustic model, it was found to demonstrate further reduction in WER for the\nSwitchboard subset and the CallHome subset (containing partly non-native\naccented speech) of the NIST 2000 conversational telephone speech test set,\nreducing the error rate by 12% relative to the baseline in both cases. This\nwork shows that multi-view features in association with articulatory\ninformation can improve speech recognition robustness to spontaneous and\nnon-native speech.", "published": "2018-02-16 07:45:53", "link": "http://arxiv.org/abs/1802.05853v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards a Continuous Knowledge Learning Engine for Chatbots", "abstract": "Although chatbots have been very popular in recent years, they still have\nsome serious weaknesses which limit the scope of their applications. One major\nweakness is that they cannot learn new knowledge during the conversation\nprocess, i.e., their knowledge is fixed beforehand and cannot be expanded or\nupdated during conversation. In this paper, we propose to build a general\nknowledge learning engine for chatbots to enable them to continuously and\ninteractively learn new knowledge during conversations. As time goes by, they\nbecome more and more knowledgeable and better and better at learning and\nconversation. We model the task as an open-world knowledge base completion\nproblem and propose a novel technique called lifelong interactive learning and\ninference (LiLi) to solve it. LiLi works by imitating how humans acquire\nknowledge and perform inference during an interactive conversation. Our\nexperimental results show LiLi is highly promising.", "published": "2018-02-16 16:50:27", "link": "http://arxiv.org/abs/1802.06024v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Interpreting DNN output layer activations: A strategy to cope with\n  unseen data in speech recognition", "abstract": "Unseen data can degrade performance of deep neural net acoustic models. To\ncope with unseen data, adaptation techniques are deployed. For unlabeled unseen\ndata, one must generate some hypothesis given an existing model, which is used\nas the label for model adaptation. However, assessing the goodness of the\nhypothesis can be difficult, and an erroneous hypothesis can lead to poorly\ntrained models. In such cases, a strategy to select data having reliable\nhypothesis can ensure better model adaptation. This work proposes a\ndata-selection strategy for DNN model adaptation, where DNN output layer\nactivations are used to ascertain the goodness of a generated hypothesis. In a\nDNN acoustic model, the output layer activations are used to generate target\nclass probabilities. Under unseen data conditions, the difference between the\nmost probable target and the next most probable target is decreased compared to\nthe same for seen data, indicating that the model may be uncertain while\ngenerating its hypothesis. This work proposes a strategy to assess a model's\nperformance by analyzing the output layer activations by using a distance\nmeasure between the most likely target and the next most likely target, which\nis used for data selection for performing unsupervised adaptation.", "published": "2018-02-16 07:42:35", "link": "http://arxiv.org/abs/1802.06861v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Joint Estimation of Room Geometry and Modes with Compressed Sensing", "abstract": "Acoustical behavior of a room for a given position of microphone and sound\nsource is usually described using the room impulse response. If we rely on the\nstandard uniform sampling, the estimation of room impulse response for\narbitrary positions in the room requires a large number of measurements. In\norder to lower the required sampling rate, some solutions have emerged that\nexploit the sparse representation of the room wavefield in the terms of plane\nwaves in the low-frequency domain. The plane wave representation has a simple\nform in rectangular rooms. In our solution, we observe the basic axial modes of\nthe wave vector grid for extraction of the room geometry and then we propagate\nthe knowledge to higher order modes out of the low-pass version of the\nmeasurements. Estimation of the approximate structure of the $k$-space should\nlead to the reduction in the terms of number of required measurements and in\nthe increase of the speed of the reconstruction without great losses of\nquality.", "published": "2018-02-16 09:41:56", "link": "http://arxiv.org/abs/1802.05879v1", "categories": ["eess.AS", "cs.CV", "eess.SP"], "primary_category": "eess.AS"}
