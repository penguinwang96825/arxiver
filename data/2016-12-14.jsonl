{"title": "Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy\n  Detection", "abstract": "The fundamental role of hypernymy in NLP has motivated the development of\nmany methods for the automatic identification of this relation, most of which\nrely on word distribution. We investigate an extensive number of such\nunsupervised measures, using several distributional semantic models that differ\nby context type and feature weighting. We analyze the performance of the\ndifferent methods based on their linguistic motivation. Comparison to the\nstate-of-the-art supervised methods shows that while supervised methods\ngenerally outperform the unsupervised ones, the former are sensitive to the\ndistribution of training instances, hurting their reliability. Being based on\ngeneral linguistic hypotheses and independent from training data, unsupervised\nmeasures are more robust, and therefore are still useful artillery for\nhypernymy detection.", "published": "2016-12-14 02:28:29", "link": "http://arxiv.org/abs/1612.04460v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mining Compatible/Incompatible Entities from Question and Answering via\n  Yes/No Answer Classification using Distant Label Expansion", "abstract": "Product Community Question Answering (PCQA) provides useful information about\nproducts and their features (aspects) that may not be well addressed by product\ndescriptions and reviews. We observe that a product's compatibility issues with\nother products are frequently discussed in PCQA and such issues are more\nfrequently addressed in accessories, i.e., via a yes/no question \"Does this\nmouse work with windows 10?\". In this paper, we address the problem of\nextracting compatible and incompatible products from yes/no questions in PCQA.\nThis problem can naturally have a two-stage framework: first, we perform\nComplementary Entity (product) Recognition (CER) on yes/no questions; second,\nwe identify the polarities of yes/no answers to assign the complementary\nentities a compatibility label (compatible, incompatible or unknown). We\nleverage an existing unsupervised method for the first stage and a 3-class\nclassifier by combining a distant PU-learning method (learning from positive\nand unlabeled examples) together with a binary classifier for the second stage.\nThe benefit of using distant PU-learning is that it can help to expand more\nimplicit yes/no answers without using any human annotated data. We conduct\nexperiments on 4 products to show that the proposed method is effective.", "published": "2016-12-14 06:05:39", "link": "http://arxiv.org/abs/1612.04499v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammatical Constraints on Intra-sentential Code-Switching: From\n  Theories to Working Models", "abstract": "We make one of the first attempts to build working models for\nintra-sentential code-switching based on the Equivalence-Constraint (Poplack\n1980) and Matrix-Language (Myers-Scotton 1993) theories. We conduct a detailed\ntheoretical analysis, and a small-scale empirical study of the two models for\nHindi-English CS. Our analyses show that the models are neither sound nor\ncomplete. Taking insights from the errors made by the models, we propose a new\nmodel that combines features of both the theories.", "published": "2016-12-14 09:00:21", "link": "http://arxiv.org/abs/1612.04538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Emoji Recommendation in Dialogue Systems", "abstract": "Emoji is an essential component in dialogues which has been broadly utilized\non almost all social platforms. It could express more delicate feelings beyond\nplain texts and thus smooth the communications between users, making dialogue\nsystems more anthropomorphic and vivid. In this paper, we focus on\nautomatically recommending appropriate emojis given the contextual information\nin multi-turn dialogue systems, where the challenges locate in understanding\nthe whole conversations. More specifically, we propose the hierarchical long\nshort-term memory model (H-LSTM) to construct dialogue representations,\nfollowed by a softmax classifier for emoji classification. We evaluate our\nmodels on the task of emoji classification in a real-world dataset, with some\nfurther explorations on parameter sensitivity and case study. Experimental\nresults demonstrate that our method achieves the best performances on all\nevaluation metrics. It indicates that our method could well capture the\ncontextual information and emotion flow in dialogues, which is significant for\nemoji recommendation.", "published": "2016-12-14 12:46:18", "link": "http://arxiv.org/abs/1612.04609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Grammatical is Character-level Neural Machine Translation? Assessing\n  MT Quality with Contrastive Translation Pairs", "abstract": "Analysing translation quality in regards to specific linguistic phenomena has\nhistorically been difficult and time-consuming. Neural machine translation has\nthe attractive property that it can produce scores for arbitrary translations,\nand we propose a novel method to assess how well NMT systems model specific\nlinguistic phenomena such as agreement over long distances, the production of\nnovel words, and the faithful translation of polarity. The core idea is that we\nmeasure whether a reference translation is more probable under a NMT model than\na contrastive translation which introduces a specific type of error. We present\nLingEval97, a large-scale data set of 97000 contrastive translation pairs based\non the WMT English->German translation task, with errors automatically created\nwith simple rules. We report results for a number of systems, and find that\nrecently introduced character-level NMT systems perform better at\ntransliteration than models with byte-pair encoding (BPE) segmentation, but\nperform more poorly at morphosyntactic agreement, and translating discontiguous\nunits of meaning.", "published": "2016-12-14 13:45:35", "link": "http://arxiv.org/abs/1612.04629v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Clustering of Commercial Domains for Adaptive Machine\n  Translation", "abstract": "In this paper, we report on domain clustering in the ambit of an adaptive MT\narchitecture. A standard bottom-up hierarchical clustering algorithm has been\ninstantiated with five different distances, which have been compared, on an MT\nbenchmark built on 40 commercial domains, in terms of dendrograms, intrinsic\nand extrinsic evaluations. The main outcome is that the most expensive distance\nis also the only one able to allow the MT engine to guarantee good performance\neven with few, but highly populated clusters of domains.", "published": "2016-12-14 15:21:48", "link": "http://arxiv.org/abs/1612.04683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Word Embeddings using Multigraphs", "abstract": "We present a family of neural-network--inspired models for computing\ncontinuous word representations, specifically designed to exploit both\nmonolingual and multilingual text. This framework allows us to perform\nunsupervised training of embeddings that exhibit higher accuracy on syntactic\nand semantic compositionality, as well as multilingual semantic similarity,\ncompared to previous models trained in an unsupervised fashion. We also show\nthat such multilingual embeddings, optimized for semantic similarity, can\nimprove the performance of statistical machine translation with respect to how\nit handles words not present in the parallel data.", "published": "2016-12-14 17:13:01", "link": "http://arxiv.org/abs/1612.04732v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoPaSul Manual -- Contour-based parametric and superpositional\n  intonation stylization", "abstract": "The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and\n(2) prosodic feature extraction from syllable to utterance level. CoPaSul\nstands for contour-based, parametric, superpositional intonation stylization.\nIn this framework intonation is represented as a superposition of global and\nlocal contours that are described parametrically in terms of polynomial\ncoefficients. On the global level (usually associated but not necessarily\nrestricted to intonation phrases) the stylization serves to represent register\nin terms of time-varying F0 level and range. On the local level (e.g. accent\ngroups), local contour shapes are described. From this parameterization several\nfeatures related to prosodic boundaries and prominence can be derived.\nFurthermore, by coefficient clustering prosodic contour classes can be obtained\nin a bottom-up way. Next to the stylization-based feature extraction also\nstandard F0 and energy measures (e.g. mean and variance) as well as rhythmic\naspects can be calculated. At the current state automatic annotation comprises:\nsegmentation into interpausal chunks, syllable nucleus extraction, and\nunsupervised localization of prosodic phrase boundaries and prominent\nsyllables. F0 and partly also energy feature sets can be derived for: standard\nmeasurements (as median and IQR), register in terms of F0 level and range,\nprosodic boundaries, local contour shapes, bottom-up derived contour classes,\nGestalt of accent groups in terms of their deviation from higher level prosodic\nunits, as well as for rhythmic aspects quantifying the relation between F0 and\nenergy contours and prosodic event rates.", "published": "2016-12-14 18:37:30", "link": "http://arxiv.org/abs/1612.04765v13", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recurrent Deep Stacking Networks for Speech Recognition", "abstract": "This paper presented our work on applying Recurrent Deep Stacking Networks\n(RDSNs) to Robust Automatic Speech Recognition (ASR) tasks. In the paper, we\nalso proposed a more efficient yet comparable substitute to RDSN, Bi- Pass\nStacking Network (BPSN). The main idea of these two models is to add\nphoneme-level information into acoustic models, transforming an acoustic model\nto the combination of an acoustic model and a phoneme-level N-gram model.\nExperiments showed that RDSN and BPsn can substantially improve the\nperformances over conventional DNNs.", "published": "2016-12-14 15:07:51", "link": "http://arxiv.org/abs/1612.04675v2", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Incorporating Language Level Information into Acoustic Models", "abstract": "This paper proposed a class of novel Deep Recurrent Neural Networks which can\nincorporate language-level information into acoustic models. For simplicity, we\nnamed these networks Recurrent Deep Language Networks (RDLNs). Multiple\nvariants of RDLNs were considered, including two kinds of context information,\ntwo methods to process the context, and two methods to incorporate the\nlanguage-level information. RDLNs provided possible methods to fine-tune the\nwhole Automatic Speech Recognition (ASR) system in the acoustic modeling\nprocess.", "published": "2016-12-14 17:40:02", "link": "http://arxiv.org/abs/1612.04744v2", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Attentive Explanations: Justifying Decisions and Pointing to the\n  Evidence", "abstract": "Deep models are the defacto standard in visual decision models due to their\nimpressive performance on a wide array of visual tasks. However, they are\nfrequently seen as opaque and are unable to explain their decisions. In\ncontrast, humans can justify their decisions with natural language and point to\nthe evidence in the visual world which led to their decisions. We postulate\nthat deep models can do this as well and propose our Pointing and Justification\n(PJ-X) model which can justify its decision with a sentence and point to the\nevidence by introspecting its decision and explanation process using an\nattention mechanism. Unfortunately there is no dataset available with reference\nexplanations for visual decision making. We thus collect two datasets in two\ndomains where it is interesting and challenging to explain decisions. First, we\nextend the visual question answering task to not only provide an answer but\nalso a natural language explanation for the answer. Second, we focus on\nexplaining human activities which is traditionally more challenging than object\nclassification. We extensively evaluate our PJ-X model, both on the\njustification and pointing tasks, by comparing it to prior models and ablations\nusing both automatic and human evaluations.", "published": "2016-12-14 18:12:47", "link": "http://arxiv.org/abs/1612.04757v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Interpretable Semantic Textual Similarity: Finding and explaining\n  differences between sentences", "abstract": "User acceptance of artificial intelligence agents might depend on their\nability to explain their reasoning, which requires adding an interpretability\nlayer that fa- cilitates users to understand their behavior. This paper focuses\non adding an in- terpretable layer on top of Semantic Textual Similarity (STS),\nwhich measures the degree of semantic equivalence between two sentences. The\ninterpretability layer is formalized as the alignment between pairs of segments\nacross the two sentences, where the relation between the segments is labeled\nwith a relation type and a similarity score. We present a publicly available\ndataset of sentence pairs annotated following the formalization. We then\ndevelop a system trained on this dataset which, given a sentence pair, explains\nwhat is similar and different, in the form of graded and typed segment\nalignments. When evaluated on the dataset, the system performs better than an\ninformed baseline, showing that the dataset and task are well-defined and\nfeasible. Most importantly, two user studies show how the system output can be\nused to automatically produce explanations in natural language. Users performed\nbetter when having access to the explanations, pro- viding preliminary evidence\nthat our dataset and method to automatically produce explanations is useful in\nreal applications.", "published": "2016-12-14 22:22:33", "link": "http://arxiv.org/abs/1612.04868v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
