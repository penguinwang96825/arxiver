{"title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation", "abstract": "Partial differential equations (PDEs) are fundamental to modeling physical\nsystems, yet solving them remains a complex challenge. Traditional numerical\nsolvers rely on expert knowledge to implement and are computationally\nexpensive, while neural-network-based solvers require large training datasets\nand often lack interpretability. In this work, we frame PDE solving as a code\ngeneration task and introduce CodePDE, the first inference framework for\ngenerating PDE solvers using large language models (LLMs). Leveraging advanced\ninference-time algorithms and scaling strategies, CodePDE unlocks critical\ncapacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and\ntest-time scaling -- all without task-specific tuning. CodePDE achieves\nsuperhuman performance across a range of representative PDE problems. We also\npresent a systematic empirical analysis of LLM generated solvers, analyzing\ntheir accuracy, efficiency, and numerical scheme choices. Our findings\nhighlight the promise and the current limitations of LLMs in PDE solving,\noffering a new perspective on solver design and opportunities for future model\ndevelopment. Our code is available at https://github.com/LithiumDA/CodePDE.", "published": "2025-05-13 17:58:08", "link": "http://arxiv.org/abs/2505.08783v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "HealthBench: Evaluating Large Language Models Towards Improved Human Health", "abstract": "We present HealthBench, an open-source benchmark measuring the performance\nand safety of large language models in healthcare. HealthBench consists of\n5,000 multi-turn conversations between a model and an individual user or\nhealthcare professional. Responses are evaluated using conversation-specific\nrubrics created by 262 physicians. Unlike previous multiple-choice or\nshort-answer benchmarks, HealthBench enables realistic, open-ended evaluation\nthrough 48,562 unique rubric criteria spanning several health contexts (e.g.,\nemergencies, transforming clinical data, global health) and behavioral\ndimensions (e.g., accuracy, instruction following, communication). HealthBench\nperformance over the last two years reflects steady initial progress (compare\nGPT-3.5 Turbo's 16% to GPT-4o's 32%) and more rapid recent improvements (o3\nscores 60%). Smaller models have especially improved: GPT-4.1 nano outperforms\nGPT-4o and is 25 times cheaper. We additionally release two HealthBench\nvariations: HealthBench Consensus, which includes 34 particularly important\ndimensions of model behavior validated via physician consensus, and HealthBench\nHard, where the current top score is 32%. We hope that HealthBench grounds\nprogress towards model development and applications that benefit human health.", "published": "2025-05-13 17:53:59", "link": "http://arxiv.org/abs/2505.08775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aya Vision: Advancing the Frontier of Multilingual Multimodality", "abstract": "Building multimodal language models is fundamentally challenging: it requires\naligning vision and language modalities, curating high-quality instruction\ndata, and avoiding the degradation of existing text-only capabilities once\nvision is introduced. These difficulties are further magnified in the\nmultilingual setting, where the need for multimodal data in different languages\nexacerbates existing data scarcity, machine translation often distorts meaning,\nand catastrophic forgetting is more pronounced. To address the aforementioned\nchallenges, we introduce novel techniques spanning both data and modeling.\nFirst, we develop a synthetic annotation framework that curates high-quality,\ndiverse multilingual multimodal instruction data, enabling Aya Vision models to\nproduce natural, human-preferred responses to multimodal inputs across many\nlanguages. Complementing this, we propose a cross-modal model merging technique\nthat mitigates catastrophic forgetting, effectively preserving text-only\ncapabilities while simultaneously enhancing multimodal generative performance.\nAya-Vision-8B achieves best-in-class performance compared to strong multimodal\nmodels such as Qwen-2.5-VL-7B, Pixtral-12B, and even much larger\nLlama-3.2-90B-Vision. We further scale this approach with Aya-Vision-32B, which\noutperforms models more than twice its size, such as Molmo-72B and\nLLaMA-3.2-90B-Vision. Our work advances multilingual progress on the\nmulti-modal frontier, and provides insights into techniques that effectively\nbend the need for compute while delivering extremely high performance.", "published": "2025-05-13 17:03:48", "link": "http://arxiv.org/abs/2505.08751v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models", "abstract": "Actual causality (AC), a fundamental aspect of causal reasoning (CR), is\nresponsible for attribution and responsibility assignment in real-world\nscenarios. However, existing LLM-based methods lack grounding in formal AC\ntheory, resulting in limited interpretability. Therefore, we propose AC-Reason,\na semi-formal reasoning framework that identifies causally relevant events\nwithin an AC scenario, infers the values of their formal causal factors (e.g.,\nsufficiency, necessity, and normality), and answers AC queries via a\ntheory-guided algorithm with explanations. While AC-Reason does not explicitly\nconstruct a causal graph, it operates over variables in the underlying causal\nstructure to support principled reasoning. To enable comprehensive evaluation,\nwe introduce AC-Bench, a new benchmark built upon and substantially extending\nBig-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully\nannotated samples, each with detailed reasoning steps and focuses solely on\nactual causation. The case study shows that synthesized samples in AC-Bench\npresent greater challenges for LLMs. Extensive experiments on BBH-CJ and\nAC-Bench show that AC-Reason consistently improves LLM performance over\nbaselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy\nof 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +\nAC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further\nenables fine-grained analysis of reasoning faithfulness, revealing that only\nQwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful\nreasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation\nstudy proves that integrating AC theory into LLMs is highly effective, with the\nproposed algorithm contributing the most significant performance gains.", "published": "2025-05-13 17:02:33", "link": "http://arxiv.org/abs/2505.08750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies", "abstract": "Can autoregressive large language models (LLMs) learn consistent probability\ndistributions when trained on sequences in different token orders? We prove\nformally that for any well-defined probability distribution, sequence\nperplexity is invariant under any factorization, including forward, backward,\nor arbitrary permutations. This result establishes a rigorous theoretical\nfoundation for studying how LLMs learn from data and defines principled\nprotocols for empirical evaluation. Applying these protocols, we show that\nprior studies examining ordering effects suffer from critical methodological\nflaws. We retrain GPT-2 models across forward, backward, and arbitrary permuted\norders on scientific text. We find systematic deviations from theoretical\ninvariance across all orderings with arbitrary permutations strongly deviating\nfrom both forward and backward models, which largely (but not completely)\nagreed with one another. Deviations were traceable to differences in\nself-attention, reflecting positional and locality biases in processing. Our\ntheoretical and empirical results provide novel avenues for understanding\npositional biases in LLMs and suggest methods for detecting when LLMs'\nprobability distributions are inconsistent and therefore untrustworthy.", "published": "2025-05-13 16:52:19", "link": "http://arxiv.org/abs/2505.08739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context", "abstract": "This work introduces the first benchmark for nursing value alignment,\nconsisting of five core value dimensions distilled from international nursing\ncodes: Altruism, Human Dignity, Integrity, Justice, and Professionalism. The\nbenchmark comprises 1,100 real-world nursing behavior instances collected\nthrough a five-month longitudinal field study across three hospitals of varying\ntiers. These instances are annotated by five clinical nurses and then augmented\nwith LLM-generated counterfactuals with reversed ethic polarity. Each original\ncase is paired with a value-aligned and a value-violating version, resulting in\n2,200 labeled instances that constitute the Easy-Level dataset. To increase\nadversarial complexity, each instance is further transformed into a\ndialogue-based format that embeds contextual cues and subtle misleading\nsignals, yielding a Hard-Level dataset. We evaluate 23 state-of-the-art (SoTA)\nLLMs on their alignment with nursing values. Our findings reveal three key\ninsights: (1) DeepSeek-V3 achieves the highest performance on the Easy-Level\ndataset (94.55), where Claude 3.5 Sonnet outperforms other models on the\nHard-Level dataset (89.43), significantly surpassing the medical LLMs; (2)\nJustice is consistently the most difficult nursing value dimension to evaluate;\nand (3) in-context learning significantly improves alignment. This work aims to\nprovide a foundation for value-sensitive LLMs development in clinical settings.\nThe dataset and the code are available at\nhttps://huggingface.co/datasets/Ben012345/NurValues.", "published": "2025-05-13 16:46:25", "link": "http://arxiv.org/abs/2505.08734v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Memorization-Compression Cycles Improve Generalization", "abstract": "We prove theoretically that generalization improves not only through data\nscaling but also by compressing internal representations. To operationalize\nthis insight, we introduce the Information Bottleneck Language Modeling (IBLM)\nobjective, which reframes language modeling as a constrained optimization\nproblem: minimizing representation entropy subject to optimal prediction\nperformance. Empirically, we observe an emergent memorization-compression cycle\nduring LLM pretraining, evidenced by oscillation positive/negative gradient\nalignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of\nrepresentation entropy. This pattern closely mirrors the predictive-compressive\ntrade-off prescribed by IBLM and also parallels the biological alternation\nbetween awake learning and sleep consolidation. Motivated by this observation,\nwe propose Gated Phase Transition (GAPT), a training algorithm that adaptively\nswitches between memorization and compression phases. When applied to GPT-2\npretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves\ncross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining\ntask on arithmetic multiplication. In a setting designed to simulate\ncatastrophic forgetting, GAPT reduces interference by compressing and\nseparating representations, achieving a 97% improvement in separation -\nparalleling the functional role of sleep consolidation.", "published": "2025-05-13 16:37:54", "link": "http://arxiv.org/abs/2505.08727v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs", "abstract": "Electronic Health Records (EHRs) are digital records of patient information,\noften containing unstructured clinical text. Named Entity Recognition (NER) is\nessential in EHRs for extracting key medical entities like problems, tests, and\ntreatments to support downstream clinical applications. This paper explores\nprompt-based medical entity recognition using large language models (LLMs),\nspecifically GPT-4o and DeepSeek-R1, guided by various prompt engineering\ntechniques, including zero-shot, few-shot, and an ensemble approach. Among all\nstrategies, GPT-4o with prompt ensemble achieved the highest classification\nperformance with an F1-score of 0.95 and recall of 0.98, outperforming\nDeepSeek-R1 on the task. The ensemble method improved reliability by\naggregating outputs through embedding-based similarity and majority voting.", "published": "2025-05-13 16:11:29", "link": "http://arxiv.org/abs/2505.08704v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation", "abstract": "Event extraction (EE) is a fundamental task in natural language processing\n(NLP) that involves identifying and extracting event information from\nunstructured text. Effective EE in real-world scenarios requires two key steps:\nselecting appropriate schemas from hundreds of candidates and executing the\nextraction process. Existing research exhibits two critical gaps: (1) the rigid\nschema fixation in existing pipeline systems, and (2) the absence of benchmarks\nfor evaluating joint schema matching and extraction. Although large language\nmodels (LLMs) offer potential solutions, their schema hallucination tendencies\nand context window limitations pose challenges for practical deployment. In\nresponse, we propose Adaptive Schema-aware Event Extraction (ASEE), a novel\nparadigm combining schema paraphrasing with schema retrieval-augmented\ngeneration. ASEE adeptly retrieves paraphrased schemas and accurately generates\ntargeted structures. To facilitate rigorous evaluation, we construct the\nMulti-Dimensional Schema-aware Event Extraction (MD-SEE) benchmark, which\nsystematically consolidates 12 datasets across diverse domains, complexity\nlevels, and language settings. Extensive evaluations on MD-SEE show that our\nproposed ASEE demonstrates strong adaptability across various scenarios,\nsignificantly improving the accuracy of event extraction.", "published": "2025-05-13 15:47:54", "link": "http://arxiv.org/abs/2505.08690v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Revealing economic facts: LLMs know more than they say", "abstract": "We investigate whether the hidden states of large language models (LLMs) can\nbe used to estimate and impute economic and financial statistics. Focusing on\ncounty-level (e.g. unemployment) and firm-level (e.g. total assets) variables,\nwe show that a simple linear model trained on the hidden states of open-source\nLLMs outperforms the models' text outputs. This suggests that hidden states\ncapture richer economic information than the responses of the LLMs reveal\ndirectly. A learning curve analysis indicates that only a few dozen labelled\nexamples are sufficient for training. We also propose a transfer learning\nmethod that improves estimation accuracy without requiring any labelled data\nfor the target variable. Finally, we demonstrate the practical utility of\nhidden-state representations in super-resolution and data imputation tasks.", "published": "2025-05-13 15:24:08", "link": "http://arxiv.org/abs/2505.08662v1", "categories": ["cs.CL", "cs.LG", "econ.GN", "q-fin.EC", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing", "abstract": "We present MegaBeam-Mistral-7B, a language model that supports 512K-token\ncontext length. Our work addresses practical limitations in long-context\ntraining, supporting real-world tasks such as compliance monitoring and\nverification. Evaluated on three long-context benchmarks, our 7B-parameter\nmodel demonstrates superior in-context learning performance on HELMET and\nrobust retrieval and tracing capability on RULER. It is currently the only open\nmodel to achieve competitive long-range reasoning on BABILong at 512K context\nlength without RAG or targeted fine-tuning. Released as fully open source under\nthe Apache 2.0 license, the model has been downloaded over 100,000 times on\nHugging Face. Model available at:\nhttps://huggingface.co/aws-prototyping/MegaBeam-Mistral-7B-512k", "published": "2025-05-13 15:13:15", "link": "http://arxiv.org/abs/2505.08651v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TRAIL: Trace Reasoning and Agentic Issue Localization", "abstract": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.", "published": "2025-05-13 14:55:31", "link": "http://arxiv.org/abs/2505.08638v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models", "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.", "published": "2025-05-13 14:40:22", "link": "http://arxiv.org/abs/2505.08622v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Automatic Task Detection and Heterogeneous LLM Speculative Decoding", "abstract": "Speculative decoding, which combines a draft model with a target model, has\nemerged as an effective approach to accelerate large language model (LLM)\ninference. However, existing methods often face a trade-off between the\nacceptance rate and decoding speed in downstream tasks due to the limited\ncapacity of the draft model, making it difficult to ensure efficiency across\ndiverse tasks. To address this problem, we propose a speculative decoding\nalgorithm tailored for downstream task optimization. It includes an automatic\ntask partitioning and assigning method, which automatically categorizes\ndownstream tasks into different sub-tasks and assigns them to a set of\nheterogeneous draft models. Each draft model is aligned with the target model\nusing task-specific data, thereby enhancing the consistency of inference\nresults. In addition, our proposed method incorporates an online lightweight\nprompt classifier to dynamically route prompts to the appropriate draft model.\nExperimental results demonstrate that the proposed method improves draft\naccuracy by 6% to 50% over vanilla speculative decoding, while achieving a\nspeedup of 1.10x to 2.64x in LLM inference.", "published": "2025-05-13 14:16:12", "link": "http://arxiv.org/abs/2505.08600v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models", "abstract": "Advancements in artificial intelligence (AI) are transforming pathology by\nintegrat-ing large language models (LLMs) with retrieval-augmented generation\n(RAG) and domain-specific foundation models. This study explores the\napplication of RAG-enhanced LLMs coupled with pathology foundation models for\nthyroid cytology diagnosis, addressing challenges in cytological\ninterpretation, standardization, and diagnostic accuracy. By leveraging a\ncurated knowledge base, RAG facilitates dy-namic retrieval of relevant case\nstudies, diagnostic criteria, and expert interpreta-tion, improving the\ncontextual understanding of LLMs. Meanwhile, pathology foun-dation models,\ntrained on high-resolution pathology images, refine feature extrac-tion and\nclassification capabilities. The fusion of these AI-driven approaches en-hances\ndiagnostic consistency, reduces variability, and supports pathologists in\ndis-tinguishing benign from malignant thyroid lesions. Our results demonstrate\nthat integrating RAG with pathology-specific LLMs significantly improves\ndiagnostic efficiency and interpretability, paving the way for AI-assisted\nthyroid cytopathology, with foundation model UNI achieving AUC 0.73-0.93 for\ncorrect prediction of surgi-cal pathology diagnosis from thyroid cytology\nsamples.", "published": "2025-05-13 14:01:35", "link": "http://arxiv.org/abs/2505.08590v1", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED", "abstract": "GPT has become nearly synonymous with large language models (LLMs), an\nincreasingly popular term in AIED proceedings. A simple keyword-based search\nreveals that 61% of the 76 long and short papers presented at AIED 2024\ndescribe novel solutions using LLMs to address some of the long-standing\nchallenges in education, and 43% specifically mention GPT. Although LLMs\npioneered by GPT create exciting opportunities to strengthen the impact of AI\non education, we argue that the field's predominant focus on GPT and other\nresource-intensive LLMs (with more than 10B parameters) risks neglecting the\npotential impact that small language models (SLMs) can make in providing\nresource-constrained institutions with equitable and affordable access to\nhigh-quality AI tools. Supported by positive results on knowledge component\n(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as\nPhi-2 can produce an effective solution without elaborate prompting strategies.\nHence, we call for more attention to developing SLM-based AIED approaches.", "published": "2025-05-13 13:58:29", "link": "http://arxiv.org/abs/2505.08588v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Are We Paying Attention to Her? Investigating Gender Disambiguation and Attention in Machine Translation", "abstract": "While gender bias in modern Neural Machine Translation (NMT) systems has\nreceived much attention, traditional evaluation metrics do not to fully capture\nthe extent to which these systems integrate contextual gender cues. We propose\na novel evaluation metric called Minimal Pair Accuracy (MPA), which measures\nthe reliance of models on gender cues for gender disambiguation. MPA is\ndesigned to go beyond surface-level gender accuracy metrics by focusing on\nwhether models adapt to gender cues in minimal pairs -- sentence pairs that\ndiffer solely in the gendered pronoun, namely the explicit indicator of the\ntarget's entity gender in the source language (EN). We evaluate a number of NMT\nmodels on the English-Italian (EN--IT) language pair using this metric, we show\nthat they ignore available gender cues in most cases in favor of (statistical)\nstereotypical gender interpretation. We further show that in anti-stereotypical\ncases, these models tend to more consistently take masculine gender cues into\naccount while ignoring the feminine cues. Furthermore, we analyze the attention\nhead weights in the encoder component and show that while all models encode\ngender information to some extent, masculine cues elicit a more diffused\nresponse compared to the more concentrated and specialized responses to\nfeminine gender cues.", "published": "2025-05-13 13:17:23", "link": "http://arxiv.org/abs/2505.08546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reassessing Graph Linearization for Sequence-to-sequence AMR Parsing: On the Advantages and Limitations of Triple-Based Encoding", "abstract": "Sequence-to-sequence models are widely used to train Abstract Meaning\nRepresentation (Banarescu et al., 2013, AMR) parsers. To train such models, AMR\ngraphs have to be linearized into a one-line text format. While Penman encoding\nis typically used for this purpose, we argue that it has limitations: (1) for\ndeep graphs, some closely related nodes are located far apart in the linearized\ntext (2) Penman's tree-based encoding necessitates inverse roles to handle node\nre-entrancy, doubling the number of relation types to predict. To address these\nissues, we propose a triple-based linearization method and compare its\nefficiency with Penman linearization. Although triples are well suited to\nrepresent a graph, our results suggest room for improvement in triple encoding\nto better compete with Penman's concise and explicit representation of a nested\ngraph structure.", "published": "2025-05-13 12:36:02", "link": "http://arxiv.org/abs/2505.08504v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models", "abstract": "Recent advances in large language models (LLMs) have enabled zero-shot\nautomated essay scoring (AES), providing a promising way to reduce the cost and\neffort of essay scoring in comparison with manual grading. However, most\nexisting zero-shot approaches rely on LLMs to directly generate absolute\nscores, which often diverge from human evaluations owing to model biases and\ninconsistent scoring. To address these limitations, we propose LLM-based\nComparative Essay Scoring (LCES), a method that formulates AES as a pairwise\ncomparison task. Specifically, we instruct LLMs to judge which of two essays is\nbetter, collect many such comparisons, and convert them into continuous scores.\nConsidering that the number of possible comparisons grows quadratically with\nthe number of essays, we improve scalability by employing RankNet to\nefficiently transform LLM preferences into scalar scores. Experiments using AES\nbenchmark datasets show that LCES outperforms conventional zero-shot methods in\naccuracy while maintaining computational efficiency. Moreover, LCES is robust\nacross different LLM backbones, highlighting its applicability to real-world\nzero-shot AES.", "published": "2025-05-13 12:26:16", "link": "http://arxiv.org/abs/2505.08498v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?", "abstract": "Charts are ubiquitous as they help people understand and reason with data.\nRecently, various downstream tasks, such as chart question answering,\nchart2text, and fact-checking, have emerged. Large Vision-Language Models\n(LVLMs) show promise in tackling these tasks, but their evaluation is costly\nand time-consuming, limiting real-world deployment. While using LVLMs as judges\nto assess the chart comprehension capabilities of other LVLMs could streamline\nevaluation processes, challenges like proprietary datasets, restricted access\nto powerful models, and evaluation costs hinder their adoption in industrial\nsettings. To this end, we present a comprehensive evaluation of 13 open-source\nLVLMs as judges for diverse chart comprehension and reasoning tasks. We design\nboth pairwise and pointwise evaluation tasks covering criteria like factual\ncorrectness, informativeness, and relevancy. Additionally, we analyze LVLM\njudges based on format adherence, positional consistency, length bias, and\ninstruction-following. We focus on cost-effective LVLMs (<10B parameters)\nsuitable for both research and commercial use, following a standardized\nevaluation protocol and rubric to measure the LVLM judge's accuracy.\nExperimental results reveal notable variability: while some open LVLM judges\nachieve GPT-4-level evaluation performance (about 80% agreement with GPT-4\njudgments), others struggle (below ~10% agreement). Our findings highlight that\nstate-of-the-art open-source LVLMs can serve as cost-effective automatic\nevaluators for chart-related tasks, though biases such as positional preference\nand length bias persist.", "published": "2025-05-13 11:50:08", "link": "http://arxiv.org/abs/2505.08468v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Large Language Models Meet Stance Detection: A Survey of Tasks, Methods, Applications, Challenges and Future Directions", "abstract": "Stance detection is essential for understanding subjective content across\nvarious platforms such as social media, news articles, and online reviews.\nRecent advances in Large Language Models (LLMs) have revolutionized stance\ndetection by introducing novel capabilities in contextual understanding,\ncross-domain generalization, and multimodal analysis. Despite these\nprogressions, existing surveys often lack comprehensive coverage of approaches\nthat specifically leverage LLMs for stance detection. To bridge this critical\ngap, our review article conducts a systematic analysis of stance detection,\ncomprehensively examining recent advancements of LLMs transforming the field,\nincluding foundational concepts, methodologies, datasets, applications, and\nemerging challenges. We present a novel taxonomy for LLM-based stance detection\napproaches, structured along three key dimensions: 1) learning methods,\nincluding supervised, unsupervised, few-shot, and zero-shot; 2) data\nmodalities, such as unimodal, multimodal, and hybrid; and 3) target\nrelationships, encompassing in-target, cross-target, and multi-target\nscenarios. Furthermore, we discuss the evaluation techniques and analyze\nbenchmark datasets and performance trends, highlighting the strengths and\nlimitations of different architectures. Key applications in misinformation\ndetection, political analysis, public health monitoring, and social media\nmoderation are discussed. Finally, we identify critical challenges such as\nimplicit stance expression, cultural biases, and computational constraints,\nwhile outlining promising future directions, including explainable stance\nreasoning, low-resource adaptation, and real-time deployment frameworks. Our\nsurvey highlights emerging trends, open challenges, and future directions to\nguide researchers and practitioners in developing next-generation stance\ndetection systems powered by large language models.", "published": "2025-05-13 11:47:49", "link": "http://arxiv.org/abs/2505.08464v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models", "abstract": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.", "published": "2025-05-13 11:47:00", "link": "http://arxiv.org/abs/2505.08463v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a way to complement the\nin-context knowledge of Large Language Models (LLMs) by integrating external\ndocuments. However, real-world applications demand not only accuracy but also\ninterpretability. While dense retrieval methods provide high accuracy, they\nlack interpretability; conversely, sparse retrieval methods offer transparency\nbut often fail to capture the full intent of queries due to their reliance on\nkeyword matching. To address these issues, we introduce IterKey, an LLM-driven\niterative keyword generation framework that enhances RAG via sparse retrieval.\nIterKey consists of three LLM-driven stages: generating keywords for retrieval,\ngenerating answers based on retrieved documents, and validating the answers. If\nvalidation fails, the process iteratively repeats with refined keywords. Across\nfour QA tasks, experimental results show that IterKey achieves 5% to 20%\naccuracy improvements over BM25-based RAG and simple baselines. Its performance\nis comparable to dense retrieval-based RAG and prior iterative query refinement\nmethods using dense models. In summary, IterKey is a novel BM25-based approach\nleveraging LLMs to iteratively refine RAG, effectively balancing accuracy with\ninterpretability.", "published": "2025-05-13 11:25:15", "link": "http://arxiv.org/abs/2505.08450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency", "abstract": "Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.", "published": "2025-05-13 11:13:27", "link": "http://arxiv.org/abs/2505.08445v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the Italian Supreme Court", "abstract": "Topic modeling in Italian legal research is hindered by the lack of public\ndatasets, limiting the analysis of legal themes in Supreme Court judgments. To\naddress this, we developed a document processing pipeline that produces an\nanonymized dataset optimized for topic modeling.\n  The pipeline integrates document layout analysis (YOLOv8x), optical character\nrecognition, and text anonymization. The DLA module achieved a mAP@50 of 0.964\nand a mAP@50-95 of 0.800. The OCR detector reached a mAP@50-95 of 0.9022, and\nthe text recognizer (TrOCR) obtained a character error rate of 0.0047 and a\nword error rate of 0.0248. Compared to OCR-only methods, our dataset improved\ntopic modeling with a diversity score of 0.6198 and a coherence score of\n0.6638.\n  We applied BERTopic to extract topics and used large language models to\ngenerate labels and summaries. Outputs were evaluated against domain expert\ninterpretations. Claude Sonnet 3.7 achieved a BERTScore F1 of 0.8119 for\nlabeling and 0.9130 for summarization.", "published": "2025-05-13 11:06:24", "link": "http://arxiv.org/abs/2505.08439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hakim: Farsi Text Embedding Model", "abstract": "Recent advancements in text embedding have significantly improved natural\nlanguage understanding across many languages, yet Persian remains notably\nunderrepresented in large-scale embedding research. In this paper, we present\nHakim, a novel state-of-the-art Persian text embedding model that achieves a\n8.5% performance improvement over existing approaches on the FaMTEB benchmark,\noutperforming all previously developed Persian language models. As part of this\nwork, we introduce three new datasets - Corpesia, Pairsia-sup, and\nPairsia-unsup - to support supervised and unsupervised training scenarios.\nAdditionally, Hakim is designed for applications in chatbots and\nretrieval-augmented generation (RAG) systems, particularly addressing retrieval\ntasks that require incorporating message history within these systems. We also\npropose a new baseline model built on the BERT architecture. Our language model\nconsistently achieves higher accuracy across various Persian NLP tasks, while\nthe RetroMAE-based model proves particularly effective for textual information\nretrieval applications. Together, these contributions establish a new\nfoundation for advancing Persian language understanding.", "published": "2025-05-13 10:57:32", "link": "http://arxiv.org/abs/2505.08435v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers", "abstract": "Recently, large language models(LLMs) have played an increasingly important\nrole in solving a wide range of NLP tasks, leveraging their capabilities of\nnatural language understanding and generating. Integration with external tools\nfurther enhances LLMs' effectiveness, providing more precise, timely, and\nspecialized responses. However, LLMs still encounter difficulties with\nnon-executable actions and improper actions, which are primarily attributed to\nincorrect parameters. The process of generating parameters by LLMs is confined\nto the tool level, employing the coarse-grained strategy without considering\nthe different difficulties of various tools. To address this issue, we propose\nTUMS, a novel framework designed to enhance the tool-use capabilities of LLMs\nby transforming tool-level processing into parameter-level processing.\nSpecifically, our framework consists of four key components: (1) an intent\nrecognizer that identifies the user's intent to help LLMs better understand the\ntask; (2) a task decomposer that breaks down complex tasks into simpler\nsubtasks, each involving a tool call; (3) a subtask processor equipped with\nmulti-structure handlers to generate accurate parameters; and (4) an executor.\nOur empirical studies have evidenced the effectiveness and efficiency of the\nTUMS framework with an average of 19.6\\% and 50.6\\% improvement separately on\neasy and hard benchmarks of ToolQA, meanwhile, we demonstrated the key\ncontribution of each part with ablation experiments, offering more insights and\nstimulating future research on Tool-augmented LLMs.", "published": "2025-05-13 09:57:28", "link": "http://arxiv.org/abs/2505.08402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping", "abstract": "Large Language Models leverage Chain-of-Thought (CoT) prompting for complex\ntasks, but their reasoning traces are often excessively verbose and\ninefficient, leading to significant computational costs and latency. Current\nCoT compression techniques typically rely on generic importance metrics and\nstatic compression rates, which may inadvertently remove functionally critical\ntokens or fail to adapt to varying reasoning complexity. To overcome these\nlimitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic\nCoT compression via supervised fine-tuning. This approach introduces two\nsynergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric\naccurately identifying functionally relevant tokens by measuring the gradient\ninfluence of their intermediate representations on the final answer loss, and\n(2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the\ncompression rate based on runtime model uncertainty while ensuring local\ncoherence through an adaptive N-token constraint. To our knowledge, this is the\nfirst work unifying a goal-oriented, gradient-based importance metric with\ndynamic, uncertainty-aware skipping for CoT compression. Trained on compressed\nMATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization\nacross diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It\nachieves substantial efficiency gains - reducing CoT token counts by over 45%\non average and delivering 1.6-2.0 times inference speedups - while maintaining\nhigh reasoning accuracy. Notably, it significantly outperforms existing\nbaselines by preserving accuracy even at high effective compression rates,\nadvancing the state of the art in the CoT reasoning efficiency-accuracy\ntrade-off.", "published": "2025-05-13 09:39:18", "link": "http://arxiv.org/abs/2505.08392v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Contamination Resistant Benchmarks", "abstract": "The rapid development of large language models (LLMs) has transformed the\nlandscape of natural language processing. Evaluating LLMs properly is crucial\nfor understanding their potential and addressing concerns such as safety.\nHowever, LLM evaluation is confronted by various factors, among which\ncontamination stands out as a key issue that undermines the reliability of\nevaluations. In this work, we introduce the concept of contamination resistance\nto address this challenge. We propose a benchmark based on Caesar ciphers\n(e.g., \"ab\" to \"bc\" when the shift is 1), which, despite its simplicity, is an\nexcellent example of a contamination resistant benchmark. We test this\nbenchmark on widely used LLMs under various settings, and we find that these\nmodels struggle with this benchmark when contamination is controlled. Our\nfindings reveal issues in current LLMs and raise important questions regarding\ntheir true capabilities. Our work contributes to the development of\ncontamination resistant benchmarks, enabling more rigorous LLM evaluation and\noffering insights into the true capabilities and limitations of LLMs.", "published": "2025-05-13 09:35:40", "link": "http://arxiv.org/abs/2505.08389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring", "abstract": "This paper investigates the potentials of Large Language Models (LLMs) as\nadaptive tutors in the context of second-language learning. In particular, we\nevaluate whether system prompting can reliably constrain LLMs to generate only\ntext appropriate to the student's competence level. We simulate full\nteacher-student dialogues in Spanish using instruction-tuned, open-source LLMs\nranging in size from 7B to 12B parameters. Dialogues are generated by having an\nLLM alternate between tutor and student roles with separate chat histories. The\noutput from the tutor model is then used to evaluate the effectiveness of\nCEFR-based prompting to control text difficulty across three proficiency levels\n(A1, B1, C1). Our findings suggest that while system prompting can be used to\nconstrain model outputs, prompting alone is too brittle for sustained,\nlong-term interactional contexts - a phenomenon we term alignment drift. Our\nresults provide insights into the feasibility of LLMs for personalized,\nproficiency-aligned adaptive tutors and provide a scalable method for low-cost\nevaluation of model performance without human participants.", "published": "2025-05-13 08:50:57", "link": "http://arxiv.org/abs/2505.08351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Geometry of Semantics in Next-token Prediction", "abstract": "Modern language models demonstrate a remarkable ability to capture linguistic\nmeaning despite being trained solely through next-token prediction (NTP). We\ninvestigate how this conceptually simple training objective leads models to\nextract and encode latent semantic and grammatical concepts. Our analysis\nreveals that NTP optimization implicitly guides models to encode concepts via\nsingular value decomposition (SVD) factors of a centered data-sparsity matrix\nthat captures next-word co-occurrence patterns. While the model never\nexplicitly constructs this matrix, learned word and context embeddings\neffectively factor it to capture linguistic structure. We find that the most\nimportant SVD factors are learned first during training, motivating the use of\nspectral clustering of embeddings to identify human-interpretable semantics,\nincluding both classical k-means and a new orthant-based method directly\nmotivated by our interpretation of concepts. Overall, our work bridges\ndistributional semantics, neural collapse geometry, and neural network training\ndynamics, providing insights into how NTP's implicit biases shape the emergence\nof meaning representations in language models.", "published": "2025-05-13 08:46:04", "link": "http://arxiv.org/abs/2505.08348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale", "abstract": "We present AM-Thinking-v1, a 32B dense language model that advances the\nfrontier of reasoning, embodying the collaborative spirit of open-source\ninnovation. Outperforming DeepSeek-R1 and rivaling leading Mixture-of-Experts\n(MoE) models like Qwen3-235B-A22B and Seed1.5-Thinking, AM-Thinking-v1 achieves\nimpressive scores of 85.3 on AIME 2024, 74.4 on AIME 2025, and 70.3 on\nLiveCodeBench, showcasing state-of-the-art mathematical and coding capabilities\namong open-source models of similar scale.\n  Built entirely from the open-source Qwen2.5-32B base model and publicly\navailable queries, AM-Thinking-v1 leverages a meticulously crafted\npost-training pipeline - combining supervised fine-tuning and reinforcement\nlearning - to deliver exceptional reasoning capabilities. This work\ndemonstrates that the open-source community can achieve high performance at the\n32B scale, a practical sweet spot for deployment and fine-tuning. By striking a\nbalance between top-tier performance and real-world usability, we hope\nAM-Thinking-v1 inspires further collaborative efforts to harness mid-scale\nmodels, pushing reasoning boundaries while keeping accessibility at the core of\ninnovation. We have open-sourced our model on\n\\href{https://huggingface.co/a-m-team/AM-Thinking-v1}{Hugging Face}.", "published": "2025-05-13 07:41:15", "link": "http://arxiv.org/abs/2505.08311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow", "abstract": "Black-Box prompt optimization methods have emerged as a promising strategy\nfor refining input prompts to better align large language models (LLMs),\nthereby enhancing their task performance. Although these methods have\ndemonstrated encouraging results, most studies and experiments have primarily\nfocused on smaller-scale models (e.g., 7B, 14B) or earlier versions (e.g.,\nGPT-3.5) of LLMs. As the scale of LLMs continues to increase, such as with\nDeepSeek V3 (671B), it remains an open question whether these black-box\noptimization techniques will continue to yield significant performance\nimprovements for models of such scale. In response to this, we select three\nwell-known black-box optimization methods and evaluate them on large-scale LLMs\n(DeepSeek V3 and Gemini 2.0 Flash) across four NLU and NLG datasets. The\nresults show that these black-box prompt optimization methods offer only\nlimited improvements on these large-scale LLMs. Furthermore, we hypothesize\nthat the scale of the model is the primary factor contributing to the limited\nbenefits observed. To explore this hypothesis, we conducted experiments on LLMs\nof varying sizes (Qwen 2.5 series, ranging from 7B to 72B) and observed an\ninverse scaling law, wherein the effectiveness of black-box optimization\nmethods diminished as the model size increased.", "published": "2025-05-13 07:26:56", "link": "http://arxiv.org/abs/2505.08303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration", "abstract": "The rapid progress in large language models (LLMs) has paved the way for\nnovel approaches in knowledge-intensive tasks. Among these, Cache-Augmented\nGeneration (CAG) has emerged as a promising alternative to Retrieval-Augmented\nGeneration (RAG). CAG minimizes retrieval latency and simplifies system design\nby preloading knowledge into the model's context. However, challenges persist\nin scaling CAG to accommodate large and dynamic knowledge bases effectively.\nThis paper introduces Adaptive Contextual Compression (ACC), an innovative\ntechnique designed to dynamically compress and manage context inputs, enabling\nefficient utilization of the extended memory capabilities of modern LLMs. To\nfurther address the limitations of standalone CAG, we propose a Hybrid CAG-RAG\nFramework, which integrates selective retrieval to augment preloaded contexts\nin scenarios requiring additional information. Comprehensive evaluations on\ndiverse datasets highlight the proposed methods' ability to enhance\nscalability, optimize efficiency, and improve multi-hop reasoning performance,\noffering practical solutions for real-world knowledge integration challenges.", "published": "2025-05-13 06:24:48", "link": "http://arxiv.org/abs/2505.08261v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement", "abstract": "The rapid advancement of large language models (LLMs) has outpaced\ntraditional evaluation methodologies. It presents novel challenges, such as\nmeasuring human-like psychological constructs, navigating beyond static and\ntask-specific benchmarks, and establishing human-centered evaluation. These\nchallenges intersect with Psychometrics, the science of quantifying the\nintangible aspects of human psychology, such as personality, values, and\nintelligence. This survey introduces and synthesizes an emerging\ninterdisciplinary field of LLM Psychometrics, which leverages psychometric\ninstruments, theories, and principles to evaluate, understand, and enhance\nLLMs. We systematically explore the role of Psychometrics in shaping\nbenchmarking principles, broadening evaluation scopes, refining methodologies,\nvalidating results, and advancing LLM capabilities. This paper integrates\ndiverse perspectives to provide a structured framework for researchers across\ndisciplines, enabling a more comprehensive understanding of this nascent field.\nUltimately, we aim to provide actionable insights for developing future\nevaluation paradigms that align with human-level AI and promote the advancement\nof human-centered AI systems for societal benefit. A curated repository of LLM\npsychometric resources is available at\nhttps://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.", "published": "2025-05-13 05:47:51", "link": "http://arxiv.org/abs/2505.08245v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Not that Groove: Zero-Shot Symbolic Music Editing", "abstract": "Most work in AI music generation focused on audio, which has seen limited use\nin the music production industry due to its rigidity. To maximize flexibility\nwhile assuming only textual instructions from producers, we are among the first\nto tackle symbolic music editing. We circumvent the known challenge of lack of\nlabeled data by proving that LLMs with zero-shot prompting can effectively edit\ndrum grooves. The recipe of success is a creatively designed format that\ninterfaces LLMs and music, while we facilitate evaluation by providing an\nevaluation dataset with annotated unit tests that highly aligns with musicians'\njudgment.", "published": "2025-05-13 03:33:36", "link": "http://arxiv.org/abs/2505.08203v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs", "abstract": "Large Language Models (LLMs) have the tendency to hallucinate, i.e., to\nsporadically generate false or fabricated information. This presents a major\nchallenge, as hallucinations often appear highly convincing and users generally\nlack the tools to detect them. Uncertainty quantification (UQ) provides a\nframework for assessing the reliability of model outputs, aiding in the\nidentification of potential hallucinations. In this work, we introduce\npre-trained UQ heads: supervised auxiliary modules for LLMs that substantially\nenhance their ability to capture uncertainty compared to unsupervised UQ\nmethods. Their strong performance stems from the powerful Transformer\narchitecture in their design and informative features derived from LLM\nattention maps. Experimental evaluation shows that these heads are highly\nrobust and achieve state-of-the-art performance in claim-level hallucination\ndetection across both in-domain and out-of-domain prompts. Moreover, these\nmodules demonstrate strong generalization to languages they were not explicitly\ntrained on. We pre-train a collection of UQ heads for popular LLM series,\nincluding Mistral, Llama, and Gemma 2. We publicly release both the code and\nthe pre-trained heads.", "published": "2025-05-13 03:30:26", "link": "http://arxiv.org/abs/2505.08200v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph", "abstract": "Text-attributed graph (TAG) provides a text description for each graph node,\nand few- and zero-shot node classification on TAGs have many applications in\nfields such as academia and social networks. Existing work utilizes various\ngraph-based augmentation techniques to train the node and text embeddings,\nwhile text-based augmentations are largely unexplored. In this paper, we\npropose Text Semantics Augmentation (TSA) to improve accuracy by introducing\nmore text semantic supervision signals. Specifically, we design two\naugmentation techniques, i.e., positive semantics matching and negative\nsemantics contrast, to provide more reference texts for each graph node or text\ndescription. Positive semantic matching retrieves texts with similar embeddings\nto match with a graph node. Negative semantic contrast adds a negative prompt\nto construct a text description with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate TSA on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that TSA\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.", "published": "2025-05-13 02:06:08", "link": "http://arxiv.org/abs/2505.08168v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage", "abstract": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.", "published": "2025-05-13 02:05:25", "link": "http://arxiv.org/abs/2505.08167v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem", "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based\nlanguage models developed by leading model providers for a wide range of tasks.\nTo support enhanced user interaction and customization, many platforms-such as\nOpenAI-now enable developers to create and publish tailored model instances,\nknown as custom GPTs, via dedicated repositories or application stores. These\ncustom GPTs empower users to browse and interact with specialized applications\ndesigned to meet specific needs. However, as custom GPTs see growing adoption,\nconcerns regarding their security vulnerabilities have intensified. Existing\nresearch on these vulnerabilities remains largely theoretical, often lacking\nempirical, large-scale, and statistically rigorous assessments of associated\nrisks.\n  In this study, we analyze 14,904 custom GPTs to assess their susceptibility\nto seven exploitable threats, such as roleplay-based attacks, system prompt\nleakage, phishing content generation, and malicious code synthesis, across\nvarious categories and popularity tiers within the OpenAI marketplace. We\nintroduce a multi-metric ranking system to examine the relationship between a\ncustom GPT's popularity and its associated security risks.\n  Our findings reveal that over 95% of custom GPTs lack adequate security\nprotections. The most prevalent vulnerabilities include roleplay-based\nvulnerabilities (96.51%), system prompt leakage (92.20%), and phishing\n(91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit\ninherent security weaknesses, which are often inherited or amplified in custom\nGPTs. These results highlight the urgent need for enhanced security measures\nand stricter content moderation to ensure the safe deployment of GPT-based\napplications.", "published": "2025-05-13 00:51:07", "link": "http://arxiv.org/abs/2505.08148v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Large Language Models for Computer-Aided Design: A Survey", "abstract": "Large Language Models (LLMs) have seen rapid advancements in recent years,\nwith models like ChatGPT and DeepSeek, showcasing their remarkable capabilities\nacross diverse domains. While substantial research has been conducted on LLMs\nin various fields, a comprehensive review focusing on their integration with\nComputer-Aided Design (CAD) remains notably absent. CAD is the industry\nstandard for 3D modeling and plays a vital role in the design and development\nof products across different industries. As the complexity of modern designs\nincreases, the potential for LLMs to enhance and streamline CAD workflows\npresents an exciting frontier. This article presents the first systematic\nsurvey exploring the intersection of LLMs and CAD. We begin by outlining the\nindustrial significance of CAD, highlighting the need for AI-driven innovation.\nNext, we provide a detailed overview of the foundation of LLMs. We also examine\nboth closed-source LLMs as well as publicly available models. The core of this\nreview focuses on the various applications of LLMs in CAD, providing a taxonomy\nof six key areas where these models are making considerable impact. Finally, we\npropose several promising future directions for further advancements, which\noffer vast opportunities for innovation and are poised to shape the future of\nCAD technology. Github:\nhttps://github.com/lichengzhanguom/LLMs-CAD-Survey-Taxonomy", "published": "2025-05-13 00:19:04", "link": "http://arxiv.org/abs/2505.08137v1", "categories": ["cs.LG", "cs.CL", "cs.GR", "cs.MM"], "primary_category": "cs.LG"}
{"title": "ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval", "abstract": "The rise of Large Language Models~(LLMs) revolutionizes information\nretrieval, allowing users to obtain required answers through complex\ninstructions within conversations. However, publicly available services remain\ninadequate in addressing the needs of faculty and students to search\ncampus-specific information. It is primarily due to the LLM's lack of\ndomain-specific knowledge and the limitation of search engines in supporting\nmultilingual and timely scenarios. To tackle these challenges, we introduce\nALOHA, a multilingual agent enhanced by hierarchical retrieval for university\norientation. We also integrate external APIs into the front-end interface to\nprovide interactive service. The human evaluation and case study show our\nproposed system has strong capabilities to yield correct, timely, and\nuser-friendly responses to the queries in multiple languages, surpassing\ncommercial chatbots and search engines. The system has been deployed and has\nprovided service for more than 12,000 people.", "published": "2025-05-13 00:01:03", "link": "http://arxiv.org/abs/2505.08130v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus", "abstract": "The Abstraction and Reasoning Corpus (ARC), later renamed ARC-AGI, poses a\nfundamental challenge in artificial general intelligence (AGI), requiring\nsolutions that exhibit robust abstraction and reasoning capabilities across\ndiverse tasks, while only few (with median count of three) correct examples are\npresented. While ARC-AGI remains very challenging for artificial intelligence\nsystems, it is rather easy for humans. This paper introduces ARC-NCA, a\ndevelopmental approach leveraging standard Neural Cellular Automata (NCA) and\nNCA enhanced with hidden memories (EngramNCA) to tackle the ARC-AGI benchmark.\nNCAs are employed for their inherent ability to simulate complex dynamics and\nemergent patterns, mimicking developmental processes observed in biological\nsystems. Developmental solutions may offer a promising avenue for enhancing\nAI's problem-solving capabilities beyond mere training data extrapolation.\nARC-NCA demonstrates how integrating developmental principles into\ncomputational models can foster adaptive reasoning and abstraction. We show\nthat our ARC-NCA proof-of-concept results may be comparable to, and sometimes\nsurpass, that of ChatGPT 4.5, at a fraction of the cost.", "published": "2025-05-13 17:55:43", "link": "http://arxiv.org/abs/2505.08778v1", "categories": ["cs.AI", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology", "abstract": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.", "published": "2025-05-13 17:34:54", "link": "http://arxiv.org/abs/2505.08765v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion", "abstract": "Nutrition estimation is an important component of promoting healthy eating\nand mitigating diet-related health risks. Despite advances in tasks such as\nfood classification and ingredient recognition, progress in nutrition\nestimation is limited due to the lack of datasets with nutritional annotations.\nTo address this issue, we introduce FastFood, a dataset with 84,446 images\nacross 908 fast food categories, featuring ingredient and nutritional\nannotations. In addition, we propose a new model-agnostic Visual-Ingredient\nFeature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating\nvisual and ingredient features. Ingredient robustness is improved through\nsynonym replacement and resampling strategies during training. The\ningredient-aware visual feature fusion module combines ingredient features and\nvisual representation to achieve accurate nutritional prediction. During\ntesting, ingredient predictions are refined using large multimodal models by\ndata augmentation and majority voting. Our experiments on both FastFood and\nNutrition5k datasets validate the effectiveness of our proposed method built in\ndifferent backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the\nimportance of ingredient information in nutrition estimation.\nhttps://huiyanqi.github.io/fastfood-nutrition-estimation/.", "published": "2025-05-13 17:01:21", "link": "http://arxiv.org/abs/2505.08747v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models", "abstract": "To advance the mathematical proficiency of large language models (LLMs), the\nDeepMath team has launched an open-source initiative aimed at developing an\nopen mathematical LLM and systematically evaluating its mathematical\ncreativity. This paper represents the initial contribution of this initiative.\nWhile recent developments in mathematical LLMs have predominantly emphasized\nreasoning skills, as evidenced by benchmarks on elementary to\nundergraduate-level mathematical tasks, the creative capabilities of these\nmodels have received comparatively little attention, and evaluation datasets\nremain scarce. To address this gap, we propose an evaluation criteria for\nmathematical creativity and introduce DeepMath-Creative, a novel, high-quality\nbenchmark comprising constructive problems across algebra, geometry, analysis,\nand other domains. We conduct a systematic evaluation of mainstream LLMs'\ncreative problem-solving abilities using this dataset. Experimental results\nshow that even under lenient scoring criteria -- emphasizing core solution\ncomponents and disregarding minor inaccuracies, such as small logical gaps,\nincomplete justifications, or redundant explanations -- the best-performing\nmodel, O3 Mini, achieves merely 70% accuracy, primarily on basic\nundergraduate-level constructive tasks. Performance declines sharply on more\ncomplex problems, with models failing to provide substantive strategies for\nopen problems. These findings suggest that, although current LLMs display a\ndegree of constructive proficiency on familiar and lower-difficulty problems,\nsuch performance is likely attributable to the recombination of memorized\npatterns rather than authentic creative insight or novel synthesis.", "published": "2025-05-13 16:58:05", "link": "http://arxiv.org/abs/2505.08744v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Securing RAG: A Risk Assessment and Mitigation Framework", "abstract": "Retrieval Augmented Generation (RAG) has emerged as the de facto industry\nstandard for user-facing NLP applications, offering the ability to integrate\ndata without re-training or fine-tuning Large Language Models (LLMs). This\ncapability enhances the quality and accuracy of responses but also introduces\nnovel security and privacy challenges, particularly when sensitive data is\nintegrated. With the rapid adoption of RAG, securing data and services has\nbecome a critical priority. This paper first reviews the vulnerabilities of RAG\npipelines, and outlines the attack surface from data pre-processing and data\nstorage management to integration with LLMs. The identified risks are then\npaired with corresponding mitigations in a structured overview. In a second\nstep, the paper develops a framework that combines RAG-specific security\nconsiderations, with existing general security guidelines, industry standards,\nand best practices. The proposed framework aims to guide the implementation of\nrobust, compliant, secure, and trustworthy RAG systems.", "published": "2025-05-13 16:39:00", "link": "http://arxiv.org/abs/2505.08728v1", "categories": ["cs.CR", "cs.AI", "cs.IR"], "primary_category": "cs.CR"}
{"title": "PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts", "abstract": "Large language models (LLMs) hosted on cloud servers alleviate the\ncomputational and storage burdens on local devices but raise privacy concerns\ndue to sensitive data transmission and require substantial communication\nbandwidth, which is challenging in constrained environments. In contrast, small\nlanguage models (SLMs) running locally enhance privacy but suffer from limited\nperformance on complex tasks. To balance computational cost, performance, and\nprivacy protection under bandwidth constraints, we propose a privacy-aware\nwireless collaborative mixture of experts (PWC-MoE) framework. Specifically,\nPWC-MoE employs a sparse privacy-aware gating network to dynamically route\nsensitive tokens to privacy experts located on local clients, while\nnon-sensitive tokens are routed to non-privacy experts located at the remote\nbase station. To achieve computational efficiency, the gating network ensures\nthat each token is dynamically routed to and processed by only one expert. To\nenhance scalability and prevent overloading of specific experts, we introduce a\ngroup-wise load-balancing mechanism for the gating network that evenly\ndistributes sensitive tokens among privacy experts and non-sensitive tokens\namong non-privacy experts. To adapt to bandwidth constraints while preserving\nmodel performance, we propose a bandwidth-adaptive and importance-aware token\noffloading scheme. This scheme incorporates an importance predictor to evaluate\nthe importance scores of non-sensitive tokens, prioritizing the most important\ntokens for transmission to the base station based on their predicted importance\nand the available bandwidth. Experiments demonstrate that the PWC-MoE framework\neffectively preserves privacy and maintains high performance even in\nbandwidth-constrained environments, offering a practical solution for deploying\nLLMs in privacy-sensitive and bandwidth-limited scenarios.", "published": "2025-05-13 16:27:07", "link": "http://arxiv.org/abs/2505.08719v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Big Data and the Computational Social Science of Entrepreneurship and Innovation", "abstract": "As large-scale social data explode and machine-learning methods evolve,\nscholars of entrepreneurship and innovation face new research opportunities but\nalso unique challenges. This chapter discusses the difficulties of leveraging\nlarge-scale data to identify technological and commercial novelty, document new\nventure origins, and forecast competition between new technologies and\ncommercial forms. It suggests how scholars can take advantage of new text,\nnetwork, image, audio, and video data in two distinct ways that advance\ninnovation and entrepreneurship research. First, machine-learning models,\ncombined with large-scale data, enable the construction of precision\nmeasurements that function as system-level observatories of innovation and\nentrepreneurship across human societies. Second, new artificial intelligence\nmodels fueled by big data generate 'digital doubles' of technology and\nbusiness, forming laboratories for virtual experimentation about innovation and\nentrepreneurship processes and policies. The chapter argues for the advancement\nof theory development and testing in entrepreneurship and innovation by\ncoupling big data with big models.", "published": "2025-05-13 16:13:18", "link": "http://arxiv.org/abs/2505.08706v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "cs.SI", "q-fin.EC", "stat.AP"], "primary_category": "econ.GN"}
{"title": "Controllable Image Colorization with Instance-aware Texts and Masks", "abstract": "Recently, the application of deep learning in image colorization has received\nwidespread attention. The maturation of diffusion models has further advanced\nthe development of image colorization models. However, current mainstream image\ncolorization models still face issues such as color bleeding and color binding\nerrors, and cannot colorize images at the instance level. In this paper, we\npropose a diffusion-based colorization method MT-Color to achieve precise\ninstance-aware colorization with use-provided guidance. To tackle color\nbleeding issue, we design a pixel-level mask attention mechanism that\nintegrates latent features and conditional gray image features through\ncross-attention. We use segmentation masks to construct cross-attention masks,\npreventing pixel information from exchanging between different instances. We\nalso introduce an instance mask and text guidance module that extracts instance\nmasks and text representations of each instance, which are then fused with\nlatent features through self-attention, utilizing instance masks to form\nself-attention masks to prevent instance texts from guiding the colorization of\nother areas, thus mitigating color binding errors. Furthermore, we apply a\nmulti-instance sampling strategy, which involves sampling each instance region\nseparately and then fusing the results. Additionally, we have created a\nspecialized dataset for instance-level colorization tasks, GPT-color, by\nleveraging large visual language models on existing image datasets. Qualitative\nand quantitative experiments show that our model and dataset outperform\nprevious methods and datasets.", "published": "2025-05-13 16:13:06", "link": "http://arxiv.org/abs/2505.08705v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Survey of Deep Learning for Complex Speech Spectrograms", "abstract": "Recent advancements in deep learning have significantly impacted the field of\nspeech signal processing, particularly in the analysis and manipulation of\ncomplex spectrograms. This survey provides a comprehensive overview of the\nstate-of-the-art techniques leveraging deep neural networks for processing\ncomplex spectrograms, which encapsulate both magnitude and phase information.\nWe begin by introducing complex spectrograms and their associated features for\nvarious speech processing tasks. Next, we explore the key components and\narchitectures of complex-valued neural networks, which are specifically\ndesigned to handle complex-valued data and have been applied for complex\nspectrogram processing. We then discuss various training strategies and loss\nfunctions tailored for training neural networks to process and model complex\nspectrograms. The survey further examines key applications, including phase\nretrieval, speech enhancement, and speech separation, where deep learning has\nachieved significant progress by leveraging complex spectrograms or their\nderived feature representations. Additionally, we examine the intersection of\ncomplex spectrograms with generative models. This survey aims to serve as a\nvaluable resource for researchers and practitioners in the field of speech\nsignal processing and complex-valued neural networks.", "published": "2025-05-13 15:53:01", "link": "http://arxiv.org/abs/2505.08694v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "VizCV: AI-assisted visualization of researchers' publications tracks", "abstract": "Analyzing how the publication records of scientists and research groups have\nevolved over the years is crucial for assessing their expertise since it can\nsupport the management of academic environments by assisting with career\nplanning and evaluation. We introduce VizCV, a novel web-based end-to-end\nvisual analytics framework that enables the interactive exploration of\nresearchers' scientific trajectories. It incorporates AI-assisted analysis and\nsupports automated reporting of career evolution. Our system aims to model\ncareer progression through three key dimensions: a) research topic evolution to\ndetect and visualize shifts in scholarly focus over time, b) publication record\nand the corresponding impact, c) collaboration dynamics depicting the growth\nand transformation of a researcher's co-authorship network. AI-driven insights\nprovide automated explanations of career transitions, detecting significant\nshifts in research direction, impact surges, or collaboration expansions. The\nsystem also supports comparative analysis between researchers, allowing users\nto compare topic trajectories and impact growth. Our interactive, multi-tab and\nmultiview system allows for the exploratory analysis of career milestones under\ndifferent perspectives, such as the most impactful articles, emerging research\nthemes, or obtaining a detailed analysis of the contribution of the researcher\nin a subfield. The key contributions include AI/ML techniques for: a) topic\nanalysis, b) dimensionality reduction for visualizing patterns and trends, c)\nthe interactive creation of textual descriptions of facets of data through\nconfigurable prompt generation and large language models, that include key\nindicators, to help understanding the career development of individuals or\ngroups.", "published": "2025-05-13 15:47:59", "link": "http://arxiv.org/abs/2505.08691v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks", "abstract": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving\npartial differential equations (PDEs). Yet their original formulation is\ncomputationally and memory intensive, motivating the introduction of Chebyshev\nType-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed\nthe vanilla KANs architecture, our rigorous theoretical analysis reveals that\nthey still suffer from rank collapse, ultimately limiting their expressive\ncapacity. To overcome these limitations, we enhance Chebyshev1KANs by\nintegrating wavelet-activated MLPs with learnable parameters and an internal\nattention mechanism. We prove that this design preserves a full-rank Jacobian\nand is capable of approximating solutions to PDEs of arbitrary order.\nFurthermore, to alleviate the loss instability and imbalance introduced by the\nChebyshev polynomial basis, we externally incorporate a Residual Gradient\nAttention (RGA) mechanism that dynamically re-weights individual loss terms\naccording to their gradient norms and residual magnitudes. By jointly\nleveraging internal and external attention, we present AC-PKAN, a novel\narchitecture that constitutes an enhancement to weakly supervised\nPhysics-Informed Neural Networks (PINNs) and extends the expressive power of\nKANs. Experimental results from nine benchmark tasks across three domains show\nthat AC-PKAN consistently outperforms or matches state-of-the-art models such\nas PINNsFormer, establishing it as a highly effective tool for solving complex\nreal-world engineering problems in zero-data or data-sparse regimes. The code\nwill be made publicly available upon acceptance.", "published": "2025-05-13 15:46:10", "link": "http://arxiv.org/abs/2505.08687v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization", "abstract": "Singing melody extraction (SME) is a key task in the field of music\ninformation retrieval. However, existing methods are facing several\nlimitations: firstly, prior models use transformers to capture the contextual\ndependencies, which requires quadratic computation resulting in low efficiency\nin the inference stage. Secondly, prior works typically rely on\nfrequencysupervised methods to estimate the fundamental frequency (f0), which\nignores that the musical performance is actually based on notes. Thirdly,\ntransformers typically require large amounts of labeled data to achieve optimal\nperformances, but the SME task lacks of sufficient annotated data. To address\nthese issues, in this paper, we propose a mamba-based network, called\nSpectMamba, for semi-supervised singing melody extraction using confidence\nbinary regularization. In particular, we begin by introducing vision mamba to\nachieve computational linear complexity. Then, we propose a novel note-f0\ndecoder that allows the model to better mimic the musical performance. Further,\nto alleviate the scarcity of the labeled data, we introduce a confidence binary\nregularization (CBR) module to leverage the unlabeled data by maximizing the\nprobability of the correct classes. The proposed method is evaluated on several\npublic datasets and the conducted experiments demonstrate the effectiveness of\nour proposed method.", "published": "2025-05-13 15:43:35", "link": "http://arxiv.org/abs/2505.08681v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Study of Data-driven Methods for Inventory Optimization", "abstract": "This paper shows a comprehensive analysis of three algorithms (Time Series,\nRandom Forest (RF) and Deep Reinforcement Learning) into three inventory models\n(the Lost Sales, Dual-Sourcing and Multi-Echelon Inventory Model). These\nmethodologies are applied in the supermarket context. The main purpose is to\nanalyse efficient methods for the data-driven. Their possibility, potential and\ncurrent challenges are taken into consideration in this report. By comparing\nthe results in each model, the effectiveness of each algorithm is evaluated\nbased on several key performance indicators, including forecast accuracy,\nadaptability to market changes, and overall impact on inventory costs and\ncustomer satisfaction levels. The data visualization tools and statistical\nmetrics are the indicators for the comparisons and show some obvious trends and\npatterns that can guide decision-making in inventory management. These tools\nenable managers to not only track the performance of different algorithms in\nreal-time but also to drill down into specific data points to understand the\nunderlying causes of inventory fluctuations. This level of detail is crucial\nfor pinpointing inefficiencies and areas for improvement within the supply\nchain.", "published": "2025-05-13 15:35:23", "link": "http://arxiv.org/abs/2505.08673v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Social Robot with Inner Speech for Dietary Guidance", "abstract": "We explore the use of inner speech as a mechanism to enhance transparency and\ntrust in social robots for dietary advice. In humans, inner speech structures\nthought processes and decision-making; in robotics, it improves explainability\nby making reasoning explicit. This is crucial in healthcare scenarios, where\ntrust in robotic assistants depends on both accurate recommendations and\nhuman-like dialogue, which make interactions more natural and engaging.\nBuilding on this, we developed a social robot that provides dietary advice, and\nwe provided the architecture with inner speech capabilities to validate user\ninput, refine reasoning, and generate clear justifications. The system\nintegrates large language models for natural language understanding and a\nknowledge graph for structured dietary information. By making decisions more\ntransparent, our approach strengthens trust and improves human-robot\ninteraction in healthcare. We validated this by measuring the computational\nefficiency of our architecture and conducting a small user study, which\nassessed the reliability of inner speech in explaining the robot's behavior.", "published": "2025-05-13 15:26:52", "link": "http://arxiv.org/abs/2505.08664v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Comparative Study of Human Activity Recognition: Motion, Tactile, and multi-modal Approaches", "abstract": "Human activity recognition (HAR) is essential for effective Human-Robot\nCollaboration (HRC), enabling robots to interpret and respond to human actions.\nThis study evaluates the ability of a vision-based tactile sensor to classify\n15 activities, comparing its performance to an IMU-based data glove.\nAdditionally, we propose a multi-modal framework combining tactile and motion\ndata to leverage their complementary strengths. We examined three approaches:\nmotion-based classification (MBC) using IMU data, tactile-based classification\n(TBC) with single or dual video streams, and multi-modal classification (MMC)\nintegrating both. Offline validation on segmented datasets assessed each\nconfiguration's accuracy under controlled conditions, while online validation\non continuous action sequences tested online performance. Results showed the\nmulti-modal approach consistently outperformed single-modality methods,\nhighlighting the potential of integrating tactile and motion sensing to enhance\nHAR systems for collaborative robotics.", "published": "2025-05-13 15:20:21", "link": "http://arxiv.org/abs/2505.08657v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) is a cornerstone of modern question\nanswering (QA) systems, enabling grounded answers based on external knowledge.\nAlthough recent progress has been driven by open-domain datasets, enterprise QA\nsystems need datasets that mirror the concrete, domain-specific issues users\nraise in day-to-day support scenarios. Critically, evaluating end-to-end RAG\nsystems requires benchmarks comprising not only question--answer pairs but also\nthe specific knowledge base (KB) snapshot from which answers were derived. To\naddress this need, we introduce WixQA, a benchmark suite featuring QA datasets\nprecisely grounded in the released KB corpus, enabling holistic evaluation of\nretrieval and generation components. WixQA includes three distinct QA datasets\nderived from Wix.com customer support interactions and grounded in a snapshot\nof the public Wix Help Center KB: (i) WixQA-ExpertWritten, 200 real user\nqueries with expert-authored, multi-step answers; (ii) WixQA-Simulated, 200\nexpert-validated QA pairs distilled from user dialogues; and (iii)\nWixQA-Synthetic, 6,222 LLM-generated QA pairs, with one pair systematically\nderived from each article in the knowledge base. We release the KB snapshot\nalongside the datasets under MIT license and provide comprehensive baseline\nresults, forming a unique benchmark for evaluating enterprise RAG systems in\nrealistic enterprise environments.", "published": "2025-05-13 15:02:54", "link": "http://arxiv.org/abs/2505.08643v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Integrating Natural Language Processing and Exercise Monitoring for Early Diagnosis of Metabolic Syndrome: A Deep Learning Approach", "abstract": "Metabolic syndrome (MetS) is a medication condition characterized by\nabdominal obesity, insulin resistance, hypertension and hyperlipidemia. It\nincreases the risk of majority of chronic diseases, including type 2 diabetes\nmellitus, and affects about one quarter of the global population. Therefore,\nearly detection and timely intervention for MetS are crucial. Standard\ndiagnosis for MetS components requires blood tests conducted within medical\ninstitutions. However, it is frequently underestimated, leading to unmet need\nfor care for MetS population. This study aims to use the least physiological\ndata and free texts about exercises related activities, which are obtained\neasily in daily life, to diagnosis MetS. We collected the data from 40\nvolunteers in a nursing home and used data augmentation to reduce the\nimbalance. We propose a deep learning framework for classifying MetS that\nintegrates natural language processing (NLP) and exercise monitoring. The\nresults showed that the best model reported a high positive result (AUROC=0.806\nand REC=76.3%) through 3-fold cross-validation. Feature importance analysis\nrevealed that text and minimum heart rate on a daily basis contribute the most\nin the classification of MetS. This study demonstrates the potential\napplication of data that are easily measurable in daily life for the early\ndiagnosis of MetS, which could contribute to reducing the cost of screening and\nmanagement for MetS population.", "published": "2025-05-13 14:48:36", "link": "http://arxiv.org/abs/2505.08628v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Resource-Efficient Language Models: Quantization for Fast and Accessible Inference", "abstract": "Large language models have significantly advanced natural language\nprocessing, yet their heavy resource demands pose severe challenges regarding\nhardware accessibility and energy consumption. This paper presents a focused\nand high-level review of post-training quantization (PTQ) techniques designed\nto optimize the inference efficiency of LLMs by the end-user, including details\non various quantization schemes, granularities, and trade-offs. The aim is to\nprovide a balanced overview between the theory and applications of\npost-training quantization.", "published": "2025-05-13 14:39:33", "link": "http://arxiv.org/abs/2505.08620v1", "categories": ["cs.AI", "68T07", "I.2.0"], "primary_category": "cs.AI"}
{"title": "MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units", "abstract": "Recurrent neural networks (RNNs) have been a long-standing candidate for\nprocessing of temporal sequence data, especially in memory-constrained systems\nthat one may find in embedded edge computing environments. Recent advances in\ntraining paradigms have now inspired new generations of efficient RNNs. We\nintroduce a streamlined and hardware-compatible architecture based on minimal\ngated recurrent units (GRUs), and an accompanying efficient mixed-signal\nhardware implementation of the model. The proposed design leverages\nswitched-capacitor circuits not only for in-memory computation (IMC), but also\nfor the gated state updates. The mixed-signal cores rely solely on commodity\ncircuits consisting of metal capacitors, transmission gates, and a clocked\ncomparator, thus greatly facilitating scaling and transfer to other technology\nnodes.\n  We benchmark the performance of our architecture on time series data,\nintroducing all constraints required for a direct mapping to the hardware\nsystem. The direct compatibility is verified in mixed-signal simulations,\nreproducing data recorded from the software-only network model.", "published": "2025-05-13 14:13:41", "link": "http://arxiv.org/abs/2505.08599v1", "categories": ["cs.AR", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.AR"}
{"title": "MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment", "abstract": "This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI)\ndataset comprising 2525 images taken by a drone flying over dense urban\nenvironments. MESSI is unique in two main features. First, it contains images\nfrom various altitudes, allowing us to investigate the effect of depth on\nsemantic segmentation. Second, it includes images taken from several different\nurban regions (at different altitudes). This is important since the variety\ncovers the visual richness captured by a drone's 3D flight, performing\nhorizontal and vertical maneuvers. MESSI contains images annotated with\nlocation, orientation, and the camera's intrinsic parameters and can be used to\ntrain a deep neural network for semantic segmentation or other applications of\ninterest (e.g., localization, navigation, and tracking). This paper describes\nthe dataset and provides annotation details. It also explains how semantic\nsegmentation was performed using several neural network models and shows\nseveral relevant statistics. MESSI will be published in the public domain to\nserve as an evaluation benchmark for semantic segmentation using images\ncaptured by a drone or similar vehicle flying over a dense urban environment.", "published": "2025-05-13 14:01:07", "link": "http://arxiv.org/abs/2505.08589v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art", "abstract": "Recent proliferation of generative AI tools for visual content\ncreation-particularly in the context of visual artworks-has raised serious\nconcerns about copyright infringement and forgery. The large-scale datasets\nused to train these models often contain a mixture of copyrighted and\nnon-copyrighted artworks. Given the tendency of generative models to memorize\ntraining patterns, they are susceptible to varying degrees of copyright\nviolation. Building on the recently proposed DeepfakeArt Challenge benchmark,\nthis work introduces DFA-CON, a contrastive learning framework designed to\ndetect copyright-infringing or forged AI-generated art. DFA-CON learns a\ndiscriminative representation space, posing affinity among original artworks\nand their forged counterparts within a contrastive learning framework. The\nmodel is trained across multiple attack types, including inpainting, style\ntransfer, adversarial perturbation, and cutmix. Evaluation results demonstrate\nrobust detection performance across most attack types, outperforming recent\npretrained foundation models. Code and model checkpoints will be released\npublicly upon acceptance.", "published": "2025-05-13 13:23:52", "link": "http://arxiv.org/abs/2505.08552v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation", "abstract": "Achieving generalization in robotic manipulation remains a critical\nchallenge, particularly for unseen scenarios and novel tasks. Current\nVision-Language-Action (VLA) models, while building on top of general\nVision-Language Models (VLMs), still fall short of achieving robust zero-shot\nperformance due to the scarcity and heterogeneity prevalent in embodied\ndatasets. To address these limitations, we propose FSD (From Seeing to Doing),\na novel vision-language model that generates intermediate representations\nthrough spatial relationship reasoning, providing fine-grained guidance for\nrobotic manipulation. Our approach combines a hierarchical data pipeline for\ntraining with a self-consistency mechanism that aligns spatial coordinates with\nvisual signals. Through extensive experiments, we comprehensively validated\nFSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding\nperformance across 8 benchmarks for general spatial reasoning and embodied\nreference abilities, as well as on our proposed more challenging benchmark\nVABench. We also verified zero-shot capabilities in robot manipulation,\ndemonstrating significant performance improvements over baseline methods in\nboth SimplerEnv and real robot settings. Experimental results show that FSD\nachieves 54.1% success rate in SimplerEnv and 72% success rate across 8\nreal-world tasks, outperforming the strongest baseline by 30%.", "published": "2025-05-13 13:20:46", "link": "http://arxiv.org/abs/2505.08548v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Guiding LLM-based Smart Contract Generation with Finite State Machine", "abstract": "Smart contract is a kind of self-executing code based on blockchain\ntechnology with a wide range of application scenarios, but the traditional\ngeneration method relies on manual coding and expert auditing, which has a high\nthreshold and low efficiency. Although Large Language Models (LLMs) show great\npotential in programming tasks, they still face challenges in smart contract\ngeneration w.r.t. effectiveness and security. To solve these problems, we\npropose FSM-SCG, a smart contract generation framework based on finite state\nmachine (FSM) and LLMs, which significantly improves the quality of the\ngenerated code by abstracting user requirements to generate FSM, guiding LLMs\nto generate smart contracts, and iteratively optimizing the code with the\nfeedback of compilation and security checks. The experimental results show that\nFSM-SCG significantly improves the quality of smart contract generation.\nCompared to the best baseline, FSM-SCG improves the compilation success rate of\ngenerated smart contract code by at most 48%, and reduces the average\nvulnerability risk score by approximately 68%.", "published": "2025-05-13 13:13:26", "link": "http://arxiv.org/abs/2505.08542v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News", "abstract": "In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.", "published": "2025-05-13 13:03:20", "link": "http://arxiv.org/abs/2505.08532v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "ExEBench: Benchmarking Foundation Models on Extreme Earth Events", "abstract": "Our planet is facing increasingly frequent extreme events, which pose major\nrisks to human lives and ecosystems. Recent advances in machine learning (ML),\nespecially with foundation models (FMs) trained on extensive datasets, excel in\nextracting features and show promise in disaster management. Nevertheless,\nthese models often inherit biases from training data, challenging their\nperformance over extreme values. To explore the reliability of FM in the\ncontext of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme\n\\textbf{E}arth Benchmark), a collection of seven extreme event categories\nacross floods, wildfires, storms, tropical cyclones, extreme precipitation,\nheatwaves, and cold waves. The dataset features global coverage, varying data\nvolumes, and diverse data sources with different spatial, temporal, and\nspectral characteristics. To broaden the real-world impact of FMs, we include\nmultiple challenging ML tasks that are closely aligned with operational needs\nin extreme events detection, monitoring, and forecasting. ExEBench aims to (1)\nassess FM generalizability across diverse, high-impact tasks and domains, (2)\npromote the development of novel ML methods that benefit disaster management,\nand (3) offer a platform for analyzing the interactions and cascading effects\nof extreme events to advance our understanding of Earth system, especially\nunder the climate change expected in the decades to come. The dataset and code\nare public https://github.com/zhaoshan2/EarthExtreme-Bench.", "published": "2025-05-13 13:02:04", "link": "http://arxiv.org/abs/2505.08529v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning", "abstract": "In the context of continual learning, acquiring new knowledge while\nmaintaining previous knowledge presents a significant challenge. Existing\nmethods often use experience replay techniques that store a small portion of\nprevious task data for training. In experience replay approaches, data\naugmentation has emerged as a promising strategy to further improve the model\nperformance by mixing limited previous task data with sufficient current task\ndata. However, we theoretically and empirically analyze that training with\nmixed samples from random sample pairs may harm the knowledge of previous tasks\nand cause greater catastrophic forgetting. We then propose GradMix, a robust\ndata augmentation method specifically designed for mitigating catastrophic\nforgetting in class-incremental learning. GradMix performs gradient-based\nselective mixup using a class-based criterion that mixes only samples from\nhelpful class pairs and not from detrimental class pairs for reducing\ncatastrophic forgetting. Our experiments on various real datasets show that\nGradMix outperforms data augmentation baselines in accuracy by minimizing the\nforgetting of previous knowledge.", "published": "2025-05-13 13:01:38", "link": "http://arxiv.org/abs/2505.08528v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On the Complexity and Properties of Preferential Propositional Dependence Logic", "abstract": "This paper considers the complexity and properties of KLM-style preferential\nreasoning in the setting of propositional logic with team semantics and\ndependence atoms, also known as propositional dependence logic. Preferential\nteam-based reasoning is shown to be cumulative, yet violates System~P. We give\nintuitive conditions that fully characterise those cases where preferential\npropositional dependence logic satisfies System~P. We show that these\ncharacterisations do, surprisingly, not carry over to preferential team-based\npropositional logic. Furthermore, we show how classical entailment and\ndependence logic entailment can be expressed in terms of non-trivial\npreferential models. Finally, we present the complexity of preferential\nteam-based reasoning for two natural representations. This includes novel\ncomplexity results for classical (non-team-based) preferential reasoning.", "published": "2025-05-13 12:54:59", "link": "http://arxiv.org/abs/2505.08522v1", "categories": ["cs.AI", "cs.LO", "03B70, 03B62", "I.2.3; F.4.1"], "primary_category": "cs.AI"}
{"title": "Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain", "abstract": "Transformers have demonstrated remarkable performance across diverse domains.\nThe key component of Transformers is self-attention, which learns the\nrelationship between any two tokens in the input sequence. Recent studies have\nrevealed that the self-attention can be understood as a normalized adjacency\nmatrix of a graph. Notably, from the perspective of graph signal processing\n(GSP), the self-attention can be equivalently defined as a simple graph filter,\napplying GSP using the value vector as the signal. However, the self-attention\nis a graph filter defined with only the first order of the polynomial matrix,\nand acts as a low-pass filter preventing the effective leverage of various\nfrequency information. Consequently, existing self-attention mechanisms are\ndesigned in a rather simplified manner. Therefore, we propose a novel method,\ncalled \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph\n\\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning\nthe graph filter in the singular value domain from the perspective of graph\nsignal processing for directed graphs with the linear complexity w.r.t. the\ninput length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate\nthat AGF achieves state-of-the-art performance on various tasks, including Long\nRange Arena benchmark and time series classification.", "published": "2025-05-13 12:48:04", "link": "http://arxiv.org/abs/2505.08516v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching", "abstract": "Patient recruitment remains a major bottleneck in clinical trials, calling\nfor scalable and automated solutions. We present TrialMatchAI, an AI-powered\nrecommendation system that automates patient-to-trial matching by processing\nheterogeneous clinical data, including structured records and unstructured\nphysician notes. Built on fine-tuned, open-source large language models (LLMs)\nwithin a retrieval-augmented generation framework, TrialMatchAI ensures\ntransparency and reproducibility and maintains a lightweight deployment\nfootprint suitable for clinical environments. The system normalizes biomedical\nentities, retrieves relevant trials using a hybrid search strategy combining\nlexical and semantic similarity, re-ranks results, and performs criterion-level\neligibility assessments using medical Chain-of-Thought reasoning. This pipeline\ndelivers explainable outputs with traceable decision rationales. In real-world\nvalidation, 92 percent of oncology patients had at least one relevant trial\nretrieved within the top 20 recommendations. Evaluation across synthetic and\nreal clinical datasets confirmed state-of-the-art performance, with expert\nassessment validating over 90 percent accuracy in criterion-level eligibility\nclassification, particularly excelling in biomarker-driven matches. Designed\nfor modularity and privacy, TrialMatchAI supports Phenopackets-standardized\ndata, enables secure local deployment, and allows seamless replacement of LLM\ncomponents as more advanced models emerge. By enhancing efficiency and\ninterpretability and offering lightweight, open-source deployment, TrialMatchAI\nprovides a scalable solution for AI-driven clinical trial matching in precision\nmedicine.", "published": "2025-05-13 12:39:06", "link": "http://arxiv.org/abs/2505.08508v1", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM", "abstract": "PDDL-based symbolic task planning remains pivotal for robot autonomy yet\nstruggles with dynamic human-robot collaboration due to scalability,\nre-planning demands, and delayed plan availability. Although a few\nneurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to\naddress these challenges, reliance on closed-source, remote models with limited\ncontext introduced critical constraints: third-party dependency, inconsistent\nresponse times, restricted plan length and complexity, and multi-domain\nscalability issues. We present Gideon, a novel framework that enables the\ntransition to modern, smaller, local LLMs with extended context length. Gideon\nintegrates a novel problem generator to systematically generate large-scale\ndatasets of realistic domain-problem-plan tuples for any domain, and adapts\nneurosymbolic planning for local LLMs, enabling on-device execution and\nextended context for multi-domain support. Preliminary experiments in\nsingle-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k\nsamples, demonstrate a valid plan percentage of 66.1% (32k model) and show that\nthe figure can be further scaled through additional data. Multi-domain tests on\n16k samples yield an even higher 70.6% planning validity rate, proving\nextensibility across domains and signaling that data variety can have a\npositive effect on learning efficiency. Although long-horizon planning and\nreduced model size make Gideon training much less efficient than baseline\nmodels based on larger LLMs, the results are still significant considering that\nthe trained model is about 120x smaller than baseline and that significant\nadvantages can be achieved in inference efficiency, scalability, and\nmulti-domain adaptability, all critical factors in human-robot collaboration.\nTraining inefficiency can be mitigated by Gideon's streamlined data generation\npipeline.", "published": "2025-05-13 12:22:38", "link": "http://arxiv.org/abs/2505.08492v1", "categories": ["cs.AI", "cs.LG", "cs.RO", "I.2.6; I.2.8; I.2.9"], "primary_category": "cs.AI"}
{"title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling", "abstract": "Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.", "published": "2025-05-13 12:17:10", "link": "http://arxiv.org/abs/2505.08487v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "BAT: Benchmark for Auto-bidding Task", "abstract": "The optimization of bidding strategies for online advertising slot auctions\npresents a critical challenge across numerous digital marketplaces. A\nsignificant obstacle to the development, evaluation, and refinement of\nreal-time autobidding algorithms is the scarcity of comprehensive datasets and\nstandardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the\ntwo most prevalent auction formats. We implement a series of robust baselines\non a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem\ndomains: budget pacing uniformity and Cost Per Click (CPC) constraint\noptimization. This benchmark provides a user-friendly and intuitive framework\nfor researchers and practitioners to develop and refine innovative autobidding\nalgorithms, thereby facilitating advancements in the field of programmatic\nadvertising. The implementation and additional resources can be accessed at the\nfollowing repository (https://github.com/avito-tech/bat-autobidding-benchmark,\nhttps://doi.org/10.5281/zenodo.14794182).", "published": "2025-05-13 12:12:34", "link": "http://arxiv.org/abs/2505.08485v1", "categories": ["cs.AI", "stat.ML", "91B26"], "primary_category": "cs.AI"}
{"title": "Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing", "abstract": "We introduce a distributed quantum-classical framework that synergizes\nphotonic quantum neural networks (QNNs) with matrix-product-state (MPS) mapping\nto achieve parameter-efficient training of classical neural networks. By\nleveraging universal linear-optical decompositions of $M$-mode interferometers\nand photon-counting measurement statistics, our architecture generates neural\nparameters through a hybrid quantum-classical workflow: photonic QNNs with\n$M(M+1)/2$ trainable parameters produce high-dimensional probability\ndistributions that are mapped to classical network weights via an MPS model\nwith bond dimension $\\chi$. Empirical validation on MNIST classification\ndemonstrates that photonic QT achieves an accuracy of $95.50\\% \\pm 0.84\\%$\nusing 3,292 parameters ($\\chi = 10$), compared to $96.89\\% \\pm 0.31\\%$ for\nclassical baselines with 6,690 parameters. Moreover, a ten-fold compression\nratio is achieved at $\\chi = 4$, with a relative accuracy loss of less than\n$3\\%$. The framework outperforms classical compression techniques (weight\nsharing/pruning) by 6--12\\% absolute accuracy while eliminating quantum\nhardware requirements during inference through classical deployment of\ncompressed parameters. Simulations incorporating realistic photonic noise\ndemonstrate the framework's robustness to near-term hardware imperfections.\nAblation studies confirm quantum necessity: replacing photonic QNNs with random\ninputs collapses accuracy to chance level ($10.0\\% \\pm 0.5\\%$). Photonic\nquantum computing's room-temperature operation, inherent scalability through\nspatial-mode multiplexing, and HPC-integrated architecture establish a\npractical pathway for distributed quantum machine learning, combining the\nexpressivity of photonic Hilbert spaces with the deployability of classical\nneural networks.", "published": "2025-05-13 11:58:45", "link": "http://arxiv.org/abs/2505.08474v1", "categories": ["quant-ph", "cs.AI", "cs.DC"], "primary_category": "quant-ph"}
{"title": "Strategy-Augmented Planning for Large Language Models via Opponent Exploitation", "abstract": "Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.", "published": "2025-05-13 11:41:10", "link": "http://arxiv.org/abs/2505.08459v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem", "abstract": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to\n  efficiently schedule multiple operations on dissimilar machines. These\noperations are gathered into jobs, and operations pertaining to the same job\nneed to be scheduled sequentially. Different methods have been previously\ntested to solve this problem, such as Constraint Solving, Tabu Search, Genetic\nAlgorithms, or Monte Carlo Tree Search (MCTS). We propose a novel algorithm\nderived from the Generalized Nested Rollout Policy Adaptation, developed to\nsolve the FJSSP. We report encouraging experimental results, as our algorithm\nperforms better than other MCTS-based approaches, even if makespans obtained on\nlarge instances are still far from known upper bounds.", "published": "2025-05-13 11:27:18", "link": "http://arxiv.org/abs/2505.08451v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Agent-as-a-Service based on Agent Network", "abstract": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.", "published": "2025-05-13 11:15:19", "link": "http://arxiv.org/abs/2505.08446v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering", "abstract": "Event cameras have emerged as promising sensors for 3D reconstruction due to\ntheir ability to capture per-pixel brightness changes asynchronously. Unlike\nconventional frame-based cameras, they produce sparse and temporally rich data\nstreams, which enable more accurate 3D reconstruction and open up the\npossibility of performing reconstruction in extreme environments such as\nhigh-speed motion, low light, or high dynamic range scenes. In this survey, we\nprovide the first comprehensive review focused exclusively on 3D reconstruction\nusing event cameras. The survey categorises existing works into three major\ntypes based on input modality - stereo, monocular, and multimodal systems, and\nfurther classifies them by reconstruction approach, including geometry-based,\ndeep learning-based, and recent neural rendering techniques such as Neural\nRadiance Fields and 3D Gaussian Splatting. Methods with a similar research\nfocus were organised chronologically into the most subdivided groups. We also\nsummarise public datasets relevant to event-based 3D reconstruction. Finally,\nwe highlight current research limitations in data availability, evaluation,\nrepresentation, and dynamic scene handling, and outline promising future\nresearch directions. This survey aims to serve as a comprehensive reference and\na roadmap for future developments in event-driven 3D reconstruction.", "published": "2025-05-13 11:04:04", "link": "http://arxiv.org/abs/2505.08438v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Explaining Autonomous Vehicles with Intention-aware Policy Graphs", "abstract": "The potential to improve road safety, reduce human driving error, and promote\nenvironmental sustainability have enabled the field of autonomous driving to\nprogress rapidly over recent decades. The performance of autonomous vehicles\nhas significantly improved thanks to advancements in Artificial Intelligence,\nparticularly Deep Learning. Nevertheless, the opacity of their decision-making,\nrooted in the use of accurate yet complex AI models, has created barriers to\ntheir societal trust and regulatory acceptance, raising the need for\nexplainability. We propose a post-hoc, model-agnostic solution to provide\nteleological explanations for the behaviour of an autonomous vehicle in urban\nenvironments. Building on Intention-aware Policy Graphs, our approach enables\nthe extraction of interpretable and reliable explanations of vehicle behaviour\nin the nuScenes dataset from global and local perspectives. We demonstrate the\npotential of these explanations to assess whether the vehicle operates within\nacceptable legal boundaries and to identify possible vulnerabilities in\nautonomous driving datasets and models.", "published": "2025-05-13 09:58:32", "link": "http://arxiv.org/abs/2505.08404v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ConDiSim: Conditional Diffusion Models for Simulation Based Inference", "abstract": "We present a conditional diffusion model - ConDiSim, for simulation-based\ninference of complex systems with intractable likelihoods. ConDiSim leverages\ndenoising diffusion probabilistic models to approximate posterior\ndistributions, consisting of a forward process that adds Gaussian noise to\nparameters, and a reverse process learning to denoise, conditioned on observed\ndata. This approach effectively captures complex dependencies and\nmulti-modalities within posteriors. ConDiSim is evaluated across ten benchmark\nproblems and two real-world test problems, where it demonstrates effective\nposterior approximation accuracy while maintaining computational efficiency and\nstability in model training. ConDiSim offers a robust and extensible framework\nfor simulation-based inference, particularly suitable for parameter inference\nworkflows requiring fast inference methods.", "published": "2025-05-13 09:58:23", "link": "http://arxiv.org/abs/2505.08403v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adaptive Diffusion Policy Optimization for Robotic Manipulation", "abstract": "Recent studies have shown the great potential of diffusion models in\nimproving reinforcement learning (RL) by modeling complex policies, expressing\na high degree of multi-modality, and efficiently handling high-dimensional\ncontinuous control tasks. However, there is currently limited research on how\nto optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably.\nIn this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a\nfast algorithmic framework containing best practices for fine-tuning\ndiffusion-based polices in robotic control tasks using the adaptive gradient\ndescent method in RL. Adaptive gradient method is less studied in training RL,\nlet alone diffusion-based policies. We confirm that ADPO outperforms other\ndiffusion-based RL methods in terms of overall effectiveness for fine-tuning on\nstandard robotic tasks. Concretely, we conduct extensive experiments on\nstandard robotic control tasks to test ADPO, where, particularly, six popular\ndiffusion-based RL methods are provided as benchmark methods. Experimental\nresults show that ADPO acquires better or comparable performance than the\nbaseline methods. Finally, we systematically analyze the sensitivity of\nmultiple hyperparameters in standard robotics tasks, providing guidance for\nsubsequent practical applications. Our video demonstrations are released in\nhttps://github.com/Timeless-lab/ADPO.git.", "published": "2025-05-13 09:21:45", "link": "http://arxiv.org/abs/2505.08376v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Non-contact Vital Signs Detection in Dynamic Environments", "abstract": "Accurate phase demodulation is critical for vital sign detection using\nmillimeter-wave radar. However, in complex environments, time-varying DC\noffsets and phase imbalances can severely degrade demodulation performance. To\naddress this, we propose a novel DC offset calibration method alongside a\nHilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The\napproach estimates time-varying DC offsets from neighboring signal peaks and\nvalleys, then employs both differential forms and Hilbert transforms of the I/Q\nchannel signals to extract vital sign information. Simulation and experimental\nresults demonstrate that the proposed method maintains robust performance under\nlow signal-to-noise ratios. Compared to existing demodulation techniques, it\noffers more accurate signal recovery in challenging scenarios and effectively\nsuppresses noise interference.", "published": "2025-05-13 09:11:48", "link": "http://arxiv.org/abs/2505.08366v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation", "abstract": "Despite impressive progress in areas like mathematical reasoning, large\nlanguage models still face significant challenges in consistently solving\ncomplex problems. Drawing inspiration from key human learning strategies, we\npropose two novel strategies to enhance the capability of large language models\nto solve these complex problems. First, Adaptive Difficulty Curriculum Learning\n(ADCL) is a novel curriculum learning strategy that tackles the Difficulty\nShift phenomenon (i.e., a model's perception of problem difficulty dynamically\nchanges during training) by periodically re-estimating difficulty within\nupcoming data batches to maintain alignment with the model's evolving\ncapabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel\nreinforcement learning strategy that bridges the gap between imitation learning\nand pure exploration by guiding models to reformulate expert solutions within\ntheir own conceptual framework, rather than relying on direct imitation,\nfostering deeper understanding and knowledge assimilation. Extensive\nexperiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B\nas the base model, demonstrate that these human-inspired strategies\nsynergistically and significantly enhance performance. Notably, their combined\napplication improves performance over the standard Zero-RL baseline by 10% on\nthe AIME24 benchmark and 16.6% on AIME25.", "published": "2025-05-13 09:10:48", "link": "http://arxiv.org/abs/2505.08364v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning", "abstract": "Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.", "published": "2025-05-13 09:08:28", "link": "http://arxiv.org/abs/2505.08361v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives", "abstract": "This paper introduces StoryAnchors, a unified framework for generating\nhigh-quality, multi-scene story frames with strong temporal consistency. The\nframework employs a bidirectional story generator that integrates both past and\nfuture contexts to ensure temporal consistency, character continuity, and\nsmooth scene transitions throughout the narrative. Specific conditions are\nintroduced to distinguish story frame generation from standard video synthesis,\nfacilitating greater scene diversity and enhancing narrative richness. To\nfurther improve generation quality, StoryAnchors integrates Multi-Event Story\nFrame Labeling and Progressive Story Frame Training, enabling the model to\ncapture both overarching narrative flow and event-level dynamics. This approach\nsupports the creation of editable and expandable story frames, allowing for\nmanual modifications and the generation of longer, more complex sequences.\nExtensive experiments show that StoryAnchors outperforms existing open-source\nmodels in key areas such as consistency, narrative coherence, and scene\ndiversity. Its performance in narrative consistency and story richness is also\non par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of\nstory-driven frame generation, offering a scalable, flexible, and highly\neditable foundation for future research.", "published": "2025-05-13 08:48:10", "link": "http://arxiv.org/abs/2505.08350v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning", "abstract": "Cross-domain few-shot learning (CD-FSL) requires models to generalize from\nlimited labeled samples under significant distribution shifts. While recent\nmethods enhance adaptability through lightweight task-specific modules, they\noperate solely in the spatial domain and overlook frequency-specific variations\nthat are often critical for robust transfer. We observe that spatially similar\nimages across domains can differ substantially in their spectral\nrepresentations, with low and high frequencies capturing complementary semantic\ninformation at coarse and fine levels. This indicates that uniform spatial\nadaptation may overlook these spectral distinctions, thus constraining\ngeneralization. To address this, we introduce Frequency Adaptation and\nDiversion (FAD), a frequency-aware framework that explicitly models and\nmodulates spectral components. At its core is the Frequency Diversion Adapter,\nwhich transforms intermediate features into the frequency domain using the\ndiscrete Fourier transform (DFT), partitions them into low, mid, and\nhigh-frequency bands via radial masks, and reconstructs each band using inverse\nDFT (IDFT). Each frequency band is then adapted using a dedicated convolutional\nbranch with a kernel size tailored to its spectral scale, enabling targeted and\ndisentangled adaptation across frequencies. Extensive experiments on the\nMeta-Dataset benchmark demonstrate that FAD consistently outperforms\nstate-of-the-art methods on both seen and unseen domains, validating the\nutility of frequency-domain representations and band-wise adaptation for\nimproving generalization in CD-FSL.", "published": "2025-05-13 08:48:06", "link": "http://arxiv.org/abs/2505.08349v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SHAP-based Explanations are Sensitive to Feature Representation", "abstract": "Local feature-based explanations are a key component of the XAI toolkit.\nThese explanations compute feature importance values relative to an\n``interpretable'' feature representation. In tabular data, feature values\nthemselves are often considered interpretable. This paper examines the impact\nof data engineering choices on local feature-based explanations. We demonstrate\nthat simple, common data engineering techniques, such as representing age with\na histogram or encoding race in a specific way, can manipulate feature\nimportance as determined by popular methods like SHAP. Notably, the sensitivity\nof explanations to feature representation can be exploited by adversaries to\nobscure issues like discrimination. While the intuition behind these results is\nstraightforward, their systematic exploration has been lacking. Previous work\nhas focused on adversarial attacks on feature-based explainers by biasing data\nor manipulating models. To the best of our knowledge, this is the first study\ndemonstrating that explainers can be misled by standard, seemingly innocuous\ndata engineering techniques.", "published": "2025-05-13 08:43:09", "link": "http://arxiv.org/abs/2505.08345v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An Identifiable Cost-Aware Causal Decision-Making Framework Using Counterfactual Reasoning", "abstract": "Decision making under abnormal conditions is a critical process that involves\nevaluating the current state and determining the optimal action to restore the\nsystem to a normal state at an acceptable cost. However, in such scenarios,\nexisting decision-making frameworks highly rely on reinforcement learning or\nroot cause analysis, resulting in them frequently neglecting the cost of the\nactions or failing to incorporate causal mechanisms adequately. By relaxing the\nexisting causal decision framework to solve the necessary cause, we propose a\nminimum-cost causal decision (MiCCD) framework via counterfactual reasoning to\naddress the above challenges. Emphasis is placed on making counterfactual\nreasoning processes identifiable in the presence of a large amount of mixed\nanomaly data, as well as finding the optimal intervention state in a continuous\ndecision space. Specifically, it formulates a surrogate model based on causal\ngraphs, using abnormal pattern clustering labels as supervisory signals. This\nenables the approximation of the structural causal model among the variables\nand lays a foundation for identifiable counterfactual reasoning. With the\ncausal structure approximated, we then established an optimization model based\non counterfactual estimation. The Sequential Least Squares Programming (SLSQP)\nalgorithm is further employed to optimize intervention strategies while taking\ncosts into account. Experimental evaluations on both synthetic and real-world\ndatasets reveal that MiCCD outperforms conventional methods across multiple\nmetrics, including F1-score, cost efficiency, and ranking quality(nDCG@k\nvalues), thus validating its efficacy and broad applicability.", "published": "2025-05-13 08:41:45", "link": "http://arxiv.org/abs/2505.08343v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Benchmarking AI scientists in omics data-driven biological research", "abstract": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.", "published": "2025-05-13 08:33:54", "link": "http://arxiv.org/abs/2505.08341v1", "categories": ["cs.AI", "cs.MA", "q-bio.GN"], "primary_category": "cs.AI"}
{"title": "A computer vision-based model for occupancy detection using low-resolution thermal images", "abstract": "Occupancy plays an essential role in influencing the energy consumption and\noperation of heating, ventilation, and air conditioning (HVAC) systems.\nTraditional HVAC typically operate on fixed schedules without considering\noccupancy. Advanced occupant-centric control (OCC) adopted occupancy status in\nregulating HVAC operations. RGB images combined with computer vision (CV)\ntechniques are widely used for occupancy detection, however, the detailed\nfacial and body features they capture raise significant privacy concerns.\nLow-resolution thermal images offer a non-invasive solution that mitigates\nprivacy issues. The study developed an occupancy detection model utilizing\nlow-resolution thermal images and CV techniques, where transfer learning was\napplied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The\ndeveloped model ultimately achieved satisfactory performance, with precision,\nrecall, mAP50, and mAP50 values approaching 1.000. The contributions of this\nmodel lie not only in mitigating privacy concerns but also in reducing\ncomputing resource demands.", "published": "2025-05-13 08:27:50", "link": "http://arxiv.org/abs/2505.08336v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Low-Complexity Inference in Continual Learning via Compressed Knowledge Transfer", "abstract": "Continual learning (CL) aims to train models that can learn a sequence of\ntasks without forgetting previously acquired knowledge. A core challenge in CL\nis balancing stability -- preserving performance on old tasks -- and plasticity\n-- adapting to new ones. Recently, large pre-trained models have been widely\nadopted in CL for their ability to support both, offering strong generalization\nfor new tasks and resilience against forgetting. However, their high\ncomputational cost at inference time limits their practicality in real-world\napplications, especially those requiring low latency or energy efficiency. To\naddress this issue, we explore model compression techniques, including pruning\nand knowledge distillation (KD), and propose two efficient frameworks tailored\nfor class-incremental learning (CIL), a challenging CL setting where task\nidentities are unavailable during inference. The pruning-based framework\nincludes pre- and post-pruning strategies that apply compression at different\ntraining stages. The KD-based framework adopts a teacher-student architecture,\nwhere a large pre-trained teacher transfers downstream-relevant knowledge to a\ncompact student. Extensive experiments on multiple CIL benchmarks demonstrate\nthat the proposed frameworks achieve a better trade-off between accuracy and\ninference complexity, consistently outperforming strong baselines. We further\nanalyze the trade-offs between the two frameworks in terms of accuracy and\nefficiency, offering insights into their use across different scenarios.", "published": "2025-05-13 08:07:40", "link": "http://arxiv.org/abs/2505.08327v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing", "abstract": "Remote sensing (RS) images are usually produced at an unprecedented scale,\nyet they are geographically and institutionally distributed, making centralized\nmodel training challenging due to data-sharing restrictions and privacy\nconcerns. Federated learning (FL) offers a solution by enabling collaborative\nmodel training across decentralized RS data sources without exposing raw data.\nHowever, there lacks a realistic federated dataset and benchmark in RS. Prior\nworks typically rely on manually partitioned single dataset, which fail to\ncapture the heterogeneity and scale of real-world RS data, and often use\ninconsistent experimental setups, hindering fair comparison. To address this\ngap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists\nof eight datasets that cover various sensors and resolutions and builds 135\nclients, which is representative of realistic operational scenarios. Data for\neach client come from the same source, exhibiting authentic federated\nproperties such as skewed label distributions, imbalanced client data volumes,\nand domain heterogeneity across clients. These characteristics reflect\npractical challenges in federated RS and support evaluation of FL methods at\nscale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation\nmetrics to construct the comprehensive FedRS-Bench. The experimental results\ndemonstrate that FL can consistently improve model performance over training on\nisolated data silos, while revealing performance trade-offs of different\nmethods under varying client heterogeneity and availability conditions. We hope\nFedRS-Bench will accelerate research on large-scale, realistic FL in RS by\nproviding a standardized, rich testbed and facilitating fair comparisons across\nfuture works. The source codes and dataset are available at\nhttps://fedrs-bench.github.io/.", "published": "2025-05-13 08:04:03", "link": "http://arxiv.org/abs/2505.08325v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems", "abstract": "A major bottleneck in multi-agent AI is the lack of simulateable models for\nthe bottom-up emergence of social structure under realistic behavioral\nconstraints. Similarly, many foundational theories in economics and sociology\nincluding the concepts of \"institutions\" and \"norms\" tend to describe social\nstructures post hoc, often relying on implicit assumptions of shared culture,\nmorality, or symbolic agreement. These concepts are often treated as primitives\nrather than reconstructed from agent-level behavior, leaving both their origins\nand operational definitions under-specified. To address this, we propose a\nthree-stage bottom-up framework: Reciprocal Dynamics, capturing\nindividual-level reciprocal exchanges; Norm Stabilization, the consolidation of\nshared expectations; and Institutional Construction, the externalization of\nstable patterns into scalable structures. By grounding social emergence in\nagent-level reciprocity, our framework enables the systematic exploration of\nhow moral, cultural, and institutional structures emerge from cognitively\nminimal interactions.", "published": "2025-05-13 07:50:01", "link": "http://arxiv.org/abs/2505.08319v1", "categories": ["cs.CY", "cs.AI", "cs.MA"], "primary_category": "cs.CY"}
{"title": "A Practical Introduction to Deep Reinforcement Learning", "abstract": "Deep reinforcement learning (DRL) has emerged as a powerful framework for\nsolving sequential decision-making problems, achieving remarkable success in a\nwide range of applications, including game AI, autonomous driving, biomedicine,\nand large language models. However, the diversity of algorithms and the\ncomplexity of theoretical foundations often pose significant challenges for\nbeginners seeking to enter the field. This tutorial aims to provide a concise,\nintuitive, and practical introduction to DRL, with a particular focus on the\nProximal Policy Optimization (PPO) algorithm, which is one of the most widely\nused and effective DRL methods. To facilitate learning, we organize all\nalgorithms under the Generalized Policy Iteration (GPI) framework, offering\nreaders a unified and systematic perspective. Instead of lengthy theoretical\nproofs, we emphasize intuitive explanations, illustrative examples, and\npractical engineering techniques. This work serves as an efficient and\naccessible guide, helping readers rapidly progress from basic concepts to the\nimplementation of advanced DRL algorithms.", "published": "2025-05-13 07:19:16", "link": "http://arxiv.org/abs/2505.08295v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis", "abstract": "Generating full-body human gestures encompassing face, body, hands, and\nglobal movements from audio is a valuable yet challenging task in virtual\navatar creation. Previous systems focused on tokenizing the human gestures\nframewisely and predicting the tokens of each frame from the input audio.\nHowever, one observation is that the number of frames required for a complete\nexpressive human gesture, defined as granularity, varies among different human\ngesture patterns. Existing systems fail to model these gesture patterns due to\nthe fixed granularity of their gesture tokens. To solve this problem, we\npropose a novel framework named Multi-Granular Gesture Generator (M3G) for\naudio-driven holistic gesture generation. In M3G, we propose a novel\nMulti-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct\nmotion sequences from different temporal granularities. Subsequently, we\nproposed a multi-granular token predictor that extracts multi-granular\ninformation from audio and predicts the corresponding motion tokens. Then M3G\nreconstructs the human gestures from the predicted tokens using the MGVQ-VAE.\nBoth objective and subjective experiments demonstrate that our proposed M3G\nframework outperforms the state-of-the-art methods in terms of generating\nnatural and expressive full-body human gestures.", "published": "2025-05-13 07:16:58", "link": "http://arxiv.org/abs/2505.08293v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.SD", "eess.AS", "I.3.6"], "primary_category": "cs.GR"}
{"title": "Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction", "abstract": "Message-passing graph neural networks (MPNNs) and structural features (SFs)\nare cornerstones for the link prediction task. However, as a common and\nintuitive mode of understanding, the potential of visual perception has been\noverlooked in the MPNN community. For the first time, we equip MPNNs with\nvision structural awareness by proposing an effective framework called Graph\nVision Network (GVN), along with a more efficient variant (E-GVN). Extensive\nempirical results demonstrate that with the proposed frameworks, GVN\nconsistently benefits from the vision enhancement across seven link prediction\ndatasets, including challenging large-scale graphs. Such improvements are\ncompatible with existing state-of-the-art (SOTA) methods and GVNs achieve new\nSOTA results, thereby underscoring a promising novel direction for link\nprediction.", "published": "2025-05-13 06:32:23", "link": "http://arxiv.org/abs/2505.08266v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification", "abstract": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.", "published": "2025-05-13 06:29:25", "link": "http://arxiv.org/abs/2505.08265v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning", "abstract": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9\\% in low traffic density, +21\\% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.", "published": "2025-05-13 06:26:57", "link": "http://arxiv.org/abs/2505.08264v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Evaluating LLM Metrics Through Real-World Capabilities", "abstract": "As generative AI becomes increasingly embedded in everyday workflows, it is\nimportant to evaluate its performance in ways that reflect real-world usage\nrather than abstract notions of intelligence. Unlike many existing benchmarks\nthat assess general intelligence, our approach focuses on real-world utility,\nevaluating how well models support users in everyday tasks. While current\nbenchmarks emphasize code generation or factual recall, users rely on AI for a\nmuch broader range of activities-from writing assistance and summarization to\ncitation formatting and stylistic feedback. In this paper, we analyze\nlarge-scale survey data and usage logs to identify six core capabilities that\nrepresent how people commonly use Large Language Models (LLMs): Summarization,\nTechnical Assistance, Reviewing Work, Data Structuring, Generation, and\nInformation Retrieval. We then assess the extent to which existing benchmarks\ncover these capabilities, revealing significant gaps in coverage, efficiency\nmeasurement, and interpretability. Drawing on this analysis, we use\nhuman-centered criteria to identify gaps in how well current benchmarks reflect\ncommon usage that is grounded in five practical criteria: coherence, accuracy,\nclarity, relevance, and efficiency. For four of the six capabilities, we\nidentify the benchmarks that best align with real-world tasks and use them to\ncompare leading models. We find that Google Gemini outperforms other\nmodels-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude,\nDeepSeek, and Qwen from Alibaba-on these utility-focused metrics.", "published": "2025-05-13 06:02:37", "link": "http://arxiv.org/abs/2505.08253v1", "categories": ["cs.AI", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Removing Watermarks with Partial Regeneration using Semantic Information", "abstract": "As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged\nas a primary line of defense for copyright and provenance. The newest\nwatermarking schemes embed semantic signals - content-aware patterns that are\ndesigned to survive common image manipulations - yet their true robustness\nagainst adaptive adversaries remains under-explored. We expose a previously\nunreported vulnerability and introduce SemanticRegen, a three-stage, label-free\nattack that erases state-of-the-art semantic and invisible watermarks while\nleaving an image's apparent meaning intact. Our pipeline (i) uses a\nvision-language model to obtain fine-grained captions, (ii) extracts foreground\nmasks with zero-shot segmentation, and (iii) inpaints only the background via\nan LLM-guided diffusion model, thereby preserving salient objects and style\ncues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,\nStegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat\nthe semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy\nbelow 0.75 for the remaining schemes, all while maintaining high perceptual\nquality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)\nto quantify fidelity within foreground regions, showing that our attack\nachieves up to 12 percent higher mSSIM than prior diffusion-based attackers.\nThese results highlight an urgent gap between current watermark defenses and\nthe capabilities of adaptive, semantics-aware adversaries, underscoring the\nneed for watermarking algorithms that are resilient to content-preserving\nregenerative attacks.", "published": "2025-05-13 05:25:06", "link": "http://arxiv.org/abs/2505.08234v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix", "abstract": "Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.", "published": "2025-05-13 05:12:07", "link": "http://arxiv.org/abs/2505.08228v1", "categories": ["cs.CV", "cs.AI", "I.2.6; I.2.10; I.4.8; I.5.1"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation", "abstract": "Multirotors play a significant role in diverse field robotics applications\nbut remain highly susceptible to actuator failures, leading to rapid\ninstability and compromised mission reliability. While various fault-tolerant\ncontrol (FTC) strategies using reinforcement learning (RL) have been widely\nexplored, most previous approaches require prior knowledge of the multirotor\nmodel or struggle to adapt to new configurations. To address these limitations,\nwe propose a novel hybrid RL-based FTC framework integrated with a\ntransformer-based online adaptation module. Our framework leverages a\ntransformer architecture to infer latent representations in real time, enabling\nadaptation to previously unseen system models without retraining. We evaluate\nour method in a PyBullet simulation under loss-of-effectiveness actuator\nfaults, achieving a 95% success rate and a positional root mean square error\n(RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success\nand an RMSE of 0.153 m. Further evaluations on quadrotors with varying\nconfigurations confirm the robustness of our framework across untrained\ndynamics. These results demonstrate the potential of our framework to enhance\nthe adaptability and reliability of multirotors, enabling efficient fault\nmanagement in dynamic and uncertain environments. Website is available at\nhttp://00dhkim.me/paper/rl-ftc", "published": "2025-05-13 04:50:29", "link": "http://arxiv.org/abs/2505.08223v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles", "abstract": "Autonomous vehicles (AV) offer a cost-effective solution for scientific\nmissions such as underwater tracking. Recently, reinforcement learning (RL) has\nemerged as a powerful method for controlling AVs in complex marine\nenvironments. However, scaling these techniques to a fleet--essential for\nmulti-target tracking or targets with rapid, unpredictable motion--presents\nsignificant computational challenges. Multi-Agent Reinforcement Learning (MARL)\nis notoriously sample-inefficient, and while high-fidelity simulators like\nGazebo's LRAUV provide 100x faster-than-real-time single-robot simulations,\nthey offer no significant speedup for multi-vehicle scenarios, making MARL\ntraining impractical. To address these limitations, we propose an iterative\ndistillation method that transfers high-fidelity simulations into a simplified,\nGPU-accelerated environment while preserving high-level dynamics. This approach\nachieves up to a 30,000x speedup over Gazebo through parallelization, enabling\nefficient training via end-to-end GPU acceleration. Additionally, we introduce\na novel Transformer-based architecture (TransfMAPPO) that learns multi-agent\npolicies invariant to the number of agents and targets, significantly improving\nsample efficiency. Following large-scale curriculum learning conducted entirely\non GPU, we perform extensive evaluations in Gazebo, demonstrating that our\nmethod maintains tracking errors below 5 meters over extended durations, even\nin the presence of multiple fast-moving targets. This work bridges the gap\nbetween large-scale MARL training and high-fidelity deployment, providing a\nscalable framework for autonomous fleet control in real-world sea missions.", "published": "2025-05-13 04:42:30", "link": "http://arxiv.org/abs/2505.08222v1", "categories": ["cs.RO", "cs.AI", "cs.DC", "cs.PF"], "primary_category": "cs.RO"}
{"title": "Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People", "abstract": "Speech foundation models (SFMs) have demonstrated strong performance across a\nvariety of downstream tasks, including speech intelligibility prediction for\nhearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been\ninsufficiently explored. In this paper, we conduct a comprehensive study to\nidentify key design factors affecting SIP-HI performance with 5 SFMs, focusing\non encoder layer selection, prediction head architecture, and ensemble\nconfigurations. Our findings show that, contrary to traditional use-all-layers\nmethods, selecting a single encoder layer yields better results. Additionally,\ntemporal modeling is crucial for effective prediction heads. We also\ndemonstrate that ensembling multiple SFMs improves performance, with stronger\nindividual models providing greater benefit. Finally, we explore the\nrelationship between key SFM attributes and their impact on SIP-HI performance.\nOur study offers practical insights into effectively adapting SFMs for speech\nintelligibility prediction for hearing-impaired populations.", "published": "2025-05-13 04:07:59", "link": "http://arxiv.org/abs/2505.08215v1", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations", "abstract": "We have developed Aitomia - a platform powered by AI to assist in performing\nAI-driven atomistic and quantum chemical (QC) simulations. This intelligent\nassistant platform is equipped with chatbots and AI agents to help experts and\nguide non-experts in setting up and running the atomistic simulations,\nmonitoring their computation status, analyzing the simulation results, and\nsummarizing them for the user in text and graphical forms. We achieve these\ngoals by exploiting fine-tuned open-source large language models (LLMs),\nrule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia\nleverages the versatility of our MLatom ecosystem for AI-enhanced computational\nchemistry. This intelligent assistant is going to be integrated into the\nAitomistic Hub and XACS online computing services, with some functionality\nalready publicly available as described at http://mlatom.com/aitomia. Aitomia\nis expected to lower the barrier to performing atomistic simulations,\naccelerating research and development in the relevant fields.", "published": "2025-05-13 03:11:41", "link": "http://arxiv.org/abs/2505.08195v1", "categories": ["physics.comp-ph", "cs.AI", "cs.LG", "cs.MA", "physics.chem-ph"], "primary_category": "physics.comp-ph"}
{"title": "DSADF: Thinking Fast and Slow for Decision Making", "abstract": "Although Reinforcement Learning (RL) agents are effective in well-defined\nenvironments, they often struggle to generalize their learned policies to\ndynamic settings due to their reliance on trial-and-error interactions. Recent\nwork has explored applying Large Language Models (LLMs) or Vision Language\nModels (VLMs) to boost the generalization of RL agents through policy\noptimization guidance or prior knowledge. However, these approaches often lack\nseamless coordination between the RL agent and the foundation model, leading to\nunreasonable decision-making in unfamiliar environments and efficiency\nbottlenecks. Making full use of the inferential capabilities of foundation\nmodels and the rapid response capabilities of RL agents and enhancing the\ninteraction between the two to form a dual system is still a lingering\nscientific question. To address this problem, we draw inspiration from\nKahneman's theory of fast thinking (System 1) and slow thinking (System 2),\ndemonstrating that balancing intuition and deep reasoning can achieve nimble\ndecision-making in a complex world. In this study, we propose a Dual-System\nAdaptive Decision Framework (DSADF), integrating two complementary modules:\nSystem 1, comprising an RL agent and a memory space for fast and intuitive\ndecision making, and System 2, driven by a VLM for deep and analytical\nreasoning. DSADF facilitates efficient and adaptive decision-making by\ncombining the strengths of both systems. The empirical study in the video game\nenvironment: Crafter and Housekeep demonstrates the effectiveness of our\nproposed method, showing significant improvements in decision abilities for\nboth unseen and known tasks.", "published": "2025-05-13 02:58:04", "link": "http://arxiv.org/abs/2505.08189v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL", "abstract": "Offline safe reinforcement learning(OSRL) derives constraint-satisfying\npolicies from pre-collected datasets, offers a promising avenue for deploying\nRL in safety-critical real-world domains such as robotics. However, the\nmajority of existing approaches emphasize only short-term safety, neglecting\nlong-horizon considerations. Consequently, they may violate safety constraints\nand fail to ensure sustained protection during online deployment. Moreover, the\nlearned policies often struggle to handle states and actions that are not\npresent or out-of-distribution(OOD) from the offline dataset, and exhibit\nlimited sample efficiency. To address these challenges, we propose a novel\nframework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based\nPessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis\nto generate reliable safety labels, which serve as supervisory signals for\ntraining both a conditional variational autoencoder (CVAE) and a safety\nclassifier. This approach not only ensures high sampling efficiency but also\nprovides rigorous long-horizon safety guarantees. Furthermore, we utilize\npessimistic estimation methods to estimate the Q-value of reward and cost,\nwhich mitigates the extrapolation errors induces by OOD actions, and penalize\nunsafe actions to enabled the agent to proactively avoid high-risk behaviors.\nMoreover, we theoretically prove the validity of this pessimistic estimation.\nExtensive experiments on DSRL benchmarks demonstrate that FASP algorithm\nachieves competitive performance across multiple experimental tasks,\nparticularly outperforming state-of-the-art algorithms in terms of safety.", "published": "2025-05-13 02:32:49", "link": "http://arxiv.org/abs/2505.08179v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Behind the Noise: Conformal Quantile Regression Reveals Emergent Representations", "abstract": "Scientific imaging often involves long acquisition times to obtain\nhigh-quality data, especially when probing complex, heterogeneous systems.\nHowever, reducing acquisition time to increase throughput inevitably introduces\nsignificant noise into the measurements. We present a machine learning approach\nthat not only denoises low-quality measurements with calibrated uncertainty\nbounds, but also reveals emergent structure in the latent space. By using\nensembles of lightweight, randomly structured neural networks trained via\nconformal quantile regression, our method performs reliable denoising while\nuncovering interpretable spatial and chemical features -- without requiring\nlabels or segmentation. Unlike conventional approaches focused solely on image\nrestoration, our framework leverages the denoising process itself to drive the\nemergence of meaningful representations. We validate the approach on real-world\ngeobiochemical imaging data, showing how it supports confident interpretation\nand guides experimental design under resource constraints.", "published": "2025-05-13 02:27:12", "link": "http://arxiv.org/abs/2505.08176v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fast Text-to-Audio Generation with Adversarial Post-Training", "abstract": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge.", "published": "2025-05-13 02:25:47", "link": "http://arxiv.org/abs/2505.08175v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Decoding Neighborhood Environments with Large Language Models", "abstract": "Neighborhood environments include physical and environmental conditions such\nas housing quality, roads, and sidewalks, which significantly influence human\nhealth and well-being. Traditional methods for assessing these environments,\nincluding field surveys and geographic information systems (GIS), are\nresource-intensive and challenging to evaluate neighborhood environments at\nscale. Although machine learning offers potential for automated analysis, the\nlaborious process of labeling training data and the lack of accessible models\nhinder scalability. This study explores the feasibility of large language\nmodels (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood\nenvironments (e.g., sidewalk and powerline) at scale. We train a robust\nYOLOv11-based model, which achieves an average accuracy of 99.13% in detecting\nsix environmental indicators, including streetlight, sidewalk, powerline,\napartment, single-lane road, and multilane road. We then evaluate four LLMs,\nincluding ChatGPT, Gemini, Claude, and Grok, to assess their feasibility,\nrobustness, and limitations in identifying these indicators, with a focus on\nthe impact of prompting strategies and fine-tuning. We apply majority voting\nwith the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs\ncould be a useful tool to decode the neighborhood environment without any\ntraining effort.", "published": "2025-05-13 01:54:54", "link": "http://arxiv.org/abs/2505.08163v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Feature Fitted Online Conformal Prediction for Deep Time Series Forecasting Model", "abstract": "Time series forecasting is critical for many applications, where deep\nlearning-based point prediction models have demonstrated strong performance.\nHowever, in practical scenarios, there is also a need to quantify predictive\nuncertainty through online confidence intervals. Existing confidence interval\nmodeling approaches building upon these deep point prediction models suffer\nfrom key limitations: they either require costly retraining, fail to fully\nleverage the representational strengths of deep models, or lack theoretical\nguarantees. To address these gaps, we propose a lightweight conformal\nprediction method that provides valid coverage and shorter interval lengths\nwithout retraining. Our approach leverages features extracted from pre-trained\npoint prediction models to fit a residual predictor and construct confidence\nintervals, further enhanced by an adaptive coverage control mechanism.\nTheoretically, we prove that our method achieves asymptotic coverage\nconvergence, with error bounds dependent on the feature quality of the\nunderlying point prediction model. Experiments on 12 datasets demonstrate that\nour method delivers tighter confidence intervals while maintaining desired\ncoverage rates. Code, model and dataset in\n\\href{https://github.com/xiannanhuang/FFDCI}{Github}", "published": "2025-05-13 01:33:53", "link": "http://arxiv.org/abs/2505.08158v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation", "abstract": "Benefiting from the effectiveness of graph neural networks (GNNs) and\ncontrastive learning, GNN-based contrastive learning has become mainstream for\nknowledge-aware recommendation. However, most existing contrastive\nlearning-based methods have difficulties in effectively capturing the\nunderlying hierarchical structure within user-item bipartite graphs and\nknowledge graphs. Moreover, they commonly generate positive samples for\ncontrastive learning by perturbing the graph structure, which may lead to a\nshift in user preference learning. To overcome these limitations, we propose\nhyperbolic contrastive learning with model-augmentation for knowledge-aware\nrecommendation. To capture the intrinsic hierarchical graph structures, we\nfirst design a novel Lorentzian knowledge aggregation mechanism, which enables\nmore effective representations of users and items. Then, we propose three\nmodel-level augmentation techniques to assist Hyperbolic contrastive learning.\nDifferent from the classical structure-level augmentation (e.g., edge\ndropping), the proposed model-augmentations can avoid preference shifts between\nthe augmented positive pair. Finally, we conduct extensive experiments to\ndemonstrate the superiority (maximum improvement of $11.03\\%$) of proposed\nmethods over existing baselines.", "published": "2025-05-13 01:30:27", "link": "http://arxiv.org/abs/2505.08157v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering", "abstract": "Complex Query Answering (CQA) aims to retrieve answer sets for complex\nlogical formulas from incomplete knowledge graphs, which is a crucial yet\nchallenging task in knowledge graph reasoning. While neuro-symbolic search\nutilized neural link predictions achieve superior accuracy, they encounter\nsignificant complexity bottlenecks: (i) Data complexity typically scales\nquadratically with the number of entities in the knowledge graph, and (ii)\nQuery complexity becomes NP-hard for cyclic queries. Consequently, these\napproaches struggle to effectively scale to larger knowledge graphs and more\ncomplex queries. To address these challenges, we propose an efficient and\nscalable symbolic search framework. First, we propose two constraint strategies\nto compute neural logical indices to reduce the domain of variables, thereby\ndecreasing the data complexity of symbolic search. Additionally, we introduce\nan approximate algorithm based on local search to tackle the NP query\ncomplexity of cyclic queries. Experiments on various CQA benchmarks demonstrate\nthat our framework reduces the computational load of symbolic methods by 90\\%\nwhile maintaining nearly the same performance, thus alleviating both efficiency\nand scalability issues.", "published": "2025-05-13 01:24:09", "link": "http://arxiv.org/abs/2505.08155v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast", "abstract": "Accurate estimation of lithium-ion battery capacity degradation is critical\nfor enhancing the reliability and safety of battery operations. Traditional\nexpert models, tailored to specific scenarios, provide isolated estimations.\nWith the rapid advancement of data-driven techniques, a series of\ngeneral-purpose time-series foundation models have been developed. However,\nfoundation models specifically designed for battery capacity degradation remain\nlargely unexplored. To enable zero-shot generalization in battery degradation\nprediction using large model technology, this study proposes a\ndegradation-aware fine-tuning strategy for time-series foundation models. We\napply this strategy to fine-tune the Timer model on approximately 10 GB of\nopen-source battery charge discharge data. Validation on our released\nCycleLife-SJTUIE dataset demonstrates that the fine-tuned Battery-Timer\npossesses strong zero-shot generalization capability in capacity degradation\nforecasting. To address the computational challenges of deploying large models,\nwe further propose a knowledge distillation framework that transfers the\nknowledge of pre-trained foundation models into compact expert models.\nDistillation results across several state-of-the-art time-series expert models\nconfirm that foundation model knowledge significantly improves the\nmulti-condition generalization of expert models.", "published": "2025-05-13 01:03:35", "link": "http://arxiv.org/abs/2505.08151v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information", "abstract": "With the wide adoption of large language models (LLMs) in information\nassistance, it is essential to examine their alignment with human communication\nstyles and values. We situate this study within the context of fact-checking\nhealth information, given the critical challenge of rectifying conceptions and\nbuilding trust. Recent studies have explored the potential of LLM for health\ncommunication, but style differences between LLMs and human experts and\nassociated reader perceptions remain under-explored. In this light, our study\nevaluates the communication styles of LLMs, focusing on how their explanations\ndiffer from those of humans in three core components of health communication:\ninformation, sender, and receiver. We compiled a dataset of 1498 health\nmisinformation explanations from authoritative fact-checking organizations and\ngenerated LLM responses to inaccurate health information. Drawing from health\ncommunication theory, we evaluate communication styles across three key\ndimensions of information linguistic features, sender persuasive strategies,\nand receiver value alignments. We further assessed human perceptions through a\nblinded evaluation with 99 participants. Our findings reveal that LLM-generated\narticles showed significantly lower scores in persuasive strategies, certainty\nexpressions, and alignment with social values and moral foundations. However,\nhuman evaluation demonstrated a strong preference for LLM content, with over\n60% responses favoring LLM articles for clarity, completeness, and\npersuasiveness. Our results suggest that LLMs' structured approach to\npresenting information may be more effective at engaging readers despite\nscoring lower on traditional measures of quality in fact-checking and health\ncommunication.", "published": "2025-05-13 00:32:38", "link": "http://arxiv.org/abs/2505.08143v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally", "abstract": "Despite their many successes, transformer-based large language models (LLMs)\ncontinue to struggle with tasks that require complex reasoning over large parts\nof their input. We argue that these failures arise due to capacity limits on\nthe accurate flow of information within LLMs. To formalize this issue, we\nintroduce the bounded attention prefix oracle (BAPO) model, a new computational\nframework that models bandwidth constraints on attention heads, the mechanism\nfor internal communication in LLMs. We show that several important reasoning\nproblems like graph reachability require high communication bandwidth for BAPOs\nto solve; we call these problems BAPO-hard. Our experiments corroborate our\ntheoretical predictions: GPT-4, Claude, and Gemini succeed on BAPO-easy tasks\nand fail even on relatively small BAPO-hard tasks. BAPOs also reveal another\nbenefit of chain of thought (CoT): we prove that breaking down a task using CoT\ncan turn any BAPO-hard problem into a BAPO-easy one. Our results offer\nprincipled explanations for key LLM failures and suggest directions for\narchitectures and inference methods that mitigate bandwidth limits.", "published": "2025-05-13 00:25:23", "link": "http://arxiv.org/abs/2505.08140v1", "categories": ["cs.AI", "cs.FL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning", "abstract": "Machine unlearning methods take a model trained on a dataset and a forget\nset, then attempt to produce a model as if it had only been trained on the\nexamples not in the forget set. We empirically show that an adversary is able\nto distinguish between a mirror model (a control model produced by retraining\nwithout the data to forget) and a model produced by an unlearning method across\nrepresentative unlearning methods from the literature. We build distinguishing\nalgorithms based on evaluation scores in the literature (i.e. membership\ninference scores) and Kullback-Leibler divergence.\n  We propose a strong formal definition for machine unlearning called\ncomputational unlearning. Computational unlearning is defined as the inability\nfor an adversary to distinguish between a mirror model and a model produced by\nan unlearning method. If the adversary cannot guess better than random (except\nwith negligible probability), then we say that an unlearning method achieves\ncomputational unlearning.\n  Our computational unlearning definition provides theoretical structure to\nprove unlearning feasibility results. For example, our computational unlearning\ndefinition immediately implies that there are no deterministic computational\nunlearning methods for entropic learning algorithms. We also explore the\nrelationship between differential privacy (DP)-based unlearning methods and\ncomputational unlearning, showing that DP-based approaches can satisfy\ncomputational unlearning at the cost of an extreme utility collapse. These\nresults demonstrate that current methodology in the literature fundamentally\nfalls short of achieving computational unlearning. We conclude by identifying\nseveral open questions for future work.", "published": "2025-05-13 00:23:17", "link": "http://arxiv.org/abs/2505.08138v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Leveraging AI for Productive and Trustworthy HPC Software: Challenges and Research Directions", "abstract": "We discuss the challenges and propose research directions for using AI to\nrevolutionize the development of high-performance computing (HPC) software. AI\ntechnologies, in particular large language models, have transformed every\naspect of software development. For its part, HPC software is recognized as a\nhighly specialized scientific field of its own. We discuss the challenges\nassociated with leveraging state-of-the-art AI technologies to develop such a\nunique and niche class of software and outline our research directions in the\ntwo US Department of Energy--funded projects for advancing HPC Software via AI:\nEllora and Durban.", "published": "2025-05-13 00:12:45", "link": "http://arxiv.org/abs/2505.08135v1", "categories": ["cs.SE", "cs.AI", "cs.DC", "cs.PF"], "primary_category": "cs.SE"}
{"title": "One Bad NOFO? AI Governance in Federal Grantmaking", "abstract": "Much scholarship considers how U.S. federal agencies govern artificial\nintelligence (AI) through rulemaking and their own internal use policies. But\nagencies have an overlooked AI governance role: setting discretionary grant\npolicy when directing billions of dollars in federal financial assistance.\nThese dollars enable state and local entities to study, create, and use AI.\nThis funding not only goes to dedicated AI programs, but also to grantees using\nAI in the course of meeting their routine grant objectives. As discretionary\ngrantmakers, agencies guide and restrict what grant winners do -- a hidden\nlever for AI governance. Agencies pull this lever by setting program\nobjectives, judging criteria, and restrictions for AI use. Using a novel\ndataset of over 40,000 non-defense federal grant notices of funding opportunity\n(NOFOs) posted to Grants.gov between 2009 and 2024, we analyze how agencies\nregulate the use of AI by grantees. We select records mentioning AI and review\ntheir stated goals and requirements. We find agencies promoting AI in notice\nnarratives, shaping adoption in ways other records of grant policy might fail\nto capture. Of the grant opportunities that mention AI, we find only a handful\nof AI-specific judging criteria or restrictions. This silence holds even when\nagencies fund AI uses in contexts affecting people's rights and which, under an\nanalogous federal procurement regime, would result in extra oversight. These\nfindings recast grant notices as a site of AI policymaking -- albeit one that\nis developing out of step with other regulatory efforts and incomplete in its\nconsideration of transparency, accountability, and privacy protections. The\npaper concludes by drawing lessons from AI procurement scholarship, while\nidentifying distinct challenges in grantmaking that invite further study.", "published": "2025-05-13 00:08:22", "link": "http://arxiv.org/abs/2505.08133v1", "categories": ["cs.CY", "cs.AI", "K.5.2"], "primary_category": "cs.CY"}
{"title": "High-order Regularization for Machine Learning and Learning-based Control", "abstract": "The paper proposes a novel regularization procedure for machine learning. The\nproposed high-order regularization (HR) provides new insight into\nregularization, which is widely used to train a neural network that can be\nutilized to approximate the action-value function in general reinforcement\nlearning problems. The proposed HR method ensures the provable convergence of\nthe approximation algorithm, which makes the much-needed connection between\nregularization and explainable learning using neural networks. The proposed HR\nmethod theoretically demonstrates that regularization can be regarded as an\napproximation in terms of inverse mapping with explicitly calculable\napproximation error, and the $L_2$ regularization is a lower-order case of the\nproposed method. We provide lower and upper bounds for the error of the\nproposed HR solution, which helps build a reliable model. We also find that\nregularization with the proposed HR can be regarded as a contraction. We prove\nthat the generalizability of neural networks can be maximized with a proper\nregularization matrix, and the proposed HR is applicable for neural networks\nwith any mapping matrix. With the theoretical explanation of the extreme\nlearning machine for neural network training and the proposed high-order\nregularization, one can better interpret the output of the neural network, thus\nleading to explainable learning. We present a case study based on regularized\nextreme learning neural networks to demonstrate the application of the proposed\nHR and give the corresponding incremental HR solution. We verify the\nperformance of the proposed HR method by solving a classic control problem in\nreinforcement learning. The result demonstrates the superior performance of the\nmethod with significant enhancement in the generalizability of the neural\nnetwork.", "published": "2025-05-13 00:00:23", "link": "http://arxiv.org/abs/2505.08129v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations", "abstract": "Mimicry is a fundamental learning mechanism in humans, enabling individuals\nto learn new tasks by observing and imitating experts. However, applying this\nability to robots presents significant challenges due to the inherent\ndifferences between human and robot embodiments in both their visual appearance\nand physical capabilities. While previous methods bridge this gap using\ncross-embodiment datasets with shared scenes and tasks, collecting such aligned\ndata between humans and robots at scale is not trivial. In this paper, we\npropose UniSkill, a novel framework that learns embodiment-agnostic skill\nrepresentations from large-scale cross-embodiment video data without any\nlabels, enabling skills extracted from human video prompts to effectively\ntransfer to robot policies trained only on robot data. Our experiments in both\nsimulation and real-world environments show that our cross-embodiment skills\nsuccessfully guide robots in selecting appropriate actions, even with unseen\nvideo prompts. The project website can be found at:\nhttps://kimhanjung.github.io/UniSkill.", "published": "2025-05-13 17:59:22", "link": "http://arxiv.org/abs/2505.08787v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving", "abstract": "The Large Visual-Language Models (LVLMs) have significantly advanced image\nunderstanding. Their comprehension and reasoning capabilities enable promising\napplications in autonomous driving scenarios. However, existing research\ntypically focuses on front-view perspectives and partial objects within scenes,\nstruggling to achieve comprehensive scene understanding. Meanwhile, existing\nLVLMs suffer from the lack of mapping relationship between 2D and 3D and\ninsufficient integration of 3D object localization and instruction\nunderstanding. To tackle these limitations, we first introduce NuInteract, a\nlarge-scale dataset with over 1.5M multi-view image language pairs spanning\ndense scene captions and diverse interactive tasks. Furthermore, we propose\nDriveMonkey, a simple yet effective framework that seamlessly integrates LVLMs\nwith a spatial processor using a series of learnable queries. The spatial\nprocessor, designed as a plug-and-play component, can be initialized with\npre-trained 3D detectors to improve 3D perception. Our experiments show that\nDriveMonkey outperforms general LVLMs, especially achieving a 9.86% notable\nimprovement on the 3D visual grounding task. The dataset and code will be\nreleased at https://github.com/zc-zhao/DriveMonkey.", "published": "2025-05-13 16:36:51", "link": "http://arxiv.org/abs/2505.08725v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TiMo: Spatiotemporal Foundation Model for Satellite Image Time Series", "abstract": "Satellite image time series (SITS) provide continuous observations of the\nEarth's surface, making them essential for applications such as environmental\nmanagement and disaster assessment. However, existing spatiotemporal foundation\nmodels rely on plain vision transformers, which encode entire temporal\nsequences without explicitly capturing multiscale spatiotemporal relationships\nbetween land objects. This limitation hinders their effectiveness in downstream\ntasks. To overcome this challenge, we propose TiMo, a novel hierarchical vision\ntransformer foundation model tailored for SITS analysis. At its core, we\nintroduce a spatiotemporal gyroscope attention mechanism that dynamically\ncaptures evolving multiscale patterns across both time and space. For\npre-training, we curate MillionST, a large-scale dataset of one million images\nfrom 100,000 geographic locations, each captured across 10 temporal phases over\nfive years, encompassing diverse geospatial changes and seasonal variations.\nLeveraging this dataset, we adapt masked image modeling to pre-train TiMo,\nenabling it to effectively learn and encode generalizable spatiotemporal\nrepresentations.Extensive experiments across multiple spatiotemporal\ntasks-including deforestation monitoring, land cover segmentation, crop type\nclassification, and flood detection-demonstrate TiMo's superiority over\nstate-of-the-art methods. Code, model, and dataset will be released at\nhttps://github.com/MiliLab/TiMo.", "published": "2025-05-13 16:35:11", "link": "http://arxiv.org/abs/2505.08723v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPAST: Arbitrary Style Transfer with Style Priors via Pre-trained Large-scale Model", "abstract": "Given an arbitrary content and style image, arbitrary style transfer aims to\nrender a new stylized\n  image which preserves the content image's structure and possesses the style\nimage's style. Existing\n  arbitrary style transfer methods are based on either small models or\npre-trained large-scale models.\n  The small model-based methods fail to generate high-quality stylized images,\nbringing artifacts and\n  disharmonious patterns. The pre-trained large-scale model-based methods can\ngenerate high-quality\n  stylized images but struggle to preserve the content structure and cost long\ninference time. To this\n  end, we propose a new framework, called SPAST, to generate high-quality\nstylized images with\n  less inference time. Specifically, we design a novel Local-global Window Size\nStylization Module\n  (LGWSSM)tofuse style features into content features. Besides, we introduce a\nnovel style prior loss,\n  which can dig out the style priors from a pre-trained large-scale model into\nthe SPAST and motivate\n  the SPAST to generate high-quality stylized images with short inference\ntime.We conduct abundant\n  experiments to verify that our proposed method can generate high-quality\nstylized images and less\n  inference time compared with the SOTA arbitrary style transfer methods.", "published": "2025-05-13 15:54:36", "link": "http://arxiv.org/abs/2505.08695v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VIViT: Variable-Input Vision Transformer Framework for 3D MR Image Segmentation", "abstract": "Self-supervised pretrain techniques have been widely used to improve the\ndownstream tasks' performance. However, real-world magnetic resonance (MR)\nstudies usually consist of different sets of contrasts due to different\nacquisition protocols, which poses challenges for the current deep learning\nmethods on large-scale pretrain and different downstream tasks with different\ninput requirements, since these methods typically require a fixed set of input\nmodalities or, contrasts. To address this challenge, we propose variable-input\nViT (VIViT), a transformer-based framework designed for self-supervised\npretraining and segmentation finetuning for variable contrasts in each study.\nWith this ability, our approach can maximize the data availability in pretrain,\nand can transfer the learned knowledge from pretrain to downstream tasks\ndespite variations in input requirements. We validate our method on brain\ninfarct and brain tumor segmentation, where our method outperforms current CNN\nand ViT-based models with a mean Dice score of 0.624 and 0.883 respectively.\nThese results highlight the efficacy of our design for better adaptability and\nperformance on tasks with real-world heterogeneous MR data.", "published": "2025-05-13 15:52:34", "link": "http://arxiv.org/abs/2505.08693v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CAD-Coder:Text-Guided CAD Files Code Generation", "abstract": "Computer-aided design (CAD) is a way to digitally create 2D drawings and 3D\nmodels of real-world products. Traditional CAD typically relies on hand-drawing\nby experts or modifications of existing library files, which doesn't allow for\nrapid personalization. With the emergence of generative artificial\nintelligence, convenient and efficient personalized CAD generation has become\npossible. However, existing generative methods typically produce outputs that\nlack interactive editability and geometric annotations, limiting their\npractical applications in manufacturing. To enable interactive generative CAD,\nwe propose CAD-Coder, a framework that transforms natural language instructions\ninto CAD script codes, which can be executed in Python environments to generate\nhuman-editable CAD files (.Dxf). To facilitate the generation of editable CAD\nsketches with annotation information, we construct a comprehensive dataset\ncomprising 29,130 Dxf files with their corresponding script codes, where each\nsketch preserves both editability and geometric annotations. We evaluate\nCAD-Coder on various 2D/3D CAD generation tasks against existing methods,\ndemonstrating superior interactive capabilities while uniquely providing\neditable sketches with geometric annotations.", "published": "2025-05-13 15:45:46", "link": "http://arxiv.org/abs/2505.08686v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results", "abstract": "Deep learning (DL) has become the dominant approach for medical image\nsegmentation, yet ensuring the reliability and clinical applicability of these\nmodels requires addressing key challenges such as annotation variability,\ncalibration, and uncertainty estimation. This is why we created the Calibration\nand Uncertainty for multiRater Volume Assessment in multiorgan Segmentation\n(CURVAS), which highlights the critical role of multiple annotators in\nestablishing a more comprehensive ground truth, emphasizing that segmentation\nis inherently subjective and that leveraging inter-annotator variability is\nessential for robust model evaluation. Seven teams participated in the\nchallenge, submitting a variety of DL models evaluated using metrics such as\nDice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and\nContinuous Ranked Probability Score (CRPS). By incorporating consensus and\ndissensus ground truth, we assess how DL models handle uncertainty and whether\ntheir confidence estimates align with true segmentation performance. Our\nfindings reinforce the importance of well-calibrated models, as better\ncalibration is strongly correlated with the quality of the results.\nFurthermore, we demonstrate that segmentation models trained on diverse\ndatasets and enriched with pre-trained knowledge exhibit greater robustness,\nparticularly in cases deviating from standard anatomical structures. Notably,\nthe best-performing models achieved high DSC and well-calibrated uncertainty\nestimates. This work underscores the need for multi-annotator ground truth,\nthorough calibration assessments, and uncertainty-aware evaluations to develop\ntrustworthy and clinically reliable DL-based medical image segmentation models.", "published": "2025-05-13 15:45:44", "link": "http://arxiv.org/abs/2505.08685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Claycode: Stylable and Deformable 2D Scannable Codes", "abstract": "This paper introduces Claycode, a novel 2D scannable code designed for\nextensive stylization and deformation. Unlike traditional matrix-based codes\n(e.g., QR codes), Claycodes encode their message in a tree structure. During\nthe encoding process, bits are mapped into a topology tree, which is then\ndepicted as a nesting of color regions drawn within the boundaries of a target\npolygon shape. When decoding, Claycodes are extracted and interpreted in\nreal-time from a camera stream. We detail the end-to-end pipeline and show that\nClaycodes allow for extensive stylization without compromising their\nfunctionality. We then empirically demonstrate Claycode's high tolerance to\nheavy deformations, outperforming traditional 2D scannable codes in scenarios\nwhere they typically fail.", "published": "2025-05-13 15:28:06", "link": "http://arxiv.org/abs/2505.08666v1", "categories": ["cs.GR", "cs.CG", "cs.CV", "cs.HC", "I.3.0; I.3.5; I.3.6; E.4"], "primary_category": "cs.GR"}
{"title": "SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation", "abstract": "Assessing human skill levels in complex activities is a challenging problem\nwith applications in sports, rehabilitation, and training. In this work, we\npresent SkillFormer, a parameter-efficient architecture for unified multi-view\nproficiency estimation from egocentric and exocentric videos. Building on the\nTimeSformer backbone, SkillFormer introduces a CrossViewFusion module that\nfuses view-specific features using multi-head cross-attention, learnable\ngating, and adaptive self-calibration. We leverage Low-Rank Adaptation to\nfine-tune only a small subset of parameters, significantly reducing training\ncosts. In fact, when evaluated on the EgoExo4D dataset, SkillFormer achieves\nstate-of-the-art accuracy in multi-view settings while demonstrating remarkable\ncomputational efficiency, using 4.5x fewer parameters and requiring 3.75x fewer\ntraining epochs than prior baselines. It excels in multiple structured tasks,\nconfirming the value of multi-view integration for fine-grained skill\nassessment.", "published": "2025-05-13 15:27:24", "link": "http://arxiv.org/abs/2505.08665v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DLO-Splatting: Tracking Deformable Linear Objects Using 3D Gaussian Splatting", "abstract": "This work presents DLO-Splatting, an algorithm for estimating the 3D shape of\nDeformable Linear Objects (DLOs) from multi-view RGB images and gripper state\ninformation through prediction-update filtering. The DLO-Splatting algorithm\nuses a position-based dynamics model with shape smoothness and rigidity\ndampening corrections to predict the object shape. Optimization with a 3D\nGaussian Splatting-based rendering loss iteratively renders and refines the\nprediction to align it with the visual observations in the update step. Initial\nexperiments demonstrate promising results in a knot tying scenario, which is\nchallenging for existing vision-only methods.", "published": "2025-05-13 15:03:40", "link": "http://arxiv.org/abs/2505.08644v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning", "abstract": "While humans can flexibly leverage interactive visual cognition for complex\nproblem-solving, enabling Large Vision-Language Models (LVLMs) to learn\nsimilarly adaptive behaviors with visual tools remains challenging. A\nsignificant hurdle is the current lack of standardized infrastructure, which\nhinders integrating diverse tools, generating rich interaction data, and\ntraining robust agents effectively. To address these gaps, we introduce\nOpenThinkIMG, the first open-source, comprehensive end-to-end framework for\ntool-augmented LVLMs. It features standardized vision tool interfaces, scalable\ntrajectory generation for policy initialization, and a flexible training\nenvironment. Furthermore, considering supervised fine-tuning (SFT) on static\ndemonstrations offers limited policy generalization for dynamic tool\ninvocation, we propose a novel reinforcement learning (RL) framework V-ToolRL\nto train LVLMs to learn adaptive policies for invoking external vision tools.\nV-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies\nby directly optimizing for task success using feedback from tool interactions.\nWe empirically validate V-ToolRL on challenging chart reasoning tasks. Our\nRL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its\nSFT-initialized counterpart (+28.83 points) and surpasses established\nsupervised tool-learning baselines like Taco and CogCom by an average of +12.7\npoints. Notably, it also surpasses prominent closed-source models like GPT-4.1\nby +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational\nframework for advancing dynamic, tool-augmented visual reasoning, helping the\ncommunity develop AI agents that can genuinely \"think with images\".", "published": "2025-05-13 14:35:51", "link": "http://arxiv.org/abs/2505.08617v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A portable diagnosis model for Keratoconus using a smartphone", "abstract": "Keratoconus (KC) is a progressive corneal disorder characterized by localized\nthinning and protrusion, leading to visual distortion. While Placido disc-based\ntopography remains a standard in clinical diagnostics, its dependence on\nspecialized equipment limits accessibility. In this paper, we propose a\nportable, smartphone-based diagnostic framework that captures corneal\nreflections of a Placido disc displayed on a phone screen and applies a\ntwo-stage detection pipeline, then validate on 3D-printed emulated eyeball\nmodels that simulate normal, moderate, and severe KC stages based on anterior\nchamber depth (ACD). The first step of the two-stage detection pipeline is\nclassifying different stages of KC with features including height and width of\nextracted reflections using weighted support vector machine (WSVM). It achieves\na maximum accuracy of 92.93%, and maintains over 90% accuracy across multiple\nsmartphone models, including the Galaxy Z Flip 3, iPhone 15 Pro, and iPhone 16\nPro. For the second step, we visualize the KC-affected protrusion regions on\nthe corneas with color maps based on inter-disc distance, that provides an\nintuitive representation of disease severity and localization. Moreover, we\nvalidate the ability of the extracted features to differentiate between KC\nstages with ANOVA and Omega Squared, with significant p-values (e.g., $p <\n10^{-6}$) and large effect sizes ($\\\\omega^2$ up to 0.8398) among classes.", "published": "2025-05-13 14:34:46", "link": "http://arxiv.org/abs/2505.08616v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks", "abstract": "Deepfake technology poses increasing risks such as privacy invasion and\nidentity theft. To address these threats, we propose WaveGuard, a proactive\nwatermarking framework that enhances robustness and imperceptibility via\nfrequency-domain embedding and graph-based structural consistency.\nSpecifically, we embed watermarks into high-frequency sub-bands using Dual-Tree\nComplex Wavelet Transform (DT-CWT) and employ a Structural Consistency Graph\nNeural Network (SC-GNN) to preserve visual quality. We also design an attention\nmodule to refine embedding precision. Experimental results on face swap and\nreenactment tasks demonstrate that WaveGuard outperforms state-of-the-art\nmethods in both robustness and visual quality. Code is available at\nhttps://github.com/vpsg-research/WaveGuard.", "published": "2025-05-13 14:31:42", "link": "http://arxiv.org/abs/2505.08614v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Zero-shot Stereo Matching using Large-scale Mixed Images Sources in the Real World", "abstract": "Stereo matching methods rely on dense pixel-wise ground truth labels, which\nare laborious to obtain, especially for real-world datasets. The scarcity of\nlabeled data and domain gaps between synthetic and real-world images also pose\nnotable challenges. In this paper, we propose a novel framework,\n\\textbf{BooSTer}, that leverages both vision foundation models and large-scale\nmixed image sources, including synthetic, real, and single-view images. First,\nto fully unleash the potential of large-scale single-view images, we design a\ndata generation strategy combining monocular depth estimation and diffusion\nmodels to generate dense stereo matching data from single-view images. Second,\nto tackle sparse labels in real-world datasets, we transfer knowledge from\nmonocular depth estimation models, using pseudo-mono depth labels and a dynamic\nscale- and shift-invariant loss for additional supervision. Furthermore, we\nincorporate vision foundation model as an encoder to extract robust and\ntransferable features, boosting accuracy and generalization. Extensive\nexperiments on benchmark datasets demonstrate the effectiveness of our\napproach, achieving significant improvements in accuracy over existing methods,\nparticularly in scenarios with limited labeled data and domain shifts.", "published": "2025-05-13 14:24:38", "link": "http://arxiv.org/abs/2505.08607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Multi-Modal Information to Enhance Dataset Distillation", "abstract": "Dataset distillation aims to create a compact and highly representative\nsynthetic dataset that preserves the knowledge of a larger real dataset. While\nexisting methods primarily focus on optimizing visual representations,\nincorporating additional modalities and refining object-level information can\nsignificantly improve the quality of distilled datasets. In this work, we\nintroduce two key enhancements to dataset distillation: caption-guided\nsupervision and object-centric masking. To integrate textual information, we\npropose two strategies for leveraging caption features: the feature\nconcatenation, where caption embeddings are fused with visual features at the\nclassification stage, and caption matching, which introduces a caption-based\nalignment loss during training to ensure semantic coherence between real and\nsynthetic data. Additionally, we apply segmentation masks to isolate target\nobjects and remove background distractions, introducing two loss functions\ndesigned for object-centric learning: masked feature alignment loss and masked\ngradient matching loss. Comprehensive evaluations demonstrate that integrating\ncaption-based guidance and object-centric masking enhances dataset\ndistillation, leading to synthetic datasets that achieve superior performance\non downstream tasks.", "published": "2025-05-13 14:20:11", "link": "http://arxiv.org/abs/2505.08605v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking", "abstract": "Out-of-distribution (OOD) detection is essential for ensuring the reliability\nof deep learning models in medical imaging applications. This work is motivated\nby the observation that class activation maps (CAMs) for in-distribution (ID)\ndata typically emphasize regions that are highly relevant to the model's\npredictions, whereas OOD data often lacks such focused activations. By masking\ninput images with inverted CAMs, the feature representations of ID data undergo\nmore substantial changes compared to those of OOD data, offering a robust\ncriterion for differentiation. In this paper, we introduce a novel unsupervised\nOOD detection framework, Multi-Exit Class Activation Map (MECAM), which\nleverages multi-exit CAMs and feature masking. By utilizing mult-exit networks\nthat combine CAMs from varying resolutions and depths, our method captures both\nglobal and local feature representations, thereby enhancing the robustness of\nOOD detection. We evaluate MECAM on multiple ID datasets, including ISIC19 and\nPathMNIST, and test its performance against three medical OOD datasets, RSNA\nPneumonia, COVID-19, and HeadCT, and one natural image OOD dataset, iSUN.\nComprehensive comparisons with state-of-the-art OOD detection methods validate\nthe effectiveness of our approach. Our findings emphasize the potential of\nmulti-exit networks and feature masking for advancing unsupervised OOD\ndetection in medical imaging, paving the way for more reliable and\ninterpretable models in clinical practice.", "published": "2025-05-13 14:18:58", "link": "http://arxiv.org/abs/2505.08604v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rejoining fragmented ancient bamboo slips with physics-driven deep learning", "abstract": "Bamboo slips are a crucial medium for recording ancient civilizations in East\nAsia, and offers invaluable archaeological insights for reconstructing the Silk\nRoad, studying material culture exchanges, and global history. However, many\nexcavated bamboo slips have been fragmented into thousands of irregular pieces,\nmaking their rejoining a vital yet challenging step for understanding their\ncontent. Here we introduce WisePanda, a physics-driven deep learning framework\ndesigned to rejoin fragmented bamboo slips. Based on the physics of fracture\nand material deterioration, WisePanda automatically generates synthetic\ntraining data that captures the physical properties of bamboo fragmentations.\nThis approach enables the training of a matching network without requiring\nmanually paired samples, providing ranked suggestions to facilitate the\nrejoining process. Compared to the leading curve matching method, WisePanda\nincreases Top-50 matching accuracy from 36\\% to 52\\%. Archaeologists using\nWisePanda have experienced substantial efficiency improvements (approximately\n20 times faster) when rejoining fragmented bamboo slips. This research\ndemonstrates that incorporating physical principles into deep learning models\ncan significantly enhance their performance, transforming how archaeologists\nrestore and study fragmented artifacts. WisePanda provides a new paradigm for\naddressing data scarcity in ancient artifact restoration through physics-driven\nmachine learning.", "published": "2025-05-13 14:16:53", "link": "http://arxiv.org/abs/2505.08601v1", "categories": ["cs.CV", "cond-mat.mtrl-sci"], "primary_category": "cs.CV"}
{"title": "PrePrompt: Predictive prompting for class incremental learning", "abstract": "Class Incremental Learning (CIL) based on pre-trained models offers a\npromising direction for open-world continual learning. Existing methods\ntypically rely on correlation-based strategies, where an image's classification\nfeature is used as a query to retrieve the most related key prompts and select\nthe corresponding value prompts for training. However, these approaches face an\ninherent limitation: fitting the entire feature space of all tasks with only a\nfew trainable prompts is fundamentally challenging. We propose Predictive\nPrompting (PrePrompt), a novel CIL framework that circumvents correlation-based\nlimitations by leveraging pre-trained models' natural classification ability to\npredict task-specific prompts. Specifically, PrePrompt decomposes CIL into a\ntwo-stage prediction framework: task-specific prompt prediction followed by\nlabel prediction. While theoretically appealing, this framework risks bias\ntoward recent classes due to missing historical data for older classifier\ncalibration. PrePrompt then mitigates this by incorporating feature\ntranslation, dynamically balancing stability and plasticity. Experiments across\nmultiple benchmarks demonstrate PrePrompt's superiority over state-of-the-art\nprompt-based CIL methods. The code will be released upon acceptance.", "published": "2025-05-13 13:57:56", "link": "http://arxiv.org/abs/2505.08586v1", "categories": ["cs.CV", "I.5.4"], "primary_category": "cs.CV"}
{"title": "A Large-scale Benchmark on Geological Fault Delineation Models: Domain Shift, Training Dynamics, Generalizability, Evaluation and Inferential Behavior", "abstract": "Machine learning has taken a critical role in seismic interpretation\nworkflows, especially in fault delineation tasks. However, despite the recent\nproliferation of pretrained models and synthetic datasets, the field still\nlacks a systematic understanding of the generalizability limits of these models\nacross seismic data representing a variety of geologic, acquisition and\nprocessing settings. Distributional shifts between different data sources,\nlimitations in fine-tuning strategies and labeled data accessibility, and\ninconsistent evaluation protocols all represent major roadblocks in the\ndeployment of reliable and robust models in real-world exploration settings. In\nthis paper, we present the first large-scale benchmarking study explicitly\ndesigned to provide answers and guidelines for domain shift strategies in\nseismic interpretation. Our benchmark encompasses over $200$ models trained and\nevaluated on three heterogeneous datasets (synthetic and real data) including\nFaultSeg3D, CRACKS, and Thebe. We systematically assess pretraining,\nfine-tuning, and joint training strategies under varying degrees of domain\nshift. Our analysis highlights the fragility of current fine-tuning practices,\nthe emergence of catastrophic forgetting, and the challenges of interpreting\nperformance in a systematic manner. We establish a robust experimental baseline\nto provide insights into the tradeoffs inherent to current fault delineation\nworkflows, and shed light on directions for developing more generalizable,\ninterpretable and effective machine learning models for seismic interpretation.\nThe insights and analyses reported provide a set of guidelines on the\ndeployment of fault delineation models within seismic interpretation workflows.", "published": "2025-05-13 13:56:43", "link": "http://arxiv.org/abs/2505.08585v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReSurgSAM2: Referring Segment Anything in Surgical Video via Credible Long-term Tracking", "abstract": "Surgical scene segmentation is critical in computer-assisted surgery and is\nvital for enhancing surgical quality and patient outcomes. Recently, referring\nsurgical segmentation is emerging, given its advantage of providing surgeons\nwith an interactive experience to segment the target object. However, existing\nmethods are limited by low efficiency and short-term tracking, hindering their\napplicability in complex real-world surgical scenarios. In this paper, we\nintroduce ReSurgSAM2, a two-stage surgical referring segmentation framework\nthat leverages Segment Anything Model 2 to perform text-referred target\ndetection, followed by tracking with reliable initial frame identification and\ndiversity-driven long-term memory. For the detection stage, we propose a\ncross-modal spatial-temporal Mamba to generate precise detection and\nsegmentation results. Based on these results, our credible initial frame\nselection strategy identifies the reliable frame for the subsequent tracking.\nUpon selecting the initial frame, our method transitions to the tracking stage,\nwhere it incorporates a diversity-driven memory mechanism that maintains a\ncredible and diverse memory bank, ensuring consistent long-term tracking.\nExtensive experiments demonstrate that ReSurgSAM2 achieves substantial\nimprovements in accuracy and efficiency compared to existing methods, operating\nin real-time at 61.2 FPS. Our code and datasets will be available at\nhttps://github.com/jinlab-imvr/ReSurgSAM2.", "published": "2025-05-13 13:56:10", "link": "http://arxiv.org/abs/2505.08581v1", "categories": ["cs.CV", "eess.IV", "q-bio.TO"], "primary_category": "cs.CV"}
{"title": "Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections", "abstract": "Rapid advances in deep learning for computer vision have driven the adoption\nof RGB camera-based adaptive traffic light systems to improve traffic safety\nand pedestrian comfort. However, these systems often overlook the needs of\npeople with mobility restrictions. Moreover, the use of RGB cameras presents\nsignificant challenges, including limited detection performance under adverse\nweather or low-visibility conditions, as well as heightened privacy concerns.\nTo address these issues, we propose a fully automated, thermal detector-based\ntraffic light system that dynamically adjusts signal durations for individuals\nwith walking impairments or mobility burden and triggers the auditory signal\nfor visually impaired individuals, thereby advancing towards barrier-free\nintersection for all users. To this end, we build the thermal dataset for\npeople with mobility restrictions (TD4PWMR), designed to capture diverse\npedestrian scenarios, particularly focusing on individuals with mobility aids\nor mobility burden under varying environmental conditions, such as different\nlighting, weather, and crowded urban settings. While thermal imaging offers\nadvantages in terms of privacy and robustness to adverse conditions, it also\nintroduces inherent hurdles for object detection due to its lack of color and\nfine texture details and generally lower resolution of thermal images. To\novercome these limitations, we develop YOLO-Thermal, a novel variant of the\nYOLO architecture that integrates advanced feature extraction and attention\nmechanisms for enhanced detection accuracy and robustness in thermal imaging.\nExperiments demonstrate that the proposed thermal detector outperforms existing\ndetectors, while the proposed traffic light system effectively enhances\nbarrier-free intersection. The source codes and dataset are available at\nhttps://github.com/leon2014dresden/YOLO-THERMAL.", "published": "2025-05-13 13:44:21", "link": "http://arxiv.org/abs/2505.08568v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection", "abstract": "Masked video modeling~(MVM) has emerged as a highly effective pre-training\nstrategy for visual foundation models, whereby the model reconstructs masked\nspatiotemporal tokens using information from visible tokens. However, a key\nchallenge in such approaches lies in selecting an appropriate masking strategy.\nPrevious studies have explored predefined masking techniques, including random\nand tube-based masking, as well as approaches that leverage key motion priors,\noptical flow and semantic cues from externally pre-trained models. In this\nwork, we introduce a novel and generalizable Trajectory-Aware Adaptive Token\nSampler (TATS), which models the motion dynamics of tokens and can be\nseamlessly integrated into the masked autoencoder (MAE) framework to select\nmotion-centric tokens in videos. Additionally, we propose a unified training\nstrategy that enables joint optimization of both MAE and TATS from scratch\nusing Proximal Policy Optimization (PPO). We show that our model allows for\naggressive masking without compromising performance on the downstream task of\naction recognition while also ensuring that the pre-training remains memory\nefficient. Extensive experiments of the proposed approach across four\nbenchmarks, including Something-Something v2, Kinetics-400, UCF101, and HMDB51,\ndemonstrate the effectiveness, transferability, generalization, and efficiency\nof our work compared to other state-of-the-art methods.", "published": "2025-05-13 13:35:41", "link": "http://arxiv.org/abs/2505.08561v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning", "abstract": "This research investigates the application of computer vision for rapid,\naccurate, and non-invasive food quality assessment, focusing on the novel\nchallenge of real-time raspberry grading into five distinct classes within an\nindustrial environment as the fruits move along a conveyor belt. To address\nthis, a dedicated dataset of raspberries, namely RaspGrade, was acquired and\nmeticulously annotated. Instance segmentation experiments revealed that\naccurate fruit-level masks can be obtained; however, the classification of\ncertain raspberry grades presents challenges due to color similarities and\nocclusion, while others are more readily distinguishable based on color. The\nacquired and annotated RaspGrade dataset is accessible on HuggingFace at:\nhttps://huggingface.co/datasets/FBK-TeV/RaspGrade.", "published": "2025-05-13 13:07:29", "link": "http://arxiv.org/abs/2505.08537v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting", "abstract": "Source-free domain adaptation (SFDA) for segmentation aims at adapting a\nmodel trained in the source domain to perform well in the target domain with\nonly the source model and unlabeled target data.Inspired by the recent success\nof Segment Anything Model (SAM) which exhibits the generality of segmenting\nimages of various modalities and in different domains given human-annotated\nprompts like bounding boxes or points, we for the first time explore the\npotentials of Segment Anything Model for SFDA via automatedly finding an\naccurate bounding box prompt. We find that the bounding boxes directly\ngenerated with existing SFDA approaches are defective due to the domain gap.To\ntackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting\napproach to search for the box prompt. Specifically, the source model is first\ntrained in a feature aggregation phase, which not only preliminarily adapts the\nsource model to the target domain but also builds a feature distribution\nwell-prepared for box prompt search. In the second phase, based on two feature\ndistribution observations, we gradually expand the box prompt with the guidance\nof the target model feature and the SAM feature to handle the class-wise\nclustered target features and the class-wise dispersed target features,\nrespectively. To remove the potentially enlarged false positive regions caused\nby the over-confident prediction of the target model, the refined pseudo-labels\nproduced by SAM are further postprocessed based on connectivity analysis.\nExperiments on 3D and 2D datasets indicate that our approach yields superior\nperformance compared to conventional methods. Code is available at\nhttps://github.com/zheangh/DFG.", "published": "2025-05-13 13:00:48", "link": "http://arxiv.org/abs/2505.08527v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Snake Upsampling Operater and Boundary-Skeleton Weighted Loss for Tubular Structure Segmentation", "abstract": "Accurate segmentation of tubular topological structures (e.g., fissures and\nvasculature) is critical in various fields to guarantee dependable downstream\nquantitative analysis and modeling. However, in dense prediction tasks such as\nsemantic segmentation and super-resolution, conventional upsampling operators\ncannot accommodate the slenderness of tubular structures and the curvature of\nmorphology. This paper introduces a dynamic snake upsampling operators and a\nboundary-skeleton weighted loss tailored for topological tubular structures.\nSpecifically, we design a snake upsampling operators based on an adaptive\nsampling domain, which dynamically adjusts the sampling stride according to the\nfeature map and selects a set of subpixel sampling points along the serpentine\npath, enabling more accurate subpixel-level feature recovery for tubular\nstructures. Meanwhile, we propose a skeleton-to-boundary increasing weighted\nloss that trades off main body and boundary weight allocation based on mask\nclass ratio and distance field, preserving main body overlap while enhancing\nfocus on target topological continuity and boundary alignment precision.\nExperiments across various domain datasets and backbone networks show that this\nplug-and-play dynamic snake upsampling operator and boundary-skeleton weighted\nloss boost both pixel-wise segmentation accuracy and topological consistency of\nresults.", "published": "2025-05-13 12:56:59", "link": "http://arxiv.org/abs/2505.08525v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Attention-based Generative Latent Replay: A Continual Learning Approach for WSI Analysis", "abstract": "Whole slide image (WSI) classification has emerged as a powerful tool in\ncomputational pathology, but remains constrained by domain shifts, e.g., due to\ndifferent organs, diseases, or institution-specific variations. To address this\nchallenge, we propose an Attention-based Generative Latent Replay Continual\nLearning framework (AGLR-CL), in a multiple instance learning (MIL) setup for\ndomain incremental WSI classification. Our method employs Gaussian Mixture\nModels (GMMs) to synthesize WSI representations and patch count distributions,\npreserving knowledge of past domains without explicitly storing original data.\nA novel attention-based filtering step focuses on the most salient patch\nembeddings, ensuring high-quality synthetic samples. This privacy-aware\nstrategy obviates the need for replay buffers and outperforms other buffer-free\ncounterparts while matching the performance of buffer-based solutions. We\nvalidate AGLR-CL on clinically relevant biomarker detection and molecular\nstatus prediction across multiple public datasets with diverse centers, organs,\nand patient cohorts. Experimental results confirm its ability to retain prior\nknowledge and adapt to new domains, offering an effective, privacy-preserving\navenue for domain incremental continual learning in WSI classification.", "published": "2025-05-13 12:55:46", "link": "http://arxiv.org/abs/2505.08524v1", "categories": ["cs.CV", "cs.ET"], "primary_category": "cs.CV"}
{"title": "A Deep Learning-Driven Framework for Inhalation Injury Grading Using Bronchoscopy Images", "abstract": "Inhalation injuries face a challenge in clinical diagnosis and grading due to\nthe limitations of traditional methods, such as Abbreviated Injury Score (AIS),\nwhich rely on subjective assessments and show weak correlations with clinical\noutcomes. This study introduces a novel deep learning-based framework for\ngrading inhalation injuries using bronchoscopy images with the duration of\nmechanical ventilation as an objective metric. To address the scarcity of\nmedical imaging data, we propose enhanced StarGAN, a generative model that\nintegrates Patch Loss and SSIM Loss to improve synthetic images' quality and\nclinical relevance. The augmented dataset generated by enhanced StarGAN\nsignificantly improved classification performance when evaluated using the Swin\nTransformer, achieving an accuracy of 77.78%, an 11.11% improvement over the\noriginal dataset. Image quality was assessed using the Fr\\'echet Inception\nDistance (FID), where Enhanced StarGAN achieved the lowest FID of 30.06,\noutperforming baseline models. Burn surgeons confirmed the realism and clinical\nrelevance of the generated images, particularly the preservation of bronchial\nstructures and color distribution. These results highlight the potential of\nenhanced StarGAN in addressing data limitations and improving classification\naccuracy for inhalation injury grading.", "published": "2025-05-13 12:48:36", "link": "http://arxiv.org/abs/2505.08517v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VCRBench: Exploring Long-form Causal Reasoning Capabilities of Large Video Language Models", "abstract": "Despite recent advances in video understanding, the capabilities of Large\nVideo Language Models (LVLMs) to perform video-based causal reasoning remains\nunderexplored, largely due to the absence of relevant and dedicated benchmarks\nfor evaluating causal reasoning in visually grounded and goal-driven settings.\nTo fill this gap, we introduce a novel benchmark named Video-based long-form\nCausal Reasoning (VCRBench). We create VCRBench using procedural videos of\nsimple everyday activities, where the steps are deliberately shuffled with each\nclip capturing a key causal event, to test whether LVLMs can identify, reason\nabout, and correctly sequence the events needed to accomplish a specific goal.\nMoreover, the benchmark is carefully designed to prevent LVLMs from exploiting\nlinguistic shortcuts, as seen in multiple-choice or binary QA formats, while\nalso avoiding the challenges associated with evaluating open-ended QA. Our\nevaluation of state-of-the-art LVLMs on VCRBench suggests that these models\nstruggle with video-based long-form causal reasoning, primarily due to their\ndifficulty in modeling long-range causal dependencies directly from visual\nobservations. As a simple step toward enabling such capabilities, we propose\nRecognition-Reasoning Decomposition (RRD), a modular approach that breaks\nvideo-based causal reasoning into two sub-tasks of video recognition and causal\nreasoning. Our experiments on VCRBench show that RRD significantly boosts\naccuracy on VCRBench, with gains of up to 25.2%. Finally, our thorough analysis\nreveals interesting insights, for instance, that LVLMs primarily rely on\nlanguage knowledge for complex video-based long-form causal reasoning tasks.", "published": "2025-05-13 11:35:58", "link": "http://arxiv.org/abs/2505.08455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection", "abstract": "The emergence and popularity of facial deepfake methods spur the vigorous\ndevelopment of deepfake datasets and facial forgery detection, which to some\nextent alleviates the security concerns about facial-related artificial\nintelligence technologies. However, when it comes to human body forgery, there\nhas been a persistent lack of datasets and detection methods, due to the later\ninception and complexity of human body generation methods. To mitigate this\nissue, we introduce TikTok-DeepFake (TT-DF), a novel large-scale\ndiffusion-based dataset containing 6,120 forged videos with 1,378,857 synthetic\nframes, specifically tailored for body forgery detection. TT-DF offers a wide\nvariety of forgery methods, involving multiple advanced human image animation\nmodels utilized for manipulation, two generative configurations based on the\ndisentanglement of identity and pose information, as well as different\ncompressed versions. The aim is to simulate any potential unseen forged data in\nthe wild as comprehensively as possible, and we also furnish a benchmark on\nTT-DF. Additionally, we propose an adapted body forgery detection model,\nTemporal Optical Flow Network (TOF-Net), which exploits the spatiotemporal\ninconsistencies and optical flow distribution differences between natural data\nand forged data. Our experiments demonstrate that TOF-Net achieves favorable\nperformance on TT-DF, outperforming current state-of-the-art extendable facial\nforgery detection models. For our TT-DF dataset, please refer to\nhttps://github.com/HashTAG00002/TT-DF.", "published": "2025-05-13 11:01:25", "link": "http://arxiv.org/abs/2505.08437v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GNCAF: A GNN-based Neighboring Context Aggregation Framework for Tertiary Lymphoid Structures Semantic Segmentation in WSI", "abstract": "Tertiary lymphoid structures (TLS) are organized clusters of immune cells,\nwhose maturity and area can be quantified in whole slide image (WSI) for\nvarious prognostic tasks. Existing methods for assessing these characteristics\ntypically rely on cell proxy tasks and require additional post-processing\nsteps. In this work, We focus on a novel task-TLS Semantic Segmentation\n(TLS-SS)-which segments both the regions and maturation stages of TLS in WSI in\nan end-to-end manner. Due to the extensive scale of WSI and patch-based\nsegmentation strategies, TLS-SS necessitates integrating from neighboring\npatches to guide target patch (target) segmentation. Previous techniques often\nemploy on multi-resolution approaches, constraining the capacity to leverage\nthe broader neighboring context while tend to preserve coarse-grained\ninformation. To address this, we propose a GNN-based Neighboring Context\nAggregation Framework (GNCAF), which progressively aggregates multi-hop\nneighboring context from the target and employs a self-attention mechanism to\nguide the segmentation of the target. GNCAF can be integrated with various\nsegmentation models to enhance their ability to perceive contextual information\noutside of the patch. We build two TLS-SS datasets, called TCGA-COAD and\nINHOUSE-PAAD, and make the former (comprising 225 WSIs and 5041 TLSs) publicly\navailable. Experiments on these datasets demonstrate the superiority of GNCAF,\nachieving a maximum of 22.08% and 26.57% improvement in mF1 and mIoU,\nrespectively. Additionally, we also validate the task scalability of GNCAF on\nsegmentation of lymph node metastases.", "published": "2025-05-13 10:47:38", "link": "http://arxiv.org/abs/2505.08430v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Visual Image Reconstruction from Brain Activity via Latent Representation", "abstract": "Visual image reconstruction, the decoding of perceptual content from brain\nactivity into images, has advanced significantly with the integration of deep\nneural networks (DNNs) and generative models. This review traces the field's\nevolution from early classification approaches to sophisticated reconstructions\nthat capture detailed, subjective visual experiences, emphasizing the roles of\nhierarchical latent representations, compositional strategies, and modular\narchitectures. Despite notable progress, challenges remain, such as achieving\ntrue zero-shot generalization for unseen images and accurately modeling the\ncomplex, subjective aspects of perception. We discuss the need for diverse\ndatasets, refined evaluation metrics aligned with human perceptual judgments,\nand compositional representations that strengthen model robustness and\ngeneralizability. Ethical issues, including privacy, consent, and potential\nmisuse, are underscored as critical considerations for responsible development.\nVisual image reconstruction offers promising insights into neural coding and\nenables new psychological measurements of visual experiences, with applications\nspanning clinical diagnostics and brain-machine interfaces.", "published": "2025-05-13 10:46:52", "link": "http://arxiv.org/abs/2505.08429v1", "categories": ["cs.CV", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "DHECA-SuperGaze: Dual Head-Eye Cross-Attention and Super-Resolution for Unconstrained Gaze Estimation", "abstract": "Unconstrained gaze estimation is the process of determining where a subject\nis directing their visual attention in uncontrolled environments. Gaze\nestimation systems are important for a myriad of tasks such as driver\ndistraction monitoring, exam proctoring, accessibility features in modern\nsoftware, etc. However, these systems face challenges in real-world scenarios,\npartially due to the low resolution of in-the-wild images and partially due to\ninsufficient modeling of head-eye interactions in current state-of-the-art\n(SOTA) methods. This paper introduces DHECA-SuperGaze, a deep learning-based\nmethod that advances gaze prediction through super-resolution (SR) and a dual\nhead-eye cross-attention (DHECA) module. Our dual-branch convolutional backbone\nprocesses eye and multiscale SR head images, while the proposed DHECA module\nenables bidirectional feature refinement between the extracted visual features\nthrough cross-attention mechanisms. Furthermore, we identified critical\nannotation errors in one of the most diverse and widely used gaze estimation\ndatasets, Gaze360, and rectified the mislabeled data. Performance evaluation on\nGaze360 and GFIE datasets demonstrates superior within-dataset performance of\nthe proposed method, reducing angular error (AE) by 0.48{\\deg} (Gaze360) and\n2.95{\\deg} (GFIE) in static configurations, and 0.59{\\deg} (Gaze360) and\n3.00{\\deg} (GFIE) in temporal settings compared to prior SOTA methods.\nCross-dataset testing shows improvements in AE of more than 1.53{\\deg}\n(Gaze360) and 3.99{\\deg} (GFIE) in both static and temporal settings,\nvalidating the robust generalization properties of our approach.", "published": "2025-05-13 10:45:08", "link": "http://arxiv.org/abs/2505.08426v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "abstract": "Facial recognition systems have achieved remarkable success by leveraging\ndeep neural networks, advanced loss functions, and large-scale datasets.\nHowever, their performance often deteriorates in real-world scenarios involving\nlow-quality facial images. Such degradations, common in surveillance footage or\nstandoff imaging include low resolution, motion blur, and various distortions,\nresulting in a substantial domain gap from the high-quality data typically used\nduring training. While existing approaches attempt to address robustness by\nmodifying network architectures or modeling global spatial transformations,\nthey frequently overlook local, non-rigid deformations that are inherently\npresent in real-world settings. In this work, we introduce DArFace, a\nDeformation-Aware robust Face recognition framework that enhances robustness to\nsuch degradations without requiring paired high- and low-quality training\nsamples. Our method adversarially integrates both global transformations (e.g.,\nrotation, translation) and local elastic deformations during training to\nsimulate realistic low-quality conditions. Moreover, we introduce a contrastive\nobjective to enforce identity consistency across different deformed views.\nExtensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and\nIJB-C demonstrate that DArFace surpasses state-of-the-art methods, with\nsignificant gains attributed to the inclusion of local deformation modeling.", "published": "2025-05-13 10:35:57", "link": "http://arxiv.org/abs/2505.08423v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An integrated language-vision foundation model for conversational diagnostics and triaging in primary eye care", "abstract": "Current deep learning models are mostly task specific and lack a\nuser-friendly interface to operate. We present Meta-EyeFM, a multi-function\nfoundation model that integrates a large language model (LLM) with vision\nfoundation models (VFMs) for ocular disease assessment. Meta-EyeFM leverages a\nrouting mechanism to enable accurate task-specific analysis based on text\nqueries. Using Low Rank Adaptation, we fine-tuned our VFMs to detect ocular and\nsystemic diseases, differentiate ocular disease severity, and identify common\nocular signs. The model achieved 100% accuracy in routing fundus images to\nappropriate VFMs, which achieved $\\ge$ 82.2% accuracy in disease detection,\n$\\ge$ 89% in severity differentiation, $\\ge$ 76% in sign identification.\nMeta-EyeFM was 11% to 43% more accurate than Gemini-1.5-flash and ChatGPT-4o\nLMMs in detecting various eye diseases and comparable to an ophthalmologist.\nThis system offers enhanced usability and diagnostic performance, making it a\nvaluable decision support tool for primary eye care or an online LLM for fundus\nevaluation.", "published": "2025-05-13 10:13:26", "link": "http://arxiv.org/abs/2505.08414v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "An incremental algorithm for non-convex AI-enhanced medical image processing", "abstract": "Solving non-convex regularized inverse problems is challenging due to their\ncomplex optimization landscapes and multiple local minima. However, these\nmodels remain widely studied as they often yield high-quality, task-oriented\nsolutions, particularly in medical imaging, where the goal is to enhance\nclinically relevant features rather than merely minimizing global error. We\npropose incDG, a hybrid framework that integrates deep learning with\nincremental model-based optimization to efficiently approximate the\n$\\ell_0$-optimal solution of imaging inverse problems. Built on the Deep Guess\nstrategy, incDG exploits a deep neural network to generate effective\ninitializations for a non-convex variational solver, which refines the\nreconstruction through regularized incremental iterations. This design combines\nthe efficiency of Artificial Intelligence (AI) tools with the theoretical\nguarantees of model-based optimization, ensuring robustness and stability. We\nvalidate incDG on TpV-regularized optimization tasks, demonstrating its\neffectiveness in medical image deblurring and tomographic reconstruction across\ndiverse datasets, including synthetic images, brain CT slices, and\nchest-abdomen scans. Results show that incDG outperforms both conventional\niterative solvers and deep learning-based methods, achieving superior accuracy\nand stability. Moreover, we confirm that training incDG without ground truth\ndoes not significantly degrade performance, making it a practical and powerful\ntool for solving non-convex inverse problems in imaging and beyond.", "published": "2025-05-13 08:03:14", "link": "http://arxiv.org/abs/2505.08324v1", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "Improving Unsupervised Task-driven Models of Ventral Visual Stream via Relative Position Predictivity", "abstract": "Based on the concept that ventral visual stream (VVS) mainly functions for\nobject recognition, current unsupervised task-driven methods model VVS by\ncontrastive learning, and have achieved good brain similarity. However, we\nbelieve functions of VVS extend beyond just object recognition. In this paper,\nwe introduce an additional function involving VVS, named relative position (RP)\nprediction. We first theoretically explain contrastive learning may be unable\nto yield the model capability of RP prediction. Motivated by this, we\nsubsequently integrate RP learning with contrastive learning, and propose a new\nunsupervised task-driven method to model VVS, which is more inline with\nbiological reality. We conduct extensive experiments, demonstrating that: (i)\nour method significantly improves downstream performance of object recognition\nwhile enhancing RP predictivity; (ii) RP predictivity generally improves the\nmodel brain similarity. Our results provide strong evidence for the involvement\nof VVS in location perception (especially RP prediction) from a computational\nperspective.", "published": "2025-05-13 07:45:21", "link": "http://arxiv.org/abs/2505.08316v1", "categories": ["cs.CE", "cs.CV"], "primary_category": "cs.CE"}
{"title": "Knowledge-Informed Deep Learning for Irrigation Type Mapping from Remote Sensing", "abstract": "Accurate mapping of irrigation methods is crucial for sustainable\nagricultural practices and food systems. However, existing models that rely\nsolely on spectral features from satellite imagery are ineffective due to the\ncomplexity of agricultural landscapes and limited training data, making this a\nchallenging problem. We present Knowledge-Informed Irrigation Mapping (KIIM), a\nnovel Swin-Transformer based approach that uses (i) a specialized projection\nmatrix to encode crop to irrigation probability, (ii) a spatial attention map\nto identify agricultural lands from non-agricultural lands, (iii)\nbi-directional cross-attention to focus complementary information from\ndifferent modalities, and (iv) a weighted ensemble for combining predictions\nfrom images and crop information. Our experimentation on five states in the US\nshows up to 22.9\\% (IoU) improvement over baseline with a 71.4% (IoU)\nimprovement for hard-to-classify drip irrigation. In addition, we propose a\ntwo-phase transfer learning approach to enhance cross-state irrigation mapping,\nachieving a 51% IoU boost in a state with limited labeled data. The ability to\nachieve baseline performance with only 40% of the training data highlights its\nefficiency, reducing the dependency on extensive manual labeling efforts and\nmaking large-scale, automated irrigation mapping more feasible and\ncost-effective.", "published": "2025-05-13 07:25:28", "link": "http://arxiv.org/abs/2505.08302v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments", "abstract": "State-space models (SSMs), particularly the Mamba architecture, have emerged\nas powerful alternatives to Transformers for sequence modeling, offering\nlinear-time complexity and competitive performance across diverse tasks.\nHowever, their large parameter counts pose significant challenges for\ndeployment in resource-constrained environments. We propose a novel\nunstructured pruning framework tailored for Mamba models that achieves up to\n70\\% parameter reduction while retaining over 95\\% of the original performance.\nOur approach integrates three key innovations: (1) a gradient-aware magnitude\npruning technique that combines weight magnitude and gradient information to\nidentify less critical parameters, (2) an iterative pruning schedule that\ngradually increases sparsity to maintain model stability, and (3) a global\npruning strategy that optimizes parameter allocation across the entire model.\nThrough extensive experiments on WikiText-103, Long Range Arena, and ETT\ntime-series benchmarks, we demonstrate significant efficiency gains with\nminimal performance degradation. Our analysis of pruning effects on Mamba's\ncomponents reveals critical insights into the architecture's redundancy and\nrobustness, enabling practical deployment in resource-constrained settings\nwhile broadening Mamba's applicability.", "published": "2025-05-13 07:23:08", "link": "http://arxiv.org/abs/2505.08299v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "FauForensics: Boosting Audio-Visual Deepfake Detection with Facial Action Units", "abstract": "The rapid evolution of generative AI has increased the threat of realistic\naudio-visual deepfakes, demanding robust detection methods. Existing solutions\nprimarily address unimodal (audio or visual) forgeries but struggle with\nmultimodal manipulations due to inadequate handling of heterogeneous modality\nfeatures and poor generalization across datasets. To this end, we propose a\nnovel framework called FauForensics by introducing biologically invariant\nfacial action units (FAUs), which is a quantitative descriptor of facial muscle\nactivity linked to emotion physiology. It serves as forgery-resistant\nrepresentations that reduce domain dependency while capturing subtle dynamics\noften disrupted in synthetic content. Besides, instead of comparing entire\nvideo clips as in prior works, our method computes fine-grained frame-wise\naudiovisual similarities via a dedicated fusion module augmented with learnable\ncross-modal queries. It dynamically aligns temporal-spatial lip-audio\nrelationships while mitigating multi-modal feature heterogeneity issues.\nExperiments on FakeAVCeleb and LAV-DF show state-of-the-art (SOTA) performance\nand superior cross-dataset generalizability with up to an average of 4.83\\%\nthan existing methods.", "published": "2025-05-13 07:18:07", "link": "http://arxiv.org/abs/2505.08294v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Disruptive Transformation of Artworks in Master-Disciple Relationships: The Case of Ukiyo-e Artworks", "abstract": "Artwork research has long relied on human sensibility and subjective\njudgment, but recent developments in machine learning have enabled the\nquantitative assessment of features that humans could not discover. In Western\npaintings, comprehensive analyses have been conducted from various perspectives\nin conjunction with large databases, but such extensive analysis has not been\nsufficiently conducted for Eastern paintings. Then, we focus on Ukiyo-e, a\ntraditional Japanese art form, as a case study of Eastern paintings, and\nconduct a quantitative analysis of creativity in works of art using 11,000\nhigh-resolution images. This involves using the concept of calculating\ncreativity from networks to analyze both the creativity of the artwork and that\nof the artists. As a result, In terms of Ukiyo-e as a whole, it was found that\nthe creativity of its appearance has declined with the maturation of culture,\nbut in terms of style, it has become more segmented with the maturation of\nculture and has maintained a high level of creativity. This not only provides\nnew insights into the study of Ukiyo-e but also shows how Ukiyo-e has evolved\nwithin the ongoing cultural history, playing a culturally significant role in\nthe analysis of Eastern art.", "published": "2025-05-13 06:55:53", "link": "http://arxiv.org/abs/2505.08284v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Decoupled Multimodal Prototypes for Visual Recognition with Missing Modalities", "abstract": "Multimodal learning enhances deep learning models by enabling them to\nperceive and understand information from multiple data modalities, such as\nvisual and textual inputs. However, most existing approaches assume the\navailability of all modalities, an assumption that often fails in real-world\napplications. Recent works have introduced learnable missing-case-aware prompts\nto mitigate performance degradation caused by missing modalities while reducing\nthe need for extensive model fine-tuning. Building upon the effectiveness of\nmissing-case-aware handling for missing modalities, we propose a novel\ndecoupled prototype-based output head, which leverages missing-case-aware\nclass-wise prototypes tailored for each individual modality. This approach\ndynamically adapts to different missing modality scenarios and can be\nseamlessly integrated with existing prompt-based methods. Extensive experiments\ndemonstrate that our proposed output head significantly improves performance\nacross a wide range of missing-modality scenarios and varying missing rates.", "published": "2025-05-13 06:53:37", "link": "http://arxiv.org/abs/2505.08283v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion", "abstract": "Existing multimodal large model-based image compression frameworks often rely\non a fragmented integration of semantic retrieval, latent compression, and\ngenerative models, resulting in suboptimal performance in both reconstruction\nfidelity and coding efficiency. To address these challenges, we propose a\nresidual-guided ultra lowrate image compression named ResULIC, which\nincorporates residual signals into both semantic retrieval and the\ndiffusion-based generation process. Specifically, we introduce Semantic\nResidual Coding (SRC) to capture the semantic disparity between the original\nimage and its compressed latent representation. A perceptual fidelity optimizer\nis further applied for superior reconstruction quality. Additionally, we\npresent the Compression-aware Diffusion Model (CDM), which establishes an\noptimal alignment between bitrates and diffusion time steps, improving\ncompression-reconstruction synergy. Extensive experiments demonstrate the\neffectiveness of ResULIC, achieving superior objective and subjective\nperformance compared to state-of-the-art diffusion-based methods with - 80.7%,\n-66.3% BD-rate saving in terms of LPIPS and FID. Project page is available at\nhttps: //njuvision.github.io/ResULIC/.", "published": "2025-05-13 06:51:23", "link": "http://arxiv.org/abs/2505.08281v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method Mapping", "abstract": "We introduce IrrMap, the first large-scale dataset (1.1 million patches) for\nirrigation method mapping across regions. IrrMap consists of multi-resolution\nsatellite imagery from LandSat and Sentinel, along with key auxiliary data such\nas crop type, land use, and vegetation indices. The dataset spans 1,687,899\nfarms and 14,117,330 acres across multiple western U.S. states from 2013 to\n2023, providing a rich and diverse foundation for irrigation analysis and\nensuring geospatial alignment and quality control. The dataset is ML-ready,\nwith standardized 224x224 GeoTIFF patches, the multiple input modalities,\ncarefully chosen train-test-split data, and accompanying dataloaders for\nseamless deep learning model training andbenchmarking in irrigation mapping.\nThe dataset is also accompanied by a complete pipeline for dataset generation,\nenabling researchers to extend IrrMap to new regions for irrigation data\ncollection or adapt it with minimal effort for other similar applications in\nagricultural and geospatial analysis. We also analyze the irrigation method\ndistribution across crop groups, spatial irrigation patterns (using Shannon\ndiversity indices), and irrigated area variations for both LandSat and\nSentinel, providing insights into regional and resolution-based differences. To\npromote further exploration, we openly release IrrMap, along with the derived\ndatasets, benchmark models, and pipeline code, through a GitHub repository:\nhttps://github.com/Nibir088/IrrMap and Data repository:\nhttps://huggingface.co/Nibir/IrrMap, providing comprehensive documentation and\nimplementation details.", "published": "2025-05-13 06:36:41", "link": "http://arxiv.org/abs/2505.08273v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Few-shot Novel Category Discovery", "abstract": "The recently proposed Novel Category Discovery (NCD) adapt paradigm of\ntransductive learning hinders its application in more real-world scenarios. In\nfact, few labeled data in part of new categories can well alleviate this\nburden, which coincides with the ease that people can label few of new category\ndata. Therefore, this paper presents a new setting in which a trained agent is\nable to flexibly switch between the tasks of identifying examples of known\n(labelled) classes and clustering novel (completely unlabeled) classes as the\nnumber of query examples increases by leveraging knowledge learned from only a\nfew (handful) support examples. Drawing inspiration from the discovery of novel\ncategories using prior-based clustering algorithms, we introduce a novel\nframework that further relaxes its assumptions to the real-world open set level\nby unifying the concept of model adaptability in few-shot learning. We refer to\nthis setting as Few-Shot Novel Category Discovery (FSNCD) and propose\nSemi-supervised Hierarchical Clustering (SHC) and Uncertainty-aware K-means\nClustering (UKC) to examine the model's reasoning capabilities. Extensive\nexperiments and detailed analysis on five commonly used datasets demonstrate\nthat our methods can achieve leading performance levels across different task\nsettings and scenarios.", "published": "2025-05-13 06:18:03", "link": "http://arxiv.org/abs/2505.08260v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CNN and ViT Efficiency Study on Tiny ImageNet and DermaMNIST Datasets", "abstract": "This study evaluates the trade-offs between convolutional and\ntransformer-based architectures on both medical and general-purpose image\nclassification benchmarks. We use ResNet-18 as our baseline and introduce a\nfine-tuning strategy applied to four Vision Transformer variants (Tiny, Small,\nBase, Large) on DermatologyMNIST and TinyImageNet. Our goal is to reduce\ninference latency and model complexity with acceptable accuracy degradation.\nThrough systematic hyperparameter variations, we demonstrate that appropriately\nfine-tuned Vision Transformers can match or exceed the baseline's performance,\nachieve faster inference, and operate with fewer parameters, highlighting their\nviability for deployment in resource-constrained environments.", "published": "2025-05-13 06:17:18", "link": "http://arxiv.org/abs/2505.08259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted", "abstract": "With the advancement of AI generative techniques, Deepfake faces have become\nincredibly realistic and nearly indistinguishable to the human eye. To counter\nthis, Deepfake detectors have been developed as reliable tools for assessing\nface authenticity. These detectors are typically developed on Deep Neural\nNetworks (DNNs) and trained using third-party datasets. However, this protocol\nraises a new security risk that can seriously undermine the trustfulness of\nDeepfake detectors: Once the third-party data providers insert poisoned\n(corrupted) data maliciously, Deepfake detectors trained on these datasets will\nbe injected ``backdoors'' that cause abnormal behavior when presented with\nsamples containing specific triggers. This is a practical concern, as\nthird-party providers may distribute or sell these triggers to malicious users,\nallowing them to manipulate detector performance and escape accountability.\n  This paper investigates this risk in depth and describes a solution to\nstealthily infect Deepfake detectors. Specifically, we develop a trigger\ngenerator, that can synthesize passcode-controlled, semantic-suppression,\nadaptive, and invisible trigger patterns, ensuring both the stealthiness and\neffectiveness of these triggers. Then we discuss two poisoning scenarios,\ndirty-label poisoning and clean-label poisoning, to accomplish the injection of\nbackdoors. Extensive experiments demonstrate the effectiveness, stealthiness,\nand practicality of our method compared to several baselines.", "published": "2025-05-13 06:09:34", "link": "http://arxiv.org/abs/2505.08255v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "Skeleton-Guided Diffusion Model for Accurate Foot X-ray Synthesis in Hallux Valgus Diagnosis", "abstract": "Medical image synthesis plays a crucial role in providing anatomically\naccurate images for diagnosis and treatment. Hallux valgus, which affects\napproximately 19% of the global population, requires frequent weight-bearing\nX-rays for assessment, placing additional strain on both patients and\nhealthcare providers. Existing X-ray models often struggle to balance image\nfidelity, skeletal consistency, and physical constraints, particularly in\ndiffusion-based methods that lack skeletal guidance. We propose the\nSkeletal-Constrained Conditional Diffusion Model (SCCDM) and introduce KCC, a\nfoot evaluation method utilizing skeletal landmarks. SCCDM incorporates\nmulti-scale feature extraction and attention mechanisms, improving the\nStructural Similarity Index (SSIM) by 5.72% (0.794) and Peak Signal-to-Noise\nRatio (PSNR) by 18.34% (21.40 dB). When combined with KCC, the model achieves\nan average score of 0.85, demonstrating strong clinical applicability. The code\nis available at https://github.com/midisec/SCCDM.", "published": "2025-05-13 05:57:15", "link": "http://arxiv.org/abs/2505.08247v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Identifying Memorization of Diffusion Models through p-Laplace Analysis", "abstract": "Diffusion models, today's leading image generative models, estimate the score\nfunction, i.e. the gradient of the log probability of (perturbed) data samples,\nwithout direct access to the underlying probability distribution. This work\ninvestigates whether the estimated score function can be leveraged to compute\nhigher-order differentials, namely p-Laplace operators. We show here these\noperators can be employed to identify memorized training data. We propose a\nnumerical p-Laplace approximation based on the learned score functions, showing\nits effectiveness in identifying key features of the probability landscape. We\nanalyze the structured case of Gaussian mixture models, and demonstrate the\nresults carry-over to image generative models, where memorization\nidentification based on the p-Laplace operator is performed for the first time.", "published": "2025-05-13 05:52:15", "link": "http://arxiv.org/abs/2505.08246v1", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "Congenital Heart Disease recognition using Deep Learning/Transformer models", "abstract": "Congenital Heart Disease (CHD) remains a leading cause of infant morbidity\nand mortality, yet non-invasive screening methods often yield false negatives.\nDeep learning models, with their ability to automatically extract features, can\nassist doctors in detecting CHD more effectively. In this work, we investigate\nthe use of dual-modality (sound and image) deep learning methods for CHD\ndiagnosis. We achieve 73.9% accuracy on the ZCHSound dataset and 80.72%\naccuracy on the DICOM Chest X-ray dataset.", "published": "2025-05-13 05:34:06", "link": "http://arxiv.org/abs/2505.08242v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ACT-R: Adaptive Camera Trajectories for 3D Reconstruction from Single Image", "abstract": "We introduce adaptive view planning to multi-view synthesis, aiming to\nimprove both occlusion revelation and 3D consistency for single-view 3D\nreconstruction. Instead of generating an unordered set of views independently\nor simultaneously, we generate a sequence of views, leveraging temporal\nconsistency to enhance 3D coherence. Most importantly, our view sequence is not\ndetermined by a pre-determined camera setup. Instead, we compute an adaptive\ncamera trajectory (ACT), specifically, an orbit of camera views, which\nmaximizes the visibility of occluded regions of the 3D object to be\nreconstructed. Once the best orbit is found, we feed it to a video diffusion\nmodel to generate novel views around the orbit, which in turn, are passed to a\nmulti-view 3D reconstruction model to obtain the final reconstruction. Our\nmulti-view synthesis pipeline is quite efficient since it involves no run-time\ntraining/optimization, only forward inferences by applying the pre-trained\nmodels for occlusion analysis and multi-view synthesis. Our method predicts\ncamera trajectories that reveal occlusions effectively and produce consistent\nnovel views, significantly improving 3D reconstruction over SOTA on the unseen\nGSO dataset, both quantitatively and qualitatively.", "published": "2025-05-13 05:31:59", "link": "http://arxiv.org/abs/2505.08239v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "EventDiff: A Unified and Efficient Diffusion Model Framework for Event-based Video Frame Interpolation", "abstract": "Video Frame Interpolation (VFI) is a fundamental yet challenging task in\ncomputer vision, particularly under conditions involving large motion,\nocclusion, and lighting variation. Recent advancements in event cameras have\nopened up new opportunities for addressing these challenges. While existing\nevent-based VFI methods have succeeded in recovering large and complex motions\nby leveraging handcrafted intermediate representations such as optical flow,\nthese designs often compromise high-fidelity image reconstruction under subtle\nmotion scenarios due to their reliance on explicit motion modeling. Meanwhile,\ndiffusion models provide a promising alternative for VFI by reconstructing\nframes through a denoising process, eliminating the need for explicit motion\nestimation or warping operations. In this work, we propose EventDiff, a unified\nand efficient event-based diffusion model framework for VFI. EventDiff features\na novel Event-Frame Hybrid AutoEncoder (HAE) equipped with a lightweight\nSpatial-Temporal Cross Attention (STCA) module that effectively fuses dynamic\nevent streams with static frames. Unlike previous event-based VFI methods,\nEventDiff performs interpolation directly in the latent space via a denoising\ndiffusion process, making it more robust across diverse and challenging VFI\nscenarios. Through a two-stage training strategy that first pretrains the HAE\nand then jointly optimizes it with the diffusion model, our method achieves\nstate-of-the-art performance across multiple synthetic and real-world event VFI\ndatasets. The proposed method outperforms existing state-of-the-art event-based\nVFI methods by up to 1.98dB in PSNR on Vimeo90K-Triplet and shows superior\nperformance in SNU-FILM tasks with multiple difficulty levels. Compared to the\nemerging diffusion-based VFI approach, our method achieves up to 5.72dB PSNR\ngain on Vimeo90K-Triplet and 4.24X faster inference.", "published": "2025-05-13 05:25:58", "link": "http://arxiv.org/abs/2505.08235v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition", "abstract": "This paper presents G-MSGINet, a unified and efficient framework for robust\ncontactless fingerprint recognition that jointly performs minutiae localization\nand identity embedding directly from raw input images. Existing approaches rely\non multi-branch architectures, orientation labels, or complex preprocessing\nsteps, which limit scalability and generalization across real-world acquisition\nscenarios. In contrast, the proposed architecture introduces the GMSGI layer, a\nnovel computational module that integrates grouped pixel-level involution,\ndynamic multi-scale kernel generation, and graph-based relational modelling\ninto a single processing unit. Stacked GMSGI layers progressively refine both\nlocal minutiae-sensitive features and global topological representations\nthrough end-to-end optimization. The architecture eliminates explicit\norientation supervision and adapts graph connectivity directly from learned\nkernel descriptors, thereby capturing meaningful structural relationships among\nfingerprint regions without fixed heuristics. Extensive experiments on three\nbenchmark datasets, namely PolyU, CFPose, and Benchmark 2D/3D, demonstrate that\nG-MSGINet consistently achieves minutiae F1-scores in the range of\n$0.83\\pm0.02$ and Rank-1 identification accuracies between 97.0% and 99.1%,\nwhile maintaining an Equal Error Rate (EER) as low as 0.5%. These results\ncorrespond to improvements of up to 4.8% in F1-score and 1.4% in Rank-1\naccuracy when compared to prior methods, using only 0.38 million parameters and\n6.63 giga floating-point operations, which represents up to ten times fewer\nparameters than competitive baselines. This highlights the scalability and\neffectiveness of G-MSGINet in real-world contactless biometric recognition\nscenarios.", "published": "2025-05-13 05:24:24", "link": "http://arxiv.org/abs/2505.08233v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HMPNet: A Feature Aggregation Architecture for Maritime Object Detection from a Shipborne Perspective", "abstract": "In the realm of intelligent maritime navigation, object detection from a\nshipborne perspective is paramount. Despite the criticality, the paucity of\nmaritime-specific data impedes the deployment of sophisticated visual\nperception techniques, akin to those utilized in autonomous vehicular systems,\nwithin the maritime context. To bridge this gap, we introduce Navigation12, a\nnovel dataset annotated for 12 object categories under diverse maritime\nenvironments and weather conditions. Based upon this dataset, we propose\nHMPNet, a lightweight architecture tailored for shipborne object detection.\nHMPNet incorporates a hierarchical dynamic modulation backbone to bolster\nfeature aggregation and expression, complemented by a matrix cascading\npoly-scale neck and a polymerization weight sharing detector, facilitating\nefficient multi-scale feature aggregation. Empirical evaluations indicate that\nHMPNet surpasses current state-of-the-art methods in terms of both accuracy and\ncomputational efficiency, realizing a 3.3% improvement in mean Average\nPrecision over YOLOv11n, the prevailing model, and reducing parameters by 23%.", "published": "2025-05-13 05:17:53", "link": "http://arxiv.org/abs/2505.08231v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Watermarking in the Era of Diffusion Models: Advances and Challenges", "abstract": "As generative artificial intelligence technologies like Stable Diffusion\nadvance, visual content becomes more vulnerable to misuse, raising concerns\nabout copyright infringement. Visual watermarks serve as effective protection\nmechanisms, asserting ownership and deterring unauthorized use. Traditional\ndeepfake detection methods often rely on passive techniques that struggle with\nsophisticated manipulations. In contrast, diffusion models enhance detection\naccuracy by allowing for the effective learning of features, enabling the\nembedding of imperceptible and robust watermarks. We analyze the strengths and\nchallenges of watermark techniques related to diffusion models, focusing on\ntheir robustness and application in watermark generation. By exploring the\nintegration of advanced diffusion models and watermarking security, we aim to\nadvance the discourse on preserving watermark robustness against evolving\nforgery threats. It emphasizes the critical importance of developing innovative\nsolutions to protect digital content and ensure the preservation of ownership\nrights in the era of generative AI.", "published": "2025-05-13 03:14:18", "link": "http://arxiv.org/abs/2505.08197v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ADC-GS: Anchor-Driven Deformable and Compressed Gaussian Splatting for Dynamic Scene Reconstruction", "abstract": "Existing 4D Gaussian Splatting methods rely on per-Gaussian deformation from\na canonical space to target frames, which overlooks redundancy among adjacent\nGaussian primitives and results in suboptimal performance. To address this\nlimitation, we propose Anchor-Driven Deformable and Compressed Gaussian\nSplatting (ADC-GS), a compact and efficient representation for dynamic scene\nreconstruction. Specifically, ADC-GS organizes Gaussian primitives into an\nanchor-based structure within the canonical space, enhanced by a temporal\nsignificance-based anchor refinement strategy. To reduce deformation\nredundancy, ADC-GS introduces a hierarchical coarse-to-fine pipeline that\ncaptures motions at varying granularities. Moreover, a rate-distortion\noptimization is adopted to achieve an optimal balance between bitrate\nconsumption and representation fidelity. Experimental results demonstrate that\nADC-GS outperforms the per-Gaussian deformation approaches in rendering speed\nby 300%-800% while achieving state-of-the-art storage efficiency without\ncompromising rendering quality. The code is released at\nhttps://github.com/H-Huang774/ADC-GS.git.", "published": "2025-05-13 03:13:40", "link": "http://arxiv.org/abs/2505.08196v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpNeRF: Memory Efficient Sparse Volumetric Neural Rendering Accelerator for Edge Devices", "abstract": "Neural rendering has gained prominence for its high-quality output, which is\ncrucial for AR/VR applications. However, its large voxel grid data size and\nirregular access patterns challenge real-time processing on edge devices. While\nprevious works have focused on improving data locality, they have not\nadequately addressed the issue of large voxel grid sizes, which necessitate\nfrequent off-chip memory access and substantial on-chip memory. This paper\nintroduces SpNeRF, a software-hardware co-design solution tailored for sparse\nvolumetric neural rendering. We first identify memory-bound rendering\ninefficiencies and analyze the inherent sparsity in the voxel grid data of\nneural rendering. To enhance efficiency, we propose novel preprocessing and\nonline decoding steps, reducing the memory size for voxel grid. The\npreprocessing step employs hash mapping to support irregular data access while\nmaintaining a minimal memory size. The online decoding step enables efficient\non-chip sparse voxel grid processing, incorporating bitmap masking to mitigate\nPSNR loss caused by hash collisions. To further optimize performance, we design\na dedicated hardware architecture supporting our sparse voxel grid processing\ntechnique. Experimental results demonstrate that SpNeRF achieves an average\n21.07$\\times$ reduction in memory size while maintaining comparable PSNR\nlevels. When benchmarked against Jetson XNX, Jetson ONX, RT-NeRF.Edge and\nNeuRex.Edge, our design achieves speedups of 95.1$\\times$, 63.5$\\times$,\n1.5$\\times$ and 10.3$\\times$, and improves energy efficiency by 625.6$\\times$,\n529.1$\\times$, 4$\\times$, and 4.4$\\times$, respectively.", "published": "2025-05-13 03:00:58", "link": "http://arxiv.org/abs/2505.08191v1", "categories": ["cs.AR", "cs.CV"], "primary_category": "cs.AR"}
{"title": "Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models", "abstract": "Raindrop removal is a challenging task in image processing. Removing\nraindrops while relying solely on a single image further increases the\ndifficulty of the task. Common approaches include the detection of raindrop\nregions in the image, followed by performing a background restoration process\nconditioned on those regions. While various methods can be applied for the\ndetection step, the most common architecture used for background restoration is\nthe Generative Adversarial Network (GAN). Recent advances in the use of\ndiffusion models have led to state-of-the-art image inpainting techniques. In\nthis paper, we introduce a novel technique for raindrop removal from a single\nimage using diffusion-based image inpainting.", "published": "2025-05-13 03:00:01", "link": "http://arxiv.org/abs/2505.08190v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Monocular Depth Guided Occlusion-Aware Disparity Refinement via Semi-supervised Learning in Laparoscopic Images", "abstract": "Occlusion and the scarcity of labeled surgical data are significant\nchallenges in disparity estimation for stereo laparoscopic images. To address\nthese issues, this study proposes a Depth Guided Occlusion-Aware Disparity\nRefinement Network (DGORNet), which refines disparity maps by leveraging\nmonocular depth information unaffected by occlusion. A Position Embedding (PE)\nmodule is introduced to provide explicit spatial context, enhancing the\nnetwork's ability to localize and refine features. Furthermore, we introduce an\nOptical Flow Difference Loss (OFDLoss) for unlabeled data, leveraging temporal\ncontinuity across video frames to improve robustness in dynamic surgical\nscenes. Experiments on the SCARED dataset demonstrate that DGORNet outperforms\nstate-of-the-art methods in terms of End-Point Error (EPE) and Root Mean\nSquared Error (RMSE), particularly in occlusion and texture-less regions.\nAblation studies confirm the contributions of the Position Embedding and\nOptical Flow Difference Loss, highlighting their roles in improving spatial and\ntemporal consistency. These results underscore DGORNet's effectiveness in\nenhancing disparity estimation for laparoscopic surgery, offering a practical\nsolution to challenges in disparity estimation and data limitations.", "published": "2025-05-13 02:29:56", "link": "http://arxiv.org/abs/2505.08178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification", "abstract": "Causal inference has emerged as a promising approach to mitigate long-tail\nclassification by handling the biases introduced by class imbalance. However,\nalong with the change of advanced backbone models from Convolutional Neural\nNetworks (CNNs) to Visual Transformers (ViT), existing causal models may not\nachieve an expected performance gain. This paper investigates the influence of\nexisting causal models on CNNs and ViT variants, highlighting that ViT's global\nfeature representation makes it hard for causal methods to model associations\nbetween fine-grained features and predictions, which leads to difficulties in\nclassifying tail classes with similar visual appearance. To address these\nissues, this paper proposes TSCNet, a two-stage causal modeling method to\ndiscover fine-grained causal associations through multi-scale causal\ninterventions. Specifically, in the hierarchical causal representation learning\nstage (HCRL), it decouples the background and objects, applying backdoor\ninterventions at both the patch and feature level to prevent model from using\nclass-irrelevant areas to infer labels which enhances fine-grained causal\nrepresentation. In the counterfactual logits bias calibration stage (CLBC), it\nrefines the optimization of model's decision boundary by adaptive constructing\ncounterfactual balanced data distribution to remove the spurious associations\nin the logits caused by data distribution. Extensive experiments conducted on\nvarious long-tail benchmarks demonstrate that the proposed TSCNet can eliminate\nmultiple biases introduced by data imbalance, which outperforms existing\nmethods.", "published": "2025-05-13 02:23:55", "link": "http://arxiv.org/abs/2505.08173v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoKD: Multi-Task Optimization for Knowledge Distillation", "abstract": "Compact models can be effectively trained through Knowledge Distillation\n(KD), a technique that transfers knowledge from larger, high-performing teacher\nmodels. Two key challenges in Knowledge Distillation (KD) are: 1) balancing\nlearning from the teacher's guidance and the task objective, and 2) handling\nthe disparity in knowledge representation between teacher and student models.\nTo address these, we propose Multi-Task Optimization for Knowledge Distillation\n(MoKD). MoKD tackles two main gradient issues: a) Gradient Conflicts, where\ntask-specific and distillation gradients are misaligned, and b) Gradient\nDominance, where one objective's gradient dominates, causing imbalance. MoKD\nreformulates KD as a multi-objective optimization problem, enabling better\nbalance between objectives. Additionally, it introduces a subspace learning\nframework to project feature representations into a high-dimensional space,\nimproving knowledge transfer. Our MoKD is demonstrated to outperform existing\nmethods through extensive experiments on image classification using the\nImageNet-1K dataset and object detection using the COCO dataset, achieving\nstate-of-the-art performance with greater efficiency. To the best of our\nknowledge, MoKD models also achieve state-of-the-art performance compared to\nmodels trained from scratch.", "published": "2025-05-13 02:13:39", "link": "http://arxiv.org/abs/2505.08170v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Isolation Forest in Novelty Detection Scenario", "abstract": "Data mining offers a diverse toolbox for extracting meaningful structures\nfrom complex datasets, with anomaly detection emerging as a critical subfield\nparticularly in the context of streaming or real-time data. Within anomaly\ndetection, novelty detection focuses on identifying previously unseen patterns\nafter training solely on regular data. While classic algorithms such as\nOne-Class SVM or Local Outlier Factor (LOF) have been widely applied, they\noften lack interpretability and scalability. In this work, we explore the\nHalf-Space Tree (HST) algorithm, originally proposed for streaming anomaly\ndetection, and propose a novel theoretical modification to adapt it\nspecifically for novelty detection tasks. Our approach is grounded in the idea\nthat anomalies i.e., novelties tend to appear in the higher leaves of the tree,\nwhich are less frequently visited by regular instances. We analytically\ndemonstrate the effectiveness of this approach using probabilistic analysis,\nexpected depth (EXD) calculations, and combinatorial reasoning. A comparative\nanalysis of expected depths between our modified HST and the original Isolation\nForest highlights that novelty points are significantly more isolated in our\napproach. This supports the hypothesis that HSTs, with appropriate structural\nadaptation, can serve as interpretable and efficient novelty detectors. The\npaper contributes a theoretical foundation and supporting analysis for this\nadaptation, setting the stage for further application and experimentation.", "published": "2025-05-13 12:21:53", "link": "http://arxiv.org/abs/2505.08489v1", "categories": ["cs.LG", "cs.DM"], "primary_category": "cs.LG"}
{"title": "Interest Changes: Considering User Interest Life Cycle in Recommendation System", "abstract": "In recommendation systems, user interests are always in a state of constant\nflux. Typically, a user interest experiences a emergent phase, a stable phase,\nand a declining phase, which are referred to as the \"user interest life-cycle\".\nRecent papers on user interest modeling have primarily focused on how to\ncompute the correlation between the target item and user's historical\nbehaviors, without thoroughly considering the life-cycle features of user\ninterest. In this paper, we propose an effective method called Deep Interest\nLife-cycle Network (DILN), which not only captures the interest life-cycle\nfeatures efficiently, but can also be easily integrated to existing ranking\nmodels. DILN contains two key components: Interest Life-cycle Encoder Module\nconstructs historical activity histograms of the user interest and then encodes\nthem into dense representation. Interest Life-cycle Fusion Module injects the\nencoded dense representation into multiple expert networks, with the aim of\nenabling the specific phase of interest life-cycle to activate distinct\nexperts. Online A/B testing reveals that DILN achieves significant improvements\nof +0.38% in CTR, +1.04% in CVR and +0.25% in duration per user, which\ndemonstrates its effectiveness. In addition, DILN inherently increase the\nexposure of users' emergent and stable interests while decreasing the exposure\nof declining interests. DILN has been deployed on the Lofter App.", "published": "2025-05-13 11:53:26", "link": "http://arxiv.org/abs/2505.08471v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Lost in Transliteration: Bridging the Script Gap in Neural IR", "abstract": "Most human languages use scripts other than the Latin alphabet. Search users\nin these languages often formulate their information needs in a transliterated\n-- usually Latinized -- form for ease of typing. For example, Greek speakers\nmight use Greeklish, and Arabic speakers might use Arabizi. This paper shows\nthat current search systems, including those that use multilingual dense\nembeddings such as BGE-M3, do not generalise to this setting, and their\nperformance rapidly deteriorates when exposed to transliterated queries. This\ncreates a ``script gap\" between the performance of the same queries when\nwritten in their native or transliterated form. We explore whether adapting the\npopular ``translate-train\" paradigm to transliterations can enhance the\nrobustness of multilingual Information Retrieval (IR) methods and bridge the\ngap between native and transliterated scripts. By exploring various\ncombinations of non-Latin and Latinized query text for training, we investigate\nwhether we can enhance the capacity of existing neural retrieval techniques and\nenable them to apply to this important setting. We show that by further\nfine-tuning IR models on an even mixture of native and Latinized text, they can\nperform this cross-script matching at nearly the same performance as when the\nquery was formulated in the native script. Out-of-domain evaluation and further\nqualitative analysis show that transliterations can also cause queries to lose\nsome of their nuances, motivating further research in this direction.", "published": "2025-05-13 10:09:51", "link": "http://arxiv.org/abs/2505.08411v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "TikTok Search Recommendations: Governance and Research Challenges", "abstract": "Like other social media, TikTok is embracing its use as a search engine,\ndeveloping search products to steer users to produce searchable content and\nengage in content discovery. Their recently developed product search\nrecommendations are preformulated search queries recommended to users on\nvideos. However, TikTok provides limited transparency about how search\nrecommendations are generated and moderated, despite requirements under\nregulatory frameworks like the European Union's Digital Services Act. By\nsuggesting that the platform simply aggregates comments and common searches\nlinked to videos, it sidesteps responsibility and issues that arise from\ncontextually problematic recommendations, reigniting long-standing concerns\nabout platform liability and moderation. This position paper addresses the\nnovelty of search recommendations on TikTok by highlighting the challenges that\nthis feature poses for platform governance and offering a computational\nresearch agenda, drawing on preliminary qualitative analysis. It sets out the\nneed for transparency in platform documentation, data access and research to\nstudy search recommendations.", "published": "2025-05-13 09:32:09", "link": "http://arxiv.org/abs/2505.08385v1", "categories": ["cs.IR", "cs.CY"], "primary_category": "cs.IR"}
{"title": "Dual-UAV-Enabled Secure Communication and Sensing for A2G-ISAC Systems with Maneuverable Jamming", "abstract": "In this paper, we propose a dual-unmanned aerial vehicle (UAV)-enabled secure\ncommunication and sensing (SCS) scheme for an air-to-ground integrated sensing\nand communication (ISAC) system, in which a dual-functional source UAV and\njamming UAV collaborate to enhance both the secure communication and target\nsensing performance. From a perspective of hybrid monostatitc-bistatic radar,\nthe jamming UAV maneuvers to aid the source UAV to detect multiple ground\ntargets by emitting artificial noise, meanwhile interfering with the ground\neavesdropper. Residual interference is considered to reflect the effects of\nimperfect successive interference cancellation (SIC) on the receive\nsignal-plus-interference-to-noise ratios, which results in a degraded system\nperformance. To maximize the average secrecy rate (ASR), the dual-UAV\ntrajectory and dual-UAV beamforming are jointly optimized subject to the\ntransmit power budget, UAV maneuvering constraint, and sensing requirements. To\ntackle the highly complicated non-convex ASR maximization problem, the dual-UAV\ntrajectory and dual-UAV beamforming are optimized for the secure communication\n(SC) purpose and the SCS purpose, sequentially. In the SC phase, a block\ncoordinate descent algorithm is proposed to optimize the dual-UAV trajectory\nand dual-UAV beamforming iteratively, using the trust-region successive convex\napproximation (SCA) and semidefinite relaxation (SDR) techniques. Then, a\nweighted distance minimization problem is formulated to determine the dual-UAV\nmaneuvering positions suitable for the SCS purpose, which is solved by a\nheuristic greedy algorithm, followed by the joint optimization of source\nbeamforming and jamming beamforming.", "published": "2025-05-13 12:55:34", "link": "http://arxiv.org/abs/2505.08523v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the hull-variation problem of equivalent vector rank metric codes", "abstract": "The intersection of a linear code with its dual is called the hull of the\ncode. It is known that, for classical linear codes under the Hamming metric,\nthe dimension of the hull can be reduced up to equivalence. This phenomenon\nleads to the so-called hull-variation problem formulated by Hao Chen in 2023.\nIn this paper, we consider the analogous problem for vector rank metric codes,\nalong with their associated matrix codes and extended block codes. We also\ndiscuss the implications in the context of $(q,m)$-polymatroids.", "published": "2025-05-13 12:37:07", "link": "http://arxiv.org/abs/2505.08506v1", "categories": ["cs.IT", "math.CO", "math.IT", "94B05"], "primary_category": "cs.IT"}
{"title": "On lattice tilings of $\\mathbb{Z}^n$ by limited magnitude error balls $\\mathcal{B}(n,2,k_{1},k_{2})$ with $k_1>k_2$", "abstract": "Lattice tilings of $\\mathbb{Z}^n$ by limited-magnitude error balls correspond\nto linear perfect codes under such error models and play a crucial role in\nflash memory applications. In this work, we establish three main results.\nFirst, we fully determine the existence of lattice tilings by\n$\\mathcal{B}(n,2,3,0)$ in all dimensions $n$. Second, we completely resolve the\ncase $k_1=k_2+1$. Finally, we prove that for any integers $k_1>k_2\\ge0$ where\n$k_1+k_2+1$ is composite, no lattice tiling of $\\mathbb{Z}^n$ by the error ball\n$\\mathcal{B}(n,2,k_1,k_2)$ exists for sufficiently large $n$.", "published": "2025-05-13 12:24:08", "link": "http://arxiv.org/abs/2505.08495v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Low-complexity Detection for Noncoherent Massive MIMO Communications", "abstract": "This work studies a point-to-point MIMO uplink in which user equipment\ntransmits data to a base station equipped with a massive array. Signal\ndetection is noncoherent and fading is assumed to follow the Weichselberger\nmodel. By exploiting the spatial stationarity of fading at the base station, a\ncyclostationary structure emerges naturally in the space-time representation,\nwhich suggests formulating the statistical properties of the received signal in\nthe Karhunen-Lo\\`eve domain. This allows the derivation of a low-complexity\nreceiver that approximates maximum likelihood detection even for a moderate\narray size. The spectral analysis of the problem provides valuable insights on\nthe design of space-time codewords.", "published": "2025-05-13 10:52:18", "link": "http://arxiv.org/abs/2505.08432v1", "categories": ["cs.IT", "eess.SP", "math.IT", "94A13"], "primary_category": "cs.IT"}
{"title": "On the Average Secrecy Performance of Satellite Networks in Short Packet Communication Systems", "abstract": "This paper investigates the secrecy performance of satellite networks in\nshort packet communication systems under shadowed Rician fading (SRF). We\nderive a lower bound on the average achievable secrecy rate in the finite\nblocklength regime (FBL) and provide analytical insights into the impact of key\nsecrecy-related performance indicators (KPIs). Monte Carlo simulations validate\nthe theoretical framework, and demonstrate that increasing the blocklength and\nimproving the legitimate receiver's signal-to-noise ratio (SNR) enhance\nsecrecy, while a stronger eavesdropper degrades it. Additionally, we show that\ndirectional antenna patterns can effectively reduce information leakage and\nprovide secure satellite communications in the short packet regime. These\nfindings offer valuable guidance for designing secure and efficient\nsatellite-based communication systems, particularly in IoT and space-based\nnetworks.", "published": "2025-05-13 10:07:38", "link": "http://arxiv.org/abs/2505.08407v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Closed-Form Information Capacity of Canonical Signaling Models", "abstract": "We employ a unified framework for computing the information capacity of\nbiological signaling systems using Fisher Information. By deriving closed-form\nor easily computable information capacity formulas, we quantify how well\ndifferent signaling models, including binomial, multinomial, Poisson, Gaussian,\nand Gamma distributions, can discriminate among input signals. These\nexpressions clarify how key features such as signal range, noise scaling,\npathway length, and receivers' diversity shape the theoretical limits of\nsensing. In particular, we show how signal-to-noise ratio and fold-change\nsensitivity arise naturally within the Fisher formalism, and how signal\ndegradation in cascades imposes linear information loss. Our results provide\nintuitive, analytically grounded tools to benchmark and guide the analysis of\nreal signaling systems, without requiring computationally expensive mutual\ninformation estimation. While motivated by cellular communication, the\nframework generalizes to any system where noisy input-output relationships\nconstrain transmission fidelity, including synthetic biology, sensor networks,\nand engineered communication channels.", "published": "2025-05-13 09:11:44", "link": "http://arxiv.org/abs/2505.08365v1", "categories": ["q-bio.QM", "cs.IT", "math.IT", "stat.AP"], "primary_category": "q-bio.QM"}
{"title": "Lorentzian-Constrained Holographic Beamforming Optimization in Multi-user Networks with Dynamic Metasurface Antennas", "abstract": "Dynamic metasurface antennas (DMAs) are promising alternatives to fully\ndigital (FD) architectures, enabling hybrid beamforming via low-cost\nreconfigurable metasurfaces. In DMAs, holographic beamforming is achieved\nthrough tunable elements by Lorentzian-constrained holography (LCH),\nsignificantly reducing the need for radio-frequency (RF) chains and analog\ncircuitry. However, the Lorentzian constraints and limited RF chains introduce\na trade-off between reduced system complexity and beamforming performance,\nespecially in dense network scenarios. This paper addresses resource allocation\nin multi-user multiple-input-single-output (MISO) networks under the\nSignal-to-Interference-plus-Noise Ratio (SINR) constraints, aiming to minimize\ntotal transmit power. We propose a holographic beamforming algorithm based on\nthe Generalized Method of Lorentzian-Constrained Holography (GMLCH), which\noptimizes DMA weights, yielding flexibility for using various LCH techniques to\ntackle the aforementioned trade-offs. Building upon GMLCH, we further propose a\nnew algorithm, Adaptive Radius Lorentzian Constrained Holography (ARLCH), which\nachieves optimization of DMA weights with additional degree of freedom in a\ngreater optimization space, and provides lower transmitted power, while\nimproving scalability for higher number of users. Numerical results show that\nARLCH reduces power consumption by over 20% compared to benchmarks, with\nincreasing effectiveness as the number of users grows.", "published": "2025-05-13 08:58:23", "link": "http://arxiv.org/abs/2505.08356v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Coding Theorem for Generalized Reed-Solomon Codes", "abstract": "In this paper, we prove that the sub-field images of generalized Reed-Solomon\n(RS) codes can achieve the symmetric capacity of p-ary memoryless channels.\nUnlike the totally random linear code ensemble, as a class of maximum distance\nseparable (MDS) codes, the generalized RS code ensemble lacks the pair-wise\nindependence among codewords and has non-identical distributions of nonzero\ncodewords. To prove the coding theorem for the p-ary images of generalized RS\ncodes, we analyze the exponential upper bound on the error probability of the\ngeneralized RS code in terms of its spectrum using random coding techniques. In\nthe finite-length region, we present an ML decoding algorithm for the\ngeneralized RS codes over the binary erasure channels (BECs). In particular,\nthe algebraic structure of the generalized RS codes allows us to implement the\nparallel Lagrange interpolation to derive an ordered systematic matrix.\nSubsequently, we can reconstruct the ML codeword through a change of basis,\naccelerating the conventional Gaussian elimination (GE), as validated in the\nsimulation results. Additionally, we apply this decoding technique to the\nLC-OSD algorithm over the additive white Gaussian noise (AWGN) channels with\nbinary phase shift keying (BPSK) modulation and three-level pulse amplitude\nmodulation (3PAM). Simulation results show that, in the high-rate region,\ngeneralized RS codes defined over fields of characteristic three with 3-PAM\nperform better than those defined over fields of characteristic two with BPSK.", "published": "2025-05-13 08:05:41", "link": "http://arxiv.org/abs/2505.08326v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Uniform Universal Sets, Splitters, and Bisectors", "abstract": "Given a subset of size $k$ of a very large universe a randomized way to find\nthis subset could consist of deleting half of the universe and then searching\nthe remaining part. With a probability of $2^{-k}$ one will succeed. By\nprobability amplification, a randomized algorithm needs about $2^k$ rounds\nuntil it succeeds. We construct bisectors that derandomize this process and\nhave size~$2^{k+o(k)}$. One application is derandomization of reductions\nbetween average case complexity classes. We also construct uniform\n$(n,k)$-universal sets that generalize universal sets in such a way that they\nare bisectors at the same time. This construction needs only linear time and\nproduces families of asymptotically optimal size without using advanced\ncombinatorial constructions as subroutines, which previous families did, but\nare basedmainly on modulo functions and refined brute force search.", "published": "2025-05-13 07:35:07", "link": "http://arxiv.org/abs/2505.08308v1", "categories": ["cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.DS"}
{"title": "On Analysis of Superimposed Pilot in Multi-User Massive MIMO with Massive Connectivity", "abstract": "The simultaneous transmission of numerous users presents substantial\nchallenges due to the inherent trade-off between channel estimation and\ninformation transmission in multi-user multiple-input multiple-output (MIMO)\nsystem. In this paper, we explore the use of the superimposed pilot (SP) scheme\nto tackle the large transmitting users, where the number of users may exceed\nthe coherent time. SP scheme incorporates both transmitted data and noise in\nthe channel estimation process, which is significant different from the\ncounterpart of RP scheme. We provide an in-depth analysis of the interaction\nbetween interference caused by channel estimation errors and noise. We then\nderive the explicit expression for the scaling law of the mutual information\nlower bound (MILB) in relation to the number of users and the levels of\ntransmitted power. Besides, the optimal power allocation between pilots and\ndata transmission is also derived analytically. The analytical results\ndemonstrate that the SP scheme significantly improves performance compared to\ntraditional RP scheme in our consider case. Numerical results are also\npresented to validate our theoretical derivations.", "published": "2025-05-13 07:22:38", "link": "http://arxiv.org/abs/2505.08298v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantic De-boosting in e-commerce Query Autocomplete", "abstract": "In ecommerce search, query autocomplete plays a critical role to help users\nin their shopping journey. Often times, query autocomplete presents users with\nsemantically similar queries, which can impede the user's ability to find\ndiverse and relevant results. This paper proposes a novel strategy to enhance\nthis service by refining the presentation of typeahead suggestions based on\ntheir semantic similarity.\n  Our solution uniquely demotes semantically equivalent queries using an\nembedding similarity of query suggestions at runtime. This strategy ensures\nonly distinct and varied queries are prioritized, thereby promoting more\ndiverse suggestions for users. To maintain comprehensive query coverage, we\nincorporate this deduplication process within the query suggestion reranking\nstep. This approach ensures that the broad spectrum of possible queries remains\navailable to users, while eliminating the redundancy and repetitiveness in the\nsuggestion list.\n  In extending this work, we propose using the distance between query\nembeddings to offer even more diverse suggestions to users using an algorithm\nsimilar to maximal marginal relevance. This approach will further ensure the\ndelivery of non-redundant, unique, and pertinent suggestions to users, thus\nenriching their search experience.\n  We evaluated our method through rigorous AB testing, demonstrating\nsubstantial improvements in key metrics. Notably, we observed a statistically\nsignificant rise in the search Add-to-Cart rate, signifying an enhanced user\nengagement and conversion rate. Furthermore, we observed a statistically\nsignificant decrease in clicks to ATC, implying that the feature improved the\nefficiency of the customer's product search journey. Finally, we also noticed a\nmarked reduction in the null page view rate, indicating the increased\npertinence and efficiency of user search sessions.", "published": "2025-05-13 02:39:55", "link": "http://arxiv.org/abs/2505.08182v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-Layer Hierarchical Federated Learning with Quantization", "abstract": "Almost all existing hierarchical federated learning (FL) models are limited\nto two aggregation layers, restricting scalability and flexibility in complex,\nlarge-scale networks. In this work, we propose a Multi-Layer Hierarchical\nFederated Learning framework (QMLHFL), which appears to be the first study that\ngeneralizes hierarchical FL to arbitrary numbers of layers and network\narchitectures through nested aggregation, while employing a layer-specific\nquantization scheme to meet communication constraints. We develop a\ncomprehensive convergence analysis for QMLHFL and derive a general convergence\ncondition and rate that reveal the effects of key factors, including\nquantization parameters, hierarchical architecture, and intra-layer iteration\ncounts. Furthermore, we determine the optimal number of intra-layer iterations\nto maximize the convergence rate while meeting a deadline constraint that\naccounts for both communication and computation times. Our results show that\nQMLHFL consistently achieves high learning accuracy, even under high data\nheterogeneity, and delivers notably improved performance when optimized,\ncompared to using randomly selected values.", "published": "2025-05-13 00:47:13", "link": "http://arxiv.org/abs/2505.08145v1", "categories": ["cs.LG", "cs.DC", "cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.LG"}
{"title": "PCS-UQ: Uncertainty Quantification via the Predictability-Computability-Stability Framework", "abstract": "As machine learning (ML) models are increasingly deployed in high-stakes\ndomains, trustworthy uncertainty quantification (UQ) is critical for ensuring\nthe safety and reliability of these models. Traditional UQ methods rely on\nspecifying a true generative model and are not robust to misspecification. On\nthe other hand, conformal inference allows for arbitrary ML models but does not\nconsider model selection, which leads to large interval sizes. We tackle these\ndrawbacks by proposing a UQ method based on the predictability, computability,\nand stability (PCS) framework for veridical data science proposed by Yu and\nKumbier. Specifically, PCS-UQ addresses model selection by using a prediction\ncheck to screen out unsuitable models. PCS-UQ then fits these screened\nalgorithms across multiple bootstraps to assess inter-sample variability and\nalgorithmic instability, enabling more reliable uncertainty estimates. Further,\nwe propose a novel calibration scheme that improves local adaptivity of our\nprediction sets. Experiments across $17$ regression and $6$ classification\ndatasets show that PCS-UQ achieves the desired coverage and reduces width over\nconformal approaches by $\\approx 20\\%$. Further, our local analysis shows\nPCS-UQ often achieves target coverage across subgroups while conformal methods\nfail to do so. For large deep-learning models, we propose computationally\nefficient approximation schemes that avoid the expensive multiple bootstrap\ntrainings of PCS-UQ. Across three computer vision benchmarks, PCS-UQ reduces\nprediction set size over conformal methods by $20\\%$. Theoretically, we show a\nmodified PCS-UQ algorithm is a form of split conformal inference and achieves\nthe desired coverage with exchangeable data.", "published": "2025-05-13 17:58:16", "link": "http://arxiv.org/abs/2505.08784v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Addressing the Current Challenges of Quantum Machine Learning through Multi-Chip Ensembles", "abstract": "Quantum Machine Learning (QML) holds significant promise for solving\ncomputational challenges across diverse domains. However, its practical\ndeployment is constrained by the limitations of noisy intermediate-scale\nquantum (NISQ) devices, including noise, limited scalability, and trainability\nissues in variational quantum circuits (VQCs). We introduce the multi-chip\nensemble VQC framework, which partitions high-dimensional computations across\nsmaller quantum chips to enhance scalability, trainability, and noise\nresilience. We show that this approach mitigates barren plateaus, reduces\nquantum error bias and variance, and maintains robust generalization through\ncontrolled entanglement. Designed to align with current and emerging quantum\nhardware, the framework demonstrates strong potential for enabling scalable QML\non near-term devices, as validated by experiments on standard benchmark\ndatasets (MNIST, FashionMNIST, CIFAR-10) and real world dataset (PhysioNet\nEEG).", "published": "2025-05-13 17:57:53", "link": "http://arxiv.org/abs/2505.08782v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Generative Molecular Design with Steerable and Granular Synthesizability Control", "abstract": "Synthesizability in small molecule generative design remains a bottleneck.\nExisting works that do consider synthesizability can output predicted synthesis\nroutes for generated molecules. However, there has been minimal attention in\naddressing the ease of synthesis and enabling flexibility to incorporate\ndesired reaction constraints. In this work, we propose a small molecule\ngenerative design framework that enables steerable and granular\nsynthesizability control. Generated molecules satisfy arbitrary multi-parameter\noptimization objectives with predicted synthesis routes containing pre-defined\nallowed reactions, while optionally avoiding others. One can also enforce that\nall reactions belong to a pre-defined set. We show the capability to\nmix-and-match these reaction constraints across the most common medicinal\nchemistry transformations. Next, we show how our framework can be used to\nvalorize industrial byproducts towards de novo optimized molecules. Going\nfurther, we demonstrate how granular control over synthesizability constraints\ncan loosely mimic virtual screening of ultra-large make-on-demand libraries.\nUsing only a single GPU, we generate and dock 15k molecules to identify\npromising candidates in Freedom 4.0 constituting 142B make-on-demand molecules\n(assessing only 0.00001% of the library). Generated molecules satisfying the\nreaction constraints have > 90% exact match rate. Lastly, we benchmark our\nframework against recent synthesizability-constrained generative models and\ndemonstrate the highest sample efficiency even when imposing the additional\nconstraint that all molecules must be synthesizable from a single reaction\ntype. The main theme is demonstrating that a pre-trained generalist molecular\ngenerative model can be incentivized to generate property-optimized small\nmolecules under challenging synthesizability constraints through reinforcement\nlearning.", "published": "2025-05-13 17:53:54", "link": "http://arxiv.org/abs/2505.08774v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "SPAT: Sensitivity-based Multihead-attention Pruning on Time Series Forecasting Models", "abstract": "Attention-based architectures have achieved superior performance in\nmultivariate time series forecasting but are computationally expensive.\nTechniques such as patching and adaptive masking have been developed to reduce\ntheir sizes and latencies. In this work, we propose a structured pruning\nmethod, SPAT ($\\textbf{S}$ensitivity $\\textbf{P}$runer for\n$\\textbf{At}$tention), which selectively removes redundant attention mechanisms\nand yields highly effective models. Different from previous approaches, SPAT\naims to remove the entire attention module, which reduces the risk of\noverfitting and enables speed-up without demanding specialized hardware. We\npropose a dynamic sensitivity metric, $\\textbf{S}$ensitivity\n$\\textbf{E}$nhanced $\\textbf{N}$ormalized $\\textbf{D}$ispersion (SEND) that\nmeasures the importance of each attention module during the pre-training phase.\nExperiments on multivariate datasets demonstrate that SPAT-pruned models\nachieve reductions of 2.842% in MSE, 1.996% in MAE, and 35.274% in FLOPs.\nFurthermore, SPAT-pruned models outperform existing lightweight, Mamba-based\nand LLM-based SOTA methods in both standard and zero-shot inference,\nhighlighting the importance of retaining only the most effective attention\nmechanisms. We have made our code publicly available\nhttps://anonymous.4open.science/r/SPAT-6042.", "published": "2025-05-13 17:39:31", "link": "http://arxiv.org/abs/2505.08768v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Implet: A Post-hoc Subsequence Explainer for Time Series Models", "abstract": "Explainability in time series models is crucial for fostering trust,\nfacilitating debugging, and ensuring interpretability in real-world\napplications. In this work, we introduce Implet, a novel post-hoc explainer\nthat generates accurate and concise subsequence-level explanations for time\nseries models. Our approach identifies critical temporal segments that\nsignificantly contribute to the model's predictions, providing enhanced\ninterpretability beyond traditional feature-attribution methods. Based on it,\nwe propose a cohort-based (group-level) explanation framework designed to\nfurther improve the conciseness and interpretability of our explanations. We\nevaluate Implet on several standard time-series classification benchmarks,\ndemonstrating its effectiveness in improving interpretability. The code is\navailable at https://github.com/LbzSteven/implet", "published": "2025-05-13 17:01:23", "link": "http://arxiv.org/abs/2505.08748v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse Problems in Parametric Differential Equations", "abstract": "Parametric differential equations of the form du/dt = f(u, x, t, p) are\nfundamental in science and engineering. While deep learning frameworks such as\nthe Fourier Neural Operator (FNO) can efficiently approximate solutions, they\nstruggle with inverse problems, sensitivity estimation (du/dp), and concept\ndrift. We address these limitations by introducing a sensitivity-based\nregularization strategy, called Sensitivity-Constrained Fourier Neural\nOperators (SC-FNO). SC-FNO achieves high accuracy in predicting solution paths\nand consistently outperforms standard FNO and FNO with physics-informed\nregularization. It improves performance in parameter inversion tasks, scales to\nhigh-dimensional parameter spaces (tested with up to 82 parameters), and\nreduces both data and training requirements. These gains are achieved with a\nmodest increase in training time (30% to 130% per epoch) and generalize across\nvarious types of differential equations and neural operators. Code and selected\nexperiments are available at: https://github.com/AMBehroozi/SC_Neural_Operators", "published": "2025-05-13 16:54:10", "link": "http://arxiv.org/abs/2505.08740v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Towards Foundation Models for Experimental Readout Systems Combining Discrete and Continuous Data", "abstract": "We present a (proto) Foundation Model for Nuclear Physics, capable of\noperating on low-level detector inputs from Imaging Cherenkov Detectors at the\nfuture Electron Ion Collider. To address limitations in existing next-token\nprediction approaches-namely resolution loss from VQ-VAE tokenization and lack\nof conditional generation-we propose three key innovations: (i) separate\nvocabularies for discrete spatial features and continuous variates, combined\nvia Causal Multi-Head Cross-Attention (CMHCA), (ii) continuous kinematic\nconditioning through prepended context embeddings, and (iii) scalable and\nsimple, high-resolution continuous variate tokenization without joint\nvocabulary inflation. Our model enables fast, high-fidelity generation of pixel\nand time sequences for Cherenkov photons, validated through closure tests in\nthe High Performance DIRC. We also show our model generalizes to reconstruction\ntasks such as pion and kaon identification, in which we show its ability to\nleverage fine-tuning.", "published": "2025-05-13 16:49:45", "link": "http://arxiv.org/abs/2505.08736v1", "categories": ["cs.LG", "hep-ex", "nucl-ex", "physics.ins-det"], "primary_category": "cs.LG"}
{"title": "Preference Optimization for Combinatorial Optimization Problems", "abstract": "Reinforcement Learning (RL) has emerged as a powerful tool for neural\ncombinatorial optimization, enabling models to learn heuristics that solve\ncomplex problems without requiring expert knowledge. Despite significant\nprogress, existing RL approaches face challenges such as diminishing reward\nsignals and inefficient exploration in vast combinatorial action spaces,\nleading to inefficiency. In this paper, we propose Preference Optimization, a\nnovel method that transforms quantitative reward signals into qualitative\npreference signals via statistical comparison modeling, emphasizing the\nsuperiority among sampled solutions. Methodologically, by reparameterizing the\nreward function in terms of policy and utilizing preference models, we\nformulate an entropy-regularized RL objective that aligns the policy directly\nwith preferences while avoiding intractable computations. Furthermore, we\nintegrate local search techniques into the fine-tuning rather than\npost-processing to generate high-quality preference pairs, helping the policy\nescape local optima. Empirical results on various benchmarks, such as the\nTraveling Salesman Problem (TSP), the Capacitated Vehicle Routing Problem\n(CVRP) and the Flexible Flow Shop Problem (FFSP), demonstrate that our method\nsignificantly outperforms existing RL algorithms, achieving superior\nconvergence efficiency and solution quality.", "published": "2025-05-13 16:47:00", "link": "http://arxiv.org/abs/2505.08735v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Contrastive Normalizing Flows for Uncertainty-Aware Parameter Estimation", "abstract": "Estimating physical parameters from data is a crucial application of machine\nlearning (ML) in the physical sciences. However, systematic uncertainties, such\nas detector miscalibration, induce data distribution distortions that can erode\nstatistical precision. In both high-energy physics (HEP) and broader ML\ncontexts, achieving uncertainty-aware parameter estimation under these domain\nshifts remains an open problem. In this work, we address this challenge of\nuncertainty-aware parameter estimation for a broad set of tasks critical for\nHEP. We introduce a novel approach based on Contrastive Normalizing Flows\n(CNFs), which achieves top performance on the HiggsML Uncertainty Challenge\ndataset. Building on the insight that a binary classifier can approximate the\nmodel parameter likelihood ratio, we address the practical limitations of\nexpressivity and the high cost of simulating high-dimensional parameter grids\nby embedding data and parameters in a learned CNF mapping. This mapping yields\na tunable contrastive distribution that enables robust classification under\nshifted data distributions. Through a combination of theoretical analysis and\nempirical evaluations, we demonstrate that CNFs, when coupled with a classifier\nand established frequentist techniques, provide principled parameter estimation\nand uncertainty quantification through classification that is robust to data\ndistribution distortions.", "published": "2025-05-13 16:14:34", "link": "http://arxiv.org/abs/2505.08709v1", "categories": ["physics.data-an", "cs.LG", "hep-ex", "hep-ph"], "primary_category": "physics.data-an"}
{"title": "Continuous Temporal Learning of Probability Distributions via Neural ODEs with Applications in Continuous Glucose Monitoring Data", "abstract": "Modeling the continuous--time dynamics of probability distributions from\ntime--dependent data samples is a fundamental problem in many fields, including\ndigital health. The aim is to analyze how the distribution of a biomarker, such\nas glucose, evolves over time and how these changes may reflect the progression\nof chronic diseases such as diabetes. In this paper, we propose a novel\nprobabilistic model based on a mixture of Gaussian distributions to capture how\nsamples from a continuous-time stochastic process evolve over the time. To\nmodel potential distribution shifts over time, we introduce a time-dependent\nfunction parameterized by a Neural Ordinary Differential Equation (Neural ODE)\nand estimate it non--parametrically using the Maximum Mean Discrepancy (MMD).\nThe proposed model is highly interpretable, detects subtle temporal shifts, and\nremains computationally efficient. Through simulation studies, we show that it\nperforms competitively in terms of estimation accuracy against\nstate-of-the-art, less interpretable methods such as normalized gradient--flows\nand non--parameteric kernel density estimators. Finally, we demonstrate the\nutility of our method on digital clinical--trial data, showing how the\ninterventions alters the time-dependent distribution of glucose levels and\nenabling a rigorous comparison of control and treatment groups from novel\nmathematical and clinical perspectives.", "published": "2025-05-13 15:57:06", "link": "http://arxiv.org/abs/2505.08698v1", "categories": ["stat.ML", "cs.LG", "math.DS", "stat.AP", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Uncertainty-Aware Surrogate-based Amortized Bayesian Inference for Computationally Expensive Models", "abstract": "Bayesian inference typically relies on a large number of model evaluations to\nestimate posterior distributions. Established methods like Markov Chain Monte\nCarlo (MCMC) and Amortized Bayesian Inference (ABI) can become computationally\nchallenging. While ABI enables fast inference after training, generating\nsufficient training data still requires thousands of model simulations, which\nis infeasible for expensive models. Surrogate models offer a solution by\nproviding approximate simulations at a lower computational cost, allowing the\ngeneration of large data sets for training. However, the introduced\napproximation errors and uncertainties can lead to overconfident posterior\nestimates. To address this, we propose Uncertainty-Aware Surrogate-based\nAmortized Bayesian Inference (UA-SABI) - a framework that combines surrogate\nmodeling and ABI while explicitly quantifying and propagating surrogate\nuncertainties through the inference pipeline. Our experiments show that this\napproach enables reliable, fast, and repeated Bayesian inference for\ncomputationally expensive models, even under tight time constraints.", "published": "2025-05-13 15:44:10", "link": "http://arxiv.org/abs/2505.08683v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Modular Federated Learning: A Meta-Framework Perspective", "abstract": "Federated Learning (FL) enables distributed machine learning training while\npreserving privacy, representing a paradigm shift for data-sensitive and\ndecentralized environments. Despite its rapid advancements, FL remains a\ncomplex and multifaceted field, requiring a structured understanding of its\nmethodologies, challenges, and applications. In this survey, we introduce a\nmeta-framework perspective, conceptualising FL as a composition of modular\ncomponents that systematically address core aspects such as communication,\noptimisation, security, and privacy. We provide a historical contextualisation\nof FL, tracing its evolution from distributed optimisation to modern\ndistributed learning paradigms. Additionally, we propose a novel taxonomy\ndistinguishing Aggregation from Alignment, introducing the concept of alignment\nas a fundamental operator alongside aggregation. To bridge theory with\npractice, we explore available FL frameworks in Python, facilitating real-world\nimplementation. Finally, we systematise key challenges across FL sub-fields,\nproviding insights into open research questions throughout the meta-framework\nmodules. By structuring FL within a meta-framework of modular components and\nemphasising the dual role of Aggregation and Alignment, this survey provides a\nholistic and adaptable foundation for understanding and advancing FL research\nand deployment.", "published": "2025-05-13 15:04:55", "link": "http://arxiv.org/abs/2505.08646v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Credit Assignment and Efficient Exploration based on Influence Scope in Multi-agent Reinforcement Learning", "abstract": "Training cooperative agents in sparse-reward scenarios poses significant\nchallenges for multi-agent reinforcement learning (MARL). Without clear\nfeedback on actions at each step in sparse-reward setting, previous methods\nstruggle with precise credit assignment among agents and effective exploration.\nIn this paper, we introduce a novel method to deal with both credit assignment\nand exploration problems in reward-sparse domains. Accordingly, we propose an\nalgorithm that calculates the Influence Scope of Agents (ISA) on states by\ntaking specific value of the dimensions/attributes of states that can be\ninfluenced by individual agents. The mutual dependence between agents' actions\nand state attributes are then used to calculate the credit assignment and to\ndelimit the exploration space for each individual agent. We then evaluate ISA\nin a variety of sparse-reward multi-agent scenarios. The results show that our\nmethod significantly outperforms the state-of-art baselines.", "published": "2025-05-13 14:49:26", "link": "http://arxiv.org/abs/2505.08630v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cost Function Estimation Using Inverse Reinforcement Learning with Minimal Observations", "abstract": "We present an iterative inverse reinforcement learning algorithm to infer\noptimal cost functions in continuous spaces. Based on a popular maximum entropy\ncriteria, our approach iteratively finds a weight improvement step and proposes\na method to find an appropriate step size that ensures learned cost function\nfeatures remain similar to the demonstrated trajectory features. In contrast to\nsimilar approaches, our algorithm can individually tune the effectiveness of\neach observation for the partition function and does not need a large sample\nset, enabling faster learning. We generate sample trajectories by solving an\noptimal control problem instead of random sampling, leading to more informative\ntrajectories. The performance of our method is compared to two state of the art\nalgorithms to demonstrate its benefits in several simulated environments.", "published": "2025-05-13 14:38:25", "link": "http://arxiv.org/abs/2505.08619v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "neuralGAM: An R Package for Fitting Generalized Additive Neural Networks", "abstract": "Nowadays, Neural Networks are considered one of the most effective methods\nfor various tasks such as anomaly detection, computer-aided disease detection,\nor natural language processing. However, these networks suffer from the\n``black-box'' problem which makes it difficult to understand how they make\ndecisions. In order to solve this issue, an R package called neuralGAM is\nintroduced. This package implements a Neural Network topology based on\nGeneralized Additive Models, allowing to fit an independent Neural Network to\nestimate the contribution of each feature to the output variable, yielding a\nhighly accurate and interpretable Deep Learning model. The neuralGAM package\nprovides a flexible framework for training Generalized Additive Neural\nNetworks, which does not impose any restrictions on the Neural Network\narchitecture. We illustrate the use of the neuralGAM package in both synthetic\nand real data examples.", "published": "2025-05-13 14:30:01", "link": "http://arxiv.org/abs/2505.08610v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Automated Model-Free Sorting of Single-Molecule Fluorescence Events Using a Deep Learning Based Hidden-State Model", "abstract": "Single-molecule fluorescence assays enable high-resolution analysis of\nbiomolecular dynamics, but traditional analysis pipelines are labor-intensive\nand rely on users' experience, limiting scalability and reproducibility. Recent\ndeep learning models have automated aspects of data processing, yet many still\nrequire manual thresholds, complex architectures, or extensive labeled data.\nTherefore, we present DASH, a fully streamlined architecture for trace\nclassification, state assignment, and automatic sorting that requires no user\ninput. DASH demonstrates robust performance across users and experimental\nconditions both in equilibrium and non-equilibrium systems such as\nCas12a-mediated DNA cleavage. This paper proposes a novel strategy for the\nautomatic and detailed sorting of single-molecule fluorescence events. The\ndynamic cleavage process of Cas12a is used as an example to provide a\ncomprehensive analysis. This approach is crucial for studying biokinetic\nstructural changes at the single-molecule level.", "published": "2025-05-13 14:26:33", "link": "http://arxiv.org/abs/2505.08608v1", "categories": ["q-bio.QM", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Clustering of Incomplete Data via a Bipartite Graph Structure", "abstract": "There are various approaches to graph learning for data clustering,\nincorporating different spectral and structural constraints through diverse\ngraph structures. Some methods rely on bipartite graph models, where nodes are\ndivided into two classes: centers and members. These models typically require\naccess to data for the center nodes in addition to observations from the member\nnodes. However, such additional data may not always be available in many\npractical scenarios. Moreover, popular Gaussian models for graph learning have\ndemonstrated limited effectiveness in modeling data with heavy-tailed\ndistributions, which are common in financial markets. In this paper, we propose\na clustering method based on a bipartite graph model that addresses these\nchallenges. First, it can infer clusters from incomplete data without requiring\ninformation about the center nodes. Second, it is designed to effectively\nhandle heavy-tailed data. Numerical experiments using real financial data\nvalidate the efficiency of the proposed method for data clustering.", "published": "2025-05-13 14:06:13", "link": "http://arxiv.org/abs/2505.08594v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MUBox: A Critical Evaluation Framework of Deep Machine Unlearning", "abstract": "Recent legal frameworks have mandated the right to be forgotten, obligating\nthe removal of specific data upon user requests. Machine Unlearning has emerged\nas a promising solution by selectively removing learned information from\nmachine learning models. This paper presents MUBox, a comprehensive platform\ndesigned to evaluate unlearning methods in deep learning. MUBox integrates 23\nadvanced unlearning techniques, tested across six practical scenarios with 11\ndiverse evaluation metrics. It allows researchers and practitioners to (1)\nassess and compare the effectiveness of different machine unlearning methods\nacross various scenarios; (2) examine the impact of current evaluation metrics\non unlearning performance; and (3) conduct detailed comparative studies on\nmachine unlearning in a unified framework. Leveraging MUBox, we systematically\nevaluate these unlearning methods in deep learning and uncover several key\ninsights: (a) Even state-of-the-art unlearning methods, including those\npublished in top-tier venues and winners of unlearning competitions,\ndemonstrate inconsistent effectiveness across diverse scenarios. Prior research\nhas predominantly focused on simplified settings, such as random forgetting and\nclass-wise unlearning, highlighting the need for broader evaluations across\nmore difficult unlearning tasks. (b) Assessing unlearning performance remains a\nnon-trivial problem, as no single evaluation metric can comprehensively capture\nthe effectiveness, efficiency, and preservation of model utility. Our findings\nemphasize the necessity of employing multiple metrics to achieve a balanced and\nholistic assessment of unlearning methods. (c) In the context of depoisoning,\nour evaluation reveals significant variability in the effectiveness of existing\napproaches, which is highly dependent on the specific type of poisoning\nattacks.", "published": "2025-05-13 13:50:51", "link": "http://arxiv.org/abs/2505.08576v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Online Learning and Unlearning", "abstract": "We formalize the problem of online learning-unlearning, where a model is\nupdated sequentially in an online setting while accommodating unlearning\nrequests between updates. After a data point is unlearned, all subsequent\noutputs must be statistically indistinguishable from those of a model trained\nwithout that point. We present two online learner-unlearner (OLU) algorithms,\nboth built upon online gradient descent (OGD). The first, passive OLU,\nleverages OGD's contractive property and injects noise when unlearning occurs,\nincurring no additional computation. The second, active OLU, uses an offline\nunlearning algorithm that shifts the model toward a solution excluding the\ndeleted data. Under standard convexity and smoothness assumptions, both methods\nachieve regret bounds comparable to those of standard OGD, demonstrating that\none can maintain competitive regret bounds while providing unlearning\nguarantees.", "published": "2025-05-13 13:33:36", "link": "http://arxiv.org/abs/2505.08557v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Diffusion-assisted Model Predictive Control Optimization for Power System Real-Time Operation", "abstract": "This paper presents a modified model predictive control (MPC) framework for\nreal-time power system operation. The framework incorporates a diffusion model\ntailored for time series generation to enhance the accuracy of the load\nforecasting module used in the system operation. In the absence of explicit\nstate transition law, a model-identification procedure is leveraged to derive\nthe system dynamics, thereby eliminating a barrier when applying MPC to a\nrenewables-dominated power system. Case study results on an industry park\nsystem and the IEEE 30-bus system demonstrate that using the diffusion model to\naugment the training dataset significantly improves load-forecasting accuracy,\nand the inferred system dynamics are applicable to the real-time grid operation\nwith solar and wind.", "published": "2025-05-13 13:04:46", "link": "http://arxiv.org/abs/2505.08535v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Building-Block Aware Generative Modeling for 3D Crystals of Metal Organic Frameworks", "abstract": "Metal-organic frameworks (MOFs) marry inorganic nodes, organic edges, and\ntopological nets into programmable porous crystals, yet their astronomical\ndesign space defies brute-force synthesis. Generative modeling holds ultimate\npromise, but existing models either recycle known building blocks or are\nrestricted to small unit cells. We introduce Building-Block-Aware MOF Diffusion\n(BBA MOF Diffusion), an SE(3)-equivariant diffusion model that learns 3D\nall-atom representations of individual building blocks, encoding\ncrystallographic topological nets explicitly. Trained on the CoRE-MOF database,\nBBA MOF Diffusion readily samples MOFs with unit cells containing 1000 atoms\nwith great geometric validity, novelty, and diversity mirroring experimental\ndatabases. Its native building-block representation produces unprecedented\nmetal nodes and organic edges, expanding accessible chemical space by orders of\nmagnitude. One high-scoring [Zn(1,4-TDC)(EtOH)2] MOF predicted by the model was\nsynthesized, where powder X-ray diffraction, thermogravimetric analysis, and N2\nsorption confirm its structural fidelity. BBA-Diff thus furnishes a practical\npathway to synthesizable and high-performing MOFs.", "published": "2025-05-13 13:02:28", "link": "http://arxiv.org/abs/2505.08531v1", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG"], "primary_category": "physics.chem-ph"}
{"title": "SPP-SBL: Space-Power Prior Sparse Bayesian Learning for Block Sparse Recovery", "abstract": "The recovery of block-sparse signals with unknown structural patterns remains\na fundamental challenge in structured sparse signal reconstruction. By\nproposing a variance transformation framework, this paper unifies existing\npattern-based block sparse Bayesian learning methods, and introduces a novel\nspace power prior based on undirected graph models to adaptively capture the\nunknown patterns of block-sparse signals. By combining the EM algorithm with\nhigh-order equation root-solving, we develop a new structured sparse Bayesian\nlearning method, SPP-SBL, which effectively addresses the open problem of space\ncoupling parameter estimation in pattern-based methods. We further demonstrate\nthat learning the relative values of space coupling parameters is key to\ncapturing unknown block-sparse patterns and improving recovery accuracy.\nExperiments validate that SPP-SBL successfully recovers various challenging\nstructured sparse signals (e.g., chain-structured signals and multi-pattern\nsparse signals) and real-world multi-modal structured sparse signals (images,\naudio), showing significant advantages in recovery accuracy across multiple\nmetrics.", "published": "2025-05-13 12:49:25", "link": "http://arxiv.org/abs/2505.08518v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "InfoPO: On Mutual Information Maximization for Large Language Model Alignment", "abstract": "We study the post-training of large language models (LLMs) with human\npreference data. Recently, direct preference optimization and its variants have\nshown considerable promise in aligning language models, eliminating the need\nfor reward models and online sampling. Despite these benefits, these methods\nrely on explicit assumptions about the Bradley-Terry (BT) model, which makes\nthem prone to overfitting and results in suboptimal performance, particularly\non reasoning-heavy tasks. To address these challenges, we propose a principled\npreference fine-tuning algorithm called InfoPO, which effectively and\nefficiently aligns large language models using preference data. InfoPO\neliminates the reliance on the BT model and prevents the likelihood of the\nchosen response from decreasing. Extensive experiments confirm that InfoPO\nconsistently outperforms established baselines on widely used open benchmarks,\nparticularly in reasoning tasks.", "published": "2025-05-13 12:37:48", "link": "http://arxiv.org/abs/2505.08507v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A new methodology to decompose a parametric domain using reduced order data manifold in machine learning", "abstract": "We propose a new methodology for parametric domain decomposition using\niterative principal component analysis. Starting with iterative principle\ncomponent analysis, the high dimension manifold is reduced to the lower\ndimension manifold. Moreover, two approaches are developed to reconstruct the\ninverse projector to project from the lower data component to the original one.\nAfterward, we provide a detailed strategy to decompose the parametric domain\nbased on the low dimension manifold. Finally, numerical examples of harmonic\ntransport problem are given to illustrate the efficiency and effectiveness of\nthe proposed method comparing to the classical meta-models such as neural\nnetworks.", "published": "2025-05-13 12:25:16", "link": "http://arxiv.org/abs/2505.08497v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Parameter Estimation using Reinforcement Learning Causal Curiosity: Limits and Challenges", "abstract": "Causal understanding is important in many disciplines of science and\nengineering, where we seek to understand how different factors in the system\ncausally affect an experiment or situation and pave a pathway towards creating\neffective or optimising existing models. Examples of use cases are autonomous\nexploration and modelling of unknown environments or assessing key variables in\noptimising large complex systems. In this paper, we analyse a Reinforcement\nLearning approach called Causal Curiosity, which aims to estimate as accurately\nand efficiently as possible, without directly measuring them, the value of\nfactors that causally determine the dynamics of a system. Whilst the idea\npresents a pathway forward, measurement accuracy is the foundation of\nmethodology effectiveness. Focusing on the current causal curiosity's robotic\nmanipulator, we present for the first time a measurement accuracy analysis of\nthe future potentials and current limitations of this technique and an analysis\nof its sensitivity and confounding factor disentanglement capability - crucial\nfor causal analysis. As a result of our work, we promote proposals for an\nimproved and efficient design of Causal Curiosity methods to be applied to\nreal-world complex scenarios.", "published": "2025-05-13 11:30:51", "link": "http://arxiv.org/abs/2505.08453v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Understanding molecular ratios in the carbon and oxygen poor outer Milky Way with interpretable machine learning", "abstract": "Context. The outer Milky Way has a lower metallicity than our solar\nneighbourhood, but still many molecules are detected in the region. Molecular\nline ratios can serve as probes to better understand the chemistry and physics\nin these regions. Aims. We use interpretable machine learning to study 9\ndifferent molecular ratios, helping us understand the forward connection\nbetween the physics of these environments and the carbon and oxygen\nchemistries. Methods. Using a large grid of astrochemical models generated\nusing UCLCHEM, we study the properties of molecular clouds of low oxygen and\ncarbon initial abundance. We first try to understand the line ratios using a\nclassical analysis. We then move on to using interpretable machine learning,\nnamely Shapley Additive Explanations (SHAP), to understand the higher order\ndependencies of the ratios over the entire parameter grid. Lastly we use the\nUniform Manifold Approximation and Projection technique (UMAP) as a reduction\nmethod to create intuitive groupings of models. Results. We find that the\nparameter space is well covered by the line ratios, allowing us to investigate\nall input parameters. SHAP analysis shows that the temperature and density are\nthe most important features, but the carbon and oxygen abundances are important\nin parts of the parameter space. Lastly, we find that we can group different\ntypes of ratios using UMAP. Conclusions. We show the chosen ratios are mostly\nsensitive to changes in the carbon initial abundance, together with the\ntemperature and density. Especially the CN/HCN and HNC/HCN ratio are shown to\nbe sensitive to the initial carbon abundance, making them excellent probes for\nthis parameter. Out of the ratios, only CS/SO shows a sensitivity to the oxygen\nabundance.", "published": "2025-05-13 10:08:37", "link": "http://arxiv.org/abs/2505.08410v1", "categories": ["astro-ph.GA", "cs.LG"], "primary_category": "astro-ph.GA"}
{"title": "Continuous World Coverage Path Planning for Fixed-Wing UAVs using Deep Reinforcement Learning", "abstract": "Unmanned Aerial Vehicle (UAV) Coverage Path Planning (CPP) is critical for\napplications such as precision agriculture and search and rescue. While\ntraditional methods rely on discrete grid-based representations, real-world UAV\noperations require power-efficient continuous motion planning. We formulate the\nUAV CPP problem in a continuous environment, minimizing power consumption while\nensuring complete coverage. Our approach models the environment with\nvariable-size axis-aligned rectangles and UAV motion with curvature-constrained\nB\\'ezier curves. We train a reinforcement learning agent using an\naction-mapping-based Soft Actor-Critic (AM-SAC) algorithm employing a\nself-adaptive curriculum. Experiments on both procedurally generated and\nhand-crafted scenarios demonstrate the effectiveness of our method in learning\nenergy-efficient coverage strategies.", "published": "2025-05-13 09:29:16", "link": "http://arxiv.org/abs/2505.08382v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Learning Treatment Allocations with Risk Control Under Partial Identifiability", "abstract": "Learning beneficial treatment allocations for a patient population is an\nimportant problem in precision medicine. Many treatments come with adverse side\neffects that are not commensurable with their potential benefits. Patients who\ndo not receive benefits after such treatments are thereby subjected to\nunnecessary harm. This is a `treatment risk' that we aim to control when\nlearning beneficial allocations. The constrained learning problem is challenged\nby the fact that the treatment risk is not in general identifiable using either\nrandomized trial or observational data. We propose a certifiable learning\nmethod that controls the treatment risk with finite samples in the partially\nidentified setting. The method is illustrated using both simulated and real\ndata.", "published": "2025-05-13 09:22:18", "link": "http://arxiv.org/abs/2505.08378v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete Data", "abstract": "This paper proposes a causal discovery method for mixed bivariate data\nconsisting of one continuous and one discrete variable. Existing\nconstraint-based approaches are ineffective in the bivariate setting, as they\nrely on conditional independence tests that are not suited to bivariate data.\nScore-based methods either impose strong distributional assumptions or face\nchallenges in fairly comparing causal directions between variables of different\ntypes, due to differences in their information content. We introduce a novel\napproach that determines causal direction by analyzing the monotonicity of the\nconditional density ratio of the continuous variable, conditioned on different\nvalues of the discrete variable. Our theoretical analysis shows that the\nconditional density ratio exhibits monotonicity when the continuous variable\ncauses the discrete variable, but not in the reverse direction. This property\nprovides a principled basis for comparing causal directions between variables\nof different types, free from strong distributional assumptions and bias\narising from differences in their information content. We demonstrate its\neffectiveness through experiments on both synthetic and real-world datasets,\nshowing superior accuracy compared to existing methods.", "published": "2025-05-13 09:18:41", "link": "http://arxiv.org/abs/2505.08371v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Localization of Impacts on Thin-Walled Structures by Recurrent Neural Networks: End-to-end Learning from Real-World Data", "abstract": "Today, machine learning is ubiquitous, and structural health monitoring (SHM)\nis no exception. Specifically, we address the problem of impact localization on\nshell-like structures, where knowledge of impact locations aids in assessing\nstructural integrity. Impacts on thin-walled structures excite Lamb waves,\nwhich can be measured with piezoelectric sensors. Their dispersive\ncharacteristics make it difficult to detect and localize impacts by\nconventional methods. In the present contribution, we explore the localization\nof impacts using neural networks. In particular, we propose to use {recurrent\nneural networks} (RNNs) to estimate impact positions end-to-end, i.e., directly\nfrom {sequential sensor data}. We deal with comparatively long sequences of\nthousands of samples, since high sampling rate are needed to accurately capture\nelastic waves. For this reason, the proposed approach builds upon Gated\nRecurrent Units (GRUs), which are less prone to vanishing gradients as compared\nto conventional RNNs. Quality and quantity of data are crucial when training\nneural networks. Often, synthetic data is used, which inevitably introduces a\nreality gap. Here, by contrast, we train our networks using {physical data from\nexperiments}, which requires automation to handle the large number of\nexperiments needed. For this purpose, a {robot is used to drop steel balls}\nonto an {aluminum plate} equipped with {piezoceramic sensors}. Our results show\nremarkable accuracy in estimating impact positions, even with a comparatively\nsmall dataset.", "published": "2025-05-13 09:08:47", "link": "http://arxiv.org/abs/2505.08362v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Structural-Temporal Coupling Anomaly Detection with Dynamic Graph Transformer", "abstract": "Detecting anomalous edges in dynamic graphs is an important task in many\napplications over evolving triple-based data, such as social networks,\ntransaction management, and epidemiology. A major challenge with this task is\nthe absence of structural-temporal coupling information, which decreases the\nability of the representation to distinguish anomalies from normal instances.\nExisting methods focus on handling independent structural and temporal features\nwith embedding models, which ignore the deep interaction between these two\ntypes of information. In this paper, we propose a structural-temporal coupling\nanomaly detection architecture with a dynamic graph transformer model.\nSpecifically, we introduce structural and temporal features from two\nintegration levels to provide anomaly-aware graph evolutionary patterns. Then,\na dynamic graph transformer enhanced by two-dimensional positional encoding is\nimplemented to capture both discrimination and contextual consistency signals.\nExtensive experiments on six datasets demonstrate that our method outperforms\ncurrent state-of-the-art models. Finally, a case study illustrates the strength\nof our method when applied to a real-world task.", "published": "2025-05-13 08:10:41", "link": "http://arxiv.org/abs/2505.08330v1", "categories": ["cs.LG", "cs.SI", "68T07, 68T09"], "primary_category": "cs.LG"}
{"title": "SpecSphere: Dual-Pass Spectral-Spatial Graph Neural Networks with Certified Robustness", "abstract": "We introduce SpecSphere, the first dual-pass spectral-spatial GNN that\ncertifies every prediction against both $\\ell\\_{0}$ edge flips and\n$\\ell\\_{\\infty}$ feature perturbations, adapts to the full\nhomophily-heterophily spectrum, and surpasses the expressive power of\n1-Weisfeiler-Lehman while retaining linear-time complexity. Our model couples a\nChebyshev-polynomial spectral branch with an attention-gated spatial branch and\nfuses their representations through a lightweight MLP trained in a\ncooperative-adversarial min-max game. We further establish (i) a uniform\nChebyshev approximation theorem, (ii) minimax-optimal risk across the\nhomophily-heterophily spectrum, (iii) closed-form robustness certificates, and\n(iv) universal approximation strictly beyond 1-WL. SpecSphere achieves\nstate-of-the-art node-classification accuracy and delivers tighter certified\nrobustness guarantees on real-world benchmarks. These results demonstrate that\nhigh expressivity, heterophily adaptation, and provable robustness can coexist\nwithin a single, scalable architecture.", "published": "2025-05-13 08:00:16", "link": "http://arxiv.org/abs/2505.08320v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rapid Overfitting of Multi-Pass Stochastic Gradient Descent in Stochastic Convex Optimization", "abstract": "We study the out-of-sample performance of multi-pass stochastic gradient\ndescent (SGD) in the fundamental stochastic convex optimization (SCO) model.\nWhile one-pass SGD is known to achieve an optimal $\\Theta(1/\\sqrt{n})$ excess\npopulation loss given a sample of size $n$, much less is understood about the\nmulti-pass version of the algorithm which is widely used in practice. Somewhat\nsurprisingly, we show that in the general non-smooth case of SCO, just a few\nepochs of SGD can already hurt its out-of-sample performance significantly and\nlead to overfitting. In particular, using a step size $\\eta =\n\\Theta(1/\\sqrt{n})$, which gives the optimal rate after one pass, can lead to\npopulation loss as large as $\\Omega(1)$ after just one additional pass. More\ngenerally, we show that the population loss from the second pass onward is of\nthe order $\\Theta(1/(\\eta T) + \\eta \\sqrt{T})$, where $T$ is the total number\nof steps. These results reveal a certain phase-transition in the out-of-sample\nbehavior of SGD after the first epoch, as well as a sharp separation between\nthe rates of overfitting in the smooth and non-smooth cases of SCO.\nAdditionally, we extend our results to with-replacement SGD, proving that the\nsame asymptotic bounds hold after $O(n \\log n)$ steps. Finally, we also prove a\nlower bound of $\\Omega(\\eta \\sqrt{n})$ on the generalization gap of one-pass\nSGD in dimension $d = \\smash{\\widetilde O}(n)$, improving on recent results of\nKoren et al.(2022) and Schliserman et al.(2024).", "published": "2025-05-13 07:32:48", "link": "http://arxiv.org/abs/2505.08306v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Iteratively reweighted kernel machines efficiently learn sparse functions", "abstract": "The impressive practical performance of neural networks is often attributed\nto their ability to learn low-dimensional data representations and hierarchical\nstructure directly from data. In this work, we argue that these two phenomena\nare not unique to neural networks, and can be elicited from classical kernel\nmethods. Namely, we show that the derivative of the kernel predictor can detect\nthe influential coordinates with low sample complexity. Moreover, by\niteratively using the derivatives to reweight the data and retrain kernel\nmachines, one is able to efficiently learn hierarchical polynomials with finite\nleap complexity. Numerical experiments illustrate the developed theory.", "published": "2025-05-13 06:41:39", "link": "http://arxiv.org/abs/2505.08277v1", "categories": ["stat.ML", "cs.LG", "math.OC", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Super-fast rates of convergence for Neural Networks Classifiers under the Hard Margin Condition", "abstract": "We study the classical binary classification problem for hypothesis spaces of\nDeep Neural Networks (DNNs) with ReLU activation under Tsybakov's low-noise\ncondition with exponent $q>0$, and its limit-case $q\\to\\infty$ which we refer\nto as the \"hard-margin condition\". We show that DNNs which minimize the\nempirical risk with square loss surrogate and $\\ell_p$ penalty can achieve\nfinite-sample excess risk bounds of order $\\mathcal{O}\\left(n^{-\\alpha}\\right)$\nfor arbitrarily large $\\alpha>0$ under the hard-margin condition, provided that\nthe regression function $\\eta$ is sufficiently smooth. The proof relies on a\nnovel decomposition of the excess risk which might be of independent interest.", "published": "2025-05-13 06:26:04", "link": "http://arxiv.org/abs/2505.08262v1", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Clustering-based Low-Rank Matrix Approximation: An Adaptive Theoretical Analysis with Application to Data Compression", "abstract": "Low-rank matrix approximation (LoRMA) is a fundamental tool for compressing\nhigh-resolution data matrices by extracting important features while\nsuppressing redundancy. Low-rank methods, such as global singular value\ndecomposition (SVD), apply uniform compression across the entire data matrix,\noften ignoring important local variations and leading to the loss of fine\nstructural details. To address these limitations, we introduce an adaptive\nLoRMA, which partitions data matrix into overlapping patches, groups\nstructurally similar patches into several clusters using k-means, and performs\nSVD within each cluster. We derive the overall compression factor accounting\nfor patch overlap and analyze how patch size influences compression efficiency\nand computational cost. While the proposed adaptive LoRMA method is applicable\nto any data exhibiting high local variation, we focus on medical imaging due to\nits pronounced local variability. We evaluate and compare our adaptive LoRMA\nagainst global SVD across four imaging modalities: MRI, ultrasound, CT scan,\nand chest X-ray. Results demonstrate that adaptive LoRMA effectively preserves\nstructural integrity, edge details, and diagnostic relevance, as measured by\npeak signal-to-noise ratio (PSNR), structural similarity index (SSIM), mean\nsquared error (MSE), intersection over union (IoU), and edge preservation index\n(EPI). Adaptive LoRMA significantly minimizes block artifacts and residual\nerrors, particularly in pathological regions, consistently outperforming global\nSVD in terms of PSNR, SSIM, IoU, EPI, and achieving lower MSE. Adaptive LoRMA\nprioritizes clinically salient regions while allowing aggressive compression in\nnon-critical regions, optimizing storage efficiency. Although adaptive LoRMA\nrequires higher processing time, its diagnostic fidelity justifies the overhead\nfor high-compression applications.", "published": "2025-05-13 06:10:05", "link": "http://arxiv.org/abs/2505.08256v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Privacy-Preserving Analytics for Smart Meter (AMI) Data: A Hybrid Approach to Comply with CPUC Privacy Regulations", "abstract": "Advanced Metering Infrastructure (AMI) data from smart electric and gas\nmeters enables valuable insights for utilities and consumers, but also raises\nsignificant privacy concerns. In California, regulatory decisions (CPUC\nD.11-07-056 and D.11-08-045) mandate strict privacy protections for customer\nenergy usage data, guided by the Fair Information Practice Principles (FIPPs).\nWe comprehensively explore solutions drawn from data anonymization,\nprivacy-preserving machine learning (differential privacy and federated\nlearning), synthetic data generation, and cryptographic techniques (secure\nmultiparty computation, homomorphic encryption). This allows advanced\nanalytics, including machine learning models, statistical and econometric\nanalysis on energy consumption data, to be performed without compromising\nindividual privacy.\n  We evaluate each technique's theoretical foundations, effectiveness, and\ntrade-offs in the context of utility data analytics, and we propose an\nintegrated architecture that combines these methods to meet real-world needs.\nThe proposed hybrid architecture is designed to ensure compliance with\nCalifornia's privacy rules and FIPPs while enabling useful analytics, from\nforecasting and personalized insights to academic research and econometrics,\nwhile strictly protecting individual privacy. Mathematical definitions and\nderivations are provided where appropriate to demonstrate privacy guarantees\nand utility implications rigorously. We include comparative evaluations of the\ntechniques, an architecture diagram, and flowcharts to illustrate how they work\ntogether in practice. The result is a blueprint for utility data scientists and\nengineers to implement privacy-by-design in AMI data handling, supporting both\ndata-driven innovation and strict regulatory compliance.", "published": "2025-05-13 05:30:35", "link": "http://arxiv.org/abs/2505.08237v1", "categories": ["cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Deep Probabilistic Modeling of User Behavior for Anomaly Detection via Mixture Density Networks", "abstract": "To improve the identification of potential anomaly patterns in complex user\nbehavior, this paper proposes an anomaly detection method based on a deep\nmixture density network. The method constructs a Gaussian mixture model\nparameterized by a neural network, enabling conditional probability modeling of\nuser behavior. It effectively captures the multimodal distribution\ncharacteristics commonly present in behavioral data. Unlike traditional\nclassifiers that rely on fixed thresholds or a single decision boundary, this\napproach defines an anomaly scoring function based on probability density using\nnegative log-likelihood. This significantly enhances the model's ability to\ndetect rare and unstructured behaviors. Experiments are conducted on the\nreal-world network user dataset UNSW-NB15. A series of performance comparisons\nand stability validation experiments are designed. These cover multiple\nevaluation aspects, including Accuracy, F1- score, AUC, and loss fluctuation.\nThe results show that the proposed method outperforms several advanced neural\nnetwork architectures in both performance and training stability. This study\nprovides a more expressive and discriminative solution for user behavior\nmodeling and anomaly detection. It strongly promotes the application of deep\nprobabilistic modeling techniques in the fields of network security and\nintelligent risk control.", "published": "2025-05-13 04:32:21", "link": "http://arxiv.org/abs/2505.08220v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Lie Group Symmetry Discovery and Enforcement Using Vector Fields", "abstract": "Symmetry-informed machine learning can exhibit advantages over machine\nlearning which fails to account for symmetry. Additionally, recent attention\nhas been given to continuous symmetry discovery using vector fields which serve\nas infinitesimal generators for Lie group symmetries. In this paper, we extend\nthe notion of non-affine symmetry discovery to functions defined by neural\nnetworks. We further extend work in this area by introducing symmetry\nenforcement of smooth models using vector fields. Finally, we extend work on\nsymmetry discovery using vector fields by providing both theoretical and\nexperimental material on the restriction of the symmetry search space to\ninfinitesimal isometries.", "published": "2025-05-13 04:24:46", "link": "http://arxiv.org/abs/2505.08219v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An Effective Flow-based Method for Positive-Unlabeled Learning: 2-HNC", "abstract": "In many scenarios of binary classification, only positive instances are\nprovided in the training data, leaving the rest of the data unlabeled. This\nsetup, known as positive-unlabeled (PU) learning, is addressed here with a\nnetwork flow-based method which utilizes pairwise similarities between samples.\nThe method we propose here, 2-HNC, leverages Hochbaum's Normalized Cut (HNC)\nand the set of solutions it provides by solving a parametric minimum cut\nproblem. The set of solutions, that are nested partitions of the samples into\ntwo sets, correspond to varying tradeoff values between the two goals: high\nintra-similarity inside the sets and low inter-similarity between the two sets.\nThis nested sequence is utilized here to deliver a ranking of unlabeled samples\nby their likelihood of being negative. Building on this insight, our method,\n2-HNC, proceeds in two stages. The first stage generates this ranking without\nassuming any negative labels, using a problem formulation that is constrained\nonly on positive labeled samples. The second stage augments the positive set\nwith likely-negative samples and recomputes the classification. The final label\nprediction selects among all generated partitions in both stages, the one that\ndelivers a positive class proportion, closest to a prior estimate of this\nquantity, which is assumed to be given. Extensive experiments across synthetic\nand real datasets show that 2-HNC yields strong performance and often surpasses\nexisting state-of-the-art algorithms.", "published": "2025-05-13 03:58:16", "link": "http://arxiv.org/abs/2505.08212v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting", "abstract": "Long-term time series forecasting (LTSF) offers broad utility in practical\nsettings like energy consumption and weather prediction. Accurately predicting\nlong-term changes, however, is demanding due to the intricate temporal patterns\nand inherent multi-scale variations within time series. This work confronts key\nissues in LTSF, including the suboptimal use of multi-granularity information,\nthe neglect of channel-specific attributes, and the unique nature of trend and\nseasonal components, by introducing a proficient MLP-based forecasting\nframework. Our method adeptly disentangles complex temporal dynamics using\nclear, concurrent predictions across various scales. These multi-scale\nforecasts are then skillfully integrated through a system that dynamically\nassigns importance to information from different granularities, sensitive to\nindividual channel characteristics. To manage the specific features of temporal\npatterns, a two-pronged structure is utilized to model trend and seasonal\nelements independently. Experimental results on eight LTSF benchmarks\ndemonstrate that MDMixer improves average MAE performance by 4.64% compared to\nthe recent state-of-the-art MLP-based method (TimeMixer), while achieving an\neffective balance between training efficiency and model interpretability.", "published": "2025-05-13 03:26:44", "link": "http://arxiv.org/abs/2505.08199v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SIM-Shapley: A Stable and Computationally Efficient Approach to Shapley Value Approximation", "abstract": "Explainable artificial intelligence (XAI) is essential for trustworthy\nmachine learning (ML), particularly in high-stakes domains such as healthcare\nand finance. Shapley value (SV) methods provide a principled framework for\nfeature attribution in complex models but incur high computational costs,\nlimiting their scalability in high-dimensional settings. We propose Stochastic\nIterative Momentum for Shapley Value Approximation (SIM-Shapley), a stable and\nefficient SV approximation method inspired by stochastic optimization. We\nanalyze variance theoretically, prove linear $Q$-convergence, and demonstrate\nimproved empirical stability and low bias in practice on real-world datasets.\nIn our numerical experiments, SIM-Shapley reduces computation time by up to 85%\nrelative to state-of-the-art baselines while maintaining comparable feature\nattribution quality. Beyond feature attribution, our stochastic mini-batch\niterative framework extends naturally to a broader class of sample average\napproximation problems, offering a new avenue for improving computational\nefficiency with stability guarantees. Code is publicly available at\nhttps://github.com/nliulab/SIM-Shapley.", "published": "2025-05-13 03:23:10", "link": "http://arxiv.org/abs/2505.08198v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Enhancing the Efficiency of Complex Systems Crystal Structure Prediction by Active Learning Guided Machine Learning Potential", "abstract": "Understanding multicomponent complex material systems is essential for design\nof advanced materials for a wide range of technological applications. While\nstate-of-the-art crystal structure prediction (CSP) methods effectively\nidentify new structures and assess phase stability, they face fundamental\nlimitations when applied to complex systems. This challenge stems from the\ncombinatorial explosion of atomic configurations and the vast stoichiometric\nspace, both of which contribute to computational demands that rapidly exceed\npractical feasibility. In this work, we propose a flexible and automated\nworkflow to build a highly generalizable and data-efficient machine learning\npotential (MLP), effectively unlocking the full potential of CSP algorithms.\nThe workflow is validated on both Mg-Ca-H ternary and Be-P-N-O quaternary\nsystems, demonstrating substantial machine learning acceleration in\nhigh-throughput structural optimization and enabling the efficient\nidentification of promising compounds. These results underscore the\neffectiveness of our approach in exploring complex material systems and\naccelerating the discovery of new multicomponent materials.", "published": "2025-05-13 01:34:34", "link": "http://arxiv.org/abs/2505.08159v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Tensor Sketch: Fast and Scalable Polynomial Kernel Approximation", "abstract": "Approximation of non-linear kernels using random feature maps has become a\npowerful technique for scaling kernel methods to large datasets. We propose\n\\textit{Tensor Sketch}, an efficient random feature map for approximating\npolynomial kernels. Given $n$ training samples in $\\R^d$ Tensor Sketch computes\nlow-dimensional embeddings in $\\R^D$ in time $\\BO{n(d+D \\log{D})}$ making it\nwell-suited for high-dimensional and large-scale settings. We provide\ntheoretical guarantees on the approximation error, ensuring the fidelity of the\nresulting kernel function estimates. We also discuss extensions and highlight\napplications where Tensor Sketch serves as a central computational tool.", "published": "2025-05-13 00:47:17", "link": "http://arxiv.org/abs/2505.08146v1", "categories": ["cs.DS", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Beyond Basic A/B testing: Improving Statistical Efficiency for Business Growth", "abstract": "The standard A/B testing approaches are mostly based on t-test in large scale\nindustry applications. These standard approaches however suffers from low\nstatistical power in business settings, due to nature of small sample-size or\nnon-Gaussian distribution or return-on-investment (ROI) consideration. In this\npaper, we propose several approaches to addresses these challenges: (i)\nregression adjustment, generalized estimating equation, Man-Whitney U and\nZero-Trimmed U that addresses each of these issues separately, and (ii) a novel\ndoubly robust generalized U that handles ROI consideration, distribution\nrobustness and small samples in one framework. We provide theoretical results\non asymptotic normality and efficiency bounds, together with insights on the\nefficiency gain from theoretical analysis. We further conduct comprehensive\nsimulation studies and apply the methods to multiple real A/B tests.", "published": "2025-05-13 00:00:06", "link": "http://arxiv.org/abs/2505.08128v1", "categories": ["stat.ME", "cs.LG", "math.ST", "stat.CO", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Scalable UAV Multi-Hop Networking via Multi-Agent Reinforcement Learning with Large Language Models", "abstract": "In disaster scenarios, establishing robust emergency communication networks\nis critical, and unmanned aerial vehicles (UAVs) offer a promising solution to\nrapidly restore connectivity. However, organizing UAVs to form multi-hop\nnetworks in large-scale dynamic environments presents significant challenges,\nincluding limitations in algorithmic scalability and the vast exploration space\nrequired for coordinated decision-making. To address these issues, we propose\nMRLMN, a novel framework that integrates multi-agent reinforcement learning\n(MARL) and large language models (LLMs) to jointly optimize UAV agents toward\nachieving optimal networking performance. The framework incorporates a grouping\nstrategy with reward decomposition to enhance algorithmic scalability and\nbalance decision-making across UAVs. In addition, behavioral constraints are\napplied to selected key UAVs to improve the robustness of the network.\nFurthermore, the framework integrates LLM agents, leveraging knowledge\ndistillation to transfer their high-level decision-making capabilities to MARL\nagents. This enhances both the efficiency of exploration and the overall\ntraining process. In the distillation module, a Hungarian algorithm-based\nmatching scheme is applied to align the decision outputs of the LLM and MARL\nagents and define the distillation loss. Extensive simulation results validate\nthe effectiveness of our approach, demonstrating significant improvements in\nnetwork performance, including enhanced coverage and communication quality.", "published": "2025-05-13 11:23:25", "link": "http://arxiv.org/abs/2505.08448v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A Reynolds-semi-robust H(div)-conforming method for unsteady incompressible non-Newtonian flows", "abstract": "In this work, we prove what appear to be the first Reynolds-semi-robust and\npressure-robust velocity error estimates for an H(div)-conforming approximation\nof unsteady incompressible flows of power-law type fluids. The proposed methods\nhinges on a discontinuous Galerkin approximation of the viscous term and a\nreinforced upwind-type stabilization of the convective term. The derived\nvelocity error estimates account for pre-asymptotic orders of convergence\nobserved in convection-dominated flows through regime-dependent estimates of\nthe error contributions. A complete set of numerical results validate the\ntheoretical findings.", "published": "2025-05-13 16:14:16", "link": "http://arxiv.org/abs/2505.08708v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Learning cardiac activation and repolarization times with operator learning", "abstract": "Solving partial or ordinary differential equation models in cardiac\nelectrophysiology is a computationally demanding task, particularly when\nhigh-resolution meshes are required to capture the complex dynamics of the\nheart. Moreover, in clinical applications, it is essential to employ\ncomputational tools that provide only relevant information, ensuring clarity\nand ease of interpretation. In this work, we exploit two recently proposed\noperator learning approaches, namely Fourier Neural Operators (FNO) and Kernel\nOperator Learning (KOL), to learn the operator mapping the applied stimulus in\nthe physical domain into the activation and repolarization time distributions.\nThese data-driven methods are evaluated on synthetic 2D and 3D domains, as well\nas on a physiologically realistic left ventricle geometry. Notably, while the\nlearned map between the applied current and activation time has its modelling\ncounterpart in the Eikonal model, no equivalent partial differential equation\n(PDE) model is known for the map between the applied current and repolarization\ntime. Our results demonstrate that both FNO and KOL approaches are robust to\nhyperparameter choices and computationally efficient compared to traditional\nPDE-based Monodomain models. These findings highlight the potential use of\nthese surrogate operators to accelerate cardiac simulations and facilitate\ntheir clinical integration.", "published": "2025-05-13 14:50:16", "link": "http://arxiv.org/abs/2505.08631v1", "categories": ["math.NA", "cs.NA", "stat.ML"], "primary_category": "math.NA"}
{"title": "Two-Level Sketching Alternating Anderson acceleration for Complex Physics Applications", "abstract": "We present a novel two-level sketching extension of the Alternating\nAnderson-Picard (AAP) method for accelerating fixed-point iterations in\nchallenging single- and multi-physics simulations governed by discretized\npartial differential equations. Our approach combines a static, physics-based\nprojection that reduces the least-squares problem to the most informative field\n(e.g., via Schur-complement insight) with a dynamic, algebraic sketching stage\ndriven by a backward stability analysis under Lipschitz continuity. We\nintroduce inexpensive estimators for stability thresholds and cache-aware\nrandomized selection strategies to balance computational cost against\nmemory-access overhead. The resulting algorithm solves reduced least-squares\nsystems in place, minimizes memory footprints, and seamlessly alternates\nbetween low-cost Picard updates and Anderson mixing. Implemented in Julia, our\ntwo-level sketching AAP achieves up to 50% time-to-solution reductions compared\nto standard Anderson acceleration-without degrading convergence rates-on\nbenchmark problems including Stokes, p-Laplacian, Bidomain, and Navier-Stokes\nformulations at varying problem sizes. These results demonstrate the method's\nrobustness, scalability, and potential for integration into high-performance\nscientific computing frameworks. Our implementation is available open-source in\nthe AAP.jl library.", "published": "2025-05-13 13:58:22", "link": "http://arxiv.org/abs/2505.08587v1", "categories": ["math.NA", "cs.NA", "65N12, 65N22, 65K10, 65F10, 65F99, 65B99"], "primary_category": "math.NA"}
{"title": "Entropy numbers of classes defined by integral operators", "abstract": "In this paper we develop the following general approach. We study asymptotic\nbehavior of the entropy numbers not for an individual smoothness class, how it\nis usually done, but for the collection of classes, which are defined by\nintegral operators with kernels coming from a given class of functions.\nEarlier, such approach was realized for the Kolmogorov widths.", "published": "2025-05-13 13:46:08", "link": "http://arxiv.org/abs/2505.08572v1", "categories": ["math.NA", "cs.NA", "math.FA"], "primary_category": "math.NA"}
{"title": "Improving Data Fidelity via Diffusion Model-based Correction and Super resolution", "abstract": "We propose a unified diffusion model-based correction and super-resolution\nmethod to enhance the fidelity and resolution of diverse low-quality data\nthrough a two-step pipeline. First, the correction step employs a novel\nenhanced stochastic differential editing technique based on an imbalanced\nperturbation and denoising process, ensuring robust and effective bias\ncorrection at the low-resolution level. The robustness and effectiveness of\nthis approach are validated theoretically and experimentally. Next, the\nsuper-resolution step leverages cascaded conditional diffusion models to\niteratively refine the corrected data to high-resolution. Numerical experiments\non three PDE problems and a climate dataset demonstrate that the proposed\nmethod effectively enhances low-fidelity, low-resolution data by correcting\nnumerical errors and noise while simultaneously improving resolution to recover\nfine-scale structures.", "published": "2025-05-13 12:59:07", "link": "http://arxiv.org/abs/2505.08526v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical Analysis of Stabilization for Random Hyperbolic Systems of Balance Laws", "abstract": "This paper extends the deterministic Lyapunov-based stabilization framework\nto random hyperbolic systems of balance laws, where uncertainties arise in\nboundary controls and initial data. Building on the finite volume\ndiscretization method from [{\\sc M. Banda and M. Herty}, Math. Control Relat.\nFields., 3 (2013), pp. 121--142], we introduce a stochastic discrete Lyapunov\nfunction to prove the exponential decay of numerical solutions for systems with\nrandom perturbations. For linear systems, we derive explicit decay rates, which\ndepend on boundary control parameters, grid resolutions, and the statistical\nproperties of the random inputs. Theoretical decay rates are verified through\nnumerical examples, including boundary stabilization of the linear wave\nequations and linearized shallow-water flows with random perturbations. We also\ndemonstrate the decay rates for a nonlinear example.", "published": "2025-05-13 12:42:31", "link": "http://arxiv.org/abs/2505.08511v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical Solution of Mixed-Dimensional PDEs Using a Neural Preconditioner", "abstract": "Mixed-dimensional partial differential equations (PDEs) are characterized by\ncoupled operators defined on domains of varying dimensions and pose significant\ncomputational challenges due to their inherent ill-conditioning. Moreover, the\ncomputational workload increases considerably when attempting to accurately\ncapture the behavior of the system under significant variations or\nuncertainties in the low-dimensional structures such as fractures, fibers, or\nvascular networks, due to the inevitable necessity of running multiple\nsimulations. In this work, we present a novel preconditioning strategy that\nleverages neural networks and unsupervised operator learning to design an\nefficient preconditioner specifically tailored to a class of 3D-1D\nmixed-dimensional PDEs. The proposed approach is capable of generalizing to\nvarying shapes of the 1D manifold without retraining, making it robust to\nchanges in the 1D graph topology. Moreover, thanks to convolutional neural\nnetworks, the neural preconditioner can adapt over a range of increasing mesh\nresolutions of the discrete problem, enabling us to train it on low resolution\nproblems and deploy it on higher resolutions. Numerical experiments validate\nthe effectiveness of the preconditioner in accelerating convergence in\niterative solvers, demonstrating its appeal and limitations over traditional\nmethods. This study lays the groundwork for applying neural network-based\npreconditioning techniques to a broader range of coupled multi-physics systems.", "published": "2025-05-13 12:22:08", "link": "http://arxiv.org/abs/2505.08491v1", "categories": ["math.NA", "cs.NA", "65F08, 65N30, 65N22, 35J57, 68T07", "G.1.3; I.2.6; G.1.8"], "primary_category": "math.NA"}
{"title": "An Optimal and Robust Nonconforming Finite Element Method for the Strain Gradient Elasticity", "abstract": "An optimal and robust low-order nonconforming finite element method is\ndeveloped for the strain gradient elasticity (SGE) model in arbitrary\ndimension. An $H^2$-nonconforming quadratic vector-valued finite element in\narbitrary dimension is constructed, which together with an $H^1$-nonconforming\nscalar finite element and the Nitsche's technique, is applied for solving the\nSGE model. The resulting nonconforming finite element method is optimal and\nrobust with respect to the Lam\\'{e} coefficient $\\lambda$ and the size\nparameter $\\iota$, as confirmed by numerical results. Additionally,\nnonconforming finite element discretization of the smooth Stokes complex in two\nand three dimensions is devised.", "published": "2025-05-13 11:41:24", "link": "http://arxiv.org/abs/2505.08461v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Lower bounds for the reach and applications", "abstract": "The reach of a submanifold of $\\mathbb{R}^N$ is defined as the largest radius\nof a tubular neighbourhood around the submanifold that avoids\nself-intersections. While essential in geometric and topological applications,\ncomputing the reach explicitly is notoriously difficult. In this paper, we\nintroduce a rigorous and practical method to compute a guaranteed lower bound\nfor the reach of a submanifold described as the common zero-set of finitely\nmany smooth functions, not necessarily polynomials. Our algorithm uses\ntechniques from numerically verified proofs and is particularly suitable for\nhigh-performance parallel implementations.\n  We illustrate the utility of this method through several applications. Of\nspecial note is a novel algorithm for computing the homology groups of planar\ncurves, achieved by constructing a cubical complex that deformation retracts\nonto the curve--an approach potentially extendable to higher-dimensional\nmanifolds. Additional applications include an improved comparison inequality\nbetween intrinsic and extrinsic distances for submanifolds of $\\mathbb{R}^N$,\nlower bounds for the first eigenvalue of the Laplacian on algebraic varieties\nand explicit bounds on how much smooth varieties can be deformed without\nchanging their diffeomorphism type.", "published": "2025-05-13 10:45:39", "link": "http://arxiv.org/abs/2505.08427v1", "categories": ["math.NA", "cs.NA", "65D18"], "primary_category": "math.NA"}
{"title": "A Fourier finite volume approach for the optical inverse problem of quantitative photoacoustic tomography", "abstract": "A new approach for solving the optical inverse problem of quantitative\nphotoacoustic tomography is introduced, which interpolates between the\nwell-known diffusion approximation and a radiative transfer equation based\nmodel. The proposed formulation combines a spatial finite volume scheme with a\ntruncated Fourier expansion in the direction variable for the radiative\ntransfer equation. The finite volume scheme provides a natural and simple\napproach for representing piecewise constant image data modelled using\ntransport equations. The truncated Fourier expansion in the direction variable\nfacilitates the interpolation between the diffusion approximation at low order,\nand the full radiative transfer model as the truncation limit\n$N\\rightarrow\\infty$. It is therefore possible to tune the precision of the\nmodel to the demands of the imaging application, taking $N=1$ for cases when\nthe diffusion approximation would suffice and increasing the number of terms\notherwise. We will then utilise the non-linear optimisation functionality of\nMatlab to address the corresponding large-scale nonlinear inverse problem using\ngradient based quasi-Newton minimisation via the limited memory\nBroyden-Fletcher-Goldfarb-Shanno algorithm. Numerical experiments for two\ntest-cases of increasing complexity and resolution will be presented, and the\neffect of logarithmically rescaling the problem data on the accuracy of the\nreconstructed solutions will be investigated. We will focus on cases where the\ndiffusion approximation is not sufficient to demonstrate that our approach can\nprovide significant accuracy gains with only a modest increase in the number of\nFourier terms included.", "published": "2025-05-13 09:55:39", "link": "http://arxiv.org/abs/2505.08400v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "physics.med-ph"], "primary_category": "physics.comp-ph"}
{"title": "The Lax--Wendroff theorem for Patankar-type methods applied to hyperbolic conservation laws", "abstract": "For hyperbolic conservation laws, the famous Lax--Wendroff theorem delivers\nsufficient conditions for the limit of a convergent numerical method to be a\nweak (entropy) solution. This theorem is a fundamental result, and many\ninvestigations have been done to verify its validity for finite difference,\nfinite volume, and finite element schemes, using either explicit or implicit\nlinear time-integration methods. Recently, the use of modified Patankar (MP)\nschemes as time-integration methods for the discretization of hyperbolic\nconservation laws has gained increasing interest. These schemes are\nunconditionally conservative and positivity-preserving and only require the\nsolution of a linear system. However, MP schemes are by construction nonlinear,\nwhich is why the theoretical investigation of these schemes is more involved.\nWe prove an extension of the Lax--Wendroff theorem for the class of MP methods.\nThis is the first extension of the Lax--Wendroff theorem to nonlinear time\nintegration methods with just an additional hypothesis on the total time\nvariation boundness of the numerical solutions. We provide some numerical\nsimulations that validate the theoretical observations.", "published": "2025-05-13 09:34:21", "link": "http://arxiv.org/abs/2505.08387v1", "categories": ["math.NA", "cs.NA", "65M06, 65M20, 65L06"], "primary_category": "math.NA"}
{"title": "Nonlinear optical response in kagome lattice with inversion symmetry breaking", "abstract": "The kagome lattice is a fundamental model structure in condensed matter\nphysics and materials science featuring symmetry-protected flat bands, saddle\npoints, and Dirac points. This structure has emerged as an ideal platform for\nexploring various quantum physics. By combining effective model analysis and\nfirst-principles calculations, we propose that the synergy among inversion\nsymmetry breaking, flat bands, and saddle point-related van Hove singularities\nwithin the kagome lattice holds significant potential for generating strong\nsecond-order nonlinear optical response. This property provides an inspiring\ninsight into the practical application of the kagome-like materials, which is\nhelpful for a comprehensive understanding of kagome lattice-related physics.\nMoreover, this work offers an alternative approach for designing materials with\nstrong a second-order nonlinear optical response.", "published": "2025-05-13 07:06:43", "link": "http://arxiv.org/abs/2505.08289v1", "categories": ["physics.optics", "cond-mat.mtrl-sci", "cs.NA", "math.NA"], "primary_category": "physics.optics"}
{"title": "Local Convergence Behavior of Extended LOBPCG for Computing Eigenvalues of Hermitian Matrices", "abstract": "This paper provides a comprehensive and detailed analysis of the local\nconvergence behavior of an extended variation of the locally optimal\npreconditioned conjugate gradient method (LOBPCG) for computing the extreme\neigenvalue of a Hermitian matrix. The convergence rates derived in this work\nare either obtained for the first time or sharper than those previously\nestablished, including those in Ovtchinnikov's work ({\\em SIAM J. Numer.\nAnal.}, 46(5):2567--2592, 2008). The study also extends to generalized\nproblems, including Hermitian matrix polynomials that admit an extended form of\nthe Rayleigh quotient. The new approach used to obtain these rates may also\nserve as a valuable tool for the convergence analysis of other gradient-type\noptimization methods.", "published": "2025-05-13 04:24:09", "link": "http://arxiv.org/abs/2505.08218v1", "categories": ["math.NA", "cs.NA", "65F15"], "primary_category": "math.NA"}
{"title": "Adaptive and hybrid reduced order models to mitigate Kolmogorov barrier in a multiscale kinetic transport equation", "abstract": "In this work, we develop reduced order models (ROMs) to predict solutions to\na multiscale kinetic transport equation with a diffusion limit under the\nparametric setting. When the underlying scattering effect is not sufficiently\nstrong, the system governed by this equation exhibits transport-dominated\nbehavior. Suffering from the Kolmogorov barrier for transport-dominant\nproblems, classical linear ROMs may become inefficient in this regime. To\naddress this issue, we first develop a piecewise linear ROM by introducing a\nnovel goal-oriented adaptive time partitioning strategy. To avoid local\nover-refinement or under-refinement, we propose an adaptive coarsening and\nrefinement strategy that remains robust with various initial empirical\npartitions. Additionally, for problems where a local linear approximation is\nnot sufficiently efficient, we further develop a hybrid ROM, which combines\nautoencoder-based nonlinear ROMs and piecewise linear ROMs. Compared to\nprevious autoencoder-based ROMs, this hybridized method reduces the offline\nautoencoder's training cost by only applying it to time intervals that are\nadaptively identified as the most challenging. Numerical experiments\ndemonstrate that our proposed approaches successfully predict full-order\nsolutions at unseen parameter values with both efficiency and accuracy. To the\nbest of our knowledge, this is the first attempt to address the Kolmogorov\nbarrier for multiscale kinetic transport problems with the coexistence of both\ntransport- and diffusion-dominant behaviors.", "published": "2025-05-13 04:07:47", "link": "http://arxiv.org/abs/2505.08214v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Dyadic Factorization and Efficient Inversion of Sparse Positive Definite Matrices", "abstract": "In inverting large sparse matrices, the key difficulty lies in effectively\nexploiting sparsity during the inversion process. One well-established strategy\nis the nested dissection, which seeks the so-called sparse Cholesky\nfactorization. We argue that the matrices for which such factors can be found\nare characterized by a hidden dyadic sparsity structure. This paper builds on\nthat idea by proposing an efficient approach for inverting such matrices. The\nmethod consists of two independent steps: the first packs the matrix into a\ndyadic form, while the second performs a sparse (dyadic) Gram-Schmidt\northogonalization of the packed matrix.\n  The novel packing procedure works by recovering block-tridiagonal structures,\nfocusing on aggregating terms near the diagonal using the $l_1$-norm, which\ncontrasts with traditional methods that prioritize minimizing bandwidth, i.e.\nthe $l_\\infty$-norm. The algorithm performs particularly well for matrices that\ncan be packed into banded or dyadic forms which are moderately dense. Due to\nthe properties of $l_1$-norm, the packing step can be applied iteratively to\nreconstruct the hidden dyadic structure, which corresponds to the detection of\nseparators in the nested dissection method.\n  We explore the algebraic properties of dyadic-structured matrices and present\nan algebraic framework that allows for a unified mathematical treatment of both\nsparse factorization and efficient inversion of factors. For matrices with a\ndyadic structure, we introduce an optimal inversion algorithm and evaluate its\ncomputational complexity.\n  The proposed inversion algorithm and core algebraic operations for dyadic\nmatrices are implemented in the R package DyadiCarma, utilizing Rcpp and\nRcppArmadillo for high-performance computing. An independent R-based matrix\npacking module, supported by C++ code, is also provided.", "published": "2025-05-13 00:33:44", "link": "http://arxiv.org/abs/2505.08144v1", "categories": ["math.NA", "cs.NA", "stat.CO", "15A23 (Primary), 15A09, 68Q25, 68R10 (Secondary)"], "primary_category": "math.NA"}
{"title": "Forecasting Intraday Volume in Equity Markets with Machine Learning", "abstract": "This study focuses on forecasting intraday trading volumes, a crucial\ncomponent for portfolio implementation, especially in high-frequency (HF)\ntrading environments. Given the current scarcity of flexible methods in this\narea, we employ a suite of machine learning (ML) models enriched with numerous\nHF predictors to enhance the predictability of intraday trading volumes. Our\nfindings reveal that intraday stock trading volume is highly predictable,\nespecially with ML and considering commonality. Additionally, we assess the\neconomic benefits of accurate volume forecasting through Volume Weighted\nAverage Price (VWAP) strategies. The results demonstrate that precise intraday\nforecasting offers substantial advantages, providing valuable insights for\ntraders to optimize their strategies.", "published": "2025-05-13 02:34:58", "link": "http://arxiv.org/abs/2505.08180v1", "categories": ["q-fin.CP", "q-fin.ST"], "primary_category": "q-fin.CP"}
{"title": "An Efficient Multi-scale Leverage Effect Estimator under Dependent Microstructure Noise", "abstract": "Estimating the leverage effect from high-frequency data is vital but\nchallenged by complex, dependent microstructure noise, often exhibiting\nnon-Gaussian higher-order moments. This paper introduces a novel multi-scale\nframework for efficient and robust leverage effect estimation under such\nflexible noise structures. We develop two new estimators, the\nSubsampling-and-Averaging Leverage Effect (SALE) and the Multi-Scale Leverage\nEffect (MSLE), which adapt subsampling and multi-scale approaches holistically\nusing a unique shifted window technique. This design simplifies the multi-scale\nestimation procedure and enhances noise robustness without requiring the\npre-averaging approach. We establish central limit theorems and stable\nconvergence, with MSLE achieving convergence rates of an optimal $n^{-1/4}$ and\na near-optimal $n^{-1/9}$ for the noise-free and noisy settings, respectively.\nA cornerstone of our framework's efficiency is a specifically designed MSLE\nweighting strategy that leverages covariance structures across scales. This\nsignificantly reduces asymptotic variance and, critically, yields substantially\nsmaller finite-sample errors than existing methods under both noise-free and\nrealistic noisy settings. Extensive simulations and empirical analyses confirm\nthe superior efficiency, robustness, and practical advantages of our approach.", "published": "2025-05-13 15:15:37", "link": "http://arxiv.org/abs/2505.08654v1", "categories": ["stat.ME", "econ.EM", "q-fin.ST"], "primary_category": "stat.ME"}
{"title": "Extreme Conformal Prediction: Reliable Intervals for High-Impact Events", "abstract": "Conformal prediction is a popular method to construct prediction intervals\nfor black-box machine learning models with marginal coverage guarantees. In\napplications with potentially high-impact events, such as flooding or financial\ncrises, regulators often require very high confidence for such intervals.\nHowever, if the desired level of confidence is too large relative to the amount\nof data used for calibration, then classical conformal methods provide\ninfinitely wide, thus, uninformative prediction intervals. In this paper, we\npropose a new method to overcome this limitation. We bridge extreme value\nstatistics and conformal prediction to provide reliable and informative\nprediction intervals with high-confidence coverage, which can be constructed\nusing any black-box extreme quantile regression method. The advantages of this\nextreme conformal prediction method are illustrated in a simulation study and\nin an application to flood risk forecasting.", "published": "2025-05-13 13:54:36", "link": "http://arxiv.org/abs/2505.08578v1", "categories": ["stat.ME", "stat.AP", "stat.ML"], "primary_category": "stat.ME"}
{"title": "A note on concentration inequalities for the overlapped batch mean variance estimators for Markov chains", "abstract": "In this paper, we study the concentration properties of quadratic forms\nassociated with Markov chains using the martingale decomposition method\nintroduced by Atchad\\'e and Cattaneo (2014). In particular, we derive\nconcentration inequalities for the overlapped batch mean (OBM) estimators of\nthe asymptotic variance for uniformly geometrically ergodic Markov chains. Our\nmain result provides an explicit control of the $p$-th moment of the difference\nbetween the OBM estimator and the asymptotic variance of the Markov chain with\nexplicit dependence upon $p$ and mixing time of the underlying Markov chain.", "published": "2025-05-13 11:36:04", "link": "http://arxiv.org/abs/2505.08456v1", "categories": ["math.PR", "math.ST", "stat.ML", "stat.TH", "60J10, 60J22, 62M10"], "primary_category": "math.PR"}
{"title": "Bayesian Estimation of Causal Effects Using Proxies of a Latent Interference Network", "abstract": "Network interference occurs when treatments assigned to some units affect the\noutcomes of others. Traditional approaches often assume that the observed\nnetwork correctly specifies the interference structure. However, in practice,\nresearchers frequently only have access to proxy measurements of the\ninterference network due to limitations in data collection or potential\nmismatches between measured networks and actual interference pathways. In this\npaper, we introduce a framework for estimating causal effects when only proxy\nnetworks are available. Our approach leverages a structural causal model that\naccommodates diverse proxy types, including noisy measurements, multiple data\nsources, and multilayer networks, and defines causal effects as interventions\non population-level treatments. Since the true interference network is latent,\nestimation poses significant challenges. To overcome them, we develop a\nBayesian inference framework. We propose a Block Gibbs sampler with Locally\nInformed Proposals to update the latent network, thereby efficiently exploring\nthe high-dimensional posterior space composed of both discrete and continuous\nparameters. We illustrate the performance of our method through numerical\nexperiments, demonstrating its accuracy in recovering causal effects even when\nonly proxies of the interference network are available.", "published": "2025-05-13 09:46:30", "link": "http://arxiv.org/abs/2505.08395v1", "categories": ["stat.ME", "stat.AP", "stat.CO", "stat.ML", "stat.OT"], "primary_category": "stat.ME"}
{"title": "High-dimensional Bayesian Tobit regression for censored response with Horseshoe prior", "abstract": "Censored response variables--where outcomes are only partially observed due\nto known bounds--arise in numerous scientific domains and present serious\nchallenges for regression analysis. The Tobit model, a classical solution for\nhandling left-censoring, has been widely used in economics and beyond. However,\nwith the increasing prevalence of high-dimensional data, where the number of\ncovariates exceeds the sample size, traditional Tobit methods become\ninadequate. While frequentist approaches for high-dimensional Tobit regression\nhave recently been developed, notably through Lasso-based estimators, the\nBayesian literature remains sparse and lacks theoretical guarantees. In this\nwork, we propose a novel Bayesian framework for high-dimensional Tobit\nregression that addresses both censoring and sparsity. Our method leverages the\nHorseshoe prior to induce shrinkage and employs a data augmentation strategy to\nfacilitate efficient posterior computation via Gibbs sampling. We establish\nposterior consistency and derive concentration rates under sparsity, providing\nthe first theoretical results for Bayesian Tobit models in high dimensions.\nNumerical experiments show that our approach outperforms favorably with the\nrecent Lasso-Tobit method.\n  Our method is implemented in the R package tobitbayes, which can be found on\nGithub.", "published": "2025-05-13 07:05:27", "link": "http://arxiv.org/abs/2505.08288v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Three Tone Networks and a Tessellation", "abstract": "We show that the Eulerian tonnetz, which associates three minor chords to\neach major chord and three major chords to each minor chord, can be represented\nby a bipartite graph with twelve white vertices signifying major chords and\ntwelve black vertices signifying minor chords. This so-called Levi graph\nuniquely determines the combinatorial geometry of a certain remarkable\nconfiguration of twelve points and twelve lines in the real projective plane\nwith the property that three points lie on each line and three lines pass\nthrough each point. Interesting features of the tonnetz, such as the existence\nof Cohn's four hexatonic cycles, crucial for the understanding of\nnineteenth-century voice leading and extended harmony, can be read off rather\ndirectly as properties of the configuration. We show that analogous tone\nnetworks can be constructed for pentatonic music and twelve-tone music.", "published": "2025-05-13 17:13:14", "link": "http://arxiv.org/abs/2505.08752v1", "categories": ["math.CO", "eess.AS", "math.AG"], "primary_category": "math.CO"}
{"title": "Granite-speech: open-source speech-aware LLMs with strong English ASR capabilities", "abstract": "Granite-speech LLMs are compact and efficient speech language models\nspecifically designed for English ASR and automatic speech translation (AST).\nThe models were trained by modality aligning the 2B and 8B parameter variants\nof granite-3.3-instruct to speech on publicly available open-source corpora\ncontaining audio inputs and text targets consisting of either human transcripts\nfor ASR or automatically generated translations for AST. Comprehensive\nbenchmarking shows that on English ASR, which was our primary focus, they\noutperform several competitors' models that were trained on orders of magnitude\nmore proprietary data, and they keep pace on English-to-X AST for major\nEuropean languages, Japanese, and Chinese. The speech-specific components are:\na conformer acoustic encoder using block attention and self-conditioning\ntrained with connectionist temporal classification, a windowed\nquery-transformer speech modality adapter used to do temporal downsampling of\nthe acoustic embeddings and map them to the LLM text embedding space, and LoRA\nadapters to further fine-tune the text LLM. Granite-speech-3.3 operates in two\nmodes: in speech mode, it performs ASR and AST by activating the encoder,\nprojector, and LoRA adapters; in text mode, it calls the underlying\ngranite-3.3-instruct model directly (without LoRA), essentially preserving all\nthe text LLM capabilities and safety. Both models are freely available on\nHuggingFace (https://huggingface.co/ibm-granite/granite-speech-3.3-2b and\nhttps://huggingface.co/ibm-granite/granite-speech-3.3-8b) and can be used for\nboth research and commercial purposes under a permissive Apache 2.0 license.", "published": "2025-05-13 15:58:57", "link": "http://arxiv.org/abs/2505.08699v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Investigating self-supervised features for expressive, multilingual voice conversion", "abstract": "Voice conversion (VC) systems are widely used for several applications, from\nspeaker anonymisation to personalised speech synthesis. Supervised approaches\nlearn a mapping between different speakers using parallel data, which is\nexpensive to produce. Unsupervised approaches are typically trained to\nreconstruct the input signal, which is composed of the content and the speaker\ninformation. Disentangling these components is a challenge and often leads to\nspeaker leakage or prosodic information removal. In this paper, we explore\nvoice conversion by leveraging the potential of self-supervised learning (SSL).\nA combination of the latent representations of SSL models, concatenated with\nspeaker embeddings, is fed to a vocoder which is trained to reconstruct the\ninput. Zero-shot voice conversion results show that this approach allows to\nkeep the prosody and content of the source speaker while matching the speaker\nsimilarity of a VC system based on phonetic posteriorgrams (PPGs).", "published": "2025-05-13 06:44:03", "link": "http://arxiv.org/abs/2505.08278v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "GNN-based Precoder Design and Fine-tuning for Cell-free Massive MIMO with Real-world CSI", "abstract": "Cell-free massive MIMO (CF-mMIMO) has emerged as a promising paradigm for\ndelivering uniformly high-quality coverage in future wireless networks. To\naddress the inherent challenges of precoding in such distributed systems,\nrecent studies have explored the use of graph neural network (GNN)-based\nmethods, using their powerful representation capabilities. However, these\napproaches have predominantly been trained and validated on synthetic datasets,\nleaving their generalizability to real-world propagation environments largely\nunverified. In this work, we initially pre-train the GNN using simulated\nchannel state information (CSI) data, which incorporates standard propagation\nmodels and small-scale Rayleigh fading. Subsequently, we finetune the model on\nreal-world CSI measurements collected from a physical testbed equipped with\ndistributed access points (APs). To balance the retention of pre-trained\nfeatures with adaptation to real-world conditions, we adopt a layer-freezing\nstrategy during fine-tuning, wherein several GNN layers are frozen and only the\nlater layers remain trainable. Numerical results demonstrate that the\nfine-tuned GNN significantly outperforms the pre-trained model, achieving an\napproximate 8.2 bits per channel use gain at 20 dB signal-to-noise ratio (SNR),\ncorresponding to a 15.7 % improvement. These findings highlight the critical\nrole of transfer learning and underscore the potential of GNN-based precoding\ntechniques to effectively generalize from synthetic to real-world wireless\nenvironments.", "published": "2025-05-13 17:59:47", "link": "http://arxiv.org/abs/2505.08788v1", "categories": ["eess.SP", "94A15 (Primary), 68T05 (Secondary)"], "primary_category": "eess.SP"}
{"title": "3GPP-Compliant Radar Cross Section Characterization of Indoor Factory Targets", "abstract": "The following paper presents a systematic 3rd Generation Partnership Project\n(3GPP)-compliant characterization of radar cross section (RCS) for indoor\nfactory (InF) objects, including small and mid-sized unmanned aerial vehicles\n(UAVs), robotic arms, and automated guided vehicles (AGVs). Through\nmeasurements in the 25-28 GHz range, we validate the 3GPP standardized\nlog-normal distribution model for RCS for above-mentioned target objects. The\n3GPP-complaint RCS parameters obtained for the small-sized UAV are in close\nagreement (<1 dB deviation) with 3GPP agreed values. The mid-sized UAVs exhibit\nhigher reflectivity compared to the small-sized UAV due to enhanced specular\ncomponents attributed to material and lithium-ion battery packs. The robotic\narm exhibits dynamic RCS behavior due to mechanical articulation, whereas UAVs\nshow clear size-dependent reflectivity patterns in AGVs. Our findings provide\nempirical validation for RCS characterization for integrated sensing and\ncommunication channel modeling in InF environments.", "published": "2025-05-13 17:15:10", "link": "http://arxiv.org/abs/2505.08754v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Robust Beamforming Design for STAR-RIS Aided RSMA Network with Hardware Impairments", "abstract": "In this article, we investigate the robust beamforming design for a\nsimultaneous transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) aided downlink rate-splitting multiple access (RSMA) communication\nsystem, where both transceivers and STAR-RIS suffer from the impact of hardware\nimpairments (HWI). A base station (BS) is deployed to transmit messages\nconcurrently to multiple users, utilizing a STAR-RIS to improve communication\nquality and expand user coverage. We aim to maximize the achievable sum rate of\nthe users while ensuring the constraints of transmit power, STAR-RIS\ncoefficients, and the actual rate of the common stream for all users. To solve\nthis challenging high-coupling and non-convexity problem, we adopt a fractional\nprogramming (FP)-based alternating optimization (AO) approach, where each\nsub-problem is addressed via semidefinite relaxation (SDR) and successive\nconvex approximation (SCA) methods. Numerical results demonstrate that the\nproposed scheme outperforms other multiple access schemes and conventional\npassive RIS in terms of the achievable sum rate. Additionally, considering the\nHWI of the transceiver and STAR-RIS makes our algorithm more robust than when\nsuch considerations are not included.", "published": "2025-05-13 14:58:55", "link": "http://arxiv.org/abs/2505.08642v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Optimization of User Association and Resource Allocation for Load Balancing With Multi-Level Fairness", "abstract": "User association, the problem of assigning each user device to a suitable\nbase station, is increasingly crucial as wireless networks become denser and\nserve more users with diverse service demands. The joint optimization of user\nassociation and resource allocation (UARA) is a fundamental issue for future\nwireless networks, as it plays a pivotal role in enhancing overall network\nperformance, user fairness, and resource efficiency. Given the\nlatency-sensitive nature of emerging network applications, network management\nfavors algorithms that are simple and computationally efficient rather than\ncomplex centralized approaches. Thus, distributed pricing-based strategies have\ngained prominence in the UARA literature, demonstrating practicality and\neffectiveness across various objective functions, e.g., sum-rate, proportional\nfairness, max-min fairness, and alpha-fairness. While the alpha-fairness\nframeworks allow for flexible adjustments between efficiency and fairness via a\nsingle parameter $\\alpha$, existing works predominantly assume a homogeneous\nfairness context, assigning an identical $\\alpha$ value to all users.\nReal-world networks, however, frequently require differentiated user\nprioritization due to varying application requirements and latency. To bridge\nthis gap, we propose a novel heterogeneous alpha-fairness (HAF) objective\nfunction, assigning distinct {\\alpha} values to different users, thereby\nproviding enhanced control over the balance between throughput, fairness, and\nlatency across the network. We present a distributed, pricing-based\noptimization approach utilizing an auxiliary variable framework and provide\nanalytical proof of its convergence to an $\\epsilon$-optimal solution, where\nthe optimality gap $\\epsilon$ decreases with the number of iterations.", "published": "2025-05-13 13:46:26", "link": "http://arxiv.org/abs/2505.08573v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Extract the Best, Discard the Rest: CSI Feedback with Offline Large AI Models", "abstract": "Large AI models (LAMs) have shown strong potential in wireless communication\ntasks, but their practical deployment remains hindered by latency and\ncomputational constraints. In this work, we focus on the challenge of\nintegrating LAMs into channel state information (CSI) feedback for\nfrequency-division duplex (FDD) massive multiple-intput multiple-output (MIMO)\nsystems. To this end, we propose two offline frameworks, namely site-specific\nLAM-enhanced CSI feedback (SSLCF) and multi-scenario LAM-enhanced CSI feedback\n(MSLCF), that incorporate LAMs into the codebook-based CSI feedback paradigm\nwithout requiring real-time inference. Specifically, SSLCF generates a\nsite-specific enhanced codebook through fine-tuning on locally collected CSI\ndata, while MSLCF improves generalization by pre-generating a set of\nenvironment-aware codebooks. Both of these frameworks build upon the LAM with\nvision-based backbone, which is pre-trained on large-scale image datasets and\nfine-tuned with CSI data to generate customized codebooks. This resulting\nnetwork named LVM4CF captures the structural similarity between CSI and image,\nallowing the LAM to refine codewords tailored to the specific environments. To\noptimize the codebook refinement capability of LVM4CF under both single- and\ndual-side deployment modes, we further propose corresponding training and\ninference algorithms. Simulation results show that our frameworks significantly\noutperform existing schemes in both reconstruction accuracy and system\nthroughput, without introducing additional inference latency or computational\noverhead. These results also support the core design methodology of our\nproposed frameworks, extracting the best and discarding the rest, as a\npromising pathway for integrating LAMs into future wireless systems.", "published": "2025-05-13 13:41:04", "link": "http://arxiv.org/abs/2505.08566v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Short Wins Long: Short Codes with Language Model Semantic Correction Outperform Long Codes", "abstract": "This paper presents a novel semantic-enhanced decoding scheme for\ntransmitting natural language sentences with multiple short block codes over\nnoisy wireless channels. After ASCII source coding, the natural language\nsentence message is divided into segments, where each is encoded with short\nblock channel codes independently before transmission. At the receiver, each\nshort block of codewords is decoded in parallel, followed by a semantic error\ncorrection (SEC) model to reconstruct corrupted segments semantically. We\ndesign and train the SEC model based on Bidirectional and Auto-Regressive\nTransformers (BART). Simulations demonstrate that the proposed scheme can\nsignificantly outperform encoding the sentence with one conventional long LDPC\ncode, in terms of block error rate (BLER), semantic metrics, and decoding\nlatency. Finally, we proposed a semantic hybrid automatic repeat request (HARQ)\nscheme to further enhance the error performance, which selectively requests\nretransmission depends on semantic uncertainty.", "published": "2025-05-13 13:07:01", "link": "http://arxiv.org/abs/2505.08536v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI-Driven Digital Twins: Optimizing 5G/6G Network Slicing with NTNs", "abstract": "Network slicing in 5G/6G Non-Terrestrial Network (NTN) is confronted with\nmobility and traffic variability. An artificial intelligence (AI)-based digital\ntwin (DT) architecture with deep reinforcement learning (DRL) using Deep\ndeterministic policy gradient (DDPG) is proposed for dynamic optimization of\nresource allocation. DT virtualizes network states to enable predictive\nanalysis, while DRL changes bandwidth for eMBB slice. Simulations show a 25\\%\nlatency reduction compared to static methods, with enhanced resource\nutilization. This scalable solution supports 5G/6G NTN applications like\ndisaster recovery and urban blockage.", "published": "2025-05-13 08:09:13", "link": "http://arxiv.org/abs/2505.08328v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "SemCSINet: A Semantic-Aware CSI Feedback Network in Massive MIMO Systems", "abstract": "Massive multiple-input multiple-output (MIMO) technology is a key enabler of\nmodern wireless communication systems, which demand accurate downlink channel\nstate information (CSI) for optimal performance. Although deep learning (DL)\nhas shown great potential in improving CSI feedback, most existing approaches\nfail to exploit the semantic relationship between CSI and other related channel\nmetrics. In this paper, we propose SemCSINet, a semantic-aware\nTransformer-based framework that incorporates Channel Quality Indicator (CQI)\ninto the CSI feedback process. By embedding CQI information and leveraging a\njoint coding-modulation (JCM) scheme, SemCSINet enables efficient,\ndigital-friendly CSI feedback under noisy feedback channels. Experimental\nresults on DeepMIMO datasets show that SemCSINet significantly outperforms\nconventional methods, particularly in scenarios with low signal-to-noise ratio\n(SNR) and low compression ratios (CRs), highlighting the effectiveness of\nsemantic embedding in enhancing CSI reconstruction accuracy and system\nrobustness.", "published": "2025-05-13 07:43:12", "link": "http://arxiv.org/abs/2505.08314v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-Active RIS-Assisted THz Cell-Free Systems: Spectral and Energy Efficiency Tradeoff", "abstract": "Reconfigurable intelligent surfaces (RISs) and cell-free massive\nmultiple-input multiple-output (CF-mMIMO) are effective solutions for\nmitigating large path loss and inter-cell interference in terahertz (THz)\nsystems. However, passive RISs are notably limited from double-fading\nattenuation, motivating the use of active RISs with power amplification to\nimprove signal strength. In this paper, we investigate a multi-active RIS-aided\nwideband CF-mMIMO system for THz communications, considering low-resolution\ndigital-to-analog converters (DACs) to optimize the spectral efficiency\n(SE)-energy efficiency (EE) tradeoff by adjusting precoding vectors and\nreflection coefficient response of the RISs, subject to power and minimum\ndesirable per-user rate constraints. This leads to a highly complex and\nnon-convex, multi-objective and fractional optimization problem. To solve it,\nwe propose a tailored quadratic transformation to manage the fractional form.\nThis allows decomposition into two subproblems, which are iteratively solved\nvia a successive convex approximation algorithm to optimize the precoding\nvectors and active RIS reflection coefficients until convergence. Numerical\nresults demonstrate that the proposed active RIS-aided CF-mMIMO system\neffectively addresses propagation loss and limited scattering in THz\ncommunication, achieving superior EE and SE compared to conventional passive\nRIS across diverse scenarios. Furthermore, the integration of low-resolution\nDACs shows significant improvement in EE while preserving satisfactory\ncommunication performance.", "published": "2025-05-13 07:03:35", "link": "http://arxiv.org/abs/2505.08287v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sparsity-Aware Near-Field Beam Training via Multi-Beam Combination", "abstract": "This paper proposes an adaptive near-field beam training method to enhance\nperformance in multi-user and multipath environments. The approach identifies\nmultiple strongest beams through beam sweeping and linearly combines their\nreceived signals - capturing both amplitude and phase - for improved channel\nestimation. Two codebooks are considered: the conventional DFT codebook and a\nnear-field codebook that samples both angular and distance domains. As the\nnear-field basis functions are generally non-orthogonal and often\nover-complete, we exploit sparsity in the solution using LASSO-based linear\nregression, which can also suppress noise. Simulation results show that the\nnear-field codebook reduces feedback overhead by up to 95% compared to the DFT\ncodebook. The proposed LASSO regression method also maintains robustness under\nvarying noise levels, particularly in low SNR regions. Furthermore, an off-grid\nrefinement scheme is introduced to enhance accuracy especially when the\ncodebook sampling is coarse, improving reconstruction accuracy by 69.4%.", "published": "2025-05-13 06:32:24", "link": "http://arxiv.org/abs/2505.08267v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "N$^2$LoS: Single-Tag mmWave Backscatter for Robust Non-Line-of-Sight Localization", "abstract": "The accuracy of traditional localization methods significantly degrades when\nthe direct path between the wireless transmitter and the target is blocked or\nnon-penetrable. This paper proposes N2LoS, a novel approach for precise\nnon-line-of-sight (NLoS) localization using a single mmWave radar and a\nbackscatter tag. N2LoS leverages multipath reflections from both the tag and\nsurrounding reflectors to accurately estimate the targets position. N2LoS\nintroduces several key innovations. First, we design HFD (Hybrid\nFrequency-Hopping and Direct Sequence Spread Spectrum) to detect and\ndifferentiate reflectors from the target. Second, we enhance signal-to-noise\nratio (SNR) by exploiting the correlation properties of the designed signals,\nimproving detection robustness in complex environments. Third, we propose\nFS-MUSIC (Frequency-Spatial Multiple Signal Classification), a super resolution\nalgorithm that extends the traditional MUSIC method by constructing a\nhigher-rank signal matrix, enabling the resolution of additional multipath\ncomponents. We evaluate N2LoS using a 24 GHz mmWave radar with 250 MHz\nbandwidth in three diverse environments: a laboratory, an office, and an\naround-the-corner corridor. Experimental results demonstrate that N2LoS\nachieves median localization errors of 10.69 cm (X) and 11.98 cm (Y) at a 5 m\nrange in the laboratory setting, showcasing its effectiveness for real-world\nNLoS localization.", "published": "2025-05-13 05:32:30", "link": "http://arxiv.org/abs/2505.08240v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Analysis of Cooperative Integrated Sensing and Communications for 6G Networks", "abstract": "In this work, we aim to effectively characterize the performance of\ncooperative integrated sensing and communication (ISAC) networks and to reveal\nhow performance metrics relate to network parameters. To this end, we introduce\na generalized stochastic geometry framework to model the cooperative ISAC\nnetworks, which approximates the spatial randomness of the network deployment.\nBased on this framework, we derive analytical expressions for key performance\nmetrics in both communication and sensing domains, with a particular focus on\ncommunication coverage probability and radar information rate. The analytical\nexpressions derived explicitly highlight how performance metrics depend on\nnetwork parameters, thereby offering valuable insights into the deployment and\ndesign of cooperative ISAC networks. In the end, we validate the theoretical\nperformance analysis through Monte Carlo simulation results. Our results\ndemonstrate that increasing the number of cooperative base stations (BSs)\nsignificantly improves both metrics, while increasing the BS deployment density\nhas a limited impact on communication coverage probability but substantially\nenhances the radar information rate. Additionally, increasing the number of\ntransmit antennas is effective when the total number of transmit antennas is\nrelatively small. The incremental performance gain reduces with the increase of\nthe number of transmit antennas, suggesting that indiscriminately increasing\nantennas is not an efficient strategy to improve the performance of the system\nin cooperative ISAC networks.", "published": "2025-05-13 04:37:56", "link": "http://arxiv.org/abs/2505.08221v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
