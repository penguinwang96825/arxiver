{"title": "Zero-shot Triplet Extraction by Template Infilling", "abstract": "The task of triplet extraction aims to extract pairs of entities and their\ncorresponding relations from unstructured text. Most existing methods train an\nextraction model on training data involving specific target relations, and are\nincapable of extracting new relations that were not observed at training time.\nGeneralizing the model to unseen relations typically requires fine-tuning on\nsynthetic training data which is often noisy and unreliable. We show that by\nreducing triplet extraction to a template infilling task over a pre-trained\nlanguage model (LM), we can equip the extraction model with zero-shot learning\ncapabilities and eliminate the need for additional training data. We propose a\nnovel framework, ZETT (ZEro-shot Triplet extraction by Template infilling),\nthat aligns the task objective to the pre-training objective of generative\ntransformers to generalize to unseen relations. Experiments on FewRel and\nWiki-ZSL datasets demonstrate that ZETT shows consistent and stable\nperformance, outperforming previous state-of-the-art methods, even when using\nautomatically generated templates. https://github.com/megagonlabs/zett/", "published": "2022-12-21 00:57:24", "link": "http://arxiv.org/abs/2212.10708v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Heterogeneous Domain Information into Relation Extraction: A\n  Case Study on Drug-Drug Interaction Extraction", "abstract": "The development of deep neural networks has improved representation learning\nin various domains, including textual, graph structural, and relational triple\nrepresentations. This development opened the door to new relation extraction\nbeyond the traditional text-oriented relation extraction. However, research on\nthe effectiveness of considering multiple heterogeneous domain information\nsimultaneously is still under exploration, and if a model can take an advantage\nof integrating heterogeneous information, it is expected to exhibit a\nsignificant contribution to many problems in the world. This thesis works on\nDrug-Drug Interactions (DDIs) from the literature as a case study and realizes\nrelation extraction utilizing heterogeneous domain information. First, a deep\nneural relation extraction model is prepared and its attention mechanism is\nanalyzed. Next, a method to combine the drug molecular structure information\nand drug description information to the input sentence information is proposed,\nand the effectiveness of utilizing drug molecular structures and drug\ndescriptions for the relation extraction task is shown. Then, in order to\nfurther exploit the heterogeneous information, drug-related items, such as\nprotein entries, medical terms and pathways are collected from multiple\nexisting databases and a new data set in the form of a knowledge graph (KG) is\nconstructed. A link prediction task on the constructed data set is conducted to\nobtain embedding representations of drugs that contain the heterogeneous domain\ninformation. Finally, a method that integrates the input sentence information\nand the heterogeneous KG information is proposed. The proposed model is trained\nand evaluated on a widely used data set, and as a result, it is shown that\nutilizing heterogeneous domain information significantly improves the\nperformance of relation extraction from the literature.", "published": "2022-12-21 01:26:07", "link": "http://arxiv.org/abs/2212.10714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via\n  Moral Discussions", "abstract": "Morality in dialogue systems has raised great attention in research recently.\nA moral dialogue system aligned with users' values could enhance conversation\nengagement and user connections. In this paper, we propose a framework,\nMoralDial to train and evaluate moral dialogue systems. In our framework, we\nfirst explore the communication mechanisms of morality and resolve expressed\nmorality into three parts, which indicate the roadmap for building a moral\ndialogue system. Based on that, we design a simple yet effective method:\nconstructing moral discussions between simulated specific users and the\ndialogue system. The constructed discussions consist of expressing, explaining,\nrevising, and inferring moral views in dialogue exchanges, which makes\nconversational models learn morality well in a natural manner. Furthermore, we\npropose a novel evaluation method under the framework. We evaluate the multiple\naspects of morality by judging the relation between dialogue responses and\nhuman values in discussions, where the multifaceted nature of morality is\nparticularly considered. Automatic and manual experiments demonstrate that our\nframework is promising to train and evaluate moral dialogue systems.", "published": "2022-12-21 02:21:37", "link": "http://arxiv.org/abs/2212.10720v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Error Attribution for Finetuned Language Models", "abstract": "Recent work has identified noisy and misannotated data as a core cause of\nhallucinations and unfaithful outputs in Natural Language Generation (NLG)\ntasks. Consequently, identifying and removing these examples is a key open\nchallenge in creating reliable NLG systems. In this work, we introduce a\nframework to identify and remove low-quality training instances that lead to\nundesirable outputs, such as faithfulness errors in text summarization. We show\nthat existing approaches for error tracing, such as gradient-based influence\nmeasures, do not perform reliably for detecting faithfulness errors in NLG\ndatasets. We overcome the drawbacks of existing error tracing methods through a\nnew, contrast-based estimate that compares undesired generations to\nhuman-corrected outputs. Our proposed method can achieve a mean average\nprecision of 0.93 at detecting known data errors across synthetic tasks with\nknown ground truth, substantially outperforming existing approaches. Using this\napproach and re-training models on cleaned data leads to a 70% reduction in\nentity hallucinations on the NYT dataset and a 55% reduction in semantic errors\non the E2E dataset.", "published": "2022-12-21 02:28:07", "link": "http://arxiv.org/abs/2212.10722v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and\n  Entailment Recognition", "abstract": "The widely studied task of Natural Language Inference (NLI) requires a system\nto recognize whether one piece of text is textually entailed by another, i.e.\nwhether the entirety of its meaning can be inferred from the other. In current\nNLI datasets and models, textual entailment relations are typically defined on\nthe sentence- or paragraph-level. However, even a simple sentence often\ncontains multiple propositions, i.e. distinct units of meaning conveyed by the\nsentence. As these propositions can carry different truth values in the context\nof a given premise, we argue for the need to recognize the textual entailment\nrelation of each proposition in a sentence individually.\n  We propose PropSegmEnt, a corpus of over 45K propositions annotated by expert\nhuman raters. Our dataset structure resembles the tasks of (1) segmenting\nsentences within a document to the set of propositions, and (2) classifying the\nentailment relation of each proposition with respect to a different yet\ntopically-aligned document, i.e. documents describing the same event or entity.\nWe establish strong baselines for the segmentation and entailment tasks.\nThrough case studies on summary hallucination detection and document-level NLI,\nwe demonstrate that our conceptual framework is potentially useful for\nunderstanding and explaining the compositionality of NLI labels.", "published": "2022-12-21 04:03:33", "link": "http://arxiv.org/abs/2212.10750v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoRRPUS: Code-based Structured Prompting for Neurosymbolic Story\n  Understanding", "abstract": "Story generation and understanding -- as with all NLG/NLU tasks -- has seen a\nsurge in neurosymbolic work. Researchers have recognized that, while large\nlanguage models (LLMs) have tremendous utility, they can be augmented with\nsymbolic means to be even better and to make up for any flaws that the neural\nnetworks might have. However, symbolic methods are extremely costly in terms of\nthe amount of time and expertise needed to create them. In this work, we\ncapitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use\nof symbolic methods for tracking the state of stories and aiding in story\nunderstanding. We show that our CoRRPUS system and abstracted prompting\nprocedures can beat current state-of-the-art structured LLM techniques on\npre-existing story understanding tasks (bAbI Task 2 and Re^3) with minimal hand\nengineering. We hope that this work can help highlight the importance of\nsymbolic representations and specialized prompting for LLMs as these models\nrequire some guidance for performing reasoning tasks properly.", "published": "2022-12-21 04:21:35", "link": "http://arxiv.org/abs/2212.10754v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JASMINE: Arabic GPT Models for Few-Shot Learning", "abstract": "Scholarship on generative pretraining (GPT) remains acutely Anglocentric,\nleaving serious gaps in our understanding of the whole class of autoregressive\nmodels. For example, we have little knowledge about the potential of these\nmodels and their societal impacts in diverse linguistic and cultural settings.\nWe alleviate this issue for Arabic, a wide collection of languages and\ndialectal varieties with more than 400 million population, by introducing\nJASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer\nlanguage models ranging in size between 300 million-6.7 billion parameters\npretrained on a large and diverse dataset (~ 235 GB of text). We also carefully\ndesign and release a comprehensive benchmark for both automated and human\nevaluation of Arabic autoregressive models, with coverage of potential social\nbiases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE\nextensively showing powerful performance intrinsically as well as in few-shot\nlearning on a wide range of NLP tasks. We aim to responsibly release our models\nand evaluation benchmark with interested researchers, along with code for\nexperimenting with them.", "published": "2022-12-21 04:21:46", "link": "http://arxiv.org/abs/2212.10755v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Does Beam Search improve Span-Level Confidence Estimation in\n  Generative Sequence Labeling?", "abstract": "Sequence labeling is a core task in text understanding for IE/IR systems.\nText generation models have increasingly become the go-to solution for such\ntasks (e.g., entity extraction and dialog slot filling). While most research\nhas focused on the labeling accuracy, a key aspect -- of vital practical\nimportance -- has slipped through the cracks: understanding model confidence.\nMore specifically, we lack a principled understanding of how to reliably gauge\nthe confidence of a model in its predictions for each labeled span. This paper\naims to provide some empirical insights on estimating model confidence for\ngenerative sequence labeling. Most notably, we find that simply using the\ndecoder's output probabilities \\textbf{is not} the best in realizing\nwell-calibrated confidence estimates. As verified over six public datasets of\ndifferent tasks, we show that our proposed approach -- which leverages\nstatistics from top-$k$ predictions by a beam search -- significantly reduces\ncalibration errors of the predictions of a generative sequence labeling model.", "published": "2022-12-21 05:01:01", "link": "http://arxiv.org/abs/2212.10767v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncontrolled Lexical Exposure Leads to Overestimation of Compositional\n  Generalization in Pretrained Models", "abstract": "Human linguistic capacity is often characterized by compositionality and the\ngeneralization it enables -- human learners can produce and comprehend novel\ncomplex expressions by composing known parts. Several benchmarks exploit\ndistributional control across training and test to gauge compositional\ngeneralization, where certain lexical items only occur in limited contexts\nduring training. While recent work using these benchmarks suggests that\npretrained models achieve impressive generalization performance, we argue that\nexposure to pretraining data may break the aforementioned distributional\ncontrol. Using the COGS benchmark of Kim and Linzen (2020), we test two\nmodified evaluation setups that control for this issue: (1) substituting\ncontext-controlled lexical items with novel character sequences, and (2)\nsubstituting them with special tokens represented by novel embeddings. We find\nthat both of these setups lead to lower generalization performance in T5\n(Raffel et al., 2020), suggesting that previously reported results have been\noverestimated due to uncontrolled lexical exposure during pretraining. The\nperformance degradation is more extreme with novel embeddings, and the\ndegradation increases with the amount of pretraining data, highlighting an\ninteresting case of inverse scaling.", "published": "2022-12-21 05:02:08", "link": "http://arxiv.org/abs/2212.10769v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ImPaKT: A Dataset for Open-Schema Knowledge Base Construction", "abstract": "Large language models have ushered in a golden age of semantic parsing. The\nseq2seq paradigm allows for open-schema and abstractive attribute and relation\nextraction given only small amounts of finetuning data. Language model\npretraining has simultaneously enabled great strides in natural language\ninference, reasoning about entailment and implication in free text. These\nadvances motivate us to construct ImPaKT, a dataset for open-schema information\nextraction, consisting of around 2500 text snippets from the C4 corpus, in the\nshopping domain (product buying guides), professionally annotated with\nextracted attributes, types, attribute summaries (attribute schema discovery\nfrom idiosyncratic text), many-to-one relations between compound and atomic\nattributes, and implication relations. We release this data in hope that it\nwill be useful in fine tuning semantic parsers for information extraction and\nknowledge base construction across a variety of domains. We evaluate the power\nof this approach by fine-tuning the open source UL2 language model on a subset\nof the dataset, extracting a set of implication relations from a corpus of\nproduct buying guides, and conducting human evaluations of the resulting\npredictions.", "published": "2022-12-21 05:02:49", "link": "http://arxiv.org/abs/2212.10770v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction\n  Tuning", "abstract": "Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However, it\nhas yet to be explored for vision and multimodal tasks. In this work, we\nintroduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark\ndataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq\nformat covering 10 broad categories. The tasks are derived from 21 existing\nopen-source datasets and each task is equipped with 5 expert-written\ninstructions. We take OFA as the base pre-trained model for multimodal\ninstruction tuning, and to further improve its zero-shot performance, we\nexplore multiple transfer learning strategies to leverage the large-scale\nNATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot\nperformance on various unseen multimodal tasks and the benefit of transfer\nlearning from a text-only instruction dataset. We also design a new evaluation\nmetric - Sensitivity, to evaluate how sensitive the model is to the variety of\ninstructions. Our results indicate that fine-tuning the model on a diverse set\nof tasks and instructions leads to a reduced sensitivity to variations in\ninstructions for each task.", "published": "2022-12-21 05:17:06", "link": "http://arxiv.org/abs/2212.10773v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reconstruction Probing", "abstract": "We propose reconstruction probing, a new analysis method for contextualized\nrepresentations based on reconstruction probabilities in masked language models\n(MLMs). This method relies on comparing the reconstruction probabilities of\ntokens in a given sequence when conditioned on the representation of a single\ntoken that has been fully contextualized and when conditioned on only the\ndecontextualized lexical prior of the model. This comparison can be understood\nas quantifying the contribution of contextualization towards reconstruction --\nthe difference in the reconstruction probabilities can only be attributed to\nthe representational change of the single token induced by contextualization.\nWe apply this analysis to three MLMs and find that contextualization boosts\nreconstructability of tokens that are close to the token being reconstructed in\nterms of linear and syntactic distance. Furthermore, we extend our analysis to\nfiner-grained decomposition of contextualized representations, and we find that\nthese boosts are largely attributable to static and positional embeddings at\nthe input layer.", "published": "2022-12-21 06:22:03", "link": "http://arxiv.org/abs/2212.10792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language\n  Models", "abstract": "We explore the use of large language models (LLMs) for zero-shot semantic\nparsing. Semantic parsing involves mapping natural language utterances to\ntask-specific meaning representations. Language models are generally trained on\nthe publicly available text and code and cannot be expected to directly\ngeneralize to domain-specific parsing tasks in a zero-shot setting. In this\nwork, we propose ZEROTOP, a zero-shot task-oriented parsing method that\ndecomposes a semantic parsing problem into a set of abstractive and extractive\nquestion-answering (QA) problems, enabling us to leverage the ability of LLMs\nto zero-shot answer reading comprehension questions. For each utterance, we\nprompt the LLM with questions corresponding to its top-level intent and a set\nof slots and use the LLM generations to construct the target meaning\nrepresentation. We observe that current LLMs fail to detect unanswerable\nquestions; and as a result, cannot handle questions corresponding to missing\nslots. To address this problem, we fine-tune a language model on public QA\ndatasets using synthetic negative samples. Experimental results show that our\nQA-based decomposition paired with the fine-tuned LLM can correctly parse ~16%\nof utterances in the MTOP dataset without requiring any annotated data.", "published": "2022-12-21 07:06:55", "link": "http://arxiv.org/abs/2212.10815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attend to the Right Context: A Plug-and-Play Module for\n  Content-Controllable Summarization", "abstract": "Content-Controllable Summarization generates summaries focused on the given\ncontrolling signals. Due to the lack of large-scale training corpora for the\ntask, we propose a plug-and-play module RelAttn to adapt any general\nsummarizers to the content-controllable summarization task. RelAttn first\nidentifies the relevant content in the source documents, and then makes the\nmodel attend to the right context by directly steering the attention weight. We\nfurther apply an unsupervised online adaptive parameter searching algorithm to\ndetermine the degree of control in the zero-shot setting, while such parameters\nare learned in the few-shot setting. By applying the module to three backbone\nsummarization models, experiments show that our method effectively improves all\nthe summarizers, and outperforms the prefix-based method and a widely used\nplug-and-play model in both zero- and few-shot settings. Tellingly, more\nbenefit is observed in the scenarios when more control is needed.", "published": "2022-12-21 07:17:32", "link": "http://arxiv.org/abs/2212.10819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Automatic Speech Recognition model for the Sudanese Dialect", "abstract": "Designing a natural voice interface rely mostly on Speech recognition for\ninteraction between human and their modern digital life equipment. In addition,\nspeech recognition narrows the gap between monolingual individuals to better\nexchange communication. However, the field lacks wide support for several\nuniversal languages and their dialects, while most of the daily conversations\nare carried out using them. This paper comes to inspect the viability of\ndesigning an Automatic Speech Recognition model for the Sudanese dialect, which\nis one of the Arabic Language dialects, and its complexity is a product of\nhistorical and social conditions unique to its speakers. This condition is\nreflected in both the form and content of the dialect, so this paper gives an\noverview of the Sudanese dialect and the tasks of collecting represented\nresources and pre-processing performed to construct a modest dataset to\novercome the lack of annotated data. Also proposed end- to-end speech\nrecognition model, the design of the model was formed using Convolution Neural\nNetworks. The Sudanese dialect dataset would be a stepping stone to enable\nfuture Natural Language Processing research targeting the dialect. The designed\nmodel provided some insights into the current recognition task and reached an\naverage Label Error Rate of 73.67%.", "published": "2022-12-21 07:35:33", "link": "http://arxiv.org/abs/2212.10826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is\n  It and How Does It Affect Transfer?", "abstract": "Multilingual BERT (mBERT) has demonstrated considerable cross-lingual\nsyntactic ability, whereby it enables effective zero-shot cross-lingual\ntransfer of syntactic knowledge. The transfer is more successful between some\nlanguages, but it is not well understood what leads to this variation and\nwhether it fairly reflects difference between languages. In this work, we\ninvestigate the distributions of grammatical relations induced from mBERT in\nthe context of 24 typologically different languages. We demonstrate that the\ndistance between the distributions of different languages is highly consistent\nwith the syntactic difference in terms of linguistic formalisms. Such\ndifference learnt via self-supervision plays a crucial role in the zero-shot\ntransfer performance and can be predicted by variation in morphosyntactic\nproperties between languages. These results suggest that mBERT properly encodes\nlanguages in a way consistent with linguistic diversity and provide insights\ninto the mechanism of cross-lingual transfer.", "published": "2022-12-21 09:44:08", "link": "http://arxiv.org/abs/2212.10879v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resolving Indirect Referring Expressions for Entity Selection", "abstract": "Recent advances in language modeling have enabled new conversational systems.\nIn particular, it is often desirable for people to make choices among specified\noptions when using such systems. We address this problem of reference\nresolution, when people use natural expressions to choose between the entities.\nFor example, given the choice `Should we make a Simnel cake or a Pandan cake?'\na natural response from a dialog participant may be indirect: `let's make the\ngreen one'. Such natural expressions have been little studied for reference\nresolution. We argue that robustly understanding such language has large\npotential for improving naturalness in dialog, recommendation, and search\nsystems. We create AltEntities (Alternative Entities), a new public dataset of\n42K entity pairs and expressions (referring to one entity in the pair), and\ndevelop models for the disambiguation problem. Consisting of indirect referring\nexpressions across three domains, our corpus enables for the first time the\nstudy of how language models can be adapted to this task. We find they achieve\n82%-87% accuracy in realistic settings, which while reasonable also invites\nfurther advances.", "published": "2022-12-21 11:22:38", "link": "http://arxiv.org/abs/2212.10933v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commentary Generation from Data Records of Multiplayer Strategy Esports\n  Game", "abstract": "Esports, a sports competition on video games, has become one of the most\nimportant sporting events. Although esports play logs have been accumulated,\nonly a small portion of them accompany text commentaries for the audience to\nretrieve and understand the plays. In this study, we therefore introduce the\ntask of generating game commentaries from esports' data records. We first build\nlarge-scale esports data-to-text datasets that pair structured data and\ncommentaries from a popular esports game, League of Legends. We then evaluate\nTransformer-based models to generate game commentaries from structured data\nrecords, while examining the impact of the pre-trained language models.\nEvaluation results on our dataset revealed the challenges of this novel task.\nWe will release our dataset to boost potential research in the data-to-text\ngeneration community.", "published": "2022-12-21 11:23:31", "link": "http://arxiv.org/abs/2212.10935v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Critic-Guided Decoding for Controlled Text Generation", "abstract": "Steering language generation towards objectives or away from undesired\ncontent has been a long-standing goal in utilizing language models (LM). Recent\nwork has demonstrated reinforcement learning and weighted decoding as effective\napproaches to achieve a higher level of language control and quality with pros\nand cons. In this work, we propose a novel critic decoding method for\ncontrolled language generation (CriticControl) that combines the strengths of\nreinforcement learning and weighted decoding. Specifically, we adopt the\nactor-critic framework to train an LM-steering critic from non-differentiable\nreward models. And similar to weighted decoding, our method freezes the\nlanguage model and manipulates the output token distribution using called\ncritic, improving training efficiency and stability. Evaluation of our method\non three controlled generation tasks, namely topic control, sentiment control,\nand detoxification, shows that our approach generates more coherent and\nwell-controlled texts than previous methods. In addition, CriticControl\ndemonstrates superior generalization ability in zero-shot settings. Human\nevaluation studies also corroborate our findings.", "published": "2022-12-21 11:25:41", "link": "http://arxiv.org/abs/2212.10938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Context Windows for Large Language Models", "abstract": "When applied to processing long text, Large Language Models (LLMs) are\nlimited by their context window. Existing efforts to address this limitation\ninvolve training specialized architectures, and cannot be easily applied to\noff-the-shelf LLMs. We present Parallel Context Windows (PCW), a method that\nalleviates the context window restriction for any off-the-shelf LLM without\nfurther training. The key to the approach is to carve a long context into\nchunks (``windows''), restrict the attention mechanism to apply only within\neach window, and re-use the positional embeddings across the windows. Our main\nresults test the PCW approach on in-context learning with models that range in\nsize between 750 million and 178 billion parameters, and show substantial\nimprovements for tasks with diverse input and output spaces. We show additional\nbenefits in other settings where long context windows may be beneficial:\nmulti-hop questions and retrieval-augmented question answering with multiple\nretrieved documents. Our results highlight Parallel Context Windows as a\npromising method for applying off-the-shelf LLMs in a range of settings that\nrequire long text sequences. We make our code publicly available at\nhttps://github.com/ai21labs/parallel-context-windows.", "published": "2022-12-21 11:38:51", "link": "http://arxiv.org/abs/2212.10947v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns\n  Predict Reading Times Over and Above GPT-2 Surprisal", "abstract": "Transformer-based large language models are trained to make predictions about\nthe next word by aggregating representations of previous tokens through their\nself-attention mechanism. In the field of cognitive modeling, such attention\npatterns have recently been interpreted as embodying the process of cue-based\nretrieval, in which attention over multiple targets is taken to generate\ninterference and latency during retrieval. Under this framework, this work\nfirst defines an entropy-based predictor that quantifies the diffuseness of\nself-attention, as well as distance-based predictors that capture the\nincremental change in attention patterns across timesteps. Moreover, following\nrecent studies that question the informativeness of attention weights, we also\nexperiment with alternative methods for incorporating vector norms into\nattention weights. Regression experiments using predictors calculated from the\nGPT-2 language model show that these predictors deliver a substantially better\nfit to held-out self-paced reading and eye-tracking data over a rigorous\nbaseline including GPT-2 surprisal. Additionally, the distance-based predictors\ngenerally demonstrated higher predictive power, with effect sizes of up to 6.59\nms per standard deviation on self-paced reading times (compared to 2.82 ms for\nsurprisal) and 1.05 ms per standard deviation on eye-gaze durations (compared\nto 3.81 ms for surprisal).", "published": "2022-12-21 16:56:07", "link": "http://arxiv.org/abs/2212.11185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Emotion Modelling in Written Stories", "abstract": "Telling stories is an integral part of human communication which can evoke\nemotions and influence the affective states of the audience. Automatically\nmodelling emotional trajectories in stories has thus attracted considerable\nscholarly interest. However, as most existing works have been limited to\nunsupervised dictionary-based approaches, there is no labelled benchmark for\nthis task. We address this gap by introducing continuous valence and arousal\nannotations for an existing dataset of children's stories annotated with\ndiscrete emotion categories. We collect additional annotations for this data\nand map the originally categorical labels to the valence and arousal space.\nLeveraging recent advances in Natural Language Processing, we propose a set of\nnovel Transformer-based methods for predicting valence and arousal signals over\nthe course of written stories. We explore several strategies for fine-tuning a\npretrained ELECTRA model and study the benefits of considering a sentence's\ncontext when inferring its emotionality. Moreover, we experiment with\nadditional LSTM and Transformer layers. The best configuration achieves a\nConcordance Correlation Coefficient (CCC) of .7338 for valence and .6302 for\narousal on the test set, demonstrating the suitability of our proposed\napproach. Our code and additional annotations are made available at\nhttps://github.com/lc0197/emotion_modelling_stories.", "published": "2022-12-21 21:46:01", "link": "http://arxiv.org/abs/2212.11382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The URW-KG: a Resource for Tackling the Underrepresentation of\n  non-Western Writers", "abstract": "Digital media have enabled the access to unprecedented literary knowledge.\nAuthors, readers, and scholars are now able to discover and share an increasing\namount of information about books and their authors. Notwithstanding, digital\narchives are still unbalanced: writers from non-Western countries are less\nrepresented, and such a condition leads to the perpetration of old forms of\ndiscrimination. In this paper, we present the Under-Represented Writers\nKnowledge Graph (URW-KG), a resource designed to explore and possibly amend\nthis lack of representation by gathering and mapping information about works\nand authors from Wikidata and three other sources: Open Library, Goodreads, and\nGoogle Books. The experiments based on KG embeddings showed that the integrated\ninformation encoded in the graph allows scholars and users to be more easily\nexposed to non-Western literary works and authors with respect to Wikidata\nalone. This opens to the development of fairer and effective tools for author\ndiscovery and exploration.", "published": "2022-12-21 07:53:26", "link": "http://arxiv.org/abs/2212.13104v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Semantic Faithfulness of Language Models via Input\n  Intervention on Question Answering", "abstract": "Transformer-based language models have been shown to be highly effective for\nseveral NLP tasks. In this paper, we consider three transformer models, BERT,\nRoBERTa, and XLNet, in both small and large versions, and investigate how\nfaithful their representations are with respect to the semantic content of\ntexts. We formalize a notion of semantic faithfulness, in which the semantic\ncontent of a text should causally figure in a model's inferences in question\nanswering. We then test this notion by observing a model's behavior on\nanswering questions about a story after performing two novel semantic\ninterventions: deletion intervention and negation intervention. While\ntransformer models achieve high performance on standard question answering\ntasks, we show that they fail to be semantically faithful once we perform these\ninterventions for a significant number of cases (~50% for deletion\nintervention, and ~20% drop in accuracy for negation intervention). We then\npropose an intervention-based training regime that can mitigate the undesirable\neffects for deletion intervention by a significant margin (from ~ 50% to ~6%).\nWe analyze the inner-workings of the models to better understand the\neffectiveness of intervention-based training for deletion intervention. But we\nshow that this training does not attenuate other aspects of semantic\nunfaithfulness such as the models' inability to deal with negation intervention\nor to capture the predicate-argument structure of texts. We also test\nInstructGPT, via prompting, for its ability to handle the two interventions and\nto capture predicate-argument structure. While InstructGPT models do achieve\nvery high performance on predicate-argument structure task, they fail to\nrespond adequately to our deletion and negation interventions.", "published": "2022-12-21 00:00:01", "link": "http://arxiv.org/abs/2212.10696v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extractive Text Summarization Using Generalized Additive Models with\n  Interactions for Sentence Selection", "abstract": "Automatic Text Summarization (ATS) is becoming relevant with the growth of\ntextual data; however, with the popularization of public large-scale datasets,\nsome recent machine learning approaches have focused on dense models and\narchitectures that, despite producing notable results, usually turn out in\nmodels difficult to interpret. Given the challenge behind interpretable\nlearning-based text summarization and the importance it may have for evolving\nthe current state of the ATS field, this work studies the application of two\nmodern Generalized Additive Models with interactions, namely Explainable\nBoosting Machine and GAMI-Net, to the extractive summarization problem based on\nlinguistic features and binary classification.", "published": "2022-12-21 00:56:50", "link": "http://arxiv.org/abs/2212.10707v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond Contrastive Learning: A Variational Generative Model for\n  Multilingual Retrieval", "abstract": "Contrastive learning has been successfully used for retrieval of semantically\naligned sentences, but it often requires large batch sizes or careful\nengineering to work well. In this paper, we instead propose a generative model\nfor learning multilingual text embeddings which can be used to retrieve or\nscore sentence pairs. Our model operates on parallel data in $N$ languages and,\nthrough an approximation we introduce, efficiently encourages source separation\nin this multilingual setting, separating semantic information that is shared\nbetween translations from stylistic or language-specific variation. We show\ncareful large-scale comparisons between contrastive and generation-based\napproaches for learning multilingual text embeddings, a comparison that has not\nbeen done to the best of our knowledge despite the popularity of these\napproaches. We evaluate this method on a suite of tasks including semantic\nsimilarity, bitext mining, and cross-lingual question retrieval -- the last of\nwhich we introduce in this paper. Overall, our Variational Multilingual\nSource-Separation Transformer (VMSST) model outperforms both a strong\ncontrastive and generative baseline on these tasks.", "published": "2022-12-21 02:41:40", "link": "http://arxiv.org/abs/2212.10726v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Spoken Language Understanding for Conversational AI: Recent Advances and\n  Future Direction", "abstract": "When a human communicates with a machine using natural language on the web\nand online, how can it understand the human's intention and semantic context of\ntheir talk? This is an important AI task as it enables the machine to construct\na sensible answer or perform a useful action for the human. Meaning is\nrepresented at the sentence level, identification of which is known as intent\ndetection, and at the word level, a labelling task called slot filling. This\ndual-level joint task requires innovative thinking about natural language and\ndeep learning network design, and as a result, many approaches and models have\nbeen proposed and applied.\n  This tutorial will discuss how the joint task is set up and introduce Spoken\nLanguage Understanding/Natural Language Understanding (SLU/NLU) with Deep\nLearning techniques. We will cover the datasets, experiments and metrics used\nin the field. We will describe how the machine uses the latest NLP and Deep\nLearning techniques to address the joint task, including recurrent and\nattention-based Transformer networks and pre-trained models (e.g. BERT). We\nwill then look in detail at a network that allows the two levels of the task,\nintent classification and slot filling, to interact to boost performance\nexplicitly. We will do a code demonstration of a Python notebook for this model\nand attendees will have an opportunity to watch coding demo tasks on this joint\nNLU to further their understanding.", "published": "2022-12-21 02:47:52", "link": "http://arxiv.org/abs/2212.10728v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ORCA: A Challenging Benchmark for Arabic Language Understanding", "abstract": "Due to their crucial role in all NLP, several benchmarks have been proposed\nto evaluate pretrained language models. In spite of these efforts, no public\nbenchmark of diverse nature currently exists for evaluation of Arabic. This\nmakes it challenging to measure progress for both Arabic and multilingual\nlanguage models. This challenge is compounded by the fact that any benchmark\ntargeting Arabic needs to take into account the fact that Arabic is not a\nsingle language but rather a collection of languages and varieties. In this\nwork, we introduce ORCA, a publicly available benchmark for Arabic language\nunderstanding evaluation. ORCA is carefully constructed to cover diverse Arabic\nvarieties and a wide range of challenging Arabic understanding tasks exploiting\n60 different datasets across seven NLU task clusters. To measure current\nprogress in Arabic NLU, we use ORCA to offer a comprehensive comparison between\n18 multilingual and Arabic language models. We also provide a public\nleaderboard with a unified single-number evaluation metric (ORCA score) to\nfacilitate future research.", "published": "2022-12-21 04:35:43", "link": "http://arxiv.org/abs/2212.10758v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SERENGETI: Massively Multilingual Language Models for Africa", "abstract": "Multilingual pretrained language models (mPLMs) acquire valuable,\ngeneralizable linguistic information during pretraining and have advanced the\nstate of the art on task-specific finetuning. To date, only ~31 out of ~2,000\nAfrican languages are covered in existing language models. We ameliorate this\nlimitation by developing SERENGETI, a massively multilingual language model\nthat covers 517 African languages and language varieties. We evaluate our novel\nmodels on eight natural language understanding tasks across 20 datasets,\ncomparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms\nother models on 11 datasets across the eights tasks, achieving 82.27 average\nF_1. We also perform analyses of errors from our models, which allows us to\ninvestigate the influence of language genealogy and linguistic similarity when\nthe models are applied under zero-shot settings. We will publicly release our\nmodels for\nresearch.\\footnote{\\href{https://github.com/UBC-NLP/serengeti}{https://github.com/UBC-NLP/serengeti}}", "published": "2022-12-21 05:54:14", "link": "http://arxiv.org/abs/2212.10785v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OpineSum: Entailment-based self-training for abstractive opinion\n  summarization", "abstract": "A typical product or place often has hundreds of reviews, and summarization\nof these texts is an important and challenging problem. Recent progress on\nabstractive summarization in domains such as news has been driven by supervised\nsystems trained on hundreds of thousands of news articles paired with\nhuman-written summaries. However for opinion texts, such large scale datasets\nare rarely available. Unsupervised methods, self-training, and few-shot\nlearning approaches bridge that gap. In this work, we present a novel\nself-training approach, OpineSum, for abstractive opinion summarization. The\nsummaries in this approach are built using a novel application of textual\nentailment and capture the consensus of opinions across the various reviews for\nan item. This method can be used to obtain silver-standard summaries on a large\nscale and train both unsupervised and few-shot abstractive summarization\nsystems. OpineSum achieves state-of-the-art performance in both settings.", "published": "2022-12-21 06:20:28", "link": "http://arxiv.org/abs/2212.10791v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Multiple-Length Summaries via Reinforcement Learning for\n  Unsupervised Sentence Summarization", "abstract": "Sentence summarization shortens given texts while maintaining core contents\nof the texts. Unsupervised approaches have been studied to summarize texts\nwithout human-written summaries. However, recent unsupervised models are\nextractive, which remove words from texts and thus they are less flexible than\nabstractive summarization. In this work, we devise an abstractive model based\non reinforcement learning without ground-truth summaries. We formulate the\nunsupervised summarization based on the Markov decision process with rewards\nrepresenting the summary quality. To further enhance the summary quality, we\ndevelop a multi-summary learning mechanism that generates multiple summaries\nwith varying lengths for a given text, while making the summaries mutually\nenhance each other. Experimental results show that the proposed model\nsubstantially outperforms both abstractive and extractive models, yet\nfrequently generating new words not contained in input texts.", "published": "2022-12-21 08:34:28", "link": "http://arxiv.org/abs/2212.10843v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-shot\n  In-Context Learners", "abstract": "Through in-context learning (ICL), large-scale language models are effective\nfew-shot learners without additional model fine-tuning. However, the ICL\nperformance does not scale well with the number of available training samples\nas it is limited by the inherent input length constraint of the underlying\nlanguage model. Meanwhile, many studies have revealed that language models are\nalso powerful feature extractors, allowing them to be utilized in a black-box\nmanner and enabling the linear probing paradigm, where lightweight\ndiscriminators are trained on top of the pre-extracted input representations.\nThis paper proposes prompt-augmented linear probing (PALP), a hybrid of linear\nprobing and ICL, which leverages the best of both worlds. PALP inherits the\nscalability of linear probing and the capability of enforcing language models\nto derive more meaningful representations via tailoring input into a more\nconceivable form. Throughout in-depth investigations on various datasets, we\nverified that PALP significantly enhances the input representations closing the\ngap between ICL in the data-hungry scenario and fine-tuning in the\ndata-abundant scenario with little training overhead, potentially making PALP a\nstrong alternative in a black-box scenario.", "published": "2022-12-21 09:37:05", "link": "http://arxiv.org/abs/2212.10873v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training language models to summarize narratives improves brain\n  alignment", "abstract": "Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.", "published": "2022-12-21 10:15:19", "link": "http://arxiv.org/abs/2212.10898v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Language Models as Inductive Reasoners", "abstract": "Inductive reasoning is a core component of human intelligence. In the past\nresearch of inductive reasoning within computer science, formal language is\nused as representations of knowledge (facts and rules, more specifically).\nHowever, formal language can cause systematic problems for inductive reasoning\nsuch as disability of handling raw input such as natural language,\nsensitiveness to mislabeled data, and incapacity to handle ambiguous input. To\nthis end, we propose a new paradigm (task) for inductive reasoning, which is to\ninduce natural language rules from natural language facts, and create a dataset\ntermed DEER containing 1.2k rule-fact pairs for the task, where rules and facts\nare written in natural language. New automatic metrics are also proposed and\nanalysed for the evaluation of this task. With DEER, we investigate a modern\napproach for inductive reasoning where we use natural language as\nrepresentation for knowledge instead of formal language and use pretrained\nlanguage models as ''reasoners''. Moreover, we provide the first and\ncomprehensive analysis of how well pretrained language models can induce\nnatural language rules from natural language facts. We also propose a new\nframework drawing insights from philosophy literature for this task, which we\nshow in the experiment section that surpasses baselines in both automatic and\nhuman evaluations. We discuss about our future perspectives for inductive\nreasoning in Section 7. Dataset and code are available at\nhttps://github.com/ZonglinY/Inductive_Reasoning.", "published": "2022-12-21 11:12:14", "link": "http://arxiv.org/abs/2212.10923v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Computer says \"No\": The Case Against Empathetic Conversational AI", "abstract": "Emotions are an integral part of human cognition and they guide not only our\nunderstanding of the world but also our actions within it. As such, whether we\nsoothe or flame an emotion is not inconsequential. Recent work in\nconversational AI has focused on responding empathetically to users, validating\nand soothing their emotions without a real basis. This AI-aided emotional\nregulation can have negative consequences for users and society, tending\ntowards a one-noted happiness defined as only the absence of \"negative\"\nemotions. We argue that we must carefully consider whether and how to respond\nto users' emotions.", "published": "2022-12-21 12:36:17", "link": "http://arxiv.org/abs/2212.10983v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Universal versus system-specific features of punctuation usage patterns\n  in~major Western~languages", "abstract": "The celebrated proverb that \"speech is silver, silence is golden\" has a long\nmultinational history and multiple specific meanings. In written texts\npunctuation can in fact be considered one of its manifestations. Indeed, the\nvirtue of effectively speaking and writing involves - often decisively - the\ncapacity to apply the properly placed breaks. In the present study, based on a\nlarge corpus of world-famous and representative literary texts in seven major\nWestern languages, it is shown that the distribution of intervals between\nconsecutive punctuation marks in almost all texts can universally be\ncharacterised by only two parameters of the discrete Weibull distribution which\ncan be given an intuitive interpretation in terms of the so-called hazard\nfunction. The values of these two parameters tend to be language-specific,\nhowever, and even appear to navigate translations. The properties of the\ncomputed hazard functions indicate that among the studied languages, English\nturns out to be the least constrained by the necessity to place a consecutive\npunctuation mark to partition a sequence of words. This may suggest that when\ncompared to other studied languages, English is more flexible, in the sense of\nallowing longer uninterrupted sequences of words. Spanish reveals similar\ntendency to only a bit lesser extent.", "published": "2022-12-21 16:52:10", "link": "http://arxiv.org/abs/2212.11182v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Improving Narrative Relationship Embeddings by Training with Additional\n  Inverse-Relationship Constraints", "abstract": "We consider the problem of embedding character-entity relationships from the\nreduced semantic space of narratives, proposing and evaluating the assumption\nthat these relationships hold under a reflection operation. We analyze this\nassumption and compare the approach to a baseline state-of-the-art model with a\nunique evaluation that simulates efficacy on a downstream clustering task with\nhuman-created labels. Although our model creates clusters that achieve\nSilhouette scores of -.084, outperforming the baseline -.227, our analysis\nreveals that the models approach the task much differently and perform well on\nvery different examples. We conclude that our assumption might be useful for\nspecific types of data and should be evaluated on a wider range of tasks.", "published": "2022-12-21 17:59:11", "link": "http://arxiv.org/abs/2212.11234v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Generalized Decoding for Pixel, Image, and Language", "abstract": "We present X-Decoder, a generalized decoding model that can predict\npixel-level segmentation and language tokens seamlessly. X-Decodert takes as\ninput two types of queries: (i) generic non-semantic queries and (ii) semantic\nqueries induced from text inputs, to decode different pixel-level and\ntoken-level outputs in the same semantic space. With such a novel design,\nX-Decoder is the first work that provides a unified way to support all types of\nimage segmentation and a variety of vision-language (VL) tasks. Further, our\ndesign enables seamless interactions across tasks at different granularities\nand brings mutual benefits by learning a common and rich pixel-level\nvisual-semantic understanding space, without any pseudo-labeling. After\npretraining on a mixed set of a limited amount of segmentation data and\nmillions of image-text pairs, X-Decoder exhibits strong transferability to a\nwide range of downstream tasks in both zero-shot and finetuning settings.\nNotably, it achieves (1) state-of-the-art results on open-vocabulary\nsegmentation and referring segmentation on eight datasets; (2) better or\ncompetitive finetuned performance to other generalist and specialist models on\nsegmentation and VL tasks; and (3) flexibility for efficient finetuning and\nnovel task composition (e.g., referring captioning and image editing). Code,\ndemo, video, and visualization are available at https://x-decoder-vl.github.io.", "published": "2022-12-21 18:58:41", "link": "http://arxiv.org/abs/2212.11270v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss\n  Policy for Transfer Learning", "abstract": "Traditional approaches to RL have focused on learning decision policies\ndirectly from episodic decisions, while slowly and implicitly learning the\nsemantics of compositional representations needed for generalization. While\nsome approaches have been adopted to refine representations via auxiliary\nself-supervised losses while simultaneously learning decision policies,\nlearning compositional representations from hand-designed and\ncontext-independent self-supervised losses (multi-view) still adapts relatively\nslowly to the real world, which contains many non-IID subspaces requiring rapid\ndistribution shift in both time and spatial attention patterns at varying\nlevels of abstraction. In contrast, supervised language model cascades have\nshown the flexibility to adapt to many diverse manifolds, and hints of\nself-learning needed for autonomous task transfer. However, to date, transfer\nmethods for language models like few-shot learning and fine-tuning still\nrequire human supervision and transfer learning using self-learning methods has\nbeen underexplored. We propose a self-supervised loss policy called contrastive\ndistillation which manifests latent variables with high mutual information with\nboth source and target tasks from weights to tokens. We show how this\noutperforms common methods of transfer learning and suggests a useful design\naxis of trading off compute for generalizability for online transfer.\nContrastive distillation is improved through sampling from memory and suggests\na simple algorithm for more efficiently sampling negative examples for\ncontrastive losses than random sampling.", "published": "2022-12-21 20:43:46", "link": "http://arxiv.org/abs/2212.11353v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Mutation-based Text Generation for Adversarial Machine Learning\n  Applications", "abstract": "Many natural language related applications involve text generation, created\nby humans or machines. While in many of those applications machines support\nhumans, yet in few others, (e.g. adversarial machine learning, social bots and\ntrolls) machines try to impersonate humans. In this scope, we proposed and\nevaluated several mutation-based text generation approaches. Unlike\nmachine-based generated text, mutation-based generated text needs human text\nsamples as inputs. We showed examples of mutation operators but this work can\nbe extended in many aspects such as proposing new text-based mutation operators\nbased on the nature of the application.", "published": "2022-12-21 04:57:59", "link": "http://arxiv.org/abs/2212.11808v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Text classification in shipping industry using unsupervised models and\n  Transformer based supervised models", "abstract": "Obtaining labelled data in a particular context could be expensive and time\nconsuming. Although different algorithms, including unsupervised learning,\nsemi-supervised learning, self-learning have been adopted, the performance of\ntext classification varies with context. Given the lack of labelled dataset, we\nproposed a novel and simple unsupervised text classification model to classify\ncargo content in international shipping industry using the Standard\nInternational Trade Classification (SITC) codes. Our method stems from\nrepresenting words using pretrained Glove Word Embeddings and finding the most\nlikely label using Cosine Similarity. To compare unsupervised text\nclassification model with supervised classification, we also applied several\nTransformer models to classify cargo content. Due to lack of training data, the\nSITC numerical codes and the corresponding textual descriptions were used as\ntraining data. A small number of manually labelled cargo content data was used\nto evaluate the classification performances of the unsupervised classification\nand the Transformer based supervised classification. The comparison reveals\nthat unsupervised classification significantly outperforms Transformer based\nsupervised classification even after increasing the size of the training\ndataset by 30%. Lacking training data is a key bottleneck that prohibits deep\nlearning models (such as Transformers) from successful practical applications.\nUnsupervised classification can provide an alternative efficient and effective\nmethod to classify text when there is scarce training data.", "published": "2022-12-21 16:00:44", "link": "http://arxiv.org/abs/2212.12407v1", "categories": ["cs.CL", "cs.LG", "ACM-class: J.m"], "primary_category": "cs.CL"}
{"title": "ToL: A Tensor of List-Based Unified Computation Model", "abstract": "Previous computation models either have equivalent abilities in representing\nall computations but fail to provide primitive operators for programming\ncomplex algorithms or lack generalized expression ability to represent\nnewly-added computations. This article presents a unified computation model\nwith generalized expression ability and a concise set of primitive operators\nfor programming high-level algorithms. We propose a unified data abstraction --\nTensor of List, and offer a unified computation model based on Tensor of List,\nwhich we call the ToL model (in short, ToL). ToL introduces five atomic\ncomputations that can represent any elementary computation by finite\ncomposition, ensured with strict formal proof. Based on ToL, we design a\npure-functional language -- ToLang. ToLang provides a concise set of primitive\noperators that can be used to program complex big data and AI algorithms. Our\nevaluations show ToL has generalized expression ability and a built-in\nperformance indicator, born with a strictly defined computation metric --\nelementary operation count (EOPs), consistent with FLOPs within a small error\nrange.", "published": "2022-12-21 03:22:24", "link": "http://arxiv.org/abs/2212.10740v1", "categories": ["cs.PL", "cs.CC", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Learning List-Level Domain-Invariant Representations for Ranking", "abstract": "Domain adaptation aims to transfer the knowledge learned on (data-rich)\nsource domains to (low-resource) target domains, and a popular method is\ninvariant representation learning, which matches and aligns the data\ndistributions on the feature space. Although this method is studied extensively\nand applied on classification and regression problems, its adoption on ranking\nproblems is sporadic, and the few existing implementations lack theoretical\njustifications. This paper revisits invariant representation learning for\nranking. Upon reviewing prior work, we found that they implement what we call\nitem-level alignment, which aligns the distributions of the items being ranked\nfrom all lists in aggregate but ignores their list structure. However, the list\nstructure should be leveraged, because it is intrinsic to ranking problems\nwhere the data and the metrics are defined and computed on lists, not the items\nby themselves. To close this discrepancy, we propose list-level alignment --\nlearning domain-invariant representations at the higher level of lists. The\nbenefits are twofold: it leads to the first domain adaptation generalization\nbound for ranking, in turn providing theoretical support for the proposed\nmethod, and it achieves better empirical transfer performance for unsupervised\ndomain adaptation on ranking tasks, including passage reranking.", "published": "2022-12-21 04:49:55", "link": "http://arxiv.org/abs/2212.10764v3", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical\n  Relation Extraction?", "abstract": "Two key obstacles in biomedical relation extraction (RE) are the scarcity of\nannotations and the prevalence of instances without explicitly pre-defined\nlabels due to low annotation coverage. Existing approaches, which treat\nbiomedical RE as a multi-class classification task, often result in poor\ngeneralization in low-resource settings and do not have the ability to make\nselective prediction on unknown cases but give a guess from seen relations,\nhindering the applicability of those approaches. We present NBR, which converts\nbiomedical RE as natural language inference formulation through indirect\nsupervision. By converting relations to natural language hypotheses, NBR is\ncapable of exploiting semantic cues to alleviate annotation scarcity. By\nincorporating a ranking-based loss that implicitly calibrates abstinent\ninstances, NBR learns a clearer decision boundary and is instructed to abstain\non uncertain instances. Extensive experiments on three widely-used biomedical\nRE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in\nboth full-set and low-resource regimes. Our analysis demonstrates that indirect\nsupervision benefits biomedical RE even when a domain gap exists, and combining\nNLI knowledge with biomedical knowledge leads to the best performance gains.", "published": "2022-12-21 05:49:08", "link": "http://arxiv.org/abs/2212.10784v3", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Multi-hop Evidence Retrieval for Cross-document Relation Extraction", "abstract": "Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose MR.COD (Multi-hop evidence\nretrieval for Cross-document relation extraction), which is a multi-hop\nevidence retrieval method based on evidence path mining and ranking. We explore\nmultiple variants of retrievers to show evidence retrieval is essential in\ncross-document RE. We also propose a contextual dense retriever for this\nsetting. Experiments on CodRED show that evidence retrieval with MR.COD\neffectively acquires crossdocument evidence and boosts end-to-end RE\nperformance in both closed and open settings.", "published": "2022-12-21 06:00:22", "link": "http://arxiv.org/abs/2212.10786v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-modal Molecule Structure-text Model for Text-based Retrieval and\n  Editing", "abstract": "There is increasing adoption of artificial intelligence in drug discovery.\nHowever, existing studies use machine learning to mainly utilize the chemical\nstructures of molecules but ignore the vast textual knowledge available in\nchemistry. Incorporating textual knowledge enables us to realize new drug\ndesign objectives, adapt to text-based instructions and predict complex\nbiological activities. Here we present a multi-modal molecule structure-text\nmodel, MoleculeSTM, by jointly learning molecules' chemical structures and\ntextual descriptions via a contrastive learning strategy. To train MoleculeSTM,\nwe construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000\nchemical structure-text pairs. To demonstrate the effectiveness and utility of\nMoleculeSTM, we design two challenging zero-shot tasks based on text\ninstructions, including structure-text retrieval and molecule editing.\nMoleculeSTM has two main properties: open vocabulary and compositionality via\nnatural language. In experiments, MoleculeSTM obtains the state-of-the-art\ngeneralization ability to novel biochemical concepts across various benchmarks.", "published": "2022-12-21 06:18:31", "link": "http://arxiv.org/abs/2212.10789v3", "categories": ["cs.LG", "cs.CL", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict\n  decoders", "abstract": "The network architecture of end-to-end (E2E) automatic speech recognition\n(ASR) can be classified into several models, including connectionist temporal\nclassification (CTC), recurrent neural network transducer (RNN-T), attention\nmechanism, and non-autoregressive mask-predict models. Since each of these\nnetwork architectures has pros and cons, a typical use case is to switch these\nseparate models depending on the application requirement, resulting in the\nincreased overhead of maintaining all models. Several methods for integrating\ntwo of these complementary models to mitigate the overhead issue have been\nproposed; however, if we integrate more models, we will further benefit from\nthese complementary models and realize broader applications with a single\nsystem. This paper proposes four-decoder joint modeling (4D) of CTC, attention,\nRNN-T, and mask-predict, which has the following three advantages: 1) The four\ndecoders are jointly trained so that they can be easily switched depending on\nthe application scenarios. 2) Joint training may bring model regularization and\nimprove the model robustness thanks to their complementary properties. 3) Novel\none-pass joint decoding methods using CTC, attention, and RNN-T further\nimproves the performance. The experimental results showed that the proposed\nmodel consistently reduced the WER.", "published": "2022-12-21 07:15:59", "link": "http://arxiv.org/abs/2212.10818v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Continual Contrastive Finetuning Improves Low-Resource Relation\n  Extraction", "abstract": "Relation extraction (RE), which has relied on structurally annotated corpora\nfor model training, has been particularly challenging in low-resource scenarios\nand domains. Recent literature has tackled low-resource RE by self-supervised\nlearning, where the solution involves pretraining the entity pair embedding by\nRE-based objective and finetuning on labeled data by classification-based\nobjective. However, a critical challenge to this approach is the gap in\nobjectives, which prevents the RE model from fully utilizing the knowledge in\npretrained representations. In this paper, we aim at bridging the gap and\npropose to pretrain and finetune the RE model using consistent objectives of\ncontrastive learning. Since in this kind of representation learning paradigm,\none relation may easily form multiple clusters in the representation space, we\nfurther propose a multi-center contrastive loss that allows one relation to\nform multiple clusters to better align with pretraining. Experiments on two\ndocument-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness\nof our method. Particularly, when using 1% end-task training data, our method\noutperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets,\nrespectively.", "published": "2022-12-21 07:30:22", "link": "http://arxiv.org/abs/2212.10823v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Survey of Mix-based Data Augmentation: Taxonomy, Methods,\n  Applications, and Explainability", "abstract": "Data augmentation (DA) is indispensable in modern machine learning and deep\nneural networks. The basic idea of DA is to construct new training data to\nimprove the model's generalization by adding slightly disturbed versions of\nexisting data or synthesizing new data. This survey comprehensively reviews a\ncrucial subset of DA techniques, namely Mix-based Data Augmentation (MixDA),\nwhich generates novel samples by combining multiple examples. In contrast to\ntraditional DA approaches that operate on single samples or entire datasets,\nMixDA stands out due to its effectiveness, simplicity, flexibility,\ncomputational efficiency, theoretical foundation, and broad applicability. We\nbegin by introducing a novel taxonomy that categorizes MixDA into Mixup-based,\nCutmix-based, and mixture approaches based on a hierarchical perspective of the\ndata mixing operation. Subsequently, we provide an in-depth review of various\nMixDA techniques, focusing on their underlying motivations. Owing to its\nversatility, MixDA has penetrated a wide range of applications, which we also\nthoroughly investigate in this survey. Moreover, we delve into the underlying\nmechanisms of MixDA's effectiveness by examining its impact on model\ngeneralization and calibration while providing insights into the model's\nbehavior by analyzing the inherent properties of MixDA. Finally, we\nrecapitulate the critical findings and fundamental challenges of current MixDA\nstudies while outlining the potential directions for future works. Different\nfrom previous related surveys that focus on DA approaches in specific domains\n(e.g., CV and NLP) or only review a limited subset of MixDA studies, we are the\nfirst to provide a systematical survey of MixDA, covering its taxonomy,\nmethodology, application, and explainability. Furthermore, we provide promising\ndirections for researchers interested in this exciting area.", "published": "2022-12-21 09:58:14", "link": "http://arxiv.org/abs/2212.10888v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning", "abstract": "Pre-trained large language models can efficiently interpolate human-written\nprompts in a natural way. Multitask prompted learning can help generalization\nthrough a diverse set of tasks at once, thus enhancing the potential for more\neffective downstream fine-tuning. To perform efficient multitask-inference in\nthe same batch, parameter-efficient fine-tuning methods such as prompt tuning\nhave been proposed. However, the existing prompt tuning methods may lack\ngeneralization. We propose SPT, a semi-parametric prompt tuning method for\nmultitask prompted learning. The novel component of SPT is a memory bank from\nwhere memory prompts are retrieved based on discrete prompts. Extensive\nexperiments, such as (i) fine-tuning a full language model with SPT on 31\ndifferent tasks from 8 different domains and evaluating zero-shot\ngeneralization on 9 heldout datasets under 5 NLP task categories and (ii)\npretraining SPT on the GLUE datasets and evaluating fine-tuning on the\nSuperGLUE datasets, demonstrate effectiveness of SPT.", "published": "2022-12-21 11:18:09", "link": "http://arxiv.org/abs/2212.10929v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "KL Regularized Normalization Framework for Low Resource Tasks", "abstract": "Large pre-trained models, such as Bert, GPT, and Wav2Vec, have demonstrated\ngreat potential for learning representations that are transferable to a wide\nvariety of downstream tasks . It is difficult to obtain a large quantity of\nsupervised data due to the limited availability of resources and time. In light\nof this, a significant amount of research has been conducted in the area of\nadopting large pre-trained datasets for diverse downstream tasks via fine\ntuning, linear probing, or prompt tuning in low resource settings.\nNormalization techniques are essential for accelerating training and improving\nthe generalization of deep neural networks and have been successfully used in a\nwide variety of applications. A lot of normalization techniques have been\nproposed but the success of normalization in low resource downstream NLP and\nspeech tasks is limited. One of the reasons is the inability to capture\nexpressiveness by rescaling parameters of normalization. We propose\nKullbackLeibler(KL) Regularized normalization (KL-Norm) which make the\nnormalized data well behaved and helps in better generalization as it reduces\nover-fitting, generalises well on out of domain distributions and removes\nirrelevant biases and features with negligible increase in model parameters and\nmemory overheads. Detailed experimental evaluation on multiple low resource NLP\nand speech tasks, demonstrates the superior performance of KL-Norm as compared\nto other popular normalization and regularization techniques.", "published": "2022-12-21 05:59:25", "link": "http://arxiv.org/abs/2212.11275v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language models are better than humans at next-token prediction", "abstract": "Current language models are considered to have sub-human capabilities at\nnatural language tasks like question-answering or writing code. However,\nlanguage models are not trained to perform well at these tasks, they are\ntrained to accurately predict the next token given previous tokes in tokenized\ntext. It is not clear whether language models are better or worse than humans\nat next token prediction. To try to answer this question, we performed two\ndistinct experiments to directly compare humans and language models on this\nfront: one measuring top-1 accuracy and the other measuring perplexity. In both\nexperiments, we find humans to be consistently \\emph{worse} than even\nrelatively small language models like GPT3-Ada at next-token prediction.", "published": "2022-12-21 17:58:01", "link": "http://arxiv.org/abs/2212.11281v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What do LLMs Know about Financial Markets? A Case Study on Reddit Market\n  Sentiment Analysis", "abstract": "Market sentiment analysis on social media content requires knowledge of both\nfinancial markets and social media jargon, which makes it a challenging task\nfor human raters. The resulting lack of high-quality labeled data stands in the\nway of conventional supervised learning methods. Instead, we approach this\nproblem using semi-supervised learning with a large language model (LLM). Our\npipeline generates weak financial sentiment labels for Reddit posts with an LLM\nand then uses that data to train a small model that can be served in\nproduction. We find that prompting the LLM to produce Chain-of-Thought\nsummaries and forcing it through several reasoning paths helps generate more\nstable and accurate labels, while using a regression loss further improves\ndistillation quality. With only a handful of prompts, the final model performs\non par with existing supervised models. Though production applications of our\nmodel are limited by ethical considerations, the model's competitive\nperformance points to the great potential of using LLMs for tasks that\notherwise require skill-intensive annotation.", "published": "2022-12-21 19:11:19", "link": "http://arxiv.org/abs/2212.11311v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "ALCAP: Alignment-Augmented Music Captioner", "abstract": "Music captioning has gained significant attention in the wake of the rising\nprominence of streaming media platforms. Traditional approaches often\nprioritize either the audio or lyrics aspect of the music, inadvertently\nignoring the intricate interplay between the two. However, a comprehensive\nunderstanding of music necessitates the integration of both these elements. In\nthis study, we delve into this overlooked realm by introducing a method to\nsystematically learn multimodal alignment between audio and lyrics through\ncontrastive learning. This not only recognizes and emphasizes the synergy\nbetween audio and lyrics but also paves the way for models to achieve deeper\ncross-modal coherence, thereby producing high-quality captions. We provide both\ntheoretical and empirical results demonstrating the advantage of the proposed\nmethod, which achieves new state-of-the-art on two music captioning datasets.", "published": "2022-12-21 10:20:54", "link": "http://arxiv.org/abs/2212.10901v3", "categories": ["cs.SD", "cs.CL", "cs.IR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Contrastive Language-Vision AI Models Pretrained on Web-Scraped\n  Multimodal Data Exhibit Sexual Objectification Bias", "abstract": "Nine language-vision AI models trained on web scrapes with the Contrastive\nLanguage-Image Pretraining (CLIP) objective are evaluated for evidence of a\nbias studied by psychologists: the sexual objectification of girls and women,\nwhich occurs when a person's human characteristics, such as emotions, are\ndisregarded and the person is treated as a body. We replicate three experiments\nin psychology quantifying sexual objectification and show that the phenomena\npersist in AI. A first experiment uses standardized images of women from the\nSexual OBjectification and EMotion Database, and finds that human\ncharacteristics are disassociated from images of objectified women: the model's\nrecognition of emotional state is mediated by whether the subject is fully or\npartially clothed. Embedding association tests (EATs) return significant effect\nsizes for both anger (d >0.80) and sadness (d >0.50), associating images of\nfully clothed subjects with emotions. GRAD-CAM saliency maps highlight that\nCLIP gets distracted from emotional expressions in objectified images. A second\nexperiment measures the effect in a representative application: an automatic\nimage captioner (Antarctic Captions) includes words denoting emotion less than\n50% as often for images of partially clothed women than for images of fully\nclothed women. A third experiment finds that images of female professionals\n(scientists, doctors, executives) are likely to be associated with sexual\ndescriptions relative to images of male professionals. A fourth experiment\nshows that a prompt of \"a [age] year old girl\" generates sexualized images (as\ndetermined by an NSFW classifier) up to 73% of the time for VQGAN-CLIP and\nStable Diffusion; the corresponding rate for boys never surpasses 9%. The\nevidence indicates that language-vision AI models trained on web scrapes learn\nbiases of sexual objectification, which propagate to downstream applications.", "published": "2022-12-21 18:54:19", "link": "http://arxiv.org/abs/2212.11261v2", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Multimodal Emotion Recognition among Couples from Lab Settings to Daily\n  Life using Smartwatches", "abstract": "Couples generally manage chronic diseases together and the management takes\nan emotional toll on both patients and their romantic partners. Consequently,\nrecognizing the emotions of each partner in daily life could provide an insight\ninto their emotional well-being in chronic disease management. The emotions of\npartners are currently inferred in the lab and daily life using self-reports\nwhich are not practical for continuous emotion assessment or observer reports\nwhich are manual, time-intensive, and costly. Currently, there exists no\ncomprehensive overview of works on emotion recognition among couples.\nFurthermore, approaches for emotion recognition among couples have (1) focused\non English-speaking couples in the U.S., (2) used data collected from the lab,\nand (3) performed recognition using observer ratings rather than partner's\nself-reported / subjective emotions. In this body of work contained in this\nthesis (8 papers - 5 published and 3 currently under review in various\njournals), we fill the current literature gap on couples' emotion recognition,\ndevelop emotion recognition systems using 161 hours of data from a total of\n1,051 individuals, and make contributions towards taking couples' emotion\nrecognition from the lab which is the status quo, to daily life. This thesis\ncontributes toward building automated emotion recognition systems that would\neventually enable partners to monitor their emotions in daily life and enable\nthe delivery of interventions to improve their emotional well-being.", "published": "2022-12-21 16:41:11", "link": "http://arxiv.org/abs/2212.13917v1", "categories": ["cs.HC", "cs.CL", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "cs.HC"}
{"title": "Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for\n  Instruction Generation Models", "abstract": "Recent work studies the cognitive capabilities of language models through\npsychological tests designed for humans. While these studies are helpful for\nunderstanding the general capabilities of these models, there is no guarantee\nthat a model possessing sufficient capabilities to pass those tests would\nactually use those capabilities in performing real-life tasks. In this work, we\nformulate task-oriented cognitive capabilities, which are human-like cognitive\ncapabilities that language models leverage to perform tasks. These capabilities\nare (i) the ability to quickly generate good candidate utterances (the search\ncapability) (ii) the ability to predict how a listener interprets those\nutterances and choose the most appropriate one (the pragmatic capability). We\ndesign an evaluation scheme for comparing these capabilities of a language\nmodel with those of a human. Applying this scheme to examine various models in\na navigation instruction generation problem, we find that their pragmatic\ncapability is severely lacking. This insight leads us to augment them with\nbetter models of the listener and obtain a significant boost of 11% in success\nrate in guiding real humans. Our work advocates for having a principled\nprocedure for aligning language models with humans that involves (i)\nformulating task-oriented capabilities, (ii) devising a method to quantify\ntheir deficiency, and (iii) iteratively improving them.", "published": "2022-12-21 04:43:19", "link": "http://arxiv.org/abs/2301.05149v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Polytopic Analysis of Music", "abstract": "Structural segmentation of music refers to the task of finding a symbolic\nrepresentation of the organisation of a song, reducing the musical flow to a\npartition of non-overlapping segments. Under this definition, the musical\nstructure may not be unique, and may even be ambiguous. One way to resolve that\nambiguity is to see this task as a compression process, and to consider the\nmusical structure as the optimization of a given compression criteria. In that\nviewpoint, C. Guichaoua developed a compression-driven model for retrieving the\nmusical structure, based on the \"System and Contrast\" model, and on polytopes,\nwhich are extension of nhypercubes. We present this model, which we call\n\"polytopic analysis of music\", along with a new opensource dedicated toolbox\ncalled MusicOnPolytopes (in Python). This model is also extended to the use of\nthe Tonnetz as a relation system. Structural segmentation experiments are\nconducted on the RWC Pop dataset. Results show improvements compared to the\nprevious ones, presented by C. Guichaoua.", "published": "2022-12-21 14:58:20", "link": "http://arxiv.org/abs/2212.11054v2", "categories": ["cs.SD", "eess.AS", "H.5.5"], "primary_category": "cs.SD"}
{"title": "Generating music with sentiment using Transformer-GANs", "abstract": "The field of Automatic Music Generation has seen significant progress thanks\nto the advent of Deep Learning. However, most of these results have been\nproduced by unconditional models, which lack the ability to interact with their\nusers, not allowing them to guide the generative process in meaningful and\npractical ways. Moreover, synthesizing music that remains coherent across\nlonger timescales while still capturing the local aspects that make it sound\n``realistic'' or ``human-like'' is still challenging. This is due to the large\ncomputational requirements needed to work with long sequences of data, and also\nto limitations imposed by the training schemes that are often employed. In this\npaper, we propose a generative model of symbolic music conditioned by data\nretrieved from human sentiment. The model is a Transformer-GAN trained with\nlabels that correspond to different configurations of the valence and arousal\ndimensions that quantitatively represent human affective states. We try to\ntackle both of the problems above by employing an efficient linear version of\nAttention and using a Discriminator both as a tool to improve the overall\nquality of the generated music and its ability to follow the conditioning\nsignals.", "published": "2022-12-21 15:59:35", "link": "http://arxiv.org/abs/2212.11134v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ReVISE: Self-Supervised Speech Resynthesis with Visual Input for\n  Universal and Generalized Speech Enhancement", "abstract": "Prior works on improving speech quality with visual input typically study\neach type of auditory distortion separately (e.g., separation, inpainting,\nvideo-to-speech) and present tailored algorithms. This paper proposes to unify\nthese subjects and study Generalized Speech Enhancement, where the goal is not\nto reconstruct the exact reference clean signal, but to focus on improving\ncertain aspects of speech. In particular, this paper concerns intelligibility,\nquality, and video synchronization. We cast the problem as audio-visual speech\nresynthesis, which is composed of two steps: pseudo audio-visual speech\nrecognition (P-AVSR) and pseudo text-to-speech synthesis (P-TTS). P-AVSR and\nP-TTS are connected by discrete units derived from a self-supervised speech\nmodel. Moreover, we utilize self-supervised audio-visual speech model to\ninitialize P-AVSR. The proposed model is coined ReVISE. ReVISE is the first\nhigh-quality model for in-the-wild video-to-speech synthesis and achieves\nsuperior performance on all LRS3 audio-visual enhancement tasks with a single\nmodel. To demonstrates its applicability in the real world, ReVISE is also\nevaluated on EasyCom, an audio-visual benchmark collected under challenging\nacoustic conditions with only 1.6 hours of training data. Similarly, ReVISE\ngreatly suppresses noise and improves quality. Project page:\nhttps://wnhsu.github.io/ReVISE.", "published": "2022-12-21 21:36:52", "link": "http://arxiv.org/abs/2212.11377v1", "categories": ["eess.AS", "cs.CV", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
