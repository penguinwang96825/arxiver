{"title": "Language Model Pre-training for Hierarchical Document Representations", "abstract": "Hierarchical neural architectures are often used to capture long-distance\ndependencies and have been applied to many document-level tasks such as\nsummarization, document segmentation, and sentiment analysis. However,\neffective usage of such a large context can be difficult to learn, especially\nin the case where there is limited labeled data available. Building on the\nrecent success of language model pretraining methods for learning flat\nrepresentations of text, we propose algorithms for pre-training hierarchical\ndocument representations from unlabeled data. Unlike prior work, which has\nfocused on pre-training contextual token representations or context-independent\n{sentence/paragraph} representations, our hierarchical document representations\ninclude fixed-length sentence/paragraph representations which integrate\ncontextual information from the entire documents. Experiments on document\nsegmentation, document-level question answering, and extractive document\nsummarization demonstrate the effectiveness of the proposed pre-training\nalgorithms.", "published": "2019-01-26 00:35:35", "link": "http://arxiv.org/abs/1901.09128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Dimension Identification in User-Generated Text with LSTM\n  Networks", "abstract": "In the process of online storytelling, individual users create and consume\nhighly diverse content that contains a great deal of implicit beliefs and not\nplainly expressed narrative. It is hard to manually detect these implicit\nbeliefs, intentions and moral foundations of the writers. We study and\ninvestigate two different tasks, each of which reflect the difficulty of\ndetecting an implicit user's knowledge, intent or belief that may be based on\nwriter's moral foundation: 1) political perspective detection in news articles\n2) identification of informational vs. conversational questions in community\nquestion answering (CQA) archives and. In both tasks we first describe new\ninteresting annotated datasets and make the datasets publicly available.\nSecond, we compare various classification algorithms, and show the differences\nin their performance on both tasks. Third, in political perspective detection\ntask we utilize a narrative representation language of local press to identify\nperspective differences between presumably neutral American and British press.", "published": "2019-01-26 14:18:57", "link": "http://arxiv.org/abs/1901.09219v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Linear-complexity Multi-biometric Forensic Document Analysis System,\n  by Fusing the Stylome and Signature Modalities", "abstract": "Forensic Document Analysis (FDA) addresses the problem of finding the\nauthorship of a given document. Identification of the document writer via a\nnumber of its modalities (e.g. handwriting, signature, linguistic writing style\n(i.e. stylome), etc.) has been studied in the FDA state-of-the-art. But, no\nresearch is conducted on the fusion of stylome and signature modalities. In\nthis paper, we propose such a bimodal FDA system (which has vast applications\nin judicial, police-related, and historical documents analysis) with a focus on\ntime-complexity. The proposed bimodal system can be trained and tested with\nlinear time complexity. For this purpose, we first revisit Multinomial Na\\\"ive\nBayes (MNB), as the best state-of-the-art linear-complexity authorship\nattribution system and, then, prove its superior accuracy to the well-known\nlinear-complexity classifiers in the state-of-the-art. Then, we propose a fuzzy\nversion of MNB for being fused with a state-of-the-art well-known\nlinear-complexity fuzzy signature recognition system. For the evaluation\npurposes, we construct a chimeric dataset, composed of signatures and textual\ncontents of different letters. Despite its linear-complexity, the proposed\nmulti-biometric system is proven to meaningfully improve its state-of-the-art\nunimodal counterparts, regarding the accuracy, F-Score, Detection Error\nTrade-off (DET), Cumulative Match Characteristics (CMC), and Match Score\nHistograms (MSH) evaluation metrics.", "published": "2019-01-26 10:26:55", "link": "http://arxiv.org/abs/1902.02176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stopping Active Learning based on Predicted Change of F Measure for Text\n  Classification", "abstract": "During active learning, an effective stopping method allows users to limit\nthe number of annotations, which is cost effective. In this paper, a new\nstopping method called Predicted Change of F Measure will be introduced that\nattempts to provide the users an estimate of how much performance of the model\nis changing at each iteration. This stopping method can be applied with any\nbase learner. This method is useful for reducing the data annotation bottleneck\nencountered when building text classification systems.", "published": "2019-01-26 00:01:27", "link": "http://arxiv.org/abs/1901.09118v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "primary_category": "cs.LG"}
{"title": "The Use of Unlabeled Data versus Labeled Data for Stopping Active\n  Learning for Text Classification", "abstract": "Annotation of training data is the major bottleneck in the creation of text\nclassification systems. Active learning is a commonly used technique to reduce\nthe amount of training data one needs to label. A crucial aspect of active\nlearning is determining when to stop labeling data. Three potential sources for\ninforming when to stop active learning are an additional labeled set of data,\nan unlabeled set of data, and the training data that is labeled during the\nprocess of active learning. To date, no one has compared and contrasted the\nadvantages and disadvantages of stopping methods based on these three\ninformation sources. We find that stopping methods that use unlabeled data are\nmore effective than methods that use labeled data.", "published": "2019-01-26 00:27:02", "link": "http://arxiv.org/abs/1901.09126v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "primary_category": "cs.LG"}
{"title": "Weighted-Sampling Audio Adversarial Example Attack", "abstract": "Recent studies have highlighted audio adversarial examples as a ubiquitous\nthreat to state-of-the-art automatic speech recognition systems. Thorough\nstudies on how to effectively generate adversarial examples are essential to\nprevent potential attacks. Despite many research on this, the efficiency and\nthe robustness of existing works are not yet satisfactory. In this paper, we\npropose~\\textit{weighted-sampling audio adversarial examples}, focusing on the\nnumbers and the weights of distortion to reinforce the attack. Further, we\napply a denoising method in the loss function to make the adversarial attack\nmore imperceptible. Experiments show that our method is the first in the field\nto generate audio adversarial examples with low noise and high audio robustness\nat the minute time-consuming level.", "published": "2019-01-26 11:57:38", "link": "http://arxiv.org/abs/1901.10300v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "End-to-End Multi-Task Denoising for joint SDR and PESQ Optimization", "abstract": "Supervised learning based on a deep neural network recently has achieved\nsubstantial improvement on speech enhancement. Denoising networks learn mapping\nfrom noisy speech to clean one directly, or to a spectrum mask which is the\nratio between clean and noisy spectra. In either case, the network is optimized\nby minimizing mean square error (MSE) between ground-truth labels and\ntime-domain or spectrum output. However, existing schemes have either of two\ncritical issues: spectrum and metric mismatches. The spectrum mismatch is a\nwell known issue that any spectrum modification after short-time Fourier\ntransform (STFT), in general, cannot be fully recovered after inverse\nshort-time Fourier transform (ISTFT). The metric mismatch is that a\nconventional MSE metric is sub-optimal to maximize our target metrics,\nsignal-to-distortion ratio (SDR) and perceptual evaluation of speech quality\n(PESQ). This paper presents a new end-to-end denoising framework with the goal\nof joint SDR and PESQ optimization. First, the network optimization is\nperformed on the time-domain signals after ISTFT to avoid spectrum mismatch.\nSecond, two loss functions which have improved correlations with SDR and PESQ\nmetrics are proposed to minimize metric mismatch. The experimental result\nshowed that the proposed denoising scheme significantly improved both SDR and\nPESQ performance over the existing methods.", "published": "2019-01-26 02:48:08", "link": "http://arxiv.org/abs/1901.09146v4", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
