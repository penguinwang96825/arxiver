{"title": "Why we have switched from building full-fledged taxonomies to simply\n  detecting hypernymy relations", "abstract": "The study of taxonomies and hypernymy relations has been extensive on the\nNatural Language Processing (NLP) literature. However, the evaluation of\ntaxonomy learning approaches has been traditionally troublesome, as it mainly\nrelies on ad-hoc experiments which are hardly reproducible and manually\nexpensive. Partly because of this, current research has been lately focusing on\nthe hypernymy detection task. In this paper we reflect on this trend, analyzing\nissues related to current evaluation procedures. Finally, we propose three\npotential avenues for future work so that is-a relations and resources based on\nthem play a more important role in downstream NLP applications.", "published": "2017-03-12 21:07:54", "link": "http://arxiv.org/abs/1703.04178v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Feature overwriting as a finite mixture process: Evidence from\n  comprehension data", "abstract": "The ungrammatical sentence \"The key to the cabinets are on the table\" is\nknown to lead to an illusion of grammaticality. As discussed in the\nmeta-analysis by Jaeger et al., 2017, faster reading times are observed at the\nverb are in the agreement-attraction sentence above compared to the equally\nungrammatical sentence \"The key to the cabinet are on the table\". One\nexplanation for this facilitation effect is the feature percolation account:\nthe plural feature on cabinets percolates up to the head noun key, leading to\nthe illusion. An alternative account is in terms of cue-based retrieval (Lewis\n& Vasishth, 2005), which assumes that the non-subject noun cabinets is\nmisretrieved due to a partial feature-match when a dependency completion\nprocess at the auxiliary initiates a memory access for a subject with plural\nmarking. We present evidence for yet another explanation for the observed\nfacilitation. Because the second sentence has two nouns with identical number,\nit is possible that these are, in some proportion of trials, more difficult to\nkeep distinct, leading to slower reading times at the verb in the first\nsentence above; this is the feature overwriting account of Nairne, 1990. We\nshow that the feature overwriting proposal can be implemented as a finite\nmixture process. We reanalysed ten published data-sets, fitting hierarchical\nBayesian mixture models to these data assuming a two-mixture distribution. We\nshow that in nine out of the ten studies, a mixture distribution corresponding\nto feature overwriting furnishes a superior fit over both the feature\npercolation and the cue-based retrieval accounts.", "published": "2017-03-12 08:11:29", "link": "http://arxiv.org/abs/1703.04081v2", "categories": ["stat.ML", "cs.CL", "stat.AP"], "primary_category": "stat.ML"}
