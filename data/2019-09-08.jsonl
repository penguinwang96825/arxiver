{"title": "Designing and Interpreting Probes with Control Tasks", "abstract": "Probes, supervised models trained to predict properties (like\nparts-of-speech) from representations (like ELMo), have achieved high accuracy\non a range of linguistic tasks. But does this mean that the representations\nencode linguistic structure or just that the probe has learned the linguistic\ntask? In this paper, we propose control tasks, which associate word types with\nrandom outputs, to complement linguistic tasks. By construction, these tasks\ncan only be learned by the probe itself. So a good probe, (one that reflects\nthe representation), should be selective, achieving high linguistic task\naccuracy and low control task accuracy. The selectivity of a probe puts\nlinguistic task accuracy in context with the probe's capacity to memorize from\nword types. We construct control tasks for English part-of-speech tagging and\ndependency edge prediction, and show that popular probes on ELMo\nrepresentations are not selective. We also find that dropout, commonly used to\ncontrol probe complexity, is ineffective for improving selectivity of MLPs, but\nthat other forms of regularization are effective. Finally, we find that while\nprobes on the first layer of ELMo yield slightly better part-of-speech tagging\naccuracy than the second, probes on the second layer are substantially more\nselective, which raises the question of which layer better represents\nparts-of-speech.", "published": "2019-09-08 02:04:32", "link": "http://arxiv.org/abs/1909.03368v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Symmetric Regularization based BERT for Pair-wise Semantic Reasoning", "abstract": "The ability of semantic reasoning over the sentence pair is essential for\nmany natural language understanding tasks, e.g., natural language inference and\nmachine reading comprehension. A recent significant improvement in these tasks\ncomes from BERT. As reported, the next sentence prediction (NSP) in BERT, which\nlearns the contextual relationship between two sentences, is of great\nsignificance for downstream problems with sentence-pair input. Despite the\neffectiveness of NSP, we suggest that NSP still lacks the essential signal to\ndistinguish between entailment and shallow correlation. To remedy this, we\npropose to augment the NSP task to a 3-class categorization task, which\nincludes a category for previous sentence prediction (PSP). The involvement of\nPSP encourages the model to focus on the informative semantics to determine the\nsentence order, thereby improves the ability of semantic understanding. This\nsimple modification yields remarkable improvement against vanilla BERT. To\nfurther incorporate the document-level information, the scope of NSP and PSP is\nexpanded into a broader range, i.e., NSP and PSP also include close but\nnonsuccessive sentences, the noise of which is mitigated by the label-smoothing\ntechnique. Both qualitative and quantitative experimental results demonstrate\nthe effectiveness of the proposed method. Our method consistently improves the\nperformance on the NLI and MRC benchmarks, including the challenging HANS\ndataset \\cite{hans}, suggesting that the document-level task is still promising\nfor the pre-training.", "published": "2019-09-08 08:55:09", "link": "http://arxiv.org/abs/1909.03405v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commonsense Knowledge + BERT for Level 2 Reading Comprehension Ability\n  Test", "abstract": "Commonsense knowledge plays an important role when we read. The performance\nof BERT on SQuAD dataset shows that the accuracy of BERT can be better than\nhuman users. However, it does not mean that computers can surpass the human\nbeing in reading comprehension. CommonsenseQA is a large-scale dataset which is\ndesigned based on commonsense knowledge. BERT only achieved an accuracy of\n55.9% on it. The result shows that computers cannot apply commonsense knowledge\nlike human beings to answer questions. Comprehension Ability Test (CAT) divided\nthe reading comprehension ability at four levels. We can achieve human like\ncomprehension ability level by level. BERT has performed well at level 1 which\ndoes not require common knowledge. In this research, we propose a system which\naims to allow computers to read articles and answer related questions with\ncommonsense knowledge like a human being for CAT level 2. This system consists\nof three parts. Firstly, we built a commonsense knowledge graph; and then\nautomatically constructed the commonsense knowledge question dataset according\nto it. Finally, BERT is combined with the commonsense knowledge to achieve the\nreading comprehension ability at CAT level 2. Experiments show that it can pass\nthe CAT as long as the required common knowledge is included in the knowledge\nbase.", "published": "2019-09-08 09:47:56", "link": "http://arxiv.org/abs/1909.03415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "May I Check Again? -- A simple but efficient way to generate and use\n  contextual dictionaries for Named Entity Recognition. Application to French\n  Legal Texts", "abstract": "In this paper we present a new method to learn a model robust to typos for a\nNamed Entity Recognition task. Our improvement over existing methods helps the\nmodel to take into account the context of the sentence inside a court decision\nin order to recognize an entity with a typo. We used state-of-the-art models\nand enriched the last layer of the neural network with high-level information\nlinked with the potential of the word to be a certain type of entity. More\nprecisely, we utilized the similarities between the word and the potential\nentity candidates in the tagged sentence context. The experiments on a dataset\nof French court decisions show a reduction of the relative F1-score error of\n32%, upgrading the score obtained with the most competitive fine-tuned\nstate-of-the-art system from 94.85% to 96.52%.", "published": "2019-09-08 12:52:46", "link": "http://arxiv.org/abs/1909.03453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-based Sentiment Classification with Aspect-specific Graph\n  Convolutional Networks", "abstract": "Due to their inherent capability in semantic alignment of aspects and their\ncontext words, attention mechanism and Convolutional Neural Networks (CNNs) are\nwidely applied for aspect-based sentiment classification. However, these models\nlack a mechanism to account for relevant syntactical constraints and long-range\nword dependencies, and hence may mistakenly recognize syntactically irrelevant\ncontextual words as clues for judging aspect sentiment. To tackle this problem,\nwe propose to build a Graph Convolutional Network (GCN) over the dependency\ntree of a sentence to exploit syntactical information and word dependencies.\nBased on it, a novel aspect-specific sentiment classification framework is\nraised. Experiments on three benchmarking collections illustrate that our\nproposed model has comparable effectiveness to a range of state-of-the-art\nmodels, and further demonstrate that both syntactical information and\nlong-range word dependencies are properly captured by the graph convolution\nstructure.", "published": "2019-09-08 14:21:54", "link": "http://arxiv.org/abs/1909.03477v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Topic Quality with Posterior Variability", "abstract": "Probabilistic topic models such as latent Dirichlet allocation (LDA) are\npopularly used with Bayesian inference methods such as Gibbs sampling to learn\nposterior distributions over topic model parameters. We derive a novel measure\nof LDA topic quality using the variability of the posterior distributions.\nCompared to several existing baselines for automatic topic evaluation, the\nproposed metric achieves state-of-the-art correlations with human judgments of\ntopic quality in experiments on three corpora. We additionally demonstrate that\ntopic quality estimation can be further improved using a supervised estimator\nthat combines multiple metrics.", "published": "2019-09-08 18:25:48", "link": "http://arxiv.org/abs/1909.03524v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Czech Text Processing with Contextual Embeddings: POS Tagging,\n  Lemmatization, Parsing and NER", "abstract": "Contextualized embeddings, which capture appropriate word meaning depending\non context, have recently been proposed. We evaluate two meth ods for\nprecomputing such embeddings, BERT and Flair, on four Czech text processing\ntasks: part-of-speech (POS) tagging, lemmatization, dependency pars ing and\nnamed entity recognition (NER). The first three tasks, POS tagging,\nlemmatization and dependency parsing, are evaluated on two corpora: the Prague\nDependency Treebank 3.5 and the Universal Dependencies 2.3. The named entity\nrecognition (NER) is evaluated on the Czech Named Entity Corpus 1.1 and 2.0. We\nreport state-of-the-art results for the above mentioned tasks and corpora.", "published": "2019-09-08 21:00:05", "link": "http://arxiv.org/abs/1909.03544v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity, Relation, and Event Extraction with Contextualized Span\n  Representations", "abstract": "We examine the capabilities of a unified, multi-task framework for three\ninformation extraction tasks: named entity recognition, relation extraction,\nand event extraction. Our framework (called DyGIE++) accomplishes all tasks by\nenumerating, refining, and scoring text spans designed to capture local\n(within-sentence) and global (cross-sentence) context. Our framework achieves\nstate-of-the-art results across all tasks, on four datasets from a variety of\ndomains. We perform experiments comparing different techniques to construct\nspan representations. Contextualized embeddings like BERT perform well at\ncapturing relationships among entities in the same or adjacent sentences, while\ndynamic span graph updates model long-range cross-sentence relationships. For\ninstance, propagating span representations via predicted coreference links can\nenable the model to disambiguate challenging entity mentions. Our code is\npublicly available at https://github.com/dwadden/dygiepp and can be easily\nadapted for new tasks or datasets.", "published": "2019-09-08 21:19:09", "link": "http://arxiv.org/abs/1909.03546v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quality Estimation for Image Captions Based on Large-scale Human\n  Evaluations", "abstract": "Automatic image captioning has improved significantly over the last few\nyears, but the problem is far from being solved, with state of the art models\nstill often producing low quality captions when used in the wild. In this\npaper, we focus on the task of Quality Estimation (QE) for image captions,\nwhich attempts to model the caption quality from a human perspective and\nwithout access to ground-truth references, so that it can be applied at\nprediction time to detect low-quality captions produced on previously unseen\nimages. For this task, we develop a human evaluation process that collects\ncoarse-grained caption annotations from crowdsourced users, which is then used\nto collect a large scale dataset spanning more than 600k caption quality\nratings. We then carefully validate the quality of the collected ratings and\nestablish baseline models for this new QE task. Finally, we further collect\nfine-grained caption quality annotations from trained raters, and use them to\ndemonstrate that QE models trained over the coarse ratings can effectively\ndetect and filter out low-quality image captions, thereby improving the user\nexperience from captioning systems.", "published": "2019-09-08 06:55:53", "link": "http://arxiv.org/abs/1909.03396v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Back to the Future -- Sequential Alignment of Text Representations", "abstract": "Language evolves over time in many ways relevant to natural language\nprocessing tasks. For example, recent occurrences of tokens 'BERT' and 'ELMO'\nin publications refer to neural network architectures rather than persons. This\ntype of temporal signal is typically overlooked, but is important if one aims\nto deploy a machine learning model over an extended period of time. In\nparticular, language evolution causes data drift between time-steps in\nsequential decision-making tasks. Examples of such tasks include prediction of\npaper acceptance for yearly conferences (regular intervals) or author stance\nprediction for rumours on Twitter (irregular intervals). Inspired by successes\nin computer vision, we tackle data drift by sequentially aligning learned\nrepresentations. We evaluate on three challenging tasks varying in terms of\ntime-scales, linguistic units, and domains. These tasks show our method\noutperforming several strong baselines, including using all available data. We\nargue that, due to its low computational expense, sequential alignment is a\npractical solution to dealing with language evolution.", "published": "2019-09-08 13:35:12", "link": "http://arxiv.org/abs/1909.03464v3", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "MULE: Multimodal Universal Language Embedding", "abstract": "Existing vision-language methods typically support two languages at a time at\nmost. In this paper, we present a modular approach which can easily be\nincorporated into existing vision-language methods in order to support many\nlanguages. We accomplish this by learning a single shared Multimodal Universal\nLanguage Embedding (MULE) which has been visually-semantically aligned across\nall languages. Then we learn to relate MULE to visual data as if it were a\nsingle language. Our method is not architecture specific, unlike prior work\nwhich typically learned separate branches for each language, enabling our\napproach to easily be adapted to many vision-language methods and tasks. Since\nMULE learns a single language branch in the multimodal model, we can also scale\nto support many languages, and languages with fewer annotations can take\nadvantage of the good representation learned from other (more abundant)\nlanguage data. We demonstrate the effectiveness of MULE on the bidirectional\nimage-sentence retrieval task, supporting up to four languages in a single\nmodel. In addition, we show that Machine Translation can be used for data\naugmentation in multilingual learning, which, combined with MULE, improves mean\nrecall by up to 21.9% on a single-language compared to prior work, with the\nmost significant gains seen on languages with relatively few annotations. Our\ncode is publicly available.", "published": "2019-09-08 16:08:04", "link": "http://arxiv.org/abs/1909.03493v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multi-Task Bidirectional Transformer Representations for Irony Detection", "abstract": "Supervised deep learning requires large amounts of training data. In the\ncontext of the FIRE2019 Arabic irony detection shared task (IDAT@FIRE2019), we\nshow how we mitigate this need by fine-tuning the pre-trained bidirectional\nencoders from transformers (BERT) on gold data in a multi-task setting. We\nfurther improve our models by by further pre-training BERT on `in-domain' data,\nthus alleviating an issue of dialect mismatch in the Google-released BERT\nmodel. Our best model acquires 82.4 macro F1 score, and has the unique\nadvantage of being feature-engineering free (i.e., based exclusively on deep\nlearning).", "published": "2019-09-08 18:31:42", "link": "http://arxiv.org/abs/1909.03526v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QuaRTz: An Open-Domain Dataset of Qualitative Relationship Questions", "abstract": "We introduce the first open-domain dataset, called QuaRTz, for reasoning\nabout textual qualitative relationships. QuaRTz contains general qualitative\nstatements, e.g., \"A sunscreen with a higher SPF protects the skin longer.\",\ntwinned with 3864 crowdsourced situated questions, e.g., \"Billy is wearing\nsunscreen with a lower SPF than Lucy. Who will be best protected from the\nsun?\", plus annotations of the properties being compared. Unlike previous\ndatasets, the general knowledge is textual and not tied to a fixed set of\nrelationships, and tests a system's ability to comprehend and apply textual\nqualitative knowledge in a novel setting. We find state-of-the-art results are\nsubstantially (20%) below human performance, presenting an open challenge to\nthe NLP community.", "published": "2019-09-08 22:05:19", "link": "http://arxiv.org/abs/1909.03553v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Countering the Effects of Lead Bias in News Summarization via\n  Multi-Stage Training and Auxiliary Losses", "abstract": "Sentence position is a strong feature for news summarization, since the lead\noften (but not always) summarizes the key points of the article. In this paper,\nwe show that recent neural systems excessively exploit this trend, which\nalthough powerful for many inputs, is also detrimental when summarizing\ndocuments where important content should be extracted from later parts of the\narticle. We propose two techniques to make systems sensitive to the importance\nof content in different parts of the article. The first technique employs\n'unbiased' data; i.e., randomly shuffled sentences of the source document, to\npretrain the model. The second technique uses an auxiliary ROUGE-based loss\nthat encourages the model to distribute importance scores throughout a document\nby mimicking sentence-level ROUGE scores on the training data. We show that\nthese techniques significantly improve the performance of a competitive\nreinforcement learning based extractive system, with the auxiliary loss being\nmore powerful than pretraining.", "published": "2019-09-08 05:50:18", "link": "http://arxiv.org/abs/1909.04028v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distributed Training of Embeddings using Graph Analytics", "abstract": "Many applications today, such as NLP, network analysis, and code analysis,\nrely on semantically embedding objects into low-dimensional fixed-length\nvectors. Such embeddings naturally provide a way to perform useful downstream\ntasks, such as identifying relations among objects or predicting objects for a\ngiven context, etc. Unfortunately, the training necessary for accurate\nembeddings is usually computationally intensive and requires processing large\namounts of data. Furthermore, distributing this training is challenging. Most\nembedding training uses stochastic gradient descent (SGD), an \"inherently\"\nsequential algorithm. Prior approaches to parallelizing SGD do not honor these\ndependencies and thus potentially suffer poor convergence.\n  This paper presents a distributed training framework for a class of\napplications that use Skip-gram-like models to generate embeddings. We call\nthis class Any2Vec and it includes Word2Vec, DeepWalk, and Node2Vec among\nothers. We first formulate Any2Vec training algorithm as a graph application\nand leverage the state-of-the-art distributed graph analytics framework,\nD-Galois. We adapt D-Galois to support dynamic graph generation and\nrepartitioning, and incorporate novel communication optimizations. Finally, we\nintroduce a novel way to combine gradients during distributed training to\nprevent accuracy loss. We show that our framework, called GraphAny2Vec, matches\non a cluster of 32 hosts the accuracy of the state-of-the-art shared-memory\nimplementations of Word2Vec and Vertex2Vec on 1 host, and gives a geo-mean\nspeedup of 12x and 5x respectively. Furthermore, GraphAny2Vec is on average 2x\nfaster than the state-of-the-art distributed Word2Vec implementation, DMTK, on\n32 hosts. We also show the superiority of our Gradient Combiner independent of\nGraphAny2Vec by incorporating it in DMTK, which raises its accuracy by > 30%.", "published": "2019-09-08 01:06:03", "link": "http://arxiv.org/abs/1909.03359v2", "categories": ["cs.LG", "cs.CL", "cs.DC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conditional Text Generation for Harmonious Human-Machine Interaction", "abstract": "In recent years, with the development of deep learning, text generation\ntechnology has undergone great changes and provided many kinds of services for\nhuman beings, such as restaurant reservation and daily communication. The\nautomatically generated text is becoming more and more fluent so researchers\nbegin to consider more anthropomorphic text generation technology, that is the\nconditional text generation, including emotional text generation, personalized\ntext generation, and so on. Conditional Text Generation (CTG) has thus become a\nresearch hotspot. As a promising research field, we find that many efforts have\nbeen paid to exploring it. Therefore, we aim to give a comprehensive review of\nthe new research trends of CTG. We first summary several key techniques and\nillustrate the technical evolution route in the field of neural text\ngeneration, based on the concept model of CTG. We further make an investigation\nof existing CTG fields and propose several general learning models for CTG.\nFinally, we discuss the open issues and promising research directions of CTG.", "published": "2019-09-08 09:31:20", "link": "http://arxiv.org/abs/1909.03409v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Story Realization: Expanding Plot Events into Sentences", "abstract": "Neural network based approaches to automated story plot generation attempt to\nlearn how to generate novel plots from a corpus of natural language plot\nsummaries. Prior work has shown that a semantic abstraction of sentences called\nevents improves neural plot generation and and allows one to decompose the\nproblem into: (1) the generation of a sequence of events (event-to-event) and\n(2) the transformation of these events into natural language sentences\n(event-to-sentence). However, typical neural language generation approaches to\nevent-to-sentence can ignore the event details and produce\ngrammatically-correct but semantically-unrelated sentences. We present an\nensemble-based model that generates natural language guided by events.We\nprovide results---including a human subjects study---for a full end-to-end\nautomated story generation system showing that our method generates more\ncoherent and plausible stories than baseline approaches.", "published": "2019-09-08 15:09:32", "link": "http://arxiv.org/abs/1909.03480v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer to CNN: Label-scarce distillation for efficient text\n  classification", "abstract": "Significant advances have been made in Natural Language Processing (NLP)\nmodelling since the beginning of 2018. The new approaches allow for accurate\nresults, even when there is little labelled data, because these NLP models can\nbenefit from training on both task-agnostic and task-specific unlabelled data.\nHowever, these advantages come with significant size and computational costs.\nThis workshop paper outlines how our proposed convolutional student\narchitecture, having been trained by a distillation process from a large-scale\nmodel, can achieve 300x inference speedup and 39x reduction in parameter count.\nIn some cases, the student model performance surpasses its teacher on the\nstudied tasks.", "published": "2019-09-08 16:57:26", "link": "http://arxiv.org/abs/1909.03508v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Large Scale Question Answering using Tourism Data", "abstract": "We introduce the novel task of answering entity-seeking recommendation\nquestions using a collection of reviews that describe candidate answer\nentities. We harvest a QA dataset that contains 47,124 paragraph-sized real\nuser questions from travelers seeking recommendations for hotels, attractions\nand restaurants. Each question can have thousands of candidate answers to\nchoose from and each candidate is associated with a collection of unstructured\nreviews. This dataset is especially challenging because commonly used neural\narchitectures for reasoning and QA are prohibitively expensive for a task of\nthis scale. As a solution, we design a scalable cluster-select-rerank approach.\nIt first clusters text for each entity to identify exemplar sentences\ndescribing an entity. It then uses a scalable neural information retrieval (IR)\nmodule to select a set of potential entities from the large candidate set. A\nreranker uses a deeper attention-based architecture to pick the best answers\nfrom the selected entities. This strategy performs better than a pure IR or a\npure attention-based reasoning approach yielding nearly 25% relative\nimprovement in Accuracy@3 over both approaches.", "published": "2019-09-08 18:35:03", "link": "http://arxiv.org/abs/1909.03527v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Transfer Learning Robustness in Multi-Class Categorization by\n  Fine-Tuning Pre-Trained Contextualized Language Models", "abstract": "This study compares the effectiveness and robustness of multi-class\ncategorization of Amazon product data using transfer learning on pre-trained\ncontextualized language models. Specifically, we fine-tuned BERT and XLNet, two\nbidirectional models that have achieved state-of-the-art performance on many\nnatural language tasks and benchmarks, including text classification. While\nexisting classification studies and benchmarks focus on binary targets, with\nthe exception of ordinal ranking tasks, here we examine the robustness of such\nmodels as the number of classes grows from 1 to 20. Our experiments demonstrate\nan approximately linear decrease in performance metrics (i.e., precision,\nrecall, $F_1$ score, and accuracy) with the number of class labels. BERT\nconsistently outperforms XLNet using identical hyperparameters on the entire\nrange of class label quantities for categorizing products based on their\ntextual descriptions. BERT is also more affordable than XLNet in terms of the\ncomputational cost (i.e., time and memory) required for training. In all cases\nstudied, the performance degradation rates were estimated to be 1% per\nadditional class label.", "published": "2019-09-08 23:35:00", "link": "http://arxiv.org/abs/1909.03564v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Order-free Learning Alleviating Exposure Bias in Multi-label\n  Classification", "abstract": "Multi-label classification (MLC) assigns multiple labels to each sample.\nPrior studies show that MLC can be transformed to a sequence prediction problem\nwith a recurrent neural network (RNN) decoder to model the label dependency.\nHowever, training a RNN decoder requires a predefined order of labels, which is\nnot directly available in the MLC specification. Besides, RNN thus trained\ntends to overfit the label combinations in the training set and have difficulty\ngenerating unseen label sequences. In this paper, we propose a new framework\nfor MLC which does not rely on a predefined label order and thus alleviates\nexposure bias. The experimental results on three multi-label classification\nbenchmark datasets show that our method outperforms competitive baselines by a\nlarge margin. We also find the proposed approach has a higher probability of\ngenerating label combinations not seen during training than the baseline\nmodels. The result shows that the proposed approach has better generalization\ncapability.", "published": "2019-09-08 11:53:24", "link": "http://arxiv.org/abs/1909.03434v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MIDI-Sandwich2: RNN-based Hierarchical Multi-modal Fusion Generation VAE\n  networks for multi-track symbolic music generation", "abstract": "Currently, almost all the multi-track music generation models use the\nConvolutional Neural Network (CNN) to build the generative model, while the\nRecurrent Neural Network (RNN) based models can not be applied in this task. In\nview of the above problem, this paper proposes a RNN-based Hierarchical\nMulti-modal Fusion Generation Variational Autoencoder (VAE) network,\nMIDI-Sandwich2, for multi-track symbolic music generation. Inspired by VQ-VAE2,\nMIDI-Sandwich2 expands the dimension of the original hierarchical model by\nusing multiple independent Binary Variational Autoencoder (BVAE) models without\nsharing weights to process the information of each track. Then, with\nmulti-modal fusion technology, the upper layer named Multi-modal Fusion\nGeneration VAE (MFG-VAE) combines the latent space vectors generated by the\nrespective tracks, and uses the decoder to perform the ascending dimension\nreconstruction to simulate the inverse operation of multi-modal fusion,\nmulti-modal generation, so as to realize the RNN-based multi-track symbolic\nmusic generation. For the multi-track format pianoroll, we also improve the\noutput binarization method of MuseGAN, which solves the problem that the\nrefinement step of the original scheme is difficult to differentiate and the\ngradient is hard to descent, making the generated song more expressive. The\nmodel is validated on the Lakh Pianoroll Dataset (LPD) multi-track dataset.\nCompared to the MuseGAN, MIDI-Sandwich2 can not only generate harmonious\nmulti-track music, the generation quality is also close to the state of the art\nlevel. At the same time, by using the VAE to restore songs, the semi-generated\nsongs reproduced by the MIDI-Sandwich2 are more beautiful than the pure\nautogeneration music generated by MuseGAN. Both the code and the audition audio\nsamples are open source on https://github.com/LiangHsia/MIDI-S2.", "published": "2019-09-08 17:55:16", "link": "http://arxiv.org/abs/1909.03522v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Ultra-broadband local active noise control with remote acoustic sensing", "abstract": "One enduring challenge for controlling high frequency sound in local active\nnoise control (ANC) systems is to obtain the acoustic signal at the specific\nlocation to be controlled. In some applications such as in ANC headrest\nsystems, it is not practical to install error microphones in a person's ears to\nprovide the user a quiet or optimally acoustically controlled environment. Many\nvirtual error sensing approaches have been proposed to estimate the acoustic\nsignal remotely with the current state-of-the-art method using an array of four\nmicrophones and a head tracking system to yield sound reduction up to 1 kHz for\na single sound source. In the work reported in this paper, a novel approach of\nincorporating remote acoustic sensing using a laser Doppler vibrometer into an\nANC headrest system is investigated. In this 'virtual ANC headphone' system, a\nlightweight retro-reflective membrane pick-up is mounted in each synthetic ear\nof a head and torso simulator to determine the sound in the ear in real-time\nwith minimal invasiveness. The membrane design and the effects of its location\non the system performance are explored, the noise spectra in the ears without\nand with ANC for a variety of relevant primary sound fields are reported, and\nthe performance of the system during head movements is demonstrated. The test\nresults show that at least 10 dB sound attenuation can be realised in the ears\nover an extended frequency range from (500 Hz to 6 kHz) under a complex sound\nfield and for several common types of synthesised environmental noise, even in\nthe presence of head motion.", "published": "2019-09-08 03:00:35", "link": "http://arxiv.org/abs/1909.03377v3", "categories": ["eess.SY", "cs.SD", "cs.SY", "eess.AS", "eess.SP"], "primary_category": "eess.SY"}
