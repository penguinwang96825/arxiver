{"title": "Low-dimensional Embeddings for Interpretable Anchor-based Topic\n  Inference", "abstract": "The anchor words algorithm performs provably efficient topic model inference\nby finding an approximate convex hull in a high-dimensional word co-occurrence\nspace. However, the existing greedy algorithm often selects poor anchor words,\nreducing topic quality and interpretability. Rather than finding an approximate\nconvex hull in a high-dimensional space, we propose to find an exact convex\nhull in a visualizable 2- or 3-dimensional space. Such low-dimensional\nembeddings both improve topics and clearly show users why the algorithm selects\ncertain words.", "published": "2017-11-18 07:52:40", "link": "http://arxiv.org/abs/1711.06826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Transfer in Text: Exploration and Evaluation", "abstract": "Style transfer is an important problem in natural language processing (NLP).\nHowever, the progress in language style transfer is lagged behind other\ndomains, such as computer vision, mainly because of the lack of parallel data\nand principle evaluation metrics. In this paper, we propose to learn style\ntransfer with non-parallel data. We explore two models to achieve this goal,\nand the key idea behind the proposed models is to learn separate content\nrepresentations and style representations using adversarial networks. We also\npropose novel evaluation metrics which measure two aspects of style transfer:\ntransfer strength and content preservation. We access our models and the\nevaluation metrics on two tasks: paper-news title transfer, and\npositive-negative review transfer. Results show that the proposed content\npreservation metric is highly correlate to human judgments, and the proposed\nmodels are able to generate sentences with higher style transfer strength and\nsimilar content preservation score comparing to auto-encoder.", "published": "2017-11-18 13:33:15", "link": "http://arxiv.org/abs/1711.06861v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically Extracting Action Graphs from Materials Science Synthesis\n  Procedures", "abstract": "Computational synthesis planning approaches have achieved recent success in\norganic chemistry, where tabulated synthesis procedures are readily available\nfor supervised learning. The syntheses of inorganic materials, however, exist\nprimarily as natural language narratives contained within scientific journal\narticles. This synthesis information must first be extracted from the text in\norder to enable analogous synthesis planning methods for inorganic materials.\nIn this work, we present a system for automatically extracting structured\nrepresentations of synthesis procedures from the texts of materials science\njournal articles that describe explicit, experimental syntheses of inorganic\ncompounds. We define the structured representation as a set of linked events\nmade up of extracted scientific entities and evaluate two unsupervised\napproaches for extracting these structures on expert-annotated articles: a\nstrong heuristic baseline and a generative model of procedural text. We also\nevaluate a variety of supervised models for extracting scientific entities. Our\nresults provide insight into the nature of the data and directions for further\nwork in this exciting new area of research.", "published": "2017-11-18 15:28:17", "link": "http://arxiv.org/abs/1711.06872v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is China Entering WTO or shijie maoyi zuzhi--a Corpus Study of English\n  Acronyms in Chinese Newspapers", "abstract": "This is one of the first studies that quantitatively examine the usage of\nEnglish acronyms (e.g. WTO) in Chinese texts. Using newspaper corpora, I try to\nanswer 1) for all instances of a concept that has an English acronym (e.g.\nWorld Trade Organization), what percentage is expressed in the English acronym\n(WTO), and what percentage in its Chinese translation (shijie maoyi zuzhi), and\n2) what factors are at play in language users' choice between the English and\nChinese forms? Results show that different concepts have different percentage\nfor English acronyms (PercentOfEn), ranging from 2% to 98%. Linear models show\nthat PercentOfEn for individual concepts can be predicted by language economy\n(how long the Chinese translation is), concept frequency, and whether the first\nappearance of the concept in Chinese newspapers is the English acronym or its\nChinese translation (all p < .05).", "published": "2017-11-18 17:01:24", "link": "http://arxiv.org/abs/1711.06895v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-attending Free-form Regions and Detections with Multi-modal\n  Multiplicative Feature Embedding for Visual Question Answering", "abstract": "Recently, the Visual Question Answering (VQA) task has gained increasing\nattention in artificial intelligence. Existing VQA methods mainly adopt the\nvisual attention mechanism to associate the input question with corresponding\nimage regions for effective question answering. The free-form region based and\nthe detection-based visual attention mechanisms are mostly investigated, with\nthe former ones attending free-form image regions and the latter ones attending\npre-specified detection-box regions. We argue that the two attention mechanisms\nare able to provide complementary information and should be effectively\nintegrated to better solve the VQA problem. In this paper, we propose a novel\ndeep neural network for VQA that integrates both attention mechanisms. Our\nproposed framework effectively fuses features from free-form image regions,\ndetection boxes, and question representations via a multi-modal multiplicative\nfeature embedding scheme to jointly attend question-related free-form image\nregions and detection boxes for more accurate question answering. The proposed\nmethod is extensively evaluated on two publicly available datasets, COCO-QA and\nVQA, and outperforms state-of-the-art approaches. Source code is available at\nhttps://github.com/lupantech/dual-mfa-vqa.", "published": "2017-11-18 02:07:34", "link": "http://arxiv.org/abs/1711.06794v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Acquiring Common Sense Spatial Knowledge through Implicit Spatial\n  Templates", "abstract": "Spatial understanding is a fundamental problem with wide-reaching real-world\napplications. The representation of spatial knowledge is often modeled with\nspatial templates, i.e., regions of acceptability of two objects under an\nexplicit spatial relationship (e.g., \"on\", \"below\", etc.). In contrast with\nprior work that restricts spatial templates to explicit spatial prepositions\n(e.g., \"glass on table\"), here we extend this concept to implicit spatial\nlanguage, i.e., those relationships (generally actions) for which the spatial\narrangement of the objects is only implicitly implied (e.g., \"man riding\nhorse\"). In contrast with explicit relationships, predicting spatial\narrangements from implicit spatial language requires significant common sense\nspatial understanding. Here, we introduce the task of predicting spatial\ntemplates for two objects under a relationship, which can be seen as a spatial\nquestion-answering task with a (2D) continuous output (\"where is the man w.r.t.\na horse when the man is walking the horse?\"). We present two simple\nneural-based models that leverage annotated images and structured text to learn\nthis task. The good performance of these models reveals that spatial locations\nare to a large extent predictable from implicit spatial language. Crucially,\nthe models attain similar performance in a challenging generalized setting,\nwhere the object-relation-object combinations (e.g.,\"man walking dog\") have\nnever been seen before. Next, we go one step further by presenting the models\nwith unseen objects (e.g., \"dog\"). In this scenario, we show that leveraging\nword embeddings enables the models to output accurate spatial predictions,\nproving that the models acquire solid common sense spatial knowledge allowing\nfor such generalization.", "published": "2017-11-18 07:00:44", "link": "http://arxiv.org/abs/1711.06821v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.AI"}
{"title": "The Cultural Evolution of National Constitutions", "abstract": "We explore how ideas from infectious disease and genetics can be used to\nuncover patterns of cultural inheritance and innovation in a corpus of 591\nnational constitutions spanning 1789 - 2008. Legal \"Ideas\" are encoded as\n\"topics\" - words statistically linked in documents - derived from topic\nmodeling the corpus of constitutions. Using these topics we derive a diffusion\nnetwork for borrowing from ancestral constitutions back to the US Constitution\nof 1789 and reveal that constitutions are complex cultural recombinants. We\nfind systematic variation in patterns of borrowing from ancestral texts and\n\"biological\"-like behavior in patterns of inheritance with the distribution of\n\"offspring\" arising through a bounded preferential-attachment process. This\nprocess leads to a small number of highly innovative (influential)\nconstitutions some of which have yet to have been identified as so in the\ncurrent literature. Our findings thus shed new light on the critical nodes of\nthe constitution-making network. The constitutional network structure reflects\nperiods of intense constitution creation, and systematic patterns of variation\nin constitutional life-span and temporal influence.", "published": "2017-11-18 17:10:25", "link": "http://arxiv.org/abs/1711.06899v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "68.U99", "J.4"], "primary_category": "cs.SI"}
{"title": "Separake: Source Separation with a Little Help From Echoes", "abstract": "It is commonly believed that multipath hurts various audio processing\nalgorithms. At odds with this belief, we show that multipath in fact helps\nsound source separation, even with very simple propagation models. Unlike most\nexisting methods, we neither ignore the room impulse responses, nor we attempt\nto estimate them fully. We rather assume that we know the positions of a few\nvirtual microphones generated by echoes and we show how this gives us enough\nspatial diversity to get a performance boost over the anechoic case. We show\nimprovements for two standard algorithms---one that uses only magnitudes of the\ntransfer functions, and one that also uses the phases. Concretely, we show that\nmultichannel non-negative matrix factorization aided with a small number of\nechoes beats the vanilla variant of the same algorithm, and that with magnitude\ninformation only, echoes enable separation where it was previously impossible.", "published": "2017-11-18 03:35:45", "link": "http://arxiv.org/abs/1711.06805v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
