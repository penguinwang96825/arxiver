{"title": "Improving Review Representations with User Attention and Product\n  Attention for Sentiment Classification", "abstract": "Neural network methods have achieved great success in reviews sentiment\nclassification. Recently, some works achieved improvement by incorporating user\nand product information to generate a review representation. However, in\nreviews, we observe that some words or sentences show strong user's preference,\nand some others tend to indicate product's characteristic. The two kinds of\ninformation play different roles in determining the sentiment label of a\nreview. Therefore, it is not reasonable to encode user and product information\ntogether into one representation. In this paper, we propose a novel framework\nto encode user and product information. Firstly, we apply two individual\nhierarchical neural networks to generate two representations, with user\nattention or with product attention. Then, we design a combined strategy to\nmake full use of the two representations for training and final prediction. The\nexperimental results show that our model obviously outperforms other\nstate-of-the-art methods on IMDB and Yelp datasets. Through the visualization\nof attention over words related to user or product, we validate our observation\nmentioned above.", "published": "2018-01-24 05:11:57", "link": "http://arxiv.org/abs/1801.07861v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Support Vector Machine Active Learning Algorithms with\n  Query-by-Committee versus Closest-to-Hyperplane Selection", "abstract": "This paper investigates and evaluates support vector machine active learning\nalgorithms for use with imbalanced datasets, which commonly arise in many\napplications such as information extraction applications. Algorithms based on\nclosest-to-hyperplane selection and query-by-committee selection are combined\nwith methods for addressing imbalance such as positive amplification based on\nprevalence statistics from initial random samples. Three algorithms (ClosestPA,\nQBagPA, and QBoostPA) are presented and carefully evaluated on datasets for\ntext classification and relation extraction. The ClosestPA algorithm is shown\nto consistently outperform the other two in a variety of ways and insights are\nprovided as to why this is the case.", "published": "2018-01-24 06:38:06", "link": "http://arxiv.org/abs/1801.07875v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "primary_category": "cs.LG"}
{"title": "Deep Learning for Sentiment Analysis : A Survey", "abstract": "Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.", "published": "2018-01-24 07:32:29", "link": "http://arxiv.org/abs/1801.07883v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Impact of Batch Size on Stopping Active Learning for Text Classification", "abstract": "When using active learning, smaller batch sizes are typically more efficient\nfrom a learning efficiency perspective. However, in practice due to speed and\nhuman annotator considerations, the use of larger batch sizes is necessary.\nWhile past work has shown that larger batch sizes decrease learning efficiency\nfrom a learning curve perspective, it remains an open question how batch size\nimpacts methods for stopping active learning. We find that large batch sizes\ndegrade the performance of a leading stopping method over and above the\ndegradation that results from reduced learning efficiency. We analyze this\ndegradation and find that it can be mitigated by changing the window size\nparameter of how many past iterations of learning are taken into account when\nmaking the stopping decision. We find that when using larger batch sizes,\nstopping methods are more effective when smaller window sizes are used.", "published": "2018-01-24 07:47:05", "link": "http://arxiv.org/abs/1801.07887v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "primary_category": "cs.LG"}
{"title": "Empirical observations of ultraslow diffusion driven by the fractional\n  dynamics in languages: Dynamical statistical properties of word counts of\n  already popular words", "abstract": "Ultraslow diffusion (i.e. logarithmic diffusion) has been extensively studied\ntheoretically, but has hardly been observed empirically. In this paper,\nfirstly, we find the ultraslow-like diffusion of the time-series of word counts\nof already popular words by analysing three different nationwide language\ndatabases: (i) newspaper articles (Japanese), (ii) blog articles (Japanese),\nand (iii) page views of Wikipedia (English, French, Chinese, and Japanese).\nSecondly, we use theoretical analysis to show that this diffusion is basically\nexplained by the random walk model with the power-law forgetting with the\nexponent $\\beta \\approx 0.5$, which is related to the fractional Langevin\nequation. The exponent $\\beta$ characterises the speed of forgetting and $\\beta\n\\approx 0.5$ corresponds to (i) the border (or thresholds) between the\nstationary and the nonstationary and (ii) the right-in-the-middle dynamics\nbetween the IID noise for $\\beta=1$ and the normal random walk for $\\beta=0$.\nThirdly, the generative model of the time-series of word counts of already\npopular words, which is a kind of Poisson process with the Poisson parameter\nsampled by the above-mentioned random walk model, can almost reproduce not only\nthe empirical mean-squared displacement but also the power spectrum density and\nthe probability density function.", "published": "2018-01-24 12:11:09", "link": "http://arxiv.org/abs/1801.07948v5", "categories": ["physics.soc-ph", "cs.CL", "cs.CY"], "primary_category": "physics.soc-ph"}
{"title": "MAttNet: Modular Attention Network for Referring Expression\n  Comprehension", "abstract": "In this paper, we address referring expression comprehension: localizing an\nimage region described by a natural language expression. While most recent work\ntreats expressions as a single unit, we propose to decompose them into three\nmodular components related to subject appearance, location, and relationship to\nother objects. This allows us to flexibly adapt to expressions containing\ndifferent types of information in an end-to-end framework. In our model, which\nwe call the Modular Attention Network (MAttNet), two types of attention are\nutilized: language-based attention that learns the module weights as well as\nthe word/phrase attention that each module should focus on; and visual\nattention that allows the subject and relationship modules to focus on relevant\nimage components. Module weights combine scores from all three modules\ndynamically to output an overall score. Experiments show that MAttNet\noutperforms previous state-of-art methods by a large margin on both\nbounding-box-level and pixel-level comprehension tasks. Demo and code are\nprovided.", "published": "2018-01-24 20:54:26", "link": "http://arxiv.org/abs/1801.08186v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Waveform Modeling and Generation Using Hierarchical Recurrent Neural\n  Networks for Speech Bandwidth Extension", "abstract": "This paper presents a waveform modeling and generation method using\nhierarchical recurrent neural networks (HRNN) for speech bandwidth extension\n(BWE). Different from conventional BWE methods which predict spectral\nparameters for reconstructing wideband speech waveforms, this BWE method models\nand predicts waveform samples directly without using vocoders. Inspired by\nSampleRNN which is an unconditional neural audio generator, the HRNN model\nrepresents the distribution of each wideband or high-frequency waveform sample\nconditioned on the input narrowband waveform samples using a neural network\ncomposed of long short-term memory (LSTM) layers and feed-forward (FF) layers.\nThe LSTM layers form a hierarchical structure and each layer operates at a\nspecific temporal resolution to efficiently capture long-span dependencies\nbetween temporal sequences. Furthermore, additional conditions, such as the\nbottleneck (BN) features derived from narrowband speech using a deep neural\nnetwork (DNN)-based state classifier, are employed as auxiliary input to\nfurther improve the quality of generated wideband speech. The experimental\nresults of comparing several waveform modeling methods show that the HRNN-based\nmethod can achieve better speech quality and run-time efficiency than the\ndilated convolutional neural network (DCNN)-based method and the plain\nsample-level recurrent neural network (SRNN)-based method. Our proposed method\nalso outperforms the conventional vocoder-based BWE method using LSTM-RNNs in\nterms of the subjective quality of the reconstructed wideband speech.", "published": "2018-01-24 08:53:55", "link": "http://arxiv.org/abs/1801.07910v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CommanderSong: A Systematic Approach for Practical Adversarial Voice\n  Recognition", "abstract": "The popularity of ASR (automatic speech recognition) systems, like Google\nVoice, Cortana, brings in security concerns, as demonstrated by recent attacks.\nThe impacts of such threats, however, are less clear, since they are either\nless stealthy (producing noise-like voice commands) or requiring the physical\npresence of an attack device (using ultrasound). In this paper, we demonstrate\nthat not only are more practical and surreptitious attacks feasible but they\ncan even be automatically constructed. Specifically, we find that the voice\ncommands can be stealthily embedded into songs, which, when played, can\neffectively control the target system through ASR without being noticed. For\nthis purpose, we developed novel techniques that address a key technical\nchallenge: integrating the commands into a song in a way that can be\neffectively recognized by ASR through the air, in the presence of background\nnoise, while not being detected by a human listener. Our research shows that\nthis can be done automatically against real world ASR applications. We also\ndemonstrate that such CommanderSongs can be spread through Internet (e.g.,\nYouTube) and radio, potentially affecting millions of ASR users. We further\npresent a new mitigation technique that controls this threat.", "published": "2018-01-24 22:02:40", "link": "http://arxiv.org/abs/1801.08535v3", "categories": ["cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
