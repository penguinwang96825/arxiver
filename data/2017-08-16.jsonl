{"title": "Learning Chinese Word Representations From Glyphs Of Characters", "abstract": "In this paper, we propose new methods to learn Chinese word representations.\nChinese characters are composed of graphical components, which carry rich\nsemantics. It is common for a Chinese learner to comprehend the meaning of a\nword from these graphical components. As a result, we propose models that\nenhance word representations by character glyphs. The character glyph features\nare directly learned from the bitmaps of characters by convolutional\nauto-encoder(convAE), and the glyph features improve Chinese word\nrepresentations which are already enhanced by character embeddings. Another\ncontribution in this paper is that we created several evaluation datasets in\ntraditional Chinese and made them public.", "published": "2017-08-16 03:17:57", "link": "http://arxiv.org/abs/1708.04755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue Act Segmentation for Vietnamese Human-Human Conversational\n  Texts", "abstract": "Dialog act identification plays an important role in understanding\nconversations. It has been widely applied in many fields such as dialogue\nsystems, automatic machine translation, automatic speech recognition, and\nespecially useful in systems with human-computer natural language dialogue\ninterfaces such as virtual assistants and chatbots. The first step of\nidentifying dialog act is identifying the boundary of the dialog act in\nutterances. In this paper, we focus on segmenting the utterance according to\nthe dialog act boundaries, i.e. functional segments identification, for\nVietnamese utterances. We investigate carefully functional segment\nidentification in two approaches: (1) machine learning approach using maximum\nentropy (ME) and conditional random fields (CRFs); (2) deep learning approach\nusing bidirectional Long Short-Term Memory (LSTM) with a CRF layer\n(Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages\n(Message data); (2) transcription from phone conversations (Phone data). To the\nbest of our knowledge, this is the first work that applies deep learning based\napproach to dialog act segmentation. As the results show, deep learning\napproach performs appreciably better as to compare with traditional machine\nlearning approaches. Moreover, it is also the first study that tackles dialog\nact and functional segment identification for Vietnamese.", "published": "2017-08-16 04:27:09", "link": "http://arxiv.org/abs/1708.04765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mAnI: Movie Amalgamation using Neural Imitation", "abstract": "Cross-modal data retrieval has been the basis of various creative tasks\nperformed by Artificial Intelligence (AI). One such highly challenging task for\nAI is to convert a book into its corresponding movie, which most of the\ncreative film makers do as of today. In this research, we take the first step\ntowards it by visualizing the content of a book using its corresponding movie\nvisuals. Given a set of sentences from a book or even a fan-fiction written in\nthe same universe, we employ deep learning models to visualize the input by\nstitching together relevant frames from the movie. We studied and compared\nthree different types of setting to match the book with the movie content: (i)\nDialog model: using only the dialog from the movie, (ii) Visual model: using\nonly the visual content from the movie, and (iii) Hybrid model: using the\ndialog and the visual content from the movie. Experiments on the publicly\navailable MovieBook dataset shows the effectiveness of the proposed models.", "published": "2017-08-16 15:12:20", "link": "http://arxiv.org/abs/1708.04923v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fault in your stars: An Analysis of Android App Reviews", "abstract": "Mobile app distribution platforms such as Google Play Store allow users to\nshare their feedback about downloaded apps in the form of a review comment and\na corresponding star rating. Typically, the star rating ranges from one to five\nstars, with one star denoting a high sense of dissatisfaction with the app and\nfive stars denoting a high sense of satisfaction.\n  Unfortunately, due to a variety of reasons, often the star rating provided by\na user is inconsistent with the opinion expressed in the review. For example,\nconsider the following review for the Facebook App on Android; \"Awesome App\".\nOne would reasonably expect the rating for this review to be five stars, but\nthe actual rating is one star!\n  Such inconsistent ratings can lead to a deflated (or inflated) overall\naverage rating of an app which can affect user downloads, as typically users\nlook at the average star ratings while making a decision on downloading an app.\nAlso, the app developers receive a biased feedback about the application that\ndoes not represent ground reality. This is especially significant for small\napps with a few thousand downloads as even a small number of mismatched reviews\ncan bring down the average rating drastically.\n  In this paper, we conducted a study on this review-rating mismatch problem.\nWe manually examined 8600 reviews from 10 popular Android apps and found that\n20% of the ratings in our dataset were inconsistent with the review. Further,\nwe developed three systems; two of which were based on traditional machine\nlearning and one on deep learning to automatically identify reviews whose\nrating did not match with the opinion expressed in the review. Our deep\nlearning system performed the best and had an accuracy of 92% in identifying\nthe correct star rating to be associated with a given review.", "published": "2017-08-16 16:37:52", "link": "http://arxiv.org/abs/1708.04968v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deconvolutional Paragraph Representation Learning", "abstract": "Learning latent representations from long text sequences is an important\nfirst step in many natural language processing applications. Recurrent Neural\nNetworks (RNNs) have become a cornerstone for this challenging task. However,\nthe quality of sentences during RNN-based decoding (reconstruction) decreases\nwith the length of the text. We propose a sequence-to-sequence, purely\nconvolutional and deconvolutional autoencoding framework that is free of the\nabove issue, while also being computationally efficient. The proposed method is\nsimple, easy to implement and can be leveraged as a building block for many\napplications. We show empirically that compared to RNNs, our framework is\nbetter at reconstructing and correcting long paragraphs. Quantitative\nevaluation on semi-supervised text classification and summarization tasks\ndemonstrate the potential for better utilization of long unlabeled text data.", "published": "2017-08-16 00:52:32", "link": "http://arxiv.org/abs/1708.04729v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Modality-specific Cross-modal Similarity Measurement with Recurrent\n  Attention Network", "abstract": "Nowadays, cross-modal retrieval plays an indispensable role to flexibly find\ninformation across different modalities of data. Effectively measuring the\nsimilarity between different modalities of data is the key of cross-modal\nretrieval. Different modalities such as image and text have imbalanced and\ncomplementary relationships, which contain unequal amount of information when\ndescribing the same semantics. For example, images often contain more details\nthat cannot be demonstrated by textual descriptions and vice versa. Existing\nworks based on Deep Neural Network (DNN) mostly construct one common space for\ndifferent modalities to find the latent alignments between them, which lose\ntheir exclusive modality-specific characteristics. Different from the existing\nworks, we propose modality-specific cross-modal similarity measurement (MCSM)\napproach by constructing independent semantic space for each modality, which\nadopts end-to-end framework to directly generate modality-specific cross-modal\nsimilarity without explicit common representation. For each semantic space,\nmodality-specific characteristics within one modality are fully exploited by\nrecurrent attention network, while the data of another modality is projected\ninto this space with attention based joint embedding to utilize the learned\nattention weights for guiding the fine-grained cross-modal correlation\nlearning, which can capture the imbalanced and complementary relationships\nbetween different modalities. Finally, the complementarity between the semantic\nspaces for different modalities is explored by adaptive fusion of the\nmodality-specific cross-modal similarities to perform cross-modal retrieval.\nExperiments on the widely-used Wikipedia and Pascal Sentence datasets as well\nas our constructed large-scale XMediaNet dataset verify the effectiveness of\nour proposed approach, outperforming 9 state-of-the-art methods.", "published": "2017-08-16 05:43:54", "link": "http://arxiv.org/abs/1708.04776v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding", "abstract": "Entity alignment is the task of finding entities in two knowledge bases (KBs)\nthat represent the same real-world object. When facing KBs in different natural\nlanguages, conventional cross-lingual entity alignment methods rely on machine\ntranslation to eliminate the language barriers. These approaches often suffer\nfrom the uneven quality of translations between languages. While recent\nembedding-based techniques encode entities and relationships in KBs and do not\nneed machine translation for cross-lingual entity alignment, a significant\nnumber of attributes remain largely unexplored. In this paper, we propose a\njoint attribute-preserving embedding model for cross-lingual entity alignment.\nIt jointly embeds the structures of two KBs into a unified vector space and\nfurther refines it by leveraging attribute correlations in the KBs. Our\nexperimental results on real-world datasets show that this approach\nsignificantly outperforms the state-of-the-art embedding approaches for\ncross-lingual entity alignment and could be complemented with methods based on\nmachine translation.", "published": "2017-08-16 19:30:17", "link": "http://arxiv.org/abs/1708.05045v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
