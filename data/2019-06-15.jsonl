{"title": "Can neural networks understand monotonicity reasoning?", "abstract": "Monotonicity reasoning is one of the important reasoning skills for any\nintelligent natural language inference (NLI) model in that it requires the\nability to capture the interaction between lexical and syntactic structures.\nSince no test set has been developed for monotonicity reasoning with wide\ncoverage, it is still unclear whether neural models can perform monotonicity\nreasoning in a proper way. To investigate this issue, we introduce the\nMonotonicity Entailment Dataset (MED). Performance by state-of-the-art NLI\nmodels on the new test set is substantially worse, under 55%, especially on\ndownward reasoning. In addition, analysis using a monotonicity-driven data\naugmentation method showed that these models might be limited in their\ngeneralization ability in upward and downward reasoning.", "published": "2019-06-15 01:18:41", "link": "http://arxiv.org/abs/1906.06448v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A weakly supervised sequence tagging and grammar induction approach to\n  semantic frame slot filling", "abstract": "This paper describes continuing work on semantic frame slot filling for a\ncommand and control task using a weakly-supervised approach. We investigate the\nadvantages of using retraining techniques that take the output of a\nhierarchical hidden markov model as input to two inductive approaches: (1)\ndiscriminative sequence labelers based on conditional random fields and\nmemory-based learning and (2) probabilistic context-free grammar induction.\nExperimental results show that this setup can significantly improve F-scores\nwithout the need for additional information sources. Furthermore, qualitative\nanalysis shows that the weakly supervised technique is able to automatically\ninduce an easily interpretable and syntactically appropriate grammar for the\ndomain and task at hand.", "published": "2019-06-15 08:13:32", "link": "http://arxiv.org/abs/1906.06493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Integration of Statistical Hypothesis Tests into Deep Neural\n  Networks", "abstract": "We report our ongoing work about a new deep architecture working in tandem\nwith a statistical test procedure for jointly training texts and their label\ndescriptions for multi-label and multi-class classification tasks. A\nstatistical hypothesis testing method is used to extract the most informative\nwords for each given class. These words are used as a class description for\nmore label-aware text classification. Intuition is to help the model to\nconcentrate on more informative words rather than more frequent ones. The model\nleverages the use of label descriptions in addition to the input text to\nenhance text classification performance. Our method is entirely data-driven,\nhas no dependency on other sources of information than the training data, and\nis adaptable to different classification problems by providing appropriate\ntraining data without major hyper-parameter tuning. We trained and tested our\nsystem on several publicly available datasets, where we managed to improve the\nstate-of-the-art on one set with a high margin, and to obtain competitive\nresults on all other ones.", "published": "2019-06-15 12:47:18", "link": "http://arxiv.org/abs/1906.06550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tagged Back-Translation", "abstract": "Recent work in Neural Machine Translation (NMT) has shown significant quality\ngains from noised-beam decoding during back-translation, a method to generate\nsynthetic parallel data. We show that the main role of such synthetic noise is\nnot to diversify the source side, as previously suggested, but simply to\nindicate to the model that the given source is synthetic. We propose a simpler\nalternative to noising techniques, consisting of tagging back-translated source\nsentences with an extra token. Our results on WMT outperform noised\nback-translation in English-Romanian and match performance on English-German,\nre-defining state-of-the-art in the former.", "published": "2019-06-15 00:36:41", "link": "http://arxiv.org/abs/1906.06442v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Attention Based Seq2seq Model for Chinese Lyrics\n  Generation", "abstract": "In this paper, we comprehensively study on context-aware generation of\nChinese song lyrics. Conventional text generative models generate a sequence or\nsentence word by word, failing to consider the contextual relationship between\nsentences. Taking account into the characteristics of lyrics, a hierarchical\nattention based Seq2Seq (Sequence-to-Sequence) model is proposed for Chinese\nlyrics generation. With encoding of word-level and sentence-level contextual\ninformation, this model promotes the topic relevance and consistency of\ngeneration. A large Chinese lyrics corpus is also leveraged for model training.\nEventually, results of automatic and human evaluations demonstrate that our\nmodel is able to compose complete Chinese lyrics with one united topic\nconstraint.", "published": "2019-06-15 06:58:42", "link": "http://arxiv.org/abs/1906.06481v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Practical User Feedback-driven Internal Search Using Online Learning to\n  Rank", "abstract": "We present a system, Spoke, for creating and searching internal knowledge\nbase (KB) articles for organizations. Spoke is available as a SaaS\n(Software-as-a-Service) product deployed across hundreds of organizations with\na diverse set of domains. Spoke continually improves search quality using\nconversational user feedback which allows it to provide better search\nexperience than standard information retrieval systems without encoding any\nexplicit domain knowledge. We achieve this by using a real-time online\nlearning-to-rank (L2R) algorithm that automatically customizes relevance\nscoring for each organization deploying Spoke by using a query similarity\nkernel.\n  The focus of this paper is on incorporating practical considerations into our\nrelevance scoring function and algorithm that make Spoke easy to deploy and\nsuitable for handling events that naturally happen over the life-cycle of any\nKB deployment. We show that Spoke outperforms competitive baselines by up to\n41% in offline F1 comparisons.", "published": "2019-06-15 15:55:43", "link": "http://arxiv.org/abs/1906.06581v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Context is Key: Grammatical Error Detection with Contextual Word\n  Representations", "abstract": "Grammatical error detection (GED) in non-native writing requires systems to\nidentify a wide range of errors in text written by language learners. Error\ndetection as a purely supervised task can be challenging, as GED datasets are\nlimited in size and the label distributions are highly imbalanced.\nContextualized word representations offer a possible solution, as they can\nefficiently capture compositional information in language and can be optimized\non large amounts of unsupervised data. In this paper, we perform a systematic\ncomparison of ELMo, BERT and Flair embeddings (Peters et al., 2017; Devlin et\nal., 2018; Akbik et al., 2018) on a range of public GED datasets, and propose\nan approach to effectively integrate such representations in current methods,\nachieving a new state of the art on GED. We further analyze the strengths and\nweaknesses of different contextual embeddings for the task at hand, and present\ndetailed analyses of their impact on different types of errors.", "published": "2019-06-15 17:29:06", "link": "http://arxiv.org/abs/1906.06593v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Hop Paragraph Retrieval for Open-Domain Question Answering", "abstract": "This paper is concerned with the task of multi-hop open-domain Question\nAnswering (QA). This task is particularly challenging since it requires the\nsimultaneous performance of textual reasoning and efficient searching. We\npresent a method for retrieving multiple supporting paragraphs, nested amidst a\nlarge knowledge base, which contain the necessary evidence to answer a given\nquestion. Our method iteratively retrieves supporting paragraphs by forming a\njoint vector representation of both a question and a paragraph. The retrieval\nis performed by considering contextualized sentence-level representations of\nthe paragraphs in the knowledge source. Our method achieves state-of-the-art\nperformance over two well-known datasets, SQuAD-Open and HotpotQA, which serve\nas our single- and multi-hop open-domain QA benchmarks, respectively.", "published": "2019-06-15 19:17:10", "link": "http://arxiv.org/abs/1906.06606v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Automatic Acrostic Couplet Generation with Three-Stage Neural Network\n  Pipelines", "abstract": "As one of the quintessence of Chinese traditional culture, couplet\ncompromises two syntactically symmetric clauses equal in length, namely, an\nantecedent and subsequent clause. Moreover, corresponding characters and\nphrases at the same position of the two clauses are paired with each other\nunder certain constraints of semantic and/or syntactic relatedness. Automatic\ncouplet generation is recognized as a challenging problem even in the\nArtificial Intelligence field. In this paper, we comprehensively study on\nautomatic generation of acrostic couplet with the first characters defined by\nusers. The complete couplet generation is mainly divided into three stages,\nthat is, antecedent clause generation pipeline, subsequent clause generation\npipeline and clause re-ranker. To realize semantic and/or syntactic relatedness\nbetween two clauses, attention-based Sequence-to-Sequence (S2S) neural network\nis employed. Moreover, to provide diverse couplet candidates for re-ranking, a\ncluster-based beam search approach is incorporated into the S2S network. Both\nBLEU metrics and human judgments have demonstrated the effectiveness of our\nproposed method. Eventually, a mini-program based on this generation system is\ndeveloped and deployed on Wechat for real users.", "published": "2019-06-15 06:47:16", "link": "http://arxiv.org/abs/1906.09321v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Computational-Hermeneutic Approach for Conceptual Explicitation", "abstract": "We present a computer-supported approach for the logical analysis and\nconceptual explicitation of argumentative discourse. Computational hermeneutics\nharnesses recent progresses in automated reasoning for higher-order logics and\naims at formalizing natural-language argumentative discourse using flexible\ncombinations of expressive non-classical logics. In doing so, it allows us to\nrender explicit the tacit conceptualizations implicit in argumentative\ndiscursive practices. Our approach operates on networks of structured arguments\nand is iterative and two-layered. At one layer we search for logically correct\nformalizations for each of the individual arguments. At the next layer we\nselect among those correct formalizations the ones which honor the argument's\ndialectic role, i.e. attacking or supporting other arguments as intended. We\noperate at these two layers in parallel and continuously rate sentences'\nformalizations by using, primarily, inferential adequacy criteria. An\ninterpretive, logical theory will thus gradually evolve. This theory is\ncomposed of meaning postulates serving as explications for concepts playing a\nrole in the analyzed arguments. Such a recursive, iterative approach to\ninterpretation does justice to the inherent circularity of understanding: the\nwhole is understood compositionally on the basis of its parts, while each part\nis understood only in the context of the whole (hermeneutic circle). We\nsummarily discuss previous work on exemplary applications of human-in-the-loop\ncomputational hermeneutics in metaphysical discourse. We also discuss some of\nthe main challenges involved in fully-automating our approach. By sketching\nsome design ideas and reviewing relevant technologies, we argue for the\ntechnological feasibility of a highly-automated computational hermeneutics.", "published": "2019-06-15 15:57:57", "link": "http://arxiv.org/abs/1906.06582v2", "categories": ["cs.AI", "cs.CL", "cs.LO", "03B60, 03B15, 68T27, 68T30, 68T15", "I.2.3; I.2.4; I.2.0; F.4"], "primary_category": "cs.AI"}
{"title": "Yoga-Veganism: Correlation Mining of Twitter Health Data", "abstract": "Nowadays social media is a huge platform of data. People usually share their\ninterest, thoughts via discussions, tweets, status. It is not possible to go\nthrough all the data manually. We need to mine the data to explore hidden\npatterns or unknown correlations, find out the dominant topic in data and\nunderstand people's interest through the discussions. In this work, we explore\nTwitter data related to health. We extract the popular topics under different\ncategories (e.g. diet, exercise) discussed in Twitter via topic modeling,\nobserve model behavior on new tweets, discover interesting correlation (i.e.\nYoga-Veganism). We evaluate accuracy by comparing with ground truth using\nmanual annotation both for train and test data.", "published": "2019-06-15 20:56:48", "link": "http://arxiv.org/abs/1906.07668v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Syllable-Structured, Contextually-Based Conditionally Generation of\n  Chinese Lyrics", "abstract": "This paper presents a novel, syllable-structured Chinese lyrics generation\nmodel given a piece of original melody. Most previously reported lyrics\ngeneration models fail to include the relationship between lyrics and melody.\nIn this work, we propose to interpret lyrics-melody alignments as syllable\nstructural information and use a multi-channel sequence-to-sequence model with\nconsidering both phrasal structures and semantics. Two different RNN encoders\nare applied, one of which is for encoding syllable structures while the other\nfor semantic encoding with contextual sentences or input keywords. Moreover, a\nlarge Chinese lyrics corpus for model training is leveraged. With automatic and\nhuman evaluations, results demonstrate the effectiveness of our proposed lyrics\ngeneration model. To the best of our knowledge, there is few previous reports\non lyrics generation considering both music and linguistic perspectives.", "published": "2019-06-15 09:09:12", "link": "http://arxiv.org/abs/1906.09322v1", "categories": ["cs.CL", "cs.AI", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Automatic Conditional Generation of Personalized Social Media Short\n  Texts", "abstract": "Automatic text generation has received much attention owing to rapid\ndevelopment of deep neural networks. In general, text generation systems based\non statistical language model will not consider anthropomorphic\ncharacteristics, which results in machine-like generated texts. To fill the\ngap, we propose a conditional language generation model with Big Five\nPersonality (BFP) feature vectors as input context, which writes human-like\nshort texts. The short text generator consists of a layer of long short memory\nnetwork (LSTM), where a BFP feature vector is concatenated as one part of input\nfor each cell. To enable supervised training generation model, a text\nclassification model based convolution neural network (CNN) has been used to\nprepare BFP-tagged Chinese micro-blog corpora. Validated by a BFP linguistic\ncomputational model, our generated Chinese short texts exhibit discriminative\npersonality styles, which are also syntactically correct and semantically\nsmooth with appropriate emoticons. With combination of natural language\ngeneration with psychological linguistics, our proposed BFP-dependent text\ngeneration model can be widely used for individualization in machine\ntranslation, image caption, dialogue generation and so on.", "published": "2019-06-15 09:20:41", "link": "http://arxiv.org/abs/1906.09324v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A New Approach to Real Time Impulsive Sound Detection for Surveillance\n  Applications", "abstract": "Most of the surveillance systems for public safety are solely based on one or\nmore video cameras. These camera systems have some drawbacks such that they\nhave poor performance in adverse weather conditions or during night time.\nTherefore most of the time, some other sensors should accompany to video\ncameras. Although audio surveillance is in its early stage, there has been\nconsiderable amount of work in this area in the last decade. In this paper we\nmake a review of impulsive sound detection algorithms. Sounds from dangerous\nevents such as gunshots, explosions, human screaming can be classified as\nimpulsive sounds, so this paper reviews all impulsive sound detection\nalgorithms along with impulsive noise detection algorithms although they\nprogress in their own path. These dangerous sound events have no other\ndetection means except audio. We try to adapt some algorithms used in impulsive\nnoise detection to the area of impulsive sound detection. Tests show that\nWarped Linear Prediction (WLP) can be used for impulsive sound detection.", "published": "2019-06-15 16:20:25", "link": "http://arxiv.org/abs/1906.06586v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Modeling Consonance and its Relationships with Temperament, Harmony, and\n  Electronic Amplification", "abstract": "After briefly revising the concepts of consonance/dissonance, a respective\nmathematic-computational model is described, based on Helmholtz's consonance\ntheory and also considering the partials intensity. It is then applied to\ncharacterize five scale temperaments, as well as some minor and major triads\nand electronic amplification. In spite of the simplicity of the described\nmodel, a surprising agreement is often observed between the obtained\nconsonances/dissonances and the typically observed properties of scales and\nchords. The representation of temperaments as graphs where links correspond to\nconsonance (or dissonance) is presented and used to compare distinct\ntemperaments, allowing the identification of two main groups of scales. The\ninteresting issue of nonlinearities in electronic music amplification is also\naddressed while considering quadratic distortions, and it is shown that such\nnonlinearities can have drastic effect in changing the original patterns of\nconsonance and dissonance.", "published": "2019-06-15 13:19:38", "link": "http://arxiv.org/abs/1906.06559v1", "categories": ["cs.SD", "cs.CY", "eess.AS", "physics.pop-ph"], "primary_category": "cs.SD"}
{"title": "Audio-Based Music Classification with DenseNet And Data Augmentation", "abstract": "In recent years, deep learning technique has received intense attention owing\nto its great success in image recognition. A tendency of adaption of deep\nlearning in various information processing fields has formed, including music\ninformation retrieval (MIR). In this paper, we conduct a comprehensive study on\nmusic audio classification with improved convolutional neural networks (CNNs).\nTo the best of our knowledge, this the first work to apply Densely Connected\nConvolutional Networks (DenseNet) to music audio tagging, which has been\ndemonstrated to perform better than Residual neural network (ResNet).\nAdditionally, two specific data augmentation approaches of time overlapping and\npitch shifting have been proposed to address the deficiency of labelled data in\nthe MIR. Moreover, an ensemble learning of stacking is employed based on SVM.\nWe believe that the proposed combination of strong representation of DenseNet\nand data augmentation can be adapted to other audio processing tasks.", "published": "2019-06-15 09:16:08", "link": "http://arxiv.org/abs/1906.11620v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
