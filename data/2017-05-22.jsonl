{"title": "W2VLDA: Almost Unsupervised System for Aspect Based Sentiment Analysis", "abstract": "With the increase of online customer opinions in specialised websites and\nsocial networks, the necessity of automatic systems to help to organise and\nclassify customer reviews by domain-specific aspect/categories and sentiment\npolarity is more important than ever. Supervised approaches to Aspect Based\nSentiment Analysis obtain good results for the domain/language their are\ntrained on, but having manually labelled data for training supervised systems\nfor all domains and languages are usually very costly and time consuming. In\nthis work we describe W2VLDA, an almost unsupervised system based on topic\nmodelling, that combined with some other unsupervised methods and a minimal\nconfiguration, performs aspect/category classifiation,\naspect-terms/opinion-words separation and sentiment polarity classification for\nany given domain and language. We evaluate the performance of the aspect and\nsentiment classification in the multilingual SemEval 2016 task 5 (ABSA)\ndataset. We show competitive results for several languages (English, Spanish,\nFrench and Dutch) and domains (hotels, restaurants, electronic-devices).", "published": "2017-05-22 12:01:10", "link": "http://arxiv.org/abs/1705.07687v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Use of Knowledge Graph in Rescoring the N-Best List in Automatic Speech\n  Recognition", "abstract": "With the evolution of neural network based methods, automatic speech\nrecognition (ASR) field has been advanced to a level where building an\napplication with speech interface is a reality. In spite of these advances,\nbuilding a real-time speech recogniser faces several problems such as low\nrecognition accuracy, domain constraint, and out-of-vocabulary words. The low\nrecognition accuracy problem is addressed by improving the acoustic model,\nlanguage model, decoder and by rescoring the N-best list at the output of the\ndecoder. We are considering the N-best list rescoring approach to improve the\nrecognition accuracy. Most of the methods in the literature use the\ngrammatical, lexical, syntactic and semantic connection between the words in a\nrecognised sentence as a feature to rescore. In this paper, we have tried to\nsee the semantic relatedness between the words in a sentence to rescore the\nN-best list. Semantic relatedness is computed using\nTransE~\\cite{bordes2013translating}, a method for low dimensional embedding of\na triple in a knowledge graph. The novelty of the paper is the application of\nsemantic web to automatic speech recognition.", "published": "2017-05-22 21:53:05", "link": "http://arxiv.org/abs/1705.08018v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Human Traits in the Language of Social Media: An Open-Vocabulary\n  Approach", "abstract": "Over the past century, personality theory and research has successfully\nidentified core sets of characteristics that consistently describe and explain\nfundamental differences in the way people think, feel and behave. Such\ncharacteristics were derived through theory, dictionary analyses, and survey\nresearch using explicit self-reports. The availability of social media data\nspanning millions of users now makes it possible to automatically derive\ncharacteristics from language use -- at large scale. Taking advantage of\nlinguistic information available through Facebook, we study the process of\ninferring a new set of potential human traits based on unprompted language use.\nWe subject these new traits to a comprehensive set of evaluations and compare\nthem with a popular five factor model of personality. We find that our\nlanguage-based trait construct is often more generalizable in that it often\npredicts non-questionnaire-based outcomes better than questionnaire-based\ntraits (e.g. entities someone likes, income and intelligence quotient), while\nthe factors remain nearly as stable as traditional factors. Our approach\nsuggests a value in new constructs of personality derived from everyday human\nlanguage use.", "published": "2017-05-22 23:13:02", "link": "http://arxiv.org/abs/1705.08038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ask the Right Questions: Active Question Reformulation with\n  Reinforcement Learning", "abstract": "We frame Question Answering (QA) as a Reinforcement Learning task, an\napproach that we call Active Question Answering. We propose an agent that sits\nbetween the user and a black box QA system and learns to reformulate questions\nto elicit the best possible answers. The agent probes the system with,\npotentially many, natural language reformulations of an initial question and\naggregates the returned evidence to yield the best answer. The reformulation\nsystem is trained end-to-end to maximize answer quality using policy gradient.\nWe evaluate on SearchQA, a dataset of complex questions extracted from\nJeopardy!. The agent outperforms a state-of-the-art base model, playing the\nrole of the environment, and other benchmarks. We also analyze the language\nthat the agent has learned while interacting with the question answering\nsystem. We find that successful question reformulations look quite different\nfrom natural language paraphrases. The agent is able to discover non-trivial\nreformulation strategies that resemble classic information retrieval techniques\nsuch as term re-weighting (tf-idf) and stemming.", "published": "2017-05-22 16:19:21", "link": "http://arxiv.org/abs/1705.07830v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Regularized Framework for Sparse and Structured Neural Attention", "abstract": "Modern neural networks are often augmented with an attention mechanism, which\ntells the network where to focus within the input. We propose in this paper a\nnew framework for sparse and structured attention, building upon a smoothed max\noperator. We show that the gradient of this operator defines a mapping from\nreal values to probabilities, suitable as an attention mechanism. Our framework\nincludes softmax and a slight generalization of the recently-proposed sparsemax\nas special cases. However, we also show how our framework can incorporate\nmodern structured penalties, resulting in more interpretable attention\nmechanisms, that focus on entire segments or groups of an input. We derive\nefficient algorithms to compute the forward and backward passes of our\nattention mechanisms, enabling their use in a neural network trained with\nbackpropagation. To showcase their potential as a drop-in replacement for\nexisting ones, we evaluate our attention mechanisms on three large-scale tasks:\ntextual entailment, machine translation, and sentence summarization. Our\nattention mechanisms improve interpretability without sacrificing performance;\nnotably, on textual entailment and summarization, we outperform the standard\nattention mechanisms based on softmax and sparsemax.", "published": "2017-05-22 13:11:24", "link": "http://arxiv.org/abs/1705.07704v3", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On-the-fly Operation Batching in Dynamic Computation Graphs", "abstract": "Dynamic neural network toolkits such as PyTorch, DyNet, and Chainer offer\nmore flexibility for implementing models that cope with data of varying\ndimensions and structure, relative to toolkits that operate on statically\ndeclared computations (e.g., TensorFlow, CNTK, and Theano). However, existing\ntoolkits - both static and dynamic - require that the developer organize the\ncomputations into the batches necessary for exploiting high-performance\nalgorithms and hardware. This batching task is generally difficult, but it\nbecomes a major hurdle as architectures become complex. In this paper, we\npresent an algorithm, and its implementation in the DyNet toolkit, for\nautomatically batching operations. Developers simply write minibatch\ncomputations as aggregations of single instance computations, and the batching\nalgorithm seamlessly executes them, on the fly, using computationally efficient\nbatched operations. On a variety of tasks, we obtain throughput similar to that\nobtained with manual batches, as well as comparable speedups over\nsingle-instance learning on architectures that are impractical to batch\nmanually.", "published": "2017-05-22 17:04:56", "link": "http://arxiv.org/abs/1705.07860v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "pix2code: Generating Code from a Graphical User Interface Screenshot", "abstract": "Transforming a graphical user interface screenshot created by a designer into\ncomputer code is a typical task conducted by a developer in order to build\ncustomized software, websites, and mobile applications. In this paper, we show\nthat deep learning methods can be leveraged to train a model end-to-end to\nautomatically generate code from a single input image with over 77% of accuracy\nfor three different platforms (i.e. iOS, Android and web-based technologies).", "published": "2017-05-22 19:32:20", "link": "http://arxiv.org/abs/1705.07962v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.NE", "68T45", "I.2.1; I.2.10; I.2.2; I.2.6"], "primary_category": "cs.LG"}
