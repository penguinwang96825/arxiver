{"title": "Enrichment of OntoSenseNet: Adding a Sense-annotated Telugu lexicon", "abstract": "The paper describes the enrichment of OntoSenseNet - a verb-centric lexical\nresource for Indian Languages. This resource contains a newly developed\nTelugu-Telugu dictionary. It is important because native speakers can better\nannotate the senses when both the word and its meaning are in Telugu. Hence\nefforts are made to develop a soft copy of Telugu dictionary. Our resource also\nhas manually annotated gold standard corpus consisting 8483 verbs, 253 adverbs\nand 1673 adjectives. Annotations are done by native speakers according to\ndefined annotation guidelines. In this paper, we provide an overview of the\nannotation procedure and present the validation of our resource through\ninter-annotator agreement. Concepts of sense-class and sense-type are\ndiscussed. Additionally, we discuss the potential of lexical sense-annotated\ncorpora in improving word sense disambiguation (WSD) tasks. Telugu WordNet is\ncrowd-sourced for annotation of individual words in synsets and is compared\nwith the developed sense-annotated lexicon (OntoSenseNet) to examine the\nimprovement. Also, we present a special categorization (spatio-temporal\nclassification) of adjectives.", "published": "2018-04-06 10:17:16", "link": "http://arxiv.org/abs/1804.02186v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chart Parsing Multimodal Grammars", "abstract": "The short note describes the chart parser for multimodal type-logical\ngrammars which has been developed in conjunction with the type-logical treebank\nfor French. The chart parser presents an incomplete but fast implementation of\nproof search for multimodal type-logical grammars using the \"deductive parsing\"\nframework. Proofs found can be transformed to natural deduction proofs.", "published": "2018-04-06 14:11:33", "link": "http://arxiv.org/abs/1804.02286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural models of factuality", "abstract": "We present two neural models for event factuality prediction, which yield\nsignificant performance gains over previous models on three event factuality\ndatasets: FactBank, UW, and MEANTIME. We also present a substantial expansion\nof the It Happened portion of the Universal Decompositional Semantics dataset,\nyielding the largest event factuality dataset to date. We report model results\non this extended factuality dataset as well.", "published": "2018-04-06 22:11:17", "link": "http://arxiv.org/abs/1804.02472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expressive Speech Synthesis via Modeling Expressions with Variational\n  Autoencoder", "abstract": "Recent advances in neural autoregressive models have improve the performance\nof speech synthesis (SS). However, as they lack the ability to model global\ncharacteristics of speech (such as speaker individualities or speaking styles),\nparticularly when these characteristics have not been labeled, making neural\nautoregressive SS systems more expressive is still an open issue. In this\npaper, we propose to combine VoiceLoop, an autoregressive SS model, with\nVariational Autoencoder (VAE). This approach, unlike traditional autoregressive\nSS systems, uses VAE to model the global characteristics explicitly, enabling\nthe expressiveness of the synthesized speech to be controlled in an\nunsupervised manner. Experiments using the VCTK and Blizzard2012 datasets show\nthe VAE helps VoiceLoop to generate higher quality speech and to control the\nexpressions in its synthesized speech by incorporating global characteristics\ninto the speech generating process.", "published": "2018-04-06 05:27:14", "link": "http://arxiv.org/abs/1804.02135v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sequence Training of DNN Acoustic Models With Natural Gradient", "abstract": "Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models.", "published": "2018-04-06 11:05:53", "link": "http://arxiv.org/abs/1804.02204v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Forex trading and Twitter: Spam, bots, and reputation manipulation", "abstract": "Currency trading (Forex) is the largest world market in terms of volume. We\nanalyze trading and tweeting about the EUR-USD currency pair over a period of\nthree years. First, a large number of tweets were manually labeled, and a\nTwitter stance classification model is constructed. The model then classifies\nall the tweets by the trading stance signal: buy, hold, or sell (EUR vs. USD).\nThe Twitter stance is compared to the actual currency rates by applying the\nevent study methodology, well-known in financial economics. It turns out that\nthere are large differences in Twitter stance distribution and potential\ntrading returns between the four groups of Twitter users: trading robots,\nspammers, trading companies, and individual traders. Additionally, we observe\nattempts of reputation manipulation by post festum removal of tweets with poor\npredictions, and deleting/reposting of identical tweets to increase the\nvisibility without tainting one's Twitter timeline.", "published": "2018-04-06 12:36:28", "link": "http://arxiv.org/abs/1804.02233v2", "categories": ["cs.SI", "cs.CL", "cs.CY", "econ.TH"], "primary_category": "cs.SI"}
{"title": "Compositional Obverter Communication Learning From Raw Visual Input", "abstract": "One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.", "published": "2018-04-06 16:12:51", "link": "http://arxiv.org/abs/1804.02341v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Understanding Actors and Evaluating Personae with Gaussian Embeddings", "abstract": "Understanding narrative content has become an increasingly popular topic.\nNonetheless, research on identifying common types of narrative characters, or\npersonae, is impeded by the lack of automatic and broad-coverage evaluation\nmethods. We argue that computationally modeling actors provides benefits,\nincluding novel evaluation mechanisms for personae. Specifically, we propose\ntwo actor-modeling tasks, cast prediction and versatility ranking, which can\ncapture complementary aspects of the relation between actors and the characters\nthey portray. For an actor model, we present a technique for embedding actors,\nmovies, character roles, genres, and descriptive keywords as Gaussian\ndistributions and translation vectors, where the Gaussian variance corresponds\nto actors' versatility. Empirical results indicate that (1) the technique\nconsiderably outperforms TransE (Bordes et al. 2013) and ablation baselines and\n(2) automatically identified persona topics (Bamman, O'Connor, and Smith 2013)\nyield statistically significant improvements in both tasks, whereas simplistic\npersona descriptors including age and gender perform inconsistently, validating\nprior research.", "published": "2018-04-06 17:44:23", "link": "http://arxiv.org/abs/1804.04164v2", "categories": ["cs.CY", "cs.CL", "cs.MM", "cs.SI"], "primary_category": "cs.CY"}
{"title": "On the Robustness of Speech Emotion Recognition for Human-Robot\n  Interaction with Deep Neural Networks", "abstract": "Speech emotion recognition (SER) is an important aspect of effective\nhuman-robot collaboration and received a lot of attention from the research\ncommunity. For example, many neural network-based architectures were proposed\nrecently and pushed the performance to a new level. However, the applicability\nof such neural SER models trained only on in-domain data to noisy conditions is\ncurrently under-researched. In this work, we evaluate the robustness of\nstate-of-the-art neural acoustic emotion recognition models in human-robot\ninteraction scenarios. We hypothesize that a robot's ego noise, room\nconditions, and various acoustic events that can occur in a home environment\ncan significantly affect the performance of a model. We conduct several\nexperiments on the iCub robot platform and propose several novel ways to reduce\nthe gap between the model's performance during training and testing in\nreal-world conditions. Furthermore, we observe large improvements in the model\nperformance on the robot and demonstrate the necessity of introducing several\ndata augmentation techniques like overlaying background noise and loudness\nvariations to improve the robustness of the neural approaches.", "published": "2018-04-06 09:03:29", "link": "http://arxiv.org/abs/1804.02173v1", "categories": ["cs.RO", "cs.CL", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
{"title": "Does k Matter? k-NN Hubness Analysis for Kernel Additive Modelling Vocal\n  Separation", "abstract": "Kernel Additive Modelling (KAM) is a framework for source separation aiming\nto explicitly model inherent properties of sound sources to help with their\nidentification and separation. KAM separates a given source by applying robust\nstatistics on the selection of time-frequency bins obtained through a\nsource-specific kernel, typically the k-NN function. Even though the parameter\nk appears to be key for a successful separation, little discussion on its\ninfluence or optimisation can be found in the literature. Here we propose a\nnovel method, based on graph theory statistics, to automatically optimise $k$\nin a vocal separation task. We introduce the k-NN hubness as an indicator to\nfind a tailored k at a low computational cost. Subsequently, we evaluate our\nmethod in comparison to the common approach to choose k. We further discuss the\ninfluence and importance of this parameter with illuminating results.", "published": "2018-04-06 15:33:29", "link": "http://arxiv.org/abs/1804.02325v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
