{"title": "Using Context Events in Neural Network Models for Event Temporal Status\n  Identification", "abstract": "Focusing on the task of identifying event temporal status, we find that\nevents directly or indirectly governing the target event in a dependency tree\nare most important contexts. Therefore, we extract dependency chains containing\ncontext events and use them as input in neural network models, which\nconsistently outperform previous models using local context words as input.\nVisualization verifies that the dependency chain representation can effectively\ncapture the context events which are closely related to the target event and\nplay key roles in predicting event temporal status.", "published": "2017-10-12 02:39:45", "link": "http://arxiv.org/abs/1710.04344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the Design Issues of Local Models for Japanese\n  Predicate-Argument Structure Analysis", "abstract": "The research trend in Japanese predicate-argument structure (PAS) analysis is\nshifting from pointwise prediction models with local features to global models\ndesigned to search for globally optimal solutions. However, the existing global\nmodels tend to employ only relatively simple local features; therefore, the\noverall performance gains are rather limited. The importance of designing a\nlocal model is demonstrated in this study by showing that the performance of a\nsophisticated local model can be considerably improved with recent feature\nembedding methods and a feature combination learning based on a neural network,\noutperforming the state-of-the-art global models in $F_1$ on a common benchmark\ndataset.", "published": "2017-10-12 10:36:41", "link": "http://arxiv.org/abs/1710.04437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Convolutional Attention-based Seq2Seq Neural Network for End-to-End ASR", "abstract": "This thesis introduces the sequence to sequence model with Luong's attention\nmechanism for end-to-end ASR. It also describes various neural network\nalgorithms including Batch normalization, Dropout and Residual network which\nconstitute the convolutional attention-based seq2seq neural network. Finally\nthe proposed model proved its effectiveness for speech recognition achieving\n15.8% phoneme error rate on TIMIT dataset.", "published": "2017-10-12 13:40:43", "link": "http://arxiv.org/abs/1710.04515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Auto Analysis of Customer Feedback using CNN and GRU Network", "abstract": "Analyzing customer feedback is the best way to channelize the data into new\nmarketing strategies that benefit entrepreneurs as well as customers. Therefore\nan automated system which can analyze the customer behavior is in great demand.\nUsers may write feedbacks in any language, and hence mining appropriate\ninformation often becomes intractable. Especially in a traditional\nfeature-based supervised model, it is difficult to build a generic system as\none has to understand the concerned language for finding the relevant features.\nIn order to overcome this, we propose deep Convolutional Neural Network (CNN)\nand Recurrent Neural Network (RNN) based approaches that do not require\nhandcrafting of features. We evaluate these techniques for analyzing customer\nfeedback sentences in four languages, namely English, French, Japanese and\nSpanish. Our empirical analysis shows that our models perform well in all the\nfour languages on the setups of IJCNLP Shared Task on Customer Feedback\nAnalysis. Our model achieved the second rank in French, with an accuracy of\n71.75% and third ranks for all the other languages.", "published": "2017-10-12 16:33:01", "link": "http://arxiv.org/abs/1710.04600v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DisSent: Sentence Representation Learning from Explicit Discourse\n  Relations", "abstract": "Learning effective representations of sentences is one of the core missions\nof natural language understanding. Existing models either train on a vast\namount of text, or require costly, manually curated sentence relation datasets.\nWe show that with dependency parsing and rule-based rubrics, we can curate a\nhigh quality sentence relation task by leveraging explicit discourse relations.\nWe show that our curated dataset provides an excellent signal for learning\nvector representations of sentence meaning, representing relations that can\nonly be determined when the meanings of two sentences are combined. We\ndemonstrate that the automatically curated corpus allows a bidirectional LSTM\nsentence encoder to yield high quality sentence embeddings and can serve as a\nsupervised fine-tuning dataset for larger models such as BERT. Our fixed\nsentence embeddings achieve high performance on a variety of transfer tasks,\nincluding SentEval, and we achieve state-of-the-art results on Penn Discourse\nTreebank's implicit relation prediction task.", "published": "2017-10-12 00:56:13", "link": "http://arxiv.org/abs/1710.04334v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emergent Translation in Multi-Agent Communication", "abstract": "While most machine translation systems to date are trained on large parallel\ncorpora, humans learn language in a different way: by being grounded in an\nenvironment and interacting with other humans. In this work, we propose a\ncommunication game where two agents, native speakers of their own respective\nlanguages, jointly learn to solve a visual referential task. We find that the\nability to understand and translate a foreign language emerges as a means to\nachieve shared goals. The emergent translation is interactive and multimodal,\nand crucially does not require parallel corpora, but only monolingual,\nindependent text and corresponding images. Our proposed translation model\nachieves this by grounding the source and target languages into a shared visual\nmodality, and outperforms several baselines on both word-level and\nsentence-level translation tasks. Furthermore, we show that agents in a\nmultilingual community learn to translate better and faster than in a bilingual\ncommunication setting.", "published": "2017-10-12 00:37:27", "link": "http://arxiv.org/abs/1710.06922v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adapting general-purpose speech recognition engine output for\n  domain-specific natural language question answering", "abstract": "Speech-based natural language question-answering interfaces to enterprise\nsystems are gaining a lot of attention. General-purpose speech engines can be\nintegrated with NLP systems to provide such interfaces. Usually,\ngeneral-purpose speech engines are trained on large `general' corpus. However,\nwhen such engines are used for specific domains, they may not recognize\ndomain-specific words well, and may produce erroneous output. Further, the\naccent and the environmental conditions in which the speaker speaks a sentence\nmay induce the speech engine to inaccurately recognize certain words. The\nsubsequent natural language question-answering does not produce the requisite\nresults as the question does not accurately represent what the speaker\nintended. Thus, the speech engine's output may need to be adapted for a domain\nbefore further natural language processing is carried out. We present two\nmechanisms for such an adaptation, one based on evolutionary development and\nthe other based on machine learning, and show how we can repair the\nspeech-output to make the subsequent natural language question-answering\nbetter.", "published": "2017-10-12 12:18:16", "link": "http://arxiv.org/abs/1710.06923v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
