{"title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "abstract": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "published": "2025-06-30 17:58:13", "link": "http://arxiv.org/abs/2506.24119v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models", "abstract": "Identifying parallel passages in biblical Hebrew is foundational in biblical\nscholarship for uncovering intertextual relationships. Traditional methods rely\non manual comparison, which is labor-intensive and prone to human error. This\nstudy evaluates the potential of pre-trained transformer-based language models,\nincluding E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in\nthe Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings\nand Chronicles, I assessed each model's capability to generate word embeddings\nthat delineate parallel from non-parallel passages. Utilizing cosine similarity\nand Wasserstein Distance measures, I found that E5 and AlephBERT show\nsignificant promise, with E5 excelling in parallel detection and AlephBERT\ndemonstrating stronger non-parallel differentiation. These findings indicate\nthat pre-trained models can enhance the efficiency and accuracy of detecting\nintertextual parallels in ancient texts, suggesting broader applications for\nancient language studies.", "published": "2025-06-30 17:57:27", "link": "http://arxiv.org/abs/2506.24117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Predictive Power of Representation Dispersion in Language Models", "abstract": "We show that a language model's ability to predict text is tightly linked to\nthe breadth of its embedding space: models that spread their contextual\nrepresentations more widely tend to achieve lower perplexity. Concretely, we\nfind that representation dispersion - the average pairwise cosine distance\namong hidden vectors - strongly and negatively correlates with perplexity\nacross diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,\nnews, scientific abstracts). Beyond illustrating this link, we show how\ndispersion can be leveraged for a range of practical tasks without requiring\nlabeled data. First, measuring dispersion on unlabeled text allows us to\npredict downstream accuracy in new domains, offering a data-efficient tool for\nmodel selection. Next, we find that identifying layers with higher dispersion\npinpoints the best representations for retrieval-based methods such as kNN-LM,\nbypassing exhaustive layer-by-layer searches. Finally, we integrate a simple\npush-away objective into training, which increases dispersion in both\nsingle-domain and cross-domain scenarios and directly improves perplexity in\neach.", "published": "2025-06-30 17:53:50", "link": "http://arxiv.org/abs/2506.24106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MotionGPT3: Human Motion as a Second Modality", "abstract": "Though recent advances in multimodal models have demonstrated strong\ncapabilities and opportunities in unified understanding and generation, the\ndevelopment of unified motion-language models remains underexplored. To enable\nsuch models with high-fidelity human motion, two core challenges must be\naddressed. The first is the reconstruction gap between the continuous motion\nmodality and discrete representation in an autoregressive manner, and the\nsecond is the degradation of language intelligence during unified training.\nInspired by the mixture of experts, we propose MotionGPT3, a bimodal\nmotion-language model that treats human motion as a second modality, decoupling\nmotion modeling via separate model parameters and enabling both effective\ncross-modal interaction and efficient multimodal scaling training. To preserve\nlanguage intelligence, the text branch retains the original structure and\nparameters of the pretrained language model, while a new motion branch is\nintegrated via a shared attention mechanism, enabling bidirectional information\nflow between two modalities. We first employ a motion Variational Autoencoder\n(VAE) to encode raw human motion into latent representations. Based on this\ncontinuous latent space, the motion branch predicts motion latents directly\nfrom intermediate hidden states using a diffusion head, bypassing discrete\ntokenization. Extensive experiments show that our approach achieves competitive\nperformance on both motion understanding and generation tasks while preserving\nstrong language capabilities, establishing a unified bimodal motion diffusion\nframework within an autoregressive manner.", "published": "2025-06-30 17:42:22", "link": "http://arxiv.org/abs/2506.24086v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "abstract": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "published": "2025-06-30 17:21:08", "link": "http://arxiv.org/abs/2506.24068v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models", "abstract": "We introduce logit-gap steering, a fast jailbreak framework that casts the\nrefusal-affirmation gap of RLHF-aligned language models as a single pass over\nthe vocabulary. A forward-computable score blends gap reduction with\nlightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\"\nsweep to complete in under a second and return a short suffix--two orders of\nmagnitude fewer model calls than beam or gradient attacks. The same suffix\ngeneralises to unseen prompts and scales from 0.5 B to 70 B checkpoints,\nlifting one-shot attack success from baseline levels to 80-100% while\npreserving topical coherence. Beyond efficiency, these suffixes expose\nsentence-boundary reward cliffs and other alignment artefacts, offering a\nlightweight probe into how safety tuning reshapes internal representations.", "published": "2025-06-30 17:01:18", "link": "http://arxiv.org/abs/2506.24056v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Ella: Embodied Social Agents with Lifelong Memory", "abstract": "We introduce Ella, an embodied social agent capable of lifelong learning\nwithin a community in a 3D open world, where agents accumulate experiences and\nacquire knowledge through everyday visual observations and social interactions.\nAt the core of Ella's capabilities is a structured, long-term multimodal memory\nsystem that stores, updates, and retrieves information effectively. It consists\nof a name-centric semantic memory for organizing acquired knowledge and a\nspatiotemporal episodic memory for capturing multimodal experiences. By\nintegrating this lifelong memory system with foundation models, Ella retrieves\nrelevant information for decision-making, plans daily activities, builds social\nrelationships, and evolves autonomously while coexisting with other intelligent\nbeings in the open world. We conduct capability-oriented evaluations in a\ndynamic 3D open world where 15 agents engage in social activities for days and\nare assessed with a suite of unseen controlled evaluations. Experimental\nresults show that Ella can influence, lead, and cooperate with other agents\nwell to achieve goals, showcasing its ability to learn effectively through\nobservation and social interaction. Our findings highlight the transformative\npotential of combining structured memory systems with foundation models for\nadvancing embodied intelligence. More videos can be found at\nhttps://umass-embodied-agi.github.io/Ella/.", "published": "2025-06-30 16:22:51", "link": "http://arxiv.org/abs/2506.24019v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations", "abstract": "Recent advances in large language models and vision-language models have led\nto growing interest in explainable evaluation metrics for image captioning.\nHowever, these metrics generate explanations without standardized criteria, and\nthe overall quality of the generated explanations remains unverified. In this\npaper, we propose EXPERT, a reference-free evaluation metric that provides\nstructured explanations based on three fundamental criteria: fluency,\nrelevance, and descriptiveness. By constructing large-scale datasets of\nhigh-quality structured explanations, we develop a two-stage evaluation\ntemplate to effectively supervise a vision-language model for both scoring and\nexplanation generation. EXPERT achieves state-of-the-art results on benchmark\ndatasets while providing significantly higher-quality explanations than\nexisting metrics, as validated through comprehensive human evaluation. Our code\nand datasets are available at https://github.com/hjkim811/EXPERT.", "published": "2025-06-30 16:20:51", "link": "http://arxiv.org/abs/2506.24016v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective", "abstract": "The progress of Large Language Models (LLMs) like ChatGPT raises the question\nof how they can be integrated into education. One hope is that they can support\nmathematics learning, including word-problem solving. Since LLMs can handle\ntextual input with ease, they appear well-suited for solving mathematical word\nproblems. Yet their real competence, whether they can make sense of the\nreal-world context, and the implications for classrooms remain unclear. We\nconducted a scoping review from a mathematics-education perspective, including\nthree parts: a technical overview, a systematic review of word problems used in\nresearch, and a state-of-the-art empirical evaluation of LLMs on mathematical\nword problems. First, in the technical overview, we contrast the\nconceptualization of word problems and their solution processes between LLMs\nand students. In computer-science research this is typically labeled\nmathematical reasoning, a term that does not align with usage in mathematics\neducation. Second, our literature review of 213 studies shows that the most\npopular word-problem corpora are dominated by s-problems, which do not require\na consideration of realities of their real-world context. Finally, our\nevaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems\nshows that most recent LLMs solve these s-problems with near-perfect accuracy,\nincluding a perfect score on 20 problems from PISA. LLMs still showed\nweaknesses in tackling problems where the real-world context is problematic or\nnon-sensical. In sum, we argue based on all three aspects that LLMs have\nmastered a superficial solution process but do not make sense of word problems,\nwhich potentially limits their value as instructional tools in mathematics\nclassrooms.", "published": "2025-06-30 16:10:42", "link": "http://arxiv.org/abs/2506.24006v1", "categories": ["cs.CL", "math.HO"], "primary_category": "cs.CL"}
{"title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning", "abstract": "Congenital heart disease (CHD) presents complex, lifelong challenges often\nunderrepresented in traditional clinical metrics. While unstructured narratives\noffer rich insights into patient and caregiver experiences, manual thematic\nanalysis (TA) remains labor-intensive and unscalable. We propose a fully\nautomated large language model (LLM) pipeline that performs end-to-end TA on\nclinical narratives, which eliminates the need for manual coding or full\ntranscript review. Our system employs a novel multi-agent framework, where\nspecialized LLM agents assume roles to enhance theme quality and alignment with\nhuman analysis. To further improve thematic relevance, we optionally integrate\nreinforcement learning from human feedback (RLHF). This supports scalable,\npatient-centered analysis of large qualitative datasets and allows LLMs to be\nfine-tuned for specific clinical contexts.", "published": "2025-06-30 16:02:28", "link": "http://arxiv.org/abs/2506.23998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Understanding of Scientific Language", "abstract": "Scientific information expresses human understanding of nature. This\nknowledge is largely disseminated in different forms of text, including\nscientific papers, news articles, and discourse among people on social media.\nWhile important for accelerating our pursuit of knowledge, not all scientific\ntext is faithful to the underlying science. As the volume of this text has\nburgeoned online in recent years, it has become a problem of societal\nimportance to be able to identify the faithfulness of a given piece of\nscientific text automatically. This thesis is concerned with the cultivation of\ndatasets, methods, and tools for machine understanding of scientific language,\nin order to analyze and understand science communication at scale. To arrive at\nthis, I present several contributions in three areas of natural language\nprocessing and machine learning: automatic fact checking, learning with limited\ndata, and scientific text processing. These contributions include new methods\nand resources for identifying check-worthy claims, adversarial claim\ngeneration, multi-source domain adaptation, learning from crowd-sourced labels,\ncite-worthiness detection, zero-shot scientific fact checking, detecting\nexaggerated scientific claims, and modeling degrees of information change in\nscience communication. Critically, I demonstrate how the research outputs of\nthis thesis are useful for effectively learning from limited amounts of\nscientific text in order to identify misinformative scientific statements and\ngenerate new insights into the science communication process", "published": "2025-06-30 15:55:10", "link": "http://arxiv.org/abs/2506.23990v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation", "abstract": "Conducting supervised fine-tuning and preference fine-tuning on large\nlanguage models (LLMs) requires high-quality datasets to improve their ability\nto follow instructions and align with human preferences and values. However,\nconstructing such datasets is resource-intensive, and most available datasets\nfor supervised and preference fine-tuning are in English. To address these\nchallenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided\n\\underline{\\textbf{P}}reference Data Generation (TaP) framework, which\nfacilitates automated and scalable construction of preference datasets across\nvarious languages. TaP is grounded in a structured taxonomy that allows\nfine-grained control over dataset composition, thereby ensuring both diversity\nand comprehensive coverage. We employ TaP-generated datasets to perform\nsupervised and preference fine-tuning on various LLMs. Experimental results\ndemonstrate that LLMs trained on TaP-generated datasets outperform those\ntrained on existing open-source datasets. Remarkably, LLMs trained on\nTaP-generated datasets surpass the performance of those trained on an\nopen-source dataset that is 180 times larger.", "published": "2025-06-30 15:45:28", "link": "http://arxiv.org/abs/2506.23979v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Agents Are the Antidote to Walled Gardens", "abstract": "While the Internet's core infrastructure was designed to be open and\nuniversal, today's application layer is dominated by closed, proprietary\nplatforms. Open and interoperable APIs require significant investment, and\nmarket leaders have little incentive to enable data exchange that could erode\ntheir user lock-in. We argue that LLM-based agents fundamentally disrupt this\nstatus quo. Agents can automatically translate between data formats and\ninteract with interfaces designed for humans: this makes interoperability\ndramatically cheaper and effectively unavoidable. We name this shift universal\ninteroperability: the ability for any two digital services to exchange data\nseamlessly using AI-mediated adapters. Universal interoperability undermines\nmonopolistic behaviours and promotes data portability. However, it can also\nlead to new security risks and technical debt. Our position is that the ML\ncommunity should embrace this development while building the appropriate\nframeworks to mitigate the downsides. By acting now, we can harness AI to\nrestore user freedom and competitive markets without sacrificing security.", "published": "2025-06-30 15:45:17", "link": "http://arxiv.org/abs/2506.23978v1", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.SI", "68T50, 68M10, 91B26", "I.2.11; I.2.7; H.4.5"], "primary_category": "cs.LG"}
{"title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders", "abstract": "Sparse Autoencoders (SAEs) have been successfully used to probe Large\nLanguage Models (LLMs) and extract interpretable concepts from their internal\nrepresentations. These concepts are linear combinations of neuron activations\nthat correspond to human-interpretable features. In this paper, we investigate\nthe effectiveness of SAE-based explainability approaches for sentence\nclassification, a domain where such methods have not been extensively explored.\nWe present a novel SAE-based architecture tailored for text classification,\nleveraging a specialized classifier head and incorporating an activation rate\nsparsity loss. We benchmark this architecture against established methods such\nas ConceptShap, Independent Component Analysis, and other SAE-based concept\nextraction techniques. Our evaluation covers two classification benchmarks and\nfour fine-tuned LLMs from the Pythia family. We further enrich our analysis\nwith two novel metrics for measuring the precision of concept-based\nexplanations, using an external sentence encoder. Our empirical results show\nthat our architecture improves both the causality and interpretability of the\nextracted features.", "published": "2025-06-30 15:18:50", "link": "http://arxiv.org/abs/2506.23951v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "abstract": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.", "published": "2025-06-30 15:07:41", "link": "http://arxiv.org/abs/2506.23940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages", "abstract": "The rapid expansion of social media leads to a marked increase in hate\nspeech, which threatens personal lives and results in numerous hate crimes.\nDetecting hate speech presents several challenges: diverse dialects, frequent\ncode-mixing, and the prevalence of misspelled words in user-generated content\non social media platforms. Recent progress in hate speech detection is\ntypically concentrated on high-resource languages. However, low-resource\nlanguages still face significant challenges due to the lack of large-scale,\nhigh-quality datasets. This paper investigates how we can overcome this\nlimitation via prompt engineering on large language models (LLMs) focusing on\nlow-resource Bengali language. We investigate six prompting strategies -\nzero-shot prompting, refusal suppression, flattering the classifier, multi-shot\nprompting, role prompting, and finally our innovative metaphor prompting to\ndetect hate speech effectively in low-resource languages. We pioneer the\nmetaphor prompting to circumvent the built-in safety mechanisms of LLMs that\nmarks a significant departure from existing jailbreaking methods. We\ninvestigate all six different prompting strategies on the Llama2-7B model and\ncompare the results extensively with three pre-trained word embeddings - GloVe,\nWord2Vec, and FastText for three different deep learning models - multilayer\nperceptron (MLP), convolutional neural network (CNN), and bidirectional gated\nrecurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in\nthe low-resource Bengali language, we also evaluate it in another low-resource\nlanguage - Hindi, and two high-resource languages - English and German. The\nperformance of all prompting techniques is evaluated using the F1 score, and\nenvironmental impact factor (IF), which measures CO$_2$ emissions, electricity\nusage, and computational time.", "published": "2025-06-30 14:59:25", "link": "http://arxiv.org/abs/2506.23930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies", "abstract": "Large Language Models (LLMs) have shown significant progress on various\nmultilingual benchmarks and are increasingly used to generate and evaluate text\nin non-English languages. However, while they may produce fluent outputs, it\nremains unclear to what extent these models truly grasp the underlying\nlinguistic complexity of those languages, particularly in morphology. To\ninvestigate this, we introduce IMPACT, a synthetically generated evaluation\nframework focused on inflectional morphology, which we publicly release,\ndesigned to evaluate LLM performance across five morphologically rich\nlanguages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes\nunit-test-style cases covering both shared and language-specific phenomena,\nfrom basic verb inflections (e.g., tense, number, gender) to unique features\nlike Arabic's reverse gender agreement and vowel harmony in Finnish and\nTurkish. We assess eight multilingual LLMs that, despite strong English\nperformance, struggle with other languages and uncommon morphological patterns,\nespecially when judging ungrammatical examples. We also show that Chain of\nThought and Thinking Models can degrade performance. Our work exposes gaps in\nLLMs' handling of linguistic complexity, pointing to clear room for\nimprovement. To support further research, we publicly release the IMPACT\nframework.", "published": "2025-06-30 14:58:23", "link": "http://arxiv.org/abs/2506.23929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Trilemma of Truth in Large Language Models", "abstract": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge.", "published": "2025-06-30 14:49:28", "link": "http://arxiv.org/abs/2506.23921v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting", "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their problem-solving capabilities. However, these models still\nstruggle when faced with complex multi-step reasoning tasks. In this paper, we\npropose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,\na novel approach designed to enhance multi-step mathematical reasoning in LLMs\nby integrating techniques such as Chain of Thought (CoT), Self-Reflection, and\nAuto-Prompting. Unlike traditional static prompting methods, MAPS employs an\niterative refinement process. Initially, the model generates a solution using\nCoT prompting. When errors are detected, an adaptive self-reflection mechanism\nidentifies and analyzes them, generating tailored prompts to guide corrections.\nThese dynamically adjusted prompts enable the model to iteratively refine its\nreasoning. Experiments on four well-established benchmarks across multiple LLMs\nshow that MAPS significantly outperforms standard CoT and achieves competitive\nresults with reasoning-optimized models. In addition, MAPS enables\ngeneral-purpose LLMs to reach performance levels comparable to specialized\nreasoning models. While deeper reflection layers improve accuracy, they also\nincrease token usage and costs. To balance this trade-off, MAPS strategically\nlimits reflection depth, ensuring an optimal balance between cost and reasoning\nperformance.", "published": "2025-06-30 14:18:35", "link": "http://arxiv.org/abs/2506.23888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It", "abstract": "We conduct a systematic audit of three widely used reasoning benchmarks,\nSocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark\nitems and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and\nLLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic\nissues in benchmark design (e.g., duplicated items, ambiguous wording, and\nimplausible answers), as well as scoring procedures that prioritize output form\nover reasoning process. Through systematic human annotation and re-evaluation\non cleaned benchmark subsets, we find that model scores often improve not due\nto due to erratic surface wording variations and not to improved reasoning.\nInfact, further analyses show that model performance is highly sensitive to\nminor input variations such as context availability and phrasing, revealing\nthat high scores may reflect alignment with format-specific cues rather than\nconsistent inference based on the input. These findings challenge the validity\nof current benchmark-based claims about reasoning in LLMs, and highlight the\nneed for evaluation protocols that assess reasoning as a process of drawing\ninference from available information, rather than as static output selection.\nWe release audited data and evaluation tools to support more interpretable and\ndiagnostic assessments of model reasoning.", "published": "2025-06-30 13:57:28", "link": "http://arxiv.org/abs/2506.23864v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts", "abstract": "While sparse autoencoders (SAEs) have generated significant excitement, a\nseries of negative results have added to skepticism about their usefulness.\nHere, we establish a conceptual distinction that reconciles competing\nnarratives surrounding SAEs. We argue that while SAEs may be less effective for\nacting on known concepts, SAEs are powerful tools for discovering unknown\nconcepts. This distinction cleanly separates existing negative and positive\nresults, and suggests several classes of SAE applications. Specifically, we\noutline use cases for SAEs in (i) ML interpretability, explainability,\nfairness, auditing, and safety, and (ii) social and health sciences.", "published": "2025-06-30 13:35:56", "link": "http://arxiv.org/abs/2506.23845v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model", "abstract": "Large Reasoning Models (LRMs) excel at solving complex problems but face an\noverthinking dilemma. When handling simple tasks, they often produce verbose\nresponses overloaded with thinking tokens (e.g., wait, however). These tokens\ntrigger unnecessary high-level reasoning behaviors like reflection and\nbacktracking, reducing efficiency. In this work, our pilot study reveals that\nthese thinking-token-induced behaviors are not essential for effective\nproblem-solving and may even hinder correct reasoning within constrained token\nbudgets. We identify this phenomenon as the thinking trap. To mitigate this\nissue, we propose Dual Policy Preference Optimization (DuP-PO), a novel\nalgorithm featuring: (1) A rollout sampling strategy that guarantees balanced\nexposure to responses with and without thinking tokens; (2) A fine-grained\nadvantage control technique to dynamically regulate the prediction of target\ntokens; (3) A policy shaping method ensuring stable gradient contributions from\nthinking tokens. Experimental results on five popular math reasoning benchmarks\nshow that DuP-PO performs well on the popular LRM, which significantly improves\ntheir token efficiency during reasoning, while achieving superior performance\nof the base model.", "published": "2025-06-30 13:30:33", "link": "http://arxiv.org/abs/2506.23840v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "abstract": "Positional bias in binary question answering occurs when a model\nsystematically favors one choice over another based solely on the ordering of\npresented options. In this study, we quantify and analyze positional bias\nacross five large language models under varying degrees of answer uncertainty.\nWe re-adapted the SQuAD-it dataset by adding an extra incorrect answer option\nand then created multiple versions with progressively less context and more\nout-of-context answers, yielding datasets that range from low to high\nuncertainty. Additionally, we evaluate two naturally higher-uncertainty\nbenchmarks: (1) WebGPT - question pairs with unequal human-assigned quality\nscores, and (2) Winning Arguments - where models predict the more persuasive\nargument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order\nof the \"correct\" (or higher-quality/persuasive) option is systematically\nflipped (first placed in position 1, then in position 2) to compute both\nPreference Fairness and Position Consistency. We observe that positional bias\nis nearly absent under low-uncertainty conditions, but grows exponentially when\nit becomes doubtful to decide which option is correct.", "published": "2025-06-30 11:30:23", "link": "http://arxiv.org/abs/2506.23743v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data", "abstract": "Large language models (LLMs) have shown remarkable performance on various\ntasks, but existing evaluation benchmarks are often static and insufficient to\nfully assess their robustness and generalization in realistic scenarios. Prior\nwork using evolutionary or adversarial data augmentation has improved\nevaluation diversity but lacks systematic control over perturbation types and\nmulti-step complexity, limiting comprehensive robustness analysis. To address\nthese gaps, we propose AutoEvoEval, an evolution-based evaluation framework for\nclose-ended tasks such as multi-choice question answering. AutoEvoEval\nintroduces 22 interpretable atomic evolution operations and supports\nmulti-round compositions, enabling controlled generation of diverse,\nchallenging, and realistic test samples. We conduct extensive experiments\naddressing four research questions on a broad set of open- and closed-source\nLLMs. Our results show that atomic operations cause an average accuracy drop of\n7.283\\%, with structure-disrupting or misleading semantic edits causing the\nlargest declines. Model sensitivities vary significantly for the same\nperturbation, and combining multiple evolution steps amplifies adversarial\neffects by up to 52.932\\%. These findings suggest current benchmarks may\noverestimate true model generalization and emphasize the need for\nevolution-aware robustness evaluation. Code and resources are available at:\nhttps://github.com/SYSUSELab/AutoEvoEval.", "published": "2025-06-30 11:18:56", "link": "http://arxiv.org/abs/2506.23735v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization", "abstract": "The increasing volume of video content in educational, professional, and\nsocial domains necessitates effective summarization techniques that go beyond\ntraditional unimodal approaches. This paper proposes a behaviour-aware\nmultimodal video summarization framework that integrates textual, audio, and\nvisual cues to generate timestamp-aligned summaries. By extracting prosodic\nfeatures, textual cues and visual indicators, the framework identifies\nsemantically and emotionally important moments. A key contribution is the\nidentification of bonus words, which are terms emphasized across multiple\nmodalities and used to improve the semantic relevance and expressive clarity of\nthe summaries. The approach is evaluated against pseudo-ground truth (pGT)\nsummaries generated using LLM-based extractive method. Experimental results\ndemonstrate significant improvements over traditional extractive method, such\nas the Edmundson method, in both text and video-based evaluation metrics.\nText-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore\nfrom 0.9152 to 0.9536, while in video-based evaluation, our proposed framework\nimproves F1-Score by almost 23%. The findings underscore the potential of\nmultimodal integration in producing comprehensive and behaviourally informed\nvideo summaries.", "published": "2025-06-30 10:41:33", "link": "http://arxiv.org/abs/2506.23714v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "abstract": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "published": "2025-06-30 10:29:42", "link": "http://arxiv.org/abs/2506.23706v1", "categories": ["cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "abstract": "Current speech language models exceed the size and latency constraints of\nmany deployment environments. We build compact, expressive speech generation\nmodels through layer-aligned distillation, matching hidden states, attention\nmaps, and softened logits to compress large multimodal transformers by 3x with\nminimal loss in performance. We introduce TinyWave, a family of 2B-parameter\nmodels for speech-to-speech and interleaved speech-text generation, trained on\n50,000 hours of public audio. TinyWave supports (i) speech-only generation\nusing phonetic or expressive tokens and (ii) mixed speech-text continuations.\nEvaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity\npoints of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%\nof the teacher's performance, outperforming size-matched baselines. These\nmodels are optimized for deployment on commodity hardware, enabling\napplications in real-time conversational agents, assistive technologies, and\nlow-resource environments. We release models, training code, and evaluation\nscripts to support reproducible research on compact, expressive speech\ngeneration.", "published": "2025-06-30 09:47:37", "link": "http://arxiv.org/abs/2506.23670v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "L0: Reinforcement Learning to Become General Agents", "abstract": "Training large language models (LLMs) to act as autonomous agents for\nmulti-turn, long-horizon tasks remains significant challenges in scalability\nand training efficiency. To address this, we introduce L-Zero (L0), a scalable,\nend-to-end training pipeline for general-purpose agents. Featuring a low-cost,\nextensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier\nfor applying reinforcement learning in complex environments. We also introduce\nNB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\"\nfashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality\nquestion-answering benchmarks. Our experiments demonstrate that a base model\ncan develop robust problem-solving skills using solely Reinforcement Learning\nwith Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method\nboosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41\n%. We have open-sourced the entire L0 system, including our L0 series models,\nthe NB-Agent, a complete training pipeline, and the corresponding training\nrecipes on (https://github.com/cmriat/l0).", "published": "2025-06-30 09:44:32", "link": "http://arxiv.org/abs/2506.23667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation", "abstract": "Context-aware embedding methods boost retrieval accuracy by conditioning on\ncorpus statistics (e.g., term co-occurrence and topical patterns) extracted\nfrom neighboring documents. However, this context-aware approach requires\naccess to the target corpus or requires domain-specific finetuning, posing\npractical barriers in privacy-sensitive or resource-constrained settings. We\npresent ZEST, a zero-shot contextual adaptation framework that replaces real\ncorpus access with a one-time offline synthesis of a compact proxy. Given only\na handful exemplar documents representative of the general target domain, we\nuse a multi-step hierarchical procedure to generate a synthetic context corpus\nof several hundred documents that aims to emulate key domain-specific\ndistributions. At inference, the frozen context-aware encoder uses this proxy\ncorpus -- without any finetuning or target corpus access -- to produce\ndomain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot\nsynthetic context adaptation using only five example documents performs within\n0.5% of models leveraging full target corpus access -- demonstrating remarkable\nefficacy without any retraining. ZEST thus provides a practical method for\ndeploying high-performance, adaptable embeddings in constrained environments.", "published": "2025-06-30 09:38:50", "link": "http://arxiv.org/abs/2506.23662v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack", "abstract": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate\nthe robustness of text classification systems through word-level modifications\nguided by beam search. Our extensions include support for word deletions and\nthe option to skip substitutions, enabling the discovery of minimal\nmodifications that alter model predictions. We also integrate LIME to better\nprioritize word replacements. Evaluated across multiple datasets and victim\nmodels (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA\nframework, our approach achieves over a 99\\% attack success rate while\npreserving the semantic and lexical similarity of the original texts. Through\nboth quantitative and qualitative analysis, we highlight BeamAttack's\neffectiveness and its limitations. Our implementation is available at\nhttps://github.com/LucK1Y/BeamAttack", "published": "2025-06-30 09:37:19", "link": "http://arxiv.org/abs/2506.23661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs", "abstract": "Large language models (LLMs) make it possible to generate synthetic\nbehavioural data at scale, offering an ethical and low-cost alternative to\nhuman experiments. Whether such data can faithfully capture psychological\ndifferences driven by personality traits, however, remains an open question. We\nevaluate the capacity of LLM agents, conditioned on Big-Five profiles, to\nreproduce personality-based variation in susceptibility to misinformation,\nfocusing on news discernment, the ability to judge true headlines as true and\nfalse headlines as false. Leveraging published datasets in which human\nparticipants with known personality profiles rated headline accuracy, we create\nmatching LLM agents and compare their responses to the original human patterns.\nCertain trait-misinformation associations, notably those involving\nAgreeableness and Conscientiousness, are reliably replicated, whereas others\ndiverge, revealing systematic biases in how LLMs internalize and express\npersonality. The results underscore both the promise and the limits of\npersonality-aligned LLMs for behavioral simulation, and offer new insight into\nmodeling cognitive diversity in artificial agents.", "published": "2025-06-30 08:16:07", "link": "http://arxiv.org/abs/2506.23610v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Semantic-guided Diverse Decoding for Large Language Model", "abstract": "Diverse decoding of large language models is crucial for applications\nrequiring multiple semantically distinct responses, yet existing methods\nprimarily achieve lexical rather than semantic diversity. This limitation\nsignificantly constrains Best-of-N strategies, group-based reinforcement\nlearning, and data synthesis. While temperature sampling and diverse beam\nsearch modify token distributions or apply n-gram penalties, they fail to\nensure meaningful semantic differentiation. We introduce Semantic-guided\nDiverse Decoding (SemDiD), operating directly in embedding space that balances\nquality with diversity through three complementary mechanisms: orthogonal\ndirectional guidance, dynamic inter-group repulsion, and position-debiased\nprobability assessment. SemDiD harmonizes these competing objectives using\nadaptive gain functions and constraint optimization, ensuring both quality\nthresholds and maximal semantic differentiation. Experiments show SemDiD\nconsistently outperforms existing methods, improving Best-of-N coverage by\n1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%\nwhile increasing accuracy by up to 2.1%.", "published": "2025-06-30 08:06:49", "link": "http://arxiv.org/abs/2506.23601v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reachability in symmetric VASS", "abstract": "We investigate the reachability problem in symmetric vector addition systems\nwith states (VASS), where transitions are invariant under a group of\npermutations of coordinates. One extremal case, the trivial groups, yields\ngeneral VASS. In another extremal case, the symmetric groups, we show that the\nreachability problem can be solved in PSPACE, regardless of the dimension of\ninput VASS (to be contrasted with Ackermannian complexity in general VASS). We\nalso consider other groups, in particular alternating and cyclic ones.\nFurthermore, motivated by the open status of the reachability problem in data\nVASS, we estimate the gain in complexity when the group arises as a combination\nof the trivial and symmetric groups.", "published": "2025-06-30 07:33:50", "link": "http://arxiv.org/abs/2506.23578v1", "categories": ["cs.FL", "cs.CL"], "primary_category": "cs.FL"}
{"title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "abstract": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "published": "2025-06-30 07:14:38", "link": "http://arxiv.org/abs/2506.23563v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?", "abstract": "This work-in-progress investigates the memorization, creativity, and nonsense\nfound in cooking recipes generated from Large Language Models (LLMs).\nPrecisely, we aim (i) to analyze memorization, creativity, and non-sense in\nLLMs using a small, high-quality set of human judgments and (ii) to evaluate\npotential approaches to automate such a human annotation in order to scale our\nstudy to hundreds of recipes. To achieve (i), we conduct a detailed human\nannotation on 20 preselected recipes generated by LLM (Mixtral), extracting\neach recipe's ingredients and step-by-step actions to assess which elements are\nmemorized--i.e., directly traceable to online sources possibly seen during\ntraining--and which arise from genuine creative synthesis or outright nonsense.\nWe find that Mixtral consistently reuses ingredients that can be found in\nonline documents, potentially seen during model training, suggesting strong\nreliance on memorized content. To achieve aim (ii) and scale our analysis\nbeyond small sample sizes and single LLM validation, we design an\n``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,\nparsing ingredients and recipe steps, and their annotation. For instance,\ncomparing its output against human annotations, the best ingredient extractor\nand annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on\ningredient matching. This automated framework enables large-scale\nquantification of memorization, creativity, and nonsense in generated recipes,\nproviding rigorous evidence of the models' creative capacities.", "published": "2025-06-30 05:27:11", "link": "http://arxiv.org/abs/2506.23527v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning", "abstract": "In the field of education, understanding students' opinions through their\ncomments is crucial, especially in the Vietnamese language, where resources\nremain limited. Existing educational datasets often lack domain relevance and\nstudent slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese\ndataset for Educational Sentiment Classification and Topic Classification,\ncurated from university forums, which offers more samples, richer class\ndiversity, longer texts, and broader vocabulary. In addition, we explore\nmultitask learning using encoder-only language models (BERT), in which we\nshowed that it achieves performance up to 83.7% and 79.8% accuracy for\nsentiment and topic classification tasks. We also benchmark our dataset and\nmodel with other datasets and models, including Large Language Models, and\ndiscuss these benchmarks. The dataset is publicly available at:\nhttps://huggingface.co/datasets/hung20gg/NEU-ESC.", "published": "2025-06-30 05:19:04", "link": "http://arxiv.org/abs/2506.23524v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "abstract": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "published": "2025-06-30 04:53:27", "link": "http://arxiv.org/abs/2506.23517v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably", "abstract": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and\nReinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large\nlanguage models to downstream tasks. While effective at task adaptation, their\nimpact on prior knowledge remains unclear. In this paper, we introduce jigsaw\npuzzles as a novel task absent from existing pretraining corpora and\nsystematically study the behavior of SFT and RFT on an open-source multimodal\nmodel, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid\ntask acquisition but leads to catastrophic forgetting, whereas RFT learns more\nslowly on novel tasks but maintains prior knowledge. We analyze this phenomenon\nthrough the lens of learning dynamics, showing that RFT reinforces correct\nsamples that are naturally aligned with the base model's probability landscape,\nmitigating interference with prior knowledge. Moreover, supervised training on\ncorrect RFT-simulated rollouts allows SFT to preserve knowledge while rapidly\nlearning new tasks. These findings suggest that data distribution, rather than\nalgorithmic differences, plays a central role in forgetting, and highlight\nRFT's potential for stable continual learning in multimodal large language\nmodels.", "published": "2025-06-30 04:15:01", "link": "http://arxiv.org/abs/2506.23508v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent", "abstract": "Interactive recommendation is a typical information-seeking task that allows\nusers to interactively express their needs through natural language and obtain\npersonalized recommendations. Large language model-powered (LLM-powered) agents\nhave become a new paradigm in interactive recommendations, effectively\ncapturing users' real-time needs and enhancing personalized experiences.\nHowever, due to limited planning and generalization capabilities, existing\nformulations of LLM-powered interactive recommender agents struggle to\neffectively address diverse and complex user intents, such as intuitive,\nunrefined, or occasionally ambiguous requests. To tackle this challenge, we\npropose a novel thought-augmented interactive recommender agent system (TAIRA)\nthat addresses complex user intents through distilled thought patterns.\nSpecifically, TAIRA is designed as an LLM-powered multi-agent system featuring\na manager agent that orchestrates recommendation tasks by decomposing user\nneeds and planning subtasks, with its planning capacity strengthened through\nThought Pattern Distillation (TPD), a thought-augmentation method that extracts\nhigh-level thoughts from the agent's and human experts' experiences. Moreover,\nwe designed a set of user simulation schemes to generate personalized queries\nof different difficulties and evaluate the recommendations based on specific\ndatasets. Through comprehensive experiments conducted across multiple datasets,\nTAIRA exhibits significantly enhanced performance compared to existing methods.\nNotably, TAIRA shows a greater advantage on more challenging tasks while\ngeneralizing effectively on novel tasks, further validating its superiority in\nmanaging complex user intents within interactive recommendation systems. The\ncode is publicly available at:https://github.com/Alcein/TAIRA.", "published": "2025-06-30 03:15:50", "link": "http://arxiv.org/abs/2506.23485v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "What to Keep and What to Drop: Adaptive Table Filtering Framework", "abstract": "Large language models (LLMs) for table-based reasoning often struggle with\nlarge tables due to input length limits. We propose ATF (Adaptive Table\nFiltering Framework), a modular and question-aware filtering pipeline that\nprunes uninformative columns and rows using LLM-generated column descriptions,\nclustering, and sparse-dense alignment scores. ATF integrates seamlessly with\nexisting models (e.g., TAPAS, TAPEX) without retraining. Experiments show that\nATF reduces table cells by ~70\\%, boosting performance on out-of-domain TableQA\ntasks while causing slight performance drops on Table Fact Verification, where\nfull-table context is more critical. These results highlight ATF's ability to\nadaptively balance informativeness and minimalism across tasks.", "published": "2025-06-30 02:03:23", "link": "http://arxiv.org/abs/2506.23463v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation", "abstract": "Residual connection has been extensively studied and widely applied at the\nmodel architecture level. However, its potential in the more challenging\ndata-centric approaches remains unexplored. In this work, we introduce the\nconcept of Data Residual Matching for the first time, leveraging data-level\nskip connections to facilitate data generation and mitigate data information\nvanishing. This approach maintains a balance between newly acquired knowledge\nthrough pixel space optimization and existing core local information\nidentification within raw data modalities, specifically for the dataset\ndistillation task. Furthermore, by incorporating optimization-level\nrefinements, our method significantly improves computational efficiency,\nachieving superior performance while reducing training time and peak GPU memory\nusage by 50%. Consequently, the proposed method Fast and Accurate Data Residual\nMatching for Dataset Distillation (FADRM) establishes a new state-of-the-art,\ndemonstrating substantial improvements over existing methods across multiple\ndataset benchmarks in both efficiency and effectiveness. For instance, with\nResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the\nmethod achieves 47.7% test accuracy in single-model dataset distillation and\n50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and\noutperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%\nand +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.", "published": "2025-06-30 17:59:34", "link": "http://arxiv.org/abs/2506.24125v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime", "abstract": "Data selection plays a crucial role in data-driven decision-making, including\nin large language models (LLMs), and is typically task-dependent. Properties\nsuch as data quality and diversity have been extensively studied and are known\nto enhance model performance. However, it remains unclear whether there exist\nother quantitative and general principles of data selection that can\nconsistently improve performance, especially for complex tasks with limited\nprior knowledge. In this paper, we demonstrate that selecting more uniformly\ndistributed data can improve training efficiency while enhancing performance.\nSpecifically, we establish that more uniform (less biased) distribution leads\nto a larger minimum pairwise distance between data points, denoted by\n$h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training\ndynamics of gradient descent (GD). Moreover, we theoretically show that the\napproximation error of neural networks decreases as $h_{\\min}$ increases. Our\nanalysis introduces a convergence framework for GD beyond the Neural Tangent\nKernel (NTK) regime, applicable to a broad class of architectures, including\ntransformers, without requiring Lipschitz smoothness. This framework further\nprovides theoretical justification for the use of residual connections and\nfunction compositions in deep neural architectures. In the end, we conduct\ncomprehensive experiments for supervised fine-tuning across various settings,\nincluding different optimization strategies, model sizes, and training\ndatasets. The results consistently demonstrate that selecting data by\nmaximizing pairwise distance significantly accelerates training and achieves\ncomparable or better performance in LLMs across diverse datasets. Code and\nDatasets are available at the link:\nhttps://github.com/SafeRL-Lab/data-uniformity.", "published": "2025-06-30 17:58:30", "link": "http://arxiv.org/abs/2506.24120v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Navigating with Annealing Guidance Scale in Diffusion Space", "abstract": "Denoising diffusion models excel at generating high-quality images\nconditioned on text prompts, yet their effectiveness heavily relies on careful\nguidance during the sampling process. Classifier-Free Guidance (CFG) provides a\nwidely used mechanism for steering generation by setting the guidance scale,\nwhich balances image quality and prompt alignment. However, the choice of the\nguidance scale has a critical impact on the convergence toward a visually\nappealing and prompt-adherent image. In this work, we propose an annealing\nguidance scheduler which dynamically adjusts the guidance scale over time based\non the conditional noisy signal. By learning a scheduling policy, our method\naddresses the temperamental behavior of CFG. Empirical results demonstrate that\nour guidance scheduler significantly enhances image quality and alignment with\nthe text prompt, advancing the performance of text-to-image generation.\nNotably, our novel scheduler requires no additional activations or memory\nconsumption, and can seamlessly replace the common classifier-free guidance,\noffering an improved trade-off between prompt alignment and quality.", "published": "2025-06-30 17:55:00", "link": "http://arxiv.org/abs/2506.24108v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies", "abstract": "Synthetic data has emerged as a cost-effective alternative to real data for\ntraining artificial neural networks (ANN). However, the disparity between\nsynthetic and real data results in a domain gap. That gap leads to poor\nperformance and generalization of the trained ANN when applied to real-world\nscenarios. Several strategies have been developed to bridge this gap, which\ncombine synthetic and real data, known as mixed training using hybrid datasets.\nWhile these strategies have been shown to mitigate the domain gap, a systematic\nevaluation of their generalizability and robustness across various tasks and\narchitectures remains underexplored. To address this challenge, our study\ncomprehensively analyzes two widely used mixing strategies on three prevalent\narchitectures and three distinct hybrid datasets. From these datasets, we\nsample subsets with varying proportions of synthetic to real data to\ninvestigate the impact of synthetic and real components. The findings of this\npaper provide valuable insights into optimizing the use of synthetic data in\nthe training process of any ANN, contributing to enhancing robustness and\nefficacy.", "published": "2025-06-30 17:48:14", "link": "http://arxiv.org/abs/2506.24093v1", "categories": ["cs.LG", "cs.AI", "I.2.1; I.2.0; F.2.3"], "primary_category": "cs.LG"}
{"title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention", "abstract": "Blending visual and textual concepts into a new visual concept is a unique\nand powerful trait of human beings that can fuel creativity. However, in\npractice, cross-modal conceptual blending for humans is prone to cognitive\nbiases, like design fixation, which leads to local minima in the design space.\nIn this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can\nautomate the blending process to enhance human creativity. Prior works related\nto cross-modal conceptual blending are limited in encoding a real image without\nloss of details or in disentangling the image and text inputs. To address these\ngaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend\nthe latent representations of a clean reference image with those of the noisy\ngenerated image. Combined with our novel blended attention, IT-Blender encodes\nthe real reference image without loss of details and blends the visual concept\nwith the object specified by the text in a disentangled way. Our experiment\nresults show that IT-Blender outperforms the baselines by a large margin in\nblending visual and textual concepts, shedding light on the new application of\nimage generative models to augment human creativity.", "published": "2025-06-30 17:41:25", "link": "http://arxiv.org/abs/2506.24085v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks", "abstract": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to\nsabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks.\nSQUASH is executed by inserting SWAP gate(s) into the variational quantum\ncircuit of the victim HQNN. Unlike conventional noise-based or adversarial\ninput attacks, SQUASH directly manipulates the circuit structure, leading to\nqubit misalignment and disrupting quantum state evolution. This attack is\nhighly stealthy, as it does not require access to training data or introduce\ndetectable perturbations in input states. Our results demonstrate that SQUASH\nsignificantly degrades classification performance, with untargeted SWAP attacks\nreducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target\nclass accuracy by up to 79.78\\%. These findings reveal a critical vulnerability\nin HQNN implementations, underscoring the need for more resilient architectures\nagainst circuit-level adversarial interventions.", "published": "2025-06-30 17:36:31", "link": "http://arxiv.org/abs/2506.24081v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "A Survey on Vision-Language-Action Models for Autonomous Driving", "abstract": "The rapid progress of multimodal large language models (MLLM) has paved the\nway for Vision-Language-Action (VLA) paradigms, which integrate visual\nperception, natural language understanding, and control within a single policy.\nResearchers in autonomous driving are actively adapting these methods to the\nvehicle domain. Such models promise autonomous vehicles that can interpret\nhigh-level instructions, reason about complex traffic scenes, and make their\nown decisions. However, the literature remains fragmented and is rapidly\nexpanding. This survey offers the first comprehensive overview of VLA for\nAutonomous Driving (VLA4AD). We (i) formalize the architectural building blocks\nshared across recent work, (ii) trace the evolution from early explainer to\nreasoning-centric VLA models, and (iii) compare over 20 representative models\naccording to VLA's progress in the autonomous driving domain. We also\nconsolidate existing datasets and benchmarks, highlighting protocols that\njointly measure driving safety, accuracy, and explanation quality. Finally, we\ndetail open challenges - robustness, real-time efficiency, and formal\nverification - and outline future directions of VLA4AD. This survey provides a\nconcise yet complete reference for advancing interpretable socially aligned\nautonomous vehicles. Github repo is available at\n\\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.", "published": "2025-06-30 16:50:02", "link": "http://arxiv.org/abs/2506.24044v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Constructing Non-Markovian Decision Process via History Aggregator", "abstract": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "published": "2025-06-30 16:32:31", "link": "http://arxiv.org/abs/2506.24026v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are widely used to compute representations of\nnode pairs for downstream tasks such as link prediction. Yet, theoretical\nunderstanding of their expressive power has focused almost entirely on\ngraph-level representations. In this work, we shift the focus to links and\nprovide the first comprehensive study of GNN expressiveness in link\nrepresentation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$\nframework, that subsumes existing message-passing link models and enables\nformal expressiveness comparisons. Using this framework, we derive a hierarchy\nof state-of-the-art methods and offer theoretical tools to analyze future\narchitectures. To complement our analysis, we propose a synthetic evaluation\nprotocol comprising the first benchmark specifically designed to assess\nlink-level expressiveness. Finally, we ask: does expressiveness matter in\npractice? We use a graph symmetry metric that quantifies the difficulty of\ndistinguishing links and show that while expressive models may underperform on\nstandard benchmarks, they significantly outperform simpler ones as symmetry\nincreases, highlighting the need for dataset-aware model selection.", "published": "2025-06-30 16:22:15", "link": "http://arxiv.org/abs/2506.24018v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems", "abstract": "Large artificial intelligence (AI) models offer revolutionary potential for\nfuture wireless systems, promising unprecedented capabilities in network\noptimization and performance. However, current paradigms largely overlook\ncrucial physical interactions. This oversight means they primarily rely on\noffline datasets, leading to difficulties in handling real-time wireless\ndynamics and non-stationary environments. Furthermore, these models often lack\nthe capability for active environmental probing. This paper proposes a\nfundamental paradigm shift towards wireless embodied large AI (WELAI), moving\nfrom passive observation to active embodiment. We first identify key challenges\nfaced by existing models, then we explore the design principles and system\nstructure of WELAI. Besides, we outline prospective applications in\nnext-generation wireless. Finally, through an illustrative case study, we\ndemonstrate the effectiveness of WELAI and point out promising research\ndirections for realizing adaptive, robust, and autonomous wireless systems.", "published": "2025-06-30 16:13:55", "link": "http://arxiv.org/abs/2506.24009v1", "categories": ["cs.IT", "cs.AI", "math.IT"], "primary_category": "cs.IT"}
{"title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems", "abstract": "Autonomous Driving System (ADS) testing is essential to ensure the safety and\nreliability of autonomous vehicles (AVs) before deployment. However, existing\ntechniques primarily focus on evaluating ADS functionalities in single-AV\nsettings. As ADSs are increasingly deployed in multi-AV traffic, it becomes\ncrucial to assess their cooperative performance, particularly regarding\ndeadlocks, a fundamental coordination failure in which multiple AVs enter a\ncircular waiting state indefinitely, resulting in motion planning failures.\nDespite its importance, the cooperative capability of ADSs to prevent deadlocks\nremains insufficiently underexplored. To address this gap, we propose the first\ndedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,\nSTCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs\ncontrolled by the ADS under test are in a circular wait state. STCLocker\nconsists of three key components: Deadlock Oracle, Conflict Feedback, and\nConflict-aware Scenario Generation. Deadlock Oracle provides a reliable\nblack-box mechanism for detecting deadlock cycles among multiple AVs within a\ngiven scenario. Conflict Feedback and Conflict-aware Scenario Generation\ncollaborate to actively guide AVs into simultaneous competition over spatial\nconflict resources (i.e., shared passing regions) and temporal competitive\nbehaviors (i.e., reaching the conflict region at the same time), thereby\nincreasing the effectiveness of generating conflict-prone deadlocks. We\nevaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,\na module-based ADS supporting cooperative communication. Experimental results\nshow that, on average, STCLocker generates more DLS than the best-performing\nbaseline.", "published": "2025-06-30 15:58:10", "link": "http://arxiv.org/abs/2506.23995v1", "categories": ["cs.SE", "cs.AI", "cs.RO"], "primary_category": "cs.SE"}
{"title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "abstract": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "published": "2025-06-30 15:55:41", "link": "http://arxiv.org/abs/2506.23992v1", "categories": ["cs.AI", "cs.ET"], "primary_category": "cs.AI"}
{"title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning", "abstract": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due\nto the inherent limitations in their design and performance capabilities.\nOnline repair plays a crucial role in mitigating such limitations, ensuring the\nruntime safety and reliability of ADSs. Existing online repair solutions\nenforce ADS compliance by transforming unacceptable trajectories into\nacceptable ones based on predefined specifications, such as rule-based\nconstraints or training datasets. However, these approaches often lack\ngeneralizability, adaptability and tend to be overly conservative, resulting in\nineffective repairs that not only fail to mitigate safety risks sufficiently\nbut also degrade the overall driving experience. To address this issue, we\npropose Adaptive Decision Repair (ADReFT), a novel and effective repair method\nthat identifies safety-critical states through offline learning from failed\ntests and generates appropriate mitigation actions to improve ADS safety.\nSpecifically, ADReFT incorporates a transformer-based model with two joint\nheads, State Monitor and Decision Adapter, designed to capture complex driving\nenvironment interactions to evaluate state safety severity and generate\nadaptive repair actions. Given the absence of oracles for state safety\nidentification, we first pretrain ADReFT using supervised learning with coarse\nannotations, i.e., labeling states preceding violations as positive samples and\nothers as negative samples. It establishes ADReFT's foundational capability to\nmitigate safety-critical violations, though it may result in somewhat\nconservative mitigation strategies. Therefore, we subsequently finetune ADReFT\nusing reinforcement learning to improve its initial capability and generate\nmore precise and contextually appropriate repair decisions. Our evaluation\nresults illustrate that ADReFT achieves better repair performance.", "published": "2025-06-30 15:29:36", "link": "http://arxiv.org/abs/2506.23960v1", "categories": ["cs.LG", "cs.AI", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "abstract": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action.", "published": "2025-06-30 15:20:10", "link": "http://arxiv.org/abs/2506.23952v1", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "primary_category": "cs.HC"}
{"title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "abstract": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "published": "2025-06-30 15:18:18", "link": "http://arxiv.org/abs/2506.23949v1", "categories": ["cs.AI", "cs.CR", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning", "abstract": "Imitation learning models for robotic tasks typically rely on multi-modal\ninputs, such as RGB images, language, and proprioceptive states. While\nproprioception is intuitively important for decision-making and obstacle\navoidance, simply incorporating all proprioceptive states leads to a surprising\ndegradation in imitation learning performance. In this work, we identify the\nunderlying issue as the proprioception shift problem, where the distributions\nof proprioceptive states diverge significantly between training and deployment.\nTo address this challenge, we propose a domain adaptation framework that\nbridges the gap by utilizing rollout data collected during deployment. Using\nWasserstein distance, we quantify the discrepancy between expert and rollout\nproprioceptive states and minimize this gap by adding noise to both sets of\nstates, proportional to the Wasserstein distance. This strategy enhances\nrobustness against proprioception shifts by aligning the training and\ndeployment distributions. Experiments on robotic manipulation tasks demonstrate\nthe efficacy of our method, enabling the imitation policy to leverage\nproprioception while mitigating its adverse effects. Our approach outperforms\nthe naive solution which discards proprioception, and other baselines designed\nto address distributional shifts.", "published": "2025-06-30 15:09:14", "link": "http://arxiv.org/abs/2506.23944v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference", "abstract": "As machine learning inferences increasingly move to edge devices, adapting to\ndiverse computational capabilities, hardware, and memory constraints becomes\nmore critical. Instead of relying on a pre-trained model fixed for all future\ninference queries across diverse edge devices, we argue that planning an\ninference pattern with a request-specific model tailored to the device's\ncomputational capacity, accuracy requirements, and time constraints is more\ncost-efficient and robust to diverse scenarios. To this end, we propose an\naccuracy-aware and workload-balanced inference system that integrates joint\nmodel quantization and inference partitioning. In this approach, the server\ndynamically responds to inference queries by sending a quantized model and\nadaptively sharing the inference workload with the device. Meanwhile, the\ndevice's computational power, channel capacity, and accuracy requirements are\nconsidered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference\nsystem, incorporating joint model quantization and partitioning. Our approach\noptimizes layer-wise quantization bit width and partition points to minimize\ntime consumption and cost while accounting for varying accuracy requirements of\ntasks through an accuracy degradation metric in our optimization model. To our\nknowledge, this work represents the first exploration of optimizing\nquantization layer-wise bit-width in the inference serving system, by\nintroducing theoretical measurement of accuracy degradation. Simulation results\ndemonstrate a substantial reduction in overall time and power consumption, with\ncomputation payloads decreasing by over 80% and accuracy degradation kept below\n1%.", "published": "2025-06-30 15:03:35", "link": "http://arxiv.org/abs/2506.23934v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.DC"}
{"title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "abstract": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "published": "2025-06-30 14:54:52", "link": "http://arxiv.org/abs/2506.23926v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "abstract": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "published": "2025-06-30 14:54:15", "link": "http://arxiv.org/abs/2506.23924v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System", "abstract": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes\nfor the manufacturing of high-performance fibre-reinforced polymer composites,\nparticularly for large-scale applications such as wind turbine blades.\nControlling the resin flow dynamics in these processes is critical to ensure\nthe uniform impregnation of the fibre reinforcements, thereby preventing\nresidual porosities and dry spots that impact the consequent structural\nintegrity of the final component. This paper presents a reinforcement learning\n(RL) based strategy, established using process simulations, for synchronising\nthe different resin flow fronts in an infusion scenario involving two resin\ninlets and a single outlet. Using Proximal Policy Optimisation (PPO), our\napproach addresses the challenge of managing the fluid dynamics in a partially\nobservable environment. The results demonstrate the effectiveness of the RL\napproach in achieving an accurate flow convergence, highlighting its potential\ntowards improving process control and product quality in composites\nmanufacturing.", "published": "2025-06-30 14:50:18", "link": "http://arxiv.org/abs/2506.23923v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "abstract": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "published": "2025-06-30 14:37:50", "link": "http://arxiv.org/abs/2506.23908v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models", "abstract": "Accurate and generalizable object segmentation in ultrasound imaging remains\na significant challenge due to anatomical variability, diverse imaging\nprotocols, and limited annotated data. In this study, we propose a\nprompt-driven vision-language model (VLM) that integrates Grounding DINO with\nSAM2 to enable object segmentation across multiple ultrasound organs. A total\nof 18 public ultrasound datasets, encompassing the breast, thyroid, liver,\nprostate, kidney, and paraspinal muscle, were utilized. These datasets were\ndivided into 15 for fine-tuning and validation of Grounding DINO using Low Rank\nAdaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for\ntesting to evaluate performance in unseen distributions. Comprehensive\nexperiments demonstrate that our approach outperforms state-of-the-art\nsegmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,\nand SAMUS on most seen datasets while maintaining strong performance on unseen\ndatasets without additional fine-tuning. These results underscore the promise\nof VLMs in scalable and robust ultrasound image analysis, reducing dependence\non large, organ-specific annotated datasets. We will publish our code on\ncode.sonography.ai after acceptance.", "published": "2025-06-30 14:33:44", "link": "http://arxiv.org/abs/2506.23903v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic", "abstract": "The chain of thought is fundamental in Transformers, which is to perform\nstep-by-step reasoning. Besides what intermediate steps work, the order of\nthese steps critically affects the difficulty of the reasoning. This study\naddresses a novel task of unraveling chain of thought - reordering decoder\ninput tokens to a learning-friendly sequence for Transformers to learn\narithmetic tasks. The proposed pipeline first trains a Transformer on a mixture\nof target sequences arranged in different orders and then identifies benign\norders as those with fast loss drops in the early stage. As the search space\ngrows factorially with sequence length, we propose a two-stage hierarchical\napproach for inter- and intra-block reordering. Experiments on four\norder-sensitive arithmetic tasks show that our method identifies a\nlearning-friendly order out of a few billion candidates. Notably, on the\nmultiplication task, it recovered the reverse-digit order reported in prior\nstudies.", "published": "2025-06-30 14:05:53", "link": "http://arxiv.org/abs/2506.23875v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance", "abstract": "We study the capabilities of generative autoregressive transformer models\ntrained on large amounts of symbolic solo-piano transcriptions. After first\npretraining on approximately 60,000 hours of music, we use a comparatively\nsmaller, high-quality subset, to finetune models to produce musical\ncontinuations, perform symbolic classification tasks, and produce\ngeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework to\nsymbolic music. When evaluating piano continuation coherence, our generative\nmodel outperforms leading symbolic generation techniques and remains\ncompetitive with proprietary audio generation models. On MIR classification\nbenchmarks, frozen representations from our contrastive model achieve\nstate-of-the-art results in linear probe experiments, while direct finetuning\ndemonstrates the generalizability of pretrained representations, often\nrequiring only a few hundred labeled examples to specialize to downstream\ntasks.", "published": "2025-06-30 14:00:14", "link": "http://arxiv.org/abs/2506.23869v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Differentially Private Synthetic Data Release for Topics API Outputs", "abstract": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an\narea of research that has received strong interest from academics, industry,\nand regulators. Despite this interest, the empirical study of these methods is\nhindered by the lack of publicly available data. Reliable empirical analysis of\nthe privacy properties of an API, in fact, requires access to a dataset\nconsisting of realistic API outputs; however, privacy concerns prevent the\ngeneral release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API\noutputs that are simultaneously realistic enough to enable accurate study and\nprovide strong privacy protections. We focus on one Privacy-Preserving Ads\nAPIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a\nmethodology to generate a differentially-private dataset that closely matches\nthe re-identification risk properties of the real Topics API data. The use of\ndifferential privacy provides strong theoretical bounds on the leakage of\nprivate user information from this release.\n  Our methodology is based on first computing a large number of\ndifferentially-private statistics describing how output API traces evolve over\ntime. Then, we design a parameterized distribution over sequences of API traces\nand optimize its parameters so that they closely match the statistics obtained.\nFinally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset\nobtained by this methodology. We hope this will enable external researchers to\nanalyze the API in-depth and replicate prior and future work on a realistic\nlarge-scale dataset. We believe that this work will contribute to fostering\ntransparency regarding the privacy properties of Privacy-Preserving Ads APIs.", "published": "2025-06-30 13:46:57", "link": "http://arxiv.org/abs/2506.23855v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "abstract": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "published": "2025-06-30 13:34:34", "link": "http://arxiv.org/abs/2506.23844v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "abstract": "Human Digital Twins (HDTs) have traditionally been conceptualized as\ndata-driven models designed to support decision-making across various domains.\nHowever, recent advancements in conversational AI open new possibilities for\nHDTs to function as authentic, interactive digital counterparts of individuals.\nThis paper introduces a novel HDT system architecture that integrates large\nlanguage models with dynamically updated personal data, enabling it to mirror\nan individual's conversational style, memories, and behaviors. To achieve this,\nour approach implements context-aware memory retrieval, neural\nplasticity-inspired consolidation, and adaptive learning mechanisms, creating a\nmore natural and evolving digital persona. The resulting system does not only\nreplicate an individual's unique conversational style depending on who they are\nspeaking with, but also enriches responses with dynamically captured personal\nexperiences, opinions, and memories. While this marks a significant step toward\ndeveloping authentic virtual counterparts, it also raises critical ethical\nconcerns regarding privacy, accountability, and the long-term implications of\npersistent digital identities. This study contributes to the field of HDTs by\ndescribing our novel system architecture, demonstrating its capabilities, and\ndiscussing future directions and emerging challenges to ensure the responsible\nand ethical development of HDTs.", "published": "2025-06-30 13:18:31", "link": "http://arxiv.org/abs/2506.23826v1", "categories": ["cs.ET", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "primary_category": "cs.ET"}
{"title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "abstract": "The influence of Artificial Intelligence (AI), and specifically Large\nLanguage Models (LLM), on education is continuously increasing. These models\nare frequently used by students, giving rise to the question whether current\nforms of assessment are still a valid way to evaluate student performance and\ncomprehension. The theoretical framework developed in this paper is grounded in\nConstructive Alignment (CA) theory and Bloom's taxonomy for defining learning\nobjectives. We argue that AI influences learning objectives of different Bloom\nlevels in a different way, and assessment has to be adopted accordingly.\nFurthermore, in line with Bloom's vision, formative and summative assessment\nshould be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be\nadapted to the presence of AI, a strong bias exists on the extent to which\nlecturers want to allow for AI in assessment. This bias is caused by a\nlecturer's familiarity with AI and specifically whether they use it themselves.\nTo avoid this bias, we propose structured guidelines on a university or faculty\nlevel, to foster alignment among the staff. Besides that, we argue that\nteaching staff should be trained on the capabilities and limitations of AI\ntools. In this way, they are better able to adapt their assessment methods.", "published": "2025-06-30 13:02:01", "link": "http://arxiv.org/abs/2506.23815v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "abstract": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "published": "2025-06-30 12:34:31", "link": "http://arxiv.org/abs/2506.23793v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "abstract": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "published": "2025-06-30 12:24:24", "link": "http://arxiv.org/abs/2506.23784v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking", "abstract": "Combining traditional RGB cameras with bio-inspired event cameras for robust\nobject tracking has garnered increasing attention in recent years. However,\nmost existing multimodal tracking algorithms depend heavily on high-complexity\nVision Transformer architectures for feature extraction and fusion across\nmodalities. This not only leads to substantial computational overhead but also\nlimits the effectiveness of cross-modal interactions. In this paper, we propose\nan efficient RGB-Event object tracking framework based on the linear-complexity\nVision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a\nlightweight Prompt Generator that utilizes embedded features from each\nmodality, together with a shared prompt pool, to dynamically generate\nmodality-specific learnable prompt vectors. These prompts, along with the\nmodality-specific embedded features, are then fed into a Vision Mamba-based\nFEMamba backbone, which facilitates prompt-guided feature extraction,\ncross-modal interaction, and fusion in a unified manner. Finally, the fused\nrepresentations are passed to the tracking head for accurate target\nlocalization. Extensive experimental evaluations on multiple RGB-Event tracking\nbenchmarks, including short-term COESOT dataset and long-term datasets, i.e.,\nFE108 and FELT V2, demonstrate the superior performance and efficiency of the\nproposed tracking framework. The source code and pre-trained models will be\nreleased on https://github.com/Event-AHU/Mamba_FETrack", "published": "2025-06-30 12:24:01", "link": "http://arxiv.org/abs/2506.23783v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling", "abstract": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance\non relational data; however, their confidence estimates often misalign with\nactual predictive correctness, posing significant limitations for deployment in\nsafety-critical settings. While existing graph-aware calibration methods seek\nto mitigate this limitation, they primarily depend on coarse one-hop\nstatistics, such as neighbor-predicted confidence, or latent node embeddings,\nthereby neglecting the fine-grained structural heterogeneity inherent in graph\ntopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a\npost-hoc calibration framework that assigns node-specific temperatures based on\ntunable heat-kernel graph wavelet features. Specifically, WATS harnesses the\nscalability and topology sensitivity of graph wavelets to refine confidence\nestimates, all without necessitating model retraining or access to neighboring\nlogits or predictions. Extensive evaluations across seven benchmark datasets\nwith varying graph structures and two GNN backbones demonstrate that WATS\nachieves the lowest Expected Calibration Error (ECE) among all compared\nmethods, outperforming both classical and graph-specific baselines by up to\n42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared\nwith graph-specific methods. Moreover, WATS remains computationally efficient,\nscaling well across graphs of diverse sizes and densities. Code will be\nreleased based on publication.", "published": "2025-06-30 12:23:57", "link": "http://arxiv.org/abs/2506.23782v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BayesL: Towards a Logical Framework for Bayesian Networks", "abstract": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "published": "2025-06-30 12:18:00", "link": "http://arxiv.org/abs/2506.23773v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving", "abstract": "Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)\nand shows clear advantages. However, most RL-based AD methods overlook policy\nstructure design. An RL policy that only outputs short-timescale vehicle\ncontrol commands results in fluctuating driving behavior due to fluctuations in\nnetwork outputs, while one that only outputs long-timescale driving goals\ncannot achieve unified optimality of driving behavior and control. Therefore,\nwe propose a multi-timescale hierarchical reinforcement learning approach. Our\napproach adopts a hierarchical policy structure, where high- and low-level RL\npolicies are unified-trained to produce long-timescale motion guidance and\nshort-timescale control commands, respectively. Therein, motion guidance is\nexplicitly represented by hybrid actions to capture multimodal driving\nbehaviors on structured road and support incremental low-level extend-state\nupdates. Additionally, a hierarchical safety mechanism is designed to ensure\nmulti-timescale safety. Evaluation in simulator-based and HighD dataset-based\nhighway multi-lane scenarios demonstrates that our approach significantly\nimproves AD performance, effectively increasing driving efficiency, action\nconsistency and safety.", "published": "2025-06-30 12:17:42", "link": "http://arxiv.org/abs/2506.23771v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "abstract": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment.", "published": "2025-06-30 12:09:29", "link": "http://arxiv.org/abs/2506.23762v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment", "abstract": "Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex\ndynamics like intransitivity and the Red Queen effect, leading to unstable\nconvergence. To counter these challenges, this paper introduces the Marker Gene\nMethod (MGM), a framework that establishes stability by using a 'marker gene'\nas a dynamic benchmark and an adaptive weighting mechanism to balance\nexploration and exploitation. We provide rigorous mathematical proofs\ndemonstrating that MGM creates strong attractors near Nash Equilibria within\nthe Strictly Competitive Game framework. Empirically, MGM demonstrates its\nefficacy across a spectrum of challenges: it stabilizes the canonical\nRock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D\non ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it\nsuccessfully tames the notoriously pathological Shapley Biased Game. This work\npresents a theoretically sound and empirically validated framework that\nsubstantially enhances the stability and robustness of CCEAs in complex\ncompetitive environments.", "published": "2025-06-30 11:13:36", "link": "http://arxiv.org/abs/2506.23734v1", "categories": ["cs.NE", "cs.AI", "cs.GT"], "primary_category": "cs.NE"}
{"title": "System-Embedded Diffusion Bridge Models", "abstract": "Solving inverse problems -- recovering signals from incomplete or noisy\nmeasurements -- is fundamental in science and engineering. Score-based\ngenerative models (SGMs) have recently emerged as a powerful framework for this\ntask. Two main paradigms have formed: unsupervised approaches that adapt\npretrained generative models to inverse problems, and supervised bridge methods\nthat train stochastic processes conditioned on paired clean and corrupted data.\nWhile the former typically assume knowledge of the measurement model, the\nlatter have largely overlooked this structural information. We introduce System\nembedded Diffusion Bridge Models (SDBs), a new class of supervised bridge\nmethods that explicitly embed the known linear measurement system into the\ncoefficients of a matrix-valued SDE. This principled integration yields\nconsistent improvements across diverse linear inverse problems and demonstrates\nrobust generalization under system misspecification between training and\ndeployment, offering a promising solution to real-world applications.", "published": "2025-06-30 10:58:49", "link": "http://arxiv.org/abs/2506.23726v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?", "abstract": "Vision-Language Models (VLMs) are increasingly pivotal for generalist robot\nmanipulation, enabling tasks such as physical reasoning, policy generation, and\nfailure detection. However, their proficiency in these high-level applications\noften assumes a deep understanding of low-level physical prerequisites, a\ncapability that remains largely unverified. For robots to perform actions\nreliably, they must comprehend intrinsic object properties (e.g., material,\nweight), action affordances (e.g., graspable, stackable), and physical\nconstraints (e.g., stability, reachability, or an object's state, such as being\nclosed). Despite the widespread use of VLMs in manipulation tasks, we argue\nthat off-the-shelf models may lack this granular, physically grounded\nunderstanding, as such prerequisites are often overlooked during training.\n  To address this critical gap, we introduce PAC Bench, a comprehensive\nbenchmark designed to systematically evaluate VLMs on their understanding of\ncore Properties, Affordances, and Constraints (PAC) from a task executability\nperspective. PAC Bench features a diverse dataset with over 30,000 annotations,\ncomprising 673 real-world images (115 object classes, 15 property types, and 1\nto 3 affordances defined per class), 100 real-world humanoid-view scenarios,\nand 120 unique simulated constraint scenarios across four tasks.\n  Our evaluations reveal significant gaps in the ability of current VLMs to\ngrasp fundamental physical concepts, highlighting limitations in their\nsuitability for reliable robot manipulation and pointing to key areas for\ntargeted research. PAC Bench also serves as a standardized benchmark for\nrigorously evaluating physical reasoning in VLMs and guiding the development of\nmore robust, physically grounded models for robotic applications.\n  Project Page: https://pacbench.github.io/", "published": "2025-06-30 10:58:36", "link": "http://arxiv.org/abs/2506.23725v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation", "abstract": "Test-time Adaptation (TTA) adapts a given model to testing domain data with\npotential domain shifts through online unsupervised learning, yielding\nimpressive performance. However, to date, existing TTA methods primarily focus\non single-model adaptation. In this work, we investigate an intriguing\nquestion: how does cross-model knowledge influence the TTA process? Our\nfindings reveal that, in TTA's unsupervised online setting, each model can\nprovide complementary, confident knowledge to the others, even when there are\nsubstantial differences in model size. For instance, a smaller model like\nMobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base\n(86.6M parameters). In light of this, we propose COCA, a Cross-Model\nCo-Learning framework for TTA, which mainly consists of two main strategies. 1)\nCo-adaptation adaptively integrates complementary knowledge from other models\nthroughout the TTA process, reducing individual model biases. 2)\nSelf-adaptation enhances each model's unique strengths via unsupervised\nlearning, enabling diverse adaptation to the target domain. Extensive\nexperiments show that COCA, which can also serve as a plug-and-play module,\nsignificantly boosts existing SOTAs, on models with various sizes--including\nResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,\nwith Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy\non ImageNet-C from 51.7% to 64.5%. The code is publicly available at\nhttps://github.com/ycarobot/COCA.", "published": "2025-06-30 10:54:50", "link": "http://arxiv.org/abs/2506.23724v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "abstract": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings.", "published": "2025-06-30 10:49:54", "link": "http://arxiv.org/abs/2506.23721v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "eess.IV"}
{"title": "DABstep: Data Agent Benchmark for Multi-step Reasoning", "abstract": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic\nmulti-step data analysis tasks. DABstep comprises over 450 real-world\nchallenges derived from a financial analytics platform, requiring models to\ncombine code-based data processing with contextual reasoning over heterogeneous\ndocumentation. Each task demands an iterative, multi-step problem-solving\napproach, testing capabilities in data manipulation, cross-referencing multiple\nsources, and precise result reporting. The benchmark provides a factoid-style\nanswer format with automatic correctness checks for objective scoring at scale.\nWe evaluate leading LLM-based agents, revealing a substantial performance gap:\neven the best agent achieves only 14.55% accuracy on the hardest tasks. We\ndetail our benchmark's design, dataset composition, task formulation,\nevaluation protocol, report baseline results and analyze failure modes. DABstep\nis released with a public leaderboard and toolkit to accelerate research in\nautonomous data analysis.", "published": "2025-06-30 10:49:21", "link": "http://arxiv.org/abs/2506.23719v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "abstract": "Multi-bit spiking neural networks (SNNs) have recently become a heated\nresearch spot, pursuing energy-efficient and high-accurate AI. However, with\nmore bits involved, the associated memory and computation demands escalate to\nthe point where the performance improvements become disproportionate. Based on\nthe insight that different layers demonstrate different importance and extra\nbits could be wasted and interfering, this paper presents an adaptive bit\nallocation strategy for direct-trained SNNs, achieving fine-grained layer-wise\nallocation of memory and computation resources. Thus, SNN's efficiency and\naccuracy can be improved. Specifically, we parametrize the temporal lengths and\nthe bit widths of weights and spikes, and make them learnable and controllable\nthrough gradients. To address the challenges caused by changeable bit widths\nand temporal lengths, we propose the refined spiking neuron, which can handle\ndifferent temporal lengths, enable the derivation of gradients for temporal\nlengths, and suit spike quantization better. In addition, we theoretically\nformulate the step-size mismatch problem of learnable bit widths, which may\nincur severe quantization errors to SNN, and accordingly propose the step-size\nrenewal mechanism to alleviate this issue. Experiments on various datasets,\nincluding the static CIFAR and ImageNet and the dynamic CIFAR-DVS and\nDVS-GESTURE, demonstrate that our methods can reduce the overall memory and\ncomputation cost while achieving higher accuracy. Particularly, our\nSEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit\nbudgets over the advanced baseline work on ImageNet. This work will be fully\nopen-sourced.", "published": "2025-06-30 10:45:16", "link": "http://arxiv.org/abs/2506.23717v1", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.NE"}
{"title": "A New Perspective On AI Safety Through Control Theory Methodologies", "abstract": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "published": "2025-06-30 10:26:59", "link": "http://arxiv.org/abs/2506.23703v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "abstract": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "published": "2025-06-30 10:11:39", "link": "http://arxiv.org/abs/2506.23692v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "abstract": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "published": "2025-06-30 10:09:13", "link": "http://arxiv.org/abs/2506.23689v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Learning Modular Exponentiation with Transformers", "abstract": "Modular exponentiation is crucial to number theory and cryptography, yet\nremains largely unexplored from a mechanistic interpretability standpoint. We\ntrain a 4-layer encoder-decoder Transformer model to perform this operation and\ninvestigate the emergence of numerical reasoning during training. Utilizing\nprincipled sampling strategies, PCA-based embedding analysis, and activation\npatching, we examine how number-theoretic properties are encoded within the\nmodel. We find that reciprocal operand training leads to strong performance\ngains, with sudden generalization across related moduli. These synchronized\naccuracy surges reflect grokking-like dynamics, suggesting the model\ninternalizes shared arithmetic structure. We also find a subgraph consisting\nentirely of attention heads in the final layer sufficient to achieve full\nperformance on the task of regular exponentiation. These results suggest that\ntransformer models learn modular arithmetic through specialized computational\ncircuits, paving the way for more interpretable and efficient neural approaches\nto modular exponentiation.", "published": "2025-06-30 10:00:44", "link": "http://arxiv.org/abs/2506.23679v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models", "abstract": "The output quality of large language models (LLMs) can be improved via\n\"reasoning\": generating segments of chain-of-thought (CoT) content to further\ncondition the model prior to producing user-facing output. While these chains\ncontain valuable information, they are verbose and lack explicit organization,\nmaking them tedious to review. Moreover, they lack opportunities for user\nfeedback, such as to remove unwanted considerations, add desired ones, or\nclarify unclear assumptions. We introduce Interactive Reasoning, an interaction\ndesign that visualizes chain-of-thought outputs as a hierarchy of topics and\nenables user review and modification. We implement interactive reasoning in\nHippo, a prototype for AI-assisted decision making in the face of uncertain\ntrade-offs. In a user study with 16 participants, we find that interactive\nreasoning in Hippo allows users to quickly identify and interrupt erroneous\ngenerations, efficiently steer the model towards customized responses, and\nbetter understand both model reasoning and model outputs. Our work contributes\nto a new paradigm that incorporates user oversight into LLM reasoning\nprocesses.", "published": "2025-06-30 10:00:43", "link": "http://arxiv.org/abs/2506.23678v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "abstract": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "published": "2025-06-30 09:52:01", "link": "http://arxiv.org/abs/2506.23673v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "abstract": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "published": "2025-06-30 09:14:49", "link": "http://arxiv.org/abs/2506.23644v1", "categories": ["cs.SE", "cs.AI", "cs.CR"], "primary_category": "cs.SE"}
{"title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation", "abstract": "As the appearance of medical images is influenced by multiple underlying\nfactors, generative models require rich attribute information beyond labels to\nproduce realistic and diverse images. For instance, generating an image of skin\nlesion with specific patterns demands descriptions that go beyond diagnosis,\nsuch as shape, size, texture, and color. However, such detailed descriptions\nare not always accessible. To address this, we explore a framework, termed\nVisual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from\npre-trained Multi-modal Large Language Models (MLLMs) to improve the quality\nand diversity of medical image generation. First, to derive descriptions from\nMLLMs without hallucination, we design a series of prompts following\nChain-of-Thoughts for common medical imaging tasks, including dermatologic,\ncolorectal, and chest X-ray images. Generated descriptions are utilized during\ntraining and stored across different categories. During testing, descriptions\nare randomly retrieved from the corresponding category for inference. Moreover,\nto make the generator robust to unseen combination of descriptions at the test\ntime, we propose a Prototype Condition Mechanism that restricts test embeddings\nto be similar to those from training. Experiments on three common types of\nmedical imaging across four datasets verify the effectiveness of VAP-Diffusion.", "published": "2025-06-30 09:11:19", "link": "http://arxiv.org/abs/2506.23641v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding", "abstract": "Multimodal large language models (MLLMs) have made significant progress in\nvision-language understanding, yet effectively aligning different modalities\nremains a fundamental challenge. We present a framework that unifies multimodal\nunderstanding by applying byte-pair encoding to visual tokens. Unlike\nconventional approaches that rely on modality-specific encoders, our method\ndirectly incorporates structural information into visual tokens, mirroring\nsuccessful tokenization strategies in text-only language models. We introduce a\npriority-guided encoding scheme that considers both frequency and spatial\nconsistency, coupled with a multi-stage training procedure based on\ncurriculum-driven data composition. These enhancements enable the transformer\nmodel to better capture cross-modal relationships and reason with visual\ninformation. Comprehensive experiments demonstrate improved performance across\ndiverse vision-language tasks. By bridging the gap between visual and textual\nrepresentations, our approach contributes to the advancement of more capable\nand efficient multimodal foundation models.", "published": "2025-06-30 09:08:08", "link": "http://arxiv.org/abs/2506.23639v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model", "abstract": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)\nwith significant advancements such as OpenAI's ChatGPT, Meta's Llama, and\nDatabricks' DBRX. This paper addresses the cost and scalability challenges\nencountered when constructing private LLM systems for personal or small group\nservices, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2\nUltra chips is established as a cost-efficient solution to host and accelerate\nthe pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our\nperformance analysis reveal that parallel execution of the model's experts\nacross two to four machine nodes significantly reduces inference time. We find\nthat computation time for the experts is comparable to the communication time\nfor exchanging their outputs, emphasizing the importance of network latency\nover bandwidth. We also observe significant management overhead due to Apple\nsoftware stack's memory management logic. Based on these findings, we develop\noptimization schemes to eliminate the memory management overhead. As a result,\nthe Mac Studio cluster is 1.15 times more cost-efficient than the\nstate-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we\nconstruct a performance model to estimate system performance under varying\nconfigurations, and the model provides valuable insights for designing private\nLLM systems.", "published": "2025-06-30 09:04:25", "link": "http://arxiv.org/abs/2506.23635v1", "categories": ["cs.DC", "cs.AI", "cs.PF", "I.6.4; I.2.7; I.2.11"], "primary_category": "cs.DC"}
{"title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures", "abstract": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by\nconverting programs into forms that are more complex to analyze. However, MBA\nhas been increasingly exploited by malware developers to evade detection and\ncause significant real-world problems. Traditional MBA deobfuscation methods\noften consider these expressions as part of a black box and overlook their\ninternal semantic information. To bridge this gap, we propose a truth table,\nwhich is an automatically constructed semantic representation of an\nexpression's behavior that does not rely on external resources. The truth table\nis a mathematical form that represents the output of expression for all\npossible combinations of input. We also propose a general and extensible guided\nMBA deobfuscation framework (gMBA) that modifies a Transformer-based neural\nencoder-decoder Seq2Seq architecture to incorporate this semantic guidance.\nExperimental results and in-depth analysis show that integrating expression\nsemantics significantly improves performance and highlights the importance of\ninternal semantic expressions in recovering obfuscated code to its original\nform.", "published": "2025-06-30 09:03:13", "link": "http://arxiv.org/abs/2506.23634v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data", "abstract": "The integrity of Water Quality Data (WQD) is critical in environmental\nmonitoring for scientific decision-making and ecological protection. However,\nwater quality monitoring systems are often challenged by large amounts of\nmissing data due to unavoidable problems such as sensor failures and\ncommunication delays, which further lead to water quality data becoming\nHigh-Dimensional and Sparse (HDS). Traditional data imputation methods are\ndifficult to depict the potential dynamics and fail to capture the deep data\nfeatures, resulting in unsatisfactory imputation performance. To effectively\naddress the above issues, this paper proposes a Nonlinear Low-rank\nRepresentation model (NLR) with Convolutional Neural Networks (CNN) for\nimputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing\ntemporal features to model the temporal dependence of data between time slots,\nand b) Extracting nonlinear interactions and local patterns to mine\nhigher-order relationships features and achieve deep fusion of multidimensional\ninformation. Experimental studies on three real water quality datasets\ndemonstrate that the proposed model significantly outperforms existing\nstate-of-the-art data imputation models in terms of estimation accuracy. It\nprovides an effective approach for handling water quality monitoring data in\ncomplex dynamic environments.", "published": "2025-06-30 08:48:19", "link": "http://arxiv.org/abs/2506.23629v1", "categories": ["cs.LG", "cs.AI", "68T07(Primary) 62M10, 65C60 (Secondary)", "I.2.7"], "primary_category": "cs.LG"}
{"title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking", "abstract": "Traditional Kubernetes networking struggles to meet the escalating demands of\nAI/ML and evolving Telco infrastructure. This paper introduces Kubernetes\nNetwork Drivers (KNDs), a transformative, modular, and declarative architecture\ndesigned to overcome current imperative provisioning and API limitations. KNDs\nintegrate network resource management into Kubernetes' core by utilizing\nDynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,\nand upcoming OCI Runtime Specification changes. Our DraNet implementation\ndemonstrates declarative attachment of network interfaces, including Remote\nDirect Memory Access (RDMA) devices, significantly boosting high-performance\nAI/ML workloads. This capability enables sophisticated cloud-native\napplications and lays crucial groundwork for future Telco solutions, fostering\na \"galaxy\" of specialized KNDs for enhanced application delivery and reduced\noperational complexity.", "published": "2025-06-30 08:45:54", "link": "http://arxiv.org/abs/2506.23628v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "abstract": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "published": "2025-06-30 08:45:04", "link": "http://arxiv.org/abs/2506.23626v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval", "abstract": "Lecture slide element detection and retrieval are key problems in slide\nunderstanding. Training effective models for these tasks often depends on\nextensive manual annotation. However, annotating large volumes of lecture\nslides for supervised training is labor intensive and requires domain\nexpertise. To address this, we propose a large language model (LLM)-guided\nsynthetic lecture slide generation pipeline, SynLecSlideGen, which produces\nhigh-quality, coherent and realistic slides. We also create an evaluation\nbenchmark, namely RealSlide by manually annotating 1,050 real lecture slides.\nTo assess the utility of our synthetic slides, we perform few-shot transfer\nlearning on real data using models pre-trained on them. Experimental results\nshow that few-shot transfer learning with pretraining on synthetic slides\nsignificantly improves performance compared to training only on real data. This\ndemonstrates that synthetic data can effectively compensate for limited labeled\nlecture slides. The code and resources of our work are publicly available on\nour project website: https://synslidegen.github.io/.", "published": "2025-06-30 08:11:31", "link": "http://arxiv.org/abs/2506.23605v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SoK: Semantic Privacy in Large Language Models", "abstract": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains, traditional data privacy measures prove inadequate for protecting\ninformation that is implicit, contextual, or inferable - what we define as\nsemantic privacy. This Systematization of Knowledge (SoK) introduces a\nlifecycle-centric framework to analyze how semantic privacy risks emerge across\ninput processing, pretraining, fine-tuning, and alignment stages of LLMs. We\ncategorize key attack vectors and assess how current defenses, such as\ndifferential privacy, embedding encryption, edge computing, and unlearning,\naddress these threats. Our analysis reveals critical gaps in semantic-level\nprotection, especially against contextual inference and latent representation\nleakage. We conclude by outlining open challenges, including quantifying\nsemantic leakage, protecting multimodal inputs, balancing de-identification\nwith generation quality, and ensuring transparency in privacy enforcement. This\nwork aims to inform future research on designing robust, semantically aware\nprivacy-preserving techniques for LLMs.", "published": "2025-06-30 08:08:15", "link": "http://arxiv.org/abs/2506.23603v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series", "abstract": "Recently, forecasting future abnormal events has emerged as an important\nscenario to tackle real-world necessities. However, the solution of predicting\nspecific future time points when anomalies will occur, known as Anomaly\nPrediction (AP), remains under-explored. Existing methods dealing with time\nseries data fail in AP, focusing only on immediate anomalies or failing to\nprovide precise predictions for future anomalies. To address the AP task, we\npropose a novel framework called Anomaly to Prompt (A2P), comprised of\nAnomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To\nenable the forecasting model to forecast abnormal time points, we adopt a\nstrategy to learn the relationships of anomalies. For the robust detection of\nanomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)\nthat simulates diverse anomaly patterns using signal adaptive prompt.\nComprehensive experiments on multiple real-world datasets demonstrate the\nsuperiority of A2P over state-of-the-art methods, showcasing its ability to\npredict future anomalies. Our implementation code is available at\nhttps://github.com/KU-VGI/AP.", "published": "2025-06-30 08:00:16", "link": "http://arxiv.org/abs/2506.23596v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Transition Matching: Scalable and Flexible Generative Modeling", "abstract": "Diffusion and flow matching models have significantly advanced media\ngeneration, yet their design space is well-explored, somewhat limiting further\nimprovements. Concurrently, autoregressive (AR) models, particularly those\ngenerating continuous tokens, have emerged as a promising direction for\nunifying text and media generation. This paper introduces Transition Matching\n(TM), a novel discrete-time, continuous-state generative paradigm that unifies\nand advances both diffusion/flow models and continuous AR generation. TM\ndecomposes complex generation tasks into simpler Markov transitions, allowing\nfor expressive non-deterministic probability transition kernels and arbitrary\nnon-continuous supervision processes, thereby unlocking new flexible design\navenues. We explore these choices through three TM variants: (i) Difference\nTransition Matching (DTM), which generalizes flow matching to discrete-time by\ndirectly learning transition probabilities, yielding state-of-the-art image\nquality and text adherence as well as improved sampling efficiency. (ii)\nAutoregressive Transition Matching (ARTM) and (iii) Full History Transition\nMatching (FHTM) are partially and fully causal models, respectively, that\ngeneralize continuous AR methods. They achieve continuous causal AR generation\nquality comparable to non-causal approaches and potentially enable seamless\nintegration with existing AR text generation techniques. Notably, FHTM is the\nfirst fully causal model to match or surpass the performance of flow-based\nmethods on text-to-image task in continuous domains. We demonstrate these\ncontributions through a rigorous large-scale comparison of TM variants and\nrelevant baselines, maintaining a fixed architecture, training data, and\nhyperparameters.", "published": "2025-06-30 07:51:58", "link": "http://arxiv.org/abs/2506.23589v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation", "abstract": "Generating radiology reports from CT scans remains a complex task due to the\nnuanced nature of medical imaging and the variability in clinical\ndocumentation. In this study, we propose a two-stage framework for generating\nrenal radiology reports from 2D CT slices. First, we extract structured\nabnormality features using a multi-task learning model trained to identify\nlesion attributes such as location, size, enhancement, and attenuation. These\nextracted features are subsequently combined with the corresponding CT image\nand fed into a fine-tuned vision-language model to generate natural language\nreport sentences aligned with clinical findings. We conduct experiments on a\ncurated dataset of renal CT studies with manually annotated\nsentence-slice-feature triplets and evaluate performance using both\nclassification metrics and natural language generation metrics. Our results\ndemonstrate that the proposed model outperforms random baselines across all\nabnormality types, and the generated reports capture key clinical content with\nreasonable textual accuracy. This exploratory work highlights the feasibility\nof modular, feature-informed report generation for renal imaging. Future\nefforts will focus on extending this pipeline to 3D CT volumes and further\nimproving clinical fidelity in multimodal medical AI systems.", "published": "2025-06-30 07:45:02", "link": "http://arxiv.org/abs/2506.23584v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection", "abstract": "Object detection plays a crucial role in many security-sensitive\napplications. However, several recent studies have shown that object detectors\ncan be easily fooled by physically realizable attacks, \\eg, adversarial patches\nand recent adversarial textures, which pose realistic and urgent threats.\nAdversarial Training (AT) has been recognized as the most effective defense\nagainst adversarial attacks. While AT has been extensively studied in the\n$l_\\infty$ attack settings on classification models, AT against physically\nrealizable attacks on object detectors has received limited exploration. Early\nattempts are only performed to defend against adversarial patches, leaving AT\nagainst a wider range of physically realizable attacks under-explored. In this\nwork, we consider defending against various physically realizable attacks with\na unified AT method. We propose PBCAT, a novel Patch-Based Composite\nAdversarial Training strategy. PBCAT optimizes the model by incorporating the\ncombination of small-area gradient-guided adversarial patches and imperceptible\nglobal adversarial perturbations covering the entire image. With these designs,\nPBCAT has the potential to defend against not only adversarial patches but also\nunseen physically realizable attacks such as adversarial textures. Extensive\nexperiments in multiple settings demonstrated that PBCAT significantly improved\nrobustness against various physically realizable attacks over state-of-the-art\ndefense methods. Notably, it improved the detection accuracy by 29.7\\% over\nprevious defense methods under one recent adversarial texture attack.", "published": "2025-06-30 07:36:21", "link": "http://arxiv.org/abs/2506.23581v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "abstract": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "published": "2025-06-30 07:29:07", "link": "http://arxiv.org/abs/2506.23576v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Online Human Action Detection during Escorting", "abstract": "The deployment of robot assistants in large indoor spaces has seen\nsignificant growth, with escorting tasks becoming a key application. However,\nmost current escorting robots primarily rely on navigation-focused strategies,\nassuming that the person being escorted will follow without issue. In crowded\nenvironments, this assumption often falls short, as individuals may struggle to\nkeep pace, become obstructed, get distracted, or need to stop unexpectedly. As\na result, conventional robotic systems are often unable to provide effective\nescorting services due to their limited understanding of human movement\ndynamics. To address these challenges, an effective escorting robot must\ncontinuously detect and interpret human actions during the escorting process\nand adjust its movement accordingly. However, there is currently no existing\ndataset designed specifically for human action detection in the context of\nescorting. Given that escorting often occurs in crowded environments, where\nother individuals may enter the robot's camera view, the robot also needs to\nidentify the specific human it is escorting (the subject) before predicting\ntheir actions. Since no existing model performs both person re-identification\nand action prediction in real-time, we propose a novel neural network\narchitecture that can accomplish both tasks. This enables the robot to adjust\nits speed dynamically based on the escortee's movements and seamlessly resume\nescorting after any disruption. In comparative evaluations against strong\nbaselines, our system demonstrates superior efficiency and effectiveness,\nshowcasing its potential to significantly improve robotic escorting services in\ncomplex, real-world scenarios.", "published": "2025-06-30 07:25:31", "link": "http://arxiv.org/abs/2506.23573v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Tensor Train Quantum State Tomography using Compressed Sensing", "abstract": "Quantum state tomography (QST) is a fundamental technique for estimating the\nstate of a quantum system from measured data and plays a crucial role in\nevaluating the performance of quantum devices. However, standard estimation\nmethods become impractical due to the exponential growth of parameters in the\nstate representation. In this work, we address this challenge by parameterizing\nthe state using a low-rank block tensor train decomposition and demonstrate\nthat our approach is both memory- and computationally efficient. This framework\napplies to a broad class of quantum states that can be well approximated by\nlow-rank decompositions, including pure states, nearly pure states, and ground\nstates of Hamiltonians.", "published": "2025-06-30 07:06:50", "link": "http://arxiv.org/abs/2506.23560v1", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.OC"], "primary_category": "quant-ph"}
{"title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "abstract": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "published": "2025-06-30 06:45:39", "link": "http://arxiv.org/abs/2506.23549v1", "categories": ["cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound", "abstract": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,\npreterm birth, and an increased risk of pregnancy complications. Compared to\ntraditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,\nproviding a clear visualization of the uterine morphology for assessing CUAs\naccurately. In this paper, we propose an intelligent system for simultaneous\nautomated plane localization and CUA diagnosis. Our highlights are: 1) we\ndevelop a denoising diffusion model with local (plane) and global (volume/text)\nguidance, using an adaptive weighting strategy to optimize attention allocation\nto different conditions; 2) we introduce a reinforcement learning-based\nframework with unsupervised rewards to extract the key slice summary from\nredundant sequences, fully integrating information across multiple planes to\nreduce learning difficulty; 3) we provide text-driven uncertainty modeling for\ncoarse prediction, and leverage it to adjust the classification probability for\noverall performance improvement. Extensive experiments on a large 3D uterine US\ndataset show the efficacy of our method, in terms of plane localization and CUA\ndiagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.", "published": "2025-06-30 06:07:41", "link": "http://arxiv.org/abs/2506.23538v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "abstract": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "published": "2025-06-30 05:11:19", "link": "http://arxiv.org/abs/2506.23520v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization", "abstract": "Federated learning (FL) often suffers from performance degradation due to key\nchallenges such as data heterogeneity and communication constraints. To address\nthese limitations, we present a novel FL framework called FedWSQ, which\nintegrates weight standardization (WS) and the proposed distribution-aware\nnon-uniform quantization (DANUQ). WS enhances FL performance by filtering out\nbiased components in local updates during training, thereby improving the\nrobustness of the model against data heterogeneity and unstable client\nparticipation. In addition, DANUQ minimizes quantization errors by leveraging\nthe statistical properties of local model updates. As a result, FedWSQ\nsignificantly reduces communication overhead while maintaining superior model\naccuracy. Extensive experiments on FL benchmark datasets demonstrate that\nFedWSQ consistently outperforms existing FL methods across various challenging\nFL settings, including extreme data heterogeneity and ultra-low-bit\ncommunication scenarios.", "published": "2025-06-30 04:46:25", "link": "http://arxiv.org/abs/2506.23516v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments", "abstract": "Relative localization is a crucial capability for multi-robot systems\noperating in GPS-denied environments. Existing approaches for multi-robot\nrelative localization often depend on costly or short-range sensors like\ncameras and LiDARs. Consequently, these approaches face challenges such as high\ncomputational overhead (e.g., map merging) and difficulties in disjoint\nenvironments. To address this limitation, this paper introduces MGPRL, a novel\ndistributed framework for multi-robot relative localization using convex-hull\nof multiple Wi-Fi access points (AP). To accomplish this, we employ\nco-regionalized multi-output Gaussian Processes for efficient Radio Signal\nStrength Indicator (RSSI) field prediction and perform uncertainty-aware\nmulti-AP localization, which is further coupled with weighted convex hull-based\nalignment for robust relative pose estimation. Each robot predicts the RSSI\nfield of the environment by an online scan of APs in its environment, which are\nutilized for position estimation of multiple APs. To perform relative\nlocalization, each robot aligns the convex hull of its predicted AP locations\nwith that of the neighbor robots. This approach is well-suited for devices with\nlimited computational resources and operates solely on widely available Wi-Fi\nRSSI measurements without necessitating any dedicated pre-calibration or\noffline fingerprinting. We rigorously evaluate the performance of the proposed\nMGPRL in ROS simulations and demonstrate it with real-world experiments,\ncomparing it against multiple state-of-the-art approaches. The results showcase\nthat MGPRL outperforms existing methods in terms of localization accuracy and\ncomputational efficiency. Finally, we open source MGPRL as a ROS package\nhttps://github.com/herolab-uga/MGPRL.", "published": "2025-06-30 04:35:00", "link": "http://arxiv.org/abs/2506.23514v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI", "abstract": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)\nrepresents a recent breakthrough in lung structure imaging, providing image\nresolution and quality comparable to computed tomography (CT). Due to the\nabsence of ionising radiation, MRI is often preferred over CT in paediatric\ndiseases such as cystic fibrosis (CF), one of the most common genetic disorders\nin Caucasians. To assess structural lung damage in CF imaging, CT scoring\nsystems provide valuable quantitative insights for disease diagnosis and\nprogression. However, few quantitative scoring systems are available in\nstructural lung MRI (e.g., UTE-MRI). To provide fast and accurate\nquantification in lung MRI, we investigated the feasibility of novel Artificial\nintelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring\nconsists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)\nlung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification\nand reporting. The results shows that our APL scoring took 8.2 minutes per\nsubject, which was more than twice as fast as the previous grid-level scoring.\nAdditionally, our pixel-level scoring was statistically more accurate\n(p=0.021), while strongly correlating with grid-level scoring (R=0.973,\np=5.85e-9). This tool has great potential to streamline the workflow of UTE\nlung MRI in clinical settings, and be extended to other structural lung MRI\nsequences (e.g., BLADE MRI), and for other lung diseases (e.g.,\nbronchopulmonary dysplasia).", "published": "2025-06-30 04:08:42", "link": "http://arxiv.org/abs/2506.23506v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "abstract": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "published": "2025-06-30 04:06:24", "link": "http://arxiv.org/abs/2506.23504v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "abstract": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "published": "2025-06-30 03:59:00", "link": "http://arxiv.org/abs/2506.23503v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Sample Margin-Aware Recalibration of Temperature Scaling", "abstract": "Recent advances in deep learning have significantly improved predictive\naccuracy. However, modern neural networks remain systematically overconfident,\nposing risks for deployment in safety-critical scenarios. Current post-hoc\ncalibration methods face a fundamental dilemma: global approaches like\nTemperature Scaling apply uniform adjustments across all samples, introducing\nhigh bias despite computational efficiency, while more expressive methods that\noperate on full logit distributions suffer from high variance due to noisy\nhigh-dimensional inputs and insufficient validation data. To address these\nchallenges, we propose Sample Margin-Aware Recalibration of Temperature\n(SMART), a lightweight, data-efficient recalibration method that precisely\nscales logits based on the margin between the top two logits -- termed the\nlogit gap. Specifically, the logit gap serves as a denoised, scalar signal\ndirectly tied to decision boundary uncertainty, providing a robust indicator\nthat avoids the noise inherent in high-dimensional logit spaces while\npreserving model prediction invariance. Meanwhile, SMART employs a novel\nsoft-binned Expected Calibration Error (SoftECE) objective that balances model\nbias and variance through adaptive binning, enabling stable parameter updates\neven with extremely limited calibration data. Extensive evaluations across\ndiverse datasets and architectures demonstrate that SMART achieves\nstate-of-the-art calibration performance even with substantially fewer\nparameters compared to existing parametric methods, offering a principled,\nrobust, and highly efficient solution for practical uncertainty quantification\nin neural network predictions. The source code is available at:\nhttps://anonymous.4open.science/r/SMART-8B11.", "published": "2025-06-30 03:35:05", "link": "http://arxiv.org/abs/2506.23492v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "abstract": "This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)\nspecifically designed for Graphical User Interface grounding tasks, achieving\nperformance competitive with significantly larger models. Unlike large-scale\nVLMs (>7B parameters) that are computationally intensive and impractical for\nconsumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while\nbeing fully trainable on a single GPU (RTX 4090). The model incorporates\nseveral key innovations: (i) combine cross-platform, multi-resolution dataset\nof 24K examples from diverse sources including mobile, desktop, and web GUI\nscreenshots to effectively address data scarcity in high-resolution desktop\nenvironments; (ii) a two-stage fine-tuning strategy, where initial\ncross-platform training establishes robust GUI understanding, followed by\nspecialized fine-tuning on high-resolution data to significantly enhance model\nadaptability; and (iii) data curation and redundancy reduction strategies,\ndemonstrating that randomly sampling a smaller subset with reduced redundancy\nachieves performance comparable to larger datasets, emphasizing data diversity\nover sheer volume. Empirical evaluation on standard GUI grounding\nbenchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging\nScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%\non ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B\nparameters. Ablation studies validate the critical role of balanced sampling\nand two-stage fine-tuning in enhancing robustness, particularly in\nhigh-resolution desktop scenarios. The Qwen-GUI-3B is available at:\nhttps://github.com/Han1018/Qwen-GUI-3B", "published": "2025-06-30 03:33:02", "link": "http://arxiv.org/abs/2506.23491v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound", "abstract": "Echocardiography is routine for cardiac examination. However, 2D ultrasound\n(US) struggles with accurate metric calculation and direct observation of 3D\ncardiac structures. Moreover, 3D US is limited by low resolution, small field\nof view and scarce availability in practice. Constructing the cardiac\nanatomical twin from 2D images is promising to provide precise treatment\nplanning and clinical quantification. However, it remains challenging due to\nthe rare paired data, complex structures, and US noises. In this study, we\nintroduce a novel generative framework UltraTwin, to obtain cardiac anatomical\ntwin from sparse multi-view 2D US. Our contribution is three-fold. First,\npioneered the construction of a real-world and high-quality dataset containing\nstrictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we\npropose a coarse-to-fine scheme to achieve hierarchical reconstruction\noptimization. Last, we introduce an implicit autoencoder for topology-aware\nconstraints. Extensive experiments show that UltraTwin reconstructs\nhigh-quality anatomical twins versus strong competitors. We believe it advances\nanatomical twin modeling for potential applications in personalized cardiac\ncare.", "published": "2025-06-30 03:27:42", "link": "http://arxiv.org/abs/2506.23490v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models", "abstract": "The success of machine learning models in industrial applications is heavily\ndependent on the quality of the datasets used to train the models. However,\nlarge-scale datasets, specially those constructed from crowd-sourcing and\nweb-scraping, often suffer from label noise, inconsistencies, and errors. This\nproblem is particularly pronounced in manufacturing domains, where obtaining\nhigh-quality labels is costly and time-consuming. This paper introduces\nVision-Language Sanitization and Refinement (VLSR), which is a\nvision-language-based framework for label sanitization and refinement in\nmulti-label manufacturing image datasets. This method embeds both images and\ntheir associated textual labels into a shared semantic space leveraging the\nCLIP vision-language model. Then two key tasks are addressed in this process by\ncomputing the cosine similarity between embeddings. First, label sanitization\nis performed to identify irrelevant, misspelled, or semantically weak labels,\nand surface the most semantically aligned label for each image by comparing\nimage-label pairs using cosine similarity between image and label embeddings.\nSecond, the method applies density-based clustering on text embeddings,\nfollowed by iterative cluster merging, to group semantically similar labels\ninto unified label groups. The Factorynet dataset, which includes noisy labels\nfrom both human annotations and web-scraped sources, is employed to evaluate\nthe effectiveness of the proposed framework. Experimental results demonstrate\nthat the VLSR framework successfully identifies problematic labels and improves\nlabel consistency. This method enables a significant reduction in label\nvocabulary through clustering, which ultimately enhances the dataset's quality\nfor training robust machine learning models in industrial applications with\nminimal human intervention.", "published": "2025-06-30 02:13:09", "link": "http://arxiv.org/abs/2506.23465v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Confidence Paradox: Can LLM Know When It's Wrong", "abstract": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "published": "2025-06-30 02:06:54", "link": "http://arxiv.org/abs/2506.23464v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification", "abstract": "Effective disaster management requires timely and accurate insights, yet\ntraditional methods struggle to integrate multimodal data such as images,\nweather records, and textual reports. To address this, we propose\nDisasterNet-LLM, a specialized Large Language Model (LLM) designed for\ncomprehensive disaster analysis. By leveraging advanced pretraining,\ncross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM\nexcels in disaster classification. Experimental results demonstrate its\nsuperiority over state-of-the-art models, achieving higher accuracy of 89.5%,\nan F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal\ndisaster classification tasks.", "published": "2025-06-30 01:56:05", "link": "http://arxiv.org/abs/2506.23462v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation", "abstract": "In this work, we focus on a novel and practical task, i.e., Time-vAriant\niMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image\nby leveraging the complementary information from a reference image, where both\nimages captured the same scene but with a significant time gap in between,\ni.e., time-variant images. Different from conventional reference-guided image\ninpainting, the reference image under TAMP setup presents significant content\ndistinction to the target image and potentially also suffers from damages. Such\nan application frequently happens in our daily lives to restore a damaged image\nby referring to another reference image, where there is no guarantee of the\nreference image's source and quality. In particular, our study finds that even\nstate-of-the-art (SOTA) reference-guided image inpainting methods fail to\nachieve plausible results due to the chaotic image complementation. To address\nsuch an ill-posed problem, we propose a novel Interactive Distribution\nTransition Estimation (InDiTE) module which interactively complements the\ntime-variant images with adaptive semantics thus facilitate the restoration of\ndamaged regions. To further boost the performance, we propose our TAMP\nsolution, namely Interactive Distribution Transition Estimation-driven\nDiffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and\nconducts latent cross-reference during sampling. Moreover, considering the lack\nof benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,\nbased on existing image and mask datasets. We conduct experiments on the\nTAMP-Street datasets under two different time-variant image inpainting\nsettings, which show our method consistently outperform SOTA reference-guided\nimage inpainting methods for solving TAMP.", "published": "2025-06-30 01:45:33", "link": "http://arxiv.org/abs/2506.23461v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection", "abstract": "Accurate recognition of Emergency Vehicle (EV) sirens is critical for the\nintegration of intelligent transportation systems, smart city monitoring\nsystems, and autonomous driving technologies. Modern automatic solutions are\nlimited by the lack of large scale, curated datasets and by the computational\ndemands of state of the art sound event detection models. This work introduces\nE2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight\nConvolutional Neural Network architecture derived from the PANNs framework,\nspecifically optimized for binary EV siren detection. Leveraging our dedicated\nsubset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across\nmultiple reference datasets and test its viability on embedded hardware. The\nexperimental campaign includes ablation studies, cross-domain benchmarking, and\nreal-time inference deployment on edge device. Interpretability analyses\nexploiting Guided Backpropagation and ScoreCAM algorithms provide insights into\nthe model internal representations and validate its ability to capture distinct\nspectrotemporal patterns associated with different types of EV sirens. Real\ntime performance is assessed through frame wise and event based detection\nmetrics, as well as a detailed analysis of false positive activations. Results\ndemonstrate that E2PANNs establish a new state of the art in this research\ndomain, with high computational efficiency, and suitability for edge-based\naudio monitoring and safety-critical applications.", "published": "2025-06-30 00:21:07", "link": "http://arxiv.org/abs/2506.23437v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T07", "E.1; H.1; I.2; I.5; J.2; K.4; C.4"], "primary_category": "cs.SD"}
{"title": "How to Design and Train Your Implicit Neural Representation for Video Compression", "abstract": "Implicit neural representation (INR) methods for video compression have\nrecently achieved visual quality and compression ratios that are competitive\nwith traditional pipelines. However, due to the need for per-sample network\ntraining, the encoding speeds of these methods are too slow for practical\nadoption. We develop a library to allow us to disentangle and review the\ncomponents of methods from the NeRV family, reframing their performance in\nterms of not only size-quality trade-offs, but also impacts on training time.\nWe uncover principles for effective video INR design and propose a\nstate-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When\nall methods are given equal training time (equivalent to 300 NeRV epochs) for 7\ndifferent UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared\nto the best-performing alternative for each video in our NeRV library. We then\ntackle the encoding speed issue head-on by investigating the viability of\nhyper-networks, which predict INR weights from video inputs, to disentangle\ntraining from encoding to allow for real-time encoding. We propose masking the\nweights of the predicted INR during training to allow for variable, higher\nquality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at\n0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by\n0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar\nspeeds. Our project website is available at https://mgwillia.github.io/vinrb/\nand our code is available at https://github.com/mgwillia/vinrb.", "published": "2025-06-30 17:59:57", "link": "http://arxiv.org/abs/2506.24127v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "abstract": "Time series forecasting traditionally relies on unimodal numerical inputs,\nwhich often struggle to capture high-level semantic patterns due to their dense\nand unstructured nature. While recent approaches have explored representing\ntime series as text using large language models (LLMs), these methods remain\nlimited by the discrete nature of token sequences and lack the perceptual\nintuition humans typically apply, such as interpreting visual patterns. In this\npaper, we propose a multimodal contrastive learning framework that transforms\nraw time series into structured visual and textual perspectives. Rather than\nusing natural language or real-world images, we construct both modalities\ndirectly from numerical sequences. We then align these views in a shared\nsemantic space via contrastive learning, enabling the model to capture richer\nand more complementary representations. Furthermore, we introduce a variate\nselection module that leverages the aligned representations to identify the\nmost informative variables for multivariate forecasting. Extensive experiments\non fifteen short-term and six long-term forecasting benchmarks demonstrate that\nour approach consistently outperforms strong unimodal and cross-modal\nbaselines, highlighting the effectiveness of multimodal alignment in enhancing\ntime series forecasting. Code is available at:\nhttps://github.com/Ironieser/TimesCLIP.", "published": "2025-06-30 17:59:14", "link": "http://arxiv.org/abs/2506.24124v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Calligrapher: Freestyle Text Image Customization", "abstract": "We introduce Calligrapher, a novel diffusion-based framework that\ninnovatively integrates advanced text customization with artistic typography\nfor digital calligraphy and design applications. Addressing the challenges of\nprecise style control and data dependency in typographic customization, our\nframework incorporates three key technical contributions. First, we develop a\nself-distillation mechanism that leverages the pre-trained text-to-image\ngenerative model itself alongside the large language model to automatically\nconstruct a style-centric typography benchmark. Second, we introduce a\nlocalized style injection framework via a trainable style encoder, which\ncomprises both Qformer and linear layers, to extract robust style features from\nreference images. An in-context generation mechanism is also employed to\ndirectly embed reference images into the denoising process, further enhancing\nthe refined alignment of target styles. Extensive quantitative and qualitative\nevaluations across diverse fonts and design contexts confirm Calligrapher's\naccurate reproduction of intricate stylistic details and precise glyph\npositioning. By automating high-quality, visually consistent typography,\nCalligrapher surpasses traditional models, empowering creative practitioners in\ndigital art, branding, and contextual typographic design.", "published": "2025-06-30 17:59:06", "link": "http://arxiv.org/abs/2506.24123v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextMesh4D: High-Quality Text-to-4D Mesh Generation", "abstract": "Recent advancements in diffusion generative models significantly advanced\nimage, video, and 3D content creation from user-provided text prompts. However,\nthe challenging problem of dynamic 3D content generation (text-to-4D) with\ndiffusion guidance remains largely unexplored. In this paper, we introduce\nTextMesh4D, a novel framework for high-quality text-to-4D generation. Our\napproach leverages per-face Jacobians as a differentiable mesh representation\nand decomposes 4D generation into two stages: static object creation and\ndynamic motion synthesis. We further propose a flexibility-rigidity\nregularization term to stabilize Jacobian optimization under video diffusion\npriors, ensuring robust geometric performance. Experiments demonstrate that\nTextMesh4D achieves state-of-the-art results in terms of temporal consistency,\nstructural fidelity, and visual realism. Moreover, TextMesh4D operates with a\nlow GPU memory overhead-requiring only a single 24GB GPU-offering a\ncost-effective yet high-quality solution for text-driven 4D mesh generation.\nThe code will be released to facilitate future research in text-to-4D\ngeneration.", "published": "2025-06-30 17:58:34", "link": "http://arxiv.org/abs/2506.24121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Epona: Autoregressive Diffusion World Model for Autonomous Driving", "abstract": "Diffusion models have demonstrated exceptional visual quality in video\ngeneration, making them promising for autonomous driving world modeling.\nHowever, existing video diffusion-based world models struggle with\nflexible-length, long-horizon predictions and integrating trajectory planning.\nThis is because conventional video diffusion models rely on global joint\ndistribution modeling of fixed-length frame sequences rather than sequentially\nconstructing localized distributions at each timestep. In this work, we propose\nEpona, an autoregressive diffusion world model that enables localized\nspatiotemporal distribution modeling through two key innovations: 1) Decoupled\nspatiotemporal factorization that separates temporal dynamics modeling from\nfine-grained future world generation, and 2) Modular trajectory and video\nprediction that seamlessly integrate motion planning with visual modeling in an\nend-to-end framework. Our architecture enables high-resolution, long-duration\ngeneration while introducing a novel chain-of-forward training strategy to\naddress error accumulation in autoregressive loops. Experimental results\ndemonstrate state-of-the-art performance with 7.4\\% FVD improvement and minutes\nlonger prediction duration compared to prior works. The learned world model\nfurther serves as a real-time motion planner, outperforming strong end-to-end\nplanners on NAVSIM benchmarks. Code will be publicly available at\n\\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.", "published": "2025-06-30 17:56:35", "link": "http://arxiv.org/abs/2506.24113v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World", "abstract": "Multimodal Large Language Models (MLLMs) demonstrate a complex understanding\nof scenes, benefiting from large-scale and high-quality datasets. Most existing\ncaption datasets lack the ground locations and relations for visual entities.\nSeveral grounded caption datasets face the problems of missing detailed\ndescriptions, relations, and massive object descriptions on high-resolution\nimages. To fill this gap for the community, we present DenseWorld-1M, the first\nmassive, detailed, dense grounded caption dataset in the real world. We design\na three-stage labeling pipeline, containing open-world perception, detailed\nobject caption generation, and dense caption merging. The first stage obtains\nentity-level masks and labels. The second stage generates the object-level,\ndetailed captions with the guidance of masks and labels from the first stage.\nThe final stage merges object captions and masks into spatial and relational\ndense captions. To accelerate the labeling process and improve caption quality,\nwe present two VLM models: the Detailed Region Caption model and the Spatial\nCaption Merging model. Extensive experiments on various settings, including\nvision-language understanding, visual grounding, and region caption generation,\ndemonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.", "published": "2025-06-30 17:51:25", "link": "http://arxiv.org/abs/2506.24102v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction", "abstract": "While recent advances in Gaussian Splatting have enabled fast reconstruction\nof high-quality 3D scenes from images, extracting accurate surface meshes\nremains a challenge. Current approaches extract the surface through costly\npost-processing steps, resulting in the loss of fine geometric details or\nrequiring significant time and leading to very dense meshes with millions of\nvertices. More fundamentally, the a posteriori conversion from a volumetric to\na surface representation limits the ability of the final mesh to preserve all\ngeometric structures captured during training. We present MILo, a novel\nGaussian Splatting framework that bridges the gap between volumetric and\nsurface representations by differentiably extracting a mesh from the 3D\nGaussians. We design a fully differentiable procedure that constructs the\nmesh-including both vertex locations and connectivity-at every iteration\ndirectly from the parameters of the Gaussians, which are the only quantities\noptimized during training. Our method introduces three key technical\ncontributions: a bidirectional consistency framework ensuring both\nrepresentations-Gaussians and the extracted mesh-capture the same underlying\ngeometry during training; an adaptive mesh extraction process performed at each\ntraining iteration, which uses Gaussians as differentiable pivots for Delaunay\ntriangulation; a novel method for computing signed distance values from the 3D\nGaussians that enables precise surface extraction while avoiding geometric\nerosion. Our approach can reconstruct complete scenes, including backgrounds,\nwith state-of-the-art quality while requiring an order of magnitude fewer mesh\nvertices than previous methods. Due to their light weight and empty interior,\nour meshes are well suited for downstream applications such as physics\nsimulations or animation.", "published": "2025-06-30 17:48:54", "link": "http://arxiv.org/abs/2506.24096v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism", "abstract": "Computer vision techniques have the potential to improve the diagnostic\nperformance of colonoscopy, but the lack of 3D colonoscopy datasets for\ntraining and validation hinders their development. This paper introduces\nC3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video\nDataset, featuring enhanced realism designed to facilitate the quantitative\nevaluation of 3D colon reconstruction algorithms. 192 video sequences were\ncaptured by imaging 60 unique, high-fidelity silicone colon phantom segments.\nGround truth depth, surface normals, optical flow, occlusion,\nsix-degree-of-freedom pose, coverage maps, and 3D models are provided for 169\ncolonoscopy videos. Eight simulated screening colonoscopy videos acquired by a\ngastroenterologist are provided with ground truth poses. The dataset includes\n15 videos featuring colon deformations for qualitative assessment. C3VDv2\nemulates diverse and challenging scenarios for 3D reconstruction algorithms,\nincluding fecal debris, mucous pools, blood, debris obscuring the colonoscope\nlens, en-face views, and fast camera motion. The enhanced realism of C3VDv2\nwill allow for more robust and representative development and evaluation of 3D\nreconstruction algorithms.", "published": "2025-06-30 17:29:06", "link": "http://arxiv.org/abs/2506.24074v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios", "abstract": "In practice, environments constantly change over time and space, posing\nsignificant challenges for object detectors trained based on a closed-set\nassumption, i.e., training and test data share the same distribution. To this\nend, continual test-time adaptation has attracted much attention, aiming to\nimprove detectors' generalization by fine-tuning a few specific parameters,\ne.g., BatchNorm layers. However, based on a small number of test images,\nfine-tuning certain parameters may affect the representation ability of other\nfixed parameters, leading to performance degradation. Instead, we explore a new\nmechanism, i.e., converting the fine-tuning process to a specific-parameter\ngeneration. Particularly, we first design a dual-path LoRA-based domain-aware\nadapter that disentangles features into domain-invariant and domain-specific\ncomponents, enabling efficient adaptation. Additionally, a conditional\ndiffusion-based parameter generation mechanism is presented to synthesize the\nadapter's parameters based on the current environment, preventing the\noptimization from getting stuck in local optima. Finally, we propose a\nclass-centered optimal transport alignment method to mitigate catastrophic\nforgetting. Extensive experiments conducted on various continuous domain\nadaptive object detection tasks demonstrate the effectiveness. Meanwhile,\nvisualization results show that the representation extracted by the generated\nparameters can capture more object-related information and strengthen the\ngeneralization ability.", "published": "2025-06-30 17:14:12", "link": "http://arxiv.org/abs/2506.24063v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data", "abstract": "Zero-shot and prompt-based technologies capitalized on using frequently\noccurring images to transform visual reasoning tasks, which explains why such\ntechnologies struggle with valuable yet scarce scientific image sets. In this\nwork, we propose Zenesis, a comprehensive no-code interactive platform designed\nto minimize barriers posed by data readiness for scientific images. We develop\nlightweight multi-modal adaptation techniques that enable zero-shot operation\non raw scientific data, along with human-in-the-loop refinement and\nheuristic-based temporal enhancement options. We demonstrate the performance of\nour approach through comprehensive comparison and validation on challenging\nFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded\nmembranes. Zenesis significantly outperforms baseline methods, achieving an\naverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a\nDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an\nIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results\nmark a substantial improvement over traditional methods like Otsu thresholding\nand even advanced models like Segment Anything Model (SAM) when used in\nisolation. Our results demonstrate that Zenesis is a powerful tool for\nscientific applications, particularly in fields where high-quality annotated\ndatasets are unavailable, accelerating accurate analysis of experimental\nimaging.", "published": "2025-06-30 16:45:23", "link": "http://arxiv.org/abs/2506.24039v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Supervised Diffusion-Model-Based PET Image Reconstruction", "abstract": "Diffusion models (DMs) have recently been introduced as a regularizing prior\nfor PET image reconstruction, integrating DMs trained on high-quality PET\nimages with unsupervised schemes that condition on measured data. While these\napproaches have potential generalization advantages due to their independence\nfrom the scanner geometry and the injected activity level, they forgo the\nopportunity to explicitly model the interaction between the DM prior and noisy\nmeasurement data, potentially limiting reconstruction accuracy. To address\nthis, we propose a supervised DM-based algorithm for PET reconstruction. Our\nmethod enforces the non-negativity of PET's Poisson likelihood model and\naccommodates the wide intensity range of PET images. Through experiments on\nrealistic brain PET phantoms, we demonstrate that our approach outperforms or\nmatches state-of-the-art deep learning-based methods quantitatively across a\nrange of dose levels. We further conduct ablation studies to demonstrate the\nbenefits of the proposed components in our model, as well as its dependence on\ntraining data, parameter count, and number of diffusion steps. Additionally, we\nshow that our approach enables more accurate posterior sampling than\nunsupervised DM-based methods, suggesting improved uncertainty estimation.\nFinally, we extend our methodology to a practical approach for fully 3D PET and\npresent example results from real [$^{18}$F]FDG brain PET data.", "published": "2025-06-30 16:39:50", "link": "http://arxiv.org/abs/2506.24034v1", "categories": ["physics.med-ph", "cs.CV"], "primary_category": "physics.med-ph"}
{"title": "ShapeKit", "abstract": "In this paper, we present a practical approach to improve anatomical shape\naccuracy in whole-body medical segmentation. Our analysis shows that a\nshape-focused toolkit can enhance segmentation performance by over 8%, without\nthe need for model re-training or fine-tuning. In comparison, modifications to\nmodel architecture typically lead to marginal gains of less than 3%. Motivated\nby this observation, we introduce ShapeKit, a flexible and easy-to-integrate\ntoolkit designed to refine anatomical shapes. This work highlights the\nunderappreciated value of shape-based tools and calls attention to their\npotential impact within the medical segmentation community.", "published": "2025-06-30 16:07:33", "link": "http://arxiv.org/abs/2506.24003v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models", "abstract": "Test-time adaptation (TTA) methods have gained significant attention for\nenhancing the performance of vision-language models (VLMs) such as CLIP during\ninference, without requiring additional labeled data. However, current TTA\nresearches generally suffer from major limitations such as duplication of\nbaseline results, limited evaluation metrics, inconsistent experimental\nsettings, and insufficient analysis. These problems hinder fair comparisons\nbetween TTA methods and obscure their practical strengths and weaknesses. To\naddress these challenges, we introduce TTA-VLM, a comprehensive benchmark for\nevaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7\nonline TTA methods within a unified and reproducible framework, and evaluates\nthem across 15 widely used datasets. Unlike prior studies focused solely on\nCLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid\nloss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA\nto assess generality. Beyond classification accuracy, TTA-VLM incorporates\nvarious evaluation metrics, including robustness, calibration,\nout-of-distribution detection, and stability, enabling a more holistic\nassessment of TTA methods. Through extensive experiments, we find that 1)\nexisting TTA methods produce limited gains compared to the previous pioneering\nwork; 2) current TTA methods exhibit poor collaboration with training-time\nfine-tuning methods; 3) accuracy gains frequently come at the cost of reduced\nmodel trustworthiness. We release TTA-VLM to provide fair comparison and\ncomprehensive evaluation of TTA methods for VLMs, and we hope it encourages the\ncommunity to develop more reliable and generalizable TTA strategies.", "published": "2025-06-30 16:05:55", "link": "http://arxiv.org/abs/2506.24000v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving", "abstract": "While personalization has been explored in traditional autonomous driving\nsystems, it remains largely overlooked in end-to-end autonomous driving\n(E2EAD), despite its growing prominence. This gap is critical, as user-aligned\nbehavior is essential for trust, comfort, and widespread adoption of autonomous\nvehicles. A core challenge is the lack of large-scale real-world datasets\nannotated with diverse and fine-grained driving preferences, hindering the\ndevelopment and evaluation of personalized E2EAD models. In this work, we\npresent the first large-scale real-world dataset enriched with annotations\ncapturing diverse driving preferences, establishing a foundation for\npersonalization in E2EAD. We extract static environmental features from\nreal-world road topology and infer dynamic contextual cues using a fine-tuned\nvisual language model (VLM), enabling consistent and fine-grained scenario\nconstruction. Based on these scenarios, we derive objective preference\nannotations through behavioral distribution analysis and rule-based heuristics.\nTo address the inherent subjectivity of driving style, we further employ the\nVLM to generate subjective annotations by jointly modeling scene semantics and\ndriver behavior. Final high-quality labels are obtained through a\nhuman-in-the-loop verification process that fuses both perspectives. Building\non this dataset, we propose the first benchmark for evaluating personalized\nE2EAD models. We assess several state-of-the-art models with and without\npreference conditioning, demonstrating that incorporating personalized\npreferences results in behavior more aligned with human driving. Our work lays\nthe foundation for personalized E2EAD by providing a standardized platform to\nsystematically integrate human preferences into data-driven E2EAD systems,\ncatalyzing future research in human-centric autonomy.", "published": "2025-06-30 15:48:38", "link": "http://arxiv.org/abs/2506.23982v1", "categories": ["cs.CV", "cs.RO", "I.4.9"], "primary_category": "cs.CV"}
{"title": "Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance", "abstract": "Understanding why a classification model prefers one class over another for\nan input instance is the challenge of contrastive explanation. This work\nimplements concept-based contrastive explanations for image classification by\nleveraging the similarity of instance embeddings and relevance of\nhuman-understandable concepts used by a fine-tuned deep learning model. Our\napproach extracts concepts with their relevance score, computes contrasts for\nsimilar instances, and evaluates the resulting contrastive explanations based\non explanation complexity. Robustness is tested for different image\naugmentations. Two research questions are addressed: (1) whether explanation\ncomplexity varies across different relevance ranges, and (2) whether\nexplanation complexity remains consistent under image augmentations such as\nrotation and noise. The results confirm that for our experiments higher concept\nrelevance leads to shorter, less complex explanations, while lower relevance\nresults in longer, more diffuse explanations. Additionally, explanations show\nvarying degrees of robustness. The discussion of these findings offers insights\ninto the potential of building more interpretable and robust AI systems.", "published": "2025-06-30 15:41:43", "link": "http://arxiv.org/abs/2506.23975v1", "categories": ["cs.CV", "68T07", "I.2; I.4"], "primary_category": "cs.CV"}
{"title": "Visual and Memory Dual Adapter for Multi-Modal Object Tracking", "abstract": "Prompt-learning-based multi-modal trackers have achieved promising progress\nby employing lightweight visual adapters to incorporate auxiliary modality\nfeatures into frozen foundation models. However, existing approaches often\nstruggle to learn reliable prompts due to limited exploitation of critical cues\nacross frequency and temporal domains. In this paper, we propose a novel visual\nand memory dual adapter (VMDA) to construct more robust and discriminative\nrepresentations for multi-modal tracking. Specifically, we develop a simple but\neffective visual adapter that adaptively transfers discriminative cues from\nauxiliary modality to dominant modality by jointly modeling the frequency,\nspatial, and channel-wise features. Additionally, we design the memory adapter\ninspired by the human memory mechanism, which stores global temporal cues and\nperforms dynamic update and retrieval operations to ensure the consistent\npropagation of reliable temporal information across video sequences. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\non the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,\nand RGB-Event tracking. Code and models are available at\nhttps://github.com/xuboyue1999/mmtrack.git.", "published": "2025-06-30 15:38:26", "link": "http://arxiv.org/abs/2506.23972v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evaluating the Impact of Khmer Font Types on Text Recognition", "abstract": "Text recognition is significantly influenced by font types, especially for\ncomplex scripts like Khmer. The variety of Khmer fonts, each with its unique\ncharacter structure, presents challenges for optical character recognition\n(OCR) systems. In this study, we evaluate the impact of 19 randomly selected\nKhmer font types on text recognition accuracy using Pytesseract. The fonts\ninclude Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong\nChhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,\nMetal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth\nFirst. Our comparison of OCR performance across these fonts reveals that Khmer,\nOdor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,\nwhile iSeth First, Bayon, and Dangrek perform poorly. This study underscores\nthe critical importance of font selection in optimizing Khmer text recognition\nand provides valuable insights for developing more robust OCR systems.", "published": "2025-06-30 15:35:51", "link": "http://arxiv.org/abs/2506.23963v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "abstract": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study.", "published": "2025-06-30 15:24:27", "link": "http://arxiv.org/abs/2506.23957v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "abstract": "Recent progress in multimodal reasoning has been significantly advanced by\ntextual Chain-of-Thought (CoT), a paradigm where models conduct reasoning\nwithin language. This text-centric approach, however, treats vision as a\nstatic, initial context, creating a fundamental \"semantic gap\" between rich\nperceptual data and discrete symbolic thought. Human cognition often transcends\nlanguage, utilizing vision as a dynamic mental sketchpad. A similar evolution\nis now unfolding in AI, marking a fundamental paradigm shift from models that\nmerely think about images to those that can truly think with images. This\nemerging paradigm is characterized by models leveraging visual information as\nintermediate steps in their thought process, transforming vision from a passive\ninput into a dynamic, manipulable cognitive workspace. In this survey, we chart\nthis evolution of intelligence along a trajectory of increasing cognitive\nautonomy, which unfolds across three key stages: from external tool\nexploration, through programmatic manipulation, to intrinsic imagination. To\nstructure this rapidly evolving field, our survey makes four key contributions.\n(1) We establish the foundational principles of the think with image paradigm\nand its three-stage framework. (2) We provide a comprehensive review of the\ncore methods that characterize each stage of this roadmap. (3) We analyze the\ncritical landscape of evaluation benchmarks and transformative applications.\n(4) We identify significant challenges and outline promising future directions.\nBy providing this structured overview, we aim to offer a clear roadmap for\nfuture research towards more powerful and human-aligned multimodal AI.", "published": "2025-06-30 14:48:35", "link": "http://arxiv.org/abs/2506.23918v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Three-dimensional end-to-end deep learning for brain MRI analysis", "abstract": "Deep learning (DL) methods are increasingly outperforming classical\napproaches in brain imaging, yet their generalizability across diverse imaging\ncohorts remains inadequately assessed. As age and sex are key neurobiological\nmarkers in clinical neuroscience, influencing brain structure and disease risk,\nthis study evaluates three of the existing three-dimensional architectures,\nnamely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window\n(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four\nindependent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study\n(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy\ncontrols), and Information eXtraction from Images (IXI, n=319). We found that\nSFCN consistently outperformed more complex architectures with AUC of 1.00\n[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for\nsex classification. For the age prediction task, SFCN demonstrated a mean\nabsolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across\nexternal datasets. Pairwise DeLong and Wilcoxon signed-rank tests with\nBonferroni corrections confirmed SFCN's superiority over Swin Transformer\nacross most cohorts (p<0.017, for three comparisons). Explainability analysis\nfurther demonstrates the regional consistency of model attention across cohorts\nand specific to each task. Our findings reveal that simpler convolutional\nnetworks outperform the denser and more complex attention-based DL\narchitectures in brain image analysis by demonstrating better generalizability\nacross different datasets.", "published": "2025-06-30 14:44:49", "link": "http://arxiv.org/abs/2506.23916v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "abstract": "Panoramic optical flow enables a comprehensive understanding of temporal\ndynamics across wide fields of view. However, severe distortions caused by\nsphere-to-plane projections, such as the equirectangular projection (ERP),\nsignificantly degrade the performance of conventional perspective-based optical\nflow methods, especially in polar regions. To address this challenge, we\npropose PriOr-Flow, a novel dual-branch framework that leverages the\nlow-distortion nature of the orthogonal view to enhance optical flow estimation\nin these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup\n(DCCL) operator, which jointly retrieves correlation information from both the\nprimitive and orthogonal cost volumes, effectively mitigating distortion noise\nduring cost volume construction. Furthermore, our Ortho-Driven Distortion\nCompensation (ODDC) module iteratively refines motion features from both\nbranches, further suppressing polar distortions. Extensive experiments\ndemonstrate that PriOr-Flow is compatible with various perspective-based\niterative optical flow methods and consistently achieves state-of-the-art\nperformance on publicly available panoramic optical flow datasets, setting a\nnew benchmark for wide-field motion estimation. The code is publicly available\nat: https://github.com/longliangLiu/PriOr-Flow.", "published": "2025-06-30 14:30:25", "link": "http://arxiv.org/abs/2506.23897v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection", "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability\nand safety of machine learning models in real-world applications, where they\nfrequently face data distributions unseen during training. Despite progress,\nexisting methods are often vulnerable to spurious correlations that mislead\nmodels and compromise robustness. To address this, we propose SPROD, a novel\nprototype-based OOD detection approach that explicitly addresses the challenge\nposed by unknown spurious correlations. Our post-hoc method refines class\nprototypes to mitigate bias from spurious features without additional data or\nhyperparameter tuning, and is broadly applicable across diverse backbones and\nOOD detection settings. We conduct a comprehensive spurious correlation OOD\ndetection benchmarking, comparing our method against existing approaches and\ndemonstrating its superior performance across challenging OOD datasets, such as\nCelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced\nAnimals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%\nover the second best.", "published": "2025-06-30 14:10:51", "link": "http://arxiv.org/abs/2506.23881v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction", "abstract": "Multi-view 3D reconstruction remains a core challenge in computer vision.\nRecent methods, such as DUST3R and its successors, directly regress pointmaps\nfrom image pairs without relying on known scene geometry or camera parameters.\nHowever, the performance of these models is constrained by the diversity and\nscale of available training data. In this work, we introduce Puzzles, a data\naugmentation strategy that synthesizes an unbounded volume of high-quality\nposed video-depth data from a single image or video clip. By simulating diverse\ncamera trajectories and realistic scene geometry through targeted image\ntransformations, Puzzles significantly enhances data variety. Extensive\nexperiments show that integrating Puzzles into existing video-based 3D\nreconstruction pipelines consistently boosts performance without modifying the\nunderlying network architecture. Notably, models trained on only ten percent of\nthe original data augmented with Puzzles still achieve accuracy comparable to\nthose trained on the full dataset. Code is available at\nhttps://jiahao-ma.github.io/puzzles/.", "published": "2025-06-30 13:57:24", "link": "http://arxiv.org/abs/2506.23863v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VMoBA: Mixture-of-Block Attention for Video Diffusion Models", "abstract": "The quadratic complexity of full attention mechanisms poses a significant\nbottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,\nhigh-resolution videos. While various sparse attention methods have been\nproposed, many are designed as training-free inference accelerators or do not\noptimally capture the unique spatio-temporal characteristics inherent in video\ndata when trained natively. This paper introduces Video Mixture of Block\nAttention (VMoBA), a novel sparse attention mechanism specifically adapted for\nVDMs. Motivated by an in-depth analysis of attention patterns within\npre-trained video transformers, which revealed strong spatio-temporal locality,\nvarying query importance, and head-specific concentration levels, VMoBA\nenhances the original MoBA framework with three key modifications: (1) a\nlayer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to\ndiverse spatio-temporal attention patterns and improve efficiency; (2) global\nblock selection to prioritize the most salient query-key block interactions\nacross an entire attention head; and (3) threshold-based block selection to\ndynamically determine the number of attended blocks based on their cumulative\nsimilarity. Extensive experiments demonstrate that VMoBA significantly\naccelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and\n1.48x latency speedup, while attaining comparable or even superior generation\nquality to full attention. Furthermore, VMoBA exhibits competitive performance\nin training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for\nhigh-res video generation.", "published": "2025-06-30 13:52:31", "link": "http://arxiv.org/abs/2506.23858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Closer Look at Conditional Prompt Tuning for Vision-Language Models", "abstract": "Despite the great promise of Prompt Tuning (PT) in adapting large\nVision-Language Pretrained Models (VLPMs) to downstream tasks, they often\nstruggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better\ntuned to a base task, their ability to generalize to new tasks diminishes.\nRecent work on conditional PT addresses this problem by replacing static\nprompts with dynamic Visual Image Information (VII)-conditioned prompts,\nimproving the model's generalization to new tasks to some extent. In this work,\nwe first identify a critical issue with existing conditional PT methods: using\nVII as the \"condition\" of prompts yields suboptimal performance, and even\nrandom noise-conditioned prompts can outperform the VII-conditioned\ncounterparts. On further analysis, we find that learning dynamic prompts\nconditioned on Textual Class Information (TCI) is the key to solving the BNT\nproblem. Motivated by this, we then propose Class-adaptive Prompt Tuning\n(CaPT), which enables fast adaptation of tuned models to new classes by\nlearning TCI-conditioned prompts from base classes. Remarkably, CaPT can be\nused as a plugin to mitigate the BNT problem for existing unconditional PT\nschemes. Extensive experiments on 11 datasets show that CaPT consistently\nimproves the performance of five strong unconditional PT baselines with\nnegligible additional computational cost. Additionally, by integrating CaPT\nwith our recently proposed DePT framework, we devise a new conditional PT\napproach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art\nconditional PT scheme by 3.49%, averaged over the 11 datasets. Code:\nhttps://github.com/Koorye/CaPT.", "published": "2025-06-30 13:51:20", "link": "http://arxiv.org/abs/2506.23856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity", "abstract": "Neural surface reconstruction faces persistent challenges in reconciling\ngeometric fidelity with photometric consistency under complex scene conditions.\nWe present HiNeuS, a unified framework that holistically addresses three core\nlimitations in existing approaches: multi-view radiance inconsistency, missing\nkeypoints in textureless regions, and structural degradation from over-enforced\nEikonal constraints during joint optimization. To resolve these issues through\na unified pipeline, we introduce: 1) Differential visibility verification\nthrough SDF-guided ray tracing, resolving reflection ambiguities via continuous\nocclusion modeling; 2) Planar-conformal regularization via ray-aligned geometry\npatches that enforce local surface coherence while preserving sharp edges\nthrough adaptive appearance weighting; and 3) Physically-grounded Eikonal\nrelaxation that dynamically modulates geometric constraints based on local\nradiance gradients, enabling detail preservation without sacrificing global\nregularity. Unlike prior methods that handle these aspects through sequential\noptimizations or isolated modules, our approach achieves cohesive integration\nwhere appearance-geometry constraints evolve synergistically throughout\ntraining. Comprehensive evaluations across synthetic and real-world datasets\ndemonstrate state-of-the-art performance, including a 21.4% reduction in\nChamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement\nagainst neural rendering counterparts. Qualitative analyses reveal superior\ncapability in recovering specular instruments, urban layouts with\ncentimeter-scale infrastructure, and low-textured surfaces without local patch\ncollapse. The method's generalizability is further validated through successful\napplication to inverse rendering tasks, including material decomposition and\nview-consistent relighting.", "published": "2025-06-30 13:45:25", "link": "http://arxiv.org/abs/2506.23854v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment", "abstract": "As camera-equipped robotic platforms become increasingly integrated into\ndaily life, robotic-generated videos have begun to appear on streaming media\nplatforms, enabling us to envision a future where humans and robots coexist. We\ninnovatively propose the concept of Robotic-Generated Content (RGC) to term\nthese videos generated from egocentric perspective of robots. The perceptual\nquality of RGC videos is critical in human-robot interaction scenarios, and RGC\nvideos exhibit unique distortions and visual requirements that differ markedly\nfrom those of professionally-generated content (PGC) videos and user-generated\ncontent (UGC) videos. However, dedicated research on quality assessment of RGC\nvideos is still lacking. To address this gap and to support broader robotic\napplications, we establish the first Robotic-Generated Content Database (RGCD),\nwhich contains a total of 2,100 videos drawn from three robot categories and\nsourced from diverse platforms. A subjective VQA experiment is conducted\nsubsequently to assess human visual perception of robotic-generated videos.\nFinally, we conduct a benchmark experiment to evaluate the performance of 11\nstate-of-the-art VQA models on our database. Experimental results reveal\nsignificant limitations in existing VQA models when applied to complex,\nrobotic-generated content, highlighting a critical need for RGC-specific VQA\nmodels. Our RGCD is publicly available at:\nhttps://github.com/IntMeGroup/RGC-VQA.", "published": "2025-06-30 13:44:30", "link": "http://arxiv.org/abs/2506.23852v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Refine Any Object in Any Scene", "abstract": "Viewpoint missing of objects is common in scene reconstruction, as camera\npaths typically prioritize capturing the overall scene structure rather than\nindividual objects. This makes it highly challenging to achieve high-fidelity\nobject-level modeling while maintaining accurate scene-level representation.\nAddressing this issue is critical for advancing downstream tasks requiring\ndetailed object understanding and appearance modeling. In this paper, we\nintroduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement\nframework that leverages 3D generative priors to recover fine-grained object\ngeometry and appearance under missing views. Starting from substituting\ndegraded objects with proxies, via a 3D generative model with strong 3D\nunderstanding, RAISE progressively refines geometry and texture by aligning\neach proxy to its degraded counterpart in 7-DOF pose, followed by correcting\nspatial and appearance inconsistencies via registration-constrained\nenhancement. This two-stage refinement ensures the high-fidelity geometry and\nappearance of the original object in unseen views while maintaining consistency\nin spatial positioning, observed geometry, and appearance. Extensive\nexperiments on challenging benchmarks show that RAISE significantly outperforms\nstate-of-the-art methods in both novel view synthesis and geometry completion\ntasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.", "published": "2025-06-30 13:26:21", "link": "http://arxiv.org/abs/2506.23835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric", "abstract": "This paper presents PointSSIM, a novel low-dimensional image-to-image\ncomparison metric that is resolution invariant. Drawing inspiration from the\nstructural similarity index measure and mathematical morphology, PointSSIM\nenables robust comparison across binary images of varying resolutions by\ntransforming them into marked point pattern representations. The key features\nof the image, referred to as anchor points, are extracted from binary images by\nidentifying locally adaptive maxima from the minimal distance transform. Image\ncomparisons are then performed using a summary vector, capturing intensity,\nconnectivity, complexity, and structural attributes. Results show that this\napproach provides an efficient and reliable method for image comparison,\nparticularly suited to applications requiring structural analysis across\ndifferent resolutions.", "published": "2025-06-30 13:24:43", "link": "http://arxiv.org/abs/2506.23833v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Low-latency vision transformers via large-scale multi-head attention", "abstract": "The emergence of spontaneous symmetry breaking among a few heads of\nmulti-head attention (MHA) across transformer blocks in classification tasks\nwas recently demonstrated through the quantification of single-nodal\nperformance (SNP). This finding indicates that each head focuses its attention\non a subset of labels through cooperation among its SNPs. This underlying\nlearning mechanism is generalized to large-scale MHA (LS-MHA) using a single\nmatrix value representing single-head performance (SHP), analogous to\nsingle-filter performance in convolutional neural networks (CNNs). The results\nindicate that each SHP matrix comprises multiple unit clusters such that each\nlabel being explicitly recognized by a few heads with negligible noise. This\nleads to an increased signal-to-noise ratio (SNR) along the transformer blocks,\nthereby improving classification accuracy. These features give rise to several\ndistinct vision transformer (ViT) architectures that achieve the same accuracy\nbut differ in their LS-MHA structures. As a result, their soft committee yields\nsuperior accuracy, an outcome not typically observed in CNNs which rely on\nhundreds of filters. In addition, a significant reduction in latency is\nachieved without affecting the accuracy by replacing the initial transformer\nblocks with convolutional layers. This substitution accelerates early-stage\nlearning, which is then improved by subsequent transformer layers. The\nextension of this learning mechanism to natural language processing tasks,\nbased on quantitative differences between CNNs and ViT architectures, has the\npotential to yield new insights in deep learning. The findings are demonstrated\nusing compact convolutional transformer architectures trained on the CIFAR-100\ndataset.", "published": "2025-06-30 13:23:46", "link": "http://arxiv.org/abs/2506.23832v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning", "abstract": "Spatial transcriptomics (ST) provides crucial insights into tissue\nmicro-environments, but is limited to its high cost and complexity. As an\nalternative, predicting gene expression from pathology whole slide images (WSI)\nis gaining increasing attention. However, existing methods typically rely on\nsingle patches or a single pathology modality, neglecting the complex spatial\nand molecular interactions between target and neighboring information (e.g.,\ngene co-expression). This leads to a failure in establishing connections among\nadjacent regions and capturing intricate cross-modal relationships. To address\nthese issues, we propose NH2ST, a framework that integrates spatial context and\nboth pathology and gene modalities for gene expression prediction. Our model\ncomprises a query branch and a neighbor branch to process paired target patch\nand gene data and their neighboring regions, where cross-attention and\ncontrastive learning are employed to capture intrinsic associations and ensure\nalignments between pathology and gene expression. Extensive experiments on six\ndatasets demonstrate that our model consistently outperforms existing methods,\nachieving over 20% in PCC metrics. Codes are available at\nhttps://github.com/MCPathology/NH2ST", "published": "2025-06-30 13:18:39", "link": "http://arxiv.org/abs/2506.23827v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Flash-VStream: Efficient Real-Time Understanding for Long Video Streams", "abstract": "Benefiting from the advances in large language models and cross-modal\nalignment, existing multimodal large language models have achieved prominent\nperformance in image and short video understanding. However, the understanding\nof long videos is still challenging, as their long-context nature results in\nsignificant computational and memory overhead. Most existing work treats long\nvideos in the same way as short videos, which is inefficient for real-world\napplications and hard to generalize to even longer videos. To address these\nissues, we propose Flash-VStream, an efficient video language model capable of\nprocessing extremely long videos and responding to user queries in real time.\nParticularly, we design a Flash Memory module, containing a low-capacity\ncontext memory to aggregate long-context temporal information and model the\ndistribution of information density, and a high-capacity augmentation memory to\nretrieve detailed spatial information based on this distribution. Compared to\nexisting models, Flash-VStream achieves significant reductions in inference\nlatency. Extensive experiments on long video benchmarks and comprehensive video\nbenchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate\nthe state-of-the-art performance and outstanding efficiency of our method. Code\nis available at https://github.com/IVGSZ/Flash-VStream.", "published": "2025-06-30 13:17:49", "link": "http://arxiv.org/abs/2506.23825v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Supercm: Revisiting Clustering for Semi-Supervised Learning", "abstract": "The development of semi-supervised learning (SSL) has in recent years largely\nfocused on the development of new consistency regularization or entropy\nminimization approaches, often resulting in models with complex training\nstrategies to obtain the desired results. In this work, we instead propose a\nnovel approach that explicitly incorporates the underlying clustering\nassumption in SSL through extending a recently proposed differentiable\nclustering module. Leveraging annotated data to guide the cluster centroids\nresults in a simple end-to-end trainable deep SSL approach. We demonstrate that\nthe proposed model improves the performance over the supervised-only baseline\nand show that our framework can be used in conjunction with other SSL methods\nto further boost their performance.", "published": "2025-06-30 13:17:08", "link": "http://arxiv.org/abs/2506.23824v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model", "abstract": "Large-scale vision-language models (VLMs), such as CLIP, have achieved\nremarkable success in zero-shot learning (ZSL) by leveraging large-scale\nvisual-text pair datasets. However, these methods often lack interpretability,\nas they compute the similarity between an entire query image and the embedded\ncategory words, making it difficult to explain their predictions. One approach\nto address this issue is to develop interpretable models by integrating\nlanguage, where classifiers are built using discrete attributes, similar to\nhuman perception. This introduces a new challenge: how to effectively align\nlocal visual features with corresponding attributes based on pre-trained VLMs.\nTo tackle this, we propose LaZSL, a locally-aligned vision-language model for\ninterpretable ZSL. LaZSL employs local visual-semantic alignment via optimal\ntransport to perform interaction between visual regions and their associated\nattributes, facilitating effective alignment and providing interpretable\nsimilarity without the need for additional training. Extensive experiments\ndemonstrate that our method offers several advantages, including enhanced\ninterpretability, improved accuracy, and strong domain generalization. Codes\navailable at: https://github.com/shiming-chen/LaZSL.", "published": "2025-06-30 13:14:46", "link": "http://arxiv.org/abs/2506.23822v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MadCLIP: Few-shot Medical Anomaly Detection with CLIP", "abstract": "An innovative few-shot anomaly detection approach is presented, leveraging\nthe pre-trained CLIP model for medical data, and adapting it for both\nimage-level anomaly classification (AC) and pixel-level anomaly segmentation\n(AS). A dual-branch design is proposed to separately capture normal and\nabnormal features through learnable adapters in the CLIP vision encoder. To\nimprove semantic alignment, learnable text prompts are employed to link visual\nfeatures. Furthermore, SigLIP loss is applied to effectively handle the\nmany-to-one relationship between images and unpaired text prompts, showcasing\nits adaptation in the medical field for the first time. Our approach is\nvalidated on multiple modalities, demonstrating superior performance over\nexisting methods for AC and AS, in both same-dataset and cross-dataset\nevaluations. Unlike prior work, it does not rely on synthetic data or memory\nbanks, and an ablation study confirms the contribution of each component. The\ncode is available at https://github.com/mahshid1998/MadCLIP.", "published": "2025-06-30 12:56:17", "link": "http://arxiv.org/abs/2506.23810v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Initialization-free Calibrated Bundle Adjustment", "abstract": "A recent series of works has shown that initialization-free BA can be\nachieved using pseudo Object Space Error (pOSE) as a surrogate objective. The\ninitial reconstruction-step optimizes an objective where all terms are\nprojectively invariant and it cannot incorporate knowledge of the camera\ncalibration. As a result, the solution is only determined up to a projective\ntransformation of the scene and the process requires more data for successful\nreconstruction.\n  In contrast, we present a method that is able to use the known camera\ncalibration thereby producing near metric solutions, that is, reconstructions\nthat are accurate up to a similarity transformation. To achieve this we\nintroduce pairwise relative rotation estimates that carry information about\ncamera calibration. These are only invariant to similarity transformations,\nthus encouraging solutions that preserve metric features of the real scene. Our\nmethod can be seen as integrating rotation averaging into the pOSE framework\nstriving towards initialization-free calibrated SfM.\n  Our experimental evaluation shows that we are able to reliably optimize our\nobjective, achieving convergence to the global minimum with high probability\nfrom random starting solutions, resulting in accurate near metric\nreconstructions.", "published": "2025-06-30 12:55:44", "link": "http://arxiv.org/abs/2506.23808v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors", "abstract": "Super-resolution (SR) techniques can enhance the spatial resolution of remote\nsensing images by utilizing low-resolution (LR) images to reconstruct\nhigh-resolution (HR) images, enabling more efficient large-scale earth\nobservation applications. While single-image super-resolution (SISR) methods\nhave shown progress, reference-based super-resolution (RefSR) offers superior\nperformance by incorporating historical HR images alongside current LR\nobservations. However, existing RefSR methods struggle with real-world\ncomplexities, such as cross-sensor resolution gap and significant land cover\nchanges, often leading to under-generation or over-reliance on reference image.\nTo address these challenges, we propose CRefDiff, a novel controllable\nreference-based diffusion model for real-world remote sensing image SR. To\naddress the under-generation problem, CRefDiff is built upon the pretrained\nStable Diffusion model, leveraging its powerful generative prior to produce\naccurate structures and textures. To mitigate over-reliance on the reference,\nwe introduce a dual-branch fusion mechanism that adaptively integrates both\nlocal and global information from the reference image. Moreover, this novel\ndual-branch design enables reference strength control during inference,\nenhancing interactivity and flexibility of the model. Finally, a strategy named\nBetter Start is proposed to significantly reduce the number of denoising steps,\nthereby accelerating the inference process. To support further research, we\nintroduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing\nimages, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land\ncover changes and significant temporal gaps. Extensive experiments on\nReal-RefRSSRD show that CRefDiff achieves state-of-the-art performance across\nvarious metrics and improves downstream tasks such as scene classification and\nsemantic segmentation.", "published": "2025-06-30 12:45:28", "link": "http://arxiv.org/abs/2506.23801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Textualization for Image Prompted Object Detection", "abstract": "We propose VisTex-OVLM, a novel image prompted object detection method that\nintroduces visual textualization -- a process that projects a few visual\nexemplars into the text feature space to enhance Object-level Vision-Language\nModels' (OVLMs) capability in detecting rare categories that are difficult to\ndescribe textually and nearly absent from their pre-training data, while\npreserving their pre-trained object-text alignment. Specifically, VisTex-OVLM\nleverages multi-scale textualizing blocks and a multi-stage fusion strategy to\nintegrate visual information from visual exemplars, generating textualized\nvisual tokens that effectively guide OVLMs alongside text prompts. Unlike\nprevious methods, our method maintains the original architecture of OVLM,\nmaintaining its generalization capabilities while enhancing performance in\nfew-shot settings. VisTex-OVLM demonstrates superior performance across\nopen-set datasets which have minimal overlap with OVLM's pre-training data and\nachieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.\nThe code will be released at https://github.com/WitGotFlg/VisTex-OVLM.", "published": "2025-06-30 12:27:35", "link": "http://arxiv.org/abs/2506.23785v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos", "abstract": "Surgical instrument segmentation under Federated Learning (FL) is a promising\ndirection, which enables multiple surgical sites to collaboratively train the\nmodel without centralizing datasets. However, there exist very limited FL works\nin surgical data science, and FL methods for other modalities do not consider\ninherent characteristics in surgical domain: i) different scenarios show\ndiverse anatomical backgrounds while highly similar instrument representation;\nii) there exist surgical simulators which promote large-scale synthetic data\ngeneration with minimal efforts. In this paper, we propose a novel Personalized\nFL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),\nwhich wisely leverages surgical domain knowledge during both local-site and\nglobal-server training to boost segmentation. Concretely, our model embraces a\nRepresentation Separation and Cooperation (RSC) mechanism in local-site\ntraining, which decouples the query embedding layer to be trained privately, to\nencode respective backgrounds. Meanwhile, other parameters are optimized\nglobally to capture the consistent representations of instruments, including\nthe temporal layer to capture similar motion patterns. A textual-guided channel\nselection is further designed to highlight site-specific features, facilitating\nmodel adapta tion to each site. Moreover, in global-server training, we propose\nSynthesis-based Explicit Representation Quantification (SERQ), which defines an\nexplicit representation target based on synthetic data to synchronize the model\nconvergence during fusion for improving model generalization.", "published": "2025-06-30 12:08:02", "link": "http://arxiv.org/abs/2506.23759v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?", "abstract": "Open-vocabulary object detectors such as Grounding DINO are trained on vast\nand diverse data, achieving remarkable performance on challenging datasets. Due\nto that, it is unclear where to find their limitations, which is of major\nconcern when using in safety-critical applications. Real-world data does not\nprovide sufficient control, required for a rigorous evaluation of model\ngeneralization. In contrast, synthetically generated data allows to\nsystematically explore the boundaries of model competence/generalization. In\nthis work, we address two research questions: 1) Can we challenge\nopen-vocabulary object detectors with generated image content? 2) Can we find\nsystematic failure modes of those models? To address these questions, we design\ntwo automated pipelines using stable diffusion to inpaint unusual objects with\nhigh diversity in semantics, by sampling multiple substantives from WordNet and\nChatGPT. On the synthetically generated data, we evaluate and compare multiple\nopen-vocabulary object detectors as well as a classical object detector. The\nsynthetic data is derived from two real-world datasets, namely LostAndFound, a\nchallenging out-of-distribution (OOD) detection benchmark, and the NuImages\ndataset. Our results indicate that inpainting can challenge open-vocabulary\nobject detectors in terms of overlooking objects. Additionally, we find a\nstrong dependence of open-vocabulary models on object location, rather than on\nobject semantics. This provides a systematic approach to challenge\nopen-vocabulary models and gives valuable insights on how data could be\nacquired to effectively improve these models.", "published": "2025-06-30 11:48:44", "link": "http://arxiv.org/abs/2506.23751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models", "abstract": "Image generative models have become increasingly popular, but training them\nrequires large datasets that are costly to collect and curate. To circumvent\nthese costs, some parties may exploit existing models by using the generated\nimages as training data for their own models. In general, watermarking is a\nvaluable tool for detecting unauthorized use of generated images. However, when\nthese images are used to train a new model, watermarking can only enable\ndetection if the watermark persists through training and remains identifiable\nin the outputs of the newly trained model - a property known as radioactivity.\nWe analyze the radioactivity of watermarks in images generated by diffusion\nmodels (DMs) and image autoregressive models (IARs). We find that existing\nwatermarking methods for DMs fail to retain radioactivity, as watermarks are\neither erased during encoding into the latent space or lost in the\nnoising-denoising process (during the training in the latent space). Meanwhile,\ndespite IARs having recently surpassed DMs in image generation quality and\nefficiency, no radioactive watermarking methods have been proposed for them. To\novercome this limitation, we propose the first watermarking method tailored for\nIARs and with radioactivity in mind - drawing inspiration from techniques in\nlarge language models (LLMs), which share IARs' autoregressive paradigm. Our\nextensive experimental evaluation highlights our method's effectiveness in\npreserving radioactivity within IARs, enabling robust provenance tracking, and\npreventing unauthorized use of their generated images.", "published": "2025-06-30 11:08:10", "link": "http://arxiv.org/abs/2506.23731v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Proteus-ID: ID-Consistent and Motion-Coherent Video Customization", "abstract": "Video identity customization seeks to synthesize realistic, temporally\ncoherent videos of a specific subject, given a single reference image and a\ntext prompt. This task presents two core challenges: (1) maintaining identity\nconsistency while aligning with the described appearance and actions, and (2)\ngenerating natural, fluid motion without unrealistic stiffness. To address\nthese challenges, we introduce Proteus-ID, a novel diffusion-based framework\nfor identity-consistent and motion-coherent video customization. First, we\npropose a Multimodal Identity Fusion (MIF) module that unifies visual and\ntextual cues into a joint identity representation using a Q-Former, providing\ncoherent guidance to the diffusion model and eliminating modality imbalance.\nSecond, we present a Time-Aware Identity Injection (TAII) mechanism that\ndynamically modulates identity conditioning across denoising steps, improving\nfine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a\nself-supervised strategy that reweights the training loss based on\noptical-flow-derived motion heatmaps, enhancing motion realism without\nrequiring additional inputs. To support this task, we construct Proteus-Bench,\na high-quality dataset comprising 200K curated clips for training and 150\nindividuals from diverse professions and ethnicities for evaluation. Extensive\nexperiments demonstrate that Proteus-ID outperforms prior methods in identity\npreservation, text alignment, and motion quality, establishing a new benchmark\nfor video identity customization. Codes and data are publicly available at\nhttps://grenoble-zhang.github.io/Proteus-ID/.", "published": "2025-06-30 11:05:32", "link": "http://arxiv.org/abs/2506.23729v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion", "abstract": "We propose Subjective Camera, a human-as-imaging-device paradigm that\nreconstructs real-world scenes from mental impressions through synergistic use\nof verbal descriptions and progressive rough sketches. This approach overcomes\ndual limitations of language ambiguity and sketch abstraction by treating the\nuser's drawing sequence as priors, effectively translating subjective\nperceptual expectations into photorealistic images.\n  Existing approaches face three fundamental barriers: (1) user-specific\nsubjective input biases, (2) huge modality gap between planar sketch and 3D\npriors in diffusion, and (3) sketch quality-sensitive performance degradation.\nCurrent solutions either demand resource-intensive model adaptation or impose\nimpractical requirements on sketch precision.\n  Our framework addresses these challenges through concept-sequential\ngeneration. (1) We establish robust appearance priors through text-reward\noptimization, and then implement sequence-aware disentangled generation that\nprocesses concepts in sketching order; these steps accommodate user-specific\nsubjective expectation in a train-free way. (2) We employ latent optimization\nthat effectively bridges the modality gap between planar sketches and 3D priors\nin diffusion. (3) Our hierarchical reward-guided framework enables the use of\nrough sketches without demanding artistic expertise. Comprehensive evaluation\nacross diverse datasets demonstrates that our approach achieves\nstate-of-the-art performance in maintaining both semantic and spatial\ncoherence.", "published": "2025-06-30 10:36:49", "link": "http://arxiv.org/abs/2506.23711v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Single Image Test-Time Adaptation via Multi-View Co-Training", "abstract": "Test-time adaptation enables a trained model to adjust to a new domain during\ninference, making it particularly valuable in clinical settings where such\non-the-fly adaptation is required. However, existing techniques depend on large\ntarget domain datasets, which are often impractical and unavailable in medical\nscenarios that demand per-patient, real-time inference. Moreover, current\nmethods commonly focus on two-dimensional images, failing to leverage the\nvolumetric richness of medical imaging data. Bridging this gap, we propose a\nPatch-Based Multi-View Co-Training method for Single Image Test-Time\nadaptation. Our method enforces feature and prediction consistency through\nuncertainty-guided self-training, enabling effective volumetric segmentation in\nthe target domain with only a single test-time image. Validated on three\npublicly available breast magnetic resonance imaging datasets for tumor\nsegmentation, our method achieves performance close to the upper bound\nsupervised benchmark while also outperforming all existing state-of-the-art\nmethods, on average by a Dice Similarity Coefficient of 3.75%. We publicly\nshare our accessible codebase, readily integrable with the popular nnUNet\nframework, at https://github.com/smriti-joshi/muvi.git.", "published": "2025-06-30 10:29:33", "link": "http://arxiv.org/abs/2506.23705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction", "abstract": "Magnetic Resonance Imaging (MRI) reconstruction is essential in medical\ndiagnostics. As the latest generative models, diffusion models (DMs) have\nstruggled to produce high-fidelity images due to their stochastic nature in\nimage domains. Latent diffusion models (LDMs) yield both compact and detailed\nprior knowledge in latent domains, which could effectively guide the model\ntowards more effective learning of the original data distribution. Inspired by\nthis, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by\npre-trained LDMs to enhance data consistency in MRI reconstruction tasks.\nSpecifically, we first construct a Visual-Mamba-based backbone, which enables\nefficient encoding and reconstruction of under-sampled images. Then pre-trained\nLDMs are integrated to provide conditional priors in both latent and image\ndomains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion\nin multi-level latent domains. Simultaneously, to effectively utilize a prior\nin both the k-space and image domain, under-sampled images are fused with\ngenerated full-sampled images by the Dual-domain Fusion Branch (DFB) for\nself-adaption guidance. Lastly, to further enhance the data consistency, we\npropose a k-space regularization strategy based on the non-auto-calibration\nsignal (NACS) set. Extensive experiments on two public MRI datasets fully\ndemonstrate the effectiveness of the proposed methodology. The code is\navailable at https://github.com/Zolento/MDPG.", "published": "2025-06-30 10:25:08", "link": "http://arxiv.org/abs/2506.23701v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation", "abstract": "Medical image segmentation plays a crucial role in clinical diagnosis and\ntreatment planning, where accurate boundary delineation is essential for\nprecise lesion localization, organ identification, and quantitative assessment.\nIn recent years, deep learning-based methods have significantly advanced\nsegmentation accuracy. However, two major challenges remain. First, the\nperformance of these methods heavily relies on large-scale annotated datasets,\nwhich are often difficult to obtain in medical scenarios due to privacy\nconcerns and high annotation costs. Second, clinically challenging scenarios,\nsuch as low contrast in certain imaging modalities and blurry lesion boundaries\ncaused by malignancy, still pose obstacles to precise segmentation. To address\nthese challenges, we propose MedSAM-CA, an architecture-level fine-tuning\napproach that mitigates reliance on extensive manual annotations by adapting\nthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA\nintroduces two key components: the Convolutional Attention-Enhanced Boundary\nRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block\n(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover\nboundary information potentially overlooked by long-range attention mechanisms,\nleveraging hierarchical convolutional processing. Atte-FFB, embedded in the\nMedSAM decoder, fuses multi-level fine-grained features from skip connections\nin CBR-Net with global representations upsampled within the decoder to enhance\nboundary delineation accuracy. Experiments on publicly available datasets\ncovering dermoscopy, CT, and MRI imaging modalities validate the effectiveness\nof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only\n2% of full training data, reaching 97.25% of full-data training performance,\ndemonstrating strong effectiveness in low-resource clinical settings.", "published": "2025-06-30 10:24:29", "link": "http://arxiv.org/abs/2506.23700v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation", "abstract": "Diffusion-based video motion customization facilitates the acquisition of\nhuman motion representations from a few video samples, while achieving\narbitrary subjects transfer through precise textual conditioning. Existing\napproaches often rely on semantic-level alignment, expecting the model to learn\nnew motion concepts and combine them with other entities (e.g., ''cats'' or\n''dogs'') to produce visually appealing results. However, video data involve\ncomplex spatio-temporal patterns, and focusing solely on semantics cause the\nmodel to overlook the visual complexity of motion. Conversely, tuning only the\nvisual representation leads to semantic confusion in representing the intended\naction. To address these limitations, we propose SynMotion, a new\nmotion-customized video generation model that jointly leverages semantic\nguidance and visual adaptation. At the semantic level, we introduce the\ndual-embedding semantic comprehension mechanism which disentangles subject and\nmotion representations, allowing the model to learn customized motion features\nwhile preserving its generative capabilities for diverse subjects. At the\nvisual level, we integrate parameter-efficient motion adapters into a\npre-trained video generation model to enhance motion fidelity and temporal\ncoherence. Furthermore, we introduce a new embedding-specific training strategy\nwhich \\textbf{alternately optimizes} subject and motion embeddings, supported\nby the manually constructed Subject Prior Video (SPV) training dataset. This\nstrategy promotes motion specificity while preserving generalization across\ndiverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark\nwith diverse motion patterns. Experimental results across both T2V and I2V\nsettings demonstrate that \\method outperforms existing baselines. Project page:\nhttps://lucaria-academy.github.io/SynMotion/", "published": "2025-06-30 10:09:32", "link": "http://arxiv.org/abs/2506.23690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement", "abstract": "Due to their powerful image generation capabilities, diffusion-based\nadversarial example generation methods through image editing are rapidly\ngaining popularity. However, due to reliance on the discriminative capability\nof the diffusion model, these diffusion-based methods often struggle to\ngeneralize beyond conventional image classification tasks, such as in Deepfake\ndetection. Moreover, traditional strategies for enhancing adversarial example\ntransferability are challenging to adapt to these methods. To address these\nchallenges, we propose a unified framework that seamlessly incorporates\ntraditional transferability enhancement strategies into diffusion model-based\nadversarial example generation via image editing, enabling their application\nacross a wider range of downstream tasks. Our method won first place in the\n\"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of\nAI-Generated Media\" competition at ACM MM25, which validates the effectiveness\nof our approach.", "published": "2025-06-30 09:59:09", "link": "http://arxiv.org/abs/2506.23676v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation", "abstract": "Vision Transformer have set new benchmarks in several tasks, but these models\ncome with the lack of high computational costs which makes them impractical for\nresource limited hardware. Network pruning reduces the computational complexity\nby removing less important operations while maintaining performance. However,\npruning a model on an unseen data domain, leads to a misevaluation of weight\nsignificance, resulting in suboptimal resource assignment. In this work, we\nfind that task-sensitive layers initially fail to improve the feature\nrepresentation on downstream tasks, leading to performance loss for early\npruning decisions. To address this problem, we introduce Pruning by Block\nBenefit (P3B), a pruning method that utilizes the relative contribution on\nblock level to globally assign parameter resources. P3B identifies low-impact\ncomponents to reduce parameter allocation while preserving critical ones.\nClassical pruning mask optimization struggles to reactivate zero-mask-elements.\nIn contrast, P3B sets a layerwise keep ratio based on global performance\nmetrics, ensuring the reactivation of late-converging blocks. We show in\nextensive experiments that P3B is a state of the art pruning method with most\nnoticeable gains in transfer learning tasks. Notably, P3B is able to conserve\nhigh performance, even in high sparsity regimes of 70% parameter reduction\nwhile only losing 0.64% in accuracy.", "published": "2025-06-30 09:58:25", "link": "http://arxiv.org/abs/2506.23675v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration", "abstract": "The ever-growing size of training datasets enhances the generalization\ncapability of modern machine learning models but also incurs exorbitant\ncomputational costs. Existing data pruning approaches aim to accelerate\ntraining by removing those less important samples. However, they often rely on\ngradients or proxy models, leading to prohibitive additional costs of gradient\nback-propagation and proxy model training. In this paper, we propose Partial\nForward Blocking (PFB), a novel framework for lossless training acceleration.\nThe efficiency of PFB stems from its unique adaptive pruning pipeline: sample\nimportance is assessed based on features extracted from the shallow layers of\nthe target model. Less important samples are then pruned, allowing only the\nretained ones to proceed with the subsequent forward pass and loss\nback-propagation. This mechanism significantly reduces the computational\noverhead of deep-layer forward passes and back-propagation for pruned samples,\nwhile also eliminating the need for auxiliary backward computations and proxy\nmodel training. Moreover, PFB introduces probability density as an indicator of\nsample importance. Combined with an adaptive distribution estimation module,\nour method dynamically prioritizes relatively rare samples, aligning with the\nconstantly evolving training state. Extensive experiments demonstrate the\nsignificant superiority of PFB in performance and speed. On ImageNet, PFB\nachieves a 0.5% accuracy improvement and 33% training time reduction with 40%\ndata pruned.", "published": "2025-06-30 09:53:26", "link": "http://arxiv.org/abs/2506.23674v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation", "abstract": "Medical image data is less accessible than in other domains due to privacy\nand regulatory constraints. In addition, labeling requires costly,\ntime-intensive manual image annotation by clinical experts. To overcome these\nchallenges, synthetic medical data generation offers a promising solution.\nGenerative AI (GenAI), employing generative deep learning models, has proven\neffective at producing realistic synthetic images. This study proposes a novel\nmask-guided GenAI approach using diffusion models to generate synthetic fetal\nhead ultrasound images paired with segmentation masks. These synthetic pairs\naugment real datasets for supervised fine-tuning of the Segment Anything Model\n(SAM). Our results show that the synthetic data captures real image features\neffectively, and this approach reaches state-of-the-art fetal head\nsegmentation, especially when trained with a limited number of real image-mask\npairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and\n94.38\\% using a handful of ultrasound images from the Spanish and African\ncohorts, respectively. Our code, models, and data are available on GitHub.", "published": "2025-06-30 09:40:12", "link": "http://arxiv.org/abs/2506.23664v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "On the Domain Robustness of Contrastive Vision-Language Models", "abstract": "In real-world vision-language applications, practitioners increasingly rely\non large, pretrained foundation models rather than custom-built solutions,\ndespite limited transparency regarding their training data and processes. While\nthese models achieve impressive performance on general benchmarks, their\neffectiveness can decline notably under specialized domain shifts, such as\nunique imaging conditions or environmental variations. In this work, we\nintroduce Deepbench, a framework designed to assess domain-specific robustness\nof vision-language models (VLMs). Deepbench leverages a large language model\n(LLM) to generate realistic, context-aware image corruptions tailored to\nspecific deployment domains without requiring labeled data. We evaluate a range\nof contrastive vision-language architectures and architectural variants across\nsix real-world domains and observe substantial variability in robustness,\nhighlighting the need for targeted, domain-aware evaluation. Deepbench is\nreleased as open-source software to support further research into domain-aware\nrobustness assessment.", "published": "2025-06-30 09:39:33", "link": "http://arxiv.org/abs/2506.23663v1", "categories": ["cs.CV", "cs.LG", "I.4"], "primary_category": "cs.CV"}
{"title": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue", "abstract": "Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is\na promising method with high translational potential. Unlike bone-mounted\ntracking devices, markerless tracking can reduce operating time and complexity.\nHowever, its use has been limited to cadaveric studies. This paper introduces\nthe first real-world clinical RGB-D dataset for spine surgery and develops\nSpineAlign, a system for capturing deformation between preoperative and\nintraoperative spine states. We also present an intraoperative segmentation\nnetwork trained on this data and introduce CorrespondNet, a multi-task\nframework for predicting key regions for registration in both intraoperative\nand preoperative scenes.", "published": "2025-06-30 09:32:19", "link": "http://arxiv.org/abs/2506.23657v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis", "abstract": "Color Doppler echocardiography is a crucial tool for diagnosing mitral\nregurgitation (MR). Recent studies have explored intelligent methods for MR\ndiagnosis to minimize user dependence and improve accuracy. However, these\napproaches often fail to align with clinical workflow and may lead to\nsuboptimal accuracy and interpretability. In this study, we introduce an\nautomated MR diagnosis model (MReg) developed on the 4-chamber cardiac color\nDoppler echocardiography video (A4C-CDV). It follows comprehensive feature\nmining strategies to detect MR and assess its severity, considering clinical\nrealities. Our contribution is threefold. First, we formulate the MR diagnosis\nas a regression task to capture the continuity and ordinal relationships\nbetween categories. Second, we design a feature selection and amplification\nmechanism to imitate the sonographer's diagnostic logic for accurate MR\ngrading. Third, inspired by the Mixture-of-Experts concept, we introduce a\nfeature summary module to extract the category-level features, enhancing the\nrepresentational capacity for more accurate grading. We trained and evaluated\nour proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases\nwith three graded regurgitation labels. Compared to other weakly supervised\nvideo anomaly detection and supervised classification methods, MReg\ndemonstrated superior performance in MR diagnosis. Our code is available at:\nhttps://github.com/cskdstz/MReg.", "published": "2025-06-30 09:22:52", "link": "http://arxiv.org/abs/2506.23648v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Blending Concepts with Text-to-Image Diffusion Models", "abstract": "Diffusion models have dramatically advanced text-to-image generation in\nrecent years, translating abstract concepts into high-fidelity images with\nremarkable ease. In this work, we examine whether they can also blend distinct\nconcepts, ranging from concrete objects to intangible ideas, into coherent new\nvisual entities under a zero-shot framework. Specifically, concept blending\nmerges the key attributes of multiple concepts (expressed as textual prompts)\ninto a single, novel image that captures the essence of each concept. We\ninvestigate four blending methods, each exploiting different aspects of the\ndiffusion pipeline (e.g., prompt scheduling, embedding interpolation, or\nlayer-wise conditioning). Through systematic experimentation across diverse\nconcept categories, such as merging concrete concepts, synthesizing compound\nwords, transferring artistic styles, and blending architectural landmarks, we\nshow that modern diffusion models indeed exhibit creative blending capabilities\nwithout further training or fine-tuning. Our extensive user study, involving\n100 participants, reveals that no single approach dominates in all scenarios:\neach blending technique excels under certain conditions, with factors like\nprompt ordering, conceptual distance, and random seed affecting the outcome.\nThese findings highlight the remarkable compositional potential of diffusion\nmodels while exposing their sensitivity to seemingly minor input variations.", "published": "2025-06-30 08:53:30", "link": "http://arxiv.org/abs/2506.23630v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Brain Tumor Detection through Thermal Imaging and MobileNET", "abstract": "Brain plays a crucial role in regulating body functions and cognitive\nprocesses, with brain tumors posing significant risks to human health. Precise\nand prompt detection is a key factor in proper treatment and better patient\noutcomes. Traditional methods for detecting brain tumors, that include\nbiopsies, MRI, and CT scans often face challenges due to their high costs and\nthe need for specialized medical expertise. Recent developments in machine\nlearning (ML) and deep learning (DL) has exhibited strong capabilities in\nautomating the identification and categorization of brain tumors from medical\nimages, especially MRI scans. However, these classical ML models have\nlimitations, such as high computational demands, the need for large datasets,\nand long training times, which hinder their accessibility and efficiency. Our\nresearch uses MobileNET model for efficient detection of these tumors. The\nnovelty of this project lies in building an accurate tumor detection model\nwhich use less computing re-sources and runs in less time followed by efficient\ndecision making through the use of image processing technique for accurate\nresults. The suggested method attained an average accuracy of 98.5%.", "published": "2025-06-30 08:45:28", "link": "http://arxiv.org/abs/2506.23627v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Revisiting Audio-Visual Segmentation with Vision-Centric Transformer", "abstract": "Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in\nvideo frames based on the associated audio signal. Prevailing AVS methods\ntypically adopt an audio-centric Transformer architecture, where object queries\nare derived from audio features. However, audio-centric Transformers suffer\nfrom two limitations: perception ambiguity caused by the mixed nature of audio,\nand weakened dense prediction ability due to visual detail loss. To address\nthese limitations, we propose a new Vision-Centric Transformer (VCT) framework\nthat leverages vision-derived queries to iteratively fetch corresponding audio\nand visual information, enabling queries to better distinguish between\ndifferent sounding objects from mixed audio and accurately delineate their\ncontours. Additionally, we also introduce a Prototype Prompted Query Generation\n(PPQG) module within our VCT framework to generate vision-derived queries that\nare both semantically aware and visually rich through audio prototype prompting\nand pixel context grouping, facilitating audio-visual information aggregation.\nExtensive experiments demonstrate that our VCT framework achieves new\nstate-of-the-art performances on three subsets of the AVSBench dataset. The\ncode is available at https://github.com/spyflying/VCT_AVS.", "published": "2025-06-30 08:40:36", "link": "http://arxiv.org/abs/2506.23623v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TurboVSR: Fantastic Video Upscalers and Where to Find Them", "abstract": "Diffusion-based generative models have demonstrated exceptional promise in\nthe video super-resolution (VSR) task, achieving a substantial advancement in\ndetail generation relative to prior methods. However, these approaches face\nsignificant computational efficiency challenges. For instance, current\ntechniques may require tens of minutes to super-resolve a mere 2-second, 1080p\nvideo. In this paper, we present TurboVSR, an ultra-efficient diffusion-based\nvideo super-resolution model. Our core design comprises three key aspects: (1)\nWe employ an autoencoder with a high compression ratio of 32$\\times$32$\\times$8\nto reduce the number of tokens. (2) Highly compressed latents pose substantial\nchallenges for training. We introduce factorized conditioning to mitigate the\nlearning complexity: we first learn to super-resolve the initial frame;\nsubsequently, we condition the super-resolution of the remaining frames on the\nhigh-resolution initial frame and the low-resolution subsequent frames. (3) We\nconvert the pre-trained diffusion model to a shortcut model to enable fewer\nsampling steps, further accelerating inference. As a result, TurboVSR performs\non par with state-of-the-art VSR methods, while being 100+ times faster, taking\nonly 7 seconds to process a 2-second long 1080p video. TurboVSR also supports\nimage resolution by considering image as a one-frame video. Our efficient\ndesign makes SR beyond 1080p possible, results on 4K (3648$\\times$2048) image\nSR show surprising fine details.", "published": "2025-06-30 08:24:13", "link": "http://arxiv.org/abs/2506.23618v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention", "abstract": "3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance\nFields (NeRF), excelling in complex scene reconstruction and efficient\nrendering. However, it relies on high-quality point clouds from\nStructure-from-Motion (SfM), limiting its applicability. SfM also fails in\ntexture-deficient or constrained-view scenarios, causing severe degradation in\n3DGS reconstruction. To address this limitation, we propose AttentionGS, a\nnovel framework that eliminates the dependency on high-quality initial point\nclouds by leveraging structural attention for direct 3D reconstruction from\nrandomly initialization. In the early training stage, we introduce geometric\nattention to rapidly recover the global scene structure. As training\nprogresses, we incorporate texture attention to refine fine-grained details and\nenhance rendering quality. Furthermore, we employ opacity-weighted gradients to\nguide Gaussian densification, leading to improved surface reconstruction.\nExtensive experiments on multiple benchmark datasets demonstrate that\nAttentionGS significantly outperforms state-of-the-art methods, particularly in\nscenarios where point cloud initialization is unreliable. Our approach paves\nthe way for more robust and flexible 3D Gaussian Splatting in real-world\napplications.", "published": "2025-06-30 08:16:43", "link": "http://arxiv.org/abs/2506.23611v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum", "abstract": "Existing open-vocabulary 3D semantic segmentation methods typically supervise\n3D segmentation models by merging text-aligned features (e.g., CLIP) extracted\nfrom multi-view images onto 3D points. However, such approaches treat\nmulti-view images merely as intermediaries for transferring open-vocabulary\ninformation, overlooking their rich semantic content and cross-view\ncorrespondences, which limits model effectiveness. To address this, we propose\nPGOV3D, a novel framework that introduces a Partial-to-Global curriculum for\nimproving open-vocabulary 3D semantic segmentation. The key innovation lies in\na two-stage training strategy. In the first stage, we pre-train the model on\npartial scenes that provide dense semantic information but relatively simple\ngeometry. These partial point clouds are derived from multi-view RGB-D inputs\nvia pixel-wise depth projection. To enable open-vocabulary learning, we\nleverage a multi-modal large language model (MLLM) and a 2D segmentation\nfoundation model to generate open-vocabulary labels for each viewpoint,\noffering rich and aligned supervision. An auxiliary inter-frame consistency\nmodule is introduced to enforce feature consistency across varying viewpoints\nand enhance spatial understanding. In the second stage, we fine-tune the model\non complete scene-level point clouds, which are sparser and structurally more\ncomplex. We aggregate the partial vocabularies associated with each scene and\ngenerate pseudo labels using the pre-trained model, effectively bridging the\nsemantic gap between dense partial observations and large-scale 3D\nenvironments. Extensive experiments on ScanNet, ScanNet200, and S3DIS\nbenchmarks demonstrate that PGOV3D achieves competitive performance in\nopen-vocabulary 3D semantic segmentation.", "published": "2025-06-30 08:13:07", "link": "http://arxiv.org/abs/2506.23607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion", "abstract": "Lidar point cloud synthesis based on generative models offers a promising\nsolution to augment deep learning pipelines, particularly when real-world data\nis scarce or lacks diversity. By enabling flexible object manipulation, this\nsynthesis approach can significantly enrich training datasets and enhance\ndiscriminative models. However, existing methods focus on unconditional lidar\npoint cloud generation, overlooking their potential for real-world\napplications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar\nDiffusion Model that employs latent alignment to enable robust\nsemantic-to-lidar synthesis. By directly operating in the native lidar space\nand leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art\nperformance in generating high-fidelity lidar point clouds guided by semantic\nlabels. Moreover, we propose the first diffusion-based lidar translation\nframework based on SG-LDM, which enables cross-domain translation as a domain\nadaptation strategy to enhance downstream perception performance. Systematic\nexperiments demonstrate that SG-LDM significantly outperforms existing lidar\ndiffusion models and the proposed lidar translation framework further improves\ndata augmentation performance in the downstream lidar segmentation task.", "published": "2025-06-30 08:13:04", "link": "http://arxiv.org/abs/2506.23606v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models", "abstract": "Although Large Vision-Language Models (LVLMs) have demonstrated powerful\ncapabilities in interpreting visual information, they frequently produce\ncontent that deviates from visual information, leading to object hallucination.\nTo tackle this, recent works mostly depend on expensive manual annotations and\ntraining cost, or significantly increase inference time. In this work, we\nobserve that LVLMs' attention to visual information is significantly stronger\nwhen answering caption queries compared to non-caption queries. Inspired by\nthis phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a\ntraining-free, plug-and-play hallucination mitigation method that leverages the\nattention activation pattern in response to caption queries to enhance LVLMs'\nvisual perception capability. Extensive experimental results across four\nbenchmarks covering both discriminative and generative tasks, demonstrate that\nCAI achieves state-of-the-art (SOTA) hallucination mitigating performance only\nwith minimal additional inference cost.", "published": "2025-06-30 07:52:36", "link": "http://arxiv.org/abs/2506.23590v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dataset Distillation via Vision-Language Category Prototype", "abstract": "Dataset distillation (DD) condenses large datasets into compact yet\ninformative substitutes, preserving performance comparable to the original\ndataset while reducing storage, transmission costs, and computational\nconsumption. However, previous DD methods mainly focus on distilling\ninformation from images, often overlooking the semantic information inherent in\nthe data. The disregard for context hinders the model's generalization ability,\nparticularly in tasks involving complex datasets, which may result in illogical\noutputs or the omission of critical objects. In this study, we integrate\nvision-language methods into DD by introducing text prototypes to distill\nlanguage information and collaboratively synthesize data with image prototypes,\nthereby enhancing dataset distillation performance. Notably, the text\nprototypes utilized in this study are derived from descriptive text information\ngenerated by an open-source large language model. This framework demonstrates\nbroad applicability across datasets without pre-existing text descriptions,\nexpanding the potential of dataset distillation beyond traditional image-based\napproaches. Compared to other methods, the proposed approach generates\nlogically coherent images containing target objects, achieving state-of-the-art\nvalidation performance and demonstrating robust generalization. Source code and\ngenerated data are available in\nhttps://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/", "published": "2025-06-30 07:34:33", "link": "http://arxiv.org/abs/2506.23580v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection", "abstract": "Enhancing the alignment between text and image features in the CLIP model is\na critical challenge in zero-shot industrial anomaly detection tasks. Recent\nstudies predominantly utilize specific category prompts during pretraining,\nwhich can cause overfitting to the training categories and limit model\ngeneralization. To address this, we propose a method that transforms category\nnames through multicategory name stacking to create stacked prompts, forming\nthe basis of our StackCLIP model. Our approach introduces two key components.\nThe Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts\nby stacking semantically analogous categories, while utilizing multi-object\ntextual feature fusion to amplify discriminative anomalies among similar\nobjects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific\nlinear layers tailored for each stack cluster and adaptively integrates them\nbased on the attributes of test categories. These modules work together to\ndeliver superior training speed, stability, and convergence, significantly\nboosting anomaly segmentation performance. Additionally, our stacked prompt\nframework offers robust generalization across classification tasks. To further\nimprove performance, we introduce the Regulating Prompt Learning (RPL) module,\nwhich leverages the generalization power of stacked prompts to refine prompt\nlearning, elevating results in anomaly detection classification tasks.\nExtensive testing on seven industrial anomaly detection datasets demonstrates\nthat our method achieves state-of-the-art performance in both zero-shot anomaly\ndetection and segmentation tasks.", "published": "2025-06-30 07:29:10", "link": "http://arxiv.org/abs/2506.23577v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline", "abstract": "Small object detection (SOD) in anti-UAV task is a challenging problem due to\nthe small size of UAVs and complex backgrounds. Traditional frame-based cameras\nstruggle to detect small objects in complex environments due to their low frame\nrates, limited dynamic range, and data redundancy. Event cameras, with\nmicrosecond temporal resolution and high dynamic range, provide a more\neffective solution for SOD. However, existing event-based object detection\ndatasets are limited in scale, feature large targets size, and lack diverse\nbackgrounds, making them unsuitable for SOD benchmarks. In this paper, we\nintroduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),\nthe first large-scale, highly diverse benchmark for anti-UAV tasks. It includes\n147 sequences with over 2.3 million event-level annotations, featuring\nextremely small targets (averaging 6.8 $\\times$ 5.4 pixels) and diverse\nscenarios such as urban clutter and extreme lighting conditions. Furthermore,\nbased on the observation that small moving targets form continuous curves in\nspatiotemporal event point clouds, we propose Event based Sparse Segmentation\nNetwork (EV-SpSegNet), a novel baseline for event segmentation in point cloud\nspace, along with a Spatiotemporal Correlation (STC) loss that leverages motion\ncontinuity to guide the network in retaining target events. Extensive\nexperiments on the EV-UAV dataset demonstrate the superiority of our method and\nprovide a benchmark for future research in EVSOD. The dataset and code are at\nhttps://github.com/ChenYichen9527/Ev-UAV.", "published": "2025-06-30 07:28:50", "link": "http://arxiv.org/abs/2506.23575v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution", "abstract": "The acquisition of high-resolution satellite imagery is often constrained by\nthe spatial and temporal limitations of satellite sensors, as well as the high\ncosts associated with frequent observations. These challenges hinder\napplications such as environmental monitoring, disaster response, and\nagricultural management, which require fine-grained and high-resolution data.\nIn this paper, we propose MWT-Diff, an innovative framework for satellite image\nsuper-resolution (SR) that combines latent diffusion models with wavelet\ntransforms to address these challenges. At the core of the framework is a novel\nmetadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates\nembeddings that capture metadata attributes, multi-scale frequency information,\nand temporal relationships. The embedded feature representations steer the\nhierarchical diffusion dynamics, through which the model progressively\nreconstructs high-resolution satellite imagery from low-resolution inputs. This\nprocess preserves critical spatial characteristics including textural patterns,\nboundary discontinuities, and high-frequency spectral components essential for\ndetailed remote sensing analysis. The comparative analysis of MWT-Diff across\nmultiple datasets demonstrated favorable performance compared to recent\napproaches, as measured by standard perceptual quality metrics including FID\nand LPIPS.", "published": "2025-06-30 07:19:50", "link": "http://arxiv.org/abs/2506.23566v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving", "abstract": "Current multi-view 3D object detection methods typically transfer 2D features\ninto 3D space using depth estimation or 3D position encoder, but in a fully\ndata-driven and implicit manner, which limits the detection performance.\nInspired by the success of radiance fields on 3D reconstruction, we assume they\ncan be used to enhance the detector's ability of 3D geometry estimation.\nHowever, we observe a decline in detection performance, when we directly use\nthem for 3D rendering as an auxiliary task. From our analysis, we find the\nperformance drop is caused by the strong responses on the background when\nrendering the whole scene. To address this problem, we propose object-centric\nradiance fields, focusing on modeling foreground objects while discarding\nbackground noises. Specifically, we employ Object-centric Radiance Fields\n(OcRF) to enhance 3D voxel features via an auxiliary task of rendering\nforeground objects. We further use opacity - the side-product of rendering- to\nenhance the 2D foreground BEV features via Height-aware Opacity-based Attention\n(HOA), where attention maps at different height levels are generated separately\nvia multiple networks in parallel. Extensive experiments on the nuScenes\nvalidation and test datasets demonstrate that our OcRFDet achieves superior\nperformance, outperforming previous state-of-the-art methods with 57.2$\\%$ mAP\nand 64.8$\\%$ NDS on the nuScenes test benchmark. Code will be available at\nhttps://github.com/Mingqj/OcRFDet.", "published": "2025-06-30 07:18:17", "link": "http://arxiv.org/abs/2506.23565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LH2Face: Loss function for Hard High-quality Face", "abstract": "In current practical face authentication systems, most face recognition (FR)\nalgorithms are based on cosine similarity with softmax classification. Despite\nits reliable classification performance, this method struggles with hard\nsamples. A popular strategy to improve FR performance is incorporating angular\nor cosine margins. However, it does not take face quality or recognition\nhardness into account, simply increasing the margin value and thus causing an\noverly uniform training strategy. To address this problem, a novel loss\nfunction is proposed, named Loss function for Hard High-quality Face (LH2Face).\nFirstly, a similarity measure based on the von Mises-Fisher (vMF) distribution\nis stated, specifically focusing on the logarithm of the Probability Density\nFunction (PDF), which represents the distance between a probability\ndistribution and a vector. Then, an adaptive margin-based multi-classification\nmethod using softmax, called the Uncertainty-Aware Margin Function, is\nimplemented in the article. Furthermore, proxy-based loss functions are used to\napply extra constraints between the proxy and sample to optimize their\nrepresentation space distribution. Finally, a renderer is constructed that\noptimizes FR through face reconstruction and vice versa. Our LH2Face is\nsuperior to similiar schemes on hard high-quality face datasets, achieving\n49.39% accuracy on the IJB-B dataset, which surpasses the second-place method\nby 2.37%.", "published": "2025-06-30 06:59:02", "link": "http://arxiv.org/abs/2506.23555v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching", "abstract": "The intrinsic link between facial motion and speech is often overlooked in\ngenerative modeling, where talking head synthesis and text-to-speech (TTS) are\ntypically addressed as separate tasks. This paper introduces JAM-Flow, a\nunified framework to simultaneously synthesize and condition on both facial\nmotion and speech. Our approach leverages flow matching and a novel Multi-Modal\nDiffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT\nand Audio-DiT modules. These are coupled via selective joint attention layers\nand incorporate key architectural choices, such as temporally aligned\npositional embeddings and localized joint attention masking, to enable\neffective cross-modal interaction while preserving modality-specific strengths.\nTrained with an inpainting-style objective, JAM-Flow supports a wide array of\nconditioning inputs-including text, reference audio, and reference\nmotion-facilitating tasks such as synchronized talking head generation from\ntext, audio-driven animation, and much more, within a single, coherent model.\nJAM-Flow significantly advances multi-modal generative modeling by providing a\npractical solution for holistic audio-visual synthesis. project page:\nhttps://joonghyuk.com/jamflow-web", "published": "2025-06-30 06:51:40", "link": "http://arxiv.org/abs/2506.23552v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions", "abstract": "The first algorithm, called Oneta, for a novel task of multi-style image\nenhancement is proposed in this work. Oneta uses two point operators\nsequentially: intensity enhancement with a transformation function (TF) and\ncolor correction with a color correction matrix (CCM). This two-step\nenhancement model, though simple, achieves a high performance upper bound.\nAlso, we introduce eigentransformation function (eigenTF) to represent TF\ncompactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and\nCCM parameters, respectively. To support $K$ styles, Oneta employs $K$\nlearnable tokens. During training, each style token is learned using image\npairs from the corresponding dataset. In testing, Oneta selects one of the $K$\nstyle tokens to enhance an image accordingly. Extensive experiments show that\nthe single Oneta network can effectively undertake six enhancement tasks --\nretouching, image signal processing, low-light image enhancement, dehazing,\nunderwater image enhancement, and white balancing -- across 30 datasets.", "published": "2025-06-30 06:36:11", "link": "http://arxiv.org/abs/2506.23547v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention", "abstract": "Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,\nrequiring denoising for reliable downstream applications. Previous works either\nfocus on single-frame processing, or perform multi-frame processing without\nconsidering depth variations at corresponding pixels across frames, leading to\nundesirable temporal inconsistency and spatial ambiguity. In this paper, we\npropose a novel ToF depth denoising network leveraging motion-invariant graph\nfusion to simultaneously enhance temporal stability and spatial sharpness.\nSpecifically, despite depth shifts across frames, graph structures exhibit\ntemporal self-similarity, enabling cross-frame geometric attention for graph\nfusion. Then, by incorporating an image smoothness prior on the fused graph and\ndata fidelity term derived from ToF noise distribution, we formulate a maximum\na posterior problem for ToF denoising. Finally, the solution is unrolled into\niterative filters whose weights are adaptively learned from the graph-informed\ngeometric attention, producing a high-performance yet interpretable network.\nExperimental results demonstrate that the proposed scheme achieves\nstate-of-the-art performance in terms of accuracy and consistency on synthetic\nDVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.\nSource code will be released at\n\\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.", "published": "2025-06-30 06:29:24", "link": "http://arxiv.org/abs/2506.23542v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pyramidal Patchification Flow for Visual Generation", "abstract": "Diffusion transformers (DiTs) adopt Patchify, mapping patch representations\nto token representations through linear projections, to adjust the number of\ntokens input to DiT blocks and thus the computation cost. Instead of a single\npatch size for all the timesteps, we introduce a Pyramidal Patchification Flow\n(PPFlow) approach: Large patch sizes are used for high noise timesteps and\nsmall patch sizes for low noise timesteps; Linear projections are learned for\neach patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,\nour approach operates over full latent representations other than pyramid\nrepresentations, and adopts the normal denoising process without requiring the\nrenoising trick. We demonstrate the effectiveness of our approach through two\ntraining manners. Training from scratch achieves a $1.6\\times$ ($2.0\\times$)\ninference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with\nslightly lower training FLOPs and similar image generation performance.\nTraining from pretrained normal DiTs achieves even better performance with\nsmall training time. The code and checkpoint are at\nhttps://github.com/fudan-generative-vision/PPFlow.", "published": "2025-06-30 06:29:24", "link": "http://arxiv.org/abs/2506.23543v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm", "abstract": "Existing learning-based methods effectively reconstruct HDR images from\nmulti-exposure LDR inputs with extended dynamic range and improved detail, but\nthey rely more on empirical design rather than theoretical foundation, which\ncan impact their reliability. To address these limitations, we propose the\ncross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR\nreconstruction is systematically decoupled into two interleaved subtasks --\nalignment and fusion -- optimized through alternating refinement, achieving\nsynergy between the two subtasks to enhance the overall performance. Our method\nformulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)\nestimation perspective, explicitly incorporating spatial correspondence priors\nacross LDR images and naturally bridging the alignment and fusion subproblems\nthrough joint constraints. Building on the mathematical foundation, we\nreimagine traditional iterative optimization through unfolding -- transforming\nthe conventional solution process into an end-to-end trainable AFUNet with\ncarefully designed modules that work progressively. Specifically, each\niteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that\nalternates between a Spatial Alignment Module (SAM) for alignment and a Channel\nFusion Module (CFM) for adaptive feature fusion, progressively bridging\nmisaligned content and exposure discrepancies. Extensive qualitative and\nquantitative evaluations demonstrate AFUNet's superior performance,\nconsistently surpassing state-of-the-art methods. Our code is available at:\nhttps://github.com/eezkni/AFUNet", "published": "2025-06-30 06:03:34", "link": "http://arxiv.org/abs/2506.23537v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "GViT: Representing Images as Gaussians for Visual Recognition", "abstract": "We introduce GVIT, a classification framework that abandons conventional\npixel or patch grid input representations in favor of a compact set of\nlearnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose\npositions, scales, orientations, colors, and opacities are optimized jointly\nwith a ViT classifier trained on top of these representations. We reuse the\nclassifier gradients as constructive guidance, steering the Gaussians toward\nclass-salient regions while a differentiable renderer optimizes an image\nreconstruction loss. We demonstrate that by 2D Gaussian input representations\ncoupled with our GVIT guidance, using a relatively standard ViT architecture,\nclosely matches the performance of a traditional patch-based ViT, reaching a\n76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.", "published": "2025-06-30 05:44:14", "link": "http://arxiv.org/abs/2506.23532v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "When Test-Time Adaptation Meets Self-Supervised Models", "abstract": "Training on test-time data enables deep learning models to adapt to dynamic\nenvironmental changes, enhancing their practical applicability. Online\nadaptation from source to target domains is promising but it remains highly\nreliant on the performance of source pretrained model. In this paper, we\ninvestigate whether test-time adaptation (TTA) methods can continuously improve\nmodels trained via self-supervised learning (SSL) without relying on source\npretraining. We introduce a self-supervised TTA protocol after observing that\nexisting TTA approaches struggle when directly applied to self-supervised\nmodels with low accuracy on the source domain. Furthermore, we propose a\ncollaborative learning framework that integrates SSL and TTA models, leveraging\ncontrastive learning and knowledge distillation for stepwise representation\nrefinement. We validate our method on diverse self-supervised models, including\nDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the\neffectiveness of our approach in SSL, showing that it achieves competitive\nperformance even without source pretraining.", "published": "2025-06-30 05:36:01", "link": "http://arxiv.org/abs/2506.23529v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving", "abstract": "Traditional vision-based autonomous driving systems often face difficulties\nin navigating complex environments when relying solely on single-image inputs.\nTo overcome this limitation, incorporating temporal data such as past image\nframes or steering sequences, has proven effective in enhancing robustness and\nadaptability in challenging scenarios. While previous high-performance methods\nexist, they often rely on resource-intensive fusion networks, making them\nimpractical for training and unsuitable for federated learning. To address\nthese challenges, we propose lightweight temporal transformer decomposition, a\nmethod that processes sequential image frames and temporal steering data by\nbreaking down large attention maps into smaller matrices. This approach reduces\nmodel complexity, enabling efficient weight updates for convergence and\nreal-time predictions while leveraging temporal information to enhance\nautonomous driving performance. Intensive experiments on three datasets\ndemonstrate that our method outperforms recent approaches by a clear margin\nwhile achieving real-time performance. Additionally, real robot experiments\nfurther confirm the effectiveness of our method.", "published": "2025-06-30 05:14:16", "link": "http://arxiv.org/abs/2506.23523v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection", "abstract": "The eye-tracking video saliency prediction (VSP) task and video salient\nobject detection (VSOD) task both focus on the most attractive objects in video\nand show the result in the form of predictive heatmaps and pixel-level saliency\nmasks, respectively. In practical applications, eye tracker annotations are\nmore readily obtainable and align closely with the authentic visual patterns of\nhuman eyes. Therefore, this paper aims to introduce fixation information to\nassist the detection of video salient objects under weak supervision. On the\none hand, we ponder how to better explore and utilize the information provided\nby fixation, and then propose a Position and Semantic Embedding (PSE) module to\nprovide location and semantic guidance during the feature learning process. On\nthe other hand, we achieve spatiotemporal feature modeling under weak\nsupervision from the aspects of feature selection and feature contrast. A\nSemantics and Locality Query (SLQ) Competitor with semantic and locality\nconstraints is designed to effectively select the most matching and accurate\nobject query for spatiotemporal modeling. In addition, an Intra-Inter Mixed\nContrastive (IIMC) model improves the spatiotemporal modeling capabilities\nunder weak supervision by forming an intra-video and inter-video contrastive\nlearning paradigm. Experimental results on five popular VSOD benchmarks\nindicate that our model outperforms other competitors on various evaluation\nmetrics.", "published": "2025-06-30 05:01:40", "link": "http://arxiv.org/abs/2506.23519v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image", "abstract": "Generating high-quality novel views of a scene from a single image requires\nmaintaining structural coherence across different views, referred to as view\nconsistency. While diffusion models have driven advancements in novel view\nsynthesis, they still struggle to preserve spatial continuity across views.\nDiffusion models have been combined with 3D models to address the issue, but\nsuch approaches lack efficiency due to their complex multi-step pipelines. This\npaper proposes a novel view-consistent image generation method which utilizes\ndiffusion models without additional modules. Our key idea is to enhance\ndiffusion models with a training-free method that enables adaptive attention\nmanipulation and noise reinitialization by leveraging view-guided warping to\nensure view consistency. Through our comprehensive metric framework suitable\nfor novel-view datasets, we show that our method improves view consistency\nacross various diffusion models, demonstrating its broader applicability.", "published": "2025-06-30 05:00:47", "link": "http://arxiv.org/abs/2506.23518v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models", "abstract": "Panoramic video generation aims to synthesize 360-degree immersive videos,\nholding significant importance in the fields of VR, world models, and spatial\nintelligence. Existing works fail to synthesize high-quality panoramic videos\ndue to the inherent modality gap between panoramic data and perspective data,\nwhich constitutes the majority of the training data for modern diffusion\nmodels. In this paper, we propose a novel framework utilizing pretrained\nperspective video models for generating panoramic videos. Specifically, we\ndesign a novel panorama representation named ViewPoint map, which possesses\nglobal spatial continuity and fine-grained visual details simultaneously. With\nour proposed Pano-Perspective attention mechanism, the model benefits from\npretrained perspective priors and captures the panoramic spatial correlations\nof the ViewPoint map effectively. Extensive experiments demonstrate that our\nmethod can synthesize highly dynamic and spatially consistent panoramic videos,\nachieving state-of-the-art performance and surpassing previous methods.", "published": "2025-06-30 04:33:34", "link": "http://arxiv.org/abs/2506.23513v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Translating between the representations of an acyclic convex geometry of bounded degree", "abstract": "We consider the problem of enumerating the irreducible closed sets of a\nclosure system given by an implicational base. In the context of Horn logic,\nthese correspond to Horn expressions and characteristic models, respectively.\nTo date, the complexity status of this problem is widely open, and it is\nfurther known to generalize the notorious hypergraph dualization problem, even\nin the context of acyclic convex geometries, i.e., closure systems admitting an\nacyclic implicational base. This paper studies this later class with a focus on\nthe degree, which corresponds to the maximal number of implications in which an\nelement occurs. We show that the problem is tractable for bounded values of\nthis parameter, even when relaxed to the notions of premise- and\nconclusion-degree. Our algorithms rely on structural properties of acyclic\nconvex geometries and involve various techniques from algorithmic enumeration\nsuch as solution graph traversal, saturation techniques, and a sequential\napproach leveraging from acyclicity. They are shown to perform in\nincremental-polynomial time for the computation of irreducible closed sets, and\nin polynomial time for the construction of an implicational base. Finally, we\nargue that our running times cannot be improved to polynomial delay using the\nstandard framework of flashlight search.", "published": "2025-06-30 16:59:12", "link": "http://arxiv.org/abs/2506.24052v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "Factorization norms and an inverse theorem for MaxCut", "abstract": "We prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded\nnormalized trace norm must contain a linear-sized all-ones or all-zeros\nsubmatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also\npresent further structural results about Boolean matrices of bounded\n$\\gamma_2$-norm and discuss applications in communication complexity, operator\ntheory, spectral graph theory, and extremal combinatorics.\n  As a key application, we establish an inverse theorem for MaxCut. A\ncelebrated result of Edwards states that every graph $G$ with $m$ edges has a\ncut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality\nachieved by complete graphs with an odd number of vertices. To contrast this,\nwe prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then\n$G$ must contain a clique of size $\\Omega(\\sqrt{m})$.", "published": "2025-06-30 15:54:45", "link": "http://arxiv.org/abs/2506.23989v1", "categories": ["math.CO", "cs.CC", "cs.DM"], "primary_category": "math.CO"}
{"title": "Linear Layouts of Graphs with Priority Queues", "abstract": "A linear layout of a graph consists of a linear ordering of its vertices and\na partition of its edges into pages such that the edges assigned to the same\npage obey some constraint. The two most prominent and widely studied types of\nlinear layouts are stack and queue layouts, in which any two edges assigned to\nthe same page are forbidden to cross and nest, respectively. The names of these\ntwo layouts derive from the fact that, when parsing the graph according to the\nlinear vertex ordering, the edges in a single page can be stored using a single\nstack or queue, respectively. Recently, the concepts of stack and queue layouts\nhave been extended by using a double-ended queue or a restricted-input queue\nfor storing the edges of a page. We extend this line of study to edge-weighted\ngraphs by introducing priority queue layouts, that is, the edges on each page\nare stored in a priority queue whose keys are the edge weights. First, we show\nthat there are edge-weighted graphs that require a linear number of priority\nqueues. Second, we characterize the graphs that admit a priority queue layout\nwith a single queue, regardless of the edge-weight function, and we provide an\nefficient recognition algorithm. Third, we show that the number of priority\nqueues required independently of the edge-weight function is bounded by the\npathwidth of the graph, but can be arbitrarily large already for graphs of\ntreewidth two. Finally, we prove that determining the minimum number of\npriority queues is NP-complete if the linear ordering of the vertices is fixed.", "published": "2025-06-30 15:09:14", "link": "http://arxiv.org/abs/2506.23943v1", "categories": ["cs.DM", "cs.CG"], "primary_category": "cs.DM"}
{"title": "A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs", "abstract": "We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle\nwith precedence constraints in the form of a partial order on the vertex set.\nWe show that the path problem is $\\mathsf{NP}$-complete for graphs of pathwidth\n4 while the cycle problem is $\\mathsf{NP}$-complete on graphs of pathwidth 5.\nWe complement these results by giving polynomial-time algorithms for graphs of\npathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and\ntreewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the\npath and cycle problems on rectangular grid graphs of bounded height. For\nthese, we show that the path and cycle problems are $\\mathsf{NP}$-complete when\nthe height of the grid is greater or equal to 7 and 9, respectively. In the\nvariant where we look for minimum edge-weighted Hamiltonian paths and cycles,\nthe problems are $\\mathsf{NP}$-hard for heights 5 and 6, respectively.", "published": "2025-06-30 12:31:47", "link": "http://arxiv.org/abs/2506.23790v1", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "Simple Approximations for General Spanner Problems", "abstract": "Consider a graph with n nodes and m edges, independent edge weights and\nlengths, and arbitrary distance demands for node pairs. The spanner problem\nasks for a minimum-weight subgraph that satisfies these demands via\nsufficiently short paths w.r.t. the edge lengths. For multiplicative\nalpha-spanners (where demands equal alpha times the original distances) and\nassuming that each edge's weight equals its length, the simple Greedy heuristic\nby Alth\\\"ofer et al. (1993) is known to yield strong solutions, both in theory\nand practice. To obtain guarantees in more general settings, recent\napproximations typically abandon this simplicity and practicality. Still, so\nfar, there is no known non-trivial approximation algorithm for the spanner\nproblem in its most general form. We provide two surprisingly simple\napproximations algorithms. In general, our Adapted Greedy achieves the first\nunconditional approximation ratio of m, which is non-trivial due to the\nindependence of weights and lengths. Crucially, it maintains all size and\nweight guarantees Greedy is known for, i.e., in the aforementioned\nmultiplicative alpha-spanner scenario and even for additive +beta-spanners.\nFurther, it generalizes some of these size guarantees to derive new weight\nguarantees. Our second approach, Randomized Rounding, establishes a graph\ntransformation that allows a simple rounding scheme over a standard\nmulticommodity flow LP. It yields an O(n log n)-approximation, assuming integer\nlengths and polynomially bounded distance demands. The only other known\napproximation guarantee in this general setting requires several complex\nsubalgorithms and analyses, yet we match it up to a factor of O(n^{1/5-eps})\nusing standard tools. Further, on bounded-degree graphs, we yield the first\nO(log n) approximation ratio for constant-bounded distance demands (beyond\nmultiplicative 2-spanners in unit-length graphs).", "published": "2025-06-30 09:05:02", "link": "http://arxiv.org/abs/2506.23638v1", "categories": ["cs.DS", "cs.DM", "math.CO", "68R10 (Primary) 05C85, 90C11 (Secondary)", "F.2.2; G.2.1; G.2.2"], "primary_category": "cs.DS"}
{"title": "Emergent musical properties of a transformer under contrastive self-supervised learning", "abstract": "In music information retrieval (MIR), contrastive self-supervised learning\nfor general-purpose representation models is effective for global tasks such as\nautomatic tagging. However, for local tasks such as chord estimation, it is\nwidely assumed that contrastively trained general-purpose self-supervised\nmodels are inadequate and that more sophisticated SSL is necessary; e.g.,\nmasked modeling. Our paper challenges this assumption by revealing the\npotential of contrastive SSL paired with a transformer in local MIR tasks. We\nconsider a lightweight vision transformer with one-dimensional patches in the\ntime--frequency domain (ViT-1D) and train it with simple contrastive SSL\nthrough normalized temperature-scaled cross-entropy loss (NT-Xent). Although\nNT-Xent operates only over the class token, we observe that, potentially thanks\nto weight sharing, informative musical properties emerge in ViT-1D's sequence\ntokens. On global tasks, the temporal average of class and sequence tokens\noffers a performance increase compared to the class token alone, showing useful\nproperties in the sequence tokens. On local tasks, sequence tokens perform\nunexpectedly well, despite not being specifically trained for. Furthermore,\nhigh-level musical features such as onsets emerge from layer-wise attention\nmaps and self-similarity matrices show different layers capture different\nmusical dimensions. Our paper does not focus on improving performance but\nadvances the musical interpretation of transformers and sheds light on some\noverlooked abilities of contrastive SSL paired with transformers for sequence\nmodeling in MIR.", "published": "2025-06-30 14:04:59", "link": "http://arxiv.org/abs/2506.23873v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation", "abstract": "Generative recommendation (GR) typically encodes behavioral or semantic\naspects of item information into discrete tokens, leveraging the standard\nautoregressive (AR) generation paradigm to make predictions. However, existing\nmethods tend to overlook their intrinsic relationship, that is, the semantic\nusually provides some reasonable explainability \"$\\textbf{why}$\" for the\nbehavior \"$\\textbf{what}$\", which may constrain the full potential of GR. To\nthis end, we present Chunk AutoRegressive Modeling (CAR), a new generation\nparadigm following the decision pattern that users usually think semantic\naspects of items (e.g. brand) and then take actions on target items (e.g.\npurchase). Our CAR, for the $\\textit{first time}$, incorporates semantics\n(SIDs) and behavior (UID) into a single autoregressive transformer from an\n``act-with-think'' dual perspective via chunk-level autoregression.\nSpecifically, CAR packs SIDs and UID into a conceptual chunk for item unified\nrepresentation, allowing each decoding step to make a holistic prediction.\nExperiments show that our CAR significantly outperforms existing methods based\non traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we\nverify the scaling effect between model performance and SIDs bit number,\ndemonstrating that CAR preliminary emulates a kind of slow-thinking style\nmechanism akin to the reasoning processes observed in large language models\n(LLMs).", "published": "2025-06-30 09:13:54", "link": "http://arxiv.org/abs/2506.23643v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On", "abstract": "The global fashion e-commerce industry has become integral to people's daily\nlives, leveraging technological advancements to offer personalized shopping\nexperiences, primarily through recommendation systems that enhance customer\nengagement through personalized suggestions. To improve customers' experience\nin online shopping, we propose a novel comprehensive KiseKloset system for\noutfit retrieval, recommendation, and try-on. We explore two approaches for\noutfit retrieval: similar item retrieval and text feedback-guided item\nretrieval. Notably, we introduce a novel transformer architecture designed to\nrecommend complementary items from diverse categories. Furthermore, we enhance\nthe overall performance of the search pipeline by integrating approximate\nalgorithms to optimize the search process. Additionally, addressing the crucial\nneeds of online shoppers, we employ a lightweight yet efficient virtual try-on\nframework capable of real-time operation, memory efficiency, and maintaining\nrealistic outputs compared to its predecessors. This virtual try-on module\nempowers users to visualize specific garments on themselves, enhancing the\ncustomers' experience and reducing costs associated with damaged items for\nretailers. We deployed our end-to-end system for online users to test and\nprovide feedback, enabling us to measure their satisfaction levels. The results\nof our user study revealed that 84% of participants found our comprehensive\nsystem highly useful, significantly improving their online shopping experience.", "published": "2025-06-30 02:25:39", "link": "http://arxiv.org/abs/2506.23471v1", "categories": ["cs.IR", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Combinatorial Multi-Access Coded Caching with Private Caches under Intersecting Index Constraints", "abstract": "We consider the coded caching system where each user, equipped with a private\ncache, accesses a distinct r-subset of access caches. A central server housing\na library of files populates both private and access caches using uncoded\nplacement. In this work, we focus on a constrained indexing regime, referred to\nas the intersection class, in which the sets used to index the demands of each\nuser must have a nonempty intersection. This regime models resource-limited IoT\nscenarios such as edge-assisted IoT systems, where devices with small private\ncaches connect to a small number of shared caches. We provide a necessary and\nsufficient condition under which the system parameters fall within this\nintersection class. Under this condition, we propose a centralized coded\ncaching scheme and characterize its rate-memory trade-off. Next, we define a\nuniform-intersection subclass and establish a condition under which the system\nbelongs to this subclass. Within this subclass, the proposed scheme has a\nregular structure, with each transmission benefiting the same number of users,\nand we characterize its rate-memory trade-off. Additionally, we derive an index\ncoding-based lower bound on the minimum achievable worst-case rate under\nuncoded placement. Finally, we provide numerical comparisons between the rate\nof the proposed scheme, the new lower bound, and bounds from the original work.", "published": "2025-06-30 17:07:59", "link": "http://arxiv.org/abs/2506.24060v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Pinching-Antenna Systems with In-Waveguide Attenuation: Performance Analysis and Algorithm Design", "abstract": "Pinching-antenna systems have emerged as a promising flexible-antenna\narchitecture for next-generation wireless networks, enabling enhanced\nadaptability and user-centric connectivity through antenna repositioning along\nwaveguides. However, existing studies often overlook in-waveguide signal\nattenuation and in the literature, there is no comprehensive analysis on\nwhether and under what conditions such an assumption is justified. This paper\naddresses this gap by explicitly incorporating in-waveguide attenuation into\nboth the system model and algorithm design, and studying its impact on the\ndownlink user data rates. We begin with a single-user scenario and derive a\nclosed-form expression for the globally optimal antenna placement, which\nreveals how the attenuation coefficient and the user-to-waveguide distance\njointly affect the optimal antenna position. Based on this analytical solution,\nwe further provide a theoretical analysis identifying the system conditions\nunder which the in-waveguide attenuation has an insignificant impact on the\nuser achievable rate. The study is then extended to the multi-user\nmultiple-input multiple-output setting, where two efficient algorithms are\ndeveloped, based on the weighted minimum mean square error method and the\nmaximum ratio combining method, to jointly optimize beamforming and antenna\nplacement. Simulation results validate the efficacy of the proposed algorithms\nand demonstrate that pinching-antenna systems substantially outperform\nconventional fixed-antenna baselines, underscoring their potential for future\nflexible wireless communications.", "published": "2025-06-30 15:36:40", "link": "http://arxiv.org/abs/2506.23966v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "ISI-Aware Code Design: A Linear Approach Towards Reliable Molecular Communication", "abstract": "Intersymbol Interference (ISI) is a major bottleneck in Molecular\nCommunication via Diffusion (MCvD), degrading system performance. This paper\nintroduces two families of linear channel codes to mitigate ISI: Zero Pad Zero\nStart (ZPZS) and Zero Pad (ZP) codes, ensuring that each codeword avoids\nconsecutive bit-1s. The ZPZS and ZP codes are then combined to form a binary ZP\ncode, offering a higher code rate than linear ZP codes and allowing simple\ndecoding via the Majority Location Rule (MLR). Additionally, a Leading One Zero\nPad (LOZP) code is proposed, which relaxes zero-padding constraints by\nprioritizing the placement of bit-1s, achieving a higher rate than ZP. A\nclosed-form expression is derived to compute expected ISI, showing it depends\non the average bit-1 density in the codewords. ISI and Bit Error Rate (BER)\nperformance are evaluated under two MCvD channel models: (i) without refresh,\nwhere past bits persist longer, and (ii) with refresh, where the channel is\ncleared after each reception. Results show that the LOZP code performs better\nin the refresh channel due to initial bit-1 placement, while ZP excels without\nrefresh by reducing average bit-1 density. The asymptotic upper bound on code\nrate illustrates a trade-off between ISI and rate. Simulations demonstrate that\nZP and LOZP codes improve BER by controlling bit-1 positions and density,\nproviding better reliability in ISI-dominated regimes compared to conventional\nerror-correcting codes.", "published": "2025-06-30 12:29:19", "link": "http://arxiv.org/abs/2506.23787v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Asymptotically Optimal Secure Aggregation for Wireless Federated Learning with Multiple Servers", "abstract": "In this paper, we investigate the transmission latency of the secure\naggregation problem in a \\emph{wireless} federated learning system with\nmultiple curious servers. We propose a privacy-preserving coded aggregation\nscheme where the servers can not infer any information about the distributed\nusers' local gradients, nor the aggregation value. In our scheme, each user\nencodes its local gradient into $\\sK$ confidential messages intended\nexclusively for different servers using a multi-secret sharing method, and each\nserver forwards the summation of the received confidential messages, while the\nusers sequentially employ artificial noise alignment techniques to facilitate\nsecure transmission. Through these summations, the user can recover the\naggregation of all local gradients. We prove the privacy guarantee in the\ninformation-theoretic sense and characterize the uplink and downlink\ncommunication latency measured by \\emph{normalized delivery time} (NDT), both\nof which decrease monotonically with the number of servers $\\sK$ while\nincreasing over most of the range of the number of users $\\sM$. Finally, we\nestablish a lower bound on the NDT of the considered system and theoretically\nprove that the scheme achieves the optimal uplink and downlink NDT under the\nconditions $\\sK \\gg \\sM \\gg 0$ and $\\sK \\gg \\sM$, respectively. For arbitrary\n$\\sK$ and $\\sM$, the proposed scheme achieves the optimal uplink NDT within a\nmultiplicative gap of $4$.", "published": "2025-06-30 10:03:38", "link": "http://arxiv.org/abs/2506.23680v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimal Quantum Algorithm for Estimating Fidelity to a Pure State", "abstract": "We present an optimal quantum algorithm for fidelity estimation between two\nquantum states when one of them is pure. In particular, the (square root)\nfidelity of a mixed state to a pure state can be estimated to within additive\nerror $\\varepsilon$ by using $\\Theta(1/\\varepsilon)$ queries to their\nstate-preparation circuits, achieving a quadratic speedup over the folklore\n$O(1/\\varepsilon^2)$. Our approach is technically simple, and can moreover\nestimate the quantity $\\sqrt{\\operatorname{tr}(\\rho\\sigma^2)}$ that is not\ncommon in the literature. To the best of our knowledge, this is the first\nquery-optimal approach to fidelity estimation involving mixed states.", "published": "2025-06-30 09:24:03", "link": "http://arxiv.org/abs/2506.23650v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Elias' Encoding from Lagrangians and Renormalization", "abstract": "An efficient approach to universality and optimality of binary codes for\nintegers known as Elias' encoding can be deduced from the classical constrained\noptimization and renormalization techniques. The most important properties,\nsuch as being a universal prefix code, also follow naturally.", "published": "2025-06-30 01:01:17", "link": "http://arxiv.org/abs/2506.23447v1", "categories": ["cs.IT", "math-ph", "math.IT", "math.MP", "H.1.1"], "primary_category": "cs.IT"}
{"title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies", "abstract": "Consensus-based optimization (CBO) has established itself as an efficient\ngradient-free optimization scheme, with attractive mathematical properties,\nsuch as mean-field convergence results for non-convex loss functions. In this\nwork, we study CBO in the context of closed-box adversarial attacks, which are\nimperceptible input perturbations that aim to fool a classifier, without\naccessing its gradient. Our contribution is to establish a connection between\nthe so-called consensus hopping as introduced by Riedl et al. and natural\nevolution strategies (NES) commonly applied in the context of adversarial\nattacks and to rigorously relate both methods to gradient-based optimization\nschemes. Beyond that, we provide a comprehensive experimental study that shows\nthat despite the conceptual similarities, CBO can outperform NES and other\nevolutionary strategies in certain scenarios.", "published": "2025-06-30 16:54:44", "link": "http://arxiv.org/abs/2506.24048v1", "categories": ["math.OC", "cs.LG", "65K10, 68Q32, 65K15, 90C26"], "primary_category": "math.OC"}
{"title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC", "abstract": "The proliferation of agentic Large Language Models (LLMs) on personal devices\nintroduces a new class of workloads characterized by a dichotomy of objectives.\nReactive tasks, initiated by users, demand immediate, low-latency responses,\nwhile proactive tasks operate invisibly and prioritize throughput. Existing\non-device LLM engines, designed for isolated inferences, fail to efficiently\nmanage these concurrent and conflicting requests on consumer-grade\nheterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces\nAgent.xpu, an efficient serving system for agentic LLM workloads on\nmemory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu\nfirst constructs a heterogeneous execution graph, which fuses and chunks model\nkernels for affinity-guided, elastic accelerator mapping with predictive kernel\nannotation. At runtime, its online scheduler enables fine-grained, kernel-level\npreemption to guarantee the responsiveness of reactive tasks. To maximize SoC\nutilization, it adopts slack-aware kernel backfill to opportunistically append\nproactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware\ndispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves\n4.6$\\times$ lower latency for reactive tasks and sustains\n1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to\nstate-of-the-art inference engines.", "published": "2025-06-30 16:50:48", "link": "http://arxiv.org/abs/2506.24045v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Faster Diffusion Models via Higher-Order Approximation", "abstract": "In this paper, we explore provable acceleration of diffusion models without\nany additional retraining. Focusing on the task of approximating a target data\ndistribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation\ndistance, we propose a principled, training-free sampling algorithm that\nrequires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate\nscores, where $K$ is an arbitrarily large fixed integer. This result applies to\na broad class of target data distributions, without the need for assumptions\nsuch as smoothness or log-concavity. Our theory is robust vis-a-vis inexact\nscore estimation, degrading gracefully as the score estimation error increases\n-- without demanding higher-order smoothness on the score estimates as assumed\nin previous work. The proposed algorithm draws insight from high-order ODE\nsolvers, leveraging high-order Lagrange interpolation and successive refinement\nto approximate the integral derived from the probability flow ODE.", "published": "2025-06-30 16:49:03", "link": "http://arxiv.org/abs/2506.24042v1", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting", "abstract": "Spike sorting is a crucial step in decoding multichannel extracellular neural\nsignals, enabling the identification of individual neuronal activity. A key\nchallenge in brain-machine interfaces (BMIs) is achieving real-time, low-power\nspike sorting at the edge while keeping high neural decoding performance. This\nstudy introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer\nspiking neural network optimized for efficient spike sorting. NSS leverages the\nLocally Competitive Algorithm (LCA) for sparse coding to extract relevant\nfeatures from noisy events with reduced computational demands. NSS learns to\nsort detected spike waveforms in an online fashion and operates entirely\nunsupervised. To exploit multi-bit spike coding capabilities of neuromorphic\nplatforms like Intel's Loihi 2, a custom neuron model was implemented, enabling\nflexible power-performance trade-offs via adjustable spike bit-widths.\nEvaluations on simulated and real-world tetrode signals with biological drift\nshowed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.\nWith 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with\nleaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%\nimprovement) while consuming 8.6mW (+1.65mW) when tested on a drifting\nrecording, with a computational processing time of 0.25ms (+60 us) per\ninference.", "published": "2025-06-30 16:48:49", "link": "http://arxiv.org/abs/2506.24041v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models", "abstract": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as\nelectroencephalography (EEG), to identify which speaker a listener is focusing\non in a multi-speaker environment. While state-of-the-art AAD algorithms can\nidentify the attended speaker on short time windows, their predictions are\noften too inaccurate for practical use. In this work, we propose augmenting AAD\nwith a hidden Markov model (HMM) that models the temporal structure of\nattention. More specifically, the HMM relies on the fact that a subject is much\nless likely to switch attention than to keep attending the same speaker at any\nmoment in time. We show how a HMM can significantly improve existing AAD\nalgorithms in both causal (real-time) and non-causal (offline) settings. We\nfurther demonstrate that HMMs outperform existing postprocessing approaches in\nboth accuracy and responsiveness, and explore how various factors such as\nwindow length, switching frequency, and AAD accuracy influence overall\nperformance. The proposed method is computationally efficient, intuitive to use\nand applicable in both real-time and offline settings.", "published": "2025-06-30 16:31:26", "link": "http://arxiv.org/abs/2506.24024v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice", "abstract": "This study investigates adaptive experimental design for treatment choice,\nalso known as fixed-budget best-arm identification. We consider an adaptive\nprocedure consisting of a treatment-allocation phase followed by a\ntreatment-choice phase, and we design an adaptive experiment for this setup to\nefficiently identify the best treatment arm, defined as the one with the\nhighest expected outcome. In our designed experiment, the treatment-allocation\nphase consists of two stages. The first stage is a pilot phase, where we\nallocate each treatment arm uniformly with equal proportions to eliminate\nclearly suboptimal arms and estimate outcome variances. In the second stage, we\nallocate treatment arms in proportion to the variances estimated in the first\nstage. After the treatment-allocation phase, the procedure enters the\ntreatment-choice phase, where we choose the treatment arm with the highest\nsample mean as our estimate of the best treatment arm. We prove that this\nsingle design is simultaneously asymptotically minimax and Bayes optimal for\nthe simple regret, with upper bounds that match our lower bounds up to exact\nconstants. Therefore, our designed experiment achieves the sharp efficiency\nlimits without requiring separate tuning for minimax and Bayesian objectives.", "published": "2025-06-30 16:11:44", "link": "http://arxiv.org/abs/2506.24007v1", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "econ.EM"}
{"title": "Provably Efficient and Agile Randomized Q-Learning", "abstract": "While Bayesian-based exploration often demonstrates superior empirical\nperformance compared to bonus-based methods in model-based reinforcement\nlearning (RL), its theoretical understanding remains limited for model-free\nsettings. Existing provable algorithms either suffer from computational\nintractability or rely on stage-wise policy updates which reduce responsiveness\nand slow down the learning process. In this paper, we propose a novel variant\nof Q-learning algorithm, refereed to as RandomizedQ, which integrates\nsampling-based exploration with agile, step-wise, policy updates, for episodic\ntabular RL. We establish an $\\widetilde{O}(\\sqrt{H^5SAT})$ regret bound, where\n$S$ is the number of states, $A$ is the number of actions, $H$ is the episode\nlength, and $T$ is the total number of episodes. In addition, we present a\nlogarithmic regret bound under a mild positive sub-optimality condition on the\noptimal Q-function. Empirically, RandomizedQ exhibits outstanding performance\ncompared to existing Q-learning variants with both bonus-based and\nBayesian-based exploration on standard benchmarks.", "published": "2025-06-30 16:08:29", "link": "http://arxiv.org/abs/2506.24005v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)", "abstract": "This document shows how to obtain the Jacobian and Hessian matrices of the\nKullback-Leibler divergence between two multivariate Gaussian distributions,\nusing the first and second-order differentials. The presented derivations are\nbased on the theory presented by \\cite{magnus99}. I've also got great\ninspiration from some of the derivations in \\cite{minka}.\n  Since I pretend to be at most didactic, the document is split into a summary\nof results and detailed derivations on each of the elements involved, with\nspecific references to the tricks used in the derivations, and to many of the\nunderlying concepts.", "published": "2025-06-30 15:58:25", "link": "http://arxiv.org/abs/2506.23996v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks", "abstract": "Certified robustness is a critical property for deploying neural networks\n(NN) in safety-critical applications. A principle approach to achieving such\nguarantees is to constrain the global Lipschitz constant of the network.\nHowever, accurate methods for Lipschitz-constrained training often suffer from\nnon-convex formulations and poor scalability due to reliance on global\nsemidefinite programs (SDPs). In this letter, we propose a convex training\nframework that enforces global Lipschitz constraints via semidefinite\nrelaxation. By reparameterizing the NN using loop transformation, we derive a\nconvex admissibility condition that enables tractable and certifiable training.\nWhile the resulting formulation guarantees robustness, its scalability is\nlimited by the size of global SDP. To overcome this, we develop a randomized\nsubspace linear matrix inequalities (RS-LMI) approach that decomposes the\nglobal constraints into sketched layerwise constraints projected onto\nlow-dimensional subspaces, yielding a smooth and memory-efficient training\nobjective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that\nthe proposed framework achieves competitive accuracy with significantly\nimproved Lipschitz bounds and runtime performance.", "published": "2025-06-30 15:42:23", "link": "http://arxiv.org/abs/2506.23977v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "UMA: A Family of Universal Models for Atoms", "abstract": "The ability to quickly and accurately compute properties from atomic\nsimulations is critical for advancing a large number of applications in\nchemistry and materials science including drug discovery, energy storage, and\nsemiconductor manufacturing. To address this need, Meta FAIR presents a family\nof Universal Models for Atoms (UMA), designed to push the frontier of speed,\naccuracy, and generalization. UMA models are trained on half a billion unique\n3D atomic structures (the largest training runs to date) by compiling data\nacross multiple chemical domains, e.g. molecules, materials, and catalysts. We\ndevelop empirical scaling laws to help understand how to increase model\ncapacity alongside dataset size to achieve the best accuracy. The UMA small and\nmedium models utilize a novel architectural design we refer to as mixture of\nlinear experts that enables increasing model capacity without sacrificing\nspeed. For example, UMA-medium has 1.4B parameters but only ~50M active\nparameters per atomic structure. We evaluate UMA models on a diverse set of\napplications across multiple domains and find that, remarkably, a single model\nwithout any fine-tuning can perform similarly or better than specialized\nmodels. We are releasing the UMA code, weights, and associated data to\naccelerate computational workflows and enable the community to continue to\nbuild increasingly capable AI models.", "published": "2025-06-30 15:38:13", "link": "http://arxiv.org/abs/2506.23971v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Constraints Directly from Network Data", "abstract": "Network data conforms to a wide range of rules that arise from protocols,\ndesign principles, and deployment decisions (e.g., a packet's queuing delay\nmust be less than its end-to-end delay). Formalizing such rules as logic\nconstraints can (i) improve the quality of synthetic data, (ii) reduce the\nbrittleness of machine learning (ML) models, and (iii) improve semantic\nunderstanding of network measurements. However, these benefits remain out of\nreach if rule extraction is manual or solely reliant on ML, as both approaches\nyield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and\nintroduces NetNomos that learns propositional logic constraints directly from\nraw network measurements. Constraint modeling in this domain is uniquely\nchallenging due to the scale of the data, the inherent learning complexity and\npassive environment, and the lack of ground truth supervision. NetNomos\naddresses these challenges via a lattice-based search structured by constraint\nspecificity and succinctness. Our approach reduces learning complexity from\nsuperquadratic to logarithmic and enables efficient traversal in combinatorial\nsearch space.\n  Our evaluations on diverse network datasets show that NetNomos learns all\nbenchmark rules, including those associated with as little as 0.01% of data\npoints, in under three hours. In contrast, baseline methods discover less than\n25% of the rules and require several days to run. Through three case studies,\nwe show that: NetNomos (i) finds rule violations in the outputs of all seven\nsynthetic traffic generators, hence can be used to assess and guide their\ngeneration process; (ii) detects semantic differences in traffic, hence can be\nused for anomaly detection; and (iii) automatically finds rules used for\ntelemetry imputation, hence can support monitoring through inference.", "published": "2025-06-30 15:36:22", "link": "http://arxiv.org/abs/2506.23964v1", "categories": ["cs.NI", "cs.LG", "C.2.3; I.2.6; I.2.3"], "primary_category": "cs.NI"}
{"title": "Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages", "abstract": "Millions of people in African countries face barriers to accessing healthcare\ndue to language and literacy gaps. This research tackles this challenge by\ntransforming complex medical documents -- in this case, prosthetic device user\nmanuals -- into accessible formats for underserved populations. This case study\nin cross-cultural translation is particularly pertinent/relevant for\ncommunities that receive donated prosthetic devices but may not receive the\naccompanying user documentation. Or, if available online, may only be available\nin formats (e.g., language and readability) that are inaccessible to local\npopulations (e.g., English-language, high resource settings/cultural context).\nThe approach is demonstrated using the widely spoken Pidgin dialect, but our\nopen-source framework has been designed to enable rapid and easy extension to\nother languages/dialects. This work presents an AI-powered framework designed\nto process and translate complex medical documents, e.g., user manuals for\nprosthetic devices, into marginalised languages. The system enables users --\nsuch as healthcare workers or patients -- to upload English-language medical\nequipment manuals, pose questions in their native language, and receive\naccurate, localised answers in real time. Technically, the system integrates a\nRetrieval-Augmented Generation (RAG) pipeline for processing and semantic\nunderstanding of the uploaded manuals. It then employs advanced Natural\nLanguage Processing (NLP) models for generative question-answering and\nmultilingual translation. Beyond simple translation, it ensures accessibility\nto device instructions, treatment protocols, and safety information, empowering\npatients and clinicians to make informed healthcare decisions.", "published": "2025-06-30 15:25:58", "link": "http://arxiv.org/abs/2506.23958v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments", "abstract": "Estimating physical parameters or material properties from experimental\nobservations is a common objective in many areas of physics and material\nscience. In many experiments, especially in shock physics, radiography is the\nprimary means of observing the system of interest. However, radiography does\nnot provide direct access to key state variables, such as density, which\nprevents the application of traditional parameter estimation approaches. Here\nwe focus on flyer plate impact experiments on porous materials, and resolving\nthe underlying parameterized equation of state (EoS) and crush porosity model\nparameters given radiographic observation(s). We use machine learning as a tool\nto demonstrate with high confidence that using only high impact velocity data\ndoes not provide sufficient information to accurately infer both EoS and crush\nmodel parameters, even with fully resolved density fields or a dynamic sequence\nof images. We thus propose an observable data set consisting of low and high\nimpact velocity experiments/simulations that capture different regimes of\ncompaction and shock propagation, and proceed to introduce a generative machine\nlearning approach which produces a posterior distribution of physical\nparameters directly from radiographs. We demonstrate the effectiveness of the\napproach in estimating parameters from simulated flyer plate impact\nexperiments, and show that the obtained estimates of EoS and crush model\nparameters can then be used in hydrodynamic simulations to obtain accurate and\nphysically admissible density reconstructions. Finally, we examine the\nrobustness of the approach to model mismatches, and find that the learned\napproach can provide useful parameter estimates in the presence of\nout-of-distribution radiographic noise and previously unseen physics, thereby\npromoting a potential breakthrough in estimating material properties from\nexperimental radiographic images.", "published": "2025-06-30 14:43:33", "link": "http://arxiv.org/abs/2506.23914v1", "categories": ["physics.comp-ph", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family", "abstract": "This work addresses the challenge of malware classification using machine\nlearning by developing a novel dataset labeled at both the malware type and\nfamily levels. Raw binaries were collected from sources such as VirusShare, VX\nUnderground, and MalwareBazaar, and subsequently labeled with family\ninformation parsed from binary names and type-level labels integrated from\nClarAVy. The dataset includes 14 malware types and 17 malware families, and was\nprocessed using a unified feature extraction pipeline based on static analysis,\nparticularly extracting features from Portable Executable headers, to support\nadvanced classification tasks. The evaluation was focused on three key\nclassification tasks. In the binary classification of malware versus benign\nsamples, Random Forest and XGBoost achieved high accuracy on the full datasets,\nreaching 98.5% for type-based detection and 98.98% for family-based detection.\nWhen using truncated datasets of 1,000 samples to assess performance under\nlimited data conditions, both models still performed strongly, achieving 97.6%\nfor type-based detection and 98.66% for family-based detection. For interclass\nclassification, which distinguishes between malware types or families, the\nmodels reached up to 97.5% accuracy on type-level tasks and up to 93.7% on\nfamily-level tasks. In the multiclass classification setting, which assigns\nsamples to the correct type or family, SVM achieved 81.1% accuracy on type\nlabels, while Random Forest and XGBoost reached approximately 73.4% on family\nlabels. The results highlight practical trade-offs between accuracy and\ncomputational cost, and demonstrate that labeling at both the type and family\nlevels enables more fine-grained and insightful malware classification. The\nwork establishes a robust foundation for future research on advanced malware\ndetection and classification.", "published": "2025-06-30 14:38:01", "link": "http://arxiv.org/abs/2506.23909v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems", "abstract": "Living plants, while contributing to ecological balance and climate\nregulation, also function as natural sensors capable of transmitting\ninformation about their internal physiological states and surrounding\nconditions. This rich source of data provides potential for applications in\nenvironmental monitoring and precision agriculture. With integration into\nbiohybrid systems, we establish novel channels of physiological signal flow\nbetween living plants and artificial devices. We equipped *Hedera helix* with a\nplant-wearable device called PhytoNode to continuously record the plant's\nelectrophysiological activity. We deployed plants in an uncontrolled outdoor\nenvironment to map electrophysiological patterns to environmental conditions.\nOver five months, we collected data that we analyzed using state-of-the-art and\nautomated machine learning (AutoML). Our classification models achieve high\nperformance, reaching macro F1 scores of up to 95 percent in binary tasks.\nAutoML approaches outperformed manual tuning, and selecting subsets of\nstatistical features further improved accuracy. Our biohybrid living system\nmonitors the electrophysiology of plants in harsh, real-world conditions. This\nwork advances scalable, self-sustaining, and plant-integrated living biohybrid\nsystems for sustainable environmental monitoring.", "published": "2025-06-30 14:04:31", "link": "http://arxiv.org/abs/2506.23872v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment", "abstract": "Understanding team formations and player positioning is crucial for tactical\nanalysis in football (soccer). This paper presents a flexible method for\nformation recognition and player position assignment in football using\npredefined static formation templates and cost minimization from spatiotemporal\ntracking data, called EFPI. Our approach employs linear sum assignment to\noptimally match players to positions within a set of template formations by\nminimizing the total distance between actual player locations and template\npositions, subsequently selecting the formation with the lowest assignment\ncost. To improve accuracy, we scale actual player positions to match the\ndimensions of these formation templates in both width and length. While the\nmethod functions effectively on individual frames, it extends naturally to\nlarger game segments such as complete periods, possession sequences or specific\nintervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we\nincorporate an optional stability parameter that prevents unnecessary formation\nchanges when assignment costs differ only marginally between time segments.\nEFPI is available as open-source code through the unravelsports Python package.", "published": "2025-06-30 13:33:37", "link": "http://arxiv.org/abs/2506.23843v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction", "abstract": "We consider centralized distributed optimization in the classical federated\nlearning setup, where $n$ workers jointly find an $\\varepsilon$-stationary\npoint of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access\nonly to unbiased stochastic gradients with variance $\\sigma^2$. Each worker\nrequires at most $h$ seconds to compute a stochastic gradient, and the\ncommunication times from the server to the workers and from the workers to the\nserver are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One\nof the main motivations for distributed optimization is to achieve scalability\nwith respect to $n$. For instance, it is well known that the distributed\nversion of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L\n\\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where\n$\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly,\nusing unbiased sparsification compressors, it is possible to reduce both the\nvariance-dependent runtime term and the communication runtime term. However,\nonce we account for the communication from the server to the workers\n$\\tau_{s}$, we prove that it becomes infeasible to design a method using\nunbiased random sparsification compressors that scales both the server-side\ncommunication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the\nvariance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$\nbetter than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,\nwhere all workers access the same distribution. To establish this result, we\nconstruct a new \"worst-case\" function and develop a new lower bound framework\nthat reduces the analysis to the concentration of a random sum, for which we\nprove a concentration bound. These results reveal fundamental limitations in\nscaling distributed optimization, even under the homogeneous assumption.", "published": "2025-06-30 13:27:39", "link": "http://arxiv.org/abs/2506.23836v1", "categories": ["math.OC", "cs.DC", "cs.LG"], "primary_category": "math.OC"}
{"title": "SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration", "abstract": "In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type\npreconditioning. Our contributions are twofold. First, we develop a unified\nconvergence analysis of SGD with adaptive preconditioning under anisotropic or\nmatrix smoothness and noise assumptions. This allows us to recover\nstate-of-the-art convergence results for several popular adaptive gradient\nmethods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In\naddition, we establish the fundamental connection between two recently proposed\nalgorithms, Scion and DASGO, and provide the first theoretical guarantees for\nthe latter. Second, we show that the convergence of methods like AdaGrad and\nDASGO can be provably accelerated beyond the best-known rates using Nesterov\nmomentum. Consequently, we obtain the first theoretical justification that\nAdaGrad-type algorithms can simultaneously benefit from both diagonal\npreconditioning and momentum, which may provide an ultimate explanation for the\npractical efficiency of Adam.", "published": "2025-06-30 12:47:10", "link": "http://arxiv.org/abs/2506.23803v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations", "abstract": "In this work we introduce a novel adaptive anomaly detection framework\nspecifically designed for monitoring sequential random finite set (RFS)\nobservations. Our approach effectively distinguishes between In-Control data\n(normal) and Out-Of-Control data (anomalies) by detecting deviations from the\nexpected statistical behavior of the process. The primary contributions of this\nstudy include the development of an innovative RFS-based framework that not\nonly learns the normal behavior of the data-generating process online but also\ndynamically adapts to behavioral shifts to accurately identify abnormal point\npatterns. To achieve this, we introduce a new class of RFS-based posterior\ndistributions, named Power Discounting Posteriors (PD), which facilitate\nadaptation to systematic changes in data while enabling anomaly detection of\npoint pattern data through a novel predictive posterior density function. The\neffectiveness of the proposed approach is demonstrated by extensive qualitative\nand quantitative simulation experiments.", "published": "2025-06-30 12:45:44", "link": "http://arxiv.org/abs/2506.23802v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards the Training of Deeper Predictive Coding Neural Networks", "abstract": "Predictive coding networks trained with equilibrium propagation are neural\nmodels that perform inference through an iterative energy minimization process.\nPrevious studies have demonstrated their effectiveness in shallow\narchitectures, but show significant performance degradation when depth exceeds\nfive to seven layers. In this work, we show that the reason behind this\ndegradation is due to exponentially imbalanced errors between layers during\nweight updates, and predictions from the previous layer not being effective in\nguiding updates in deeper layers. We address the first issue by introducing two\nnovel methods to optimize the latent variables that use precision-weighting to\nre-balance the distribution of energy among layers during the `relaxation\nphase', and the second issue by proposing a novel weight update mechanism that\nreduces error accumulation in deeper layers. Empirically, we test our methods\non a large number of image classification tasks, resulting in large\nimprovements in test accuracy across networks with more than seven layers, with\nperformances comparable to those of backprop on similar models. These findings\nsuggest that a better understanding of the relaxation phase is important to\ntrain models using equilibrium propagation at scale, and open new possibilities\nfor their application in complex tasks.", "published": "2025-06-30 12:44:47", "link": "http://arxiv.org/abs/2506.23800v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KAIROS: Scalable Model-Agnostic Data Valuation", "abstract": "Training data increasingly shapes not only model accuracy but also regulatory\ncompliance and market valuation of AI assets. Yet existing valuation methods\nremain inadequate: model-based techniques depend on a single fitted model and\ninherit its biases, while algorithm-based approaches such as Data Shapley\nrequire costly retrainings at web scale. Recent Wasserstein-based\nmodel-agnostic methods rely on approximations that misrank examples relative to\ntheir true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,\nmodel-agnostic valuation framework that assigns each example a distributional\ninfluence score: its contribution to the Maximum Mean Discrepancy (MMD) between\nthe empirical training distribution and a clean reference set. Unlike\nWasserstein surrogates, our MMD-based influence admits a closed-form solution\nthat faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,\nrequires no retraining, and naturally extends to conditional kernels for\nunified label- and feature-error detection. Moreover, KAIROS supports efficient\nonline updates: when a new batch of size m arrives, all scores can be updated\nin $O(mN)$ time, delivering up to 50x speedup without compromising ranking\nquality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks\nshow that KAIROS consistently outperforms state-of-the-art model-, Shapley-,\nand Wasserstein-based baselines in both accuracy and runtime. We provide\nrigorous theoretical guarantees, including symmetry for reproducible rankings\nand density-separation for interpretable thresholds.", "published": "2025-06-30 12:44:28", "link": "http://arxiv.org/abs/2506.23799v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Model-driven Stochastic Trace Clustering", "abstract": "Process discovery algorithms automatically extract process models from event\nlogs, but high variability often results in complex and hard-to-understand\nmodels. To mitigate this issue, trace clustering techniques group process\nexecutions into clusters, each represented by a simpler and more understandable\nprocess model. Model-driven trace clustering improves on this by assigning\ntraces to clusters based on their conformity to cluster-specific process\nmodels. However, most existing clustering techniques rely on either no process\nmodel discovery, or non-stochastic models, neglecting the frequency or\nprobability of activities and transitions, thereby limiting their capability to\ncapture real-world execution dynamics. We propose a novel model-driven trace\nclustering method that optimizes stochastic process models within each cluster.\nOur approach uses entropic relevance, a stochastic conformance metric based on\ndirectly-follows probabilities, to guide trace assignment. This allows\nclustering decisions to consider both structural alignment with a cluster's\nprocess model and the likelihood that a trace originates from a given\nstochastic process model. The method is computationally efficient, scales\nlinearly with input size, and improves model interpretability by producing\nclusters with clearer control-flow patterns. Extensive experiments on public\nreal-life datasets show that our method outperforms existing alternatives in\nrepresenting process behavior and reveals how clustering performance rankings\ncan shift when stochasticity is considered.", "published": "2025-06-30 12:18:26", "link": "http://arxiv.org/abs/2506.23776v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach", "abstract": "Every publicly traded U.S. company files an annual 10-K report containing\ncritical insights into financial health and risk. We propose Tiny eXplainable\nRisk Assessor (TinyXRA), a lightweight and explainable transformer-based model\nthat automatically assesses company risk from these reports. Unlike prior work\nthat relies solely on the standard deviation of excess returns (adjusted for\nthe Fama-French model), which indiscriminately penalizes both upside and\ndownside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio\nfor more comprehensive risk assessment. We leverage TinyBERT as our encoder to\nefficiently process lengthy financial documents, coupled with a novel dynamic,\nattention-based word cloud mechanism that provides intuitive risk visualization\nwhile filtering irrelevant terms. This lightweight design ensures scalable\ndeployment across diverse computing environments with real-time processing\ncapabilities for thousands of financial documents which is essential for\nproduction systems with constrained computational resources. We employ triplet\nloss for risk quartile classification, improving over pairwise loss approaches\nin existing literature by capturing both the direction and magnitude of risk\ndifferences. Our TinyXRA achieves state-of-the-art predictive accuracy across\nseven test years on a dataset spanning 2013-2024, while providing transparent\nand interpretable risk assessments. We conduct comprehensive ablation studies\nto evaluate our contributions and assess model explanations both quantitatively\nby systematically removing highly attended words and sentences, and\nqualitatively by examining explanation coherence. The paper concludes with\nfindings, practical implications, limitations, and future research directions.", "published": "2025-06-30 12:13:35", "link": "http://arxiv.org/abs/2506.23767v1", "categories": ["q-fin.RM", "cs.LG"], "primary_category": "q-fin.RM"}
{"title": "Training of Spiking Neural Networks with Expectation-Propagation", "abstract": "In this paper, we propose a unifying message-passing framework for training\nspiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free\nmethod is capable of learning the marginal distributions of network parameters\nand simultaneously marginalizes nuisance parameters, such as the outputs of\nhidden layers. This framework allows for the first time, training of discrete\nand continuous weights, for deterministic and stochastic spiking networks,\nusing batches of training samples. Although its convergence is not ensured, the\nalgorithm converges in practice faster than gradient-based methods, without\nrequiring a large number of passes through the training data. The\nclassification and regression results presented pave the way for new efficient\ntraining methods for deep Bayesian networks.", "published": "2025-06-30 11:59:56", "link": "http://arxiv.org/abs/2506.23757v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies", "abstract": "Recently, researchers have explored ML-based Traffic Engineering (TE),\nleveraging neural networks to solve TE problems traditionally addressed by\noptimization. However, existing ML-based TE schemes remain impractical: they\neither fail to handle topology changes or suffer from poor scalability due to\nexcessive computational and memory overhead. To overcome these limitations, we\npropose Geminet, a lightweight and scalable ML-based TE framework that can\nhandle changing topologies. Geminet is built upon two key insights: (i) a\nmethodology that decouples neural networks from topology by learning an\niterative gradient-descent-based adjustment process, as the update rule of\ngradient descent is topology-agnostic, relying only on a few gradient-related\nquantities; (ii) shifting optimization from path-level routing weights to\nedge-level dual variables, reducing memory consumption by leveraging the fact\nthat edges are far fewer than paths. Evaluations on WAN and data center\ndatasets show that Geminet significantly improves scalability. Its neural\nnetwork size is only 0.04% to 7% of existing schemes, while handling topology\nvariations as effectively as HARP, a state-of-the-art ML-based TE approach,\nwithout performance degradation. When trained on large-scale topologies,\nGeminet consumes under 10 GiB of memory, more than eight times less than the\n80-plus GiB required by HARP, while achieving 5.45 times faster convergence\nspeed, demonstrating its potential for large-scale deployment.", "published": "2025-06-30 09:09:50", "link": "http://arxiv.org/abs/2506.23640v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Overparametrized models with posterior drift", "abstract": "This paper investigates the impact of posterior drift on out-of-sample\nforecasting accuracy in overparametrized machine learning models. We document\nthe loss in performance when the loadings of the data generating process change\nbetween the training and testing samples. This matters crucially in settings in\nwhich regime changes are likely to occur, for instance, in financial markets.\nApplied to equity premium forecasting, our results underline the sensitivity of\na market timing strategy to sub-periods and to the bandwidth parameters that\ncontrol the complexity of the model. For the average investor, we find that\nfocusing on holding periods of 15 years can generate very heterogeneous\nreturns, especially for small bandwidths. Large bandwidths yield much more\nconsistent outcomes, but are far less appealing from a risk-adjusted return\nstandpoint. All in all, our findings tend to recommend cautiousness when\nresorting to large linear models for stock market predictions.", "published": "2025-06-30 08:31:15", "link": "http://arxiv.org/abs/2506.23619v1", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "stat.ML"], "primary_category": "q-fin.ST"}
{"title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning", "abstract": "Federated learning with secure aggregation enables private and collaborative\nlearning from decentralised data without leaking sensitive client information.\nHowever, secure aggregation also complicates the detection of malicious client\nbehaviour and the evaluation of individual client contributions to the\nlearning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et\nal.) were proposed for contribution evaluation (CE) and misbehaviour detection\n(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance\non the random selection of clients in each training round, while FedGT lacks\nthe CE ability. In this work, we combine the strengths of QI and FedGT to\nachieve both robust MD and accurate CE. Our experiments demonstrate superior\nperformance compared to using either method independently.", "published": "2025-06-30 07:40:18", "link": "http://arxiv.org/abs/2506.23583v1", "categories": ["cs.CR", "cs.DC", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A unified framework on the universal approximation of transformer-type architectures", "abstract": "We investigate the universal approximation property (UAP) of transformer-type\narchitectures, providing a unified theoretical framework that extends prior\nresults on residual networks to models incorporating attention mechanisms. Our\nwork identifies token distinguishability as a fundamental requirement for UAP\nand introduces a general sufficient condition that applies to a broad class of\narchitectures. Leveraging an analyticity assumption on the attention layer, we\ncan significantly simplify the verification of this condition, providing a\nnon-constructive approach in establishing UAP for such architectures. We\ndemonstrate the applicability of our framework by proving UAP for transformers\nwith various attention mechanisms, including kernel-based and sparse attention\nmechanisms. The corollaries of our results either generalize prior works or\nestablish UAP for architectures not previously covered. Furthermore, our\nframework offers a principled foundation for designing novel transformer\narchitectures with inherent UAP guarantees, including those with specific\nfunctional symmetries. We propose examples to illustrate these insights.", "published": "2025-06-30 06:50:39", "link": "http://arxiv.org/abs/2506.23551v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Seeding neural network quantum states with tensor network states", "abstract": "We find an efficient approach to approximately convert matrix product states\n(MPSs) into restricted Boltzmann machine wave functions consisting of a\nmultinomial hidden unit through a canonical polyadic (CP) decomposition of the\nMPSs. This method allows us to generate well-behaved initial neural network\nquantum states for quantum many-body ground-state calculations in polynomial\ntime of the number of variational parameters and systematically shorten the\ndistance between the initial states and the ground states with increasing the\nrank of the CP decomposition. We demonstrate the efficiency of our method by\ntaking the transverse-field Ising model as an example and discuss possible\napplications of our method to more general quantum many-body systems in which\nthe ground-state wave functions possess complex nodal structures.", "published": "2025-06-30 06:49:31", "link": "http://arxiv.org/abs/2506.23550v1", "categories": ["cond-mat.str-el", "cs.LG", "cs.NA", "math.NA", "quant-ph"], "primary_category": "cond-mat.str-el"}
{"title": "Neural Langevin Machine: a local asymmetric learning rule can be creative", "abstract": "Fixed points of recurrent neural networks can be leveraged to store and\ngenerate information. These fixed points can be captured by the Boltzmann-Gibbs\nmeasure, which leads to neural Langevin dynamics that can be used for sampling\nand learning a real dataset. We call this type of generative model neural\nLangevin machine, which is interpretable due to its analytic form of\ndistribution and is simple to train. Moreover, the learning process is derived\nas a local asymmetric plasticity rule, bearing biological relevance. Therefore,\none can realize a continuous sampling of creative dynamics in a neural network,\nmimicking an imagination process in brain circuits. This neural Langevin\nmachine may be another promising generative model, at least in its strength in\ncircuit-based sampling and biologically plausible learning rule.", "published": "2025-06-30 06:35:43", "link": "http://arxiv.org/abs/2506.23546v1", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.LG", "cs.NE"], "primary_category": "q-bio.NC"}
{"title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "abstract": "Momentum methods were originally introduced for their superiority to\nstochastic gradient descent (SGD) in deterministic settings with convex\nobjective functions. However, despite their widespread application to deep\nneural networks -- a representative case of stochastic nonconvex optimization\n-- the theoretical justification for their effectiveness in such settings\nremains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that\ngeneralizes various momentum methods and has been studied to better understand\nthe class of momentum-based algorithms as a whole. In this paper, we provide\nboth asymptotic and non-asymptotic convergence results for mini-batch QHM with\nan increasing batch size. We show that achieving asymptotic convergence\nrequires either a decaying learning rate or an increasing batch size. Since a\ndecaying learning rate adversely affects non-asymptotic convergence, we\ndemonstrate that using mini-batch QHM with an increasing batch size -- without\ndecaying the learning rate -- can be a more effective strategy. Our experiments\nshow that even a finite increase in batch size can provide benefits for\ntraining neural networks.", "published": "2025-06-30 06:31:30", "link": "http://arxiv.org/abs/2506.23544v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Test of partial effects for Frechet regression on Bures-Wasserstein manifolds", "abstract": "We propose a novel test for assessing partial effects in Frechet regression\non Bures Wasserstein manifolds. Our approach employs a sample splitting\nstrategy: the first subsample is used to fit the Frechet regression model,\nyielding estimates of the covariance matrices and their associated optimal\ntransport maps, while the second subsample is used to construct the test\nstatistic. We prove that this statistic converges in distribution to a weighted\nmixture of chi squared components, where the weights correspond to the\neigenvalues of an integral operator defined by an appropriate RKHS kernel. We\nestablish that our procedure achieves the nominal asymptotic size and\ndemonstrate that its worst-case power converges uniformly to one. Through\nextensive simulations and a real data application, we illustrate the test's\nfinite-sample accuracy and practical utility.", "published": "2025-06-30 03:20:05", "link": "http://arxiv.org/abs/2506.23487v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection", "abstract": "Graph anomaly detection is critical in domains such as healthcare and\neconomics, where identifying deviations can prevent substantial losses.\nExisting unsupervised approaches strive to learn a single model capable of\ndetecting both attribute and structural anomalies. However, they confront the\ntug-of-war problem between two distinct types of anomalies, resulting in\nsuboptimal performance. This work presents TripleAD, a mutual\ndistillation-based triple-channel graph anomaly detection framework. It\nincludes three estimation modules to identify the attribute, structural, and\nmixed anomalies while mitigating the interference between different types of\nanomalies. In the first channel, we design a multiscale attribute estimation\nmodule to capture extensive node interactions and ameliorate the over-smoothing\nissue. To better identify structural anomalies, we introduce a link-enhanced\nstructure estimation module in the second channel that facilitates information\nflow to topologically isolated nodes. The third channel is powered by an\nattribute-mixed curvature, a new indicator that encapsulates both attribute and\nstructural information for discriminating mixed anomalies. Moreover, a mutual\ndistillation strategy is introduced to encourage communication and\ncollaboration between the three channels. Extensive experiments demonstrate the\neffectiveness of the proposed TripleAD model against strong baselines.", "published": "2025-06-30 02:23:32", "link": "http://arxiv.org/abs/2506.23469v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays", "abstract": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated\nsuperior performance across various visual tasks including medical image\nclassification. However, fairness concerns, including demographic biases, have\nreceived limited attention for CLIP models. This oversight leads to critical\nissues, particularly those related to race and gender, resulting in disparities\nin diagnostic outcomes and reduced reliability for underrepresented groups. To\naddress these challenges, we introduce AdFair-CLIP, a novel framework employing\nadversarial feature intervention to suppress sensitive attributes, thereby\nmitigating spurious correlations and improving prediction fairness. We conduct\ncomprehensive experiments on chest X-ray (CXR) datasets, and show that\nAdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while\nmaintaining robust generalization in zero-shot and few-shot scenarios. These\nresults establish new benchmarks for fairness-aware learning in CLIP-based\nmedical diagnostic models, particularly for CXR analysis.", "published": "2025-06-30 02:19:22", "link": "http://arxiv.org/abs/2506.23467v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "abstract": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings.", "published": "2025-06-30 01:42:31", "link": "http://arxiv.org/abs/2506.23458v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy", "abstract": "Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al.", "published": "2025-06-30 01:36:32", "link": "http://arxiv.org/abs/2506.23456v1", "categories": ["math.ST", "cs.DS", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift", "abstract": "Covariate shift occurs when the distribution of input features differs\nbetween the training and testing phases. In covariate shift, estimating an\nunknown function's moment is a classical problem that remains under-explored,\ndespite its common occurrence in real-world scenarios. In this paper, we\ninvestigate the minimax lower bound of the problem when the source and target\ndistributions are known. To achieve the minimax optimal bound (up to a\nlogarithmic factor), we propose a two-stage algorithm. Specifically, it first\ntrains an optimal estimator for the function under the source distribution, and\nthen uses a likelihood ratio reweighting procedure to calibrate the moment\nestimator. In practice, the source and target distributions are typically\nunknown, and estimating the likelihood ratio may be unstable. To solve this\nproblem, we propose a truncated version of the estimator that ensures double\nrobustness and provide the corresponding upper bound. Extensive numerical\nstudies on synthetic examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.", "published": "2025-06-30 01:32:36", "link": "http://arxiv.org/abs/2506.23453v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders", "abstract": "Insider threat detection presents unique challenges due to the authorized\nstatus of malicious actors and the subtlety of anomalous behaviors. Existing\nmachine learning methods often treat user activity as isolated events, thereby\nfailing to leverage sequential dependencies in user behavior. In this study, we\npropose a User-Based Sequencing (UBS) methodology, transforming the CERT\ninsider threat dataset into structured temporal sequences suitable for deep\nsequential modeling. We deploy a Transformer Encoder architecture to model\nbenign user activity and employ its reconstruction errors as anomaly scores.\nThese scores are subsequently evaluated using three unsupervised outlier\ndetection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and\nIsolation Forest (iForest). Across four rigorously designed test sets,\nincluding combinations of multiple CERT dataset releases, our UBS-Transformer\npipeline consistently achieves state-of-the-art performance - notably 96.61%\naccuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low\nfalse negative (0.0057) and false positive (0.0571) rates. Comparative analyses\ndemonstrate that our approach substantially outperforms tabular and\nconventional autoencoder baselines, underscoring the efficacy of sequential\nuser modeling and advanced anomaly detection in the insider threat domain.", "published": "2025-06-30 00:47:31", "link": "http://arxiv.org/abs/2506.23446v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sparse grids vs. random points for high-dimensional polynomial approximation", "abstract": "We study polynomial approximation on a $d$-cube, where $d$ is large, and\ncompare interpolation on sparse grids, aka Smolyak's algorithm (SA), with a\nsimple least squares method based on randomly generated points (LS) using\nstandard benchmark functions. Our main motivation is the influential paper\n[Barthelmann, Novak, Ritter: High dimensional polynomial interpolation on\nsparse grids, Adv. Comput. Math. 12, 2000]. We repeat and extend their\ntheoretical analysis and numerical experiments for SA and compare to LS in\ndimensions up to 100. Our extensive experiments demonstrate that LS, even with\nonly slight oversampling, consistently matches the accuracy of SA in low\ndimensions. In high dimensions, however, LS shows clear superiority.", "published": "2025-06-30 16:59:26", "link": "http://arxiv.org/abs/2506.24054v1", "categories": ["math.NA", "cs.NA", "65D05 (Primary)"], "primary_category": "math.NA"}
{"title": "Full history recursive multilevel Picard approximations suffer from the curse of dimensionality for the Hamilton-Jacobi-Bellman equation of a stochastic control problem", "abstract": "Full history recursive multilevel Picard (MLP) approximations have been\nproved to overcome the curse of dimensionality in the numerical approximation\nof semilinear heat equations with nonlinearities which are globally Lipschitz\ncontinuous with respect to the maximum-norm. Nonlinearities in\nHamilton-Jacobi-Bellman equations in stochastic control theory, however, are\noften (locally) Lipschitz continuous with respect to the standard Euclidean\nnorm. In this paper we prove the surprising fact that MLP approximations for\none such example equation suffer from the curse of dimensionality.", "published": "2025-06-30 15:37:27", "link": "http://arxiv.org/abs/2506.23969v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Explicit modified Euler approximations of the A\u00eft-Sahalia type model with Poisson jumps", "abstract": "This paper focuses on mean-square approximations of a generalized\nA\\\"it-Sahalia interest rate model with Poisson jumps. The main challenge in the\nconstruction and analysis of time-discrete numerical schemes is caused by a\ndrift that blows up at the origin, highly nonlinear drift and diffusion\ncoefficients and positivity-preserving requirement. Due to the presence of the\nPoisson jumps, additional difficulties arise in recovering the exact order\n$1/2$ of convergence for the time-stepping schemes. By incorporating\nimplicitness in the term $\\alpha_{-1}x^{-1} $ and introducing the modifications\nfunctions $f_h$ and $g_h$ in the recursion, a novel explicit Euler-type scheme\nis proposed, which is easy to implement and preserves the positivity of the\noriginal model unconditionally, i.e., for any time step-size $h>0$. A\nmean-square convergence rate of order $1/2$ is established for the proposed\nscheme in both the non-critical and general critical cases. Finally, numerical\nexperiments are provided to confirm the theoretical findings.", "published": "2025-06-30 15:13:26", "link": "http://arxiv.org/abs/2506.23947v1", "categories": ["math.NA", "cs.NA", "60H35, 60H15, 65C30"], "primary_category": "math.NA"}
{"title": "Structure-preserving approximation of the non-isothermal Cahn-Hilliard system", "abstract": "We propose and analyze a structure-preserving approximation of the\nnon-isothermal Cahn-Hilliard equation using conforming finite elements for the\nspatial discretization and a problem-specific mixed explicit-implicit approach\nfor the temporal discretization. To ensure the preservation of structural\nproperties, i.e. conservation of mass and internal energy as well as entropy\nproduction, we introduce a suitable variational formulation for the continuous\nproblem, based on the entropy equation. Analytical findings are supported by\nnumerical tests, including convergence analysis.", "published": "2025-06-30 15:03:01", "link": "http://arxiv.org/abs/2506.23933v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances", "abstract": "Bayesian inverse problems use observed data to update a prior probability\ndistribution for an unknown state or parameter of a scientific system to a\nposterior distribution conditioned on the data. In many applications, the\nunknown parameter is high-dimensional, making computation of the posterior\nexpensive due to the need to sample in a high-dimensional space and the need to\nevaluate an expensive high-dimensional forward model relating the unknown\nparameter to the data. However, inverse problems often exhibit low-dimensional\nstructure due to the fact that the available data are only informative in a\nlow-dimensional subspace of the parameter space. Dimension reduction approaches\nexploit this structure by restricting inference to the low-dimensional subspace\ninformed by the data, which can be sampled more efficiently. Further\ncomputational cost reductions can be achieved by replacing expensive\nhigh-dimensional forward models with cheaper lower-dimensional reduced models.\nIn this work, we propose new dimension and model reduction approaches for\nlinear Bayesian inverse problems with rank-deficient prior covariances, which\narise in many practical inference settings. The dimension reduction approach is\napplicable to general linear Bayesian inverse problems whereas the model\nreduction approaches are specific to the problem of inferring the initial\ncondition of a linear dynamical system. We provide theoretical approximation\nguarantees as well as numerical experiments demonstrating the accuracy and\nefficiency of the proposed approaches.", "published": "2025-06-30 14:20:58", "link": "http://arxiv.org/abs/2506.23892v1", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY"], "primary_category": "math.NA"}
{"title": "Error analysis for a Finite Element Discretization of a radially symmetric harmonic map heat flow problem", "abstract": "We consider the harmonic map heat flow problem for a radially symmetric case.\nFor discretization of this problem we apply a $H^1$-conforming finite element\nmethod in space combined with a semi-implicit Euler time stepping. The\nsemi-implicit Euler method results in a linear problem in each time step. We\nrestrict to the regime of smooth solutions of the continuous problem and\npresent an error analysis of this discretization method. This results in\noptimal order discretization error bounds. Key ingredients of the analysis are\na discrete energy estimate, that mimics the energy dissipation of the\ncontinuous solution, and a convexity property that is essential for discrete\nstability and for control of the linearization error. We also present numerical\nresults that validate the theoretical ones.", "published": "2025-06-30 11:42:03", "link": "http://arxiv.org/abs/2506.23748v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient Numerical Integration for Finite Element Trunk Spaces in 2D and 3D using Machine Learning: A new Optimisation Paradigm to Construct Application-Specific Quadrature Rules", "abstract": "Finite element methods usually construct basis functions and quadrature rules\nfor multidimensional domains via tensor products of one-dimensional\ncounterparts. While straightforward, this approach results in integration\nspaces larger than necessary, especially as the polynomial degree $p$ or the\nspatial dimension increases, leading to considerable computational overhead.\nThis work starts from the hypothesis that reducing the dimensionality of the\npolynomial space can lead to quadrature rules with fewer points and lower\ncomputational cost, while preserving the exactness of numerical integration. We\nuse trunk spaces that exclude high-degree monomials that do not improve the\napproximation quality of the discrete space. These reduced spaces retain\nsufficient expressive power and allow us to construct smaller (more economical)\nintegration domains. Given a maximum degree $p$, we define trial and test\nspaces $U$ and $V$ as 2D or 3D trunk spaces and form the integration space\n$\\mathcal{S} = U \\otimes V$. We then construct exact quadrature rules by\nsolving a non-convex optimisation problem over the number of points $q$, their\ncoordinates, and weights. We use a shallow neural network with linear\nactivations to parametrise the rule, and a random restart strategy to mitigate\nconvergence to poor local minima. When necessary, we dynamically increase $q$\nto achieve exact integration. Our construction reaches machine-precision\naccuracy (errors below 1e-22) using significantly fewer points than standard\ntensor-product Gaussian quadrature: up to 30\\% reduction in 2D for $p \\leq 10$,\nand 50\\% in 3D for $p \\leq 6$. These results show that combining the\nmathematical understanding of polynomial structure with numerical optimisation\ncan lead to a practical and extensible methodology for improving the\nadaptiveness, efficiency, and scalability of quadrature rules for high-order\nfinite element simulations.", "published": "2025-06-30 11:28:55", "link": "http://arxiv.org/abs/2506.23741v1", "categories": ["math.NA", "cs.NA", "65D32"], "primary_category": "math.NA"}
{"title": "Rectangular $C^1$-$Q_k$ Bell finite elements in two and three dimensions", "abstract": "Both the function and its normal derivative on the element boundary are $Q_k$\npolynomials\n  for the Bogner-Fox-Schmit $C^1$-$Q_k$ finite element functions.\nMathematically, to keep the optimal order of approximation, their spaces are\nrequired to\n  include $P_k$ and $P_{k-1}$ polynomials respectively. We construct a Bell\ntype $C^1$-$Q_k$ finite element on rectangular meshes in 2D and 3D,\n  which has its normal derivative as a $Q_{k-1}$ polynomial on each face, for\n$k\\ge 4$. We show, with a big reduction of the space, the $C^1$-$Q_k$ Bell\n  finite element retains the optimal order of convergence. Numerical\nexperiments are performed, comparing the new elements with the original\nelements.", "published": "2025-06-30 10:25:46", "link": "http://arxiv.org/abs/2506.23702v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the convergence of iterative regularization method assisted by the graph Laplacian with early stopping", "abstract": "We present a data-assisted iterative regularization method for solving\nill-posed inverse problems in Hilbert space settings. The proposed approach,\ntermed \\texttt{IRMGL+\\(\\Psi\\)}, integrates classical iterative techniques with\na data-driven regularization term realized through an iteratively updated graph\nLaplacian. Our method commences by computing a preliminary solution using any\nsuitable reconstruction method, which then serves as the basis for constructing\nthe initial graph Laplacian. The solution is subsequently refined through an\niterative process, where the graph Laplacian is simultaneously recalibrated at\neach step to effectively capture the evolving structure of the solution. A key\ninnovation of this work lies in the formulation of this iterative scheme and\nthe rigorous justification of the classical discrepancy principle as a reliable\nearly stopping criterion specifically tailored to the proposed method. Under\nstandard assumptions, we establish stability and convergence results for the\nscheme when the discrepancy principle is applied. Furthermore, we demonstrate\nthe robustness and effectiveness of our method through numerical experiments\nutilizing four distinct initial reconstructors $\\Psi$: the adjoint operator\n(Adj), filtered back projection (FBP), total variation (TV) denoising, and\nstandard Tikhonov regularization (Tik). It is observed that \\texttt{IRMGL+Adj}\ndemonstrates a distinct advantage over the other initializers, producing a\nrobust and stable approximate solution directly from a basic initial\nreconstruction.", "published": "2025-06-30 03:07:15", "link": "http://arxiv.org/abs/2506.23483v1", "categories": ["math.NA", "cs.NA", "math.FA", "math.OC"], "primary_category": "math.NA"}
{"title": "Fourth-order compact difference schemes for the one-dimensional Euler-Bernoulli beam equation with damping term", "abstract": "This paper proposes and analyzes a finite difference method based on compact\nschemes for the Euler-Bernoulli beam equation with damping terms. The method\nachieves fourth-order accuracy in space and second-order accuracy in time,\nwhile requiring only three spatial grid points within a single compact stencil.\nSpatial discretization is carried out using a compact finite difference scheme,\nwith a variable substitution technique employed to reduce the order of the\nequation and effectively handle the damping terms. For the temporal\ndiscretization, the Crank-Nicolson scheme is applied. The consistency,\nstability, and convergence of the proposed method are rigorously proved.\nNumerical experiments are presented to verify the theoretical results and\ndemonstrate the accuracy and efficiency of the method.", "published": "2025-06-30 01:21:35", "link": "http://arxiv.org/abs/2506.23449v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Explicit local volatility formula for Cheyette-type interest rate models", "abstract": "We derive an explicit analytical approximation for the local volatility\nfunction in the Cheyette interest rate model, extending the classical Dupire\nframework to fixed-income markets. The result expresses local volatility in\nterms of time and strike derivatives of the Bachelier implied variance,\nnaturally generalizes to multi-factor Cheyette models, and provides a practical\ntool for model calibration.", "published": "2025-06-30 14:06:10", "link": "http://arxiv.org/abs/2506.23876v1", "categories": ["q-fin.PR", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "StreamFlow: Streaming Flow Matching with Block-wise Guided Attention Mask for Speech Token Decoding", "abstract": "Recent advancements in discrete token-based speech generation have\nhighlighted the importance of token-to-waveform generation for audio quality,\nparticularly in real-time interactions. Traditional frameworks integrating\nsemantic tokens with flow matching (FM) struggle with streaming capabilities\ndue to their reliance on a global receptive field. Additionally, directly\nimplementing token-by-token streaming speech generation often results in\ndegraded audio quality. To address these challenges, we propose StreamFlow, a\nnovel neural architecture that facilitates streaming flow matching with\ndiffusion transformers (DiT). To mitigate the long-sequence extrapolation\nissues arising from lengthy historical dependencies, we design a local\nblock-wise receptive field strategy. Specifically, the sequence is first\nsegmented into blocks, and we introduce block-wise attention masks that enable\nthe current block to receive information from the previous or subsequent block.\nThese attention masks are combined hierarchically across different DiT-blocks\nto regulate the receptive field of DiTs. Both subjective and objective\nexperimental results demonstrate that our approach achieves performance\ncomparable to non-streaming methods while surpassing other streaming methods in\nterms of speech quality, all the while effectively managing inference time\nduring long-sequence generation. Furthermore, our method achieves a notable\nfirst-packet latency of only 180 ms.\\footnote{Speech samples:\nhttps://dukguo.github.io/StreamFlow/}", "published": "2025-06-30 15:50:08", "link": "http://arxiv.org/abs/2506.23986v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "URGENT-PK: Perceptually-Aligned Ranking Model Designed for Speech Enhancement Competition", "abstract": "The Mean Opinion Score (MOS) is fundamental to speech quality assessment.\nHowever, its acquisition requires significant human annotation. Although deep\nneural network approaches, such as DNSMOS and UTMOS, have been developed to\npredict MOS to avoid this issue, they often suffer from insufficient training\ndata. Recognizing that the comparison of speech enhancement (SE) systems\nprioritizes a reliable system comparison over absolute scores, we propose\nURGENT-PK, a novel ranking approach leveraging pairwise comparisons. URGENT-PK\ntakes homologous enhanced speech pairs as input to predict relative quality\nrankings. This pairwise paradigm efficiently utilizes limited training data, as\nall pairwise permutations of multiple systems constitute a training instance.\nExperiments across multiple open test sets demonstrate URGENT-PK's superior\nsystem-level ranking performance over state-of-the-art baselines, despite its\nsimple network architecture and limited training data.", "published": "2025-06-30 14:05:17", "link": "http://arxiv.org/abs/2506.23874v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Less is More: Data Curation Matters in Scaling Speech Enhancement", "abstract": "The vast majority of modern speech enhancement systems rely on data-driven\nneural network models. Conventionally, larger datasets are presumed to yield\nsuperior model performance, an observation empirically validated across\nnumerous tasks in other domains. However, recent studies reveal diminishing\nreturns when scaling speech enhancement data. We focus on a critical factor:\nprevalent quality issues in ``clean'' training labels within large-scale\ndatasets. This work re-examines this phenomenon and demonstrates that, within\nlarge-scale training sets, prioritizing high-quality training data is more\nimportant than merely expanding the data volume. Experimental findings suggest\nthat models trained on a carefully curated subset of 700 hours can outperform\nmodels trained on the 2,500-hour full dataset. This outcome highlights the\ncrucial role of data curation in scaling speech enhancement systems\neffectively.", "published": "2025-06-30 13:55:10", "link": "http://arxiv.org/abs/2506.23859v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "RELATE: Subjective evaluation dataset for automatic evaluation of relevance between text and audio", "abstract": "In text-to-audio (TTA) research, the relevance between input text and output\naudio is an important evaluation aspect. Traditionally, it has been evaluated\nfrom both subjective and objective perspectives. However, subjective evaluation\nis costly in terms of money and time, and objective evaluation is unclear\nregarding the correlation to subjective evaluation scores. In this study, we\nconstruct RELATE, an open-sourced dataset that subjectively evaluates the\nrelevance. Also, we benchmark a model for automatically predicting the\nsubjective evaluation score from synthesized audio. Our model outperforms a\nconventional CLAPScore model, and that trend extends to many sound categories.", "published": "2025-06-30 07:36:28", "link": "http://arxiv.org/abs/2506.23582v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Human-CLAP: Human-perception-based contrastive language-audio pretraining", "abstract": "Contrastive language-audio pretraining (CLAP) is widely used for audio\ngeneration and recognition tasks. For example, CLAPScore, which utilizes the\nsimilarity of CLAP embeddings, has been a major metric for the evaluation of\nthe relevance between audio and text in text-to-audio. However, the\nrelationship between CLAPScore and human subjective evaluation scores is still\nunclarified. We show that CLAPScore has a low correlation with human subjective\nevaluation scores. Additionally, we propose a human-perception-based CLAP\ncalled Human-CLAP by training a contrastive language-audio model using the\nsubjective evaluation score. In our experiments, the results indicate that our\nHuman-CLAP improved the Spearman's rank correlation coefficient (SRCC) between\nthe CLAPScore and the subjective evaluation scores by more than 0.25 compared\nwith the conventional CLAP.", "published": "2025-06-30 06:57:57", "link": "http://arxiv.org/abs/2506.23553v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Optimized Frequency-Diverse Movable Antenna Arrays for Directional Secrecy in Wireless Systems", "abstract": "Movable-antenna (MA) arrays are envisioned as a promising technique for\nenhancing secrecy performance in wireless communications by leveraging\nadditional spatial degrees of freedom. However, when the eavesdropper is\nlocated in the same direction as the legitimate user, particularly in\nmmWave/THz bands where line-of-sight (LOS) propagation dominates, the secrecy\nperformance of MA arrays becomes significantly limited, thus directionally\ninsecure. To address this challenge, we employ a joint design that combines an\nMA array with a frequency-diverse array (FDA) at the transmitter to secure the\ntransmission across both range and direction. Specifically, we derive\nclosed-form expressions for the optimal antenna positions and frequency shifts,\nassuming small perturbations in both parameters from a linear frequency-diverse\nMA configuration. Furthermore, we compare the worst-case secrecy rate under\nthis minor perturbation assumption with that obtained under a general\nconstraint, where simulated annealing is employed to numerically determine the\noptimal parameters. Simulation results confirm that the proposed optimized\nfrequency diverse MA approach significantly enhances secrecy performance in the\npresence of an eavesdropper aligned with the direction of the legitimate\nreceiver.", "published": "2025-06-30 15:05:43", "link": "http://arxiv.org/abs/2506.23937v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "E-WAN: Efficient Communication in Energy Harvesting Low-Power Networks", "abstract": "The ever-increasing number of distributed embedded systems in the context of\nthe Internet of Things (IoT), Wireless Sensor Networks (WSN), and\nCyber-Physical Systems (CPS) rely on wireless communication to collect and\nexchange data. Nodes can employ single-hop communication which, despite its\nease, may necessitate energy-intensive long-range communication to cover long\ndistances. Conversely, multi-hop communication allows for more energy-efficient\nshort-range communication since nodes can rely on other nodes to forward their\ndata. Yet, this approach requires relay nodes to be available and continuous\nmaintenance of a dynamically changing distributed state. At the same time,\nenergy harvesting has the potential to outperform traditional battery-based\nsystems by improving their lifetime, scalability with lower maintenance costs,\nand environmental impact. However, the limited and temporally and spatially\nvariable harvested energy poses significant challenges for networking in energy\nharvesting networks, particularly considering the energy demands and\ncharacteristics of both multi-hop and single-hop communication. We propose\nE-WAN, a protocol for energy harvesting wide-area low-power networks that\nbuilds on the concept of \\emph{virtual sub-networks} to enable\nresource-efficient multi-hop communication when possible and reliable however\nenergy-intensive point-to-point communication otherwise. Nodes autonomously and\ndynamically move between the two and adjust to changing network states and\nresources based only on easily obtainable network state information. We\nillustrate E-WAN's advantages both in terms of efficiency and adaptability in\nvarious communication and harvesting scenarios. Furthermore, we demonstrate\nE-WAN operating in a realistic setting by deploying an energy harvesting\nnetwork in a real-world indoor environment.", "published": "2025-06-30 12:29:28", "link": "http://arxiv.org/abs/2506.23788v1", "categories": ["eess.SP", "cs.NI"], "primary_category": "eess.SP"}
{"title": "How Long Can I Transmit? A Mobility Aware mmWave-based UAV Communication Framework", "abstract": "One primary focus of next generation wireless communication networks is the\nmillimeterwave (mmWave) spectrum, typically considered in the 30 GHz to 300 GHz\nfrequency range. Despite their promise of high data rates, mmWaves suffer from\nsevere attenuation while passing through obstacles. Unmanned aerial vehicles\n(UAVs) have been proposed to offset this limitation on account of their\nadditional degrees of freedom, which can be leveraged to provide line of sight\n(LoS) transmission paths. While some prior works have proposed analytical\nframeworks to compute the LoS probability for static ground users and a UAV,\nthe same is lacking for mobile users on the ground. In this paper, we consider\nthe popular Manhattan point line process (MPLP) to model an urban environment,\nwithin which a ground user moves with a known velocity for a small time\ninterval along the roads. We derive an expression for the expected duration of\nLoS between a static UAV in the air and a mobile ground user, and validate the\nsame through simulations. To demonstrate the efficacy of the proposed analysis,\nwe propose a simple user association algorithm that greedily assigns the UAVs\nto users with the highest expected LoS time, and show that it outperforms the\nexisting benchmark schemes that assign the users to the nearest UAVs with LoS\nwithout considering the user mobility.", "published": "2025-06-30 11:51:38", "link": "http://arxiv.org/abs/2506.23755v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Wideband Coverage Enhancement for IRS-Aided Wireless Networks Based on Power Measurement", "abstract": "By applying tunable phase shifts to incident waves via passive signal\nreflection, intelligent reflecting surface (IRS) can offer significant\nperformance improvement for wireless communication systems. To reap such\nperformance gain, channel knowledge for IRS-cascaded links is generally\nrequired, which is practically challenging to acquire due to their\nhigh-dimensional and time-varying characteristics. Conventional pilot-based\nchannel estimation incurs excessive overhead due to the large number of\nreflecting elements, thus undermining the IRS efficiency, especially for\nwideband systems with frequency-selective fading channels. To tackle this\nissue, we propose in this letter a power-measurement-based channel\nautocorrelation matrix estimation and coverage enhancement approach for\nIRS-aided orthogonal frequency division multiplexing (OFDM) systems.\nSpecifically, by estimating equivalent channel autocorrelation matrices of\nIRS-cascaded OFDM channels based on receive signal power and optimizing the IRS\nreflection vector based on them, the average coverage performance in the\nIRS-aided region is enhanced without the need for frequent reconfiguration of\nIRS reflection coefficients based on user instantaneous channels. Simulation\nresults validate the effectiveness of the proposed approach for improving the\naverage channel gain over the coverage region.", "published": "2025-06-30 11:46:35", "link": "http://arxiv.org/abs/2506.23750v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wireless Propagation Parameter Estimation with Convolutional Neural Networks", "abstract": "Wireless channel propagation parameter estimation forms the foundation of\nchannel sounding, estimation, modeling, and sensing. This paper introduces a\nDeep Learning approach for joint delay- and Doppler estimation from frequency\nand time samples of a radio channel transfer function.\n  Our work estimates the two-dimensional path parameters from a channel impulse\nresponse containing an unknown number of paths. Compared to existing deep\nlearning-based methods, the parameters are not estimated via classification but\nin a quasi-grid-free manner. We employ a deterministic preprocessing scheme\nthat incorporates a multi-channel windowing to increase the estimator's\nrobustness and enables the use of a CNN architecture. The proposed architecture\nthen jointly estimates the number of paths along with the respective delay and\nDoppler-shift parameters of the paths. Hence, it jointly solves the model order\nselection and parameter estimation task. We also integrate the CNN into an\nexisting maximum-likelihood estimator framework for efficient initialization of\na gradient-based iteration, to provide more accurate estimates.\n  In the analysis, we compare our approach to other methods in terms of\nestimate accuracy and model order error on synthetic data. Finally, we\ndemonstrate its applicability to real-world measurement data from a anechoic\nbi-static RADAR emulation measurement.", "published": "2025-06-30 08:38:27", "link": "http://arxiv.org/abs/2506.23621v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Fast and Accurate 3-D Reconstruction Algorithm for Near-Range Microwave Imaging with Handheld Synthetic Aperture Radar", "abstract": "The design of image reconstruction algorithms for near-range handheld\nsynthetic aperture radar (SAR) systems has gained increasing popularity due to\nthe promising performance of portable millimeter-wave (MMW) imaging devices in\nvarious application fields. Time domain imaging algorithms including the\nbackprojection algorithm (BPA) and the Kirchhoff migration algorithm (KMA) are\nwidely adopted due to their direct applicability to arbitrary scan\ntrajectories. However, they suffer from time complexity issues that hinder\ntheir practical application. Wavenumber domain algorithms greatly improve the\ncomputational efficiency but most of them are restricted to specific array\ntopologies. Based on the factorization techniques as adopted in far-field\nsynthetic aperture radar imaging, the time domain fast factorized\nbackprojection algorithm for handheld synthetic aperture radar (HHFFBPA) is\nproposed. The local spectral properties of the radar images for handheld\nsystems are analyzed and analytical spectrum compression techniques are derived\nto realize efficient sampling of the subimages. Validated through numerical\nsimulations and experiments, HHFFBPA achieves fast and accurate 3-D imaging for\nhandheld synthetic aperture radar systems with arbitrary trajectories.", "published": "2025-06-30 07:22:09", "link": "http://arxiv.org/abs/2506.23568v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Data-Driven Modulation Optimization with LMMSE Equalization for Reliability Enhancement in Underwater Acoustic Communications", "abstract": "Ultra-reliable underwater acoustic (UWA) communications serve as one of the\nkey enabling technologies for future space-air-ground-underwater integrated\nnetworks. However, the reliability of current UWA transmission is still\ninsufficient since severe performance degradation occurs for conventional\nmulticarrier systems in UWA channels with severe delay-scale spread. To solve\nthis problem, we exploit learning-inspired approaches to optimize the\nmodulation scheme under the assumption of linear minimum mean square error\n(LMMSE) equalization, where the discrete representation of waveforms is adopted\nby utilizing Nyquist filters. The optimization problem is first transferred\ninto maximizing the fairness of estimation mean square error (MSE) for each\ndata symbol since the total MSE is invariant considering the property of\northogonal modulation. The Siamese architecture is then adopted to obtain\nconsistent optimization results across various channel conditions, which avoids\nthe overhead of online feedback, cooperation, and deployment of neural networks\nand guarantees generalization. The overall scheme including the loss function,\nneural network structure, and training process is also investigated in depth in\nthis paper. The excellent performance and robustness of the proposed modulation\nscheme are verified by carrying out the bit error rate test over various UWA\nchannels with severe delay-scale spread.", "published": "2025-06-30 07:04:46", "link": "http://arxiv.org/abs/2506.23557v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing for Free: Learn to Localize More Sources than Antennas without Pilots", "abstract": "Integrated sensing and communication (ISAC) represents a key paradigm for\nfuture wireless networks. However, existing approaches require waveform\nmodifications, dedicated pilots, or overhead that complicates standards\nintegration. We propose sensing for free - performing multi-source localization\nwithout pilots by reusing uplink data symbols, making sensing occur during\ntransmission and directly compatible with 3GPP 5G NR and 6G specifications.\nWith ever-increasing devices in dense 6G networks, this approach is\nparticularly compelling when combined with sparse arrays, which can localize\nmore sources than uniform arrays via an enlarged virtual array. Existing\npilot-free multi-source localization algorithms first reconstruct an extended\ncovariance matrix and apply subspace methods, incurring cubic complexity and\nlimited to second-order statistics. Performance degrades under non-Gaussian\ndata symbols and few snapshots, and higher-order statistics remain unexploited.\nWe address these challenges with an attention-only transformer that directly\nprocesses raw signal snapshots for grid-less end-to-end direction-of-arrival\n(DOA) estimation. The model efficiently captures higher-order statistics while\nbeing permutation-invariant and adaptive to varying snapshot counts. Our\nalgorithm greatly outperforms state-of-the-art AI-based benchmarks with over\n30x reduction in parameters and runtime, and enjoys excellent generalization\nunder practical mismatches. Applied to multi-user MIMO beam training, our\nalgorithm can localize uplink DOAs of multiple users during data transmission.\nThrough angular reciprocity, estimated uplink DOAs prune downlink beam sweeping\ncandidates and improve throughput via sensing-assisted beam management. This\nwork shows how reusing existing data transmission for sensing can enhance both\nmulti-source localization and beam management in 3GPP efforts towards 6G.", "published": "2025-06-30 05:21:11", "link": "http://arxiv.org/abs/2506.23525v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Mutli-Level Autoencoder: Deep Learning Based Channel Coding and Modulation", "abstract": "In this paper, we design a deep learning-based convolutional autoencoder for\nchannel coding and modulation. The objective is to develop an adaptive scheme\ncapable of operating at various signal-to-noise ratios (SNR)s without the need\nfor re-training. Additionally, the proposed framework allows validation by\ntesting all possible codes in the codebook, as opposed to previous AI-based\nencoder/decoder frameworks which relied on testing only a small subset of the\navailable codes. This limitation in earlier methods often led to unreliable\nconclusions when generalized to larger codebooks. In contrast to previous\nmethods, our multi-level encoding and decoding approach splits the message into\nblocks, where each encoder block processes a distinct group of $B$ bits. By\ndoing so, the proposed scheme can exhaustively test $2^{B}$ possible codewords\nfor each encoder/decoder level, constituting a layer of the overall scheme. The\nproposed model was compared to classical polar codes and TurboAE-MOD schemes,\nshowing improved reliability with achieving comparable, or even superior\nresults in some settings. Notably, the architecture can adapt to different SNRs\nby selectively removing one of the encoder/decoder layers without re-training,\nthus demonstrating flexibility and efficiency in practical wireless\ncommunication scenarios.", "published": "2025-06-30 04:24:56", "link": "http://arxiv.org/abs/2506.23511v1", "categories": ["eess.SP", "cs.ET"], "primary_category": "eess.SP"}
{"title": "Far-Field vs. Near-Field Propagation Channels: Key Differences and Impact on 6G XL-MIMO Performance Evaluation", "abstract": "Extremely large-scale multiple-input multiple-output (XL-MIMO) is regarded as\na promising technology for next-generation communication systems. However, this\nwill expand the near-field (NF) range, rendering more users more likely to be\nlocated in the NF region. In this paper, we aim to answer two questions: What\nare the new characteristics of the NF channel? Is it necessary to develop new\ntransciver techniques to maintain system performance within the NF region? To\nthis end, we first review current NF channel models and analyze the differences\nbetween the existing 3GPP TR 38.901 channel model and the NF channel model,\nincluding the spherical wavefront and spatially non-stationarity. Then, we\nprovide examples on how these differences affect the XL-MIMO system performance\nin terms of beamforming gain and achievable rate. Simulation results\ndemonstrate that, when using far-field (FF) technique under the NF channel, the\nmaximum normalized beam gain loss is less than 3 dB for most users in the NF\nregion defined by Rayleigh distance. Moreover, the achievable rate loss of beam\ntraining is less than 3% compared to that realized by NF technique. Finally, we\ndemonstrate the necessity of employing NF transceiver techniques based on\nsimulation results.", "published": "2025-06-30 03:39:51", "link": "http://arxiv.org/abs/2506.23495v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Securing the Sky: Integrated Satellite-UAV Physical Layer Security for Low-Altitude Wireless Networks", "abstract": "Low-altitude wireless networks (LAWNs) have garnered significant attention in\nthe forthcoming 6G networks. In LAWNs, satellites with wide coverage and\nunmanned aerial vehicles (UAVs) with flexible mobility can complement each\nother to form integrated satellite-UAV networks, providing ubiquitous and\nhigh-speed connectivity for low-altitude operations. However, the higher\nline-of-sight probability in low-altitude airspace increases transmission\nsecurity concerns. In this work, we present a collaborative beamforming-based\nphysical layer security scheme for LAWNs. We introduce the fundamental aspects\nof integrated satellite-UAV networks, physical layer security, UAV swarms, and\ncollaborative beamforming for LAWN applications. Following this, we highlight\nseveral opportunities for collaborative UAV swarm secure applications enabled\nby satellite networks, including achieving physical layer security in scenarios\ninvolving data dissemination, data relay, eavesdropper collusion, and imperfect\neavesdropper information. Next, we detail two case studies: a secure relay\nsystem and a two-way aerial secure communication framework specifically\ndesigned for LAWN environments. Simulation results demonstrate that these\nphysical layer security schemes are effective and beneficial for secure\nlow-altitude wireless communications. A short practicality analysis shows that\nthe proposed method is applicable to LAWN scenarios. Finally, we discuss\ncurrent challenges and future research directions for enhancing security in\nLAWNs.", "published": "2025-06-30 03:35:42", "link": "http://arxiv.org/abs/2506.23493v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Cooperative Sensing in Cell-free Massive MIMO ISAC Systems: Performance Optimization and Signal Processing", "abstract": "Integrated sensing and communication (ISAC), as a technology enabled seamless\nconnection between communication and sensing, is regarded a core enabling\ntechnology for these applications. However, the accuracy of single-node sensing\nin ISAC system is limited, prompting the emergence of multi-node cooperative\nsensing. In multi-node cooperative sensing, the synchronization error limits\nthe sensing accuracy, which can be mitigated by the architecture of cell-free\nmassive multi-input multi-output (CF-mMIMO), since the multiple nodes are\ninterconnected via optical fibers with high synchronization accuracy. However,\nthe multi-node cooperative sensing in CF-mMIMO ISAC systems faces the following\nchallenges: 1) The joint optimization of placement and resource allocation of\ndistributed access points (APs) to improve the sensing performance in\nmulti-target detection scenario is difficult; 2) The fusion of the sensing\ninformation from distributed APs with multi-view discrepancies is difficult. To\naddress these challenges, this paper proposes a joint placement and antenna\nresource optimization scheme for distributed APs to minimize the sensing\nCramr-Rao bound for targets' parameters within the area of interest. Then, a\nsymbol-level fusion-based multi-dynamic target sensing (SL-MDTS) scheme is\nprovided, effectively fusing sensing information from multiple APs. The\nsimulation results validate the effectiveness of the joint optimization scheme\nand the superiority of the SL-MDTS scheme. Compared to state-of-the-art\ngrid-based symbol-level sensing information fusion schemes, the proposed\nSL-MDTS scheme improves the accuracy of localization and velocity estimation by\n44 % and 41.4 %, respectively.", "published": "2025-06-30 02:36:56", "link": "http://arxiv.org/abs/2506.23473v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Automatic Phase Calibration for High-resolution mmWave Sensing via Ambient Radio Anchors", "abstract": "Millimeter-wave (mmWave) radar systems with large array have pushed radar\nsensing into a new era, thanks to their high angular resolution. However, our\nlong-term experiments indicate that array elements exhibit phase drift over\ntime and require periodic phase calibration to maintain high-resolution,\ncreating an obstacle for practical high-resolution mmWave sensing.\nUnfortunately, existing calibration methods are inadequate for periodic\nrecalibration, either because they rely on artificial references or fail to\nprovide sufficient precision. To address this challenge, we introduce\nAutoCalib, the first framework designed to automatically and accurately\ncalibrate high-resolution mmWave radars by identifying Ambient Radio Anchors\n(ARAs)-naturally existing objects in ambient environments that offer stable\nphase references. AutoCalib achieves calibration by first generating spatial\nspectrum templates based on theoretical electromagnetic characteristics. It\nthen employs a pattern-matching and scoring mechanism to accurately detect\nthese anchors and select the optimal one for calibration. Extensive experiments\nacross 11 environments demonstrate that AutoCalib capable of identifying ARAs\nthat existing methods miss due to their focus on strong reflectors. AutoCalib's\ncalibration performance approaches corner reflectors (74% phase error\nreduction) while outperforming existing methods by 83%. Beyond radar\ncalibration, AutoCalib effectively supports other phase-dependent applications\nlike handheld imaging, delivering 96% of corner reflector calibration\nperformance without artificial references.", "published": "2025-06-30 02:29:49", "link": "http://arxiv.org/abs/2506.23472v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "General Signal Model and Capacity Limit for Rydberg Quantum Information System", "abstract": "Rydberg atomic receivers represent a transformative approach to achieving\nhigh-sensitivity, broadband, and miniaturized radio frequency (RF) reception.\nHowever, existing static signal models for Rydberg atomic receivers rely on the\nsteady-state assumption of atomic quantum states, which cannot fully describe\nthe signal reception process of dynamic signals. To fill in this gap, in this\npaper, we present a general model to compute the dynamic signal response of\nRydberg atomic receivers in closed form. Specifically, by applying small-signal\nperturbation techniques to the quantum master equation, we derive closed-form\nLaplace domain transfer functions that characterize the receiver's dynamic\nresponses to time-varying signal fields. To gain more insights into the\nquantum-based RF-photocurrent conversion process, we further introduce the\nconcept of quantum transconductance that describes the quantum system as an\nequivalent classical system. By applying quantum transconductance, we quantify\nthe influence of in-band blackbody radiation (BBR) noise on the atomic receiver\nsensitivity. Extensive simulations for Rydberg atomic receivers validate the\nproposed signal model, and demonstrate the possibility of quantum receivers to\noutperform classical electronic receivers through the improvement of quantum\ntransconductance.", "published": "2025-06-30 01:36:06", "link": "http://arxiv.org/abs/2506.23455v1", "categories": ["eess.SP", "quant-ph"], "primary_category": "eess.SP"}
{"title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "abstract": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "published": "2025-06-30 17:58:13", "link": "http://arxiv.org/abs/2506.24119v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Intertextual Parallel Detection in Biblical Hebrew: A Transformer-Based Benchmark", "abstract": "Identifying parallel passages in biblical Hebrew (BH) is central to biblical\nscholarship for understanding intertextual relationships. Traditional methods\nrely on manual comparison, a labor-intensive process prone to human error. This\nstudy evaluates the potential of pre-trained transformer-based language models,\nincluding E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in\nthe Hebrew Bible. Focusing on known parallels between Samuel/Kings and\nChronicles, I assessed each model's capability to generate word embeddings\ndistinguishing parallel from non-parallel passages. Using cosine similarity and\nWasserstein Distance measures, I found that E5 and AlephBERT show promise; E5\nexcels in parallel detection, while AlephBERT demonstrates stronger\nnon-parallel differentiation. These findings indicate that pre-trained models\ncan enhance the efficiency and accuracy of detecting intertextual parallels in\nancient texts, suggesting broader applications for ancient language studies.", "published": "2025-06-30 17:57:27", "link": "http://arxiv.org/abs/2506.24117v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs", "abstract": "Multimodal Large Language Models (MLLMs) have achieved success across various\ndomains. However, their applicability tends to degrade when confronted with\ndifferent types of data inputs, especially for MLLMs that have been fine-tuned\nfor specific tasks. Despite its importance, the study of knowledge sharing\namong domain-specific MLLMs--such as those trained for mathematics or\ncode--remains largely underexplored. To address the fragmentation of knowledge\nacross domain-specialized MLLMs, we propose a unified parameter integration\nframework that enables modular composition of expert capabilities. Our method\nis grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,\nwhich leverages both local functional attribution and global\ninformation-theoretic signals to guide selective parameter fusion. By extending\nthis mechanism to the low-rank adaptation layer granularity, we ensure\nefficient integration with minimal inference overhead. Furthermore, we\nintroduce a domain compatibility scoring mechanism that quantifies inter-expert\nalignment at the activation level and correlates with downstream task utility.\nThis principled fusion protocol allows the final model to synergize\nheterogeneous expertise while preserving structural modularity. Extensive\nevaluations across diverse multimodal benchmarks validate the effectiveness of\nour framework, offering a scalable path toward compositional, domain-adaptive\nMLLMs.", "published": "2025-06-30 15:07:41", "link": "http://arxiv.org/abs/2506.23940v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences", "abstract": "Positional bias in binary question answering occurs when a model\nsystematically favors one choice over another based solely on the ordering of\npresented options. In this study, we quantify and analyze positional bias\nacross five large language models under varying degrees of answer uncertainty.\nWe re-adapted the SQuAD-it dataset by adding an extra incorrect answer option\nand then created multiple versions with progressively less context and more\nout-of-context answers, yielding datasets that range from low to high\nuncertainty. Additionally, we evaluate two naturally higher-uncertainty\nbenchmarks: (1) WebGPT - question pairs with unequal human-assigned quality\nscores, and (2) Winning Arguments - where models predict the more persuasive\nargument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order\nof the \"correct\" (or higher-quality/persuasive) option is systematically\nflipped (first placed in position 1, then in position 2) to compute both\nPreference Fairness and Position Consistency. We observe that positional bias\nis nearly absent under low-uncertainty conditions, but grows exponentially when\nit becomes doubtful to decide which option is correct.", "published": "2025-06-30 11:30:23", "link": "http://arxiv.org/abs/2506.23743v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "abstract": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action.", "published": "2025-06-30 15:20:10", "link": "http://arxiv.org/abs/2506.23952v2", "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "primary_category": "cs.HC"}
{"title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning", "abstract": "Imitation learning models for robotic tasks typically rely on multi-modal\ninputs, such as RGB images, language, and proprioceptive states. While\nproprioception is intuitively important for decision-making and obstacle\navoidance, simply incorporating all proprioceptive states leads to a surprising\ndegradation in imitation learning performance. In this work, we identify the\nunderlying issue as the proprioception shift problem, where the distributions\nof proprioceptive states diverge significantly between training and deployment.\nTo address this challenge, we propose a domain adaptation framework that\nbridges the gap by utilizing rollout data collected during deployment. Using\nWasserstein distance, we quantify the discrepancy between expert and rollout\nproprioceptive states and minimize this gap by adding noise to both sets of\nstates, proportional to the Wasserstein distance. This strategy enhances\nrobustness against proprioception shifts by aligning the training and\ndeployment distributions. Experiments on robotic manipulation tasks demonstrate\nthe efficacy of our method, enabling the imitation policy to leverage\nproprioception while mitigating its adverse effects. Our approach outperforms\nthe naive solution which discards proprioception, and other baselines designed\nto address distributional shifts.", "published": "2025-06-30 15:09:14", "link": "http://arxiv.org/abs/2506.23944v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment", "abstract": "The influence of Artificial Intelligence (AI), and specifically Large\nLanguage Models (LLM), on education is continuously increasing. These models\nare frequently used by students, giving rise to the question whether current\nforms of assessment are still a valid way to evaluate student performance and\ncomprehension. The theoretical framework developed in this paper is grounded in\nConstructive Alignment (CA) theory and Bloom's taxonomy for defining learning\nobjectives. We argue that AI influences learning objectives of different Bloom\nlevels in a different way, and assessment has to be adopted accordingly.\nFurthermore, in line with Bloom's vision, formative and summative assessment\nshould be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be\nadapted to the presence of AI, a strong bias exists on the extent to which\nlecturers want to allow for AI in assessment. This bias is caused by a\nlecturer's familiarity with AI and specifically whether they use it themselves.\nTo avoid this bias, we propose structured guidelines on a university or faculty\nlevel, to foster alignment among the staff. Besides that, we argue that\nteaching staff should be trained on the capabilities and limitations of AI\ntools. In this way, they are better able to adapt their assessment methods.", "published": "2025-06-30 13:02:01", "link": "http://arxiv.org/abs/2506.23815v2", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "abstract": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "published": "2025-06-30 05:11:19", "link": "http://arxiv.org/abs/2506.23520v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "abstract": "This paper introduces ZonUI-3B, a lightweight Vision-Language Model (VLM)\nspecifically designed for Graphical User Interface grounding tasks, achieving\nperformance competitive with significantly larger models. Unlike large-scale\nVLMs (>7B parameters) that are computationally intensive and impractical for\nconsumer-grade hardware, ZonUI-3B delivers strong grounding accuracy while\nbeing fully trainable on a single GPU (RTX 4090). The model incorporates\nseveral key innovations: (i) combine cross-platform, multi-resolution dataset\nof 24K examples from diverse sources including mobile, desktop, and web GUI\nscreenshots to effectively address data scarcity in high-resolution desktop\nenvironments; (ii) a two-stage fine-tuning strategy, where initial\ncross-platform training establishes robust GUI understanding, followed by\nspecialized fine-tuning on high-resolution data to significantly enhance model\nadaptability; and (iii) data curation and redundancy reduction strategies,\ndemonstrating that randomly sampling a smaller subset with reduced redundancy\nachieves performance comparable to larger datasets, emphasizing data diversity\nover sheer volume. Empirical evaluation on standard GUI grounding\nbenchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging\nScreenSpot-Pro, highlights ZonUI-3B's exceptional accuracy, achieving 84.9% on\nScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B\nparameters. Ablation studies validate the critical role of balanced sampling\nand two-stage fine-tuning in enhancing robustness, particularly in\nhigh-resolution desktop scenarios. The ZonUI-3B is available at:\nhttps://github.com/Han1018/ZonUI-3B", "published": "2025-06-30 03:33:02", "link": "http://arxiv.org/abs/2506.23491v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives", "abstract": "Time series forecasting traditionally relies on unimodal numerical inputs,\nwhich often struggle to capture high-level semantic patterns due to their dense\nand unstructured nature. While recent approaches have explored representing\ntime series as text using large language models (LLMs), these methods remain\nlimited by the discrete nature of token sequences and lack the perceptual\nintuition humans typically apply, such as interpreting visual patterns. In this\npaper, we propose a multimodal contrastive learning framework that transforms\nraw time series into structured visual and textual perspectives. Rather than\nusing natural language or real-world images, we construct both modalities\ndirectly from numerical sequences. We then align these views in a shared\nsemantic space via contrastive learning, enabling the model to capture richer\nand more complementary representations. Furthermore, we introduce a variate\nselection module that leverages the aligned representations to identify the\nmost informative variables for multivariate forecasting. Extensive experiments\non fifteen short-term and six long-term forecasting benchmarks demonstrate that\nour approach consistently outperforms strong unimodal and cross-modal\nbaselines, highlighting the effectiveness of multimodal alignment in enhancing\ntime series forecasting. Code is available at:\nhttps://github.com/Ironieser/TimesCLIP.", "published": "2025-06-30 17:59:14", "link": "http://arxiv.org/abs/2506.24124v2", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers", "abstract": "Recent progress in multimodal reasoning has been significantly advanced by\ntextual Chain-of-Thought (CoT), a paradigm where models conduct reasoning\nwithin language. This text-centric approach, however, treats vision as a\nstatic, initial context, creating a fundamental \"semantic gap\" between rich\nperceptual data and discrete symbolic thought. Human cognition often transcends\nlanguage, utilizing vision as a dynamic mental sketchpad. A similar evolution\nis now unfolding in AI, marking a fundamental paradigm shift from models that\nmerely think about images to those that can truly think with images. This\nemerging paradigm is characterized by models leveraging visual information as\nintermediate steps in their thought process, transforming vision from a passive\ninput into a dynamic, manipulable cognitive workspace. In this survey, we chart\nthis evolution of intelligence along a trajectory of increasing cognitive\nautonomy, which unfolds across three key stages: from external tool\nexploration, through programmatic manipulation, to intrinsic imagination. To\nstructure this rapidly evolving field, our survey makes four key contributions.\n(1) We establish the foundational principles of the think with image paradigm\nand its three-stage framework. (2) We provide a comprehensive review of the\ncore methods that characterize each stage of this roadmap. (3) We analyze the\ncritical landscape of evaluation benchmarks and transformative applications.\n(4) We identify significant challenges and outline promising future directions.\nBy providing this structured overview, we aim to offer a clear roadmap for\nfuture research towards more powerful and human-aligned multimodal AI.", "published": "2025-06-30 14:48:35", "link": "http://arxiv.org/abs/2506.23918v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View", "abstract": "Panoramic optical flow enables a comprehensive understanding of temporal\ndynamics across wide fields of view. However, severe distortions caused by\nsphere-to-plane projections, such as the equirectangular projection (ERP),\nsignificantly degrade the performance of conventional perspective-based optical\nflow methods, especially in polar regions. To address this challenge, we\npropose PriOr-Flow, a novel dual-branch framework that leverages the\nlow-distortion nature of the orthogonal view to enhance optical flow estimation\nin these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup\n(DCCL) operator, which jointly retrieves correlation information from both the\nprimitive and orthogonal cost volumes, effectively mitigating distortion noise\nduring cost volume construction. Furthermore, our Ortho-Driven Distortion\nCompensation (ODDC) module iteratively refines motion features from both\nbranches, further suppressing polar distortions. Extensive experiments\ndemonstrate that PriOr-Flow is compatible with various perspective-based\niterative optical flow methods and consistently achieves state-of-the-art\nperformance on publicly available panoramic optical flow datasets, setting a\nnew benchmark for wide-field motion estimation. The code is publicly available\nat: https://github.com/longliangLiu/PriOr-Flow.", "published": "2025-06-30 14:30:25", "link": "http://arxiv.org/abs/2506.23897v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue", "abstract": "Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is\na promising method with high translational potential. Unlike bone-mounted\ntracking devices, markerless tracking can reduce operating time and complexity.\nHowever, its use has been limited to cadaveric studies. This paper introduces\nthe first real-world clinical RGB-D dataset for spine surgery and develops\nSpineAlign, a system for capturing deformation between preoperative and\nintraoperative spine states. We also present an intraoperative segmentation\nnetwork trained on this data and introduce CorrespondNet, a multi-task\nframework for predicting key regions for registration in both intraoperative\nand preoperative scenes.", "published": "2025-06-30 09:32:19", "link": "http://arxiv.org/abs/2506.23657v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Simple Approximations for General Spanner Problems", "abstract": "Consider a graph with n nodes and m edges, independent edge weights and\nlengths, and arbitrary distance demands for node pairs. The spanner problem\nasks for a minimum-weight subgraph that satisfies these demands via\nsufficiently short paths w.r.t. the edge lengths. For multiplicative\nalpha-spanners (where demands equal alpha times the original distances) and\nassuming that each edge's weight equals its length, the simple Greedy heuristic\nby Alth\\\"ofer et al. (1993) is known to yield strong solutions, both in theory\nand practice. To obtain guarantees in more general settings, recent\napproximations typically abandon this simplicity and practicality. Still, so\nfar, there is no known non-trivial approximation algorithm for the spanner\nproblem in its most general form. We provide two surprisingly simple\napproximations algorithms. In general, our Augmented Greedy achieves the first\nunconditional approximation ratio of m, which is non-trivial due to the\nindependence of weights and lengths. Crucially, it maintains all size and\nweight guarantees Greedy is known for, i.e., in the aforementioned\nmultiplicative alpha-spanner scenario and even for additive +beta-spanners.\nFurther, it generalizes some of these size guarantees to derive new weight\nguarantees. Our second approach, Randomized Rounding, establishes a graph\ntransformation that allows a simple rounding scheme over a standard\nmulticommodity flow LP. It yields an O(n log n)-approximation, assuming integer\nlengths and polynomially bounded distance demands. The only other known\napproximation guarantee in this general setting requires several complex\nsubalgorithms and analyses, yet we match it up to a factor of O(n^{1/5-eps})\nusing standard tools. Further, on bounded-degree graphs, we yield the first\nO(log n) approximation ratio for constant-bounded distance demands (beyond\nmultiplicative 2-spanners in unit-length graphs).", "published": "2025-06-30 09:05:02", "link": "http://arxiv.org/abs/2506.23638v2", "categories": ["cs.DS", "cs.DM", "math.CO", "68R10 (Primary) 05C85, 90C11 (Secondary)", "F.2.2; G.2.1; G.2.2"], "primary_category": "cs.DS"}
{"title": "Towards the Training of Deeper Predictive Coding Neural Networks", "abstract": "Predictive coding networks trained with equilibrium propagation are neural\nmodels that perform inference through an iterative energy minimization process.\nPrevious studies have demonstrated their effectiveness in shallow\narchitectures, but show significant performance degradation when depth exceeds\nfive to seven layers. In this work, we show that the reason behind this\ndegradation is due to exponentially imbalanced errors between layers during\nweight updates, and predictions from the previous layer not being effective in\nguiding updates in deeper layers. We address the first issue by introducing two\nnovel methods to optimize the latent variables that use precision-weighting to\nre-balance the distribution of energy among layers during the `relaxation\nphase', and the second issue by proposing a novel weight update mechanism that\nreduces error accumulation in deeper layers. Empirically, we test our methods\non a large number of image classification tasks, resulting in large\nimprovements in test accuracy across networks with more than seven layers, with\nperformances comparable to those of backprop on similar models. These findings\nsuggest that a better understanding of the relaxation phase is important to\ntrain models using equilibrium propagation at scale, and open new possibilities\nfor their application in complex tasks.", "published": "2025-06-30 12:44:47", "link": "http://arxiv.org/abs/2506.23800v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size", "abstract": "Momentum methods were originally introduced for their superiority to\nstochastic gradient descent (SGD) in deterministic settings with convex\nobjective functions. However, despite their widespread application to deep\nneural networks -- a representative case of stochastic nonconvex optimization\n-- the theoretical justification for their effectiveness in such settings\nremains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that\ngeneralizes various momentum methods and has been studied to better understand\nthe class of momentum-based algorithms as a whole. In this paper, we provide\nboth asymptotic and non-asymptotic convergence results for mini-batch QHM with\nan increasing batch size. We show that achieving asymptotic convergence\nrequires either a decaying learning rate or an increasing batch size. Since a\ndecaying learning rate adversely affects non-asymptotic convergence, we\ndemonstrate that using mini-batch QHM with an increasing batch size -- without\ndecaying the learning rate -- can be a more effective strategy. Our experiments\nshow that even a finite increase in batch size can provide benefits for\ntraining neural networks.", "published": "2025-06-30 06:31:30", "link": "http://arxiv.org/abs/2506.23544v2", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs", "abstract": "Portable and wearable consumer-grade electroencephalography (EEG) devices,\nlike Muse headbands, offer unprecedented mobility for daily brain-computer\ninterface (BCI) applications, including cognitive load detection. However, the\nexacerbated non-stationarity in portable EEG signals constrains data fidelity\nand decoding accuracy, creating a fundamental trade-off between portability and\nperformance. To mitigate such limitation, we propose MuseCogNet (Muse-based\nCognitive Network), a unified joint learning framework integrating\nself-supervised and supervised training paradigms. In particular, we introduce\nan EEG-grounded self-supervised reconstruction loss based on average pooling to\ncapture robust neurophysiological patterns, while cross-entropy loss refines\ntask-specific cognitive discriminants. This joint learning framework resembles\nthe bottom-up and top-down attention in humans, enabling MuseCogNet to\nsignificantly outperform state-of-the-art methods on a publicly available Muse\ndataset and establish an implementable pathway for neurocognitive monitoring in\necological settings.", "published": "2025-06-30 01:42:31", "link": "http://arxiv.org/abs/2506.23458v2", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "StreamFlow: Streaming Flow Matching with Block-wise Guided Attention Mask for Speech Token Decoding", "abstract": "Recent advancements in discrete token-based speech generation have\nhighlighted the importance of token-to-waveform generation for audio quality,\nparticularly in real-time interactions. Traditional frameworks integrating\nsemantic tokens with flow matching (FM) struggle with streaming capabilities\ndue to their reliance on a global receptive field. Additionally, directly\nimplementing token-by-token streaming speech generation often results in\ndegraded audio quality. To address these challenges, we propose StreamFlow, a\nnovel neural architecture that facilitates streaming flow matching with\ndiffusion transformers (DiT). To mitigate the long-sequence extrapolation\nissues arising from lengthy historical dependencies, we design a local\nblock-wise receptive field strategy. Specifically, the sequence is first\nsegmented into blocks, and we introduce block-wise attention masks that enable\nthe current block to receive information from the previous or subsequent block.\nThese attention masks are combined hierarchically across different DiT-blocks\nto regulate the receptive field of DiTs. Both subjective and objective\nexperimental results demonstrate that our approach achieves performance\ncomparable to non-streaming methods while surpassing other streaming methods in\nterms of speech quality, all the while effectively managing inference time\nduring long-sequence generation. Furthermore, our method achieves a notable\nfirst-packet latency of only 180 ms.\\footnote{Speech samples:\nhttps://dukguo.github.io/StreamFlow/}", "published": "2025-06-30 15:50:08", "link": "http://arxiv.org/abs/2506.23986v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Linear Layouts of Graphs with Priority Queues", "abstract": "A linear layout of a graph consists of a linear ordering of its vertices and\na partition of its edges into pages such that the edges assigned to the same\npage obey some constraint. The two most prominent and widely studied types of\nlinear layouts are stack and queue layouts, in which any two edges assigned to\nthe same page are forbidden to cross and nest, respectively. The names of these\ntwo layouts derive from the fact that, when parsing the graph according to the\nlinear vertex ordering, the edges in a single page can be stored using a single\nstack or queue, respectively. Recently, the concepts of stack and queue layouts\nhave been extended by using a double-ended queue or a restricted-input queue\nfor storing the edges of a page. We extend this line of study to edge-weighted\ngraphs by introducing priority queue layouts, that is, the edges on each page\nare stored in a priority queue whose keys are the edge weights. First, we show\nthat there are edge-weighted graphs that require a linear number of priority\nqueues. Second, we characterize the graphs that admit a priority queue layout\nwith a single queue, regardless of the edge-weight function, and we provide an\nefficient recognition algorithm. Third, we show that the number of priority\nqueues required independently of the edge-weight function is bounded by the\npathwidth of the graph, but can be arbitrarily large already for graphs of\ntreewidth two. Finally, we prove that determining the minimum number of\npriority queues is NP-complete if the linear ordering of the vertices is fixed.", "published": "2025-06-30 15:09:14", "link": "http://arxiv.org/abs/2506.23943v2", "categories": ["cs.DM", "cs.CG"], "primary_category": "cs.DM"}
{"title": "Elias' Encoding from Lagrangians and Renormalization", "abstract": "An efficient approach to universality and optimality of binary codes for\nintegers known as Elias' encoding can be deduced from the classical constrained\noptimization and renormalization techniques. The most important properties,\nsuch as being a universal prefix code, also follow naturally.", "published": "2025-06-30 01:01:17", "link": "http://arxiv.org/abs/2506.23447v2", "categories": ["cs.IT", "math-ph", "math.IT", "math.MP", "H.1.1"], "primary_category": "cs.IT"}
{"title": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones", "abstract": "Despite remarkable advances in coding capabilities, language models (LMs)\nstill struggle with simple syntactic tasks such as generating balanced\nparentheses. In this study, we investigate the underlying mechanisms behind the\npersistence of these errors across LMs of varying sizes (124M-7B) to both\nunderstand and mitigate the errors. Our study reveals that LMs rely on a number\nof components (attention heads and FF neurons) that independently make their\nown predictions. While some components reliably promote correct answers across\na generalized range of inputs (i.e., implementing \"sound mechanisms''), others\nare less reliable and introduce noise by promoting incorrect tokens (i.e.,\nimplementing \"faulty mechanisms''). Errors occur when the faulty mechanisms\novershadow the sound ones and dominantly affect the predictions. Motivated by\nthis insight, we introduce RASteer, a steering method to systematically\nidentify and increase the contribution of reliable components for improving\nmodel performance. RASteer substantially improves performance on balanced\nparentheses tasks, boosting accuracy of some models from $0$% to around $100$%\nwithout impairing the models' general coding ability. We further demonstrate\nits broader applicability in arithmetic reasoning tasks, achieving performance\ngains of up to around $20$%.", "published": "2025-06-30 23:35:19", "link": "http://arxiv.org/abs/2507.00322v1", "categories": ["cs.CL", "cs.AI", "cs.SE", "I.2.7"], "primary_category": "cs.CL"}
{"title": "$\u03bc^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation", "abstract": "Automated radiology report generation (RRG) aims to produce detailed textual\nreports from clinical imaging, such as computed tomography (CT) scans, to\nimprove the accuracy and efficiency of diagnosis and provision of management\nadvice. RRG is complicated by two key challenges: (1) inherent complexity in\nextracting relevant information from imaging data under resource constraints,\nand (2) difficulty in objectively evaluating discrepancies between\nmodel-generated and expert-written reports. To address these challenges, we\npropose $\\mu^2$LLM, a $\\underline{\\textbf{mu}}$ltiscale\n$\\underline{\\textbf{mu}}$ltimodal large language models for RRG tasks. The\nnovel ${\\mu}^2$Tokenizer, as an intermediate layer, integrates multi-modal\nfeatures from the multiscale visual tokenizer and the text tokenizer, then\nenhances report generation quality through direct preference optimization\n(DPO), guided by GREEN-RedLlama. Experimental results on four large CT\nimage-report medical datasets demonstrate that our method outperforms existing\napproaches, highlighting the potential of our fine-tuned $\\mu^2$LLMs on limited\ndata for RRG tasks. At the same time, for prompt engineering, we introduce a\nfive-stage, LLM-driven pipeline that converts routine CT reports into paired\nvisual-question-answer triples and citation-linked reasoning narratives,\ncreating a scalable, high-quality supervisory corpus for explainable multimodal\nradiology LLM. All code, datasets, and models will be publicly available in our\nofficial repository. https://github.com/Siyou-Li/u2Tokenizer", "published": "2025-06-30 23:14:49", "link": "http://arxiv.org/abs/2507.00316v2", "categories": ["cs.LG", "cs.CL", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Open-ended Scientific Discovery via Bayesian Surprise", "abstract": "The promise of autonomous scientific discovery (ASD) hinges not only on\nanswering questions, but also on knowing which questions to ask. Most recent\nworks in ASD explore the use of large language models (LLMs) in goal-driven\nsettings, relying on human-specified research questions to guide hypothesis\ngeneration. However, scientific discovery may be accelerated further by\nallowing the AI system to drive exploration by its own criteria. The few\nexisting approaches in open-ended ASD select hypotheses based on diversity\nheuristics or subjective proxies for human interestingness, but the former\nstruggles to meaningfully navigate the typically vast hypothesis space, and the\nlatter suffers from imprecise definitions. This paper presents AutoDS -- a\nmethod for open-ended ASD that instead drives scientific exploration using\nBayesian surprise. Here, we quantify the epistemic shift from the LLM's prior\nbeliefs about a hypothesis to its posterior beliefs after gathering\nexperimental results. To efficiently explore the space of nested hypotheses,\nour method employs a Monte Carlo tree search (MCTS) strategy with progressive\nwidening using surprisal as the reward function. We evaluate AutoDS in the\nsetting of data-driven discovery across 21 real-world datasets spanning domains\nsuch as biology, economics, finance, and behavioral science. Our results\ndemonstrate that under a fixed budget, AutoDS substantially outperforms\ncompetitors by producing 5--29\\% more discoveries deemed surprising by the LLM.\nOur human evaluation further finds that two-thirds of AutoDS discoveries are\nsurprising to the domain experts, suggesting this is an important step forward\ntowards building open-ended ASD systems.", "published": "2025-06-30 22:53:59", "link": "http://arxiv.org/abs/2507.00310v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Natural language processing for African languages", "abstract": "Recent advances in word embeddings and language models use large-scale,\nunlabelled data and self-supervised learning to boost NLP performance.\nMultilingual models, often trained on web-sourced data like Wikipedia, face\nchallenges: few low-resource languages are included, their data is often noisy,\nand lack of labeled datasets makes it hard to evaluate performance outside\nhigh-resource languages like English. In this dissertation, we focus on\nlanguages spoken in Sub-Saharan Africa where all the indigenous languages in\nthis region can be regarded as low-resourced in terms of the availability of\nlabelled data for NLP tasks and unlabelled data found on the web. We analyse\nthe noise in the publicly available corpora, and curate a high-quality corpus,\ndemonstrating that the quality of semantic representations learned in word\nembeddings does not only depend on the amount of data but on the quality of\npre-training data. We demonstrate empirically the limitations of word\nembeddings, and the opportunities the multilingual pre-trained language model\n(PLM) offers especially for languages unseen during pre-training and\nlow-resource scenarios. We further study how to adapt and specialize\nmultilingual PLMs to unseen African languages using a small amount of\nmonolingual texts. To address the under-representation of the African languages\nin NLP research, we developed large scale human-annotated labelled datasets for\n21 African languages in two impactful NLP tasks: named entity recognition and\nmachine translation. We conduct an extensive empirical evaluation using\nstate-of-the-art methods across supervised, weakly-supervised, and transfer\nlearning settings.", "published": "2025-06-30 22:26:36", "link": "http://arxiv.org/abs/2507.00297v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Impact of Fine-Tuning Methods on Memorization in Large Language Models", "abstract": "As the capabilities of pre-trained large language models (LLMs) continue to\nadvance, the \"pre-train and fine-tune\" paradigm has become increasingly\nmainstream, leading to the development of various fine-tuning methods. However,\nthe privacy risks arising from memorization during fine-tuning have received\nrelatively little attention. To address this gap, we categorize popular\nfine-tuning approaches and assess their impact on memorization through the lens\nof membership inference attacks (MIAs). Our results show that, compared to\nparameter-based fine-tuning, prompt-based fine-tuning achieves competitive\nperformance while exhibiting lower vulnerability to MIAs. Furthermore,\nprompt-based methods maintain low memorization regardless of model scale. These\nfindings suggest that parameter-based fine-tuning is more prone to leaking\nprivate information, whereas prompt-based fine-tuning serves as a more\nprivacy-preserving option.", "published": "2025-06-30 20:52:15", "link": "http://arxiv.org/abs/2507.00258v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Faces in rectilinear drawings of complete graphs", "abstract": "We initiate the study of extremal problems about faces in convex rectilinear\ndrawings of~$K_n$, that is, drawings where vertices are represented by points\nin the plane in convex position and edges by line segments between the points\nrepresenting the end-vertices. We show that if a convex rectilinear drawing of\n$K_n$ does not contain a common interior point of at least three edges, then\nthere is always a face forming a convex 5-gon while there are such drawings\nwithout any face forming a convex $k$-gon with $k \\geq 6$.\n  A convex rectilinear drawing of $K_n$ is \\emph{regular} if its vertices\ncorrespond to vertices of a regular convex $n$-gon. We characterize positive\nintegers $n$ for which regular drawings of $K_n$ contain a face forming a\nconvex 5-gon.\n  To our knowledge, this type of problems has not been considered in the\nliterature before and so we also pose several new natural open problems.", "published": "2025-06-30 23:08:26", "link": "http://arxiv.org/abs/2507.00313v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Compact Representation of Semilinear and Terrain-like Graphs", "abstract": "We consider the existence and construction of \\textit{biclique covers} of\ngraphs, consisting of coverings of their edge sets by complete bipartite\ngraphs. The \\textit{size} of such a cover is the sum of the sizes of the\nbicliques. Small-size biclique covers of graphs are ubiquitous in computational\ngeometry, and have been shown to be useful compact representations of graphs.\nWe give a brief survey of classical and recent results on biclique covers and\ntheir applications, and give new families of graphs having biclique covers of\nnear-linear size.\n  In particular, we show that semilinear graphs, whose edges are defined by\nlinear relations in bounded dimensional space, always have biclique covers of\nsize $O(n\\polylog n)$. This generalizes many previously known results on\nspecial classes of graphs including interval graphs, permutation graphs, and\ngraphs of bounded boxicity, but also new classes such as intersection graphs of\nL-shapes in the plane. It also directly implies the bounds for Zarankiewicz's\nproblem derived by Basit, Chernikov, Starchenko, Tao, and Tran (\\textit{Forum\nMath. Sigma}, 2021).\n  We also consider capped graphs, also known as terrain-like graphs, defined as\nordered graphs forbidding a certain ordered pattern on four vertices.\nTerrain-like graphs contain the induced subgraphs of terrain visibility graphs.\nWe give an elementary proof that these graphs admit biclique partitions of size\n$O(n\\log^3 n)$. This provides a simple combinatorial analogue of a classical\nresult from Agarwal, Alon, Aronov, and Suri on polygon visibility graphs\n(\\textit{Discrete Comput. Geom.} 1994).\n  Finally, we prove that there exists families of unit disk graphs on $n$\nvertices that do not admit biclique coverings of size $o(n^{4/3})$, showing\nthat we are unlikely to improve on Szemer\\'edi-Trotter type incidence bounds\nfor higher-degree semialgebraic graphs.", "published": "2025-06-30 20:39:44", "link": "http://arxiv.org/abs/2507.00252v1", "categories": ["math.CO", "cs.CG", "cs.DM", "05C75, 05C85", "G.2.2; F.2.2"], "primary_category": "math.CO"}
{"title": "$\u03c3$-Maximal Ancestral Graphs", "abstract": "Maximal Ancestral Graphs (MAGs) provide an abstract representation of\nDirected Acyclic Graphs (DAGs) with latent (selection) variables. These\ngraphical objects encode information about ancestral relations and\nd-separations of the DAGs they represent. This abstract representation has been\nused amongst others to prove the soundness and completeness of the FCI\nalgorithm for causal discovery, and to derive a do-calculus for its output. One\nsignificant inherent limitation of MAGs is that they rule out the possibility\nof cyclic causal relationships. In this work, we address that limitation. We\nintroduce and study a class of graphical objects that we coin\n''$\\sigma$-Maximal Ancestral Graphs'' (''$\\sigma$-MAGs''). We show how these\ngraphs provide an abstract representation of (possibly cyclic) Directed Graphs\n(DGs) with latent (selection) variables, analogously to how MAGs represent\nDAGs. We study the properties of these objects and provide a characterization\nof their Markov equivalence classes.", "published": "2025-06-30 10:08:21", "link": "http://arxiv.org/abs/2507.00093v1", "categories": ["cs.DM", "cs.AI", "cs.DS", "math.ST", "stat.TH"], "primary_category": "cs.DM"}
{"title": "Embedding-based Retrieval in Multimodal Content Moderation", "abstract": "Video understanding plays a fundamental role for content moderation on short\nvideo platforms, enabling the detection of inappropriate content. While\nclassification remains the dominant approach for content moderation, it often\nstruggles in scenarios requiring rapid and cost-efficient responses, such as\ntrend adaptation and urgent escalations. To address this issue, we introduce an\nEmbedding-Based Retrieval (EBR) method designed to complement traditional\nclassification approaches. We first leverage a Supervised Contrastive Learning\n(SCL) framework to train a suite of foundation embedding models, including both\nsingle-modal and multi-modal architectures. Our models demonstrate superior\nperformance over established contrastive learning methods such as CLIP and\nMoCo. Building on these embedding models, we design and implement the\nembedding-based retrieval system that integrates embedding generation and video\nretrieval to enable efficient and effective trend handling. Comprehensive\noffline experiments on 25 diverse emerging trends show that EBR improves\nROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online\nexperiments reveal that EBR increases action rates by 10.32% and reduces\noperational costs by over 80%, while also enhancing interpretability and\nflexibility compared to classification-based solutions.", "published": "2025-06-30 19:11:25", "link": "http://arxiv.org/abs/2507.01066v1", "categories": ["cs.IR", "cs.CV", "cs.LG"], "primary_category": "cs.IR"}
{"title": "FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations", "abstract": "Online dating platforms have fundamentally transformed the formation of\nromantic relationships, with millions of users worldwide relying on algorithmic\nmatching systems to find compatible partners. However, current recommendation\nsystems in dating applications suffer from significant algorithmic\ndeficiencies, including but not limited to popularity bias, filter bubble\neffects, and inadequate reciprocity modeling that limit effectiveness and\nintroduce harmful biases. This research integrates foundational work with\nrecent empirical findings to deliver a detailed analysis of dating app\nrecommendation systems, highlighting key issues and suggesting research-backed\nsolutions. Through analysis of reciprocal recommendation frameworks, fairness\nevaluation metrics, and industry implementations, we demonstrate that current\nsystems achieve modest performance with collaborative filtering reaching 25.1\\%\nwhile reciprocal methods achieve 28.7\\%. Our proposed mathematical framework\naddresses these limitations through enhanced similarity measures,\nmulti-objective optimization, and fairness-aware algorithms that maintain\ncompetitive accuracy while improving demographic representation to reduce\nalgorithmic bias.", "published": "2025-06-30 10:36:57", "link": "http://arxiv.org/abs/2507.01063v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Optimizing Conversational Product Recommendation via Reinforcement Learning", "abstract": "We propose a reinforcement learning-based approach to optimize conversational\nstrategies for product recommendation across diverse industries. As\norganizations increasingly adopt intelligent agents to support sales and\nservice operations, the effectiveness of a conversation hinges not only on what\nis recommended but how and when recommendations are delivered. We explore a\nmethodology where agentic systems learn optimal dialogue policies through\nfeedback-driven reinforcement learning. By mining aggregate behavioral patterns\nand conversion outcomes, our approach enables agents to refine talk tracks that\ndrive higher engagement and product uptake, while adhering to contextual and\nregulatory constraints. We outline the conceptual framework, highlight key\ninnovations, and discuss the implications for scalable, personalized\nrecommendation in enterprise environments.", "published": "2025-06-30 00:59:58", "link": "http://arxiv.org/abs/2507.01060v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD", "abstract": "In this work, we propose a lightweight decoder based solely on\nbelief-propagation (BP), augmented with a speculative post-processing strategy\ninspired by classical Chase decoding. Our method identifies unreliable bits via\nBP oscillation statistics, generates a set of modified test patterns, and\ndecodes them in parallel using low-iteration BP. We demonstrate that our\napproach can achieve logical error rates comparable to or even better than\nBP-OSD, but has lower latency over its parallelization for a variety of\nbivariate bicycle codes, which significantly reduces decoding complexity.", "published": "2025-06-30 20:47:28", "link": "http://arxiv.org/abs/2507.00254v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise", "abstract": "AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform\nentropy directly from physical noise, eliminating the need for bulky quantum\ndevices or expensive laboratory-grade RF receivers. Instead, it relies on a\nlow-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and\nthen emits 32-bit high-entropy streams without any quantization step.\n  Unlike deterministic or trained artificial intelligence random number\ngenerators (RNGs), our dynamic inner-outer network couples adaptive natural\nsources and reseeding, yielding truly unpredictable and autonomous sequences.\nGenerated numbers pass the NIST SP 800-22 battery better than a CPU-based\nmethod. It also passes nineteen bespoke statistical tests for both bit- and\ninteger-level analysis. All results satisfy cryptographic standards, while\nforward and backward prediction experiments reveal no exploitable biases. The\nmodel's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft\ncores, as well as suitable for other resource-constrained platforms.\n  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG\nbroadens the reach of high-integrity random number generators across secure\nsystems, cryptographic protocols, embedded and edge devices, stochastic\nsimulations, and server applications that need randomness.", "published": "2025-06-30 18:01:40", "link": "http://arxiv.org/abs/2507.00145v1", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.CR"}
{"title": "Functional Renormalization for Signal Detection: Dimensional Analysis and Dimensional Phase Transition for Nearly Continuous Spectra Effective Field Theory", "abstract": "Signal detection is one of the main challenges of data science. According to\nthe nature of the data, the presence of noise may corrupt measurements and\nhinder the discovery of significant patterns. A wide range of techniques aiming\nat extracting the relevant degrees of freedom from data has been thus developed\nover the years. However, signal detection in almost continuous spectra, for\nsmall signal-to-noise ratios, remains a known difficult issue. This paper\ndevelops over recent advancements proposing to tackle this issue by analysing\nthe properties of the underlying effective field theory arising as a sort of\nmaximal entropy distribution in the vicinity of universal random matrix\ndistributions. Nearly continuous spectra provide an intrinsic and\nnon-conventional scaling law for field and couplings, the scaling dimensions\ndepending on the energy scale. The coarse-graining over small eigenvalues of\nthe empirical spectrum defines a specific renormalization group, whose\ncharacteristics change when the collective behaviour of \"informational\" modes\nbecome significant, that is, stronger than the intrinsic fluctuations of noise.\nThis paper pursues three different goals. First, we propose to quantify the\nreal effects of fluctuations relative to what can be called \"signal\", while\nimproving the robustness of the results obtained in our previous work. Second,\nwe show that quantitative changes in the presence of a signal result in a\ncounterintuitive modification of the distribution of eigenvectors. Finally, we\npropose a method for estimating the number of noise components and define a\nlimit of detection in a general nearly continuous spectrum using the\nrenormalization group. The main statements of this paper are essentially\nnumeric, and their reproducibility can be checked using the associated code.", "published": "2025-06-30 18:00:09", "link": "http://arxiv.org/abs/2507.01064v1", "categories": ["physics.data-an", "cond-mat.stat-mech", "cs.IT", "hep-th", "math.IT", "stat.ME"], "primary_category": "physics.data-an"}
{"title": "On the Optimality of Coded Distributed Computing for Ring Networks", "abstract": "We consider a coded distributed computing problem in a ring-based\ncommunication network, where $N$ computing nodes are arranged in a ring\ntopology and each node can only communicate with its neighbors within a\nconstant distance $d$. To mitigate the communication bottleneck in exchanging\nintermediate values, we propose new coded distributed computing schemes for the\nring-based network that exploit both ring topology and redundant computation\n(i.e., each map function is computed by $r$ nodes). Two typical cases are\nconsidered: all-gather where each node requires all intermediate values mapped\nfrom all input files, and all-to-all where each node requires a distinct set of\nintermediate values from other nodes. For the all-gather case, we propose a new\ncoded scheme based on successive reverse carpooling where nodes transmit every\nencoded packet containing two messages traveling in opposite directions along\nthe same path. Theoretical converse proof shows that our scheme achieves the\noptimal tradeoff between communication load, computation load $r$, and\nbroadcast distance $d$ when $N\\gg d$. For the all-to-all case, instead of\nsimply repeating our all-gather scheme, we delicately deliver intermediate\nvalues based on their proximity to intended nodes to reduce unnecessary\ntransmissions. We derive an information-theoretic lower bound on the optimal\ncommunication load and show that our scheme is asymptotically optimal under the\ncyclic placement when $N\\gg r$. The optimality results indicate that in\nring-based networks, the redundant computation $r$ only leads to an additive\ngain in reducing communication load while the broadcast distance $d$\ncontributes to a multiplicative gain.", "published": "2025-06-30 09:51:19", "link": "http://arxiv.org/abs/2507.00091v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness", "abstract": "This thesis contributes to the theoretical understanding of local update\nalgorithms, especially Local SGD, in distributed and federated optimization\nunder realistic models of data heterogeneity. A central focus is on the bounded\nsecond-order heterogeneity assumption, which is shown to be both necessary and\nsufficient for local updates to outperform centralized or mini-batch methods in\nconvex and non-convex settings. The thesis establishes tight upper and lower\nbounds in several regimes for various local update algorithms and characterizes\nthe min-max complexity of multiple problem classes. At its core is a\nfine-grained consensus-error-based analysis framework that yields sharper\nfinite-time convergence bounds under third-order smoothness and relaxed\nheterogeneity assumptions. The thesis also extends to online federated\nlearning, providing fundamental regret bounds under both first-order and bandit\nfeedback. Together, these results clarify when and why local updates offer\nprovable advantages, and the thesis serves as a self-contained guide for\nanalyzing Local SGD in heterogeneous environments.", "published": "2025-06-30 19:06:02", "link": "http://arxiv.org/abs/2507.00195v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "State and Memory is All You Need for Robust and Reliable AI Agents", "abstract": "Large language models (LLMs) have enabled powerful advances in natural\nlanguage understanding and generation. Yet their application to complex,\nreal-world scientific workflows remain limited by challenges in memory,\nplanning, and tool integration. Here, we introduce SciBORG (Scientific Bespoke\nArtificial Intelligence Agents Optimized for Research Goals), a modular agentic\nframework that allows LLM-based agents to autonomously plan, reason, and\nachieve robust and reliable domain-specific task execution. Agents are\nconstructed dynamically from source code documentation and augmented with\nfinite-state automata (FSA) memory, enabling persistent state tracking and\ncontext-aware decision-making. This approach eliminates the need for manual\nprompt engineering and allows for robust, scalable deployment across diverse\napplications via maintaining context across extended workflows and to recover\nfrom tool or execution failures. We validate SciBORG through integration with\nboth physical and virtual hardware, such as microwave synthesizers for\nexecuting user-specified reactions, with context-aware decision making and\ndemonstrate its use in autonomous multi-step bioassay retrieval from the\nPubChem database utilizing multi-step planning, reasoning, agent-to-agent\ncommunication and coordination for execution of exploratory tasks. Systematic\nbenchmarking shows that SciBORG agents achieve reliable execution, adaptive\nplanning, and interpretable state transitions. Our results show that memory and\nstate awareness are critical enablers of agentic planning and reliability,\noffering a generalizable foundation for deploying AI agents in complex\nenvironments.", "published": "2025-06-30 02:02:35", "link": "http://arxiv.org/abs/2507.00081v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.ET", "physics.chem-ph"], "primary_category": "cs.MA"}
{"title": "Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations", "abstract": "This work presents structure-preserving Lift & Learn, a scientific machine\nlearning method that employs lifting variable transformations to learn\nstructure-preserving reduced-order models for nonlinear partial differential\nequations (PDEs) with conservation laws. We propose a hybrid learning approach\nbased on a recently developed energy-quadratization strategy that uses\nknowledge of the nonlinearity at the PDE level to derive an equivalent\nquadratic lifted system with quadratic system energy. The lifted dynamics\nobtained via energy quadratization are linear in the old variables, making\nmodel learning very effective in the lifted setting. Based on the lifted\nquadratic PDE model form, the proposed method derives quadratic reduced terms\nanalytically and then uses those derived terms to formulate a constrained\noptimization problem to learn the remaining linear reduced operators in a\nstructure-preserving way. The proposed hybrid learning approach yields\ncomputationally efficient quadratic reduced-order models that respect the\nunderlying physics of the high-dimensional problem. We demonstrate the\ngeneralizability of quadratic models learned via the proposed\nstructure-preserving Lift & Learn method through three numerical examples: the\none-dimensional wave equation with exponential nonlinearity, the\ntwo-dimensional sine-Gordon equation, and the two-dimensional\nKlein-Gordon-Zakharov equations. The numerical results show that the proposed\nlearning approach is competitive with the state-of-the-art structure-preserving\ndata-driven model reduction method in terms of both accuracy and computational\nefficiency.", "published": "2025-06-30 22:35:25", "link": "http://arxiv.org/abs/2507.00301v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Automatic discovery of optimal meta-solvers for time-dependent nonlinear PDEs", "abstract": "We present a general and scalable framework for the automated discovery of\noptimal meta-solvers for the solution of time-dependent nonlinear partial\ndifferential equations after appropriate discretization. By integrating\nclassical numerical methods (e.g., Krylov-based methods) with modern deep\nlearning components, such as neural operators, our approach enables flexible,\non-demand solver design tailored to specific problem classes and objectives.\nThe fast solvers tackle the large linear system resulting from the\nNewton--Raphson iteration or by using an implicit-explicit (IMEX) time\nintegration scheme. Specifically, we formulate solver discovery as a\nmulti-objective optimization problem, balancing various performance criteria\nsuch as accuracy, speed, and memory usage. The resulting Pareto optimal set\nprovides a principled foundation for solver selection based on user-defined\npreference functions. When applied to problems in reaction--diffusion, fluid\ndynamics, and solid mechanics, the discovered meta-solvers consistently\noutperform conventional iterative methods, demonstrating both practical\nefficiency and broad applicability.", "published": "2025-06-30 21:35:52", "link": "http://arxiv.org/abs/2507.00278v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Minimal residual rational Krylov subspace method for sequences of shifted linear systems", "abstract": "The solution of sequences of shifted linear systems is a classic problem in\nnumerical linear algebra, and a variety of efficient methods have been proposed\nover the years. Nevertheless, there still exist challenging scenarios\nwitnessing a lack of performing solvers. For instance, state-of-the-art\nprocedures struggle to handle nonsymmetric problems where the shifts are\ncomplex numbers that do not come as conjugate pairs. We design a novel\nprojection strategy based on the rational Krylov subspace equipped with a\nminimal residual condition. We also devise a novel pole selection procedure,\ntailored to our problem, providing poles for the rational Krylov basis\nconstruction that yield faster convergence than those computed by available\ngeneral-purpose schemes. A panel of diverse numerical experiments shows that\nour novel approach performs better than state-of-the-art techniques, especially\non the very challenging problems mentioned above.", "published": "2025-06-30 21:21:39", "link": "http://arxiv.org/abs/2507.00267v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error Estimates for Non Conforming Discretisation of Time-dependent Convection-Diffusion-Reaction Model", "abstract": "We use a generic framework, namely the gradient discretisation method (GDM),\nto propose a unified numerical analysis for general time-dependent\nconvection-diffusion-reaction models. We establish novel results for\nconvergence rates of numerical approximations of such models under reasonable\nassumptions on exact solutions, and prove the existence and uniqueness of the\napproximate solution for suitably small time steps. The main interest of our\nresults lies in covering several approximation methods and various applications\nof the considered model such as the generalised Burgers-Fisher (GBF) and the\ngeneralised Burgers-Huxley (GBH) models. Numerical tests based on the hybrid\nmimetic mixed (HMM) method for the GBF model are performed on various types of\ngeneral meshes to examine the accuracy of the proposed gradient scheme. The\nresults confirm our theoretical rates of convergence, even on mesh with extreme\ndistortions.", "published": "2025-06-30 19:42:30", "link": "http://arxiv.org/abs/2507.00219v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An energy-stable parametric finite element method for Willmore flow with normal-tangential velocity splitting", "abstract": "We propose and analyze an energy-stable fully discrete parametric\napproximation for Willmore flow of hypersurfaces in two and three space\ndimensions. We allow for the presence of spontaneous curvature effects and for\nopen surfaces with boundary. The presented scheme is based on a new geometric\npartial differential equation (PDE) that combines an evolution equation for the\nmean curvature with a separate equation that prescribes the tangential\nvelocity. The mean curvature is used to determine the normal velocity within\nthe gradient flow structure, thus guaranteeing an unconditional energy\nstability for the discrete solution upon suitable discretization. We introduce\na novel weak formulation for this geometric PDE, in which different types of\nboundary conditions can be naturally enforced. We further discretize the weak\nformulation to obtain a fully discrete parametric finite element method, for\nwhich well-posedness can be rigorously shown. Moreover, the constructed scheme\nadmits an unconditional stability estimate in terms of the discrete energy.\nExtensive numerical experiments are reported to showcase the accuracy and\nrobustness of the proposed method for computing Willmore flow of both curves in\n$\\mathbb{R}^2$ and surfaces in $\\mathbb{R}^3$.", "published": "2025-06-30 19:03:20", "link": "http://arxiv.org/abs/2507.00193v1", "categories": ["math.NA", "cs.NA", "65M60, 65M15, 65M12, 35R01"], "primary_category": "math.NA"}
{"title": "Localized evaluation and fast summation in the extrapolated regularization method for integrals in Stokes flow", "abstract": "Boundary integral equation methods are widely used in the solution of many\npartial differential equations. The kernels that appear in these surface\nintegrals are nearly singular when evaluated near the boundary, and\nstraightforward numerical integration produces inaccurate results. In Beale and\nTlupova (Adv. Comput. Math, 2024), an extrapolated regularization method was\nproposed to accurately evaluate the nearly singular single and double-layer\nsurface integrals for harmonic potentials or Stokes flow. The kernels are\nregularized using a smoothing parameter, and then a standard quadrature is\napplied. The integrals are computed for three choices of the smoothing\nparameter to find the extrapolated value to fifth order accuracy. In this work,\nwe apply several techniques to reduce the computational cost of the\nextrapolated regularization method applied to the Stokes single and double\nlayer integrals. First, we use a straightforward OpenMP parallelization over\nthe target points. Second, we note that the effect of the regularization is\nlocal and evaluate only the local component of the sum for three values of the\nsmoothing parameter. The non-local component of the sum is only evaluated once\nand reused in the other sums. This component is still the computational\nbottleneck as it is $O(N^2)$, where $N$ is the system size. We apply the\nkernel-independent treecode to these far-field interactions to reduce the CPU\ntime. We carry out experiments to determine optimal parameters both in terms of\naccuracy and efficiency of the computations. We then use these techniques to\ncompute Stokes flow around two spheres that are nearly touching.", "published": "2025-06-30 18:07:57", "link": "http://arxiv.org/abs/2507.00156v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Enhancing Interpretability in Generative Modeling: Statistically Disentangled Latent Spaces Guided by Generative Factors in Scientific Datasets", "abstract": "This study addresses the challenge of statistically extracting generative\nfactors from complex, high-dimensional datasets in unsupervised or\nsemi-supervised settings. We investigate encoder-decoder-based generative\nmodels for nonlinear dimensionality reduction, focusing on disentangling\nlow-dimensional latent variables corresponding to independent physical factors.\nIntroducing Aux-VAE, a novel architecture within the classical Variational\nAutoencoder framework, we achieve disentanglement with minimal modifications to\nthe standard VAE loss function by leveraging prior statistical knowledge\nthrough auxiliary variables. These variables guide the shaping of the latent\nspace by aligning latent factors with learned auxiliary variables. We validate\nthe efficacy of Aux-VAE through comparative assessments on multiple datasets,\nincluding astronomical simulations.", "published": "2025-06-30 22:29:01", "link": "http://arxiv.org/abs/2507.00298v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Disentangled Feature Importance", "abstract": "Feature importance quantification faces a fundamental challenge: when\npredictors are correlated, standard methods systematically underestimate their\ncontributions. We prove that major existing approaches target identical\npopulation functionals under squared-error loss, revealing why they share this\ncorrelation-induced bias.\n  To address this limitation, we introduce \\emph{Disentangled Feature\nImportance (DFI)}, a nonparametric generalization of the classical $R^2$\ndecomposition via optimal transport. DFI transforms correlated features into\nindependent latent variables using a transport map, eliminating correlation\ndistortion. Importance is computed in this disentangled space and attributed\nback through the transport map's sensitivity. DFI provides a principled\ndecomposition of importance scores that sum to the total predictive variability\nfor latent additive models and to interaction-weighted functional ANOVA\nvariances more generally, under arbitrary feature dependencies.\n  We develop a comprehensive semiparametric theory for DFI. For general\ntransport maps, we establish root-$n$ consistency and asymptotic normality of\nimportance estimators in the latent space, which extends to the original\nfeature space for the Bures-Wasserstein map. Notably, our estimators achieve\nsecond-order estimation error, which vanishes if both regression function and\ntransport map estimation errors are $o_{\\mathbb{P}}(n^{-1/4})$. By design, DFI\navoids the computational burden of repeated submodel refitting and the\nchallenges of conditional covariate distribution estimation, thereby achieving\ncomputational efficiency.", "published": "2025-06-30 20:54:48", "link": "http://arxiv.org/abs/2507.00260v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Collecting, Curating, and Annotating Good Quality Speech deepfake dataset for Famous Figures: Process and Challenges", "abstract": "Recent advances in speech synthesis have introduced unprecedented challenges\nin maintaining voice authenticity, particularly concerning public figures who\nare frequent targets of impersonation attacks. This paper presents a\ncomprehensive methodology for collecting, curating, and generating synthetic\nspeech data for political figures and a detailed analysis of challenges\nencountered. We introduce a systematic approach incorporating an automated\npipeline for collecting high-quality bonafide speech samples, featuring\ntranscription-based segmentation that significantly improves synthetic speech\nquality. We experimented with various synthesis approaches; from single-speaker\nto zero-shot synthesis, and documented the evolution of our methodology. The\nresulting dataset comprises bonafide and synthetic speech samples from ten\npublic figures, demonstrating superior quality with a NISQA-TTS naturalness\nscore of 3.69 and the highest human misclassification rate of 61.9\\%.", "published": "2025-06-30 23:41:04", "link": "http://arxiv.org/abs/2507.00324v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss", "abstract": "Speech super-resolution (SSR) enhances low-resolution speech by increasing\nthe sampling rate. While most SSR methods focus on magnitude reconstruction,\nrecent research highlights the importance of phase reconstruction for improved\nperceptual quality. Therefore, we introduce CTFT-Net, a Complex Time-Frequency\nTransformation Network that reconstructs both magnitude and phase in complex\ndomains for improved SSR tasks. It incorporates a complex global attention\nblock to model inter-phoneme and inter-frequency dependencies and a complex\nconformer to capture long-range and local features, improving frequency\nreconstruction and noise robustness. CTFT-Net employs time-domain and\nmulti-resolution frequency-domain loss functions for better generalization.\nExperiments show CTFT-Net outperforms state-of-the-art models (NU-Wave,\nWSRGlow, NVSR, AERO) on the VCTK dataset, particularly for extreme upsampling\n(2 kHz to 48 kHz), reconstructing high frequencies effectively without noisy\nartifacts.", "published": "2025-06-30 19:53:15", "link": "http://arxiv.org/abs/2507.00229v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis", "abstract": "While generative methods have progressed rapidly in recent years, generating\nexpressive prosody for an utterance remains a challenging task in\ntext-to-speech synthesis. This is particularly true for systems that model\nprosody explicitly through parameters such as pitch, energy, and duration,\nwhich is commonly done for the sake of interpretability and controllability. In\nthis work, we investigate the effectiveness of stochastic methods for this\ntask, including Normalizing Flows, Conditional Flow Matching, and Rectified\nFlows. We compare these methods to a traditional deterministic baseline, as\nwell as to real human realizations. Our extensive subjective and objective\nevaluations demonstrate that stochastic methods produce natural prosody on par\nwith human speakers by capturing the variability inherent in human speech.\nFurther, they open up additional controllability options by allowing the\nsampling temperature to be tuned.", "published": "2025-06-30 19:52:32", "link": "http://arxiv.org/abs/2507.00227v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?", "abstract": "Binaural audio remains underexplored within the music information retrieval\ncommunity. Motivated by the rising popularity of virtual and augmented reality\nexperiences as well as potential applications to accessibility, we investigate\nhow well existing music source separation (MSS) models perform on binaural\naudio. Although these models process two-channel inputs, it is unclear how\neffectively they retain spatial information. In this work, we evaluate how\nseveral popular MSS models preserve spatial information on both standard stereo\nand novel binaural datasets. Our binaural data is synthesized using stems from\nMUSDB18-HQ and open-source head-related transfer functions by positioning\ninstrument sources randomly along the horizontal plane. We then assess the\nspatial quality of the separated stems using signal processing and interaural\ncue-based metrics. Our results show that stereo MSS models fail to preserve the\nspatial information critical for maintaining the immersive quality of binaural\naudio, and that the degradation depends on model architecture as well as the\ntarget instrument. Finally, we highlight valuable opportunities for future work\nat the intersection of MSS and immersive audio.", "published": "2025-06-30 18:07:30", "link": "http://arxiv.org/abs/2507.00155v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Fast Simulation of Damage Diffusion Distribution in Scanning Transmission Electron Microscopy", "abstract": "Scanning Transmission Electron Microscopy (STEM) is a critical tool for\nimaging the properties of materials and biological specimens at atomic scale,\nyet our understanding of relevant electron beam damage mechanisms is\nincomplete. Recent studies suggest that certain types of damage can be modelled\nas a diffusion process. However, numerical simulation of such diffusion\nprocesses has remained computationally intensive. This work introduces a\nhigh-performance C++ framework for simulating damage diffusion process in STEM\nthat combines efficient numerical computation, advanced visualisations, and\nmultithreading to achieve efficient runtime while maintaining accuracy.", "published": "2025-06-30 22:15:55", "link": "http://arxiv.org/abs/2507.00294v1", "categories": ["eess.SP", "cond-mat.mtrl-sci"], "primary_category": "eess.SP"}
{"title": "Observation of Blood Flow in Major Neck Vessels Modulated 1 by Physiological Maneuvers", "abstract": "Large neck vessels (carotid artery and internal jugular vein, IJV) offer a\nunique opportunity to monitor hemodynamics non-invasively by optical means. The\nprimary shortcoming of past work has been the focus on healthy volunteers in\nnormal physiological conditions and well-controlled environments. To drive the\ntechnology closer to the bedside, testing is required under more re-alistic\nconditions, including in pathologies and real-world environments (e.g., similar\ntoICU or emergency care settings). The primary goal of the current work was to\nextend the range of physiological maneuvers for blood flow modulation by\nintroducing new maneuvers and ob-serving PPG response to them. The data from\nthe necks of two healthy volunteers in a supine position were collected by\nclinical PPG and in-house built PPG sensors, accompanied by ECG signal\ncollection. Seven maneuvers (abdominojugular test, breath holding, Valsalva,\nproximal occlusion of right IJV, distal occlusion of right IJV, proximal\nocclusion of left IJV, distal occlusion of left IJV) were performed in sequence\nwith 1 min allocated for each maneuver. The 1 min was split into three\nsegments: baseline (15 s), experiment (15 s), and recovery (30 s). Thus, the\noverall du-ration of the experiment was 7 min. AC amplitude from clinical PPG,\nDC amplitudes from in-house built PPG, and ECG signal were compared during all\nseven physiological maneuvers. Newly proposed maneuvers (Valsalva and IJV\nocclusions) demonstrated modulation of blood flow, which was more significant\nthan previously reported maneuvers (abdominojugular test and breath holding).\nThe proposed physiological maneuvers demonstrate high potential as instruments\nfor modulating blood flow in major neck vessels.", "published": "2025-06-30 19:59:05", "link": "http://arxiv.org/abs/2507.00231v1", "categories": ["physics.med-ph", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "physics.med-ph"}
{"title": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series", "abstract": "Ensuring consistent product quality in modern manufacturing is crucial,\nparticularly in safety-critical applications. Conventional quality control\napproaches, reliant on manually defined thresholds and features, lack\nadaptability to the complexity and variability inherent in production data and\nnecessitate extensive domain expertise. Conversely, data-driven methods, such\nas machine learning, demonstrate high detection performance but typically\nfunction as black-box models, thereby limiting their acceptance in industrial\nenvironments where interpretability is paramount. This paper introduces a\nmethodology for industrial fault detection, which is both data-driven and\ntransparent. The approach integrates a supervised machine learning model for\nmulti-class fault classification, Shapley Additive Explanations for post-hoc\ninterpretability, and a do-main-specific visualisation technique that maps\nmodel explanations to operator-interpretable features. Furthermore, the study\nproposes an evaluation methodology that assesses model explanations through\nquantitative perturbation analysis and evaluates visualisations by qualitative\nexpert assessment. The approach was applied to the crimping process, a\nsafety-critical joining technique, using a dataset of univariate, discrete time\nseries. The system achieves a fault detection accuracy of 95.9 %, and both\nquantitative selectivity analysis and qualitative expert evaluations confirmed\nthe relevance and inter-pretability of the generated explanations. This\nhuman-centric approach is designed to enhance trust and interpretability in\ndata-driven fault detection, thereby contributing to applied system design in\nindustrial quality control.", "published": "2025-06-30 14:11:48", "link": "http://arxiv.org/abs/2507.00102v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Curated Collaborative AI Edge with Network Data Analytics for B5G/6G Radio Access Networks", "abstract": "Despite advancements, Radio Access Networks (RAN) still account for over 50\\%\nof the total power consumption in 5G networks. Existing RAN split options do\nnot fully harness data potential, presenting an opportunity to reduce\noperational expenditures. This paper addresses this opportunity through a\ntwofold approach. First, highly accurate network traffic and user predictions\nare achieved using the proposed Curated Collaborative Learning (CCL) framework,\nwhich selectively collaborates with relevant correlated data for traffic\nforecasting. CCL optimally determines whom, when, and what to collaborate with,\nsignificantly outperforming state-of-the-art approaches, including global,\nfederated, personalized federated, and cyclic institutional incremental\nlearnings by 43.9%, 39.1%, 40.8%, and 31.35%, respectively. Second, the\nDistributed Unit Pooling Scheme (DUPS) is proposed, leveraging deep\nreinforcement learning and prediction inferences from CCL to reduce the number\nof active DU servers efficiently. DUPS dynamically redirects traffic from\nunderutilized DU servers to optimize resource use, improving energy efficiency\nby up to 89% over conventional strategies, translating into substantial\nmonetary benefits for operators. By integrating CCL-driven predictions with\nDUPS, this paper demonstrates a transformative approach for minimizing energy\nconsumption and operational costs in 5G RANs, significantly enhancing\nefficiency and cost-effectiveness.", "published": "2025-06-30 06:48:45", "link": "http://arxiv.org/abs/2507.01994v1", "categories": ["cs.NI", "cs.MA"], "primary_category": "cs.NI"}
{"title": "Finding good bets in the lottery, and why you shouldn't take them", "abstract": "We give a criterion under which the expected return on a ticket for certain\nlarge lotteries is positive. In this circumstance, we use elementary portfolio\nanalysis to show that an optimal investment strategy includes a very small\nallocation for such tickets.", "published": "2025-06-30 00:38:46", "link": "http://arxiv.org/abs/2507.01993v1", "categories": ["math.HO", "math.PR", "q-fin.ST"], "primary_category": "math.HO"}
{"title": "Introducing Answered with Evidence -- a framework for evaluating whether LLM responses to biomedical questions are founded in evidence", "abstract": "The growing use of large language models (LLMs) for biomedical question\nanswering raises concerns about the accuracy and evidentiary support of their\nresponses. To address this, we present Answered with Evidence, a framework for\nevaluating whether LLM-generated answers are grounded in scientific literature.\nWe analyzed thousands of physician-submitted questions using a comparative\npipeline that included: (1) Alexandria, fka the Atropos Evidence Library, a\nretrieval-augmented generation (RAG) system based on novel observational\nstudies, and (2) two PubMed-based retrieval-augmented systems (System and\nPerplexity). We found that PubMed-based systems provided evidence-supported\nanswers for approximately 44% of questions, while the novel evidence source did\nso for about 50%. Combined, these sources enabled reliable answers to over 70%\nof biomedical queries. As LLMs become increasingly capable of summarizing\nscientific content, maximizing their value will require systems that can\naccurately retrieve both published and custom-generated evidence or generate\nsuch evidence in real time.", "published": "2025-06-30 18:00:52", "link": "http://arxiv.org/abs/2507.02975v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while they remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have explored enhancing models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to the single-query mode. In this paper, we propose\nRAG-R1, a novel training framework designed to enable LLMs to adaptively\nleverage internal and external knowledge during the reasoning process. We\nfurther expand the generation and retrieval processes within the framework from\nsingle-query mode to multi-query parallelism, aimed at reducing inference time\nand enhancing the model's capabilities. Extensive experiments on seven\nquestion-answering benchmarks demonstrate that our method outperforms the\nstrongest baseline by up to 13.2% and decreases inference time by 11.1%.", "published": "2025-06-30 09:02:45", "link": "http://arxiv.org/abs/2507.02962v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice", "abstract": "This study investigates adaptive experimental design for treatment choice,\nalso known as fixed-budget best-arm identification. We consider an adaptive\nprocedure consisting of a treatment-allocation phase followed by a\ntreatment-choice phase, and we design an adaptive experiment for this setup to\nefficiently identify the best treatment arm, defined as the one with the\nhighest expected outcome. In our designed experiment, the treatment-allocation\nphase consists of two stages. The first stage is a pilot phase, where we\nallocate each treatment arm uniformly with equal proportions to eliminate\nclearly suboptimal arms and estimate outcome variances. In the second stage, we\nallocate treatment arms in proportion to the variances estimated in the first\nstage. After the treatment-allocation phase, the procedure enters the\ntreatment-choice phase, where we choose the treatment arm with the highest\nsample mean as our estimate of the best treatment arm. We prove that this\nsingle design is simultaneously asymptotically minimax and Bayes optimal for\nthe simple regret, with upper bounds that match our lower bounds up to exact\nconstants. Therefore, our designed experiment achieves the sharp efficiency\nlimits without requiring separate tuning for minimax and Bayesian objectives.", "published": "2025-06-30 16:11:44", "link": "http://arxiv.org/abs/2506.24007v2", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "econ.EM"}
{"title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while they remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have explored enhancing models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to the single-query mode. In this paper, we propose\nRAG-R1, a novel training framework designed to enable LLMs to adaptively\nleverage internal and external knowledge during the reasoning process. We\nfurther expand the generation and retrieval processes within the framework from\nsingle-query mode to multi-query parallelism, aimed at reducing inference time\nand enhancing the model's capabilities. Extensive experiments on seven\nquestion-answering benchmarks demonstrate that our method outperforms the\nstrongest baseline by up to 13.2% and decreases inference time by 11.1%.", "published": "2025-06-30 09:02:45", "link": "http://arxiv.org/abs/2507.02962v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD", "abstract": "In this work, we propose a lightweight decoder based solely on\nbelief-propagation (BP), augmented with a speculative post-processing strategy\ninspired by classical Chase decoding. Our method identifies unreliable bits via\nBP oscillation statistics, generates a set of modified test patterns, and\ndecodes them in parallel using low-iteration BP. We demonstrate that our\napproach can achieve logical error rates comparable to or even better than\nBP-OSD, but has lower latency over its parallelization for a variety of\nbivariate bicycle codes, which significantly reduces decoding complexity.", "published": "2025-06-30 20:47:28", "link": "http://arxiv.org/abs/2507.00254v2", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Explicit local volatility formula for Cheyette-type interest rate models", "abstract": "This paper addresses the approximation of the local volatility function in\nthe Cheyette interest rate model. Its main contribution is an explicit\nanalytical formula for approximating local volatility, derived by extending the\nclassical Dupire framework to interest rate models. In particular, an implicit\nDupire-like expression for local volatility is first derived for options\nwritten on the short rate. This expression is then approximated using a\ncombination of perturbation methods and probabilistic techniques, resulting in\na formula expressed in terms of time and strike derivatives of the Bachelier\nimplied variance. The final formula naturally extends to multi-factor Cheyette\nmodels and provides a practical tool for model calibration.", "published": "2025-06-30 14:06:10", "link": "http://arxiv.org/abs/2506.23876v2", "categories": ["q-fin.PR", "q-fin.MF"], "primary_category": "q-fin.PR"}
