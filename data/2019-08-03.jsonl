{"title": "The TALP-UPC System for the WMT Similar Language Task: Statistical vs\n  Neural Machine Translation", "abstract": "Although the problem of similar language translation has been an area of\nresearch interest for many years, yet it is still far from being solved. In\nthis paper, we study the performance of two popular approaches: statistical and\nneural. We conclude that both methods yield similar results; however, the\nperformance varies depending on the language pair. While the statistical\napproach outperforms the neural one by a difference of 6 BLEU points for the\nSpanish-Portuguese language pair, the proposed neural model surpasses the\nstatistical one by a difference of 2 BLEU points for Czech-Polish. In the\nformer case, the language similarity (based on perplexity) is much higher than\nin the latter case. Additionally, we report negative results for the system\ncombination with back-translation. Our TALP-UPC system submission won 1st place\nfor Czech-to-Polish and 2nd place for Spanish-to-Portuguese in the official\nevaluation of the 1st WMT Similar Language Translation task.", "published": "2019-08-03 15:38:19", "link": "http://arxiv.org/abs/1908.01192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Typhoon Related Tweets using Standard and\n  Bidirectional Recurrent Neural Networks", "abstract": "The Philippines is a common ground to natural calamities like typhoons,\nfloods, volcanic eruptions and earthquakes. With Twitter as one of the most\nused social media platform in the Philippines, a total of 39,867 preprocessed\ntweets were obtained given a time frame starting from November 1, 2013 to\nJanuary 31, 2014. Sentiment analysis determines the underlying emotion given a\nseries of words. The main purpose of this study is to identify the sentiments\nexpressed in the tweets sent by the Filipino people before, during, and after\nTyphoon Yolanda using two variations of Recurrent Neural Networks; standard and\nbidirectional. The best generated models after training with various\nhyperparameters achieved a high accuracy of 81.79% for fine-grained\nclassification using standard RNN and 87.69% for binary classification using\nbidirectional RNN. Findings revealed that 51.1% of the tweets sent were\npositive expressing support, love, and words of courage to the victims; 19.8%\nwere negative stating sadness and despair for the loss of lives and hate for\ncorrupt officials; while the other 29% were neutral tweets from local news\nstations, announcements of relief operations, donation drives, and observations\nby citizens.", "published": "2019-08-03 23:48:05", "link": "http://arxiv.org/abs/1908.01765v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
{"title": "Exploring the Robustness of NMT Systems to Nonsensical Inputs", "abstract": "Neural machine translation (NMT) systems have been shown to give undesirable\ntranslation when a small change is made in the source sentence. In this paper,\nwe study the behaviour of NMT systems when multiple changes are made to the\nsource sentence. In particular, we ask the following question \"Is it possible\nfor an NMT system to predict same translation even when multiple words in the\nsource sentence have been replaced?\". To this end, we propose a soft-attention\nbased technique to make the aforementioned word replacements. The experiments\nare conducted on two language pairs: English-German (en-de) and English-French\n(en-fr) and two state-of-the-art NMT systems: BLSTM-based encoder-decoder with\nattention and Transformer. The proposed soft-attention based technique achieves\nhigh success rate and outperforms existing methods like HotFlip by a\nsignificant margin for all the conducted experiments. The results demonstrate\nthat state-of-the-art NMT systems are unable to capture the semantics of the\nsource language. The proposed soft-attention based technique is an\ninvariance-based adversarial attack on NMT systems. To better evaluate such\nattacks, we propose an alternate metric and argue its benefits in comparison\nwith success rate.", "published": "2019-08-03 12:59:40", "link": "http://arxiv.org/abs/1908.01165v3", "categories": ["cs.LG", "cs.CL", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Word2vec to behavior: morphology facilitates the grounding of language\n  in machines", "abstract": "Enabling machines to respond appropriately to natural language commands could\ngreatly expand the number of people to whom they could be of service. Recently,\nadvances in neural network-trained word embeddings have empowered non-embodied\ntext-processing algorithms, and suggest they could be of similar utility for\nembodied machines. Here we introduce a method that does so by training robots\nto act similarly to semantically-similar word2vec encoded commands. We show\nthat this enables them to act appropriately, after training, to\npreviously-unheard commands. Finally, we show that inducing such an alignment\nbetween motoric and linguistic similarities can be facilitated or hindered by\nthe mechanical structure of the robot. This points to future, large scale\nmethods that find and exploit relationships between action, language, and robot\nstructure.", "published": "2019-08-03 18:09:56", "link": "http://arxiv.org/abs/1908.01211v1", "categories": ["cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
