{"title": "ESPnet: End-to-End Speech Processing Toolkit", "abstract": "This paper introduces a new open source platform for end-to-end speech\nprocessing named ESPnet. ESPnet mainly focuses on end-to-end automatic speech\nrecognition (ASR), and adopts widely-used dynamic neural network toolkits,\nChainer and PyTorch, as a main deep learning engine. ESPnet also follows the\nKaldi ASR toolkit style for data processing, feature extraction/format, and\nrecipes to provide a complete setup for speech recognition and other speech\nprocessing experiments. This paper explains a major architecture of this\nsoftware platform, several important functionalities, which differentiate\nESPnet from other open source ASR toolkits, and experimental results with major\nASR benchmarks.", "published": "2018-03-30 18:09:39", "link": "http://arxiv.org/abs/1804.00015v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning General Purpose Distributed Sentence Representations via Large\n  Scale Multi-task Learning", "abstract": "A lot of the recent success in natural language processing (NLP) has been\ndriven by distributed vector representations of words trained on large amounts\nof text in an unsupervised manner. These representations are typically used as\ngeneral purpose features for words across a range of NLP problems. However,\nextending this success to learning representations of sequences of words, such\nas sentences, remains an open problem. Recent work has explored unsupervised as\nwell as supervised learning techniques with different training objectives to\nlearn general purpose fixed-length sentence representations. In this work, we\npresent a simple, effective multi-task learning framework for sentence\nrepresentations that combines the inductive biases of diverse training\nobjectives in a single model. We train this model on several data sources with\nmultiple training objectives on over 100 million sentences. Extensive\nexperiments demonstrate that sharing a single recurrent sentence encoder across\nweakly related tasks leads to consistent improvements over previous methods. We\npresent substantial improvements in the context of transfer learning and\nlow-resource settings using our learned general-purpose representations.", "published": "2018-03-30 23:05:15", "link": "http://arxiv.org/abs/1804.00079v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Cross-lingual Hypernymy Detection using Dependency Context", "abstract": "Cross-lingual Hypernymy Detection involves determining if a word in one\nlanguage (\"fruit\") is a hypernym of a word in another language (\"pomme\" i.e.\napple in French). The ability to detect hypernymy cross-lingually can aid in\nsolving cross-lingual versions of tasks such as textual entailment and event\ncoreference. We propose BISPARSE-DEP, a family of unsupervised approaches for\ncross-lingual hypernymy detection, which learns sparse, bilingual word\nembeddings based on dependency contexts. We show that BISPARSE-DEP can\nsignificantly improve performance on this task, compared to approaches based\nonly on lexical context. Our approach is also robust, showing promise for\nlow-resource settings: our dependency-based embeddings can be learned using a\nparser trained on related languages, with negligible loss in performance. We\nalso crowd-source a challenging dataset for this task on four languages --\nRussian, French, Arabic, and Chinese. Our embeddings and datasets are publicly\navailable.", "published": "2018-03-30 00:01:08", "link": "http://arxiv.org/abs/1803.11291v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Cascade Multi-task Learning for Slot Filling in Online Shopping\n  Assistant", "abstract": "Slot filling is a critical task in natural language understanding (NLU) for\ndialog systems. State-of-the-art approaches treat it as a sequence labeling\nproblem and adopt such models as BiLSTM-CRF. While these models work relatively\nwell on standard benchmark datasets, they face challenges in the context of\nE-commerce where the slot labels are more informative and carry richer\nexpressions. In this work, inspired by the unique structure of E-commerce\nknowledge base, we propose a novel multi-task model with cascade and residual\nconnections, which jointly learns segment tagging, named entity tagging and\nslot filling. Experiments show the effectiveness of the proposed cascade and\nresidual structures. Our model has a 14.6% advantage in F1 score over the\nstrong baseline methods on a new Chinese E-commerce shopping assistant dataset,\nwhile achieving competitive accuracies on a standard dataset. Furthermore,\nonline test deployed on such dominant E-commerce platform shows 130%\nimprovement on accuracy of understanding user utterances. Our model has already\ngone into production in the E-commerce platform.", "published": "2018-03-30 03:49:18", "link": "http://arxiv.org/abs/1803.11326v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Generation of Chinese Short Product Titles for Mobile Display", "abstract": "This paper studies the problem of automatically extracting a short title from\na manually written longer description of E-commerce products for display on\nmobile devices. It is a new extractive summarization problem on short text\ninputs, for which we propose a feature-enriched network model, combining three\ndifferent categories of features in parallel. Experimental results show that\nour framework significantly outperforms several baselines by a substantial gain\nof 4.5%. Moreover, we produce an extractive summarization dataset for\nE-commerce short texts and will release it to the research community.", "published": "2018-03-30 06:34:17", "link": "http://arxiv.org/abs/1803.11359v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Attention Mechanism for Neural Machine Translation", "abstract": "Neural machine translation (NMT) has been a new paradigm in machine\ntranslation, and the attention mechanism has become the dominant approach with\nthe state-of-the-art records in many language pairs. While there are variants\nof the attention mechanism, all of them use only temporal attention where one\nscalar value is assigned to one context vector corresponding to a source word.\nIn this paper, we propose a fine-grained (or 2D) attention mechanism where each\ndimension of a context vector will receive a separate attention score. In\nexperiments with the task of En-De and En-Fi translation, the fine-grained\nattention method improves the translation quality in terms of BLEU score. In\naddition, our alignment analysis reveals how the fine-grained attention\nmechanism exploits the internal structure of context vectors.", "published": "2018-03-30 10:38:33", "link": "http://arxiv.org/abs/1803.11407v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatically augmenting an emotion dataset improves classification\n  using audio", "abstract": "In this work, we tackle a problem of speech emotion classification. One of\nthe issues in the area of affective computation is that the amount of annotated\ndata is very limited. On the other hand, the number of ways that the same\nemotion can be expressed verbally is enormous due to variability between\nspeakers. This is one of the factors that limits performance and\ngeneralization. We propose a simple method that extracts audio samples from\nmovies using textual sentiment analysis. As a result, it is possible to\nautomatically construct a larger dataset of audio samples with positive,\nnegative emotional and neutral speech. We show that pretraining recurrent\nneural network on such a dataset yields better results on the challenging\nEmotiW corpus. This experiment shows a potential benefit of combining textual\nsentiment analysis with vocal information.", "published": "2018-03-30 15:14:51", "link": "http://arxiv.org/abs/1803.11506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reusing Neural Speech Representations for Auditory Emotion Recognition", "abstract": "Acoustic emotion recognition aims to categorize the affective state of the\nspeaker and is still a difficult task for machine learning models. The\ndifficulties come from the scarcity of training data, general subjectivity in\nemotion perception resulting in low annotator agreement, and the uncertainty\nabout which features are the most relevant and robust ones for classification.\nIn this paper, we will tackle the latter problem. Inspired by the recent\nsuccess of transfer learning methods we propose a set of architectures which\nutilize neural representations inferred by training on large speech databases\nfor the acoustic emotion recognition task. Our experiments on the IEMOCAP\ndataset show ~10% relative improvements in the accuracy and F1-score over the\nbaseline recurrent neural network which is trained end-to-end for emotion\nrecognition.", "published": "2018-03-30 15:18:20", "link": "http://arxiv.org/abs/1803.11508v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GradAscent at EmoInt-2017: Character- and Word-Level Recurrent Neural\n  Network Models for Tweet Emotion Intensity Detection", "abstract": "The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity\nvalues of tweet messages. Given the text of a tweet and its emotion category\n(anger, joy, fear, and sadness), the participants were asked to build a system\nthat assigns emotion intensity values. Emotion intensity estimation is a\nchallenging problem given the short length of the tweets, the noisy structure\nof the text and the lack of annotated data. To solve this problem, we developed\nan ensemble of two neural models, processing input on the character. and\nword-level with a lexicon-driven system. The correlation scores across all four\nemotions are averaged to determine the bottom-line competition metric, and our\nsystem ranks place forth in full intensity range and third in 0.5-1 range of\nintensity among 23 systems at the time of writing (June 2017).", "published": "2018-03-30 15:21:00", "link": "http://arxiv.org/abs/1803.11509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attentive Interaction Model: Modeling Changes in View in Argumentation", "abstract": "We present a neural architecture for modeling argumentative dialogue that\nexplicitly models the interplay between an Opinion Holder's (OH's) reasoning\nand a challenger's argument, with the goal of predicting if the argument\nsuccessfully changes the OH's view. The model has two components: (1)\nvulnerable region detection, an attention model that identifies parts of the\nOH's reasoning that are amenable to change, and (2) interaction encoding, which\nidentifies the relationship between the content of the OH's reasoning and that\nof the challenger's argument. Based on evaluation on discussions from the\nChange My View forum on Reddit, the two components work together to predict an\nOH's change in view, outperforming several baselines. A posthoc analysis\nsuggests that sentences picked out by the attention model are addressed more\nfrequently by successful arguments than by unsuccessful ones.", "published": "2018-03-30 21:57:40", "link": "http://arxiv.org/abs/1804.00065v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Characterizing Interconnections and Linguistic Patterns in Twitter", "abstract": "Social media is considered a democratic space in which people connect and\ninteract with each other regardless of their gender, race, or any other\ndemographic aspect. Despite numerous efforts that explore demographic aspects\nin social media, it is still unclear whether social media perpetuates old\ninequalities from the offline world. In this dissertation, we attempt to\nidentify gender and race of Twitter users located in the United States using\nadvanced image processing algorithms from Face++. We investigate how different\ndemographic groups connect with each other and differentiate them regarding\nlinguistic styles and also their interests. We quantify to what extent one\ngroup follows and interacts with each other and the extent to which these\nconnections and interactions reflect in inequalities in Twitter. We also\nextract linguistic features from six categories (affective attributes,\ncognitive attributes, lexical density and awareness, temporal references,\nsocial and personal concerns, and interpersonal focus) in order to identify the\nsimilarities and the differences in the messages they share in Twitter.\nFurthermore, we extract the absolute ranking difference of top phrases between\ndemographic groups. As a dimension of diversity, we use the topics of interest\nthat we retrieve from each user. Our analysis shows that users identified as\nwhite and male tend to attain higher positions, in terms of the number of\nfollowers and number of times in another user's lists, in Twitter. There are\nclear differences in the way of writing across different demographic groups in\nboth gender and race domains as well as in the topic of interest. We hope our\neffort can stimulate the development of new theories of demographic information\nin the online space. Finally, we developed a Web-based system that leverages\nthe demographic aspects of users to provide transparency to the Twitter\ntrending topics system.", "published": "2018-03-30 23:31:43", "link": "http://arxiv.org/abs/1804.00084v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "The Training of Neuromodels for Machine Comprehension of Text.\n  Brain2Text Algorithm", "abstract": "Nowadays, the Internet represents a vast informational space, growing\nexponentially and the problem of search for relevant data becomes essential as\nnever before. The algorithm proposed in the article allows to perform natural\nlanguage queries on content of the document and get comprehensive meaningful\nanswers. The problem is partially solved for English as SQuAD contains enough\ndata to learn on, but there is no such dataset in Russian, so the methods used\nby scientists now are not applicable to Russian. Brain2 framework allows to\ncope with the problem - it stands out for its ability to be applied on small\ndatasets and does not require impressive computing power. The algorithm is\nillustrated on Sberbank of Russia Strategy's text and assumes the use of a\nneuromodel consisting of 65 mln synapses. The trained model is able to\nconstruct word-by-word answers to questions based on a given text. The existing\nlimitations are its current inability to identify synonyms, pronoun relations\nand allegories. Nevertheless, the results of conducted experiments showed high\ncapacity and generalisation ability of the suggested approach.", "published": "2018-03-30 08:32:42", "link": "http://arxiv.org/abs/1804.00551v1", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Conditional End-to-End Audio Transforms", "abstract": "We present an end-to-end method for transforming audio from one style to\nanother. For the case of speech, by conditioning on speaker identities, we can\ntrain a single model to transform words spoken by multiple people into multiple\ntarget voices. For the case of music, we can specify musical instruments and\nachieve the same result. Architecturally, our method is a fully-differentiable\nsequence-to-sequence model based on convolutional and hierarchical recurrent\nneural networks. It is designed to capture long-term acoustic dependencies,\nrequires minimal post-processing, and produces realistic audio transforms.\nAblation studies confirm that our model can separate speaker and instrument\nproperties from acoustic content at different receptive fields. Empirically,\nour method achieves competitive performance on community-standard datasets.", "published": "2018-03-30 20:17:31", "link": "http://arxiv.org/abs/1804.00047v2", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting Alzheimer's Disease Using Gated Convolutional Neural Network\n  from Audio Data", "abstract": "We propose an automatic detection method of Alzheimer's diseases using a\ngated convolutional neural network (GCNN) from speech data. This GCNN can be\ntrained with a relatively small amount of data and can capture the temporal\ninformation in audio paralinguistic features. Since it does not utilize any\nlinguistic features, it can be easily applied to any languages. We evaluated\nour method using Pitt Corpus. The proposed method achieved the accuracy of\n73.6%, which is better than the conventional sequential minimal optimization\n(SMO) by 7.6 points.", "published": "2018-03-30 05:33:05", "link": "http://arxiv.org/abs/1803.11344v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spectral Estimation of Plasma Fluctuations I: Comparison of Methods", "abstract": "The relative root mean squared errors (RMSE) of nonparametric methods for\nspectral estimation is compared for microwave scattering data of plasma\nfluctuations. These methods reduce the variance of the periodogram estimate by\naveraging the spectrum over a frequency bandwidth. As the bandwidth increases,\nthe variance decreases, but the bias error increases. The plasma spectra vary\nby over four orders of magnitude, and therefore, using a spectral window is\nnecessary. We compare the smoothed tapered periodogram with the adaptive\nmultiple taper methods and hybrid methods. We find that a hybrid method, which\nuses four orthogonal tapers and then applies a kernel smoother, performs best.\nFor 300 point data segments, even an optimized smoothed tapered periodogram has\na 24 \\% larger relative RMSE than the hybrid method. We present two new\nadaptive multi-taper weightings which outperform Thomson's original adaptive\nweighting.", "published": "2018-03-30 19:54:45", "link": "http://arxiv.org/abs/1804.00003v1", "categories": ["stat.AP", "eess.AS", "eess.SP", "math.ST", "stat.TH"], "primary_category": "stat.AP"}
