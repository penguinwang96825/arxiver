{"title": "Understanding Postpartum Parents' Experiences via Two Digital Platforms", "abstract": "Digital platforms, including online forums and helplines, have emerged as\navenues of support for caregivers suffering from postpartum mental health\ndistress. Understanding support seekers' experiences as shared on these\nplatforms could provide crucial insight into caregivers' needs during this\nvulnerable time. In the current work, we provide a descriptive analysis of the\nconcerns, psychological states, and motivations shared by healthy and\ndistressed postpartum support seekers on two digital platforms, a one-on-one\ndigital helpline and a publicly available online forum. Using a combination of\nhuman annotations, dictionary models and unsupervised techniques, we find stark\ndifferences between the experiences of distressed and healthy mothers.\nDistressed mothers described interpersonal problems and a lack of support, with\n8.60% - 14.56% reporting severe symptoms including suicidal ideation. In\ncontrast, the majority of healthy mothers described childcare issues, such as\nquestions about breastfeeding or sleeping, and reported no severe mental health\nconcerns. Across the two digital platforms, we found that distressed mothers\nshared similar content. However, the patterns of speech and affect shared by\ndistressed mothers differed between the helpline vs. the online forum,\nsuggesting the design of these platforms may shape meaningful measures of their\nsupport-seeking experiences. Our results provide new insight into the\nexperiences of caregivers suffering from postpartum mental health distress. We\nconclude by discussing methodological considerations for understanding content\nshared by support seekers and design considerations for the next generation of\nsupport tools for postpartum parents.", "published": "2022-12-22 02:13:30", "link": "http://arxiv.org/abs/2212.11455v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAMeMBERT: Cascading Assistant-Mediated Multilingual BERT", "abstract": "Large language models having hundreds of millions, and even billions, of\nparameters have performed extremely well on a variety of natural language\nprocessing (NLP) tasks. Their widespread use and adoption, however, is hindered\nby the lack of availability and portability of sufficiently large computational\nresources. This paper proposes a knowledge distillation (KD) technique building\non the work of LightMBERT, a student model of multilingual BERT (mBERT). By\nrepeatedly distilling mBERT through increasingly compressed toplayer distilled\nteacher assistant networks, CAMeMBERT aims to improve upon the time and space\ncomplexities of mBERT while keeping loss of accuracy beneath an acceptable\nthreshold. At present, CAMeMBERT has an average accuracy of around 60.1%, which\nis subject to change after future improvements to the hyperparameters used in\nfine-tuning.", "published": "2022-12-22 02:19:25", "link": "http://arxiv.org/abs/2212.11456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Lingual DALL-E Storytime", "abstract": "While recent advancements in artificial intelligence (AI) language models\ndemonstrate cutting-edge performance when working with English texts,\nequivalent models do not exist in other languages or do not reach the same\nperformance level. This undesired effect of AI advancements increases the gap\nbetween access to new technology from different populations across the world.\nThis unsought bias mainly discriminates against individuals whose English\nskills are less developed, e.g., non-English speakers children. Following\nsignificant advancements in AI research in recent years, OpenAI has recently\npresented DALL-E: a powerful tool for creating images based on English text\nprompts. While DALL-E is a promising tool for many applications, its decreased\nperformance when given input in a different language, limits its audience and\ndeepens the gap between populations. An additional limitation of the current\nDALL-E model is that it only allows for the creation of a few images in\nresponse to a given input prompt, rather than a series of consecutive coherent\nframes that tell a story or describe a process that changes over time. Here, we\npresent an easy-to-use automatic DALL-E storytelling framework that leverages\nthe existing DALL-E model to enable fast and coherent visualizations of\nnon-English songs and stories, pushing the limit of the one-step-at-a-time\noption DALL-E currently offers. We show that our framework is able to\neffectively visualize stories from non-English texts and portray the changes in\nthe plot over time. It is also able to create a narrative and maintain\ninterpretable changes in the description across frames. Additionally, our\nframework offers users the ability to specify constraints on the story\nelements, such as a specific location or context, and to maintain a consistent\nstyle throughout the visualization.", "published": "2022-12-22 07:06:35", "link": "http://arxiv.org/abs/2212.11985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the\n  Lens of Generalization", "abstract": "Recent work has shown that fine-tuning large pre-trained language models on a\ncollection of tasks described via instructions, a.k.a. instruction-tuning,\nimproves their zero and few-shot generalization to unseen tasks. However, there\nis a limited understanding of the performance trade-offs of different decisions\nmade during the instruction-tuning process. These decisions include the scale\nand diversity of the instruction-tuning benchmark, different task sampling\nstrategies, fine-tuning with and without demonstrations, training using\nspecialized datasets for reasoning and dialogue, and finally, the fine-tuning\nobjectives themselves. In this paper, we characterize the effect of\ninstruction-tuning decisions on downstream task performance when scaling both\nmodel and benchmark sizes. To this end, we create OPT-IML Bench: a large\nbenchmark for Instruction Meta-Learning (IML) of 2000 NLP tasks consolidated\ninto task categories from 8 existing benchmarks, and prepare an evaluation\nframework to measure three types of model generalizations: to tasks from fully\nheld-out categories, to held-out tasks from seen categories, and to held-out\ninstances from seen tasks. Through the lens of this framework, we first present\ninsights about instruction-tuning decisions as applied to OPT-30B and further\nexploit these insights to train OPT-IML 30B and 175B, which are\ninstruction-tuned versions of OPT. OPT-IML demonstrates all three\ngeneralization abilities at both scales on four different evaluation benchmarks\nwith diverse tasks and input formats -- PromptSource, FLAN,\nSuper-NaturalInstructions, and UnifiedSKG. Not only does it significantly\noutperform OPT on all benchmarks but is also highly competitive with existing\nmodels fine-tuned on each specific benchmark. We release OPT-IML at both\nscales, together with the OPT-IML Bench evaluation framework.", "published": "2022-12-22 19:56:09", "link": "http://arxiv.org/abs/2212.12017v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Generation with Diffusion Language Models: A Pre-training Approach\n  with Continuous Paragraph Denoise", "abstract": "In this paper, we introduce a novel dIffusion language modEl pre-training\nframework for text generation, which we call GENIE. GENIE is a large-scale\npretrained diffusion language model that consists of an encoder and a\ndiffusion-based decoder, which can generate text by gradually transforming a\nrandom noise sequence into a coherent text sequence. To pre-train GENIE on a\nlarge-scale language corpus, we design a new continuous paragraph denoise\nobjective, which encourages the diffusion-decoder to reconstruct a clean text\nparagraph from a corrupted version, while preserving the semantic and syntactic\ncoherence. We evaluate GENIE on four downstream text generation benchmarks,\nnamely XSum, CNN/DailyMail, Gigaword, and CommonGen. Our experimental results\nshow that GENIE achieves comparable performance with the state-of-the-art\nautoregressive models on these benchmarks, and generates more diverse text\nsamples. The code and models of GENIE are available at\nhttps://github.com/microsoft/ProphetNet/tree/master/GENIE.", "published": "2022-12-22 13:17:11", "link": "http://arxiv.org/abs/2212.11685v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Integer-Only Deep Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNN) are the backbone of many text and speech\napplications. These architectures are typically made up of several\ncomputationally complex components such as; non-linear activation functions,\nnormalization, bi-directional dependence and attention. In order to maintain\ngood accuracy, these components are frequently run using full-precision\nfloating-point computation, making them slow, inefficient and difficult to\ndeploy on edge devices. In addition, the complex nature of these operations\nmakes them challenging to quantize using standard quantization methods without\na significant performance drop. We present a quantization-aware training method\nfor obtaining a highly accurate integer-only recurrent neural network (iRNN).\nOur approach supports layer normalization, attention, and an adaptive piecewise\nlinear (PWL) approximation of activation functions, to serve a wide range of\nstate-of-the-art RNNs. The proposed method enables RNN-based language models to\nrun on edge devices with $2\\times$ improvement in runtime, and $4\\times$\nreduction in model size while maintaining similar accuracy as its\nfull-precision counterpart.", "published": "2022-12-22 15:22:36", "link": "http://arxiv.org/abs/2212.11791v1", "categories": ["cs.LG", "cs.CL", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Multilingual News Location Detection using an Entity-Based Siamese\n  Network with Semi-Supervised Contrastive Learning and Knowledge Base", "abstract": "Early detection of relevant locations in a piece of news is especially\nimportant in extreme events such as environmental disasters, war conflicts,\ndisease outbreaks, or political turmoils. Additionally, this detection also\nhelps recommender systems to promote relevant news based on user locations.\nNote that, when the relevant locations are not mentioned explicitly in the\ntext, state-of-the-art methods typically fail to recognize them because these\nmethods rely on syntactic recognition. In contrast, by incorporating a\nknowledge base and connecting entities with their locations, our system\nsuccessfully infers the relevant locations even when they are not mentioned\nexplicitly in the text. To evaluate the effectiveness of our approach, and due\nto the lack of datasets in this area, we also contribute to the research\ncommunity with a gold-standard multilingual news-location dataset, NewsLOC. It\ncontains the annotation of the relevant locations (and their WikiData IDs) of\n600+ Wikinews articles in five different languages: English, French, German,\nItalian, and Spanish. Through experimental evaluations, we show that our\nproposed system outperforms the baselines and the fine-tuned version of the\nmodel using semi-supervised data that increases the classification rate. The\nsource code and the NewsLOC dataset are publicly available for being used by\nthe research community at https://github.com/vsuarezpaniagua/NewsLocation.", "published": "2022-12-22 16:42:21", "link": "http://arxiv.org/abs/2212.11856v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Alignment Entropy Regularization", "abstract": "Existing training criteria in automatic speech recognition(ASR) permit the\nmodel to freely explore more than one time alignments between the feature and\nlabel sequences. In this paper, we use entropy to measure a model's\nuncertainty, i.e. how it chooses to distribute the probability mass over the\nset of allowed alignments. Furthermore, we evaluate the effect of entropy\nregularization in encouraging the model to distribute the probability mass only\non a smaller subset of allowed alignments. Experiments show that entropy\nregularization enables a much simpler decoding method without sacrificing word\nerror rate, and provides better time alignment quality.", "published": "2022-12-22 18:51:02", "link": "http://arxiv.org/abs/2212.12442v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Induction of Language Models Via Probabilistic Concept\n  Formation", "abstract": "This paper presents a novel approach to the acquisition of language models\nfrom corpora. The framework builds on Cobweb, an early system for constructing\ntaxonomic hierarchies of probabilistic concepts that used a tabular,\nattribute-value encoding of training cases and concepts, making it unsuitable\nfor sequential input like language. In response, we explore three new\nextensions to Cobweb -- the Word, Leaf, and Path variants. These systems encode\neach training case as an anchor word and surrounding context words, and they\nstore probabilistic descriptions of concepts as distributions over anchor and\ncontext information. As in the original Cobweb, a performance element sorts a\nnew instance downward through the hierarchy and uses the final node to predict\nmissing features. Learning is interleaved with performance, updating concept\nprobabilities and hierarchy structure as classification occurs. Thus, the new\napproaches process training cases in an incremental, online manner that it very\ndifferent from most methods for statistical language learning. We examine how\nwell the three variants place synonyms together and keep homonyms apart, their\nability to recall synonyms as a function of training set size, and their\ntraining efficiency. Finally, we discuss related work on incremental learning\nand directions for further research.", "published": "2022-12-22 18:16:58", "link": "http://arxiv.org/abs/2212.11937v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "When are Lemons Purple? The Concept Association Bias of Vision-Language\n  Models", "abstract": "Large-scale vision-language models such as CLIP have shown impressive\nperformance on zero-shot image classification and image-to-text retrieval.\nHowever, such performance does not realize in tasks that require a\nfiner-grained correspondence between vision and language, such as Visual\nQuestion Answering (VQA). As a potential cause of the difficulty of applying\nthese models to VQA and similar tasks, we report an interesting phenomenon of\nvision-language models, which we call the Concept Association Bias (CAB). We\nfind that models with CAB tend to treat input as a bag of concepts and attempt\nto fill in the other missing concept crossmodally, leading to an unexpected\nzero-shot prediction. We demonstrate CAB by showing that CLIP's zero-shot\nclassification performance greatly suffers when there is a strong concept\nassociation between an object (e.g. eggplant) and an attribute (e.g. color\npurple). We also show that the strength of CAB predicts the performance on VQA.\nWe observe that CAB is prevalent in vision-language models trained with\ncontrastive losses, even when autoregressive losses are jointly employed.\nHowever, a model that solely relies on autoregressive loss seems to exhibit\nminimal or no signs of CAB.", "published": "2022-12-22 21:27:12", "link": "http://arxiv.org/abs/2212.12043v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Pushing the performances of ASR models on English and Spanish accents", "abstract": "Speech to text models tend to be trained and evaluated against a single\ntarget accent. This is especially true for English for which native speakers\nfrom the United States became the main benchmark. In this work, we are going to\nshow how two simple methods: pre-trained embeddings and auxiliary\nclassification losses can improve the performance of ASR systems. We are\nlooking for upgrades as universal as possible and therefore we will explore\ntheir impact on several models architectures and several languages.", "published": "2022-12-22 21:48:29", "link": "http://arxiv.org/abs/2212.12048v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MN-DS: A Multilabeled News Dataset for News Articles Hierarchical\n  Classification", "abstract": "This article presents a dataset of 10,917 news articles with hierarchical\nnews categories collected between 1 January 2019 and 31 December 2019. We\nmanually labeled the articles based on a hierarchical taxonomy with 17\nfirst-level and 109 second-level categories. This dataset can be used to train\nmachine learning models for automatically classifying news articles by topic.\nThis dataset can be helpful for researchers working on news structuring,\nclassification, and predicting future events based on released news.", "published": "2022-12-22 22:27:26", "link": "http://arxiv.org/abs/2212.12061v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Methodological reflections for AI alignment research using human\n  feedback", "abstract": "The field of artificial intelligence (AI) alignment aims to investigate\nwhether AI technologies align with human interests and values and function in a\nsafe and ethical manner. AI alignment is particularly relevant for large\nlanguage models (LLMs), which have the potential to exhibit unintended behavior\ndue to their ability to learn and adapt in ways that are difficult to predict.\nIn this paper, we discuss methodological challenges for the alignment problem\nspecifically in the context of LLMs trained to summarize texts. In particular,\nwe focus on methods for collecting reliable human feedback on summaries to\ntrain a reward model which in turn improves the summarization model. We\nconclude by suggesting specific improvements in the experimental design of\nalignment studies for LLMs' summarization capabilities.", "published": "2022-12-22 14:27:33", "link": "http://arxiv.org/abs/2301.06859v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "HMM-based data augmentation for E2E systems for building conversational\n  speech synthesis systems", "abstract": "This paper proposes an approach to build a high-quality text-to-speech (TTS)\nsystem for technical domains using data augmentation. An end-to-end (E2E)\nsystem is trained on hidden Markov model (HMM) based synthesized speech and\nfurther fine-tuned with studio-recorded TTS data to improve the timbre of the\nsynthesized voice. The motivation behind the work is that issues of word skips\nand repetitions are usually absent in HMM systems due to their ability to model\nthe duration distribution of phonemes accurately. Context-dependent pentaphone\nmodeling, along with tree-based clustering and state-tying, takes care of\nunseen context and out-of-vocabulary words. A language model is also employed\nto reduce synthesis errors further. Subjective evaluations indicate that speech\nproduced using the proposed system is superior to the baseline E2E synthesis\napproach in terms of intelligibility when combining complementing attributes\nfrom HMM and E2E frameworks. The further analysis highlights the proposed\napproach's efficacy in low-resource scenarios.", "published": "2022-12-22 18:59:36", "link": "http://arxiv.org/abs/2212.11982v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "StoRM: A Diffusion-based Stochastic Regeneration Model for Speech\n  Enhancement and Dereverberation", "abstract": "Diffusion models have shown a great ability at bridging the performance gap\nbetween predictive and generative approaches for speech enhancement. We have\nshown that they may even outperform their predictive counterparts for\nnon-additive corruption types or when they are evaluated on mismatched\nconditions. However, diffusion models suffer from a high computational burden,\nmainly as they require to run a neural network for each reverse diffusion step,\nwhereas predictive approaches only require one pass. As diffusion models are\ngenerative approaches they may also produce vocalizing and breathing artifacts\nin adverse conditions. In comparison, in such difficult scenarios, predictive\nmodels typically do not produce such artifacts but tend to distort the target\nspeech instead, thereby degrading the speech quality. In this work, we present\na stochastic regeneration approach where an estimate given by a predictive\nmodel is provided as a guide for further diffusion. We show that the proposed\napproach uses the predictive model to remove the vocalizing and breathing\nartifacts while producing very high quality samples thanks to the diffusion\nmodel, even in adverse conditions. We further show that this approach enables\nto use lighter sampling schemes with fewer diffusion steps without sacrificing\nquality, thus lifting the computational burden by an order of magnitude. Source\ncode and audio examples are available online (https://uhh.de/inf-sp-storm).", "published": "2022-12-22 16:35:42", "link": "http://arxiv.org/abs/2212.11851v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
