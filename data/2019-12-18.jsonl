{"title": "DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog", "abstract": "Visual Dialog is a vision-language task that requires an AI agent to engage\nin a conversation with humans grounded in an image. It remains a challenging\ntask since it requires the agent to fully understand a given question before\nmaking an appropriate response not only from the textual dialog history, but\nalso from the visually-grounded information. While previous models typically\nleverage single-hop reasoning or single-channel reasoning to deal with this\ncomplex multimodal reasoning task, which is intuitively insufficient. In this\npaper, we thus propose a novel and more powerful Dual-channel Multi-hop\nReasoning Model for Visual Dialog, named DMRM. DMRM synchronously captures\ninformation from the dialog history and the image to enrich the semantic\nrepresentation of the question by exploiting dual-channel reasoning.\nSpecifically, DMRM maintains a dual channel to obtain the question- and\nhistory-aware image features and the question- and image-aware dialog history\nfeatures by a mulit-hop reasoning process in each channel. Additionally, we\nalso design an effective multimodal attention to further enhance the decoder to\ngenerate more accurate responses. Experimental results on the VisDial v0.9 and\nv1.0 datasets demonstrate that the proposed model is effective and outperforms\ncompared models by a significant margin.", "published": "2019-12-18 03:09:12", "link": "http://arxiv.org/abs/1912.08360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating summaries tailored to target characteristics", "abstract": "Recently, research efforts have gained pace to cater to varied user\npreferences while generating text summaries. While there have been attempts to\nincorporate a few handpicked characteristics such as length or entities, a\nholistic view around these preferences is missing and crucial insights on why\ncertain characteristics should be incorporated in a specific manner are absent.\nWith this objective, we provide a categorization around these characteristics\nrelevant to the task of text summarization: one, focusing on what content needs\nto be generated and second, focusing on the stylistic aspects of the output\nsummaries. We use our insights to provide guidelines on appropriate methods to\nincorporate various classes characteristics in sequence-to-sequence\nsummarization framework. Our experiments with incorporating topics, readability\nand simplicity indicate the viability of the proposed prescriptions", "published": "2019-12-18 10:05:49", "link": "http://arxiv.org/abs/1912.08492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Document-level Neural Machine Translation: Methods and\n  Evaluation", "abstract": "Machine translation (MT) is an important task in natural language processing\n(NLP) as it automates the translation process and reduces the reliance on human\ntranslators. With the resurgence of neural networks, the translation quality\nsurpasses that of the translations obtained using statistical techniques for\nmost language-pairs. Up until a few years ago, almost all of the neural\ntranslation models translated sentences independently, without incorporating\nthe wider document-context and inter-dependencies among the sentences. The aim\nof this survey paper is to highlight the major works that have been undertaken\nin the space of document-level machine translation after the neural revolution,\nso that researchers can recognise the current state and future directions of\nthis field. We provide an organisation of the literature based on novelties in\nmodelling and architectures as well as training and decoding strategies. In\naddition, we cover evaluation strategies that have been introduced to account\nfor the improvements in document MT, including automatic metrics and\ndiscourse-targeted test sets. We conclude by presenting possible avenues for\nfuture exploration in this research field.", "published": "2019-12-18 10:07:20", "link": "http://arxiv.org/abs/1912.08494v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive\n  Summarization", "abstract": "Recent work pre-training Transformers with self-supervised objectives on\nlarge text corpora has shown great success when fine-tuned on downstream NLP\ntasks including text summarization. However, pre-training objectives tailored\nfor abstractive text summarization have not been explored. Furthermore there is\na lack of systematic evaluation across diverse domains. In this work, we\npropose pre-training large Transformer-based encoder-decoder models on massive\ntext corpora with a new self-supervised objective. In PEGASUS, important\nsentences are removed/masked from an input document and are generated together\nas one output sequence from the remaining sentences, similar to an extractive\nsummary. We evaluated our best PEGASUS model on 12 downstream summarization\ntasks spanning news, science, stories, instructions, emails, patents, and\nlegislative bills. Experiments demonstrate it achieves state-of-the-art\nperformance on all 12 downstream datasets measured by ROUGE scores. Our model\nalso shows surprising performance on low-resource summarization, surpassing\nprevious state-of-the-art results on 6 datasets with only 1000 examples.\nFinally we validated our results using human evaluation and show that our model\nsummaries achieve human performance on multiple datasets.", "published": "2019-12-18 18:16:20", "link": "http://arxiv.org/abs/1912.08777v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asymmetrical Hierarchical Networks with Attentive Interactions for\n  Interpretable Review-Based Recommendation", "abstract": "Recently, recommender systems have been able to emit substantially improved\nrecommendations by leveraging user-provided reviews. Existing methods typically\nmerge all reviews of a given user or item into a long document, and then\nprocess user and item documents in the same manner. In practice, however, these\ntwo sets of reviews are notably different: users' reviews reflect a variety of\nitems that they have bought and are hence very heterogeneous in their topics,\nwhile an item's reviews pertain only to that single item and are thus topically\nhomogeneous. In this work, we develop a novel neural network model that\nproperly accounts for this important difference by means of asymmetric\nattentive modules. The user module learns to attend to only those signals that\nare relevant with respect to the target item, whereas the item module learns to\nextract the most salient contents with regard to properties of the item. Our\nmulti-hierarchical paradigm accounts for the fact that neither are all reviews\nequally useful, nor are all sentences within each review equally pertinent.\nExtensive experimental results on a variety of real datasets demonstrate the\neffectiveness of our method.", "published": "2019-12-18 23:48:42", "link": "http://arxiv.org/abs/2001.04346v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Uncovering Relations for Marketing Knowledge Representation", "abstract": "Online behaviors of consumers and marketers generate massive marketing data,\nwhich ever more sophisticated models attempt to turn into insights and aid\ndecisions by marketers. Yet, in making decisions human managers bring to bear\nmarketing knowledge which reside outside of data and models. Thus, it behooves\ncreation of an automated marketing knowledge base that can interact with data\nand models. Currently, marketing knowledge is dispersed in large corpora, but\nno definitive knowledge base for marketing exists. Out of the two broad aspects\nof marketing knowledge - representation and reasoning - this treatise focuses\non the former. Specifically, we focus on creation of marketing knowledge graph\nfrom corpora, which requires identification of entities and relations. The\nrelation identification task is particularly challenging in marketing, because\nof the non-factoid nature of much marketing knowledge, and the difficulty of\nforming rules that govern relations. Specifically, we define a set of relations\nto capture marketing knowledge, propose a pipeline for creating the knowledge\ngraph from text and propose a rule-guided semi-supervised relation prediction\nalgorithm to extract relations between marketing entities from sentences.", "published": "2019-12-18 04:32:18", "link": "http://arxiv.org/abs/1912.08374v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards an automatic recognition of mixed languages: The\n  Ukrainian-Russian hybrid language Surzhyk", "abstract": "Language interference is common in today's multilingual societies where more\nlanguages are being in contact and as a global final result leads to the\ncreation of hybrid languages. These, together with doubts on their right to be\nofficially recognised made emerge in the area of computational linguistics the\nproblem of their automatic identification and further elaboration. In this\npaper, we propose a first attempt to identify the elements of a\nUkrainian-Russian hybrid language, Surzhyk, through the adoption of the\nexample-based rules created with the instruments of programming language R. Our\nexample-based study consists of: 1) analysis of spoken samples of Surzhyk\nregistered by Del Gaudio (2010) in Kyiv area and creation of the written\ncorpus; 2) production of specific rules on the identification of Surzhyk\npatterns and their implementation; 3) testing the code and analysing the\neffectiveness.", "published": "2019-12-18 13:13:29", "link": "http://arxiv.org/abs/1912.08582v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Collective Entity Alignment via Adaptive Features", "abstract": "Entity alignment (EA) identifies entities that refer to the same real-world\nobject but locate in different knowledge graphs (KGs), and has been harnessed\nfor KG construction and integration. When generating EA results, current\nsolutions treat entities independently and fail to take into account the\ninterdependence between entities. To fill this gap, we propose a collective EA\nframework. We first employ three representative features, i.e., structural,\nsemantic and string signals, which are adapted to capture different aspects of\nthe similarity between entities in heterogeneous KGs. In order to make\ncollective EA decisions, we formulate EA as the classical stable matching\nproblem, which is further effectively solved by deferred acceptance algorithm.\nOur proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks\nagainst state-of-the-art solutions, and the empirical results verify its\neffectiveness and superiority.", "published": "2019-12-18 06:25:12", "link": "http://arxiv.org/abs/1912.08404v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multi-channel Reverse Dictionary Model", "abstract": "A reverse dictionary takes the description of a target word as input and\noutputs the target word together with other words that match the description.\nExisting reverse dictionary methods cannot deal with highly variable input\nqueries and low-frequency target words successfully. Inspired by the\ndescription-to-word inference process of humans, we propose the multi-channel\nreverse dictionary model, which can mitigate the two problems simultaneously.\nOur model comprises a sentence encoder and multiple predictors. The predictors\nare expected to identify different characteristics of the target word from the\ninput query. We evaluate our model on English and Chinese datasets including\nboth dictionary definitions and human-written descriptions. Experimental\nresults show that our model achieves the state-of-the-art performance, and even\noutperforms the most popular commercial reverse dictionary system on the\nhuman-written description dataset. We also conduct quantitative analyses and a\ncase study to demonstrate the effectiveness and robustness of our model. All\nthe code and data of this work can be obtained on\nhttps://github.com/thunlp/MultiRD.", "published": "2019-12-18 08:13:43", "link": "http://arxiv.org/abs/1912.08441v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MALA: Cross-Domain Dialogue Generation with Action Learning", "abstract": "Response generation for task-oriented dialogues involves two basic\ncomponents: dialogue planning and surface realization. These two components,\nhowever, have a discrepancy in their objectives, i.e., task completion and\nlanguage quality. To deal with such discrepancy, conditioned response\ngeneration has been introduced where the generation process is factorized into\naction decision and language generation via explicit action representations. To\nobtain action representations, recent studies learn latent actions in an\nunsupervised manner based on the utterance lexical similarity. Such an action\nlearning approach is prone to diversities of language surfaces, which may\nimpinge task completion and language quality. To address this issue, we propose\nmulti-stage adaptive latent action learning (MALA) that learns semantic latent\nactions by distinguishing the effects of utterances on dialogue progress. We\nmodel the utterance effect using the transition of dialogue states caused by\nthe utterance and develop a semantic similarity measurement that estimates\nwhether utterances have similar effects. For learning semantic actions on\ndomains without dialogue states, MsALA extends the semantic similarity\nmeasurement across domains progressively, i.e., from aligning shared actions to\nlearning domain-specific actions. Experiments using multi-domain datasets, SMD\nand MultiWOZ, show that our proposed model achieves consistent improvements\nover the baselines models in terms of both task completion and language\nquality.", "published": "2019-12-18 08:14:10", "link": "http://arxiv.org/abs/1912.08442v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-end training of time domain audio separation and recognition", "abstract": "The rising interest in single-channel multi-speaker speech separation sparked\ndevelopment of End-to-End (E2E) approaches to multi-speaker speech recognition.\nHowever, up until now, state-of-the-art neural network-based time domain source\nseparation has not yet been combined with E2E speech recognition. We here\ndemonstrate how to combine a separation module based on a Convolutional Time\ndomain Audio Separation Network (Conv-TasNet) with an E2E speech recognizer and\nhow to train such a model jointly by distributing it over multiple GPUs or by\napproximating truncated back-propagation for the convolutional front-end. To\nput this work into perspective and illustrate the complexity of the design\nspace, we provide a compact overview of single-channel multi-speaker\nrecognition systems. Our experiments show a word error rate of 11.0% on\nWSJ0-2mix and indicate that our joint time domain model can yield substantial\nimprovements over cascade DNN-HMM and monolithic E2E frequency domain systems\nproposed so far.", "published": "2019-12-18 09:08:05", "link": "http://arxiv.org/abs/1912.08462v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Curriculum Learning Strategies for IR: An Empirical Study on\n  Conversation Response Ranking", "abstract": "Neural ranking models are traditionally trained on a series of random\nbatches, sampled uniformly from the entire training set. Curriculum learning\nhas recently been shown to improve neural models' effectiveness by sampling\nbatches non-uniformly, going from easy to difficult instances during training.\nIn the context of neural Information Retrieval (IR) curriculum learning has not\nbeen explored yet, and so it remains unclear (1) how to measure the difficulty\nof training instances and (2) how to transition from easy to difficult\ninstances during training. To address both challenges and determine whether\ncurriculum learning is beneficial for neural ranking models, we need\nlarge-scale datasets and a retrieval task that allows us to conduct a wide\nrange of experiments. For this purpose, we resort to the task of conversation\nresponse ranking: ranking responses given the conversation history. In order to\ndeal with challenge (1), we explore scoring functions to measure the difficulty\nof conversations based on different input spaces. To address challenge (2) we\nevaluate different pacing functions, which determine the velocity in which we\ngo from easy to difficult instances. We find that, overall, by just\nintelligently sorting the training data (i.e., by performing curriculum\nlearning) we can improve the retrieval effectiveness by up to 2%.", "published": "2019-12-18 12:13:30", "link": "http://arxiv.org/abs/1912.08555v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "iASiS Open Data Graph: Automated Semantic Integration of\n  Disease-Specific Knowledge", "abstract": "In biomedical research, unified access to up-to-date domain-specific\nknowledge is crucial, as such knowledge is continuously accumulated in\nscientific literature and structured resources. Identifying and extracting\nspecific information is a challenging task and computational analysis of\nknowledge bases can be valuable in this direction. However, for\ndisease-specific analyses researchers often need to compile their own datasets,\nintegrating knowledge from different resources, or reuse existing datasets,\nthat can be out-of-date. In this study, we propose a framework to automatically\nretrieve and integrate disease-specific knowledge into an up-to-date semantic\ngraph, the iASiS Open Data Graph. This disease-specific semantic graph provides\naccess to knowledge relevant to specific concepts and their individual aspects,\nin the form of concept relations and attributes. The proposed approach is\nimplemented as an open-source framework and applied to three diseases (Lung\nCancer, Dementia, and Duchenne Muscular Dystrophy). Exemplary queries are\npresented, investigating the potential of this automatically generated semantic\ngraph as a basis for retrieval and analysis of disease-specific knowledge.", "published": "2019-12-18 14:33:05", "link": "http://arxiv.org/abs/1912.08633v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language", "abstract": "We introduce the task of 3D object localization in RGB-D scans using natural\nlanguage descriptions. As input, we assume a point cloud of a scanned 3D scene\nalong with a free-form description of a specified target object. To address\nthis task, we propose ScanRefer, learning a fused descriptor from 3D object\nproposals and encoded sentence embeddings. This fused descriptor correlates\nlanguage expressions with geometric features, enabling regression of the 3D\nbounding box of a target object. We also introduce the ScanRefer dataset,\ncontaining 51,583 descriptions of 11,046 objects from 800 ScanNet scenes.\nScanRefer is the first large-scale effort to perform object localization via\nnatural language expression directly in 3D.", "published": "2019-12-18 19:00:49", "link": "http://arxiv.org/abs/1912.08830v3", "categories": ["cs.CV", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Macaw: An Extensible Conversational Information Seeking Platform", "abstract": "Conversational information seeking (CIS) has been recognized as a major\nemerging research area in information retrieval. Such research will require\ndata and tools, to allow the implementation and study of conversational\nsystems. This paper introduces Macaw, an open-source framework with a modular\narchitecture for CIS research. Macaw supports multi-turn, multi-modal, and\nmixed-initiative interactions, and enables research for tasks such as document\nretrieval, question answering, recommendation, and structured data exploration.\nIt has a modular design to encourage the study of new CIS algorithms, which can\nbe evaluated in batch mode. It can also integrate with a user interface, which\nallows user studies and data collection in an interactive mode, where the back\nend can be fully algorithmic or a wizard of oz setup. Macaw is distributed\nunder the MIT License.", "published": "2019-12-18 21:51:22", "link": "http://arxiv.org/abs/1912.08904v1", "categories": ["cs.IR", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "MedCAT -- Medical Concept Annotation Tool", "abstract": "Biomedical documents such as Electronic Health Records (EHRs) contain a large\namount of information in an unstructured format. The data in EHRs is a hugely\nvaluable resource documenting clinical narratives and decisions, but whilst the\ntext can be easily understood by human doctors it is challenging to use in\nresearch and clinical applications. To uncover the potential of biomedical\ndocuments we need to extract and structure the information they contain. The\ntask at hand is Named Entity Recognition and Linking (NER+L). The number of\nentities, ambiguity of words, overlapping and nesting make the biomedical area\nsignificantly more difficult than many others. To overcome these difficulties,\nwe have developed the Medical Concept Annotation Tool (MedCAT), an open-source\nunsupervised approach to NER+L. MedCAT uses unsupervised machine learning to\ndisambiguate entities. It was validated on MIMIC-III (a freely accessible\ncritical care database) and MedMentions (Biomedical papers annotated with\nmentions from the Unified Medical Language System). In case of NER+L, the\ncomparison with existing tools shows that MedCAT improves the previous best\nwith only unsupervised learning (F1=0.848 vs 0.691 for disease detection;\nF1=0.710 vs. 0.222 for general concept detection). A qualitative analysis of\nthe vector embeddings learnt by MedCAT shows that it captures latent medical\nknowledge available in EHRs (MIMIC-III). Unsupervised learning can improve the\nperformance of large scale entity extraction, but it has some limitations when\nworking with only a couple of entities and a small dataset. In that case\noptions are supervised learning or active learning, both of which are supported\nin MedCAT via the MedCATtrainer extension. Our approach can detect and link\nmillions of different biomedical concepts with state-of-the-art performance,\nwhilst being lightweight, fast and easy to use.", "published": "2019-12-18 17:42:31", "link": "http://arxiv.org/abs/1912.10166v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Cycle-GAN Approach to Model Natural Perturbations in Speech for ASR\n  Applications", "abstract": "Naturally introduced perturbations in audio signal, caused by emotional and\nphysical states of the speaker, can significantly degrade the performance of\nAutomatic Speech Recognition (ASR) systems. In this paper, we propose a\nfront-end based on Cycle-Consistent Generative Adversarial Network (CycleGAN)\nwhich transforms naturally perturbed speech into normal speech, and hence\nimproves the robustness of an ASR system. The CycleGAN model is trained on\nnon-parallel examples of perturbed and normal speech. Experiments on\nspontaneous laughter-speech and creaky-speech datasets show that the\nperformance of four different ASR systems improve by using speech obtained from\nCycleGAN based front-end, as compared to directly using the original perturbed\nspeech. Visualization of the features of the laughter perturbed speech and\nthose generated by the proposed front-end further demonstrates the\neffectiveness of our approach.", "published": "2019-12-18 12:26:38", "link": "http://arxiv.org/abs/1912.11151v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Topic subject creation using unsupervised learning for topic modeling", "abstract": "We describe the use of Non-Negative Matrix Factorization (NMF) and Latent\nDirichlet Allocation (LDA) algorithms to perform topic mining and labelling\napplied to retail customer communications in attempt to characterize the\nsubject of customers inquiries. In this paper we compare both algorithms in the\ntopic mining performance and propose methods to assign topic subject labels in\nan automated way.", "published": "2019-12-18 20:11:03", "link": "http://arxiv.org/abs/1912.08868v1", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Detecting Adversarial Attacks On Audiovisual Speech Recognition", "abstract": "Adversarial attacks pose a threat to deep learning models. However, research\non adversarial detection methods, especially in the multi-modal domain, is very\nlimited. In this work, we propose an efficient and straightforward detection\nmethod based on the temporal correlation between audio and video streams. The\nmain idea is that the correlation between audio and video in adversarial\nexamples will be lower than benign examples due to added adversarial noise. We\nuse the synchronisation confidence score as a proxy for audiovisual correlation\nand based on it we can detect adversarial attacks. To the best of our\nknowledge, this is the first work on detection of adversarial attacks on\naudiovisual speech recognition models. We apply recent adversarial attacks on\ntwo audiovisual speech recognition models trained on the GRID and LRW datasets.\nThe experimental results demonstrate that the proposed approach is an effective\nway for detecting such attacks.", "published": "2019-12-18 14:43:43", "link": "http://arxiv.org/abs/1912.08639v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Location Forensics Analysis Using ENF Sequences Extracted from Power and\n  Audio Recordings", "abstract": "Electrical network frequency (ENF) is the signature of a power distribution\ngrid which represents the nominal frequency (50 or 60 Hz) of a power system\nnetwork. Due to load variations in a power grid, ENF sequences experience\nfluctuations. These ENF variations are inherently located in a multimedia\nsignal which is recorded close to the grid or directly from the mains power\nline. Therefore, a multimedia recording can be localized by analyzing the ENF\nsequences of that signal in absence of the concurrent power signal. In this\npaper, a novel approach to analyze location forensics using ENF sequences\nextracted from a number of power and audio recordings is proposed. The digital\nrecordings are collected from different grid locations around the world.\nPotential feature components are determined from the ENF sequences. Then, a\nmulti-class support vector machine (SVM) classification model is developed to\nvalidate the location authenticity of the recordings. The performance\nassessments affirm the efficacy of the presented work.", "published": "2019-12-18 17:15:28", "link": "http://arxiv.org/abs/1912.09428v1", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "eess.SP"}
