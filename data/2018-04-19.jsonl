{"title": "Improving Distantly Supervised Relation Extraction using Word and Entity\n  Based Attention", "abstract": "Relation extraction is the problem of classifying the relationship between\ntwo entities in a given sentence. Distant Supervision (DS) is a popular\ntechnique for developing relation extractors starting with limited supervision.\nWe note that most of the sentences in the distant supervision relation\nextraction setting are very long and may benefit from word attention for better\nsentence representation. Our contributions in this paper are threefold.\nFirstly, we propose two novel word attention models for distantly- supervised\nrelation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based\nword attention model (BGWA), (2) an entity-centric attention model (EA), and\n(3) a combination model which combines multiple complementary models using\nweighted voting method for improved relation extraction. Secondly, we introduce\nGDS, a new distant supervision dataset for relation extraction. GDS removes\ntest data noise present in all previous distant- supervision benchmark\ndatasets, making credible automatic evaluation possible. Thirdly, through\nextensive experiments on multiple real-world datasets, we demonstrate the\neffectiveness of the proposed methods.", "published": "2018-04-19 03:38:43", "link": "http://arxiv.org/abs/1804.06987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QuaSE: Accurate Text Style Transfer under Quantifiable Guidance", "abstract": "We propose the task of Quantifiable Sequence Editing (QuaSE): editing an\ninput sequence to generate an output sequence that satisfies a given numerical\noutcome value measuring a certain property of the sequence, with the\nrequirement of keeping the main content of the input sequence. For example, an\ninput sequence could be a word sequence, such as review sentence and\nadvertisement text. For a review sentence, the outcome could be the review\nrating; for an advertisement, the outcome could be the click-through rate. The\nmajor challenge in performing QuaSE is how to perceive the outcome-related\nwordings, and only edit them to change the outcome. In this paper, the proposed\nframework contains two latent factors, namely, outcome factor and content\nfactor, disentangled from the input sentence to allow convenient editing to\nchange the outcome and keep the content. Our framework explores the\npseudo-parallel sentences by modeling their content similarity and outcome\ndifferences to enable a better disentanglement of the latent factors, which\nallows generating an output to better satisfy the desired outcome and keep the\ncontent. The dual reconstruction structure further enhances the capability of\ngenerating expected output by exploiting the couplings of latent factors of\npseudo-parallel sentences. For evaluation, we prepared a dataset of Yelp review\nsentences with the ratings as outcome. Extensive experimental results are\nreported and discussed to elaborate the peculiarities of our framework.", "published": "2018-04-19 06:13:48", "link": "http://arxiv.org/abs/1804.07007v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Extract Coherent Summary via Deep Reinforcement Learning", "abstract": "Coherence plays a critical role in producing a high-quality summary from a\ndocument. In recent years, neural extractive summarization is becoming\nincreasingly attractive. However, most of them ignore the coherence of\nsummaries when extracting sentences. As an effort towards extracting coherent\nsummaries, we propose a neural coherence model to capture the cross-sentence\nsemantic and syntactic coherence patterns. The proposed neural coherence model\nobviates the need for feature engineering and can be trained in an end-to-end\nfashion using unlabeled data. Empirical results show that the proposed neural\ncoherence model can efficiently capture the cross-sentence coherence patterns.\nUsing the combined output of the neural coherence model and ROUGE package as\nthe reward, we design a reinforcement learning method to train a proposed\nneural extractive summarizer which is named Reinforced Neural Extractive\nSummarization (RNES) model. The RNES model learns to optimize coherence and\ninformative importance of the summary simultaneously. Experimental results show\nthat the proposed RNES outperforms existing baselines and achieves\nstate-of-the-art performance in term of ROUGE on CNN/Daily Mail dataset. The\nqualitative evaluation indicates that summaries produced by RNES are more\ncoherent and readable.", "published": "2018-04-19 08:42:32", "link": "http://arxiv.org/abs/1804.07036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Consistent CCG Parsing over Multiple Sentences for Improved Logical\n  Reasoning", "abstract": "In formal logic-based approaches to Recognizing Textual Entailment (RTE), a\nCombinatory Categorial Grammar (CCG) parser is used to parse input premises and\nhypotheses to obtain their logical formulas. Here, it is important that the\nparser processes the sentences consistently; failing to recognize a similar\nsyntactic structure results in inconsistent predicate argument structures among\nthem, in which case the succeeding theorem proving is doomed to failure. In\nthis work, we present a simple method to extend an existing CCG parser to parse\na set of sentences consistently, which is achieved with an inter-sentence\nmodeling with Markov Random Fields (MRF). When combined with existing\nlogic-based systems, our method always shows improvement in the RTE experiments\non English and Japanese languages.", "published": "2018-04-19 10:17:47", "link": "http://arxiv.org/abs/1804.07068v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Putting Question-Answering Systems into Practice: Transfer Learning for\n  Efficient Domain Customization", "abstract": "Traditional information retrieval (such as that offered by web search\nengines) impedes users with information overload from extensive result pages\nand the need to manually locate the desired information therein. Conversely,\nquestion-answering systems change how humans interact with information systems:\nusers can now ask specific questions and obtain a tailored answer - both\nconveniently in natural language. Despite obvious benefits, their use is often\nlimited to an academic context, largely because of expensive domain\ncustomizations, which means that the performance in domain-specific\napplications often fails to meet expectations. This paper proposes\ncost-efficient remedies: (i) we leverage metadata through a filtering\nmechanism, which increases the precision of document retrieval, and (ii) we\ndevelop a novel fuse-and-oversample approach for transfer learning in order to\nimprove the performance of answer extraction. Here knowledge is inductively\ntransferred from a related, yet different, tasks to the domain-specific\napplication, while accounting for potential differences in the sample sizes\nacross both tasks. The resulting performance is demonstrated with actual use\ncases from a finance company and the film industry, where fewer than 400\nquestion-answer pairs had to be annotated in order to yield significant\nperformance gains. As a direct implication to management, this presents a\npromising path to better leveraging of knowledge stored in information systems.", "published": "2018-04-19 11:40:08", "link": "http://arxiv.org/abs/1804.07097v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Disentangled Representations of Texts with Application to\n  Biomedical Abstracts", "abstract": "We propose a method for learning disentangled representations of texts that\ncode for distinct and complementary aspects, with the aim of affording\nefficient model transfer and interpretability. To induce disentangled\nembeddings, we propose an adversarial objective based on the (dis)similarity\nbetween triplets of documents with respect to specific aspects. Our motivating\napplication is embedding biomedical abstracts describing clinical trials in a\nmanner that disentangles the populations, interventions, and outcomes in a\ngiven trial. We show that our method learns representations that encode these\nclinically salient aspects, and that these can be effectively used to perform\naspect-specific retrieval. We demonstrate that the approach generalizes beyond\nour motivating application in experiments on two multi-aspect review corpora.", "published": "2018-04-19 15:09:14", "link": "http://arxiv.org/abs/1804.07212v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Helping or Hurting? Predicting Changes in Users' Risk of Self-Harm\n  Through Online Community Interactions", "abstract": "In recent years, online communities have formed around suicide and self-harm\nprevention. While these communities offer support in moment of crisis, they can\nalso normalize harmful behavior, discourage professional treatment, and\ninstigate suicidal ideation. In this work, we focus on how interaction with\nothers in such a community affects the mental state of users who are seeking\nsupport. We first build a dataset of conversation threads between users in a\ndistressed state and community members offering support. We then show how to\nconstruct a classifier to predict whether distressed users are helped or harmed\nby the interactions in the thread, and we achieve a macro-F1 score of up to\n0.69.", "published": "2018-04-19 16:18:51", "link": "http://arxiv.org/abs/1804.07253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Language Proficiency from Eye Movements in Reading", "abstract": "We present a novel approach for determining learners' second language\nproficiency which utilizes behavioral traces of eye movements during reading.\nOur approach provides stand-alone eyetracking based English proficiency scores\nwhich reflect the extent to which the learner's gaze patterns in reading are\nsimilar to those of native English speakers. We show that our scores correlate\nstrongly with standardized English proficiency tests. We also demonstrate that\ngaze information can be used to accurately predict the outcomes of such tests.\nOur approach yields the strongest performance when the test taker is presented\nwith a suite of sentences for which we have eyetracking data from other\nreaders. However, it remains effective even using eyetracking with sentences\nfor which eye movement data have not been previously collected. By deriving\nproficiency as an automatic byproduct of eye movements during ordinary reading,\nour approach offers a potentially valuable new tool for second language\nproficiency assessment. More broadly, our results open the door to future\nmethods for inferring reader characteristics from the behavioral traces of\nreading.", "published": "2018-04-19 18:32:11", "link": "http://arxiv.org/abs/1804.07329v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Predictive Model for Notional Anaphora in English", "abstract": "Notional anaphors are pronouns which disagree with their antecedents'\ngrammatical categories for notional reasons, such as plural to singular\nagreement in: 'the government ... they'. Since such cases are rare and conflict\nwith evidence from strictly agreeing cases ('the government ... it'), they\npresent a substantial challenge to both coreference resolution and referring\nexpression generation. Using the OntoNotes corpus, this paper takes an ensemble\napproach to predicting English notional anaphora in context on the basis of the\nlargest empirical data to date. In addition to state of the art prediction\naccuracy, the results suggest that theoretical approaches positing a plural\nconstrual at the antecedent's utterance are insufficient, and that\ncircumstances at the anaphor's utterance location, as well as global factors\nsuch as genre, have a strong effect on the choice of referring expression.", "published": "2018-04-19 20:48:53", "link": "http://arxiv.org/abs/1804.07375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utilizing Neural Networks and Linguistic Metadata for Early Detection of\n  Depression Indications in Text Sequences", "abstract": "Depression is ranked as the largest contributor to global disability and is\nalso a major reason for suicide. Still, many individuals suffering from forms\nof depression are not treated for various reasons. Previous studies have shown\nthat depression also has an effect on language usage and that many depressed\nindividuals use social media platforms or the internet in general to get\ninformation or discuss their problems. This paper addresses the early detection\nof depression using machine learning models based on messages on a social\nplatform. In particular, a convolutional neural network based on different word\nembeddings is evaluated and compared to a classification based on user-level\nlinguistic metadata. An ensemble of both approaches is shown to achieve\nstate-of-the-art results in a current early detection task. Furthermore, the\ncurrently popular ERDE score as metric for early detection systems is examined\nin detail and its drawbacks in the context of shared tasks are illustrated. A\nslightly modified metric is proposed and compared to the original score.\nFinally, a new word embedding was trained on a large corpus of the same domain\nas the described task and is evaluated as well.", "published": "2018-04-19 05:25:51", "link": "http://arxiv.org/abs/1804.07000v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Stylistic Variation in Social Media Part-of-Speech Tagging", "abstract": "Social media features substantial stylistic variation, raising new challenges\nfor syntactic analysis of online writing. However, this variation is often\naligned with author attributes such as age, gender, and geography, as well as\nmore readily-available social network metadata. In this paper, we report new\nevidence on the link between language and social networks in the task of\npart-of-speech tagging. We find that tagger error rates are correlated with\nnetwork structure, with high accuracy in some parts of the network, and lower\naccuracy elsewhere. As a result, tagger accuracy depends on training from a\nbalanced sample of the network, rather than training on texts from a narrow\nsubcommunity. We also describe our attempts to add robustness to stylistic\nvariation, by building a mixture-of-experts model in which each expert is\nassociated with a region of the social network. While prior work found that\nsimilar approaches yield performance improvements in sentiment analysis and\nentity linking, we were unable to obtain performance improvements in\npart-of-speech tagging, despite strong evidence for the link between\npart-of-speech error rates and social network structure.", "published": "2018-04-19 18:37:40", "link": "http://arxiv.org/abs/1804.07331v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Video based Contextual Question Answering", "abstract": "The primary aim of this project is to build a contextual Question-Answering\nmodel for videos. The current methodologies provide a robust model for image\nbased Question-Answering, but we are aim to generalize this approach to be\nvideos. We propose a graphical representation of video which is able to handle\nseveral types of queries across the whole video. For example, if a frame has an\nimage of a man and a cat sitting, it should be able to handle queries like,\nwhere is the cat sitting with respect to the man? or ,what is the man holding\nin his hand?. It should be able to answer queries relating to temporal\nrelationships also.", "published": "2018-04-19 23:06:00", "link": "http://arxiv.org/abs/1804.07399v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LightRel SemEval-2018 Task 7: Lightweight and Fast Relation\n  Classification", "abstract": "We present LightRel, a lightweight and fast relation classifier. Our goal is\nto develop a high baseline for different relation extraction tasks. By defining\nonly very few data-internal, word-level features and external knowledge sources\nin the form of word clusters and word embeddings, we train a fast and simple\nlinear classifier.", "published": "2018-04-19 09:42:01", "link": "http://arxiv.org/abs/1804.08426v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic Text Analysis for Detection of Compromised Accounts on Social\n  Networks", "abstract": "Compromised accounts on social networks are regular user accounts that have\nbeen taken over by an entity with malicious intent. Since the adversary\nexploits the already established trust of a compromised account, it is crucial\nto detect these accounts to limit the damage they can cause. We propose a novel\ngeneral framework for semantic analysis of text messages coming out from an\naccount to detect compromised accounts. Our framework is built on the\nobservation that normal users will use language that is measurably different\nfrom the language that an adversary would use when the account is compromised.\nWe propose to use the difference of language models of users and adversaries to\ndefine novel interpretable semantic features for measuring semantic incoherence\nin a message stream. We study the effectiveness of the proposed semantic\nfeatures using a Twitter data set. Evaluation results show that the proposed\nframework is effective for discovering compromised accounts on social networks\nand a KL-divergence-based language model feature works best.", "published": "2018-04-19 16:06:29", "link": "http://arxiv.org/abs/1804.07247v4", "categories": ["cs.SI", "cs.CL", "cs.CR"], "primary_category": "cs.SI"}
{"title": "Weakly Supervised Representation Learning for Unsynchronized\n  Audio-Visual Events", "abstract": "Audio-visual representation learning is an important task from the\nperspective of designing machines with the ability to understand complex\nevents. To this end, we propose a novel multimodal framework that instantiates\nmultiple instance learning. We show that the learnt representations are useful\nfor classifying events and localizing their characteristic audio-visual\nelements. The system is trained using only video-level event labels without any\ntiming information. An important feature of our method is its capacity to learn\nfrom unsynchronized audio-visual events. We achieve state-of-the-art results on\na large-scale dataset of weakly-labeled audio event videos. Visualizations of\nlocalized visual regions and audio segments substantiate our system's efficacy,\nespecially when dealing with noisy situations where modality-specific cues\nappear asynchronously.", "published": "2018-04-19 19:33:11", "link": "http://arxiv.org/abs/1804.07345v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
