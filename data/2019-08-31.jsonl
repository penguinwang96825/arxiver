{"title": "(Male, Bachelor) and (Female, Ph.D) have different connotations:\n  Parallelly Annotated Stylistic Language Dataset with Multiple Personas", "abstract": "Stylistic variation in text needs to be studied with different aspects\nincluding the writer's personal traits, interpersonal relations, rhetoric, and\nmore. Despite recent attempts on computational modeling of the variation, the\nlack of parallel corpora of style language makes it difficult to systematically\ncontrol the stylistic change as well as evaluate such models. We release\nPASTEL, the parallel and annotated stylistic language dataset, that contains\n~41K parallel sentences (8.3K parallel stories) annotated across different\npersonas. Each persona has different styles in conjunction: gender, age,\ncountry, political view, education, ethnic, and time-of-writing. The dataset is\ncollected from human annotators with solid control of input denotation: not\nonly preserving original meaning between text, but promoting stylistic\ndiversity to annotators. We test the dataset on two interesting applications of\nstyle language, where PASTEL helps design appropriate experiment and\nevaluation. First, in predicting a target style (e.g., male or female in\ngender) given a text, multiple styles of PASTEL make other external style\nvariables controlled (or fixed), which is a more accurate experimental design.\nSecond, a simple supervised model with our parallel text outperforms the\nunsupervised models using nonparallel text in style transfer. Our dataset is\npublicly available.", "published": "2019-08-31 00:33:32", "link": "http://arxiv.org/abs/1909.00098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Small and Practical BERT Models for Sequence Labeling", "abstract": "We propose a practical scheme to train a single multilingual sequence\nlabeling model that yields state of the art results and is small and fast\nenough to run on a single CPU. Starting from a public multilingual BERT\ncheckpoint, our final model is 6x smaller and 27x faster, and has higher\naccuracy than a state-of-the-art multilingual baseline. We show that our model\nespecially outperforms on low-resource languages, and works on codemixed input\ntext without being explicitly trained on codemixed examples. We showcase the\neffectiveness of our method by reporting on part-of-speech tagging and\nmorphological prediction on 70 treebanks and 48 languages.", "published": "2019-08-31 00:39:12", "link": "http://arxiv.org/abs/1909.00100v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Behavior Gated Language Models", "abstract": "Most current language modeling techniques only exploit co-occurrence,\nsemantic and syntactic information from the sequence of words. However, a range\nof information such as the state of the speaker and dynamics of the interaction\nmight be useful. In this work we derive motivation from psycholinguistics and\npropose the addition of behavioral information into the context of language\nmodeling. We propose the augmentation of language models with an additional\nmodule which analyzes the behavioral state of the current context. This\nbehavioral information is used to gate the outputs of the language model before\nthe final word prediction output. We show that the addition of behavioral\ncontext in language models achieves lower perplexities on behavior-rich\ndatasets. We also confirm the validity of the proposed models on a variety of\nmodel architectures and improve on previous state-of-the-art models with\ngeneric domain Penn Treebank Corpus.", "published": "2019-08-31 02:10:32", "link": "http://arxiv.org/abs/1909.00107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantity doesn't buy quality syntax with neural language models", "abstract": "Recurrent neural networks can learn to predict upcoming words remarkably well\non average; in syntactically complex contexts, however, they often assign\nunexpectedly high probabilities to ungrammatical words. We investigate to what\nextent these shortcomings can be mitigated by increasing the size of the\nnetwork and the corpus on which it is trained. We find that gains from\nincreasing network size are minimal beyond a certain point. Likewise, expanding\nthe training corpus yields diminishing returns; we estimate that the training\ncorpus would need to be unrealistically large for the models to match human\nperformance. A comparison to GPT and BERT, Transformer-based models trained on\nbillions of words, reveals that these models perform even more poorly than our\nLSTMs in some constructions. Our results make the case for more data efficient\narchitectures.", "published": "2019-08-31 02:41:49", "link": "http://arxiv.org/abs/1909.00111v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Graph Structure in Transformer for Better AMR-to-Text\n  Generation", "abstract": "Recent studies on AMR-to-text generation often formalize the task as a\nsequence-to-sequence (seq2seq) learning problem by converting an Abstract\nMeaning Representation (AMR) graph into a word sequence. Graph structures are\nfurther modeled into the seq2seq framework in order to utilize the structural\ninformation in the AMR graphs. However, previous approaches only consider the\nrelations between directly connected concepts while ignoring the rich structure\nin AMR graphs. In this paper we eliminate such a strong limitation and propose\na novel structure-aware self-attention approach to better modeling the\nrelations between indirectly connected concepts in the state-of-the-art seq2seq\nmodel, i.e., the Transformer. In particular, a few different methods are\nexplored to learn structural representations between two concepts. Experimental\nresults on English AMR benchmark datasets show that our approach significantly\noutperforms the state of the art with 29.66 and 31.82 BLEU scores on LDC2015E86\nand LDC2017T10, respectively. To the best of our knowledge, these are the best\nresults achieved so far by supervised models on the benchmarks.", "published": "2019-08-31 05:45:20", "link": "http://arxiv.org/abs/1909.00136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EntEval: A Holistic Evaluation Benchmark for Entity Representations", "abstract": "Rich entity representations are useful for a wide class of problems involving\nentities. Despite their importance, there is no standardized benchmark that\nevaluates the overall quality of entity representations. In this work, we\npropose EntEval: a test suite of diverse tasks that require nontrivial\nunderstanding of entities including entity typing, entity similarity, entity\nrelation prediction, and entity disambiguation. In addition, we develop\ntraining techniques for learning better entity representations by using natural\nhyperlink annotations in Wikipedia. We identify effective objectives for\nincorporating the contextual information in hyperlinks into state-of-the-art\npretrained language models and show that they improve strong baselines on\nmultiple EntEval tasks.", "published": "2019-08-31 06:02:11", "link": "http://arxiv.org/abs/1909.00137v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question-type Driven Question Generation", "abstract": "Question generation is a challenging task which aims to ask a question based\non an answer and relevant context. The existing works suffer from the\nmismatching between question type and answer, i.e. generating a question with\ntype $how$ while the answer is a personal name. We propose to automatically\npredict the question type based on the input answer and context. Then, the\nquestion type is fused into a seq2seq model to guide the question generation,\nso as to deal with the mismatching problem. We achieve significant improvement\non the accuracy of question type prediction and finally obtain state-of-the-art\nresults for question generation on both SQuAD and MARCO datasets.", "published": "2019-08-31 06:11:31", "link": "http://arxiv.org/abs/1909.00140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence\n  Representations", "abstract": "Prior work on pretrained sentence embeddings and benchmarks focus on the\ncapabilities of stand-alone sentences. We propose DiscoEval, a test suite of\ntasks to evaluate whether sentence representations include broader context\ninformation. We also propose a variety of training objectives that makes use of\nnatural annotations from Wikipedia to build sentence encoders capable of\nmodeling discourse. We benchmark sentence encoders pretrained with our proposed\ntraining objectives, as well as other popular pretrained sentence encoders on\nDiscoEval and other sentence evaluation tasks. Empirically, we show that these\ntraining objectives help to encode different aspects of information in document\nstructures. Moreover, BERT and ELMo demonstrate strong performances over\nDiscoEval with individual hidden layers showing different characteristics.", "published": "2019-08-31 06:19:42", "link": "http://arxiv.org/abs/1909.00142v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NCLS: Neural Cross-Lingual Summarization", "abstract": "Cross-lingual summarization (CLS) is the task to produce a summary in one\nparticular language for a source document in a different language. Existing\nmethods simply divide this task into two steps: summarization and translation,\nleading to the problem of error propagation. To handle that, we present an\nend-to-end CLS framework, which we refer to as Neural Cross-Lingual\nSummarization (NCLS), for the first time. Moreover, we propose to further\nimprove NCLS by incorporating two related tasks, monolingual summarization and\nmachine translation, into the training process of CLS under multi-task\nlearning. Due to the lack of supervised CLS data, we propose a round-trip\ntranslation strategy to acquire two high-quality large-scale CLS datasets based\non existing monolingual summarization datasets. Experimental results have shown\nthat our NCLS achieves remarkable improvement over traditional pipeline methods\non both English-to-Chinese and Chinese-to-English CLS human-corrected test\nsets. In addition, NCLS with multi-task learning can further significantly\nimprove the quality of generated summaries. We make our dataset and code\npublicly available here: http://www.nlpr.ia.ac.cn/cip/dataset.htm.", "published": "2019-08-31 07:24:48", "link": "http://arxiv.org/abs/1909.00156v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Back-Translation with Uncertainty-based Confidence Estimation", "abstract": "While back-translation is simple and effective in exploiting abundant\nmonolingual corpora to improve low-resource neural machine translation (NMT),\nthe synthetic bilingual corpora generated by NMT models trained on limited\nauthentic bilingual data are inevitably noisy. In this work, we propose to\nquantify the confidence of NMT model predictions based on model uncertainty.\nWith word- and sentence-level confidence measures based on uncertainty, it is\npossible for back-translation to better cope with noise in synthetic bilingual\ncorpora. Experiments on Chinese-English and English-German translation tasks\nshow that uncertainty-based confidence estimation significantly improves the\nperformance of back-translation.", "published": "2019-08-31 07:35:36", "link": "http://arxiv.org/abs/1909.00157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and\n  Entailment Approach", "abstract": "Zero-shot text classification (0Shot-TC) is a challenging NLU problem to\nwhich little attention has been paid by the research community. 0Shot-TC aims\nto associate an appropriate label with a piece of text, irrespective of the\ntext domain and the aspect (e.g., topic, emotion, event, etc.) described by the\nlabel. And there are only a few articles studying 0Shot-TC, all focusing only\non topical categorization which, we argue, is just the tip of the iceberg in\n0Shot-TC. In addition, the chaotic experiments in literature make no uniform\ncomparison, which blurs the progress.\n  This work benchmarks the 0Shot-TC problem by providing unified datasets,\nstandardized evaluations, and state-of-the-art baselines. Our contributions\ninclude: i) The datasets we provide facilitate studying 0Shot-TC relative to\nconceptually different and diverse aspects: the ``topic'' aspect includes\n``sports'' and ``politics'' as labels; the ``emotion'' aspect includes ``joy''\nand ``anger''; the ``situation'' aspect includes ``medical assistance'' and\n``water shortage''. ii) We extend the existing evaluation setup\n(label-partially-unseen) -- given a dataset, train on some labels, test on all\nlabels -- to include a more challenging yet realistic evaluation\nlabel-fully-unseen 0Shot-TC (Chang et al., 2008), aiming at classifying text\nsnippets without seeing task specific training data at all. iii) We unify the\n0Shot-TC of diverse aspects within a textual entailment formulation and study\nit this way.\n  Code & Data: https://github.com/yinwenpeng/BenchmarkingZeroShot", "published": "2019-08-31 07:42:11", "link": "http://arxiv.org/abs/1909.00161v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Detection and Location of English Puns", "abstract": "A pun is a form of wordplay for an intended humorous or rhetorical effect,\nwhere a word suggests two or more meanings by exploiting polysemy (homographic\npun) or phonological similarity to another word (heterographic pun). This paper\npresents an approach that addresses pun detection and pun location jointly from\na sequence labeling perspective. We employ a new tagging scheme such that the\nmodel is capable of performing such a joint task, where useful structural\ninformation can be properly captured. We show that our proposed model is\neffective in handling both homographic and heterographic puns. Empirical\nresults on the benchmark datasets demonstrate that our approach can achieve new\nstate-of-the-art results.", "published": "2019-08-31 09:31:36", "link": "http://arxiv.org/abs/1909.00175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantity Tagger: A Latent-Variable Sequence Labeling Approach to Solving\n  Addition-Subtraction Word Problems", "abstract": "An arithmetic word problem typically includes a textual description\ncontaining several constant quantities. The key to solving the problem is to\nreveal the underlying mathematical relations (such as addition and subtraction)\namong quantities, and then generate equations to find solutions. This work\npresents a novel approach, Quantity Tagger, that automatically discovers such\nhidden relations by tagging each quantity with a sign corresponding to one type\nof mathematical operation. For each quantity, we assume there exists a latent,\nvariable-sized quantity span surrounding the quantity token in the text, which\nconveys information useful for determining its sign. Empirical results show\nthat our method achieves 5 and 8 points of accuracy gains on two datasets\nrespectively, compared to prior approaches.", "published": "2019-08-31 09:33:04", "link": "http://arxiv.org/abs/1909.00176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explicit Cross-lingual Pre-training for Unsupervised Machine Translation", "abstract": "Pre-training has proven to be effective in unsupervised machine translation\ndue to its ability to model deep context information in cross-lingual\nscenarios. However, the cross-lingual information obtained from shared BPE\nspaces is inexplicit and limited. In this paper, we propose a novel\ncross-lingual pre-training method for unsupervised machine translation by\nincorporating explicit cross-lingual training signals. Specifically, we first\ncalculate cross-lingual n-gram embeddings and infer an n-gram translation table\nfrom them. With those n-gram translation pairs, we propose a new pre-training\nmodel called Cross-lingual Masked Language Model (CMLM), which randomly chooses\nsource n-grams in the input text stream and predicts their translation\ncandidates at each time step. Experiments show that our method can incorporate\nbeneficial cross-lingual information into pre-trained models. Taking\npre-trained CMLM models as the encoder and decoder, we significantly improve\nthe performance of unsupervised machine translation.", "published": "2019-08-31 09:58:57", "link": "http://arxiv.org/abs/1909.00180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Ordinal Regression for Pledge Specificity Prediction", "abstract": "Many pledges are made in the course of an election campaign, forming\nimportant corpora for political analysis of campaign strategy and governmental\naccountability. At present, there are no publicly available annotated datasets\nof pledges, and most political analyses rely on manual analysis. In this paper\nwe collate a novel dataset of manifestos from eleven Australian federal\nelection cycles, with over 12,000 sentences annotated with specificity (e.g.,\nrhetorical vs.\\ detailed pledge) on a fine-grained scale. We propose deep\nordinal regression approaches for specificity prediction, under both supervised\nand semi-supervised settings, and provide empirical results demonstrating the\neffectiveness of the proposed techniques over several baseline approaches. We\nanalyze the utility of pledge specificity modeling across a spectrum of policy\nissues in performing ideology prediction, and further provide qualitative\nanalysis in terms of capturing party-specific issue salience across election\ncycles.", "published": "2019-08-31 10:38:56", "link": "http://arxiv.org/abs/1909.00187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Multi-Head Attention with Capsule Networks", "abstract": "Multi-head attention advances neural machine translation by working out\nmultiple versions of attention in different subspaces, but the neglect of\nsemantic overlapping between subspaces increases the difficulty of translation\nand consequently hinders the further improvement of translation performance. In\nthis paper, we employ capsule networks to comb the information from the\nmultiple heads of the attention so that similar information can be clustered\nand unique information can be reserved. To this end, we adopt two routing\nmechanisms of Dynamic Routing and EM Routing, to fulfill the clustering and\nseparating. We conducted experiments on Chinese-to-English and\nEnglish-to-German translation tasks and got consistent improvements over the\nstrong Transformer baseline.", "published": "2019-08-31 10:43:06", "link": "http://arxiv.org/abs/1909.00188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NEZHA: Neural Contextualized Representation for Chinese Language\n  Understanding", "abstract": "The pre-trained language models have achieved great successes in various\nnatural language understanding (NLU) tasks due to its capacity to capture the\ndeep contextualized information in text by pre-training on large-scale corpora.\nIn this technical report, we present our practice of pre-training language\nmodels named NEZHA (NEural contextualiZed representation for CHinese lAnguage\nunderstanding) on Chinese corpora and finetuning for the Chinese NLU tasks. The\ncurrent version of NEZHA is based on BERT with a collection of proven\nimprovements, which include Functional Relative Positional Encoding as an\neffective positional encoding scheme, Whole Word Masking strategy, Mixed\nPrecision Training and the LAMB Optimizer in training the models. The\nexperimental results show that NEZHA achieves the state-of-the-art performances\nwhen finetuned on several representative Chinese tasks, including named entity\nrecognition (People's Daily NER), sentence matching (LCQMC), Chinese sentiment\nclassification (ChnSenti) and natural language inference (XNLI).", "published": "2019-08-31 12:08:53", "link": "http://arxiv.org/abs/1909.00204v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Connecting the Dots: Document-level Neural Relation Extraction with\n  Edge-oriented Graphs", "abstract": "Document-level relation extraction is a complex human process that requires\nlogical inference to extract relationships between named entities in text.\nExisting approaches use graph-based neural models with words as nodes and edges\nas relations between them, to encode relations across sentences. These models\nare node-based, i.e., they form pair representations based solely on the two\ntarget node representations. However, entity relations can be better expressed\nthrough unique edge representations formed as paths between nodes. We thus\npropose an edge-oriented graph neural model for document-level relation\nextraction. The model utilises different types of nodes and edges to create a\ndocument-level graph. An inference mechanism on the graph edges enables to\nlearn intra- and inter-sentence relations using multi-instance learning\ninternally. Experiments on two document-level biomedical datasets for\nchemical-disease and gene-disease associations show the usefulness of the\nproposed edge-oriented approach.", "published": "2019-08-31 15:14:01", "link": "http://arxiv.org/abs/1909.00228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Sentiment Analysis Reveal Structure in a Plotless Novel?", "abstract": "Modernist novels are thought to break with traditional plot structure. In\nthis paper, we test this theory by applying Sentiment Analysis to one of the\nmost famous modernist novels, To the Lighthouse by Virginia Woolf. We first\nassess Sentiment Analysis in light of the critique that it cannot adequately\naccount for literary language: we use a unique statistical comparison to\ndemonstrate that even simple lexical approaches to Sentiment Analysis are\nsurprisingly effective. We then use the Syuzhet.R package to explore\nsimilarities and differences across modeling methods. This comparative\napproach, when paired with literary close reading, can offer interpretive\nclues. To our knowledge, we are the first to undertake a hybrid model that\nfully leverages the strengths of both computational analysis and close reading.\nThis hybrid model raises new questions for the literary critic, such as how to\ninterpret relative versus absolute emotional valence and how to take into\naccount subjective identification. Our finding is that while To the Lighthouse\ndoes not replicate a plot centered around a traditional hero, it does reveal an\nunderlying emotional structure distributed between characters - what we term a\ndistributed heroine model. This finding is innovative in the field of modernist\nand narrative studies and demonstrates that a hybrid method can yield\nsignificant discoveries.", "published": "2019-08-31 17:25:00", "link": "http://arxiv.org/abs/1910.01441v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Giving BERT a Calculator: Finding Operations and Arguments with Reading\n  Comprehension", "abstract": "Reading comprehension models have been successfully applied to extractive\ntext answers, but it is unclear how best to generalize these models to\nabstractive numerical answers. We enable a BERT-based reading comprehension\nmodel to perform lightweight numerical reasoning. We augment the model with a\npredefined set of executable 'programs' which encompass simple arithmetic as\nwell as extraction. Rather than having to learn to manipulate numbers directly,\nthe model can pick a program and execute it. On the recent Discrete Reasoning\nOver Passages (DROP) dataset, designed to challenge reading comprehension\nmodels, we show a 33% absolute improvement by adding shallow programs. The\nmodel can learn to predict new operations when appropriate in a math word\nproblem setting (Roy and Roth, 2015) with very few training examples.", "published": "2019-08-31 02:30:24", "link": "http://arxiv.org/abs/1909.00109v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Semantics-Assisted Video Captioning Model Trained with Scheduled\n  Sampling", "abstract": "Given the features of a video, recurrent neural networks can be used to\nautomatically generate a caption for the video. Existing methods for video\ncaptioning have at least three limitations. First, semantic information has\nbeen widely applied to boost the performance of video captioning models, but\nexisting networks often fail to provide meaningful semantic features. Second,\nthe Teacher Forcing algorithm is often utilized to optimize video captioning\nmodels, but during training and inference, different strategies are applied to\nguide word generation, leading to poor performance. Third, current video\ncaptioning models are prone to generate relatively short captions that express\nvideo contents inappropriately. Toward resolving these three problems, we\nsuggest three corresponding improvements. First of all, we propose a metric to\ncompare the quality of semantic features, and utilize appropriate features as\ninput for a semantic detection network (SDN) with adequate complexity in order\nto generate meaningful semantic features for videos. Then, we apply a scheduled\nsampling strategy that gradually transfers the training phase from a\nteacher-guided manner toward a more self-teaching manner. Finally, the ordinary\nlogarithm probability loss function is leveraged by sentence length so that the\ninclination of generating short sentences is alleviated. Our model achieves\nbetter results than previous models on the YouTube2Text dataset and is\ncompetitive with the previous best model on the MSR-VTT dataset.", "published": "2019-08-31 04:01:38", "link": "http://arxiv.org/abs/1909.00121v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Learning with Noisy Labels for Sentence-level Sentiment Classification", "abstract": "Deep neural networks (DNNs) can fit (or even over-fit) the training data very\nwell. If a DNN model is trained using data with noisy labels and tested on data\nwith clean labels, the model may perform poorly. This paper studies the problem\nof learning with noisy labels for sentence-level sentiment classification. We\npropose a novel DNN model called NetAb (as shorthand for convolutional neural\nNetworks with Ab-networks) to handle noisy labels during training. NetAb\nconsists of two convolutional neural networks, one with a noise transition\nlayer for dealing with the input noisy labels and the other for predicting\n'clean' labels. We train the two networks using their respective loss functions\nin a mutual reinforcement manner. Experimental results demonstrate the\neffectiveness of the proposed model.", "published": "2019-08-31 04:18:50", "link": "http://arxiv.org/abs/1909.00124v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning with Contextual Embeddings for Zero-resource\n  Cross-lingual Classification and NER", "abstract": "Contextual word embeddings (e.g. GPT, BERT, ELMo, etc.) have demonstrated\nstate-of-the-art performance on various NLP tasks. Recent work with the\nmultilingual version of BERT has shown that the model performs very well in\nzero-shot and zero-resource cross-lingual settings, where only labeled English\ndata is used to finetune the model. We improve upon multilingual BERT's\nzero-resource cross-lingual performance via adversarial learning. We report the\nmagnitude of the improvement on the multilingual MLDoc text classification and\nCoNLL 2002/2003 named entity recognition tasks. Furthermore, we show that\nlanguage-adversarial training encourages BERT to align the embeddings of\nEnglish documents and their translations, which may be the cause of the\nobserved performance gains.", "published": "2019-08-31 06:59:46", "link": "http://arxiv.org/abs/1909.00153v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition Only from Word Embeddings", "abstract": "Deep neural network models have helped named entity (NE) recognition achieve\namazing performance without handcrafting features. However, existing systems\nrequire large amounts of human annotated training data. Efforts have been made\nto replace human annotations with external knowledge (e.g., NE dictionary,\npart-of-speech tags), while it is another challenge to obtain such effective\nresources. In this work, we propose a fully unsupervised NE recognition model\nwhich only needs to take informative clues from pre-trained word embeddings. We\nfirst apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture\nModel on word embeddings for entity span detection and type prediction, and\nthen further design an instance selector based on reinforcement learning to\ndistinguish positive sentences from noisy sentences and refine these\ncoarse-grained annotations through neural networks. Extensive experiments on\nCoNLL benchmark datasets demonstrate that our proposed light NE recognition\nmodel achieves remarkable performance without using any annotated lexicon or\ncorpus.", "published": "2019-08-31 08:22:13", "link": "http://arxiv.org/abs/1909.00164v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Open Named Entity Modeling from Embedding Distribution", "abstract": "In this paper, we report our discovery on named entity distribution in a\ngeneral word embedding space, which helps an open definition on multilingual\nnamed entity definition rather than previous closed and constraint definition\non named entities through a named entity dictionary, which is usually derived\nfrom human labor and replies on schedule update. Our initial visualization of\nmonolingual word embeddings indicates named entities tend to gather together\ndespite of named entity types and language difference, which enable us to model\nall named entities using a specific geometric structure inside embedding space,\nnamely, the named entity hypersphere. For monolingual cases, the proposed named\nentity model gives an open description of diverse named entity types and\ndifferent languages. For cross-lingual cases, mapping the proposed named entity\nmodel provides a novel way to build a named entity dataset for resource-poor\nlanguages. At last, the proposed named entity model may be shown as a handy\nclue to enhance state-of-the-art named entity recognition systems generally.", "published": "2019-08-31 08:56:46", "link": "http://arxiv.org/abs/1909.00170v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Humor Detection: A Transformer Gets the Last Laugh", "abstract": "Much previous work has been done in attempting to identify humor in text. In\nthis paper we extend that capability by proposing a new task: assessing whether\nor not a joke is humorous. We present a novel way of approaching this problem\nby building a model that learns to identify humorous jokes based on ratings\ngleaned from Reddit pages, consisting of almost 16,000 labeled instances. Using\nthese ratings to determine the level of humor, we then employ a Transformer\narchitecture for its advantages in learning from sentence context. We\ndemonstrate the effectiveness of this approach and show results that are\ncomparable to human performance. We further demonstrate our model's increased\ncapabilities on humor identification problems, such as the previously created\ndatasets for short jokes and puns. These experiments show that this method\noutperforms all previous work done on these tasks, with an F-measure of 93.1%\nfor the Puns dataset and 98.6% on the Short Jokes dataset.", "published": "2019-08-31 18:01:29", "link": "http://arxiv.org/abs/1909.00252v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense\n  Reasoning", "abstract": "Understanding narratives requires reading between the lines, which in turn,\nrequires interpreting the likely causes and effects of events, even when they\nare not mentioned explicitly. In this paper, we introduce Cosmos QA, a\nlarge-scale dataset of 35,600 problems that require commonsense-based reading\ncomprehension, formulated as multiple-choice questions. In stark contrast to\nmost existing reading comprehension datasets where the questions focus on\nfactual and literal understanding of the context paragraph, our dataset focuses\non reading between the lines over a diverse collection of people's everyday\nnarratives, asking such questions as \"what might be the possible reason of\n...?\", or \"what would have happened if ...\" that require reasoning beyond the\nexact text spans in the context. To establish baseline performances on Cosmos\nQA, we experiment with several state-of-the-art neural architectures for\nreading comprehension, and also propose a new architecture that improves over\nthe competitive baselines. Experimental results demonstrate a significant gap\nbetween machine (68.4%) and human performance (94%), pointing to avenues for\nfuture research on commonsense machine comprehension. Dataset, code and\nleaderboard is publicly available at https://wilburone.github.io/cosmos.", "published": "2019-08-31 19:55:44", "link": "http://arxiv.org/abs/1909.00277v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Let's Ask Again: Refine Network for Automatic Question Generation", "abstract": "In this work, we focus on the task of Automatic Question Generation (AQG)\nwhere given a passage and an answer the task is to generate the corresponding\nquestion. It is desired that the generated question should be (i) grammatically\ncorrect (ii) answerable from the passage and (iii) specific to the given\nanswer. An analysis of existing AQG models shows that they produce questions\nwhich do not adhere to one or more of {the above-mentioned qualities}. In\nparticular, the generated questions look like an incomplete draft of the\ndesired question with a clear scope for refinement. {To alleviate this\nshortcoming}, we propose a method which tries to mimic the human process of\ngenerating questions by first creating an initial draft and then refining it.\nMore specifically, we propose Refine Network (RefNet) which contains two\ndecoders. The second decoder uses a dual attention network which pays attention\nto both (i) the original passage and (ii) the question (initial draft)\ngenerated by the first decoder. In effect, it refines the question generated by\nthe first decoder, thereby making it more correct and complete. We evaluate\nRefNet on three datasets, \\textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show\nthat it outperforms existing state-of-the-art methods by 7-16\\% on all of these\ndatasets. Lastly, we show that we can improve the quality of the second decoder\non specific metrics, such as, fluency and answerability by explicitly rewarding\nrevisions that improve on the corresponding metric during training. The code\nhas been made publicly available\n\\footnote{https://github.com/PrekshaNema25/RefNet-QG}", "published": "2019-08-31 04:03:26", "link": "http://arxiv.org/abs/1909.05355v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Enhanced Attention for Robust Natural Language Inference", "abstract": "Neural network models have been very successful at achieving high accuracy on\nnatural language inference (NLI) tasks. However, as demonstrated in recent\nliterature, when tested on some simple adversarial examples, most of the models\nsuffer a significant drop in performance. This raises the concern about the\nrobustness of NLI models. In this paper, we propose to make NLI models robust\nby incorporating external knowledge to the attention mechanism using a simple\ntransformation. We apply the new attention to two popular types of NLI models:\none is Transformer encoder, and the other is a decomposable model, and show\nthat our method can significantly improve their robustness. Moreover, when\ncombined with BERT pretraining, our method achieves the human-level performance\non the adversarial SNLI data set.", "published": "2019-08-31 01:04:58", "link": "http://arxiv.org/abs/1909.00102v1", "categories": ["cs.CL", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Generating Personalized Recipes from Historical User Preferences", "abstract": "Existing approaches to recipe generation are unable to create recipes for\nusers with culinary preferences but incomplete knowledge of ingredients in\nspecific dishes. We propose a new task of personalized recipe generation to\nhelp these users: expanding a name and incomplete ingredient details into\ncomplete natural-text instructions aligned with the user's historical\npreferences. We attend on technique- and recipe-level representations of a\nuser's previously consumed recipes, fusing these 'user-aware' representations\nin an attention fusion layer to control recipe text generation. Experiments on\na new dataset of 180K recipes and 700K interactions show our model's ability to\ngenerate plausible and personalized recipes compared to non-personalized\nbaselines.", "published": "2019-08-31 01:50:42", "link": "http://arxiv.org/abs/1909.00105v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Logic-Driven Framework for Consistency of Neural Models", "abstract": "While neural models show remarkable accuracy on individual predictions, their\ninternal beliefs can be inconsistent across examples. In this paper, we\nformalize such inconsistency as a generalization of prediction error. We\npropose a learning framework for constraining models using logic rules to\nregularize them away from inconsistency. Our framework can leverage both\nlabeled and unlabeled examples and is directly compatible with off-the-shelf\nlearning schemes without model redesign. We instantiate our framework on\nnatural language inference, where experiments show that enforcing invariants\nstated in logic can help make the predictions of neural models both accurate\nand consistent.", "published": "2019-08-31 04:38:06", "link": "http://arxiv.org/abs/1909.00126v4", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Evaluating Pronominal Anaphora in Machine Translation: An Evaluation\n  Measure and a Test Suite", "abstract": "The ongoing neural revolution in machine translation has made it easier to\nmodel larger contexts beyond the sentence-level, which can potentially help\nresolve some discourse-level ambiguities such as pronominal anaphora, thus\nenabling better translations. Unfortunately, even when the resulting\nimprovements are seen as substantial by humans, they remain virtually unnoticed\nby traditional automatic evaluation measures like BLEU, as only a few words end\nup being affected. Thus, specialized evaluation measures are needed. With this\naim in mind, we contribute an extensive, targeted dataset that can be used as a\ntest suite for pronoun translation, covering multiple source languages and\ndifferent pronoun errors drawn from real system translations, for English. We\nfurther propose an evaluation measure to differentiate good and bad pronoun\ntranslations. We also conduct a user study to report correlations with human\njudgments.", "published": "2019-08-31 05:28:51", "link": "http://arxiv.org/abs/1909.00131v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Reinforcement Learning with Distributional Semantic Rewards for\n  Abstractive Summarization", "abstract": "Deep reinforcement learning (RL) has been a commonly-used strategy for the\nabstractive summarization task to address both the exposure bias and\nnon-differentiable task issues. However, the conventional reward Rouge-L simply\nlooks for exact n-grams matches between candidates and annotated references,\nwhich inevitably makes the generated sentences repetitive and incoherent. In\nthis paper, instead of Rouge-L, we explore the practicability of utilizing the\ndistributional semantics to measure the matching degrees. With distributional\nsemantics, sentence-level evaluation can be obtained, and semantically-correct\nphrases can also be generated without being limited to the surface form of the\nreference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets\nshow that our proposed distributional semantics reward (DSR) has distinct\nsuperiority in capturing the lexical and compositional diversity of natural\nlanguage.", "published": "2019-08-31 06:13:33", "link": "http://arxiv.org/abs/1909.00141v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Rethinking travel behavior modeling representations through embeddings", "abstract": "This paper introduces the concept of travel behavior embeddings, a method for\nre-representing discrete variables that are typically used in travel demand\nmodeling, such as mode, trip purpose, education level, family type or\noccupation. This re-representation process essentially maps those variables\ninto a latent space called the \\emph{embedding space}. The benefit of this is\nthat such spaces allow for richer nuances than the typical transformations used\nin categorical variables (e.g. dummy encoding, contrasted encoding, principal\ncomponents analysis). While the usage of latent variable representations is not\nnew per se in travel demand modeling, the idea presented here brings several\ninnovations: it is an entirely data driven algorithm; it is informative and\nconsistent, since the latent space can be visualized and interpreted based on\ndistances between different categories; it preserves interpretability of\ncoefficients, despite being based on Neural Network principles; and it is\ntransferrable, in that embeddings learned from one dataset can be reused for\nother ones, as long as travel behavior keeps consistent between the datasets.\n  The idea is strongly inspired on natural language processing techniques,\nnamely the word2vec algorithm. Such algorithm is behind recent developments\nsuch as in automatic translation or next word prediction. Our method is\ndemonstrated using a model choice model, and shows improvements of up to 60\\%\nwith respect to initial likelihood, and up to 20% with respect to likelihood of\nthe corresponding traditional model (i.e. using dummy variables) in\nout-of-sample evaluation. We provide a new Python package, called PyTre (PYthon\nTRavel Embeddings), that others can straightforwardly use to replicate our\nresults or improve their own models. Our experiments are themselves based on an\nopen dataset (swissmetro).", "published": "2019-08-31 07:05:43", "link": "http://arxiv.org/abs/1909.00154v1", "categories": ["econ.EM", "cs.CL", "cs.LG"], "primary_category": "econ.EM"}
{"title": "Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs", "abstract": "Recently, biomedical version of embeddings obtained from language models such\nas BioELMo have shown state-of-the-art results for the textual inference task\nin the medical domain. In this paper, we explore how to incorporate structured\ndomain knowledge, available in the form of a knowledge graph (UMLS), for the\nMedical NLI task. Specifically, we experiment with fusing embeddings obtained\nfrom knowledge graph with the state-of-the-art approaches for NLI task (ESIM\nmodel). We also experiment with fusing the domain-specific sentiment\ninformation for the task. Experiments conducted on MedNLI dataset clearly show\nthat this strategy improves the baseline BioELMo architecture for the Medical\nNLI task.", "published": "2019-08-31 07:41:42", "link": "http://arxiv.org/abs/1909.00160v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QAInfomax: Learning Robust Question Answering System by Mutual\n  Information Maximization", "abstract": "Standard accuracy metrics indicate that modern reading comprehension systems\nhave achieved strong performance in many question answering datasets. However,\nthe extent these systems truly understand language remains unknown, and\nexisting systems are not good at distinguishing distractor sentences, which\nlook related but do not actually answer the question. To address this problem,\nwe propose QAInfomax as a regularizer in reading comprehension systems by\nmaximizing mutual information among passages, a question, and its answer.\nQAInfomax helps regularize the model to not simply learn the superficial\ncorrelation for answering questions. The experiments show that our proposed\nQAInfomax achieves the state-of-the-art performance on the benchmark\nAdversarial-SQuAD dataset.", "published": "2019-08-31 13:50:28", "link": "http://arxiv.org/abs/1909.00215v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Collaborative Policy Learning for Open Knowledge Graph Reasoning", "abstract": "In recent years, there has been a surge of interests in interpretable graph\nreasoning methods. However, these models often suffer from limited performance\nwhen working on sparse and incomplete graphs, due to the lack of evidential\npaths that can reach target entities. Here we study open knowledge graph\nreasoning---a task that aims to reason for missing facts over a graph augmented\nby a background text corpus. A key challenge of the task is to filter out\n\"irrelevant\" facts extracted from corpus, in order to maintain an effective\nsearch space during path inference. We propose a novel reinforcement learning\nframework to train two collaborative agents jointly, i.e., a multi-hop graph\nreasoner and a fact extractor. The fact extraction agent generates fact triples\nfrom corpora to enrich the graph on the fly; while the reasoning agent provides\nfeedback to the fact extractor and guides it towards promoting facts that are\nhelpful for the interpretable reasoning. Experiments on two public datasets\ndemonstrate the effectiveness of the proposed approach. Source code and\ndatasets used in this paper can be downloaded at\nhttps://github.com/shanzhenren/CPL", "published": "2019-08-31 15:46:05", "link": "http://arxiv.org/abs/1909.00230v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Generating Classical Chinese Poems from Vernacular Chinese", "abstract": "Classical Chinese poetry is a jewel in the treasure house of Chinese culture.\nPrevious poem generation models only allow users to employ keywords to\ninterfere the meaning of generated poems, leaving the dominion of generation to\nthe model. In this paper, we propose a novel task of generating classical\nChinese poems from vernacular, which allows users to have more control over the\nsemantic of generated poems. We adapt the approach of unsupervised machine\ntranslation (UMT) to our task. We use segmentation-based padding and\nreinforcement learning to address under-translation and over-translation\nrespectively. According to experiments, our approach significantly improve the\nperplexity and BLEU compared with typical UMT models. Furthermore, we explored\nguidelines on how to write the input vernacular to generate better poems. Human\nevaluation showed our approach can generate high-quality poems which are\ncomparable to amateur poems.", "published": "2019-08-31 20:07:25", "link": "http://arxiv.org/abs/1909.00279v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entity Projection via Machine Translation for Cross-Lingual NER", "abstract": "Although over 100 languages are supported by strong off-the-shelf machine\ntranslation systems, only a subset of them possess large annotated corpora for\nnamed entity recognition. Motivated by this fact, we leverage machine\ntranslation to improve annotation-projection approaches to cross-lingual named\nentity recognition. We propose a system that improves over prior\nentity-projection methods by: (a) leveraging machine translation systems twice:\nfirst for translating sentences and subsequently for translating entities; (b)\nmatching entities based on orthographic and phonetic similarity; and (c)\nidentifying matches based on distributional statistics derived from the\ndataset. Our approach improves upon current state-of-the-art methods for\ncross-lingual named entity recognition on 5 diverse languages by an average of\n4.1 points. Further, our method achieves state-of-the-art F_1 scores for\nArmenian, outperforming even a monolingual model trained on Armenian source\ndata.", "published": "2019-08-31 17:40:21", "link": "http://arxiv.org/abs/1909.05356v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Out-of-Domain Detection for Low-Resource Text Classification Tasks", "abstract": "Out-of-domain (OOD) detection for low-resource text classification is a\nrealistic but understudied task. The goal is to detect the OOD cases with\nlimited in-domain (ID) training data, since we observe that training data is\noften insufficient in machine learning applications. In this work, we propose\nan OOD-resistant Prototypical Network to tackle this zero-shot OOD detection\nand few-shot ID classification task. Evaluation on real-world datasets show\nthat the proposed solution outperforms state-of-the-art methods in zero-shot\nOOD detection task, while maintaining a competitive performance on ID\nclassification task.", "published": "2019-08-31 20:23:26", "link": "http://arxiv.org/abs/1909.05357v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Extracting information from free text through unsupervised graph-based\n  clustering: an application to patient incident records", "abstract": "The large volume of text in electronic healthcare records often remains\nunderused due to a lack of methodologies to extract interpretable content. Here\nwe present an unsupervised framework for the analysis of free text that\ncombines text-embedding with paragraph vectors and graph-theoretical multiscale\ncommunity detection. We analyse text from a corpus of patient incident reports\nfrom the National Health Service in England to find content-based clusters of\nreports in an unsupervised manner and at different levels of resolution. Our\nunsupervised method extracts groups with high intrinsic textual consistency and\ncompares well against categories hand-coded by healthcare personnel. We also\nshow how to use our content-driven clusters to improve the supervised\nprediction of the degree of harm of the incident based on the text of the\nreport. Finally, we discuss future directions to monitor reports over time, and\nto detect emerging trends outside pre-existing categories.", "published": "2019-08-31 10:03:11", "link": "http://arxiv.org/abs/1909.00183v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "math.SP", "stat.ML"], "primary_category": "cs.LG"}
