{"title": "Data Augmentation to Address Out-of-Vocabulary Problem in Low-Resource\n  Sinhala-English Neural Machine Translation", "abstract": "Out-of-Vocabulary (OOV) is a problem for Neural Machine Translation (NMT).\nOOV refers to words with a low occurrence in the training data, or to those\nthat are absent from the training data. To alleviate this, word or phrase-based\nData Augmentation (DA) techniques have been used. However, existing DA\ntechniques have addressed only one of these OOV types and limit to considering\neither syntactic constraints or semantic constraints. We present a word and\nphrase replacement-based DA technique that consider both types of OOV, by\naugmenting (1) rare words in the existing parallel corpus, and (2) new words\nfrom a bilingual dictionary. During augmentation, we consider both syntactic\nand semantic properties of the words to guarantee fluency in the synthetic\nsentences. This technique was experimented with low resource Sinhala-English\nlanguage pair. We observe with only semantic constraints in the DA, the results\nare comparable with the scores obtained considering syntactic constraints, and\nis favourable for low-resourced languages that lacks linguistic tool support.\nAdditionally, results can be further improved by considering both syntactic and\nsemantic constraints.", "published": "2022-05-18 04:52:43", "link": "http://arxiv.org/abs/2205.08722v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Persian Natural Language Inference: A Meta-learning approach", "abstract": "Incorporating information from other languages can improve the results of\ntasks in low-resource languages. A powerful method of building functional\nnatural language processing systems for low-resource languages is to combine\nmultilingual pre-trained representations with cross-lingual transfer learning.\nIn general, however, shared representations are learned separately, either\nacross tasks or across languages. This paper proposes a meta-learning approach\nfor inferring natural language in Persian. Alternately, meta-learning uses\ndifferent task information (such as QA in Persian) or other language\ninformation (such as natural language inference in English). Also, we\ninvestigate the role of task augmentation strategy for forming additional\nhigh-quality tasks. We evaluate the proposed method using four languages and an\nauxiliary task. Compared to the baseline approach, the proposed model\nconsistently outperforms it, improving accuracy by roughly six percent. We also\nexamine the effect of finding appropriate initial parameters using zero-shot\nevaluation and CCA similarity.", "published": "2022-05-18 06:51:58", "link": "http://arxiv.org/abs/2205.08755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Extraction with Weighted Contrastive Pre-training on Distant\n  Supervision", "abstract": "Contrastive pre-training on distant supervision has shown remarkable\neffectiveness in improving supervised relation extraction tasks. However, the\nexisting methods ignore the intrinsic noise of distant supervision during the\npre-training stage. In this paper, we propose a weighted contrastive learning\nmethod by leveraging the supervised data to estimate the reliability of\npre-training instances and explicitly reduce the effect of noise. Experimental\nresults on three supervised datasets demonstrate the advantages of our proposed\nweighted contrastive learning approach compared to two state-of-the-art\nnon-weighted baselines.Our code and models are available at:\nhttps://github.com/YukinoWan/WCL", "published": "2022-05-18 07:45:59", "link": "http://arxiv.org/abs/2205.08770v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LogiGAN: Learning Logical Reasoning via Adversarial Pre-training", "abstract": "We present LogiGAN, an unsupervised adversarial pre-training framework for\nimproving logical reasoning abilities of language models. Upon automatic\nidentifying logical reasoning phenomena in massive text corpus via detection\nheuristics, we train language models to predict the masked-out logical\nstatements. Inspired by the facilitation effect of reflective thinking in human\nlearning, we analogically simulate the learning-thinking process with an\nadversarial Generator-Verifier architecture to assist logic learning. LogiGAN\nimplements a novel sequential GAN approach that (a) circumvents the\nnon-differentiable challenge of the sequential GAN by leveraging the Generator\nas a sentence-level generative likelihood scorer with a learning objective of\nreaching scoring consensus with the Verifier; (b) is computationally feasible\nfor large-scale pre-training with arbitrary target length. Both base and large\nsize language models pre-trained with LogiGAN demonstrate obvious performance\nimprovement on 12 datasets requiring general reasoning abilities, revealing the\nfundamental role of logic in broad reasoning, as well as the effectiveness of\nLogiGAN. Ablation studies on LogiGAN components reveal the relative\northogonality between linguistic and logic abilities and suggest that\nreflective thinking's facilitation effect might also generalize to machine\nlearning.", "published": "2022-05-18 08:46:49", "link": "http://arxiv.org/abs/2205.08794v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Regex in a Time of Deep Learning: The Role of an Old Technology in Age\n  Discrimination Detection in Job Advertisements", "abstract": "Deep learning holds great promise for detecting discriminatory language in\nthe public sphere. However, for the detection of illegal age discrimination in\njob advertisements, regex approaches are still strong performers. In this\npaper, we investigate job advertisements in the Netherlands. We present a\nqualitative analysis of the benefits of the 'old' approach based on regexes and\ninvestigate how neural embeddings could address its limitations.", "published": "2022-05-18 09:27:58", "link": "http://arxiv.org/abs/2205.08813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Social Media Content for Self-Supervised Style Transfer", "abstract": "Recent research on style transfer takes inspiration from unsupervised neural\nmachine translation (UNMT), learning from large amounts of non-parallel data by\nexploiting cycle consistency loss, back-translation, and denoising\nautoencoders. By contrast, the use of self-supervised NMT (SSNMT), which\nleverages (near) parallel instances hidden in non-parallel data more\nefficiently than UNMT, has not yet been explored for style transfer. In this\npaper we present a novel Self-Supervised Style Transfer (3ST) model, which\naugments SSNMT with UNMT methods in order to identify and efficiently exploit\nsupervisory signals in non-parallel social media posts. We compare 3ST with\nstate-of-the-art (SOTA) style transfer models across civil rephrasing,\nformality and polarity tasks. We show that 3ST is able to balance the three\nmajor objectives (fluency, content preservation, attribute transfer accuracy)\nthe best, outperforming SOTA models on averaged performance across their tested\ntasks in automatic and human evaluation.", "published": "2022-05-18 09:28:27", "link": "http://arxiv.org/abs/2205.08814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BFCAI at SemEval-2022 Task 6: Multi-Layer Perceptron for Sarcasm\n  Detection in Arabic Texts", "abstract": "This paper describes the systems submitted to iSarcasm shared task. The aim\nof iSarcasm is to identify the sarcastic contents in Arabic and English text.\nOur team participated in iSarcasm for the Arabic language. A multi-Layer\nmachine learning based model has been submitted for Arabic sarcasm detection.\nIn this model, a vector space TF-IDF has been used as for feature\nrepresentation. The submitted system is simple and does not need any external\nresources. The test results show encouraging results.", "published": "2022-05-18 11:33:07", "link": "http://arxiv.org/abs/2205.08868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Scalable Workflow to Build Machine Learning Classifiers with\n  Clinician-in-the-Loop to Identify Patients in Specific Diseases", "abstract": "Clinicians may rely on medical coding systems such as International\nClassification of Diseases (ICD) to identify patients with diseases from\nElectronic Health Records (EHRs). However, due to the lack of detail and\nspecificity as well as a probability of miscoding, recent studies suggest the\nICD codes often cannot characterise patients accurately for specific diseases\nin real clinical practice, and as a result, using them to find patients for\nstudies or trials can result in high failure rates and missing out on uncoded\npatients. Manual inspection of all patients at scale is not feasible as it is\nhighly costly and slow.\n  This paper proposes a scalable workflow which leverages both structured data\nand unstructured textual notes from EHRs with techniques including NLP, AutoML\nand Clinician-in-the-Loop mechanism to build machine learning classifiers to\nidentify patients at scale with given diseases, especially those who might\ncurrently be miscoded or missed by ICD codes.\n  Case studies in the MIMIC-III dataset were conducted where the proposed\nworkflow demonstrates a higher classification performance in terms of F1 scores\ncompared to simply using ICD codes on gold testing subset to identify patients\nwith Ovarian Cancer (0.901 vs 0.814), Lung Cancer (0.859 vs 0.828), Cancer\nCachexia (0.862 vs 0.650), and Lupus Nephritis (0.959 vs 0.855). Also, the\nproposed workflow that leverages unstructured notes consistently outperforms\nthe baseline that uses structured data only with an increase of F1 (Ovarian\nCancer 0.901 vs 0.719, Lung Cancer 0.859 vs 0.787, Cancer Cachexia 0.862 vs\n0.838 and Lupus Nephritis 0.959 vs 0.785). Experiments on the large testing set\nalso demonstrate the proposed workflow can find more patients who are miscoded\nor missed by ICD codes. Moreover, interpretability studies are also conducted\nto clinically validate the top impact features of the classifiers.", "published": "2022-05-18 12:24:07", "link": "http://arxiv.org/abs/2205.08891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Features of Perceived Metaphoricity on the Discourse Level: Abstractness\n  and Emotionality", "abstract": "Research on metaphorical language has shown ties between abstractness and\nemotionality with regard to metaphoricity; prior work is however limited to the\nword and sentence levels, and up to date there is no empirical study\nestablishing the extent to which this is also true on the discourse level. This\npaper explores which textual and perceptual features human annotators perceive\nas important for the metaphoricity of discourses and expressions, and addresses\ntwo research questions more specifically. First, is a metaphorically-perceived\ndiscourse more abstract and more emotional in comparison to a\nliterally-perceived discourse? Second, is a metaphorical expression preceded by\na more metaphorical/abstract/emotional context than a synonymous literal\nalternative? We used a dataset of 1,000 corpus-extracted discourses for which\ncrowdsourced annotators (1) provided judgements on whether they perceived the\ndiscourses as more metaphorical or more literal, and (2) systematically listed\nlexical terms which triggered their decisions in (1). Our results indicate that\nmetaphorical discourses are more emotional and to a certain extent more\nabstract than literal discourses. However, neither the metaphoricity nor the\nabstractness and emotionality of the preceding discourse seem to play a role in\ntriggering the choice between synonymous metaphorical vs. literal expressions.\nOur dataset is available at\nhttps://www.ims.uni-stuttgart.de/data/discourse-met-lit.", "published": "2022-05-18 14:09:10", "link": "http://arxiv.org/abs/2205.08939v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Rule Induction for Interpretable Semi-Supervised Learning", "abstract": "Semi-supervised learning has shown promise in allowing NLP models to\ngeneralize from small amounts of labeled data. Meanwhile, pretrained\ntransformer models act as black-box correlation engines that are difficult to\nexplain and sometimes behave unreliably. In this paper, we propose tackling\nboth of these challenges via Automatic Rule Induction (ARI), a simple and\ngeneral-purpose framework for the automatic discovery and integration of\nsymbolic rules into pretrained transformer models. First, we extract weak\nsymbolic rules from low-capacity machine learning models trained on small\namounts of labeled data. Next, we use an attention mechanism to integrate these\nrules into high-capacity pretrained transformer models. Last, the\nrule-augmented system becomes part of a self-training framework to boost\nsupervision signal on unlabeled data. These steps can be layered beneath a\nvariety of existing weak supervision and semi-supervised NLP algorithms in\norder to improve performance and interpretability. Experiments across nine\nsequence classification and relation extraction tasks suggest that ARI can\nimprove state-of-the-art methods with no manual effort and minimal\ncomputational overhead.", "published": "2022-05-18 16:50:20", "link": "http://arxiv.org/abs/2205.09067v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self\n  On-the-fly Distillation for Dense Passage Retrieval", "abstract": "Neural retrievers based on pre-trained language models (PLMs), such as\ndual-encoders, have achieved promising performance on the task of open-domain\nquestion answering (QA). Their effectiveness can further reach new\nstate-of-the-arts by incorporating cross-architecture knowledge distillation.\nHowever, most of the existing studies just directly apply conventional\ndistillation methods. They fail to consider the particular situation where the\nteacher and student have different structures. In this paper, we propose a\nnovel distillation method that significantly advances cross-architecture\ndistillation for dual-encoders. Our method 1) introduces a self on-the-fly\ndistillation method that can effectively distill late interaction (i.e.,\nColBERT) to vanilla dual-encoder, and 2) incorporates a cascade distillation\nprocess to further improve the performance with a cross-encoder teacher.\nExtensive experiments are conducted to validate that our proposed solution\noutperforms strong baselines and establish a new state-of-the-art on\nopen-domain QA benchmarks.", "published": "2022-05-18 18:05:13", "link": "http://arxiv.org/abs/2205.09153v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Color Overmodification Emerges from Data-Driven Learning and Pragmatic\n  Reasoning", "abstract": "Speakers' referential expressions often depart from communicative ideals in\nways that help illuminate the nature of pragmatic language use. Patterns of\novermodification, in which a speaker uses a modifier that is redundant given\ntheir communicative goal, have proven especially informative in this regard. It\nseems likely that these patterns are shaped by the environment a speaker is\nexposed to in complex ways. Unfortunately, systematically manipulating these\nfactors during human language acquisition is impossible. In this paper, we\npropose to address this limitation by adopting neural networks (NN) as learning\nagents. By systematically varying the environments in which these agents are\ntrained, while keeping the NN architecture constant, we show that\novermodification is more likely with environmental features that are infrequent\nor salient. We show that these findings emerge naturally in the context of a\nprobabilistic model of pragmatic communication.", "published": "2022-05-18 18:42:43", "link": "http://arxiv.org/abs/2205.09172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner", "abstract": "Large language models have achieved high performance on various question\nanswering (QA) benchmarks, but the explainability of their output remains\nelusive. Structured explanations, called entailment trees, were recently\nsuggested as a way to explain and inspect a QA system's answer. In order to\nbetter generate such entailment trees, we propose an architecture called\nIterative Retrieval-Generation Reasoner (IRGR). Our model is able to explain a\ngiven hypothesis by systematically generating a step-by-step explanation from\ntextual premises. The IRGR model iteratively searches for suitable premises,\nconstructing a single entailment step at a time. Contrary to previous\napproaches, our method combines generation steps and retrieval of premises,\nallowing the model to leverage intermediate conclusions, and mitigating the\ninput size limit of baseline encoder-decoder models. We conduct experiments\nusing the EntailmentBank dataset, where we outperform existing benchmarks on\npremise retrieval and entailment tree generation, with around 300% gain in\noverall correctness.", "published": "2022-05-18 21:52:11", "link": "http://arxiv.org/abs/2205.09224v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Modeling Multi-hop Question Answering as Single Sequence Prediction", "abstract": "Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question\nanswering (QA) model that leverages passage retrieval with a pre-trained\ntransformer and pushed the state of the art on single-hop QA. However, the\ncomplexity of multi-hop QA hinders the effectiveness of the generative QA\napproach. In this work, we propose a simple generative approach (PathFid) that\nextends the task beyond just answer generation by explicitly modeling the\nreasoning process to resolve the answer for multi-hop questions. By linearizing\nthe hierarchical reasoning path of supporting passages, their key sentences,\nand finally the factoid answer, we cast the problem as a single sequence\nprediction task. To facilitate complex reasoning with multiple clues, we\nfurther extend the unified flat representation of multiple input documents by\nencoding cross-passage interactions. Our extensive experiments demonstrate that\nPathFid leads to strong performance gains on two multi-hop QA datasets:\nHotpotQA and IIRC. Besides the performance gains, PathFid is more\ninterpretable, which in turn yields answers that are more faithfully grounded\nto the supporting passages and facts compared to the baseline Fid model.", "published": "2022-05-18 21:57:59", "link": "http://arxiv.org/abs/2205.09226v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing Resource and Privacy Constraints in Semantic Parsing Through\n  Data Augmentation", "abstract": "We introduce a novel setup for low-resource task-oriented semantic parsing\nwhich incorporates several constraints that may arise in real-world scenarios:\n(1) lack of similar datasets/models from a related domain, (2) inability to\nsample useful logical forms directly from a grammar, and (3) privacy\nrequirements for unlabeled natural utterances. Our goal is to improve a\nlow-resource semantic parser using utterances collected through user\ninteractions. In this highly challenging but realistic setting, we investigate\ndata augmentation approaches involving generating a set of structured canonical\nutterances corresponding to logical forms, before simulating corresponding\nnatural language and filtering the resulting pairs. We find that such\napproaches are effective despite our restrictive setup: in a low-resource\nsetting on the complex SMCalFlow calendaring dataset (Andreas et al., 2020), we\nobserve 33% relative improvement over a non-data-augmented baseline in top-1\nmatch.", "published": "2022-05-18 01:14:47", "link": "http://arxiv.org/abs/2205.08675v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A reproducible experimental survey on biomedical sentence similarity: a\n  string-based method sets the state of the art", "abstract": "This registered report introduces the largest, and for the first time,\nreproducible experimental survey on biomedical sentence similarity with the\nfollowing aims: (1) to elucidate the state of the art of the problem; (2) to\nsolve some reproducibility problems preventing the evaluation of most of\ncurrent methods; (3) to evaluate several unexplored sentence similarity\nmethods; (4) to evaluate an unexplored benchmark, called\nCorpus-Transcriptional-Regulation; (5) to carry out a study on the impact of\nthe pre-processing stages and Named Entity Recognition (NER) tools on the\nperformance of the sentence similarity methods; and finally, (6) to bridge the\nlack of reproducibility resources for methods and experiments in this line of\nresearch. Our experimental survey is based on a single software platform that\nis provided with a detailed reproducibility protocol and dataset as\nsupplementary material to allow the exact replication of all our experiments.\nIn addition, we introduce a new aggregated string-based sentence similarity\nmethod, called LiBlock, together with eight variants of current ontology-based\nmethods and a new pre-trained word embedding model trained on the full-text\narticles in the PMC-BioC corpus. Our experiments show that our novel\nstring-based measure sets the new state of the art on the sentence similarity\ntask in the biomedical domain and significantly outperforms all the methods\nevaluated herein, except one ontology-based method. Likewise, our experiments\nconfirm that the pre-processing stages, and the choice of the NER tool, have a\nsignificant impact on the performance of the sentence similarity methods. We\nalso detail some drawbacks and limitations of current methods, and warn on the\nneed of refining the current benchmarks. Finally, a noticeable finding is that\nour new string-based method significantly outperforms all state-of-the-art\nMachine Learning models evaluated herein.", "published": "2022-05-18 06:20:42", "link": "http://arxiv.org/abs/2205.08740v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluation of Transfer Learning for Polish with a Text-to-Text Model", "abstract": "We introduce a new benchmark for assessing the quality of text-to-text models\nfor Polish. The benchmark consists of diverse tasks and datasets: KLEJ\nbenchmark adapted for text-to-text, en-pl translation, summarization, and\nquestion answering. In particular, since summarization and question answering\nlack benchmark datasets for the Polish language, we describe their construction\nand make them publicly available. Additionally, we present plT5 - a\ngeneral-purpose text-to-text model for Polish that can be fine-tuned on various\nNatural Language Processing (NLP) tasks with a single training objective.\nUnsupervised denoising pre-training is performed efficiently by initializing\nthe model weights with a multi-lingual T5 (mT5) counterpart. We evaluate the\nperformance of plT5, mT5, Polish BART (plBART), and Polish GPT-2 (papuGaPT2).\nThe plT5 scores top on all of these tasks except summarization, where plBART is\nbest. In general (except for summarization), the larger the model, the better\nthe results. The encoder-decoder architectures prove to be better than the\ndecoder-only equivalent.", "published": "2022-05-18 09:17:14", "link": "http://arxiv.org/abs/2205.08808v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GPoeT-2: A GPT-2 Based Poem Generator", "abstract": "This project aims to produce the next volume of machine-generated poetry, a\ncomplex art form that can be structured and unstructured, and carries depth in\nthe meaning between the lines. GPoeT-2 is based on fine-tuning a state of the\nart natural language model (i.e. GPT-2) to generate limericks, typically\nhumorous structured poems consisting of five lines with a AABBA rhyming scheme.\nWith a two-stage generation system utilizing both forward and reverse language\nmodeling, GPoeT-2 is capable of freely generating limericks in diverse topics\nwhile following the rhyming structure without any seed phrase or a posteriori\nconstraints.Based on the automated generation process, we explore a wide\nvariety of evaluation metrics to quantify \"good poetry,\" including syntactical\ncorrectness, lexical diversity, and subject continuity. Finally, we present a\ncollection of 94 categorized limericks that rank highly on the explored \"good\npoetry\" metrics to provoke human creativity.", "published": "2022-05-18 10:25:12", "link": "http://arxiv.org/abs/2205.08847v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CREATER: CTR-driven Advertising Text Generation with Controlled\n  Pre-Training and Contrastive Fine-Tuning", "abstract": "This paper focuses on automatically generating the text of an ad, and the\ngoal is that the generated text can capture user interest for achieving higher\nclick-through rate (CTR). We propose CREATER, a CTR-driven advertising text\ngeneration approach, to generate ad texts based on high-quality user reviews.\nTo incorporate CTR objective, our model learns from online A/B test data with\ncontrastive learning, which encourages the model to generate ad texts that\nobtain higher CTR. To alleviate the low-resource issue, we design a customized\nself-supervised objective reducing the gap between pre-training and\nfine-tuning. Experiments on industrial datasets show that CREATER significantly\noutperforms current approaches. It has been deployed online in a leading\nadvertising platform and brings uplift on core online metrics.", "published": "2022-05-18 14:17:04", "link": "http://arxiv.org/abs/2205.08943v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Leveraging Pseudo-labeled Data to Improve Direct Speech-to-Speech\n  Translation", "abstract": "Direct Speech-to-speech translation (S2ST) has drawn more and more attention\nrecently. The task is very challenging due to data scarcity and complex\nspeech-to-speech mapping. In this paper, we report our recent achievements in\nS2ST. Firstly, we build a S2ST Transformer baseline which outperforms the\noriginal Translatotron. Secondly, we utilize the external data by\npseudo-labeling and obtain a new state-of-the-art result on the Fisher\nEnglish-to-Spanish test set. Indeed, we exploit the pseudo data with a\ncombination of popular techniques which are not trivial when applied to S2ST.\nMoreover, we evaluate our approach on both syntactically similar\n(Spanish-English) and distant (English-Chinese) language pairs. Our\nimplementation is available at\nhttps://github.com/fengpeng-yue/speech-to-speech-translation.", "published": "2022-05-18 15:24:02", "link": "http://arxiv.org/abs/2205.08993v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Dialog Inpainting: Turning Documents into Dialogs", "abstract": "Many important questions (e.g. \"How to eat healthier?\") require conversation\nto establish context and explore in depth. However, conversational question\nanswering (ConvQA) systems have long been stymied by scarce training data that\nis expensive to collect. To address this problem, we propose a new technique\nfor synthetically generating diverse and high-quality dialog data: dialog\ninpainting. Our approach takes the text of any document and transforms it into\na two-person dialog between the writer and an imagined reader: we treat\nsentences from the article as utterances spoken by the writer, and then use a\ndialog inpainter to predict what the imagined reader asked or said in between\neach of the writer's utterances. By applying this approach to passages from\nWikipedia and the web, we produce WikiDialog and WebDialog, two datasets\ntotalling 19 million diverse information-seeking dialogs -- 1,000x larger than\nthe largest existing ConvQA dataset. Furthermore, human raters judge the answer\nadequacy and conversationality of WikiDialog to be as good or better than\nexisting manually-collected datasets. Using our inpainted data to pre-train\nConvQA retrieval systems, we significantly advance state-of-the-art across\nthree benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains\non standard evaluation metrics.", "published": "2022-05-18 16:58:50", "link": "http://arxiv.org/abs/2205.09073v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance", "abstract": "We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL\nsystem predicts how well a given sentence will be translated, without recourse\nto the actual translation, thus eschewing unnecessary resource allocation when\ntranslation quality is bound to be low. PreQuEL can be defined relative to a\ngiven MT system (e.g., some industry service) or generally relative to the\nstate-of-the-art. From a theoretical perspective, PreQuEL places the focus on\nthe source text, tracing properties, possibly linguistic features, that make a\nsentence harder to machine translate.\n  We develop a baseline model for the task and analyze its performance. We also\ndevelop a data augmentation method (from parallel corpora), that improves\nresults substantially. We show that this augmentation method can improve the\nperformance of the Quality-Estimation task as well. We investigate the\nproperties of the input text that our model is sensitive to, by testing it on\nchallenge sets and different languages. We conclude that it is aware of\nsyntactic and semantic distinctions, and correlates and even over-emphasizes\nthe importance of standard NLP features.", "published": "2022-05-18 18:55:05", "link": "http://arxiv.org/abs/2205.09178v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"I'm sorry to hear that\": Finding New Biases in Language Models with a\n  Holistic Descriptor Dataset", "abstract": "As language models grow in popularity, it becomes increasingly important to\nclearly measure all possible markers of demographic identity in order to avoid\nperpetuating existing societal harms. Many datasets for measuring bias\ncurrently exist, but they are restricted in their coverage of demographic axes\nand are commonly used with preset bias tests that presuppose which types of\nbiases models can exhibit. In this work, we present a new, more inclusive bias\nmeasurement dataset, HolisticBias, which includes nearly 600 descriptor terms\nacross 13 different demographic axes. HolisticBias was assembled in a\nparticipatory process including experts and community members with lived\nexperience of these terms. These descriptors combine with a set of bias\nmeasurement templates to produce over 450,000 unique sentence prompts, which we\nuse to explore, identify, and reduce novel forms of bias in several generative\nmodels. We demonstrate that HolisticBias is effective at measuring previously\nundetectable biases in token likelihoods from language models, as well as in an\noffensiveness classifier. We will invite additions and amendments to the\ndataset, which we hope will serve as a basis for more easy-to-use and\nstandardized methods for evaluating bias in NLP models.", "published": "2022-05-18 20:37:25", "link": "http://arxiv.org/abs/2205.09209v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "PromptDA: Label-guided Data Augmentation for Prompt-based Few-shot\n  Learners", "abstract": "Recent advances in large pre-trained language models (PLMs) lead to\nimpressive gains in natural language understanding (NLU) tasks with\ntask-specific fine-tuning. However, directly fine-tuning PLMs heavily relies on\nsufficient labeled training instances, which are usually hard to obtain.\nPrompt-based tuning on PLMs has shown to be powerful for various downstream\nfew-shot tasks. Existing works studying prompt-based tuning for few-shot NLU\ntasks mainly focus on deriving proper label words with a verbalizer or\ngenerating prompt templates to elicit semantics from PLMs. In addition,\nconventional data augmentation strategies such as synonym substitution, though\nwidely adopted in low-resource scenarios, only bring marginal improvements for\nprompt-based few-shot learning. Thus, an important research question arises:\nhow to design effective data augmentation methods for prompt-based few-shot\ntuning? To this end, considering the label semantics are essential in\nprompt-based tuning, we propose a novel label-guided data augmentation\nframework PromptDA, which exploits the enriched label semantic information for\ndata augmentation. Extensive experiment results on few-shot text classification\ntasks demonstrate the superior performance of the proposed framework by\neffectively leveraging label semantics and data augmentation for natural\nlanguage understanding. Our code is available at\nhttps://github.com/canyuchen/PromptDA.", "published": "2022-05-18 22:15:20", "link": "http://arxiv.org/abs/2205.09229v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for\n  Multi-stage Ranking", "abstract": "This paper describes the PASH participation in TREC 2021 Deep Learning Track.\nIn the recall stage, we adopt a scheme combining sparse and dense retrieval\nmethod. In the multi-stage ranking phase, point-wise and pair-wise ranking\nstrategies are used one after another based on model continual pre-trained on\ngeneral knowledge and document-level data. Compared to TREC 2020 Deep Learning\nTrack, we have additionally introduced the generative model T5 to further\nenhance the performance.", "published": "2022-05-18 04:38:15", "link": "http://arxiv.org/abs/2205.11245v4", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Topic Segmentation of Research Article Collections", "abstract": "Collections of research article data harvested from the web have become\ncommon recently since they are important resources for experimenting on tasks\nsuch as named entity recognition, text summarization, or keyword generation. In\nfact, certain types of experiments require collections that are both large and\ntopically structured, with records assigned to separate research disciplines.\nUnfortunately, the current collections of publicly available research articles\nare either small or heterogeneous and unstructured. In this work, we perform\ntopic segmentation of a paper data collection that we crawled and produce a\nmultitopic dataset of roughly seven million paper data records. We construct a\ntaxonomy of topics extracted from the data records and then annotate each\ndocument with its corresponding topic from that taxonomy. As a result, it is\npossible to use this newly proposed dataset in two modalities: as a\nheterogeneous collection of documents from various disciplines or as a set of\nhomogeneous collections, each from a single research topic.", "published": "2022-05-18 15:19:42", "link": "http://arxiv.org/abs/2205.11249v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "The Solvability of Interpretability Evaluation Metrics", "abstract": "Feature attribution methods are popular for explaining neural network\npredictions, and they are often evaluated on metrics such as comprehensiveness\nand sufficiency. In this paper, we highlight an intriguing property of these\nmetrics: their solvability. Concretely, we can define the problem of optimizing\nan explanation for a metric, which can be solved by beam search. This\nobservation leads to the obvious yet unaddressed question: why do we use\nexplainers (e.g., LIME) not based on solving the target metric, if the metric\nvalue represents explanation quality? We present a series of investigations\nshowing strong performance of this beam search explainer and discuss its\nbroader implication: a definition-evaluation duality of interpretability\nconcepts. We implement the explainer and release the Python solvex package for\nmodels of text, image and tabular domains.", "published": "2022-05-18 02:52:03", "link": "http://arxiv.org/abs/2205.08696v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Graph Adaptive Semantic Transfer for Cross-domain Sentiment\n  Classification", "abstract": "Cross-domain sentiment classification (CDSC) aims to use the transferable\nsemantics learned from the source domain to predict the sentiment of reviews in\nthe unlabeled target domain. Existing studies in this task attach more\nattention to the sequence modeling of sentences while largely ignoring the rich\ndomain-invariant semantics embedded in graph structures (i.e., the\npart-of-speech tags and dependency relations). As an important aspect of\nexploring characteristics of language comprehension, adaptive graph\nrepresentations have played an essential role in recent years. To this end, in\nthe paper, we aim to explore the possibility of learning invariant semantic\nfeatures from graph-like structures in CDSC. Specifically, we present Graph\nAdaptive Semantic Transfer (GAST) model, an adaptive syntactic graph embedding\nmethod that is able to learn domain-invariant semantics from both word\nsequences and syntactic graphs. More specifically, we first raise a\nPOS-Transformer module to extract sequential semantic features from the word\nsequences as well as the part-of-speech tags. Then, we design a Hybrid Graph\nAttention (HGAT) module to generate syntax-based semantic features by\nconsidering the transferable dependency relations. Finally, we devise an\nIntegrated aDaptive Strategy (IDS) to guide the joint learning process of both\nmodules. Extensive experiments on four public datasets indicate that GAST\nachieves comparable effectiveness to a range of state-of-the-art models.", "published": "2022-05-18 07:47:01", "link": "http://arxiv.org/abs/2205.08772v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Entity Alignment with Reliable Path Reasoning and Relation-Aware\n  Heterogeneous Graph Transformer", "abstract": "Entity Alignment (EA) has attracted widespread attention in both academia and\nindustry, which aims to seek entities with same meanings from different\nKnowledge Graphs (KGs). There are substantial multi-step relation paths between\nentities in KGs, indicating the semantic relations of entities. However,\nexisting methods rarely consider path information because not all natural paths\nfacilitate for EA judgment. In this paper, we propose a more effective entity\nalignment framework, RPR-RHGT, which integrates relation and path structure\ninformation, as well as the heterogeneous information in KGs. Impressively, an\ninitial reliable path reasoning algorithm is developed to generate the paths\nfavorable for EA task from the relation structures of KGs, which is the first\nalgorithm in the literature to successfully use unrestricted path information.\nIn addition, to efficiently capture heterogeneous features in entity\nneighborhoods, a relation-aware heterogeneous graph transformer is designed to\nmodel the relation and path structures of KGs. Extensive experiments on three\nwell-known datasets show RPR-RHGT significantly outperforms 11 state-of-the-art\nmethods, exceeding the best performing baseline up to 8.62% on Hits@1. We also\nshow its better performance than the baselines on different ratios of training\nset, and harder datasets.", "published": "2022-05-18 09:12:37", "link": "http://arxiv.org/abs/2205.08806v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Minimising Biasing Word Errors for Contextual ASR with the\n  Tree-Constrained Pointer Generator", "abstract": "Contextual knowledge is essential for reducing speech recognition errors on\nhigh-valued long-tail words. This paper proposes a novel tree-constrained\npointer generator (TCPGen) component that enables end-to-end ASR models to bias\ntowards a list of long-tail words obtained using external contextual\ninformation. With only a small overhead in memory use and computation cost,\nTCPGen can structure thousands of biasing words efficiently into a symbolic\nprefix-tree and creates a neural shortcut between the tree and the final ASR\noutput to facilitate the recognition of the biasing words. To enhance TCPGen,\nwe further propose a novel minimum biasing word error (MBWE) loss that directly\noptimises biasing word errors during training, along with a biasing-word-driven\nlanguage model discounting (BLMD) method during the test. All contextual ASR\nsystems were evaluated on the public Librispeech audiobook corpus and the data\nfrom the dialogue state tracking challenges (DSTC) with the biasing lists\nextracted from the dialogue-system ontology. Consistent word error rate (WER)\nreductions were achieved with TCPGen, which were particularly significant on\nthe biasing words with around 40\\% relative reductions in the recognition error\nrates. MBWE and BLMD further improved the effectiveness of TCPGen and achieved\nmore significant WER reductions on the biasing words. TCPGen also achieved\nzero-shot learning of words not in the audio training set with large WER\nreductions on the out-of-vocabulary words in the biasing list.", "published": "2022-05-18 16:40:50", "link": "http://arxiv.org/abs/2205.09058v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "DDXPlus: A New Dataset For Automatic Medical Diagnosis", "abstract": "There has been a rapidly growing interest in Automatic Symptom Detection\n(ASD) and Automatic Diagnosis (AD) systems in the machine learning research\nliterature, aiming to assist doctors in telemedicine services. These systems\nare designed to interact with patients, collect evidence about their symptoms\nand relevant antecedents, and possibly make predictions about the underlying\ndiseases. Doctors would review the interactions, including the evidence and the\npredictions, collect if necessary additional information from patients, before\ndeciding on next steps. Despite recent progress in this area, an important\npiece of doctors' interactions with patients is missing in the design of these\nsystems, namely the differential diagnosis. Its absence is largely due to the\nlack of datasets that include such information for models to train on. In this\nwork, we present a large-scale synthetic dataset of roughly 1.3 million\npatients that includes a differential diagnosis, along with the ground truth\npathology, symptoms and antecedents for each patient. Unlike existing datasets\nwhich only contain binary symptoms and antecedents, this dataset also contains\ncategorical and multi-choice symptoms and antecedents useful for efficient data\ncollection. Moreover, some symptoms are organized in a hierarchy, making it\npossible to design systems able to interact with patients in a logical way. As\na proof-of-concept, we extend two existing AD and ASD systems to incorporate\nthe differential diagnosis, and provide empirical evidence that using\ndifferentials as training signals is essential for the efficiency of such\nsystems or for helping doctors better understand the reasoning of those\nsystems.", "published": "2022-05-18 18:03:39", "link": "http://arxiv.org/abs/2205.09148v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Carbon Figures of Merit Knowledge Creation with a Hybrid Solution and\n  Carbon Tables API", "abstract": "Nowadays there are algorithms, methods, and platforms that are being created\nto accelerate the discovery of materials that are able to absorb or adsorb\n$CO_2$ molecules that are in the atmosphere or during the combustion in power\nplants, for instance. In this work an asynchronous REST API is described to\naccelerate the creation of Carbon figures of merit knowledge, called Carbon\nTables, because the knowledge is created from tables in scientific PDF\ndocuments and stored in knowledge graphs. The figures of merit knowledge\ncreation solution uses a hybrid approach, in which heuristics and machine\nlearning are part of. As a result, one can search the knowledge with mature and\nsophisticated cognitive tools, and create more with regards to Carbon figures\nof merit.", "published": "2022-05-18 18:53:07", "link": "http://arxiv.org/abs/2205.09175v1", "categories": ["cs.AI", "cs.CL", "physics.chem-ph"], "primary_category": "cs.AI"}
{"title": "Learning Rate Curriculum", "abstract": "Most curriculum learning methods require an approach to sort the data samples\nby difficulty, which is often cumbersome to perform. In this work, we propose a\nnovel curriculum learning approach termed Learning Rate Curriculum (LeRaC),\nwhich leverages the use of a different learning rate for each layer of a neural\nnetwork to create a data-agnostic curriculum during the initial training\nepochs. More specifically, LeRaC assigns higher learning rates to neural layers\ncloser to the input, gradually decreasing the learning rates as the layers are\nplaced farther away from the input. The learning rates increase at various\npaces during the first training iterations, until they all reach the same\nvalue. From this point on, the neural model is trained as usual. This creates a\nmodel-level curriculum learning strategy that does not require sorting the\nexamples by difficulty and is compatible with any neural network, generating\nhigher performance levels regardless of the architecture. We conduct\ncomprehensive experiments on 12 data sets from the computer vision (CIFAR-10,\nCIFAR-100, Tiny ImageNet, ImageNet-200, Food-101, UTKFace, PASCAL VOC),\nlanguage (BoolQ, QNLI, RTE) and audio (ESC-50, CREMA-D) domains, considering\nvarious convolutional (ResNet-18, Wide-ResNet-50, DenseNet-121, YOLOv5),\nrecurrent (LSTM) and transformer (CvT, BERT, SepTr) architectures. We compare\nour approach with the conventional training regime, as well as with Curriculum\nby Smoothing (CBS), a state-of-the-art data-agnostic curriculum learning\napproach. Unlike CBS, our performance improvements over the standard training\nregime are consistent across all data sets and models. Furthermore, we\nsignificantly surpass CBS in terms of training time (there is no additional\ncost over the standard training regime for LeRaC). Our code is freely available\nat: https://github.com/CroitoruAlin/LeRaC.", "published": "2022-05-18 18:57:36", "link": "http://arxiv.org/abs/2205.09180v4", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On the Limits of Evaluating Embodied Agent Model Generalization Using\n  Validation Sets", "abstract": "Natural language guided embodied task completion is a challenging problem\nsince it requires understanding natural language instructions, aligning them\nwith egocentric visual observations, and choosing appropriate actions to\nexecute in the environment to produce desired changes. We experiment with\naugmenting a transformer model for this task with modules that effectively\nutilize a wider field of view and learn to choose whether the next step\nrequires a navigation or manipulation action. We observed that the proposed\nmodules resulted in improved, and in fact state-of-the-art performance on an\nunseen validation set of a popular benchmark dataset, ALFRED. However, our best\nmodel selected using the unseen validation set underperforms on the unseen test\nsplit of ALFRED, indicating that performance on the unseen validation set may\nnot in itself be a sufficient indicator of whether model improvements\ngeneralize to unseen test sets. We highlight this result as we believe it may\nbe a wider phenomenon in machine learning tasks but primarily noticeable only\nin benchmarks that limit evaluations on test splits, and highlights the need to\nmodify benchmark design to better account for variance in model performance.", "published": "2022-05-18 23:52:21", "link": "http://arxiv.org/abs/2205.09249v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.CL"}
{"title": "U-Former: Improving Monaural Speech Enhancement with Multi-head Self and\n  Cross Attention", "abstract": "For supervised speech enhancement, contextual information is important for\naccurate spectral mapping. However, commonly used deep neural networks (DNNs)\nare limited in capturing temporal contexts. To leverage long-term contexts for\ntracking a target speaker, this paper treats the speech enhancement as\nsequence-to-sequence mapping, and propose a novel monaural speech enhancement\nU-net structure based on Transformer, dubbed U-Former. The key idea is to model\nlong-term correlations and dependencies, which are crucial for accurate noisy\nspeech modeling, through the multi-head attention mechanisms. For this purpose,\nU-Former incorporates multi-head attention mechanisms at two levels: 1) a\nmulti-head self-attention module which calculate the attention map along both\ntime- and frequency-axis to generate time and frequency sub-attention maps for\nleveraging global interactions between encoder features, while 2) multi-head\ncross-attention module which are inserted in the skip connections allows a fine\nrecovery in the decoder by filtering out uncorrelated features. Experimental\nresults illustrate that the U-Former obtains consistently better performance\nthan recent models of PESQ, STOI, and SSNR scores.", "published": "2022-05-18 01:33:10", "link": "http://arxiv.org/abs/2205.08681v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "3D Single Source Localization Based on Euclidean Distance Matrices", "abstract": "A popular approach for 3D source localization using multiple microphones is\nthe steered-response power method, where the source position is directly\nestimated by maximizing a function of three continuous position variables.\nInstead of directly estimating the source position, in this paper we propose an\nindirect, distance-based method for 3D source localization. Based on properties\nof Euclidean distance matrices (EDMs), we reformulate the 3D source\nlocalization problem as the minimization of a cost function of a single\nvariable, namely the distance between the source and the reference microphone.\nUsing the known microphone geometry and estimated time-differences of arrival\n(TDOAs) between the microphones, we show how the 3D source position can be\ncomputed based on this variable. In addition, instead of using a single TDOA\nestimate per microphone pair, we propose an extension that enables to select\nthe most appropriate estimate from a set of candidate TDOA estimates, which is\nespecially relevant in reverberant environments with strong early reflections.\nExperimental results for different source and microphone constellations show\nthat the proposed EDM-based method consistently outperforms the\nsteered-response power method, especially when the source is close to the\nmicrophones.", "published": "2022-05-18 14:33:36", "link": "http://arxiv.org/abs/2205.08960v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Coherence-Based Frequency Subset Selection For Binaural RTF-Vector-Based\n  Direction of Arrival Estimation for Multiple Speakers", "abstract": "Recently, a method has been proposed to estimate the direction of arrival\n(DOA) of a single speaker by minimizing the frequency-averaged Hermitian angle\nbetween an estimated relative transfer function (RTF) vector and a database of\nprototype anechoic RTF vectors. In this paper, we extend this method to\nmulti-speaker localization by introducing the frequency-averaged Hermitian\nangle spectrum and selecting peaks of this spatial spectrum. To construct the\nHermitian angle spectrum, we consider only a subset of frequencies, where it is\nlikely that one speaker is dominant. We compare the effectiveness of the\ngeneralized magnitude squared coherence and two coherent-to-diffuse ratio (CDR)\nestimators as frequency selection criteria. Simulation results for estimating\nthe DOAs of two speakers in a reverberant environment with diffuse-like babble\nnoise using binaural hearing devices show that using the binaural\neffective-coherence-based CDR estimate as a frequency selection criterion\nyields the best performance.", "published": "2022-05-18 15:17:01", "link": "http://arxiv.org/abs/2205.08985v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Multi-Frame MVDR Filtering for Binaural Noise Reduction", "abstract": "To improve speech intelligibility and speech quality in noisy environments,\nbinaural noise reduction algorithms for head-mounted assistive listening\ndevices are of crucial importance. Several binaural noise reduction algorithms\nsuch as the well-known binaural minimum variance distortionless response (MVDR)\nbeamformer have been proposed, which exploit spatial correlations of both the\ntarget speech and the noise components. Furthermore, for single-microphone\nscenarios, multi-frame algorithms such as the multi-frame MVDR (MFMVDR) filter\nhave been proposed, which exploit temporal instead of spatial correlations. In\nthis contribution, we propose a binaural extension of the MFMVDR filter, which\nexploits both spatial and temporal correlations. The binaural MFMVDR filters\nare embedded in an end-to-end deep learning framework, where the required\nparameters, i.e., the speech spatio-temporal correlation vectors as well as the\n(inverse) noise spatio-temporal covariance matrix, are estimated by temporal\nconvolutional networks (TCNs) that are trained by minimizing the mean spectral\nabsolute error loss function. Simulation results comprising measured binaural\nroom impulses and diverse noise sources at signal-to-noise ratios from -5 dB to\n20 dB demonstrate the advantage of utilizing the binaural MFMVDR filter\nstructure over directly estimating the binaural multi-frame filter coefficients\nwith TCNs.", "published": "2022-05-18 15:16:36", "link": "http://arxiv.org/abs/2205.08983v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Dictionary-Based Fusion of Contact and Acoustic Microphones for Wind\n  Noise Reduction", "abstract": "In mobile speech communication applications, wind noise can lead to a severe\nreduction of speech quality and intelligibility. Since the performance of\nspeech enhancement algorithms using acoustic microphones tends to substantially\ndegrade in extremely challenging scenarios, auxiliary sensors such as contact\nmicrophones can be used. Although contact microphones offer a much lower\nrecorded wind noise level, they come at the cost of speech distortion and\nadditional noise components. Aiming at exploiting the advantages of acoustic\nand contact microphones for wind noise reduction, in this paper we propose to\nextend conventional single-microphone dictionary-based speech enhancement\napproaches by simultaneously modeling the acoustic and contact microphone\nsignals. We propose to train a single speech dictionary and two noise\ndictionaries and use a relative transfer function to model the relationship\nbetween the speech components at the microphones. Simulation results show that\nthe proposed approach yields improvements in both speech quality and\nintelligibility compared to several baseline approaches, most notably\napproaches using only the contact microphones or only the acoustic microphone.", "published": "2022-05-18 15:53:10", "link": "http://arxiv.org/abs/2205.09017v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Macedonian Speech Synthesis for Assistive Technology Applications", "abstract": "Speech technology is becoming ever more ubiquitous with the advance of speech\nenabled devices and services. The use of speech synthesis in Augmentative and\nAlternative Communication tools, has facilitated inclusion of individuals with\nspeech impediments allowing them to communicate with their surroundings using\nspeech. Although there are numerous speech synthesis systems for the most\nspoken world languages, there is still a limited offer for smaller languages.\nWe propose and compare three models built using parametric and deep learning\ntechniques for Macedonian trained on a newly recorded corpus. We target\nlow-resource edge deployment for Augmentative and Alternative Communication and\nassistive technologies, such as communication boards and screen readers. The\nlistening test results show that parametric speech synthesis is as performant\ncompared to the more advanced deep learning models. Since it also requires less\nresources, and offers full speech rate and pitch control, it is the preferred\nchoice for building a Macedonian TTS system for this application scenario.", "published": "2022-05-18 20:16:49", "link": "http://arxiv.org/abs/2205.09198v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Seeing Sounds, Hearing Shapes: a gamified study to evaluate\n  sound-sketches", "abstract": "Sound-shape associations, a subset of cross-modal associations between the\nauditory and visual domain, have been studied mainly in the context of matching\na set of purposefully crafted shapes to sounds. Recent studies have explored\nhow humans represent sound through free-form sketching and how a graphical\nsketch input could be used for sound production. In this paper, the potential\nof communicating sound characteristics through these free-form sketches is\ninvestigated in a gamified study that was conducted with eighty-two\nparticipants at two online exhibition events. The results show that\nparticipants managed to recognise sounds at a higher rate than the random\nbaseline would suggest, however it appeared difficult to visually encode\nnuanced timbral differences.", "published": "2022-05-18 11:28:00", "link": "http://arxiv.org/abs/2205.08866v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D\n  Scenes", "abstract": "We propose a mesh-based neural network (MESH2IR) to generate acoustic impulse\nresponses (IRs) for indoor 3D scenes represented using a mesh. The IRs are used\nto create a high-quality sound experience in interactive applications and audio\nprocessing. Our method can handle input triangular meshes with arbitrary\ntopologies (2K - 3M triangles). We present a novel training technique to train\nMESH2IR using energy decay relief and highlight its benefits. We also show that\ntraining MESH2IR on IRs preprocessed using our proposed technique significantly\nimproves the accuracy of IR generation. We reduce the non-linearity in the mesh\nspace by transforming 3D scene meshes to latent space using a graph convolution\nnetwork. Our MESH2IR is more than 200 times faster than a geometric acoustic\nalgorithm on a CPU and can generate more than 10,000 IRs per second on an\nNVIDIA GeForce RTX 2080 Ti GPU for a given furnished indoor 3D scene. The\nacoustic metrics are used to characterize the acoustic environment. We show\nthat the acoustic metrics of the IRs predicted from our MESH2IR match the\nground truth with less than 10% error. We also highlight the benefits of\nMESH2IR on audio and speech processing applications such as speech\ndereverberation and speech separation. To the best of our knowledge, ours is\nthe first neural-network-based approach to predict IRs from a given 3D scene\nmesh in real-time.", "published": "2022-05-18 23:50:34", "link": "http://arxiv.org/abs/2205.09248v2", "categories": ["cs.SD", "cs.CV", "cs.GR", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
