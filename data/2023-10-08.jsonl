{"title": "Domain Knowledge Graph Construction Via A Simple Checker", "abstract": "With the availability of large language models, there is a growing interest\nfor semiconductor chip design companies to leverage the technologies. For those\ncompanies, deployment of a new methodology must include two important\nconsiderations: confidentiality and scalability. In this context, this work\ntackles the problem of knowledge graph construction from hardware-design domain\ntexts. We propose an oracle-checker scheme to leverage the power of GPT3.5 and\ndemonstrate that the essence of the problem is in distillation of domain\nexpert's background knowledge. Using RISC-V unprivileged ISA specification as\nan example, we explain key ideas and discuss practicality of our proposed\noracle-checker approach.", "published": "2023-10-08 00:09:31", "link": "http://arxiv.org/abs/2310.04949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Better Chain-of-Thought Prompting Strategies: A Survey", "abstract": "Chain-of-Thought (CoT), a step-wise and coherent reasoning chain, shows its\nimpressive strength when used as a prompting strategy for large language models\n(LLM). Recent years, the prominent effect of CoT prompting has attracted\nemerging research. However, there still lacks of a systematic summary about key\nfactors of CoT prompting and comprehensive guide for prompts utilizing. For a\ndeeper understanding about CoT prompting, we survey on a wide range of current\nresearch, presenting a systematic and comprehensive analysis on several factors\nthat may influence the effect of CoT prompting, and introduce how to better\napply it in different applications under these discussions. We further analyze\nthe challenges and propose some future directions about CoT prompting. This\nsurvey could provide an overall reference on related research.", "published": "2023-10-08 01:16:55", "link": "http://arxiv.org/abs/2310.04959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Usage of Chinese Pinyin in Pretraining", "abstract": "Unlike alphabetic languages, Chinese spelling and pronunciation are\ndifferent. Both characters and pinyin take an important role in Chinese\nlanguage understanding. In Chinese NLP tasks, we almost adopt characters or\nwords as model input, and few works study how to use pinyin. However, pinyin is\nessential in many scenarios, such as error correction and fault tolerance for\nASR-introduced errors. Most of these errors are caused by the same or similar\npronunciation words, and we refer to this type of error as SSP(the same or\nsimilar pronunciation) errors for short. In this work, we explore various ways\nof using pinyin in pretraining models and propose a new pretraining method\ncalled PmBERT. Our method uses characters and pinyin in parallel for\npretraining. Through delicate pretraining tasks, the characters and pinyin\nrepresentation are fused, which can enhance the error tolerance for SSP errors.\nWe do comprehensive experiments and ablation tests to explore what makes a\nrobust phonetic enhanced Chinese language model. The experimental results on\nboth the constructed noise-added dataset and the public error-correction\ndataset demonstrate that our model is more robust compared to SOTA models.", "published": "2023-10-08 01:26:44", "link": "http://arxiv.org/abs/2310.04960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models", "abstract": "Large language models (LLMs) have shown superior performance without\ntask-specific fine-tuning. Despite the success, the knowledge stored in the\nparameters of LLMs could still be incomplete and difficult to update due to the\ncomputational costs. As complementary, retrieval-based methods can offer\nnon-parametric world knowledge and improve the performance on tasks such as\nquestion answering. However, we find that the retrieved knowledge does not\nalways help and even has a negative impact on original responses occasionally.\nTo better make use of both internal knowledge and external world knowledge, we\ninvestigate eliciting the model's ability to recognize what they know and do\nnot know (which is also called self-knowledge) and propose Self-Knowledge\nguided Retrieval augmentation (SKR), a simple yet effective method which can\nlet LLMs refer to the questions they have previously encountered and adaptively\ncall for external resources when dealing with new questions. We evaluate SKR on\nmultiple datasets and demonstrate that it outperforms chain-of-thought based\nand fully retrieval-based methods by using either InstructGPT or ChatGPT.", "published": "2023-10-08 04:22:33", "link": "http://arxiv.org/abs/2310.05002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot\n  Question Answering", "abstract": "Recent advances in few-shot question answering (QA) mostly rely on the power\nof pre-trained large language models (LLMs) and fine-tuning in specific\nsettings. Although the pre-training stage has already equipped LLMs with\npowerful reasoning capabilities, LLMs still need to be fine-tuned to adapt to\nspecific domains to achieve the best results. In this paper, we propose to\nselect the most informative data for fine-tuning, thereby improving the\nefficiency of the fine-tuning process with comparative or even better accuracy\non the open-domain QA task. We present MinPrompt, a minimal data augmentation\nframework for open-domain QA based on an approximate graph algorithm and\nunsupervised question generation. We transform the raw text into a graph\nstructure to build connections between different factual sentences, then apply\ngraph algorithms to identify the minimal set of sentences needed to cover the\nmost information in the raw text. We then generate QA pairs based on the\nidentified sentence subset and train the model on the selected sentences to\nobtain the final model. Empirical results on several benchmark datasets and\ntheoretical analysis show that MinPrompt is able to achieve comparable or\nbetter results than baselines with a high degree of efficiency, bringing\nconsistent improvements in F-1 scores.", "published": "2023-10-08 04:44:36", "link": "http://arxiv.org/abs/2310.05007v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiIns: A High-Quality Dataset for Controlled Text Editing by Natural\n  Language Instruction", "abstract": "Text editing, i.e., the process of modifying or manipulating text, is a\ncrucial step in human writing process. In this paper, we study the problem of\ncontrolled text editing by natural language instruction. According to a given\ninstruction that conveys the edit intention and necessary information, an\noriginal draft text is required to be revised into a target text. Existing\nautomatically constructed datasets for this task are limited because they do\nnot have informative natural language instruction. The informativeness requires\nthe information contained in the instruction to be enough to produce the\nrevised text. To address this limitation, we build and release WikiIns, a\nhigh-quality controlled text editing dataset with improved informativeness. We\nfirst preprocess the Wikipedia edit history database to extract the raw data\n(WikiIns-Raw). Then we crowdsource high-quality validation and test sets, as\nwell as a small-scale training set (WikiIns-Gold). With the high-quality\nannotated dataset, we further propose automatic approaches to generate a\nlarge-scale ``silver'' training set (WikiIns-Silver). Finally, we provide some\ninsightful analysis on our WikiIns dataset, including the evaluation results\nand the edit intention analysis. Our analysis and the experiment results on\nWikiIns may assist the ongoing research on text editing. The dataset, source\ncode and annotation guideline are available at\nhttps://github.com/CasparSwift/WikiIns.", "published": "2023-10-08 04:46:39", "link": "http://arxiv.org/abs/2310.05009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synslator: An Interactive Machine Translation Tool with Online Learning", "abstract": "Interactive machine translation (IMT) has emerged as a progression of the\ncomputer-aided translation paradigm, where the machine translation system and\nthe human translator collaborate to produce high-quality translations. This\npaper introduces Synslator, a user-friendly computer-aided translation (CAT)\ntool that not only supports IMT, but is adept at online learning with real-time\ntranslation memories. To accommodate various deployment environments for CAT\nservices, Synslator integrates two different neural translation models to\nhandle translation memories for online learning. Additionally, the system\nemploys a language model to enhance the fluency of translations in an\ninteractive mode. In evaluation, we have confirmed the effectiveness of online\nlearning through the translation models, and have observed a 13% increase in\npost-editing efficiency with the interactive functionalities of Synslator. A\ntutorial video is available at:https://youtu.be/K0vRsb2lTt8.", "published": "2023-10-08 06:05:55", "link": "http://arxiv.org/abs/2310.05025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Walking Down the Memory Maze: Beyond Context Limit through Interactive\n  Reading", "abstract": "Large language models (LLMs) have advanced in large strides due to the\neffectiveness of the self-attention mechanism that processes and compares all\ntokens at once. However, this mechanism comes with a fundamental issue -- the\npredetermined context window is bound to be limited. Despite attempts to extend\nthe context window through methods like extrapolating the positional embedding,\nusing recurrence, or selectively retrieving essential parts of the long\nsequence, long-text understanding continues to be a challenge. We propose an\nalternative approach which instead treats the LLM as an interactive agent,\nallowing it to decide how to read the text via iterative prompting. We\nintroduce MemWalker, a method that first processes the long context into a tree\nof summary nodes. Upon receiving a query, the model navigates this tree in\nsearch of relevant information, and responds once it gathers sufficient\ninformation. On long-text question answering tasks our method outperforms\nbaseline approaches that use long context windows, recurrence, and retrieval.\nWe show that, beyond effective reading, MemWalker enhances explainability by\nhighlighting the reasoning steps as it interactively reads the text;\npinpointing the relevant text segments related to the query.", "published": "2023-10-08 06:18:14", "link": "http://arxiv.org/abs/2310.05029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FakeGPT: Fake News Generation, Explanation and Detection of Large\n  Language Models", "abstract": "The rampant spread of fake news has adversely affected society, resulting in\nextensive research on curbing its spread. As a notable milestone in large\nlanguage models (LLMs), ChatGPT has gained significant attention due to its\nexceptional natural language processing capabilities. In this study, we present\na thorough exploration of ChatGPT's proficiency in generating, explaining, and\ndetecting fake news as follows. Generation -- We employ four prompt methods to\ngenerate fake news samples and prove the high quality of these samples through\nboth self-assessment and human evaluation. Explanation -- We obtain nine\nfeatures to characterize fake news based on ChatGPT's explanations and analyze\nthe distribution of these factors across multiple public datasets. Detection --\nWe examine ChatGPT's capacity to identify fake news. We explore its detection\nconsistency and then propose a reason-aware prompt method to improve its\nperformance. Although our experiments demonstrate that ChatGPT shows\ncommendable performance in detecting fake news, there is still room for its\nimprovement. Consequently, we further probe into the potential extra\ninformation that could bolster its effectiveness in detecting fake news.", "published": "2023-10-08 07:01:07", "link": "http://arxiv.org/abs/2310.05046v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BRAINTEASER: Lateral Thinking Puzzles for Large Language Models", "abstract": "The success of language models has inspired the NLP community to attend to\ntasks that require implicit and complex reasoning, relying on human-like\ncommonsense mechanisms. While such vertical thinking tasks have been relatively\npopular, lateral thinking puzzles have received little attention. To bridge\nthis gap, we devise BRAINTEASER: a multiple-choice Question Answering task\ndesigned to test the model's ability to exhibit lateral thinking and defy\ndefault commonsense associations. We design a three-step procedure for creating\nthe first lateral thinking benchmark, consisting of data collection, distractor\ngeneration, and generation of adversarial examples, leading to 1,100 puzzles\nwith high-quality annotations. To assess the consistency of lateral reasoning\nby models, we enrich BRAINTEASER based on a semantic and contextual\nreconstruction of its questions. Our experiments with state-of-the-art\ninstruction- and commonsense language models reveal a significant gap between\nhuman and model performance, which is further widened when consistency across\nadversarial formats is considered. We make all of our code and data available\nto stimulate work on developing and evaluating lateral thinking models.", "published": "2023-10-08 07:46:01", "link": "http://arxiv.org/abs/2310.05057v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "sign.mt: Real-Time Multilingual Sign Language Translation Application", "abstract": "This demo paper presents sign.mt, an open-source application pioneering\nreal-time multilingual bi-directional translation between spoken and signed\nlanguages. Harnessing state-of-the-art open-source models, this tool aims to\naddress the communication divide between the hearing and the deaf, facilitating\nseamless translation in both spoken-to-signed and signed-to-spoken translation\ndirections.\n  Promising reliable and unrestricted communication, sign.mt offers offline\nfunctionality, crucial in areas with limited internet connectivity. It further\nenhances user engagement by offering customizable photo-realistic sign language\navatars, thereby encouraging a more personalized and authentic user experience.\n  Licensed under CC BY-NC-SA 4.0, sign.mt signifies an important stride towards\nopen, inclusive communication. The app can be used, and modified for personal\nand academic uses, and even supports a translation API, fostering integration\ninto a wider range of applications. However, it is by no means a finished\nproduct.\n  We invite the NLP community to contribute towards the evolution of sign.mt.\nWhether it be the integration of more refined models, the development of\ninnovative pipelines, or user experience improvements, your contributions can\npropel this project to new heights. Available at https://sign.mt, it stands as\na testament to what we can achieve together, as we strive to make communication\naccessible to all.", "published": "2023-10-08 08:14:03", "link": "http://arxiv.org/abs/2310.05064v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot\n  Performance via Probability Calibration", "abstract": "Pretrained multilingual encoder models can directly perform zero-shot\nmultilingual tasks or linguistic probing by reformulating the input examples\ninto cloze-style prompts. This is accomplished by predicting the probabilities\nof the label words at the masked token position, without requiring any updates\nto the model parameters. However, the performance of this method is limited by\nthe model's bias toward predicting label words which frequently occurred during\nthe pretraining. These words typically receive high probabilities. To address\nthis issue, we combine the models with calibration techniques which modify the\nprobabilities of label words predicted by the models. We first validate the\neffectiveness of a proposed simple calibration method together with other\nexisting techniques on monolingual encoders in both zero- and few-shot\nscenarios. We subsequently employ these calibration techniques on multilingual\nencoders, resulting in substantial performance improvements across a wide range\nof tasks.", "published": "2023-10-08 08:31:05", "link": "http://arxiv.org/abs/2310.05069v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Argument Structure Extraction with Efficient Leverage of\n  Contextual Information", "abstract": "Argument structure extraction (ASE) aims to identify the discourse structure\nof arguments within documents. Previous research has demonstrated that\ncontextual information is crucial for developing an effective ASE model.\nHowever, we observe that merely concatenating sentences in a contextual window\ndoes not fully utilize contextual information and can sometimes lead to\nexcessive attention on less informative sentences. To tackle this challenge, we\npropose an Efficient Context-aware ASE model (ECASE) that fully exploits\ncontextual information by enhancing modeling capacity and augmenting training\ndata. Specifically, we introduce a sequence-attention module and\ndistance-weighted similarity loss to aggregate contextual information and\nargumentative information. Additionally, we augment the training data by\nrandomly masking discourse markers and sentences, which reduces the model's\nreliance on specific words or less informative sentences. Our experiments on\nfive datasets from various domains demonstrate that our model achieves\nstate-of-the-art performance. Furthermore, ablation studies confirm the\neffectiveness of each module in our model.", "published": "2023-10-08 08:47:10", "link": "http://arxiv.org/abs/2310.05073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Language Models with Augmented Instructions for\n  Fine-grained Information Extraction", "abstract": "Information Extraction (IE) is an essential task in Natural Language\nProcessing. Traditional methods have relied on coarse-grained extraction with\nsimple instructions. However, with the emergence of Large Language Models\n(LLMs), there is a need to adapt IE techniques to leverage the capabilities of\nthese models. This paper introduces a fine-grained IE benchmark dataset\ntailored for LLMs, employing augmented instructions for each information type,\nwhich includes task descriptions, extraction rules, output formats, and\nexamples. Through extensive evaluations, we observe that encoder-decoder\nmodels, particularly T5 and FLAN-T5, perform well in generalizing to unseen\ninformation types, while ChatGPT exhibits greater adaptability to new task\nforms. Our results also indicate that performance is not solely dictated by\nmodel scale, and highlight the significance of architecture, data diversity,\nand learning techniques. This work paves the way for a more refined and\nversatile utilization of LLMs in Information Extraction.", "published": "2023-10-08 09:41:18", "link": "http://arxiv.org/abs/2310.05092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text\n  via Conditional Probability Curvature", "abstract": "Large language models (LLMs) have shown the ability to produce fluent and\ncogent content, presenting both productivity opportunities and societal risks.\nTo build trustworthy AI systems, it is imperative to distinguish between\nmachine-generated and human-authored content. The leading zero-shot detector,\nDetectGPT, showcases commendable performance but is marred by its intensive\ncomputational costs. In this paper, we introduce the concept of conditional\nprobability curvature to elucidate discrepancies in word choices between LLMs\nand humans within a given context. Utilizing this curvature as a foundational\nmetric, we present **Fast-DetectGPT**, an optimized zero-shot detector, which\nsubstitutes DetectGPT's perturbation step with a more efficient sampling step.\nOur evaluations on various datasets, source models, and test conditions\nindicate that Fast-DetectGPT not only surpasses DetectGPT by a relative around\n75% in both the white-box and black-box settings but also accelerates the\ndetection process by a factor of 340, as detailed in Table 1. See\n\\url{https://github.com/baoguangsheng/fast-detect-gpt} for code, data, and\nresults.", "published": "2023-10-08 11:41:28", "link": "http://arxiv.org/abs/2310.05130v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Generation Synergy Augmented Large Language Models", "abstract": "Large language models augmented with task-relevant documents have\ndemonstrated impressive performance on knowledge-intensive tasks. However,\nregarding how to obtain effective documents, the existing methods are mainly\ndivided into two categories. One is to retrieve from an external knowledge\nbase, and the other is to utilize large language models to generate documents.\nWe propose an iterative retrieval-generation collaborative framework. It is not\nonly able to leverage both parametric and non-parametric knowledge, but also\nhelps to find the correct reasoning path through retrieval-generation\ninteractions, which is very important for tasks that require multi-step\nreasoning. We conduct experiments on four question answering datasets,\nincluding single-hop QA and multi-hop QA tasks. Empirical results show that our\nmethod significantly improves the reasoning ability of large language models\nand outperforms previous baselines.", "published": "2023-10-08 12:50:57", "link": "http://arxiv.org/abs/2310.05149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Investigation of LLMs' Inefficacy in Understanding Converse Relations", "abstract": "Large Language Models (LLMs) have achieved remarkable success in many formal\nlanguage oriented tasks, such as structural data-to-text and semantic parsing.\nHowever current benchmarks mostly follow the data distribution of the\npre-training data of LLMs. Therefore, a natural question rises that do LLMs\nreally understand the structured semantics of formal languages. In this paper,\nwe investigate this problem on a special case, converse binary relation. We\nintroduce a new benchmark ConvRe focusing on converse relations, which contains\n17 relations and 1240 triples extracted from popular knowledge graph completion\ndatasets. Our ConvRE features two tasks, Re2Text and Text2Re, which are\nformulated as multi-choice question answering to evaluate LLMs' ability to\ndetermine the matching between relations and associated text. For the\nevaluation protocol, apart from different prompting methods, we further\nintroduce variants to the test text and few-shot example text. We conduct\nexperiments on three popular LLM families and have observed various scaling\ntrends. The results suggest that LLMs often resort to shortcut learning and\nstill face challenges on our proposed benchmark.", "published": "2023-10-08 13:45:05", "link": "http://arxiv.org/abs/2310.05163v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Zero-Shot Generalization of Machine-Generated Text Detectors", "abstract": "The rampant proliferation of large language models, fluent enough to generate\ntext indistinguishable from human-written language, gives unprecedented\nimportance to the detection of machine-generated text. This work is motivated\nby an important research question: How will the detectors of machine-generated\ntext perform on outputs of a new generator, that the detectors were not trained\non? We begin by collecting generation data from a wide range of LLMs, and train\nneural detectors on data from each generator and test its performance on\nheld-out generators. While none of the detectors can generalize to all\ngenerators, we observe a consistent and interesting pattern that the detectors\ntrained on data from a medium-size LLM can zero-shot generalize to the larger\nversion. As a concrete application, we demonstrate that robust detectors can be\nbuilt on an ensemble of training data from medium-sized models.", "published": "2023-10-08 13:49:51", "link": "http://arxiv.org/abs/2310.05165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Know about Facts?", "abstract": "Large language models (LLMs) have recently driven striking performance\nimprovements across a range of natural language processing tasks. The factual\nknowledge acquired during pretraining and instruction tuning can be useful in\nvarious downstream tasks, such as question answering, and language generation.\nUnlike conventional Knowledge Bases (KBs) that explicitly store factual\nknowledge, LLMs implicitly store facts in their parameters. Content generated\nby the LLMs can often exhibit inaccuracies or deviations from the truth, due to\nfacts that can be incorrectly induced or become obsolete over time. To this\nend, we aim to comprehensively evaluate the extent and scope of factual\nknowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains\n20K diverse factual questions that span different sources, timelines, domains,\nregions, and languages. Furthermore, we investigate whether LLMs are able to\ncompose multiple facts, update factual knowledge temporally, reason over\nmultiple pieces of facts, identify subtle factual differences, and resist\nadversarial examples. Extensive experiments on different sizes and types of\nLLMs show that existing LLMs still lack factual knowledge and suffer from\nvarious spurious correlations. We believe this is a critical bottleneck for\nrealizing trustworthy artificial intelligence. The dataset Pinocchio and our\ncodes will be publicly available.", "published": "2023-10-08 14:26:55", "link": "http://arxiv.org/abs/2310.05177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-as-a-tutor in EFL Writing Education: Focusing on Evaluation of\n  Student-LLM Interaction", "abstract": "In the context of English as a Foreign Language (EFL) writing education,\nLLM-as-a-tutor can assist students by providing real-time feedback on their\nessays. However, challenges arise in assessing LLM-as-a-tutor due to differing\nstandards between educational and general use cases. To bridge this gap, we\nintegrate pedagogical principles to assess student-LLM interaction. First, we\nexplore how LLMs can function as English tutors, providing effective essay\nfeedback tailored to students. Second, we propose three metrics to evaluate\nLLM-as-a-tutor specifically designed for EFL writing education, emphasizing\npedagogical aspects. In this process, EFL experts evaluate the feedback from\nLLM-as-a-tutor regarding quality and characteristics. On the other hand, EFL\nlearners assess their learning outcomes from interaction with LLM-as-a-tutor.\nThis approach lays the groundwork for developing LLMs-as-a-tutor tailored to\nthe needs of EFL learners, advancing the effectiveness of writing education in\nthis context.", "published": "2023-10-08 15:00:04", "link": "http://arxiv.org/abs/2310.05191v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning\n  from Human Feedback", "abstract": "Reinforcement learning from human feedback serves as a crucial bridge,\naligning large language models with human and societal values. This alignment\nrequires a vast corpus of human feedback to learn a reward model, which is\nsubsequently used to finetune language models. However, we have identified that\nthe reward model often finds shortcuts to bypass its intended objectives,\nmisleadingly assuming that humans prefer longer responses. The emergence of\nlength bias often induces the model to favor longer outputs, yet it doesn't\nequate to an increase in helpful information within these outputs. In this\npaper, we propose an innovative solution, applying the Product-of-Experts (PoE)\ntechnique to separate reward modeling from the influence of sequence length. In\nour framework, the main expert concentrates on understanding human intents,\nwhile the biased expert targets the identification and capture of length bias.\nTo further enhance the learning of bias, we introduce perturbations into the\nbias-focused expert, disrupting the flow of semantic information. Experimental\nresults validate the effectiveness of our approach, indicating that language\nmodel performance is improved, irrespective of sequence length.", "published": "2023-10-08 15:14:39", "link": "http://arxiv.org/abs/2310.05199v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Large Language Models from A Human Behavioral Perspective", "abstract": "Large Language Models (LLMs) have emerged as dominant foundational models in\nmodern NLP. However, the understanding of their prediction processes and\ninternal mechanisms, such as feed-forward networks (FFN) and multi-head\nself-attention (MHSA), remains largely unexplored. In this work, we probe LLMs\nfrom a human behavioral perspective, correlating values from LLMs with\neye-tracking measures, which are widely recognized as meaningful indicators of\nhuman reading patterns. Our findings reveal that LLMs exhibit a similar\nprediction pattern with humans but distinct from that of Shallow Language\nModels (SLMs). Moreover, with the escalation of LLM layers from the middle\nlayers, the correlation coefficients also increase in FFN and MHSA, indicating\nthat the logits within FFN increasingly encapsulate word semantics suitable for\npredicting tokens from the vocabulary.", "published": "2023-10-08 16:16:21", "link": "http://arxiv.org/abs/2310.05216v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Pre-Trained Language Models with Sentence Position Embeddings\n  for Rhetorical Roles Recognition in Legal Opinions", "abstract": "The legal domain is a vast and complex field that involves a considerable\namount of text analysis, including laws, legal arguments, and legal opinions.\nLegal practitioners must analyze these texts to understand legal cases,\nresearch legal precedents, and prepare legal documents. The size of legal\nopinions continues to grow, making it increasingly challenging to develop a\nmodel that can accurately predict the rhetorical roles of legal opinions given\ntheir complexity and diversity. In this research paper, we propose a novel\nmodel architecture for automatically predicting rhetorical roles using\npre-trained language models (PLMs) enhanced with knowledge of sentence position\ninformation within a document. Based on an annotated corpus from the\nLegalEval@SemEval2023 competition, we demonstrate that our approach requires\nfewer parameters, resulting in lower computational costs when compared to\ncomplex architectures employing a hierarchical model in a global-context, yet\nit achieves great performance. Moreover, we show that adding more attention to\na hierarchical model based only on BERT in the local-context, along with\nincorporating sentence position information, enhances the results.", "published": "2023-10-08 20:33:55", "link": "http://arxiv.org/abs/2310.05276v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation\n  with the GeNTE Corpus", "abstract": "Gender inequality is embedded in our communication practices and perpetuated\nin translation technologies. This becomes particularly apparent when\ntranslating into grammatical gender languages, where machine translation (MT)\noften defaults to masculine and stereotypical representations by making undue\nbinary gender assumptions. Our work addresses the rising demand for inclusive\nlanguage by focusing head-on on gender-neutral translation from English to\nItalian. We start from the essentials: proposing a dedicated benchmark and\nexploring automated evaluation methods. First, we introduce GeNTE, a natural,\nbilingual test set for gender-neutral translation, whose creation was informed\nby a survey on the perception and use of neutral language. Based on GeNTE, we\nthen overview existing reference-based evaluation approaches, highlight their\nlimits, and propose a reference-free method more suitable to assess\ngender-neutral translation.", "published": "2023-10-08 21:44:00", "link": "http://arxiv.org/abs/2310.05294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Storytelling with Question-Answer Plans", "abstract": "Visual storytelling aims to generate compelling narratives from image\nsequences. Existing models often focus on enhancing the representation of the\nimage sequence, e.g., with external knowledge sources or advanced graph\nstructures. Despite recent progress, the stories are often repetitive,\nillogical, and lacking in detail. To mitigate these issues, we present a novel\nframework which integrates visual representations with pretrained language\nmodels and planning. Our model translates the image sequence into a visual\nprefix, a sequence of continuous embeddings which language models can\ninterpret. It also leverages a sequence of question-answer pairs as a blueprint\nplan for selecting salient visual concepts and determining how they should be\nassembled into a narrative. Automatic and human evaluation on the VIST\nbenchmark (Huang et al., 2016) demonstrates that blueprint-based models\ngenerate stories that are more coherent, interesting, and natural compared to\ncompetitive baselines and state-of-the-art systems.", "published": "2023-10-08 21:45:34", "link": "http://arxiv.org/abs/2310.05295v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Document-level Event Argument Extraction with Contextual Clues\n  and Role Relevance", "abstract": "Document-level event argument extraction poses new challenges of long input\nand cross-sentence inference compared to its sentence-level counterpart.\nHowever, most prior works focus on capturing the relations between candidate\narguments and the event trigger in each event, ignoring two crucial points: a)\nnon-argument contextual clue information; b) the relevance among argument\nroles. In this paper, we propose a SCPRG (Span-trigger-based Contextual Pooling\nand latent Role Guidance) model, which contains two novel and effective modules\nfor the above problem. The Span-Trigger-based Contextual Pooling(STCP)\nadaptively selects and aggregates the information of non-argument clue words\nbased on the context attention weights of specific argument-trigger pairs from\npre-trained model. The Role-based Latent Information Guidance (RLIG) module\nconstructs latent role representations, makes them interact through\nrole-interactive encoding to capture semantic relevance, and merges them into\ncandidate arguments. Both STCP and RLIG introduce no more than 1% new\nparameters compared with the base model and can be easily applied to other\nevent extraction models, which are compact and transplantable. Experiments on\ntwo public datasets show that our SCPRG outperforms previous state-of-the-art\nmethods, with 1.13 F1 and 2.64 F1 improvements on RAMS and WikiEvents\nrespectively. Further analyses illustrate the interpretability of our model.", "published": "2023-10-08 11:29:10", "link": "http://arxiv.org/abs/2310.05991v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series\n  Forecasting", "abstract": "The past decade has witnessed significant advances in time series modeling\nwith deep learning. While achieving state-of-the-art results, the\nbest-performing architectures vary highly across applications and domains.\nMeanwhile, for natural language processing, the Generative Pre-trained\nTransformer (GPT) has demonstrated impressive performance via training one\ngeneral-purpose model across various textual datasets. It is intriguing to\nexplore whether GPT-type architectures can be effective for time series,\ncapturing the intrinsic dynamic attributes and leading to significant accuracy\nimprovements. In this paper, we propose a novel framework, TEMPO, that can\neffectively learn time series representations. We focus on utilizing two\nessential inductive biases of the time series task for pre-trained models: (i)\ndecomposition of the complex interaction between trend, seasonal and residual\ncomponents; and (ii) introducing the design of prompts to facilitate\ndistribution adaptation in different types of time series. TEMPO expands the\ncapability for dynamically modeling real-world temporal phenomena from data\nwithin diverse domains. Our experiments demonstrate the superior performance of\nTEMPO over state-of-the-art methods on zero shot setting for a number of time\nseries benchmark datasets. This performance gain is observed not only in\nscenarios involving previously unseen datasets but also in scenarios with\nmulti-modal inputs. This compelling finding highlights TEMPO's potential to\nconstitute a foundational model-building framework.", "published": "2023-10-08 00:02:25", "link": "http://arxiv.org/abs/2310.04948v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TopicAdapt- An Inter-Corpora Topics Adaptation Approach", "abstract": "Topic models are popular statistical tools for detecting latent semantic\ntopics in a text corpus. They have been utilized in various applications across\ndifferent fields. However, traditional topic models have some limitations,\nincluding insensitivity to user guidance, sensitivity to the amount and quality\nof data, and the inability to adapt learned topics from one corpus to another.\nTo address these challenges, this paper proposes a neural topic model,\nTopicAdapt, that can adapt relevant topics from a related source corpus and\nalso discover new topics in a target corpus that are absent in the source\ncorpus. The proposed model offers a promising approach to improve topic\nmodeling performance in practical scenarios. Experiments over multiple datasets\nfrom diverse domains show the superiority of the proposed model against the\nstate-of-the-art topic models.", "published": "2023-10-08 02:56:44", "link": "http://arxiv.org/abs/2310.04978v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting Large Language Models as Zero-shot Relation Extractors", "abstract": "Relation extraction (RE) consistently involves a certain degree of labeled or\nunlabeled data even if under zero-shot setting. Recent studies have shown that\nlarge language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt, which provides the possibility of extracting\nrelations from text without any data and parameter tuning. This work focuses on\nthe study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors.\nOn the one hand, we analyze the drawbacks of existing RE prompts and attempt to\nincorporate recent prompt techniques such as chain-of-thought (CoT) to improve\nzero-shot RE. We propose the summarize-and-ask (\\textsc{SumAsk}) prompting, a\nsimple prompt recursively using LLMs to transform RE inputs to the effective\nquestion answering (QA) format. On the other hand, we conduct comprehensive\nexperiments on various benchmarks and settings to investigate the capabilities\nof LLMs on zero-shot RE. Specifically, we have the following findings: (i)\n\\textsc{SumAsk} consistently and significantly improves LLMs performance on\ndifferent model sizes, benchmarks and settings; (ii) Zero-shot prompting with\nChatGPT achieves competitive or superior results compared with zero-shot and\nfully supervised methods; (iii) LLMs deliver promising performance in\nextracting overlapping relations; (iv) The performance varies greatly regarding\ndifferent relations. Different from small language models, LLMs are effective\nin handling challenge none-of-the-above (NoTA) relation.", "published": "2023-10-08 06:17:39", "link": "http://arxiv.org/abs/2310.05028v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as\n  You May Think -- Introducing AI Detectability Index", "abstract": "With the rise of prolific ChatGPT, the risk and consequences of AI-generated\ntext has increased alarmingly. To address the inevitable question of ownership\nattribution for AI-generated artifacts, the US Copyright Office released a\nstatement stating that 'If a work's traditional elements of authorship were\nproduced by a machine, the work lacks human authorship and the Office will not\nregister it'. Furthermore, both the US and the EU governments have recently\ndrafted their initial proposals regarding the regulatory framework for AI.\nGiven this cynosural spotlight on generative AI, AI-generated text detection\n(AGTD) has emerged as a topic that has already received immediate attention in\nresearch, with some initial methods having been proposed, soon followed by\nemergence of techniques to bypass detection. This paper introduces the Counter\nTuring Test (CT^2), a benchmark consisting of techniques aiming to offer a\ncomprehensive evaluation of the robustness of existing AGTD techniques. Our\nempirical findings unequivocally highlight the fragility of the proposed AGTD\nmethods under scrutiny. Amidst the extensive deliberations on policy-making for\nregulating AI development, it is of utmost importance to assess the\ndetectability of content generated by LLMs. Thus, to establish a quantifiable\nspectrum facilitating the evaluation and ranking of LLMs according to their\ndetectability levels, we propose the AI Detectability Index (ADI). We conduct a\nthorough examination of 15 contemporary LLMs, empirically demonstrating that\nlarger LLMs tend to have a higher ADI, indicating they are less detectable\ncompared to smaller LLMs. We firmly believe that ADI holds significant value as\na tool for the wider NLP community, with the potential to serve as a rubric in\nAI-related policy-making.", "published": "2023-10-08 06:20:36", "link": "http://arxiv.org/abs/2310.05030v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Convinced Prompting: Few-Shot Question Answering with Repeated\n  Introspection", "abstract": "While large language models (LLMs) such as ChatGPT and PaLM have demonstrated\nremarkable performance in various language understanding and generation tasks,\ntheir capabilities in complex reasoning and intricate knowledge utilization\nstill fall short of human-level proficiency. Recent studies have established\nthe effectiveness of prompts in steering LLMs towards generating desired\noutputs. Building on these insights, we introduce a novel framework that\nharnesses the potential of large-scale pre-trained language models, to\niteratively enhance performance of the LLMs. Our framework incorporates three\ncomponents: \\textit{Normal CoT}, a \\textit{Convincer}, and an\n\\textit{Answerer}. It processes the output of a typical few-shot\nchain-of-thought prompt, assesses the correctness of the response, scrutinizes\nthe answer, refines the reasoning, and ultimately produces a new solution.\nExperimental results on the 7 datasets of miscellaneous problems validate the\nefficacy of the Self-Convince framework, achieving substantial improvements\ncompared to the baselines. This study contributes to the burgeoning body of\nresearch focused on integrating pre-trained language models with tailored\nprompts and iterative refinement processes to augment their performance in\ncomplex tasks.", "published": "2023-10-08 06:36:26", "link": "http://arxiv.org/abs/2310.05035v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AvalonBench: Evaluating LLMs Playing the Game of Avalon", "abstract": "In this paper, we explore the potential of Large Language Models (LLMs)\nAgents in playing the strategic social deduction game, Resistance Avalon.\nPlayers in Avalon are challenged not only to make informed decisions based on\ndynamically evolving game phases, but also to engage in discussions where they\nmust deceive, deduce, and negotiate with other players. These characteristics\nmake Avalon a compelling test-bed to study the decision-making and\nlanguage-processing capabilities of LLM Agents. To facilitate research in this\nline, we introduce AvalonBench - a comprehensive game environment tailored for\nevaluating multi-agent LLM Agents. This benchmark incorporates: (1) a game\nenvironment for Avalon, (2) rule-based bots as baseline opponents, and (3)\nReAct-style LLM agents with tailored prompts for each role. Notably, our\nevaluations based on AvalonBench highlight a clear capability gap. For\ninstance, models like ChatGPT playing good-role got a win rate of 22.2% against\nrule-based bots playing evil, while good-role bot achieves 38.2% win rate in\nthe same setting. We envision AvalonBench could be a good test-bed for\ndeveloping more advanced LLMs (with self-playing) and agent frameworks that can\neffectively model the layered complexities of such game environments.", "published": "2023-10-08 06:37:08", "link": "http://arxiv.org/abs/2310.05036v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Guideline Learning for In-context Information Extraction", "abstract": "Large language models (LLMs) can perform a new task by merely conditioning on\ntask instructions and a few input-output examples, without optimizing any\nparameters. This is called In-Context Learning (ICL). In-context Information\nExtraction (IE) has recently garnered attention in the research community.\nHowever, the performance of In-context IE generally lags behind the\nstate-of-the-art supervised expert models. We highlight a key reason for this\nshortfall: underspecified task description. The limited-length context\nstruggles to thoroughly express the intricate IE task instructions and various\nedge cases, leading to misalignment in task comprehension with humans. In this\npaper, we propose a Guideline Learning (GL) framework for In-context IE which\nreflectively learns and follows guidelines. During the learning phrase, GL\nautomatically synthesizes a set of guidelines based on a few error cases, and\nduring inference, GL retrieves helpful guidelines for better ICL. Moreover, we\npropose a self-consistency-based active learning method to enhance the\nefficiency of GL. Experiments on event extraction and relation extraction show\nthat GL can significantly improve the performance of in-context IE.", "published": "2023-10-08 08:25:16", "link": "http://arxiv.org/abs/2310.05066v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller\n  Language Models", "abstract": "Chain-of-Thought (CoT) prompting has proven to be effective in enhancing the\nreasoning capabilities of Large Language Models (LLMs) with at least 100\nbillion parameters. However, it is ineffective or even detrimental when applied\nto reasoning tasks in Smaller Language Models (SLMs) with less than 10 billion\nparameters. To address this limitation, we introduce Dialogue-guided\nChain-of-Thought (DialCoT) which employs a dialogue format to generate\nintermediate reasoning steps, guiding the model toward the final answer.\nAdditionally, we optimize the model's reasoning path selection using the\nProximal Policy Optimization (PPO) algorithm, further enhancing its reasoning\ncapabilities. Our method offers several advantages compared to previous\napproaches. Firstly, we transform the process of solving complex reasoning\nquestions by breaking them down into a series of simpler sub-questions,\nsignificantly reducing the task difficulty and making it more suitable for\nSLMs. Secondly, we optimize the model's reasoning path selection through the\nPPO algorithm. We conduct comprehensive experiments on four arithmetic\nreasoning datasets, demonstrating that our method achieves significant\nperformance improvements compared to state-of-the-art competitors.", "published": "2023-10-08 08:52:13", "link": "http://arxiv.org/abs/2310.05074v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Reliable Are AI-Generated-Text Detectors? An Assessment Framework\n  Using Evasive Soft Prompts", "abstract": "In recent years, there has been a rapid proliferation of AI-generated text,\nprimarily driven by the release of powerful pre-trained language models (PLMs).\nTo address the issue of misuse associated with AI-generated text, various\nhigh-performing detectors have been developed, including the OpenAI detector\nand the Stanford DetectGPT. In our study, we ask how reliable these detectors\nare. We answer the question by designing a novel approach that can prompt any\nPLM to generate text that evades these high-performing detectors. The proposed\napproach suggests a universal evasive prompt, a novel type of soft prompt,\nwhich guides PLMs in producing \"human-like\" text that can mislead the\ndetectors. The novel universal evasive prompt is achieved in two steps: First,\nwe create an evasive soft prompt tailored to a specific PLM through prompt\ntuning; and then, we leverage the transferability of soft prompts to transfer\nthe learned evasive soft prompt from one PLM to another. Employing multiple\nPLMs in various writing tasks, we conduct extensive experiments to evaluate the\nefficacy of the evasive soft prompts in their evasion of state-of-the-art\ndetectors.", "published": "2023-10-08 09:53:46", "link": "http://arxiv.org/abs/2310.05095v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking Down Word Semantics from Pre-trained Language Models through\n  Layer-wise Dimension Selection", "abstract": "Contextual word embeddings obtained from pre-trained language model (PLM)\nhave proven effective for various natural language processing tasks at the word\nlevel. However, interpreting the hidden aspects within embeddings, such as\nsyntax and semantics, remains challenging. Disentangled representation learning\nhas emerged as a promising approach, which separates specific aspects into\ndistinct embeddings. Furthermore, different linguistic knowledge is believed to\nbe stored in different layers of PLM. This paper aims to disentangle semantic\nsense from BERT by applying a binary mask to middle outputs across the layers,\nwithout updating pre-trained parameters. The disentangled embeddings are\nevaluated through binary classification to determine if the target word in two\ndifferent sentences has the same meaning. Experiments with cased\nBERT$_{\\texttt{base}}$ show that leveraging layer-wise information is effective\nand disentangling semantic sense further improve performance.", "published": "2023-10-08 11:07:19", "link": "http://arxiv.org/abs/2310.05115v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Utilizing Contextual Clues and Role Correlations for Enhancing\n  Document-level Event Argument Extraction", "abstract": "Document-level event argument extraction is a crucial yet challenging task\nwithin the field of information extraction. Current mainstream approaches\nprimarily focus on the information interaction between event triggers and their\narguments, facing two limitations: insufficient context interaction and the\nignorance of event correlations. Here, we introduce a novel framework named\nCARLG (Contextual Aggregation of clues and Role-based Latent Guidance),\ncomprising two innovative components: the Contextual Clues Aggregation (CCA)\nand the Role-based Latent Information Guidance (RLIG). The CCA module leverages\nthe attention weights derived from a pre-trained encoder to adaptively\nassimilates broader contextual information, while the RLIG module aims to\ncapture the semantic correlations among event roles. We then instantiate the\nCARLG framework into two variants based on two types of current mainstream EAE\napproaches. Notably, our CARLG framework introduces less than 1% new parameters\nyet significantly improving the performance. Comprehensive experiments across\nthe RAMS, WikiEvents, and MLEE datasets confirm the superiority of CARLG,\nshowing significant superiority in terms of both performance and inference\nspeed compared to major benchmarks. Further analyses demonstrate the\neffectiveness of the proposed modules.", "published": "2023-10-08 11:09:16", "link": "http://arxiv.org/abs/2310.05116v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Harnessing the Power of Large Language Models for Empathetic Response\n  Generation: Empirical Investigations and Improvements", "abstract": "Empathetic dialogue is an indispensable part of building harmonious social\nrelationships and contributes to the development of a helpful AI. Previous\napproaches are mainly based on fine small-scale language models. With the\nadvent of ChatGPT, the application effect of large language models (LLMs) in\nthis field has attracted great attention. This work empirically investigates\nthe performance of LLMs in generating empathetic responses and proposes three\nimprovement methods of semantically similar in-context learning, two-stage\ninteractive generation, and combination with the knowledge base. Extensive\nexperiments show that LLMs can significantly benefit from our proposed methods\nand is able to achieve state-of-the-art performance in both automatic and human\nevaluations. Additionally, we explore the possibility of GPT-4 simulating human\nevaluators.", "published": "2023-10-08 12:21:24", "link": "http://arxiv.org/abs/2310.05140v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model (LLM) as a System of Multiple Expert Agents: An\n  Approach to solve the Abstraction and Reasoning Corpus (ARC) Challenge", "abstract": "We attempt to solve the Abstraction and Reasoning Corpus (ARC) Challenge\nusing Large Language Models (LLMs) as a system of multiple expert agents. Using\nthe flexibility of LLMs to be prompted to do various novel tasks using\nzero-shot, few-shot, context-grounded prompting, we explore the feasibility of\nusing LLMs to solve the ARC Challenge. We firstly convert the input image into\nmultiple suitable text-based abstraction spaces. We then utilise the\nassociative power of LLMs to derive the input-output relationship and map this\nto actions in the form of a working program, similar to Voyager / Ghost in the\nMineCraft. In addition, we use iterative environmental feedback in order to\nguide LLMs to solve the task. Our proposed approach achieves 50 solves out of\n111 training set problems (45%) with just three abstraction spaces - grid,\nobject and pixel - and we believe that with more abstraction spaces and\nlearnable actions, we will be able to solve more.", "published": "2023-10-08 12:37:28", "link": "http://arxiv.org/abs/2310.05146v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "From Data to Dialogue: Leveraging the Structure of Knowledge Graphs for\n  Conversational Exploratory Search", "abstract": "Exploratory search is an open-ended information retrieval process that aims\nat discovering knowledge about a topic or domain rather than searching for a\nspecific answer or piece of information. Conversational interfaces are\nparticularly suitable for supporting exploratory search, allowing users to\nrefine queries and examine search results through interactive dialogues. In\naddition to conversational search interfaces, knowledge graphs are also useful\nin supporting information exploration due to their rich semantic representation\nof data items. In this study, we demonstrate the synergistic effects of\ncombining knowledge graphs and conversational interfaces for exploratory\nsearch, bridging the gap between structured and unstructured information\nretrieval. To this end, we propose a knowledge-driven dialogue system for\nexploring news articles by asking natural language questions and using the\ngraph structure to navigate between related topics. Based on a user study with\n54 participants, we empirically evaluate the effectiveness of the graph-based\nexploratory search and discuss design implications for developing such systems.", "published": "2023-10-08 12:52:09", "link": "http://arxiv.org/abs/2310.05150v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on\n  Open-Source Model", "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in\nutilizing tools, but their closed-source nature and high inference costs pose\nlimitations on their adaptability, necessitating a valid method that leverages\nsmaller, open-sourced models. In this paper, we introduce Toolink, a\ncomprehensive framework that performs task-solving by first creating a toolkit\nand then integrating the planning and calling of tools through a\nchain-of-solving (CoS) approach. We first validate the efficacy of Toolink in\nharnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we\ncurate CoS-GPT, a chain-of-solving dataset designed for tool-using, and\nfinetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source\nmodel with advanced tool-planning and tool-calling capabilities. Evaluation of\ndiverse tasks from BIG-bench demonstrates its CoS ability matches that of\nChatGPT while its performance surpasses the chain-of-thought approach. Further\nstudies highlight the generalization of LLaMA-CoS to unseen tasks and showcase\nits capability in using toolkits not explicitly tailored for the target task,\naffirming its robustness in real-world scenarios.", "published": "2023-10-08 13:07:42", "link": "http://arxiv.org/abs/2310.05155v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MenatQA: A New Dataset for Testing the Temporal Comprehension and\n  Reasoning Abilities of Large Language Models", "abstract": "Large language models (LLMs) have shown nearly saturated performance on many\nnatural language processing (NLP) tasks. As a result, it is natural for people\nto believe that LLMs have also mastered abilities such as time understanding\nand reasoning. However, research on the temporal sensitivity of LLMs has been\ninsufficiently emphasized. To fill this gap, this paper constructs Multiple\nSensitive Factors Time QA (MenatQA), which encompasses three temporal factors\n(scope factor, order factor, counterfactual factor) with total 2,853 samples\nfor evaluating the time comprehension and reasoning abilities of LLMs. This\npaper tests current mainstream LLMs with different parameter sizes, ranging\nfrom billions to hundreds of billions. The results show most LLMs fall behind\nsmaller temporal reasoning models with different degree on these factors. In\nspecific, LLMs show a significant vulnerability to temporal biases and depend\nheavily on the temporal information provided in questions. Furthermore, this\npaper undertakes a preliminary investigation into potential improvement\nstrategies by devising specific prompts and leveraging external tools. These\napproaches serve as valuable baselines or references for future research\nendeavors.", "published": "2023-10-08 13:19:52", "link": "http://arxiv.org/abs/2310.05157v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational\n  Knowledge Graph Construction", "abstract": "Beyond traditional binary relational facts, n-ary relational knowledge graphs\n(NKGs) are comprised of n-ary relational facts containing more than two\nentities, which are closer to real-world facts with broader applications.\nHowever, the construction of NKGs remains at a coarse-grained level, which is\nalways in a single schema, ignoring the order and variable arity of entities.\nTo address these restrictions, we propose Text2NKG, a novel fine-grained n-ary\nrelation extraction framework for n-ary relational knowledge graph\nconstruction. We introduce a span-tuple classification approach with\nhetero-ordered merging and output merging to accomplish fine-grained n-ary\nrelation extraction in different arity. Furthermore, Text2NKG supports four\ntypical NKG schemas: hyper-relational schema, event-based schema, role-based\nschema, and hypergraph-based schema, with high flexibility and practicality.\nThe experimental results demonstrate that Text2NKG achieves state-of-the-art\nperformance in F1 scores on the fine-grained n-ary relation extraction\nbenchmark. Our code and datasets are publicly available.", "published": "2023-10-08 14:47:13", "link": "http://arxiv.org/abs/2310.05185v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Scaling Laws of RoPE-based Extrapolation", "abstract": "The extrapolation capability of Large Language Models (LLMs) based on Rotary\nPosition Embedding is currently a topic of considerable interest. The\nmainstream approach to addressing extrapolation with LLMs involves modifying\nRoPE by replacing 10000, the rotary base of $\\theta_n={10000}^{-2n/d}$ in the\noriginal RoPE, with a larger value and providing longer fine-tuning text. In\nthis work, we first observe that fine-tuning a RoPE-based LLM with either a\nsmaller or larger base in pre-training context length could significantly\nenhance its extrapolation performance. After that, we propose\n\\textbf{\\textit{Scaling Laws of RoPE-based Extrapolation}}, a unified framework\nfrom the periodic perspective, to describe the relationship between the\nextrapolation performance and base value as well as tuning context length. In\nthis process, we also explain the origin of the RoPE-based extrapolation issue\nby \\textbf{\\textit{critical dimension for extrapolation}}. Besides these\nobservations and analyses, we achieve extrapolation up to 1 million context\nlength within only 16K training length on LLaMA2 7B and 13B.", "published": "2023-10-08 15:50:36", "link": "http://arxiv.org/abs/2310.05209v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TILFA: A Unified Framework for Text, Image, and Layout Fusion in\n  Argument Mining", "abstract": "A main goal of Argument Mining (AM) is to analyze an author's stance. Unlike\nprevious AM datasets focusing only on text, the shared task at the 10th\nWorkshop on Argument Mining introduces a dataset including both text and\nimages. Importantly, these images contain both visual elements and optical\ncharacters. Our new framework, TILFA (A Unified Framework for Text, Image, and\nLayout Fusion in Argument Mining), is designed to handle this mixed data. It\nexcels at not only understanding text but also detecting optical characters and\nrecognizing layout details in images. Our model significantly outperforms\nexisting baselines, earning our team, KnowComp, the 1st place in the\nleaderboard of Argumentative Stance Classification subtask in this shared task.", "published": "2023-10-08 15:54:37", "link": "http://arxiv.org/abs/2310.05210v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generative Spoken Language Model based on continuous word-sized audio\n  tokens", "abstract": "In NLP, text language models based on words or subwords are known to\noutperform their character-based counterparts. Yet, in the speech community,\nthe standard input of spoken LMs are 20ms or 40ms-long discrete units (shorter\nthan a phoneme). Taking inspiration from word-based LM, we introduce a\nGenerative Spoken Language Model (GSLM) based on word-size continuous-valued\naudio embeddings that can generate diverse and expressive language output. This\nis obtained by replacing lookup table for lexical types with a Lexical\nEmbedding function, the cross entropy loss by a contrastive loss, and\nmultinomial sampling by k-NN sampling. The resulting model is the first\ngenerative language model based on word-size continuous embeddings. Its\nperformance is on par with discrete unit GSLMs regarding generation quality as\nmeasured by automatic metrics and subjective human judgements. Moreover, it is\nfive times more memory efficient thanks to its large 200ms units. In addition,\nthe embeddings before and after the Lexical Embedder are phonetically and\nsemantically interpretable.", "published": "2023-10-08 16:46:14", "link": "http://arxiv.org/abs/2310.05224v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatRadio-Valuer: A Chat Large Language Model for Generalizable\n  Radiology Report Generation Based on Multi-institution and Multi-system Data", "abstract": "Radiology report generation, as a key step in medical image analysis, is\ncritical to the quantitative analysis of clinically informed decision-making\nlevels. However, complex and diverse radiology reports with cross-source\nheterogeneity pose a huge generalizability challenge to the current methods\nunder massive data volume, mainly because the style and normativity of\nradiology reports are obviously distinctive among institutions, body regions\ninspected and radiologists. Recently, the advent of large language models (LLM)\noffers great potential for recognizing signs of health conditions. To resolve\nthe above problem, we collaborate with the Second Xiangya Hospital in China and\npropose ChatRadio-Valuer based on the LLM, a tailored model for automatic\nradiology report generation that learns generalizable representations and\nprovides a basis pattern for model adaptation in sophisticated analysts' cases.\nSpecifically, ChatRadio-Valuer is trained based on the radiology reports from a\nsingle institution by means of supervised fine-tuning, and then adapted to\ndisease diagnosis tasks for human multi-system evaluation (i.e., chest,\nabdomen, muscle-skeleton, head, and maxillofacial $\\&$ neck) from six different\ninstitutions in clinical-level events. The clinical dataset utilized in this\nstudy encompasses a remarkable total of \\textbf{332,673} observations. From the\ncomprehensive results on engineering indicators, clinical efficacy and\ndeployment cost metrics, it can be shown that ChatRadio-Valuer consistently\noutperforms state-of-the-art models, especially ChatGPT (GPT-3.5-Turbo) and\nGPT-4 et al., in terms of the diseases diagnosis from radiology reports.\nChatRadio-Valuer provides an effective avenue to boost model generalization\nperformance and alleviate the annotation workload of experts to enable the\npromotion of clinical AI applications in radiology reports.", "published": "2023-10-08 17:23:17", "link": "http://arxiv.org/abs/2310.05242v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona\n  Biases in Dialogue Systems", "abstract": "Recent advancements in Large Language Models empower them to follow freeform\ninstructions, including imitating generic or specific demographic personas in\nconversations. We define generic personas to represent demographic groups, such\nas \"an Asian person\", whereas specific personas may take the form of specific\npopular Asian names like \"Yumi\". While the adoption of personas enriches user\nexperiences by making dialogue systems more engaging and approachable, it also\ncasts a shadow of potential risk by exacerbating social biases within model\nresponses, thereby causing societal harm through interactions with users. In\nthis paper, we systematically study \"persona biases\", which we define to be the\nsensitivity of dialogue models' harmful behaviors contingent upon the personas\nthey adopt. We categorize persona biases into biases in harmful expression and\nharmful agreement, and establish a comprehensive evaluation framework to\nmeasure persona biases in five aspects: Offensiveness, Toxic Continuation,\nRegard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to\ninvestigate persona biases by experimenting with UNIVERSALPERSONA, a\nsystematically constructed persona dataset encompassing various types of both\ngeneric and specific model personas. Through benchmarking on four different\nmodels -- including Blender, ChatGPT, Alpaca, and Vicuna -- our study uncovers\nsignificant persona biases in dialogue systems. Our findings also underscore\nthe pressing need to revisit the use of personas in dialogue agents to ensure\nsafe application.", "published": "2023-10-08 21:03:18", "link": "http://arxiv.org/abs/2310.05280v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hybrid Quantum-Classical Machine Learning for Sentiment Analysis", "abstract": "The collaboration between quantum computing and classical machine learning\noffers potential advantages in natural language processing, particularly in the\nsentiment analysis of human emotions and opinions expressed in large-scale\ndatasets. In this work, we propose a methodology for sentiment analysis using\nhybrid quantum-classical machine learning algorithms. We investigate quantum\nkernel approaches and variational quantum circuit-based classifiers and\nintegrate them with classical dimension reduction techniques such as PCA and\nHaar wavelet transform. The proposed methodology is evaluated using two\ndistinct datasets, based on English and Bengali languages. Experimental results\nshow that after dimensionality reduction of the data, performance of the\nquantum-based hybrid algorithms were consistent and better than classical\nmethods.", "published": "2023-10-08 05:45:22", "link": "http://arxiv.org/abs/2310.10672v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain\n  Everyday Tasks", "abstract": "Automatically generating scripts (i.e. sequences of key steps described in\ntext) from video demonstrations and reasoning about the subsequent steps are\ncrucial to the modern AI virtual assistants to guide humans to complete\neveryday tasks, especially unfamiliar ones. However, current methods for\ngenerative script learning rely heavily on well-structured preceding steps\ndescribed in text and/or images or are limited to a certain domain, resulting\nin a disparity with real-world user scenarios. To address these limitations, we\npresent a new benchmark challenge -- MultiScript, with two new tasks on\ntask-oriented multimodal script learning: (1) multimodal script generation, and\n(2) subsequent step prediction. For both tasks, the input consists of a target\ntask name and a video illustrating what has been done to complete the target\ntask, and the expected output is (1) a sequence of structured step descriptions\nin text based on the demonstration video, and (2) a single text description for\nthe subsequent step, respectively. Built from WikiHow, MultiScript covers\nmultimodal scripts in videos and text descriptions for over 6,655 human\neveryday tasks across 19 diverse domains. To establish baseline performance on\nMultiScript, we propose two knowledge-guided multimodal generative frameworks\nthat incorporate the task-related knowledge prompted from large language models\nsuch as Vicuna. Experimental results show that our proposed approaches\nsignificantly improve over the competitive baselines.", "published": "2023-10-08 01:51:17", "link": "http://arxiv.org/abs/2310.04965v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Transfer Learning in Deep Learning\n  Text-to-Speech Models on a Few-Shot, Low-Resource, Customized Dataset", "abstract": "Text-to-Speech (TTS) synthesis using deep learning relies on voice quality.\nModern TTS models are advanced, but they need large amount of data. Given the\ngrowing computational complexity of these models and the scarcity of large,\nhigh-quality datasets, this research focuses on transfer learning, especially\non few-shot, low-resource, and customized datasets. In this research,\n\"low-resource\" specifically refers to situations where there are limited\namounts of training data, such as a small number of audio recordings and\ncorresponding transcriptions for a particular language or dialect. This thesis,\nis rooted in the pressing need to find TTS models that require less training\ntime, fewer data samples, yet yield high-quality voice output. The research\nevaluates TTS state-of-the-art model transfer learning capabilities through a\nthorough technical analysis. It then conducts a hands-on experimental analysis\nto compare models' performance in a constrained dataset. This study\ninvestigates the efficacy of modern TTS systems with transfer learning on\nspecialized datasets and a model that balances training efficiency and\nsynthesis quality. Initial hypotheses suggest that transfer learning could\nsignificantly improve TTS models' performance on compact datasets, and an\noptimal model may exist for such unique conditions. This thesis predicts a rise\nin transfer learning in TTS as data scarcity increases. In the future, custom\nTTS applications will favour models optimized for specific datasets over\ngeneric, data-intensive ones.", "published": "2023-10-08 03:08:25", "link": "http://arxiv.org/abs/2310.04982v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Distantly-Supervised Joint Extraction with Noise-Robust Learning", "abstract": "Joint entity and relation extraction is a process that identifies entity\npairs and their relations using a single model. We focus on the problem of\njoint extraction in distantly-labeled data, whose labels are generated by\naligning entity mentions with the corresponding entity and relation tags using\na knowledge base (KB). One key challenge is the presence of noisy labels\narising from both incorrect entity and relation annotations, which\nsignificantly impairs the quality of supervised learning. Existing approaches,\neither considering only one source of noise or making decisions using external\nknowledge, cannot well-utilize significant information in the training data. We\npropose DENRL, a generalizable framework that 1) incorporates a lightweight\ntransformer backbone into a sequence labeling scheme for joint tagging, and 2)\nemploys a noise-robust framework that regularizes the tagging model with\nsignificant relation patterns and entity-relation dependencies, then\niteratively self-adapts to instances with less noise from both sources.\nSurprisingly, experiments on two benchmark datasets show that DENRL, using\nmerely its own parametric distribution and simple data-driven heuristics,\noutperforms large language model-based baselines by a large margin with better\ninterpretability.", "published": "2023-10-08 03:42:15", "link": "http://arxiv.org/abs/2310.04994v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FLatS: Principled Out-of-Distribution Detection with Feature-Based\n  Likelihood Ratio Score", "abstract": "Detecting out-of-distribution (OOD) instances is crucial for NLP models in\npractical applications. Although numerous OOD detection methods exist, most of\nthem are empirical. Backed by theoretical analysis, this paper advocates for\nthe measurement of the \"OOD-ness\" of a test case $\\boldsymbol{x}$ through the\nlikelihood ratio between out-distribution $\\mathcal P_{\\textit{out}}$ and\nin-distribution $\\mathcal P_{\\textit{in}}$. We argue that the state-of-the-art\n(SOTA) feature-based OOD detection methods, such as Maha and KNN, are\nsuboptimal since they only estimate in-distribution density\n$p_{\\textit{in}}(\\boldsymbol{x})$. To address this issue, we propose FLatS, a\nprincipled solution for OOD detection based on likelihood ratio. Moreover, we\ndemonstrate that FLatS can serve as a general framework capable of enhancing\nother OOD detection methods by incorporating out-distribution density\n$p_{\\textit{out}}(\\boldsymbol{x})$ estimation. Experiments show that FLatS\nestablishes a new SOTA on popular benchmarks. Our code is publicly available at\nhttps://github.com/linhaowei1/FLatS.", "published": "2023-10-08 09:16:46", "link": "http://arxiv.org/abs/2310.05083v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Detection of Machine-Generated Codes", "abstract": "This work proposes a training-free approach for the detection of\nLLMs-generated codes, mitigating the risks associated with their indiscriminate\nusage. To the best of our knowledge, our research is the first to investigate\nzero-shot detection techniques applied to code generated by advanced black-box\nLLMs like ChatGPT. Firstly, we find that existing training-based or zero-shot\ntext detectors are ineffective in detecting code, likely due to the unique\nstatistical properties found in code structures. We then modify the previous\nzero-shot text detection method, DetectGPT (Mitchell et al., 2023) by utilizing\na surrogate white-box model to estimate the probability of the rightmost\ntokens, allowing us to identify code snippets generated by language models.\nThrough extensive experiments conducted on the python codes of the CodeContest\nand APPS dataset, our approach demonstrates its effectiveness by achieving\nstate-of-the-art detection results on text-davinci-003, GPT-3.5, and GPT-4\nmodels. Moreover, our method exhibits robustness against revision attacks and\ngeneralizes well to Java codes. We also find that the smaller code language\nmodel like PolyCoder-160M performs as a universal code detector, outperforming\nthe billion-scale counterpart. The codes will be available at\nhttps://github.com/ Xianjun-Yang/Code_detection.git", "published": "2023-10-08 10:08:21", "link": "http://arxiv.org/abs/2310.05103v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Instances and Labels: Hierarchy-aware Joint Supervised Contrastive\n  Learning for Hierarchical Multi-Label Text Classification", "abstract": "Hierarchical multi-label text classification (HMTC) aims at utilizing a label\nhierarchy in multi-label classification. Recent approaches to HMTC deal with\nthe problem of imposing an over-constrained premise on the output space by\nusing contrastive learning on generated samples in a semi-supervised manner to\nbring text and label embeddings closer. However, the generation of samples\ntends to introduce noise as it ignores the correlation between similar samples\nin the same batch. One solution to this issue is supervised contrastive\nlearning, but it remains an underexplored topic in HMTC due to its complex\nstructured labels. To overcome this challenge, we propose $\\textbf{HJCL}$, a\n$\\textbf{H}$ierarchy-aware $\\textbf{J}$oint Supervised $\\textbf{C}$ontrastive\n$\\textbf{L}$earning method that bridges the gap between supervised contrastive\nlearning and HMTC. Specifically, we employ both instance-wise and label-wise\ncontrastive learning techniques and carefully construct batches to fulfill the\ncontrastive learning objective. Extensive experiments on four multi-path HMTC\ndatasets demonstrate that HJCL achieves promising results and the effectiveness\nof Contrastive Learning on HMTC.", "published": "2023-10-08 11:36:45", "link": "http://arxiv.org/abs/2310.05128v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are Emily and Greg Still More Employable than Lakisha and Jamal?\n  Investigating Algorithmic Hiring Bias in the Era of ChatGPT", "abstract": "Large Language Models (LLMs) such as GPT-3.5, Bard, and Claude exhibit\napplicability across numerous tasks. One domain of interest is their use in\nalgorithmic hiring, specifically in matching resumes with job categories. Yet,\nthis introduces issues of bias on protected attributes like gender, race and\nmaternity status. The seminal work of Bertrand & Mullainathan (2003) set the\ngold-standard for identifying hiring bias via field experiments where the\nresponse rate for identical resumes that differ only in protected attributes,\ne.g., racially suggestive names such as Emily or Lakisha, is compared. We\nreplicate this experiment on state-of-art LLMs (GPT-3.5, Bard, Claude and\nLlama) to evaluate bias (or lack thereof) on gender, race, maternity status,\npregnancy status, and political affiliation. We evaluate LLMs on two tasks: (1)\nmatching resumes to job categories; and (2) summarizing resumes with employment\nrelevant information. Overall, LLMs are robust across race and gender. They\ndiffer in their performance on pregnancy status and political affiliation. We\nuse contrastive input decoding on open-source LLMs to uncover potential sources\nof bias.", "published": "2023-10-08 12:08:48", "link": "http://arxiv.org/abs/2310.05135v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata", "abstract": "Studying language models (LMs) in terms of well-understood formalisms allows\nus to precisely characterize their abilities and limitations. Previous work has\ninvestigated the representational capacity of recurrent neural network (RNN)\nLMs in terms of their capacity to recognize unweighted formal languages.\nHowever, LMs do not describe unweighted formal languages -- rather, they define\n\\emph{probability distributions} over strings. In this work, we study what\nclasses of such probability distributions RNN LMs can represent, which allows\nus to make more direct statements about their capabilities. We show that simple\nRNNs are equivalent to a subclass of probabilistic finite-state automata, and\ncan thus model a strict subset of probability distributions expressible by\nfinite-state models. Furthermore, we study the space complexity of representing\nfinite-state LMs with RNNs. We show that, to represent an arbitrary\ndeterministic finite-state LM with $N$ states over an alphabet $\\alphabet$, an\nRNN requires $\\Omega\\left(N |\\Sigma|\\right)$ neurons. These results present a\nfirst step towards characterizing the classes of distributions RNN LMs can\nrepresent and thus help us understand their capabilities and limitations.", "published": "2023-10-08 13:36:05", "link": "http://arxiv.org/abs/2310.05161v4", "categories": ["cs.CL", "cs.CC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimizing Large Language Models to Expedite the Development of Smart\n  Contracts", "abstract": "Programming has always been at the heart of technological innovation in the\n21st century. With the advent of blockchain technologies and the proliferation\nof web3 paradigms of decentralised applications, smart contracts have been very\ninstrumental in enabling developers to build applications that reside on\ndecentralised blockchains. Despite the huge interest and potential of smart\ncontracts, there is still a significant knowledge and skill gap that developers\nneed to cross in order to build web3 applications. In light of this, we\nintroduce MazzumaGPT, a large language model that has been optimised to\ngenerate smart contract code and aid developers to scaffold development and\nimprove productivity. As part of this research, we outline the optimisation and\nfine-tuning parameters, evaluate the model's performance on functional\ncorrectness and address the limitations and broader impacts of our research.", "published": "2023-10-08 14:29:33", "link": "http://arxiv.org/abs/2310.05178v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Factuality Challenges in the Era of Large Language Models", "abstract": "The emergence of tools based on Large Language Models (LLMs), such as\nOpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered\nimmense public attention. These incredibly useful, natural-sounding tools mark\nsignificant advances in natural language generation, yet they exhibit a\npropensity to generate false, erroneous, or misleading content -- commonly\nreferred to as \"hallucinations.\" Moreover, LLMs can be exploited for malicious\napplications, such as generating false but credible-sounding content and\nprofiles at scale. This poses a significant challenge to society in terms of\nthe potential deception of users and the increasing dissemination of inaccurate\ninformation. In light of these risks, we explore the kinds of technological\ninnovations, regulatory reforms, and AI literacy initiatives needed from\nfact-checkers, news organizations, and the broader research and policy\ncommunities. By identifying the risks, the imminent threats, and some viable\nsolutions, we seek to shed light on navigating various aspects of veracity in\nthe era of generative AI.", "published": "2023-10-08 14:55:02", "link": "http://arxiv.org/abs/2310.05189v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MindfulDiary: Harnessing Large Language Model to Support Psychiatric\n  Patients' Journaling", "abstract": "In the mental health domain, Large Language Models (LLMs) offer promising new\nopportunities, though their inherent complexity and low controllability have\nraised questions about their suitability in clinical settings. We present\nMindfulDiary, a mobile journaling app incorporating an LLM to help psychiatric\npatients document daily experiences through conversation. Designed in\ncollaboration with mental health professionals (MHPs), MindfulDiary takes a\nstate-based approach to safely comply with the experts' guidelines while\ncarrying on free-form conversations. Through a four-week field study involving\n28 patients with major depressive disorder and five psychiatrists, we found\nthat MindfulDiary supported patients in consistently enriching their daily\nrecords and helped psychiatrists better empathize with their patients through\nan understanding of their thoughts and daily contexts. Drawing on these\nfindings, we discuss the implications of leveraging LLMs in the mental health\ndomain, bridging the technical feasibility and their integration into clinical\nsettings.", "published": "2023-10-08 17:00:04", "link": "http://arxiv.org/abs/2310.05231v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "XLS-R fine-tuning on noisy word boundaries for unsupervised speech\n  segmentation into words", "abstract": "Due to the absence of explicit word boundaries in the speech stream, the task\nof segmenting spoken sentences into word units without text supervision is\nparticularly challenging. In this work, we leverage the most recent\nself-supervised speech models that have proved to quickly adapt to new tasks\nthrough fine-tuning, even in low resource conditions. Taking inspiration from\nsemi-supervised learning, we fine-tune an XLS-R model to predict word\nboundaries themselves produced by top-tier speech segmentation systems: DPDP,\nVG-HuBERT, GradSeg and DP-Parse. Once XLS-R is fine-tuned, it is used to infer\nnew word boundary labels that are used in turn for another fine-tuning step.\nOur method consistently improves the performance of each system and sets a new\nstate-of-the-art that is, on average 130% higher than the previous one as\nmeasured by the F1 score on correctly discovered word tokens on five corpora\nfeaturing different languages. Finally, our system can segment speech from\nlanguages unseen during fine-tuning in a zero-shot fashion.", "published": "2023-10-08 17:05:00", "link": "http://arxiv.org/abs/2310.05235v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Explainable Claim Verification via Knowledge-Grounded Reasoning with\n  Large Language Models", "abstract": "Claim verification plays a crucial role in combating misinformation. While\nexisting works on claim verification have shown promising results, a crucial\npiece of the puzzle that remains unsolved is to understand how to verify claims\nwithout relying on human-annotated data, which is expensive to create at a\nlarge scale. Additionally, it is important for models to provide comprehensive\nexplanations that can justify their decisions and assist human fact-checkers.\nThis paper presents First-Order-Logic-Guided Knowledge-Grounded (FOLK)\nReasoning that can verify complex claims and generate explanations without the\nneed for annotated evidence using Large Language Models (LLMs). FOLK leverages\nthe in-context learning ability of LLMs to translate the claim into a\nFirst-Order-Logic (FOL) clause consisting of predicates, each corresponding to\na sub-claim that needs to be verified. Then, FOLK performs FOL-Guided reasoning\nover a set of knowledge-grounded question-and-answer pairs to make veracity\npredictions and generate explanations to justify its decision-making process.\nThis process makes our model highly explanatory, providing clear explanations\nof its reasoning process in human-readable form. Our experiment results\nindicate that FOLK outperforms strong baselines on three datasets encompassing\nvarious claim verification challenges. Our code and data are available.", "published": "2023-10-08 18:04:05", "link": "http://arxiv.org/abs/2310.05253v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"A Nova Eletricidade: Aplica\u00e7\u00f5es, Riscos e Tend\u00eancias da IA\n  Moderna -- \"The New Electricity\": Applications, Risks, and Trends in Current\n  AI", "abstract": "The thought-provoking analogy between AI and electricity, made by computer\nscientist and entrepreneur Andrew Ng, summarizes the deep transformation that\nrecent advances in Artificial Intelligence (AI) have triggered in the world.\nThis chapter presents an overview of the ever-evolving landscape of AI, written\nin Portuguese. With no intent to exhaust the subject, we explore the AI\napplications that are redefining sectors of the economy, impacting society and\nhumanity. We analyze the risks that may come along with rapid technological\nprogress and future trends in AI, an area that is on the path to becoming a\ngeneral-purpose technology, just like electricity, which revolutionized society\nin the 19th and 20th centuries.\n  A provocativa compara\\c{c}\\~ao entre IA e eletricidade, feita pelo cientista\nda computa\\c{c}\\~ao e empreendedor Andrew Ng, resume a profunda\ntransforma\\c{c}\\~ao que os recentes avan\\c{c}os em Intelig\\^encia Artificial\n(IA) t\\^em desencadeado no mundo. Este cap\\'itulo apresenta uma vis\\~ao geral\npela paisagem em constante evolu\\c{c}\\~ao da IA. Sem pretens\\~oes de exaurir o\nassunto, exploramos as aplica\\c{c}\\~oes que est\\~ao redefinindo setores da\neconomia, impactando a sociedade e a humanidade. Analisamos os riscos que\nacompanham o r\\'apido progresso tecnol\\'ogico e as tend\\^encias futuras da IA,\n\\'area que trilha o caminho para se tornar uma tecnologia de prop\\'osito geral,\nassim como a eletricidade, que revolucionou a sociedade dos s\\'eculos XIX e XX.", "published": "2023-10-08 09:01:18", "link": "http://arxiv.org/abs/2310.18324v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "68", "I.2"], "primary_category": "cs.AI"}
{"title": "A Comparative Study of Voice Conversion Models with Large-Scale Speech\n  and Singing Data: The T13 Systems for the Singing Voice Conversion Challenge\n  2023", "abstract": "This paper presents our systems (denoted as T13) for the singing voice\nconversion challenge (SVCC) 2023. For both in-domain and cross-domain English\nsinging voice conversion (SVC) tasks (Task 1 and Task 2), we adopt a\nrecognition-synthesis approach with self-supervised learning-based\nrepresentation. To achieve data-efficient SVC with a limited amount of target\nsinger/speaker's data (150 to 160 utterances for SVCC 2023), we first train a\ndiffusion-based any-to-any voice conversion model using publicly available\nlarge-scale 750 hours of speech and singing data. Then, we finetune the model\nfor each target singer/speaker of Task 1 and Task 2. Large-scale listening\ntests conducted by SVCC 2023 show that our T13 system achieves competitive\nnaturalness and speaker similarity for the harder cross-domain SVC (Task 2),\nwhich implies the generalization ability of our proposed method. Our objective\nevaluation results show that using large datasets is particularly beneficial\nfor cross-domain SVC.", "published": "2023-10-08 15:30:44", "link": "http://arxiv.org/abs/2310.05203v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "PromptSpeaker: Speaker Generation Based on Text Descriptions", "abstract": "Recently, text-guided content generation has received extensive attention. In\nthis work, we explore the possibility of text description-based speaker\ngeneration, i.e., using text prompts to control the speaker generation process.\nSpecifically, we propose PromptSpeaker, a text-guided speaker generation\nsystem. PromptSpeaker consists of a prompt encoder, a zero-shot VITS, and a\nGlow model, where the prompt encoder predicts a prior distribution based on the\ntext description and samples from this distribution to obtain a semantic\nrepresentation. The Glow model subsequently converts the semantic\nrepresentation into a speaker representation, and the zero-shot VITS finally\nsynthesizes the speaker's voice based on the speaker representation. We verify\nthat PromptSpeaker can generate speakers new from the training set by objective\nmetrics, and the synthetic speaker voice has reasonable subjective matching\nquality with the speaker prompt.", "published": "2023-10-08 04:09:45", "link": "http://arxiv.org/abs/2310.05001v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SALT: Distinguishable Speaker Anonymization Through Latent Space\n  Transformation", "abstract": "Speaker anonymization aims to conceal a speaker's identity without degrading\nspeech quality and intelligibility. Most speaker anonymization systems\ndisentangle the speaker representation from the original speech and achieve\nanonymization by averaging or modifying the speaker representation. However,\nthe anonymized speech is subject to reduction in pseudo speaker\ndistinctiveness, speech quality and intelligibility for out-of-distribution\nspeaker. To solve this issue, we propose SALT, a Speaker Anonymization system\nbased on Latent space Transformation. Specifically, we extract latent features\nby a self-supervised feature extractor and randomly sample multiple speakers\nand their weights, and then interpolate the latent vectors to achieve speaker\nanonymization. Meanwhile, we explore the extrapolation method to further extend\nthe diversity of pseudo speakers. Experiments on Voice Privacy Challenge\ndataset show our system achieves a state-of-the-art distinctiveness metric\nwhile preserving speech quality and intelligibility. Our code and demo is\navailible at https://github.com/BakerBunker/SALT .", "published": "2023-10-08 07:21:44", "link": "http://arxiv.org/abs/2310.05051v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Partial Rank Similarity Minimization Method for Quality MOS Prediction\n  of Unseen Speech Synthesis Systems in Zero-Shot and Semi-supervised setting", "abstract": "This paper introduces a novel objective function for quality mean opinion\nscore (MOS) prediction of unseen speech synthesis systems. The proposed\nfunction measures the similarity of relative positions of predicted MOS values,\nin a mini-batch, rather than the actual MOS values. That is the partial rank\nsimilarity is measured (PRS) rather than the individual MOS values as with the\nL1 loss. Our experiments on out-of-domain speech synthesis systems demonstrate\nthat the PRS outperforms L1 loss in zero-shot and semi-supervised settings,\nexhibiting stronger correlation with ground truth. These findings highlight the\nimportance of considering rank order, as done by PRS, when training MOS\nprediction models. We also argue that mean squared error and linear correlation\ncoefficient metrics may be unreliable for evaluating MOS prediction models. In\nconclusion, PRS-trained models provide a robust framework for evaluating speech\nquality and offer insights for developing high-quality speech synthesis\nsystems. Code and models are available at\ngithub.com/nii-yamagishilab/partial_rank_similarity/", "published": "2023-10-08 09:01:31", "link": "http://arxiv.org/abs/2310.05078v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VITS-based Singing Voice Conversion System with DSPGAN post-processing\n  for SVCC2023", "abstract": "This paper presents the T02 team's system for the Singing Voice Conversion\nChallenge 2023 (SVCC2023). Our system entails a VITS-based SVC model,\nincorporating three modules: a feature extractor, a voice converter, and a\npost-processor. Specifically, the feature extractor provides F0 contours and\nextracts speaker-independent linguistic content from the input singing voice by\nleveraging a HuBERT model. The voice converter is employed to recompose the\nspeaker timbre, F0, and linguistic content to generate the waveform of the\ntarget speaker. Besides, to further improve the audio quality, a fine-tuned\nDSPGAN vocoder is introduced to re-synthesise the waveform. Given the limited\ntarget speaker data, we utilize a two-stage training strategy to adapt the base\nmodel to the target speaker. During model adaptation, several tricks, such as\ndata augmentation and joint training with auxiliary singer data, are involved.\nOfficial challenge results show that our system achieves superior performance,\nespecially in the cross-domain task, ranking 1st and 2nd in naturalness and\nsimilarity, respectively. Further ablation justifies the effectiveness of our\nsystem design.", "published": "2023-10-08 11:16:57", "link": "http://arxiv.org/abs/2310.05118v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Separable Hidden Unit Contributions for Speaker-Adaptive\n  Lip-Reading", "abstract": "In this paper, we propose a novel method for speaker adaptation in lip\nreading, motivated by two observations. Firstly, a speaker's own\ncharacteristics can always be portrayed well by his/her few facial images or\neven a single image with shallow networks, while the fine-grained dynamic\nfeatures associated with speech content expressed by the talking face always\nneed deep sequential networks to represent accurately. Therefore, we treat the\nshallow and deep layers differently for speaker adaptive lip reading. Secondly,\nwe observe that a speaker's unique characteristics ( e.g. prominent oral cavity\nand mandible) have varied effects on lip reading performance for different\nwords and pronunciations, necessitating adaptive enhancement or suppression of\nthe features for robust lip reading. Based on these two observations, we\npropose to take advantage of the speaker's own characteristics to automatically\nlearn separable hidden unit contributions with different targets for shallow\nlayers and deep layers respectively. For shallow layers where features related\nto the speaker's characteristics are stronger than the speech content related\nfeatures, we introduce speaker-adaptive features to learn for enhancing the\nspeech content features. For deep layers where both the speaker's features and\nthe speech content features are all expressed well, we introduce the\nspeaker-adaptive features to learn for suppressing the speech content\nirrelevant noise for robust lip reading. Our approach consistently outperforms\nexisting methods, as confirmed by comprehensive analysis and comparison across\ndifferent settings. Besides the evaluation on the popular LRW-ID and GRID\ndatasets, we also release a new dataset for evaluation, CAS-VSR-S68h, to\nfurther assess the performance in an extreme setting where just a few speakers\nare available but the speech content covers a large and diversified range.", "published": "2023-10-08 07:48:25", "link": "http://arxiv.org/abs/2310.05058v3", "categories": ["cs.CV", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A framework to generate sparsity-inducing regularizers for enhanced\n  low-rank matrix completion", "abstract": "Applying half-quadratic optimization to loss functions can yield the\ncorresponding regularizers, while these regularizers are usually not\nsparsity-inducing regularizers (SIRs). To solve this problem, we devise a\nframework to generate an SIR with closed-form proximity operator. Besides, we\nspecify our framework using several commonly-used loss functions, and produce\nthe corresponding SIRs, which are then adopted as nonconvex rank surrogates for\nlow-rank matrix completion. Furthermore, algorithms based on the alternating\ndirection method of multipliers are developed. Extensive numerical results show\nthe effectiveness of our methods in terms of recovery performance and runtime.", "published": "2023-10-08 00:35:54", "link": "http://arxiv.org/abs/2310.04954v1", "categories": ["math.OC", "cs.IR", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "math.OC"}
{"title": "Unified speech and gesture synthesis using flow matching", "abstract": "As text-to-speech technologies achieve remarkable naturalness in read-aloud\ntasks, there is growing interest in multimodal synthesis of verbal and\nnon-verbal communicative behaviour, such as spontaneous speech and associated\nbody gestures. This paper presents a novel, unified architecture for jointly\nsynthesising speech acoustics and skeleton-based 3D gesture motion from text,\ntrained using optimal-transport conditional flow matching (OT-CFM). The\nproposed architecture is simpler than the previous state of the art, has a\nsmaller memory footprint, and can capture the joint distribution of speech and\ngestures, generating both modalities together in one single process. The new\ntraining regime, meanwhile, enables better synthesis quality in much fewer\nsteps (network evaluations) than before. Uni- and multimodal subjective tests\ndemonstrate improved speech naturalness, gesture human-likeness, and\ncross-modal appropriateness compared to existing benchmarks. Please see\nhttps://shivammehta25.github.io/Match-TTSG/ for video examples and code.", "published": "2023-10-08 14:37:28", "link": "http://arxiv.org/abs/2310.05181v2", "categories": ["eess.AS", "cs.GR", "cs.HC", "cs.LG", "cs.SD", "68T07 (Primary), 68T42 (Secondary)", "I.2.7; I.2.6; H.5"], "primary_category": "eess.AS"}
