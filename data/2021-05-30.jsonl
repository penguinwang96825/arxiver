{"title": "Modeling Text-visual Mutual Dependency for Multi-modal Dialog Generation", "abstract": "Multi-modal dialog modeling is of growing interest. In this work, we propose\nframeworks to resolve a specific case of multi-modal dialog generation that\nbetter mimics multi-modal dialog generation in the real world, where each\ndialog turn is associated with the visual context in which it takes place.\nSpecifically, we propose to model the mutual dependency between text-visual\nfeatures, where the model not only needs to learn the probability of generating\nthe next dialog utterance given preceding dialog utterances and visual\ncontexts, but also the probability of predicting the visual features in which a\ndialog utterance takes place, leading the generated dialog utterance specific\nto the visual context. We observe significant performance boosts over vanilla\nmodels when the mutual dependency between text and visual features is modeled.\nCode is available at https://github.com/ShannonAI/OpenViDial.", "published": "2021-05-30 07:20:28", "link": "http://arxiv.org/abs/2105.14445v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based\n  Simulation", "abstract": "We propose NeuralWOZ, a novel dialogue collection framework that uses\nmodel-based dialogue simulation. NeuralWOZ has two pipelined models, Collector\nand Labeler. Collector generates dialogues from (1) user's goal instructions,\nwhich are the user context and task constraints in natural language, and (2)\nsystem's API call results, which is a list of possible query responses for user\nrequests from the given knowledge base. Labeler annotates the generated\ndialogue by formulating the annotation as a multiple-choice problem, in which\nthe candidate labels are extracted from goal instructions and API call results.\nWe demonstrate the effectiveness of the proposed method in the zero-shot domain\ntransfer learning for dialogue state tracking. In the evaluation, the synthetic\ndialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with\nimprovements of 4.4% point joint goal accuracy on average across domains, and\nimprovements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1\ndataset.", "published": "2021-05-30 07:54:54", "link": "http://arxiv.org/abs/2105.14454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLEVE: Contrastive Pre-training for Event Extraction", "abstract": "Event extraction (EE) has considerably benefited from pre-trained language\nmodels (PLMs) by fine-tuning. However, existing pre-training methods have not\ninvolved modeling event characteristics, resulting in the developed EE models\ncannot take full advantage of large-scale unsupervised data. To this end, we\npropose CLEVE, a contrastive pre-training framework for EE to better learn\nevent knowledge from large unsupervised data and their semantic structures\n(e.g. AMR) obtained with automatic parsers. CLEVE contains a text encoder to\nlearn event semantics and a graph encoder to learn event structures\nrespectively. Specifically, the text encoder learns event semantic\nrepresentations by self-supervised contrastive learning to represent the words\nof the same events closer than those unrelated words; the graph encoder learns\nevent structure representations by graph contrastive pre-training on parsed\nevent-related semantic structures. The two complementary representations then\nwork together to improve both the conventional supervised EE and the\nunsupervised \"liberal\" EE, which requires jointly extracting events and\ndiscovering event schemata without any annotated data. Experiments on ACE 2005\nand MAVEN datasets show that CLEVE achieves significant improvements,\nespecially in the challenging unsupervised setting. The source code and\npre-trained checkpoints can be obtained from https://github.com/THU-KEG/CLEVE.", "published": "2021-05-30 09:50:17", "link": "http://arxiv.org/abs/2105.14485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REAM$\\sharp$: An Enhancement Approach to Reference-based Evaluation\n  Metrics for Open-domain Dialog Generation", "abstract": "The lack of reliable automatic evaluation metrics is a major impediment to\nthe development of open-domain dialogue systems. Various reference-based\nmetrics have been proposed to calculate a score between a predicted response\nand a small set of references. However, these metrics show unsatisfactory\ncorrelations with human judgments. For a reference-based metric, its\nreliability mainly depends on two factors: its ability to measure the\nsimilarity between the predicted response and the reference response, as well\nas the reliability of the given reference set. Yet, there are few discussions\non the latter. Our work attempts to fill this vacancy. We first clarify an\nassumption on reference-based metrics that, if more high-quality references are\nadded into the reference set, the reliability of the metric will increase.\nNext, we present REAM$\\sharp$: an enhancement approach to Reference-based\nEvAluation Metrics for open-domain dialogue systems. A prediction model is\ndesigned to estimate the reliability of the given reference set. We show how\nits predicted results can be helpful to augment the reference set, and thus\nimprove the reliability of the metric. Experiments validate both the\neffectiveness of our prediction model and that the reliability of\nreference-based metrics improves with the augmented reference sets.", "published": "2021-05-30 10:04:13", "link": "http://arxiv.org/abs/2105.14488v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Sentiment Analysis as Dependency Graph Parsing", "abstract": "Structured sentiment analysis attempts to extract full opinion tuples from a\ntext, but over time this task has been subdivided into smaller and smaller\nsub-tasks, e,g,, target extraction or targeted polarity classification. We\nargue that this division has become counterproductive and propose a new unified\nframework to remedy the situation. We cast the structured sentiment problem as\ndependency graph parsing, where the nodes are spans of sentiment holders,\ntargets and expressions, and the arcs are the relations between them. We\nperform experiments on five datasets in four languages (English, Norwegian,\nBasque, and Catalan) and show that this approach leads to strong improvements\nover state-of-the-art baselines. Our analysis shows that refining the sentiment\ngraphs with syntactic dependency information further improves results.", "published": "2021-05-30 11:19:46", "link": "http://arxiv.org/abs/2105.14504v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Low is Too Low? A Computational Perspective on Extremely\n  Low-Resource Languages", "abstract": "Despite the recent advancements of attention-based deep learning\narchitectures across a majority of Natural Language Processing tasks, their\napplication remains limited in a low-resource setting because of a lack of\npre-trained models for such languages. In this study, we make the first attempt\nto investigate the challenges of adapting these techniques for an extremely\nlow-resource language -- Sumerian cuneiform -- one of the world's oldest\nwritten languages attested from at least the beginning of the 3rd millennium\nBC. Specifically, we introduce the first cross-lingual information extraction\npipeline for Sumerian, which includes part-of-speech tagging, named entity\nrecognition, and machine translation. We further curate InterpretLR, an\ninterpretability toolkit for low-resource NLP, and use it alongside human\nattributions to make sense of the models. We emphasize on human evaluations to\ngauge all our techniques. Notably, most components of our pipeline can be\ngeneralised to any other language to obtain an interpretable execution of the\ntechniques, especially in a low-resource setting. We publicly release all\nsoftware, model checkpoints, and a novel dataset with domain-specific\npre-processing to promote further research.", "published": "2021-05-30 12:09:59", "link": "http://arxiv.org/abs/2105.14515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Nearest Neighbor Machine Translation", "abstract": "Though nearest neighbor Machine Translation ($k$NN-MT)\n\\citep{khandelwal2020nearest} has proved to introduce significant performance\nboosts over standard neural MT systems, it is prohibitively slow since it uses\nthe entire reference corpus as the datastore for the nearest neighbor search.\nThis means each step for each beam in the beam search has to search over the\nentire reference corpus. $k$NN-MT is thus two-orders slower than vanilla MT\nmodels, making it hard to be applied to real-world applications, especially\nonline services. In this work, we propose Fast $k$NN-MT to address this issue.\nFast $k$NN-MT constructs a significantly smaller datastore for the nearest\nneighbor search: for each word in a source sentence, Fast $k$NN-MT first\nselects its nearest token-level neighbors, which is limited to tokens that are\nthe same as the query token. Then at each decoding step, in contrast to using\nthe entire corpus as the datastore, the search space is limited to target\ntokens corresponding to the previously selected reference source tokens. This\nstrategy avoids search through the whole datastore for nearest neighbors and\ndrastically improves decoding efficiency. Without loss of performance, Fast\n$k$NN-MT is two-orders faster than $k$NN-MT, and is only two times slower than\nthe standard NMT model. Fast $k$NN-MT enables the practical use of $k$NN-MT\nsystems in real-world MT applications. The code is available at\n\\url{https://github.com/ShannonAI/fast-knn-nmt}", "published": "2021-05-30 13:10:32", "link": "http://arxiv.org/abs/2105.14528v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Defending Pre-trained Language Models from Adversarial Word\n  Substitutions Without Performance Sacrifice", "abstract": "Pre-trained contextualized language models (PrLMs) have led to strong\nperformance gains in downstream natural language understanding tasks. However,\nPrLMs can still be easily fooled by adversarial word substitution, which is one\nof the most challenging textual adversarial attack methods. Existing defence\napproaches suffer from notable performance loss and complexities. Thus, this\npaper presents a compact and performance-preserved framework, Anomaly Detection\nwith Frequency-Aware Randomization (ADFAR). In detail, we design an auxiliary\nanomaly detection classifier and adopt a multi-task learning procedure, by\nwhich PrLMs are able to distinguish adversarial input samples. Then, in order\nto defend adversarial word substitution, a frequency-aware randomization\nprocess is applied to those recognized adversarial input samples. Empirical\nresults show that ADFAR significantly outperforms those newly proposed defense\nmethods over various tasks with much higher inference speed. Remarkably, ADFAR\ndoes not impair the overall performance of PrLMs. The code is available at\nhttps://github.com/LilyNLP/ADFAR", "published": "2021-05-30 14:24:53", "link": "http://arxiv.org/abs/2105.14553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HIT: A Hierarchically Fused Deep Attention Network for Robust Code-mixed\n  Language Representation", "abstract": "Understanding linguistics and morphology of resource-scarce code-mixed texts\nremains a key challenge in text processing. Although word embedding comes in\nhandy to support downstream tasks for low-resource languages, there are plenty\nof scopes in improving the quality of language representation particularly for\ncode-mixed languages. In this paper, we propose HIT, a robust representation\nlearning method for code-mixed texts. HIT is a hierarchical transformer-based\nframework that captures the semantic relationship among words and\nhierarchically learns the sentence-level semantics using a fused attention\nmechanism. HIT incorporates two attention modules, a multi-headed\nself-attention and an outer product attention module, and computes their\nweighted sum to obtain the attention weights. Our evaluation of HIT on one\nEuropean (Spanish) and five Indic (Hindi, Bengali, Tamil, Telugu, and\nMalayalam) languages across four NLP tasks on eleven datasets suggests\nsignificant performance improvement against various state-of-the-art systems.\nWe further show the adaptability of learned representation across tasks in a\ntransfer learning setup (with and without fine-tuning).", "published": "2021-05-30 18:53:33", "link": "http://arxiv.org/abs/2105.14600v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Models for Offensive Language Detection", "abstract": "Offensive language detection is an ever-growing natural language processing\n(NLP) application. This growth is mainly because of the widespread usage of\nsocial networks, which becomes a mainstream channel for people to communicate,\nwork, and enjoy entertainment content. Many incidents of sharing aggressive and\noffensive content negatively impacted society to a great extend. We believe\ncontributing to improving and comparing different machine learning models to\nfight such harmful contents is an important and challenging goal for this\nthesis. We targeted the problem of offensive language detection for building\nefficient automated models for offensive language detection. With the recent\nadvancements of NLP models, specifically, the Transformer model, which tackled\nmany shortcomings of the standard seq-to-seq techniques. The BERT model has\nshown state-of-the-art results on many NLP tasks. Although the literature still\nexploring the reasons for the BERT achievements in the NLP field. Other\nefficient variants have been developed to improve upon the standard BERT, such\nas RoBERTa and ALBERT. Moreover, due to the multilingual nature of text on\nsocial media that could affect the model decision on a given tween, it is\nbecoming essential to examine multilingual models such as XLM-RoBERTa trained\non 100 languages and how did it compare to unilingual models. The RoBERTa based\nmodel proved to be the most capable model and achieved the highest F1 score for\nthe tasks. Another critical aspect of a well-rounded offensive language\ndetection system is the speed at which a model can be trained and make\ninferences. In that respect, we have considered the model run-time and\nfine-tuned the very efficient implementation of FastText called BlazingText\nthat achieved good results, which is much faster than BERT-based models.", "published": "2021-05-30 13:02:45", "link": "http://arxiv.org/abs/2106.14609v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Good for Misconceived Reasons: An Empirical Revisiting on the Need for\n  Visual Context in Multimodal Machine Translation", "abstract": "A neural multimodal machine translation (MMT) system is one that aims to\nperform better translation by extending conventional text-only translation\nmodels with multimodal information. Many recent studies report improvements\nwhen equipping their models with the multimodal module, despite the controversy\nof whether such improvements indeed come from the multimodal part. We revisit\nthe contribution of multimodal information in MMT by devising two interpretable\nMMT models. To our surprise, although our models replicate similar gains as\nrecently developed multimodal-integrated systems achieved, our models learn to\nignore the multimodal information. Upon further investigation, we discover that\nthe improvements achieved by the multimodal models over text-only counterparts\nare in fact results of the regularization effect. We report empirical findings\nthat highlight the importance of MMT models' interpretability, and discuss how\nour findings will benefit future research.", "published": "2021-05-30 08:27:16", "link": "http://arxiv.org/abs/2105.14462v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Determining the Credibility of Science Communication", "abstract": "Most work on scholarly document processing assumes that the information\nprocessed is trustworthy and factually correct. However, this is not always the\ncase. There are two core challenges, which should be addressed: 1) ensuring\nthat scientific publications are credible -- e.g. that claims are not made\nwithout supporting evidence, and that all relevant supporting evidence is\nprovided; and 2) that scientific findings are not misrepresented, distorted or\noutright misreported when communicated by journalists or the general public. I\nwill present some first steps towards addressing these problems and outline\nremaining challenges.", "published": "2021-05-30 09:16:11", "link": "http://arxiv.org/abs/2105.14473v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Pre-training Universal Language Representation", "abstract": "Despite the well-developed cut-edge representation learning for language,\nmost language representation models usually focus on specific levels of\nlinguistic units. This work introduces universal language representation\nlearning, i.e., embeddings of different levels of linguistic units or text with\nquite diverse lengths in a uniform vector space. We propose the training\nobjective MiSAD that utilizes meaningful n-grams extracted from large unlabeled\ncorpus by a simple but effective algorithm for pre-trained language models.\nThen we empirically verify that well designed pre-training scheme may\neffectively yield universal language representation, which will bring great\nconvenience when handling multiple layers of linguistic objects in a unified\nway. Especially, our model achieves the highest accuracy on analogy tasks in\ndifferent language levels and significantly improves the performance on\ndownstream tasks in the GLUE benchmark and a question answering dataset.", "published": "2021-05-30 09:29:01", "link": "http://arxiv.org/abs/2105.14478v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diversifying Dialog Generation via Adaptive Label Smoothing", "abstract": "Neural dialogue generation models trained with the one-hot target\ndistribution suffer from the over-confidence issue, which leads to poor\ngeneration diversity as widely reported in the literature. Although existing\napproaches such as label smoothing can alleviate this issue, they fail to adapt\nto diverse dialog contexts. In this paper, we propose an Adaptive Label\nSmoothing (AdaLabel) approach that can adaptively estimate a target label\ndistribution at each time step for different contexts. The maximum probability\nin the predicted distribution is used to modify the soft target distribution\nproduced by a novel light-weight bi-directional decoder module. The resulting\ntarget distribution is aware of both previous and future contexts and is\nadjusted to avoid over-training the dialogue model. Our model can be trained in\nan end-to-end manner. Extensive experiments on two benchmark datasets show that\nour approach outperforms various competitive baselines in producing diverse\nresponses.", "published": "2021-05-30 14:41:09", "link": "http://arxiv.org/abs/2105.14556v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LEAP: Learnable Pruning for Transformer-based Models", "abstract": "Pruning is an effective method to reduce the memory footprint and\ncomputational cost associated with large natural language processing models.\nHowever, current pruning algorithms either only focus on one pruning category,\ne.g., structured pruning and unstructured, or need extensive hyperparameter\ntuning in order to get reasonable accuracy performance. To address these\nchallenges, we propose LEArnable Pruning (LEAP), an effective method to\ngradually prune the model based on thresholds learned by gradient descent.\nDifferent than previous learnable pruning methods, which utilize $L_0$ or $L_1$\npenalty to indirectly affect the final pruning ratio, LEAP introduces a novel\nregularization function, that directly interacts with the preset target pruning\nratio. Moreover, in order to reduce hyperparameter tuning, a novel adaptive\nregularization coefficient is deployed to control the regularization penalty\nadaptively. With the new regularization term and its associated adaptive\nregularization coefficient, LEAP is able to be applied for different pruning\ngranularity, including unstructured pruning, structured pruning, and hybrid\npruning, with minimal hyperparameter tuning. We apply LEAP for BERT models on\nQQP/MNLI/SQuAD for different pruning settings. Our result shows that for all\ndatasets, pruning granularity, and pruning ratios, LEAP achieves on-par or\nbetter results as compared to previous heavily hand-tuned methods.", "published": "2021-05-30 22:00:44", "link": "http://arxiv.org/abs/2105.14636v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Domain-Specialised Representations for Cross-Lingual Biomedical\n  Entity Linking", "abstract": "Injecting external domain-specific knowledge (e.g., UMLS) into pretrained\nlanguage models (LMs) advances their capability to handle specialised in-domain\ntasks such as biomedical entity linking (BEL). However, such abundant expert\nknowledge is available only for a handful of languages (e.g., English). In this\nwork, by proposing a novel cross-lingual biomedical entity linking task\n(XL-BEL) and establishing a new XL-BEL benchmark spanning 10 typologically\ndiverse languages, we first investigate the ability of standard\nknowledge-agnostic as well as knowledge-enhanced monolingual and multilingual\nLMs beyond the standard monolingual English BEL task. The scores indicate large\ngaps to English performance. We then address the challenge of transferring\ndomain-specific knowledge in resource-rich languages to resource-poor ones. To\nthis end, we propose and evaluate a series of cross-lingual transfer methods\nfor the XL-BEL task, and demonstrate that general-domain bitext helps propagate\nthe available English knowledge to languages with little to no in-domain data.\nRemarkably, we show that our proposed domain-specific transfer methods yield\nconsistent gains across all target languages, sometimes up to 20 Precision@1\npoints, without any in-domain knowledge in the target language, and without any\nin-domain parallel data.", "published": "2021-05-30 00:50:00", "link": "http://arxiv.org/abs/2105.14398v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Re-evaluating Word Mover's Distance", "abstract": "The word mover's distance (WMD) is a fundamental technique for measuring the\nsimilarity of two documents. As the crux of WMD, it can take advantage of the\nunderlying geometry of the word space by employing an optimal transport\nformulation. The original study on WMD reported that WMD outperforms classical\nbaselines such as bag-of-words (BOW) and TF-IDF by significant margins in\nvarious datasets. In this paper, we point out that the evaluation in the\noriginal study could be misleading. We re-evaluate the performances of WMD and\nthe classical baselines and find that the classical baselines are competitive\nwith WMD if we employ an appropriate preprocessing, i.e., L1 normalization. In\naddition, we introduce an analogy between WMD and L1-normalized BOW and find\nthat not only the performance of WMD but also the distance values resemble\nthose of BOW in high dimensional spaces.", "published": "2021-05-30 01:35:03", "link": "http://arxiv.org/abs/2105.14403v3", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural\n  Architecture Search", "abstract": "While pre-trained language models (e.g., BERT) have achieved impressive\nresults on different natural language processing tasks, they have large numbers\nof parameters and suffer from big computational and memory costs, which make\nthem difficult for real-world deployment. Therefore, model compression is\nnecessary to reduce the computation and memory cost of pre-trained models. In\nthis work, we aim to compress BERT and address the following two challenging\npractical issues: (1) The compression algorithm should be able to output\nmultiple compressed models with different sizes and latencies, in order to\nsupport devices with different memory and latency limitations; (2) The\nalgorithm should be downstream task agnostic, so that the compressed models are\ngenerally applicable for different downstream tasks. We leverage techniques in\nneural architecture search (NAS) and propose NAS-BERT, an efficient method for\nBERT compression. NAS-BERT trains a big supernet on a search space containing a\nvariety of architectures and outputs multiple compressed models with adaptive\nsizes and latency. Furthermore, the training of NAS-BERT is conducted on\nstandard self-supervised pre-training tasks (e.g., masked language model) and\ndoes not depend on specific downstream tasks. Thus, the compressed models can\nbe used across various downstream tasks. The technical challenge of NAS-BERT is\nthat training a big supernet on the pre-training task is extremely costly. We\nemploy several techniques including block-wise search, search space pruning,\nand performance approximation to improve search efficiency and accuracy.\nExtensive experiments on GLUE and SQuAD benchmark datasets demonstrate that\nNAS-BERT can find lightweight models with better accuracy than previous\napproaches, and can be directly applied to different downstream tasks with\nadaptive model sizes for different requirements of memory or latency.", "published": "2021-05-30 07:20:27", "link": "http://arxiv.org/abs/2105.14444v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Longer Version for \"Deep Context-Encoding Network for Retinal Image\n  Captioning\"", "abstract": "Automatically generating medical reports for retinal images is one of the\npromising ways to help ophthalmologists reduce their workload and improve work\nefficiency. In this work, we propose a new context-driven encoding network to\nautomatically generate medical reports for retinal images. The proposed model\nis mainly composed of a multi-modal input encoder and a fused-feature decoder.\nOur experimental results show that our proposed method is capable of\neffectively leveraging the interactive information between the input image and\ncontext, i.e., keywords in our case. The proposed method creates more accurate\nand meaningful reports for retinal images than baseline models and achieves\nstate-of-the-art performance. This performance is shown in several commonly\nused metrics for the medical report generation task: BLEU-avg (+16%), CIDEr\n(+10.2%), and ROUGE (+8.6%).", "published": "2021-05-30 13:37:03", "link": "http://arxiv.org/abs/2105.14538v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
