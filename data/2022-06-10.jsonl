{"title": "Ask to Know More: Generating Counterfactual Explanations for Fake Claims", "abstract": "Automated fact checking systems have been proposed that quickly provide\nveracity prediction at scale to mitigate the negative influence of fake news on\npeople and on public opinion. However, most studies focus on veracity\nclassifiers of those systems, which merely predict the truthfulness of news\narticles. We posit that effective fact checking also relies on people's\nunderstanding of the predictions. In this paper, we propose elucidating fact\nchecking predictions using counterfactual explanations to help people\nunderstand why a specific piece of news was identified as fake. In this work,\ngenerating counterfactual explanations for fake news involves three steps:\nasking good questions, finding contradictions, and reasoning appropriately. We\nframe this research question as contradicted entailment reasoning through\nquestion answering (QA). We first ask questions towards the false claim and\nretrieve potential answers from the relevant evidence documents. Then, we\nidentify the most contradictory answer to the false claim by use of an\nentailment classifier. Finally, a counterfactual explanation is created using a\nmatched QA pair with three different counterfactual explanation forms.\nExperiments are conducted on the FEVER dataset for both system and human\nevaluations. Results suggest that the proposed approach generates the most\nhelpful explanations compared to state-of-the-art methods.", "published": "2022-06-10 04:42:00", "link": "http://arxiv.org/abs/2206.04869v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RuCoCo: a new Russian corpus with coreference annotation", "abstract": "We present a new corpus with coreference annotation, Russian Coreference\nCorpus (RuCoCo). The goal of RuCoCo is to obtain a large number of annotated\ntexts while maintaining high inter-annotator agreement. RuCoCo contains news\ntexts in Russian, part of which were annotated from scratch, and for the rest\nthe machine-generated annotations were refined by human annotators. The size of\nour corpus is one million words and around 150,000 mentions. We make the corpus\npublicly available.", "published": "2022-06-10 07:50:09", "link": "http://arxiv.org/abs/2206.04925v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sort by Structure: Language Model Ranking as Dependency Probing", "abstract": "Making an informed choice of pre-trained language model (LM) is critical for\nperformance, yet environmentally costly, and as such widely underexplored. The\nfield of Computer Vision has begun to tackle encoder ranking, with promising\nforays into Natural Language Processing, however they lack coverage of\nlinguistic tasks such as structured prediction. We propose probing to rank LMs,\nspecifically for parsing dependencies in a given language, by measuring the\ndegree to which labeled trees are recoverable from an LM's contextualized\nembeddings. Across 46 typologically and architecturally diverse LM-language\npairs, our probing approach predicts the best LM choice 79% of the time using\norders of magnitude less compute than training a full parser. Within this\nstudy, we identify and analyze one recently proposed decoupled LM - RemBERT -\nand find it strikingly contains less inherent dependency information, but often\nyields the best parser after full fine-tuning. Without this outlier our\napproach identifies the best LM in 89% of cases.", "published": "2022-06-10 08:10:29", "link": "http://arxiv.org/abs/2206.04935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generate, Evaluate, and Select: A Dialogue System with a Response\n  Evaluator for Diversity-Aware Response Generation", "abstract": "We aim to overcome the lack of diversity in responses of current dialogue\nsystems and to develop a dialogue system that is engaging as a conversational\npartner. We propose a generator-evaluator model that evaluates multiple\nresponses generated by a response generator and selects the best response by an\nevaluator. By generating multiple responses, we obtain diverse responses. We\nconduct human evaluations to compare the output of the proposed system with\nthat of a baseline system. The results of the human evaluations showed that the\nproposed system's responses were often judged to be better than the baseline\nsystem's, and indicated the effectiveness of the proposed method.", "published": "2022-06-10 08:22:22", "link": "http://arxiv.org/abs/2206.04937v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Borrowing or Codeswitching? Annotating for Finer-Grained Distinctions in\n  Language Mixing", "abstract": "We present a new corpus of Twitter data annotated for codeswitching and\nborrowing between Spanish and English. The corpus contains 9,500 tweets\nannotated at the token level with codeswitches, borrowings, and named entities.\nThis corpus differs from prior corpora of codeswitching in that we attempt to\nclearly define and annotate the boundary between codeswitching and borrowing\nand do not treat common \"internet-speak\" ('lol', etc.) as codeswitching when\nused in an otherwise monolingual context. The result is a corpus that enables\nthe study and modeling of Spanish-English borrowing and codeswitching on\nTwitter in one dataset. We present baseline scores for modeling the labels of\nthis corpus using Transformer-based language models. The annotation itself is\nreleased with a CC BY 4.0 license, while the text it applies to is distributed\nin compliance with the Twitter terms of service.", "published": "2022-06-10 10:06:57", "link": "http://arxiv.org/abs/2206.04973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised and Few-shot Parsing from Pretrained Language Models", "abstract": "Pretrained language models are generally acknowledged to be able to encode\nsyntax [Tenney et al., 2019, Jawahar et al., 2019, Hewitt and Manning, 2019].\nIn this article, we propose UPOA, an Unsupervised constituent Parsing model\nthat calculates an Out Association score solely based on the self-attention\nweight matrix learned in a pretrained language model as the syntactic distance\nfor span segmentation. We further propose an enhanced version, UPIO, which\nexploits both inside association and outside association scores for estimating\nthe likelihood of a span. Experiments with UPOA and UPIO disclose that the\nlinear projection matrices for the query and key in the self-attention\nmechanism play an important role in parsing. We therefore extend the\nunsupervised models to few-shot parsing models (FPOA, FPIO) that use a few\nannotated trees to learn better linear projection matrices for parsing.\nExperiments on the Penn Treebank demonstrate that our unsupervised parsing\nmodel UPIO achieves results comparable to the state of the art on short\nsentences (length <= 10). Our few-shot parsing model FPIO trained with only 20\nannotated trees outperforms a previous few-shot parsing method trained with 50\nannotated trees. Experiments on cross-lingual parsing show that both\nunsupervised and few-shot parsing methods are better than previous methods on\nmost languages of SPMRL [Seddah et al., 2013].", "published": "2022-06-10 10:29:15", "link": "http://arxiv.org/abs/2206.04980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building an Icelandic Entity Linking Corpus", "abstract": "In this paper, we present the first Entity Linking corpus for Icelandic. We\ndescribe our approach of using a multilingual entity linking model (mGENRE) in\ncombination with Wikipedia API Search (WAPIS) to label our data and compare it\nto an approach using WAPIS only. We find that our combined method reaches 53.9%\ncoverage on our corpus, compared to 30.9% using only WAPIS. We analyze our\nresults and explain the value of using a multilingual system when working with\nIcelandic. Additionally, we analyze the data that remain unlabeled, identify\npatterns and discuss why they may be more difficult to annotate.", "published": "2022-06-10 12:01:57", "link": "http://arxiv.org/abs/2206.05014v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment analysis on electricity twitter posts", "abstract": "In today's world, everyone is expressive in some way, and the focus of this\nproject is on people's opinions about rising electricity prices in United\nKingdom and India using data from Twitter, a micro-blogging platform on which\npeople post messages, known as tweets. Because many people's incomes are not\ngood and they have to pay so many taxes and bills, maintaining a home has\nbecome a disputed issue these days. Despite the fact that Government offered\nsubsidy schemes to compensate people electricity bills but it is not welcomed\nby people. In this project, the aim is to perform sentiment analysis on\npeople's expressions and opinions expressed on Twitter. In order to grasp the\nelectricity prices opinion, it is necessary to carry out sentiment analysis for\nthe government and consumers in energy market. Furthermore, text present on\nthese medias are unstructured in nature, so to process them we firstly need to\npre-process the data. There are so many feature extraction techniques such as\nBag of Words, TF-IDF (Term Frequency-Inverse Document Frequency), word\nembedding, NLP based features like word count. In this project, we analysed the\nimpact of feature TF-IDF word level on electricity bills dataset of sentiment\nanalysis. We found that by using TF-IDF word level performance of sentiment\nanalysis is 3-4 higher than using N-gram features. Analysis is done using four\nclassification algorithms including Naive Bayes, Decision Tree, Random Forest,\nand Logistic Regression and considering F-Score, Accuracy, Precision, and\nRecall performance parameters.", "published": "2022-06-10 12:31:56", "link": "http://arxiv.org/abs/2206.05042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2\n  Language Learning", "abstract": "One of the challenges of language teaching is how to organize the rules\nregarding syntax, semantics, or phonology of the language in a meaningful\nmanner. This not only requires pedagogical skills, but also requires a deep\nunderstanding of that language. While comprehensive materials to develop such\ncurricula are available in English and some broadly spoken languages, for many\nother languages, teachers need to manually create them in response to their\nstudents' needs. This process is challenging because i) it requires that such\nexperts be accessible and have the necessary resources, and ii) even if there\nare such experts, describing all the intricacies of a language is\ntime-consuming and prone to omission. In this article, we present an automatic\nframework that aims to facilitate this process by automatically discovering and\nvisualizing descriptions of different aspects of grammar. Specifically, we\nextract descriptions from a natural text corpus that answer questions about\nmorphosyntax (learning of word order, agreement, case marking, or word\nformation) and semantics (learning of vocabulary) and show illustrative\nexamples. We apply this method for teaching the Indian languages, Kannada and\nMarathi, which, unlike English, do not have well-developed pedagogical\nresources and, therefore, are likely to benefit from this exercise. To assess\nthe perceived utility of the extracted material, we enlist the help of language\neducators from schools in North America who teach these languages to perform a\nmanual evaluation. Overall, teachers find the materials to be interesting as a\nreference material for their own lesson preparation or even for learner\nevaluation.", "published": "2022-06-10 14:52:22", "link": "http://arxiv.org/abs/2206.05154v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nominal Metaphor Generation with Multitask Learning", "abstract": "Metaphor generation is a challenging task which can impact many downstream\ntasks such as improving user satisfaction with dialogue systems and story\ngeneration. This paper tackles the problem of Chinese nominal metaphor\ngeneration by introducing a multitask metaphor generation framework with\nself-training and metaphor identification mechanisms. Self-training addresses\nthe data scarcity issue of metaphor datasets. That is, instead of solely\nrelying on labelled metaphor datasets which are usually small in size,\nself-training helps identify potential metaphors from a large-scale unlabelled\ncorpus for metaphor generation. The metaphor weighting mechanism enables our\nmodel to focus on the metaphor-related parts of the input (e.g., the comparison\nof the metaphor and comparator) during model learning and thus improves the\nmetaphoricity of the generated metaphors. Our model is trained on an annotated\ncorpus consisting of 6.3k sentences that contain diverse metaphorical\nexpressions. Experimental results show that our model is able to generate\nmetaphors with better readability and creativity compared to the baseline\nmodels, even in the situation where training data is insufficient.", "published": "2022-06-10 15:53:55", "link": "http://arxiv.org/abs/2206.05195v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus\n  Creation, Annotation Reliability, and Prediction", "abstract": "The most prominent tasks in emotion analysis are to assign emotions to texts\nand to understand how emotions manifest in language. An observation for NLP is\nthat emotions can be communicated implicitly by referring to events, appealing\nto an empathetic, intersubjective understanding of events, even without\nexplicitly mentioning an emotion name. In psychology, the class of emotion\ntheories known as appraisal theories aims at explaining the link between events\nand emotions. Appraisals can be formalized as variables that measure a\ncognitive evaluation by people living through an event that they consider\nrelevant. They include the assessment if an event is novel, if the person\nconsiders themselves to be responsible, if it is in line with the own goals,\nand many others. Such appraisals explain which emotions are developed based on\nan event, e.g., that a novel situation can induce surprise or one with\nuncertain consequences could evoke fear. We analyze the suitability of\nappraisal theories for emotion analysis in text with the goal of understanding\nif appraisal concepts can reliably be reconstructed by annotators, if they can\nbe predicted by text classifiers, and if appraisal concepts help to identify\nemotion categories. To achieve that, we compile a corpus by asking people to\ntextually describe events that triggered particular emotions and to disclose\ntheir appraisals. Then, we ask readers to reconstruct emotions and appraisals\nfrom the text. This setup allows us to measure if emotions and appraisals can\nbe recovered purely from text and provides a human baseline. Our comparison of\ntext classification methods to human annotators shows that both can reliably\ndetect emotions and appraisals with similar performance. Therefore, appraisals\nconstitute an alternative computational emotion analysis paradigm and further\nimprove the categorization of emotions in text with joint models.", "published": "2022-06-10 17:20:17", "link": "http://arxiv.org/abs/2206.05238v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Label Noise-Resistant Mean Teaching for Weakly Supervised Fake News\n  Detection", "abstract": "Fake news spreads at an unprecedented speed, reaches global audiences and\nposes huge risks to users and communities. Most existing fake news detection\nalgorithms focus on building supervised training models on a large amount of\nmanually labeled data, which is expensive to acquire or often unavailable. In\nthis work, we propose a novel label noise-resistant mean teaching approach\n(LNMT) for weakly supervised fake news detection. LNMT leverages unlabeled news\nand feedback comments of users to enlarge the amount of training data and\nfacilitates model training by generating refined labels as weak supervision.\nSpecifically, LNMT automatically assigns initial weak labels to unlabeled\nsamples based on semantic correlation and emotional association between news\ncontent and the comments. Moreover, in order to suppress the noises in weak\nlabels, LNMT establishes a mean teacher framework equipped with label\npropagation and label reliability estimation. The framework measures a weak\nlabel similarity matrix between the teacher and student networks, and\npropagates different valuable weak label information to refine the weak labels.\nMeanwhile, it exploits the consistency between the output class likelihood\nvectors of the two networks to evaluate the reliability of the weak labels and\nincorporates the reliability into model optimization to alleviate the negative\neffect of noisy weak labels. Extensive experiments show the superior\nperformance of LNMT.", "published": "2022-06-10 16:01:58", "link": "http://arxiv.org/abs/2206.12260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Sentence Simplification via Dependency Parsing", "abstract": "Text simplification is the task of rewriting a text so that it is readable\nand easily understood. In this paper, we propose a simple yet novel\nunsupervised sentence simplification system that harnesses parsing structures\ntogether with sentence embeddings to produce linguistically effective\nsimplifications. This means our model is capable of introducing substantial\nmodifications to simplify a sentence while maintaining its original semantics\nand adequate fluency. We establish the unsupervised state-of-the-art at 39.13\nSARI on TurkCorpus set and perform competitively against supervised baselines\non various quality metrics. Furthermore, we demonstrate our framework's\nextensibility to other languages via a proof-of-concept on Vietnamese data.\nCode for reproduction is published at \\url{https://github.com/isVy08/USDP}.", "published": "2022-06-10 07:55:25", "link": "http://arxiv.org/abs/2206.12261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emoji-based Fine-grained Attention Network for Sentiment Analysis in the\n  Microblog Comments", "abstract": "Microblogs have become a social platform for people to express their emotions\nin real-time, and it is a trend to analyze user emotional tendencies from the\ninformation on Microblogs. The dynamic features of emojis can affect the\nsentiment polarity of microblog texts. Since existing models seldom consider\nthe diversity of emoji sentiment polarity,the paper propose a microblog\nsentiment classification model based on ALBERT-FAET. We obtain text embedding\nvia ALBERT pretraining model and learn the inter-emoji embedding with an\nattention-based LSTM network. In addition, a fine-grained attention mechanism\nis proposed to capture the word-level interactions between plain text and\nemoji. Finally, we concatenate these features and feed them into a CNN\nclassifier to predict the sentiment labels of the microblogs. To verify the\neffectiveness of the model and the fine-grained attention network, we conduct\ncomparison experiments and ablation experiments. The comparison experiments\nshow that the model outperforms previous methods in three evaluation indicators\n(accuracy, precision, and recall) and the model can significantly improve\nsentiment classification. The ablation experiments show that compared with\nALBERT-AET, the proposed model ALBERT-FAET is better in the metrics, indicating\nthat the fine-grained attention network can understand the diversified\ninformation of emoticons.", "published": "2022-06-10 04:24:48", "link": "http://arxiv.org/abs/2206.12262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction", "abstract": "Relation extraction is an important but challenging task that aims to extract\nall hidden relational facts from the text. With the development of deep\nlanguage models, relation extraction methods have achieved good performance on\nvarious benchmarks. However, we observe two shortcomings of previous methods:\nfirst, there is no unified framework that works well under various relation\nextraction settings; second, effectively utilizing external knowledge as\nbackground information is absent. In this work, we propose a knowledge-enhanced\ngenerative model to mitigate these two issues. Our generative model is a\nunified framework to sequentially generate relational triplets under various\nrelation extraction settings and explicitly utilizes relevant knowledge from\nKnowledge Graph (KG) to resolve ambiguities. Our model achieves superior\nperformance on multiple benchmarks and settings, including WebNLG, NYT10, and\nTACRED.", "published": "2022-06-10 13:59:38", "link": "http://arxiv.org/abs/2206.05123v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Multi-Task Benchmark for Korean Legal Language Understanding and\n  Judgement Prediction", "abstract": "The recent advances of deep learning have dramatically changed how machine\nlearning, especially in the domain of natural language processing, can be\napplied to legal domain. However, this shift to the data-driven approaches\ncalls for larger and more diverse datasets, which are nevertheless still small\nin number, especially in non-English languages. Here we present the first\nlarge-scale benchmark of Korean legal AI datasets, LBOX OPEN, that consists of\none legal corpus, two classification tasks, two legal judgement prediction\n(LJP) tasks, and one summarization task. The legal corpus consists of 147k\nKorean precedents (259M tokens), of which 63k are sentenced in last 4 years and\n96k are from the first and the second level courts in which factual issues are\nreviewed. The two classification tasks are case names (11.3k) and statutes\n(2.8k) prediction from the factual description of individual cases. The LJP\ntasks consist of (1) 10.5k criminal examples where the model is asked to\npredict fine amount, imprisonment with labor, and imprisonment without labor\nranges for the given facts, and (2) 4.7k civil examples where the inputs are\nfacts and claim for relief and outputs are the degrees of claim acceptance. The\nsummarization task consists of the Supreme Court precedents and the\ncorresponding summaries (20k). We also release realistic variants of the\ndatasets by extending the domain (1) to infrequent case categories in case name\n(31k examples) and statute (17.7k) classification tasks, and (2) to long input\nsequences in the summarization task (51k). Finally, we release LCUBE, the first\nKorean legal language model trained on the legal corpus from this study. Given\nthe uniqueness of the Law of South Korea and the diversity of the legal tasks\ncovered in this work, we believe that LBOX OPEN contributes to the\nmultilinguality of global legal research. LBOX OPEN and LCUBE will be publicly\navailable.", "published": "2022-06-10 16:51:45", "link": "http://arxiv.org/abs/2206.05224v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph-in-Graph Network for Automatic Gene Ontology Description\n  Generation", "abstract": "Gene Ontology (GO) is the primary gene function knowledge base that enables\ncomputational tasks in biomedicine. The basic element of GO is a term, which\nincludes a set of genes with the same function. Existing research efforts of GO\nmainly focus on predicting gene term associations. Other tasks, such as\ngenerating descriptions of new terms, are rarely pursued. In this paper, we\npropose a novel task: GO term description generation. This task aims to\nautomatically generate a sentence that describes the function of a GO term\nbelonging to one of the three categories, i.e., molecular function, biological\nprocess, and cellular component. To address this task, we propose a\nGraph-in-Graph network that can efficiently leverage the structural information\nof GO. The proposed network introduces a two-layer graph: the first layer is a\ngraph of GO terms where each node is also a graph (gene graph). Such a\nGraph-in-Graph network can derive the biological functions of GO terms and\ngenerate proper descriptions. To validate the effectiveness of the proposed\nnetwork, we build three large-scale benchmark datasets. By incorporating the\nproposed Graph-in-Graph network, the performances of seven different\nsequence-to-sequence models can be substantially boosted across all evaluation\nmetrics, with up to 34.7%, 14.5%, and 39.1% relative improvements in BLEU,\nROUGE-L, and METEOR, respectively.", "published": "2022-06-10 18:17:17", "link": "http://arxiv.org/abs/2206.05311v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Cross-TOP: Zero-Shot Cross-Schema Task-Oriented Parsing", "abstract": "Deep learning methods have enabled task-oriented semantic parsing of\nincreasingly complex utterances. However, a single model is still typically\ntrained and deployed for each task separately, requiring labeled training data\nfor each, which makes it challenging to support new tasks, even within a single\nbusiness vertical (e.g., food-ordering or travel booking). In this paper we\ndescribe Cross-TOP (Cross-Schema Task-Oriented Parsing), a zero-shot method for\ncomplex semantic parsing in a given vertical. By leveraging the fact that user\nrequests from the same vertical share lexical and semantic similarities, a\nsingle cross-schema parser is trained to service an arbitrary number of tasks,\nseen or unseen, within a vertical. We show that Cross-TOP can achieve high\naccuracy on a previously unseen task without requiring any additional training\ndata, thereby providing a scalable way to bootstrap semantic parsers for new\ntasks. As part of this work we release the FoodOrdering dataset, a\ntask-oriented parsing dataset in the food-ordering vertical, with utterances\nand annotations derived from five schemas, each from a different restaurant\nmenu.", "published": "2022-06-10 20:50:08", "link": "http://arxiv.org/abs/2206.05352v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural\n  Machine Translation", "abstract": "Chinese dialects are different variations of Chinese and can be considered as\ndifferent languages in the same language family with Mandarin. Though they all\nuse Chinese characters, the pronunciations, grammar and idioms can vary\nsignificantly, and even local speakers may find it hard to input correct\nwritten forms of dialect. Besides, using Mandarin text as text-to-speech inputs\nwould generate speech with poor naturalness. In this paper, we propose a novel\nChinese dialect TTS frontend with a translation module, which converts Mandarin\ntext into dialectic expressions to improve the intelligibility and naturalness\nof synthesized speech. A non-autoregressive neural machine translation model\nwith various tricks is proposed for the translation task. It is the first known\nwork to incorporate translation with TTS frontend. Experiments on Cantonese\nshow the proposed model improves 2.56 BLEU and TTS improves 0.27 MOS with\nMandarin inputs.", "published": "2022-06-10 07:46:34", "link": "http://arxiv.org/abs/2206.04922v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Going Beyond the Cookie Theft Picture Test: Detecting Cognitive\n  Impairments using Acoustic Features", "abstract": "Standardized tests play a crucial role in the detection of cognitive\nimpairment. Previous work demonstrated that automatic detection of cognitive\nimpairment is possible using audio data from a standardized picture description\ntask. The presented study goes beyond that, evaluating our methods on data\ntaken from two standardized neuropsychological tests, namely the German SKT and\na German version of the CERAD-NB, and a semi-structured clinical interview\nbetween a patient and a psychologist. For the tests, we focus on speech\nrecordings of three sub-tests: reading numbers (SKT 3), interference (SKT 7),\nand verbal fluency (CERAD-NB 1). We show that acoustic features from\nstandardized tests can be used to reliably discriminate cognitively impaired\nindividuals from non-impaired ones. Furthermore, we provide evidence that even\nfeatures extracted from random speech samples of the interview can be a\ndiscriminator of cognitive impairment. In our baseline experiments, we use\nOpenSMILE features and Support Vector Machine classifiers. In an improved\nsetup, we show that using wav2vec 2.0 features instead, we can achieve an\naccuracy of up to 85%.", "published": "2022-06-10 12:04:22", "link": "http://arxiv.org/abs/2206.05018v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model", "abstract": "Current architectures for multi-modality tasks such as visual question\nanswering suffer from their high complexity. As a result, these architectures\nare difficult to train and require high computational resources. To address\nthese problems we present a CLIP-based architecture that does not require any\nfine-tuning of the feature extractors. A simple linear classifier is used on\nthe concatenated features of the image and text encoder. During training an\nauxiliary loss is added which operates on the answer types. The resulting\nclassification is then used as an attention gate on the answer class selection.\nOn the VizWiz 2022 Visual Question Answering Challenge we achieve 60.15 %\naccuracy on Task 1: Predict Answer to a Visual Question and AP score of 83.78 %\non Task 2: Predict Answerability of a Visual Question.", "published": "2022-06-10 07:03:52", "link": "http://arxiv.org/abs/2206.05281v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AHD ConvNet for Speech Emotion Classification", "abstract": "Accomplishments in the field of artificial intelligence are utilized in the\nadvancement of computing and making of intelligent machines for facilitating\nmankind and improving user experience. Emotions are rudimentary for people,\naffecting thinking and ordinary exercises like correspondence, learning and\ndirection. Speech emotion recognition is domain of interest in this regard and\nin this work, we propose a novel mel spectrogram learning approach in which our\nmodel uses the datapoints to learn emotions from the given wav form voice notes\nin the popular CREMA-D dataset. Our model uses log mel-spectrogram as feature\nwith number of mels = 64. It took less training time compared to other\napproaches used to address the problem of emotion speech recognition.", "published": "2022-06-10 11:57:28", "link": "http://arxiv.org/abs/2206.05286v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Putting GPT-3's Creativity to the (Alternative Uses) Test", "abstract": "AI large language models have (co-)produced amazing written works from\nnewspaper articles to novels and poetry. These works meet the standards of the\nstandard definition of creativity: being original and useful, and sometimes\neven the additional element of surprise. But can a large language model\ndesigned to predict the next text fragment provide creative, out-of-the-box,\nresponses that still solve the problem at hand? We put Open AI's generative\nnatural language model, GPT-3, to the test. Can it provide creative solutions\nto one of the most commonly used tests in creativity research? We assessed\nGPT-3's creativity on Guilford's Alternative Uses Test and compared its\nperformance to previously collected human responses on expert ratings of\noriginality, usefulness and surprise of responses, flexibility of each set of\nideas as well as an automated method to measure creativity based on the\nsemantic distance between a response and the AUT object in question. Our\nresults show that -- on the whole -- humans currently outperform GPT-3 when it\ncomes to creative output. But, we believe it is only a matter of time before\nGPT-3 catches up on this particular task. We discuss what this work reveals\nabout human and AI creativity, creativity testing and our definition of\ncreativity.", "published": "2022-06-10 15:36:45", "link": "http://arxiv.org/abs/2206.08932v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Feature-informed Embedding Space Regularization For Audio Classification", "abstract": "Feature representations derived from models pre-trained on large-scale\ndatasets have shown their generalizability on a variety of audio analysis\ntasks. Despite this generalizability, however, task-specific features can\noutperform if sufficient training data is available, as specific task-relevant\nproperties can be learned. Furthermore, the complex pre-trained models bring\nconsiderable computational burdens during inference. We propose to leverage\nboth detailed task-specific features from spectrogram input and generic\npre-trained features by introducing two regularization methods that integrate\nthe information of both feature classes. The workload is kept low during\ninference as the pre-trained features are only necessary for training. In\nexperiments with the pre-trained features VGGish, OpenL3, and a combination of\nboth, we show that the proposed methods not only outperform baseline methods,\nbut also can improve state-of-the-art models on several audio classification\ntasks. The results also suggest that using the mixture of features performs\nbetter than using individual features.", "published": "2022-06-10 02:51:59", "link": "http://arxiv.org/abs/2206.04850v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Feature Learning and Ensemble Pre-Tasks Based Self-Supervised Speech\n  Denoising and Dereverberation", "abstract": "Self-supervised learning (SSL) achieves great success in monaural speech\nenhancement, while the accuracy of the target speech estimation, particularly\nfor unseen speakers, remains inadequate with existing pre-tasks. As speech\nsignal contains multi-faceted information including speaker identity,\nparalinguistics, and spoken content, the latent representation for speech\nenhancement becomes a tough task. In this paper, we study the effectiveness of\neach feature which is commonly used in speech enhancement and exploit the\nfeature combination in the SSL case. Besides, we propose an ensemble training\nstrategy. The latent representation of the clean speech signal is learned,\nmeanwhile, the dereverberated mask and the estimated ratio mask are exploited\nto denoise and dereverberate the mixture. The latent representation learning\nand the masks estimation are considered as two pre-tasks in the training stage.\nIn addition, to study the effectiveness between the pre-tasks, we compare\ndifferent training routines to train the model and further refine the\nperformance. The NOISEX and DAPS corpora are used to evaluate the efficacy of\nthe proposed method, which also outperforms the state-of-the-art methods.", "published": "2022-06-10 09:22:10", "link": "http://arxiv.org/abs/2206.04962v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Optimizing musical chord inversions using the cartesian coordinate\n  system", "abstract": "In classical music and in any genre of contemporary music, the tonal elements\nor notes used for playing are the same. The numerous possibilities of chords\nfor a given instance in a piece make the playing, in general, very intricate,\nand advanced. The theory sounds quite trivial, yet the application has vast\noptions, each leading to inarguably different outcomes, characterized by\nscientific and musical principles. Chords and their importance are\nself-explanatory. A chord is a bunch of notes played together. As far as\nscientists are concerned, it is a set of tonal frequencies ringing together\nresulting in a consonant/dissonant sound. It is well-known that the notes of a\nchord can be rearranged to come up with various voicings (1) of the same chord\nwhich enables a composer/player to choose the most optimal one to convey the\nemotion they wish to convey. Though there are numerous possibilities, it is\nscientific to think that there is just one appropriate voicing for a particular\nsituation of tonal movements. In this study, we attempt to find the optimal\nvoicings by considering chords to be points in a 3-dimensional cartesian\ncoordinate system and further the fundamental understanding of mathematics in\nmusic theory.", "published": "2022-06-10 14:48:30", "link": "http://arxiv.org/abs/2206.06117v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Zero-Shot Audio Classification using Image Embeddings", "abstract": "Supervised learning methods can solve the given problem in the presence of a\nlarge set of labeled data. However, the acquisition of a dataset covering all\nthe target classes typically requires manual labeling which is expensive and\ntime-consuming. Zero-shot learning models are capable of classifying the unseen\nconcepts by utilizing their semantic information. The present study introduces\nimage embeddings as side information on zero-shot audio classification by using\na nonlinear acoustic-semantic projection. We extract the semantic image\nrepresentations from the Open Images dataset and evaluate the performance of\nthe models on an audio subset of AudioSet using semantic information in\ndifferent domains; image, audio, and textual. We demonstrate that the image\nembeddings can be used as semantic information to perform zero-shot audio\nclassification. The experimental results show that the image and textual\nembeddings display similar performance both individually and together. We\nadditionally calculate the semantic acoustic embeddings from the test samples\nto provide an upper limit to the performance. The results show that the\nclassification performance is highly sensitive to the semantic relation between\ntest and training classes and textual and image embeddings can reach up to the\nsemantic acoustic embeddings when the seen and unseen classes are semantically\nsimilar.", "published": "2022-06-10 10:36:56", "link": "http://arxiv.org/abs/2206.04984v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
