{"title": "Knowledge Distillation and Dataset Distillation of Large Language Models: Emerging Trends, Challenges, and Future Directions", "abstract": "The exponential growth of Large Language Models (LLMs) continues to highlight\nthe need for efficient strategies to meet ever-expanding computational and data\ndemands. This survey provides a comprehensive analysis of two complementary\nparadigms: Knowledge Distillation (KD) and Dataset Distillation (DD), both\naimed at compressing LLMs while preserving their advanced reasoning\ncapabilities and linguistic diversity. We first examine key methodologies in\nKD, such as task-specific alignment, rationale-based training, and\nmulti-teacher frameworks, alongside DD techniques that synthesize compact,\nhigh-impact datasets through optimization-based gradient matching, latent space\nregularization, and generative synthesis. Building on these foundations, we\nexplore how integrating KD and DD can produce more effective and scalable\ncompression strategies. Together, these approaches address persistent\nchallenges in model scalability, architectural heterogeneity, and the\npreservation of emergent LLM abilities. We further highlight applications\nacross domains such as healthcare and education, where distillation enables\nefficient deployment without sacrificing performance. Despite substantial\nprogress, open challenges remain in preserving emergent reasoning and\nlinguistic diversity, enabling efficient adaptation to continually evolving\nteacher models and datasets, and establishing comprehensive evaluation\nprotocols. By synthesizing methodological innovations, theoretical foundations,\nand practical insights, our survey charts a path toward sustainable,\nresource-efficient LLMs through the tighter integration of KD and DD\nprinciples.", "published": "2025-04-20 23:50:23", "link": "http://arxiv.org/abs/2504.14772v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Disentangling Linguistic Features with Dimension-Wise Analysis of Vector Embeddings", "abstract": "Understanding the inner workings of neural embeddings, particularly in models\nsuch as BERT, remains a challenge because of their high-dimensional and opaque\nnature. This paper proposes a framework for uncovering the specific dimensions\nof vector embeddings that encode distinct linguistic properties (LPs). We\nintroduce the Linguistically Distinct Sentence Pairs (LDSP-10) dataset, which\nisolates ten key linguistic features such as synonymy, negation, tense, and\nquantity. Using this dataset, we analyze BERT embeddings with various methods,\nincluding the Wilcoxon signed-rank test, mutual information, and recursive\nfeature elimination, to identify the most influential dimensions for each LP.\nWe introduce a new metric, the Embedding Dimension Impact (EDI) score, which\nquantifies the relevance of each embedding dimension to a LP. Our findings show\nthat certain properties, such as negation and polarity, are robustly encoded in\nspecific dimensions, while others, like synonymy, exhibit more complex\npatterns. This study provides insights into the interpretability of embeddings,\nwhich can guide the development of more transparent and optimized language\nmodels, with implications for model bias mitigation and the responsible\ndeployment of AI systems.", "published": "2025-04-20 23:38:16", "link": "http://arxiv.org/abs/2504.14766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PROMPTEVALS: A Dataset of Assertions and Guardrails for Custom Production Large Language Model Pipelines", "abstract": "Large language models (LLMs) are increasingly deployed in specialized\nproduction data processing pipelines across diverse domains -- such as finance,\nmarketing, and e-commerce. However, when running them in production across many\ninputs, they often fail to follow instructions or meet developer expectations.\nTo improve reliability in these applications, creating assertions or guardrails\nfor LLM outputs to run alongside the pipelines is essential. Yet, determining\nthe right set of assertions that capture developer requirements for a task is\nchallenging. In this paper, we introduce PROMPTEVALS, a dataset of 2087 LLM\npipeline prompts with 12623 corresponding assertion criteria, sourced from\ndevelopers using our open-source LLM pipeline tools. This dataset is 5x larger\nthan previous collections. Using a hold-out test split of PROMPTEVALS as a\nbenchmark, we evaluated closed- and open-source models in generating relevant\nassertions. Notably, our fine-tuned Mistral and Llama 3 models outperform\nGPT-4o by 20.93% on average, offering both reduced latency and improved\nperformance. We believe our dataset can spur further research in LLM\nreliability, alignment, and prompt engineering.", "published": "2025-04-20 21:04:23", "link": "http://arxiv.org/abs/2504.14738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating BERTopic on Open-Ended Data: A Case Study with Belgian Dutch Daily Narratives", "abstract": "This study explores BERTopic's potential for modeling open-ended Belgian\nDutch daily narratives, contrasting its performance with Latent Dirichlet\nAllocation (LDA) and KMeans. Although LDA scores well on certain automated\nmetrics, human evaluations reveal semantically irrelevant co-occurrences,\nhighlighting the limitations of purely statistic-based methods. In contrast,\nBERTopic's reliance on contextual embeddings yields culturally resonant themes,\nunderscoring the importance of hybrid evaluation frameworks that account for\nmorphologically rich languages. KMeans performed less coherently than prior\nresearch suggested, pointing to the unique challenges posed by personal\nnarratives. Our findings emphasize the need for robust generalization in NLP\nmodels, especially in underrepresented linguistic contexts.", "published": "2025-04-20 18:51:08", "link": "http://arxiv.org/abs/2504.14707v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding", "abstract": "The practical deployment of medical vision-language models (Med-VLMs)\nnecessitates seamless integration of textual data with diverse visual\nmodalities, including 2D/3D images and videos, yet existing models typically\nemploy separate encoders for different modalities. To address this limitation,\nwe present OmniV-Med, a unified framework for multimodal medical understanding.\nOur technical contributions are threefold: First, we construct\nOmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252K\ninstructional samples spanning 14 medical image modalities and 11 clinical\ntasks. Second, we devise a rotary position-adaptive encoder that processes\nmulti-resolution 2D/3D images and videos within a unified architecture,\ndiverging from conventional modality-specific encoders. Third, we introduce a\nmedical-aware token pruning mechanism that exploits spatial-temporal redundancy\nin volumetric data (e.g., consecutive CT slices) and medical videos,\neffectively reducing 60\\% of visual tokens without performance degradation.\nEmpirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-art\nperformance on 7 benchmarks spanning 2D/3D medical imaging and video\nunderstanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attains\ncomparable performance while requiring only 8 RTX3090 GPUs for training and\nsupporting efficient long-video inference. Data, code and model will be\nreleased.", "published": "2025-04-20 17:53:56", "link": "http://arxiv.org/abs/2504.14692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FarsEval-PKBETS: A new diverse benchmark for evaluating Persian large language models", "abstract": "Research on evaluating and analyzing large language models (LLMs) has been\nextensive for resource-rich languages such as English, yet their performance in\nlanguages such as Persian has received considerably less attention. This paper\nintroduces FarsEval-PKBETS benchmark, a subset of FarsEval project for\nevaluating large language models in Persian. This benchmark consists of 4000\nquestions and answers in various formats, including multiple choice, short\nanswer and descriptive responses. It covers a wide range of domains and\ntasks,including medicine, law, religion, Persian language, encyclopedic\nknowledge, human preferences, social knowledge, ethics and bias, text\ngeneration, and respecting others' rights. This bechmark incorporates\nlinguistics, cultural, and local considerations relevant to the Persian\nlanguage and Iran. To ensure the questions are challenging for current LLMs,\nthree models -- Llama3-70B, PersianMind, and Dorna -- were evaluated using this\nbenchmark. Their average accuracy was below 50%, meaning they provided fully\ncorrect answers to fewer than half of the questions. These results indicate\nthat current language models are still far from being able to solve this\nbenchmark", "published": "2025-04-20 17:43:47", "link": "http://arxiv.org/abs/2504.14690v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7; E.0"], "primary_category": "cs.CL"}
{"title": "Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data", "abstract": "The rise of Large Language Models (LLMs) has reshaped machine translation\n(MT), but multilingual MT still relies heavily on parallel data for supervised\nfine-tuning (SFT), facing challenges like data scarcity for low-resource\nlanguages and catastrophic forgetting. To address these issues, we propose\nTRANS-ZERO, a self-play framework that leverages only monolingual data and the\nintrinsic multilingual knowledge of LLM. TRANS-ZERO combines Genetic\nMonte-Carlo Tree Search (G-MCTS) with preference optimization, achieving strong\ntranslation performance that rivals supervised methods. Experiments demonstrate\nthat this approach not only matches the performance of models trained on\nlarge-scale parallel data but also excels in non-English translation\ndirections. Further analysis reveals that G-MCTS itself significantly enhances\ntranslation quality by exploring semantically consistent candidates through\niterative translations, providing a robust foundation for the framework's\nsuccuss.", "published": "2025-04-20 16:20:30", "link": "http://arxiv.org/abs/2504.14669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Case Study Exploring the Current Landscape of Synthetic Medical Record Generation with Commercial LLMs", "abstract": "Synthetic Electronic Health Records (EHRs) offer a valuable opportunity to\ncreate privacy preserving and harmonized structured data, supporting numerous\napplications in healthcare. Key benefits of synthetic data include precise\ncontrol over the data schema, improved fairness and representation of patient\npopulations, and the ability to share datasets without concerns about\ncompromising real individuals privacy. Consequently, the AI community has\nincreasingly turned to Large Language Models (LLMs) to generate synthetic data\nacross various domains. However, a significant challenge in healthcare is\nensuring that synthetic health records reliably generalize across different\nhospitals, a long standing issue in the field. In this work, we evaluate the\ncurrent state of commercial LLMs for generating synthetic data and investigate\nmultiple aspects of the generation process to identify areas where these models\nexcel and where they fall short. Our main finding from this work is that while\nLLMs can reliably generate synthetic health records for smaller subsets of\nfeatures, they struggle to preserve realistic distributions and correlations as\nthe dimensionality of the data increases, ultimately limiting their ability to\ngeneralize across diverse hospital settings.", "published": "2025-04-20 15:37:05", "link": "http://arxiv.org/abs/2504.14657v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LeetCodeDataset: A Temporal Dataset for Robust Evaluation and Efficient Training of Code LLMs", "abstract": "We introduce LeetCodeDataset, a high-quality benchmark for evaluating and\ntraining code-generation models, addressing two key challenges in LLM research:\nthe lack of reasoning-focused coding benchmarks and self-contained training\ntestbeds. By curating LeetCode Python problems with rich metadata, broad\ncoverage, 100+ test cases per problem, and temporal splits (pre/post July\n2024), our dataset enables contamination-free evaluation and efficient\nsupervised fine-tuning (SFT). Experiments show reasoning models significantly\noutperform non-reasoning counterparts, while SFT with only 2.6K model-generated\nsolutions achieves performance comparable to 110K-sample counterparts. The\ndataset and evaluation framework are available on Hugging Face and Github.", "published": "2025-04-20 15:28:16", "link": "http://arxiv.org/abs/2504.14655v1", "categories": ["cs.LG", "cs.CL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Risk Assessment Framework for Code LLMs via Leveraging Internal States", "abstract": "The pre-training paradigm plays a key role in the success of Large Language\nModels (LLMs), which have been recognized as one of the most significant\nadvancements of AI recently. Building on these breakthroughs, code LLMs with\nadvanced coding capabilities bring huge impacts on software engineering,\nshowing the tendency to become an essential part of developers' daily routines.\nHowever, the current code LLMs still face serious challenges related to\ntrustworthiness, as they can generate incorrect, insecure, or unreliable code.\nRecent exploratory studies find that it can be promising to detect such risky\noutputs by analyzing LLMs' internal states, akin to how the human brain\nunconsciously recognizes its own mistakes. Yet, most of these approaches are\nlimited to narrow sub-domains of LLM operations and fall short of achieving\nindustry-level scalability and practicability. To address these challenges, in\nthis paper, we propose PtTrust, a two-stage risk assessment framework for code\nLLM based on internal state pre-training, designed to integrate seamlessly with\nthe existing infrastructure of software companies. The core idea is that the\nrisk assessment framework could also undergo a pre-training process similar to\nLLMs. Specifically, PtTrust first performs unsupervised pre-training on\nlarge-scale unlabeled source code to learn general representations of LLM\nstates. Then, it uses a small, labeled dataset to train a risk predictor. We\ndemonstrate the effectiveness of PtTrust through fine-grained, code line-level\nrisk assessment and demonstrate that it generalizes across tasks and different\nprogramming languages. Further experiments also reveal that PtTrust provides\nhighly intuitive and interpretable features, fostering greater user trust. We\nbelieve PtTrust makes a promising step toward scalable and trustworthy\nassurance for code LLMs.", "published": "2025-04-20 14:44:18", "link": "http://arxiv.org/abs/2504.14640v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Harnessing Generative LLMs for Enhanced Financial Event Entity Extraction Performance", "abstract": "Financial event entity extraction is a crucial task for analyzing market\ndynamics and building financial knowledge graphs, yet it presents significant\nchallenges due to the specialized language and complex structures in financial\ntexts. Traditional approaches often rely on sequence labeling models, which can\nstruggle with long-range dependencies and the inherent complexity of extracting\nmultiple, potentially overlapping entities. Motivated by the advanced language\nunderstanding and generative capabilities of Large Language Models (LLMs), we\npropose a novel method that reframes financial event entity extraction as a\ntext-to-structured-output generation task. Our approach involves fine-tuning a\npre-trained LLM using Parameter-Efficient Fine-Tuning (PEFT) to directly\ngenerate a structured representation, such as a JSON object, containing the\nextracted entities and their precise character spans from the input text. We\nevaluate our method on the challenging CCKS 2019 Financial Event Entity\nExtraction dataset, comparing its performance against strong sequence labeling\nbaselines, including SEBERTNets and sebertNets. Experimental results\ndemonstrate that our generative LLM method achieves a new state-of-the-art F1\nscore on this benchmark, significantly outperforming previous methods. Through\ndetailed quantitative analysis across event types, entity types, and instance\ncomplexity, as well as human evaluation, we show that our approach is more\neffective at handling the nuances of financial text and extracting high-quality\nentities. This work validates the potential of applying generative LLMs\ndirectly to complex, domain-specific information extraction tasks requiring\nstructured output.", "published": "2025-04-20 14:23:31", "link": "http://arxiv.org/abs/2504.14633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Text Summarization (ATS) for Research Documents in Sorani Kurdish", "abstract": "Extracting concise information from scientific documents aids learners,\nresearchers, and practitioners. Automatic Text Summarization (ATS), a key\nNatural Language Processing (NLP) application, automates this process. While\nATS methods exist for many languages, Kurdish remains underdeveloped due to\nlimited resources. This study develops a dataset and language model based on\n231 scientific papers in Sorani Kurdish, collected from four academic\ndepartments in two universities in the Kurdistan Region of Iraq (KRI),\naveraging 26 pages per document. Using Sentence Weighting and Term\nFrequency-Inverse Document Frequency (TF-IDF) algorithms, two experiments were\nconducted, differing in whether the conclusions were included. The average word\ncount was 5,492.3 in the first experiment and 5,266.96 in the second. Results\nwere evaluated manually and automatically using ROUGE-1, ROUGE-2, and ROUGE-L\nmetrics, with the best accuracy reaching 19.58%. Six experts conducted manual\nevaluations using three criteria, with results varying by document. This\nresearch provides valuable resources for Kurdish NLP researchers to advance ATS\nand related fields.", "published": "2025-04-20 14:17:17", "link": "http://arxiv.org/abs/2504.14630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hierarchical Framework for Measuring Scientific Paper Innovation via Large Language Models", "abstract": "Measuring scientific paper innovation is both important and challenging.\nExisting content-based methods often overlook the full-paper context, fail to\ncapture the full scope of innovation, and lack generalization. We propose\nHSPIM, a hierarchical and training-free framework based on large language\nmodels (LLMs). It introduces a Paper-to-Sections-to-QAs decomposition to assess\ninnovation. We segment the text by section titles and use zero-shot LLM\nprompting to implement section classification, question-answering (QA)\naugmentation, and weighted novelty scoring. The generated QA pair focuses on\nsection-level innovation and serves as additional context to improve the LLM\nscoring. For each chunk, the LLM outputs a novelty score and a confidence\nscore. We use confidence scores as weights to aggregate novelty scores into a\npaper-level innovation score. To further improve performance, we propose a\ntwo-layer question structure consisting of common and section-specific\nquestions, and apply a genetic algorithm to optimize the question-prompt\ncombinations. Comprehensive experiments on scientific conference paper datasets\nshow that HSPIM outperforms baseline methods in effectiveness, generalization,\nand interpretability.", "published": "2025-04-20 13:58:20", "link": "http://arxiv.org/abs/2504.14620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Translation Analytics for Freelancers: I. Introduction, Data Preparation, Baseline Evaluations", "abstract": "This is the first in a series of papers exploring the rapidly expanding new\nopportunities arising from recent progress in language technologies for\nindividual translators and language service providers with modest resources.\nThe advent of advanced neural machine translation systems, large language\nmodels, and their integration into workflows via computer-assisted translation\ntools and translation management systems have reshaped the translation\nlandscape. These advancements enable not only translation but also quality\nevaluation, error spotting, glossary generation, and adaptation to\ndomain-specific needs, creating new technical opportunities for freelancers. In\nthis series, we aim to empower translators with actionable methods to harness\nthese advancements. Our approach emphasizes Translation Analytics, a suite of\nevaluation techniques traditionally reserved for large-scale industry\napplications but now becoming increasingly available for smaller-scale users.\nThis first paper introduces a practical framework for adapting automatic\nevaluation metrics -- such as BLEU, chrF, TER, and COMET -- to freelancers'\nneeds. We illustrate the potential of these metrics using a trilingual corpus\nderived from a real-world project in the medical domain and provide statistical\nanalysis correlating human evaluations with automatic scores. Our findings\nemphasize the importance of proactive engagement with emerging technologies to\nnot only adapt but thrive in the evolving professional environment.", "published": "2025-04-20 13:54:28", "link": "http://arxiv.org/abs/2504.14619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "a1: Steep Test-time Scaling Law via Environment Augmented Generation", "abstract": "Large Language Models (LLMs) have made remarkable breakthroughs in reasoning,\nyet continue to struggle with hallucinations, logical errors, and inability to\nself-correct during complex multi-step tasks. Current approaches like\nchain-of-thought prompting offer limited reasoning capabilities that fail when\nprecise step validation is required. We propose Environment Augmented\nGeneration (EAG), a framework that enhances LLM reasoning through: (1)\nreal-time environmental feedback validating each reasoning step, (2) dynamic\nbranch exploration for investigating alternative solution paths when faced with\nerrors, and (3) experience-based learning from successful reasoning\ntrajectories. Unlike existing methods, EAG enables deliberate backtracking and\nstrategic replanning through tight integration of execution feedback with\nbranching exploration. Our a1-32B model achieves state-of-the-art performance\namong similar-sized models across all benchmarks, matching larger models like\no1 on competition mathematics while outperforming comparable models by up to\n24.4 percentage points. Analysis reveals EAG's distinctive scaling pattern:\ninitial token investment in environment interaction yields substantial\nlong-term performance dividends, with advantages amplifying proportionally to\ntask complexity. EAG's theoretical framework demonstrates how environment\ninteractivity and systematic branch exploration together establish a new\nparadigm for reliable machine reasoning, particularly for problems requiring\nprecise multi-step calculation and logical verification.", "published": "2025-04-20 12:55:59", "link": "http://arxiv.org/abs/2504.14597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HealthGenie: Empowering Users with Healthy Dietary Guidance through Knowledge Graph and Large Language Models", "abstract": "Seeking dietary guidance often requires navigating complex professional\nknowledge while accommodating individual health conditions. Knowledge Graphs\n(KGs) offer structured and interpretable nutritional information, whereas Large\nLanguage Models (LLMs) naturally facilitate conversational recommendation\ndelivery. In this paper, we present HealthGenie, an interactive system that\ncombines the strengths of LLMs and KGs to provide personalized dietary\nrecommendations along with hierarchical information visualization for a quick\nand intuitive overview. Upon receiving a user query, HealthGenie performs query\nrefinement and retrieves relevant information from a pre-built KG. The system\nthen visualizes and highlights pertinent information, organized by defined\ncategories, while offering detailed, explainable recommendation rationales.\nUsers can further tailor these recommendations by adjusting preferences\ninteractively. Our evaluation, comprising a within-subject comparative\nexperiment and an open-ended discussion, demonstrates that HealthGenie\neffectively supports users in obtaining personalized dietary guidance based on\ntheir health conditions while reducing interaction effort and cognitive load.\nThese findings highlight the potential of LLM-KG integration in supporting\ndecision-making through explainable and visualized information. We examine the\nsystem's usefulness and effectiveness with an N=12 within-subject study and\nprovide design considerations for future systems that integrate conversational\nLLM and KG.", "published": "2025-04-20 12:51:16", "link": "http://arxiv.org/abs/2504.14594v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation", "abstract": "Recent advances in large language models (LLMs) have enabled social\nsimulation through multi-agent systems. Prior efforts focus on agent societies\ncreated from scratch, assigning agents with newly defined personas. However,\nsimulating established fictional worlds and characters remain largely\nunderexplored, despite its significant practical value. In this paper, we\nintroduce BookWorld, a comprehensive system for constructing and simulating\nbook-based multi-agent societies. BookWorld's design covers comprehensive\nreal-world intricacies, including diverse and dynamic characters, fictional\nworldviews, geographical constraints and changes, e.t.c. BookWorld enables\ndiverse applications including story generation, interactive games and social\nsimulation, offering novel ways to extend and explore beloved fictional works.\nThrough extensive experiments, we demonstrate that BookWorld generates\ncreative, high-quality stories while maintaining fidelity to the source books,\nsurpassing previous methods with a win rate of 75.36%. The code of this paper\ncan be found at the project page: https://bookworld2025.github.io/.", "published": "2025-04-20 08:56:27", "link": "http://arxiv.org/abs/2504.14538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Causality for Natural Language Processing", "abstract": "Causal reasoning is a cornerstone of human intelligence and a critical\ncapability for artificial systems aiming to achieve advanced understanding and\ndecision-making. This thesis delves into various dimensions of causal reasoning\nand understanding in large language models (LLMs). It encompasses a series of\nstudies that explore the causal inference skills of LLMs, the mechanisms behind\ntheir performance, and the implications of causal and anticausal learning for\nnatural language processing (NLP) tasks. Additionally, it investigates the\napplication of causal reasoning in text-based computational social science,\nspecifically focusing on political decision-making and the evaluation of\nscientific impact through citations. Through novel datasets, benchmark tasks,\nand methodological frameworks, this work identifies key challenges and\nopportunities to improve the causal capabilities of LLMs, providing a\ncomprehensive foundation for future research in this evolving field.", "published": "2025-04-20 08:11:11", "link": "http://arxiv.org/abs/2504.14530v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are Vision LLMs Road-Ready? A Comprehensive Benchmark for Safety-Critical Driving Video Understanding", "abstract": "Vision Large Language Models (VLLMs) have demonstrated impressive\ncapabilities in general visual tasks such as image captioning and visual\nquestion answering. However, their effectiveness in specialized,\nsafety-critical domains like autonomous driving remains largely unexplored.\nAutonomous driving systems require sophisticated scene understanding in complex\nenvironments, yet existing multimodal benchmarks primarily focus on normal\ndriving conditions, failing to adequately assess VLLMs' performance in\nsafety-critical scenarios. To address this, we introduce DVBench, a pioneering\nbenchmark designed to evaluate the performance of VLLMs in understanding\nsafety-critical driving videos. Built around a hierarchical ability taxonomy\nthat aligns with widely adopted frameworks for describing driving scenarios\nused in assessing highly automated driving systems, DVBench features 10,000\nmultiple-choice questions with human-annotated ground-truth answers, enabling a\ncomprehensive evaluation of VLLMs' capabilities in perception and reasoning.\nExperiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, reveal\nsignificant performance gaps, with no model achieving over 40% accuracy,\nhighlighting critical limitations in understanding complex driving scenarios.\nTo probe adaptability, we fine-tuned selected models using domain-specific data\nfrom DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentage\npoints, with relative improvements of up to 43.59%. This improvement\nunderscores the necessity of targeted adaptation to bridge the gap between\ngeneral-purpose VLLMs and mission-critical driving applications. DVBench\nestablishes an essential evaluation framework and research roadmap for\ndeveloping VLLMs that meet the safety and robustness requirements for\nreal-world autonomous systems. We released the benchmark toolbox and the\nfine-tuned model at: https://github.com/tong-zeng/DVBench.git.", "published": "2025-04-20 07:50:44", "link": "http://arxiv.org/abs/2504.14526v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "abstract": "This survey explores the development of meta-thinking capabilities in Large\nLanguage Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL)\nperspective. Meta-thinking self-reflection, assessment, and control of thinking\nprocesses is an important next step in enhancing LLM reliability, flexibility,\nand performance, particularly for complex or high-stakes tasks. The survey\nbegins by analyzing current LLM limitations, such as hallucinations and the\nlack of internal self-assessment mechanisms. It then talks about newer methods,\nincluding RL from human feedback (RLHF), self-distillation, and\nchain-of-thought prompting, and each of their limitations. The crux of the\nsurvey is to talk about how multi-agent architectures, namely supervisor-agent\nhierarchies, agent debates, and theory of mind frameworks, can emulate\nhuman-like introspective behavior and enhance LLM robustness. By exploring\nreward mechanisms, self-play, and continuous learning methods in MARL, this\nsurvey gives a comprehensive roadmap to building introspective, adaptive, and\ntrustworthy LLMs. Evaluation metrics, datasets, and future research avenues,\nincluding neuroscience-inspired architectures and hybrid symbolic reasoning,\nare also discussed.", "published": "2025-04-20 07:34:26", "link": "http://arxiv.org/abs/2504.14520v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Functional Abstraction of Knowledge Recall in Large Language Models", "abstract": "Pre-trained transformer large language models (LLMs) demonstrate strong\nknowledge recall capabilities. This paper investigates the knowledge recall\nmechanism in LLMs by abstracting it into a functional structure. We propose\nthat during knowledge recall, the model's hidden activation space implicitly\nentails a function execution process where specific activation vectors align\nwith functional components (Input argument, Function body, and Return values).\nSpecifically, activation vectors of relation-related tokens define a mapping\nfunction from subjects to objects, with subject-related token activations\nserving as input arguments and object-related token activations as return\nvalues. For experimental verification, we first design a patching-based\nknowledge-scoring algorithm to identify knowledge-aware activation vectors as\nindependent functional components. Then, we conduct counter-knowledge testing\nto examine the independent functional effects of each component on knowledge\nrecall outcomes. From this functional perspective, we improve the contextual\nknowledge editing approach augmented by activation patching. By rewriting\nincoherent activations in context, we enable improved short-term memory\nretention for new knowledge prompting.", "published": "2025-04-20 05:17:57", "link": "http://arxiv.org/abs/2504.14496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FairSteer: Inference Time Debiasing for LLMs with Dynamic Activation Steering", "abstract": "Large language models (LLMs) are prone to capturing biases from training\ncorpus, leading to potential negative social impacts. Existing prompt-based\ndebiasing methods exhibit instability due to their sensitivity to prompt\nchanges, while fine-tuning-based techniques incur substantial computational\noverhead and catastrophic forgetting. In this paper, we propose FairSteer, a\nnovel inference-time debiasing framework without requiring customized prompt\ndesign or model retraining. Motivated by the linear representation hypothesis,\nour preliminary investigation demonstrates that fairness-related features can\nbe encoded into separable directions in the hidden activation space. FairSteer\noperates in three steps: biased activation detection, debiasing steering vector\n(DSV) computation, and dynamic activation steering. Specifically, it first\ntrains a lightweight linear classifier to detect bias signatures in\nactivations, and then computes DSVs as intervention directions derived from\nsmall contrastive prompt pairs. Subsequently, it performs debiasing by\nadjusting activations with DSVs in the inference stage. Comprehensive\nevaluation with six LLMs demonstrates the superiority of FairSteer across\nquestion-answering, counterfactual input evaluation and open-ended text\ngeneration tasks. Code will be released.", "published": "2025-04-20 04:57:00", "link": "http://arxiv.org/abs/2504.14492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue", "abstract": "Speech synthesis is crucial for human-computer interaction, enabling natural\nand intuitive communication. However, existing datasets involve high\nconstruction costs due to manual annotation and suffer from limited character\ndiversity, contextual scenarios, and emotional expressiveness. To address these\nissues, we propose DialogueAgents, a novel hybrid agent-based speech synthesis\nframework, which integrates three specialized agents -- a script writer, a\nspeech synthesizer, and a dialogue critic -- to collaboratively generate\ndialogues. Grounded in a diverse character pool, the framework iteratively\nrefines dialogue scripts and synthesizes speech based on speech review,\nboosting emotional expressiveness and paralinguistic features of the\nsynthesized dialogues. Using DialogueAgent, we contribute MultiTalk, a\nbilingual, multi-party, multi-turn speech dialogue dataset covering diverse\ntopics. Extensive experiments demonstrate the effectiveness of our framework\nand the high quality of the MultiTalk dataset. We release the dataset and code\nhttps://github.com/uirlx/DialogueAgents to facilitate future research on\nadvanced speech synthesis models and customized data generation.", "published": "2025-04-20 04:14:30", "link": "http://arxiv.org/abs/2504.14482v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment", "abstract": "Interpreting neural activity through meaningful latent representations\nremains a complex and evolving challenge at the intersection of neuroscience\nand artificial intelligence. We investigate the potential of multimodal\nfoundation models to align invasive brain recordings with natural language. We\npresent SSENSE, a contrastive learning framework that projects single-subject\nstereo-electroencephalography (sEEG) signals into the sentence embedding space\nof a frozen CLIP model, enabling sentence-level retrieval directly from brain\nactivity. SSENSE trains a neural encoder on spectral representations of sEEG\nusing InfoNCE loss, without fine-tuning the text encoder. We evaluate our\nmethod on time-aligned sEEG and spoken transcripts from a naturalistic\nmovie-watching dataset. Despite limited data, SSENSE achieves promising\nresults, demonstrating that general-purpose language representations can serve\nas effective priors for neural decoding.", "published": "2025-04-20 03:01:42", "link": "http://arxiv.org/abs/2504.14468v1", "categories": ["cs.CL", "cs.LG", "eess.SP", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "CoLoTa: A Dataset for Entity-based Commonsense Reasoning over Long-Tail Knowledge", "abstract": "The rise of Large Language Models (LLMs) has redefined the AI landscape,\nparticularly due to their ability to encode factual and commonsense knowledge,\nand their outstanding performance in tasks requiring reasoning. Despite these\nadvances, hallucinations and reasoning errors remain a significant barrier to\ntheir deployment in high-stakes settings. In this work, we observe that even\nthe most prominent LLMs, such as OpenAI-o1, suffer from high rates of reasoning\nerrors and hallucinations on tasks requiring commonsense reasoning over\nobscure, long-tail entities. To investigate this limitation, we present a new\ndataset for Commonsense reasoning over Long-Tail entities (CoLoTa), that\nconsists of 3,300 queries from question answering and claim verification tasks\nand covers a diverse range of commonsense reasoning skills. We remark that\nCoLoTa can also serve as a Knowledge Graph Question Answering (KGQA) dataset\nsince the support of knowledge required to answer its queries is present in the\nWikidata knowledge graph. However, as opposed to existing KGQA benchmarks that\nmerely focus on factoid questions, our CoLoTa queries also require commonsense\nreasoning. Our experiments with strong LLM-based KGQA methodologies indicate\ntheir severe inability to answer queries involving commonsense reasoning.\nHence, we propose CoLoTa as a novel benchmark for assessing both (i) LLM\ncommonsense reasoning capabilities and their robustness to hallucinations on\nlong-tail entities and (ii) the commonsense reasoning capabilities of KGQA\nmethods.", "published": "2025-04-20 02:47:18", "link": "http://arxiv.org/abs/2504.14462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data", "abstract": "Language models (LMs) can memorize and reproduce segments from their\npretraining data verbatim even in non-adversarial settings, raising concerns\nabout copyright, plagiarism, privacy, and creativity. We introduce Paraphrase\nPreference Optimization (ParaPO), a post-training method that fine-tunes LMs to\nreduce unintentional regurgitation while preserving their overall utility.\nParaPO trains LMs to prefer paraphrased versions of memorized segments over the\noriginal verbatim content from the pretraining data. To maintain the ability to\nrecall famous quotations when appropriate, we develop a variant of ParaPO that\nuses system prompts to control regurgitation behavior. In our evaluation on\nLlama3.1-8B, ParaPO consistently reduces regurgitation across all tested\ndatasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative\nwriting), whereas unlearning methods used in prior work to mitigate\nregurgitation are less effective outside their targeted unlearned domain (from\n17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO\nwith system prompting successfully preserves famous quotation recall while\nreducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when\nprompted not to regurgitate. In contrast, without ParaPO tuning, prompting the\nmodel not to regurgitate produces only a marginal reduction (8.7 to 8.4).", "published": "2025-04-20 01:59:46", "link": "http://arxiv.org/abs/2504.14452v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LoRe: Personalizing LLMs via Low-Rank Reward Modeling", "abstract": "Personalizing large language models (LLMs) to accommodate diverse user\npreferences is essential for enhancing alignment and user satisfaction.\nTraditional reinforcement learning from human feedback (RLHF) approaches often\nrely on monolithic value representations, limiting their ability to adapt to\nindividual preferences. We introduce a novel framework that leverages low-rank\npreference modeling to efficiently learn and generalize user-specific reward\nfunctions. By representing reward functions in a low-dimensional subspace and\nmodeling individual preferences as weighted combinations of shared basis\nfunctions, our approach avoids rigid user categorization while enabling\nscalability and few-shot adaptation. We validate our method on multiple\npreference datasets, demonstrating superior generalization to unseen users and\nimproved accuracy in preference prediction tasks.", "published": "2025-04-20 01:16:24", "link": "http://arxiv.org/abs/2504.14439v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Combinatorial Theory of Dropout: Subnetworks, Graph Geometry, and Generalization", "abstract": "We propose a combinatorial and graph-theoretic theory of dropout by modeling\ntraining as a random walk over a high-dimensional graph of binary subnetworks.\nEach node represents a masked version of the network, and dropout induces\nstochastic traversal across this space. We define a subnetwork contribution\nscore that quantifies generalization and show that it varies smoothly over the\ngraph. Using tools from spectral graph theory, PAC-Bayes analysis, and\ncombinatorics, we prove that generalizing subnetworks form large, connected,\nlow-resistance clusters, and that their number grows exponentially with network\nwidth. This reveals dropout as a mechanism for sampling from a robust,\nstructured ensemble of well-generalizing subnetworks with built-in redundancy.\nExtensive experiments validate every theoretical claim across diverse\narchitectures. Together, our results offer a unified foundation for\nunderstanding dropout and suggest new directions for mask-guided regularization\nand subnetwork optimization.", "published": "2025-04-20 23:09:20", "link": "http://arxiv.org/abs/2504.14762v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs", "abstract": "Large language models (LLMs) are transforming automated program repair (APR)\nthrough agent-based approaches that localize bugs, generate patches, and verify\nfixes. However, the lack of high-quality, scalable training datasets,\nespecially those with verifiable outputs and intermediate reasoning\ntraces-limits progress, particularly for open-source models. In this work, we\npresent SWE-Synth, a framework for synthesizing realistic, verifiable, and\nprocess-aware bug-fix datasets at the repository level. SWE-Synth leverages LLM\nagents to simulate debugging workflows, producing not only bug-fix pairs but\nalso test cases and structured repair trajectories. Compared to manually\ncurated datasets, our method scales with minimal human effort while preserving\ncontextual richness and correctness. Experiments show that models trained on\nSWE-Synth outperform those trained on real-world datasets by 2.3% on SWE-Bench\nLite. Our results highlight the potential of synthetic, agent-generated data to\nadvance the state of the art in APR and software engineering automation.", "published": "2025-04-20 22:37:43", "link": "http://arxiv.org/abs/2504.14757v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "AI for the Open-World: the Learning Principles", "abstract": "During the past decades, numerous successes of AI has been made on \"specific\ncapabilities\", named closed-world, such as artificial environments or specific\nreal-world tasks. This well-defined narrow capability brings two nice benefits,\na clear criterion of success and the opportunity to collect a lot of examples.\nThe criteria not only reveal whether a machine has achieved a goal, but reveal\nhow the machine falls short of the goal. As a result, human designers can fix\nthe problems one after the other until the machine is deemed good enough for\nthe task. Furthermore, the large set of collected examples reduces the\ndifficulty of this problem-fixing process (by the central limit theorem).\n  Do the success in closed-world translate into broad open-world, where a\nmachine is required to perform any task that a human could possibly undertake\nwith fewer examples and less priori knowledge from human designers? No. Because\ncompetence in a specific task provides little insight in handling other tasks,\nthe valuable criteria for specific tasks become helpless when handling broader\nunseen tasks. Furthermore, due to the shortage of examples in unseen tasks,\ncentral limit theorem does not stand on our side. At the end, human designers\nlose the oscilloscope to \"hack\" an AI system for the open-world.\n  Achieving AI for the open-world requires unique learning principles and\ninnovated techniques, which are different from the ones in building AI for the\nclosed-world. This thesis explores necessary learning principles required to\nconstruct AI for the open-world, including rich features (analogy a large tool\nbox), disentangled representation (an organized tool box), and inference-time\nlearning (a tool-savvy hand). Driven by the learning principles, this thesis\nfurther proposes techniques to use the learning principles, conducts enormous\nlarge-scale experiments to verify the learning principles.", "published": "2025-04-20 22:22:00", "link": "http://arxiv.org/abs/2504.14751v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Modularized Design Approach for GelSight Family of Vision-based Tactile Sensors", "abstract": "GelSight family of vision-based tactile sensors has proven to be effective\nfor multiple robot perception and manipulation tasks. These sensors are based\non an internal optical system and an embedded camera to capture the deformation\nof the soft sensor surface, inferring the high-resolution geometry of the\nobjects in contact. However, customizing the sensors for different robot hands\nrequires a tedious trial-and-error process to re-design the optical system. In\nthis paper, we formulate the GelSight sensor design process as a systematic and\nobjective-driven design problem and perform the design optimization with a\nphysically accurate optical simulation. The method is based on modularizing and\nparameterizing the sensor's optical components and designing four generalizable\nobjective functions to evaluate the sensor. We implement the method with an\ninteractive and easy-to-use toolbox called OptiSense Studio. With the toolbox,\nnon-sensor experts can quickly optimize their sensor design in both forward and\ninverse ways following our predefined modules and steps. We demonstrate our\nsystem with four different GelSight sensors by quickly optimizing their initial\ndesign in simulation and transferring it to the real sensors.", "published": "2025-04-20 21:07:41", "link": "http://arxiv.org/abs/2504.14739v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "SuperCL: Superpixel Guided Contrastive Learning for Medical Image Segmentation Pre-training", "abstract": "Medical image segmentation is a critical yet challenging task, primarily due\nto the difficulty of obtaining extensive datasets of high-quality,\nexpert-annotated images. Contrastive learning presents a potential but still\nproblematic solution to this issue. Because most existing methods focus on\nextracting instance-level or pixel-to-pixel representation, which ignores the\ncharacteristics between intra-image similar pixel groups. Moreover, when\nconsidering contrastive pairs generation, most SOTA methods mainly rely on\nmanually setting thresholds, which requires a large number of gradient\nexperiments and lacks efficiency and generalization. To address these issues,\nwe propose a novel contrastive learning approach named SuperCL for medical\nimage segmentation pre-training. Specifically, our SuperCL exploits the\nstructural prior and pixel correlation of images by introducing two novel\ncontrastive pairs generation strategies: Intra-image Local Contrastive Pairs\n(ILCP) Generation and Inter-image Global Contrastive Pairs (IGCP) Generation.\nConsidering superpixel cluster aligns well with the concept of contrastive\npairs generation, we utilize the superpixel map to generate pseudo masks for\nboth ILCP and IGCP to guide supervised contrastive learning. Moreover, we also\npropose two modules named Average SuperPixel Feature Map Generation (ASP) and\nConnected Components Label Generation (CCL) to better exploit the prior\nstructural information for IGCP. Finally, experiments on 8 medical image\ndatasets indicate our SuperCL outperforms existing 12 methods. i.e. Our SuperCL\nachieves a superior performance with more precise predictions from\nvisualization figures and 3.15%, 5.44%, 7.89% DSC higher than the previous best\nresults on MMWHS, CHAOS, Spleen with 10% annotations. Our code will be released\nafter acceptance.", "published": "2025-04-20 20:57:03", "link": "http://arxiv.org/abs/2504.14737v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Semi-parametric Memory Consolidation: Towards Brain-like Deep Continual Learning", "abstract": "Humans and most animals inherently possess a distinctive capacity to\ncontinually acquire novel experiences and accumulate worldly knowledge over\ntime. This ability, termed continual learning, is also critical for deep neural\nnetworks (DNNs) to adapt to the dynamically evolving world in open\nenvironments. However, DNNs notoriously suffer from catastrophic forgetting of\npreviously learned knowledge when trained on sequential tasks. In this work,\ninspired by the interactive human memory and learning system, we propose a\nnovel biomimetic continual learning framework that integrates semi-parametric\nmemory and the wake-sleep consolidation mechanism. For the first time, our\nmethod enables deep neural networks to retain high performance on novel tasks\nwhile maintaining prior knowledge in real-world challenging continual learning\nscenarios, e.g., class-incremental learning on ImageNet. This study\ndemonstrates that emulating biological intelligence provides a promising path\nto enable deep neural networks with continual learning capabilities.", "published": "2025-04-20 19:53:13", "link": "http://arxiv.org/abs/2504.14727v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Exposing the Copycat Problem of Imitation-based Planner: A Novel Closed-Loop Simulator, Causal Benchmark and Joint IL-RL Baseline", "abstract": "Machine learning (ML)-based planners have recently gained significant\nattention. They offer advantages over traditional optimization-based planning\nalgorithms. These advantages include fewer manually selected parameters and\nfaster development. Within ML-based planning, imitation learning (IL) is a\ncommon algorithm. It primarily learns driving policies directly from supervised\ntrajectory data. While IL has demonstrated strong performance on many open-loop\nbenchmarks, it remains challenging to determine if the learned policy truly\nunderstands fundamental driving principles, rather than simply extrapolating\nfrom the ego-vehicle's initial state. Several studies have identified this\nlimitation and proposed algorithms to address it. However, these methods often\nuse original datasets for evaluation. In these datasets, future trajectories\nare heavily dependent on initial conditions. Furthermore, IL often overfits to\nthe most common scenarios. It struggles to generalize to rare or unseen\nsituations.\n  To address these challenges, this work proposes: 1) a novel closed-loop\nsimulator supporting both imitation and reinforcement learning, 2) a causal\nbenchmark derived from the Waymo Open Dataset to rigorously assess the impact\nof the copycat problem, and 3) a novel framework integrating imitation learning\nand reinforcement learning to overcome the limitations of purely imitative\napproaches. The code for this work will be released soon.", "published": "2025-04-20 18:51:26", "link": "http://arxiv.org/abs/2504.14709v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Time Frequency Analysis of EMG Signal for Gesture Recognition using Fine grained Features", "abstract": "Electromyography (EMG) based hand gesture recognition converts forearm muscle\nactivity into control commands for prosthetics, rehabilitation, and human\ncomputer interaction. This paper proposes a novel approach to EMG-based hand\ngesture recognition that uses fine-grained classification and presents XMANet,\nwhich unifies low-level local and high level semantic cues through cross layer\nmutual attention among shallow to deep CNN experts. Using stacked spectrograms\nand scalograms derived from the Short Time Fourier Transform (STFT) and Wavelet\nTransform (WT), we benchmark XMANet against ResNet50, DenseNet-121,\nMobileNetV3, and EfficientNetB0. Experimental results on the Grabmyo dataset\nindicate that, using STFT, the proposed XMANet model outperforms the baseline\nResNet50, EfficientNetB0, MobileNetV3, and DenseNet121 models with improvement\nof approximately 1.72%, 4.38%, 5.10%, and 2.53%, respectively. When employing\nthe WT approach, improvements of around 1.57%, 1.88%, 1.46%, and 2.05% are\nobserved over the same baselines. Similarly, on the FORS EMG dataset, the\nXMANet(ResNet50) model using STFT shows an improvement of about 5.04% over the\nbaseline ResNet50. In comparison, the XMANet(DenseNet121) and\nXMANet(MobileNetV3) models yield enhancements of approximately 4.11% and 2.81%,\nrespectively. Moreover, when using WT, the proposed XMANet achieves gains of\naround 4.26%, 9.36%, 5.72%, and 6.09% over the baseline ResNet50, DenseNet121,\nMobileNetV3, and EfficientNetB0 models, respectively. These results confirm\nthat XMANet consistently improves performance across various architectures and\nsignal processing techniques, demonstrating the strong potential of fine\ngrained features for accurate and robust EMG classification.", "published": "2025-04-20 18:51:10", "link": "http://arxiv.org/abs/2504.14708v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models", "abstract": "The human-level performance of Large Language Models (LLMs) across various\ntasks has raised expectations for the potential of Artificial Intelligence (AI)\nto possess emotions someday. To explore the capability of current LLMs to\nexpress emotions in their outputs, we conducted an experiment using several\nLLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to\nrole-play as agents answering questions with specified emotional states.We\ndefined the emotional states using Russell's Circumplex model, a\nwell-established framework that characterizes emotions along the\nsleepy-activated (arousal) and pleasure-displeasure (valence) axes. We chose\nthis model for its simplicity, utilizing two continuous parameters, which\nallows for better controllability in applications involving continuous changes\nin emotional states. The responses generated were evaluated using a sentiment\nanalysis model, independent of the LLMs, trained on the GoEmotions dataset. The\nevaluation showed that the emotional states of the generated answers were\nconsistent with the specifications, demonstrating the LLMs' capability for\nemotional expression. This indicates the potential for LLM-based AI agents to\nsimulate emotions, opening up a wide range of applications for emotion-based\ninteractions, such as advisors or consultants who can provide advice or\nopinions with a personal touch.", "published": "2025-04-20 18:49:25", "link": "http://arxiv.org/abs/2504.14706v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can We Ignore Labels In Out of Distribution Detection?", "abstract": "Out-of-distribution (OOD) detection methods have recently become more\nprominent, serving as a core element in safety-critical autonomous systems. One\nmajor purpose of OOD detection is to reject invalid inputs that could lead to\nunpredictable errors and compromise safety. Due to the cost of labeled data,\nrecent works have investigated the feasibility of self-supervised learning\n(SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In\nthis work, we identify a set of conditions for a theoretical guarantee of\nfailure in unlabeled OOD detection algorithms from an information-theoretic\nperspective. These conditions are present in all OOD tasks dealing with\nreal-world data: I) we provide theoretical proof of unlabeled OOD detection\nfailure when there exists zero mutual information between the learning\nobjective and the in-distribution labels, a.k.a. 'label blindness', II) we\ndefine a new OOD task - Adjacent OOD detection - that tests for label blindness\nand accounts for a previously ignored safety gap in all OOD detection\nbenchmarks, and III) we perform experiments demonstrating that existing\nunlabeled OOD methods fail under conditions suggested by our label blindness\ntheory and analyze the implications for future research in unlabeled OOD\nmethods.", "published": "2025-04-20 18:37:51", "link": "http://arxiv.org/abs/2504.14704v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "IXGS-Intraoperative 3D Reconstruction from Sparse, Arbitrarily Posed Real X-rays", "abstract": "Spine surgery is a high-risk intervention demanding precise execution, often\nsupported by image-based navigation systems. Recently, supervised learning\napproaches have gained attention for reconstructing 3D spinal anatomy from\nsparse fluoroscopic data, significantly reducing reliance on\nradiation-intensive 3D imaging systems. However, these methods typically\nrequire large amounts of annotated training data and may struggle to generalize\nacross varying patient anatomies or imaging conditions. Instance-learning\napproaches like Gaussian splatting could offer an alternative by avoiding\nextensive annotation requirements. While Gaussian splatting has shown promise\nfor novel view synthesis, its application to sparse, arbitrarily posed real\nintraoperative X-rays has remained largely unexplored. This work addresses this\nlimitation by extending the $R^2$-Gaussian splatting framework to reconstruct\nanatomically consistent 3D volumes under these challenging conditions. We\nintroduce an anatomy-guided radiographic standardization step using style\ntransfer, improving visual consistency across views, and enhancing\nreconstruction quality. Notably, our framework requires no pretraining, making\nit inherently adaptable to new patients and anatomies. We evaluated our\napproach using an ex-vivo dataset. Expert surgical evaluation confirmed the\nclinical utility of the 3D reconstructions for navigation, especially when\nusing 20 to 30 views, and highlighted the standardization's benefit for\nanatomical clarity. Benchmarking via quantitative 2D metrics (PSNR/SSIM)\nconfirmed performance trade-offs compared to idealized settings, but also\nvalidated the improvement gained from standardization over raw inputs. This\nwork demonstrates the feasibility of instance-based volumetric reconstruction\nfrom arbitrary sparse-view X-rays, advancing intraoperative 3D imaging for\nsurgical navigation.", "published": "2025-04-20 18:28:13", "link": "http://arxiv.org/abs/2504.14699v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Critically: Selective Self Distillation in Federated Learning on Non-IID Data", "abstract": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal model while keeping local data decentralized. Data heterogeneity\n(non-IID) across clients has imposed significant challenges to FL, which makes\nlocal models re-optimize towards their own local optima and forget the global\nknowledge, resulting in performance degradation and convergence slowdown. Many\nexisting works have attempted to address the non-IID issue by adding an extra\nglobal-model-based regularizing item to the local training but without an\nadaption scheme, which is not efficient enough to achieve high performance with\ndeep learning models. In this paper, we propose a Selective Self-Distillation\nmethod for Federated learning (FedSSD), which imposes adaptive constraints on\nthe local updates by self-distilling the global model's knowledge and\nselectively weighting it by evaluating the credibility at both the class and\nsample level. The convergence guarantee of FedSSD is theoretically analyzed and\nextensive experiments are conducted on three public benchmark datasets, which\ndemonstrates that FedSSD achieves better generalization and robustness in fewer\ncommunication rounds, compared with other state-of-the-art FL methods.", "published": "2025-04-20 18:06:55", "link": "http://arxiv.org/abs/2504.14694v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Video-MMLU: A Massive Multi-Discipline Lecture Understanding Benchmark", "abstract": "Recent advancements in language multimodal models (LMMs) for video have\ndemonstrated their potential for understanding video content, yet the task of\ncomprehending multi-discipline lectures remains largely unexplored. We\nintroduce Video-MMLU, a massive benchmark designed to evaluate the capabilities\nof LMMs in understanding Multi-Discipline Lectures. We evaluate over 90\nopen-source and proprietary models, ranging from 0.5B to 40B parameters. Our\nresults highlight the limitations of current models in addressing the cognitive\nchallenges presented by these lectures, especially in tasks requiring both\nperception and reasoning. Additionally, we explore how the number of visual\ntokens and the large language models influence performance, offering insights\ninto the interplay between multimodal perception and reasoning in lecture\ncomprehension.", "published": "2025-04-20 17:58:46", "link": "http://arxiv.org/abs/2504.14693v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Uncovering Issues in the Radio Access Network by Looking at the Neighbors", "abstract": "Mobile network operators (MNOs) manage Radio Access Networks (RANs) with\nmassive amounts of cells over multiple radio generations (2G-5G). To handle\nsuch complexity, operations teams rely on monitoring systems, including anomaly\ndetection tools that identify unexpected behaviors. In this paper, we present\nc-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on Graph\nNeural Networks (GNNs). Our solution captures spatio-temporal variations by\nanalyzing the behavior of individual cells in relation to their local\nneighborhoods, enabling the detection of anomalies that are independent of\nexternal mobility factors. This, in turn, allows focusing on anomalies\nassociated with network issues (e.g., misconfigurations, equipment failures).\nWe evaluate c-ANEMON using real-world data from a large European metropolitan\narea (7,890 cells; 3 months). First, we show that the GNN model within our\nsolution generalizes effectively to cells from previously unseen areas,\nsuggesting the possibility of using a single model across extensive deployment\nregions. Then, we analyze the anomalies detected by c-ANEMON through manual\ninspection and define several categories of long-lasting anomalies (6+ hours).\nNotably, 45.95% of these anomalies fall into a category that is more likely to\nrequire intervention by operations teams.", "published": "2025-04-20 17:36:52", "link": "http://arxiv.org/abs/2504.14686v1", "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "An LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework", "abstract": "Existing LLM-enabled multi-agent frameworks are predominantly limited to\ndigital or simulated environments and confined to narrowly focused knowledge\ndomain, constraining their applicability to complex engineering tasks that\nrequire the design of physical embodiment, cross-disciplinary integration, and\nconstraint-aware reasoning. This work proposes a multi-agent autonomous\nmechatronics design framework, integrating expertise across mechanical design,\noptimization, electronics, and software engineering to autonomously generate\nfunctional prototypes with minimal direct human design input. Operating\nprimarily through a language-driven workflow, the framework incorporates\nstructured human feedback to ensure robust performance under real-world\nconstraints. To validate its capabilities, the framework is applied to a\nreal-world challenge involving autonomous water-quality monitoring and\nsampling, where traditional methods are labor-intensive and ecologically\ndisruptive. Leveraging the proposed system, a fully functional autonomous\nvessel was developed with optimized propulsion, cost-effective electronics, and\nadvanced control. The design process was carried out by specialized agents,\nincluding a high-level planning agent responsible for problem abstraction and\ndedicated agents for structural, electronics, control, and software\ndevelopment. This approach demonstrates the potential of LLM-based multi-agent\nsystems to automate real-world engineering workflows and reduce reliance on\nextensive domain expertise.", "published": "2025-04-20 16:57:45", "link": "http://arxiv.org/abs/2504.14681v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Evaluating Temporal Plasticity in Foundation Time Series Models for Incremental Fine-tuning", "abstract": "Time series foundation models excel at diverse time series forecasting tasks,\nbut their capacity for continuous improvement through incremental learning\nremains unexplored. We present the first comprehensive study investigating\nthese models' temporal plasticity - their ability to progressively enhance\nperformance through continual learning while maintaining existing capabilities.\nThrough experiments on real-world datasets exhibiting distribution shifts, we\nevaluate both conventional deep learning models and foundation models using a\nnovel continual learning framework. Our findings reveal that while traditional\nmodels struggle with performance deterioration during incremental fine-tuning,\nfoundation models like Time-MoE and Chronos demonstrate sustained improvement\nin predictive accuracy. This suggests that optimizing foundation model\nfine-tuning strategies may be more valuable than developing domain-specific\nsmall models. Our research introduces new evaluation methodologies and insights\nfor developing foundation time series models with robust continuous learning\ncapabilities.", "published": "2025-04-20 16:43:01", "link": "http://arxiv.org/abs/2504.14677v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents", "abstract": "Large Language Models (LLMs) exhibit substantial promise in enhancing\ntask-planning capabilities within embodied agents due to their advanced\nreasoning and comprehension. However, the systemic safety of these agents\nremains an underexplored frontier. In this study, we present Safe-BeAl, an\nintegrated framework for the measurement (SafePlan-Bench) and alignment\n(Safe-Align) of LLM-based embodied agents' behaviors. SafePlan-Bench\nestablishes a comprehensive benchmark for evaluating task-planning safety,\nencompassing 2,027 daily tasks and corresponding environments distributed\nacross 8 distinct hazard categories (e.g., Fire Hazard). Our empirical analysis\nreveals that even in the absence of adversarial inputs or malicious intent,\nLLM-based agents can exhibit unsafe behaviors. To mitigate these hazards, we\npropose Safe-Align, a method designed to integrate physical-world safety\nknowledge into LLM-based embodied agents while maintaining task-specific\nperformance. Experiments across a variety of settings demonstrate that\nSafe-BeAl provides comprehensive safety validation, improving safety by 8.55 -\n15.22%, compared to embodied agents based on GPT-4, while ensuring successful\ntask completion.", "published": "2025-04-20 15:12:14", "link": "http://arxiv.org/abs/2504.14650v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Surrogate Fitness Metrics for Interpretable Reinforcement Learning", "abstract": "We employ an evolutionary optimization framework that perturbs initial states\nto generate informative and diverse policy demonstrations. A joint surrogate\nfitness function guides the optimization by combining local diversity,\nbehavioral certainty, and global population diversity. To assess demonstration\nquality, we apply a set of evaluation metrics, including the reward-based\noptimality gap, fidelity interquartile means (IQMs), fitness composition\nanalysis, and trajectory visualizations. Hyperparameter sensitivity is also\nexamined to better understand the dynamics of trajectory optimization. Our\nfindings demonstrate that optimizing trajectory selection via surrogate fitness\nmetrics significantly improves interpretability of RL policies in both discrete\nand continuous environments. In gridworld domains, evaluations reveal\nsignificantly enhanced demonstration fidelities compared to random and ablated\nbaselines. In continuous control, the proposed framework offers valuable\ninsights, particularly for early-stage policies, while fidelity-based\noptimization proves more effective for mature policies. By refining and\nsystematically analyzing surrogate fitness functions, this study advances the\ninterpretability of RL models. The proposed improvements provide deeper\ninsights into RL decision-making, benefiting applications in safety-critical\nand explainability-focused domains.", "published": "2025-04-20 15:01:19", "link": "http://arxiv.org/abs/2504.14645v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AlphaZero-Edu: Making AlphaZero Accessible to Everyone", "abstract": "Recent years have witnessed significant progress in reinforcement learning,\nespecially with Zero-like paradigms, which have greatly boosted the\ngeneralization and reasoning abilities of large-scale language models.\nNevertheless, existing frameworks are often plagued by high implementation\ncomplexity and poor reproducibility. To tackle these challenges, we present\nAlphaZero-Edu, a lightweight, education-focused implementation built upon the\nmathematical framework of AlphaZero. It boasts a modular architecture that\ndisentangles key components, enabling transparent visualization of the\nalgorithmic processes. Additionally, it is optimized for resource-efficient\ntraining on a single NVIDIA RTX 3090 GPU and features highly parallelized\nself-play data generation, achieving a 3.2-fold speedup with 8 processes. In\nGomoku matches, the framework has demonstrated exceptional performance,\nachieving a consistently high win rate against human opponents. AlphaZero-Edu\nhas been open-sourced at https://github.com/StarLight1212/AlphaZero_Edu,\nproviding an accessible and practical benchmark for both academic research and\nindustrial applications.", "published": "2025-04-20 14:29:39", "link": "http://arxiv.org/abs/2504.14636v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "abstract": "Large language models (LLMs) have transformed code generation, yet their\napplication in hardware design produces gate counts 38\\%--1075\\% higher than\nhuman designs. We present CircuitMind, a multi-agent framework that achieves\nhuman-competitive efficiency through three key innovations: syntax locking\n(constraining generation to basic logic gates), retrieval-augmented generation\n(enabling knowledge-driven design), and dual-reward optimization (balancing\ncorrectness with efficiency). To evaluate our approach, we introduce TC-Bench,\nthe first gate-level benchmark harnessing collective intelligence from the\nTuringComplete ecosystem -- a competitive circuit design platform with hundreds\nof thousands of players. Experiments show CircuitMind enables 55.6\\% of model\nimplementations to match or exceed top-tier human experts in composite\nefficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model\nto outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency\ncomparable to the top 25\\% of human experts without requiring specialized\ntraining. These innovations establish a new paradigm for hardware optimization\nwhere collaborative AI systems leverage collective human expertise to achieve\noptimal circuit designs. Our model, data, and code are open-source at\nhttps://github.com/BUAA-CLab/CircuitMind.", "published": "2025-04-20 14:05:17", "link": "http://arxiv.org/abs/2504.14625v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Consensus in Motion: A Case of Dynamic Rationality of Sequential Learning in Probability Aggregation", "abstract": "We propose a framework for probability aggregation based on propositional\nprobability logic. Unlike conventional judgment aggregation, which focuses on\nstatic rationality, our model addresses dynamic rationality by ensuring that\ncollective beliefs update consistently with new information. We show that any\nconsensus-compatible and independent aggregation rule on a non-nested agenda is\nnecessarily linear. Furthermore, we provide sufficient conditions for a fair\nlearning process, where individuals initially agree on a specified subset of\npropositions known as the common ground, and new information is restricted to\nthis shared foundation. This guarantees that updating individual judgments via\nBayesian conditioning-whether performed before or after aggregation-yields the\nsame collective belief. A distinctive feature of our framework is its treatment\nof sequential decision-making, which allows new information to be incorporated\nprogressively through multiple stages while maintaining the established common\nground. We illustrate our findings with a running example in a political\nscenario concerning healthcare and immigration policies.", "published": "2025-04-20 14:04:39", "link": "http://arxiv.org/abs/2504.14624v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Advancing Video Anomaly Detection: A Bi-Directional Hybrid Framework for Enhanced Single- and Multi-Task Approaches", "abstract": "Despite the prevailing transition from single-task to multi-task approaches\nin video anomaly detection, we observe that many adopt sub-optimal frameworks\nfor individual proxy tasks. Motivated by this, we contend that optimizing\nsingle-task frameworks can advance both single- and multi-task approaches.\nAccordingly, we leverage middle-frame prediction as the primary proxy task, and\nintroduce an effective hybrid framework designed to generate accurate\npredictions for normal frames and flawed predictions for abnormal frames. This\nhybrid framework is built upon a bi-directional structure that seamlessly\nintegrates both vision transformers and ConvLSTMs. Specifically, we utilize\nthis bi-directional structure to fully analyze the temporal dimension by\npredicting frames in both forward and backward directions, significantly\nboosting the detection stability. Given the transformer's capacity to model\nlong-range contextual dependencies, we develop a convolutional temporal\ntransformer that efficiently associates feature maps from all context frames to\ngenerate attention-based predictions for target frames. Furthermore, we devise\na layer-interactive ConvLSTM bridge that facilitates the smooth flow of\nlow-level features across layers and time-steps, thereby strengthening\npredictions with fine details. Anomalies are eventually identified by\nscrutinizing the discrepancies between target frames and their corresponding\npredictions. Several experiments conducted on public benchmarks affirm the\nefficacy of our hybrid framework, whether used as a standalone single-task\napproach or integrated as a branch in a multi-task approach. These experiments\nalso underscore the advantages of merging vision transformers and ConvLSTMs for\nvideo anomaly detection.", "published": "2025-04-20 22:27:24", "link": "http://arxiv.org/abs/2504.14753v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "ChronoRoot 2.0: An Open AI-Powered Platform for 2D Temporal Plant Phenotyping", "abstract": "The analysis of plant developmental plasticity, including root system\narchitecture, is fundamental to understanding plant adaptability and\ndevelopment, particularly in the context of climate change and agricultural\nsustainability. While significant advances have been made in plant phenotyping\ntechnologies, comprehensive temporal analysis of root development remains\nchallenging, with most existing solutions providing either limited throughput\nor restricted structural analysis capabilities. Here, we present ChronoRoot\n2.0, an integrated open-source platform that combines affordable hardware with\nadvanced artificial intelligence to enable sophisticated temporal plant\nphenotyping. The system introduces several major advances, offering an integral\nperspective of seedling development: (i) simultaneous multi-organ tracking of\nsix distinct plant structures, (ii) quality control through real-time\nvalidation, (iii) comprehensive architectural measurements including novel\ngravitropic response parameters, and (iv) dual specialized user interfaces for\nboth architectural analysis and high-throughput screening. We demonstrate the\nsystem's capabilities through three use cases for Arabidopsis thaliana:\ncharacterization of circadian growth patterns under different light conditions,\ndetailed analysis of gravitropic responses in transgenic plants, and\nhigh-throughput screening of etiolation responses across multiple genotypes.\nChronoRoot 2.0 maintains its predecessor's advantages of low cost and\nmodularity while significantly expanding its capabilities, making sophisticated\ntemporal phenotyping more accessible to the broader plant science community.\nThe system's open-source nature, combined with extensive documentation and\ncontainerized deployment options, ensures reproducibility and enables\ncommunity-driven development of new analytical capabilities.", "published": "2025-04-20 20:56:25", "link": "http://arxiv.org/abs/2504.14736v1", "categories": ["cs.CV", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "TAPIP3D: Tracking Any Point in Persistent 3D Geometry", "abstract": "We introduce TAPIP3D, a novel approach for long-term 3D point tracking in\nmonocular RGB and RGB-D videos. TAPIP3D represents videos as camera-stabilized\nspatio-temporal feature clouds, leveraging depth and camera motion information\nto lift 2D video features into a 3D world space where camera motion is\neffectively canceled. TAPIP3D iteratively refines multi-frame 3D motion\nestimates within this stabilized representation, enabling robust tracking over\nextended periods. To manage the inherent irregularities of 3D point\ndistributions, we propose a Local Pair Attention mechanism. This 3D\ncontextualization strategy effectively exploits spatial relationships in 3D,\nforming informative feature neighborhoods for precise 3D trajectory estimation.\nOur 3D-centric approach significantly outperforms existing 3D point tracking\nmethods and even enhances 2D tracking accuracy compared to conventional 2D\npixel trackers when accurate depth is available. It supports inference in both\ncamera coordinates (i.e., unstabilized) and world coordinates, and our results\ndemonstrate that compensating for camera motion improves tracking performance.\nOur approach replaces the conventional 2D square correlation neighborhoods used\nin prior 2D and 3D trackers, leading to more robust and accurate results across\nvarious 3D point tracking benchmarks. Project Page: https://tapip3d.github.io", "published": "2025-04-20 19:09:43", "link": "http://arxiv.org/abs/2504.14717v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Med-2D SegNet: A Light Weight Deep Neural Network for Medical 2D Image Segmentation", "abstract": "Accurate and efficient medical image segmentation is crucial for advancing\nclinical diagnostics and surgical planning, yet remains a complex challenge due\nto the variability in anatomical structures and the demand for low-complexity\nmodels. In this paper, we introduced Med-2D SegNet, a novel and highly\nefficient segmentation architecture that delivers outstanding accuracy while\nmaintaining a minimal computational footprint. Med-2D SegNet achieves\nstate-of-the-art performance across multiple benchmark datasets, including\nKVASIR-SEG, PH2, EndoVis, and GLAS, with an average Dice similarity coefficient\n(DSC) of 89.77% across 20 diverse datasets. Central to its success is the\ncompact Med Block, a specialized encoder design that incorporates dimension\nexpansion and parameter reduction, enabling precise feature extraction while\nkeeping model parameters to a low count of just 2.07 million. Med-2D SegNet\nexcels in cross-dataset generalization, particularly in polyp segmentation,\nwhere it was trained on KVASIR-SEG and showed strong performance on unseen\ndatasets, demonstrating its robustness in zero-shot learning scenarios, even\nthough we acknowledge that further improvements are possible. With top-tier\nperformance in both binary and multi-class segmentation, Med-2D SegNet\nredefines the balance between accuracy and efficiency, setting a new benchmark\nfor medical image analysis. This work paves the way for developing accessible,\nhigh-performance diagnostic tools suitable for clinical environments and\nresource-constrained settings, making it a step forward in the democratization\nof advanced medical technology.", "published": "2025-04-20 19:04:43", "link": "http://arxiv.org/abs/2504.14715v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seurat: From Moving Points to Depth", "abstract": "Accurate depth estimation from monocular videos remains challenging due to\nambiguities inherent in single-view geometry, as crucial depth cues like\nstereopsis are absent. However, humans often perceive relative depth\nintuitively by observing variations in the size and spacing of objects as they\nmove. Inspired by this, we propose a novel method that infers relative depth by\nexamining the spatial relationships and temporal evolution of a set of tracked\n2D trajectories. Specifically, we use off-the-shelf point tracking models to\ncapture 2D trajectories. Then, our approach employs spatial and temporal\ntransformers to process these trajectories and directly infer depth changes\nover time. Evaluated on the TAPVid-3D benchmark, our method demonstrates robust\nzero-shot performance, generalizing effectively from synthetic to real-world\ndatasets. Results indicate that our approach achieves temporally smooth,\nhigh-accuracy depth predictions across diverse domains.", "published": "2025-04-20 17:37:02", "link": "http://arxiv.org/abs/2504.14687v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens", "abstract": "Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unify\nvisual comprehension and generation by combining LLM and diffusion models, the\nstate-of-the-art in each task, respectively. Existing approaches rely on\nspatial visual tokens, where image patches are encoded and arranged according\nto a spatial order (e.g., raster scan). However, we show that spatial tokens\nlack the recursive structure inherent to languages, hence form an impossible\nlanguage for LLM to master. In this paper, we build a proper visual language by\nleveraging diffusion timesteps to learn discrete, recursive visual tokens. Our\nproposed tokens recursively compensate for the progressive attribute loss in\nnoisy images as timesteps increase, enabling the diffusion model to reconstruct\nthe original image at any timestep. This approach allows us to effectively\nintegrate the strengths of LLMs in autoregressive reasoning and diffusion\nmodels in precise image generation, achieving seamless multimodal comprehension\nand generation within a unified framework. Extensive experiments show that we\nachieve superior performance for multimodal comprehension and generation\nsimultaneously compared with other MLLMs. Project Page:\nhttps://DDT-LLaMA.github.io/.", "published": "2025-04-20 16:14:28", "link": "http://arxiv.org/abs/2504.14666v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DMPCN: Dynamic Modulated Predictive Coding Network with Hybrid Feedback Representations", "abstract": "Traditional predictive coding networks, inspired by theories of brain\nfunction, consistently achieve promising results across various domains,\nextending their influence into the field of computer vision. However, the\nperformance of the predictive coding networks is limited by their error\nfeedback mechanism, which traditionally employs either local or global\nrecurrent updates, leading to suboptimal performance in processing both local\nand broader details simultaneously. In addition, traditional predictive coding\nnetworks face difficulties in dynamically adjusting to the complexity and\ncontext of varying input data, which is crucial for achieving high levels of\nperformance in diverse scenarios. Furthermore, there is a gap in the\ndevelopment and application of specific loss functions that could more\neffectively guide the model towards optimal performance. To deal with these\nissues, this paper introduces a hybrid prediction error feedback mechanism with\ndynamic modulation for deep predictive coding networks by effectively combining\nglobal contexts and local details while adjusting feedback based on input\ncomplexity. Additionally, we present a loss function tailored to this framework\nto improve accuracy by focusing on precise prediction error minimization.\nExperimental results demonstrate the superiority of our model over other\napproaches, showcasing faster convergence and higher predictive accuracy in\nCIFAR-10, CIFAR-100, MNIST, and FashionMNIST datasets.", "published": "2025-04-20 16:14:07", "link": "http://arxiv.org/abs/2504.14665v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Frequency-domain Learning with Kernel Prior for Blind Image Deblurring", "abstract": "While achieving excellent results on various datasets, many deep learning\nmethods for image deblurring suffer from limited generalization capabilities\nwith out-of-domain data. This limitation is likely caused by their dependence\non certain domain-specific datasets. To address this challenge, we argue that\nit is necessary to introduce the kernel prior into deep learning methods, as\nthe kernel prior remains independent of the image context. For effective fusion\nof kernel prior information, we adopt a rational implementation method inspired\nby traditional deblurring algorithms that perform deconvolution in the\nfrequency domain. We propose a module called Frequency Integration Module (FIM)\nfor fusing the kernel prior and combine it with a frequency-based deblurring\nTransfomer network. Experimental results demonstrate that our method\noutperforms state-of-the-art methods on multiple blind image deblurring tasks,\nshowcasing robust generalization abilities. Source code will be available soon.", "published": "2025-04-20 16:00:38", "link": "http://arxiv.org/abs/2504.14664v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mitigating Parameter Interference in Model Merging via Sharpness-Aware Fine-Tuning", "abstract": "Large-scale deep learning models with a pretraining-finetuning paradigm have\nled to a surge of numerous task-specific models fine-tuned from a common\npre-trained model. Recently, several research efforts have been made on merging\nthese large models into a single multi-task model, particularly with simple\narithmetic on parameters. Such merging methodology faces a central challenge:\ninterference between model parameters fine-tuned on different tasks. Few recent\nworks have focused on designing a new fine-tuning scheme that can lead to small\nparameter interference, however at the cost of the performance of each\ntask-specific fine-tuned model and thereby limiting that of a merged model. To\nimprove the performance of a merged model, we note that a fine-tuning scheme\nshould aim for (1) smaller parameter interference and (2) better performance of\neach fine-tuned model on the corresponding task. In this work, we aim to design\na new fine-tuning objective function to work towards these two goals. In the\ncourse of this process, we find such objective function to be strikingly\nsimilar to sharpness-aware minimization (SAM) objective function, which aims to\nachieve generalization by finding flat minima. Drawing upon our observation, we\npropose to fine-tune pre-trained models via sharpness-aware minimization. The\nexperimental and theoretical results showcase the effectiveness and\northogonality of our proposed approach, improving performance upon various\nmerging and fine-tuning methods. Our code is available at\nhttps://github.com/baiklab/SAFT-Merge.", "published": "2025-04-20 15:57:12", "link": "http://arxiv.org/abs/2504.14662v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "EmoSEM: Segment and Explain Emotion Stimuli in Visual Art", "abstract": "This paper focuses on a key challenge in visual art understanding: given an\nart image, the model pinpoints pixel regions that trigger a specific human\nemotion, and generates linguistic explanations for the emotional arousal.\nDespite recent advances in art understanding, pixel-level emotion understanding\nstill faces a dual challenge: first, the subjectivity of emotion makes it\ndifficult for general segmentation models like SAM to adapt to emotion-oriented\nsegmentation tasks; and second, the abstract nature of art expression makes it\ndifficult for captioning models to balance pixel-level semantic understanding\nand emotion reasoning. To solve the above problems, this paper proposes the\nEmotion stimuli Segmentation and Explanation Model (EmoSEM) to endow the\nsegmentation model SAM with emotion comprehension capability. First, to enable\nthe model to perform segmentation under the guidance of emotional intent well,\nwe introduce an emotional prompt with a learnable mask token as the conditional\ninput for segmentation decoding. Then, we design an emotion projector to\nestablish the association between emotion and visual features. Next, more\nimportantly, to address emotion-visual stimuli alignment, we develop a\nlightweight prefix projector, a module that fuses the learned emotional mask\nwith the corresponding emotion into a unified representation compatible with\nthe language model.Finally, we input the joint visual, mask, and emotional\ntokens into the language model and output the emotional explanations. It\nensures that the generated interpretations remain semantically and emotionally\ncoherent with the visual stimuli. The method innovatively realizes end-to-end\nmodeling from low-level pixel features to high-level emotion interpretation,\nproviding the first interpretable fine-grained analysis framework for artistic\nemotion computing. Extensive experiments validate the effectiveness of our\nmodel.", "published": "2025-04-20 15:40:00", "link": "http://arxiv.org/abs/2504.14658v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Relation-R1: Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relational Comprehension", "abstract": "Recent advances in multi-modal large language models (MLLMs) have\nsignificantly improved object-level grounding and region captioning, but remain\nlimited in visual relation understanding (\\eg, scene graph generation),\nparticularly in modeling \\textit{N}-ary relationships that identify multiple\nsemantic roles among an action event. Such a lack of \\textit{semantic\ndependencies} modeling among multi-entities leads to unreliable outputs,\nintensifying MLLMs' hallucinations and over-reliance on language priors. To\nthis end, we propose Relation-R1, the first unified relational comprehension\nframework that explicitly integrates cognitive chain-of-thought (CoT)-guided\nSupervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO)\nwithin a reinforcement learning (RL) paradigm. Specifically, we first establish\nfoundational reasoning capabilities via SFT, enforcing structured outputs with\nthinking processes. Then, GRPO is utilized to refine these outputs via\nmulti-reward optimization, prioritizing visual-semantic grounding over\nlanguage-induced biases, thereby improving generalization capability. Extensive\nexperiments on widely-used PSG and SWiG datasets demonstrate that Relation-R1\nachieves state-of-the-art performance in both binary and \\textit{N}-ary\nrelation understanding.", "published": "2025-04-20 14:50:49", "link": "http://arxiv.org/abs/2504.14642v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NVSMask3D: Hard Visual Prompting with Camera Pose Interpolation for 3D Open Vocabulary Instance Segmentation", "abstract": "Vision-language models (VLMs) have demonstrated impressive zero-shot transfer\ncapabilities in image-level visual perception tasks. However, they fall short\nin 3D instance-level segmentation tasks that require accurate localization and\nrecognition of individual objects. To bridge this gap, we introduce a novel 3D\nGaussian Splatting based hard visual prompting approach that leverages camera\ninterpolation to generate diverse viewpoints around target objects without any\n2D-3D optimization or fine-tuning. Our method simulates realistic 3D\nperspectives, effectively augmenting existing hard visual prompts by enforcing\ngeometric consistency across viewpoints. This training-free strategy seamlessly\nintegrates with prior hard visual prompts, enriching object-descriptive\nfeatures and enabling VLMs to achieve more robust and accurate 3D instance\nsegmentation in diverse 3D scenes.", "published": "2025-04-20 14:39:27", "link": "http://arxiv.org/abs/2504.14638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Representations for Visual Proprioception in Inexpensive Robots", "abstract": "Robotic manipulation requires explicit or implicit knowledge of the robot's\njoint positions. Precise proprioception is standard in high-quality industrial\nrobots but is often unavailable in inexpensive robots operating in unstructured\nenvironments. In this paper, we ask: to what extent can a fast, single-pass\nregression architecture perform visual proprioception from a single external\ncamera image, available even in the simplest manipulation settings? We explore\nseveral latent representations, including CNNs, VAEs, ViTs, and bags of\nuncalibrated fiducial markers, using fine-tuning techniques adapted to the\nlimited data available. We evaluate the achievable accuracy through experiments\non an inexpensive 6-DoF robot.", "published": "2025-04-20 14:24:54", "link": "http://arxiv.org/abs/2504.14634v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MSAD-Net: Multiscale and Spatial Attention-based Dense Network for Lung Cancer Classification", "abstract": "Lung cancer, a severe form of malignant tumor that originates in the tissues\nof the lungs, can be fatal if not detected in its early stages. It ranks among\nthe top causes of cancer-related mortality worldwide. Detecting lung cancer\nmanually using chest X-Ray image or Computational Tomography (CT) scans image\nposes significant challenges for radiologists. Hence, there is a need for\nautomatic diagnosis system of lung cancers from radiology images. With the\nrecent emergence of deep learning, particularly through Convolutional Neural\nNetworks (CNNs), the automated detection of lung cancer has become a much\nsimpler task. Nevertheless, numerous researchers have addressed that the\nperformance of conventional CNNs may be hindered due to class imbalance issue,\nwhich is prevalent in medical images. In this research work, we have proposed a\nnovel CNN architecture ``Multi-Scale Dense Network (MSD-Net)''\n(trained-from-scratch). The novelties we bring in the proposed model are (I) We\nintroduce novel dense modules in the 4th block and 5th block of the CNN model.\nWe have leveraged 3 depthwise separable convolutional (DWSC) layers, and one\n1x1 convolutional layer in each dense module, in order to reduce complexity of\nthe model considerably. (II) Additionally, we have incorporated one skip\nconnection from 3rd block to 5th block and one parallel branch connection from\n4th block to Global Average Pooling (GAP) layer. We have utilized dilated\nconvolutional layer (with dilation rate=2) in the last parallel branch in order\nto extract multi-scale features. Extensive experiments reveal that our proposed\nmodel has outperformed latest CNN model ConvNext-Tiny, recent trend Vision\nTransformer (ViT), Pooling-based ViT (PiT), and other existing models by\nsignificant margins.", "published": "2025-04-20 14:07:21", "link": "http://arxiv.org/abs/2504.14626v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts", "abstract": "Wireless signal-based human sensing technologies, such as WiFi,\nmillimeter-wave (mmWave) radar, and Radio Frequency Identification (RFID),\nenable the detection and interpretation of human presence, posture, and\nactivities, thereby providing critical support for applications in public\nsecurity, healthcare, and smart environments. These technologies exhibit\nnotable advantages due to their non-contact operation and environmental\nadaptability; however, existing systems often fail to leverage the textual\ninformation inherent in datasets. To address this, we propose an innovative\ntext-enhanced wireless sensing framework, WiTalk, that seamlessly integrates\nsemantic knowledge through three hierarchical prompt strategies-label-only,\nbrief description, and detailed action description-without requiring\narchitectural modifications or incurring additional data costs. We rigorously\nvalidate this framework across three public benchmark datasets: XRF55 for human\naction recognition (HAR), and WiFiTAL and XRFV2 for WiFi temporal action\nlocalization (TAL). Experimental results demonstrate significant performance\nimprovements: on XRF55, accuracy for WiFi, RFID, and mmWave increases by 3.9%,\n2.59%, and 0.46%, respectively; on WiFiTAL, the average performance of WiFiTAD\nimproves by 4.98%; and on XRFV2, the mean average precision gains across\nvarious methods range from 4.02% to 13.68%. Our codes have been included in\nhttps://github.com/yangzhenkui/WiTalk.", "published": "2025-04-20 13:58:35", "link": "http://arxiv.org/abs/2504.14621v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VM-BHINet:Vision Mamba Bimanual Hand Interaction Network for 3D Interacting Hand Mesh Recovery From a Single RGB Image", "abstract": "Understanding bimanual hand interactions is essential for realistic 3D pose\nand shape reconstruction. However, existing methods struggle with occlusions,\nambiguous appearances, and computational inefficiencies. To address these\nchallenges, we propose Vision Mamba Bimanual Hand Interaction Network\n(VM-BHINet), introducing state space models (SSMs) into hand reconstruction to\nenhance interaction modeling while improving computational efficiency. The core\ncomponent, Vision Mamba Interaction Feature Extraction Block (VM-IFEBlock),\ncombines SSMs with local and global feature operations, enabling deep\nunderstanding of hand interactions. Experiments on the InterHand2.6M dataset\nshow that VM-BHINet reduces Mean per-joint position error (MPJPE) and Mean\nper-vertex position error (MPVPE) by 2-3%, significantly surpassing\nstate-of-the-art methods.", "published": "2025-04-20 13:54:22", "link": "http://arxiv.org/abs/2504.14618v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MP-Mat: A 3D-and-Instance-Aware Human Matting and Editing Framework with Multiplane Representation", "abstract": "Human instance matting aims to estimate an alpha matte for each human\ninstance in an image, which is challenging as it easily fails in complex cases\nrequiring disentangling mingled pixels belonging to multiple instances along\nhairy and thin boundary structures. In this work, we address this by\nintroducing MP-Mat, a novel 3D-and-instance-aware matting framework with\nmultiplane representation, where the multiplane concept is designed from two\ndifferent perspectives: scene geometry level and instance level. Specifically,\nwe first build feature-level multiplane representations to split the scene into\nmultiple planes based on depth differences. This approach makes the scene\nrepresentation 3D-aware, and can serve as an effective clue for splitting\ninstances in different 3D positions, thereby improving interpretability and\nboundary handling ability especially in occlusion areas. Then, we introduce\nanother multiplane representation that splits the scene in an instance-level\nperspective, and represents each instance with both matte and color. We also\ntreat background as a special instance, which is often overlooked by existing\nmethods. Such an instance-level representation facilitates both foreground and\nbackground content awareness, and is useful for other down-stream tasks like\nimage editing. Once built, the representation can be reused to realize\ncontrollable instance-level image editing with high efficiency. Extensive\nexperiments validate the clear advantage of MP-Mat in matting task. We also\ndemonstrate its superiority in image editing tasks, an area under-explored by\nexisting matting-focused methods, where our approach under zero-shot inference\neven outperforms trained specialized image editing techniques by large margins.\nCode is open-sourced at https://github.com/JiaoSiyi/MPMat.git}.", "published": "2025-04-20 13:15:07", "link": "http://arxiv.org/abs/2504.14606v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NTIRE 2025 Challenge on Real-World Face Restoration: Methods and Results", "abstract": "This paper provides a review of the NTIRE 2025 challenge on real-world face\nrestoration, highlighting the proposed solutions and the resulting outcomes.\nThe challenge focuses on generating natural, realistic outputs while\nmaintaining identity consistency. Its goal is to advance state-of-the-art\nsolutions for perceptual quality and realism, without imposing constraints on\ncomputational resources or training data. The track of the challenge evaluates\nperformance using a weighted image quality assessment (IQA) score and employs\nthe AdaFace model as an identity checker. The competition attracted 141\nregistrants, with 13 teams submitting valid models, and ultimately, 10 teams\nachieved a valid score in the final ranking. This collaborative effort advances\nthe performance of real-world face restoration while offering an in-depth\noverview of the latest trends in the field.", "published": "2025-04-20 13:00:24", "link": "http://arxiv.org/abs/2504.14600v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction", "abstract": "Building a generalizable self-correction system is crucial for robots to\nrecover from failures. Despite advancements in Multimodal Large Language Models\n(MLLMs) that empower robots with semantic reflection ability for failure,\ntranslating semantic reflection into how to correct fine-grained robotic\nactions remains a significant challenge. To address this gap, we build the\nPhoenix framework, which leverages motion instruction as a bridge to connect\nhigh-level semantic reflection with low-level robotic action correction. In\nthis motion-based self-reflection framework, we start with a dual-process\nmotion adjustment mechanism with MLLMs to translate the semantic reflection\ninto coarse-grained motion instruction adjustment. To leverage this motion\ninstruction for guiding how to correct fine-grained robotic actions, a\nmulti-task motion-conditioned diffusion policy is proposed to integrate visual\nobservations for high-frequency robotic action correction. By combining these\ntwo models, we could shift the demand for generalization capability from the\nlow-level manipulation policy to the MLLMs-driven motion adjustment model and\nfacilitate precise, fine-grained robotic action correction. Utilizing this\nframework, we further develop a lifelong learning method to automatically\nimprove the model's capability from interactions with dynamic environments. The\nexperiments conducted in both the RoboMimic simulation and real-world scenarios\nprove the superior generalization and robustness of our framework across a\nvariety of manipulation tasks. Our code is released at\n\\href{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}.", "published": "2025-04-20 12:30:43", "link": "http://arxiv.org/abs/2504.14588v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Using street view imagery and deep generative modeling for estimating the health of urban forests", "abstract": "Healthy urban forests comprising of diverse trees and shrubs play a crucial\nrole in mitigating climate change. They provide several key advantages such as\nproviding shade for energy conservation, and intercepting rainfall to reduce\nflood runoff and soil erosion. Traditional approaches for monitoring the health\nof urban forests require instrumented inspection techniques, often involving a\nhigh amount of human labor and subjective evaluations. As a result, they are\nnot scalable for cities which lack extensive resources. Recent approaches\ninvolving multi-spectral imaging data based on terrestrial sensing and\nsatellites, are constrained respectively with challenges related to dedicated\ndeployments and limited spatial resolutions. In this work, we propose an\nalternative approach for monitoring the urban forests using simplified inputs:\nstreet view imagery, tree inventory data and meteorological conditions. We\npropose to use image-to-image translation networks to estimate two urban forest\nhealth parameters, namely, NDVI and CTD. Finally, we aim to compare the\ngenerated results with ground truth data using an onsite campaign utilizing\nhandheld multi-spectral and thermal imaging sensors. With the advent and\nexpansion of street view imagery platforms such as Google Street View and\nMapillary, this approach should enable effective management of urban forests\nfor the authorities in cities at scale.", "published": "2025-04-20 12:09:15", "link": "http://arxiv.org/abs/2504.14583v1", "categories": ["cs.CV", "cs.CY"], "primary_category": "cs.CV"}
{"title": "NTIRE 2025 Challenge on Image Super-Resolution ($\\times$4): Methods and Results", "abstract": "This paper presents the NTIRE 2025 image super-resolution ($\\times$4)\nchallenge, one of the associated competitions of the 10th NTIRE Workshop at\nCVPR 2025. The challenge aims to recover high-resolution (HR) images from\nlow-resolution (LR) counterparts generated through bicubic downsampling with a\n$\\times$4 scaling factor. The objective is to develop effective network designs\nor solutions that achieve state-of-the-art SR performance. To reflect the dual\nobjectives of image SR research, the challenge includes two sub-tracks: (1) a\nrestoration track, emphasizes pixel-wise accuracy and ranks submissions based\non PSNR; (2) a perceptual track, focuses on visual realism and ranks results by\na perceptual score. A total of 286 participants registered for the competition,\nwith 25 teams submitting valid entries. This report summarizes the challenge\ndesign, datasets, evaluation protocol, the main results, and methods of each\nteam. The challenge serves as a benchmark to advance the state of the art and\nfoster progress in image SR.", "published": "2025-04-20 12:08:22", "link": "http://arxiv.org/abs/2504.14582v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "How Local Separators Shape Community Structure in Large Networks", "abstract": "Community detection is a key tool for analyzing the structure of large\nnetworks. Standard methods, such as modularity optimization, focus on\nidentifying densely connected groups but often overlook natural local\nseparations in the graph. In this paper, we investigate local separator\nmethods, which decompose networks based on structural bottlenecks rather than\nglobal connectivity. We systematically compare them with well-established\ncommunity detection algorithms on large real-world networks. Our results show\nthat local 1-separators consistently identify the densest communities,\noutperforming modularity-based methods in this regard, while local 2-separators\nreveal hierarchical structures but may over-fragment small clusters. These\nfindings are particularly strong for road networks, suggesting practical\napplications in transportation and infrastructure analysis. Our study\nhighlights local separators as a scalable and interpretable alternative for\nnetwork decomposition.", "published": "2025-04-20 05:59:16", "link": "http://arxiv.org/abs/2504.14501v1", "categories": ["cs.SI", "cs.DM", "68R10 (Primary) 05C40, 05C85, 05C90 (Secondary)", "G.2.2; G.2.1; F.2.2"], "primary_category": "cs.SI"}
{"title": "Generative Auto-Bidding with Value-Guided Explorations", "abstract": "Auto-bidding, with its strong capability to optimize bidding decisions within\ndynamic and competitive online environments, has become a pivotal strategy for\nadvertising platforms. Existing approaches typically employ rule-based\nstrategies or Reinforcement Learning (RL) techniques. However, rule-based\nstrategies lack the flexibility to adapt to time-varying market conditions, and\nRL-based methods struggle to capture essential historical dependencies and\nobservations within Markov Decision Process (MDP) frameworks. Furthermore,\nthese approaches often face challenges in ensuring strategy adaptability across\ndiverse advertising objectives. Additionally, as offline training methods are\nincreasingly adopted to facilitate the deployment and maintenance of stable\nonline strategies, the issues of documented behavioral patterns and behavioral\ncollapse resulting from training on fixed offline datasets become increasingly\nsignificant. To address these limitations, this paper introduces a novel\noffline Generative Auto-bidding framework with Value-Guided Explorations\n(GAVE). GAVE accommodates various advertising objectives through a score-based\nReturn-To-Go (RTG) module. Moreover, GAVE integrates an action exploration\nmechanism with an RTG-based evaluation method to explore novel actions while\nensuring stability-preserving updates. A learnable value function is also\ndesigned to guide the direction of action exploration and mitigate\nOut-of-Distribution (OOD) problems. Experimental results on two offline\ndatasets and real-world deployments demonstrate that GAVE outperforms\nstate-of-the-art baselines in both offline evaluations and online A/B tests.\nThe implementation code is publicly available to facilitate reproducibility and\nfurther research.", "published": "2025-04-20 12:28:49", "link": "http://arxiv.org/abs/2504.14587v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Matrix Factorization with Dynamic Multi-view Clustering for Recommender System", "abstract": "Matrix factorization (MF), a cornerstone of recommender systems, decomposes\nuser-item interaction matrices into latent representations. Traditional MF\napproaches, however, employ a two-stage, non-end-to-end paradigm, sequentially\nperforming recommendation and clustering, resulting in prohibitive\ncomputational costs for large-scale applications like e-commerce and IoT, where\nbillions of users interact with trillions of items. To address this, we propose\nMatrix Factorization with Dynamic Multi-view Clustering (MFDMC), a unified\nframework that balances efficient end-to-end training with comprehensive\nutilization of web-scale data and enhances interpretability. MFDMC leverages\ndynamic multi-view clustering to learn user and item representations,\nadaptively pruning poorly formed clusters. Each entity's representation is\nmodeled as a weighted projection of robust clusters, capturing its diverse\nroles across views. This design maximizes representation space utilization,\nimproves interpretability, and ensures resilience for downstream tasks.\nExtensive experiments demonstrate MFDMC's superior performance in recommender\nsystems and other representation learning domains, such as computer vision,\nhighlighting its scalability and versatility.", "published": "2025-04-20 10:47:21", "link": "http://arxiv.org/abs/2504.14565v1", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Regret-aware Re-ranking for Guaranteeing Two-sided Fairness and Accuracy in Recommender Systems", "abstract": "In multi-stakeholder recommender systems (RS), users and providers operate as\ntwo crucial and interdependent roles, whose interests must be well-balanced.\nPrior research, including our work BankFair, has demonstrated the importance of\nguaranteeing both provider fairness and user accuracy to meet their interests.\nHowever, when they balance the two objectives, another critical factor emerges\nin RS: individual fairness, which manifests as a significant disparity in\nindividual recommendation accuracy, with some users receiving high accuracy\nwhile others are left with notably low accuracy. This oversight severely harms\nthe interests of users and exacerbates social polarization. How to guarantee\nindividual fairness while ensuring user accuracy and provider fairness remains\nan unsolved problem. To bridge this gap, in this paper, we propose our method\nBankFair+. Specifically, BankFair+ extends BankFair with two steps: (1)\nintroducing a non-linear function from regret theory to ensure individual\nfairness while enhancing user accuracy; (2) formulating the re-ranking process\nas a regret-aware fuzzy programming problem to meet the interests of both\nindividual user and provider, therefore balancing the trade-off between\nindividual fairness and provider fairness. Experiments on two real-world\nrecommendation datasets demonstrate that BankFair+ outperforms all baselines\nregarding individual fairness, user accuracy, and provider fairness.", "published": "2025-04-20 09:43:23", "link": "http://arxiv.org/abs/2504.14550v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "abstract": "Leveraging large language models in real-world settings often entails a need\nto utilize domain-specific data and tools in order to follow the complex\nregulations that need to be followed for acceptable use. Within financial\nsectors, modern enterprises increasingly rely on Retrieval-Augmented Generation\n(RAG) systems to address complex compliance requirements in financial document\nworkflows. However, existing solutions struggle to account for the inherent\nheterogeneity of data (e.g., text, tables, diagrams) and evolving nature of\nregulatory standards used in financial filings, leading to compromised accuracy\nin critical information extraction. We propose the FinSage framework as a\nsolution, utilizing a multi-aspect RAG framework tailored for regulatory\ncompliance analysis in multi-modal financial documents. FinSage introduces\nthree innovative components: (1) a multi-modal pre-processing pipeline that\nunifies diverse data formats and generates chunk-level metadata summaries, (2)\na multi-path sparse-dense retrieval system augmented with query expansion\n(HyDE) and metadata-aware semantic search, and (3) a domain-specialized\nre-ranking module fine-tuned via Direct Preference Optimization (DPO) to\nprioritize compliance-critical content. Extensive experiments demonstrate that\nFinSage achieves an impressive recall of 92.51% on 75 expert-curated questions\nderived from surpasses the best baseline method on the FinanceBench question\nanswering datasets by 24.06% in accuracy. Moreover, FinSage has been\nsuccessfully deployed as financial question-answering agent in online meetings,\nwhere it has already served more than 1,200 people.", "published": "2025-04-20 04:58:14", "link": "http://arxiv.org/abs/2504.14493v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Optimal Additive Noise Mechanisms for Differential Privacy", "abstract": "We propose a unified optimization framework for designing continuous and\ndiscrete noise distributions that ensure differential privacy (DP) by\nminimizing R\\'enyi DP, a variant of DP, under a cost constraint. R\\'enyi DP has\nthe advantage that by considering different values of the R\\'enyi parameter\n$\\alpha$, we can tailor our optimization for any number of compositions. To\nsolve the optimization problem, we reduce it to a finite-dimensional convex\nformulation and perform preconditioned gradient descent. The resulting noise\ndistributions are then compared to their Gaussian and Laplace counterparts.\nNumerical results demonstrate that our optimized distributions are consistently\nbetter, with significant improvements in $(\\varepsilon, \\delta)$-DP guarantees\nin the moderate composition regimes, compared to Gaussian and Laplace\ndistributions with the same variance.", "published": "2025-04-20 20:04:41", "link": "http://arxiv.org/abs/2504.14730v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Additive energy, uncertainty principle and signal recovery mechanisms", "abstract": "Given a signal $f:G\\to\\mathbb{C}$, where $G$ is a finite abelian group, under\nwhat reasonable assumptions can we guarantee the exact recovery of $f$ from a\nproper subset of its Fourier coefficients? In 1989, Donoho and Stark\nestablished a result \\cite{DS89} using the classical uncertainty principle,\nwhich states that $|\\text{supp}(f)|\\cdot|\\text{supp}(\\hat{f})|\\geq |G|$ for any\nnonzero signal $f$. Another result, first proven by Santose and Symes\n\\cite{SS86}, was based on the Logan phenomenon \\cite{L65}. In particular, the\nresult showcases how the $L^1$ and $L^2$ minimizing signals with matching\nFourier frequencies often recovers the original signal.\n  The purpose of this paper is to relate these recovery mechanisms to additive\nenergy, a combinatorial measure denoted and defined by $$\\Lambda(A)=\\left|\n\\left\\{ (x_1, x_2, x_3, x_4) \\in A^4 \\mid x_1 + x_2 = x_3 + x_4 \\right\\}\n\\right|,$$ where $A\\subset\\mathbb{Z}_N^d$. In the first part of this paper, we\nuse combinatorial techniques to establish an improved variety of the\nuncertainty principle in terms of additive energy. In a similar fashion as the\nDonoho-Stark argument, we use this principle to establish an often stronger\nrecovery condition. In the latter half of the paper, we invoke these\ncombinatorial methods to demonstrate two $L^p$ minimizing recovery results.", "published": "2025-04-20 18:31:25", "link": "http://arxiv.org/abs/2504.14702v1", "categories": ["math.CA", "cs.IT", "math.IT", "94A12, 42B10"], "primary_category": "math.CA"}
{"title": "Reveal-or-Obscure: A Differentially Private Sampling Algorithm for Discrete Distributions", "abstract": "We introduce a differentially private (DP) algorithm called reveal-or-obscure\n(ROO) to generate a single representative sample from a dataset of $n$\nobservations drawn i.i.d. from an unknown discrete distribution $P$. Unlike\nmethods that add explicit noise to the estimated empirical distribution, ROO\nachieves $\\epsilon$-differential privacy by randomly choosing whether to\n\"reveal\" or \"obscure\" the empirical distribution. While ROO is structurally\nidentical to Algorithm 1 proposed by Cheu and Nayak (arXiv:2412.10512), we\nprove a strictly better bound on the sampling complexity than that established\nin Theorem 12 of (arXiv:2412.10512). To further improve the privacy-utility\ntrade-off, we propose a novel generalized sampling algorithm called\nData-Specific ROO (DS-ROO), where the probability of obscuring the empirical\ndistribution of the dataset is chosen adaptively. We prove that DS-ROO\nsatisfies $\\epsilon$-DP, and provide empirical evidence that DS-ROO can achieve\nbetter utility under the same privacy budget of vanilla ROO.", "published": "2025-04-20 18:20:11", "link": "http://arxiv.org/abs/2504.14696v1", "categories": ["cs.IT", "cs.CR", "cs.DS", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Binary cyclic codes from permutation polynomials over $\\mathbb{F}_{2^m}$", "abstract": "Binary cyclic codes having large dimensions and minimum distances close to\nthe square-root bound are highly valuable in applications where high-rate\ntransmission and robust error correction are both essential. They provide an\noptimal trade-off between these two factors, making them suitable for demanding\ncommunication and storage systems, post-quantum cryptography, radar and sonar\nsystems, wireless sensor networks, and space communications. This paper aims to\ninvestigate cyclic codes by an efficient approach introduced by Ding\n\\cite{SETA5} from several known classes of permutation monomials and trinomials\nover $\\mathbb{F}_{2^m}$. We present several infinite families of binary cyclic\ncodes of length $2^m-1$ with dimensions larger than $(2^m-1)/2$. By applying\nthe Hartmann-Tzeng bound, some of the lower bounds on the minimum distances of\nthese cyclic codes are relatively close to the square root bound. Moreover, we\nobtain a new infinite family of optimal binary cyclic codes with parameters\n$[2^m-1,2^m-2-3m,8]$, where $m\\geq 5$ is odd, according to the sphere-packing\nbound.", "published": "2025-04-20 16:33:57", "link": "http://arxiv.org/abs/2504.14674v1", "categories": ["cs.IT", "math.IT", "94B15, 11T71, 11T06", "B.4.1; H.1.1"], "primary_category": "cs.IT"}
{"title": "Markovian Continuity of the MMSE", "abstract": "Minimum mean square error (MMSE) estimation is widely used in signal\nprocessing and related fields. While it is known to be non-continuous with\nrespect to all standard notions of stochastic convergence, it remains robust in\npractical applications. In this work, we review the known counterexamples to\nthe continuity of the MMSE. We observe that, in these counterexamples, the\ndiscontinuity arises from an element in the converging measurement sequence\nproviding more information about the estimand than the limit of the measurement\nsequence. We argue that this behavior is uncharacteristic of real-world\napplications and introduce a new stochastic convergence notion, termed\nMarkovian convergence, to address this issue. We prove that the MMSE is, in\nfact, continuous under this new notion. We supplement this result with\nsemi-continuity and continuity guarantees of the MMSE in other settings and\nprove the continuity of the MMSE under linear estimation.", "published": "2025-04-20 15:42:41", "link": "http://arxiv.org/abs/2504.14659v1", "categories": ["eess.SP", "cs.IT", "math.IT", "math.ST", "stat.TH"], "primary_category": "eess.SP"}
{"title": "Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond", "abstract": "The emergence of sixth-generation and beyond communication systems is\nexpected to fundamentally transform digital experiences through introducing\nunparalleled levels of intelligence, efficiency, and connectivity. A promising\ntechnology poised to enable this revolutionary vision is the wireless large AI\nmodel (WLAM), characterized by its exceptional capabilities in data processing,\ninference, and decision-making. In light of these remarkable capabilities, this\npaper provides a comprehensive survey of WLAM, elucidating its fundamental\nprinciples, diverse applications, critical challenges, and future research\nopportunities. We begin by introducing the background of WLAM and analyzing the\nkey synergies with wireless networks, emphasizing the mutual benefits.\nSubsequently, we explore the foundational characteristics of WLAM, delving into\ntheir unique relevance in wireless environments. Then, the role of WLAM in\noptimizing wireless communication systems across various use cases and the\nreciprocal benefits are systematically investigated. Furthermore, we discuss\nthe integration of WLAM with emerging technologies, highlighting their\npotential to enable transformative capabilities and breakthroughs in wireless\ncommunication. Finally, we thoroughly examine the high-level challenges\nhindering the practical implementation of WLAM and discuss pivotal future\nresearch directions.", "published": "2025-04-20 15:25:58", "link": "http://arxiv.org/abs/2504.14653v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantic HARQ for Intelligent Transportation Systems: Joint Source-Channel Coding-Powered Reliable Retransmissions", "abstract": "The surge of data traffic in Intelligent Transportation Systems (ITS) places\na significant challenge on limited wireless resources. Semantic communication,\nwhich transmits essential semantics of the raw data, offers a promising\nsolution by reducing redundancy and improving spectrum efficiency. However,\nhigh vehicle mobility, dynamic channel conditions, and dense vehicular networks\nseverely impact transmission reliability in ITS. To address these limitations,\nwe integrate Hybrid Automatic Repeat reQuest (HARQ) with Joint Source-Channel\nCoding (JSCC) to provide reliable semantic communications for ITS. To\ncounteract the adverse effects of time-varying fading channels and noise, we\npropose a generative signal reconstructor module supported by a local knowledge\nbase, which employs a discriminator for channel error detection and a\nconditional generative network for error correction. We propose three\ninnovative semantic HARQ (sem-HARQ) schemes, Type I sem-HARQ (sem-HARQ-I),\nsem-HARQ with weighted combining (sem-HARQ-WC), and sem-HARQ with synonymous\ncombining (sem-HARQ-SC) to enable reliable JSCC-based semantic communications.\nAt the transmitter, both sem-HARQ-I and sem-HARQ-WC retransmit the same\nsemantic signals, while sem-HARQ-SC introduces redundant semantics across\ndifferent HARQ rounds through synonymous mapping. At the receiver, sem-HARQ-I\nperforms semantic decoding based solely on the currently received signal. In\ncontrast, sem-HARQ-WC enhances reliability by fusing the current received\nsemantic signal with prior erroneous signals at the feature or decision level,\nthereby exploiting semantic information from failed HARQ rounds. Similarly,\nsem-HARQ-SC employs feature-level combining, leveraging incremental semantic\nredundancy to merge semantic features from retransmissions.", "published": "2025-04-20 13:46:26", "link": "http://arxiv.org/abs/2504.14615v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalized Derangetropy Functionals for Modeling Cyclical Information Flow", "abstract": "This paper introduces a framework for modeling cyclical and feedback-driven\ninformation flow through a generalized family of entropy-modulated\ntransformations called derangetropy functionals. Unlike scalar and static\nentropy measures such as Shannon entropy, these functionals act directly on\nprobability densities and provide a topographical representation of information\nstructure across the support of the distribution. The framework captures\nperiodic and self-referential aspects of information distribution and encodes\nthem through functional operators governed by nonlinear differential equations.\nWhen applied recursively, these operators induce a spectral diffusion process\ngoverned by the heat equation, leading to convergence toward a Gaussian\ncharacteristic function. This convergence theorem provides a unified analytical\nfoundation for describing the long-term dynamics of information under cyclic\nmodulation. The proposed framework offers new tools for analyzing the temporal\nevolution of information in systems characterized by periodic structure,\nstochastic feedback, and delayed interaction, with applications in artificial\nneural networks, communication theory, and non-equilibrium statistical\nmechanics.", "published": "2025-04-20 13:09:21", "link": "http://arxiv.org/abs/2504.14605v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Joint Channel Estimation and Signal Detection for MIMO-OFDM: A Novel Data-Aided Approach with Reduced Computational Overhead", "abstract": "The acquisition of channel state information (CSI) is essential in MIMO-OFDM\ncommunication systems. Data-aided enhanced receivers, by incorporating domain\nknowledge, effectively mitigate performance degradation caused by imperfect\nCSI, particularly in dynamic wireless environments. However, existing\nmethodologies face notable challenges: they either refine channel estimates\nwithin MIMO subsystems separately, which proves ineffective due to deviations\nfrom assumptions regarding the time-varying nature of channels, or fully\nexploit the time-frequency characteristics but incur significantly high\ncomputational overhead due to dimensional concatenation. To address these\nissues, this study introduces a novel data-aided method aimed at reducing\ncomplexity, particularly suited for fast-fading scenarios in fifth-generation\n(5G) and beyond networks. We derive a general form of a data-aided linear\nminimum mean-square error (LMMSE)-based algorithm, optimized for iterative\njoint channel estimation and signal detection. Additionally, we propose a\ncomputationally efficient alternative to this algorithm, which achieves\ncomparable performance with significantly reduced complexity. Empirical\nevaluations reveal that our proposed algorithms outperform several\nstate-of-the-art approaches across various MIMO-OFDM configurations, pilot\nsequence lengths, and in the presence of time variability. Comparative analysis\nwith basis expansion model-based iterative receivers highlights the superiority\nof our algorithms in achieving an effective trade-off between accuracy and\ncomputational complexity.", "published": "2025-04-20 02:49:12", "link": "http://arxiv.org/abs/2504.14463v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Tunability of Random Survival Forests Model for Predictive Maintenance", "abstract": "This paper investigates the tunability of the Random Survival Forest (RSF)\nmodel in predictive maintenance, where accurate time-to-failure estimation is\ncrucial. Although RSF is widely used due to its flexibility and ability to\nhandle censored data, its performance is sensitive to hyperparameter\nconfigurations. However, systematic evaluations of RSF tunability remain\nlimited, especially in predictive maintenance contexts. We introduce a\nthree-level framework to quantify tunability: (1) a model-level metric\nmeasuring overall performance gain from tuning, (2) a hyperparameter-level\nmetric assessing individual contributions, and (3) identification of optimal\ntuning ranges. These metrics are evaluated across multiple datasets using\nsurvival-specific criteria: the C-index for discrimination and the Brier score\nfor calibration. Experiments on four CMAPSS dataset subsets, simulating\naircraft engine degradation, reveal that hyperparameter tuning consistently\nimproves model performance. On average, the C-index increased by 0.0547, while\nthe Brier score decreased by 0.0199. These gains were consistent across all\nsubsets. Moreover, ntree and mtry showed the highest average tunability, while\nnodesize offered stable improvements within the range of 10 to 30. In contrast,\nsplitrule demonstrated negative tunability on average, indicating that improper\ntuning may reduce model performance. Our findings emphasize the practical\nimportance of hyperparameter tuning in survival models and provide actionable\ninsights for optimizing RSF in real-world predictive maintenance applications.", "published": "2025-04-20 21:27:23", "link": "http://arxiv.org/abs/2504.14744v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "AltGDmin: Alternating GD and Minimization for Partly-Decoupled (Federated) Optimization", "abstract": "This article describes a novel optimization solution framework, called\nalternating gradient descent (GD) and minimization (AltGDmin), that is useful\nfor many problems for which alternating minimization (AltMin) is a popular\nsolution. AltMin is a special case of the block coordinate descent algorithm\nthat is useful for problems in which minimization w.r.t one subset of variables\nkeeping the other fixed is closed form or otherwise reliably solved. Denote the\ntwo blocks/subsets of the optimization variables Z by Za, Zb, i.e., Z = {Za,\nZb}. AltGDmin is often a faster solution than AltMin for any problem for which\n(i) the minimization over one set of variables, Zb, is much quicker than that\nover the other set, Za; and (ii) the cost function is differentiable w.r.t. Za.\nOften, the reason for one minimization to be quicker is that the problem is\n``decoupled\" for Zb and each of the decoupled problems is quick to solve. This\ndecoupling is also what makes AltGDmin communication-efficient for federated\nsettings.\n  Important examples where this assumption holds include (a) low rank\ncolumn-wise compressive sensing (LRCS), low rank matrix completion (LRMC), (b)\ntheir outlier-corrupted extensions such as robust PCA, robust LRCS and robust\nLRMC; (c) phase retrieval and its sparse and low-rank model based extensions;\n(d) tensor extensions of many of these problems such as tensor LRCS and tensor\ncompletion; and (e) many partly discrete problems where GD does not apply --\nsuch as clustering, unlabeled sensing, and mixed linear regression. LRCS finds\nimportant applications in multi-task representation learning and few shot\nlearning, federated sketching, and accelerated dynamic MRI. LRMC and robust PCA\nfind important applications in recommender systems, computer vision and video\nanalytics.", "published": "2025-04-20 21:07:59", "link": "http://arxiv.org/abs/2504.14741v1", "categories": ["cs.LG", "math.OC", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Reinforcement Learning from Multi-level and Episodic Human Feedback", "abstract": "Designing an effective reward function has long been a challenge in\nreinforcement learning, particularly for complex tasks in unstructured\nenvironments. To address this, various learning paradigms have emerged that\nleverage different forms of human input to specify or refine the reward\nfunction. Reinforcement learning from human feedback is a prominent approach\nthat utilizes human comparative feedback, expressed as a preference for one\nbehavior over another, to tackle this problem. In contrast to comparative\nfeedback, we explore multi-level human feedback, which is provided in the form\nof a score at the end of each episode. This type of feedback offers more coarse\nbut informative signals about the underlying reward function than binary\nfeedback. Additionally, it can handle non-Markovian rewards, as it is based on\nthe evaluation of an entire episode. We propose an algorithm to efficiently\nlearn both the reward function and the optimal policy from this form of\nfeedback. Moreover, we show that the proposed algorithm achieves sublinear\nregret and demonstrate its empirical effectiveness through extensive\nsimulations.", "published": "2025-04-20 20:09:19", "link": "http://arxiv.org/abs/2504.14732v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Geometric Learning Dynamics", "abstract": "We present a unified geometric framework for modeling learning dynamics in\nphysical, biological, and machine learning systems. The theory reveals three\nfundamental regimes, each emerging from the power-law relationship $g \\propto\n\\kappa^a$ between the metric tensor $g$ in the space of trainable variables and\nthe noise covariance matrix $\\kappa$. The quantum regime corresponds to $a = 1$\nand describes Schr\\\"odinger-like dynamics that emerges from a discrete shift\nsymmetry. The efficient learning regime corresponds to $a = \\tfrac{1}{2}$ and\ndescribes very fast machine learning algorithms. The equilibration regime\ncorresponds to $a = 0$ and describes classical models of biological evolution.\nWe argue that the emergence of the intermediate regime $a = \\tfrac{1}{2}$ is a\nkey mechanism underlying the emergence of biological complexity.", "published": "2025-04-20 19:56:41", "link": "http://arxiv.org/abs/2504.14728v1", "categories": ["cs.LG", "q-bio.PE", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Video QoE Metrics from Encrypted Traffic: Application-agnostic Methodology", "abstract": "Instant Messaging-Based Video Call Applications (IMVCAs) and Video\nConferencing Applications (VCAs) have become integral to modern communication.\nEnsuring a high Quality of Experience (QoE) for users in this context is\ncritical for network operators, as network conditions significantly impact user\nQoE. However, network operators lack access to end-device QoE metrics due to\nencrypted traffic. Existing solutions estimate QoE metrics from encrypted\ntraffic traversing the network, with the most advanced approaches leveraging\nmachine learning models. Subsequently, the need for ground truth QoE metrics\nfor training and validation poses a challenge, as not all video applications\nprovide these metrics. To address this challenge, we propose an\napplication-agnostic approach for objective QoE estimation from encrypted\ntraffic. Independent of the video application, we obtained key video QoE\nmetrics, enabling broad applicability to various proprietary IMVCAs and VCAs.\nTo validate our solution, we created a diverse dataset from WhatsApp video\nsessions under various network conditions, comprising 25,680 seconds of traffic\ndata and QoE metrics. Our evaluation shows high performance across the entire\ndataset, with 85.2% accuracy for FPS predictions within an error margin of two\nFPS, and 90.2% accuracy for PIQE-based quality rating classification.", "published": "2025-04-20 19:18:13", "link": "http://arxiv.org/abs/2504.14720v1", "categories": ["cs.NI", "cs.LG", "cs.MM", "C.2.1; C.2.3; I.2.6"], "primary_category": "cs.NI"}
{"title": "Pairwise or Pointwise? Evaluating Feedback Protocols for Bias in LLM-Based Evaluation", "abstract": "Large Language Models (LLMs) are widely used as proxies for human labelers in\nboth training (Reinforcement Learning from AI Feedback) and large-scale\nresponse evaluation (LLM-as-a-judge). Alignment and evaluation are critical\ncomponents in the development of reliable LLMs, and the choice of feedback\nprotocol plays a central role in both but remains understudied. In this work,\nwe show that the choice of feedback protocol (absolute scores versus relative\npreferences) can significantly affect evaluation reliability and induce\nsystematic biases. In particular, we show that pairwise evaluation protocols\nare more vulnerable to distracted evaluation. Generator models can exploit\nspurious attributes (or distractor features) favored by the LLM judge,\nresulting in inflated scores for lower-quality outputs and misleading training\nsignals. We find that absolute scoring is more robust to such manipulation,\nproducing judgments that better reflect response quality and are less\ninfluenced by distractor features. Our results demonstrate that generator\nmodels can flip preferences by embedding distractor features, skewing\nLLM-as-a-judge comparisons and leading to inaccurate conclusions about model\nquality in benchmark evaluations. Pairwise preferences flip in about 35% of the\ncases, compared to only 9% for absolute scores. We offer recommendations for\nchoosing feedback protocols based on dataset characteristics and evaluation\nobjectives.", "published": "2025-04-20 19:05:59", "link": "http://arxiv.org/abs/2504.14716v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Connecting Parameter Magnitudes and Hessian Eigenspaces at Scale using Sketched Methods", "abstract": "Recently, it has been observed that when training a deep neural net with SGD,\nthe majority of the loss landscape's curvature quickly concentrates in a tiny\n*top* eigenspace of the loss Hessian, which remains largely stable thereafter.\nIndependently, it has been shown that successful magnitude pruning masks for\ndeep neural nets emerge early in training and remain stable thereafter. In this\nwork, we study these two phenomena jointly and show that they are connected: We\ndevelop a methodology to measure the similarity between arbitrary parameter\nmasks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap*\nas the most useful such metric due to its interpretability and stability. To\ncompute *overlap*, we develop a matrix-free algorithm based on sketched SVDs\nthat allows us to compute over 1000 Hessian eigenpairs for nets with over 10M\nparameters --an unprecedented scale by several orders of magnitude. Our\nexperiments reveal an *overlap* between magnitude parameter masks and top\nHessian eigenspaces consistently higher than chance-level, and that this effect\ngets accentuated for larger network sizes. This result indicates that *top\nHessian eigenvectors tend to be concentrated around larger parameters*, or\nequivalently, that *larger parameters tend to align with directions of larger\nloss curvature*. Our work provides a methodology to approximate and analyze\ndeep learning Hessians at scale, as well as a novel insight on the structure of\ntheir eigenspace.", "published": "2025-04-20 18:29:39", "link": "http://arxiv.org/abs/2504.14701v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Quantitative Clustering in Mean-Field Transformer Models", "abstract": "The evolution of tokens through a deep transformer models can be modeled as\nan interacting particle system that has been shown to exhibit an asymptotic\nclustering behavior akin to the synchronization phenomenon in Kuramoto models.\nIn this work, we investigate the long-time clustering of mean-field transformer\nmodels. More precisely, we establish exponential rates of contraction to a\nDirac point mass for any suitably regular initialization under some assumptions\non the parameters of transformer models, any suitably regular mean-field\ninitialization synchronizes exponentially fast with some quantitative rates.", "published": "2025-04-20 18:21:34", "link": "http://arxiv.org/abs/2504.14697v1", "categories": ["cs.LG", "math.AP", "math.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Federated Split Learning for Large Language Models over Communication Networks", "abstract": "Fine-tuning pre-trained large language models (LLM) in a distributed manner\nposes significant challenges on resource-constrained edge devices. To address\nthis challenge, we propose FedsLLM, a novel framework that integrates split\nfederated learning with parameter-efficient fine-tuning techniques. By\nleveraging model splitting and Low-Rank Adaptation (LoRA), FedsLLM reduces the\ncomputational burden on edge devices. Furthermore, the introduction of a\nfederated server facilitates parallel training and enhances privacy. To\naccommodate heterogeneous communication conditions and diverse computational\ncapabilities of edge devices, as well as the impact of LoRA rank selection on\nmodel convergence and training cost, we formulate a joint optimization problem.\nThe formulated problem jointly optimizes subchannel allocation, power control,\nmodel splitting point selection, and LoRA rank configuration, all aimed at\nminimizing total training delay. An alternating optimization algorithm is\ndeveloped to efficiently solve this problem and accelerate the training\nprocess. Simulation results demonstrate that the proposed FedsLLM framework\nachieves comparable model accuracy while significantly reducing client-side\ncomputational requirements. Furthermore, the proposed resource allocation\nscheme and adaptive LoRA rank selection strategy notably reduce the training\nlatency compared to conventional approaches.", "published": "2025-04-20 16:16:54", "link": "http://arxiv.org/abs/2504.14667v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "GENE-FL: Gene-Driven Parameter-Efficient Dynamic Federated Learning", "abstract": "Real-world \\underline{F}ederated \\underline{L}earning systems often encounter\n\\underline{D}ynamic clients with \\underline{A}gnostic and highly heterogeneous\ndata distributions (DAFL), which pose challenges for efficient communication\nand model initialization. To address these challenges, we draw inspiration from\nthe recently proposed Learngene paradigm, which compresses the large-scale\nmodel into lightweight, cross-task meta-information fragments. Learngene\neffectively encapsulates and communicates core knowledge, making it\nparticularly well-suited for DAFL, where dynamic client participation requires\ncommunication efficiency and rapid adaptation to new data distributions. Based\non this insight, we propose a Gene-driven parameter-efficient dynamic Federated\nLearning (GENE-FL) framework. First, local models perform quadratic constraints\nbased on parameters with high Fisher values in the global model, as these\nparameters are considered to encapsulate generalizable knowledge. Second, we\napply the strategy of parameter sensitivity analysis in local model parameters\nto condense the \\textit{learnGene} for interaction. Finally, the server\naggregates these small-scale trained \\textit{learnGene}s into a robust\n\\textit{learnGene} with cross-task generalization capability, facilitating the\nrapid initialization of dynamic agnostic client models. Extensive experimental\nresults demonstrate that GENE-FL reduces \\textbf{4 $\\times$} communication\ncosts compared to FEDAVG and effectively initializes agnostic client models\nwith only about \\textbf{9.04} MB.", "published": "2025-04-20 14:10:02", "link": "http://arxiv.org/abs/2504.14628v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "No Imputation of Missing Values In Tabular Data Classification Using Incremental Learning", "abstract": "Tabular data sets with varying missing values are prepared for machine\nlearning using an arbitrary imputation strategy. Synthetic values generated by\nimputation models often concern data stakeholders about computational\ncomplexity, data quality, and data-driven outcomes. This paper eliminates these\nconcerns by proposing no imputation incremental learning (NIIL) of tabular data\nwith varying missing value rates and types. The proposed method incrementally\nlearns partitions of overlapping feature sets while using attention masks to\nexclude missing values from attention scoring. The average classification\nperformance rank order across 15 diverse tabular data sets highlights the\nsuperiority of NIIL over 11 state-of-the-art learning methods with or without\nmissing value imputations. Further experiments substantiate the robustness of\nNIIL against varying missing value types and rates compared to methods that\ninvolve the imputation of missing values. Our empirical analysis reveals that a\nfeature partition size of half of the original feature space is,\ncomputation-wise and accuracy-wise, the best choice for the proposed\nincremental learning. The proposed method is one of the first deep learning\nsolutions that can effectively learn tabular data without requiring the\nimputation of missing values.", "published": "2025-04-20 13:31:49", "link": "http://arxiv.org/abs/2504.14610v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data Selection for ERMs", "abstract": "Learning theory has traditionally followed a model-centric approach, focusing\non designing optimal algorithms for a fixed natural learning task (e.g., linear\nclassification or regression). In this paper, we adopt a complementary\ndata-centric perspective, whereby we fix a natural learning rule and focus on\noptimizing the training data. Specifically, we study the following question:\ngiven a learning rule $\\mathcal{A}$ and a data selection budget $n$, how well\ncan $\\mathcal{A}$ perform when trained on at most $n$ data points selected from\na population of $N$ points? We investigate when it is possible to select $n \\ll\nN$ points and achieve performance comparable to training on the entire\npopulation.\n  We address this question across a variety of empirical risk minimizers. Our\nresults include optimal data-selection bounds for mean estimation, linear\nclassification, and linear regression. Additionally, we establish two general\nresults: a taxonomy of error rates in binary classification and in stochastic\nconvex optimization. Finally, we propose several open questions and directions\nfor future research.", "published": "2025-04-20 11:26:01", "link": "http://arxiv.org/abs/2504.14572v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models", "abstract": "Large language models (LLMs) exhibit remarkable performance across various\nnatural language processing tasks but suffer from immense computational and\nmemory demands, limiting their deployment in resource-constrained environments.\nTo address this challenge, we propose NoWag: (Normalized Weight and Activation\nGuided Compression), a unified framework for zero-shot shape preserving\ncompression algorithms. We compressed Llama-2 7B/13B/70B and Llama-3 8/70BB\nmodels, using two popular forms of shape-preserving compression, vector\nquantization NoWag-VQ (NoWag for Vector Quantization), and\nunstructured/semi-structured pruning NoWag-P (NoWag for Pruning). We found that\nNoWag-VQ significantly outperforms state-of-the-art zero shot VQ, and that\nNoWag-P performs competitively against state-of-the-art methods. These results\nsuggest commonalities between these compression paradigms that could inspire\nfuture work. Our code is available at https://github.com/LawrenceRLiu/NoWag", "published": "2025-04-20 11:00:29", "link": "http://arxiv.org/abs/2504.14569v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Quantum-Enhanced Weight Optimization for Neural Networks Using Grover's Algorithm", "abstract": "The main approach to hybrid quantum-classical neural networks (QNN) is\nemploying quantum computing to build a neural network (NN) that has quantum\nfeatures, which is then optimized classically. Here, we propose a different\nstrategy: to use quantum computing in order to optimize the weights of a\nclassical NN. As such, we design an instance of Grover's quantum search\nalgorithm to accelerate the search for the optimal parameters of an NN during\nthe training process, a task traditionally performed using the backpropagation\nalgorithm with the gradient descent method. Indeed, gradient descent has issues\nsuch as exploding gradient, vanishing gradient, or convexity problem. Other\nmethods tried to address such issues with strategies like genetic searches, but\nthey carry additional problems like convergence consistency. Our original\nmethod avoids these issues -- because it does not calculate gradients -- and\ncapitalizes on classical architectures' robustness and Grover's quadratic\nspeedup in high-dimensional search spaces to significantly reduce test loss\n(58.75%) and improve test accuracy (35.25%), compared to classical NN weight\noptimization, on small datasets. Unlike most QNNs that are trained on small\ndatasets only, our method is also scalable, as it allows the optimization of\ndeep networks; for an NN with 3 hidden layers, trained on the Digits dataset\nfrom scikit-learn, we obtained a mean accuracy of 97.7%. Moreover, our method\nrequires a much smaller number of qubits compared to other QNN approaches,\nmaking it very practical for near-future quantum computers that will still\ndeliver a limited number of logical qubits.", "published": "2025-04-20 10:59:04", "link": "http://arxiv.org/abs/2504.14568v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "LLM-Enabled In-Context Learning for Data Collection Scheduling in UAV-assisted Sensor Networks", "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly being used in various\nprivate and commercial applications, e.g. traffic control, package delivery,\nand Search and Rescue (SAR) operations. Machine Learning (ML) methods used in\nUAV-assisted Sensor Networks (UASNETs) and especially in Deep Reinforcement\nLearning (DRL) face challenges such as complex and lengthy model training, gaps\nbetween simulation and reality, and low sample efficiency, which conflict with\nthe urgency of emergencies such as SAR operations. This paper proposes\nIn-Context Learning (ICL)-based Data Collection Scheduling (ICLDC) scheme, as\nan alternative to DRL in emergencies. The UAV collects and transmits logged\nsensory data, to an LLM, to generate a task description in natural language,\nfrom which it obtains a data collection schedule to be executed by the UAV. The\nsystem continuously adapts by adding feedback to task descriptions and\nutilizing feedback for future decisions. This method is tested against\njailbreaking attacks, where task description is manipulated to undermine\nnetwork performance, highlighting the vulnerability of LLMs to such attacks.\nThe proposed ICLDC outperforms the Maximum Channel Gain by reducing cumulative\npacket loss by approximately 56\\%. ICLDC presents a promising direction for\nintelligent scheduling and control in UAV-assisted data collection.", "published": "2025-04-20 10:05:07", "link": "http://arxiv.org/abs/2504.14556v1", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.RO", "53-01", "C.2"], "primary_category": "cs.AI"}
{"title": "TrustLoRA: Low-Rank Adaptation for Failure Detection under Out-of-distribution Data", "abstract": "Reliable prediction is an essential requirement for deep neural models that\nare deployed in open environments, where both covariate and semantic\nout-of-distribution (OOD) data arise naturally. In practice, to make safe\ndecisions, a reliable model should accept correctly recognized inputs while\nrejecting both those misclassified covariate-shifted and semantic-shifted\nexamples. Besides, considering the potential existing trade-off between\nrejecting different failure cases, more convenient, controllable, and flexible\nfailure detection approaches are needed. To meet the above requirements, we\npropose a simple failure detection framework to unify and facilitate\nclassification with rejection under both covariate and semantic shifts. Our key\ninsight is that by separating and consolidating failure-specific reliability\nknowledge with low-rank adapters and then integrating them, we can enhance the\nfailure detection ability effectively and flexibly. Extensive experiments\ndemonstrate the superiority of our framework.", "published": "2025-04-20 09:20:55", "link": "http://arxiv.org/abs/2504.14545v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Model Resistant to Transferable Adversarial Examples via Trigger Activation", "abstract": "Adversarial examples, characterized by imperceptible perturbations, pose\nsignificant threats to deep neural networks by misleading their predictions. A\ncritical aspect of these examples is their transferability, allowing them to\ndeceive {unseen} models in black-box scenarios. Despite the widespread\nexploration of defense methods, including those on transferability, they show\nlimitations: inefficient deployment, ineffective defense, and degraded\nperformance on clean images. In this work, we introduce a novel training\nparadigm aimed at enhancing robustness against transferable adversarial\nexamples (TAEs) in a more efficient and effective way. We propose a model that\nexhibits random guessing behavior when presented with clean data\n$\\boldsymbol{x}$ as input, and generates accurate predictions when with\ntriggered data $\\boldsymbol{x}+\\boldsymbol{\\tau}$. Importantly, the trigger\n$\\boldsymbol{\\tau}$ remains constant for all data instances. We refer to these\nmodels as \\textbf{models with trigger activation}. We are surprised to find\nthat these models exhibit certain robustness against TAEs. Through the\nconsideration of first-order gradients, we provide a theoretical analysis of\nthis robustness. Moreover, through the joint optimization of the learnable\ntrigger and the model, we achieve improved robustness to transferable attacks.\nExtensive experiments conducted across diverse datasets, evaluating a variety\nof attacking methods, underscore the effectiveness and superiority of our\napproach.", "published": "2025-04-20 09:07:10", "link": "http://arxiv.org/abs/2504.14541v1", "categories": ["cs.CR", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction", "abstract": "Multi-agent frameworks with Large Language Models (LLMs) have become\npromising tools for generating general-purpose programming languages using\ntest-driven development, allowing developers to create more accurate and robust\ncode. However, their potential has not been fully unleashed for domain-specific\nprogramming languages, where specific domain exhibits unique optimization\nopportunities for customized improvement. In this paper, we take the first step\nin exploring multi-agent code generation for quantum programs. By identifying\nthe unique optimizations in quantum designs such as quantum error correction,\nwe introduce a novel multi-agent framework tailored to generating accurate,\nfault-tolerant quantum code. Each agent in the framework focuses on distinct\noptimizations, iteratively refining the code using a semantic analyzer with\nmulti-pass inference, alongside an error correction code decoder. We also\nexamine the effectiveness of inference-time techniques, like Chain-of-Thought\n(CoT) and Retrieval-Augmented Generation (RAG) in the context of quantum\nprogramming, uncovering observations that are different from general-purpose\ncode generation. To evaluate our approach, we develop a test suite to measure\nthe impact each optimization has on the accuracy of the generated code. Our\nfindings indicate that techniques such as structured CoT significantly improve\nthe generation of quantum algorithms by up to 50%. In contrast, we have also\nfound that certain techniques such as RAG show limited improvement, yielding an\naccuracy increase of only 4%. Moreover, we showcase examples of AI-assisted\nquantum error prediction and correction, demonstrating the effectiveness of our\nmulti-agent framework in reducing the quantum errors of generated quantum\nprograms.", "published": "2025-04-20 10:06:37", "link": "http://arxiv.org/abs/2504.14557v1", "categories": ["quant-ph", "cs.MA"], "primary_category": "quant-ph"}
{"title": "A note on unshifted lattice rules for high-dimensional integration in weighted unanchored Sobolev spaces", "abstract": "This short article studies a deterministic quasi-Monte Carlo lattice rule in\nweighted unanchored Sobolev spaces of smoothness $1$. Building on the error\nanalysis by Kazashi and Sloan, we prove the existence of unshifted rank-1\nlattice rules that achieve a worst-case error of $O(n^{-1/4}(\\log n)^{1/2})$,\nwith the implied constant independent of the dimension, under certain\nsummability conditions on the weights. Although this convergence rate is\ninferior to the one achievable for the shifted-averaged root mean squared\nworst-case error, the result does not rely on random shifting or transformation\nand holds unconditionally without any conjecture, as assumed by Kazashi and\nSloan.", "published": "2025-04-20 23:39:30", "link": "http://arxiv.org/abs/2504.14768v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Data-driven model order reduction for T-Product-Based dynamical systems", "abstract": "Model order reduction plays a crucial role in simplifying complex systems\nwhile preserving their essential dynamic characteristics, making it an\ninvaluable tool in a wide range of applications, including robotic systems,\nsignal processing, and fluid dynamics. However, traditional model order\nreduction techniques like balanced truncation are not designed to handle tensor\ndata directly and instead require unfolding the data, which may lead to the\nloss of important higher-order structural information. In this article, we\nintroduce a novel framework for data-driven model order reduction of\nT-product-based dynamical systems (TPDSs), which are often used to capture the\nevolution of third-order tensor data such as images and videos through the\nT-product. Specifically, we develop advanced T-product-based techniques,\nincluding T-balanced truncation, T-balanced proper orthogonal decomposition,\nand the T-eigensystem realization algorithm for input-output TPDSs by\nleveraging the unique properties of T-singular value decomposition. We\ndemonstrate that these techniques offer significant memory and computational\nsavings while achieving reduction errors that are comparable to those of\nconventional methods. The effectiveness of the proposed framework is further\nvalidated through synthetic and real-world examples.", "published": "2025-04-20 19:28:20", "link": "http://arxiv.org/abs/2504.14721v1", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.DS", "math.NA", "93C05, 15A69, 93B30, 65F99"], "primary_category": "eess.SY"}
{"title": "Assessing the Performance of Mixed-Precision ILU(0)-Preconditioned Multiple-Precision Real and Complex Krylov Subspace Methods", "abstract": "Krylov subspace methods are linear solvers based on matrix-vector\nmultiplications and vector operations. While easily parallelizable, they are\nsensitive to rounding errors and may experience convergence issues. ILU(0), an\nincomplete LU factorization with zero fill-in, is a well-known preconditioning\ntechnique that enhances convergence for sparse matrices. In this paper, we\nimplement a double-precision and multiple-precision ILU(0) preconditioner,\ncompatible with product-type Krylov subspace methods, and evaluate its\nperformance.", "published": "2025-04-20 05:33:02", "link": "http://arxiv.org/abs/2504.14498v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Memorization Problem: Can We Trust LLMs' Economic Forecasts?", "abstract": "Large language models (LLMs) cannot be trusted for economic forecasts during\nperiods covered by their training data. We provide the first systematic\nevaluation of LLMs' memorization of economic and financial data, including\nmajor economic indicators, news headlines, stock returns, and conference calls.\nOur findings show that LLMs can perfectly recall the exact numerical values of\nkey economic variables from before their knowledge cutoff dates. This recall\nappears to be randomly distributed across different dates and data types. This\nselective perfect memory creates a fundamental issue -- when testing\nforecasting capabilities before their knowledge cutoff dates, we cannot\ndistinguish whether LLMs are forecasting or simply accessing memorized data.\nExplicit instructions to respect historical data boundaries fail to prevent\nLLMs from achieving recall-level accuracy in forecasting tasks. Further, LLMs\nseem exceptional at reconstructing masked entities from minimal contextual\nclues, suggesting that masking provides inadequate protection against motivated\nreasoning. Our findings raise concerns about using LLMs to forecast historical\ndata or backtest trading strategies, as their apparent predictive success may\nmerely reflect memorization rather than genuine economic insight. Any\napplication where future knowledge would change LLMs' outputs can be affected\nby memorization. In contrast, consistent with the absence of data\ncontamination, LLMs cannot recall data after their knowledge cutoff date.", "published": "2025-04-20 23:36:27", "link": "http://arxiv.org/abs/2504.14765v1", "categories": ["q-fin.GN", "q-fin.ST"], "primary_category": "q-fin.GN"}
{"title": "DiffVox: A Differentiable Model for Capturing and Analysing Professional Effects Distributions", "abstract": "This study introduces a novel and interpretable model, DiffVox, for matching\nvocal effects in music production. DiffVox, short for ``Differentiable Vocal\nFx\", integrates parametric equalisation, dynamic range control, delay, and\nreverb with efficient differentiable implementations to enable gradient-based\noptimisation for parameter estimation. Vocal presets are retrieved from two\ndatasets, comprising 70 tracks from MedleyDB and 365 tracks from a private\ncollection. Analysis of parameter correlations highlights strong relationships\nbetween effects and parameters, such as the high-pass and low-shelf filters\noften behaving together to shape the low end, and the delay time correlates\nwith the intensity of the delayed signals. Principal component analysis reveals\nconnections to McAdams' timbre dimensions, where the most crucial component\nmodulates the perceived spaciousness while the secondary components influence\nspectral brightness. Statistical testing confirms the non-Gaussian nature of\nthe parameter distribution, highlighting the complexity of the vocal effects\nspace. These initial findings on the parameter distributions set the foundation\nfor future research in vocal effects modelling and automatic mixing. Our source\ncode and datasets are accessible at https://github.com/SonyResearch/diffvox.", "published": "2025-04-20 20:52:58", "link": "http://arxiv.org/abs/2504.14735v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Predicting speech intelligibility in older adults using the Gammachirp Envelope Similarity Index, GESI", "abstract": "We propose an objective intelligibility measure (OIM), called the Gammachirp\nEnvelope Similarity Index (GESI), that can predict speech intelligibility (SI)\nin older adults. GESI is a bottom-up model based on psychoacoustic knowledge\nfrom the peripheral to the central auditory system and requires no training\ndata. It computes the single SI metric using the gammachirp filterbank (GCFB),\nthe modulation filterbank, and the extended cosine similarity measure. It takes\ninto account not only the hearing level represented in the audiogram, but also\nthe temporal processing characteristics captured by the temporal modulation\ntransfer function (TMTF). To evaluate performance, SI experiments were\nconducted with older adults of various hearing levels using speech-in-noise\nwith ideal speech enhancement on familiarity-controlled words. The prediction\nperformance was compared with HASPIw2, which was developed for keyword SI\nprediction. The results showed that GESI predicted the subjective SI scores\nmore accurately than HASPIw2. The effect of introducing TMTF into the GESI\nalgorithm was not significant, indicating that more research is needed to know\nhow to introduce temporal response characteristics into the OIM.", "published": "2025-04-20 01:10:28", "link": "http://arxiv.org/abs/2504.14437v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Max-Min Fairness for Stacked Intelligent Metasurface-Assisted Multi-User MISO Systems", "abstract": "Stacked intelligent metasurface (SIM) is an emerging technology that uses\nmultiple reconfigurable surface layers to enable flexible wave-based\nbeamforming. In this paper, we focus on an \\ac{SIM}-assisted multi-user\nmultiple-input single-output system, where it is essential to ensure that all\nusers receive a fair and reliable service level. To this end, we develop two\nmax-min fairness algorithms based on instantaneous channel state information\n(CSI) and statistical CSI. For the instantaneous CSI case, we propose an\nalternating optimization algorithm that jointly optimizes power allocation\nusing geometric programming and wave-based beamforming coefficients using the\ngradient descent-ascent method. For the statistical CSI case, since deriving an\nexact expression for the average minimum achievable rate is analytically\nintractable, we derive a tight upper bound and thereby formulate a stochastic\noptimization problem. This problem is then solved, capitalizing on an\nalternating approach combining geometric programming and gradient descent\nalgorithms, to obtain the optimal policies. Our numerical results show\nsignificant improvements in the minimum achievable rate compared to the\nbenchmark schemes. In particular, for the instantaneous CSI scenario, the\nindividual impact of the optimal wave-based beamforming is significantly higher\nthan that of the power allocation strategy. Moreover, the proposed upper bound\nis shown to be tight in the low signal-to-noise ratio regime under the\nstatistical CSI.", "published": "2025-04-20 12:13:05", "link": "http://arxiv.org/abs/2504.14584v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Beamforming Design and Association Scheme for Multi-RIS Multi-User mmWave Systems Through Graph Neural Networks", "abstract": "Reconfigurable intelligent surface (RIS) is emerging as a promising\ntechnology for next-generation wireless communication networks, offering a\nvariety of merits such as the ability to tailor the communication environment.\nMoreover, deploying multiple RISs helps mitigate severe signal blocking between\nthe base station (BS) and users, providing a practical and efficient solution\nto enhance the service coverage. However, fully reaping the potential of a\nmulti-RIS aided communication system requires solving a non-convex optimization\nproblem. This challenge motivates the adoption of learning-based methods for\ndetermining the optimal policy. In this paper, we introduce a novel\nheterogeneous graph neural network (GNN) to effectively leverage the graph\ntopology of a wireless communication environment. Specifically, we design an\nassociation scheme that selects a suitable RIS for each user. Then, we maximize\nthe weighted sum rate (WSR) of all the users by iteratively optimizing the RIS\nassociation scheme, and beamforming designs until the considered heterogeneous\nGNN converges. Based on the proposed approach, each user is associated with the\nbest RIS, which is shown to significantly improve the system capacity in\nmulti-RIS multi-user millimeter wave (mmWave) communications. Specifically,\nsimulation results demonstrate that the proposed heterogeneous GNN closely\napproaches the performance of the high-complexity alternating optimization (AO)\nalgorithm in the considered multi-RIS aided communication system, and it\noutperforms other benchmark schemes. Moreover, the performance improvement\nachieved through the RIS association scheme is shown to be of the order of 30%.", "published": "2025-04-20 02:49:42", "link": "http://arxiv.org/abs/2504.14464v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models", "abstract": "The human-level performance of Large Language Models (LLMs) across various\ntasks has raised expectations for the potential of Artificial Intelligence (AI)\nto possess emotions someday. To explore the capability of current LLMs to\nexpress emotions in their outputs, we conducted an experiment using several\nLLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to\nrole-play as agents answering questions with specified emotional states. We\ndefined the emotional states using Russell's Circumplex model, a\nwell-established framework that characterizes emotions along the\nsleepy-activated (arousal) and pleasure-displeasure (valence) axes. We chose\nthis model for its simplicity, utilizing two continuous parameters, which\nallows for better controllability in applications involving continuous changes\nin emotional states. The responses generated were evaluated using a sentiment\nanalysis model, independent of the LLMs, trained on the GoEmotions dataset. The\nevaluation showed that the emotional states of the generated answers were\nconsistent with the specifications, demonstrating the LLMs' capability for\nemotional expression. This indicates the potential for LLM-based AI agents to\nsimulate emotions, opening up a wide range of applications for emotion-based\ninteractions, such as advisors or consultants who can provide advice or\nopinions with a personal touch.", "published": "2025-04-20 18:49:25", "link": "http://arxiv.org/abs/2504.14706v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EmoSEM: Segment and Explain Emotion Stimuli in Visual Art", "abstract": "This paper focuses on a key challenge in visual art understanding: given an\nart image, the model pinpoints pixel regions that trigger a specific human\nemotion, and generates linguistic explanations for the emotional arousal.\nDespite recent advances in art understanding, pixel-level emotion understanding\nstill faces a dual challenge: first, the subjectivity of emotion makes it\ndifficult for general segmentation models like SAM to adapt to emotion-oriented\nsegmentation tasks; and second, the abstract nature of art expression makes it\ndifficult for captioning models to balance pixel-level semantic understanding\nand emotion reasoning. To solve the above problems, this paper proposes the\nEmotion stimuli Segmentation and Explanation Model (EmoSEM) to endow the\nsegmentation model SAM with emotion comprehension capability. First, to enable\nthe model to perform segmentation under the guidance of emotional intent well,\nwe introduce an emotional prompt with a learnable mask token as the conditional\ninput for segmentation decoding. Then, we design an emotion projector to\nestablish the association between emotion and visual features. Next, more\nimportantly, to address emotion-visual stimuli alignment, we develop a\nlightweight prefix projector, a module that fuses the learned emotional mask\nwith the corresponding emotion into a unified representation compatible with\nthe language model. Finally, we input the joint visual, mask, and emotional\ntokens into the language model and output the emotional explanations. It\nensures that the generated interpretations remain semantically and emotionally\ncoherent with the visual stimuli. The method innovatively realizes end-to-end\nmodeling from low-level pixel features to high-level emotion interpretation,\nproviding the first interpretable fine-grained analysis framework for artistic\nemotion computing. Extensive experiments validate the effectiveness of our\nmodel.", "published": "2025-04-20 15:40:00", "link": "http://arxiv.org/abs/2504.14658v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Talk is Not Always Cheap: Promoting Wireless Sensing Models with Text Prompts", "abstract": "Wireless signal-based human sensing technologies, such as WiFi,\nmillimeter-wave (mmWave) radar, and Radio Frequency Identification (RFID),\nenable the detection and interpretation of human presence, posture, and\nactivities, thereby providing critical support for applications in public\nsecurity, healthcare, and smart environments. These technologies exhibit\nnotable advantages due to their non-contact operation and environmental\nadaptability; however, existing systems often fail to leverage the textual\ninformation inherent in datasets. To address this, we propose an innovative\ntext-enhanced wireless sensing framework, WiTalk, that seamlessly integrates\nsemantic knowledge through three hierarchical prompt strategies-label-only,\nbrief description, and detailed action description-without requiring\narchitectural modifications or incurring additional data costs. We rigorously\nvalidate this framework across three public benchmark datasets: XRF55 for human\naction recognition (HAR), and WiFiTAL and XRFV2 for WiFi temporal action\nlocalization (TAL). Experimental results demonstrate significant performance\nimprovements: on XRF55, accuracy for WiFi, RFID, and mmWave increases by 3.9%,\n2.59%, and 0.46%, respectively; on WiFiTAL, the average performance of WiFiTAD\nimproves by 4.98%; and on XRFV2, the mean average precision gains across\nvarious methods range from 4.02% to 13.68%. Our codes have been included in\nhttps://github.com/yangzhenkui/WiTalk.", "published": "2025-04-20 13:58:35", "link": "http://arxiv.org/abs/2504.14621v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative Auto-Bidding with Value-Guided Explorations", "abstract": "Auto-bidding, with its strong capability to optimize bidding decisions within\ndynamic and competitive online environments, has become a pivotal strategy for\nadvertising platforms. Existing approaches typically employ rule-based\nstrategies or Reinforcement Learning (RL) techniques. However, rule-based\nstrategies lack the flexibility to adapt to time-varying market conditions, and\nRL-based methods struggle to capture essential historical dependencies and\nobservations within Markov Decision Process (MDP) frameworks. Furthermore,\nthese approaches often face challenges in ensuring strategy adaptability across\ndiverse advertising objectives. Additionally, as offline training methods are\nincreasingly adopted to facilitate the deployment and maintenance of stable\nonline strategies, the issues of documented behavioral patterns and behavioral\ncollapse resulting from training on fixed offline datasets become increasingly\nsignificant. To address these limitations, this paper introduces a novel\noffline Generative Auto-bidding framework with Value-Guided Explorations\n(GAVE). GAVE accommodates various advertising objectives through a score-based\nReturn-To-Go (RTG) module. Moreover, GAVE integrates an action exploration\nmechanism with an RTG-based evaluation method to explore novel actions while\nensuring stability-preserving updates. A learnable value function is also\ndesigned to guide the direction of action exploration and mitigate\nOut-of-Distribution (OOD) problems. Experimental results on two offline\ndatasets and real-world deployments demonstrate that GAVE outperforms\nstate-of-the-art baselines in both offline evaluations and online A/B tests. By\napplying the core methods of this framework, we proudly secured first place in\nthe NeurIPS 2024 competition, 'AIGB Track: Learning Auto-Bidding Agents with\nGenerative Models'.", "published": "2025-04-20 12:28:49", "link": "http://arxiv.org/abs/2504.14587v2", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Wireless Large AI Model: Shaping the AI-Native Future of 6G and Beyond", "abstract": "The emergence of sixth-generation and beyond communication systems is\nexpected to fundamentally transform digital experiences through introducing\nunparalleled levels of intelligence, efficiency, and connectivity. A promising\ntechnology poised to enable this revolutionary vision is the wireless large AI\nmodel (WLAM), characterized by its exceptional capabilities in data processing,\ninference, and decision-making. In light of these remarkable capabilities, this\npaper provides a comprehensive survey of WLAM, elucidating its fundamental\nprinciples, diverse applications, critical challenges, and future research\nopportunities. We begin by introducing the background of WLAM and analyzing the\nkey synergies with wireless networks, emphasizing the mutual benefits.\nSubsequently, we explore the foundational characteristics of WLAM, delving into\ntheir unique relevance in wireless environments. Then, the role of WLAM in\noptimizing wireless communication systems across various use cases and the\nreciprocal benefits are systematically investigated. Furthermore, we discuss\nthe integration of WLAM with emerging technologies, highlighting their\npotential to enable transformative capabilities and breakthroughs in wireless\ncommunication. Finally, we thoroughly examine the high-level challenges\nhindering the practical implementation of WLAM and discuss pivotal future\nresearch directions.", "published": "2025-04-20 15:25:58", "link": "http://arxiv.org/abs/2504.14653v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Data Selection for ERMs", "abstract": "Learning theory has traditionally followed a model-centric approach, focusing\non designing optimal algorithms for a fixed natural learning task (e.g., linear\nclassification or regression). In this paper, we adopt a complementary\ndata-centric perspective, whereby we fix a natural learning rule and focus on\noptimizing the training data. Specifically, we study the following question:\ngiven a learning rule $\\mathcal{A}$ and a data selection budget $n$, how well\ncan $\\mathcal{A}$ perform when trained on at most $n$ data points selected from\na population of $N$ points? We investigate when it is possible to select $n \\ll\nN$ points and achieve performance comparable to training on the entire\npopulation.\n  We address this question across a variety of empirical risk minimizers. Our\nresults include optimal data-selection bounds for mean estimation, linear\nclassification, and linear regression. Additionally, we establish two general\nresults: a taxonomy of error rates in binary classification and in stochastic\nconvex optimization. Finally, we propose several open questions and directions\nfor future research.", "published": "2025-04-20 11:26:01", "link": "http://arxiv.org/abs/2504.14572v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
