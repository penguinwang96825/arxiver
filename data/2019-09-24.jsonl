{"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "abstract": "As distributed approaches to natural language semantics have developed and\ndiversified, embedders for linguistic units larger than words have come to play\nan increasingly important role. To date, such embedders have been evaluated\nusing benchmark tasks (e.g., GLUE) and linguistic probes. We propose a\ncomparative approach, nearest neighbor overlap (N2O), that quantifies\nsimilarity between embedders in a task-agnostic manner. N2O requires only a\ncollection of examples and is simple to understand: two embedders are more\nsimilar if, for the same set of inputs, there is greater overlap between the\ninputs' nearest neighbors. Though applicable to embedders of texts of any size,\nwe focus on sentence embedders and use N2O to show the effects of different\ndesign choices and architectures.", "published": "2019-09-24 06:03:35", "link": "http://arxiv.org/abs/1909.10724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Content Understanding in Conversational Question\n  Answering", "abstract": "With a lot of work about context-free question answering systems, there is an\nemerging trend of conversational question answering models in the natural\nlanguage processing field. Thanks to the recently collected datasets, including\nQuAC and CoQA, there has been more work on conversational question answering,\nand recent work has achieved competitive performance on both datasets. However,\nto best of our knowledge, two important questions for conversational\ncomprehension research have not been well studied: 1) How well can the\nbenchmark dataset reflect models' content understanding? 2) Do the models well\nutilize the conversation content when answering questions? To investigate these\nquestions, we design different training settings, testing settings, as well as\nan attack to verify the models' capability of content understanding on QuAC and\nCoQA. The experimental results indicate some potential hazards in the benchmark\ndatasets, QuAC and CoQA, for conversational comprehension research. Our\nanalysis also sheds light on both what models may learn and how datasets may\nbias the models. With deep investigation of the task, it is believed that this\nwork can benefit the future progress of conversation comprehension. The source\ncode is available at https://github.com/MiuLab/CQA-Study.", "published": "2019-09-24 07:36:45", "link": "http://arxiv.org/abs/1909.10743v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Technical report on Conversational Question Answering", "abstract": "Conversational Question Answering is a challenging task since it requires\nunderstanding of conversational history. In this project, we propose a new\nsystem RoBERTa + AT +KD, which involves rationale tagging multi-task,\nadversarial training, knowledge distillation and a linguistic post-process\nstrategy. Our single model achieves 90.4(F1) on the CoQA test set without data\naugmentation, outperforming the current state-of-the-art single model by 2.6%\nF1.", "published": "2019-09-24 09:26:24", "link": "http://arxiv.org/abs/1909.10772v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In Conclusion Not Repetition: Comprehensive Abstractive Summarization\n  With Diversified Attention Based On Determinantal Point Processes", "abstract": "Various Seq2Seq learning models designed for machine translation were applied\nfor abstractive summarization task recently. Despite these models provide high\nROUGE scores, they are limited to generate comprehensive summaries with a high\nlevel of abstraction due to its degenerated attention distribution. We\nintroduce Diverse Convolutional Seq2Seq Model(DivCNN Seq2Seq) using\nDeterminantal Point Processes methods(Micro DPPs and Macro DPPs) to produce\nattention distribution considering both quality and diversity. Without breaking\nthe end to end architecture, DivCNN Seq2Seq achieves a higher level of\ncomprehensiveness compared to vanilla models and strong baselines. All the\nreproducible codes and datasets are available online.", "published": "2019-09-24 12:53:36", "link": "http://arxiv.org/abs/1909.10852v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-switching Language Modeling With Bilingual Word Embeddings: A Case\n  Study for Egyptian Arabic-English", "abstract": "Code-switching (CS) is a widespread phenomenon among bilingual and\nmultilingual societies. The lack of CS resources hinders the performance of\nmany NLP tasks. In this work, we explore the potential use of bilingual word\nembeddings for code-switching (CS) language modeling (LM) in the low resource\nEgyptian Arabic-English language. We evaluate different state-of-the-art\nbilingual word embeddings approaches that require cross-lingual resources at\ndifferent levels and propose an innovative but simple approach that jointly\nlearns bilingual word representations without the use of any parallel data,\nrelying only on monolingual and a small amount of CS data. While all\nrepresentations improve CS LM, ours performs the best and improves perplexity\n33.5% relative over the baseline.", "published": "2019-09-24 13:27:30", "link": "http://arxiv.org/abs/1909.10892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficiently Reusing Old Models Across Languages via Transfer Learning", "abstract": "Recent progress in neural machine translation is directed towards larger\nneural networks trained on an increasing amount of hardware resources. As a\nresult, NMT models are costly to train, both financially, due to the\nelectricity and hardware cost, and environmentally, due to the carbon\nfootprint. It is especially true in transfer learning for its additional cost\nof training the \"parent\" model before transferring knowledge and training the\ndesired \"child\" model. In this paper, we propose a simple method of re-using an\nalready trained model for different language pairs where there is no need for\nmodifications in model architecture. Our approach does not need a separate\nparent model for each investigated language pair, as it is typical in NMT\ntransfer learning. To show the applicability of our method, we recycle a\nTransformer model trained by different researchers and use it to seed models\nfor different language pairs. We achieve better translation quality and shorter\nconvergence times than when training from random initialization.", "published": "2019-09-24 14:32:52", "link": "http://arxiv.org/abs/1909.10955v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Lexico-Semantic Relational Knowledge Captured by Word and\n  Concept Embeddings", "abstract": "Deep learning currently dominates the benchmarks for various NLP tasks and,\nat the basis of such systems, words are frequently represented as embeddings\n--vectors in a low dimensional space-- learned from large text corpora and\nvarious algorithms have been proposed to learn both word and concept\nembeddings. One of the claimed benefits of such embeddings is that they capture\nknowledge about semantic relations. Such embeddings are most often evaluated\nthrough tasks such as predicting human-rated similarity and analogy which only\ntest a few, often ill-defined, relations. In this paper, we propose a method\nfor (i) reliably generating word and concept pair datasets for a wide number of\nrelations by using a knowledge graph and (ii) evaluating to what extent\npre-trained embeddings capture those relations. We evaluate the approach\nagainst a proprietary and a public knowledge graph and analyze the results,\nshowing which lexico-semantic relational knowledge is captured by current\nembedding learning approaches.", "published": "2019-09-24 16:52:18", "link": "http://arxiv.org/abs/1909.11042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Generative Rhetorical Structure Parsing", "abstract": "Rhetorical structure trees have been shown to be useful for several\ndocument-level tasks including summarization and document classification.\nPrevious approaches to RST parsing have used discriminative models; however,\nthese are less sample efficient than generative models, and RST parsing\ndatasets are typically small. In this paper, we present the first generative\nmodel for RST parsing. Our model is a document-level RNN grammar (RNNG) with a\nbottom-up traversal order. We show that, for our parser's traversal order,\nprevious beam search algorithms for RNNGs have a left-branching bias which is\nill-suited for RST parsing. We develop a novel beam search algorithm that keeps\ntrack of both structure- and word-generating actions without exhibiting this\nbranching bias and results in absolute improvements of 6.8 and 2.9 on\nunlabelled and labelled F1 over previous algorithms. Overall, our generative\nmodel outperforms a discriminative model with the same features by 2.6 F1\npoints and achieves performance comparable to the state-of-the-art,\noutperforming all published parsers from a recent replication study that do not\nuse additional training data.", "published": "2019-09-24 17:02:32", "link": "http://arxiv.org/abs/1909.11049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TripleNet: Triple Attention Network for Multi-Turn Response Selection in\n  Retrieval-based Chatbots", "abstract": "We consider the importance of different utterances in the context for\nselecting the response usually depends on the current query. In this paper, we\npropose the model TripleNet to fully model the task with the triple <context,\nquery, response> instead of <context, response> in previous works. The heart of\nTripleNet is a novel attention mechanism named triple attention to model the\nrelationships within the triple at four levels. The new mechanism updates the\nrepresentation for each element based on the attention with the other two\nconcurrently and symmetrically. We match the triple <C, Q, R> centered on the\nresponse from char to context level for prediction. Experimental results on two\nlarge-scale multi-turn response selection datasets show that the proposed model\ncan significantly outperform the state-of-the-art methods. TripleNet source\ncode is available at https://github.com/wtma/TripleNet", "published": "2019-09-24 00:45:32", "link": "http://arxiv.org/abs/1909.10666v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Layerwise Relevance Visualization in Convolutional Text Graph\n  Classifiers", "abstract": "Representations in the hidden layers of Deep Neural Networks (DNN) are often\nhard to interpret since it is difficult to project them into an interpretable\ndomain. Graph Convolutional Networks (GCN) allow this projection, but existing\nexplainability methods do not exploit this fact, i.e. do not focus their\nexplanations on intermediate states. In this work, we present a novel method\nthat traces and visualizes features that contribute to a classification\ndecision in the visible and hidden layers of a GCN. Our method exposes hidden\ncross-layer dynamics in the input graph structure. We experimentally\ndemonstrate that it yields meaningful layerwise explanations for a GCN sentence\nclassifier.", "published": "2019-09-24 13:37:02", "link": "http://arxiv.org/abs/1909.10911v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diachronic Topics in New High German Poetry", "abstract": "Statistical topic models are increasingly and popularly used by Digital\nHumanities scholars to perform distant reading tasks on literary data. It\nallows us to estimate what people talk about. Especially Latent Dirichlet\nAllocation (LDA) has shown its usefulness, as it is unsupervised, robust, easy\nto use, scalable, and it offers interpretable results. In a preliminary study,\nwe apply LDA to a corpus of New High German poetry (textgrid, with 51k poems,\n8m token), and use the distribution of topics over documents for a\nclassification of poems into time periods and for authorship attribution.", "published": "2019-09-24 21:19:01", "link": "http://arxiv.org/abs/1909.11189v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Attention Interpretability Across NLP Tasks", "abstract": "The attention layer in a neural network model provides insights into the\nmodel's reasoning behind its prediction, which are usually criticized for being\nopaque. Recently, seemingly contradictory viewpoints have emerged about the\ninterpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,\n2019). Amid such confusion arises the need to understand attention mechanism\nmore systematically. In this work, we attempt to fill this gap by giving a\ncomprehensive explanation which justifies both kinds of observations (i.e.,\nwhen is attention interpretable and when it is not). Through a series of\nexperiments on diverse NLP tasks, we validate our observations and reinforce\nour claim of interpretability of attention through manual evaluation.", "published": "2019-09-24 22:58:44", "link": "http://arxiv.org/abs/1909.11218v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge-Enriched Transformer for Emotion Detection in Textual\n  Conversations", "abstract": "Messages in human conversations inherently convey emotions. The task of\ndetecting emotions in textual conversations leads to a wide range of\napplications such as opinion mining in social networks. However, enabling\nmachines to analyze emotions in conversations is challenging, partly because\nhumans often rely on the context and commonsense knowledge to express emotions.\nIn this paper, we address these challenges by proposing a Knowledge-Enriched\nTransformer (KET), where contextual utterances are interpreted using\nhierarchical self-attention and external commonsense knowledge is dynamically\nleveraged using a context-aware affective graph attention mechanism.\nExperiments on multiple textual conversation datasets demonstrate that both\ncontext and commonsense knowledge are consistently beneficial to the emotion\ndetection performance. In addition, the experimental results show that our KET\nmodel outperforms the state-of-the-art models on most of the tested datasets in\nF1 score.", "published": "2019-09-24 02:08:29", "link": "http://arxiv.org/abs/1909.10681v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LitGen: Genetic Literature Recommendation Guided by Human Explanations", "abstract": "As genetic sequencing costs decrease, the lack of clinical interpretation of\nvariants has become the bottleneck in using genetics data. A major rate\nlimiting step in clinical interpretation is the manual curation of evidence in\nthe genetic literature by highly trained biocurators. What makes curation\nparticularly time-consuming is that the curator needs to identify papers that\nstudy variant pathogenicity using different types of approaches and\nevidences---e.g. biochemical assays or case control analysis. In collaboration\nwith the Clinical Genomic Resource (ClinGen)---the flagship NIH program for\nclinical curation---we propose the first machine learning system, LitGen, that\ncan retrieve papers for a particular variant and filter them by specific\nevidence types used by curators to assess for pathogenicity. LitGen uses\nsemi-supervised deep learning to predict the type of evidence provided by each\npaper. It is trained on papers annotated by ClinGen curators and systematically\nevaluated on new test data collected by ClinGen. LitGen further leverages rich\nhuman explanations and unlabeled data to gain 7.9%-12.6% relative performance\nimprovement over models learned only on the annotated papers. It is a useful\nframework to improve clinical variant curation.", "published": "2019-09-24 03:56:48", "link": "http://arxiv.org/abs/1909.10699v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do Massively Pretrained Language Models Make Better Storytellers?", "abstract": "Large neural language models trained on massive amounts of text have emerged\nas a formidable strategy for Natural Language Understanding tasks. However, the\nstrength of these models as Natural Language Generators is less clear. Though\nanecdotal evidence suggests that these models generate better quality text,\nthere has been no detailed study characterizing their generation abilities. In\nthis work, we compare the performance of an extensively pretrained model,\nOpenAI GPT2-117 (Radford et al., 2019), to a state-of-the-art neural story\ngeneration model (Fan et al., 2018). By evaluating the generated text across a\nwide variety of automatic metrics, we characterize the ways in which pretrained\nmodels do, and do not, make better storytellers. We find that although GPT2-117\nconditions more strongly on context, is more sensitive to ordering of events,\nand uses more unusual words, it is just as likely to produce repetitive and\nunder-diverse text when using likelihood-maximizing decoding algorithms.", "published": "2019-09-24 04:26:27", "link": "http://arxiv.org/abs/1909.10705v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Text Mining of Instagram Data Without Strong Supervision", "abstract": "With the advent of social media, our online feeds increasingly consist of\nshort, informal, and unstructured text. This textual data can be analyzed for\nthe purpose of improving user recommendations and detecting trends. Instagram\nis one of the largest social media platforms, containing both text and images.\nHowever, most of the prior research on text processing in social media is\nfocused on analyzing Twitter data, and little attention has been paid to text\nmining of Instagram data. Moreover, many text mining methods rely on annotated\ntraining data, which in practice is both difficult and expensive to obtain. In\nthis paper, we present methods for unsupervised mining of fashion attributes\nfrom Instagram text, which can enable a new kind of user recommendation in the\nfashion domain. In this context, we analyze a corpora of Instagram posts from\nthe fashion domain, introduce a system for extracting fashion attributes from\nInstagram, and train a deep clothing classifier with weak supervision to\nclassify Instagram posts based on the associated text.\n  With our experiments, we confirm that word embeddings are a useful asset for\ninformation extraction. Experimental results show that information extraction\nusing word embeddings outperforms a baseline that uses Levenshtein distance.\nThe results also show the benefit of combining weak supervision signals using\ngenerative models instead of majority voting. Using weak supervision and\ngenerative modeling, an F1 score of 0.61 is achieved on the task of classifying\nthe image contents of Instagram posts based solely on the associated text,\nwhich is on level with human performance. Finally, our empirical study provides\none of the few available studies on Instagram text and shows that the text is\nnoisy, that the text distribution exhibits the long-tail phenomenon, and that\ncomment sections on Instagram are multi-lingual.", "published": "2019-09-24 11:04:02", "link": "http://arxiv.org/abs/1909.10812v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50"], "primary_category": "cs.CL"}
{"title": "Talk2Car: Taking Control of Your Self-Driving Car", "abstract": "A long-term goal of artificial intelligence is to have an agent execute\ncommands communicated through natural language. In many cases the commands are\ngrounded in a visual environment shared by the human who gives the command and\nthe agent. Execution of the command then requires mapping the command into the\nphysical visual space, after which the appropriate action can be taken. In this\npaper we consider the former. Or more specifically, we consider the problem in\nan autonomous driving setting, where a passenger requests an action that can be\nassociated with an object found in a street scene. Our work presents the\nTalk2Car dataset, which is the first object referral dataset that contains\ncommands written in natural language for self-driving cars. We provide a\ndetailed comparison with related datasets such as ReferIt, RefCOCO, RefCOCO+,\nRefCOCOg, Cityscape-Ref and CLEVR-Ref. Additionally, we include a performance\nanalysis using strong state-of-the-art models. The results show that the\nproposed object referral task is a challenging one for which the models show\npromising results but still require additional research in natural language\nprocessing, computer vision and the intersection of these fields. The dataset\ncan be found on our website: http://macchina-ai.eu/", "published": "2019-09-24 12:29:27", "link": "http://arxiv.org/abs/1909.10838v2", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Learning ASR-Robust Contextualized Embeddings for Spoken Language\n  Understanding", "abstract": "Employing pre-trained language models (LM) to extract contextualized word\nrepresentations has achieved state-of-the-art performance on various NLP tasks.\nHowever, applying this technique to noisy transcripts generated by automatic\nspeech recognizer (ASR) is concerned. Therefore, this paper focuses on making\ncontextualized representations more ASR-robust. We propose a novel\nconfusion-aware fine-tuning method to mitigate the impact of ASR errors to\npre-trained LMs. Specifically, we fine-tune LMs to produce similar\nrepresentations for acoustically confusable words that are obtained from word\nconfusion networks (WCNs) produced by ASR. Experiments on the benchmark ATIS\ndataset show that the proposed method significantly improves the performance of\nspoken language understanding when performing on ASR transcripts. Our source\ncode is available at https://github.com/MiuLab/SpokenVec", "published": "2019-09-24 13:06:43", "link": "http://arxiv.org/abs/1909.10861v2", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Understanding Semantics from Speech Through Pre-training", "abstract": "End-to-end Spoken Language Understanding (SLU) is proposed to infer the\nsemantic meaning directly from audio features without intermediate text\nrepresentation. Although the acoustic model component of an end-to-end SLU\nsystem can be pre-trained with Automatic Speech Recognition (ASR) targets, the\nSLU component can only learn semantic features from limited task-specific\ntraining data. In this paper, for the first time we propose to do large-scale\nunsupervised pre-training for the SLU component of an end-to-end SLU system, so\nthat the SLU component may preserve semantic features from massive unlabeled\naudio data. As the output of the acoustic model component, i.e. phoneme\nposterior sequences, has much different characteristic from text sequences, we\npropose a novel pre-training model called BERT-PLM, which stands for\nBidirectional Encoder Representations from Transformers through Permutation\nLanguage Modeling. BERT-PLM trains the SLU component on unlabeled data through\na regression objective equivalent to the partial permutation language modeling\nobjective, while leverages full bi-directional context information with BERT\nnetworks. The experiment results show that our approach out-perform the\nstate-of-the-art end-to-end systems with over 12.5% error reduction.", "published": "2019-09-24 13:49:14", "link": "http://arxiv.org/abs/1909.10924v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Paying Attention to Function Words", "abstract": "All natural languages exhibit a distinction between content words (like nouns\nand adjectives) and function words (like determiners, auxiliaries,\nprepositions). Yet surprisingly little has been said about the emergence of\nthis universal architectural feature of natural languages. Why have human\nlanguages evolved to exhibit this division of labor between content and\nfunction words? How could such a distinction have emerged in the first place?\nThis paper takes steps towards answering these questions by showing how the\ndistinction can emerge through reinforcement learning in agents playing a\nsignaling game across contexts which contain multiple objects that possess\nmultiple perceptually salient gradable properties.", "published": "2019-09-24 17:18:48", "link": "http://arxiv.org/abs/1909.11060v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Noise Robustness In Speaker Identification Using A Two-Stage\n  Attention Model", "abstract": "While the use of deep neural networks has significantly boosted speaker\nrecognition performance, it is still challenging to separate speakers in poor\nacoustic environments. To improve robustness of speaker recognition system\nperformance in noise, a novel two-stage attention mechanism which can be used\nin existing architectures such as Time Delay Neural Networks (TDNNs) and\nConvolutional Neural Networks (CNNs) is proposed. Noise is known to often mask\nimportant information in both time and frequency domain. The proposed mechanism\nallows the models to concentrate on reliable time/frequency components of the\nsignal. The proposed approach is evaluated using the Voxceleb1 dataset, which\naims at assessment of speaker recognition in real world situations. In addition\nthree types of noise at different signal-noise-ratios (SNRs) were added for\nthis work. The proposed mechanism is compared with three strong baselines:\nX-vectors, Attentive X-vector, and Resnet-34. Results on both identification\nand verification tasks show that the two-stage attention mechanism consistently\nimproves upon these for all noise conditions.", "published": "2019-09-24 21:46:42", "link": "http://arxiv.org/abs/1909.11200v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sign Language Recognition Analysis using Multimodal Data", "abstract": "Voice-controlled personal and home assistants (such as the Amazon Echo and\nApple Siri) are becoming increasingly popular for a variety of applications.\nHowever, the benefits of these technologies are not readily accessible to Deaf\nor Hard-ofHearing (DHH) users. The objective of this study is to develop and\nevaluate a sign recognition system using multiple modalities that can be used\nby DHH signers to interact with voice-controlled devices. With the advancement\nof depth sensors, skeletal data is used for applications like video analysis\nand activity recognition. Despite having similarity with the well-studied human\nactivity recognition, the use of 3D skeleton data in sign language recognition\nis rare. This is because unlike activity recognition, sign language is mostly\ndependent on hand shape pattern. In this work, we investigate the feasibility\nof using skeletal and RGB video data for sign language recognition using a\ncombination of different deep learning architectures. We validate our results\non a large-scale American Sign Language (ASL) dataset of 12 users and 13107\nsamples across 51 signs. It is named as GMUASL51. We collected the dataset over\n6 months and it will be publicly released in the hope of spurring further\nmachine learning research towards providing improved accessibility for digital\nassistants.", "published": "2019-09-24 23:44:49", "link": "http://arxiv.org/abs/1909.11232v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Keyphrase Generation for Scientific Articles using GANs", "abstract": "In this paper, we present a keyphrase generation approach using conditional\nGenerative Adversarial Networks (GAN). In our GAN model, the generator outputs\na sequence of keyphrases based on the title and abstract of a scientific\narticle. The discriminator learns to distinguish between machine-generated and\nhuman-curated keyphrases. We evaluate this approach on standard benchmark\ndatasets. Our model achieves state-of-the-art performance in generation of\nabstractive keyphrases and is also comparable to the best performing extractive\ntechniques. We also demonstrate that our method generates more diverse\nkeyphrases and make our implementation publicly available.", "published": "2019-09-24 02:46:58", "link": "http://arxiv.org/abs/1909.12229v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
