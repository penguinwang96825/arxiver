{"title": "Topical Classification of Food Safety Publications with a Knowledge Base", "abstract": "The vast body of scientific publications presents an increasing challenge of\nfinding those that are relevant to a given research question, and making\ninformed decisions on their basis. This becomes extremely difficult without the\nuse of automated tools. Here, one possible area for improvement is automatic\nclassification of publication abstracts according to their topic. This work\nintroduces a novel, knowledge base-oriented publication classifier. The\nproposed method focuses on achieving scalability and easy adaptability to other\ndomains. Classification speed and accuracy are shown to be satisfactory, in the\nvery demanding field of food safety. Further development and evaluation of the\nmethod is needed, as the proposed approach shows much potential.", "published": "2022-01-02 16:15:05", "link": "http://arxiv.org/abs/2201.00374v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Informed Multi-context Entity Alignment", "abstract": "Entity alignment is a crucial step in integrating knowledge graphs (KGs) from\nmultiple sources. Previous attempts at entity alignment have explored different\nKG structures, such as neighborhood-based and path-based contexts, to learn\nentity embeddings, but they are limited in capturing the multi-context\nfeatures. Moreover, most approaches directly utilize the embedding similarity\nto determine entity alignment without considering the global interaction among\nentities and relations. In this work, we propose an Informed Multi-context\nEntity Alignment (IMEA) model to address these issues. In particular, we\nintroduce Transformer to flexibly capture the relation, path, and neighborhood\ncontexts, and design holistic reasoning to estimate alignment probabilities\nbased on both embedding similarity and the relation/entity functionality. The\nalignment evidence obtained from holistic reasoning is further injected back\ninto the Transformer via the proposed soft label editing to inform embedding\nlearning. Experimental results on several benchmark datasets demonstrate the\nsuperiority of our IMEA model compared with existing state-of-the-art entity\nalignment methods.", "published": "2022-01-02 06:29:30", "link": "http://arxiv.org/abs/2201.00304v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On Sensitivity of Deep Learning Based Text Classification Algorithms to\n  Practical Input Perturbations", "abstract": "Text classification is a fundamental Natural Language Processing task that\nhas a wide variety of applications, where deep learning approaches have\nproduced state-of-the-art results. While these models have been heavily\ncriticized for their black-box nature, their robustness to slight perturbations\nin input text has been a matter of concern. In this work, we carry out a\ndata-focused study evaluating the impact of systematic practical perturbations\non the performance of the deep learning based text classification models like\nCNN, LSTM, and BERT-based algorithms. The perturbations are induced by the\naddition and removal of unwanted tokens like punctuation and stop-words that\nare minimally associated with the final performance of the model. We show that\nthese deep learning approaches including BERT are sensitive to such legitimate\ninput perturbations on four standard benchmark datasets SST2, TREC-6, BBC News,\nand tweet_eval. We observe that BERT is more susceptible to the removal of\ntokens as compared to the addition of tokens. Moreover, LSTM is slightly more\nsensitive to input perturbations as compared to CNN based model. The work also\nserves as a practical guide to assessing the impact of discrepancies in\ntrain-test conditions on the final performance of models.", "published": "2022-01-02 08:33:49", "link": "http://arxiv.org/abs/2201.00318v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Establishing Strong Baselines for TripClick Health Retrieval", "abstract": "We present strong Transformer-based re-ranking and dense retrieval baselines\nfor the recently released TripClick health ad-hoc retrieval collection. We\nimprove the - originally too noisy - training data with a simple negative\nsampling policy. We achieve large gains over BM25 in the re-ranking task of\nTripClick, which were not achieved with the original baselines. Furthermore, we\nstudy the impact of different domain-specific pre-trained models on TripClick.\nFinally, we show that dense retrieval outperforms BM25 by considerable margins,\neven with simple training procedures.", "published": "2022-01-02 15:03:19", "link": "http://arxiv.org/abs/2201.00365v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Building Human-like Communicative Intelligence: A Grounded Perspective", "abstract": "Modern Artificial Intelligence (AI) systems excel at diverse tasks, from\nimage classification to strategy games, even outperforming humans in many of\nthese domains. After making astounding progress in language learning in the\nrecent decade, AI systems, however, seem to approach the ceiling that does not\nreflect important aspects of human communicative capacities. Unlike human\nlearners, communicative AI systems often fail to systematically generalize to\nnew data, suffer from sample inefficiency, fail to capture common-sense\nsemantic knowledge, and do not translate to real-world communicative\nsituations. Cognitive Science offers several insights on how AI could move\nforward from this point. This paper aims to: (1) suggest that the dominant\ncognitively-inspired AI directions, based on nativist and symbolic paradigms,\nlack necessary substantiation and concreteness to guide progress in modern AI,\nand (2) articulate an alternative, \"grounded\", perspective on AI advancement,\ninspired by Embodied, Embedded, Extended, and Enactive Cognition (4E) research.\nI review results on 4E research lines in Cognitive Science to distinguish the\nmain aspects of naturalistic learning conditions that play causal roles for\nhuman language development. I then use this analysis to propose a list of\nconcrete, implementable components for building \"grounded\" linguistic\nintelligence. These components include embodying machines in a\nperception-action cycle, equipping agents with active exploration mechanisms so\nthey can build their own curriculum, allowing agents to gradually develop motor\nabilities to promote piecemeal language development, and endowing the agents\nwith adaptive feedback from their physical and social environment. I hope that\nthese ideas can direct AI research towards building machines that develop\nhuman-like language abilities through their experiences with the world.", "published": "2022-01-02 01:43:24", "link": "http://arxiv.org/abs/2201.02734v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Trustworthy AutoGrading of Short, Multi-lingual, Multi-type\n  Answers", "abstract": "Autograding short textual answers has become much more feasible due to the\nrise of NLP and the increased availability of question-answer pairs brought\nabout by a shift to online education. Autograding performance is still inferior\nto human grading. The statistical and black-box nature of state-of-the-art\nmachine learning models makes them untrustworthy, raising ethical concerns and\nlimiting their practical utility. Furthermore, the evaluation of autograding is\ntypically confined to small, monolingual datasets for a specific question type.\nThis study uses a large dataset consisting of about 10 million question-answer\npairs from multiple languages covering diverse fields such as math and\nlanguage, and strong variation in question and answer syntax. We demonstrate\nthe effectiveness of fine-tuning transformer models for autograding for such\ncomplex datasets. Our best hyperparameter-tuned model yields an accuracy of\nabout 86.5\\%, comparable to the state-of-the-art models that are less general\nand more tuned to a specific type of question, subject, and language. More\nimportantly, we address trust and ethical concerns. By involving humans in the\nautograding process, we show how to improve the accuracy of automatically\ngraded answers, achieving accuracy equivalent to that of teaching assistants.\nWe also show how teachers can effectively control the type of errors made by\nthe system and how they can validate efficiently that the autograder's\nperformance on individual exams is close to the expected performance.", "published": "2022-01-02 12:17:24", "link": "http://arxiv.org/abs/2201.03425v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IQDUBBING: Prosody modeling based on discrete self-supervised speech\n  representation for expressive voice conversion", "abstract": "Prosody modeling is important, but still challenging in expressive voice\nconversion. As prosody is difficult to model, and other factors, e.g., speaker,\nenvironment and content, which are entangled with prosody in speech, should be\nremoved in prosody modeling. In this paper, we present IQDubbing to solve this\nproblem for expressive voice conversion. To model prosody, we leverage the\nrecent advances in discrete self-supervised speech representation (DSSR).\nSpecifically, prosody vector is first extracted from pre-trained VQ-Wav2Vec\nmodel, where rich prosody information is embedded while most speaker and\nenvironment information are removed effectively by quantization. To further\nfilter out the redundant information except prosody, such as content and\npartial speaker information, we propose two kinds of prosody filters to sample\nprosody from the prosody vector. Experiments show that IQDubbing is superior to\nbaseline and comparison systems in terms of speech quality while maintaining\nprosody consistency and speaker similarity.", "published": "2022-01-02 01:22:38", "link": "http://arxiv.org/abs/2201.00269v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
