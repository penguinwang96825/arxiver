{"title": "Similarity measure for Public Persons", "abstract": "For the webportal \"Who is in the News!\" with statistics about the appearence\nof persons in written news we developed an extension, which measures the\nrelationship of public persons depending on a time parameter, as the\nrelationship may vary over time. On a training corpus of English and German\nnews articles we built a measure by extracting the persons occurrence in the\ntext via pretrained named entity extraction and then construct time series of\ncounts for each person. Pearson correlation over a sliding window is then used\nto measure the relation of two persons.", "published": "2018-09-17 09:09:48", "link": "http://arxiv.org/abs/1809.06083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Subtitles Paraphrase Corpus for Six Languages", "abstract": "This paper accompanies the release of Opusparcus, a new paraphrase corpus for\nsix European languages: German, English, Finnish, French, Russian, and Swedish.\nThe corpus consists of paraphrases, that is, pairs of sentences in the same\nlanguage that mean approximately the same thing. The paraphrases are extracted\nfrom the OpenSubtitles2016 corpus, which contains subtitles from movies and TV\nshows. The informal and colloquial genre that occurs in subtitles makes such\ndata a very interesting language resource, for instance, from the perspective\nof computer assisted language learning. For each target language, the\nOpusparcus data have been partitioned into three types of data sets: training,\ndevelopment and test sets. The training sets are large, consisting of millions\nof sentence pairs, and have been compiled automatically, with the help of\nprobabilistic ranking functions. The development and test sets consist of\nsentence pairs that have been checked manually; each set contains approximately\n1000 sentence pairs that have been verified to be acceptable paraphrases by two\nannotators.", "published": "2018-09-17 11:49:19", "link": "http://arxiv.org/abs/1809.06142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Categorizing Comparative Sentences", "abstract": "We tackle the tasks of automatically identifying comparative sentences and\ncategorizing the intended preference (e.g., \"Python has better NLP libraries\nthan MATLAB\" => (Python, better, MATLAB). To this end, we manually annotate\n7,199 sentences for 217 distinct target item pairs from several domains (27% of\nthe sentences contain an oriented comparison in the sense of \"better\" or\n\"worse\"). A gradient boosting model based on pre-trained sentence embeddings\nreaches an F1 score of 85% in our experimental evaluation. The model can be\nused to extract comparative sentences for pro/con argumentation in comparative\n/ argument search engines or debating technologies.", "published": "2018-09-17 12:04:24", "link": "http://arxiv.org/abs/1809.06152v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Fast and the Flexible: training neural networks to learn to follow\n  instructions from small data", "abstract": "Learning to follow human instructions is a long-pursued goal in artificial\nintelligence. The task becomes particularly challenging if no prior knowledge\nof the employed language is assumed while relying only on a handful of examples\nto learn from. Work in the past has relied on hand-coded components or manually\nengineered features to provide strong inductive biases that make learning in\nsuch situations possible. In contrast, here we seek to establish whether this\nknowledge can be acquired automatically by a neural network system through a\ntwo phase training procedure: A (slow) offline learning stage where the network\nlearns about the general structure of the task and a (fast) online adaptation\nphase where the network learns the language of a new given speaker. Controlled\nexperiments show that when the network is exposed to familiar instructions but\ncontaining novel words, the model adapts very efficiently to the new\nvocabulary. Moreover, even for human speakers whose language usage can depart\nsignificantly from our artificial training language, our network can still make\nuse of its automatically acquired inductive bias to learn to follow\ninstructions more effectively.", "published": "2018-09-17 13:34:49", "link": "http://arxiv.org/abs/1809.06194v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Sense-Aware Hypernymy Extraction", "abstract": "In this paper, we show how unsupervised sense representations can be used to\nimprove hypernymy extraction. We present a method for extracting disambiguated\nhypernymy relationships that propagates hypernyms to sets of synonyms\n(synsets), constructs embeddings for these sets, and establishes sense-aware\nrelationships between matching synsets. Evaluation on two gold standard\ndatasets for English and Russian shows that the method successfully recognizes\nhypernymy relationships that cannot be found with standard Hearst patterns and\nWiktionary datasets for the respective languages.", "published": "2018-09-17 14:16:49", "link": "http://arxiv.org/abs/1809.06223v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Transfer Through Multilingual and Feedback-Based Back-Translation", "abstract": "Style transfer is the task of transferring an attribute of a sentence (e.g.,\nformality) while maintaining its semantic content. The key challenge in style\ntransfer is to strike a balance between the competing goals, one to preserve\nmeaning and the other to improve the style transfer accuracy. Prior research\nhas identified that the task of meaning preservation is generally harder to\nattain and evaluate. This paper proposes two extensions of the state-of-the-art\nstyle transfer models aiming at improving the meaning preservation in style\ntransfer. Our evaluation shows that these extensions help to ground meaning\nbetter while improving the transfer accuracy.", "published": "2018-09-17 15:47:06", "link": "http://arxiv.org/abs/1809.06284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Text Generation via Feature-Mover's Distance", "abstract": "Generative adversarial networks (GANs) have achieved significant success in\ngenerating real-valued data. However, the discrete nature of text hinders the\napplication of GAN to text-generation tasks. Instead of using the standard GAN\nobjective, we propose to improve text-generation GAN via a novel approach\ninspired by optimal transport. Specifically, we consider matching the latent\nfeature distributions of real and synthetic sentences using a novel metric,\ntermed the feature-mover's distance (FMD). This formulation leads to a highly\ndiscriminative critic and easy-to-optimize objective, overcoming the\nmode-collapsing and brittle-training problems in existing methods. Extensive\nexperiments are conducted on a variety of tasks to evaluate the proposed model\nempirically, including unconditional text generation, style transfer from\nnon-parallel text, and unsupervised cipher cracking. The proposed model yields\nsuperior performance, demonstrating wide applicability and effectiveness.", "published": "2018-09-17 16:03:13", "link": "http://arxiv.org/abs/1809.06297v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Spoken Language Understanding via Paraphrasing", "abstract": "Learning intents and slot labels from user utterances is a fundamental step\nin all spoken language understanding (SLU) and dialog systems. State-of-the-art\nneural network based methods, after deployment, often suffer from performance\ndegradation on encountering paraphrased utterances, and out-of-vocabulary\nwords, rarely observed in their training set. We address this challenging\nproblem by introducing a novel paraphrasing based SLU model which can be\nintegrated with any existing SLU model in order to improve their overall\nperformance. We propose two new paraphrase generators using RNN and\nsequence-to-sequence based neural networks, which are suitable for our\napplication. Our experiments on existing benchmark and in house datasets\ndemonstrate the robustness of our models to rare and complex paraphrased\nutterances, even under adversarial test distributions.", "published": "2018-09-17 21:01:35", "link": "http://arxiv.org/abs/1809.06444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commonsense for Generative Multi-Hop Question Answering Tasks", "abstract": "Reading comprehension QA tasks have seen a recent surge in popularity, yet\nmost works have focused on fact-finding extractive QA. We instead focus on a\nmore challenging multi-hop generative task (NarrativeQA), which requires the\nmodel to reason, gather, and synthesize disjoint pieces of information within\nthe context to generate an answer. This type of multi-step reasoning also often\nrequires understanding implicit relations, which humans resolve via external,\nbackground commonsense knowledge. We first present a strong generative baseline\nthat uses a multi-attention mechanism to perform multiple hops of reasoning and\na pointer-generator decoder to synthesize the answer. This model performs\nsubstantially better than previous generative models, and is competitive with\ncurrent state-of-the-art span prediction models. We next introduce a novel\nsystem for selecting grounded multi-hop relational commonsense information from\nConceptNet via a pointwise mutual information and term-frequency based scoring\nfunction. Finally, we effectively use this extracted commonsense information to\nfill in gaps of reasoning between context hops, using a selectively-gated\nattention mechanism. This boosts the model's performance significantly (also\nverified via human evaluation), establishing a new state-of-the-art for the\ntask. We also show promising initial results of the generalizability of our\nbackground knowledge enhancements by demonstrating some improvement on\nQAngaroo-WikiHop, another multi-hop reasoning dataset.", "published": "2018-09-17 16:24:00", "link": "http://arxiv.org/abs/1809.06309v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "abstract": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "published": "2018-09-17 19:51:18", "link": "http://arxiv.org/abs/1809.06416v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Open-world Learning and Application to Product Classification", "abstract": "Classic supervised learning makes the closed-world assumption, meaning that\nclasses seen in testing must have been seen in training. However, in the\ndynamic world, new or unseen class examples may appear constantly. A model\nworking in such an environment must be able to reject unseen classes (not seen\nor used in training). If enough data is collected for the unseen classes, the\nsystem should incrementally learn to accept/classify them. This learning\nparadigm is called open-world learning (OWL). Existing OWL methods all need\nsome form of re-training to accept or include the new classes in the overall\nmodel. In this paper, we propose a meta-learning approach to the problem. Its\nkey novelty is that it only needs to train a meta-classifier, which can then\ncontinually accept new classes when they have enough labeled data for the\nmeta-classifier to use, and also detect/reject future unseen classes. No\nre-training of the meta-classifier or a new overall classifier covering all old\nand new classes is needed. In testing, the method only uses the examples of the\nseen classes (including the newly added classes) on-the-fly for classification\nand rejection. Experimental results demonstrate the effectiveness of the new\napproach.", "published": "2018-09-17 03:08:58", "link": "http://arxiv.org/abs/1809.06004v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepDrum: An Adaptive Conditional Neural Network", "abstract": "Considering music as a sequence of events with multiple complex dependencies,\nthe Long Short-Term Memory (LSTM) architecture has proven very efficient in\nlearning and reproducing musical styles. However, the generation of rhythms\nrequires additional information regarding musical structure and accompanying\ninstruments. In this paper we present DeepDrum, an adaptive Neural Network\ncapable of generating drum rhythms under constraints imposed by Feed-Forward\n(Conditional) Layers which contain musical parameters along with given\ninstrumentation information (e.g. bass and guitar notes). Results on generated\ndrum sequences are presented indicating that DeepDrum is effective in producing\nrhythms that resemble the learned style, while at the same time conforming to\ngiven constraints that were unknown during the training process.", "published": "2018-09-17 11:08:52", "link": "http://arxiv.org/abs/1809.06127v2", "categories": ["cs.SD", "cs.IR", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Generative x-vectors for text-independent speaker verification", "abstract": "Speaker verification (SV) systems using deep neural network embeddings,\nso-called the x-vector systems, are becoming popular due to its good\nperformance superior to the i-vector systems. The fusion of these systems\nprovides improved performance benefiting both from the discriminatively trained\nx-vectors and generative i-vectors capturing distinct speaker characteristics.\nIn this paper, we propose a novel method to include the complementary\ninformation of i-vector and x-vector, that is called generative x-vector. The\ngenerative x-vector utilizes a transformation model learned from the i-vector\nand x-vector representations of the background data. Canonical correlation\nanalysis is applied to derive this transformation model, which is later used to\ntransform the standard x-vectors of the enrollment and test segments to the\ncorresponding generative x-vectors. The SV experiments performed on the NIST\nSRE 2010 dataset demonstrate that the system using generative x-vectors\nprovides considerably better performance than the baseline i-vector and\nx-vector systems. Furthermore, the generative x-vectors outperform the fusion\nof i-vector and x-vector systems for long-duration utterances, while yielding\ncomparable results for short-duration utterances.", "published": "2018-09-17 06:04:54", "link": "http://arxiv.org/abs/1809.06798v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
