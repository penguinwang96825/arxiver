{"title": "Scalable Cross Lingual Pivots to Model Pronoun Gender for Translation", "abstract": "Machine translation systems with inadequate document understanding can make\nerrors when translating dropped or neutral pronouns into languages with\ngendered pronouns (e.g., English). Predicting the underlying gender of these\npronouns is difficult since it is not marked textually and must instead be\ninferred from coreferent mentions in the context. We propose a novel\ncross-lingual pivoting technique for automatically producing high-quality\ngender labels, and show that this data can be used to fine-tune a BERT\nclassifier with 92% F1 for Spanish dropped feminine pronouns, compared with\n30-51% for neural machine translation models and 54-71% for a non-fine-tuned\nBERT model. We augment a neural machine translation model with labels from our\nclassifier to improve pronoun translation, while still having parallelizable\ntranslation models that translate a sentence at a time.", "published": "2020-06-16 02:41:46", "link": "http://arxiv.org/abs/2006.08881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The SPPD System for Schema Guided Dialogue State Tracking Challenge", "abstract": "This paper introduces one of our group's work on the Dialog System Technology\nChallenges 8 (DSTC8), the SPPD system for Schema Guided dialogue state tracking\nchallenge. This challenge, named as Track 4 in DSTC8, provides a brand new and\nchallenging dataset for developing scalable multi-domain dialogue state\ntracking algorithms for real world dialogue systems. We propose a zero-shot\ndialogue state tracking system for this task. The key components of the system\nis a number of BERT based zero-shot NLU models that can effectively capture\nsemantic relations between natural language descriptions of services' schemas\nand utterances from dialogue turns. We also propose some strategies to make the\nsystem better to exploit information from longer dialogue history and to\novercome the slot carryover problem for multi-domain dialogues. The\nexperimental results show that the proposed system achieves a significant\nimprovement compared with the baseline system.", "published": "2020-06-16 09:57:40", "link": "http://arxiv.org/abs/2006.09035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Probe Sentence Embeddings in Low-Resource Languages: On\n  Structural Design Choices for Probing Task Evaluation", "abstract": "Sentence encoders map sentences to real valued vectors for use in downstream\napplications. To peek into these representations - e.g., to increase\ninterpretability of their results - probing tasks have been designed which\nquery them for linguistic knowledge. However, designing probing tasks for\nlesser-resourced languages is tricky, because these often lack large-scale\nannotated data or (high-quality) dependency parsers as a prerequisite of\nprobing task design in English. To investigate how to probe sentence embeddings\nin such cases, we investigate sensitivity of probing task results to structural\ndesign choices, conducting the first such large scale study. We show that\ndesign choices like size of the annotated probing dataset and type of\nclassifier used for evaluation do (sometimes substantially) influence probing\noutcomes. We then probe embeddings in a multilingual setup with design choices\nthat lie in a 'stable region', as we identify for English, and find that\nresults on English do not transfer to other languages. Fairer and more\ncomprehensive sentence-level probing evaluation should thus be carried out on\nmultiple languages in the future.", "published": "2020-06-16 12:37:50", "link": "http://arxiv.org/abs/2006.09109v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly-supervised Domain Adaption for Aspect Extraction via Multi-level\n  Interaction Transfer", "abstract": "Fine-grained aspect extraction is an essential sub-task in aspect based\nopinion analysis. It aims to identify the aspect terms (a.k.a. opinion targets)\nof a product or service in each sentence. However, expensive annotation process\nis usually involved to acquire sufficient token-level labels for each domain.\nTo address this limitation, some previous works propose domain adaptation\nstrategies to transfer knowledge from a sufficiently labeled source domain to\nunlabeled target domains. But due to both the difficulty of fine-grained\nprediction problems and the large domain gap between domains, the performance\nremains unsatisfactory. This work conducts a pioneer study on leveraging\nsentence-level aspect category labels that can be usually available in\ncommercial services like review sites to promote token-level transfer for the\nextraction purpose. Specifically, the aspect category information is used to\nconstruct pivot knowledge for transfer with assumption that the interactions\nbetween sentence-level aspect category and token-level aspect terms are\ninvariant across domains. To this end, we propose a novel multi-level\nreconstruction mechanism that aligns both the fine-grained and coarse-grained\ninformation in multiple levels of abstractions. Comprehensive experiments\ndemonstrate that our approach can fully utilize sentence-level aspect category\nlabels to improve cross-domain aspect extraction with a large performance gain.", "published": "2020-06-16 15:11:51", "link": "http://arxiv.org/abs/2006.09235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Graph Structure via Relative Position for Text Generation from\n  Knowledge Graphs", "abstract": "We present Graformer, a novel Transformer-based encoder-decoder architecture\nfor graph-to-text generation. With our novel graph self-attention, the encoding\nof a node relies on all nodes in the input graph - not only direct neighbors -\nfacilitating the detection of global patterns. We represent the relation\nbetween two nodes as the length of the shortest path between them. Graformer\nlearns to weight these node-node relations differently for different attention\nheads, thus virtually learning differently connected views of the input graph.\nWe evaluate Graformer on two popular graph-to-text generation benchmarks,\nAGENDA and WebNLG, where it achieves strong performance while using many fewer\nparameters than other approaches.", "published": "2020-06-16 15:20:04", "link": "http://arxiv.org/abs/2006.09242v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Communicative need modulates competition in language change", "abstract": "All living languages change over time. The causes for this are many, one\nbeing the emergence and borrowing of new linguistic elements. Competition\nbetween the new elements and older ones with a similar semantic or grammatical\nfunction may lead to speakers preferring one of them, and leaving the other to\ngo out of use. We introduce a general method for quantifying competition\nbetween linguistic elements in diachronic corpora which does not require\nlanguage-specific resources other than a sufficiently large corpus. This\napproach is readily applicable to a wide range of languages and linguistic\nsubsystems. Here, we apply it to lexical data in five corpora differing in\nlanguage, type, genre, and time span. We find that changes in communicative\nneed are consistently predictive of lexical competition dynamics.\nNear-synonymous words are more likely to directly compete if they belong to a\ntopic of conversation whose importance to language users is constant over time,\npossibly leading to the extinction of one of the competing words. By contrast,\nin topics which are increasing in importance for language users,\nnear-synonymous words tend not to compete directly and can coexist. This\nsuggests that, in addition to direct competition between words, language change\ncan be driven by competition between topics or semantic subspaces.", "published": "2020-06-16 16:11:04", "link": "http://arxiv.org/abs/2006.09277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Cultural Similarity Features for Cross-Lingual Transfer Learning\n  of Pragmatically Motivated Tasks", "abstract": "Much work in cross-lingual transfer learning explored how to select better\ntransfer languages for multilingual tasks, primarily focusing on typological\nand genealogical similarities between languages. We hypothesize that these\nmeasures of linguistic proximity are not enough when working with\npragmatically-motivated tasks, such as sentiment analysis. As an alternative,\nwe introduce three linguistic features that capture cross-cultural similarities\nthat manifest in linguistic patterns and quantify distinct aspects of language\npragmatics: language context-level, figurative language, and the lexification\nof emotion concepts. Our analyses show that the proposed pragmatic features do\ncapture cross-cultural similarities and align well with existing work in\nsociolinguistics and linguistic anthropology. We further corroborate the\neffectiveness of pragmatically-driven transfer in the downstream task of\nchoosing transfer languages for cross-lingual sentiment analysis.", "published": "2020-06-16 17:20:25", "link": "http://arxiv.org/abs/2006.09336v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Role of Verb Semantics in Hungarian Verb-Object Order", "abstract": "Hungarian is often referred to as a discourse-configurational language, since\nthe structural position of constituents is determined by their logical function\n(topic or comment) rather than their grammatical function (e.g., subject or\nobject). We build on work by Koml\\'osy (1989) and argue that in addition to\ndiscourse context, the lexical semantics of the verb also plays a significant\nrole in determining Hungarian word order. In order to investigate the role of\nlexical semantics in determining Hungarian word order, we conduct a\nlarge-scale, data-driven analysis on the ordering of 380 transitive verbs and\ntheir objects, as observed in hundreds of thousands of examples extracted from\nthe Hungarian Gigaword Corpus. We test the effect of lexical semantics on the\nordering of verbs and their objects by grouping verbs into 11 semantic classes.\nIn addition to the semantic class of the verb, we also include two control\nfeatures related to information structure, object definiteness and object NP\nweight, chosen to allow a comparison of their effect size to that of verb\nsemantics. Our results suggest that all three features have a significant\neffect on verb-object ordering in Hungarian and among these features, the\nsemantic class of the verb has the largest effect. Specifically, we find that\nstative verbs, such as fed \"cover\", jelent \"mean\" and \\\"ovez \"surround\", tend\nto be OV-preferring (with the exception of psych verbs which are strongly\nVO-preferring) and non-stative verbs, such as b\\'ir\\'al \"judge\", cs\\\"okkent\n\"reduce\" and cs\\'okol \"kiss\", verbs tend to be VO-preferring. These findings\nsupport our hypothesis that lexical semantic factors influence word order in\nHungarian.", "published": "2020-06-16 18:23:58", "link": "http://arxiv.org/abs/2006.09432v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Manipulating emotions for ground truth emotion analysis", "abstract": "Text data are being used as a lens through which human cognition can be\nstudied at a large scale. Methods like emotion analysis are now in the standard\ntoolkit of computational social scientists but typically rely on third-person\nannotation with unknown validity. As an alternative, this paper introduces\nonline emotion induction techniques from experimental behavioural research as a\nmethod for text-based emotion analysis. Text data were collected from\nparticipants who were randomly allocated to a happy, neutral or sad condition.\nThe findings support the mood induction procedure. We then examined how well\nlexicon approaches can retrieve the induced emotion. All approaches resulted in\nstatistical differences between the true emotion conditions. Overall, only up\nto one-third of the variance in emotion was captured by text-based\nmeasurements. Pretrained classifiers performed poorly on detecting true\nemotions. The paper concludes with limitations and suggestions for future\nresearch.", "published": "2020-06-16 07:03:28", "link": "http://arxiv.org/abs/2006.08952v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "PERL: Pivot-based Domain Adaptation for Pre-trained Deep Contextualized\n  Embedding Models", "abstract": "Pivot-based neural representation models have lead to significant progress in\ndomain adaptation for NLP. However, previous works that follow this approach\nutilize only labeled data from the source domain and unlabeled data from the\nsource and target domains, but neglect to incorporate massive unlabeled corpora\nthat are not necessarily drawn from these domains. To alleviate this, we\npropose PERL: A representation learning model that extends contextualized word\nembedding models such as BERT with pivot-based fine-tuning. PERL outperforms\nstrong baselines across 22 sentiment classification domain adaptation setups,\nimproves in-domain model performance, yields effective reduced-size models and\nincreases model stability.", "published": "2020-06-16 11:14:06", "link": "http://arxiv.org/abs/2006.09075v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Selective Question Answering under Domain Shift", "abstract": "To avoid giving wrong answers, question answering (QA) models need to know\nwhen to abstain from answering. Moreover, users often ask questions that\ndiverge from the model's training data, making errors more likely and thus\nabstention more critical. In this work, we propose the setting of selective\nquestion answering under domain shift, in which a QA model is tested on a\nmixture of in-domain and out-of-domain data, and must answer (i.e., not abstain\non) as many questions as possible while maintaining high accuracy. Abstention\npolicies based solely on the model's softmax probabilities fare poorly, since\nmodels are overconfident on out-of-domain inputs. Instead, we train a\ncalibrator to identify inputs on which the QA model errs, and abstain when it\npredicts an error is likely. Crucially, the calibrator benefits from observing\nthe model's behavior on out-of-domain data, even if from a different domain\nthan the test data. We combine this method with a SQuAD-trained QA model and\nevaluate on mixtures of SQuAD and five other QA datasets. Our method answers\n56% of questions while maintaining 80% accuracy; in contrast, directly using\nthe model's probabilities only answers 48% at 80% accuracy.", "published": "2020-06-16 19:13:21", "link": "http://arxiv.org/abs/2006.09462v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EPIE Dataset: A Corpus For Possible Idiomatic Expressions", "abstract": "Idiomatic expressions have always been a bottleneck for language\ncomprehension and natural language understanding, specifically for tasks like\nMachine Translation(MT). MT systems predominantly produce literal translations\nof idiomatic expressions as they do not exhibit generic and linguistically\ndeterministic patterns which can be exploited for comprehension of the\nnon-compositional meaning of the expressions. These expressions occur in\nparallel corpora used for training, but due to the comparatively high\noccurrences of the constituent words of idiomatic expressions in literal\ncontext, the idiomatic meaning gets overpowered by the compositional meaning of\nthe expression. State of the art Metaphor Detection Systems are able to detect\nnon-compositional usage at word level but miss out on idiosyncratic phrasal\nidiomatic expressions. This creates a dire need for a dataset with a wider\ncoverage and higher occurrence of commonly occurring idiomatic expressions, the\nspans of which can be used for Metaphor Detection. With this in mind, we\npresent our English Possible Idiomatic Expressions(EPIE) corpus containing\n25206 sentences labelled with lexical instances of 717 idiomatic expressions.\nThese spans also cover literal usages for the given set of idiomatic\nexpressions. We also present the utility of our dataset by using it to train a\nsequence labelling module and testing on three independent datasets with high\naccuracy, precision and recall scores.", "published": "2020-06-16 19:43:30", "link": "http://arxiv.org/abs/2006.09479v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Retrieval for Iterative Self-Supervised Training", "abstract": "Recent studies have demonstrated the cross-lingual alignment ability of\nmultilingual pretrained language models. In this work, we found that the\ncross-lingual alignment can be further improved by training seq2seq models on\nsentence pairs mined using their own encoder outputs. We utilized these\nfindings to develop a new approach -- cross-lingual retrieval for iterative\nself-supervised training (CRISS), where mining and training processes are\napplied iteratively, improving cross-lingual alignment and translation ability\nat the same time. Using this method, we achieved state-of-the-art unsupervised\nmachine translation results on 9 language directions with an average\nimprovement of 2.4 BLEU, and on the Tatoeba sentence retrieval task in the\nXTREME benchmark on 16 languages with an average improvement of 21.5% in\nabsolute accuracy. Furthermore, CRISS also brings an additional 1.8 BLEU\nimprovement on average compared to mBART, when finetuned on supervised machine\ntranslation downstream tasks.", "published": "2020-06-16 21:30:51", "link": "http://arxiv.org/abs/2006.09526v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generative Semantic Hashing Enhanced via Boltzmann Machines", "abstract": "Generative semantic hashing is a promising technique for large-scale\ninformation retrieval thanks to its fast retrieval speed and small memory\nfootprint. For the tractability of training, existing generative-hashing\nmethods mostly assume a factorized form for the posterior distribution,\nenforcing independence among the bits of hash codes. From the perspectives of\nboth model representation and code space size, independence is always not the\nbest assumption. In this paper, to introduce correlations among the bits of\nhash codes, we propose to employ the distribution of Boltzmann machine as the\nvariational posterior. To address the intractability issue of training, we\nfirst develop an approximate method to reparameterize the distribution of a\nBoltzmann machine by augmenting it as a hierarchical concatenation of a\nGaussian-like distribution and a Bernoulli distribution. Based on that, an\nasymptotically-exact lower bound is further derived for the evidence lower\nbound (ELBO). With these novel techniques, the entire model can be optimized\nefficiently. Extensive experimental results demonstrate that by effectively\nmodeling correlations among different bits within a hash code, our model can\nachieve significant performance gains.", "published": "2020-06-16 01:23:39", "link": "http://arxiv.org/abs/2006.08858v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "End-to-End Code Switching Language Models for Automatic Speech\n  Recognition", "abstract": "In this paper, we particularly work on the code-switched text, one of the\nmost common occurrences in the bilingual communities across the world. Due to\nthe discrepancies in the extraction of code-switched text from an Automated\nSpeech Recognition(ASR) module, and thereby extracting the monolingual text\nfrom the code-switched text, we propose an approach for extracting monolingual\ntext using Deep Bi-directional Language Models(LM) such as BERT and other\nMachine Translation models, and also explore different ways of extracting\ncode-switched text from the ASR model. We also explain the robustness of the\nmodel by comparing the results of Perplexity and other different metrics like\nWER, to the standard bi-lingual text output without any external information.", "published": "2020-06-16 02:11:18", "link": "http://arxiv.org/abs/2006.08870v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Causal Knowledge Extraction from Scholarly Papers in Social Sciences", "abstract": "The scale and scope of scholarly articles today are overwhelming human\nresearchers who seek to timely digest and synthesize knowledge. In this paper,\nwe seek to develop natural language processing (NLP) models to accelerate the\nspeed of extraction of relationships from scholarly papers in social sciences,\nidentify hypotheses from these papers, and extract the cause-and-effect\nentities. Specifically, we develop models to 1) classify sentences in scholarly\ndocuments in business and management as hypotheses (hypothesis classification),\n2) classify these hypotheses as causal relationships or not (causality\nclassification), and, if they are causal, 3) extract the cause and effect\nentities from these hypotheses (entity extraction). We have achieved high\nperformance for all the three tasks using different modeling techniques. Our\napproach may be generalizable to scholarly documents in a wide range of social\nsciences, as well as other types of textual materials.", "published": "2020-06-16 03:37:40", "link": "http://arxiv.org/abs/2006.08904v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual\n  Question Answering", "abstract": "Fact-based Visual Question Answering (FVQA) requires external knowledge\nbeyond visible content to answer questions about an image, which is challenging\nbut indispensable to achieve general VQA. One limitation of existing FVQA\nsolutions is that they jointly embed all kinds of information without\nfine-grained selection, which introduces unexpected noises for reasoning the\nfinal answer. How to capture the question-oriented and\ninformation-complementary evidence remains a key challenge to solve the\nproblem. In this paper, we depict an image by a multi-modal heterogeneous\ngraph, which contains multiple layers of information corresponding to the\nvisual, semantic and factual features. On top of the multi-layer graph\nrepresentations, we propose a modality-aware heterogeneous graph convolutional\nnetwork to capture evidence from different layers that is most relevant to the\ngiven question. Specifically, the intra-modal graph convolution selects\nevidence from each modality and cross-modal graph convolution aggregates\nrelevant information across different modalities. By stacking this process\nmultiple times, our model performs iterative reasoning and predicts the optimal\nanswer by analyzing all question-oriented evidence. We achieve a new\nstate-of-the-art performance on the FVQA task and demonstrate the effectiveness\nand interpretability of our model with extensive experiments.", "published": "2020-06-16 11:03:37", "link": "http://arxiv.org/abs/2006.09073v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Results of the seventh edition of the BioASQ Challenge", "abstract": "The results of the seventh edition of the BioASQ challenge are presented in\nthis paper. The aim of the BioASQ challenge is the promotion of systems and\nmethodologies through the organization of a challenge on the tasks of\nlarge-scale biomedical semantic indexing and question answering. In total, 30\nteams with more than 100 systems participated in the challenge this year. As in\nprevious years, the best systems were able to outperform the strong baselines.\nThis suggests that state-of-the-art systems are continuously improving, pushing\nthe frontier of research.", "published": "2020-06-16 14:23:27", "link": "http://arxiv.org/abs/2006.09174v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Computational Power of Transformers and its Implications in\n  Sequence Modeling", "abstract": "Transformers are being used extensively across several sequence modeling\ntasks. Significant research effort has been devoted to experimentally probe the\ninner workings of Transformers. However, our conceptual and theoretical\nunderstanding of their power and inherent limitations is still nascent. In\nparticular, the roles of various components in Transformers such as positional\nencodings, attention heads, residual connections, and feedforward networks, are\nnot clear. In this paper, we take a step towards answering these questions. We\nanalyze the computational power as captured by Turing-completeness. We first\nprovide an alternate and simpler proof to show that vanilla Transformers are\nTuring-complete and then we prove that Transformers with only positional\nmasking and without any positional encoding are also Turing-complete. We\nfurther analyze the necessity of each component for the Turing-completeness of\nthe network; interestingly, we find that a particular type of residual\nconnection is necessary. We demonstrate the practical implications of our\nresults via experiments on machine translation and synthetic tasks.", "published": "2020-06-16 16:27:56", "link": "http://arxiv.org/abs/2006.09286v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AVLnet: Learning Audio-Visual Language Representations from\n  Instructional Videos", "abstract": "Current methods for learning visually grounded language from videos often\nrely on text annotation, such as human generated captions or machine generated\nautomatic speech recognition (ASR) transcripts. In this work, we introduce the\nAudio-Video Language Network (AVLnet), a self-supervised network that learns a\nshared audio-visual embedding space directly from raw video inputs. To\ncircumvent the need for text annotation, we learn audio-visual representations\nfrom randomly segmented video clips and their raw audio waveforms. We train\nAVLnet on HowTo100M, a large corpus of publicly available instructional videos,\nand evaluate on image retrieval and video retrieval tasks, achieving\nstate-of-the-art performance. We perform analysis of AVLnet's learned\nrepresentations, showing our model utilizes speech and natural sounds to learn\naudio-visual concepts. Further, we propose a tri-modal model that jointly\nprocesses raw audio, video, and text captions from videos to learn a\nmulti-modal semantic embedding space useful for text-video retrieval. Our code,\ndata, and trained models will be released at avlnet.csail.mit.edu", "published": "2020-06-16 14:38:03", "link": "http://arxiv.org/abs/2006.09199v2", "categories": ["cs.CV", "cs.CL", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Towards Automated Assessment of Stuttering and Stuttering Therapy", "abstract": "Stuttering is a complex speech disorder that can be identified by\nrepetitions, prolongations of sounds, syllables or words, and blocks while\nspeaking. Severity assessment is usually done by a speech therapist. While\nattempts at automated assessment were made, it is rarely used in therapy.\nCommon methods for the assessment of stuttering severity include percent\nstuttered syllables (% SS), the average of the three longest stuttering\nsymptoms during a speech task, or the recently introduced Speech Efficiency\nScore (SES). This paper introduces the Speech Control Index (SCI), a new method\nto evaluate the severity of stuttering. Unlike SES, it can also be used to\nassess therapy success for fluency shaping. We evaluate both SES and SCI on a\nnew comprehensively labeled dataset containing stuttered German speech of\nclients prior to, during, and after undergoing stuttering therapy. Phone\nalignments of an automatic speech recognition system are statistically\nevaluated in relation to their relative position to labeled stuttering events.\nThe results indicate that phone length distributions differ with respect to\ntheir position in and around labeled stuttering events", "published": "2020-06-16 14:50:56", "link": "http://arxiv.org/abs/2006.09222v1", "categories": ["q-bio.QM", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "q-bio.QM"}
{"title": "Quantization of Acoustic Model Parameters in Automatic Speech\n  Recognition Framework", "abstract": "State-of-the-art hybrid automatic speech recognition (ASR) system exploits\ndeep neural network (DNN) based acoustic models (AM) trained with Lattice\nFree-Maximum Mutual Information (LF-MMI) criterion and n-gram language models.\nThe AMs typically have millions of parameters and require significant parameter\nreduction to operate on embedded devices. The impact of parameter quantization\non the overall word recognition performance is studied in this paper. Following\napproaches are presented: (i) AM trained in Kaldi framework with conventional\nfactorized TDNN (TDNN-F) architecture, (ii) the TDNN AM built in Kaldi loaded\ninto the PyTorch toolkit using a C++ wrapper for post-training quantization,\n(iii) quantization-aware training in PyTorch for Kaldi TDNN model, (iv)\nquantization-aware training in Kaldi. Results obtained on standard Librispeech\nsetup provide an interesting overview of recognition accuracy w.r.t. applied\nquantization scheme.", "published": "2020-06-16 10:19:23", "link": "http://arxiv.org/abs/2006.09054v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Comparing Representations for Audio Synthesis Using Generative\n  Adversarial Networks", "abstract": "In this paper, we compare different audio signal representations, including\nthe raw audio waveform and a variety of time-frequency representations, for the\ntask of audio synthesis with Generative Adversarial Networks (GANs). We conduct\nthe experiments on a subset of the NSynth dataset. The architecture follows the\nbenchmark Progressive Growing Wasserstein GAN. We perform experiments both in a\nfully non-conditional manner as well as conditioning the network on the pitch\ninformation. We quantitatively evaluate the generated material utilizing\nstandard metrics for assessing generative models, and compare training and\nsampling times. We show that complex-valued as well as the magnitude and\nInstantaneous Frequency of the Short-Time Fourier Transform achieve the best\nresults, and yield fast generation and inversion times. The code for feature\nextraction, training and evaluating the model is available online.", "published": "2020-06-16 15:48:17", "link": "http://arxiv.org/abs/2006.09266v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust Sound Source Tracking Using SRP-PHAT and 3D Convolutional Neural\n  Networks", "abstract": "In this paper, we present a new single sound source DOA estimation and\ntracking system based on the well-known SRP-PHAT algorithm and a\nthree-dimensional Convolutional Neural Network. It uses SRP-PHAT power maps as\ninput features of a fully convolutional causal architecture that uses 3D\nconvolutional layers to accurately perform the tracking of a sound source even\nin highly reverberant scenarios where most of the state of the art techniques\nfail. Unlike previous methods, since we do not use bidirectional recurrent\nlayers and all our convolutional layers are causal in the time dimension, our\nsystem is feasible for real-time applications and it provides a new DOA\nestimation for each new SRP-PHAT map. To train the model, we introduce a new\nprocedure to simulate random trajectories as they are needed during the\ntraining, equivalent to an infinite-size dataset with high flexibility to\nmodify its acoustical conditions such as the reverberation time. We use both\nacoustical simulations on a large range of reverberation times and the actual\nrecordings of the LOCATA dataset to prove the robustness of our system and its\ngood performance even using low-resolution SRP-PHAT maps.", "published": "2020-06-16 09:07:33", "link": "http://arxiv.org/abs/2006.09006v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Adversarial representation learning for private speech generation", "abstract": "As more and more data is collected in various settings across organizations,\ncompanies, and countries, there has been an increase in the demand of user\nprivacy. Developing privacy preserving methods for data analytics is thus an\nimportant area of research. In this work we present a model based on generative\nadversarial networks (GANs) that learns to obfuscate specific sensitive\nattributes in speech data. We train a model that learns to hide sensitive\ninformation in the data, while preserving the meaning in the utterance. The\nmodel is trained in two steps: first to filter sensitive information in the\nspectrogram domain, and then to generate new and private information\nindependent of the filtered one. The model is based on a U-Net CNN that takes\nmel-spectrograms as input. A MelGAN is used to invert the spectrograms back to\nraw audio waveforms. We show that it is possible to hide sensitive information\nsuch as gender by generating new data, trained adversarially to maintain\nutility and realism.", "published": "2020-06-16 12:44:35", "link": "http://arxiv.org/abs/2006.09114v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Assisted music creation with Flow Machines: towards new categories of\n  new", "abstract": "This chapter reflects on about 10 years of research in AI- assisted music\ncomposition, in particular during the Flow Machines project. We reflect on the\nmotivations for such a project, its background, its main results and impact,\nboth technological and musical, several years after its completion. We conclude\nwith a proposal for new categories of new, created by the many uses of AI\ntechniques to generate novel material.", "published": "2020-06-16 15:08:22", "link": "http://arxiv.org/abs/2006.09232v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generative Modelling for Controllable Audio Synthesis of Expressive\n  Piano Performance", "abstract": "We present a controllable neural audio synthesizer based on Gaussian Mixture\nVariational Autoencoders (GM-VAE), which can generate realistic piano\nperformances in the audio domain that closely follows temporal conditions of\ntwo essential style features for piano performances: articulation and dynamics.\nWe demonstrate how the model is able to apply fine-grained style morphing over\nthe course of synthesizing the audio. This is based on conditions which are\nlatent variables that can be sampled from the prior or inferred from other\npieces. One of the envisioned use cases is to inspire creative and brand new\ninterpretations for existing pieces of piano music.", "published": "2020-06-16 12:54:41", "link": "http://arxiv.org/abs/2006.09833v2", "categories": ["eess.AS", "cs.LG", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LSTM Networks for Music Generation", "abstract": "The paper presents a method of the music generation based on LSTM (Long\nShort-Term Memory), contrasts the effects of different network structures on\nthe music generation and introduces other methods used by some researchers.", "published": "2020-06-16 04:44:30", "link": "http://arxiv.org/abs/2006.09838v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
