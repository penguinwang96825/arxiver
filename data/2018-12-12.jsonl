{"title": "Sentence-wise Smooth Regularization for Sequence to Sequence Learning", "abstract": "Maximum-likelihood estimation (MLE) is widely used in sequence to sequence\ntasks for model training. It uniformly treats the generation/prediction of each\ntarget token as multi-class classification, and yields non-smooth prediction\nprobabilities: in a target sequence, some tokens are predicted with small\nprobabilities while other tokens are with large probabilities. According to our\nempirical study, we find that the non-smoothness of the probabilities results\nin low quality of generated sequences. In this paper, we propose a\nsentence-wise regularization method which aims to output smooth prediction\nprobabilities for all the tokens in the target sequence. Our proposed method\ncan automatically adjust the weights and gradients of each token in one\nsentence to ensure the predictions in a sequence uniformly well. Experiments on\nthree neural machine translation tasks and one text summarization task show\nthat our method outperforms conventional MLE loss on all these tasks and\nachieves promising BLEU scores on WMT14 English-German and WMT17\nChinese-English translation task.", "published": "2018-12-12 02:47:11", "link": "http://arxiv.org/abs/1812.04784v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multimodal LSTM for Predicting Listener Empathic Responses Over Time", "abstract": "People naturally understand the emotions of-and often also empathize\nwith-those around them. In this paper, we predict the emotional valence of an\nempathic listener over time as they listen to a speaker narrating a life story.\nWe use the dataset provided by the OMG-Empathy Prediction Challenge, a workshop\nheld in conjunction with IEEE FG 2019. We present a multimodal LSTM model with\nfeature-level fusion and local attention that predicts empathic responses from\naudio, text, and visual features. Our best-performing model, which used only\nthe audio and text features, achieved a concordance correlation coefficient\n(CCC) of 0.29 and 0.32 on the Validation set for the Generalized and\nPersonalized track respectively, and achieved a CCC of 0.14 and 0.14 on the\nheld-out Test set. We discuss the difficulties faced and the lessons learnt\ntackling this challenge.", "published": "2018-12-12 10:57:52", "link": "http://arxiv.org/abs/1812.04891v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SMT vs NMT: A Comparison over Hindi & Bengali Simple Sentences", "abstract": "In the present article, we identified the qualitative differences between\nStatistical Machine Translation (SMT) and Neural Machine Translation (NMT)\noutputs. We have tried to answer two important questions: 1. Does NMT perform\nequivalently well with respect to SMT and 2. Does it add extra flavor in\nimproving the quality of MT output by employing simple sentences as training\nunits. In order to obtain insights, we have developed three core models viz.,\nSMT model based on Moses toolkit, followed by character and word level NMT\nmodels. All of the systems use English-Hindi and English-Bengali language pairs\ncontaining simple sentences as well as sentences of other complexity. In order\nto preserve the translations semantics with respect to the target words of a\nsentence, we have employed soft-attention into our word level NMT model. We\nhave further evaluated all the systems with respect to the scenarios where they\nsucceed and fail. Finally, the quality of translation has been validated using\nBLEU and TER metrics along with manual parameters like fluency, adequacy etc.\nWe observed that NMT outperforms SMT in case of simple sentences whereas SMT\noutperforms in case of all types of sentence.", "published": "2018-12-12 11:11:08", "link": "http://arxiv.org/abs/1812.04898v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PyText: A Seamless Path from NLP research to production", "abstract": "We introduce PyText - a deep learning based NLP modeling framework built on\nPyTorch. PyText addresses the often-conflicting requirements of enabling rapid\nexperimentation and of serving models at scale. It achieves this by providing\nsimple and extensible interfaces for model components, and by using PyTorch's\ncapabilities of exporting models for inference via the optimized Caffe2\nexecution engine. We report our own experience of migrating experimentation and\nproduction workflows to PyText, which enabled us to iterate faster on novel\nmodeling ideas and then seamlessly ship them at industrial scale.", "published": "2018-12-12 23:06:43", "link": "http://arxiv.org/abs/1812.08729v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding Language through Perception in Situated\n  Human-Robot Interaction: From Word Grounding to Grammar Induction", "abstract": "Robots are widely collaborating with human users in diferent tasks that\nrequire high-level cognitive functions to make them able to discover the\nsurrounding environment. A difcult challenge that we briefy highlight in this\nshort paper is inferring the latent grammatical structure of language, which\nincludes grounding parts of speech (e.g., verbs, nouns, adjectives, and\nprepositions) through visual perception, and induction of Combinatory\nCategorial Grammar (CCG) for phrases. This paves the way towards grounding\nphrases so as to make a robot able to understand human instructions\nappropriately during interaction.", "published": "2018-12-12 08:06:30", "link": "http://arxiv.org/abs/1812.04840v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Temporal Analysis of Entity Relatedness and its Evolution using\n  Wikipedia and DBpedia", "abstract": "Many researchers have made use of the Wikipedia network for relatedness and\nsimilarity tasks. However, most approaches use only the most recent information\nand not historical changes in the network. We provide an analysis of entity\nrelatedness using temporal graph-based approaches over different versions of\nthe Wikipedia article link network and DBpedia, which is an open-source\nknowledge base extracted from Wikipedia. We consider creating the Wikipedia\narticle link network as both a union and intersection of edges over multiple\ntime points and present a novel variation of the Jaccard index to weight edges\nbased on their transience. We evaluate our results against the KORE dataset,\nwhich was created in 2010, and show that using the 2010 Wikipedia article link\nnetwork produces the strongest result, suggesting that semantic similarity is\ntime sensitive. We then show that integrating multiple time frames in our\nmethods can give a better overall similarity demonstrating that temporal\nevolution can have an important effect on entity relatedness.", "published": "2018-12-12 16:11:31", "link": "http://arxiv.org/abs/1812.05001v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Structured Neural Topic Models for Reviews", "abstract": "We present Variational Aspect-based Latent Topic Allocation (VALTA), a family\nof autoencoding topic models that learn aspect-based representations of\nreviews. VALTA defines a user-item encoder that maps bag-of-words vectors for\ncombined reviews associated with each paired user and item onto structured\nembeddings, which in turn define per-aspect topic weights. We model individual\nreviews in a structured manner by inferring an aspect assignment for each\nsentence in a given review, where the per-aspect topic weights obtained by the\nuser-item encoder serve to define a mixture over topics, conditioned on the\naspect. The result is an autoencoding neural topic model for reviews, which can\nbe trained in a fully unsupervised manner to learn topics that are structured\ninto aspects. Experimental evaluation on large number of datasets demonstrates\nthat aspects are interpretable, yield higher coherence scores than\nnon-structured autoencoding topic model variants, and can be utilized to\nperform aspect-based comparison and genre discovery.", "published": "2018-12-12 17:12:58", "link": "http://arxiv.org/abs/1812.05035v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Networks with Pre-trained Language Model Embedding for\n  Slot Filling Task", "abstract": "In recent years, Recurrent Neural Networks (RNNs) based models have been\napplied to the Slot Filling problem of Spoken Language Understanding and\nachieved the state-of-the-art performances. In this paper, we investigate the\neffect of incorporating pre-trained language models into RNN based Slot Filling\nmodels. Our evaluation on the Airline Travel Information System (ATIS) data\ncorpus shows that we can significantly reduce the size of labeled training data\nand achieve the same level of Slot Filling performance by incorporating extra\nword embedding and language model embedding layers pre-trained on unlabeled\ncorpora.", "published": "2018-12-12 23:49:58", "link": "http://arxiv.org/abs/1812.05199v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning of Semantic Relevance in Text to Image Synthesis", "abstract": "We describe a new approach that improves the training of generative\nadversarial nets (GANs) for synthesizing diverse images from a text input. Our\napproach is based on the conditional version of GANs and expands on previous\nwork leveraging an auxiliary task in the discriminator. Our generated images\nare not limited to certain classes and do not suffer from mode collapse while\nsemantically matching the text input. A key to our training methods is how to\nform positive and negative training examples with respect to the class label of\na given image. Instead of selecting random training examples, we perform\nnegative sampling based on the semantic distance from a positive example in the\nclass. We evaluate our approach using the Oxford-102 flower dataset, adopting\nthe inception score and multi-scale structural similarity index (MS-SSIM)\nmetrics to assess discriminability and diversity of the generated images. The\nempirical results indicate greater diversity in the generated images,\nespecially when we gradually select more negative training examples closer to a\npositive example in the semantic space.", "published": "2018-12-12 18:44:23", "link": "http://arxiv.org/abs/1812.05083v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Bayesian Sparsification of Gated Recurrent Neural Networks", "abstract": "Bayesian methods have been successfully applied to sparsify weights of neural\nnetworks and to remove structure units from the networks, e. g. neurons. We\napply and further develop this approach for gated recurrent architectures.\nSpecifically, in addition to sparsification of individual weights and neurons,\nwe propose to sparsify preactivations of gates and information flow in LSTM. It\nmakes some gates and information flow components constant, speeds up forward\npass and improves compression. Moreover, the resulting structure of gate\nsparsity is interpretable and depends on the task. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN", "published": "2018-12-12 14:32:16", "link": "http://arxiv.org/abs/1812.05692v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Global Anchor Method for Quantifying Linguistic Shifts and Domain\n  Adaptation", "abstract": "Language is dynamic, constantly evolving and adapting with respect to time,\ndomain or topic. The adaptability of language is an active research area, where\nresearchers discover social, cultural and domain-specific changes in language\nusing distributional tools such as word embeddings. In this paper, we introduce\nthe global anchor method for detecting corpus-level language shifts. We show\nboth theoretically and empirically that the global anchor method is equivalent\nto the alignment method, a widely-used method for comparing word embeddings, in\nterms of detecting corpus-level language shifts. Despite their equivalence in\nterms of detection abilities, we demonstrate that the global anchor method is\nsuperior in terms of applicability as it can compare embeddings of different\ndimensionalities. Furthermore, the global anchor method has implementation and\nparallelization advantages. We show that the global anchor method reveals fine\nstructures in the evolution of language and domain adaptation. When combined\nwith the graph Laplacian technique, the global anchor method recovers the\nevolution trajectory and domain clustering of disparate text corpora.", "published": "2018-12-12 02:38:56", "link": "http://arxiv.org/abs/1812.10382v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Detecting weak and strong Islamophobic hate speech on social media", "abstract": "Islamophobic hate speech on social media inflicts considerable harm on both\ntargeted individuals and wider society, and also risks reputational damage for\nthe host platforms. Accordingly, there is a pressing need for robust tools to\ndetect and classify Islamophobic hate speech at scale. Previous research has\nlargely approached the detection of Islamophobic hate speech on social media as\na binary task. However, the varied nature of Islamophobia means that this is\noften inappropriate for both theoretically-informed social science and\neffectively monitoring social media. Drawing on in-depth conceptual work we\nbuild a multi-class classifier which distinguishes between non-Islamophobic,\nweak Islamophobic and strong Islamophobic content. Accuracy is 77.6% and\nbalanced accuracy is 83%. We apply the classifier to a dataset of 109,488\ntweets produced by far right Twitter accounts during 2017. Whilst most tweets\nare not Islamophobic, weak Islamophobia is considerably more prevalent (36,963\ntweets) than strong (14,895 tweets). Our main input feature is a gloVe word\nembeddings model trained on a newly collected corpus of 140 million tweets. It\noutperforms a generic word embeddings model by 5.9 percentage points,\ndemonstrating the importan4ce of context. Unexpectedly, we also find that a\none-against-one multi class SVM outperforms a deep learning algorithm.", "published": "2018-12-12 10:34:21", "link": "http://arxiv.org/abs/1812.10400v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Word Embedding based on Low-Rank Doubly Stochastic Matrix Decomposition", "abstract": "Word embedding, which encodes words into vectors, is an important starting\npoint in natural language processing and commonly used in many text-based\nmachine learning tasks. However, in most current word embedding approaches, the\nsimilarity in embedding space is not optimized in the learning. In this paper\nwe propose a novel neighbor embedding method which directly learns an embedding\nsimplex where the similarities between the mapped words are optimal in terms of\nminimal discrepancy to the input neighborhoods. Our method is built upon\ntwo-step random walks between words via topics and thus able to better reveal\nthe topics among the words. Experiment results indicate that our method,\ncompared with another existing word embedding approach, is more favorable for\nvarious queries.", "published": "2018-12-12 15:38:46", "link": "http://arxiv.org/abs/1812.10401v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "FPETS : Fully Parallel End-to-End Text-to-Speech System", "abstract": "End-to-end Text-to-speech (TTS) system can greatly improve the quality of\nsynthesised speech. But it usually suffers form high time latency due to its\nauto-regressive structure. And the synthesised speech may also suffer from some\nerror modes, e.g. repeated words, mispronunciations, and skipped words. In this\npaper, we propose a novel non-autoregressive, fully parallel end-to-end TTS\nsystem (FPETS). It utilizes a new alignment model and the recently proposed\nU-shape convolutional structure, UFANS. Different from RNN, UFANS can capture\nlong term information in a fully parallel manner. Trainable position encoding\nand two-step training strategy are used for learning better alignments.\nExperimental results show FPETS utilizes the power of parallel computation and\nreaches a significant speed up of inference compared with state-of-the-art\nend-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,\n50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates\naudios with equal or better quality and fewer errors comparing with other\nsystem. As far as we know, FPETS is the first end-to-end TTS system which is\nfully parallel.", "published": "2018-12-12 05:17:23", "link": "http://arxiv.org/abs/1812.05710v5", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "MorpheuS: generating structured music with constrained patterns and\n  tension", "abstract": "Automatic music generation systems have gained in popularity and\nsophistication as advances in cloud computing have enabled large-scale complex\ncomputations such as deep models and optimization algorithms on personal\ndevices. Yet, they still face an important challenge, that of long-term\nstructure, which is key to conveying a sense of musical coherence. We present\nthe MorpheuS music generation system designed to tackle this problem. MorpheuS'\nnovel framework has the ability to generate polyphonic pieces with a given\ntension profile and long- and short-term repeated pattern structures. A\nmathematical model for tonal tension quantifies the tension profile and\nstate-of-the-art pattern detection algorithms extract repeated patterns in a\ntemplate piece. An efficient optimization metaheuristic, variable neighborhood\nsearch, generates music by assigning pitches that best fit the prescribed\ntension profile to the template rhythm while hard constraining long-term\nstructure through the detected patterns. This ability to generate affective\nmusic with specific tension profile and long-term structure is particularly\nuseful in a game or film music context. Music generated by the MorpheuS system\nhas been performed live in concerts.", "published": "2018-12-12 07:17:48", "link": "http://arxiv.org/abs/1812.04832v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Description of algorithms for Ben-Gurion University Submission to the\n  LOCATA challenge", "abstract": "This paper summarizes the methods used to localize the sources recorded for\nthe LOCalization And TrAcking (LOCATA) challenge. The tasks of stationary\nsources and arrays were considered, i.e., tasks 1 and 2 of the challenge, which\nwere recorded with the Nao robot array, and the Eigenmike array. For both\narrays, direction of arrival (DOA) estimation has been performed with\nmeasurements in the short time Fourier transform domain, and with direct-path\ndominance (DPD) based tests, which aim to identify time-frequency (TF) bins\ndominated by the direct sound. For the recordings with Nao, a DPD test which is\napplied directly to the microphone signals was used. For the Eigenmike\nrecordings, a DPD based test designed for plane-wave density measurements in\nthe spherical harmonics domain was used. After acquiring DOA estimates with TF\nbins that passed the DPD tests, a stage of k-means clustering is performed, to\nassign a final DOA estimate for each speaker.", "published": "2018-12-12 13:55:33", "link": "http://arxiv.org/abs/1812.04942v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
