{"title": "Extract, Integrate, Compete: Towards Verification Style Reading\n  Comprehension", "abstract": "In this paper, we present a new verification style reading comprehension\ndataset named VGaokao from Chinese Language tests of Gaokao. Different from\nexisting efforts, the new dataset is originally designed for native speakers'\nevaluation, thus requiring more advanced language understanding skills. To\naddress the challenges in VGaokao, we propose a novel Extract-Integrate-Compete\napproach, which iteratively selects complementary evidence with a novel query\nupdating mechanism and adaptively distills supportive evidence, followed by a\npairwise competition to push models to learn the subtle difference among\nsimilar text pieces. Experiments show that our methods outperform various\nbaselines on VGaokao with retrieved complementary evidence, while having the\nmerits of efficiency and explainability. Our dataset and code are released for\nfurther research.", "published": "2021-09-11 01:34:59", "link": "http://arxiv.org/abs/2109.05149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural SQL: Making SQL Easier to Infer from Natural Language\n  Specifications", "abstract": "Addressing the mismatch between natural language descriptions and the\ncorresponding SQL queries is a key challenge for text-to-SQL translation. To\nbridge this gap, we propose an SQL intermediate representation (IR) called\nNatural SQL (NatSQL). Specifically, NatSQL preserves the core functionalities\nof SQL, while it simplifies the queries as follows: (1) dispensing with\noperators and keywords such as GROUP BY, HAVING, FROM, JOIN ON, which are\nusually hard to find counterparts for in the text descriptions; (2) removing\nthe need for nested subqueries and set operators; and (3) making schema linking\neasier by reducing the required number of schema items. On Spider, a\nchallenging text-to-SQL benchmark that contains complex and nested SQL queries,\nwe demonstrate that NatSQL outperforms other IRs, and significantly improves\nthe performance of several previous SOTA models. Furthermore, for existing\nmodels that do not support executable SQL generation, NatSQL easily enables\nthem to generate executable SQL queries, and achieves the new state-of-the-art\nexecution accuracy.", "published": "2021-09-11 01:53:55", "link": "http://arxiv.org/abs/2109.05153v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Underexplored Limitations of Cross-Domain Text-to-SQL\n  Generalization", "abstract": "Recently, there has been significant progress in studying neural networks for\ntranslating text descriptions into SQL queries under the zero-shot cross-domain\nsetting. Despite achieving good performance on some public benchmarks, we\nobserve that existing text-to-SQL models do not generalize when facing domain\nknowledge that does not frequently appear in the training data, which may\nrender the worse prediction performance for unseen domains. In this work, we\ninvestigate the robustness of text-to-SQL models when the questions require\nrarely observed domain knowledge. In particular, we define five types of domain\nknowledge and introduce Spider-DK (DK is the abbreviation of domain knowledge),\na human-curated dataset based on the Spider benchmark for text-to-SQL\ntranslation. NL questions in Spider-DK are selected from Spider, and we modify\nsome samples by adding domain knowledge that reflects real-world question\nparaphrases. We demonstrate that the prediction accuracy dramatically drops on\nsamples that require such domain knowledge, even if the domain knowledge\nappears in the training set, and the model provides the correct predictions for\nrelated training samples.", "published": "2021-09-11 02:01:04", "link": "http://arxiv.org/abs/2109.05157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StreamHover: Livestream Transcript Summarization and Annotation", "abstract": "With the explosive growth of livestream broadcasting, there is an urgent need\nfor new summarization technology that enables us to create a preview of\nstreamed content and tap into this wealth of knowledge. However, the problem is\nnontrivial due to the informal nature of spoken language. Further, there has\nbeen a shortage of annotated datasets that are necessary for transcript\nsummarization. In this paper, we present StreamHover, a framework for\nannotating and summarizing livestream transcripts. With a total of over 500\nhours of videos annotated with both extractive and abstractive summaries, our\nbenchmark dataset is significantly larger than currently existing annotated\ncorpora. We explore a neural extractive summarization model that leverages\nvector-quantized variational autoencoder to learn latent vector representations\nof spoken utterances and identify salient utterances from the transcripts to\nform summaries. We show that our model generalizes better and improves\nperformance over strong baselines. The results of this study provide an avenue\nfor future research to improve summarization solutions for efficient browsing\nof livestreams.", "published": "2021-09-11 02:19:37", "link": "http://arxiv.org/abs/2109.05160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Categorization of Social Knowledge for Commonsense Question\n  Answering", "abstract": "Large pre-trained language models (PLMs) have led to great success on various\ncommonsense question answering (QA) tasks in an end-to-end fashion. However,\nlittle attention has been paid to what commonsense knowledge is needed to\ndeeply characterize these QA tasks. In this work, we proposed to categorize the\nsemantics needed for these tasks using the SocialIQA as an example. Building\nupon our labeled social knowledge categories dataset on top of SocialIQA, we\nfurther train neural QA models to incorporate such social knowledge categories\nand relation information from a knowledge base. Unlike previous work, we\nobserve our models with semantic categorizations of social knowledge can\nachieve comparable performance with a relatively simple model and smaller size\ncompared to other complex approaches.", "published": "2021-09-11 02:56:14", "link": "http://arxiv.org/abs/2109.05168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "College Student Retention Risk Analysis From Educational Database using\n  Multi-Task Multi-Modal Neural Fusion", "abstract": "We develop a Multimodal Spatiotemporal Neural Fusion network for Multi-Task\nLearning (MSNF-MTCL) to predict 5 important students' retention risks: future\ndropout, next semester dropout, type of dropout, duration of dropout and cause\nof dropout. First, we develop a general purpose multi-modal neural fusion\nnetwork model MSNF for learning students' academic information representation\nby fusing spatial and temporal unstructured advising notes with spatiotemporal\nstructured data. MSNF combines a Bidirectional Encoder Representations from\nTransformers (BERT)-based document embedding framework to represent each\nadvising note, Long-Short Term Memory (LSTM) network to model temporal advising\nnote embeddings, LSTM network to model students' temporal performance variables\nand students' static demographics altogether. The final fused representation\nfrom MSNF has been utilized on a Multi-Task Cascade Learning (MTCL) model\ntowards building MSNF-MTCL for predicting 5 student retention risks. We\nevaluate MSNFMTCL on a large educational database consists of 36,445 college\nstudents over 18 years period of time that provides promising performances\ncomparing with the nearest state-of-art models. Additionally, we test the\nfairness of such model given the existence of biases.", "published": "2021-09-11 04:06:03", "link": "http://arxiv.org/abs/2109.05178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking Questions Like Educational Experts: Automatically Generating\n  Question-Answer Pairs on Real-World Examination Data", "abstract": "Generating high quality question-answer pairs is a hard but meaningful task.\nAlthough previous works have achieved great results on answer-aware question\ngeneration, it is difficult to apply them into practical application in the\neducation field. This paper for the first time addresses the question-answer\npair generation task on the real-world examination data, and proposes a new\nunified framework on RACE. To capture the important information of the input\npassage we first automatically generate(rather than extracting) keyphrases,\nthus this task is reduced to keyphrase-question-answer triplet joint\ngeneration. Accordingly, we propose a multi-agent communication model to\ngenerate and optimize the question and keyphrases iteratively, and then apply\nthe generated question and keyphrases to guide the generation of answers. To\nestablish a solid benchmark, we build our model on the strong generative\npre-training model. Experimental results show that our model makes great\nbreakthroughs in the question-answer pair generation task. Moreover, we make a\ncomprehensive analysis on our model, suggesting new directions for this\nchallenging task.", "published": "2021-09-11 04:10:57", "link": "http://arxiv.org/abs/2109.05179v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker-Oriented Latent Structures for Dialogue-Based Relation\n  Extraction", "abstract": "Dialogue-based relation extraction (DiaRE) aims to detect the structural\ninformation from unstructured utterances in dialogues. Existing relation\nextraction models may be unsatisfactory under such a conversational setting,\ndue to the entangled logic and information sparsity issues in utterances\ninvolving multiple speakers. To this end, we introduce SOLS, a novel model\nwhich can explicitly induce speaker-oriented latent structures for better\nDiaRE. Specifically, we learn latent structures to capture the relationships\namong tokens beyond the utterance boundaries, alleviating the entangled logic\nissue. During the learning process, our speaker-specific regularization method\nprogressively highlights speaker-related key clues and erases the irrelevant\nones, alleviating the information sparsity issue. Experiments on three public\ndatasets demonstrate the effectiveness of our proposed approach.", "published": "2021-09-11 04:24:51", "link": "http://arxiv.org/abs/2109.05182v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Total Recall: a Customized Continual Learning Method for Neural Semantic\n  Parsers", "abstract": "This paper investigates continual learning for semantic parsing. In this\nsetting, a neural semantic parser learns tasks sequentially without accessing\nfull training data from previous tasks. Direct application of the SOTA\ncontinual learning algorithms to this problem fails to achieve comparable\nperformance with re-training models with all seen tasks because they have not\nconsidered the special properties of structured outputs yielded by semantic\nparsers. Therefore, we propose TotalRecall, a continual learning method\ndesigned for neural semantic parsers from two aspects: i) a sampling method for\nmemory replay that diversifies logical form templates and balances\ndistributions of parse actions in a memory; ii) a two-stage training method\nthat significantly improves generalization capability of the parsers across\ntasks. We conduct extensive experiments to study the research problems involved\nin continual semantic parsing and demonstrate that a neural semantic parser\ntrained with TotalRecall achieves superior performance than the one trained\ndirectly with the SOTA continual learning algorithms and achieve a 3-6 times\nspeedup compared to re-training from scratch. Code and datasets are available\nat: https://github.com/zhuang-li/cl_nsp.", "published": "2021-09-11 04:33:28", "link": "http://arxiv.org/abs/2109.05186v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncovering Main Causalities for Long-tailed Information Extraction", "abstract": "Information Extraction (IE) aims to extract structural information from\nunstructured texts. In practice, long-tailed distributions caused by the\nselection bias of a dataset, may lead to incorrect correlations, also known as\nspurious correlations, between entities and labels in the conventional\nlikelihood models. This motivates us to propose counterfactual IE (CFIE), a\nnovel framework that aims to uncover the main causalities behind data in the\nview of causal inference. Specifically, 1) we first introduce a unified\nstructural causal model (SCM) for various IE tasks, describing the\nrelationships among variables; 2) with our SCM, we then generate\ncounterfactuals based on an explicit language structure to better calculate the\ndirect causal effect during the inference stage; 3) we further propose a novel\ndebiasing approach to yield more robust predictions. Experiments on three IE\ntasks across five public datasets show the effectiveness of our CFIE model in\nmitigating the spurious correlation issues.", "published": "2021-09-11 08:08:24", "link": "http://arxiv.org/abs/2109.05213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Evaluation of Cross-document Coreference Resolution Models Using\n  Datasets with Diverse Annotation Schemes", "abstract": "Established cross-document coreference resolution (CDCR) datasets contain\nevent-centric coreference chains of events and entities with identity\nrelations. These datasets establish strict definitions of the coreference\nrelations across related tests but typically ignore anaphora with more vague\ncontext-dependent loose coreference relations. In this paper, we qualitatively\nand quantitatively compare the annotation schemes of ECB+, a CDCR dataset with\nidentity coreference relations, and NewsWCL50, a CDCR dataset with a mix of\nloose context-dependent and strict coreference relations. We propose a phrasing\ndiversity metric (PD) that encounters for the diversity of full phrases unlike\nthe previously proposed metrics and allows to evaluate lexical diversity of the\nCDCR datasets in a higher precision. The analysis shows that coreference chains\nof NewsWCL50 are more lexically diverse than those of ECB+ but annotating of\nNewsWCL50 leads to the lower inter-coder reliability. We discuss the different\ntasks that both CDCR datasets create for the CDCR models, i.e., lexical\ndisambiguation and lexical diversity. Finally, to ensure generalizability of\nthe CDCR models, we propose a direction for CDCR evaluation that combines CDCR\ndatasets with multiple annotation schemes that focus of various properties of\nthe coreference chains.", "published": "2021-09-11 10:33:17", "link": "http://arxiv.org/abs/2109.05250v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XCoref: Cross-document Coreference Resolution in the Wild", "abstract": "Datasets and methods for cross-document coreference resolution (CDCR) focus\non events or entities with strict coreference relations. They lack, however,\nannotating and resolving coreference mentions with more abstract or loose\nrelations that may occur when news articles report about controversial and\npolarized events. Bridging and loose coreference relations trigger associations\nthat may lead to exposing news readers to bias by word choice and labeling. For\nexample, coreferential mentions of \"direct talks between U.S. President Donald\nTrump and Kim\" such as \"an extraordinary meeting following months of heated\nrhetoric\" or \"great chance to solve a world problem\" form a more positive\nperception of this event. A step towards bringing awareness of bias by word\nchoice and labeling is the reliable resolution of coreferences with high\nlexical diversity. We propose an unsupervised method named XCoref, which is a\nCDCR method that capably resolves not only previously prevalent entities, such\nas persons, e.g., \"Donald Trump,\" but also abstractly defined concepts, such as\ngroups of persons, \"caravan of immigrants,\" events and actions, e.g., \"marching\nto the U.S. border.\" In an extensive evaluation, we compare the proposed XCoref\nto a state-of-the-art CDCR method and a previous method TCA that resolves such\ncomplex coreference relations and find that XCoref outperforms these methods.\nOutperforming an established CDCR model shows that the new CDCR models need to\nbe evaluated on semantically complex mentions with more loose coreference\nrelations to indicate their applicability of models to resolve mentions in the\n\"wild\" of political news articles.", "published": "2021-09-11 10:41:09", "link": "http://arxiv.org/abs/2109.05252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Translation via Grafting Pre-trained Language Models", "abstract": "Can pre-trained BERT for one language and GPT for another be glued together\nto translate texts? Self-supervised training using only monolingual data has\nled to the success of pre-trained (masked) language models in many NLP tasks.\nHowever, directly connecting BERT as an encoder and GPT as a decoder can be\nchallenging in machine translation, for GPT-like models lack a cross-attention\ncomponent that is needed in seq2seq decoders. In this paper, we propose\nGraformer to graft separately pre-trained (masked) language models for machine\ntranslation. With monolingual data for pre-training and parallel data for\ngrafting training, we maximally take advantage of the usage of both types of\ndata. Experiments on 60 directions show that our method achieves average\nimprovements of 5.8 BLEU in x2en and 2.9 BLEU in en2x directions comparing with\nthe multilingual Transformer of the same size.", "published": "2021-09-11 10:57:45", "link": "http://arxiv.org/abs/2109.05256v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's in a Name? Answer Equivalence For Open-Domain Question Answering", "abstract": "A flaw in QA evaluation is that annotations often only provide one gold\nanswer. Thus, model predictions semantically equivalent to the answer but\nsuperficially different are considered incorrect. This work explores mining\nalias entities from knowledge bases and using them as additional gold answers\n(i.e., equivalent answers). We incorporate answers for two settings: evaluation\nwith additional answers and model training with equivalent answers. We analyse\nthree QA benchmarks: Natural Questions, TriviaQA, and SQuAD. Answer expansion\nincreases the exact match score on all datasets for evaluation, while\nincorporating it helps model training over real-world datasets. We ensure the\nadditional answers are valid through a human post hoc evaluation.", "published": "2021-09-11 14:26:25", "link": "http://arxiv.org/abs/2109.05289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Looking for Confirmations: An Effective and Human-Like Visual Dialogue\n  Strategy", "abstract": "Generating goal-oriented questions in Visual Dialogue tasks is a challenging\nand long-standing problem. State-Of-The-Art systems are shown to generate\nquestions that, although grammatically correct, often lack an effective\nstrategy and sound unnatural to humans. Inspired by the cognitive literature on\ninformation search and cross-situational word learning, we design Confirm-it, a\nmodel based on a beam search re-ranking algorithm that guides an effective\ngoal-oriented strategy by asking questions that confirm the model's conjecture\nabout the referent. We take the GuessWhat?! game as a case-study. We show that\ndialogues generated by Confirm-it are more natural and effective than beam\nsearch decoding without re-ranking.", "published": "2021-09-11 16:28:58", "link": "http://arxiv.org/abs/2109.05312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To Protect and To Serve? Analyzing Entity-Centric Framing of Police\n  Violence", "abstract": "Framing has significant but subtle effects on public opinion and policy. We\npropose an NLP framework to measure entity-centric frames. We use it to\nunderstand media coverage on police violence in the United States in a new\nPolice Violence Frames Corpus of 82k news articles spanning 7k police killings.\nOur work uncovers more than a dozen framing devices and reveals significant\ndifferences in the way liberal and conservative news sources frame both the\nissue of police violence and the entities involved. Conservative sources\nemphasize when the victim is armed or attacking an officer and are more likely\nto mention the victim's criminal record. Liberal sources focus more on the\nunderlying systemic injustice, highlighting the victim's race and that they\nwere unarmed. We discover temporary spikes in these injustice frames near\nhigh-profile shooting events, and finally, we show protest volume correlates\nwith and precedes media framing decisions.", "published": "2021-09-11 17:37:21", "link": "http://arxiv.org/abs/2109.05325v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HYDRA -- Hyper Dependency Representation Attentions", "abstract": "Attention is all we need as long as we have enough data. Even so, it is\nsometimes not easy to determine how much data is enough while the models are\nbecoming larger and larger. In this paper, we propose HYDRA heads, lightweight\npretrained linguistic self-attention heads to inject knowledge into transformer\nmodels without pretraining them again. Our approach is a balanced paradigm\nbetween leaving the models to learn unsupervised and forcing them to conform to\nlinguistic knowledge rigidly as suggested in previous studies. Our experiment\nproves that the approach is not only the boost performance of the model but\nalso lightweight and architecture friendly. We empirically verify our framework\non benchmark datasets to show the contribution of linguistic knowledge to a\ntransformer model. This is a promising result for a new approach to\ntransferring knowledge from linguistic resources into transformer-based models.", "published": "2021-09-11 19:17:34", "link": "http://arxiv.org/abs/2109.05349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Language Description: Low-shot Named Entity Recognition\n  via Decomposed Framework", "abstract": "In this work, we study the problem of named entity recognition (NER) in a low\nresource scenario, focusing on few-shot and zero-shot settings. Built upon\nlarge-scale pre-trained language models, we propose a novel NER framework,\nnamely SpanNER, which learns from natural language supervision and enables the\nidentification of never-seen entity classes without using in-domain labeled\ndata. We perform extensive experiments on 5 benchmark datasets and evaluate the\nproposed method in the few-shot learning, domain transfer and zero-shot\nlearning settings. The experimental results show that the proposed method can\nbring 10%, 23% and 26% improvements in average over the best baselines in\nfew-shot learning, domain transfer and zero-shot learning settings\nrespectively.", "published": "2021-09-11 19:52:09", "link": "http://arxiv.org/abs/2109.05357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Premise Generation with Discourse-aware Commonsense Knowledge\n  Models", "abstract": "Enthymemes are defined as arguments where a premise or conclusion is left\nimplicit. We tackle the task of generating the implicit premise in an\nenthymeme, which requires not only an understanding of the stated conclusion\nand premise but also additional inferences that could depend on commonsense\nknowledge. The largest available dataset for enthymemes (Habernal et al., 2018)\nconsists of 1.7k samples, which is not large enough to train a neural text\ngeneration model. To address this issue, we take advantage of a similar task\nand dataset: Abductive reasoning in narrative text (Bhagavatula et al., 2020).\nHowever, we show that simply using a state-of-the-art seq2seq model fine-tuned\non this data might not generate meaningful implicit premises associated with\nthe given enthymemes. We demonstrate that encoding discourse-aware commonsense\nduring fine-tuning improves the quality of the generated implicit premises and\noutperforms all other baselines both in automatic and human evaluations on\nthree different datasets.", "published": "2021-09-11 19:54:39", "link": "http://arxiv.org/abs/2109.05358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COMBO: State-of-the-Art Morphosyntactic Analysis", "abstract": "We introduce COMBO - a fully neural NLP system for accurate part-of-speech\ntagging, morphological analysis, lemmatisation, and (enhanced) dependency\nparsing. It predicts categorical morphosyntactic features whilst also exposes\ntheir vector representations, extracted from hidden layers. COMBO is an easy to\ninstall Python package with automatically downloadable pre-trained models for\nover 40 languages. It maintains a balance between efficiency and quality. As it\nis an end-to-end system and its modules are jointly trained, its training is\ncompetitively fast. As its models are optimised for accuracy, they achieve\noften better prediction quality than SOTA. The COMBO library is available at:\nhttps://gitlab.clarin-pl.eu/syntactic-tools/combo.", "published": "2021-09-11 20:00:20", "link": "http://arxiv.org/abs/2109.05361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modular Self-Supervision for Document-Level Relation Extraction", "abstract": "Extracting relations across large text spans has been relatively\nunderexplored in NLP, but it is particularly important for high-value domains\nsuch as biomedicine, where obtaining high recall of the latest findings is\ncrucial for practical applications. Compared to conventional information\nextraction confined to short text spans, document-level relation extraction\nfaces additional challenges in both inference and learning. Given longer text\nspans, state-of-the-art neural architectures are less effective and\ntask-specific self-supervision such as distant supervision becomes very noisy.\nIn this paper, we propose decomposing document-level relation extraction into\nrelation detection and argument resolution, taking inspiration from Davidsonian\nsemantics. This enables us to incorporate explicit discourse modeling and\nleverage modular self-supervision for each sub-problem, which is less\nnoise-prone and can be further refined end-to-end via variational EM. We\nconduct a thorough evaluation in biomedical machine reading for precision\noncology, where cross-paragraph relation mentions are prevalent. Our method\noutperforms prior state of the art, such as multi-scale learning and graph\nneural networks, by over 20 absolute F1 points. The gain is particularly\npronounced among the most challenging relation instances whose arguments never\nco-occur in a paragraph.", "published": "2021-09-11 20:09:18", "link": "http://arxiv.org/abs/2109.05362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Impact of Positional Encodings on Multilingual Compression", "abstract": "In order to preserve word-order information in a non-autoregressive setting,\ntransformer architectures tend to include positional knowledge, by (for\ninstance) adding positional encodings to token embeddings. Several\nmodifications have been proposed over the sinusoidal positional encodings used\nin the original transformer architecture; these include, for instance,\nseparating position encodings and token embeddings, or directly modifying\nattention weights based on the distance between word pairs. We first show that\nsurprisingly, while these modifications tend to improve monolingual language\nmodels, none of them result in better multilingual language models. We then\nanswer why that is: Sinusoidal encodings were explicitly designed to facilitate\ncompositionality by allowing linear projections over arbitrary time steps.\nHigher variances in multilingual training distributions requires higher\ncompression, in which case, compositionality becomes indispensable. Learned\nabsolute positional encodings (e.g., in mBERT) tend to approximate sinusoidal\nembeddings in multilingual settings, but more complex positional encoding\narchitectures lack the inductive bias to effectively learn compositionality and\ncross-lingual alignment. In other words, while sinusoidal positional encodings\nwere originally designed for monolingual applications, they are particularly\nuseful in multilingual language models.", "published": "2021-09-11 23:22:50", "link": "http://arxiv.org/abs/2109.05388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their\n  Targets", "abstract": "Internet memes have become powerful means to transmit political,\npsychological, and socio-cultural ideas. Although memes are typically humorous,\nrecent days have witnessed an escalation of harmful memes used for trolling,\ncyberbullying, and abuse. Detecting such memes is challenging as they can be\nhighly satirical and cryptic. Moreover, while previous work has focused on\nspecific aspects of memes such as hate speech and propaganda, there has been\nlittle work on harm in general. Here, we aim to bridge this gap. We focus on\ntwo tasks: (i)detecting harmful memes, and (ii)identifying the social entities\nthey target. We further extend a recently released HarMeme dataset, which\ncovered COVID-19, with additional memes and a new topic: US politics. To solve\nthese tasks, we propose MOMENTA (MultimOdal framework for detecting harmful\nMemEs aNd Their tArgets), a novel multimodal deep neural network that uses\nglobal and local perspectives to detect harmful memes. MOMENTA systematically\nanalyzes the local and the global perspective of the input meme (in both\nmodalities) and relates it to the background context. MOMENTA is interpretable\nand generalizable, and our experiments show that it outperforms several strong\nrivaling approaches.", "published": "2021-09-11 04:29:32", "link": "http://arxiv.org/abs/2109.05184v2", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "TopicRefine: Joint Topic Prediction and Dialogue Response Generation for\n  Multi-turn End-to-End Dialogue System", "abstract": "A multi-turn dialogue always follows a specific topic thread, and topic shift\nat the discourse level occurs naturally as the conversation progresses,\nnecessitating the model's ability to capture different topics and generate\ntopic-aware responses. Previous research has either predicted the topic first\nand then generated the relevant response, or simply applied the attention\nmechanism to all topics, ignoring the joint distribution of the topic\nprediction and response generation models and resulting in uncontrollable and\nunrelated responses. In this paper, we propose a joint framework with a topic\nrefinement mechanism to learn these two tasks simultaneously. Specifically, we\ndesign a three-pass iteration mechanism to generate coarse response first, then\npredict corresponding topics, and finally generate refined response conditioned\non predicted topics. Moreover, we utilize GPT2DoubleHeads and BERT for the\ntopic prediction task respectively, aiming to investigate the effects of joint\nlearning and the understanding ability of GPT model. Experimental results\ndemonstrate that our proposed framework achieves new state-of-the-art\nperformance at response generation task and the great potential understanding\ncapability of GPT model.", "published": "2021-09-11 04:43:07", "link": "http://arxiv.org/abs/2109.05187v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PoKE: A Prompt-based Knowledge Eliciting Approach for Event Argument\n  Extraction", "abstract": "Eliciting knowledge from pre-trained language models via prompt-based\nlearning has shown great potential in many natural language processing tasks.\nWhereas, the applications for more complex tasks such as event extraction are\nless studied since the design of prompt is not straightforward for the\nstructured event containing various triggers and arguments. % Meanwhile,\ncurrent conditional generation methods employ large encoder-decoder models,\nwhich are costly to train and serve. In this paper, we present a novel\nprompt-based approach, which elicits both the independent and joint knowledge\nabout different events for event argument extraction. The experimental results\non the benchmark ACE2005 dataset show the great advantages of our proposed\napproach. In particular, our approach is superior to the recent advanced\nmethods in both fully-supervised and low-resource scenarios.", "published": "2021-09-11 05:16:33", "link": "http://arxiv.org/abs/2109.05190v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empirical Analysis of Training Strategies of Transformer-based Japanese\n  Chit-chat Systems", "abstract": "In recent years, several high-performance conversational systems have been\nproposed based on the Transformer encoder-decoder model. Although previous\nstudies analyzed the effects of the model parameters and the decoding method on\nsubjective dialogue evaluations with overall metrics, they did not analyze how\nthe differences of fine-tuning datasets affect on user's detailed impression.\nIn addition, the Transformer-based approach has only been verified for English,\nnot for such languages with large inter-language distances as Japanese. In this\nstudy, we develop large-scale Transformer-based Japanese dialogue models and\nJapanese chit-chat datasets to examine the effectiveness of the\nTransformer-based approach for building chit-chat dialogue systems. We\nevaluated and analyzed the impressions of human dialogues in different\nfine-tuning datasets, model parameters, and the use of additional information.", "published": "2021-09-11 08:24:23", "link": "http://arxiv.org/abs/2109.05217v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with\n  Incomplete Annotations", "abstract": "State-of-the-art Named Entity Recognition(NER) models rely heavily on large\namountsof fully annotated training data. However, ac-cessible data are often\nincompletely annotatedsince the annotators usually lack comprehen-sive\nknowledge in the target domain. Normallythe unannotated tokens are regarded as\nnon-entities by default, while we underline thatthese tokens could either be\nnon-entities orpart of any entity. Here, we study NER mod-eling with incomplete\nannotated data whereonly a fraction of the named entities are la-beled, and the\nunlabeled tokens are equiva-lently multi-labeled by every possible label.Taking\nmulti-labeled tokens into account, thenumerous possible paths can distract the\ntrain-ing model from the gold path (ground truthlabel sequence), and thus\nhinders the learn-ing ability. In this paper, we propose AdaK-NER, named the\nadaptive top-Kapproach, tohelp the model focus on a smaller feasible re-gion\nwhere the gold path is more likely to belocated. We demonstrate the superiority\nofour approach through extensive experimentson both English and Chinese\ndatasets, aver-agely improving 2% in F-score on the CoNLL-2003 and over 10% on\ntwo Chinese datasetscompared with the prior state-of-the-art works.", "published": "2021-09-11 09:30:47", "link": "http://arxiv.org/abs/2109.05233v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prior Omission of Dissimilar Source Domain(s) for Cost-Effective\n  Few-Shot Learning", "abstract": "Few-shot slot tagging is an emerging research topic in the field of Natural\nLanguage Understanding (NLU). With sufficient annotated data from source\ndomains, the key challenge is how to train and adapt the model to another\ntarget domain which only has few labels. Conventional few-shot approaches use\nall the data from the source domains without considering inter-domain relations\nand implicitly assume each sample in the domain contributes equally. However,\nour experiments show that the data distribution bias among different domains\nwill significantly affect the adaption performance. Moreover, transferring\nknowledge from dissimilar domains will even introduce some extra noises so that\naffect the performance of models. To tackle this problem, we propose an\neffective similarity-based method to select data from the source domains. In\naddition, we propose a Shared-Private Network (SP-Net) for the few-shot slot\ntagging task. The words from the same class would have some shared features. We\nextract those shared features from the limited annotated data on the target\ndomain and merge them together as the label embedding to help us predict other\nunlabelled data on the target domain. The experiment shows that our method\noutperforms the state-of-the-art approaches with fewer source data. The result\nalso proves that some training data from dissimilar sources are redundant and\neven negative for the adaption.", "published": "2021-09-11 09:30:59", "link": "http://arxiv.org/abs/2109.05234v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Universal Simultaneous Machine Translation with Mixture-of-Experts\n  Wait-k Policy", "abstract": "Simultaneous machine translation (SiMT) generates translation before reading\nthe entire source sentence and hence it has to trade off between translation\nquality and latency. To fulfill the requirements of different translation\nquality and latency in practical applications, the previous methods usually\nneed to train multiple SiMT models for different latency levels, resulting in\nlarge computational costs. In this paper, we propose a universal SiMT model\nwith Mixture-of-Experts Wait-k Policy to achieve the best translation quality\nunder arbitrary latency with only one trained model. Specifically, our method\nemploys multi-head attention to accomplish the mixture of experts where each\nhead is treated as a wait-k expert with its own waiting words number, and given\na test latency and source inputs, the weights of the experts are accordingly\nadjusted to produce the best translation. Experiments on three datasets show\nthat our method outperforms all the strong baselines under different latency,\nincluding the state-of-the-art adaptive policy.", "published": "2021-09-11 09:43:15", "link": "http://arxiv.org/abs/2109.05238v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Concentrated Cross-Attention for Neural Machine Translation\n  with Gaussian Mixture Model", "abstract": "Cross-attention is an important component of neural machine translation\n(NMT), which is always realized by dot-product attention in previous methods.\nHowever, dot-product attention only considers the pair-wise correlation between\nwords, resulting in dispersion when dealing with long sentences and neglect of\nsource neighboring relationships. Inspired by linguistics, the above issues are\ncaused by ignoring a type of cross-attention, called concentrated attention,\nwhich focuses on several central words and then spreads around them. In this\nwork, we apply Gaussian Mixture Model (GMM) to model the concentrated attention\nin cross-attention. Experiments and analyses we conducted on three datasets\nshow that the proposed method outperforms the baseline and has significant\nimprovement on alignment quality, N-gram accuracy, and long sentence\ntranslation.", "published": "2021-09-11 10:01:24", "link": "http://arxiv.org/abs/2109.05244v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Latent Hatred: A Benchmark for Understanding Implicit Hate Speech", "abstract": "Hate speech has grown significantly on social media, causing serious\nconsequences for victims of all demographics. Despite much attention being paid\nto characterize and detect discriminatory speech, most work has focused on\nexplicit or overt hate speech, failing to address a more pervasive form based\non coded or indirect language. To fill this gap, this work introduces a\ntheoretically-justified taxonomy of implicit hate speech and a benchmark corpus\nwith fine-grained labels for each message and its implication. We present\nsystematic analyses of our dataset using contemporary baselines to detect and\nexplain implicit hate speech, and we discuss key features that challenge\nexisting models. This dataset will continue to serve as a useful benchmark for\nunderstanding this multifaceted issue.", "published": "2021-09-11 16:52:56", "link": "http://arxiv.org/abs/2109.05322v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "An Objective Metric for Explainable AI: How and Why to Estimate the\n  Degree of Explainability", "abstract": "Explainable AI was born as a pathway to allow humans to explore and\nunderstand the inner working of complex systems. However, establishing what is\nan explanation and objectively evaluating explainability are not trivial tasks.\nThis paper presents a new model-agnostic metric to measure the Degree of\nExplainability of information in an objective way. We exploit a specific\ntheoretical model from Ordinary Language Philosophy called the Achinstein's\nTheory of Explanations, implemented with an algorithm relying on deep language\nmodels for knowledge graph extraction and information retrieval. To understand\nwhether this metric can measure explainability, we devised a few experiments\nand user studies involving more than 190 participants, evaluating two realistic\nsystems for healthcare and finance using famous AI technology, including\nArtificial Neural Networks and TreeSHAP. The results we obtained are\nstatistically significant (with P values lower than .01), suggesting that our\nproposed metric for measuring the Degree of Explainability is robust in several\nscenarios, and it aligns with concrete expectations.", "published": "2021-09-11 17:44:13", "link": "http://arxiv.org/abs/2109.05327v5", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Survey on Multi-modal Summarization", "abstract": "The new era of technology has brought us to the point where it is convenient\nfor people to share their opinions over an abundance of platforms. These\nplatforms have a provision for the users to express themselves in multiple\nforms of representations, including text, images, videos, and audio. This,\nhowever, makes it difficult for users to obtain all the key information about a\ntopic, making the task of automatic multi-modal summarization (MMS) essential.\nIn this paper, we present a comprehensive survey of the existing research in\nthe area of MMS, covering various modalities like text, image, audio, and\nvideo. Apart from highlighting the different evaluation metrics and datasets\nused for the MMS task, our work also discusses the current challenges and\nfuture directions in this field.", "published": "2021-09-11 06:39:54", "link": "http://arxiv.org/abs/2109.05199v2", "categories": ["cs.CL", "cs.MM", "cs.NE"], "primary_category": "cs.CL"}
{"title": "COSMic: A Coherence-Aware Generation Metric for Image Descriptions", "abstract": "Developers of text generation models rely on automated evaluation metrics as\na stand-in for slow and expensive manual evaluations. However, image captioning\nmetrics have struggled to give accurate learned estimates of the semantic and\npragmatic success of output text. We address this weakness by introducing the\nfirst discourse-aware learned generation metric for evaluating image\ndescriptions. Our approach is inspired by computational theories of discourse\nfor capturing information goals using coherence. We present a dataset of\nimage$\\unicode{x2013}$description pairs annotated with coherence relations. We\nthen train a coherence-aware metric on a subset of the Conceptual Captions\ndataset and measure its effectiveness$\\unicode{x2014}$its ability to predict\nhuman ratings of output captions$\\unicode{x2014}$on a test set composed of\nout-of-domain images. We demonstrate a higher Kendall Correlation Coefficient\nfor our proposed metric with the human judgments for the results of a number of\nstate-of-the-art coherence-aware caption generation models when compared to\nseveral other metrics including recently proposed learned metrics such as\nBLEURT and BERTScore.", "published": "2021-09-11 13:43:36", "link": "http://arxiv.org/abs/2109.05281v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bayesian Topic Regression for Causal Inference", "abstract": "Causal inference using observational text data is becoming increasingly\npopular in many research areas. This paper presents the Bayesian Topic\nRegression (BTR) model that uses both text and numerical information to model\nan outcome variable. It allows estimation of both discrete and continuous\ntreatment effects. Furthermore, it allows for the inclusion of additional\nnumerical confounding factors next to text data. To this end, we combine a\nsupervised Bayesian topic model with a Bayesian regression framework and\nperform supervised representation learning for the text features jointly with\nthe regression parameter training, respecting the Frisch-Waugh-Lovell theorem.\nOur paper makes two main contributions. First, we provide a regression\nframework that allows causal inference in settings when both text and numerical\nconfounders are of relevance. We show with synthetic and semi-synthetic\ndatasets that our joint approach recovers ground truth with lower bias than any\nbenchmark model, when text and numerical features are correlated. Second,\nexperiments on two real-world datasets demonstrate that a joint and supervised\nlearning strategy also yields superior prediction results compared to\nstrategies that estimate regression weights for text and non-text features\nseparately, being even competitive with more complex deep neural networks.", "published": "2021-09-11 16:40:43", "link": "http://arxiv.org/abs/2109.05317v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Scaling and Acceleration of Three-dimensional Structure Determination\n  for Single-Particle Imaging Experiments with SpiniFEL", "abstract": "The Linac Coherent Light Source (LCLS) is an X- ray free electron laser\n(XFEL) facility enabling the study of the structure and dynamics of single\nmacromolecules. A major upgrade will bring the repetition rate of the X-ray\nsource from 120 to 1 million pulses per second. Exascale high performance\ncomputing (HPC) capabilities will be required to process the corresponding data\nrates. We present SpiniFEL, an application used for structure determination of\nproteins from single-particle imaging (SPI) experiments. An emerging technique\nfor imaging individual proteins and other large molecular complexes by\noutrunning radiation damage, SPI breaks free from the need for crystallization\n(which is difficult for some proteins) and allows for imaging molecular\ndynamics at near ambient conditions. SpiniFEL is being developed to run on\nsupercomputers in near real-time while an experiment is taking place, so that\nthe feedback about the data can guide the data collection strategy. We describe\nhere how we reformulated the mathematical framework for parallelizable\nimplementation and accelerated the most compute intensive parts of the\napplication. We also describe the use of Pygion, a Python interface for the\nLegion task-based programming model and compare to our existing MPI+GPU\nimplementation.", "published": "2021-09-11 18:49:54", "link": "http://arxiv.org/abs/2109.05339v1", "categories": ["physics.comp-ph", "cs.CE", "cs.CL", "physics.bio-ph"], "primary_category": "physics.comp-ph"}
{"title": "Sequential Modelling with Applications to Music Recommendation,\n  Fact-Checking, and Speed Reading", "abstract": "Sequential modelling entails making sense of sequential data, which naturally\noccurs in a wide array of domains. One example is systems that interact with\nusers, log user actions and behaviour, and make recommendations of items of\npotential interest to users on the basis of their previous interactions. In\nsuch cases, the sequential order of user interactions is often indicative of\nwhat the user is interested in next. Similarly, for systems that automatically\ninfer the semantics of text, capturing the sequential order of words in a\nsentence is essential, as even a slight re-ordering could significantly alter\nits original meaning. This thesis makes methodological contributions and new\ninvestigations of sequential modelling for the specific application areas of\nsystems that recommend music tracks to listeners and systems that process text\nsemantics in order to automatically fact-check claims, or \"speed read\" text for\nefficient further classification. (Rest of abstract omitted due to arXiv\nabstract limit)", "published": "2021-09-11 08:05:48", "link": "http://arxiv.org/abs/2109.06736v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Clinical Trial Information Extraction with BERT", "abstract": "Natural language processing (NLP) of clinical trial documents can be useful\nin new trial design. Here we identify entity types relevant to clinical trial\ndesign and propose a framework called CT-BERT for information extraction from\nclinical trial text. We trained named entity recognition (NER) models to\nextract eligibility criteria entities by fine-tuning a set of pre-trained BERT\nmodels. We then compared the performance of CT-BERT with recent baseline\nmethods including attention-based BiLSTM and Criteria2Query. The results\ndemonstrate the superiority of CT-BERT in clinical trial NLP.", "published": "2021-09-11 17:15:10", "link": "http://arxiv.org/abs/2110.10027v1", "categories": ["q-bio.QM", "cs.CL", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Incorporating Real-world Noisy Speech in Neural-network-based Speech\n  Enhancement Systems", "abstract": "Supervised speech enhancement relies on parallel databases of degraded speech\nsignals and their clean reference signals during training. This setting\nprohibits the use of real-world degraded speech data that may better represent\nthe scenarios where such systems are used. In this paper, we explore methods\nthat enable supervised speech enhancement systems to train on real-world\ndegraded speech data. Specifically, we propose a semi-supervised approach for\nspeech enhancement in which we first train a modified vector-quantized\nvariational autoencoder that solves a source separation task. We then use this\ntrained autoencoder to further train an enhancement network using real-world\nnoisy speech data by computing a triplet-based unsupervised loss function.\nExperiments show promising results for incorporating real-world data in\ntraining speech enhancement systems.", "published": "2021-09-11 03:35:46", "link": "http://arxiv.org/abs/2109.05172v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "In-filter Computing For Designing Ultra-light Acoustic Pattern\n  Recognizers", "abstract": "We present a novel in-filter computing framework that can be used for\ndesigning ultra-light acoustic classifiers for use in smart internet-of-things\n(IoTs). Unlike a conventional acoustic pattern recognizer, where the feature\nextraction and classification are designed independently, the proposed\narchitecture integrates the convolution and nonlinear filtering operations\ndirectly into the kernels of a Support Vector Machine (SVM). The result of this\nintegration is a template-based SVM whose memory and computational footprint\n(training and inference) is light enough to be implemented on an FPGA-based IoT\nplatform. While the proposed in-filter computing framework is general enough,\nin this paper, we demonstrate this concept using a Cascade of Asymmetric\nResonator with Inner Hair Cells (CAR-IHC) based acoustic feature extraction\nalgorithm. The complete system has been optimized using time-multiplexing and\nparallel-pipeline techniques for a Xilinx Spartan 7 series Field Programmable\nGate Array (FPGA). We show that the system can achieve robust classification\nperformance on benchmark sound recognition tasks using only ~ 1.5k Look-Up\nTables (LUTs) and ~ 2.8k Flip-Flops (FFs), a significant improvement over other\napproaches.", "published": "2021-09-11 08:16:53", "link": "http://arxiv.org/abs/2109.06171v1", "categories": ["eess.AS", "cs.LG", "cs.NE", "cs.SD", "cs.SY", "eess.SY"], "primary_category": "eess.AS"}
