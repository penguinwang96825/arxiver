{"title": "Computational analyses of linguistic features with schizophrenic and\n  autistic traits along with formal thought disorders", "abstract": "[See full abstract in the pdf] Formal Thought Disorder (FTD), which is a\ngroup of symptoms in cognition that affects language and thought, can be\nobserved through language. FTD is seen across such developmental or psychiatric\ndisorders as Autism Spectrum Disorder (ASD) or Schizophrenia, and its related\nSchizotypal Personality Disorder (SPD). This paper collected a Japanese\naudio-report dataset with score labels related to ASD and SPD through a\ncrowd-sourcing service from the general population. We measured language\ncharacteristics with the 2nd edition of the Social Responsiveness Scale (SRS2)\nand the Schizotypal Personality Questionnaire (SPQ), including an odd speech\nsubscale from SPQ to quantify the FTD symptoms. We investigated the following\nfour research questions through machine-learning-based score predictions: (RQ1)\nHow are schizotypal and autistic measures correlated? (RQ2) What is the most\nsuitable task to elicit FTD symptoms? (RQ3) Does the length of speech affect\nthe elicitation of FTD symptoms? (RQ4) Which features are critical for\ncapturing FTD symptoms? We confirmed that an FTD-related subscale, odd speech,\nwas significantly correlated with both the total SPQ and SRS scores, although\nthey themselves were not correlated significantly. Our regression analysis\nindicated that longer speech about a negative memory elicited more FTD\nsymptoms. The ablation study confirmed the importance of function words and\nboth the abstract and temporal features for FTD-related odd speech estimation.\nIn contrast, content words were effective only in the SRS predictions, and\ncontent words were effective only in the SPQ predictions, a result that implies\nthe differences between SPD-like and ASD-like symptoms. Data and programs used\nin this paper can be found here:\nhttps://sites.google.com/view/sagatake/resource.", "published": "2023-10-14 05:05:11", "link": "http://arxiv.org/abs/2310.09494v1", "categories": ["cs.CL", "J.4; J.3; I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "DepNeCTI: Dependency-based Nested Compound Type Identification for\n  Sanskrit", "abstract": "Multi-component compounding is a prevalent phenomenon in Sanskrit, and\nunderstanding the implicit structure of a compound's components is crucial for\ndeciphering its meaning. Earlier approaches in Sanskrit have focused on binary\ncompounds and neglected the multi-component compound setting. This work\nintroduces the novel task of nested compound type identification (NeCTI), which\naims to identify nested spans of a multi-component compound and decode the\nimplicit semantic relations between them. To the best of our knowledge, this is\nthe first attempt in the field of lexical semantics to propose this task.\n  We present 2 newly annotated datasets including an out-of-domain dataset for\nthis task. We also benchmark these datasets by exploring the efficacy of the\nstandard problem formulations such as nested named entity recognition,\nconstituency parsing and seq2seq, etc. We present a novel framework named\nDepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the\nperformance of the best baseline with an average absolute improvement of 13.1\npoints F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement\nin inference efficiency. In line with the previous findings in the binary\nSanskrit compound identification task, context provides benefits for the NeCTI\ntask. The codebase and datasets are publicly available at:\nhttps://github.com/yaswanth-iitkgp/DepNeCTI", "published": "2023-10-14 06:11:53", "link": "http://arxiv.org/abs/2310.09501v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attentive Multi-Layer Perceptron for Non-autoregressive Generation", "abstract": "Autoregressive~(AR) generation almost dominates sequence generation for its\nefficacy. Recently, non-autoregressive~(NAR) generation gains increasing\npopularity for its efficiency and growing efficacy. However, its efficiency is\nstill bottlenecked by quadratic complexity in sequence lengths, which is\nprohibitive for scaling to long sequence generation and few works have been\ndone to mitigate this problem. In this paper, we propose a novel MLP variant,\n\\textbf{A}ttentive \\textbf{M}ulti-\\textbf{L}ayer \\textbf{P}erceptron~(AMLP), to\nproduce a generation model with linear time and space complexity. Different\nfrom classic MLP with static and learnable projection matrices, AMLP leverages\nadaptive projections computed from inputs in an attentive mode. The\nsample-aware adaptive projections enable communications among tokens in a\nsequence, and model the measurement between the query and key space.\nFurthermore, we marry AMLP with popular NAR models, deriving a highly efficient\nNAR-AMLP architecture with linear time and space complexity. Empirical results\nshow that such marriage architecture surpasses competitive efficient NAR\nmodels, by a significant margin on text-to-speech synthesis and machine\ntranslation. We also test AMLP's self- and cross-attention ability separately\nwith extensive ablation experiments, and find them comparable or even superior\nto the other efficient models. The efficiency analysis further shows that AMLP\nextremely reduces the memory cost against vanilla non-autoregressive models for\nlong sequences.", "published": "2023-10-14 06:44:24", "link": "http://arxiv.org/abs/2310.09512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a\n  Unidirectional Reward Model", "abstract": "While large language models have proven effective in a huge range of\ndownstream applications, they often generate text that is problematic or lacks\na desired attribute. In this paper, we introduce Reward-Augmented Decoding\n(RAD), a text generation procedure that uses a small unidirectional reward\nmodel to encourage a language model to generate text that has certain\nproperties. Specifically, RAD uses the reward model to score generations as\nthey are produced and rescales sampling probabilities to favor high-reward\ntokens. By using a unidirectional reward model, RAD can cache activations from\nprior generation steps to decrease computational overhead. Through experiments\non generating non-toxic and sentiment-controlled text, we demonstrate that RAD\nperforms best among methods that change only the generation procedure and\nmatches the performance of state-of-the-art methods that involve re-training\nthe language model. We further validate that RAD is effective on very large\nlanguage models while incurring a minimal computational overhead.", "published": "2023-10-14 07:19:47", "link": "http://arxiv.org/abs/2310.09520v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Model Comprehend Ancient Chinese? A Preliminary Test\n  on ACLUE", "abstract": "Large language models (LLMs) have showcased remarkable capabilities in\nunderstanding and generating language. However, their ability in comprehending\nancient languages, particularly ancient Chinese, remains largely unexplored. To\nbridge this gap, we present ACLUE, an evaluation benchmark designed to assess\nthe capability of language models in comprehending ancient Chinese. ACLUE\nconsists of 15 tasks cover a range of skills, spanning phonetic, lexical,\nsyntactic, semantic, inference and knowledge. Through the evaluation of eight\nstate-of-the-art LLMs, we observed a noticeable disparity in their performance\nbetween modern Chinese and ancient Chinese. Among the assessed models, ChatGLM2\ndemonstrates the most remarkable performance, achieving an average score of\n37.4%. We have made our code and data public available.", "published": "2023-10-14 10:06:39", "link": "http://arxiv.org/abs/2310.09550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Detoxifying Language Models via Toxification Reversal", "abstract": "Language model detoxification aims to minimize the risk of generating\noffensive or harmful content in pretrained language models (PLMs) for safer\ndeployment. Existing methods can be roughly categorized as finetuning-based and\ndecoding-based. However, the former is often resource-intensive, while the\nlatter relies on additional components and potentially compromises the\ngeneration fluency. In this paper, we propose a more lightweight approach that\nenables the PLM itself to achieve \"self-detoxification\". Our method is built\nupon the observation that prepending a negative steering prompt can effectively\ninduce PLMs to generate toxic content. At the same time, we are inspired by the\nrecent research in the interpretability field, which formulates the evolving\ncontextualized representations within the PLM as an information stream\nfacilitated by the attention layers. Drawing on this idea, we devise a method\nto identify the toxification direction from the normal generation process to\nthe one prompted with the negative prefix, and then steer the generation to the\nreversed direction by manipulating the information movement within the\nattention layers. Experimental results show that our approach, without any\nfine-tuning or extra components, can achieve comparable performance with\nstate-of-the-art methods.", "published": "2023-10-14 12:51:38", "link": "http://arxiv.org/abs/2310.09573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RethinkingTMSC: An Empirical Study for Target-Oriented Multimodal\n  Sentiment Classification", "abstract": "Recently, Target-oriented Multimodal Sentiment Classification (TMSC) has\ngained significant attention among scholars. However, current multimodal models\nhave reached a performance bottleneck. To investigate the causes of this\nproblem, we perform extensive empirical evaluation and in-depth analysis of the\ndatasets to answer the following questions: Q1: Are the modalities equally\nimportant for TMSC? Q2: Which multimodal fusion modules are more effective? Q3:\nDo existing datasets adequately support the research? Our experiments and\nanalyses reveal that the current TMSC systems primarily rely on the textual\nmodality, as most of targets' sentiments can be determined solely by text.\nConsequently, we point out several directions to work on for the TMSC task in\nterms of model design and dataset construction. The code and data can be found\nin https://github.com/Junjie-Ye/RethinkingTMSC.", "published": "2023-10-14 14:52:37", "link": "http://arxiv.org/abs/2310.09596v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Moral consensus and divergence in partisan language use", "abstract": "Polarization has increased substantially in political discourse, contributing\nto a widening partisan divide. In this paper, we analyzed large-scale,\nreal-world language use in Reddit communities (294,476,146 comments) and in\nnews outlets (6,749,781 articles) to uncover psychological dimensions along\nwhich partisan language is divided. Using word embedding models that captured\nsemantic associations based on co-occurrences of words in vast textual corpora,\nwe identified patterns of affective polarization present in natural political\ndiscourse. We then probed the semantic associations of words related to seven\npolitical topics (e.g., abortion, immigration) along the dimensions of morality\n(moral-to-immoral), threat (threatening-to-safe), and valence\n(pleasant-to-unpleasant). Across both Reddit communities and news outlets, we\nidentified a small but systematic divergence in the moral associations of words\nbetween text sources with different partisan leanings. Moral associations of\nwords were highly correlated between conservative and liberal text sources\n(average $\\rho$ = 0.96), but the differences remained reliable to enable us to\ndistinguish text sources along partisan lines with above 85% classification\naccuracy. These findings underscore that despite a shared moral understanding\nacross the political spectrum, there are consistent differences that shape\npartisan language and potentially exacerbate political polarization. Our\nresults, drawn from both informal interactions on social media and curated\nnarratives in news outlets, indicate that these trends are widespread.\nLeveraging advanced computational techniques, this research offers a fresh\nperspective that complements traditional methods in political attitudes.", "published": "2023-10-14 16:50:26", "link": "http://arxiv.org/abs/2310.09618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Expression Tree Decoding Strategy for Mathematical Equation\n  Generation", "abstract": "Generating mathematical equations from natural language requires an accurate\nunderstanding of the relations among math expressions. Existing approaches can\nbe broadly categorized into token-level and expression-level generation. The\nformer treats equations as a mathematical language, sequentially generating\nmath tokens. Expression-level methods generate each expression one by one.\nHowever, each expression represents a solving step, and there naturally exist\nparallel or dependent relations between these steps, which are ignored by\ncurrent sequential methods. Therefore, we integrate tree structure into the\nexpression-level generation and advocate an expression tree decoding strategy.\nTo generate a tree with expression as its node, we employ a layer-wise parallel\ndecoding strategy: we decode multiple independent expressions (leaf nodes) in\nparallel at each layer and repeat parallel decoding layer by layer to\nsequentially generate these parent node expressions that depend on others.\nBesides, a bipartite matching algorithm is adopted to align multiple\npredictions with annotations for each layer. Experiments show our method\noutperforms other baselines, especially for these equations with complex\nstructures.", "published": "2023-10-14 17:00:28", "link": "http://arxiv.org/abs/2310.09619v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Digital Language Coherence Marker for Monitoring Dementia", "abstract": "The use of spontaneous language to derive appropriate digital markers has\nbecome an emergent, promising and non-intrusive method to diagnose and monitor\ndementia. Here we propose methods to capture language coherence as a\ncost-effective, human-interpretable digital marker for monitoring cognitive\nchanges in people with dementia. We introduce a novel task to learn the\ntemporal logical consistency of utterances in short transcribed narratives and\ninvestigate a range of neural approaches. We compare such language coherence\npatterns between people with dementia and healthy controls and conduct a\nlongitudinal evaluation against three clinical bio-markers to investigate the\nreliability of our proposed digital coherence marker. The coherence marker\nshows a significant difference between people with mild cognitive impairment,\nthose with Alzheimer's Disease and healthy controls. Moreover our analysis\nshows high association between the coherence marker and the clinical\nbio-markers as well as generalisability potential to other related conditions.", "published": "2023-10-14 17:10:19", "link": "http://arxiv.org/abs/2310.09623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Legend at ArAIEval Shared Task: Persuasion Technique Detection using a\n  Language-Agnostic Text Representation Model", "abstract": "In this paper, we share our best performing submission to the Arabic AI Tasks\nEvaluation Challenge (ArAIEval) at ArabicNLP 2023. Our focus was on Task 1,\nwhich involves identifying persuasion techniques in excerpts from tweets and\nnews articles. The persuasion technique in Arabic texts was detected using a\ntraining loop with XLM-RoBERTa, a language-agnostic text representation model.\nThis approach proved to be potent, leveraging fine-tuning of a multilingual\nlanguage model. In our evaluation of the test set, we achieved a micro F1 score\nof 0.64 for subtask A of the competition.", "published": "2023-10-14 20:27:04", "link": "http://arxiv.org/abs/2310.09661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language\n  Models", "abstract": "Various Large Language Models~(LLMs) from the Generative Pretrained\nTransformer(GPT) family have achieved outstanding performances in a wide range\nof text generation tasks. However, the enormous model sizes have hindered their\npractical use in real-world applications due to high inference latency.\nTherefore, improving the efficiencies of LLMs through quantization, pruning,\nand other means has been a key issue in LLM studies. In this work, we propose a\nmethod based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs\nto at least 50% sparsity without the need of any retraining. It allocates\nsparsity adaptively based on sensitivity, allowing us to reduce pruning-induced\nerror while maintaining the overall sparsity level. The advantages of the\nproposed method exhibit even more when the sparsity is extremely high.\nFurthermore, our method is compatible with quantization, enabling further\ncompression of LLMs. We have released the available code.", "published": "2023-10-14 05:43:09", "link": "http://arxiv.org/abs/2310.09499v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Solving Math Word Problems with Reexamination", "abstract": "Math word problem (MWP) solving aims to understand the descriptive math\nproblem and calculate the result, for which previous efforts are mostly devoted\nto upgrade different technical modules. This paper brings a different\nperspective of \\textit{reexamination process} during training by introducing a\npseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)\nlearning scheme to model such process, which is model-agnostic thus can be\nadapted to any existing MWP solvers. The pseudo-dual task is specifically\ndefined as filling the numbers in the expression back into the original word\nproblem with numbers masked. To facilitate the effective joint learning of the\ntwo tasks, we further design a scheduled fusion strategy for the number\ninfilling task, which smoothly switches the input from the ground-truth math\nexpressions to the predicted ones. Our pseudo-dual learning scheme has been\ntested and proven effective when being equipped in several representative MWP\nsolvers through empirical studies. \\textit{The codes and trained models are\navailable at:} \\url{https://github.com/steven640pixel/PsedualMWP}.\n\\end{abstract}", "published": "2023-10-14 14:23:44", "link": "http://arxiv.org/abs/2310.09590v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An End-to-End System for Reproducibility Assessment of Source Code\n  Repositories via Their Readmes", "abstract": "Increased reproducibility of machine learning research has been a driving\nforce for dramatic improvements in learning performances. The scientific\ncommunity further fosters this effort by including reproducibility ratings in\nreviewer forms and considering them as a crucial factor for the overall\nevaluation of papers. Accompanying source code is not sufficient to make a work\nreproducible. The shared codes should meet the ML reproducibility checklist as\nwell. This work aims to support reproducibility evaluations of papers with\nsource codes. We propose an end-to-end system that operates on the Readme file\nof the source code repositories. The system checks the compliance of a given\nReadme to a template proposed by a widely used platform for sharing source\ncodes of research. Our system generates scores based on a custom function to\ncombine section scores. We also train a hierarchical transformer model to\nassign a class label to a given Readme. The experimental results show that the\nsection similarity-based system performs better than the hierarchical\ntransformer. Moreover, it has an advantage regarding explainability since one\ncan directly relate the score to the sections of Readme files.", "published": "2023-10-14 18:01:11", "link": "http://arxiv.org/abs/2310.09634v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Beyond Testers' Biases: Guiding Model Testing with Knowledge Bases using\n  LLMs", "abstract": "Current model testing work has mostly focused on creating test cases.\nIdentifying what to test is a step that is largely ignored and poorly\nsupported. We propose Weaver, an interactive tool that supports requirements\nelicitation for guiding model testing. Weaver uses large language models to\ngenerate knowledge bases and recommends concepts from them interactively,\nallowing testers to elicit requirements for further testing. Weaver provides\nrich external knowledge to testers and encourages testers to systematically\nexplore diverse concepts beyond their own biases. In a user study, we show that\nboth NLP experts and non-experts identified more, as well as more diverse\nconcepts worth testing when using Weaver. Collectively, they found more than\n200 failing test cases for stance detection with zero-shot ChatGPT. Our case\nstudies further show that Weaver can help practitioners test models in\nreal-world settings, where developers define more nuanced application scenarios\n(e.g., code understanding and transcript summarization) using LLMs.", "published": "2023-10-14 21:24:03", "link": "http://arxiv.org/abs/2310.09668v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Autonomous Tree-search Ability of Large Language Models", "abstract": "Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.", "published": "2023-10-14 14:14:38", "link": "http://arxiv.org/abs/2310.10686v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Instruction Tuning with Human Curriculum", "abstract": "In this work, we (1) introduce Curriculum Instruction Tuning, (2) explore the\npotential advantages of employing diverse curriculum strategies, and (3)\ndelineate a synthetic instruction-response generation framework that\ncomplements our theoretical approach. Distinct from the existing instruction\ntuning dataset, our generation pipeline is systematically structured to emulate\nthe sequential and orderly characteristic of human learning. Additionally, we\ndescribe a methodology for generating instruction-response datasets that\nextensively span the various stages of human education, from middle school\nthrough the graduate level, utilizing educational subject catalogs.\n  Before training, we meticulously organize the instruction data to ensure that\nquestions escalate in difficulty regarding (A) the subject matter and (B) the\nintricacy of the instructions. The findings of our study reveal that\nsubstantial improvements in performance can be achieved through the mere\napplication of curriculum ordering to instruction data (achieving gains of\n+4.76 on TruthfulQA, +2.98 on MMLU, +2.8 on OpenbookQA, and +1.28 on ARC-hard)\ncompared to random shuffling. This enhancement is achieved without incurring\nadditional computational expenses. Through comprehensive experimentation, we\nobserve that the advantages of our proposed method are consistently evident\nacross nine benchmarks.", "published": "2023-10-14 07:16:08", "link": "http://arxiv.org/abs/2310.09518v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CarExpert: Leveraging Large Language Models for In-Car Conversational\n  Question Answering", "abstract": "Large language models (LLMs) have demonstrated remarkable performance by\nfollowing natural language instructions without fine-tuning them on\ndomain-specific tasks and data. However, leveraging LLMs for domain-specific\nquestion answering suffers from severe limitations. The generated answer tends\nto hallucinate due to the training data collection time (when using\noff-the-shelf), complex user utterance and wrong retrieval (in\nretrieval-augmented generation). Furthermore, due to the lack of awareness\nabout the domain and expected output, such LLMs may generate unexpected and\nunsafe answers that are not tailored to the target domain. In this paper, we\npropose CarExpert, an in-car retrieval-augmented conversational\nquestion-answering system leveraging LLMs for different tasks. Specifically,\nCarExpert employs LLMs to control the input, provide domain-specific documents\nto the extractive and generative answering components, and controls the output\nto ensure safe and domain-specific answers. A comprehensive empirical\nevaluation exhibits that CarExpert outperforms state-of-the-art LLMs in\ngenerating natural, safe and car-specific answers.", "published": "2023-10-14 08:46:24", "link": "http://arxiv.org/abs/2310.09536v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the\n  Robustness of Large Language Models", "abstract": "As large language models are integrated into society, robustness toward a\nsuite of prompts is increasingly important to maintain reliability in a\nhigh-variance environment.Robustness evaluations must comprehensively\nencapsulate the various settings in which a user may invoke an intelligent\nsystem. This paper proposes ASSERT, Automated Safety Scenario Red Teaming,\nconsisting of three methods -- semantically aligned augmentation, target\nbootstrapping, and adversarial knowledge injection. For robust safety\nevaluation, we apply these methods in the critical domain of AI safety to\nalgorithmically generate a test suite of prompts covering diverse robustness\nsettings -- semantic equivalence, related scenarios, and adversarial. We\npartition our prompts into four safety domains for a fine-grained analysis of\nhow the domain affects model performance. Despite dedicated safeguards in\nexisting state-of-the-art models, we find statistically significant performance\ndifferences of up to 11% in absolute classification accuracy among semantically\nrelated scenarios and error rates of up to 19% absolute error in zero-shot\nadversarial settings, raising concerns for users' physical safety.", "published": "2023-10-14 17:10:28", "link": "http://arxiv.org/abs/2310.09624v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Lexical Entrainment for Conversational Systems", "abstract": "Conversational agents have become ubiquitous in assisting with daily tasks,\nand are expected to possess human-like features. One such feature is lexical\nentrainment (LE), a phenomenon in which speakers in human-human conversations\ntend to naturally and subconsciously align their lexical choices with those of\ntheir interlocutors, leading to more successful and engaging conversations. As\nan example, if a digital assistant replies 'Your appointment for Jinling Noodle\nPub is at 7 pm' to the question 'When is my reservation for Jinling Noodle Bar\ntoday?', it may feel as though the assistant is trying to correct the speaker,\nwhereas a response of 'Your reservation for Jinling Noodle Bar is at 7 pm'\nwould likely be perceived as more positive. This highlights the importance of\nLE in establishing a shared terminology for maximum clarity and reducing\nambiguity in conversations. However, we demonstrate in this work that current\nresponse generation models do not adequately address this crucial humanlike\nphenomenon. To address this, we propose a new dataset, named MULTIWOZ-ENTR, and\na measure for LE for conversational systems. Additionally, we suggest a way to\nexplicitly integrate LE into conversational systems with two new tasks, a LE\nextraction task and a LE generation task. We also present two baseline\napproaches for the LE extraction task, which aim to detect LE expressions from\ndialogue contexts.", "published": "2023-10-14 19:47:37", "link": "http://arxiv.org/abs/2310.09651v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Model-Agnostic Multi-Group Equivariant Networks", "abstract": "Constructing model-agnostic group equivariant networks, such as equitune\n(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be\ncomputationally expensive for large product groups. We address this problem by\nproviding efficient model-agnostic equivariant designs for two related\nproblems: one where the network has multiple inputs each with potentially\ndifferent groups acting on them, and another where there is a single input but\nthe group acting on it is a large product group. For the first design, we\ninitially consider a linear model and characterize the entire equivariant space\nthat satisfies this constraint. This characterization gives rise to a novel\nfusion layer between different channels that satisfies an invariance-symmetry\n(IS) constraint, which we call an IS layer. We then extend this design beyond\nlinear models, similar to equitune, consisting of equivariant and IS layers. We\nalso show that the IS layer is a universal approximator of invariant-symmetric\nfunctions. Inspired by the first design, we use the notion of the IS property\nto design a second efficient model-agnostic equivariant design for large\nproduct groups acting on a single input. For the first design, we provide\nexperiments on multi-image classification where each view is transformed\nindependently with transformations such as rotations. We find equivariant\nmodels are robust to such transformations and perform competitively otherwise.\nFor the second design, we consider three applications: language\ncompositionality on the SCAN dataset to product groups; fairness in natural\nlanguage generation from GPT-2 to address intersectionality; and robust\nzero-shot image classification with CLIP. Overall, our methods are simple and\ngeneral, competitive with equitune and its variants, while also being\ncomputationally more efficient.", "published": "2023-10-14 22:24:26", "link": "http://arxiv.org/abs/2310.09675v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Improved Contextual Recognition In Automatic Speech Recognition Systems\n  By Semantic Lattice Rescoring", "abstract": "Automatic Speech Recognition (ASR) has witnessed a profound research\ninterest. Recent breakthroughs have given ASR systems different prospects such\nas faithfully transcribing spoken language, which is a pivotal advancement in\nbuilding conversational agents. However, there is still an imminent challenge\nof accurately discerning context-dependent words and phrases. In this work, we\npropose a novel approach for enhancing contextual recognition within ASR\nsystems via semantic lattice processing leveraging the power of deep learning\nmodels in accurately delivering spot-on transcriptions across a wide variety of\nvocabularies and speaking styles. Our solution consists of using Hidden Markov\nModels and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks\n(DNN) models integrating both language and acoustic modeling for better\naccuracy. We infused our network with the use of a transformer-based model to\nproperly rescore the word lattice achieving remarkable capabilities with a\npalpable reduction in Word Error Rate (WER). We demonstrate the effectiveness\nof our proposed framework on the LibriSpeech dataset with empirical analyses.", "published": "2023-10-14 23:16:05", "link": "http://arxiv.org/abs/2310.09680v4", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large Language Model Unlearning", "abstract": "We study how to perform unlearning, i.e. forgetting undesirable misbehaviors,\non large language models (LLMs). We show at least three scenarios of aligning\nLLMs with human preferences can benefit from unlearning: (1) removing harmful\nresponses, (2) erasing copyright-protected content as requested, and (3)\nreducing hallucinations. Unlearning, as an alignment technique, has three\nadvantages. (1) It only requires negative (e.g. harmful) examples, which are\nmuch easier and cheaper to collect (e.g. via red teaming or user reporting)\nthan positive (e.g. helpful and often human-written) examples required in RLHF\n(RL from human feedback). (2) It is computationally efficient. (3) It is\nespecially effective when we know which training samples cause the misbehavior.\nTo the best of our knowledge, our work is among the first to explore LLM\nunlearning. We are also among the first to formulate the settings, goals, and\nevaluations in LLM unlearning. We show that if practitioners only have limited\nresources, and therefore the priority is to stop generating undesirable outputs\nrather than to try to generate desirable outputs, unlearning is particularly\nappealing. Despite only having negative samples, our ablation study shows that\nunlearning can still achieve better alignment performance than RLHF with just\n2% of its computational time.", "published": "2023-10-14 00:32:55", "link": "http://arxiv.org/abs/2310.10683v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A decoder-only foundation model for time-series forecasting", "abstract": "Motivated by recent advances in large language models for Natural Language\nProcessing (NLP), we design a time-series foundation model for forecasting\nwhose out-of-the-box zero-shot performance on a variety of public datasets\ncomes close to the accuracy of state-of-the-art supervised forecasting models\nfor each individual dataset. Our model is based on pretraining a\npatched-decoder style attention model on a large time-series corpus, and can\nwork well across different forecasting history lengths, prediction lengths and\ntemporal granularities.", "published": "2023-10-14 17:01:37", "link": "http://arxiv.org/abs/2310.10688v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A study of the impact of generative AI-based data augmentation on\n  software metadata classification", "abstract": "This paper presents the system submitted by the team from IIT(ISM) Dhanbad in\nFIRE IRSE 2023 shared task 1 on the automatic usefulness prediction of\ncode-comment pairs as well as the impact of Large Language Model(LLM) generated\ndata on original base data towards an associated source code. We have developed\na framework where we train a machine learning-based model using the neural\ncontextual representations of the comments and their corresponding codes to\npredict the usefulness of code-comments pair and performance analysis with\nLLM-generated data with base data. In the official assessment, our system\nachieves a 4% increase in F1-score from baseline and the quality of generated\ndata.", "published": "2023-10-14 10:47:10", "link": "http://arxiv.org/abs/2310.13714v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Leveraging Generative AI: Improving Software Metadata Classification\n  with Generated Code-Comment Pairs", "abstract": "In software development, code comments play a crucial role in enhancing code\ncomprehension and collaboration. This research paper addresses the challenge of\nobjectively classifying code comments as \"Useful\" or \"Not Useful.\" We propose a\nnovel solution that harnesses contextualized embeddings, particularly BERT, to\nautomate this classification process. We address this task by incorporating\ngenerated code and comment pairs. The initial dataset comprised 9048 pairs of\ncode and comments written in C, labeled as either Useful or Not Useful. To\naugment this dataset, we sourced an additional 739 lines of code-comment pairs\nand generated labels using a Large Language Model Architecture, specifically\nBERT. The primary objective was to build classification models that can\neffectively differentiate between useful and not useful code comments. Various\nmachine learning algorithms were employed, including Logistic Regression,\nDecision Tree, K-Nearest Neighbors (KNN), Support Vector Machine (SVM),\nGradient Boosting, Random Forest, and a Neural Network. Each algorithm was\nevaluated using precision, recall, and F1-score metrics, both with the original\nseed dataset and the augmented dataset. This study showcases the potential of\ngenerative AI for enhancing binary code comment quality classification models,\nproviding valuable insights for software developers and researchers in the\nfield of natural language processing and software engineering.", "published": "2023-10-14 12:09:43", "link": "http://arxiv.org/abs/2311.03365v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Chatbot-supported Thesis Writing: An Autoethnographic Report", "abstract": "The release of the large language model based chatbot ChatGPT in November\n2022 has brought considerable attention to the subject of artificial\nintelligence, not only in the public. From the perspective of higher education,\nChatGPT challenges various learning and assessment formats as it significantly\nreduces the effectiveness of their learning and assessment functionalities. In\nparticular, ChatGPT might be applied to formats that require learners to\ngenerate text, such as bachelor theses or student research papers. Accordingly,\nthe research question arises to what extent writing of bachelor theses is still\na valid learning and assessment format. Correspondingly, in this study, the\nfirst author was asked to write his bachelor's thesis exploiting ChatGPT. For\ntracing the impact of ChatGPT, methodically an autoethnographic approach was\nused. First, all considerations on the potential use of ChatGPT were documented\nin logs and secondly, all ChatGPT chats were logged. Both logs and chat\nhistories were analyzed and are presented along to the recommendations for\nstudents regarding the use of ChatGPT suggested by Gimpel et al. (2023). In\nconclusion, ChatGPT is beneficial in thesis writing during various activities,\nsuch as brainstorming, structuring and text revision. However, there arise\nlimitations, e.g., in referencing. Thus, ChatGPT requires a continuous\nvalidation of the outcomes generated fostering learning. Currently, ChatGPT is\nto be valued as a beneficial tool in thesis writing. However, writing a\nconclusive thesis still requires the learner's meaningful engagement.\nAccordingly, writing a thesis is still a valid learning and assessment format.\nWith further releases of ChatGPT, an increase in capabilities is to be expected\nand the research question needs to be reevaluated from time to time.", "published": "2023-10-14 09:09:26", "link": "http://arxiv.org/abs/2311.10729v1", "categories": ["cs.CY", "cs.CL", "cs.HC", "97U50 (Primary), 68T50 (Secondary)", "I.2.7; I.2.1; K.3.1"], "primary_category": "cs.CY"}
{"title": "Advancing Test-Time Adaptation in Wild Acoustic Test Settings", "abstract": "Acoustic foundation models, fine-tuned for Automatic Speech Recognition\n(ASR), suffer from performance degradation in wild acoustic test settings when\ndeployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA)\nunder these conditions remains an open and unexplored question. Existing wild\nvision TTA methods often fail to handle speech data effectively due to the\nunique characteristics of high-entropy speech frames, which are unreliably\nfiltered out even when containing crucial semantic content. Furthermore, unlike\nstatic vision data, speech signals follow short-term consistency, requiring\nspecialized adaptation strategies. In this work, we propose a novel wild\nacoustic TTA method tailored for ASR fine-tuned acoustic foundation models. Our\nmethod, Confidence-Enhanced Adaptation, performs frame-level adaptation using a\nconfidence-aware weight scheme to avoid filtering out essential information in\nhigh-entropy frames. Additionally, we apply consistency regularization during\ntest-time optimization to leverage the inherent short-term consistency of\nspeech signals. Our experiments on both synthetic and real-world datasets\ndemonstrate that our approach outperforms existing baselines under various wild\nacoustic test settings, including Gaussian noise, environmental sounds, accent\nvariations, and sung speech.", "published": "2023-10-14 06:22:08", "link": "http://arxiv.org/abs/2310.09505v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dynamic Prediction of Full-Ocean Depth SSP by Hierarchical LSTM: An\n  Experimental Result", "abstract": "SSP distribution is an important parameter for underwater positioning,\nnavigation and timing (PNT) because it affects the propagation mode of\nunderwater acoustic signals. To accurate predict future sound speed\ndistribution, we propose a hierarchical long short--term memory (H--LSTM)\nneural network for future sound speed prediction, which explore the\ndistribution pattern of sound velocity in the time dimension. To verify the\nfeasibility and effectiveness, we conducted both simulations and real\nexperiments. The ocean experiment was held in the South China Sea in April,\n2023. Results show that the accuracy of the proposed method outperforms the\nstate--of--the--art methods.", "published": "2023-10-14 07:25:52", "link": "http://arxiv.org/abs/2310.09522v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "SelfVC: Voice Conversion With Iterative Refinement using Self\n  Transformations", "abstract": "We propose SelfVC, a training strategy to iteratively improve a voice\nconversion model with self-synthesized examples. Previous efforts on voice\nconversion focus on factorizing speech into explicitly disentangled\nrepresentations that separately encode speaker characteristics and linguistic\ncontent. However, disentangling speech representations to capture such\nattributes using task-specific loss terms can lead to information loss. In this\nwork, instead of explicitly disentangling attributes with loss terms, we\npresent a framework to train a controllable voice conversion model on entangled\nspeech representations derived from self-supervised learning (SSL) and speaker\nverification models. First, we develop techniques to derive prosodic\ninformation from the audio signal and SSL representations to train predictive\nsubmodules in the synthesis model. Next, we propose a training strategy to\niteratively improve the synthesis model for voice conversion, by creating a\nchallenging training objective using self-synthesized examples. We demonstrate\nthat incorporating such self-synthesized examples during training improves the\nspeaker similarity of generated speech as compared to a baseline voice\nconversion model trained solely on heuristically perturbed inputs. Our\nframework is trained without any text and achieves state-of-the-art results in\nzero-shot voice conversion on metrics evaluating naturalness, speaker\nsimilarity, and intelligibility of synthesized audio.", "published": "2023-10-14 19:51:17", "link": "http://arxiv.org/abs/2310.09653v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
