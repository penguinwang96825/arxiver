{"title": "A Category Theory Approach to Interoperability", "abstract": "In this article, we propose a Category Theory approach to (syntactic)\ninteroperability between linguistic tools. The resulting category consists of\ntextual documents, including any linguistic annotations, NLP tools that analyze\ntexts and add additional linguistic information, and format converters. Format\nconverters are necessary to make the tools both able to read and to produce\ndifferent output formats, which is the key to interoperability. The idea behind\nthis document is the parallelism between the concepts of composition and\nassociativity in Category Theory with the NLP pipelines. We show how pipelines\nof linguistic tools can be modeled into the conceptual framework of Category\nTheory and we successfully apply this method to two real-life examples.", "published": "2020-05-14 11:14:10", "link": "http://arxiv.org/abs/2005.06872v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRTS Parsing with Structure-Aware Encoding and Decoding", "abstract": "Discourse representation tree structure (DRTS) parsing is a novel semantic\nparsing task which has been concerned most recently. State-of-the-art\nperformance can be achieved by a neural sequence-to-sequence model, treating\nthe tree construction as an incremental sequence generation problem. Structural\ninformation such as input syntax and the intermediate skeleton of the partial\noutput has been ignored in the model, which could be potentially useful for the\nDRTS parsing. In this work, we propose a structural-aware model at both the\nencoder and decoder phase to integrate the structural information, where graph\nattention network (GAT) is exploited for effectively modeling. Experimental\nresults on a benchmark dataset show that our proposed model is effective and\ncan obtain the best performance in the literature.", "published": "2020-05-14 12:09:23", "link": "http://arxiv.org/abs/2005.06901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NIT-Agartala-NLP-Team at SemEval-2020 Task 8: Building Multimodal\n  Classifiers to tackle Internet Humor", "abstract": "The paper describes the systems submitted to SemEval-2020 Task 8: Memotion by\nthe `NIT-Agartala-NLP-Team'. A dataset of 8879 memes was made available by the\ntask organizers to train and test our models. Our systems include a Logistic\nRegression baseline, a BiLSTM + Attention-based learner and a transfer learning\napproach with BERT. For the three sub-tasks A, B and C, we attained ranks\n24/33, 11/29 and 15/26, respectively. We highlight our difficulties in\nharnessing image information as well as some techniques and handcrafted\nfeatures we employ to overcome these issues. We also discuss various modelling\nissues and theorize possible solutions and reasons as to why these problems\npersist.", "published": "2020-05-14 13:23:59", "link": "http://arxiv.org/abs/2005.06943v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition as Dependency Parsing", "abstract": "Named Entity Recognition (NER) is a fundamental task in Natural Language\nProcessing, concerned with identifying spans of text expressing references to\nentities. NER research is often focused on flat entities only (flat NER),\nignoring the fact that entity references can be nested, as in [Bank of [China]]\n(Finkel and Manning, 2009). In this paper, we use ideas from graph-based\ndependency parsing to provide our model a global view on the input via a\nbiaffine model (Dozat and Manning, 2017). The biaffine model scores pairs of\nstart and end tokens in a sentence which we use to explore all spans, so that\nthe model is able to predict named entities accurately. We show that the model\nworks well for both nested and flat NER through evaluation on 8 corpora and\nachieving SoTA performance on all of them, with accuracy gains of up to 2.2\npercentage points.", "published": "2020-05-14 17:11:41", "link": "http://arxiv.org/abs/2005.07150v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NAT: Noise-Aware Training for Robust Neural Sequence Labeling", "abstract": "Sequence labeling systems should perform reliably not only under ideal\nconditions but also with corrupted inputs - as these systems often process\nuser-generated text or follow an error-prone upstream component. To this end,\nwe formulate the noisy sequence labeling problem, where the input may undergo\nan unknown noising process and propose two Noise-Aware Training (NAT)\nobjectives that improve robustness of sequence labeling performed on perturbed\ninput: Our data augmentation method trains a neural model using a mixture of\nclean and noisy samples, whereas our stability training algorithm encourages\nthe model to create a noise-invariant latent representation. We employ a\nvanilla noise model at training time. For evaluation, we use both the original\ndata and its variants perturbed with real OCR errors and misspellings.\nExtensive experiments on English and German named entity recognition benchmarks\nconfirmed that NAT consistently improved robustness of popular sequence\nlabeling models, preserving accuracy on the original input. We make our code\nand data publicly available for the research community.", "published": "2020-05-14 17:30:06", "link": "http://arxiv.org/abs/2005.07162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training technique to localize medical BERT and enhance biomedical\n  BERT", "abstract": "Pre-training large-scale neural language models on raw texts has made a\nsignificant contribution to improving transfer learning in natural language\nprocessing (NLP). With the introduction of transformer-based language models,\nsuch as bidirectional encoder representations from transformers (BERT), the\nperformance of information extraction from a free text by NLP has significantly\nimproved for both the general domain and medical domain; however, it is\ndifficult to train specific BERT models that perform well for domains in which\nthere are few publicly available databases of high quality and large size. We\nhypothesized that this problem can be addressed by up-sampling a\ndomain-specific corpus and using it for pre-training with a larger corpus in a\nbalanced manner. Our proposed method consists of a single intervention with one\noption: simultaneous pre-training after up-sampling and amplified vocabulary.\nWe conducted three experiments and evaluated the resulting products. We\nconfirmed that our Japanese medical BERT outperformed conventional baselines\nand the other BERT models in terms of the medical document classification task\nand that our English BERT pre-trained using both the general and medical-domain\ncorpora performed sufficiently well for practical use in terms of the\nbiomedical language understanding evaluation (BLUE) benchmark. Moreover, our\nenhanced biomedical BERT model, in which clinical notes were not used during\npre-training, showed that both the clinical and biomedical scores of the BLUE\nbenchmark were 0.3 points above that of the ablation model trained without our\nproposed method. Well-balanced pre-training by up-sampling instances derived\nfrom a corpus appropriate for the target task allows us to construct a\nhigh-performance BERT model.", "published": "2020-05-14 18:00:01", "link": "http://arxiv.org/abs/2005.07202v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VirAAL: Virtual Adversarial Active Learning For NLU", "abstract": "This paper presents VirAAL, an Active Learning framework based on Adversarial\nTraining. VirAAL aims to reduce the effort of annotation in Natural Language\nUnderstanding (NLU). VirAAL is based on Virtual Adversarial Training (VAT), a\nsemi-supervised approach that regularizes the model through Local\nDistributional Smoothness. With that, adversarial perturbations are added to\nthe inputs making the posterior distribution more consistent. Therefore,\nentropy-based Active Learning becomes robust by querying more informative\nsamples without requiring additional components. The first set of experiments\nstudies the impact of an adapted VAT for joint-NLU tasks within low labeled\ndata regimes. The second set shows the effect of VirAAL in an Active Learning\n(AL) process. Results demonstrate that VAT is robust even on multi-task\ntraining, where the adversarial noise is computed from multiple loss functions.\nSubstantial improvements are observed with entropy-based AL with VirAAL for\nquerying data to annotate. VirAAL is an inexpensive method in terms of AL\ncomputation with a positive impact on data sampling. Furthermore, VirAAL\ndecreases annotations in AL up to 80% and shows improvements over existing data\naugmentation methods. The code is publicly available.", "published": "2020-05-14 22:47:37", "link": "http://arxiv.org/abs/2005.07287v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OSACT4 Shared Task on Offensive Language Detection: Intensive\n  Preprocessing-Based Approach", "abstract": "The preprocessing phase is one of the key phases within the text\nclassification pipeline. This study aims at investigating the impact of the\npreprocessing phase on text classification, specifically on offensive language\nand hate speech classification for Arabic text. The Arabic language used in\nsocial media is informal and written using Arabic dialects, which makes the\ntext classification task very complex. Preprocessing helps in dimensionality\nreduction and removing useless content. We apply intensive preprocessing\ntechniques to the dataset before processing it further and feeding it into the\nclassification model. An intensive preprocessing-based approach demonstrates\nits significant impact on offensive language detection and hate speech\ndetection shared tasks of the fourth workshop on Open-Source Arabic Corpora and\nCorpora Processing Tools (OSACT). Our team wins the third place (3rd) in the\nSub-Task A Offensive Language Detection division and wins the first place (1st)\nin the Sub-Task B Hate Speech Detection division, with an F1 score of 89% and\n95%, respectively, by providing the state-of-the-art performance in terms of\nF1, accuracy, recall, and precision for Arabic hate speech detection.", "published": "2020-05-14 23:46:10", "link": "http://arxiv.org/abs/2005.07297v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Data Augmentation for Formality Style Transfer", "abstract": "The main barrier to progress in the task of Formality Style Transfer is the\ninadequacy of training data. In this paper, we study how to augment parallel\ndata and propose novel and simple data augmentation methods for this task to\nobtain useful sentence pairs with easily accessible models and systems.\nExperiments demonstrate that our augmented parallel data largely helps improve\nformality style transfer when it is used to pre-train the model, leading to the\nstate-of-the-art results in the GYAFC benchmark dataset.", "published": "2020-05-14 04:05:29", "link": "http://arxiv.org/abs/2005.07522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining Black Box Predictions and Unveiling Data Artifacts through\n  Influence Functions", "abstract": "Modern deep learning models for NLP are notoriously opaque. This has\nmotivated the development of methods for interpreting such models, e.g., via\ngradient-based saliency maps or the visualization of attention weights. Such\napproaches aim to provide explanations for a particular model prediction by\nhighlighting important words in the corresponding input text. While this might\nbe useful for tasks where decisions are explicitly influenced by individual\ntokens in the input, we suspect that such highlighting is not suitable for\ntasks where model decisions should be driven by more complex reasoning. In this\nwork, we investigate the use of influence functions for NLP, providing an\nalternative approach to interpreting neural text classifiers. Influence\nfunctions explain the decisions of a model by identifying influential training\nexamples. Despite the promise of this approach, influence functions have not\nyet been extensively evaluated in the context of NLP, a gap addressed by this\nwork. We conduct a comparison between influence functions and common\nword-saliency methods on representative tasks. As suspected, we find that\ninfluence functions are particularly useful for natural language inference, a\ntask in which 'saliency maps' may not have clear interpretation. Furthermore,\nwe develop a new quantitative measure based on influence functions that can\nreveal artifacts in training data.", "published": "2020-05-14 00:45:23", "link": "http://arxiv.org/abs/2005.06676v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mitigating Gender Bias in Machine Learning Data Sets", "abstract": "Artificial Intelligence has the capacity to amplify and perpetuate societal\nbiases and presents profound ethical implications for society. Gender bias has\nbeen identified in the context of employment advertising and recruitment tools,\ndue to their reliance on underlying language processing and recommendation\nalgorithms. Attempts to address such issues have involved testing learned\nassociations, integrating concepts of fairness to machine learning and\nperforming more rigorous analysis of training data. Mitigating bias when\nalgorithms are trained on textual data is particularly challenging given the\ncomplex way gender ideology is embedded in language. This paper proposes a\nframework for the identification of gender bias in training data for machine\nlearning.The work draws upon gender theory and sociolinguistics to\nsystematically indicate levels of bias in textual training data and associated\nneural word embedding models, thus highlighting pathways for both removing bias\nfrom training data and critically assessing its impact.", "published": "2020-05-14 12:06:02", "link": "http://arxiv.org/abs/2005.06898v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured\n  Webpages", "abstract": "In many documents, such as semi-structured webpages, textual semantics are\naugmented with additional information conveyed using visual elements including\nlayout, font size, and color. Prior work on information extraction from\nsemi-structured websites has required learning an extraction model specific to\na given template via either manually labeled or distantly supervised data from\nthat template. In this work, we propose a solution for \"zero-shot\" open-domain\nrelation extraction from webpages with a previously unseen template, including\nfrom websites with little overlap with existing sources of knowledge for\ndistant supervision and websites in entirely new subject verticals. Our model\nuses a graph neural network-based approach to build a rich representation of\ntext fields on a webpage and the relationships between them, enabling\ngeneralization to new templates. Experiments show this approach provides a 31%\nF1 gain over a baseline for zero-shot extraction in a new subject vertical.", "published": "2020-05-14 16:15:58", "link": "http://arxiv.org/abs/2005.07105v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Estimating predictive uncertainty for rumour verification models", "abstract": "The inability to correctly resolve rumours circulating online can have\nharmful real-world consequences. We present a method for incorporating model\nand data uncertainty estimates into natural language processing models for\nautomatic rumour verification. We show that these estimates can be used to\nfilter out model predictions likely to be erroneous, so that these difficult\ninstances can be prioritised by a human fact-checker. We propose two methods\nfor uncertainty-based instance rejection, supervised and unsupervised. We also\nshow how uncertainty estimates can be used to interpret model performance as a\nrumour unfolds.", "published": "2020-05-14 17:42:25", "link": "http://arxiv.org/abs/2005.07174v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Evaluation of Recent Neural Sequence Tagging Models in Turkish Named\n  Entity Recognition", "abstract": "Named entity recognition (NER) is an extensively studied task that extracts\nand classifies named entities in a text. NER is crucial not only in downstream\nlanguage processing applications such as relation extraction and question\nanswering but also in large scale big data operations such as real-time\nanalysis of online digital media content. Recent research efforts on Turkish, a\nless studied language with morphologically rich nature, have demonstrated the\neffectiveness of neural architectures on well-formed texts and yielded\nstate-of-the art results by formulating the task as a sequence tagging problem.\nIn this work, we empirically investigate the use of recent neural architectures\n(Bidirectional long short-term memory and Transformer-based networks) proposed\nfor Turkish NER tagging in the same setting. Our results demonstrate that\ntransformer-based networks which can model long-range context overcome the\nlimitations of BiLSTM networks where different input features at the character,\nsubword, and word levels are utilized. We also propose a transformer-based\nnetwork with a conditional random field (CRF) layer that leads to the\nstate-of-the-art result (95.95\\% f-measure) on a common dataset. Our study\ncontributes to the literature that quantifies the impact of transfer learning\non processing morphologically rich languages.", "published": "2020-05-14 06:54:07", "link": "http://arxiv.org/abs/2005.07692v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective\n  Learning", "abstract": "Human society had a long history of suffering from cognitive biases leading\nto social prejudices and mass injustice. The prevalent existence of cognitive\nbiases in large volumes of historical data can pose a threat of being\nmanifested as unethical and seemingly inhuman predictions as outputs of AI\nsystems trained on such data. To alleviate this problem, we propose a\nbias-aware multi-objective learning framework that given a set of identity\nattributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories\nof the possible classes of prediction outputs, learns to reduce the frequency\nof predicting certain combinations of them, e.g. predicting stereotypes such as\n`most blacks use abusive language', or `fear is a virtue of women'. Our\nexperiments conducted on an emotion prediction task with balanced class priors\nshows that a set of baseline bias-agnostic models exhibit cognitive biases with\nrespect to gender, such as women are prone to be afraid whereas men are more\nprone to be angry. In contrast, our proposed bias-aware multi-objective\nlearning methodology is shown to reduce such biases in the predictied emotions.", "published": "2020-05-14 17:01:53", "link": "http://arxiv.org/abs/2005.06618v2", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "India nudges to contain COVID-19 pandemic: a reactive public policy\n  analysis using machine-learning based topic modelling", "abstract": "India locked down 1.3 billion people on March 25, 2020 in the wake of\nCOVID-19 pandemic. The economic cost of it was estimated at USD 98 billion,\nwhile the social costs are still unknown. This study investigated how\ngovernment formed reactive policies to fight coronavirus across its policy\nsectors. Primary data was collected from the Press Information Bureau (PIB) in\nthe form press releases of government plans, policies, programme initiatives\nand achievements. A text corpus of 260,852 words was created from 396 documents\nfrom the PIB. An unsupervised machine-based topic modelling using Latent\nDirichlet Allocation (LDA) algorithm was performed on the text corpus. It was\ndone to extract high probability topics in the policy sectors. The\ninterpretation of the extracted topics was made through a nudge theoretic lens\nto derive the critical policy heuristics of the government. Results showed that\nmost interventions were targeted to generate endogenous nudge by using external\ntriggers. Notably, the nudges from the Prime Minister of India was critical in\ncreating herd effect on lockdown and social distancing norms across the nation.\nA similar effect was also observed around the public health (e.g., masks in\npublic spaces; Yoga and Ayurveda for immunity), transport (e.g., old trains\nconverted to isolation wards), micro, small and medium enterprises (e.g., rapid\nproduction of PPE and masks), science and technology sector (e.g., diagnostic\nkits, robots and nano-technology), home affairs (e.g., surveillance and\nlockdown), urban (e.g. drones, GIS-tools) and education (e.g., online\nlearning). A conclusion was drawn on leveraging these heuristics are crucial\nfor lockdown easement planning.", "published": "2020-05-14 04:14:09", "link": "http://arxiv.org/abs/2005.06619v2", "categories": ["cs.CY", "cs.CL", "cs.LG", "J.4; K.4.1"], "primary_category": "cs.CY"}
{"title": "S2IGAN: Speech-to-Image Generation via Adversarial Learning", "abstract": "An estimated half of the world's languages do not have a written form, making\nit impossible for these languages to benefit from any existing text-based\ntechnologies. In this paper, a speech-to-image generation (S2IG) framework is\nproposed which translates speech descriptions to photo-realistic images without\nusing any text information, thus allowing unwritten languages to potentially\nbenefit from this technology. The proposed S2IG framework, named S2IGAN,\nconsists of a speech embedding network (SEN) and a relation-supervised\ndensely-stacked generative model (RDG). SEN learns the speech embedding with\nthe supervision of the corresponding visual information. Conditioned on the\nspeech embedding produced by SEN, the proposed RDG synthesizes images that are\nsemantically consistent with the corresponding speech descriptions. Extensive\nexperiments on two public benchmark datasets CUB and Oxford-102 demonstrate the\neffectiveness of the proposed S2IGAN on synthesizing high-quality and\nsemantically-consistent images from the speech signal, yielding a good\nperformance and a solid baseline for the S2IG task.", "published": "2020-05-14 13:39:56", "link": "http://arxiv.org/abs/2005.06968v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Multi-agent Communication meets Natural Language: Synergies between\n  Functional and Structural Language Learning", "abstract": "We present a method for combining multi-agent communication and traditional\ndata-driven approaches to natural language learning, with an end goal of\nteaching agents to communicate with humans in natural language. Our starting\npoint is a language model that has been trained on generic, not task-specific\nlanguage data. We then place this model in a multi-agent self-play environment\nthat generates task-specific rewards used to adapt or modulate the model,\nturning it into a task-conditional language model. We introduce a new way for\ncombining the two types of learning based on the idea of reranking language\nmodel samples, and show that this method outperforms others in communicating\nwith humans in a visual referential communication task. Finally, we present a\ntaxonomy of different types of language drift that can occur alongside a set of\nmeasures to detect them.", "published": "2020-05-14 15:32:23", "link": "http://arxiv.org/abs/2005.07064v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling neural networks into skipgram-level decision lists", "abstract": "Several previous studies on explanation for recurrent neural networks focus\non approaches that find the most important input segments for a network as its\nexplanations. In that case, the manner in which these input segments combine\nwith each other to form an explanatory pattern remains unknown. To overcome\nthis, some previous work tries to find patterns (called rules) in the data that\nexplain neural outputs. However, their explanations are often insensitive to\nmodel parameters, which limits the scalability of text explanations. To\novercome these limitations, we propose a pipeline to explain RNNs by means of\ndecision lists (also called rules) over skipgrams. For evaluation of\nexplanations, we create a synthetic sepsis-identification dataset, as well as\napply our technique on additional clinical and sentiment analysis datasets. We\nfind that our technique persistently achieves high explanation fidelity and\nqualitatively interpretable rules.", "published": "2020-05-14 16:25:42", "link": "http://arxiv.org/abs/2005.07111v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "You Do Not Need More Data: Improving End-To-End Speech Recognition by\n  Text-To-Speech Data Augmentation", "abstract": "Data augmentation is one of the most effective ways to make end-to-end\nautomatic speech recognition (ASR) perform close to the conventional hybrid\napproach, especially when dealing with low-resource tasks. Using recent\nadvances in speech synthesis (text-to-speech, or TTS), we build our TTS system\non an ASR training database and then extend the data with synthesized speech to\ntrain a recognition model. We argue that, when the training data amount is\nrelatively low, this approach can allow an end-to-end model to reach hybrid\nsystems' quality. For an artificial low-to-medium-resource setup, we compare\nthe proposed augmentation with the semi-supervised learning technique. We also\ninvestigate the influence of vocoder usage on final ASR performance by\ncomparing Griffin-Lim algorithm with our modified LPCNet. When applied with an\nexternal language model, our approach outperforms a semi-supervised setup for\nLibriSpeech test-clean and only 33% worse than a comparable supervised setup.\nOur system establishes a competitive result for end-to-end ASR trained on\nLibriSpeech train-clean-100 set with WER 4.3% for test-clean and 13.5% for\ntest-other.", "published": "2020-05-14 17:24:57", "link": "http://arxiv.org/abs/2005.07157v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Target-Speaker Voice Activity Detection: a Novel Approach for\n  Multi-Speaker Diarization in a Dinner Party Scenario", "abstract": "Speaker diarization for real-life scenarios is an extremely challenging\nproblem. Widely used clustering-based diarization approaches perform rather\npoorly in such conditions, mainly due to the limited ability to handle\noverlapping speech. We propose a novel Target-Speaker Voice Activity Detection\n(TS-VAD) approach, which directly predicts an activity of each speaker on each\ntime frame. TS-VAD model takes conventional speech features (e.g., MFCC) along\nwith i-vectors for each speaker as inputs. A set of binary classification\noutput layers produces activities of each speaker. I-vectors can be estimated\niteratively, starting with a strong clustering-based diarization. We also\nextend the TS-VAD approach to the multi-microphone case using a simple\nattention mechanism on top of hidden representations extracted from the\nsingle-channel TS-VAD model. Moreover, post-processing strategies for the\npredicted speaker activity probabilities are investigated. Experiments on the\nCHiME-6 unsegmented data show that TS-VAD achieves state-of-the-art results\noutperforming the baseline x-vector-based system by more than 30% Diarization\nError Rate (DER) abs.", "published": "2020-05-14 21:24:56", "link": "http://arxiv.org/abs/2005.07272v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Streaming keyword spotting on mobile devices", "abstract": "In this work we explore the latency and accuracy of keyword spotting (KWS)\nmodels in streaming and non-streaming modes on mobile phones. NN model\nconversion from non-streaming mode (model receives the whole input sequence and\nthen returns the classification result) to streaming mode (model receives\nportion of the input sequence and classifies it incrementally) may require\nmanual model rewriting. We address this by designing a Tensorflow/Keras based\nlibrary which allows automatic conversion of non-streaming models to streaming\nones with minimum effort. With this library we benchmark multiple KWS models in\nboth streaming and non-streaming modes on mobile phones and demonstrate\ndifferent tradeoffs between latency and accuracy. We also explore novel KWS\nmodels with multi-head attention which reduce the classification error over the\nstate-of-art by 10% on Google speech commands data sets V2. The streaming\nlibrary with all experiments is open-sourced.", "published": "2020-05-14 05:05:22", "link": "http://arxiv.org/abs/2005.06720v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in\n  TDNN Based Speaker Verification", "abstract": "Current speaker verification techniques rely on a neural network to extract\nspeaker representations. The successful x-vector architecture is a Time Delay\nNeural Network (TDNN) that applies statistics pooling to project\nvariable-length utterances into fixed-length speaker characterizing embeddings.\nIn this paper, we propose multiple enhancements to this architecture based on\nrecent trends in the related fields of face verification and computer vision.\nFirstly, the initial frame layers can be restructured into 1-dimensional\nRes2Net modules with impactful skip connections. Similarly to SE-ResNet, we\nintroduce Squeeze-and-Excitation blocks in these modules to explicitly model\nchannel interdependencies. The SE block expands the temporal context of the\nframe layer by rescaling the channels according to global properties of the\nrecording. Secondly, neural networks are known to learn hierarchical features,\nwith each layer operating on a different level of complexity. To leverage this\ncomplementary information, we aggregate and propagate features of different\nhierarchical levels. Finally, we improve the statistics pooling module with\nchannel-dependent frame attention. This enables the network to focus on\ndifferent subsets of frames during each of the channel's statistics estimation.\nThe proposed ECAPA-TDNN architecture significantly outperforms state-of-the-art\nTDNN based systems on the VoxCeleb test sets and the 2019 VoxCeleb Speaker\nRecognition Challenge.", "published": "2020-05-14 17:02:15", "link": "http://arxiv.org/abs/2005.07143v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FaceFilter: Audio-visual speech separation using still images", "abstract": "The objective of this paper is to separate a target speaker's speech from a\nmixture of two speakers using a deep audio-visual speech separation network.\nUnlike previous works that used lip movement on video clips or pre-enrolled\nspeaker information as an auxiliary conditional feature, we use a single face\nimage of the target speaker. In this task, the conditional feature is obtained\nfrom facial appearance in cross-modal biometric task, where audio and visual\nidentity representations are shared in latent space. Learnt identities from\nfacial images enforce the network to isolate matched speakers and extract the\nvoices from mixed speech. It solves the permutation problem caused by swapped\nchannel outputs, frequently occurred in speech separation tasks. The proposed\nmethod is far more practical than video-based speech separation since user\nprofile images are readily available on many platforms. Also, unlike\nspeaker-aware separation methods, it is applicable on separation with unseen\nspeakers who have never been enrolled before. We show strong qualitative and\nquantitative results on challenging real-world examples.", "published": "2020-05-14 15:42:31", "link": "http://arxiv.org/abs/2005.07074v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semi-supervised Neural Chord Estimation Based on a Variational\n  Autoencoder with Latent Chord Labels and Features", "abstract": "This paper describes a statistically-principled semi-supervised method of\nautomatic chord estimation (ACE) that can make effective use of music signals\nregardless of the availability of chord annotations. The typical approach to\nACE is to train a deep classification model (neural chord estimator) in a\nsupervised manner by using only annotated music signals. In this discriminative\napproach, prior knowledge about chord label sequences (model output) has\nscarcely been taken into account. In contrast, we propose a unified generative\nand discriminative approach in the framework of amortized variational\ninference. More specifically, we formulate a deep generative model that\nrepresents the generative process of chroma vectors (observed variables) from\ndiscrete labels and continuous features (latent variables), which are assumed\nto follow a Markov model favoring self-transitions and a standard Gaussian\ndistribution, respectively. Given chroma vectors as observed data, the\nposterior distributions of the latent labels and features are computed\napproximately by using deep classification and recognition models,\nrespectively. These three models form a variational autoencoder and can be\ntrained jointly in a semi-supervised manner. The experimental results show that\nthe regularization of the classification model based on the Markov prior of\nchord labels and the generative model of chroma vectors improved the\nperformance of ACE even under the supervised condition. The semi-supervised\nlearning using additional non-annotated data can further improve the\nperformance.", "published": "2020-05-14 15:58:36", "link": "http://arxiv.org/abs/2005.07091v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
