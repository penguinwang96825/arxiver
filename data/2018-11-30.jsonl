{"title": "Document Structure Measure for Hypernym discovery", "abstract": "Hypernym discovery is the problem of finding terms that have is-a\nrelationship with a given term. We introduce a new context type, and a\nrelatedness measure to differentiate hypernyms from other types of semantic\nrelationships. Our Document Structure measure is based on hierarchical position\nof terms in a document, and their presence or otherwise in definition text.\nThis measure quantifies the document structure using multiple attributes, and\nclasses of weighted distance functions.", "published": "2018-11-30 11:10:59", "link": "http://arxiv.org/abs/1811.12728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TIFTI: A Framework for Extracting Drug Intervals from Longitudinal\n  Clinic Notes", "abstract": "Oral drugs are becoming increasingly common in oncology care. In contrast to\nintravenous chemotherapy, which is administered in the clinic and carefully\ntracked via structure electronic health records (EHRs), oral drug treatment is\nself-administered and therefore not tracked as well. Often, the details of oral\ncancer treatment occur only in unstructured clinic notes. Extracting this\ninformation is critical to understanding a patient's treatment history. Yet,\nthis a challenging task because treatment intervals must be inferred\nlongitudinally from both explicit mentions in the text as well as from document\ntimestamps. In this work, we present TIFTI (Temporally Integrated Framework for\nTreatment Intervals), a robust framework for extracting oral drug treatment\nintervals from a patient's unstructured notes. TIFTI leverages distinct sources\nof temporal information by breaking the problem down into two separate\nsubtasks: document-level sequence labeling and date extraction. On a labeled\ndataset of metastatic renal-cell carcinoma (RCC) patients, it exactly matched\nthe labeled start date in 46% of the examples (86% of the examples within 30\ndays), and it exactly matched the labeled end date in 52% of the examples (78%\nof the examples within 30 days). Without retraining, the model achieved a\nsimilar level of performance on a labeled dataset of advanced non-small-cell\nlung cancer (NSCLC) patients.", "published": "2018-11-30 13:50:15", "link": "http://arxiv.org/abs/1811.12793v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Offensive Content in Open-domain Conversations using Two Stage\n  Semi-supervision", "abstract": "As open-ended human-chatbot interaction becomes commonplace, sensitive\ncontent detection gains importance. In this work, we propose a two stage\nsemi-supervised approach to bootstrap large-scale data for automatic sensitive\nlanguage detection from publicly available web resources. We explore various\ndata selection methods including 1) using a blacklist to rank online discussion\nforums by the level of their sensitiveness followed by randomly sampling\nutterances and 2) training a weakly supervised model in conjunction with the\nblacklist for scoring sentences from online discussion forums to curate a\ndataset. Our data collection strategy is flexible and allows the models to\ndetect implicit sensitive content for which manual annotations may be\ndifficult. We train models using publicly available annotated datasets as well\nas using the proposed large-scale semi-supervised datasets. We evaluate the\nperformance of all the models on Twitter and Toxic Wikipedia comments testsets\nas well as on a manually annotated spoken language dataset collected during a\nlarge scale chatbot competition. Results show that a model trained on this\ncollected data outperforms the baseline models by a large margin on both\nin-domain and out-of-domain testsets, achieving an F1 score of 95.5% on an\nout-of-domain testset compared to a score of 75% for models trained on public\ndatasets. We also showcase that large scale two stage semi-supervision\ngeneralizes well across multiple classes of sensitivities such as hate speech,\nracism, sexual and pornographic content, etc. without even providing explicit\nlabels for these classes, leading to an average recall of 95.5% versus the\nmodels trained using annotated public datasets which achieve an average recall\nof 73.2% across seven sensitive classes on out-of-domain testsets.", "published": "2018-11-30 17:14:30", "link": "http://arxiv.org/abs/1811.12900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling natural language emergence with integral transform theory and\n  reinforcement learning", "abstract": "Zipf's law predicts a power-law relationship between word rank and frequency\nin language communication systems and has been widely reported in a variety of\nnatural language processing applications. However, the emergence of natural\nlanguage is often modeled as a function of bias between speaker and listener\ninterests, which lacks a direct way of relating information-theoretic bias to\nZipfian rank. A function of bias also serves as an unintuitive interpretation\nof the communicative effort exchanged between a speaker and a listener. We\ncounter these shortcomings by proposing a novel integral transform and kernel\nfor mapping communicative bias functions to corresponding word frequency-rank\nrepresentations at any arbitrary phase transition point, resulting in a direct\nway to link communicative effort (modeled by speaker/listener bias) to specific\nvocabulary used (represented by word rank). We demonstrate the practical\nutility of our integral transform by showing how a change from bias to rank\nresults in greater accuracy and performance at an image classification task for\nassigning word labels to images randomly subsampled from CIFAR10. We model this\ntask as a reinforcement learning game between a speaker and listener and\ncompare the relative impact of bias and Zipfian word rank on communicative\nperformance (and accuracy) between the two agents.", "published": "2018-11-30 19:12:04", "link": "http://arxiv.org/abs/1812.01431v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Systematic Generalization: What Is Required and Can It Be Learned?", "abstract": "Numerous models for grounded language understanding have been recently\nproposed, including (i) generic models that can be easily adapted to any given\ntask and (ii) intuitively appealing modular models that require background\nknowledge to be instantiated. We compare both types of models in how much they\nlend themselves to a particular form of systematic generalization. Using a\nsynthetic VQA test, we evaluate which models are capable of reasoning about all\npossible object pairs after training on only a small subset of them. Our\nfindings show that the generalization of modular models is much more systematic\nand that it is highly sensitive to the module layout, i.e. to how exactly the\nmodules are connected. We furthermore investigate if modular models that\ngeneralize well could be made more end-to-end by learning their layout and\nparametrization. We find that end-to-end methods from prior work often learn\ninappropriate layouts or parametrizations that do not facilitate systematic\ngeneralization. Our results suggest that, in addition to modularity, systematic\ngeneralization in language understanding may require explicit regularizers or\npriors.", "published": "2018-11-30 17:01:28", "link": "http://arxiv.org/abs/1811.12889v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Flexible and Scalable State Tracking Framework for Goal-Oriented\n  Dialogue Systems", "abstract": "Goal-oriented dialogue systems typically rely on components specifically\ndeveloped for a single task or domain. This limits such systems in two\ndifferent ways: If there is an update in the task domain, the dialogue system\nusually needs to be updated or completely re-trained. It is also harder to\nextend such dialogue systems to different and multiple domains. The dialogue\nstate tracker in conventional dialogue systems is one such component - it is\nusually designed to fit a well-defined application domain. For example, it is\ncommon for a state variable to be a categorical distribution over a\nmanually-predefined set of entities (Henderson et al., 2013), resulting in an\ninflexible and hard-to-extend dialogue system. In this paper, we propose a new\napproach for dialogue state tracking that can generalize well over multiple\ndomains without incorporating any domain-specific knowledge. Under this\nframework, discrete dialogue state variables are learned independently and the\ninformation of a predefined set of possible values for dialogue state variables\nis not required. Furthermore, it enables adding arbitrary dialogue context as\nfeatures and allows for multiple values to be associated with a single state\nvariable. These characteristics make it much easier to expand the dialogue\nstate space. We evaluate our framework using the widely used dialogue state\ntracking challenge data set (DSTC2) and show that our framework yields\ncompetitive results with other state-of-the-art results despite incorporating\nlittle domain knowledge. We also show that this framework can benefit from\nwidely available external resources such as pre-trained word embeddings.", "published": "2018-11-30 17:01:48", "link": "http://arxiv.org/abs/1811.12891v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Inferring Concept Prerequisite Relations from Online Educational\n  Resources", "abstract": "The Internet has rich and rapidly increasing sources of high quality\neducational content. Inferring prerequisite relations between educational\nconcepts is required for modern large-scale online educational technology\napplications such as personalized recommendations and automatic curriculum\ncreation. We present PREREQ, a new supervised learning method for inferring\nconcept prerequisite relations. PREREQ is designed using latent representations\nof concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a\nneural network based on the Siamese network architecture. PREREQ can learn\nunknown concept prerequisites from course prerequisites and labeled concept\nprerequisite data. It outperforms state-of-the-art approaches on benchmark\ndatasets and can effectively learn from very less training data. PREREQ can\nalso use unlabeled video playlists, a steadily growing source of training data,\nto learn concept prerequisites, thus obviating the need for manual annotation\nof course prerequisites.", "published": "2018-11-30 06:55:20", "link": "http://arxiv.org/abs/1811.12640v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Neural separation of observed and unobserved distributions", "abstract": "Separating mixed distributions is a long standing challenge for machine\nlearning and signal processing. Most current methods either rely on making\nstrong assumptions on the source distributions or rely on having training\nsamples of each source in the mixture. In this work, we introduce a new\nmethod---Neural Egg Separation---to tackle the scenario of extracting a signal\nfrom an unobserved distribution additively mixed with a signal from an observed\ndistribution. Our method iteratively learns to separate the known distribution\nfrom progressively finer estimates of the unknown distribution. In some\nsettings, Neural Egg Separation is initialization sensitive, we therefore\nintroduce Latent Mixture Masking which ensures a good initialization. Extensive\nexperiments on audio and image separation tasks show that our method\noutperforms current methods that use the same level of supervision, and often\nachieves similar performance to full supervision.", "published": "2018-11-30 11:38:54", "link": "http://arxiv.org/abs/1811.12739v2", "categories": ["cs.LG", "cs.CL", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
