{"title": "Improving Large-scale Language Models and Resources for Filipino", "abstract": "In this paper, we improve on existing language resources for the low-resource\nFilipino language in two ways. First, we outline the construction of the\nTLUnified dataset, a large-scale pretraining corpus that serves as an\nimprovement over smaller existing pretraining datasets for the language in\nterms of scale and topic variety. Second, we pretrain new Transformer language\nmodels following the RoBERTa pretraining technique to supplant existing models\ntrained with small corpora. Our new RoBERTa models show significant\nimprovements over existing Filipino models in three benchmark datasets with an\naverage gain of 4.47% test accuracy across the three classification tasks of\nvarying difficulty.", "published": "2021-11-11 05:00:58", "link": "http://arxiv.org/abs/2111.06053v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Enactivist account of Mind Reading in Natural Language Understanding", "abstract": "In this paper we apply our understanding of the radical enactivist agenda to\nthe classic AI-hard problem of Natural Language Understanding. When Turing\ndevised his famous test the assumption was that a computer could use language\nand the challenge would be to mimic human intelligence. It turned out playing\nchess and formal logic were easy compared to understanding what people say. The\ntechniques of good old-fashioned AI (GOFAI) assume symbolic representation is\nthe core of reasoning and by that paradigm human communication consists of\ntransferring representations from one mind to another. However, one finds that\nrepresentations appear in another's mind, without appearing in the intermediary\nlanguage. People communicate by mind reading it seems. Systems with speech\ninterfaces such as Alexa and Siri are of course common, but they are limited.\nRather than adding mind reading skills, we introduced a \"cheat\" that enabled\nour systems to fake it. The cheat is simple and only slightly interesting to\ncomputer scientists and not at all interesting to philosophers. However,\nreading about the enactivist idea that we \"directly perceive\" the intentions of\nothers, our cheat took on a new light and in this paper look again at how\nnatural language understanding might actually work between humans.", "published": "2021-11-11 12:46:00", "link": "http://arxiv.org/abs/2111.06179v5", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multilingual and Multilabel Emotion Recognition using Virtual\n  Adversarial Training", "abstract": "Virtual Adversarial Training (VAT) has been effective in learning robust\nmodels under supervised and semi-supervised settings for both computer vision\nand NLP tasks. However, the efficacy of VAT for multilingual and multilabel\ntext classification has not been explored before. In this work, we explore VAT\nfor multilabel emotion recognition with a focus on leveraging unlabelled data\nfrom different languages to improve the model performance. We perform extensive\nsemi-supervised experiments on SemEval2018 multilabel and multilingual emotion\nrecognition dataset and show performance gains of 6.2% (Arabic), 3.8% (Spanish)\nand 1.8% (English) over supervised learning with same amount of labelled data\n(10% of training data). We also improve the existing state-of-the-art by 7%,\n4.5% and 1% (Jaccard Index) for Spanish, Arabic and English respectively and\nperform probing experiments for understanding the impact of different layers of\nthe contextual models.", "published": "2021-11-11 12:47:44", "link": "http://arxiv.org/abs/2111.06181v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-level HyperNetworks for Hate Speech Detection", "abstract": "The massive spread of hate speech, hateful content targeted at specific\nsubpopulations, is a problem of critical social importance. Automated methods\nof hate speech detection typically employ state-of-the-art deep learning\n(DL)-based text classifiers-large pretrained neural language models of over 100\nmillion parameters, adapting these models to the task of hate speech detection\nusing relevant labeled datasets. Unfortunately, there are only a few public\nlabeled datasets of limited size that are available for this purpose. We make\nseveral contributions with high potential for advancing this state of affairs.\nWe present HyperNetworks for hate speech detection, a special class of DL\nnetworks whose weights are regulated by a small-scale auxiliary network. These\narchitectures operate at character-level, as opposed to word or subword-level,\nand are several orders of magnitude smaller compared to the popular DL\nclassifiers. We further show that training hate detection classifiers using\nadditional large amounts of automatically generated examples is beneficial in\ngeneral, yet this practice especially boosts the performance of the proposed\nHyperNetworks. We report the results of extensive experiments, assessing the\nperformance of multiple neural architectures on hate detection using five\npublic datasets. The assessed methods include the pretrained language models of\nBERT, RoBERTa, ALBERT, MobileBERT and CharBERT, a variant of BERT that\nincorporates character alongside subword embeddings. In addition to the\ntraditional setup of within-dataset evaluation, we perform cross-dataset\nevaluation experiments, testing the generalization of the various models in\nconditions of data shift. Our results show that the proposed HyperNetworks\nachieve performance that is competitive, and better in some cases, than these\npretrained language models, while being smaller by orders of magnitude.", "published": "2021-11-11 17:48:31", "link": "http://arxiv.org/abs/2111.06336v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AnswerSumm: A Manually-Curated Dataset and Pipeline for Answer\n  Summarization", "abstract": "Community Question Answering (CQA) fora such as Stack Overflow and Yahoo!\nAnswers contain a rich resource of answers to a wide range of community-based\nquestions. Each question thread can receive a large number of answers with\ndifferent perspectives. One goal of answer summarization is to produce a\nsummary that reflects the range of answer perspectives. A major obstacle for\nthis task is the absence of a dataset to provide supervision for producing such\nsummaries. Recent works propose heuristics to create such data, but these are\noften noisy and do not cover all answer perspectives present. This work\nintroduces a novel dataset of 4,631 CQA threads for answer summarization\ncurated by professional linguists. Our pipeline gathers annotations for all\nsubtasks of answer summarization, including relevant answer sentence selection,\ngrouping these sentences based on perspectives, summarizing each perspective,\nand producing an overall summary. We analyze and benchmark state-of-the-art\nmodels on these subtasks and introduce a novel unsupervised approach for\nmulti-perspective data augmentation that boosts summarization performance\naccording to automatic evaluation. Finally, we propose reinforcement learning\nrewards to improve factual consistency and answer coverage and analyze areas\nfor improvement.", "published": "2021-11-11 21:48:02", "link": "http://arxiv.org/abs/2111.06474v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kronecker Factorization for Preventing Catastrophic Forgetting in\n  Large-scale Medical Entity Linking", "abstract": "Multi-task learning is useful in NLP because it is often practically\ndesirable to have a single model that works across a range of tasks. In the\nmedical domain, sequential training on tasks may sometimes be the only way to\ntrain models, either because access to the original (potentially sensitive)\ndata is no longer available, or simply owing to the computational costs\ninherent to joint retraining. A major issue inherent to sequential learning,\nhowever, is catastrophic forgetting, i.e., a substantial drop in accuracy on\nprior tasks when a model is updated for a new task. Elastic Weight\nConsolidation is a recently proposed method to address this issue, but scaling\nthis approach to the modern large models used in practice requires making\nstrong independence assumptions about model parameters, limiting its\neffectiveness. In this work, we apply Kronecker Factorization--a recent\napproach that relaxes independence assumptions--to prevent catastrophic\nforgetting in convolutional and Transformer-based neural networks at scale. We\nshow the effectiveness of this technique on the important and illustrative task\nof medical entity linking across three datasets, demonstrating the capability\nof the technique to be used to make efficient updates to existing methods as\nnew medical data becomes available. On average, the proposed method reduces\ncatastrophic forgetting by 51% when using a BERT-based model, compared to a 27%\nreduction using standard Elastic Weight Consolidation, while maintaining\nspatial complexity proportional to the number of model parameters.", "published": "2021-11-11 01:51:01", "link": "http://arxiv.org/abs/2111.06012v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explainable Sentence-Level Sentiment Analysis for Amazon Product Reviews", "abstract": "In this paper, we conduct a sentence level sentiment analysis on the product\nreviews from Amazon and thorough analysis on the model interpretability. For\nthe sentiment analysis task, we use the BiLSTM model with attention mechanism.\nFor the study of interpretability, we consider the attention weights\ndistribution of single sentence and the attention weights of main aspect terms.\nThe model has an accuracy of up to 0.96. And we find that the aspect terms have\nthe same or even more attention weights than the sentimental words in\nsentences.", "published": "2021-11-11 06:35:42", "link": "http://arxiv.org/abs/2111.06070v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Robust Knowledge Graph Embedding via Multi-task Reinforcement\n  Learning", "abstract": "Nowadays, Knowledge graphs (KGs) have been playing a pivotal role in\nAI-related applications. Despite the large sizes, existing KGs are far from\ncomplete and comprehensive. In order to continuously enrich KGs, automatic\nknowledge construction and update mechanisms are usually utilized, which\ninevitably bring in plenty of noise. However, most existing knowledge graph\nembedding (KGE) methods assume that all the triple facts in KGs are correct,\nand project both entities and relations into a low-dimensional space without\nconsidering noise and knowledge conflicts. This will lead to low-quality and\nunreliable representations of KGs. To this end, in this paper, we propose a\ngeneral multi-task reinforcement learning framework, which can greatly\nalleviate the noisy data problem. In our framework, we exploit reinforcement\nlearning for choosing high-quality knowledge triples while filtering out the\nnoisy ones. Also, in order to take full advantage of the correlations among\nsemantically similar relations, the triple selection processes of similar\nrelations are trained in a collective way with multi-task learning. Moreover,\nwe extend popular KGE models TransE, DistMult, ConvE and RotatE with the\nproposed framework. Finally, the experimental validation shows that our\napproach is able to enhance existing KGE models and can provide more robust\nrepresentations of KGs in noisy scenarios.", "published": "2021-11-11 08:51:37", "link": "http://arxiv.org/abs/2111.06103v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training Cross-Lingual embeddings for Setswana and Sepedi", "abstract": "African languages still lag in the advances of Natural Language Processing\ntechniques, one reason being the lack of representative data, having a\ntechnique that can transfer information between languages can help mitigate\nagainst the lack of data problem. This paper trains Setswana and Sepedi\nmonolingual word vectors and uses VecMap to create cross-lingual embeddings for\nSetswana-Sepedi in order to do a cross-lingual transfer.\n  Word embeddings are word vectors that represent words as continuous floating\nnumbers where semantically similar words are mapped to nearby points in\nn-dimensional space. The idea of word embeddings is based on the distribution\nhypothesis that states, semantically similar words are distributed in similar\ncontexts (Harris, 1954).\n  Cross-lingual embeddings leverages monolingual embeddings by learning a\nshared vector space for two separately trained monolingual vectors such that\nwords with similar meaning are represented by similar vectors. In this paper,\nwe investigate cross-lingual embeddings for Setswana-Sepedi monolingual word\nvector. We use the unsupervised cross lingual embeddings in VecMap to train the\nSetswana-Sepedi cross-language word embeddings. We evaluate the quality of the\nSetswana-Sepedi cross-lingual word representation using a semantic evaluation\ntask. For the semantic similarity task, we translated the WordSim and SimLex\ntasks into Setswana and Sepedi. We release this dataset as part of this work\nfor other researchers. We evaluate the intrinsic quality of the embeddings to\ndetermine if there is improvement in the semantic representation of the word\nembeddings.", "published": "2021-11-11 14:26:15", "link": "http://arxiv.org/abs/2111.06230v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Identification of Fine-Grained Location Mentions in Crisis Tweets", "abstract": "Identification of fine-grained location mentions in crisis tweets is central\nin transforming situational awareness information extracted from social media\ninto actionable information. Most prior works have focused on identifying\ngeneric locations, without considering their specific types. To facilitate\nprogress on the fine-grained location identification task, we assemble two\ntweet crisis datasets and manually annotate them with specific location types.\nThe first dataset contains tweets from a mixed set of crisis events, while the\nsecond dataset contains tweets from the global COVID-19 pandemic. We\ninvestigate the performance of state-of-the-art deep learning models for\nsequence tagging on these datasets, in both in-domain and cross-domain\nsettings.", "published": "2021-11-11 17:48:03", "link": "http://arxiv.org/abs/2111.06334v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CU-UD: text-mining drug and chemical-protein interactions with ensembles\n  of BERT-based models", "abstract": "Identifying the relations between chemicals and proteins is an important text\nmining task. BioCreative VII track 1 DrugProt task aims to promote the\ndevelopment and evaluation of systems that can automatically detect relations\nbetween chemical compounds/drugs and genes/proteins in PubMed abstracts. In\nthis paper, we describe our submission, which is an ensemble system, including\nmultiple BERT-based language models. We combine the outputs of individual\nmodels using majority voting and multilayer perceptron. Our system obtained\n0.7708 in precision and 0.7770 in recall, for an F1 score of 0.7739,\ndemonstrating the effectiveness of using ensembles of BERT-based language\nmodels for automatically detecting relations between chemicals and proteins.\nOur code is available at https://github.com/bionlplab/drugprot_bcvii.", "published": "2021-11-11 13:55:21", "link": "http://arxiv.org/abs/2112.03004v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Chinese Multi-type Complex Questions Answering Dataset over Wikidata", "abstract": "Complex Knowledge Base Question Answering is a popular area of research in\nthe past decade. Recent public datasets have led to encouraging results in this\nfield, but are mostly limited to English and only involve a small number of\nquestion types and relations, hindering research in more realistic settings and\nin languages other than English. In addition, few state-of-the-art KBQA models\nare trained on Wikidata, one of the most popular real-world knowledge bases. We\npropose CLC-QuAD, the first large scale complex Chinese semantic parsing\ndataset over Wikidata to address these challenges. Together with the dataset,\nwe present a text-to-SPARQL baseline model, which can effectively answer\nmulti-type complex questions, such as factual questions, dual intent questions,\nboolean questions, and counting questions, with Wikidata as the background\nknowledge. We finally analyze the performance of SOTA KBQA models on this\ndataset and identify the challenges facing Chinese KBQA.", "published": "2021-11-11 07:39:16", "link": "http://arxiv.org/abs/2111.06086v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "From words to connections: Word use similarity as an honest signal\n  conducive to employees' digital communication", "abstract": "Bringing together considerations from three research trends (honest signals\nof collaboration, socio-semantic networks and homophily theory), we hypothesise\nthat word use similarity and having similar social network positions are linked\nwith the level of employees' digital interaction. To verify our hypothesis, we\nanalyse the communication of close to 1600 employees, interacting on the\nintranet communication forum of a large company. We study their social dynamics\nand the 'honest signals' that, in past research, proved to be conducive to\nemployees' engagement and collaboration. We find that word use similarity is\nthe main driver of interaction, much more than other language characteristics\nor similarity in network position. Our results suggest carefully choosing the\nlanguage according to the target audience and have practical implications for\nboth company managers and online community administrators. Understanding how to\nbetter use language could, for example, support the development of knowledge\nsharing practices or internal communication campaigns.", "published": "2021-11-11 10:32:33", "link": "http://arxiv.org/abs/2111.06133v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "I.2.7; H.0; J.4; H.4.0"], "primary_category": "cs.SI"}
{"title": "Self-Normalized Importance Sampling for Neural Language Modeling", "abstract": "To mitigate the problem of having to traverse over the full vocabulary in the\nsoftmax normalization of a neural language model, sampling-based training\ncriteria are proposed and investigated in the context of large vocabulary\nword-based neural language models. These training criteria typically enjoy the\nbenefit of faster training and testing, at a cost of slightly degraded\nperformance in terms of perplexity and almost no visible drop in word error\nrate. While noise contrastive estimation is one of the most popular choices,\nrecently we show that other sampling-based criteria can also perform well, as\nlong as an extra correction step is done, where the intended class posterior\nprobability is recovered from the raw model outputs. In this work, we propose\nself-normalized importance sampling. Compared to our previous work, the\ncriteria considered in this work are self-normalized and there is no need to\nfurther conduct a correction step. Through self-normalized language model\ntraining as well as lattice rescoring experiments, we show that our proposed\nself-normalized importance sampling is competitive in both research-oriented\nand production-oriented automatic speech recognition tasks.", "published": "2021-11-11 16:57:53", "link": "http://arxiv.org/abs/2111.06310v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Poisoning Knowledge Graph Embeddings via Relation Inference Patterns", "abstract": "We study the problem of generating data poisoning attacks against Knowledge\nGraph Embedding (KGE) models for the task of link prediction in knowledge\ngraphs. To poison KGE models, we propose to exploit their inductive abilities\nwhich are captured through the relationship patterns like symmetry, inversion\nand composition in the knowledge graph. Specifically, to degrade the model's\nprediction confidence on target facts, we propose to improve the model's\nprediction confidence on a set of decoy facts. Thus, we craft adversarial\nadditions that can improve the model's prediction confidence on decoy facts\nthrough different inference patterns. Our experiments demonstrate that the\nproposed poisoning attacks outperform state-of-art baselines on four KGE models\nfor two publicly available datasets. We also find that the symmetry pattern\nbased attacks generalize across all model-dataset combinations which indicates\nthe sensitivity of KGE models to this pattern.", "published": "2021-11-11 17:57:37", "link": "http://arxiv.org/abs/2111.06345v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Catalytic Role Of Noise And Necessity Of Inductive Biases In The\n  Emergence Of Compositional Communication", "abstract": "Communication is compositional if complex signals can be represented as a\ncombination of simpler subparts. In this paper, we theoretically show that\ninductive biases on both the training framework and the data are needed to\ndevelop a compositional communication. Moreover, we prove that compositionality\nspontaneously arises in the signaling games, where agents communicate over a\nnoisy channel. We experimentally confirm that a range of noise levels, which\ndepends on the model and the data, indeed promotes compositionality. Finally,\nwe provide a comprehensive study of this dependence and report results in terms\nof recently studied compositionality metrics: topographical similarity,\nconflict count, and context independence.", "published": "2021-11-11 21:15:21", "link": "http://arxiv.org/abs/2111.06464v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SynthBio: A Case Study in Human-AI Collaborative Curation of Text\n  Datasets", "abstract": "NLP researchers need more, higher-quality text datasets. Human-labeled\ndatasets are expensive to collect, while datasets collected via automatic\nretrieval from the web such as WikiBio are noisy and can include undesired\nbiases. Moreover, data sourced from the web is often included in datasets used\nto pretrain models, leading to inadvertent cross-contamination of training and\ntest sets. In this work we introduce a novel method for efficient dataset\ncuration: we use a large language model to provide seed generations to human\nraters, thereby changing dataset authoring from a writing task to an editing\ntask. We use our method to curate SynthBio - a new evaluation set for WikiBio -\ncomposed of structured attribute lists describing fictional individuals, mapped\nto natural language biographies. We show that our dataset of fictional\nbiographies is less noisy than WikiBio, and also more balanced with respect to\ngender and nationality.", "published": "2021-11-11 21:21:48", "link": "http://arxiv.org/abs/2111.06467v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards an Efficient Voice Identification Using Wav2Vec2.0 and HuBERT\n  Based on the Quran Reciters Dataset", "abstract": "Current authentication and trusted systems depend on classical and biometric\nmethods to recognize or authorize users. Such methods include audio speech\nrecognitions, eye, and finger signatures. Recent tools utilize deep learning\nand transformers to achieve better results. In this paper, we develop a deep\nlearning constructed model for Arabic speakers identification by using\nWav2Vec2.0 and HuBERT audio representation learning tools. The end-to-end\nWav2Vec2.0 paradigm acquires contextualized speech representations learnings by\nrandomly masking a set of feature vectors, and then applies a transformer\nneural network. We employ an MLP classifier that is able to differentiate\nbetween invariant labeled classes. We show several experimental results that\nsafeguard the high accuracy of the proposed model. The experiments ensure that\nan arbitrary wave signal for a certain speaker can be identified with 98% and\n97.1% accuracies in the cases of Wav2Vec2.0 and HuBERT, respectively.", "published": "2021-11-11 17:44:50", "link": "http://arxiv.org/abs/2111.06331v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Uformer: A Unet based dilated complex & real dual-path conformer network\n  for simultaneous speech enhancement and dereverberation", "abstract": "Complex spectrum and magnitude are considered as two major features of speech\nenhancement and dereverberation. Traditional approaches always treat these two\nfeatures separately, ignoring their underlying relationship. In this paper, we\npropose Uformer, a Unet based dilated complex & real dual-path conformer\nnetwork in both complex and magnitude domain for simultaneous speech\nenhancement and dereverberation. We exploit time attention (TA) and dilated\nconvolution (DC) to leverage local and global contextual information and\nfrequency attention (FA) to model dimensional information. These three\nsub-modules contained in the proposed dilated complex & real dual-path\nconformer module effectively improve the speech enhancement and dereverberation\nperformance. Furthermore, hybrid encoder and decoder are adopted to\nsimultaneously model the complex spectrum and magnitude and promote the\ninformation interaction between two domains. Encoder decoder attention is also\napplied to enhance the interaction between encoder and decoder. Our\nexperimental results outperform all SOTA time and complex domain models\nobjectively and subjectively. Specifically, Uformer reaches 3.6032 DNSMOS on\nthe blind test set of Interspeech 2021 DNS Challenge, which outperforms all\ntop-performed models. We also carry out ablation experiments to tease apart all\nproposed sub-modules that are most important.", "published": "2021-11-11 01:56:07", "link": "http://arxiv.org/abs/2111.06015v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Music Score Expansion with Variable-Length Infilling", "abstract": "In this paper, we investigate using the variable-length infilling (VLI)\nmodel, which is originally proposed to infill missing segments, to \"prolong\"\nexisting musical segments at musical boundaries. Specifically, as a case study,\nwe expand 20 musical segments from 12 bars to 16 bars, and examine the degree\nto which the VLI model preserves musical boundaries in the expanded results\nusing a few objective metrics, including the Register Histogram Similarity we\nnewly propose. The results show that the VLI model has the potential to address\nthe expansion task.", "published": "2021-11-11 04:27:48", "link": "http://arxiv.org/abs/2111.06046v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unsupervised Noise Adaptive Speech Enhancement by\n  Discriminator-Constrained Optimal Transport", "abstract": "This paper presents a novel discriminator-constrained optimal transport\nnetwork (DOTN) that performs unsupervised domain adaptation for speech\nenhancement (SE), which is an essential regression task in speech processing.\nThe DOTN aims to estimate clean references of noisy speech in a target domain,\nby exploiting the knowledge available from the source domain. The domain shift\nbetween training and testing data has been reported to be an obstacle to\nlearning problems in diverse fields. Although rich literature exists on\nunsupervised domain adaptation for classification, the methods proposed,\nespecially in regressions, remain scarce and often depend on additional\ninformation regarding the input data. The proposed DOTN approach tactically\nfuses the optimal transport (OT) theory from mathematical analysis with\ngenerative adversarial frameworks, to help evaluate continuous labels in the\ntarget domain. The experimental results on two SE tasks demonstrate that by\nextending the classical OT formulation, our proposed DOTN outperforms previous\nadversarial domain adaptation frameworks in a purely unsupervised manner.", "published": "2021-11-11 17:15:37", "link": "http://arxiv.org/abs/2111.06316v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MultiSV: Dataset for Far-Field Multi-Channel Speaker Verification", "abstract": "Motivated by unconsolidated data situation and the lack of a standard\nbenchmark in the field, we complement our previous efforts and present a\ncomprehensive corpus designed for training and evaluating text-independent\nmulti-channel speaker verification systems. It can be readily used also for\nexperiments with dereverberation, denoising, and speech enhancement. We tackled\nthe ever-present problem of the lack of multi-channel training data by\nutilizing data simulation on top of clean parts of the Voxceleb dataset. The\ndevelopment and evaluation trials are based on a retransmitted Voices Obscured\nin Complex Environmental Settings (VOiCES) corpus, which we modified to provide\nmulti-channel trials. We publish full recipes that create the dataset from\npublic sources as the MultiSV corpus, and we provide results with two of our\nmulti-channel speaker verification systems with neural network-based\nbeamforming based either on predicting ideal binary masks or the more recent\nConv-TasNet.", "published": "2021-11-11 20:55:58", "link": "http://arxiv.org/abs/2111.06458v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
