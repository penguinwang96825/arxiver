{"title": "AI Based Chatbot: An Approach of Utilizing On Customer Service\n  Assistance", "abstract": "Providing the best customer experience is one of the primary concerns for the\nfirms that are based online. The advancement of machine learning is\nrevolutionising the company's attitude towards the client through improving the\nservice quality by implementing chatbot solutions, which gives the user instant\nand satisfactory answers to their enquiries. The acceptance of this technology\nis increasing with the new improvements and efficiency of the chatbot system.\nThis thesis paper will cover the concept of chatbot system for the company, as\na use case we took AK traders Ltd. It involves the research work on various\nchatbot technologies available and based on research, use them to develop a\nchatbot system for the company. This system will work based on the text as a\nconversational agent that can interact with humans by natural language. The\nmain objective project is to develop the chatbot solution that could comply\nwith complex questions and logical output answers in a well-defined approach.\nThe ultimate goal is to give high-quality results (answers) based on user input\n(question). For the successful implementation of this project, we have\nundertaken an in-depth analysis of the various machine learning techniques\navailable and followed well-structured implementation to figure out the best\nsolution for the company. The primary concern of this project includes natural\nlanguage processing (NLP), machine learning and the vector space model (VSM).\nThe outcome of the project shows the problem-solving technique for the\nimplementation of the chatbot system for the company at a reasonable quality\nlevel", "published": "2022-06-18 00:59:10", "link": "http://arxiv.org/abs/2207.10573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Double-Graph Based Framework for Frame Semantic Parsing", "abstract": "Frame semantic parsing is a fundamental NLP task, which consists of three\nsubtasks: frame identification, argument identification and role\nclassification. Most previous studies tend to neglect relations between\ndifferent subtasks and arguments and pay little attention to ontological frame\nknowledge defined in FrameNet. In this paper, we propose a Knowledge-guided\nIncremental semantic parser with Double-graph (KID). We first introduce Frame\nKnowledge Graph (FKG), a heterogeneous graph containing both frames and FEs\n(Frame Elements) built on the frame knowledge so that we can derive\nknowledge-enhanced representations for frames and FEs. Besides, we propose\nFrame Semantic Graph (FSG) to represent frame semantic structures extracted\nfrom the text with graph structures. In this way, we can transform frame\nsemantic parsing into an incremental graph construction problem to strengthen\ninteractions between subtasks and relations between arguments. Our experiments\nshow that KID outperforms the previous state-of-the-art method by up to 1.7\nF1-score on two FrameNet datasets. Our code is availavle at\nhttps://github.com/PKUnlp-icler/KID.", "published": "2022-06-18 09:39:38", "link": "http://arxiv.org/abs/2206.09158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MANorm: A Normalization Dictionary for Moroccan Arabic Dialect Written\n  in Latin Script", "abstract": "Social media user-generated text is actually the main resource for many NLP\ntasks. This text however, does not follow the standard rules of writing.\nMoreover, the use of dialect such as Moroccan Arabic in written communications\nincreases further NLP tasks complexity. A dialect is a verbal language that\ndoes not have a standard orthography, which leads users to improvise spelling\nwhile writing. Thus, for the same word we can find multiple forms of\ntransliterations. Subsequently, it is mandatory to normalize these different\ntransliterations to one canonical word form. To reach this goal, we have\nexploited the powerfulness of word embedding models generated with a corpus of\nYouTube comments. Besides, using a Moroccan Arabic dialect dictionary that\nprovides the canonical forms, we have built a normalization dictionary that we\nrefer to as MANorm. We have conducted several experiments to demonstrate the\nefficiency of MANorm, which have shown its usefulness in dialect normalization.", "published": "2022-06-18 10:17:46", "link": "http://arxiv.org/abs/2206.09167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collocation2Text: Controllable Text Generation from Guide Phrases in\n  Russian", "abstract": "Large pre-trained language models are capable of generating varied and fluent\ntexts. Starting from the prompt, these models generate a narrative that can\ndevelop unpredictably. The existing methods of controllable text generation,\nwhich guide the narrative in the text in the user-specified direction, require\ncreating a training corpus and an additional time-consuming training procedure.\nThe paper proposes and investigates Collocation2Text, a plug-and-play method\nfor automatic controllable text generation in Russian, which does not require\nfine-tuning. The method is based on two interacting models: the autoregressive\nlanguage ruGPT-3 model and the autoencoding language ruRoBERTa model. The idea\nof the method is to shift the output distribution of the autoregressive model\naccording to the output distribution of the autoencoding model in order to\nensure a coherent transition of the narrative in the text towards the guide\nphrase, which can contain single words or collocations. The autoencoding model,\nwhich is able to take into account the left and right contexts of the token,\n\"tells\" the autoregressive model which tokens are the most and least logical at\nthe current generation step, increasing or decreasing the probabilities of the\ncorresponding tokens. The experiments on generating news articles using the\nproposed method showed its effectiveness for automatically generated fluent\ntexts which contain coherent transitions between user-specified phrases.", "published": "2022-06-18 17:10:08", "link": "http://arxiv.org/abs/2206.09248v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RuArg-2022: Argument Mining Evaluation", "abstract": "Argumentation analysis is a field of computational linguistics that studies\nmethods for extracting arguments from texts and the relationships between them,\nas well as building argumentation structure of texts. This paper is a report of\nthe organizers on the first competition of argumentation analysis systems\ndealing with Russian language texts within the framework of the Dialogue\nconference. During the competition, the participants were offered two tasks:\nstance detection and argument classification. A corpus containing 9,550\nsentences (comments on social media posts) on three topics related to the\nCOVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared,\nannotated, and used for training and testing. The system that won the first\nplace in both tasks used the NLI (Natural Language Inference) variant of the\nBERT architecture, automatic translation into English to apply a specialized\nBERT model, retrained on Twitter posts discussing COVID-19, as well as\nadditional masking of target entities. This system showed the following\nresults: for the stance detection task an F1-score of 0.6968, for the argument\nclassification task an F1-score of 0.7404. We hope that the prepared dataset\nand baselines will help to foster further research on argument mining for the\nRussian language.", "published": "2022-06-18 17:13:37", "link": "http://arxiv.org/abs/2206.09249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Argumentative Text Generation in Economic Domain", "abstract": "The development of large and super-large language models, such as GPT-3, T5,\nSwitch Transformer, ERNIE, etc., has significantly improved the performance of\ntext generation. One of the important research directions in this area is the\ngeneration of texts with arguments. The solution of this problem can be used in\nbusiness meetings, political debates, dialogue systems, for preparation of\nstudent essays. One of the main domains for these applications is the economic\nsphere. The key problem of the argument text generation for the Russian\nlanguage is the lack of annotated argumentation corpora. In this paper, we use\ntranslated versions of the Argumentative Microtext, Persuasive Essays and UKP\nSentential corpora to fine-tune RuBERT model. Further, this model is used to\nannotate the corpus of economic news by argumentation. Then the annotated\ncorpus is employed to fine-tune the ruGPT-3 model, which generates argument\ntexts. The results show that this approach improves the accuracy of the\nargument generation by more than 20 percentage points (63.2\\% vs. 42.5\\%)\ncompared to the original ruGPT-3 model.", "published": "2022-06-18 17:22:06", "link": "http://arxiv.org/abs/2206.09251v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Summarization of Russian Texts: Comparison of Extractive and\n  Abstractive Methods", "abstract": "The development of large and super-large language models, such as GPT-3, T5,\nSwitch Transformer, ERNIE, etc., has significantly improved the performance of\ntext generation. One of the important research directions in this area is the\ngeneration of texts with arguments. The solution of this problem can be used in\nbusiness meetings, political debates, dialogue systems, for preparation of\nstudent essays. One of the main domains for these applications is the economic\nsphere. The key problem of the argument text generation for the Russian\nlanguage is the lack of annotated argumentation corpora. In this paper, we use\ntranslated versions of the Argumentative Microtext, Persuasive Essays and UKP\nSentential corpora to fine-tune RuBERT model. Further, this model is used to\nannotate the corpus of economic news by argumentation. Then the annotated\ncorpus is employed to fine-tune the ruGPT-3 model, which generates argument\ntexts. The results show that this approach improves the accuracy of the\nargument generation by more than 20 percentage points (63.2% vs. 42.5%)\ncompared to the original ruGPT-3 model.", "published": "2022-06-18 17:28:04", "link": "http://arxiv.org/abs/2206.09253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Language Models Capture Graph Semantics? From Graphs to Language\n  Model and Vice-Versa", "abstract": "Knowledge Graphs are a great resource to capture semantic knowledge in terms\nof entities and relationships between the entities. However, current deep\nlearning models takes as input distributed representations or vectors. Thus,\nthe graph is compressed in a vectorized representation. We conduct a study to\nexamine if the deep learning model can compress a graph and then output the\nsame graph with most of the semantics intact. Our experiments show that\nTransformer models are not able to express the full semantics of the input\nknowledge graph. We find that this is due to the disparity between the\ndirected, relationship and type based information contained in a Knowledge\nGraph and the fully connected token-token undirected graphical interpretation\nof the Transformer Attention matrix.", "published": "2022-06-18 18:12:20", "link": "http://arxiv.org/abs/2206.09259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks", "abstract": "Current state-of-the-art vision-and-language models are evaluated on tasks\neither individually or in a multi-task setting, overlooking the challenges of\ncontinually learning (CL) tasks as they arrive. Existing CL benchmarks have\nfacilitated research on task adaptation and mitigating \"catastrophic\nforgetting\", but are limited to vision-only and language-only tasks. We present\nCLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL\nsetting, and to systematically evaluate how upstream continual learning can\nrapidly generalize to new multimodal and unimodal tasks. CLiMB includes\nimplementations of several CL algorithms and a modified Vision-Language\nTransformer (ViLT) model that can be deployed on both multimodal and unimodal\ntasks. We find that common CL methods can help mitigate forgetting during\nmultimodal task learning, but do not enable cross-task knowledge transfer. We\nenvision that CLiMB will facilitate research on a new class of CL algorithms\nfor this challenging multimodal setting.", "published": "2022-06-18 00:16:37", "link": "http://arxiv.org/abs/2206.09059v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoupled Federated Learning for ASR with Non-IID Data", "abstract": "Automatic speech recognition (ASR) with federated learning (FL) makes it\npossible to leverage data from multiple clients without compromising privacy.\nThe quality of FL-based ASR could be measured by recognition performance,\ncommunication and computation costs. When data among different clients are not\nindependently and identically distributed (non-IID), the performance could\ndegrade significantly. In this work, we tackle the non-IID issue in FL-based\nASR with personalized FL, which learns personalized models for each client.\nConcretely, we propose two types of personalized FL approaches for ASR.\nFirstly, we adapt the personalization layer based FL for ASR, which keeps some\nlayers locally to learn personalization models. Secondly, to reduce the\ncommunication and computation costs, we propose decoupled federated learning\n(DecoupleFL). On one hand, DecoupleFL moves the computation burden to the\nserver, thus decreasing the computation on clients. On the other hand,\nDecoupleFL communicates secure high-level features instead of model parameters,\nthus reducing communication cost when models are large. Experiments demonstrate\ntwo proposed personalized FL-based ASR approaches could reduce WER by 2.3% -\n3.4% compared with FedAvg. Among them, DecoupleFL has only 11.4% communication\nand 75% computation cost compared with FedAvg, which is also significantly less\nthan the personalization layer based FL.", "published": "2022-06-18 03:44:37", "link": "http://arxiv.org/abs/2206.09102v1", "categories": ["eess.AS", "cs.CL", "cs.DC", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NASTAR: Noise Adaptive Speech Enhancement with Target-Conditional\n  Resampling", "abstract": "For deep learning-based speech enhancement (SE) systems, the training-test\nacoustic mismatch can cause notable performance degradation. To address the\nmismatch issue, numerous noise adaptation strategies have been derived. In this\npaper, we propose a novel method, called noise adaptive speech enhancement with\ntarget-conditional resampling (NASTAR), which reduces mismatches with only one\nsample (one-shot) of noisy speech in the target environment. NASTAR uses a\nfeedback mechanism to simulate adaptive training data via a noise extractor and\na retrieval model. The noise extractor estimates the target noise from the\nnoisy speech, called pseudo-noise. The noise retrieval model retrieves relevant\nnoise samples from a pool of noise signals according to the noisy speech,\ncalled relevant-cohort. The pseudo-noise and the relevant-cohort set are\njointly sampled and mixed with the source speech corpus to prepare simulated\ntraining data for noise adaptation. Experimental results show that NASTAR can\neffectively use one noisy speech sample to adapt an SE model to a target\ncondition. Moreover, both the noise extractor and the noise retrieval model\ncontribute to model adaptation. To our best knowledge, NASTAR is the first work\nto perform one-shot noise adaptation through noise extraction and retrieval.", "published": "2022-06-18 00:15:48", "link": "http://arxiv.org/abs/2206.09058v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Semi-supervised Time Domain Target Speaker Extraction with Attention", "abstract": "In this work, we propose Exformer, a time-domain architecture for target\nspeaker extraction. It consists of a pre-trained speaker embedder network and a\nseparator network based on transformer encoder blocks. We study multiple\nmethods to combine speaker information with the input mixture, and the\nresulting Exformer architecture obtains superior extraction performance\ncompared to prior time-domain networks. Furthermore, we investigate a two-stage\nprocedure to train the model using mixtures without reference signals upon a\npre-trained supervised model. Experimental results show that the proposed\nsemi-supervised learning procedure improves the performance of the supervised\nbaselines.", "published": "2022-06-18 00:49:35", "link": "http://arxiv.org/abs/2206.09072v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks\n  on Speaker Verification Systems", "abstract": "An automatic speaker verification system aims to verify the speaker identity\nof a speech signal. However, a voice conversion system could manipulate a\nperson's speech signal to make it sound like another speaker's voice and\ndeceive the speaker verification system. Most countermeasures for voice\nconversion-based spoofing attacks are designed to discriminate bona fide speech\nfrom spoofed speech for speaker verification systems. In this paper, we\ninvestigate the problem of source speaker identification -- inferring the\nidentity of the source speaker given the voice converted speech. To perform\nsource speaker identification, we simply add voice-converted speech data with\nthe label of source speaker identity to the genuine speech dataset during\nspeaker embedding network training. Experimental results show the feasibility\nof source speaker identification when training and testing with converted\nspeeches from the same voice conversion model(s). In addition, our results\ndemonstrate that having more converted utterances from various voice conversion\nmodel for training helps improve the source speaker identification performance\non converted utterances from unseen voice conversion models.", "published": "2022-06-18 03:45:34", "link": "http://arxiv.org/abs/2206.09103v2", "categories": ["eess.AS", "cs.CR"], "primary_category": "eess.AS"}
{"title": "Redundancy Reduction Twins Network: A Training framework for\n  Multi-output Emotion Regression", "abstract": "In this paper, we propose the Redundancy Reduction Twins Network (RRTN), a\nredundancy reduction training framework that minimizes redundancy by measuring\nthe cross-correlation matrix between the outputs of the same network fed with\ndistorted versions of a sample and bringing it as close to the identity matrix\nas possible. RRTN also applies a new loss function, the Barlow Twins loss\nfunction, to help maximize the similarity of representations obtained from\ndifferent distorted versions of a sample. However, as the distribution of\nlosses can cause performance fluctuations in the network, we also propose the\nuse of a Restrained Uncertainty Weight Loss (RUWL) or joint training to\nidentify the best weights for the loss function. Our best approach on CNN14\nwith the proposed methodology obtains a CCC over emotion regression of 0.678 on\nthe ExVo Multi-task dev set, a 4.8% increase over a vanilla CNN 14 CCC of\n0.647, which achieves a significant difference at the 95% confidence interval\n(2-tailed).", "published": "2022-06-18 07:56:02", "link": "http://arxiv.org/abs/2206.09142v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Tackling Spoofing-Aware Speaker Verification with Multi-Model Fusion", "abstract": "Recent years have witnessed the extraordinary development of automatic\nspeaker verification (ASV). However, previous works show that state-of-the-art\nASV models are seriously vulnerable to voice spoofing attacks, and the recently\nproposed high-performance spoofing countermeasure (CM) models only focus solely\non the standalone anti-spoofing tasks, and ignore the subsequent speaker\nverification process. How to integrate the CM and ASV together remains an open\nquestion. A spoofing aware speaker verification (SASV) challenge has recently\ntaken place with the argument that better performance can be delivered when\nboth CM and ASV subsystems are optimized jointly. Under the challenge's\nscenario, the integrated systems proposed by the participants are required to\nreject both impostor speakers and spoofing attacks from target speakers, which\nintuitively and effectively matches the expectation of a reliable,\nspoofing-robust ASV system. This work focuses on fusion-based SASV solutions\nand proposes a multi-model fusion framework to leverage the power of multiple\nstate-of-the-art ASV and CM models. The proposed framework vastly improves the\nSASV-EER from 8.75% to 1.17\\%, which is 86% relative improvement compared to\nthe best baseline system in the SASV challenge.", "published": "2022-06-18 06:41:06", "link": "http://arxiv.org/abs/2206.09131v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
