{"title": "DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture", "abstract": "We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual\nbenchmark centered exclusively on Indian culture, designed to evaluate the\ncultural understanding of generative AI systems. Unlike existing benchmarks\nwith a generic or global scope, DRISHTIKON offers deep, fine-grained coverage\nacross India's diverse regions, spanning 15 languages, covering all states and\nunion territories, and incorporating over 64,000 aligned text-image pairs. The\ndataset captures rich cultural themes including festivals, attire, cuisines,\nart forms, and historical heritage amongst many more. We evaluate a wide range\nof vision-language models (VLMs), including open-source small and large models,\nproprietary systems, reasoning-specialized VLMs, and Indic-focused models,\nacross zero-shot and chain-of-thought settings. Our results expose key\nlimitations in current models' ability to reason over culturally grounded,\nmultimodal inputs, particularly for low-resource languages and less-documented\ntraditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a\nrobust testbed to advance culturally aware, multimodally competent language\ntechnologies.", "published": "2025-09-23 17:40:43", "link": "http://arxiv.org/abs/2509.19274v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "abstract": "Intent classification models have made a lot of progress in recent years.\nHowever, previous studies primarily focus on high-resource languages datasets,\nwhich results in a gap for low-resource languages and for regions with a high\nrate of illiterate people where languages are more spoken than read or written.\nThis is the case in Senegal, for example, where Wolof is spoken by around 90\\%\nof the population, with an illiteracy rate of 42\\% for the country. Wolof is\nactually spoken by more than 10 million people in West African region. To\ntackle such limitations, we release a Wolof Intent Classification Dataset\n(WolBanking77), for academic research in intent classification. WolBanking77\ncurrently contains 9,791 text sentences in the banking domain and more than 4\nhours of spoken sentences. Experiments on various baselines are conducted in\nthis work, including text and voice state-of-the-art models. The results are\nvery promising on this current dataset. This paper also provides detailed\nanalyses of the contents of the data. We report baseline f1-score and word\nerror rate metrics respectively on NLP and ASR models trained on WolBanking77\ndataset and also comparisons between models. We plan to share and conduct\ndataset maintenance, updates and to release open-source code.", "published": "2025-09-23 17:34:10", "link": "http://arxiv.org/abs/2509.19271v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data", "abstract": "Automatic Speech Recognition (ASR) for low-resource languages like Slovak is\nhindered by the scarcity of training data. To address this, we introduce\nSloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of\nspeech from parliamentary proceedings. We developed a robust processing\npipeline to align and segment long-form recordings into clean, 30-second\naudio-transcript pairs suitable for model training. We use this dataset to\nfine-tune several OpenAI Whisper models (small, medium, large-v3, and\nlarge-v3-turbo), achieving significant Word Error Rate (WER) reductions on\nstandard Slovak benchmarks like Common Voice and FLEURS. For instance, the\nfine-tuned Whisper-small model's WER dropped by up to 70\\%, approaching the\nbaseline performance of the much larger Whisper-large-v3 model. To foster\nfuture research in low-resource speech recognition, we publicly release the\ncomplete SloPalSpeech dataset, the fully segmented transcripts (60 million\nwords), and all our fine-tuned models.", "published": "2025-09-23 17:33:57", "link": "http://arxiv.org/abs/2509.19270v1", "categories": ["cs.CL", "cs.AI", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Extracting Conceptual Spaces from LLMs Using Prototype Embeddings", "abstract": "Conceptual spaces represent entities and concepts using cognitively\nmeaningful dimensions, typically referring to perceptual features. Such\nrepresentations are widely used in cognitive science and have the potential to\nserve as a cornerstone for explainable AI. Unfortunately, they have proven\nnotoriously difficult to learn, although recent LLMs appear to capture the\nrequired perceptual features to a remarkable extent. Nonetheless, practical\nmethods for extracting the corresponding conceptual spaces are currently still\nlacking. While various methods exist for extracting embeddings from LLMs,\nextracting conceptual spaces also requires us to encode the underlying\nfeatures. In this paper, we propose a strategy in which features (e.g.\nsweetness) are encoded by embedding the description of a corresponding\nprototype (e.g. a very sweet food). To improve this strategy, we fine-tune the\nLLM to align the prototype embeddings with the corresponding conceptual space\ndimensions. Our empirical analysis finds this approach to be highly effective.", "published": "2025-09-23 17:33:30", "link": "http://arxiv.org/abs/2509.19269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World", "abstract": "Large language models (LLMs) often reflect Western-centric biases, limiting\ntheir effectiveness in diverse cultural contexts. Although some work has\nexplored cultural alignment, the potential for cross-cultural transfer, using\nalignment in one culture to improve performance in others, remains\nunderexplored. This paper investigates cross-cultural transfer of commonsense\nreasoning in the Arab world, where linguistic and historical similarities\ncoexist with local cultural differences. Using a culturally grounded\ncommonsense reasoning dataset covering 13 Arab countries, we evaluate\nlightweight alignment methods such as in-context learning and\ndemonstration-based reinforcement (DITTO), alongside baselines like supervised\nfine-tuning and direct preference optimization. Our results show that merely 12\nculture-specific examples from one country can improve performance in others by\n10\\% on average, within multilingual models. In addition, we demonstrate that\nout-of-culture demonstrations from Indonesia and US contexts can match or\nsurpass in-culture alignment for MCQ reasoning, highlighting cultural\ncommonsense transferability beyond the Arab world. These findings demonstrate\nthat efficient cross-cultural alignment is possible and offer a promising\napproach to adapt LLMs to low-resource cultural settings.", "published": "2025-09-23 17:24:14", "link": "http://arxiv.org/abs/2509.19265v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Reinforcement Learning on Pre-Training Data", "abstract": "The growing disparity between the exponential scaling of computational\nresources and the finite growth of high-quality text data now constrains\nconventional scaling approaches for large language models (LLMs). To address\nthis challenge, we introduce Reinforcement Learning on Pre-Training data\n(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast\nto prior approaches that scale training primarily through supervised learning,\nRLPT enables the policy to autonomously explore meaningful trajectories to\nlearn from pre-training data and improve its capability through reinforcement\nlearning (RL). While existing RL strategies such as reinforcement learning from\nhuman feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)\nrely on human annotation for reward construction, RLPT eliminates this\ndependency by deriving reward signals directly from pre-training data.\nSpecifically, it adopts a next-segment reasoning objective, rewarding the\npolicy for accurately predicting subsequent text segments conditioned on the\npreceding context. This formulation allows RL to be scaled on pre-training\ndata, encouraging the exploration of richer trajectories across broader\ncontexts and thereby fostering more generalizable reasoning skills. Extensive\nexperiments on both general-domain and mathematical reasoning benchmarks across\nmultiple models validate the effectiveness of RLPT. For example, when applied\nto Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,\n$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and\nAIME25, respectively. The results further demonstrate favorable scaling\nbehavior, suggesting strong potential for continued gains with more compute. In\naddition, RLPT provides a solid foundation, extending the reasoning boundaries\nof LLMs and enhancing RLVR performance.", "published": "2025-09-23 17:10:40", "link": "http://arxiv.org/abs/2509.19249v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation", "abstract": "We present ChiReSSD, a speech reconstruction framework that preserves\nchildren speaker's identity while suppressing mispronunciations. Unlike prior\napproaches trained on healthy adult speech, ChiReSSD adapts to the voices of\nchildren with speech sound disorders (SSD), with particular emphasis on pitch\nand prosody. We evaluate our method on the STAR dataset and report substantial\nimprovements in lexical accuracy and speaker identity preservation.\nFurthermore, we automatically predict the phonetic content in the original and\nreconstructed pairs, where the proportion of corrected consonants is comparable\nto the percentage of correct consonants (PCC), a clinical speech assessment\nmetric. Our experiments show Pearson correlation of 0.63 between automatic and\nhuman expert annotations, highlighting the potential to reduce the manual\ntranscription burden. In addition, experiments on the TORGO dataset demonstrate\neffective generalization for reconstructing adult dysarthric speech. Our\nresults indicate that disentangled, style-based TTS reconstruction can provide\nidentity-preserving speech across diverse clinical populations.", "published": "2025-09-23 16:53:07", "link": "http://arxiv.org/abs/2509.19231v1", "categories": ["cs.SD", "cs.AI", "cs.CL"], "primary_category": "cs.SD"}
{"title": "CompLLM: Compression for Long Context Q&A", "abstract": "Large Language Models (LLMs) face significant computational challenges when\nprocessing long contexts due to the quadratic complexity of self-attention.\nWhile soft context compression methods, which map input text to smaller latent\nrepresentations, have shown promise, their real-world adoption is limited.\nExisting techniques typically compress the context as a single unit, which\nleads to quadratic compression complexity and an inability to reuse\ncomputations across queries with overlapping contexts. In this work, we\nintroduce CompLLM, a soft compression technique designed for practical\ndeployment. Instead of processing the context holistically, CompLLM divides it\ninto segments and compresses each one independently. This simple design choice\nyields three critical properties: efficiency, as the compression step scales\nlinearly with the context length; scalability, enabling models trained on short\nsequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and\nreusability, allowing compressed segments to be cached and reused across\ndifferent queries. Our experiments show that with a 2x compression rate, at\nhigh context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x\nand reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance\ncomparable to that obtained with the uncompressed context, and even surpasses\nit on very long sequences, demonstrating its effectiveness and practical\nutility.", "published": "2025-09-23 16:49:43", "link": "http://arxiv.org/abs/2509.19228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction", "abstract": "Attention-based models have become the leading approach in modeling medical\nlanguage for Natural Language Processing (NLP) in clinical notes. These models\noutperform traditional techniques by effectively capturing contextual rep-\nresentations of language. In this research a comparative analysis is done\namongst pre- trained attention based models namely Bert Base, BioBert, two\nvariations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task\nrelated to Electronic Health Record (EHR) information extraction. The tasks\nfrom Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges\n(n2c2) are considered for this comparison, with the Contextualized Medication\nEvent Dataset (CMED) given for these task. CMED is a dataset of unstructured\nEHRs and annotated notes that contain task relevant information about the EHRs.\nThe goal of the challenge is to develop effective solutions for extracting\ncontextual information related to patient medication events from EHRs using\ndata driven methods. Each pre-trained model is fine-tuned and applied on CMED\nto perform medication extraction, medical event detection, and\nmulti-dimensional medication event context classification. Pro- cessing methods\nare also detailed for breaking down EHRs for compatibility with the applied\nmodels. Performance analysis has been carried out using a script based on\nconstructing medical terms from the evaluation portion of CMED with metrics\nincluding recall, precision, and F1-Score. The results demonstrate that models\npre-trained on clinical data are more effective in detecting medication and\nmedication events, but Bert Base, pre- trained on general domain data showed to\nbe the most effective for classifying the context of events related to\nmedications.", "published": "2025-09-23 16:48:28", "link": "http://arxiv.org/abs/2509.19224v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Steering Multimodal Large Language Models Decoding for Context-Aware Safety", "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nreal-world applications, yet their ability to make context-aware safety\ndecisions remains limited. Existing methods often fail to balance\noversensitivity (unjustified refusals of benign queries) and undersensitivity\n(missed detection of visually grounded risks), leaving a persistent gap in\nsafety alignment. To address this issue, we introduce Safety-aware Contrastive\nDecoding (SafeCoDe), a lightweight and model-agnostic decoding framework that\ndynamically adjusts token generation based on multimodal context. SafeCoDe\noperates in two stages: (1) a contrastive decoding mechanism that highlights\ntokens sensitive to visual context by contrasting real and Gaussian-noised\nimages, and (2) a global-aware token modulation strategy that integrates\nscene-level reasoning with token-level adjustment to adapt refusals according\nto the predicted safety verdict. Extensive experiments across diverse MLLM\narchitectures and safety benchmarks, covering undersensitivity,\noversensitivity, and general safety evaluations, show that SafeCoDe\nconsistently improves context-sensitive refusal behaviors while preserving\nmodel helpfulness.", "published": "2025-09-23 16:32:25", "link": "http://arxiv.org/abs/2509.19212v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Online Process Reward Leanring for Agentic Reinforcement Learning", "abstract": "Large language models (LLMs) are increasingly trained with reinforcement\nlearning (RL) as autonomous agents that reason and act over long horizons in\ninteractive environments.\n  However, sparse and sometimes unverifiable rewards make temporal credit\nassignment extremely challenging.\n  Recent work attempts to integrate process supervision into agent learning but\nsuffers from biased annotation, reward hacking, high-variance from overly\nfine-grained signals or failtures when state overlap is rare.\n  We therefore introduce Online Process Reward Learning (OPRL), a general\ncredit-assignment strategy for agentic RL that integrates seamlessly with\nstandard on-policy algorithms without relying on additional rollouts or\nexplicit step labels.\n  In OPRL, we optimize an implicit process reward model (PRM) alternately with\nthe agent's policy to transform trajectory preferences into implicit step\nrewards through a trajectory-based DPO objective.\n  These step rewards are then used to compute step-level advantages, which are\ncombined with episode-level advantages from outcome rewards for policy update,\ncreating a self-reinforcing loop.\n  Theoretical findings guarantee that the learned step rewards are consistent\nwith trajectory preferences and act as potential-based shaping rewards,\nproviding bounded gradients to stabilize training.\n  Empirically, we evaluate OPRL on three distinct agent benmarks, including\nWebShop and VisualSokoban, as well as open-ended social interactions with\nunverfiable rewards in SOTOPIA.\n  Crucially, OPRL shows superior performance over frontier LLMs and strong RL\nbaselines across domains, achieving state-of-the-art results with higher\nsample-efficiency and lower variance during training.\n  Further analysis also demonstrates the efficient exploration by OPRL using\nfewer actions, underscoring its potential for agentic learning in real-world\nscenarios.", "published": "2025-09-23 16:15:42", "link": "http://arxiv.org/abs/2509.19199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Soft Tokens, Hard Truths", "abstract": "The use of continuous instead of discrete tokens during the Chain-of-Thought\n(CoT) phase of reasoning LLMs has garnered attention recently, based on the\nintuition that a continuous mixture of discrete tokens could simulate a\nsuperposition of several reasoning paths simultaneously. Theoretical results\nhave formally proven that continuous tokens have much greater expressivity and\ncan solve specific problems more efficiently. However, practical use of\ncontinuous tokens has been limited by strong training difficulties: previous\nworks either just use continuous tokens at inference time on a pre-trained\ndiscrete-token model, or must distill the continuous CoT from ground-truth\ndiscrete CoTs and face computational costs that limit the CoT to very few\ntokens.\n  This is the first work introducing a scalable method to learn continuous CoTs\nvia reinforcement learning (RL), without distilling from reference discrete\nCoTs. We use \"soft\" tokens: mixtures of tokens together with noise on the input\nembedding to provide RL exploration. Computational overhead is minimal,\nenabling us to learn continuous CoTs with hundreds of tokens. On math reasoning\nbenchmarks with Llama and Qwen models up to 8B, training with continuous CoTs\nmatch discrete-token CoTs for pass@1 and surpass them for pass@32, showing\ngreater CoT diversity. In systematic comparisons, the best-performing scenario\nis to train with continuous CoT tokens then use discrete tokens for inference,\nmeaning the \"soft\" models can be deployed in a standard way. Finally, we show\ncontinuous CoT RL training better preserves the predictions of the base model\non out-of-domain tasks, thus providing a softer touch to the base model.", "published": "2025-09-23 15:43:47", "link": "http://arxiv.org/abs/2509.19170v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring AI \"Slop\" in Text", "abstract": "AI \"slop\" is an increasingly popular term used to describe low-quality\nAI-generated text, but there is currently no agreed upon definition of this\nterm nor a means to measure its occurrence. In this work, we develop a taxonomy\nof \"slop\" through interviews with experts in NLP, writing, and philosophy, and\npropose a set of interpretable dimensions for its assessment in text. Through\nspan-level annotation, we find that binary \"slop\" judgments are (somewhat)\nsubjective, but such determinations nonetheless correlate with latent\ndimensions such as coherence and relevance. Our framework can be used to\nevaluate AI-generated text in both detection and binary preference tasks,\npotentially offering new insights into the linguistic and stylistic factors\nthat contribute to quality judgments.", "published": "2025-09-23 15:41:19", "link": "http://arxiv.org/abs/2509.19163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anecdoctoring: Automated Red-Teaming Across Language and Place", "abstract": "Disinformation is among the top risks of generative artificial intelligence\n(AI) misuse. Global adoption of generative AI necessitates red-teaming\nevaluations (i.e., systematic adversarial probing) that are robust across\ndiverse languages and cultures, but red-teaming datasets are commonly US- and\nEnglish-centric. To address this gap, we propose \"anecdoctoring\", a novel\nred-teaming approach that automatically generates adversarial prompts across\nlanguages and cultures. We collect misinformation claims from fact-checking\nwebsites in three languages (English, Spanish, and Hindi) and two geographies\n(US and India). We then cluster individual claims into broader narratives and\ncharacterize the resulting clusters with knowledge graphs, with which we\naugment an attacker LLM. Our method produces higher attack success rates and\noffers interpretability benefits relative to few-shot prompting. Results\nunderscore the need for disinformation mitigations that scale globally and are\ngrounded in real-world adversarial misuse.", "published": "2025-09-23 15:26:13", "link": "http://arxiv.org/abs/2509.19143v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering", "abstract": "The rapid growth of scientific literature demands efficient methods to\norganize and synthesize research findings. Existing taxonomy construction\nmethods, leveraging unsupervised clustering or direct prompting of large\nlanguage models (LLMs), often lack coherence and granularity. We propose a\nnovel context-aware hierarchical taxonomy generation framework that integrates\nLLM-guided multi-aspect encoding with dynamic clustering. Our method leverages\nLLMs to identify key aspects of each paper (e.g., methodology, dataset,\nevaluation) and generates aspect-specific paper summaries, which are then\nencoded and clustered along each aspect to form a coherent hierarchy. In\naddition, we introduce a new evaluation benchmark of 156 expert-crafted\ntaxonomies encompassing 11.6k papers, providing the first naturally annotated\ndataset for this task. Experimental results demonstrate that our method\nsignificantly outperforms prior approaches, achieving state-of-the-art\nperformance in taxonomy coherence, granularity, and interpretability.", "published": "2025-09-23 15:12:58", "link": "http://arxiv.org/abs/2509.19125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human-Annotated NER Dataset for the Kyrgyz Language", "abstract": "We introduce KyrgyzNER, the first manually annotated named entity recognition\ndataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG\nnews portal, the dataset contains 10,900 sentences and 39,075 entity mentions\nacross 27 named entity classes. We show our annotation scheme, discuss the\nchallenges encountered in the annotation process, and present the descriptive\nstatistics. We also evaluate several named entity recognition models, including\ntraditional sequence labeling approaches based on conditional random fields and\nstate-of-the-art multilingual transformer-based models fine-tuned on our\ndataset. While all models show difficulties with rare entity categories, models\nsuch as the multilingual RoBERTa variant pretrained on a large corpus across\nmany languages achieve a promising balance between precision and recall. These\nfindings emphasize both the challenges and opportunities of using multilingual\npretrained models for processing languages with limited resources. Although the\nmultilingual RoBERTa model performed best, other multilingual models yielded\ncomparable results. This suggests that future work exploring more granular\nannotation schemes may offer deeper insights for Kyrgyz language processing\npipelines evaluation.", "published": "2025-09-23 14:56:10", "link": "http://arxiv.org/abs/2509.19109v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are most sentences unique? An empirical examination of Chomskyan claims", "abstract": "A repeated claim in linguistics is that the majority of linguistic utterances\nare unique. For example, Pinker (1994: 10), summarizing an argument by Noam\nChomsky, states that \"virtually every sentence that a person utters or\nunderstands is a brand-new combination of words, appearing for the first time\nin the history of the universe.\" With the increased availability of large\ncorpora, this is a claim that can be empirically investigated. The current\npaper addresses the question by using the NLTK Python library to parse corpora\nof different genres, providing counts of exact string matches in each. Results\nshow that while completely unique sentences are often the majority of corpora,\nthis is highly constrained by genre, and that duplicate sentences are not an\ninsignificant part of any individual corpus.", "published": "2025-09-23 14:54:19", "link": "http://arxiv.org/abs/2509.19108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering", "abstract": "Personalization is essential for adapting question answering (QA) systems to\nuser-specific information needs, thereby improving both accuracy and user\nsatisfaction. However, personalized QA remains relatively underexplored due to\nchallenges such as inferring preferences from long, noisy, and implicit\ncontexts, and generating responses that are simultaneously correct,\ncontextually appropriate, and aligned with user expectations and background\nknowledge. To address these challenges, we propose Pathways of Thoughts (PoT),\nan inference-stage method that applies to any large language model (LLM)\nwithout requiring task-specific fine-tuning. The approach models the reasoning\nof an LLM as an iterative decision process, where the model dynamically selects\namong cognitive operations such as reasoning, revision, personalization, and\nclarification. This enables exploration of multiple reasoning trajectories,\nproducing diverse candidate responses that capture different perspectives. PoT\nthen aggregates and reweights these candidates according to inferred user\npreferences, yielding a final personalized response that benefits from the\ncomplementary strengths of diverse reasoning paths. Experiments on the LaMP-QA\nbenchmark for personalized QA show that PoT consistently outperforms\ncompetitive baselines, achieving up to a 13.1% relative improvement. Human\nevaluation corroborates these results, with annotators preferring outputs from\nPoT in 66% of cases and reporting ties in only 15% of cases.", "published": "2025-09-23 14:44:46", "link": "http://arxiv.org/abs/2509.19094v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning", "abstract": "Medical imaging provides critical evidence for clinical diagnosis, treatment\nplanning, and surgical decisions, yet most existing imaging models are narrowly\nfocused and require multiple specialized networks, limiting their\ngeneralization. Although large-scale language and multimodal models exhibit\nstrong reasoning and multi-task capabilities, real-world clinical applications\ndemand precise visual grounding, multimodal integration, and chain-of-thought\nreasoning. We introduce Citrus-V, a multimodal medical foundation model that\ncombines image analysis with textual reasoning. The model integrates detection,\nsegmentation, and multimodal chain-of-thought reasoning, enabling pixel-level\nlesion localization, structured report generation, and physician-like\ndiagnostic inference in a single framework. We propose a novel multimodal\ntraining approach and release a curated open-source data suite covering\nreasoning, detection, segmentation, and document understanding tasks.\nEvaluations demonstrate that Citrus-V outperforms existing open-source medical\nmodels and expert-level imaging systems across multiple benchmarks, delivering\na unified pipeline from visual grounding to clinical reasoning and supporting\nprecise lesion quantification, automated reporting, and reliable second\nopinions.", "published": "2025-09-23 14:42:31", "link": "http://arxiv.org/abs/2509.19090v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?", "abstract": "This paper presents ColorBlindnessEval, a novel benchmark designed to\nevaluate the robustness of Vision-Language Models (VLMs) in visually\nadversarial scenarios inspired by the Ishihara color blindness test. Our\ndataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with\nvarying color combinations, challenging VLMs to accurately recognize numerical\ninformation embedded in complex visual patterns. We assess 9 VLMs using Yes/No\nand open-ended prompts and compare their performance with human participants.\nOur experiments reveal limitations in the models' ability to interpret numbers\nin adversarial contexts, highlighting prevalent hallucination issues. These\nfindings underscore the need to improve the robustness of VLMs in complex\nvisual environments. ColorBlindnessEval serves as a valuable tool for\nbenchmarking and improving the reliability of VLMs in real-world applications\nwhere accuracy is critical.", "published": "2025-09-23 14:33:21", "link": "http://arxiv.org/abs/2509.19070v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus", "abstract": "Over the past decade, Computational Linguistics (CL) and Natural Language\nProcessing (NLP) have evolved rapidly, especially with the advent of\nTransformer-based Large Language Models (LLMs). This shift has transformed\nresearch goals and priorities, from Lexical and Semantic Resources to Language\nModelling and Multimodality. In this study, we track the research trends of the\nItalian CL and NLP community through an analysis of the contributions to\nCLiC-it, arguably the leading Italian conference in the field. We compile the\nproceedings from the first 10 editions of the CLiC-it conference (from 2014 to\n2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its\nmetadata, including author provenance, gender, affiliations, and more, as well\nas the content of the papers themselves, which address various topics. Our goal\nis to provide the Italian and international research communities with valuable\ninsights into emerging trends and key developments over time, supporting\ninformed decisions and future directions in the field.", "published": "2025-09-23 14:06:09", "link": "http://arxiv.org/abs/2509.19033v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Investigating Test-Time Scaling with Reranking for Machine Translation", "abstract": "Scaling model parameters has become the de facto strategy for improving NLP\nsystems, but it comes with substantial computational costs. Test-Time Scaling\n(TTS) offers an alternative by allocating more computation at inference:\ngenerating multiple candidates and selecting the best. While effective in tasks\nsuch as mathematical reasoning, TTS has not been systematically explored for\nmachine translation (MT). In this paper, we present the first systematic study\nof TTS for MT, investigating a simple but practical best-of-N framework on\nWMT24 benchmarks. Our experiments cover six high-resource and one low-resource\nlanguage pairs, five model sizes (3B-72B), and various TTS compute budget (N up\nto 1024). Our results show that a) For high-resource languages, TTS generally\nimproves translation quality according to multiple neural MT evaluation\nmetrics, and our human evaluation confirms these gains; b) Augmenting smaller\nmodels with large $N$ can match or surpass larger models at $N{=}1$ with more\ncompute cost; c) Under fixed compute budgets, larger models are typically more\nefficient, and TTS can degrade quality due to metric blind spots in\nlow-resource cases.", "published": "2025-09-23 13:58:16", "link": "http://arxiv.org/abs/2509.19020v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction", "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced video understanding capabilities, opening new\npossibilities for practical applications. Yet current video benchmarks focus\nlargely on indoor scenes or short-range outdoor activities, leaving the\nchallenges associated with long-distance travel largely unexplored. Mastering\nextended geospatial-temporal trajectories is critical for next-generation\nMLLMs, underpinning real-world tasks such as embodied-AI planning and\nnavigation. To bridge this gap, we present VIR-Bench, a novel benchmark\nconsisting of 200 travel videos that frames itinerary reconstruction as a\nchallenging task designed to evaluate and push forward MLLMs'\ngeospatial-temporal intelligence. Experimental results reveal that\nstate-of-the-art MLLMs, including proprietary ones, struggle to achieve high\nscores, underscoring the difficulty of handling videos that span extended\nspatial and temporal scales. Moreover, we conduct an in-depth case study in\nwhich we develop a prototype travel-planning agent that leverages the insights\ngained from VIR-Bench. The agent's markedly improved itinerary recommendations\nverify that our evaluation protocol not only benchmarks models effectively but\nalso translates into concrete performance gains in user-facing applications.", "published": "2025-09-23 13:46:31", "link": "http://arxiv.org/abs/2509.19002v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment", "abstract": "End-to-End Speech Translation (E2E-ST) is the task of translating source\nspeech directly into target text bypassing the intermediate transcription step.\nThe representation discrepancy between the speech and text modalities has\nmotivated research on what is known as bridging the modality gap.\nState-of-the-art methods addressed this by aligning speech and text\nrepresentations on the word or token level. Unfortunately, this requires an\nalignment tool that is not available for all languages. Although this issue has\nbeen addressed by aligning speech and text embeddings using nearest-neighbor\nsimilarity search, it does not lead to accurate alignments. In this work, we\nadapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during\ntraining. Our experiments demonstrate the effectiveness of our method in\nbridging the modality gap in E2E-ST. Compared to previous work, our method\nproduces more accurate alignments and achieves comparable E2E-ST results while\nbeing significantly faster. Furthermore, our method outperforms previous work\nin low resource settings on 5 out of 6 language directions.", "published": "2025-09-23 13:37:15", "link": "http://arxiv.org/abs/2509.18987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass", "abstract": "Recent works in Natural Language Inference (NLI) and related tasks, such as\nautomated fact-checking, employ atomic fact decomposition to enhance\ninterpretability and robustness. For this, existing methods rely on\nresource-intensive generative large language models (LLMs) to perform\ndecomposition. We propose JEDI, an encoder-only architecture that jointly\nperforms extractive atomic fact decomposition and interpretable inference\nwithout requiring generative models during inference. To facilitate training,\nwe produce a large corpus of synthetic rationales covering multiple NLI\nbenchmarks. Experimental results demonstrate that JEDI achieves competitive\naccuracy in distribution and significantly improves robustness out of\ndistribution and in adversarial settings over models based solely on extractive\nrationale supervision. Our findings show that interpretability and robust\ngeneralization in NLI can be realized using encoder-only architectures and\nsynthetic rationales. Code and data available at https://jedi.nicpopovic.com", "published": "2025-09-23 11:30:42", "link": "http://arxiv.org/abs/2509.18901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diversity Boosts AI-Generated Text Detection", "abstract": "Detecting AI-generated text is an increasing necessity to combat misuse of\nLLMs in education, business compliance, journalism, and social media, where\nsynthetic fluency can mask misinformation or deception. While prior detectors\noften rely on token-level likelihoods or opaque black-box classifiers, these\napproaches struggle against high-quality generations and offer little\ninterpretability. In this work, we propose DivEye, a novel detection framework\nthat captures how unpredictability fluctuates across a text using\nsurprisal-based features. Motivated by the observation that human-authored text\nexhibits richer variability in lexical and structural unpredictability than LLM\noutputs, DivEye captures this signal through a set of interpretable statistical\nfeatures. Our method outperforms existing zero-shot detectors by up to 33.2%\nand achieves competitive performance with fine-tuned baselines across multiple\nbenchmarks. DivEye is robust to paraphrasing and adversarial attacks,\ngeneralizes well across domains and models, and improves the performance of\nexisting detectors by up to 18.7% when used as an auxiliary signal. Beyond\ndetection, DivEye provides interpretable insights into why a text is flagged,\npointing to rhythmic unpredictability as a powerful and underexplored signal\nfor LLM detection.", "published": "2025-09-23 10:21:22", "link": "http://arxiv.org/abs/2509.18880v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Hierarchical Feature Detection for Large Language Model Generated Text", "abstract": "With the rapid advancement of large language model technology, there is\ngrowing interest in whether multi-feature approaches can significantly improve\nAI text detection beyond what single neural models achieve. While intuition\nsuggests that combining semantic, syntactic, and statistical features should\nprovide complementary signals, this assumption has not been rigorously tested\nwith modern LLM-generated text. This paper provides a systematic empirical\ninvestigation of multi-hierarchical feature integration for AI text detection,\nspecifically testing whether the computational overhead of combining multiple\nfeature types is justified by performance gains. We implement MHFD\n(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic\nanalysis, syntactic parsing, and statistical probability features through\nadaptive fusion. Our investigation reveals important negative results: despite\ntheoretical expectations, multi-feature integration provides minimal benefits\n(0.4-0.5% improvement) while incurring substantial computational costs (4.2x\noverhead), suggesting that modern neural language models may already capture\nmost relevant detection signals efficiently. Experimental results on multiple\nbenchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in\nin-domain detection and maintains 84.2% stable performance in cross-domain\ndetection, showing modest improvements of 0.4-2.6% over existing methods.", "published": "2025-09-23 09:55:42", "link": "http://arxiv.org/abs/2509.18862v1", "categories": ["cs.CL", "I.2.7; I.2.1"], "primary_category": "cs.CL"}
{"title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions", "abstract": "Tool-augmented large language models (LLMs) are usually trained with\nsupervised imitation or coarse-grained reinforcement learning that optimizes\nsingle tool calls. Current self-reflection practices rely on heuristic prompts\nor one-way reasoning: the model is urged to 'think more' instead of learning\nerror diagnosis and repair. This is fragile in multi-turn interactions; after a\nfailure the model often repeats the same mistake. We propose structured\nreflection, which turns the path from error to repair into an explicit,\ncontrollable, and trainable action. The agent produces a short yet precise\nreflection: it diagnoses the failure using evidence from the previous step and\nthen proposes a correct, executable follow-up call. For training we combine\nDAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing\nthe stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce\nTool-Reflection-Bench, a lightweight benchmark that programmatically checks\nstructural validity, executability, parameter correctness, and result\nconsistency. Tasks are built as mini trajectories of erroneous call,\nreflection, and corrected call, with disjoint train and test splits.\nExperiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn\ntool-call success and error recovery, and a reduction of redundant calls. These\nresults indicate that making reflection explicit and optimizing it directly\nimproves the reliability of tool interaction and offers a reproducible path for\nagents to learn from failure.", "published": "2025-09-23 09:35:49", "link": "http://arxiv.org/abs/2509.18847v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?", "abstract": "Open-weight versions of large language models (LLMs) are rapidly advancing,\nwith state-of-the-art models like DeepSeek-V3 now performing comparably to\nproprietary LLMs. This progression raises the question of whether small\nopen-weight LLMs are capable of effectively replacing larger closed-source\nmodels. We are particularly interested in the context of biomedical\nquestion-answering, a domain we explored by participating in Task 13B Phase B\nof the BioASQ challenge. In this work, we compare several open-weight models\nagainst top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and\nClaude 3.7 Sonnet. To enhance question answering capabilities, we use various\ntechniques including retrieving the most relevant snippets based on embedding\ndistance, in-context learning, and structured outputs. For certain submissions,\nwe utilize ensemble approaches to leverage the diverse outputs generated by\ndifferent models for exact-answer questions. Our results demonstrate that\nopen-weight LLMs are comparable to proprietary ones. In some instances,\nopen-weight LLMs even surpassed their closed counterparts, particularly when\nensembling strategies were applied. All code is publicly available at\nhttps://github.com/evidenceprime/BioASQ-13b.", "published": "2025-09-23 09:27:57", "link": "http://arxiv.org/abs/2509.18843v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models", "abstract": "Large Audio-Language Models (LALMs) often suffer from audio-textual attention\nimbalance, prioritizing text over acoustic information, particularly in the\nmulti-modal fusion layers of the Transformer architecture. This bias hinders\ntheir ability to fully utilize acoustic cues, causing suboptimal performance on\naudio reasoning tasks. To mitigate this, we propose \\textbf{MATA}, a novel\ntraining-free method that dynamically pushes LALMs to pay \\textbf{M}ore\n\\textbf{A}ttention \\textbf{T}o \\textbf{A}udio tokens within the self-attention\nmechanism. Specifically, MATA intervenes post raw attention scoring, targeting\nonly the last token in intermediate layers without introducing additional\nparameters or computational overhead. Experiments on the MMAU and MMAR\nbenchmarks confirm MATA's effectiveness, with consistent performance gains.\nNotably, on MMAR, MATA enables an open-source model to surpass the proprietary\nGemini 2.0 Flash for the first time. Our work provides an efficient solution to\nmitigate attention bias and opens a new research direction for enhancing the\naudio-processing capabilities of multi-modal models.", "published": "2025-09-23 09:02:15", "link": "http://arxiv.org/abs/2509.18816v1", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction", "abstract": "Keyphrase extraction is a fundamental task in natural language processing.\nHowever, existing unsupervised prompt-based methods for Large Language Models\n(LLMs) often rely on single-stage inference pipelines with uniform prompting,\nregardless of document length or LLM backbone. Such one-size-fits-all designs\nhinder the full exploitation of LLMs' reasoning and generation capabilities,\nespecially given the complexity of keyphrase extraction across diverse\nscenarios. To address these challenges, we propose MAPEX, the first framework\nthat introduces multi-agent collaboration into keyphrase extraction. MAPEX\ncoordinates LLM-based agents through modules for expert recruitment, candidate\nextraction, topic guidance, knowledge augmentation, and post-processing. A\ndual-path strategy dynamically adapts to document length: knowledge-driven\nextraction for short texts and topic-guided extraction for long texts.\nExtensive experiments on six benchmark datasets across three different LLMs\ndemonstrate its strong generalization and universality, outperforming the\nstate-of-the-art unsupervised method by 2.44\\% and standard LLM baselines by\n4.01\\% in F1@5 on average. Code is available at\nhttps://github.com/NKU-LITI/MAPEX.", "published": "2025-09-23 09:00:43", "link": "http://arxiv.org/abs/2509.18813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing", "abstract": "As fine-tuning becomes the dominant paradigm for improving large language\nmodels (LLMs), understanding what changes during this process is increasingly\nimportant. Traditional benchmarking often fails to explain why one model\noutperforms another. In this work, we use model diffing, a mechanistic\ninterpretability approach, to analyze the specific capability differences\nbetween Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we\nidentify and categorize latent representations that differentiate the two\nmodels. We find that SimPO acquired latent concepts predominantly enhance\nsafety mechanisms (+32.8%), multilingual capabilities (+43.8%), and\ninstruction-following (+151.7%), while its additional training also reduces\nemphasis on model self-reference (-44.1%) and hallucination management\n(-68.5%). Our analysis shows that model diffing can yield fine-grained insights\nbeyond leaderboard metrics, attributing performance gaps to concrete\nmechanistic capabilities. This approach offers a transparent and targeted\nframework for comparing LLMs.", "published": "2025-09-23 08:35:58", "link": "http://arxiv.org/abs/2509.18792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field", "abstract": "Large language models (LLMs), as a novel information technology, are seeing\nincreasing adoption in the Architecture, Engineering, and Construction (AEC)\nfield. They have shown their potential to streamline processes throughout the\nbuilding lifecycle. However, the robustness and reliability of LLMs in such a\nspecialized and safety-critical domain remain to be evaluated. To address this\nchallenge, this paper establishes AECBench, a comprehensive benchmark designed\nto quantify the strengths and limitations of current LLMs in the AEC domain.\nThe benchmark defines 23 representative tasks within a five-level\ncognition-oriented evaluation framework encompassing Knowledge Memorization,\nUnderstanding, Reasoning, Calculation, and Application. These tasks were\nderived from authentic AEC practice, with scope ranging from codes retrieval to\nspecialized documents generation. Subsequently, a 4,800-question dataset\nencompassing diverse formats, including open-ended questions, was crafted\nprimarily by engineers and validated through a two-round expert review.\nFurthermore, an LLM-as-a-Judge approach was introduced to provide a scalable\nand consistent methodology for evaluating complex, long-form responses\nleveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear\nperformance decline across five cognitive levels was revealed. Despite\ndemonstrating proficiency in foundational tasks at the Knowledge Memorization\nand Understanding levels, the models showed significant performance deficits,\nparticularly in interpreting knowledge from tables in building codes, executing\ncomplex reasoning and calculation, and generating domain-specific documents.\nConsequently, this study lays the groundwork for future research and\ndevelopment aimed at the robust and reliable integration of LLMs into\nsafety-critical engineering practices.", "published": "2025-09-23 08:09:58", "link": "http://arxiv.org/abs/2509.18776v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Financial Risk Relation Identification through Dual-view Adaptation", "abstract": "A multitude of interconnected risk events -- ranging from regulatory changes\nto geopolitical tensions -- can trigger ripple effects across firms.\nIdentifying inter-firm risk relations is thus crucial for applications like\nportfolio management and investment strategy. Traditionally, such assessments\nrely on expert judgment and manual analysis, which are, however, subjective,\nlabor-intensive, and difficult to scale. To address this, we propose a\nsystematic method for extracting inter-firm risk relations using Form 10-K\nfilings -- authoritative, standardized financial documents -- as our data\nsource. Leveraging recent advances in natural language processing, our approach\ncaptures implicit and abstract risk connections through unsupervised\nfine-tuning based on chronological and lexical patterns in the filings. This\nenables the development of a domain-specific financial encoder with a deeper\ncontextual understanding and introduces a quantitative risk relation score for\ntransparency, interpretable analysis. Extensive experiments demonstrate that\nour method outperforms strong baselines across multiple evaluation settings.", "published": "2025-09-23 08:09:30", "link": "http://arxiv.org/abs/2509.18775v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models", "abstract": "Large language models (LLMs) have achieved impressive performance across\nnatural language processing (NLP) tasks. As real-world applications\nincreasingly demand longer context windows, continued pretraining and\nsupervised fine-tuning (SFT) on long-context data has become a common approach.\nWhile the effects of data length in continued pretraining have been extensively\nstudied, their implications for SFT remain unclear. In this work, we\nsystematically investigate how SFT data length influences LLM behavior on\nshort-context tasks. Counterintuitively, we find that long-context SFT improves\nshort-context performance, contrary to the commonly observed degradation from\nlong-context pretraining. To uncover the underlying mechanisms of this\nphenomenon, we first decouple and analyze two key components, Multi-Head\nAttention (MHA) and Feed-Forward Network (FFN), and show that both\nindependently benefit from long-context SFT. We further study their interaction\nand reveal a knowledge preference bias: long-context SFT promotes contextual\nknowledge, while short-context SFT favors parametric knowledge, making\nexclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that\nhybrid training mitigates this bias, offering explainable guidance for\nfine-tuning LLMs.", "published": "2025-09-23 07:55:38", "link": "http://arxiv.org/abs/2509.18762v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models", "abstract": "Subword tokenizers trained on multilingual corpora naturally produce\noverlapping tokens across languages. Does token overlap facilitate\ncross-lingual transfer or instead introduce interference between languages?\nPrior work offers mixed evidence, partly due to varied setups and confounders,\nsuch as token frequency or subword segmentation granularity. To address this\nquestion, we devise a controlled experiment where we train bilingual\nautoregressive models on multiple language pairs under systematically varied\nvocabulary overlap settings. Crucially, we explore a new dimension to\nunderstanding how overlap affects transfer: the semantic similarity of tokens\nshared across languages. We first analyze our models' hidden representations\nand find that overlap of any kind creates embedding spaces that capture\ncross-lingual semantic relationships, while this effect is much weaker in\nmodels with disjoint vocabularies. On XNLI and XQuAD, we find that models with\noverlap outperform models with disjoint vocabularies, and that transfer\nperformance generally improves as overlap increases. Overall, our findings\nhighlight the advantages of token overlap in multilingual models and show that\nsubstantial shared vocabulary remains a beneficial design choice for\nmultilingual tokenizers.", "published": "2025-09-23 07:47:54", "link": "http://arxiv.org/abs/2509.18750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models", "abstract": "Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph\ninteractions and associated text attributes, are prevalent in real-world\napplications. Existing methods, such as Graph Neural Networks (GNNs) and Large\nLanguage Models (LLMs), mostly focus on static TAGs. Extending these existing\nmethods to DyTAGs is challenging as they largely neglect the recent-global\ntemporal semantics: the recent semantic dependencies among interaction texts\nand the global semantic evolution of nodes over time. Furthermore, applying\nLLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To\ntackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic\nProcessing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to\nefficiently and effectively reason on DyTAGs. Specifically, we first design a\nnode-centric implicit reasoning method together with a sliding window mechanism\nto efficiently capture recent temporal semantics. In addition, to capture\nglobal semantic dynamics of nodes, we leverage explicit reasoning with tailored\nprompts and an RNN-like chain structure to infer long-term semantics. Lastly,\nwe intricately integrate the recent and global temporal semantics as well as\nthe dynamic graph structural information using updating and merging layers.\nExtensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,\nachieving up to 34% improvement in Hit@10 for destination node retrieval task.\nBesides, DyGRASP exhibits strong generalization across different temporal GNNs\nand LLMs.", "published": "2025-09-23 07:35:42", "link": "http://arxiv.org/abs/2509.18742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR", "abstract": "We present LOTUSDIS, a publicly available Thai meeting corpus designed to\nadvance far-field conversational ASR. The dataset comprises 114 hours of\nspontaneous, unscripted dialogue collected in 15-20 minute sessions with three\nparticipants, where overlapping speech is frequent and natural. Speech was\nrecorded simultaneously by nine independent single-channel devices spanning six\nmicrophone types at distances from 0.12 m to 10 m, preserving the authentic\neffects of reverberation, noise, and device coloration without relying on\nmicrophone arrays. We provide standard train, dev, test splits and release a\nreproducible baseline system. We benchmarked several Whisper variants under\nzero-shot and fine-tuned conditions. Off-the-shelf models showed strong\ndegradation with distance, confirming a mismatch between pre-training data and\nThai far-field speech. Fine-tuning on LOTUSDIS dramatically improved\nrobustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and\nfar-field WER from 81.6 to 49.5, with especially large gains on the most\ndistant microphones. These results underscore the importance of\ndistance-diverse training data for robust ASR. The corpus is available under\nCC-BY-SA 4.0. We also release training and evaluation scripts as a baseline\nsystem to promote reproducible research in this field.", "published": "2025-09-23 07:11:06", "link": "http://arxiv.org/abs/2509.18722v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service", "abstract": "Large Language Model-based agents(LLM-based agents) are increasingly deployed\nin customer service, yet they often forget across sessions, repeat errors, and\nlack mechanisms for continual self-improvement. This makes them unreliable in\ndynamic settings where stability and consistency are critical. To better\nevaluate these properties, we emphasize two indicators: task success rate as a\nmeasure of overall effectiveness, and consistency metrics such as Pass$^k$ to\ncapture reliability across multiple trials. To address the limitations of\nexisting approaches, we propose MemOrb, a lightweight and plug-and-play verbal\nreinforcement memory layer that distills multi-turn interactions into compact\nstrategy reflections. These reflections are stored in a shared memory bank and\nretrieved to guide decision-making, without requiring any fine-tuning.\nExperiments show that MemOrb significantly improves both success rate and\nstability, achieving up to a 63 percentage-point gain in multi-turn success\nrate and delivering more consistent performance across repeated trials. Our\nresults demonstrate that structured reflection is a powerful mechanism for\nenhancing long-term reliability of frozen LLM agents in customer service\nscenarios.", "published": "2025-09-23 06:57:07", "link": "http://arxiv.org/abs/2509.18713v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Agentic AutoSurvey: Let LLMs Survey LLMs", "abstract": "The exponential growth of scientific literature poses unprecedented\nchallenges for researchers attempting to synthesize knowledge across rapidly\nevolving fields. We present \\textbf{Agentic AutoSurvey}, a multi-agent\nframework for automated survey generation that addresses fundamental\nlimitations in existing approaches. Our system employs four specialized agents\n(Paper Search Specialist, Topic Mining \\& Clustering, Academic Survey Writer,\nand Quality Evaluator) working in concert to generate comprehensive literature\nsurveys with superior synthesis quality. Through experiments on six\nrepresentative LLM research topics from COLM 2024 categories, we demonstrate\nthat our multi-agent approach achieves significant improvements over existing\nbaselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent\narchitecture processes 75--443 papers per topic (847 total across six topics)\nwhile targeting high citation coverage (often $\\geq$80\\% on 75--100-paper sets;\nlower on very large sets such as RLHF) through specialized agent orchestration.\nOur 12-dimension evaluation captures organization, synthesis integration, and\ncritical analysis beyond basic metrics. These findings demonstrate that\nmulti-agent architectures represent a meaningful advancement for automated\nliterature survey generation in rapidly evolving scientific domains.", "published": "2025-09-23 05:28:43", "link": "http://arxiv.org/abs/2509.18661v1", "categories": ["cs.IR", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction", "abstract": "LLM-as-a-judge has become a promising paradigm for using large language\nmodels (LLMs) to evaluate natural language generation (NLG), but the\nuncertainty of its evaluation remains underexplored. This lack of reliability\nmay limit its deployment in many applications. This work presents the first\nframework to analyze the uncertainty by offering a prediction interval of\nLLM-based scoring via conformal prediction. Conformal prediction constructs\ncontinuous prediction intervals from a single evaluation run, and we design an\nordinal boundary adjustment for discrete rating tasks. We also suggest a\nmidpoint-based score within the interval as a low-bias alternative to raw model\nscore and weighted average. We perform extensive experiments and analysis,\nwhich show that conformal prediction can provide valid prediction interval with\ncoverage guarantees. We also explore the usefulness of interval midpoint and\njudge reprompting for better judgment.", "published": "2025-09-23 05:26:28", "link": "http://arxiv.org/abs/2509.18658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering", "abstract": "Parameter-Preserving Knowledge Editing (PPKE) enables updating models with\nnew or corrected information without retraining or parameter adjustment. Recent\nPPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)\ncapabilities to multi-hop question answering (MHQA). However, these methods\noften lack consistency, leading to knowledge contamination, unstable updates,\nand retrieval behaviors that fail to reflect the intended edits. Such\ninconsistencies undermine the reliability of PPKE in multi- hop reasoning. We\npresent CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge\nGraphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures\nKG construction, update, and retrieval are always aligned with the requirements\nof the MHQA task, maintaining coherent reasoning over both unedited and edited\nknowledge. Extensive experiments on the MQuAKE benchmark show accuracy\nimprovements in PPKE performance for MHQA, demonstrating the effectiveness of\naddressing consistency in PPKE.", "published": "2025-09-23 05:17:39", "link": "http://arxiv.org/abs/2509.18655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users", "abstract": "To assist users in complex tasks, LLMs generate plans: step-by-step\ninstructions towards a goal. While alignment methods aim to ensure LLM plans\nare helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,\nassuming this reflects what helps them. We test this with Planorama: an\ninterface where 126 users answer 300 multi-step questions with LLM plans. We\nget 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA\nsuccess) and user preferences on plans, and recreate the setup in agents and\nreward models to see if they simulate or prefer what helps users. We expose: 1)\nuser/model preferences and agent success do not accurately predict which plans\nhelp users, so common alignment feedback can misalign with helpfulness; 2) this\ngap is not due to user-specific preferences, as users are similarly successful\nwhen using plans they prefer/disprefer; 3) surface-level cues like brevity and\nquestion similarity strongly link to preferences, but such biases fail to\npredict helpfulness. In all, we argue aligning helpful LLMs needs feedback from\nreal user interactions, not just preferences of what looks helpful, so we\ndiscuss the plan NLP researchers can execute to solve this problem.", "published": "2025-09-23 04:33:30", "link": "http://arxiv.org/abs/2509.18632v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation", "abstract": "Radiology report generation (RRG) aims to automatically produce clinically\nfaithful reports from chest X-ray images. Prevailing work typically follows a\nscale-driven paradigm, by multi-stage training over large paired corpora and\noversized backbones, making pipelines highly data- and compute-intensive. In\nthis paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based\nreward (FactS) to tackle the RRG task under constrained budgets. OraPO enables\nsingle-stage, RL-only training by converting failed GRPO explorations on rare\nor difficult studies into direct preference supervision via a lightweight\noracle step. FactS grounds learning in diagnostic evidence by extracting atomic\nclinical facts and checking entailment against ground-truth labels, yielding\ndense, interpretable sentence-level rewards. Together, OraPO and FactS create a\ncompact and powerful framework that significantly improves learning efficiency\non clinically challenging cases, setting the new SOTA performance on the\nCheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training\ndata using a small base VLM on modest hardware.", "published": "2025-09-23 03:42:26", "link": "http://arxiv.org/abs/2509.18600v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "UniECG: Understanding and Generating ECG in One Unified Model", "abstract": "Recent unified models such as GPT-5 have achieved encouraging progress on\nvision-language tasks. However, these unified models typically fail to\ncorrectly understand ECG signals and provide accurate medical diagnoses, nor\ncan they correctly generate ECG signals. To address these limitations, we\npropose UniECG, the first unified model for ECG capable of concurrently\nperforming evidence-based ECG interpretation and text-conditioned ECG\ngeneration tasks. Through a decoupled two-stage training approach, the model\nfirst learns evidence-based interpretation skills (ECG-to-Text), and then\ninjects ECG generation capabilities (Text-to-ECG) via latent space alignment.\nUniECG can autonomously choose to interpret or generate an ECG based on user\ninput, significantly extending the capability boundaries of current ECG models.\nOur code and checkpoints will be made publicly available at\nhttps://github.com/PKUDigitalHealth/UniECG upon acceptance.", "published": "2025-09-23 03:15:53", "link": "http://arxiv.org/abs/2509.18588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning", "abstract": "Fine-tuning large pre-trained models for downstream tasks has become a\nfundamental approach in natural language processing. Fully fine-tuning all\nmodel parameters is computationally expensive and memory-intensive, especially\nin resource-constrained environments. Existing parameter-efficient fine-tuning\nmethods reduce the number of trainable parameters but typically overlook the\nvarying sensitivity of different model layers and the importance of training\ndata. In this work, we propose TsqLoRA, a novel method that integrates\ndata-quality-driven selection with sensitivity-aware low-rank adaptation,\nconsisted of two main components: a quality-aware sampling mechanism for\nselecting the most informative training data, and a dynamic rank allocation\nmodule that adjusts the rank of each layer based on its sensitivity to\nparameter updates. The experimental results demonstrate that TsqLoRA improves\nfine-tuning efficiency while maintaining or even improving performance on a\nvariety of NLP tasks. Our code will be available at\nhttps://github.com/Benjamin-Ricky/TsqLoRA.", "published": "2025-09-23 03:10:41", "link": "http://arxiv.org/abs/2509.18585v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation", "abstract": "While large audio language models excel at tasks like ASR and emotion\nrecognition, they still struggle with complex reasoning due to the modality gap\nbetween audio and text as well as the lack of structured intermediate\nsupervision. To address this, we propose a unified knowledge distillation\nframework to transfer reasoning capabilities from a high-capacity textual\nteacher model to a student audio models while preserving its acoustic\ncompetence. Our method introduces two key dimensions: source-wise distillation,\nwhich leverages both textual and acoustic teachers to provide complementary\nmodality-specific supervision; and layer-wise distillation, which aligns\nteacher signals with appropriate student layers to improve transfer efficiency.\nThis dual-dimensional strategy enables fine-grained control over the\ndistillation process, effectively bridging the gap between symbolic reasoning\nand speech representations. Experimental results show significant improvements\nin audio reasoning performance, demonstrating the effectiveness of our\nframework as a reasoning transfer solution for audio modeling.", "published": "2025-09-23 02:58:16", "link": "http://arxiv.org/abs/2509.18579v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity", "abstract": "As large language models (LLMs) are pretrained on massive web corpora,\ncareful selection of data becomes essential to ensure effective and efficient\nlearning. While perplexity (PPL)-based filtering has shown strong performance,\nit suffers from drawbacks: substantial time costs and inherent unreliability of\nthe model when handling noisy or out-of-distribution samples. In this work, we\npropose a simple yet powerful alternative: a prior-based data filtering method\nthat estimates token priors using corpus-level term frequency statistics,\ninspired by linguistic insights on word roles and lexical density. Our approach\nfilters documents based on the mean and standard deviation of token priors,\nserving as a fast proxy to PPL while requiring no model inference. Despite its\nsimplicity, the prior-based filter achieves the highest average performance\nacross 20 downstream benchmarks, while reducing time cost by over 1000x\ncompared to PPL-based filtering. We further demonstrate its applicability to\nsymbolic languages such as code and math, and its dynamic adaptability to\nmultilingual corpora without supervision", "published": "2025-09-23 02:57:29", "link": "http://arxiv.org/abs/2509.18577v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "HarmoniFuse: A Component-Selective and Prompt-Adaptive Framework for Multi-Task Speech Language Modeling", "abstract": "Recent advances in large language models have facilitated the development of\nunified speech language models (SLMs) capable of supporting multiple speech\ntasks within a shared architecture. However, tasks such as automatic speech\nrecognition (ASR) and speech emotion recognition (SER) rely on distinct types\nof information: ASR primarily depends on linguistic content, whereas SER\nrequires the integration of both linguistic and paralinguistic cues. Existing\nmultitask SLMs typically adopt naive parameter sharing or prompt-based\nconditioning without explicitly modeling the differences in information\ncomposition required by each task. Such designs risk task interference and\nperformance degradation, especially under limited data conditions. To address\nthese limitations, we propose HarmoniFuse, a component-selective and\nprompt-adaptive framework for multi-task speech language modeling. HarmoniFuse\nis designed to harmonize heterogeneous task demands by selecting and fusing\ntask-relevant components of speech representations. Specifically, it integrates\na gated speech encoder to extract task-specific acoustic features and a\nprompt-adaptive dynamic fusion module to aggregate transformer layers based on\ntask characteristics. In addition, a batch-interleaved training strategy\nenables leveraging separate ASR and SER datasets without requiring joint\nannotation. Experimental results demonstrate that HarmoniFuse improves both ASR\nand SER performance, offering a scalable and robust solution for multitask\nspeech understanding under realistic data constraints.", "published": "2025-09-23 02:53:38", "link": "http://arxiv.org/abs/2509.18570v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs", "abstract": "Recently, inference-time reasoning strategies have further improved the\naccuracy of large language models (LLMs), but their effectiveness on smaller\nmodels remains unclear. Based on the observation that conventional approaches\noften fail to improve performance in this context, we propose\n\\textbf{C}ycle-\\textbf{C}onsistency in \\textbf{Q}uestion \\textbf{A}nswering\n(CCQA), a novel reasoning method that can be effectively applied to SLMs.\nInspired by cycle consistency, CCQA generates a question from each reasoning\npath and answer, evaluates each by its similarity to the original question, and\nthen selects the candidate solution with the highest similarity score as the\nfinal response. Since conventional SLMs struggle to generate accurate questions\nfrom their own reasoning paths and answers, we employ a lightweight Flan-T5\nmodel specialized for question generation to support this process efficiently.\nFrom the experimental results, it is verified that CCQA consistently\noutperforms existing state-of-the-art (SOTA) methods across eight models on\nmathematical and commonsense reasoning benchmarks. Furthermore, our method\nestablishes a new practical baseline for efficient reasoning in SLMs. Source\ncode can be found at https://github.com/scai-research/ccqa_official.", "published": "2025-09-23 02:01:03", "link": "http://arxiv.org/abs/2509.18536v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector", "abstract": "The widespread adoption of ChatGPT has raised concerns about its misuse,\nhighlighting the need for robust detection of AI-generated text. Current\nword-level detectors are vulnerable to paraphrasing or simple prompts (PSP),\nsuffer from biases induced by ChatGPT's word-level patterns (CWP) and training\ndata content, degrade on modified text, and often require large models or\nonline LLM interaction. To tackle these issues, we introduce a novel task to\ndetect both original and PSP-modified AI-generated texts, and propose a\nlightweight framework that classifies texts based on their internal structure,\nwhich remains invariant under word-level changes. Our approach encodes sentence\nembeddings from pre-trained language models and models their relationships via\nattention. We employ contrastive learning to mitigate embedding biases from\nautoregressive generation and incorporate a causal graph with counterfactual\nmethods to isolate structural features from topic-related biases. Experiments\non two curated datasets, including abstract comparisons and revised life FAQs,\nvalidate the effectiveness of our method.", "published": "2025-09-23 02:00:35", "link": "http://arxiv.org/abs/2509.18535v1", "categories": ["cs.CL", "eess.SP"], "primary_category": "cs.CL"}
{"title": "No Verifiable Reward for Prosody: Toward Preference-Guided Prosody Learning in TTS", "abstract": "Recent work reports gains in neural text-to-speech (TTS) with Group Relative\nPolicy Optimization (GRPO). However, in the absence of a verifiable reward for\n\\textit{prosody}, GRPO trained on transcription-oriented signals (CER/NLL)\nlowers error rates yet collapses prosody into monotone, unnatural speech;\nadding speaker-similarity further destabilizes training and degrades CER. We\naddress this with an \\textit{iterative Direct Preference Optimization (DPO)}\nscheme that uses only a few hundred human-labeled preference pairs per round to\ndirectly optimize prosodic naturalness while regularizing to the current model.\nOn \\textbf{KoCC-TTS}, a curated dataset of authentic Korean call center\ninteractions capturing task-oriented dialogues, our method attains the highest\nhuman preference (ELO) with competitive CER, outperforming GRPO and strong\ncommercial baselines. These results suggest that when prosody cannot be\nrewarded automatically, \\textit{human preference optimization} offers a\npractical and data-efficient path to natural and robust TTS. The demo page is\navailable at \\href{https://tts.ch.dev}", "published": "2025-09-23 01:51:38", "link": "http://arxiv.org/abs/2509.18531v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition", "abstract": "This paper presents a methodology for inserting phrases in Arabic poems to\nconform to a specific rhythm using ByT5, a byte-level multilingual\ntransformer-based model. Our work discusses a rule-based grapheme-to-beat\ntransformation tailored for extracting the rhythm from fully diacritized Arabic\nscript. Our approach employs a conditional denoising objective to fine-tune\nByT5, where the model reconstructs masked words to match a target rhythm. We\nadopt a curriculum learning strategy, pre-training on a general Arabic dataset\nbefore fine-tuning on poetic dataset, and explore cross-lingual transfer from\nEnglish to Arabic. Experimental results demonstrate that our models achieve\nhigh rhythmic alignment while maintaining semantic coherence. The proposed\nmodel has the potential to be used in co-creative applications in the process\nof composing classical Arabic poems.", "published": "2025-09-23 01:22:15", "link": "http://arxiv.org/abs/2509.18514v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference", "abstract": "Large language models (LLMs) are increasingly used for text-rich graph\nmachine learning tasks such as node classification in high-impact domains like\nfraud detection and recommendation systems. Yet, despite a surge of interest,\nthe field lacks a principled understanding of the capabilities of LLMs in their\ninteraction with graph data. In this work, we conduct a large-scale, controlled\nevaluation across several key axes of variability to systematically assess the\nstrengths and weaknesses of LLM-based graph reasoning methods in text-based\napplications. The axes include the LLM-graph interaction mode, comparing\nprompting, tool-use, and code generation; dataset domains, spanning citation,\nweb-link, e-commerce, and social networks; structural regimes contrasting\nhomophilic and heterophilic graphs; feature characteristics involving both\nshort- and long-text node attributes; and model configurations with varying LLM\nsizes and reasoning capabilities. We further analyze dependencies by\nmethodically truncating features, deleting edges, and removing labels to\nquantify reliance on input types. Our findings provide practical and actionable\nguidance. (1) LLMs as code generators achieve the strongest overall performance\non graph data, with especially large gains on long-text or high-degree graphs\nwhere prompting quickly exceeds the token budget. (2) All interaction\nstrategies remain effective on heterophilic graphs, challenging the assumption\nthat LLM-based methods collapse under low homophily. (3) Code generation is\nable to flexibly adapt its reliance between structure, features, or labels to\nleverage the most informative input type. Together, these findings provide a\ncomprehensive view of the strengths and limitations of current LLM-graph\ninteraction modes and highlight key design principles for future approaches.", "published": "2025-09-23 00:46:21", "link": "http://arxiv.org/abs/2509.18487v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Audio-Based Pedestrian Detection in the Presence of Vehicular Noise", "abstract": "Audio-based pedestrian detection is a challenging task and has, thus far,\nonly been explored in noise-limited environments. We present a new dataset,\nresults, and a detailed analysis of the state-of-the-art in audio-based\npedestrian detection in the presence of vehicular noise. In our study, we\nconduct three analyses: (i) cross-dataset evaluation between noisy and\nnoise-limited environments, (ii) an assessment of the impact of noisy data on\nmodel performance, highlighting the influence of acoustic context, and (iii) an\nevaluation of the model's predictive robustness on out-of-domain sounds. The\nnew dataset is a comprehensive 1321-hour roadside dataset. It incorporates\ntraffic-rich soundscapes. Each recording includes 16kHz audio synchronized with\nframe-level pedestrian annotations and 1fps video thumbnails.", "published": "2025-09-23 17:57:44", "link": "http://arxiv.org/abs/2509.19295v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration", "abstract": "Intelligent agents progress by continually refining their capabilities\nthrough actively exploring environments. Yet robot policies often lack\nsufficient exploration capability due to action mode collapse. Existing methods\nthat encourage exploration typically rely on random perturbations, which are\nunsafe and induce unstable, erratic behaviors, thereby limiting their\neffectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a\nframework that enhances policy exploration and improvement in robotic\nmanipulation. SOE learns a compact latent representation of task-relevant\nfactors and constrains exploration to the manifold of valid actions, ensuring\nsafety, diversity, and effectiveness. It can be seamlessly integrated with\narbitrary policy models as a plug-in module, augmenting exploration without\ndegrading the base policy performance. Moreover, the structured latent space\nenables human-guided exploration, further improving efficiency and\ncontrollability. Extensive experiments in both simulation and real-world tasks\ndemonstrate that SOE consistently outperforms prior methods, achieving higher\ntask success rates, smoother and safer exploration, and superior sample\nefficiency. These results establish on-manifold exploration as a principled\napproach to sample-efficient policy self-improvement. Project website:\nhttps://ericjin2002.github.io/SOE", "published": "2025-09-23 17:54:47", "link": "http://arxiv.org/abs/2509.19292v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurobromas in whole-body MRI", "abstract": "Background and Objectives: Neurofibromatosis type 1 is a genetic disorder\ncharacterized by the development of numerous neurofibromas (NFs) throughout the\nbody. Whole-body MRI (WB-MRI) is the clinical standard for detection and\nlongitudinal surveillance of NF tumor growth. Existing interactive segmentation\nmethods fail to combine high lesion-wise precision with scalability to hundreds\nof lesions. This study proposes a novel interactive segmentation model tailored\nto this challenge.\n  Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation\nmodel that extends the state-of-the-art, transformer-based, promptable Segment\nAnything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was\ntrained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using\nT2-weighted fat-suppressed sequences. The dataset was split at the patient\nlevel into a training set and four test sets (one in-domain and three\nreflecting different domain shift scenarios, e.g., MRI field strength\nvariation, low tumor burden, differences in clinical site and scanner vendor).\n  Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of\n0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC:\n0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained\nunder MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC:\n0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1\nscores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader\nvariability analysis showed model-to-expert agreement (DSC: 0.62-0.68),\ncomparable to inter-expert agreement (DSC: 0.57-0.69).\n  Conclusions: The proposed MOIS-SAM2 enables efficient and scalable\ninteractive segmentation of NFs in WB-MRI with minimal user input and strong\ngeneralization, supporting integration into clinical workflows.", "published": "2025-09-23 17:42:24", "link": "http://arxiv.org/abs/2509.19277v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps", "abstract": "Continuous human motion understanding remains a core challenge in computer\nvision due to its high dimensionality and inherent redundancy. Efficient\ncompression and representation are crucial for analyzing complex motion\ndynamics. In this work, we introduce an adversarially-refined VQ-GAN framework\nwith dense motion tokenization for compressing spatio-temporal heatmaps while\npreserving the fine-grained traces of human motion. Our approach combines dense\nmotion tokenization with adversarial refinement, which eliminates\nreconstruction artifacts like motion smearing and temporal misalignment\nobserved in non-adversarial baselines. Our experiments on the CMU Panoptic\ndataset provide conclusive evidence of our method's superiority, outperforming\nthe dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.\nFurthermore, our dense tokenization strategy enables a novel analysis of motion\ncomplexity, revealing that 2D motion can be optimally represented with a\ncompact 128-token vocabulary, while 3D motion's complexity demands a much\nlarger 1024-token codebook for faithful reconstruction. These results establish\npractical deployment feasibility across diverse motion analysis applications.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Pose-Quantization.", "published": "2025-09-23 17:12:20", "link": "http://arxiv.org/abs/2509.19252v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration", "abstract": "Proper initialization is crucial for any system, particularly in multi-agent\nsystems (MAS), where it plays a pivotal role in determining both the system's\nefficiency and effectiveness. However, existing MAS initialization methods do\nnot fully account for the collaborative needs of the generated agents in\nsubsequent stages. Inspired by the principles of effective team composition, we\npropose AgentInit, which aims to optimize the structure of agent teams.\nSpecifically, in addition to multi-round interactions and reflections between\nagents during agent generation, AgentInit incorporates a Natural Language to\nFormat mechanism to ensure consistency and standardization. Balanced team\nselection strategies using Pareto principles are subsequently applied to\njointly consider agent team diversity and task relevance to promote effective\nand efficient collaboration and enhance overall system performance. Experiments\nshow that AgentInit consistently outperforms state-of-the-art initialization\nmethods and pre-defined strategies across various frameworks and tasks,\nachieving an overall performance improvement of up to 1.2 and 1.6,\nrespectively, while also significantly reducing token consumption. Further\nanalysis confirms its strong transferability to similar tasks and verifies the\neffectiveness of its key components, demonstrating its capability and\nadaptability as a reliable MAS initialization method. Source code and models\nare available at https://github.com/1737423697/AgentInit.", "published": "2025-09-23 16:58:54", "link": "http://arxiv.org/abs/2509.19236v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation", "abstract": "With the widespread deployment of dashcams and advancements in computer\nvision, developing accident prediction models from the dashcam perspective has\nbecome critical for proactive safety interventions. However, two key challenges\npersist: modeling feature-level interactions among traffic participants (often\noccluded in dashcam views) and capturing complex, asynchronous multi-temporal\nbehavioral cues preceding accidents. To deal with these two challenges, a\nMulti-scale Feature Interaction Network (MsFIN) is proposed for early-stage\naccident anticipation from dashcam videos. MsFIN has three layers for\nmulti-scale feature aggregation, temporal feature processing and multi-scale\nfeature post fusion, respectively. For multi-scale feature aggregation, a\nMulti-scale Module is designed to extract scene representations at short-term,\nmid-term and long-term temporal scales. Meanwhile, the Transformer architecture\nis leveraged to facilitate comprehensive feature interactions. Temporal feature\nprocessing captures the sequential evolution of scene and object features under\ncausal constraints. In the multi-scale feature post fusion stage, the network\nfuses scene and object features across multiple temporal scales to generate a\ncomprehensive risk representation. Experiments on DAD and DADA datasets show\nthat MsFIN significantly outperforms state-of-the-art models with single-scale\nfeature extraction in both prediction correctness and earliness. Ablation\nstudies validate the effectiveness of each module in MsFIN, highlighting how\nthe network achieves superior performance through multi-scale feature fusion\nand contextual interaction modeling.", "published": "2025-09-23 16:49:25", "link": "http://arxiv.org/abs/2509.19227v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity", "abstract": "Federated learning in practice must contend with heterogeneous feature\nspaces, severe non-IID data, and scarce labels across clients. We present\nFedFusion, a federated transfer-learning framework that unifies domain\nadaptation and frugal labelling with diversity-/cluster-aware encoders (DivEn,\nDivEn-mix, DivEn-c). Labelled teacher clients guide learner clients via\nconfidence-filtered pseudo-labels and domain-adaptive transfer, while clients\nmaintain personalised encoders tailored to local data. To preserve global\ncoherence under heterogeneity, FedFusion employs similarity-weighted classifier\ncoupling (with optional cluster-wise averaging), mitigating dominance by\ndata-rich sites and improving minority-client performance. The frugal-labelling\npipeline combines self-/semi-supervised pretext training with selective\nfine-tuning, reducing annotation demands without sharing raw data. Across\ntabular and imaging benchmarks under IID, non-IID, and label-scarce regimes,\nFedFusion consistently outperforms state-of-the-art baselines in accuracy,\nrobustness, and fairness while maintaining comparable communication and\ncomputation budgets. These results show that harmonising personalisation,\ndomain adaptation, and label efficiency is an effective recipe for robust\nfederated learning under real-world constraints.", "published": "2025-09-23 16:46:06", "link": "http://arxiv.org/abs/2509.19220v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus", "abstract": "Evaluation of hydrocephalus in children is challenging, and the related\nresearch is limited by a lack of publicly available, expert-annotated datasets,\nparticularly those with segmentation of the choroid plexus. To address this, we\npresent HyKid, an open-source dataset from 48 pediatric patients with\nhydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was\nreconstructed from routine low-resolution images using a slice-to-volume\nalgorithm. Manually corrected segmentations of brain tissues, including white\nmatter, grey matter, lateral ventricle, external CSF, and the choroid plexus,\nwere provided by an experienced neurologist. Additionally, structured data was\nextracted from clinical radiology reports using a Retrieval-Augmented\nGeneration framework. The strong correlation between choroid plexus volume and\ntotal CSF volume provided a potential biomarker for hydrocephalus evaluation,\nachieving excellent performance in a predictive model (AUC = 0.87). The\nproposed HyKid dataset provided a high-quality benchmark for neuroimaging\nalgorithms development, and it revealed the choroid plexus-related features in\nhydrocephalus assessments. Our datasets are publicly available at\nhttps://www.synapse.org/Synapse:syn68544889.", "published": "2025-09-23 16:42:16", "link": "http://arxiv.org/abs/2509.19218v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "YAC: Bridging Natural Language and Interactive Visual Exploration with Generative AI for Biomedical Data Discovery", "abstract": "Incorporating natural language input has the potential to improve the\ncapabilities of biomedical data discovery interfaces. However, user interface\nelements and visualizations are still powerful tools for interacting with data,\neven in the new world of generative AI. In our prototype system, YAC, Yet\nAnother Chatbot, we bridge the gap between natural language and interactive\nvisualizations by generating structured declarative output with a multi-agent\nsystem and interpreting that output to render linked interactive visualizations\nand apply data filters. Furthermore, we include widgets, which allow users to\nadjust the values of that structured output through user interface elements. We\nreflect on the capabilities and design of this system with an analysis of its\ntechnical dimensions and illustrate the capabilities through four usage\nscenarios.", "published": "2025-09-23 15:57:42", "link": "http://arxiv.org/abs/2509.19182v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions", "abstract": "Recent self-supervised stereo matching methods have made significant\nprogress, but their performance significantly degrades under adverse weather\nconditions such as night, rain, and fog. We identify two primary weaknesses\ncontributing to this performance degradation. First, adverse weather introduces\nnoise and reduces visibility, making CNN-based feature extractors struggle with\ndegraded regions like reflective and textureless areas. Second, these degraded\nregions can disrupt accurate pixel correspondences, leading to ineffective\nsupervision based on the photometric consistency assumption. To address these\nchallenges, we propose injecting robust priors derived from the visual\nfoundation model into the CNN-based feature extractor to improve feature\nrepresentation under adverse weather conditions. We then introduce scene\ncorrespondence priors to construct robust supervisory signals rather than\nrelying solely on the photometric consistency assumption. Specifically, we\ncreate synthetic stereo datasets with realistic weather degradations. These\ndatasets feature clear and adverse image pairs that maintain the same semantic\ncontext and disparity, preserving the scene correspondence property. With this\nknowledge, we propose a robust self-supervised training paradigm, consisting of\ntwo key steps: robust self-supervised scene correspondence learning and adverse\nweather distillation. Both steps aim to align underlying scene results from\nclean and adverse image pairs, thus improving model disparity estimation under\nadverse weather effects. Extensive experiments demonstrate the effectiveness\nand versatility of our proposed solution, which outperforms existing\nstate-of-the-art self-supervised methods. Codes are available at\n\\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.", "published": "2025-09-23 15:41:40", "link": "http://arxiv.org/abs/2509.19165v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generative Propaganda", "abstract": "Generative propaganda is the use of generative artificial intelligence (AI)\nto shape public opinion. To characterize its use in real-world settings, we\nconducted interviews with defenders (e.g., factcheckers, journalists,\nofficials) in Taiwan and creators (e.g., influencers, political consultants,\nadvertisers) as well as defenders in India, centering two places characterized\nby high levels of online propaganda. The term \"deepfakes\", we find, exerts\noutsized discursive power in shaping defenders' expectations of misuse and, in\nturn, the interventions that are prioritized. To better characterize the space\nof generative propaganda, we develop a taxonomy that distinguishes between\nobvious versus hidden and promotional versus derogatory use. Deception was\nneither the main driver nor the main impact vector of AI's use; instead, Indian\ncreators sought to persuade rather than to deceive, often making AI's use\nobvious in order to reduce legal and reputational risks, while Taiwan's\ndefenders saw deception as a subset of broader efforts to distort the\nprevalence of strategic narratives online. AI was useful and used, however, in\nproducing efficiency gains in communicating across languages and modes, and in\nevading human and algorithmic detection. Security researchers should reconsider\nthreat models to clearly differentiate deepfakes from promotional and obvious\nuses, to complement and bolster the social factors that constrain misuse by\ninternal actors, and to counter efficiency gains globally.", "published": "2025-09-23 15:27:00", "link": "http://arxiv.org/abs/2509.19147v1", "categories": ["cs.CY", "cs.AI", "cs.SI", "K.4.2"], "primary_category": "cs.CY"}
{"title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "abstract": "The use of natural language (NL) test cases for validating graphical user\ninterface (GUI) applications is emerging as a promising direction to manually\nwritten executable test scripts, which are costly to develop and difficult to\nmaintain. Recent advances in large language models (LLMs) have opened the\npossibility of the direct execution of NL test cases by LLM agents. This paper\ninvestigates this direction, focusing on the impact on NL test case unsoundness\nand on test case execution consistency. NL test cases are inherently unsound,\nas they may yield false failures due to ambiguous instructions or unpredictable\nagent behaviour. Furthermore, repeated executions of the same NL test case may\nlead to inconsistent outcomes, undermining test reliability. To address these\nchallenges, we propose an algorithm for executing NL test cases with guardrail\nmechanisms and specialised agents that dynamically verify the correct execution\nof each test step. We introduce measures to evaluate the capabilities of LLMs\nin test execution and one measure to quantify execution consistency. We propose\na definition of weak unsoundness to characterise contexts in which NL test case\nexecution remains acceptable, with respect to the industrial quality levels Six\nSigma. Our experimental evaluation with eight publicly available LLMs, ranging\nfrom 3B to 70B parameters, demonstrates both the potential and current\nlimitations of current LLM agents for GUI testing. Our experiments show that\nMeta Llama 3.1 70B demonstrates acceptable capabilities in NL test case\nexecution with high execution consistency (above the level 3-sigma). We provide\nprototype tools, test suites, and results.", "published": "2025-09-23 15:20:40", "link": "http://arxiv.org/abs/2509.19136v1", "categories": ["cs.SE", "cs.AI", "D.2.4; D.2.5; F.3.1"], "primary_category": "cs.SE"}
{"title": "GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding", "abstract": "Human mobility traces, often recorded as sequences of check-ins, provide a\nunique window into both short-term visiting patterns and persistent lifestyle\nregularities. In this work we introduce GSTM-HMU, a generative spatio-temporal\nframework designed to advance mobility analysis by explicitly modeling the\nsemantic and temporal complexity of human movement. The framework consists of\nfour key innovations. First, a Spatio-Temporal Concept Encoder (STCE)\nintegrates geographic location, POI category semantics, and periodic temporal\nrhythms into unified vector representations. Second, a Cognitive Trajectory\nMemory (CTM) adaptively filters historical visits, emphasizing recent and\nbehaviorally salient events in order to capture user intent more effectively.\nThird, a Lifestyle Concept Bank (LCB) contributes structured human preference\ncues, such as activity types and lifestyle patterns, to enhance\ninterpretability and personalization. Finally, task-oriented generative heads\ntransform the learned representations into predictions for multiple downstream\ntasks. We conduct extensive experiments on four widely used real-world\ndatasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate\nperformance on three benchmark tasks: next-location prediction, trajectory-user\nidentification, and time estimation. The results demonstrate consistent and\nsubstantial improvements over strong baselines, confirming the effectiveness of\nGSTM-HMU in extracting semantic regularities from complex mobility data. Beyond\nraw performance gains, our findings also suggest that generative modeling\nprovides a promising foundation for building more robust, interpretable, and\ngeneralizable systems for human mobility intelligence.", "published": "2025-09-23 15:20:38", "link": "http://arxiv.org/abs/2509.19135v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Analysis on distribution and clustering of weight", "abstract": "The study on architecture and parameter characteristics remains the hot topic\nin the research of large language models. In this paper we concern with the\ncharacteristics of weight which are used to analyze the correlations and\ndifferences between models. Two kinds of vectors-standard deviation vector and\nclustering vector-are proposed to describe features of models. In the first\ncase, the weights are assumed to follow normal distribution. The standard\ndeviation values of projection matrices are normalized to form\nStandard-Deviation Vector, representing the distribution characteristics of\nmodels. In the second case, the singular values from each weight projection\nmatrix are extracted and grouped by K-Means algorithm. The grouped data with\nthe same type matrix are combined as Clustering Vector to represent the\ncorrelation characteristics of models' weights. The study reveals that these\ntwo vectors can effectively distinguish between different models and clearly\nshow the similarities among models of the same family. Moreover, after\nconducting LoRA fine-tuning with different datasets and models, it is found\nthat the distribution of weights represented by standard deviation vector is\ndirectly influenced by the dataset, but the correlations between different\nweights represented by clustering vector remain unaffected and maintain a high\nconsistency with the pre-trained model.", "published": "2025-09-23 15:08:25", "link": "http://arxiv.org/abs/2509.19122v1", "categories": ["cs.LG", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.LG"}
{"title": "FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI", "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for\nprivacy-preserving model training, yet deployments in sensitive domains such as\nhealthcare face persistent challenges from non-IID data, client unreliability,\nand adversarial manipulation. This paper introduces FedFiTS, a trust and\nfairness-aware selective FL framework that advances the FedFaSt line by\ncombining fitness-based client election with slotted aggregation. FedFiTS\nimplements a three-phase participation strategy-free-for-all training, natural\nselection, and slotted team participation-augmented with dynamic client\nscoring, adaptive thresholding, and cohort-based scheduling to balance\nconvergence efficiency with robustness. A theoretical convergence analysis\nestablishes bounds for both convex and non-convex objectives under standard\nassumptions, while a communication-complexity analysis shows reductions\nrelative to FedAvg and other baselines. Experiments on diverse datasets-medical\nimaging (X-ray pneumonia), vision benchmarks (MNIST, FMNIST), and tabular\nagricultural data (Crop Recommendation)-demonstrate that FedFiTS consistently\noutperforms FedAvg, FedRand, and FedPow in accuracy, time-to-target, and\nresilience to poisoning attacks. By integrating trust-aware aggregation with\nfairness-oriented client selection, FedFiTS advances scalable and secure FL,\nmaking it well suited for real-world healthcare and cross-domain deployments.", "published": "2025-09-23 15:06:04", "link": "http://arxiv.org/abs/2509.19120v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation", "abstract": "Understanding causality in event sequences where outcome labels such as\ndiseases or system failures arise from preceding events like symptoms or error\ncodes is critical. Yet remains an unsolved challenge across domains like\nhealthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label\ncausal discovery method for sparse, high-dimensional event sequences comprising\nof thousands of unique event types. Using two pretrained causal Transformers as\ndomain-specific foundation models for event sequences. CARGO infers in\nparallel, per sequence one-shot causal graphs and aggregates them using an\nadaptive frequency fusion to reconstruct the global Markov boundaries of\nlabels. This two-stage approach enables efficient probabilistic reasoning at\nscale while bypassing the intractable cost of full-dataset conditional\nindependence testing. Our results on a challenging real-world automotive fault\nprediction dataset with over 29,100 unique event types and 474 imbalanced\nlabels demonstrate CARGO's ability to perform structured reasoning.", "published": "2025-09-23 14:58:50", "link": "http://arxiv.org/abs/2509.19112v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation", "abstract": "General-purpose robotic skills from end-to-end demonstrations often leads to\ntask-specific policies that fail to generalize beyond the training\ndistribution. Therefore, we introduce FunCanon, a framework that converts\nlong-horizon manipulation tasks into sequences of action chunks, each defined\nby an actor, verb, and object. These chunks focus policy learning on the\nactions themselves, rather than isolated tasks, enabling compositionality and\nreuse. To make policies pose-aware and category-general, we perform functional\nobject canonicalization for functional alignment and automatic manipulation\ntrajectory transfer, mapping objects into shared functional frames using\naffordance cues from large vision language models. An object centric and action\ncentric diffusion policy FuncDiffuser trained on this aligned data naturally\nrespects object affordances and poses, simplifying learning and improving\ngeneralization ability. Experiments on simulated and real-world benchmarks\ndemonstrate category-level generalization, cross-task behavior reuse, and\nrobust sim2real deployment, showing that functional canonicalization provides a\nstrong inductive bias for scalable imitation learning in complex manipulation\ndomains. Details of the demo and supplemental material are available on our\nproject website https://sites.google.com/view/funcanon.", "published": "2025-09-23 14:49:05", "link": "http://arxiv.org/abs/2509.19102v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Algorithms for Adversarially Robust Deep Learning", "abstract": "Given the widespread use of deep learning models in safety-critical\napplications, ensuring that the decisions of such models are robust against\nadversarial exploitation is of fundamental importance. In this thesis, we\ndiscuss recent progress toward designing algorithms that exhibit desirable\nrobustness properties. First, we discuss the problem of adversarial examples in\ncomputer vision, for which we introduce new technical results, training\nparadigms, and certification algorithms. Next, we consider the problem of\ndomain generalization, wherein the task is to train neural networks to\ngeneralize from a family of training distributions to unseen test\ndistributions. We present new algorithms that achieve state-of-the-art\ngeneralization in medical imaging, molecular identification, and image\nclassification. Finally, we study the setting of jailbreaking large language\nmodels (LLMs), wherein an adversarial user attempts to design prompts that\nelicit objectionable content from an LLM. We propose new attacks and defenses,\nwhich represent the frontier of progress toward designing robust language-based\nagents.", "published": "2025-09-23 14:48:58", "link": "http://arxiv.org/abs/2509.19100v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Training Flow Matching Models with Reliable Labels via Self-Purification", "abstract": "Training datasets are inherently imperfect, often containing mislabeled\nsamples due to human annotation errors, limitations of tagging models, and\nother sources of noise. Such label contamination can significantly degrade the\nperformance of a trained model. In this work, we introduce Self-Purifying Flow\nMatching (SPFM), a principled approach to filtering unreliable data within the\nflow-matching framework. SPFM identifies suspicious data using the model itself\nduring the training process, bypassing the need for pretrained models or\nadditional modules. Our experiments demonstrate that models trained with SPFM\ngenerate samples that accurately adhere to the specified conditioning, even\nwhen trained on noisy labels. Furthermore, we validate the robustness of SPFM\non the TITW dataset, which consists of in-the-wild speech data, achieving\nperformance that surpasses existing baselines.", "published": "2025-09-23 14:43:27", "link": "http://arxiv.org/abs/2509.19091v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Mega-Study of Digital Twins Reveals Strengths, Weaknesses and Opportunities for Further Improvement", "abstract": "Do \"digital twins\" capture individual responses in surveys and experiments?\nWe run 19 pre-registered studies on a national U.S. panel and their LLM-powered\ndigital twins (constructed based on previously-collected extensive\nindividual-level data) and compare twin and human answers across 164 outcomes.\nThe correlation between twin and human answers is modest (approximately 0.2 on\naverage) and twin responses are less variable than human responses. While\nconstructing digital twins based on rich individual-level data improves our\nability to capture heterogeneity across participants and predict relative\ndifferences between them, it does not substantially improve our ability to\npredict the exact answers given by specific participants or enhance predictions\nof population means. Twin performance varies by domain and is higher among more\neducated, higher-income, and ideologically moderate participants. These results\nsuggest current digital twins can capture some degree of relative differences\nbut are unreliable for individual-level predictions and sample mean and\nvariance estimation, underscoring the need for careful validation before use.\nOur data and code are publicly available for researchers and practitioners\ninterested in optimizing digital twin pipelines.", "published": "2025-09-23 14:42:14", "link": "http://arxiv.org/abs/2509.19088v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "stat.AP"], "primary_category": "cs.CY"}
{"title": "Graph Neural Networks with Similarity-Navigated Probabilistic Feature Copying", "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success across\nvarious graph-based tasks. However, they face some fundamental limitations:\nfeature oversmoothing can cause node representations to become\nindistinguishable in deeper networks, they struggle to effectively manage\nheterogeneous relationships where connected nodes differ significantly, and\nthey process entire feature vectors as indivisible units, which limits\nflexibility. We seek to address these limitations. We propose AxelGNN, a novel\nGNN architecture inspired by Axelrod's cultural dissemination model that\naddresses these limitations through a unified framework. AxelGNN incorporates\nsimilarity-gated probabilistic interactions that adaptively promote convergence\nor divergence based on node similarity, implements trait-level copying\nmechanisms for fine-grained feature aggregation at the segment level, and\nmaintains global polarization to preserve node distinctiveness across multiple\nrepresentation clusters. The model's bistable convergence dynamics naturally\nhandle both homophilic and heterophilic graphs within a single architecture.\nExtensive experiments on node classification and influence estimation\nbenchmarks demonstrate that AxelGNN consistently outperforms or matches\nstate-of-the-art GNN methods across diverse graph structures with varying\nhomophily-heterophily characteristics.", "published": "2025-09-23 14:39:09", "link": "http://arxiv.org/abs/2509.19084v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation", "abstract": "Robotic manipulation policies are commonly initialized through imitation\nlearning, but their performance is limited by the scarcity and narrow coverage\nof expert data. Reinforcement learning can refine polices to alleviate this\nlimitation, yet real-robot training is costly and unsafe, while training in\nsimulators suffers from the sim-to-real gap. Recent advances in generative\nmodels have demonstrated remarkable capabilities in real-world simulation, with\ndiffusion models in particular excelling at generation. This raises the\nquestion of how diffusion model-based world models can be combined to enhance\npre-trained policies in robotic manipulation. In this work, we propose\nWorld4RL, a framework that employs diffusion-based world models as\nhigh-fidelity simulators to refine pre-trained policies entirely in imagined\nenvironments for robotic manipulation. Unlike prior works that primarily employ\nworld models for planning, our framework enables direct end-to-end policy\noptimization. World4RL is designed around two principles: pre-training a\ndiffusion world model that captures diverse dynamics on multi-task datasets and\nrefining policies entirely within a frozen world model to avoid online\nreal-world interactions. We further design a two-hot action encoding scheme\ntailored for robotic manipulation and adopt diffusion backbones to improve\nmodeling fidelity. Extensive simulation and real-world experiments demonstrate\nthat World4RL provides high-fidelity environment modeling and enables\nconsistent policy refinement, yielding significantly higher success rates\ncompared to imitation learning and other baselines. More visualization results\nare available at https://world4rl.github.io/.", "published": "2025-09-23 14:38:15", "link": "http://arxiv.org/abs/2509.19080v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Code Driven Planning with Domain-Adaptive Critic", "abstract": "Large Language Models (LLMs) have been widely adopted as task planners for AI\nagents in sequential decision-making problems, leveraging their extensive world\nknowledge. However, the gap between their general knowledge and\nenvironment-specific requirements often leads to inaccurate plans. To address\nthis, existing approaches rely on frequent LLM queries to iteratively refine\nplans based on immediate environmental feedback, which incurs substantial query\ncosts. However, this refinement is typically guided by short-term environmental\nfeedback, limiting LLMs from developing plans aligned with long-term rewards.\nWe propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of\nrelying on frequent queries, CoPiC employs LLMs to generate a diverse set of\nhigh-level planning programs, which iteratively produce and refine candidate\nplans. A trained domain-adaptive critic then evaluates these candidates and\nselects the one most aligned with long-term rewards for execution. Using\nhigh-level planning programs as planner and domain-adaptive critic as\nestimator, CoPiC improves planning while significantly reducing query costs.\nResults in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC\noutperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving\nan average (1) 23.33% improvement in success rate and (2) 91.27% reduction in\nquery costs.", "published": "2025-09-23 14:36:12", "link": "http://arxiv.org/abs/2509.19077v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond Backpropagation: Exploring Innovative Algorithms for Energy-Efficient Deep Neural Network Training", "abstract": "The rising computational and energy demands of deep neural networks (DNNs),\ndriven largely by backpropagation (BP), challenge sustainable AI development.\nThis paper rigorously investigates three BP-free training methods: the\nForward-Forward (FF), Cascaded-Forward (CaFo), and Mono-Forward (MF)\nalgorithms, tracing their progression from foundational concepts to a\ndemonstrably superior solution.\n  A robust comparative framework was established: each algorithm was\nimplemented on its native architecture (MLPs for FF and MF, a CNN for CaFo) and\nbenchmarked against an equivalent BP-trained model. Hyperparameters were\noptimized with Optuna, and consistent early stopping criteria were applied\nbased on validation performance, ensuring all models were optimally tuned\nbefore comparison.\n  Results show that MF not only competes with but consistently surpasses BP in\nclassification accuracy on its native MLPs. Its superior generalization stems\nfrom converging to a more favorable minimum in the validation loss landscape,\nchallenging the assumption that global optimization is required for\nstate-of-the-art results. Measured at the hardware level using the NVIDIA\nManagement Library (NVML) API, MF reduces energy consumption by up to 41% and\nshortens training time by up to 34%, translating to a measurably smaller carbon\nfootprint as estimated by CodeCarbon.\n  Beyond this primary result, we present a hardware-level analysis that\nexplains the efficiency gains: exposing FF's architectural inefficiencies,\nvalidating MF's computationally lean design, and challenging the assumption\nthat all BP-free methods are inherently more memory-efficient. By documenting\nthe evolution from FF's conceptual groundwork to MF's synthesis of accuracy and\nsustainability, this work offers a clear, data-driven roadmap for future\nenergy-efficient deep learning.", "published": "2025-09-23 14:27:44", "link": "http://arxiv.org/abs/2509.19063v1", "categories": ["cs.LG", "cs.AI", "68T07"], "primary_category": "cs.LG"}
{"title": "Towards Causal Representation Learning with Observable Sources as Auxiliaries", "abstract": "Causal representation learning seeks to recover latent factors that generate\nobservational data through a mixing function. Needing assumptions on latent\nstructures or relationships to achieve identifiability in general, prior works\noften build upon conditional independence given known auxiliary variables.\nHowever, prior frameworks limit the scope of auxiliary variables to be external\nto the mixing function. Yet, in some cases, system-driving latent factors can\nbe easily observed or extracted from data, possibly facilitating\nidentification. In this paper, we introduce a framework of observable sources\nbeing auxiliaries, serving as effective conditioning variables. Our main\nresults show that one can identify entire latent variables up to subspace-wise\ntransformations and permutations using volume-preserving encoders. Moreover,\nwhen multiple known auxiliary variables are available, we offer a\nvariable-selection scheme to choose those that maximize recoverability of the\nlatent factors given knowledge of the latent causal graph. Finally, we\ndemonstrate the effectiveness of our framework through experiments on synthetic\ngraph and image data, thereby extending the boundaries of current approaches.", "published": "2025-09-23 14:22:39", "link": "http://arxiv.org/abs/2509.19058v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action", "abstract": "Algorithmic evaluation of procedurally generated content struggles to find\nmetrics that align with human experience, particularly for composite artefacts.\nAutomatic decomposition as a possible solution requires concepts that meet a\nrange of properties. To this end, drawing on Games Studies and Game AI\nresearch, we introduce the nested concepts of \\textit{Landmarks},\n\\textit{Monuments}, and \\textit{Beacons}. These concepts are based on the\nartefact's perceivability, evocativeness, and Call to Action, all from a\nplayer-centric perspective. These terms are generic to games and usable across\ngenres. We argue that these entities can be found and evaluated with techniques\ncurrently used in both research and industry, opening a path towards a fully\nautomated decomposition of PCG, and evaluation of the salient sub-components.\nAlthough the work presented here emphasises mixed-initiative PCG and\ncompositional PCG, we believe it applies beyond those domains. With this\napproach, we intend to create a connection between humanities and technical\ngame research and allow for better computational PCG evaluation", "published": "2025-09-23 14:03:54", "link": "http://arxiv.org/abs/2509.19030v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion", "abstract": "We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a\ntwo-stage reinforcement learning framework for humanoid walking that requires\nno motion capture data or elaborate reward shaping. In the first stage, a\ncompact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via\nProximal Policy Optimization. This generates energy-efficient gait templates.\nIn the second stage, those dynamically consistent trajectories guide a\nfull-body policy trained with Soft Actor--Critic augmented by an adversarial\ndiscriminator, ensuring the student's five-dimensional gait feature\ndistribution matches the ROM's demonstrations. Experiments at 1\nmeter-per-second and 4 meter-per-second show that ROM-GRL produces stable,\nsymmetric gaits with substantially lower tracking error than a pure-reward\nbaseline. By distilling lightweight ROM guidance into high-dimensional\npolicies, ROM-GRL bridges the gap between reward-only and imitation-based\nlocomotion methods, enabling versatile, naturalistic humanoid behaviors without\nany human demonstrations.", "published": "2025-09-23 13:58:36", "link": "http://arxiv.org/abs/2509.19023v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Fully Learnable Neural Reward Machines", "abstract": "Non-Markovian Reinforcement Learning (RL) tasks present significant\nchallenges, as agents must reason over entire trajectories of state-action\npairs to make optimal decisions. A common strategy to address this is through\nsymbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which\nprovide a structured way to express temporally extended objectives. However,\nthese approaches often rely on restrictive assumptions -- such as the\navailability of a predefined Symbol Grounding (SG) function mapping raw\nobservations to high-level symbolic representations, or prior knowledge of the\ntemporal task. In this work, we propose a fully learnable version of Neural\nReward Machines (NRM), which can learn both the SG function and the automaton\nend-to-end, removing any reliance on prior knowledge. Our approach is therefore\nas easily applicable as classic deep RL (DRL) approaches, while being far more\nexplainable, because of the finite and compact nature of automata. Furthermore,\nwe show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL,\nour method outperforms previous approaches based on Recurrent Neural Networks\n(RNNs).", "published": "2025-09-23 13:57:13", "link": "http://arxiv.org/abs/2509.19017v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Pure Vision Language Action (VLA) Models: A Comprehensive Survey", "abstract": "The emergence of Vision Language Action (VLA) models marks a paradigm shift\nfrom traditional policy-based control to generalized robotics, reframing Vision\nLanguage Models (VLMs) from passive sequence generators into active agents for\nmanipulation and decision-making in complex, dynamic environments. This survey\ndelves into advanced VLA methods, aiming to provide a clear taxonomy and a\nsystematic, comprehensive review of existing research. It presents a\ncomprehensive analysis of VLA applications across different scenarios and\nclassifies VLA approaches into several paradigms: autoregression-based,\ndiffusion-based, reinforcement-based, hybrid, and specialized methods; while\nexamining their motivations, core strategies, and implementations in detail. In\naddition, foundational datasets, benchmarks, and simulation platforms are\nintroduced. Building on the current VLA landscape, the review further proposes\nperspectives on key challenges and future directions to advance research in VLA\nmodels and generalizable robotics. By synthesizing insights from over three\nhundred recent studies, this survey maps the contours of this rapidly evolving\nfield and highlights the opportunities and challenges that will shape the\ndevelopment of scalable, general-purpose VLA methods.", "published": "2025-09-23 13:53:52", "link": "http://arxiv.org/abs/2509.19012v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)", "abstract": "Predictive process monitoring is a sub-domain of process mining which aims to\nforecast the future of ongoing process executions. One common prediction target\nis the remaining time, meaning the time that will elapse until a process\nexecution is completed. In this paper, we compare four different remaining time\nprediction approaches in a real-life outbound warehouse process of a logistics\ncompany in the aviation business. For this process, the company provided us\nwith a novel and original event log with 169,523 traces, which we can make\npublicly available. Unsurprisingly, we find that deep learning models achieve\nthe highest accuracy, but shallow methods like conventional boosting techniques\nachieve competitive accuracy and require significantly fewer computational\nresources.", "published": "2025-09-23 13:37:09", "link": "http://arxiv.org/abs/2509.18986v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system", "abstract": "We investigate whether large language models (LLMs) can generate effective,\nuser-facing explanations from a mathematically interpretable recommendation\nmodel. The model is based on constrained matrix factorization, where user types\nare explicitly represented and predicted item scores share the same scale as\nobserved ratings, making the model's internal representations and predicted\nscores directly interpretable. This structure is translated into natural\nlanguage explanations using carefully designed LLM prompts. Many works in\nexplainable AI rely on automatic evaluation metrics, which often fail to\ncapture users' actual needs and perceptions. In contrast, we adopt a\nuser-centered approach: we conduct a study with 326 participants who assessed\nthe quality of the explanations across five key dimensions-transparency,\neffectiveness, persuasion, trust, and satisfaction-as well as the\nrecommendations themselves.To evaluate how different explanation strategies are\nperceived, we generate multiple explanation types from the same underlying\nmodel, varying the input information provided to the LLM. Our analysis reveals\nthat all explanation types are generally well received, with moderate\nstatistical differences between strategies. User comments further underscore\nhow participants react to each type of explanation, offering complementary\ninsights beyond the quantitative results.", "published": "2025-09-23 13:30:03", "link": "http://arxiv.org/abs/2509.18980v1", "categories": ["cs.AI", "cs.HC", "cs.IR", "H.3.3; H.5.2; I.2.7"], "primary_category": "cs.AI"}
{"title": "LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions", "abstract": "Driven by the rapid advancements of Large Language Models (LLMs), LLM-based\nagents have emerged as powerful intelligent systems capable of human-like\ncognition, reasoning, and interaction. These agents are increasingly being\ndeployed across diverse real-world applications, including student education,\nscientific research, and financial analysis. However, despite their remarkable\npotential, LLM-based agents remain vulnerable to hallucination issues, which\ncan result in erroneous task execution and undermine the reliability of the\noverall system design. Addressing this critical challenge requires a deep\nunderstanding and a systematic consolidation of recent advances on LLM-based\nagents. To this end, we present the first comprehensive survey of\nhallucinations in LLM-based agents. By carefully analyzing the complete\nworkflow of agents, we propose a new taxonomy that identifies different types\nof agent hallucinations occurring at different stages. Furthermore, we conduct\nan in-depth examination of eighteen triggering causes underlying the emergence\nof agent hallucinations. Through a detailed review of a large number of\nexisting studies, we summarize approaches for hallucination mitigation and\ndetection, and highlight promising directions for future research. We hope this\nsurvey will inspire further efforts toward addressing hallucinations in\nLLM-based agents, ultimately contributing to the development of more robust and\nreliable agent systems.", "published": "2025-09-23 13:24:48", "link": "http://arxiv.org/abs/2509.18970v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations", "abstract": "Vision-Language-Action (VLA) models have emerged as promising solutions for\nrobotic manipulation, yet their robustness to real-world physical variations\nremains critically underexplored. To bridge this gap, we propose Eva-VLA, the\nfirst unified framework that systematically evaluates the robustness of VLA\nmodels by transforming discrete physical variations into continuous\noptimization problems. However, comprehensively assessing VLA robustness\npresents two key challenges: (1) how to systematically characterize diverse\nphysical variations encountered in real-world deployments while maintaining\nevaluation reproducibility, and (2) how to discover worst-case scenarios\nwithout prohibitive real-world data collection costs efficiently. To address\nthe first challenge, we decompose real-world variations into three critical\ndomains: object 3D transformations that affect spatial reasoning, illumination\nvariations that challenge visual perception, and adversarial patches that\ndisrupt scene understanding. For the second challenge, we introduce a\ncontinuous black-box optimization framework that transforms discrete physical\nvariations into parameter optimization, enabling systematic exploration of\nworst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models\nacross multiple benchmarks reveal alarming vulnerabilities: all variation types\ntrigger failure rates exceeding 60%, with object transformations causing up to\n97.8% failure in long-horizon tasks. Our findings expose critical gaps between\ncontrolled laboratory success and unpredictable deployment readiness, while the\nEva-VLA framework provides a practical pathway for hardening VLA-based robotic\nmanipulation models against real-world deployment challenges.", "published": "2025-09-23 13:02:23", "link": "http://arxiv.org/abs/2509.18953v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Towards Privacy-Aware Bayesian Networks: A Credal Approach", "abstract": "Bayesian networks (BN) are probabilistic graphical models that enable\nefficient knowledge representation and inference. These have proven effective\nacross diverse domains, including healthcare, bioinformatics and economics. The\nstructure and parameters of a BN can be obtained by domain experts or directly\nlearned from available data. However, as privacy concerns escalate, it becomes\nincreasingly critical for publicly released models to safeguard sensitive\ninformation in training data. Typically, released models do not prioritize\nprivacy by design. In particular, tracing attacks from adversaries can combine\nthe released BN with auxiliary data to determine whether specific individuals\nbelong to the data from which the BN was learned. State-of-the-art protection\ntecniques involve introducing noise into the learned parameters. While this\noffers robust protection against tracing attacks, it significantly impacts the\nmodel's utility, in terms of both the significance and accuracy of the\nresulting inferences. Hence, high privacy may be attained at the cost of\nreleasing a possibly ineffective model. This paper introduces credal networks\n(CN) as a novel solution for balancing the model's privacy and utility. After\nadapting the notion of tracing attacks, we demonstrate that a CN enables the\nmasking of the learned BN, thereby reducing the probability of successful\nattacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve\nmeaningful inferences while safeguarding privacy. Moreover, we identify key\nlearning information that must be concealed to prevent attackers from\nrecovering the underlying BN. Finally, we conduct a set of numerical\nexperiments to analyze how privacy gains can be modulated by tuning the CN\nhyperparameters. Our results confirm that CNs provide a principled, practical,\nand effective approach towards the development of privacy-aware probabilistic\ngraphical models.", "published": "2025-09-23 12:58:32", "link": "http://arxiv.org/abs/2509.18949v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning", "abstract": "Recent advancements in Large Language Models (LLMs) have emphasized the\ncritical role of fine-tuning (FT) techniques in adapting LLMs to specific\ntasks, especially when retraining from scratch is computationally infeasible.\nFine-tuning enables LLMs to leverage task- or domain-specific data, producing\nmodels that more effectively meet the requirements of targeted applications.\nHowever, con- ventional FT approaches often suffer from catastrophic forgetting\nand suboptimal data efficiency, limiting their real-world applicability. To\naddress these challenges, this paper proposes DEAL, a novel framework that\nintegrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.\nBy incorporating knowledge retention and adaptive parameter update modules, the\nframework mitigates the lim- itations of existing FT methods while maintaining\nefficiency in privacy-preserving settings. Experiments on 15 diverse datasets\nshow that DEAL consistently outper- forms baseline methods, yielding\nsubstantial gains in task accuracy and resource efficiency. These findings\ndemonstrate the potential of our approach to advance continual adaptation in\nLLMs by enhancing task performance while improving resource efficiency.", "published": "2025-09-23 12:55:57", "link": "http://arxiv.org/abs/2509.18942v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning", "abstract": "While deep learning, including Convolutional Neural Networks (CNNs) and\nVision Transformers (ViTs), has significantly advanced classification\nperformance, its typical reliance on extensive annotated datasets presents a\nmajor obstacle in many practical scenarios where such data is scarce.\nVision-language models (VLMs) and transfer learning with pre-trained visual\nmodels appear as promising techniques to deal with this problem. This paper\nproposes a novel zero-shot image classification framework that combines a VLM\nand a pre-trained visual model within a self-learning cycle. Requiring only the\nset of class names and no labeled training data, our method utilizes a\nconfidence-based pseudo-labeling strategy to train a lightweight classifier\ndirectly on the test data, enabling dynamic adaptation. The VLM identifies\nhigh-confidence samples, and the pre-trained visual model enhances their visual\nrepresentations. These enhanced features then iteratively train the classifier,\nallowing the system to capture complementary semantic and visual cues without\nsupervision. Notably, our approach avoids VLM fine-tuning and the use of large\nlanguage models, relying on the visual-only model to reduce the dependence on\nsemantic representation. Experimental evaluations on ten diverse datasets\ndemonstrate that our approach outperforms the baseline zero-shot method.", "published": "2025-09-23 12:54:52", "link": "http://arxiv.org/abs/2509.18938v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Accurate and Efficient Prediction of Wi-Fi Link Quality Based on Machine Learning", "abstract": "Wireless communications are characterized by their unpredictability, posing\nchallenges for maintaining consistent communication quality. This paper\npresents a comprehensive analysis of various prediction models, with a focus on\nachieving accurate and efficient Wi-Fi link quality forecasts using machine\nlearning techniques. Specifically, the paper evaluates the performance of\ndata-driven models based on the linear combination of exponential moving\naverages, which are designed for low-complexity implementations and are then\nsuitable for hardware platforms with limited processing resources. Accuracy of\nthe proposed approaches was assessed using experimental data from a real-world\nWi-Fi testbed, considering both channel-dependent and channel-independent\ntraining data. Remarkably, channel-independent models, which allow for\ngeneralized training by equipment manufacturers, demonstrated competitive\nperformance. Overall, this study provides insights into the practical\ndeployment of machine learning-based prediction models for enhancing Wi-Fi\ndependability in industrial environments.", "published": "2025-09-23 12:52:01", "link": "http://arxiv.org/abs/2509.18933v1", "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning", "abstract": "Neural Algorithmic Reasoning (NAR) is a paradigm that trains neural networks\nto execute classic algorithms by supervised learning. Despite its successes,\nimportant limitations remain: inability to construct valid solutions without\npost-processing and to reason about multiple correct ones, poor performance on\ncombinatorial NP-hard problems, and inapplicability to problems for which\nstrong algorithms are not yet known. To address these limitations, we reframe\nthe problem of learning algorithm trajectories as a Markov Decision Process,\nwhich imposes structure on the solution construction procedure and unlocks the\npowerful tools of imitation and reinforcement learning (RL). We propose the\nGNARL framework, encompassing the methodology to translate problem formulations\nfrom NAR to RL and a learning architecture suitable for a wide range of\ngraph-based problems. We achieve very high graph accuracy results on several\nCLRS-30 problems, performance matching or exceeding much narrower NAR\napproaches for NP-hard problems and, remarkably, applicability even when\nlacking an expert algorithm.", "published": "2025-09-23 12:49:25", "link": "http://arxiv.org/abs/2509.18930v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models", "abstract": "Autonomous vehicles (AVs) are expected to revolutionize transportation by\nimproving efficiency and safety. Their success relies on 3D vision systems that\neffectively sense the environment and detect traffic agents. Among sensors AVs\nuse to create a comprehensive view of surroundings, LiDAR provides\nhigh-resolution depth data enabling accurate object detection, safe navigation,\nand collision avoidance. However, collecting real-world LiDAR data is\ntime-consuming and often affected by noise and sparsity due to adverse weather\nor sensor limitations. This work applies a denoising diffusion probabilistic\nmodel (DDPM), enhanced with novel noise scheduling and time-step embedding\ntechniques to generate high-quality synthetic data for augmentation, thereby\nimproving performance across a range of computer vision tasks, particularly in\nAV perception. These modifications impact the denoising process and the model's\ntemporal awareness, allowing it to produce more realistic point clouds based on\nthe projection. The proposed method was extensively evaluated under various\nconfigurations using the IAMCV and KITTI-360 datasets, with four performance\nmetrics compared against state-of-the-art (SOTA) methods. The results\ndemonstrate the model's superior performance over most existing baselines and\nits effectiveness in mitigating the effects of noisy and sparse LiDAR data,\nproducing diverse point clouds with rich spatial relationships and structural\ndetail.", "published": "2025-09-23 12:35:07", "link": "http://arxiv.org/abs/2509.18917v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective", "abstract": "Visual Spatial Reasoning (VSR) is a core human cognitive ability and a\ncritical requirement for advancing embodied intelligence and autonomous\nsystems. Despite recent progress in Vision-Language Models (VLMs), achieving\nhuman-level VSR remains highly challenging due to the complexity of\nrepresenting and reasoning over three-dimensional space. In this paper, we\npresent a systematic investigation of VSR in VLMs, encompassing a review of\nexisting methodologies across input modalities, model architectures, training\nstrategies, and reasoning mechanisms. Furthermore, we categorize spatial\nintelligence into three levels of capability, ie, basic perception, spatial\nunderstanding, spatial planning, and curate SIBench, a spatial intelligence\nbenchmark encompassing nearly 20 open-source datasets across 23 task settings.\nExperiments with state-of-the-art VLMs reveal a pronounced gap between\nperception and reasoning, as models show competence in basic perceptual tasks\nbut consistently underperform in understanding and planning tasks, particularly\nin numerical estimation, multi-view reasoning, temporal dynamics, and spatial\nimagination. These findings underscore the substantial challenges that remain\nin achieving spatial intelligence, while providing both a systematic roadmap\nand a comprehensive benchmark to drive future research in the field. The\nrelated resources of this study are accessible at\nhttps://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.", "published": "2025-09-23 12:00:14", "link": "http://arxiv.org/abs/2509.18905v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "The AI Literacy Heptagon: A Structured Approach to AI Literacy in Higher Education", "abstract": "The integrative literature review addresses the conceptualization and\nimplementation of AI Literacy (AIL) in Higher Education (HE) by examining\nrecent research literature. Through an analysis of publications (2021-2024), we\nexplore (1) how AIL is defined and conceptualized in current research,\nparticularly in HE, and how it can be delineated from related concepts such as\nData Literacy, Media Literacy, and Computational Literacy; (2) how various\ndefinitions can be synthesized into a comprehensive working definition, and (3)\nhow scientific insights can be effectively translated into educational\npractice. Our analysis identifies seven central dimensions of AIL: technical,\napplicational, critical thinking, ethical, social, integrational, and legal.\nThese are synthesized in the AI Literacy Heptagon, deepening conceptual\nunderstanding and supporting the structured development of AIL in HE. The study\naims to bridge the gap between theoretical AIL conceptualizations and the\npractical implementation in academic curricula.", "published": "2025-09-23 11:28:30", "link": "http://arxiv.org/abs/2509.18900v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "LongCat-Flash-Thinking Technical Report", "abstract": "We present LongCat-Flash-Thinking, an efficient 560-billion-parameter\nopen-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities\nare cultivated through a meticulously crafted training process, beginning with\nlong Chain-of-Thought (CoT) data cold-start and culminating in large-scale\nReinforcement Learning (RL). We first employ a well-designed cold-start\ntraining strategy, which significantly enhances the reasoning potential and\nequips the model with specialized skills in both formal and agentic reasoning.\nThen, a core innovation is our domain-parallel training scheme, which decouples\noptimization across distinct domains (e.g., STEM, Code, Agentic) and\nsubsequently fuses the resulting expert models into a single, nearly\nPareto-optimal model. This entire process is powered by our Dynamic\nORchestration for Asynchronous rollout (DORA) system, a large-scale RL\nframework that delivers a greater than threefold training speedup over\nsynchronous methods on tens of thousands of accelerators. As a result,\nLongCat-Flash-Thinking achieves state-of-the-art performance among open-source\nmodels on a suite of complex reasoning tasks. The model exhibits exceptional\nefficiency in agentic reasoning, reducing average token consumption by 64.5%\n(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We\nrelease LongCat-Flash-Thinking to promote further advances in reasoning systems\nand agentic AI research.", "published": "2025-09-23 10:25:48", "link": "http://arxiv.org/abs/2509.18883v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Ads Become Profiles: Large-Scale Audit of Algorithmic Biases and LLM Profiling Risks", "abstract": "Automated ad targeting on social media is opaque, creating risks of\nexploitation and invisibility to external scrutiny. Users may be steered toward\nharmful content while independent auditing of these processes remains blocked.\nLarge Language Models (LLMs) raise a new concern: the potential to\nreverse-engineer sensitive user attributes from exposure alone. We introduce a\nmulti-stage auditing framework to investigate these risks. First, a large-scale\naudit of over 435,000 ad impressions delivered to 891 Australian Facebook users\nreveals algorithmic biases, including disproportionate Gambling and Politics\nads shown to socioeconomically vulnerable and politically aligned groups.\nSecond, a multimodal LLM can reconstruct users' demographic profiles from ad\nstreams, outperforming census-based baselines and matching or exceeding human\nperformance. Our results provide the first empirical evidence that ad streams\nconstitute rich digital footprints for public AI inference, highlighting urgent\nprivacy risks and the need for content-level auditing and governance.", "published": "2025-09-23 10:10:37", "link": "http://arxiv.org/abs/2509.18874v1", "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Memory in Large Language Models: Mechanisms, Evaluation and Evolution", "abstract": "Under a unified operational definition, we define LLM memory as a persistent\nstate written during pretraining, finetuning, or inference that can later be\naddressed and that stably influences outputs. We propose a four-part taxonomy\n(parametric, contextual, external, procedural/episodic) and a memory quadruple\n(location, persistence, write/access path, controllability). We link mechanism,\nevaluation, and governance via the chain write -> read -> inhibit/update. To\navoid distorted comparisons across heterogeneous setups, we adopt a\nthree-setting protocol (parametric only, offline retrieval, online retrieval)\nthat decouples capability from information availability on the same data and\ntimeline. On this basis we build a layered evaluation: parametric (closed-book\nrecall, edit differential, memorization/privacy), contextual (position curves\nand the mid-sequence drop), external (answer correctness vs snippet\nattribution/faithfulness), and procedural/episodic (cross-session consistency\nand timeline replay, E MARS+). The framework integrates temporal governance and\nleakage auditing (freshness hits, outdated answers, refusal slices) and\nuncertainty reporting via inter-rater agreement plus paired tests with\nmultiple-comparison correction. For updating and forgetting, we present DMM\nGov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),\nand RAG to form an auditable loop covering admission thresholds, rollout,\nmonitoring, rollback, and change audits, with specs for timeliness, conflict\nhandling, and long-horizon consistency. Finally, we give four testable\npropositions: minimum identifiability; a minimal evaluation card; causally\nconstrained editing with verifiable forgetting; and when retrieval with\nsmall-window replay outperforms ultra-long-context reading. This yields a\nreproducible, comparable, and governable coordinate system for research and\ndeployment.", "published": "2025-09-23 10:06:58", "link": "http://arxiv.org/abs/2509.18868v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling", "abstract": "User profiling, as a core technique for user understanding, aims to infer\nstructural attributes from user information. Large Language Models (LLMs)\nprovide a promising avenue for user profiling, yet the progress is hindered by\nthe lack of comprehensive benchmarks. To bridge this gap, we propose\nProfileBench, an industrial benchmark derived from a real-world video platform,\nencompassing heterogeneous user data and a well-structured profiling taxonomy.\nHowever, the profiling task remains challenging due to the difficulty of\ncollecting large-scale ground-truth labels, and the heterogeneous and noisy\nuser information can compromise the reliability of LLMs. To approach label-free\nand reliable user profiling, we propose a Confidence-driven Profile reasoning\nframework Conf-Profile, featuring a two-stage paradigm. We first synthesize\nhigh-quality labels by leveraging advanced LLMs with confidence hints, followed\nby confidence-weighted voting for accuracy improvement and confidence\ncalibration for a balanced distribution. The multiple profile results,\nrationales, and confidence scores are aggregated and distilled into a\nlightweight LLM. We further enhance the reasoning ability via confidence-guided\nunsupervised reinforcement learning, which exploits confidence for difficulty\nfiltering, quasi-ground truth voting, and reward weighting. Experimental\nresults demonstrate that Conf-Profile delivers substantial performance through\nthe two-stage training, improving F1 by 13.97 on Qwen3-8B.", "published": "2025-09-23 09:58:37", "link": "http://arxiv.org/abs/2509.18864v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NGRPO: Negative-enhanced Group Relative Policy Optimization", "abstract": "RLVR has enhanced the reasoning capabilities of Large Language Models (LLMs)\nacross various tasks. However, GRPO, a representative RLVR algorithm, suffers\nfrom a critical limitation: when all responses within a group are either\nentirely correct or entirely incorrect, the model fails to learn from these\nhomogeneous responses. This is particularly problematic for homogeneously\nincorrect groups, where GRPO's advantage function yields a value of zero,\nleading to null gradients and the loss of valuable learning signals. To\novercome this issue, we propose NGRPO (Negative-enhanced Group Relative Policy\nOptimization), an algorithm designed to convert homogeneous errors into robust\nlearning signals. First, NGRPO introduces Advantage Calibration. This mechanism\nhypothesizes the existence of a virtual maximum-reward sample during advantage\ncalculation, thereby altering the mean and variance of rewards within a group\nand ensuring that the advantages for homogeneously incorrect samples are no\nlonger zero. Second, NGRPO employs Asymmetric Clipping, which relaxes the\nupdate magnitude for positive samples while imposing stricter constraints on\nthat of negative samples. This serves to stabilize the exploration pressure\nintroduced by the advantage calibration. Our experiments on Qwen2.5-Math-7B\ndemonstrate that NGRPO significantly outperforms baselines such as PPO, GRPO,\nDAPO, and PSR-NSR on mathematical benchmarks including MATH500, AMC23, and\nAIME2025. These results validate NGRPO's ability to learn from homogeneous\nerrors, leading to stable and substantial improvements in mathematical\nreasoning. Our code is available at https://github.com/nangongrui-ngr/NGRPO.", "published": "2025-09-23 09:38:10", "link": "http://arxiv.org/abs/2509.18851v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MAPO: Mixed Advantage Policy Optimization", "abstract": "Recent advances in reinforcement learning for foundation models, such as\nGroup Relative Policy Optimization (GRPO), have significantly improved the\nperformance of foundation models on reasoning tasks. Notably, the advantage\nfunction serves as a central mechanism in GRPO for ranking the trajectory\nimportance. However, existing explorations encounter both advantage reversion\nand advantage mirror problems, which hinder the reasonable advantage allocation\nacross different query samples. In this work, we propose an easy but effective\nGRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the\ntrajectory appears with different certainty and propose the advantage percent\ndeviation for samples with high-certainty trajectories. Furthermore, we\ndynamically reweight the advantage function for samples with varying trajectory\ncertainty, thereby adaptively configuring the advantage function to account for\nsample-specific characteristics. Comparison with related state-of-the-art\nmethods, along with ablation studies on different advantage variants, validates\nthe effectiveness of our approach.", "published": "2025-09-23 09:37:16", "link": "http://arxiv.org/abs/2509.18849v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning", "abstract": "Accurate International Classification of Diseases (ICD) coding is critical\nfor clinical documentation, billing, and healthcare analytics, yet it remains a\nlabour-intensive and error-prone task. Although large language models (LLMs)\nshow promise in automating ICD coding, their challenges in base model\nselection, input contextualization, and training data redundancy limit their\neffectiveness. We propose a modular framework for ICD-10 Clinical Modification\n(ICD-10-CM) code prediction that addresses these challenges through principled\nmodel selection, redundancy-aware data sampling, and structured input design.\nThe framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce\naggregation to assess and rank open-source LLMs based on their intrinsic\ncomprehension of ICD-10-CM code definitions. We introduced embedding-based\nsimilarity measures, a redundancy-aware sampling strategy to remove\nsemantically duplicated discharge summaries. We leverage structured discharge\nsummaries from Taiwanese hospitals to evaluate contextual effects and examine\nsection-wise content inclusion under universal and section-specific modelling\nparadigms. Experiments across two institutional datasets demonstrate that the\nselected base model after fine-tuning consistently outperforms baseline LLMs in\ninternal and external evaluations. Incorporating more clinical sections\nconsistently improves prediction performance. This study uses open-source LLMs\nto establish a practical and principled approach to ICD-10-CM code prediction.\nThe proposed framework provides a scalable, institution-ready solution for\nreal-world deployment of automated medical coding systems by combining informed\nmodel selection, efficient data refinement, and context-aware prompting.", "published": "2025-09-23 09:35:05", "link": "http://arxiv.org/abs/2509.18846v1", "categories": ["cs.AI", "I.2.6; I.2.7; J.3"], "primary_category": "cs.AI"}
{"title": "Bounded PCTL Model Checking of Large Language Model Outputs", "abstract": "In this paper, we introduce LLMCHECKER, a model-checking-based verification\nmethod to verify the probabilistic computation tree logic (PCTL) properties of\nan LLM text generation process. We empirically show that only a limited number\nof tokens are typically chosen during text generation, which are not always the\nsame. This insight drives the creation of $\\alpha$-$k$-bounded text generation,\nnarrowing the focus to the $\\alpha$ maximal cumulative probability on the\ntop-$k$ tokens at every step of the text generation process. Our verification\nmethod considers an initial string and the subsequent top-$k$ tokens while\naccommodating diverse text quantification methods, such as evaluating text\nquality and biases. The threshold $\\alpha$ further reduces the selected tokens,\nonly choosing those that exceed or meet it in cumulative probability.\nLLMCHECKER then allows us to formally verify the PCTL properties of\n$\\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in\nseveral LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our\nknowledge, this is the first time PCTL-based model checking has been used to\ncheck the consistency of the LLM text generation process.", "published": "2025-09-23 09:19:37", "link": "http://arxiv.org/abs/2509.18836v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters", "abstract": "Recent advances in diffusion models have significantly improved image and\nvideo synthesis. In addition, several concept control methods have been\nproposed to enable fine-grained, continuous, and flexible control over\nfree-form text prompts. However, these methods not only require intensive\ntraining time and GPU memory usage to learn the sliders or embeddings but also\nneed to be retrained for different diffusion backbones, limiting their\nscalability and adaptability. To address these limitations, we introduce Text\nSlider, a lightweight, efficient and plug-and-play framework that identifies\nlow-rank directions within a pre-trained text encoder, enabling continuous\ncontrol of visual concepts while significantly reducing training time, GPU\nmemory consumption, and the number of trainable parameters. Furthermore, Text\nSlider supports multi-concept composition and continuous control, enabling\nfine-grained and flexible manipulation in both image and video synthesis. We\nshow that Text Slider enables smooth and continuous modulation of specific\nattributes while preserving the original spatial layout and structure of the\ninput. Text Slider achieves significantly better efficiency: 5$\\times$ faster\ntraining than Concept Slider and 47$\\times$ faster than Attribute Control,\nwhile reducing GPU memory usage by nearly 2$\\times$ and 4$\\times$,\nrespectively.", "published": "2025-09-23 09:17:18", "link": "http://arxiv.org/abs/2509.18831v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.GR"}
{"title": "A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising", "abstract": "Achieving high image quality for temporal frames in dynamic positron emission\ntomography (PET) is challenging due to the limited statistic especially for the\nshort frames. Recent studies have shown that deep learning (DL) is useful in a\nwide range of medical image denoising tasks. In this paper, we propose a\nmodel-based neural network for dynamic PET image denoising. The inter-frame\nspatial correlation and intra-frame structural consistency in dynamic PET are\nused to establish the kernel space-based multidimensional sparse (KMDS) model.\nWe then substitute the inherent forms of the parameter estimation with neural\nnetworks to enable adaptive parameters optimization, forming the end-to-end\nneural KMDS-Net. Extensive experimental results from simulated and real data\ndemonstrate that the neural KMDS-Net exhibits strong denoising performance for\ndynamic PET, outperforming previous baseline methods. The proposed method may\nbe used to effectively achieve high temporal and spatial resolution for dynamic\nPET. Our source code is available at\nhttps://github.com/Kuangxd/Neural-KMDS-Net/tree/main.", "published": "2025-09-23 08:48:36", "link": "http://arxiv.org/abs/2509.18801v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Detection of security smells in IaC scripts through semantics-aware code and language processing", "abstract": "Infrastructure as Code (IaC) automates the provisioning and management of IT\ninfrastructure through scripts and tools, streamlining software deployment.\nPrior studies have shown that IaC scripts often contain recurring security\nmisconfigurations, and several detection and mitigation approaches have been\nproposed. Most of these rely on static analysis, using statistical code\nrepresentations or Machine Learning (ML) classifiers to distinguish insecure\nconfigurations from safe code.\n  In this work, we introduce a novel approach that enhances static analysis\nwith semantic understanding by jointly leveraging natural language and code\nrepresentations. Our method builds on two complementary ML models: CodeBERT, to\ncapture semantics across code and text, and LongFormer, to represent long IaC\nscripts without losing contextual information. We evaluate our approach on\nmisconfiguration datasets from two widely used IaC tools, Ansible and Puppet.\nTo validate its effectiveness, we conduct two ablation studies (removing code\ntext from the natural language input and truncating scripts to reduce context)\nand compare against four large language models (LLMs) and prior work. Results\nshow that semantic enrichment substantially improves detection, raising\nprecision and recall from 0.46 and 0.79 to 0.92 and 0.88 on Ansible, and from\n0.55 and 0.97 to 0.87 and 0.75 on Puppet, respectively.", "published": "2025-09-23 08:28:49", "link": "http://arxiv.org/abs/2509.18790v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CR"}
{"title": "The AGNTCY Agent Directory Service: Architecture and Implementation", "abstract": "The Agent Directory Service (ADS) is a distributed directory for the\ndiscovery of AI agent capabilities, metadata, and provenance. It leverages\ncontent-addressed storage, hierarchical taxonomies, and cryptographic signing\nto enable efficient, verifiable, and multi-dimensional discovery across\nheterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema\nFramework (OASF), ADS decouples capability indexing from content location\nthrough a two-level mapping realized over a Kademlia-based Distributed Hash\nTable (DHT). It reuses mature OCI / ORAS infrastructure for artifact\ndistribution, integrates Sigstore for provenance, and supports schema-driven\nextensibility for emerging agent modalities (LLM prompt agents, MCP servers,\nA2A-enabled components). This paper formalizes the architectural model,\ndescribes storage and discovery layers, explains security and performance\nproperties, and positions ADS within the broader landscape of emerging agent\nregistry and interoperability initiatives.", "published": "2025-09-23 08:25:33", "link": "http://arxiv.org/abs/2509.18787v1", "categories": ["cs.AI", "C.2.4"], "primary_category": "cs.AI"}
{"title": "VGGT-DP: Generalizable Robot Control via Vision Foundation Models", "abstract": "Visual imitation learning frameworks allow robots to learn manipulation\nskills from expert demonstrations. While existing approaches mainly focus on\npolicy design, they often neglect the structure and capacity of visual\nencoders, limiting spatial understanding and generalization. Inspired by\nbiological vision systems, which rely on both visual and proprioceptive cues\nfor robust control, we propose VGGT-DP, a visuomotor policy framework that\nintegrates geometric priors from a pretrained 3D perception model with\nproprioceptive feedback. We adopt the Visual Geometry Grounded Transformer\n(VGGT) as the visual encoder and introduce a proprioception-guided visual\nlearning strategy to align perception with internal robot states, improving\nspatial grounding and closed-loop control. To reduce inference latency, we\ndesign a frame-wise token reuse mechanism that compacts multi-view tokens into\nan efficient spatial representation. We further apply random token pruning to\nenhance policy robustness and reduce overfitting. Experiments on challenging\nMetaWorld tasks show that VGGT-DP significantly outperforms strong baselines\nsuch as DP and DP3, particularly in precision-critical and long-horizon\nscenarios.", "published": "2025-09-23 08:15:30", "link": "http://arxiv.org/abs/2509.18778v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Experience Scaling: Post-Deployment Evolution For Large Language Models", "abstract": "Scaling model size, training data, and compute power have driven advances in\nlarge language models (LLMs), but these approaches are reaching saturation as\nhuman-generated text is exhausted and further gains diminish. We propose\nexperience scaling, a framework for continuous post-deployment evolution for\nLLMs through autonomous interaction with the environment and collaborative\nsharing of accumulated experience. The framework captures raw interactions,\ndistills them into compact, reusable knowledge, and periodically refines stored\ncontent to preserve relevance and efficiency. We validate the framework in\nsimulated real-world scenarios involving generalization to previously unseen\nbut related tasks, repetitive queries, and over-saturated knowledge stores.\nAcross all settings, experience scaling improves accuracy, sustains performance\nover time, and maintains gains when applied to novel situations. These results\ndemonstrate that structured post-deployment learning can extend LLM\ncapabilities beyond the limits of static human-generated data, offering a\nscalable path for continued intelligence progress.", "published": "2025-09-23 08:04:58", "link": "http://arxiv.org/abs/2509.18771v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision", "abstract": "Self-supervised learning (SSL) has emerged as a powerful paradigm for medical\nimage representation learning, particularly in settings with limited labeled\ndata. However, existing SSL methods often rely on complex architectures,\nanatomy-specific priors, or heavily tuned augmentations, which limit their\nscalability and generalizability. More critically, these models are prone to\nshortcut learning, especially in modalities like chest X-rays, where anatomical\nsimilarity is high and pathology is subtle. In this work, we introduce DiSSECT\n-- Discrete Self-Supervision for Efficient Clinical Transferable\nRepresentations, a framework that integrates multi-scale vector quantization\ninto the SSL pipeline to impose a discrete representational bottleneck. This\nconstrains the model to learn repeatable, structure-aware features while\nsuppressing view-specific or low-utility patterns, improving representation\ntransfer across tasks and domains. DiSSECT achieves strong performance on both\nclassification and segmentation tasks, requiring minimal or no fine-tuning, and\nshows particularly high label efficiency in low-label regimes. We validate\nDiSSECT across multiple public medical imaging datasets, demonstrating its\nrobustness and generalizability compared to existing state-of-the-art\napproaches.", "published": "2025-09-23 07:58:21", "link": "http://arxiv.org/abs/2509.18765v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Security smells in infrastructure as code: a taxonomy update beyond the seven sins", "abstract": "Infrastructure as Code (IaC) has become essential for modern software\nmanagement, yet security flaws in IaC scripts can have severe consequences, as\nexemplified by the recurring exploits of Cloud Web Services. Prior work has\nrecognized the need to build a precise taxonomy of security smells in IaC\nscripts as a first step towards developing approaches to improve IaC security.\nThis first effort led to the unveiling of seven sins, limited by the focus on a\nsingle IaC tool as well as by the extensive, and potentially biased, manual\neffort that was required. We propose, in our work, to revisit this taxonomy:\nfirst, we extend the study of IaC security smells to a more diverse dataset\nwith scripts associated with seven popular IaC tools, including Terraform,\nAnsible, Chef, Puppet, Pulumi, Saltstack, and Vagrant; second, we bring in some\nautomation for the analysis by relying on an LLM. While we leverage LLMs for\ninitial pattern processing, all taxonomic decisions underwent systematic human\nvalidation and reconciliation with established security standards. Our study\nyields a comprehensive taxonomy of 62 security smell categories, significantly\nexpanding beyond the previously known seven. We demonstrate actionability by\nimplementing new security checking rules within linters for seven popular IaC\ntools, often achieving 1.00 precision score. Our evolution study of security\nsmells in GitHub projects reveals that these issues persist for extended\nperiods, likely due to inadequate detection and mitigation tools. This work\nprovides IaC practitioners with insights for addressing common security smells\nand systematically adopting DevSecOps practices to build safer infrastructure\ncode.", "published": "2025-09-23 07:55:35", "link": "http://arxiv.org/abs/2509.18761v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Complexity of Activity Patterns in a Bio-Inspired Hopfield-Type Network in Different Topologies", "abstract": "Neural network models capable of storing memory have been extensively studied\nin computer science and computational neuroscience. The Hopfield network is a\nprototypical example of a model designed for associative, or\ncontent-addressable, memory and has been analyzed in many forms. Further, ideas\nand methods from complex network theory have been incorporated into artificial\nneural networks and learning, emphasizing their structural properties.\nNevertheless, the temporal dynamics also play a vital role in biological neural\nnetworks, whose temporal structure is a crucial feature to examine. Biological\nneural networks display complex intermittency and, thus, can be studied through\nthe lens of the temporal complexity (TC) theory. The TC approach look at the\nmetastability of self-organized states, characterized by a power-law decay in\nthe inter-event time distribution and in the total activity distribution or a\nscaling behavior in the corresponding event-driven diffusion processes. In this\nstudy, we present a temporal complexity (TC) analysis of a\nbiologically-inspired Hopfield-type neural network model. We conducted a\ncomparative assessment between scale-free and random network topologies, with\nparticular emphasis on their global activation patterns. Our parametric\nanalysis revealed comparable dynamical behaviors across both neural network\narchitectures. Furthermore, our investigation into temporal complexity\ncharacteristics uncovered that seemingly distinct dynamical patterns exhibit\nsimilar temporal complexity behaviors. In particular, similar power-law decay\nin the activity distribution and similar complexity levels are observed in both\ntopologies, but with a much reduced noise in the scale-free topology. Notably,\nmost of the complex dynamical profiles were consistently observed in scale-free\nnetwork configurations, thus confirming the crucial role of hubs in neural\nnetwork dynamics.", "published": "2025-09-23 07:53:27", "link": "http://arxiv.org/abs/2509.18758v1", "categories": ["q-bio.NC", "cs.AI", "nlin.AO", "physics.bio-ph"], "primary_category": "q-bio.NC"}
{"title": "MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning", "abstract": "Recent advances in imitation learning have shown great promise for developing\nrobust robot manipulation policies from demonstrations. However, this promise\nis contingent on the availability of diverse, high-quality datasets, which are\nnot only challenging and costly to collect but are often constrained to a\nspecific robot embodiment. Portable handheld grippers have recently emerged as\nintuitive and scalable alternatives to traditional robotic teleoperation\nmethods for data collection. However, their reliance solely on first-person\nview wrist-mounted cameras often creates limitations in capturing sufficient\nscene contexts. In this paper, we present MV-UMI (Multi-View Universal\nManipulation Interface), a framework that integrates a third-person perspective\nwith the egocentric camera to overcome this limitation. This integration\nmitigates domain shifts between human demonstration and robot deployment,\npreserving the cross-embodiment advantages of handheld data-collection devices.\nOur experimental results, including an ablation study, demonstrate that our\nMV-UMI framework improves performance in sub-tasks requiring broad scene\nunderstanding by approximately 47% across 3 tasks, confirming the effectiveness\nof our approach in expanding the range of feasible manipulation tasks that can\nbe learned using handheld gripper systems, without compromising the\ncross-embodiment advantages inherent to such systems.", "published": "2025-09-23 07:53:05", "link": "http://arxiv.org/abs/2509.18757v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "COLT: Enhancing Video Large Language Models with Continual Tool Usage", "abstract": "The success of Large Language Models (LLMs) has significantly propelled the\nresearch of video understanding. To harvest the benefits of well-trained expert\nmodels (i.e., tools), video LLMs prioritize the exploration of tool usage\ncapabilities. Existing methods either prompt closed-source LLMs or employ the\ninstruction tuning paradigm for tool-use fine-tuning. These methods, however,\nassume an established repository of fixed tools and struggle to generalize to\nreal-world environments where tool data is perpetually evolving and streaming\nin. To this end, we propose to enhance open-source video LLMs with COntinuaL\nTool usage (termed COLT), which automatically acquires tool-use ability in a\nsuccessive tool stream without suffering 'catastrophic forgetting' of the past\nlearned tools. Specifically, our COLT incorporates a learnable tool codebook as\na tool-specific memory system. Then relevant tools are dynamically selected\nbased on the similarity between user instruction and tool features within the\ncodebook. To unleash the tool usage potential of video LLMs, we collect a\nvideo-centric tool-use instruction tuning dataset VideoToolBench. Extensive\nexperiments on both previous video LLM benchmarks and the tool-use-specific\nVideoToolBench dataset demonstrate the state-of-the-art performance of our\nproposed COLT.", "published": "2025-09-23 07:49:30", "link": "http://arxiv.org/abs/2509.18754v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Generalized Bisimulation Metric of State Similarity between Markov Decision Processes: From Theoretical Propositions to Applications", "abstract": "The bisimulation metric (BSM) is a powerful tool for computing state\nsimilarities within a Markov decision process (MDP), revealing that states\ncloser in BSM have more similar optimal value functions. While BSM has been\nsuccessfully utilized in reinforcement learning (RL) for tasks like state\nrepresentation learning and policy exploration, its application to multiple-MDP\nscenarios, such as policy transfer, remains challenging. Prior work has\nattempted to generalize BSM to pairs of MDPs, but a lack of rigorous analysis\nof its mathematical properties has limited further theoretical progress. In\nthis work, we formally establish a generalized bisimulation metric (GBSM)\nbetween pairs of MDPs, which is rigorously proven with the three fundamental\nproperties: GBSM symmetry, inter-MDP triangle inequality, and the distance\nbound on identical state spaces. Leveraging these properties, we theoretically\nanalyse policy transfer, state aggregation, and sampling-based estimation in\nMDPs, obtaining explicit bounds that are strictly tighter than those derived\nfrom the standard BSM. Additionally, GBSM provides a closed-form sample\ncomplexity for estimation, improving upon existing asymptotic results based on\nBSM. Numerical results validate our theoretical findings and demonstrate the\neffectiveness of GBSM in multi-MDP scenarios.", "published": "2025-09-23 07:02:05", "link": "http://arxiv.org/abs/2509.18714v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images", "abstract": "Remote sensing visual grounding (RSVG) aims to localize objects in remote\nsensing images based on free-form natural language expressions. Existing\napproaches are typically constrained to closed-set vocabularies, limiting their\napplicability in open-world scenarios. While recent attempts to leverage\ngeneric foundation models for open-vocabulary RSVG, they overly rely on\nexpensive high-quality datasets and time-consuming fine-tuning. To address\nthese limitations, we propose \\textbf{RSVG-ZeroOV}, a training-free framework\nthat aims to explore the potential of frozen generic foundation models for\nzero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key\nstages: (i) Overview: We utilize a vision-language model (VLM) to obtain\ncross-attention\\footnote[1]{In this paper, although decoder-only VLMs use\nself-attention over all tokens, we refer to the image-text interaction part as\ncross-attention to distinguish it from pure visual self-attention.}maps that\ncapture semantic correlations between text queries and visual regions. (ii)\nFocus: By leveraging the fine-grained modeling priors of a diffusion model\n(DM), we fill in gaps in structural and shape information of objects, which are\noften overlooked by VLM. (iii) Evolve: A simple yet effective attention\nevolution module is introduced to suppress irrelevant activations, yielding\npurified segmentation masks over the referred objects. Without cumbersome\ntask-specific training, RSVG-ZeroOV offers an efficient and scalable solution.\nExtensive experiments demonstrate that the proposed framework consistently\noutperforms existing weakly-supervised and zero-shot methods.", "published": "2025-09-23 06:52:15", "link": "http://arxiv.org/abs/2509.18711v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Autonomous Data Agents: A New Opportunity for Smart Data", "abstract": "As data continues to grow in scale and complexity, preparing, transforming,\nand analyzing it remains labor-intensive, repetitive, and difficult to scale.\nSince data contains knowledge and AI learns knowledge from it, the alignment\nbetween AI and data is essential. However, data is often not structured in ways\nthat are optimal for AI utilization. Moreover, an important question arises:\nhow much knowledge can we pack into data through intensive data operations?\nAutonomous data agents (DataAgents), which integrate LLM reasoning with task\ndecomposition, action reasoning and grounding, and tool calling, can\nautonomously interpret data task descriptions, decompose tasks into subtasks,\nreason over actions, ground actions into python code or tool calling, and\nexecute operations. Unlike traditional data management and engineering tools,\nDataAgents dynamically plan workflows, call powerful tools, and adapt to\ndiverse data tasks at scale. This report argues that DataAgents represent a\nparadigm shift toward autonomous data-to-knowledge systems. DataAgents are\ncapable of handling collection, integration, preprocessing, selection,\ntransformation, reweighing, augmentation, reprogramming, repairs, and\nretrieval. Through these capabilities, DataAgents transform complex and\nunstructured data into coherent and actionable knowledge. We first examine why\nthe convergence of agentic AI and data-to-knowledge systems has emerged as a\ncritical trend. We then define the concept of DataAgents and discuss their\narchitectural design, training strategies, as well as the new skills and\ncapabilities they enable. Finally, we call for concerted efforts to advance\naction workflow optimization, establish open datasets and benchmark ecosystems,\nsafeguard privacy, balance efficiency with scalability, and develop trustworthy\nDataAgent guardrails to prevent malicious actions.", "published": "2025-09-23 06:46:41", "link": "http://arxiv.org/abs/2509.18710v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "An overview of neural architectures for self-supervised audio representation learning from masked spectrograms", "abstract": "In recent years, self-supervised learning has amassed significant interest\nfor training deep neural representations without labeled data. One such\nself-supervised learning approach is masked spectrogram modeling, where the\nobjective is to learn semantically rich contextual representations by\npredicting removed or hidden portions of the input audio spectrogram. With the\nTransformer neural architecture at its core, masked spectrogram modeling has\nemerged as the prominent approach for learning general purpose audio\nrepresentations, a.k.a. audio foundation models. Meanwhile, addressing the\nissues of the Transformer architecture, in particular the underlying Scaled\nDot-product Attention operation, which scales quadratically with input sequence\nlength, has led to renewed interest in recurrent sequence modeling approaches.\nAmong them, Selective structured state space models (such as Mamba) and\nextended Long Short-Term Memory (xLSTM) are the two most promising approaches\nwhich have experienced widespread adoption. While the body of work on these two\ntopics continues to grow, there is currently a lack of an adequate overview\nencompassing the intersection of these topics. In this paper, we present a\ncomprehensive overview of the aforementioned research domains, covering masked\nspectrogram modeling and the previously mentioned neural sequence modeling\narchitectures, Mamba and xLSTM. Further, we compare Transformers, Mamba and\nxLSTM based masked spectrogram models in a unified, reproducible framework on\nten diverse downstream audio classification tasks, which will help interested\nreaders to make informed decisions regarding suitability of the evaluated\napproaches to adjacent applications.", "published": "2025-09-23 06:20:41", "link": "http://arxiv.org/abs/2509.18691v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advances in Large Language Models for Medicine", "abstract": "Artificial intelligence (AI) technology has advanced rapidly in recent years,\nwith large language models (LLMs) emerging as a significant breakthrough. LLMs\nare increasingly making an impact across various industries, with the medical\nfield standing out as the most prominent application area. This paper\nsystematically reviews the up-to-date research progress of LLMs in the medical\nfield, providing an in-depth analysis of training techniques for large medical\nmodels, their adaptation in healthcare settings, related applications, as well\nas their strengths and limitations. Furthermore, it innovatively categorizes\nmedical LLMs into three distinct types based on their training methodologies\nand classifies their evaluation approaches into two categories. Finally, the\nstudy proposes solutions to existing challenges and outlines future research\ndirections based on identified issues in the field of medical LLMs. By\nsystematically reviewing previous and advanced research findings, we aim to\nhighlight the necessity of developing medical LLMs, provide a deeper\nunderstanding of their current state of development, and offer clear guidance\nfor subsequent research.", "published": "2025-09-23 06:16:39", "link": "http://arxiv.org/abs/2509.18690v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection", "abstract": "RGB-D salient object detection (SOD) aims to identify the most conspicuous\nobjects in a scene with the incorporation of depth cues. Existing methods\nmainly rely on CNNs, limited by the local receptive fields, or Vision\nTransformers that suffer from the cost of quadratic complexity, posing a\nchallenge in balancing performance and computational efficiency. Recently,\nstate space models (SSM), Mamba, have shown great potential for modeling\nlong-range dependency with linear complexity. However, directly applying SSM to\nRGB-D SOD may lead to deficient local semantics as well as the inadequate\ncross-modality fusion. To address these issues, we propose a Local Emphatic and\nAdaptive Fusion state space model (LEAF-Mamba) that contains two novel\ncomponents: 1) a local emphatic state space module (LE-SSM) to capture\nmulti-scale local dependencies for both modalities. 2) an SSM-based adaptive\nfusion module (AFM) for complementary cross-modality interaction and reliable\ncross-modality integration. Extensive experiments demonstrate that the\nLEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in\nboth efficacy and efficiency. Moreover, our method can achieve excellent\nperformance on the RGB-T SOD task, proving a powerful generalization ability.", "published": "2025-09-23 06:08:17", "link": "http://arxiv.org/abs/2509.18683v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Implementation of airborne ML models with semantics preservation", "abstract": "Machine Learning (ML) may offer new capabilities in airborne systems.\nHowever, as any piece of airborne systems, ML-based systems will be required to\nguarantee their safe operation. Thus, their development will have to be\ndemonstrated to be compliant with the adequate guidance. So far, the European\nUnion Aviation Safety Agency (EASA) has published a concept paper and an\nEUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level\nobjectives to confirm the ML model achieves its intended function and maintains\ntraining performance in the target environment. The paper aims to clarify the\ndifference between an ML model and its corresponding unambiguous description,\nreferred to as the Machine Learning Model Description (MLMD). It then refines\nthe essential notion of semantics preservation to ensure the accurate\nreplication of the model. We apply our contributions to several industrial use\ncases to build and compare several target models.", "published": "2025-09-23 06:01:52", "link": "http://arxiv.org/abs/2509.18681v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NaviSense: A Multimodal Assistive Mobile application for Object Retrieval by Persons with Visual Impairment", "abstract": "People with visual impairments often face significant challenges in locating\nand retrieving objects in their surroundings. Existing assistive technologies\npresent a trade-off: systems that offer precise guidance typically require\npre-scanning or support only fixed object categories, while those with\nopen-world object recognition lack spatial feedback for reaching the object. To\naddress this gap, we introduce 'NaviSense', a mobile assistive system that\ncombines conversational AI, vision-language models, augmented reality (AR), and\nLiDAR to support open-world object detection with real-time audio-haptic\nguidance. Users specify objects via natural language and receive continuous\nspatial feedback to navigate toward the target without needing prior setup.\nDesigned with insights from a formative study and evaluated with 12 blind and\nlow-vision participants, NaviSense significantly reduced object retrieval time\nand was preferred over existing tools, demonstrating the value of integrating\nopen-world perception with precise, accessible guidance.", "published": "2025-09-23 05:45:11", "link": "http://arxiv.org/abs/2509.18672v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "abstract": "Graph-based Retrieval-augmented generation (RAG) has become a widely studied\napproach for improving the reasoning, accuracy, and factuality of Large\nLanguage Models. However, many existing graph-based RAG systems overlook the\nhigh cost associated with LLM token usage during graph construction, hindering\nlarge-scale adoption. To address this, we propose TERAG, a simple yet effective\nframework designed to build informative graphs at a significantly lower cost.\nInspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the\nretrieval phase, and we achieve at least 80% of the accuracy of widely used\ngraph-based RAG methods while consuming only 3%-11% of the output tokens.", "published": "2025-09-23 05:34:34", "link": "http://arxiv.org/abs/2509.18667v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer", "abstract": "Safety remains a major concern for deploying reinforcement learning (RL) in\nreal-world applications. Simulators provide safe, scalable training\nenvironments, but the inevitable sim-to-real gap introduces additional safety\nconcerns, as policies must satisfy constraints in real-world conditions that\ndiffer from simulation. To address this challenge, robust safe RL techniques\noffer principled methods, but are often incompatible with standard scalable\ntraining pipelines. In contrast, domain randomization, a simple and popular\nsim-to-real technique, stands out as a promising alternative, although it often\nresults in unsafe behaviors in practice. We present SPiDR, short for\nSim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with\nprovable guarantees for safe sim-to-real transfer. SPiDR uses domain\nrandomization to incorporate the uncertainty about the sim-to-real gap into the\nsafety constraints, making it versatile and highly compatible with existing\ntraining pipelines. Through extensive experiments on sim-to-sim benchmarks and\ntwo distinct real-world robotic platforms, we demonstrate that SPiDR\neffectively ensures safety despite the sim-to-real gap while maintaining strong\nperformance.", "published": "2025-09-23 05:03:00", "link": "http://arxiv.org/abs/2509.18648v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Do You Need Proprioceptive States in Visuomotor Policies?", "abstract": "Imitation-learning-based visuomotor policies have been widely used in robot\nmanipulation, where both visual observations and proprioceptive states are\ntypically adopted together for precise control. However, in this study, we find\nthat this common practice makes the policy overly reliant on the proprioceptive\nstate input, which causes overfitting to the training trajectories and results\nin poor spatial generalization. On the contrary, we propose the State-free\nPolicy, removing the proprioceptive state input and predicting actions only\nconditioned on visual observations. The State-free Policy is built in the\nrelative end-effector action space, and should ensure the full task-relevant\nvisual observations, here provided by dual wide-angle wrist cameras. Empirical\nresults demonstrate that the State-free policy achieves significantly stronger\nspatial generalization than the state-based policy: in real-world tasks such as\npick-and-place, challenging shirt-folding, and complex whole-body manipulation,\nspanning multiple robot embodiments, the average success rate improves from 0\\%\nto 85\\% in height generalization and from 6\\% to 64\\% in horizontal\ngeneralization. Furthermore, they also show advantages in data efficiency and\ncross-embodiment adaptation, enhancing their practicality for real-world\ndeployment.", "published": "2025-09-23 04:56:59", "link": "http://arxiv.org/abs/2509.18644v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Learning neuroimaging models from health system-scale data", "abstract": "Neuroimaging is a ubiquitous tool for evaluating patients with neurological\ndiseases. The global demand for magnetic resonance imaging (MRI) studies has\nrisen steadily, placing significant strain on health systems, prolonging\nturnaround times, and intensifying physician burnout \\cite{Chen2017-bt,\nRula2024-qp-1}. These challenges disproportionately impact patients in\nlow-resource and rural settings. Here, we utilized a large academic health\nsystem as a data engine to develop Prima, the first vision language model (VLM)\nserving as an AI foundation for neuroimaging that supports real-world, clinical\nMRI studies as input. Trained on over 220,000 MRI studies, Prima uses a\nhierarchical vision architecture that provides general and transferable MRI\nfeatures. Prima was tested in a 1-year health system-wide study that included\n30K MRI studies. Across 52 radiologic diagnoses from the major neurologic\ndisorders, including neoplastic, inflammatory, infectious, and developmental\nlesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0,\noutperforming other state-of-the-art general and medical AI models. Prima\noffers explainable differential diagnoses, worklist priority for radiologists,\nand clinical referral recommendations across diverse patient demographics and\nMRI systems. Prima demonstrates algorithmic fairness across sensitive groups\nand can help mitigate health system biases, such as prolonged turnaround times\nfor low-resource populations. These findings highlight the transformative\npotential of health system-scale VLMs and Prima's role in advancing AI-driven\nhealthcare.", "published": "2025-09-23 04:49:59", "link": "http://arxiv.org/abs/2509.18638v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents", "abstract": "Climate risk assessment requires modelling complex interactions between\nspatially heterogeneous hazards and adaptive economic systems. We present a\nnovel geospatial agent-based model that integrates climate hazard data with\nevolutionary learning for economic agents. Our framework combines Mesa-based\nspatial modelling with CLIMADA climate impact assessment, introducing adaptive\nlearning behaviours that allow firms to evolve strategies for budget\nallocation, pricing, wages, and risk adaptation through fitness-based selection\nand mutation. We demonstrate the framework using riverine flood projections\nunder RCP8.5 until 2100, showing that evolutionary adaptation enables firms to\nconverge with baseline (no hazard) production levels after decades of\ndisruption due to climate stress. Our results reveal systemic risks where even\nagents that are not directly exposed to floods face impacts through supply\nchain disruptions, with the end-of-century average price of goods 5.6% higher\nunder RCP8.5 compared to the baseline. This open-source framework provides\nfinancial institutions and companies with tools to quantify both direct and\ncascading climate risks while evaluating cost-effective adaptation strategies.", "published": "2025-09-23 04:33:58", "link": "http://arxiv.org/abs/2509.18633v1", "categories": ["cs.AI", "q-fin.RM"], "primary_category": "cs.AI"}
{"title": "Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training", "abstract": "Behavior cloning has shown promise for robot manipulation, but real-world\ndemonstrations are costly to acquire at scale. While simulated data offers a\nscalable alternative, particularly with advances in automated demonstration\ngeneration, transferring policies to the real world is hampered by various\nsimulation and real domain gaps. In this work, we propose a unified\nsim-and-real co-training framework for learning generalizable manipulation\npolicies that primarily leverages simulation and only requires a few real-world\ndemonstrations. Central to our approach is learning a domain-invariant,\ntask-relevant feature space. Our key insight is that aligning the joint\ndistributions of observations and their corresponding actions across domains\nprovides a richer signal than aligning observations (marginals) alone. We\nachieve this by embedding an Optimal Transport (OT)-inspired loss within the\nco-training framework, and extend this to an Unbalanced OT framework to handle\nthe imbalance between abundant simulation data and limited real-world examples.\nWe validate our method on challenging manipulation tasks, showing it can\nleverage abundant simulation data to achieve up to a 30% improvement in the\nreal-world success rate and even generalize to scenarios seen only in\nsimulation.", "published": "2025-09-23 04:32:53", "link": "http://arxiv.org/abs/2509.18631v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "HyperAdapt: Simple High-Rank Adaptation", "abstract": "Foundation models excel across diverse tasks, but adapting them to\nspecialized applications often requires fine-tuning, an approach that is memory\nand compute-intensive. Parameter-efficient fine-tuning (PEFT) methods mitigate\nthis by updating only a small subset of weights. In this paper, we introduce\nHyperAdapt, a parameter-efficient fine-tuning method that significantly reduces\nthe number of trainable parameters compared to state-of-the-art methods like\nLoRA. Specifically, HyperAdapt adapts a pre-trained weight matrix by applying\nrow- and column-wise scaling through diagonal matrices, thereby inducing a\nhigh-rank update while requiring only $n+m$ trainable parameters for an $n\n\\times m$ matrix. Theoretically, we establish an upper bound on the rank of\nHyperAdapt's updates, and empirically, we confirm that it consistently induces\nhigh-rank transformations across model layers. Experiments on GLUE, arithmetic\nreasoning, and commonsense reasoning benchmarks with models up to 14B\nparameters demonstrate that HyperAdapt matches or nearly matches the\nperformance of full fine-tuning and state-of-the-art PEFT methods while using\norders of magnitude fewer trainable parameters.", "published": "2025-09-23 04:29:26", "link": "http://arxiv.org/abs/2509.18629v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BRAID: Input-Driven Nonlinear Dynamical Modeling of Neural-Behavioral Data", "abstract": "Neural populations exhibit complex recurrent structures that drive behavior,\nwhile continuously receiving and integrating external inputs from sensory\nstimuli, upstream regions, and neurostimulation. However, neural populations\nare often modeled as autonomous dynamical systems, with little consideration\ngiven to the influence of external inputs that shape the population activity\nand behavioral outcomes. Here, we introduce BRAID, a deep learning framework\nthat models nonlinear neural dynamics underlying behavior while explicitly\nincorporating any measured external inputs. Our method disentangles intrinsic\nrecurrent neural population dynamics from the effects of inputs by including a\nforecasting objective within input-driven recurrent neural networks. BRAID\nfurther prioritizes the learning of intrinsic dynamics that are related to a\nbehavior of interest by using a multi-stage optimization scheme. We validate\nBRAID with nonlinear simulations, showing that it can accurately learn the\nintrinsic dynamics shared between neural and behavioral modalities. We then\napply BRAID to motor cortical activity recorded during a motor task and\ndemonstrate that our method more accurately fits the neural-behavioral data by\nincorporating measured sensory stimuli into the model and improves the\nforecasting of neural-behavioral data compared with various baseline methods,\nwhether input-driven or not.", "published": "2025-09-23 04:22:53", "link": "http://arxiv.org/abs/2509.18627v1", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving", "abstract": "Learning-based autonomous driving systems are trained mostly on incident-free\ndata, offering little guidance near safety-performance boundaries. Real crash\nreports contain precisely the contrastive evidence needed, but they are hard to\nuse: narratives are unstructured, third-person, and poorly grounded to sensor\nviews. We address these challenges by normalizing crash narratives to\nego-centric language and converting both logs and crashes into a unified\nscene-action representation suitable for retrieval. At decision time, our\nsystem adjudicates proposed actions by retrieving relevant precedents from this\nunified index; an agentic counterfactual extension proposes plausible\nalternatives, retrieves for each, and reasons across outcomes before deciding.\nOn a nuScenes benchmark, precedent retrieval substantially improves\ncalibration, with recall on contextually preferred actions rising from 24% to\n53%. The counterfactual variant preserves these gains while sharpening\ndecisions near risk.", "published": "2025-09-23 04:21:39", "link": "http://arxiv.org/abs/2509.18626v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Flow marching for a generative PDE foundation model", "abstract": "Pretraining on large-scale collections of PDE-governed spatiotemporal\ntrajectories has recently shown promise for building generalizable models of\ndynamical systems. Yet most existing PDE foundation models rely on\ndeterministic Transformer architectures, which lack generative flexibility for\nmany science and engineering applications. We propose Flow Marching, an\nalgorithm that bridges neural operator learning with flow matching motivated by\nan analysis of error accumulation in physical dynamical systems, and we build a\ngenerative PDE foundation model on top of it. By jointly sampling the noise\nlevel and the physical time step between adjacent states, the model learns a\nunified velocity field that transports a noisy current state toward its clean\nsuccessor, reducing long-term rollout drift while enabling uncertainty-aware\nensemble generations. Alongside this core algorithm, we introduce a\nPhysics-Pretrained Variational Autoencoder (P2VAE) to embed physical states\ninto a compact latent space, and an efficient Flow Marching Transformer (FMT)\nthat combines a diffusion-forcing scheme with latent temporal pyramids,\nachieving up to 15x greater computational efficiency than full-length video\ndiffusion models and thereby enabling large-scale pretraining at substantially\nreduced cost. We curate a corpus of ~2.5M trajectories across 12 distinct PDE\nfamilies and train suites of P2VAEs and FMTs at multiple scales. On downstream\nevaluation, we benchmark on unseen Kolmogorov turbulence with few-shot\nadaptation, demonstrate long-term rollout stability over deterministic\ncounterparts, and present uncertainty-stratified ensemble results, highlighting\nthe importance of generative PDE foundation models for real-world applications.", "published": "2025-09-23 04:00:41", "link": "http://arxiv.org/abs/2509.18611v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning", "abstract": "Reliable navigation in under-canopy agricultural environments remains a\nchallenge due to GNSS unreliability, cluttered rows, and variable lighting. To\naddress these limitations, we present an end-to-end learning-based navigation\nsystem that maps raw 3D LiDAR data directly to control commands using a deep\nreinforcement learning policy trained entirely in simulation. Our method\nincludes a voxel-based downsampling strategy that reduces LiDAR input size by\n95.83%, enabling efficient policy learning without relying on labeled datasets\nor manually designed control interfaces. The policy was validated in\nsimulation, achieving a 100% success rate in straight-row plantations and\nshowing a gradual decline in performance as row curvature increased, tested\nacross varying sinusoidal frequencies and amplitudes.", "published": "2025-09-23 03:56:10", "link": "http://arxiv.org/abs/2509.18608v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "FlexSED: Towards Open-Vocabulary Sound Event Detection", "abstract": "Despite recent progress in large-scale sound event detection (SED) systems\ncapable of handling hundreds of sound classes, existing multi-class\nclassification frameworks remain fundamentally limited. They cannot process\nfree-text sound queries, which enable more flexible and user-friendly\ninteraction, and they lack zero-shot capabilities and offer poor few-shot\nadaptability. Although text-query-based separation methods have been explored,\nthey primarily focus on source separation and are ill-suited for SED tasks that\nrequire precise temporal localization and efficient detection across large and\ndiverse sound vocabularies. In this paper, we propose FlexSED, an\nopen-vocabulary sound event detection system. FlexSED builds on a pretrained\naudio SSL model and the CLAP text encoder, introducing an encoder-decoder\ncomposition and an adaptive fusion strategy to enable effective continuous\ntraining from pretrained weights. To ensure robust supervision, it also employs\nlarge language models (LLMs) to assist in event query selection during\ntraining, addressing challenges related to missing labels. As a result, FlexSED\nachieves superior performance compared to vanilla SED models on\nAudioSet-Strong, while demonstrating strong zero-shot and few-shot\ncapabilities. We release the code and pretrained models to support future\nresearch and applications based on FlexSED.", "published": "2025-09-23 03:52:52", "link": "http://arxiv.org/abs/2509.18606v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SynSonic: Augmenting Sound Event Detection through Text-to-Audio Diffusion ControlNet and Effective Sample Filtering", "abstract": "Data synthesis and augmentation are essential for Sound Event Detection (SED)\ndue to the scarcity of temporally labeled data. While augmentation methods like\nSpecAugment and Mix-up can enhance model performance, they remain constrained\nby the diversity of existing samples. Recent generative models offer new\nopportunities, yet their direct application to SED is challenging due to the\nlack of precise temporal annotations and the risk of introducing noise through\nunreliable filtering. To address these challenges and enable generative-based\naugmentation for SED, we propose SynSonic, a data augmentation method tailored\nfor this task. SynSonic leverages text-to-audio diffusion models guided by an\nenergy-envelope ControlNet to generate temporally coherent sound events. A\njoint score filtering strategy with dual classifiers ensures sample quality,\nand we explore its practical integration into training pipelines. Experimental\nresults show that SynSonic improves Polyphonic Sound Detection Scores (PSDS1\nand PSDS2), enhancing both temporal localization and sound class\ndiscrimination.", "published": "2025-09-23 03:48:26", "link": "http://arxiv.org/abs/2509.18603v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching", "abstract": "Conditional generative modeling aims to learn a conditional data distribution\nfrom samples containing data-condition pairs. For this, diffusion and\nflow-based methods have attained compelling results. These methods use a\nlearned (flow) model to transport an initial standard Gaussian noise that\nignores the condition to the conditional data distribution. The model is hence\nrequired to learn both mass transport and conditional injection. To ease the\ndemand on the model, we propose Condition-Aware Reparameterization for Flow\nMatching (CAR-Flow) -- a lightweight, learned shift that conditions the source,\nthe target, or both distributions. By relocating these distributions, CAR-Flow\nshortens the probability path the model must learn, leading to faster training\nin practice. On low-dimensional synthetic data, we visualize and quantify the\neffects of CAR. On higher-dimensional natural image data (ImageNet-256),\nequipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while\nintroducing less than 0.6% additional parameters.", "published": "2025-09-23 17:59:31", "link": "http://arxiv.org/abs/2509.19300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction", "abstract": "Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective\nsolution for novel view synthesis. Existing methods predominantly rely on a\npixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a\n3D Gaussian. We rethink this widely adopted formulation and identify several\ninherent limitations: it renders the reconstructed 3D models heavily dependent\non the number of input views, leads to view-biased density distributions, and\nintroduces alignment errors, particularly when source views contain occlusions\nor low texture. To address these challenges, we introduce VolSplat, a new\nmulti-view feed-forward paradigm that replaces pixel alignment with\nvoxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D\nvoxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature\nmatching, ensuring robust multi-view consistency. Furthermore, it enables\nadaptive control over Gaussian density based on 3D scene complexity, yielding\nmore faithful Gaussian point clouds, improved geometric consistency, and\nenhanced novel-view rendering quality. Experiments on widely used benchmarks\nincluding RealEstate10K and ScanNet demonstrate that VolSplat achieves\nstate-of-the-art performance while producing more plausible and view-consistent\nGaussian reconstructions. In addition to superior results, our approach\nestablishes a more scalable framework for feed-forward 3D reconstruction with\ndenser and more robust representations, paving the way for further research in\nwider communities. The video results, code and trained models are available on\nour project page: https://lhmd.top/volsplat.", "published": "2025-09-23 17:59:02", "link": "http://arxiv.org/abs/2509.19297v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation", "abstract": "The ability to generate virtual environments is crucial for applications\nranging from gaming to physical AI domains such as robotics, autonomous\ndriving, and industrial AI. Current learning-based 3D reconstruction methods\nrely on the availability of captured real-world multi-view data, which is not\nalways readily available. Recent advancements in video diffusion models have\nshown remarkable imagination capabilities, yet their 2D nature limits the\napplications to simulation where a robot needs to navigate and interact with\nthe environment. In this paper, we propose a self-distillation framework that\naims to distill the implicit 3D knowledge in the video diffusion models into an\nexplicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for\nmulti-view training data. Specifically, we augment the typical RGB decoder with\na 3DGS decoder, which is supervised by the output of the RGB decoder. In this\napproach, the 3DGS decoder can be purely trained with synthetic data generated\nby video diffusion models. At inference time, our model can synthesize 3D\nscenes from either a text prompt or a single image for real-time rendering. Our\nframework further extends to dynamic 3D scene generation from a monocular input\nvideo. Experimental results show that our framework achieves state-of-the-art\nperformance in static and dynamic 3D scene generation.", "published": "2025-09-23 17:58:01", "link": "http://arxiv.org/abs/2509.19296v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps", "abstract": "Despite steady progress in layout-to-image generation, current methods still\nstruggle with layouts containing significant overlap between bounding boxes. We\nidentify two primary challenges: (1) large overlapping regions and (2)\noverlapping instances with minimal semantic distinction. Through both\nqualitative examples and quantitative analysis, we demonstrate how these\nfactors degrade generation quality. To systematically assess this issue, we\nintroduce OverLayScore, a novel metric that quantifies the complexity of\noverlapping bounding boxes. Our analysis reveals that existing benchmarks are\nbiased toward simpler cases with low OverLayScore values, limiting their\neffectiveness in evaluating model performance under more challenging\nconditions. To bridge this gap, we present OverLayBench, a new benchmark\nfeaturing high-quality annotations and a balanced distribution across different\nlevels of OverLayScore. As an initial step toward improving performance on\ncomplex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a\ncurated amodal mask dataset. Together, our contributions lay the groundwork for\nmore robust layout-to-image generation under realistic and challenging\nscenarios. Project link: https://mlpc-ucsd.github.io/OverLayBench.", "published": "2025-09-23 17:50:00", "link": "http://arxiv.org/abs/2509.19282v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Moving by Looking: Towards Vision-Driven Avatar Motion Generation", "abstract": "The way we perceive the world fundamentally shapes how we move, whether it is\nhow we navigate in a room or how we interact with other humans. Current human\nmotion generation methods, neglect this interdependency and use task-specific\n``perception'' that differs radically from that of humans. We argue that the\ngeneration of human-like avatar behavior requires human-like perception.\nConsequently, in this work we present CLOPS, the first human avatar that solely\nuses egocentric vision to perceive its surroundings and navigate. Using vision\nas the primary driver of motion however, gives rise to a significant challenge\nfor training avatars: existing datasets have either isolated human motion,\nwithout the context of a scene, or lack scale. We overcome this challenge by\ndecoupling the learning of low-level motion skills from learning of high-level\ncontrol that maps visual input to motion. First, we train a motion prior model\non a large motion capture dataset. Then, a policy is trained using Q-learning\nto map egocentric visual inputs to high-level control commands for the motion\nprior. Our experiments empirically demonstrate that egocentric vision can give\nrise to human-like motion characteristics in our avatars. For example, the\navatars walk such that they avoid obstacles present in their visual field.\nThese findings suggest that equipping avatars with human-like sensors,\nparticularly egocentric vision, holds promise for training avatars that behave\nlike humans.", "published": "2025-09-23 17:18:56", "link": "http://arxiv.org/abs/2509.19259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies", "abstract": "A significant challenge in solid tumors is reliably distinguishing\nconfounding pathologies from malignant neoplasms on routine imaging. While\nradiomics methods seek surrogate markers of lesion heterogeneity on CT/MRI,\nmany aggregate features across the region of interest (ROI) and miss complex\nspatial relationships among varying intensity compositions. We present a new\nGraph-Radiomic Learning (GrRAiL) descriptor for characterizing intralesional\nheterogeneity (ILH) on clinical MRI scans. GrRAiL (1) identifies clusters of\nsub-regions using per-voxel radiomic measurements, then (2) computes\ngraph-theoretic metrics to quantify spatial associations among clusters. The\nresulting weighted graphs encode higher-order spatial relationships within the\nROI, aiming to reliably capture ILH and disambiguate confounding pathologies\nfrom malignancy. To assess efficacy and clinical feasibility, GrRAiL was\nevaluated in n=947 subjects spanning three use cases: differentiating tumor\nrecurrence from radiation effects in glioblastoma (GBM; n=106) and brain\nmetastasis (n=233), and stratifying pancreatic intraductal papillary mucinous\nneoplasms (IPMNs) into no+low vs high risk (n=608). In a multi-institutional\nsetting, GrRAiL consistently outperformed state-of-the-art baselines - Graph\nNeural Networks (GNNs), textural radiomics, and intensity-graph analysis. In\nGBM, cross-validation (CV) and test accuracies for recurrence vs\npseudo-progression were 89% and 78% with >10% test-accuracy gains over\ncomparators. In brain metastasis, CV and test accuracies for recurrence vs\nradiation necrosis were 84% and 74% (>13% improvement). For IPMN risk\nstratification, CV and test accuracies were 84% and 75%, showing >10%\nimprovement.", "published": "2025-09-23 17:18:33", "link": "http://arxiv.org/abs/2509.19258v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ConViS-Bench: Estimating Video Similarity Through Semantic Concepts", "abstract": "What does it mean for two videos to be similar? Videos may appear similar\nwhen judged by the actions they depict, yet entirely different if evaluated\nbased on the locations where they were filmed. While humans naturally compare\nvideos by taking different aspects into account, this ability has not been\nthoroughly studied and presents a challenge for models that often depend on\nbroad global similarity scores. Large Multimodal Models (LMMs) with video\nunderstanding capabilities open new opportunities for leveraging natural\nlanguage in comparative video tasks. We introduce Concept-based Video\nSimilarity estimation (ConViS), a novel task that compares pairs of videos by\ncomputing interpretable similarity scores across a predefined set of key\nsemantic concepts. ConViS allows for human-like reasoning about video\nsimilarity and enables new applications such as concept-conditioned video\nretrieval. To support this task, we also introduce ConViS-Bench, a new\nbenchmark comprising carefully annotated video pairs spanning multiple domains.\nEach pair comes with concept-level similarity scores and textual descriptions\nof both differences and similarities. Additionally, we benchmark several\nstate-of-the-art models on ConViS, providing insights into their alignment with\nhuman judgments. Our results reveal significant performance differences on\nConViS, indicating that some concepts present greater challenges for estimating\nvideo similarity. We believe that ConViS-Bench will serve as a valuable\nresource for advancing research in language-driven video understanding.", "published": "2025-09-23 17:06:11", "link": "http://arxiv.org/abs/2509.19245v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation", "abstract": "We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM)\ncapable of image understanding and generation tasks. Unlike existing multimodal\ndiffsion language models such as MMaDa and Muddit which only support simple\nimage-level understanding tasks and low-resolution image generation, Lavida-O\nexhibits many new capabilities such as object grounding, image-editing, and\nhigh-resolution (1024px) image synthesis. It is also the first unified MDM that\nuses its understanding capabilities to improve image generation and editing\nresults through planning and iterative self-reflection. To allow effective and\nefficient training and sampling, Lavida-O ntroduces many novel techniques such\nas Elastic Mixture-of-Transformer architecture, universal text conditioning,\nand stratified sampling. \\ours~achieves state-of-the-art performance on a wide\nrange of benchmarks such as RefCOCO object grounding, GenEval text-to-image\ngeneration, and ImgEdit image editing, outperforming existing autoregressive\nand continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while\noffering considerable speedup at inference.", "published": "2025-09-23 17:05:46", "link": "http://arxiv.org/abs/2509.19244v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces", "abstract": "The rise of realistic digital face generation and manipulation poses\nsignificant social risks. The primary challenge lies in the rapid and diverse\nevolution of generation techniques, which often outstrip the detection\ncapabilities of existing models. To defend against the ever-evolving new types\nof forgery, we need to enable our model to quickly adapt to new domains with\nlimited computation and data while avoiding forgetting previously learned\nforgery types. In this work, we posit that genuine facial samples are abundant\nand relatively stable in acquisition methods, while forgery faces continuously\nevolve with the iteration of manipulation techniques. Given the practical\ninfeasibility of exhaustively collecting all forgery variants, we frame face\nforgery detection as a continual learning problem and allow the model to\ndevelop as new forgery types emerge. Specifically, we employ a Developmental\nMixture of Experts (MoE) architecture that uses LoRA models as its individual\nexperts. These experts are organized into two groups: a Real-LoRA to learn and\nrefine knowledge of real faces, and multiple Fake-LoRAs to capture incremental\ninformation from different forgery types. To prevent catastrophic forgetting,\nwe ensure that the learning direction of Fake-LoRAs is orthogonal to the\nestablished subspace. Moreover, we integrate orthogonal gradients into the\northogonal loss of Fake-LoRAs, preventing gradient interference throughout the\ntraining process of each task. Experimental results under both the datasets and\nmanipulation types incremental protocols demonstrate the effectiveness of our\nmethod.", "published": "2025-09-23 16:52:27", "link": "http://arxiv.org/abs/2509.19230v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data", "abstract": "Accurate plant segmentation in thermal imagery remains a significant\nchallenge for high throughput field phenotyping, particularly in outdoor\nenvironments where low contrast between plants and weeds and frequent\nocclusions hinder performance. To address this, we present a framework that\nleverages synthetic RGB imagery, a limited set of real annotations, and\nGAN-based cross-modality alignment to enhance semantic segmentation in thermal\nimages. We trained models on 1,128 synthetic images containing complex mixtures\nof crop and weed plants in order to generate image segmentation masks for crop\nand weed plants. We additionally evaluated the benefit of integrating as few as\nfive real, manually segmented field images within the training process using\nvarious sampling strategies. When combining all the synthetic images with a few\nlabeled real images, we observed a maximum relative improvement of 22% for the\nweed class and 17% for the plant class compared to the full real-data baseline.\nCross-modal alignment was enabled by translating RGB to thermal using\nCycleGAN-turbo, allowing robust template matching without calibration. Results\ndemonstrated that combining synthetic data with limited manual annotations and\ncross-domain translation via generative models can significantly boost\nsegmentation performance in complex field environments for multi-model imagery.", "published": "2025-09-23 16:29:13", "link": "http://arxiv.org/abs/2509.19208v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs", "abstract": "Contrastive vision-language models (VLMs) have made significant progress in\nbinding visual and textual information, but understanding long, dense captions\nremains an open challenge. We hypothesize that compositionality, the capacity\nto reason about object-attribute bindings and inter-object relationships, is\nkey to understanding longer captions. In this paper, we investigate the\ninteraction between compositionality and long-caption understanding, asking\nwhether training for one property enhances the other. We train and evaluate a\nrange of models that target each of these capabilities. Our results reveal a\nbidirectional relationship: compositional training improves performance on\nlong-caption retrieval, and training on long captions promotes\ncompositionality. However, these gains are sensitive to data quality and model\ndesign. We find that training on poorly structured captions, or with limited\nparameter updates, fails to support generalization. Likewise, strategies that\naim at retaining general alignment, such as freezing positional embeddings, do\nnot improve compositional understanding. Overall, we find that compositional\nunderstanding and long-caption understanding are intertwined capabilities that\ncan be jointly learned through training on dense, grounded descriptions.\nDespite these challenges, we show that models trained on high-quality,\nlong-caption data can achieve strong performance in both tasks, offering\npractical guidance for improving VLM generalization.", "published": "2025-09-23 16:28:51", "link": "http://arxiv.org/abs/2509.19207v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions", "abstract": "Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have\nbecome the standard approach for learning discriminative vision-language\nrepresentations. However, these models often exhibit shallow language\nunderstanding, manifesting bag-of-words behaviour. These limitations are\nreinforced by their dual-encoder design, which induces a modality gap.\nAdditionally, the reliance on vast web-collected data corpora for training\nmakes the process computationally expensive and introduces significant privacy\nconcerns. To address these limitations, in this work, we challenge the\nnecessity of vision encoders for retrieval tasks by introducing a vision-free,\nsingle-encoder retrieval pipeline. Departing from the traditional text-to-image\nretrieval paradigm, we migrate to a text-to-text paradigm with the assistance\nof VLLM-generated structured image descriptions. We demonstrate that this\nparadigm shift has significant advantages, including a substantial reduction of\nthe modality gap, improved compositionality, and better performance on short\nand long caption queries, all attainable with only a few hours of calibration\non two GPUs. Additionally, substituting raw images with textual descriptions\nintroduces a more privacy-friendly alternative for retrieval. To further assess\ngeneralisation and address some of the shortcomings of prior compositionality\nbenchmarks, we release two benchmarks derived from Flickr30k and COCO,\ncontaining diverse compositional queries made of short captions, which we coin\nsubFlickr and subCOCO. Our vision-free retriever matches and often surpasses\ntraditional multimodal models. Importantly, our approach achieves\nstate-of-the-art zero-shot performance on multiple retrieval and\ncompositionality benchmarks, with models as small as 0.3B parameters. Code is\navailable at: https://github.com/IoannaNti/LexiCLIP", "published": "2025-09-23 16:22:27", "link": "http://arxiv.org/abs/2509.19203v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models", "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable performance across\na variety of real-world tasks. However, existing VLMs typically process visual\ninformation by serializing images, a method that diverges significantly from\nthe parallel nature of human vision. Moreover, their opaque internal mechanisms\nhinder both deeper understanding and architectural innovation. Inspired by the\ndual-stream hypothesis of human vision, which distinguishes the \"what\" and\n\"where\" pathways, we deconstruct the visual processing in VLMs into object\nrecognition and spatial perception for separate study. For object recognition,\nwe convert images into text token maps and find that the model's perception of\nimage content unfolds as a two-stage process from shallow to deep layers,\nbeginning with attribute recognition and culminating in semantic\ndisambiguation. For spatial perception, we theoretically derive and empirically\nverify the geometric structure underlying the positional representation in\nVLMs. Based on these findings, we introduce an instruction-agnostic token\ncompression algorithm based on a plug-and-play visual decoder to improve\ndecoding efficiency, and a RoPE scaling technique to enhance spatial reasoning.\nThrough rigorous experiments, our work validates these analyses, offering a\ndeeper understanding of VLM internals and providing clear principles for\ndesigning more capable future architectures.", "published": "2025-09-23 16:07:18", "link": "http://arxiv.org/abs/2509.19191v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC", "abstract": "This technical report explores the MOSEv2 track of the LSVOS Challenge, which\ntargets complex semi-supervised video object segmentation. By analysing and\nadapting SeC, an enhanced SAM-2 framework, we conduct a detailed study of its\nlong-term memory and concept-aware memory, showing that long-term memory\npreserves temporal continuity under occlusion and reappearance, while\nconcept-aware memory supplies semantic priors that suppress distractors;\ntogether, these traits directly benefit several MOSEv2's core challenges. Our\nsolution achieves a JF score of 39.89% on the test set, ranking 1st in the\nMOSEv2 track of the LSVOS Challenge.", "published": "2025-09-23 15:58:13", "link": "http://arxiv.org/abs/2509.19183v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives", "abstract": "Colorectal cancer (CRC), a lethal disease, begins with the growth of abnormal\nmucosal cell proliferation called polyps in the inner wall of the colon. When\nleft undetected, polyps can become malignant tumors. Colonoscopy is the\nstandard procedure for detecting polyps, as it enables direct visualization and\nremoval of suspicious lesions. Manual detection by colonoscopy can be\ninconsistent and is subject to oversight. Therefore, object detection based on\ndeep learning offers a better solution for a more accurate and real-time\ndiagnosis during colonoscopy. In this work, we propose YOLO-LAN, a YOLO-based\npolyp detection pipeline, trained using M2IoU loss, versatile data\naugmentations and negative data to replicate real clinical situations. Our\npipeline outperformed existing methods for the Kvasir-seg and BKAI-IGH NeoPolyp\ndatasets, achieving mAP$_{50}$ of 0.9619, mAP$_{50:95}$ of 0.8599 with YOLOv12\nand mAP$_{50}$ of 0.9540, mAP$_{50:95}$ of 0.8487 with YOLOv8 on the Kvasir-seg\ndataset. The significant increase is achieved in mAP$_{50:95}$ score, showing\nthe precision of polyp detection. We show robustness based on polyp size and\nprecise location detection, making it clinically relevant in AI-assisted\ncolorectal screening.", "published": "2025-09-23 15:41:44", "link": "http://arxiv.org/abs/2509.19166v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit", "abstract": "Spiking Neural Networks (SNNs) offer significant potential for enabling\nenergy-efficient intelligence at the edge. However, performing full SNN\ninference at the edge can be challenging due to the latency and energy\nconstraints arising from fixed and high timestep overheads. Edge-cloud\nco-inference systems present a promising solution, but their deployment is\noften hindered by high latency and feature transmission costs. To address these\nissues, we introduce NeuCODEX, a neuromorphic co-inference architecture that\njointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a\nlearned spike-driven compression module to reduce data transmission and employs\na dynamic early-exit mechanism to adaptively terminate inference based on\noutput confidence. We evaluated NeuCODEX on both static images (CIFAR10 and\nCaltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To\ndemonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16\nbackbones in a real edge-to-cloud testbed. Our proposed system reduces data\ntransfer by up to 2048x and edge energy consumption by over 90%, while reducing\nend-to-end latency by up to 3x compared to edge-only inference, all with a\nnegligible accuracy drop of less than 2%. In doing so, NeuCODEX enables\npractical, high-performance SNN deployment in resource-constrained\nenvironments.", "published": "2025-09-23 15:34:33", "link": "http://arxiv.org/abs/2509.19156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments", "abstract": "We introduce KAMERA: a comprehensive system for multi-camera, multi-spectral\nsynchronization and real-time detection of seals and polar bears. Utilized in\naerial surveys for ice-associated seals in the Bering, Chukchi, and Beaufort\nseas around Alaska, KAMERA provides up to an 80% reduction in dataset\nprocessing time over previous methods. Our rigorous calibration and hardware\nsynchronization enable using multiple spectra for object detection. All\ncollected data are annotated with metadata so they can be easily referenced\nlater. All imagery and animal detections from a survey are mapped onto a world\nplane for accurate surveyed area estimates and quick assessment of survey\nresults. We hope KAMERA will inspire other mapping and detection efforts in the\nscientific community, with all software, models, and schematics fully\nopen-sourced.", "published": "2025-09-23 15:15:37", "link": "http://arxiv.org/abs/2509.19129v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Track-On2: Enhancing Online Point Tracking with Memory", "abstract": "In this paper, we consider the problem of long-term point tracking, which\nrequires consistent identification of points across video frames under\nsignificant appearance changes, motion, and occlusion. We target the online\nsetting, i.e. tracking points frame-by-frame, making it suitable for real-time\nand streaming applications. We extend our prior model Track-On into Track-On2,\na simple and efficient transformer-based model for online long-term tracking.\nTrack-On2 improves both performance and efficiency through architectural\nrefinements, more effective use of memory, and improved synthetic training\nstrategies. Unlike prior approaches that rely on full-sequence access or\niterative updates, our model processes frames causally and maintains temporal\ncoherence via a memory mechanism, which is key to handling drift and occlusions\nwithout requiring future frames. At inference, we perform coarse patch-level\nclassification followed by refinement. Beyond architecture, we systematically\nstudy synthetic training setups and their impact on memory behavior, showing\nhow they shape temporal robustness over long sequences. Through comprehensive\nexperiments, Track-On2 achieves state-of-the-art results across five synthetic\nand real-world benchmarks, surpassing prior online trackers and even strong\noffline methods that exploit bidirectional context. These results highlight the\neffectiveness of causal, memory-based architectures trained purely on synthetic\ndata as scalable solutions for real-world point tracking. Project page:\nhttps://kuis-ai.github.io/track_on2", "published": "2025-09-23 15:00:18", "link": "http://arxiv.org/abs/2509.19115v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Investigating Traffic Accident Detection Using Multimodal Large Language Models", "abstract": "Traffic safety remains a critical global concern, with timely and accurate\naccident detection essential for hazard reduction and rapid emergency response.\nInfrastructure-based vision sensors offer scalable and efficient solutions for\ncontinuous real-time monitoring, facilitating automated detection of acci-\ndents directly from captured images. This research investigates the zero-shot\ncapabilities of multimodal large language models (MLLMs) for detecting and\ndescribing traffic accidents using images from infrastructure cameras, thus\nminimizing reliance on extensive labeled datasets. Main contributions include:\n(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,\nexplicitly addressing the scarcity of diverse, realistic, infrastructure-based\naccident data through controlled simulations; (2) Comparative performance\nanalysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in acci- dent\nidentification and descriptive capabilities without prior fine-tuning; and (3)\nIntegration of advanced visual analytics, specifically YOLO for object\ndetection, Deep SORT for multi- object tracking, and Segment Anything (SAM) for\ninstance segmentation, into enhanced prompts to improve model accuracy and\nexplainability. Key numerical results show Pixtral as the top performer with an\nF1-score of 0.71 and 83% recall, while Gemini models gained precision with\nenhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and\nrecall losses. Gemma 3 offered the most balanced performance with minimal\nmetric fluctuation. These findings demonstrate the substantial potential of\nintegrating MLLMs with advanced visual analytics techniques, enhancing their\napplicability in real-world automated traffic monitoring systems.", "published": "2025-09-23 14:47:33", "link": "http://arxiv.org/abs/2509.19096v1", "categories": ["cs.CV", "cs.SE"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications", "abstract": "Multi-spectral imagery plays a crucial role in diverse Remote Sensing\napplications including land-use classification, environmental monitoring and\nurban planning. These images are widely adopted because their additional\nspectral bands correlate strongly with physical materials on the ground, such\nas ice, water, and vegetation. This allows for more accurate identification,\nand their public availability from missions, such as Sentinel-2 and Landsat,\nonly adds to their value. Currently, the automatic analysis of such data is\npredominantly managed through machine learning models specifically trained for\nmulti-spectral input, which are costly to train and support. Furthermore,\nalthough providing a lot of utility for Remote Sensing, such additional inputs\ncannot be used with powerful generalist large multimodal models, which are\ncapable of solving many visual problems, but are not able to understand\nspecialized multi-spectral signals.\n  To address this, we propose a training-free approach which introduces new\nmulti-spectral data in a Zero-Shot-only mode, as inputs to generalist\nmultimodal models, trained on RGB-only inputs. Our approach leverages the\nmultimodal models' understanding of the visual space, and proposes to adapt to\ninputs to that space, and to inject domain-specific information as instructions\ninto the model. We exemplify this idea with the Gemini2.5 model and observe\nstrong Zero-Shot performance gains of the approach on popular Remote Sensing\nbenchmarks for land cover and land use classification and demonstrate the easy\nadaptability of Gemini2.5 to new inputs. These results highlight the potential\nfor geospatial professionals, working with non-standard specialized inputs, to\neasily leverage powerful multimodal models, such as Gemini2.5, to accelerate\ntheir work, benefiting from their rich reasoning and contextual capabilities,\ngrounded in the specialized sensor data.", "published": "2025-09-23 14:40:52", "link": "http://arxiv.org/abs/2509.19087v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference", "abstract": "Sa2VA is a recent model for language-guided dense grounding in images and\nvideo that achieves state-of-the-art results on multiple segmentation\nbenchmarks and that has become widely popular. However, we found that Sa2VA\ndoes not perform according to its full potential for referring video object\nsegmentation tasks. We identify inconsistencies between training and inference\nprocedures as the key factor holding it back. To mitigate this issue, we\npropose an improved version of Sa2VA, Sa2VA-i, that rectifies these issues and\nimproves the results. In fact, Sa2VA-i sets a new state of the art for multiple\nvideo benchmarks and achieves improvements of up to +11.6 J&F on MeViS, +1.4 on\nRef-YT-VOS, +3.3 on Ref-DAVIS and +4.1 on ReVOS using the same Sa2VA\ncheckpoints. With our fixes, the Sa2VA-i-1B model even performs on par with the\noriginal Sa2VA-26B model on the MeViS benchmark. We hope that this work will\nshow the importance of seemingly trivial implementation details and that it\nwill provide valuable insights for the referring video segmentation field. We\nprovide the code and updated models at https://github.com/kumuji/sa2va-i", "published": "2025-09-23 14:38:25", "link": "http://arxiv.org/abs/2509.19082v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction", "abstract": "3D Gaussian Splatting (3DGS) has become a powerful representation for\nimage-based object reconstruction, yet its performance drops sharply in\nsparse-view settings. Prior works address this limitation by employing\ndiffusion models to repair corrupted renders, subsequently using them as pseudo\nground truths for later optimization. While effective, such approaches incur\nheavy computation from the diffusion fine-tuning and repair steps. We present\nWaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object\nreconstruction. Our key idea is to shift diffusion into the wavelet domain:\ndiffusion is applied only to the low-resolution LL subband, while\nhigh-frequency subbands are refined with a lightweight network. We further\npropose an efficient online random masking strategy to curate training pairs\nfor diffusion fine-tuning, replacing the commonly used, but inefficient,\nleave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360\nand OmniObject3D, show WaveletGaussian achieves competitive rendering quality\nwhile substantially reducing training time.", "published": "2025-09-23 14:34:10", "link": "http://arxiv.org/abs/2509.19073v1", "categories": ["cs.CV", "eess.IV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation", "abstract": "Accurate segmentation of cardiac anatomy in echocardiography is essential for\ncardiovascular diagnosis and treatment. Yet echocardiography is prone to\ndeformation and speckle noise, causing frame-to-frame segmentation jitter. Even\nwith high accuracy in single-frame segmentation, temporal instability can\nweaken functional estimates and impair clinical interpretability. To address\nthese issues, we propose DyL-UNet, a dynamic learning-based temporal\nconsistency U-Net segmentation architecture designed to achieve temporally\nstable and precise echocardiographic segmentation. The framework constructs an\nEcho-Dynamics Graph (EDG) through dynamic learning to extract dynamic\ninformation from videos. DyL-UNet incorporates multiple Swin-Transformer-based\nencoder-decoder branches for processing single-frame images. It further\nintroduces Cardiac Phase-Dynamics Attention (CPDA) at the skip connections,\nwhich uses EDG-encoded dynamic features and cardiac-phase cues to enforce\ntemporal consistency during segmentation. Extensive experiments on the CAMUS\nand EchoNet-Dynamic datasets demonstrate that DyL-UNet maintains segmentation\naccuracy comparable to existing methods while achieving superior temporal\nconsistency, providing a reliable solution for automated clinical\nechocardiography.", "published": "2025-09-23 14:17:01", "link": "http://arxiv.org/abs/2509.19052v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks", "abstract": "Black-box adversarial attacks remain challenging due to limited access to\nmodel internals. Existing methods often depend on specific network\narchitectures or require numerous queries, resulting in limited\ncross-architecture transferability and high query costs. To address these\nlimitations, we propose JAD, a latent diffusion model framework for black-box\nadversarial attacks. JAD generates adversarial examples by leveraging a latent\ndiffusion model guided by attention maps distilled from both a convolutional\nneural network (CNN) and a Vision Transformer (ViT) models. By focusing on\nimage regions that are commonly sensitive across architectures, this approach\ncrafts adversarial perturbations that transfer effectively between different\nmodel types. This joint attention distillation strategy enables JAD to be\narchitecture-agnostic, achieving superior attack generalization across diverse\nmodels. Moreover, the generative nature of the diffusion framework yields high\nadversarial sample generation efficiency by reducing reliance on iterative\nqueries. Experiments demonstrate that JAD offers improved attack\ngeneralization, generation efficiency, and cross-architecture transferability\ncompared to existing methods, providing a promising and effective paradigm for\nblack-box adversarial attacks.", "published": "2025-09-23 14:12:41", "link": "http://arxiv.org/abs/2509.19044v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model", "abstract": "In this paper, we propose a weakly supervised semantic segmentation approach\nfor food images which takes advantage of the zero-shot capabilities and\npromptability of the Segment Anything Model (SAM) along with the attention\nmechanisms of Vision Transformers (ViTs). Specifically, we use class activation\nmaps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable\nfor food image segmentation. The ViT model, a Swin Transformer, is trained\nexclusively using image-level annotations, eliminating the need for pixel-level\nannotations during training. Additionally, to enhance the quality of the\nSAM-generated masks, we examine the use of image preprocessing techniques in\ncombination with single-mask and multi-mask SAM generation strategies. The\nmethodology is evaluated on the FoodSeg103 dataset, generating an average of\n2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for\nthe multi-mask scenario. We envision the proposed approach as a tool to\naccelerate food image annotation tasks or as an integrated component in food\nand nutrition tracking applications.", "published": "2025-09-23 14:01:51", "link": "http://arxiv.org/abs/2509.19028v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards", "abstract": "Chain of thought reasoning has demonstrated remarkable success in large\nlanguage models, yet its adaptation to vision-language reasoning remains an\nopen challenge with unclear best practices. Existing attempts typically employ\nreasoning chains at a coarse-grained level, which struggles to perform\nfine-grained structured reasoning and, more importantly, are difficult to\nevaluate the reward and quality of intermediate reasoning. In this work, we\ndelve into chain of step reasoning for vision-language models, enabling\nassessing reasoning step quality accurately and leading to effective\nreinforcement learning and inference-time scaling with fine-grained rewards. We\npresent a simple, effective, and fully transparent framework, including the\nstep-level reasoning data, process reward model (PRM), and reinforcement\nlearning training. With the proposed approaches, our models set strong\nbaselines with consistent improvements on challenging vision-language\nbenchmarks. More importantly, we conduct a thorough empirical analysis and\nablation study, unveiling the impact of each component and several intriguing\nproperties of inference-time scaling. We believe this paper serves as a\nbaseline for vision-language models and offers insights into more complex\nmultimodal reasoning. Our dataset, PRM, and code will be available at\nhttps://github.com/baaivision/CoS.", "published": "2025-09-23 13:47:32", "link": "http://arxiv.org/abs/2509.19003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Category-Level Object Shape and Pose Estimation in Less Than a Millisecond", "abstract": "Object shape and pose estimation is a foundational robotics problem,\nsupporting tasks from manipulation to scene understanding and navigation. We\npresent a fast local solver for shape and pose estimation which requires only\ncategory-level object priors and admits an efficient certificate of global\noptimality. Given an RGB-D image of an object, we use a learned front-end to\ndetect sparse, category-level semantic keypoints on the target object. We\nrepresent the target object's unknown shape using a linear active shape model\nand pose a maximum a posteriori optimization problem to solve for position,\norientation, and shape simultaneously. Expressed in unit quaternions, this\nproblem admits first-order optimality conditions in the form of an eigenvalue\nproblem with eigenvector nonlinearities. Our primary contribution is to solve\nthis problem efficiently with self-consistent field iteration, which only\nrequires computing a 4-by-4 matrix and finding its minimum eigenvalue-vector\npair at each iterate. Solving a linear system for the corresponding Lagrange\nmultipliers gives a simple global optimality certificate. One iteration of our\nsolver runs in about 100 microseconds, enabling fast outlier rejection. We test\nour method on synthetic data and a variety of real-world settings, including\ntwo public datasets and a drone tracking scenario. Code is released at\nhttps://github.com/MIT-SPARK/Fast-ShapeAndPose.", "published": "2025-09-23 13:29:32", "link": "http://arxiv.org/abs/2509.18979v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images", "abstract": "Domain adaptive segmentation (DAS) of numerous organelle instances from\nlarge-scale electron microscopy (EM) is a promising way to enable\nannotation-efficient learning. Inspired by SAM, we propose a promptable\nmultitask framework, namely Prompt-DAS, which is flexible enough to utilize any\nnumber of point prompts during the adaptation training stage and testing stage.\nThus, with varying prompt configurations, Prompt-DAS can perform unsupervised\ndomain adaptation (UDA) and weakly supervised domain adaptation (WDA), as well\nas interactive segmentation during testing. Unlike the foundation model SAM,\nwhich necessitates a prompt for each individual object instance, Prompt-DAS is\nonly trained on a small dataset and can utilize full points on all instances,\nsparse points on partial instances, or even no points at all, facilitated by\nthe incorporation of an auxiliary center-point detection task. Moreover, a\nnovel prompt-guided contrastive learning is proposed to enhance discriminative\nfeature learning. Comprehensive experiments conducted on challenging benchmarks\ndemonstrate the effectiveness of the proposed approach over existing UDA, WDA,\nand SAM-based approaches.", "published": "2025-09-23 13:26:06", "link": "http://arxiv.org/abs/2509.18973v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generative data augmentation for biliary tract detection on intraoperative images", "abstract": "Cholecystectomy is one of the most frequently performed procedures in\ngastrointestinal surgery, and the laparoscopic approach is the gold standard\nfor symptomatic cholecystolithiasis and acute cholecystitis. In addition to the\nadvantages of a significantly faster recovery and better cosmetic results, the\nlaparoscopic approach bears a higher risk of bile duct injury, which has a\nsignificant impact on quality of life and survival. To avoid bile duct injury,\nit is essential to improve the intraoperative visualization of the bile duct.\nThis work aims to address this problem by leveraging a deep-learning approach\nfor the localization of the biliary tract from white-light images acquired\nduring the surgical procedures. To this end, the construction and annotation of\nan image database to train the Yolo detection algorithm has been employed.\nBesides classical data augmentation techniques, the paper proposes Generative\nAdversarial Network (GAN) for the generation of a synthetic portion of the\ntraining dataset. Experimental results have been discussed along with ethical\nconsiderations.", "published": "2025-09-23 13:11:53", "link": "http://arxiv.org/abs/2509.18958v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting", "abstract": "Mirror-containing environments pose unique challenges for 3D reconstruction\nand novel view synthesis (NVS), as reflective surfaces introduce view-dependent\ndistortions and inconsistencies. While cutting-edge methods such as Neural\nRadiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical\nscenes, their performance deteriorates in the presence of mirrors. Existing\nsolutions mainly focus on handling mirror surfaces through symmetry mapping but\noften overlook the rich information carried by mirror reflections. These\nreflections offer complementary perspectives that can fill in absent details\nand significantly enhance reconstruction quality. To advance 3D reconstruction\nin mirror-rich environments, we present MirrorScene3D, a comprehensive dataset\nfeaturing diverse indoor scenes, 1256 high-quality images, and annotated mirror\nmasks, providing a benchmark for evaluating reconstruction methods in\nreflective settings. Building on this, we propose ReflectiveGS, an extension of\n3D Gaussian Splatting that utilizes mirror reflections as complementary\nviewpoints rather than simple symmetry artifacts, enhancing scene geometry and\nrecovering absent details. Experiments on MirrorScene3D show that\nReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and\ntraining speed, setting a new benchmark for 3D reconstruction in mirror-rich\nenvironments.", "published": "2025-09-23 13:06:00", "link": "http://arxiv.org/abs/2509.18956v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation", "abstract": "LiDAR-based localization and SLAM often rely on iterative matching\nalgorithms, particularly the Iterative Closest Point (ICP) algorithm, to align\nsensor data with pre-existing maps or previous scans. However, ICP is prone to\nerrors in featureless environments and dynamic scenes, leading to inaccurate\npose estimation. Accurately predicting the uncertainty associated with ICP is\ncrucial for robust state estimation but remains challenging, as existing\napproaches often rely on handcrafted models or simplified assumptions.\nMoreover, a few deep learning-based methods for localizability estimation\neither depend on a pre-built map, which may not always be available, or provide\na binary classification of localizable versus non-localizable, which fails to\nproperly model uncertainty. In this work, we propose a data-driven framework\nthat leverages deep learning to estimate the registration error covariance of\nICP before matching, even in the absence of a reference map. By associating\neach LiDAR scan with a reliable 6-DoF error covariance estimate, our method\nenables seamless integration of ICP within Kalman filtering, enhancing\nlocalization accuracy and robustness. Extensive experiments on the KITTI\ndataset demonstrate the effectiveness of our approach, showing that it\naccurately predicts covariance and, when applied to localization using a\npre-built map or SLAM, reduces localization errors and improves robustness.", "published": "2025-09-23 13:02:44", "link": "http://arxiv.org/abs/2509.18954v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "One-shot Embroidery Customization via Contrastive LoRA Modulation", "abstract": "Diffusion models have significantly advanced image manipulation techniques,\nand their ability to generate photorealistic images is beginning to transform\nretail workflows, particularly in presale visualization. Beyond artistic style\ntransfer, the capability to perform fine-grained visual feature transfer is\nbecoming increasingly important. Embroidery is a textile art form characterized\nby intricate interplay of diverse stitch patterns and material properties,\nwhich poses unique challenges for existing style transfer methods. To explore\nthe customization for such fine-grained features, we propose a novel\ncontrastive learning framework that disentangles fine-grained style and content\nfeatures with a single reference image, building on the classic concept of\nimage analogy. We first construct an image pair to define the target style, and\nthen adopt a similarity metric based on the decoupled representations of\npretrained diffusion models for style-content separation. Subsequently, we\npropose a two-stage contrastive LoRA modulation technique to capture\nfine-grained style features. In the first stage, we iteratively update the\nwhole LoRA and the selected style blocks to initially separate style from\ncontent. In the second stage, we design a contrastive learning strategy to\nfurther decouple style and content through self-knowledge distillation.\nFinally, we build an inference pipeline to handle image or text inputs with\nonly the style blocks. To evaluate our method on fine-grained style transfer,\nwe build a benchmark for embroidery customization. Our approach surpasses prior\nmethods on this task and further demonstrates strong generalization to three\nadditional domains: artistic style transfer, sketch colorization, and\nappearance transfer.", "published": "2025-09-23 12:58:15", "link": "http://arxiv.org/abs/2509.18948v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Quantum Random Synthetic Skyrmion Texture Generation, a Qiskit Simulation", "abstract": "An integer winding, i.e., topological charge, is a characteristic of\nskyrmions, which are topologically nontrivial spin patterns in magnets. They\nemerge when smooth two-dimensional spin configurations are stabilized by\nconflicting interactions such as exchange, anisotropy, the\nDzyaloshinskii-Moriya interaction, or geometric frustration. These nanoscale\ntextures, which are typically a few to tens of nanometers in size, are strong\n'particle-like' excitations because they are shielded by energy barriers\nconnected to their topology. By exploiting their helicity, i.e., spin rotation\nangle or associated internal modes, as a two-level system, skyrmions can\nfunction as quantum bits or qubits. Two quantized helicity states of a\nnanometer-scale skyrmion encode the logical value states in a 'skyrmion qubit.'\nInterestingly, skyrmion qubits are topologically protected and macroscopic,\ni.e., they involve a large number of spins; however, external influences can\nstill affect them. When the texture is tiny and disconnected, the helicity\nangle of the skyrmion becomes quantized. A qubit basis is made up of the lowest\ntwo energy eigenstates, i.e., symmetric or antisymmetric superpositions of\nopposite helicity, for example. Therefore, Skyrmion textures can provide\nvaluable insights for different purposes. However, is it possible to\nsynthetically generate skyrmion textures using quantum computing? This paper\ninvestigates the possibility and generates a few hundred different textures,\nproducing sample comparisons from various types, which indicate a novel\ndirection for skyrmion-based research based on quantum randomness and other\ncriteria.", "published": "2025-09-23 12:58:12", "link": "http://arxiv.org/abs/2509.18947v1", "categories": ["quant-ph", "cs.CV"], "primary_category": "quant-ph"}
{"title": "SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines", "abstract": "Dendritic spines are key structural components of excitatory synapses in the\nbrain. Given the size of dendritic spines provides a proxy for synaptic\nefficacy, their detection and tracking across time is important for studies of\nthe neural basis of learning and memory. Despite their relevance, large-scale\nanalyses of the structural dynamics of dendritic spines in 3D+time microscopy\ndata remain challenging and labor-intense. Here, we present a modular machine\nlearning-based pipeline designed to automate the detection, time-tracking, and\nfeature extraction of dendritic spines in volumes chronically recorded with\ntwo-photon microscopy. Our approach tackles the challenges posed by biological\ndata by combining a transformer-based detection module, a depth-tracking\ncomponent that integrates spatial features, a time-tracking module to associate\n3D spines across time by leveraging spatial consistency, and a feature\nextraction unit that quantifies biologically relevant spine properties. We\nvalidate our method on open-source labeled spine data, and on two complementary\nannotated datasets that we publish alongside this work: one for detection and\ndepth-tracking, and one for time-tracking, which, to the best of our knowledge,\nis the first data of this kind. To encourage future research, we release our\ndata, code, and pre-trained weights at\nhttps://github.com/pamelaosuna/SynapFlow, establishing a baseline for scalable,\nend-to-end analysis of dendritic spine dynamics.", "published": "2025-09-23 12:47:43", "link": "http://arxiv.org/abs/2509.18926v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Audio-Driven Universal Gaussian Head Avatars", "abstract": "We introduce the first method for audio-driven universal photorealistic\navatar synthesis, combining a person-agnostic speech model with our novel\nUniversal Head Avatar Prior (UHAP). UHAP is trained on cross-identity\nmulti-view videos. In particular, our UHAP is supervised with neutral scan\ndata, enabling it to capture the identity-specific details at high fidelity. In\ncontrast to previous approaches, which predominantly map audio features to\ngeometric deformations only while ignoring audio-dependent appearance\nvariations, our universal speech model directly maps raw audio inputs into the\nUHAP latent expression space. This expression space inherently encodes, both,\ngeometric and appearance variations. For efficient personalization to new\nsubjects, we employ a monocular encoder, which enables lightweight regression\nof dynamic expression variations across video frames. By accounting for these\nexpression-dependent changes, it enables the subsequent model fine-tuning stage\nto focus exclusively on capturing the subject's global appearance and geometry.\nDecoding these audio-driven expression codes via UHAP generates highly\nrealistic avatars with precise lip synchronization and nuanced expressive\ndetails, such as eyebrow movement, gaze shifts, and realistic mouth interior\nappearance as well as motion. Extensive evaluations demonstrate that our method\nis not only the first generalizable audio-driven avatar model that can account\nfor detailed appearance modeling and rendering, but it also outperforms\ncompeting (geometry-only) methods across metrics measuring lip-sync accuracy,\nquantitative image quality, and perceptual realism.", "published": "2025-09-23 12:46:43", "link": "http://arxiv.org/abs/2509.18924v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset", "abstract": "The pretraining-finetuning paradigm is a crucial strategy in metallic surface\ndefect detection for mitigating the challenges posed by data scarcity. However,\nits implementation presents a critical dilemma. Pretraining on natural image\ndatasets such as ImageNet, faces a significant domain gap. Meanwhile, naive\nself-supervised pretraining on in-domain industrial data is often ineffective\ndue to the inability of existing learning objectives to distinguish subtle\ndefect patterns from complex background noise and textures. To resolve this, we\nintroduce Anomaly-Guided Self-Supervised Pretraining (AGSSP), a novel paradigm\nthat explicitly guides representation learning through anomaly priors. AGSSP\nemploys a two-stage framework: (1) it first pretrains the model's backbone by\ndistilling knowledge from anomaly maps, encouraging the network to capture\ndefect-salient features; (2) it then pretrains the detector using pseudo-defect\nboxes derived from these maps, aligning it with localization tasks. To enable\nthis, we develop a knowledge-enhanced method to generate high-quality anomaly\nmaps and collect a large-scale industrial dataset of 120,000 images.\nAdditionally, we present two small-scale, pixel-level labeled metallic surface\ndefect datasets for validation. Extensive experiments demonstrate that AGSSP\nconsistently enhances performance across various settings, achieving up to a\n10\\% improvement in mAP@0.5 and 11.4\\% in mAP@0.5:0.95 compared to\nImageNet-based models. All code, pretrained models, and datasets are publicly\navailable at https://clovermini.github.io/AGSSP-Dev/.", "published": "2025-09-23 12:35:32", "link": "http://arxiv.org/abs/2509.18919v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision", "abstract": "Deep learning has become the de facto standard and dominant paradigm in image\nanalysis tasks, achieving state-of-the-art performance. However, this approach\noften results in \"black-box\" models, whose decision-making processes are\ndifficult to interpret, raising concerns about reliability in critical\napplications. To address this challenge and provide human a method to\nunderstand how AI model process and make decision, the field of xAI has\nemerged. This paper surveys four representative approaches in xAI for visual\nperception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM),\n(iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their\nunderlying mechanisms, strengths and limitations, as well as evaluation\nmetrics, thereby providing a comprehensive overview to guide future research\nand applications.", "published": "2025-09-23 12:33:54", "link": "http://arxiv.org/abs/2509.18913v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation", "abstract": "Audio-visual segmentation (AVS) plays a critical role in multimodal machine\nlearning by effectively integrating audio and visual cues to precisely segment\nobjects or regions within visual scenes. Recent AVS methods have demonstrated\nsignificant improvements. However, they overlook the inherent frequency-domain\ncontradictions between audio and visual modalities--the pervasively interfering\nnoise in audio high-frequency signals vs. the structurally rich details in\nvisual high-frequency signals. Ignoring these differences can result in\nsuboptimal performance. In this paper, we rethink the AVS task from a deeper\nperspective by reformulating AVS task as a frequency-domain decomposition and\nrecomposition problem. To this end, we introduce a novel Frequency-Aware\nAudio-Visual Segmentation (FAVS) framework consisting of two key modules:\nFrequency-Domain Enhanced Decomposer (FDED) module and Synergistic Cross-Modal\nConsistency (SCMC) module. FDED module employs a residual-based iterative\nfrequency decomposition to discriminate modality-specific semantics and\nstructural features, and SCMC module leverages a mixture-of-experts\narchitecture to reinforce semantic consistency and modality-specific feature\npreservation through dynamic expert routing. Extensive experiments demonstrate\nthat our FAVS framework achieves state-of-the-art performance on three\nbenchmark datasets, and abundant qualitative visualizations further verify the\neffectiveness of the proposed FDED and SCMC modules. The code will be released\nas open source upon acceptance of the paper.", "published": "2025-09-23 12:33:48", "link": "http://arxiv.org/abs/2509.18912v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Moir\u00e9Net: A Compact Dual-Domain Network for Image Demoir\u00e9ing", "abstract": "Moir\\'e patterns arise from spectral aliasing between display pixel lattices\nand camera sensor grids, manifesting as anisotropic, multi-scale artifacts that\npose significant challenges for digital image demoir\\'eing. We propose\nMoir\\'eNet, a convolutional neural U-Net-based framework that synergistically\nintegrates frequency and spatial domain features for effective artifact\nremoval. Moir\\'eNet introduces two key components: a Directional\nFrequency-Spatial Encoder (DFSE) that discerns moir\\'e orientation via\ndirectional difference convolution, and a Frequency-Spatial Adaptive Selector\n(FSAS) that enables precise, feature-adaptive suppression. Extensive\nexperiments demonstrate that Moir\\'eNet achieves state-of-the-art performance\non public and actively used datasets while being highly parameter-efficient.\nWith only 5.513M parameters, representing a 48% reduction compared to ESDNet-L,\nMoir\\'eNet combines superior restoration quality with parameter efficiency,\nmaking it well-suited for resource-constrained applications including\nsmartphone photography, industrial imaging, and augmented reality.", "published": "2025-09-23 12:33:23", "link": "http://arxiv.org/abs/2509.18910v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring", "abstract": "In this paper, we propose the first Structure-from-Motion (SfM)-free\ndeblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.\nWe address the motion-deblurring problem in two ways. First, we leverage the\npretrained capability of the dense stereo module (DUSt3R) to directly obtain\naccurate initial point clouds from blurred images. Without calculating camera\nposes as an intermediate result, we avoid the cumulative errors transfer from\ninaccurate camera poses to the initial point clouds' positions. Second, we\nintroduce the event stream into the deblur pipeline for its high sensitivity to\ndynamic change. By decoding the latent sharp images from the event stream and\nblurred images, we can provide a fine-grained supervision signal for scene\nreconstruction optimization. Extensive experiments across a range of scenes\ndemonstrate that DeblurSplat not only excels in generating high-fidelity novel\nviews but also achieves significant rendering efficiency compared to the SOTAs\nin deblur 3D-GS.", "published": "2025-09-23 11:21:54", "link": "http://arxiv.org/abs/2509.18898v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing", "abstract": "In this paper, we introduce a novel benchmark designed to propel the\nadvancement of general-purpose, large-scale 3D vision models for remote sensing\nimagery. While several datasets have been proposed within the realm of remote\nsensing, many existing collections either lack comprehensive depth information\nor fail to establish precise alignment between depth data and remote sensing\nimages. To address this deficiency, we present a visual Benchmark for 3D\nunderstanding of Remotely Sensed images, dubbed RS3DBench. This dataset\nencompasses 54,951 pairs of remote sensing images and pixel-level aligned depth\nmaps, accompanied by corresponding textual descriptions, spanning a broad array\nof geographical contexts. It serves as a tool for training and assessing 3D\nvisual perception models within remote sensing image spatial understanding\ntasks. Furthermore, we introduce a remotely sensed depth estimation model\nderived from stable diffusion, harnessing its multimodal fusion capabilities,\nthereby delivering state-of-the-art performance on our dataset. Our endeavor\nseeks to make a profound contribution to the evolution of 3D visual perception\nmodels and the advancement of geographic artificial intelligence within the\nremote sensing domain. The dataset, models and code will be accessed on the\nhttps://rs3dbench.github.io.", "published": "2025-09-23 11:20:51", "link": "http://arxiv.org/abs/2509.18897v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SmartWilds: Multimodal Wildlife Monitoring Dataset", "abstract": "We present the first release of SmartWilds, a multimodal wildlife monitoring\ndataset. SmartWilds is a synchronized collection of drone imagery, camera trap\nphotographs and videos, and bioacoustic recordings collected during summer 2025\nat The Wilds safari park in Ohio. This dataset supports multimodal AI research\nfor comprehensive environmental monitoring, addressing critical needs in\nendangered species research, conservation ecology, and habitat management. Our\npilot deployment captured four days of synchronized monitoring across three\nmodalities in a 220-acre pasture containing Pere David's deer, Sichuan takin,\nPrzewalski's horses, as well as species native to Ohio, including bald eagles,\nwhite-tailed deer, and coyotes. We provide a comparative analysis of sensor\nmodality performance, demonstrating complementary strengths for landuse\npatterns, species detection, behavioral analysis, and habitat monitoring. This\nwork establishes reproducible protocols for multimodal wildlife monitoring\nwhile contributing open datasets to advance conservation computer vision\nresearch. Future releases will include synchronized GPS tracking data from\ntagged individuals, citizen science data, and expanded temporal coverage across\nmultiple seasons.", "published": "2025-09-23 11:07:18", "link": "http://arxiv.org/abs/2509.18894v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model", "abstract": "Prompt quality plays a critical role in the performance of the Segment\nAnything Model (SAM), yet existing approaches often rely on heuristic or\nmanually crafted prompts, limiting scalability and generalization. In this\npaper, we propose Point Prompt Defender, an adversarial reinforcement learning\nframework that adopts an attack-for-defense paradigm to automatically optimize\npoint prompts. We construct a task-agnostic point prompt environment by\nrepresenting image patches as nodes in a dual-space graph, where edges encode\nboth physical and semantic distances. Within this environment, an attacker\nagent learns to activate a subset of prompts that maximally degrade SAM's\nsegmentation performance, while a defender agent learns to suppress these\ndisruptive prompts and restore accuracy. Both agents are trained using Deep\nQ-Networks with a reward signal based on segmentation quality variation. During\ninference, only the defender is deployed to refine arbitrary coarse prompt\nsets, enabling enhanced SAM segmentation performance across diverse tasks\nwithout retraining. Extensive experiments show that Point Prompt Defender\neffectively improves SAM's robustness and generalization, establishing a\nflexible, interpretable, and plug-and-play framework for prompt-based\nsegmentation.", "published": "2025-09-23 10:59:24", "link": "http://arxiv.org/abs/2509.18891v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction", "abstract": "Image Representation Learning is an important problem in Computer Vision.\nTraditionally, images were processed as grids, using Convolutional Neural\nNetworks or as a sequence of visual tokens, using Vision Transformers.\nRecently, Vision Graph Neural Networks (ViG) have proposed the treatment of\nimages as a graph of nodes; which provides a more intuitive image\nrepresentation. The challenge is to construct a graph of nodes in each layer\nthat best represents the relations between nodes and does not need a\nhyper-parameter search. ViG models in the literature depend on\nnon-parameterized and non-learnable statistical methods that operate on the\nlatent features of nodes to create a graph. This might not select the best\nneighborhood for each node. Starting from k-NN graph construction to HyperGraph\nConstruction and Similarity-Thresholded graph construction, these methods lack\nthe ability to provide a learnable hyper-parameter-free graph construction\nmethod. To overcome those challenges, we present the Learnable Reparameterized\nGraph Construction (LRGC) for Vision Graph Neural Networks. LRGC applies\nkey-query attention between every pair of nodes; then uses soft-threshold\nreparameterization for edge selection, which allows the use of a differentiable\nmathematical model for training. Using learnable parameters to select the\nneighborhood removes the bias that is induced by any clustering or thresholding\nmethods previously introduced in the literature. In addition, LRGC allows\ntuning the threshold in each layer to the training data since the thresholds\nare learnable through training and are not provided as hyper-parameters to the\nmodel. We demonstrate that the proposed ViG-LRGC approach outperforms\nstate-of-the-art ViG models of similar sizes on the ImageNet-1k benchmark\ndataset.", "published": "2025-09-23 09:25:22", "link": "http://arxiv.org/abs/2509.18840v1", "categories": ["cs.CV", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography", "abstract": "This study evaluates the capabilities of Multimodal Large Language Models\n(LLMs) and Vision Language Models (VLMs) in the task of single-label\nclassification of Christian Iconography. The goal was to assess whether\ngeneral-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5,\ncan interpret the Iconography, typically addressed by supervised classifiers,\nand evaluate their performance. Two research questions guided the analysis:\n(RQ1) How do multimodal LLMs perform on image classification of Christian\nsaints? And (RQ2), how does performance vary when enriching input with\ncontextual information or few-shot exemplars? We conducted a benchmarking study\nusing three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and\nWikidata, filtered to include the top 10 most frequent classes. Models were\ntested under three conditions: (1) classification using class labels, (2)\nclassification with Iconclass descriptions, and (3) few-shot learning with five\nexemplars. Results were compared against ResNet50 baselines fine-tuned on the\nsame datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed\nthe ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset,\nwhere Siglip reached the highest accuracy score, suggesting model sensitivity\nto image size and metadata alignment. Enriching prompts with class descriptions\ngenerally improved zero-shot performance, while few-shot learning produced\nlower results, with only occasional and minimal increments in accuracy. We\nconclude that general-purpose multimodal LLMs are capable of classification in\nvisually complex cultural heritage domains. These results support the\napplication of LLMs as metadata curation tools in digital humanities workflows,\nsuggesting future research on prompt optimization and the expansion of the\nstudy to other classification strategies and models.", "published": "2025-09-23 09:23:31", "link": "http://arxiv.org/abs/2509.18839v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation", "abstract": "Human skin provides a rich tactile sensing stream, localizing intentional and\nunintentional contact events over a large and contoured region. Replicating\nthese tactile sensing capabilities for dexterous robotic manipulation systems\nremains a longstanding challenge. In this work, we take a step towards this\ngoal by introducing DexSkin. DexSkin is a soft, conformable capacitive\nelectronic skin that enables sensitive, localized, and calibratable tactile\nsensing, and can be tailored to varying geometries. We demonstrate its efficacy\nfor learning downstream robotic manipulation by sensorizing a pair of parallel\njaw gripper fingers, providing tactile coverage across almost the entire finger\nsurfaces. We empirically evaluate DexSkin's capabilities in learning\nchallenging manipulation tasks that require sensing coverage across the entire\nsurface of the fingers, such as reorienting objects in hand and wrapping\nelastic bands around boxes, in a learning-from-demonstration framework. We then\nshow that, critically for data-driven approaches, DexSkin can be calibrated to\nenable model transfer across sensor instances, and demonstrate its\napplicability to online reinforcement learning on real robots. Our results\nhighlight DexSkin's suitability and practicality for learning real-world,\ncontact-rich manipulation. Please see our project webpage for videos and\nvisualizations: https://dex-skin.github.io/.", "published": "2025-09-23 09:16:34", "link": "http://arxiv.org/abs/2509.18830v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation", "abstract": "Unified multimodal models have recently attracted considerable attention for\ntheir remarkable abilities in jointly understanding and generating diverse\ncontent. However, as contexts integrate increasingly numerous interleaved\nmultimodal tokens, the iterative processes of diffusion denoising and\nautoregressive decoding impose significant computational overhead. To address\nthis, we propose Hyper-Bagel, a unified acceleration framework designed to\nsimultaneously speed up both multimodal understanding and generation tasks. Our\napproach uses a divide-and-conquer strategy, employing speculative decoding for\nnext-token prediction and a multi-stage distillation process for diffusion\ndenoising. The framework delivers substantial performance gains, achieving over\na 2x speedup in multimodal understanding. For generative tasks, our resulting\nlossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a\n22x speedup in image editing, all while preserving the high-quality output of\nthe original model. We further develop a highly efficient 1-NFE model that\nenables near real-time interactive editing and generation. By combining\nadvanced adversarial distillation with human feedback learning, this model\nachieves ultimate cost-effectiveness and responsiveness, making complex\nmultimodal interactions seamless and instantaneous.", "published": "2025-09-23 09:12:46", "link": "http://arxiv.org/abs/2509.18824v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Surgical Video Understanding with Label Interpolation", "abstract": "Robot-assisted surgery (RAS) has become a critical paradigm in modern\nsurgery, promoting patient recovery and reducing the burden on surgeons through\nminimally invasive approaches. To fully realize its potential, however, a\nprecise understanding of the visual data generated during surgical procedures\nis essential. Previous studies have predominantly focused on single-task\napproaches, but real surgical scenes involve complex temporal dynamics and\ndiverse instrument interactions that limit comprehensive understanding.\nMoreover, the effective application of multi-task learning (MTL) requires\nsufficient pixel-level segmentation data, which are difficult to obtain due to\nthe high cost and expertise required for annotation. In particular, long-term\nannotations such as phases and steps are available for every frame, whereas\nshort-term annotations such as surgical instrument segmentation and action\ndetection are provided only for key frames, resulting in a significant\ntemporal-spatial imbalance. To address these challenges, we propose a novel\nframework that combines optical flow-based segmentation label interpolation\nwith multi-task learning. optical flow estimated from annotated key frames is\nused to propagate labels to adjacent unlabeled frames, thereby enriching sparse\nspatial supervision and balancing temporal and spatial information for\ntraining. This integration improves both the accuracy and efficiency of\nsurgical scene understanding and, in turn, enhances the utility of RAS.", "published": "2025-09-23 08:49:07", "link": "http://arxiv.org/abs/2509.18802v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Application Aligned Synthetic Surgical Image Synthesis", "abstract": "The scarcity of annotated surgical data poses a significant challenge for\ndeveloping deep learning systems in computer-assisted interventions. While\ndiffusion models can synthesize realistic images, they often suffer from data\nmemorization, resulting in inconsistent or non-diverse samples that may fail to\nimprove, or even harm, downstream performance. We introduce \\emph{Surgical\nApplication-Aligned Diffusion} (SAADi), a new framework that aligns diffusion\nmodels with samples preferred by downstream models. Our method constructs pairs\nof \\emph{preferred} and \\emph{non-preferred} synthetic images and employs\nlightweight fine-tuning of diffusion models to align the image generation\nprocess with downstream objectives explicitly. Experiments on three surgical\ndatasets demonstrate consistent gains of $7$--$9\\%$ in classification and\n$2$--$10\\%$ in segmentation tasks, with the considerable improvements observed\nfor underrepresented classes. Iterative refinement of synthetic samples further\nboosts performance by $4$--$10\\%$. Unlike baseline approaches, our method\novercomes sample degradation and establishes task-aware alignment as a key\nprinciple for mitigating data scarcity and advancing surgical vision\napplications.", "published": "2025-09-23 08:40:40", "link": "http://arxiv.org/abs/2509.18796v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Human-Interpretable Uncertainty Explanations for Point Cloud Registration", "abstract": "In this paper, we address the point cloud registration problem, where\nwell-known methods like ICP fail under uncertainty arising from sensor noise,\npose-estimation errors, and partial overlap due to occlusion. We develop a\nnovel approach, Gaussian Process Concept Attribution (GP-CA), which not only\nquantifies registration uncertainty but also explains it by attributing\nuncertainty to well-known sources of errors in registration problems. Our\napproach leverages active learning to discover new uncertainty sources in the\nwild by querying informative instances. We validate GP-CA on three publicly\navailable datasets and in our real-world robot experiment. Extensive ablations\nsubstantiate our design choices. Our approach outperforms other\nstate-of-the-art methods in terms of runtime, high sample-efficiency with\nactive learning, and high accuracy. Our real-world experiment clearly\ndemonstrates its applicability. Our video also demonstrates that GP-CA enables\neffective failure-recovery behaviors, yielding more robust robotic perception.", "published": "2025-09-23 08:23:51", "link": "http://arxiv.org/abs/2509.18786v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Reconstruction of Optical Coherence Tomography Images from Wavelength-space Using Deep-learning", "abstract": "Conventional Fourier-domain Optical Coherence Tomography (FD-OCT) systems\ndepend on resampling into wavenumber (k) domain to extract the depth profile.\nThis either necessitates additional hardware resources or amplifies the\nexisting computational complexity. Moreover, the OCT images also suffer from\nspeckle noise, due to systemic reliance on low coherence interferometry. We\npropose a streamlined and computationally efficient approach based on\nDeep-Learning (DL) which enables reconstructing speckle-reduced OCT images\ndirectly from the wavelength domain. For reconstruction, two encoder-decoder\nstyled networks namely Spatial Domain Convolution Neural Network (SD-CNN) and\nFourier Domain CNN (FD-CNN) are used sequentially. The SD-CNN exploits the\nhighly degraded images obtained by Fourier transforming the domain fringes to\nreconstruct the deteriorated morphological structures along with suppression of\nunwanted noise. The FD-CNN leverages this output to enhance the image quality\nfurther by optimization in Fourier domain (FD). We quantitatively and visually\ndemonstrate the efficacy of the method in obtaining high-quality OCT images.\nFurthermore, we illustrate the computational complexity reduction by harnessing\nthe power of DL models. We believe that this work lays the framework for\nfurther innovations in the realm of OCT image reconstruction.", "published": "2025-09-23 08:21:53", "link": "http://arxiv.org/abs/2509.18783v1", "categories": ["physics.optics", "cs.CV", "cs.LG"], "primary_category": "physics.optics"}
{"title": "Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning", "abstract": "Deer-vehicle collisions represent a critical safety challenge in the United\nStates, causing nearly 2.1 million incidents annually and resulting in\napproximately 440 fatalities, 59,000 injuries, and 10 billion USD in economic\ndamages. These collisions also contribute significantly to declining deer\npopulations. This paper presents a real-time detection and driver warning\nsystem that integrates thermal imaging, deep learning, and\nvehicle-to-everything communication to help mitigate deer-vehicle collisions.\nOur system was trained and validated on a custom dataset of over 12,000 thermal\ndeer images collected in Mars Hill, North Carolina. Experimental evaluation\ndemonstrates exceptional performance with 98.84 percent mean average precision,\n95.44 percent precision, and 95.96 percent recall. The system was field tested\nduring a follow-up visit to Mars Hill and readily sensed deer providing the\ndriver with advanced warning. Field testing validates robust operation across\ndiverse weather conditions, with thermal imaging maintaining between 88 and 92\npercent detection accuracy in challenging scenarios where conventional visible\nlight based cameras achieve less than 60 percent effectiveness. When a high\nprobability threshold is reached sensor data sharing messages are broadcast to\nsurrounding vehicles and roadside units via cellular vehicle to everything\n(CV2X) communication devices. Overall, our system achieves end to end latency\nconsistently under 100 milliseconds from detection to driver alert. This\nresearch establishes a viable technological pathway for reducing deer-vehicle\ncollisions through thermal imaging and connected vehicles.", "published": "2025-09-23 08:16:25", "link": "http://arxiv.org/abs/2509.18779v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models", "abstract": "We address the critical gap between the computational demands of\nvision-language models and the possible ultra-low-bit weight precision\n(bitwidth $\\leq2$ bits) we can use for higher efficiency. Our work is motivated\nby the substantial computational cost and memory requirements of VLMs, which\nrestrict their applicability in hardware-constrained environments. We propose\nBi-VLM, which separates model weights non-uniformly based on the Gaussian\nquantiles. Our formulation groups the model weights into outlier (salient) and\nmultiple inlier (unsalient) subsets, ensuring that each subset contains a\nproportion of weights corresponding to its quantile in the distribution. We\npropose a saliency-aware hybrid quantization algorithm and use it to quantize\nweights by imposing different constraints on the scaler and binary matrices\nbased on the saliency metric and compression objective. We have evaluated our\napproach on different VLMs. For the language model part of the VLM, our Bi-VLM\noutperforms the SOTA by 3%-47% on the visual question answering task in terms\nof four different benchmarks and three different models. For the overall VLM,\nour Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the\nquantized models and observe that there is redundancy of image tokens 90% - 99%\nin the quantized models. This helps us to further prune the visual tokens to\nimprove efficiency.", "published": "2025-09-23 07:55:48", "link": "http://arxiv.org/abs/2509.18763v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation", "abstract": "Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in\n3D reconstruction and novel view synthesis. However, reconstructing 3D scenes\nfrom sparse viewpoints remains highly challenging due to insufficient visual\ninformation, which results in noticeable artifacts persisting across the 3D\nrepresentation. To address this limitation, recent methods have resorted to\ngenerative priors to remove artifacts and complete missing content in\nunder-constrained areas. Despite their effectiveness, these approaches struggle\nto ensure multi-view consistency, resulting in blurred structures and\nimplausible details. In this work, we propose FixingGS, a training-free method\nthat fully exploits the capabilities of the existing diffusion model for\nsparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our\ndistillation approach, which delivers more accurate and cross-view coherent\ndiffusion priors, thereby enabling effective artifact removal and inpainting.\nIn addition, we propose an adaptive progressive enhancement scheme that further\nrefines reconstructions in under-constrained regions. Extensive experiments\ndemonstrate that FixingGS surpasses existing state-of-the-art methods with\nsuperior visual quality and reconstruction performance. Our code will be\nreleased publicly.", "published": "2025-09-23 07:53:46", "link": "http://arxiv.org/abs/2509.18759v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing", "abstract": "LiDAR-based perception is central to autonomous driving and robotics, yet raw\npoint clouds remain highly vulnerable to noise, occlusion, and adversarial\ncorruptions. Autoencoders offer a natural framework for denoising and\nreconstruction, but their performance degrades under challenging real-world\nconditions. In this work, we propose TriFusion-AE, a multimodal cross-attention\nautoencoder that integrates textual priors, monocular depth maps from\nmulti-view images, and LiDAR point clouds to improve robustness. By aligning\nsemantic cues from text, geometric (depth) features from images, and spatial\nstructure from LiDAR, TriFusion-AE learns representations that are resilient to\nstochastic noise and adversarial perturbations. Interestingly, while showing\nlimited gains under mild perturbations, our model achieves significantly more\nrobust reconstruction under strong adversarial attacks and heavy noise, where\nCNN-based autoencoders collapse. We evaluate on the nuScenes-mini dataset to\nreflect realistic low-data deployment scenarios. Our multimodal fusion\nframework is designed to be model-agnostic, enabling seamless integration with\nany CNN-based point cloud autoencoder for joint representation learning.", "published": "2025-09-23 07:37:28", "link": "http://arxiv.org/abs/2509.18743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection", "abstract": "RGB-thermal salient object detection (RGB-T SOD) aims to identify prominent\nobjects by integrating complementary information from RGB and thermal\nmodalities. However, learning the precise boundaries and complete objects\nremains challenging due to the intrinsic insufficient feature fusion and the\nextrinsic limitations of data scarcity. In this paper, we propose a novel\nhybrid prompt-driven segment anything model (HyPSAM), which leverages the\nzero-shot generalization capabilities of the segment anything model (SAM) for\nRGB-T SOD. Specifically, we first propose a dynamic fusion network (DFNet) that\ngenerates high-quality initial saliency maps as visual prompts. DFNet employs\ndynamic convolution and multi-branch decoding to facilitate adaptive\ncross-modality interaction, overcoming the limitations of fixed-parameter\nkernels and enhancing multi-modal feature representation. Moreover, we propose\na plug-and-play refinement network (P2RNet), which serves as a general\noptimization strategy to guide SAM in refining saliency maps by using hybrid\nprompts. The text prompt ensures reliable modality input, while the mask and\nbox prompts enable precise salient object localization. Extensive experiments\non three public datasets demonstrate that our method achieves state-of-the-art\nperformance. Notably, HyPSAM has remarkable versatility, seamlessly integrating\nwith different RGB-T SOD methods to achieve significant performance gains,\nthereby highlighting the potential of prompt engineering in this field. The\ncode and results of our method are available at:\nhttps://github.com/milotic233/HyPSAM.", "published": "2025-09-23 07:32:11", "link": "http://arxiv.org/abs/2509.18738v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Knowledge Transfer from Interaction Learning", "abstract": "Current visual foundation models (VFMs) face a fundamental limitation in\ntransferring knowledge from vision language models (VLMs), while VLMs excel at\nmodeling cross-modal interactions through unified representation spaces,\nexisting VFMs predominantly adopt result-oriented paradigms that neglect the\nunderlying interaction processes. This representational discrepancy hinders\neffective knowledge transfer and limits generalization across diverse vision\ntasks. We propose Learning from Interactions (LFI), a cognitive-inspired\nframework that addresses this gap by explicitly modeling visual understanding\nas an interactive process. Our key insight is that capturing the dynamic\ninteraction patterns encoded in pre-trained VLMs enables more faithful and\nefficient knowledge transfer to VFMs. The approach centers on two technical\ninnovations, Interaction Queries, which maintain persistent relational\nstructures across network layers, and interaction-based supervision, derived\nfrom the cross-modal attention mechanisms of VLMs. Comprehensive experiments\ndemonstrate consistent improvements across multiple benchmarks, achieving 3.3\nand 1.6mAP/2.4AP absolute gains on TinyImageNet classification and COCO\ndetection/segmentation respectively, with minimal parameter overhead and faster\nconvergence. The framework particularly excels in cross-domain settings,\ndelivering 2.4 and 9.3 zero-shot improvements on PACS and VLCS. Human\nevaluations further confirm its cognitive alignment, outperforming\nresult-oriented methods by 2.7 times in semantic consistency metrics.", "published": "2025-09-23 07:27:36", "link": "http://arxiv.org/abs/2509.18733v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment", "abstract": "Recent studies have shown that Contrastive Language-Image Pre-training (CLIP)\nmodels are threatened by targeted data poisoning and backdoor attacks due to\nmassive training image-caption pairs crawled from the Internet. Previous\ndefense methods correct poisoned image-caption pairs by matching a new caption\nfor each image. However, the matching process relies solely on the global\nrepresentations of images and captions, overlooking fine-grained features of\nvisual and textual features. It may introduce incorrect image-caption pairs and\nharm the CLIP pre-training. To address their limitations, we propose an Optimal\nTransport-based framework to reconstruct image-caption pairs, named OTCCLIP. We\npropose a new optimal transport-based distance measure between fine-grained\nvisual and textual feature sets and re-assign new captions based on the\nproposed optimal transport distance. Additionally, to further reduce the\nnegative impact of mismatched pairs, we encourage the inter- and intra-modality\nfine-grained alignment by employing optimal transport-based objective\nfunctions. Our experiments demonstrate that OTCCLIP can successfully decrease\nthe attack success rates of poisoning attacks. Also, compared to previous\nmethods, OTCCLIP significantly improves CLIP's zero-shot and linear probing\nperformance trained on poisoned datasets.", "published": "2025-09-23 07:05:43", "link": "http://arxiv.org/abs/2509.18717v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "What Makes You Unique? Attribute Prompt Composition for Object Re-Identification", "abstract": "Object Re-IDentification (ReID) aims to recognize individuals across\nnon-overlapping camera views. While recent advances have achieved remarkable\nprogress, most existing models are constrained to either single-domain or\ncross-domain scenarios, limiting their real-world applicability. Single-domain\nmodels tend to overfit to domain-specific features, whereas cross-domain models\noften rely on diverse normalization strategies that may inadvertently suppress\nidentity-specific discriminative cues. To address these limitations, we propose\nan Attribute Prompt Composition (APC) framework, which exploits textual\nsemantics to jointly enhance discrimination and generalization. Specifically,\nwe design an Attribute Prompt Generator (APG) consisting of a Semantic\nAttribute Dictionary (SAD) and a Prompt Composition Module (PCM). SAD is an\nover-complete attribute dictionary to provide rich semantic descriptions, while\nPCM adaptively composes relevant attributes from SAD to generate discriminative\nattribute-aware features. In addition, motivated by the strong generalization\nability of Vision-Language Models (VLM), we propose a Fast-Slow Training\nStrategy (FSTS) to balance ReID-specific discrimination and generalizable\nrepresentation learning. Specifically, FSTS adopts a Fast Update Stream (FUS)\nto rapidly acquire ReID-specific discriminative knowledge and a Slow Update\nStream (SUS) to retain the generalizable knowledge inherited from the\npre-trained VLM. Through a mutual interaction, the framework effectively\nfocuses on ReID-relevant features while mitigating overfitting. Extensive\nexperiments on both conventional and Domain Generalized (DG) ReID datasets\ndemonstrate that our framework surpasses state-of-the-art methods, exhibiting\nsuperior performances in terms of both discrimination and generalization. The\nsource code is available at https://github.com/AWangYQ/APC.", "published": "2025-09-23 07:03:08", "link": "http://arxiv.org/abs/2509.18715v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries", "abstract": "Automated identification of plants has improved considerably thanks to the\nrecent progress in deep learning and the availability of training data.\nHowever, this profusion of data only concerns a few tens of thousands of\nspecies, while the planet has nearly 369K. The LifeCLEF 2019 Plant\nIdentification challenge (or \"PlantCLEF 2019\") was designed to evaluate\nautomated identification on the flora of data deficient regions. It is based on\na dataset of 10K species mainly focused on the Guiana shield and the Northern\nAmazon rainforest, an area known to have one of the greatest diversity of\nplants and animals in the world. As in the previous edition, a comparison of\nthe performance of the systems evaluated with the best tropical flora experts\nwas carried out. This paper presents the resources and assessments of the\nchallenge, summarizes the approaches and systems employed by the participating\nresearch groups, and provides an analysis of the main outcomes.", "published": "2025-09-23 06:42:30", "link": "http://arxiv.org/abs/2509.18705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping", "abstract": "Fusing cross-category objects to a single coherent object has gained\nincreasing attention in text-to-image (T2I) generation due to its broad\napplications in virtual reality, digital media, film, and gaming. However,\nexisting methods often produce biased, visually chaotic, or semantically\ninconsistent results due to overlapping artifacts and poor integration.\nMoreover, progress in this field has been limited by the absence of a\ncomprehensive benchmark dataset. To address these problems, we propose\n\\textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective\napproach comprising two key components: (1) Group-wise Embedding Swapping,\nwhich fuses semantic attributes from different concepts through feature\nmanipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism\nguided by a balance evaluation score to ensure coherent synthesis.\nAdditionally, we introduce \\textbf{Cross-category Object Fusion (COF)}, a\nlarge-scale, hierarchically structured dataset built upon ImageNet-1K and\nWordNet. COF includes 95 superclasses, each with 10 subclasses, enabling\n451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap\noutperforms state-of-the-art compositional T2I methods, including GPT-Image-1\nusing simple and complex prompts.", "published": "2025-09-23 06:32:14", "link": "http://arxiv.org/abs/2509.18699v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overview of PlantCLEF 2021: cross-domain plant identification", "abstract": "Automated plant identification has improved considerably thanks to recent\nadvances in deep learning and the availability of training data with more and\nmore field photos. However, this profusion of data concerns only a few tens of\nthousands of species, mainly located in North America and Western Europe, much\nless in the richest regions in terms of biodiversity such as tropical\ncountries. On the other hand, for several centuries, botanists have\nsystematically collected, catalogued and stored plant specimens in herbaria,\nespecially in tropical regions, and recent efforts by the biodiversity\ninformatics community have made it possible to put millions of digitised\nrecords online. The LifeCLEF 2021 plant identification challenge (or \"PlantCLEF\n2021\") was designed to assess the extent to which automated identification of\nflora in data-poor regions can be improved by using herbarium collections. It\nis based on a dataset of about 1,000 species mainly focused on the Guiana\nShield of South America, a region known to have one of the highest plant\ndiversities in the world. The challenge was evaluated as a cross-domain\nclassification task where the training set consisted of several hundred\nthousand herbarium sheets and a few thousand photos to allow learning a\ncorrespondence between the two domains. In addition to the usual metadata\n(location, date, author, taxonomy), the training data also includes the values\nof 5 morphological and functional traits for each species. The test set\nconsisted exclusively of photos taken in the field. This article presents the\nresources and evaluations of the assessment carried out, summarises the\napproaches and systems used by the participating research groups and provides\nan analysis of the main results.", "published": "2025-09-23 06:26:24", "link": "http://arxiv.org/abs/2509.18697v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery", "abstract": "Open-set land-cover analysis in remote sensing requires the ability to\nachieve fine-grained spatial localization and semantically open categorization.\nThis involves not only detecting and segmenting novel objects without\ncategorical supervision but also assigning them interpretable semantic labels\nthrough multimodal reasoning. In this study, we introduce OSDA, an integrated\nthree-stage framework for annotation-free open-set land-cover discovery,\nsegmentation, and description. The pipeline consists of: (1) precise discovery\nand mask extraction with a promptable fine-tuned segmentation model (SAM), (2)\nsemantic attribution and contextual description via a two-phase fine-tuned\nmultimodal large language model (MLLM), and (3) LLM-as-judge and manual scoring\nof the MLLMs evaluation. By combining pixel-level accuracy with high-level\nsemantic understanding, OSDA addresses key challenges in open-world remote\nsensing interpretation. Designed to be architecture-agnostic and label-free,\nthe framework supports robust evaluation across diverse satellite imagery\nwithout requiring manual annotation. Our work provides a scalable and\ninterpretable solution for dynamic land-cover monitoring, showing strong\npotential for automated cartographic updating and large-scale earth observation\nanalysis.", "published": "2025-09-23 06:23:56", "link": "http://arxiv.org/abs/2509.18693v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification", "abstract": "With the rapid development of society and continuous advances in science and\ntechnology, the food industry increasingly demands higher production quality\nand efficiency. Food image classification plays a vital role in enabling\nautomated quality control on production lines, supporting food safety\nsupervision, and promoting intelligent agricultural production. However, this\ntask faces challenges due to the large number of parameters and high\ncomputational complexity of Vision Transformer models. To address these issues,\nwe propose a lightweight food image classification algorithm that integrates a\nWindow Multi-Head Attention Mechanism (WMHAM) and a Spatial Attention Mechanism\n(SAM). The WMHAM reduces computational cost by capturing local and global\ncontextual features through efficient window partitioning, while the SAM\nadaptively emphasizes key spatial regions to improve discriminative feature\nrepresentation. Experiments conducted on the Food-101 and Vireo Food-172\ndatasets demonstrate that our model achieves accuracies of 95.24% and 94.33%,\nrespectively, while significantly reducing parameters and FLOPs compared with\nbaseline methods. These results confirm that the proposed approach achieves an\neffective balance between computational efficiency and classification\nperformance, making it well-suited for deployment in resource-constrained\nenvironments.", "published": "2025-09-23 06:23:50", "link": "http://arxiv.org/abs/2509.18692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-shot Monocular Metric Depth for Endoscopic Images", "abstract": "Monocular relative and metric depth estimation has seen a tremendous boost in\nthe last few years due to the sharp advancements in foundation models and in\nparticular transformer based networks. As we start to see applications to the\ndomain of endoscopic images, there is still a lack of robust benchmarks and\nhigh-quality datasets in that area. This paper addresses these limitations by\npresenting a comprehensive benchmark of state-of-the-art (metric and relative)\ndepth estimation models evaluated on real, unseen endoscopic images, providing\ncritical insights into their generalisation and performance in clinical\nscenarios. Additionally, we introduce and publish a novel synthetic dataset\n(EndoSynth) of endoscopic surgical instruments paired with ground truth metric\ndepth and segmentation masks, designed to bridge the gap between synthetic and\nreal-world data. We demonstrate that fine-tuning depth foundation models using\nour synthetic dataset boosts accuracy on most unseen real data by a significant\nmargin. By providing both a benchmark and a synthetic dataset, this work\nadvances the field of depth estimation for endoscopic images and serves as an\nimportant resource for future research. Project page, EndoSynth dataset and\ntrained weights are available at https://github.com/TouchSurgery/EndoSynth.", "published": "2025-09-23 04:56:25", "link": "http://arxiv.org/abs/2509.18642v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation", "abstract": "Recent works have made notable advancements in enhancing unified models for\ntext-to-image generation through the Chain-of-Thought (CoT). However, these\nreasoning methods separate the processes of understanding and generation, which\nlimits their ability to guide the reasoning of unified models in addressing the\ndeficiencies of their generative capabilities. To this end, we propose a novel\nreasoning framework for unified models, Understanding-in-Generation (UiG),\nwhich harnesses the robust understanding capabilities of unified models to\nreinforce their performance in image generation. The core insight of our UiG is\nto integrate generative guidance by the strong understanding capabilities\nduring the reasoning process, thereby mitigating the limitations of generative\nabilities. To achieve this, we introduce \"Image Editing\" as a bridge to infuse\nunderstanding into the generation process. Initially, we verify the generated\nimage and incorporate the understanding of unified models into the editing\ninstructions. Subsequently, we enhance the generated image step by step,\ngradually infusing the understanding into the generation process. Our UiG\nframework demonstrates a significant performance improvement in text-to-image\ngeneration over existing text-to-image reasoning methods, e.g., a 3.92% gain on\nthe long prompt setting of the TIIF benchmark. The project code:\nhttps://github.com/QC-LY/UiG", "published": "2025-09-23 04:52:39", "link": "http://arxiv.org/abs/2509.18639v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prompt-Guided Dual Latent Steering for Inversion Problems", "abstract": "Inverting corrupted images into the latent space of diffusion models is\nchallenging. Current methods, which encode an image into a single latent\nvector, struggle to balance structural fidelity with semantic accuracy, leading\nto reconstructions with semantic drift, such as blurred details or incorrect\nattributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering\n(PDLS), a novel, training-free framework built upon Rectified Flow models for\ntheir stable inversion paths. PDLS decomposes the inversion process into two\ncomplementary streams: a structural path to preserve source integrity and a\nsemantic path guided by a prompt. We formulate this dual guidance as an optimal\ncontrol problem and derive a closed-form solution via a Linear Quadratic\nRegulator (LQR). This controller dynamically steers the generative trajectory\nat each step, preventing semantic drift while ensuring the preservation of fine\ndetail without costly, per-image optimization. Extensive experiments on FFHQ-1K\nand ImageNet-1K under various inversion tasks, including Gaussian deblurring,\nmotion deblurring, super-resolution and freeform inpainting, demonstrate that\nPDLS produces reconstructions that are both more faithful to the original image\nand better aligned with the semantic information than single-latent baselines.", "published": "2025-09-23 04:11:06", "link": "http://arxiv.org/abs/2509.18619v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving", "abstract": "The emerging 4D millimeter-wave radar, measuring the range, azimuth,\nelevation, and Doppler velocity of objects, is recognized for its\ncost-effectiveness and robustness in autonomous driving. Nevertheless, its\npoint clouds exhibit significant sparsity and noise, restricting its standalone\napplication in 3D object detection. Recent 4D radar-camera fusion methods have\nprovided effective perception. Most existing approaches, however, adopt\nexplicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera\nfusion, neglecting radar's inherent drawbacks. Specifically, they overlook the\nsparse and incomplete geometry of radar point clouds and restrict fusion to\ncoarse scene-level integration. To address these problems, we propose\nMLF-4DRCNet, a novel two-stage framework for 3D object detection via\nmulti-level fusion of 4D radar and camera images. Our model incorporates the\npoint-, scene-, and proposal-level multi-modal information, enabling\ncomprehensive feature representation. It comprises three crucial components:\nthe Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion\nPooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module.\nOperating at the point-level, ERPE densities radar point clouds with 2D image\ninstances and encodes them into voxels via the proposed Triple-Attention Voxel\nFeature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D\nimage features using deformable attention to capture scene context and adopts\npooling to the fused features. PLFE refines region proposals by fusing image\nfeatures, and further integrates with the pooled features from HSFP.\nExperimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets\ndemonstrate that MLF-4DRCNet achieves the state-of-the-art performance.\nNotably, it attains performance comparable to LiDAR-based models on the VoD\ndataset.", "published": "2025-09-23 04:02:28", "link": "http://arxiv.org/abs/2509.18613v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation", "abstract": "We propose Adaptive Multi-Style Fusion (AMSF), a reference-based\ntraining-free framework that enables controllable fusion of multiple reference\nstyles in diffusion models. Most of the existing reference-based methods are\nlimited by (a) acceptance of only one style image, thus prohibiting hybrid\naesthetics and scalability to more styles, and (b) lack of a principled\nmechanism to balance several stylistic influences. AMSF mitigates these\nchallenges by encoding all style images and textual hints with a semantic token\ndecomposition module that is adaptively injected into every cross-attention\nlayer of an frozen diffusion model. A similarity-aware re-weighting module then\nrecalibrates, at each denoising step, the attention allocated to every style\ncomponent, yielding balanced and user-controllable blends without any\nfine-tuning or external adapters. Both qualitative and quantitative evaluations\nshow that AMSF produces multi-style fusion results that consistently outperform\nthe state-of-the-art approaches, while its fusion design scales seamlessly to\ntwo or more styles. These capabilities position AMSF as a practical step toward\nexpressive multi-style generation in diffusion models.", "published": "2025-09-23 03:47:59", "link": "http://arxiv.org/abs/2509.18602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution", "abstract": "Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims\nto enhance low-resolution (LR) contrasts leveraging high-resolution (HR)\nreferences, shortening acquisition time and improving imaging efficiency while\npreserving anatomical details. The main challenge lies in maintaining\nspatial-semantic consistency, ensuring anatomical structures remain\nwell-aligned and coherent despite structural discrepancies and motion between\nthe target and reference images. Conventional methods insufficiently model\nspatial-semantic consistency and underuse frequency-domain information, which\nleads to poor fine-grained alignment and inadequate recovery of high-frequency\ndetails. In this paper, we propose the Spatial-Semantic Consistent Model\n(SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast\nspatial alignment, a Semantic-Aware Token Aggregation Block for long-range\nsemantic consistency, and a Spatial-Frequency Fusion Block for fine structure\nrestoration. Experiments on public and private datasets show that SSCM achieves\nstate-of-the-art performance with fewer parameters while ensuring spatially and\nsemantically consistent reconstructions.", "published": "2025-09-23 03:24:32", "link": "http://arxiv.org/abs/2509.18593v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation", "abstract": "Rapid adaptation in unseen environments is essential for scalable real-world\nautonomy, yet existing approaches rely on exhaustive exploration or rigid\nnavigation policies that fail to generalize. We present VLN-Zero, a two-phase\nvision-language navigation framework that leverages vision-language models to\nefficiently construct symbolic scene graphs and enable zero-shot neurosymbolic\nnavigation. In the exploration phase, structured prompts guide VLM-based search\ntoward informative and diverse trajectories, yielding compact scene graph\nrepresentations. In the deployment phase, a neurosymbolic planner reasons over\nthe scene graph and environmental observations to generate executable plans,\nwhile a cache-enabled execution module accelerates adaptation by reusing\npreviously computed task-location trajectories. By combining rapid exploration,\nsymbolic reasoning, and cache-enabled execution, the proposed framework\novercomes the computational inefficiency and poor generalization of prior\nvision-language navigation methods, enabling robust and scalable\ndecision-making in unseen environments. VLN-Zero achieves 2x higher success\nrate compared to state-of-the-art zero-shot models, outperforms most fine-tuned\nbaselines, and reaches goal locations in half the time with 55% fewer VLM calls\non average compared to state-of-the-art models across diverse environments.\nCodebase, datasets, and videos for VLN-Zero are available at:\nhttps://vln-zero.github.io/.", "published": "2025-09-23 03:23:03", "link": "http://arxiv.org/abs/2509.18592v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network", "abstract": "This paper presents an advanced tumor segmentation framework for real-time\nMRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method\nleverages the XMem model, a memory-augmented architecture, to segment tumors\nacross long cine-MRI sequences. The proposed system efficiently integrates\nmemory mechanisms to track tumor motion in real-time, achieving high\nsegmentation accuracy even under challenging conditions with limited annotated\ndata. Unfortunately, the detailed experimental records have been lost,\npreventing us from reporting precise quantitative results at this stage.\nNevertheless, From our preliminary impressions during development, the\nXMem-based framework demonstrated reasonable segmentation performance and\nsatisfied the clinical real-time requirement. Our work contributes to improving\nthe precision of tumor tracking during MRI-guided radiotherapy, which is\ncrucial for enhancing the accuracy and safety of cancer treatments.", "published": "2025-09-23 03:22:06", "link": "http://arxiv.org/abs/2509.18591v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers", "abstract": "While editing directly from life, photographers have found it too difficult\nto see simultaneously both the blue and the sky. Photographer and curator,\nSzarkowski insightfully revealed one of the notable gaps between general and\naesthetic visual understanding: while the former focuses on identifying the\nfactual element in an image (sky), the latter transcends such object\nidentification, viewing it instead as an aesthetic component--a pure color\nblock (blue). Such fundamental distinctions between general (detection,\nlocalization, etc.) and aesthetic (color, lighting, composition, etc.) visual\nunderstanding present a significant challenge for Multimodal Large Language\nModels (MLLMs). Although some recent works have made initial explorations, they\nare often limited to general and basic aesthetic commonsense. As a result, they\nfrequently fall short in real-world scenarios (Fig. 1), which require extensive\nexpertise--including photographic techniques, photo pre/post-processing\nknowledge, and more, to provide a detailed analysis and description. To\nfundamentally enhance the aesthetics understanding of MLLMs, we first introduce\na novel dataset, PhotoCritique, derived from extensive discussions among\nprofessional photographers and enthusiasts, and characterized by the large\nscale, expertise, and diversity. Then, to better learn visual aesthetics from\nPhotoCritique, we furthur propose a novel model, PhotoEye, featuring a\nlanguageguided multi-view vision fusion mechanism to understand image\naesthetics from multiple perspectives. Finally, we present a novel benchmark,\nPhotoBench, a comprehensive and professional benchmark for aesthetic visual\nunderstanding. On existing benchmarks and PhotoBench, our model demonstrates\nclear advantages over existing models.", "published": "2025-09-23 02:59:41", "link": "http://arxiv.org/abs/2509.18582v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought", "abstract": "Real-time threat monitoring identifies threatening behaviors in video streams\nand provides reasoning and assessment of threat events through explanatory\ntext. However, prevailing methodologies, whether based on supervised learning\nor generative models, struggle to concurrently satisfy the demanding\nrequirements of real-time performance and decision explainability. To bridge\nthis gap, we introduce Live-E2T, a novel framework that unifies these two\nobjectives through three synergistic mechanisms. First, we deconstruct video\nframes into structured Human-Object-Interaction-Place semantic tuples. This\napproach creates a compact, semantically focused representation, circumventing\nthe information degradation common in conventional feature compression. Second,\nan efficient online event deduplication and updating mechanism is proposed to\nfilter spatio-temporal redundancies, ensuring the system's real time\nresponsiveness. Finally, we fine-tune a Large Language Model using a\nChain-of-Thought strategy, endow it with the capability for transparent and\nlogical reasoning over event sequences to produce coherent threat assessment\nreports. Extensive experiments on benchmark datasets, including XD-Violence and\nUCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art\nmethods in terms of threat detection accuracy, real-time efficiency, and the\ncrucial dimension of explainability.", "published": "2025-09-23 02:53:43", "link": "http://arxiv.org/abs/2509.18571v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction", "abstract": "Reconstructing dynamic humans together with static scenes from monocular\nvideos remains difficult, especially under fast motion, where RGB frames suffer\nfrom motion blur. Event cameras exhibit distinct advantages, e.g., microsecond\ntemporal resolution, making them a superior sensing choice for dynamic human\nreconstruction. Accordingly, we present a novel event-guided human-scene\nreconstruction framework that jointly models human and scene from a single\nmonocular event camera via 3D Gaussian Splatting. Specifically, a unified set\nof 3D Gaussians carries a learnable semantic attribute; only Gaussians\nclassified as human undergo deformation for animation, while scene Gaussians\nstay static. To combat blur, we propose an event-guided loss that matches\nsimulated brightness changes between consecutive renderings with the event\nstream, improving local fidelity in fast-moving regions. Our approach removes\nthe need for external human masks and simplifies managing separate Gaussian\nsets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers\nstate-of-the-art human-scene reconstruction, with notable gains over strong\nbaselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.", "published": "2025-09-23 02:50:56", "link": "http://arxiv.org/abs/2509.18566v1", "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Efficient Breast and Ovarian Cancer Classification via ViT-Based Preprocessing and Transfer Learning", "abstract": "Cancer is one of the leading health challenges for women, specifically breast\nand ovarian cancer. Early detection can help improve the survival rate through\ntimely intervention and treatment. Traditional methods of detecting cancer\ninvolve manually examining mammograms, CT scans, ultrasounds, and other imaging\ntypes. However, this makes the process labor-intensive and requires the\nexpertise of trained pathologists. Hence, making it both time-consuming and\nresource-intensive. In this paper, we introduce a novel vision transformer\n(ViT)-based method for detecting and classifying breast and ovarian cancer. We\nuse a pre-trained ViT-Base-Patch16-224 model, which is fine-tuned for both\nbinary and multi-class classification tasks using publicly available\nhistopathological image datasets. Further, we use a preprocessing pipeline that\nconverts raw histophological images into standardized PyTorch tensors, which\nare compatible with the ViT architecture and also help improve the model\nperformance. We evaluated the performance of our model on two benchmark\ndatasets: the BreakHis dataset for binary classification and the UBC-OCEAN\ndataset for five-class classification without any data augmentation. Our model\nsurpasses existing CNN, ViT, and topological data analysis-based approaches in\nbinary classification. For multi-class classification, it is evaluated against\nrecent topological methods and demonstrates superior performance. Our study\nhighlights the effectiveness of Vision Transformer-based transfer learning\ncombined with efficient preprocessing in oncological diagnostics.", "published": "2025-09-23 02:25:44", "link": "http://arxiv.org/abs/2509.18553v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles", "abstract": "The distinction between genuine and posed emotions represents a fundamental\npattern recognition challenge with significant implications for data mining\napplications in social sciences, healthcare, and human-computer interaction.\nWhile recent multi-task learning frameworks have shown promise in combining\ndeep learning architectures with handcrafted D-Marker features for smile facial\nemotion recognition, these approaches exhibit computational inefficiencies due\nto auxiliary task supervision and complex loss balancing requirements. This\npaper introduces HadaSmileNet, a novel feature fusion framework that directly\nintegrates transformer-based representations with physiologically grounded\nD-Markers through parameter-free multiplicative interactions. Through\nsystematic evaluation of 15 fusion strategies, we demonstrate that Hadamard\nmultiplicative fusion achieves optimal performance by enabling direct feature\ninteractions while maintaining computational efficiency. The proposed approach\nestablishes new state-of-the-art results for deep learning methods across four\nbenchmark datasets: UvA-NEMO (88.7 percent, +0.8), MMI (99.7 percent), SPOS\n(98.5 percent, +0.7), and BBC (100 percent, +5.0). Comprehensive computational\nanalysis reveals 26 percent parameter reduction and simplified training\ncompared to multi-task alternatives, while feature visualization demonstrates\nenhanced discriminative power through direct domain knowledge integration. The\nframework's efficiency and effectiveness make it particularly suitable for\npractical deployment in multimedia data mining applications that require\nreal-time affective computing capabilities.", "published": "2025-09-23 02:20:43", "link": "http://arxiv.org/abs/2509.18550v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models", "abstract": "No-Reference Image Quality Assessment (NR-IQA) models play an important role\nin various real-world applications. Recently, adversarial attacks against\nNR-IQA models have attracted increasing attention, as they provide valuable\ninsights for revealing model vulnerabilities and guiding robust system design.\nSome effective attacks have been proposed against NR-IQA models in white-box\nsettings, where the attacker has full access to the target model. However,\nthese attacks often suffer from poor transferability to unknown target models\nin more realistic black-box scenarios, where the target model is inaccessible.\nThis work makes the first attempt to address the challenge of low\ntransferability in attacking NR-IQA models by proposing a transferable Signed\nEnsemble Gaussian black-box Attack (SEGA). The main idea is to approximate the\ngradient of the target model by applying Gaussian smoothing to source models\nand ensembling their smoothed gradients. To ensure the imperceptibility of\nadversarial perturbations, SEGA further removes inappropriate perturbations\nusing a specially designed perturbation filter mask. Experimental results on\nthe CLIVE dataset demonstrate the superior transferability of SEGA, validating\nits effectiveness in enabling successful transfer-based black-box attacks\nagainst NR-IQA models.", "published": "2025-09-23 02:10:42", "link": "http://arxiv.org/abs/2509.18546v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoRemover: Removing Objects and Their Causal Visual Artifacts", "abstract": "Towards intelligent image editing, object removal should eliminate both the\ntarget object and its causal visual artifacts, such as shadows and reflections.\nHowever, existing image appearance-based methods either follow strictly\nmask-aligned training and fail to remove these causal effects which are not\nexplicitly masked, or adopt loosely mask-aligned strategies that lack\ncontrollability and may unintentionally over-erase other objects. We identify\nthat these limitations stem from ignoring the causal relationship between an\nobject's geometry presence and its visual effects. To address this limitation,\nwe propose a geometry-aware two-stage framework that decouples object removal\ninto (1) geometry removal and (2) appearance rendering. In the first stage, we\nremove the object directly from the geometry (e.g., depth) using strictly\nmask-aligned supervision, enabling structure-aware editing with strong\ngeometric constraints. In the second stage, we render a photorealistic RGB\nimage conditioned on the updated geometry, where causal visual effects are\nconsidered implicitly as a result of the modified 3D geometry. To guide\nlearning in the geometry removal stage, we introduce a preference-driven\nobjective based on positive and negative sample pairs, encouraging the model to\nremove objects as well as their causal visual artifacts while avoiding new\nstructural insertions. Extensive experiments demonstrate that our method\nachieves state-of-the-art performance in removing both objects and their\nassociated artifacts on two popular benchmarks. The code is available at\nhttps://github.com/buxiangzhiren/GeoRemover.", "published": "2025-09-23 02:04:19", "link": "http://arxiv.org/abs/2509.18538v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamical Modeling of Behaviorally Relevant Spatiotemporal Patterns in Neural Imaging Data", "abstract": "High-dimensional imaging of neural activity, such as widefield calcium and\nfunctional ultrasound imaging, provide a rich source of information for\nunderstanding the relationship between brain activity and behavior. Accurately\nmodeling neural dynamics in these modalities is crucial for understanding this\nrelationship but is hindered by the high-dimensionality, complex spatiotemporal\ndependencies, and prevalent behaviorally irrelevant dynamics in these\nmodalities. Existing dynamical models often employ preprocessing steps to\nobtain low-dimensional representations from neural image modalities. However,\nthis process can discard behaviorally relevant information and miss\nspatiotemporal structure. We propose SBIND, a novel data-driven deep learning\nframework to model spatiotemporal dependencies in neural images and disentangle\ntheir behaviorally relevant dynamics from other neural dynamics. We validate\nSBIND on widefield imaging datasets, and show its extension to functional\nultrasound imaging, a recent modality whose dynamical modeling has largely\nremained unexplored. We find that our model effectively identifies both local\nand long-range spatial dependencies across the brain while also dissociating\nbehaviorally relevant neural dynamics. Doing so, SBIND outperforms existing\nmodels in neural-behavioral prediction. Overall, SBIND provides a versatile\ntool for investigating the neural mechanisms underlying behavior using imaging\nmodalities.", "published": "2025-09-23 01:16:23", "link": "http://arxiv.org/abs/2509.18507v1", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Tight eigenvalue bound on the traveling salesman problem", "abstract": "A lower bound on the solution to the traveling salesman problem is provided,\nwhich is expressed in terms of eigenvalues related to the distance matrix for\nthe problem. This bound has many interesting properties such as transforming\nappropriately under affine distance transformations and is notably tight for\nvarious families of traveling salesman problems with arbitrarily many cities.\nIt is also computed for some real world traveling salesman problems. The\neigenvalues in the bound are further related to the Schoenberg criterion from\nEuclidean geometry. Graph theoretic applications to the Hamiltonian cycle and\npath problems are given by the fact that the new bound entails necessary graph\neigenvalue conditions for a graph to be Hamiltonian or traceable. Various\nnon-trivial families of Cayley graphs saturate these Hamiltonicity conditions,\nthus in a sense providing almost counterexamples to the famous conjecture that\nall Cayley graphs are Hamiltonian.", "published": "2025-09-23 13:29:07", "link": "http://arxiv.org/abs/2509.18977v1", "categories": ["math.CO", "cs.DM", "05C50, 05C45, 68R01"], "primary_category": "math.CO"}
{"title": "A Scalable Lift-and-Project Differentiable Approach For the Maximum Cut Problem", "abstract": "We propose a scalable framework for solving the Maximum Cut (MaxCut) problem\nin large graphs using projected gradient ascent on quadratic objectives.\nNotably, while our approach is differentiable and leverages GPUs for\ngradient-based optimization, it is not a machine learning method and does not\nrequire training data beyond the given problem formulation. Starting from a\ncontinuous relaxation of the classical quadratic binary formulation, we present\na parallelized strategy that explores multiple initialization vectors in batch,\noffering an efficient and memory-friendly alternative to traditional solvers.\nWe analyze the relaxed objective, showing it is convex and has fixed-points\ncorresponding to local optima -- particularly at boundary points --\nhighlighting a key challenge in non-convex optimization. To address this, we\nintroduce a lifted quadratic formulation that over-parameterizes the solution\nspace, allowing the algorithm to escape poor fixed-points. We also provide a\ntheoretical characterization of these lifted fixed-points. Finally, we propose\nDECO, a dimension-alternating algorithm that switches between the unlifted and\nlifted formulations, leveraging their complementary strengths along with\nimportance-based degree initialization and a population-based evolutionary\nhyper-parameter search. Experiments on diverse graph families show that our\nmethods attain comparable or superior performance relative to recent\ntraining-data-intensive, dataless, and GPU-accelerated sampling approaches.", "published": "2025-09-23 04:00:55", "link": "http://arxiv.org/abs/2509.18612v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "A Knowledge Graph and a Tripartite Evaluation Framework Make Retrieval-Augmented Generation Scalable and Transparent", "abstract": "Large Language Models (LLMs) have significantly enhanced conversational\nArtificial Intelligence(AI) chatbots; however, domain-specific accuracy and the\navoidance of factual inconsistencies remain pressing challenges, particularly\nfor large datasets. Designing an effective chatbot with appropriate methods and\nevaluating its effectiveness is among the challenges in this domain. This study\npresents a Retrieval Augmented Generation (RAG) chatbot that harnesses a\nknowledge graph and vector search retrieval to deliver precise, context-rich\nresponses in an exemplary use case from over high-volume engineering\nproject-related emails, thereby minimising the need for document chunking. A\ncentral innovation of this work is the introduction of RAG Evaluation\n(RAG-Eval), a novel chain-of-thought LLM-based tripartite evaluation framework\nspecifically developed to assess RAG applications. This framework operates in\nparallel with the chatbot, jointly assessing the user's query, the retrieved\ndocument, and the generated response, enabling a holistic evaluation across\nmultiple quality metrics like query relevance, factual accuracy, coverage,\ncoherence and fluency. The resulting scoring system is provided directly to\nusers as a confidence score (1 to 100%), enabling quick identification of\npossible misaligned or incomplete answers. This proposed approach promotes\ntransparency and rapid verification by incorporating metadata email IDs,\ntimestamps into responses. Experimental comparisons against BERTScore and\nG-EVAL for summarisation evaluation tasks confirm its effectiveness, and\nempirical analysis also shows RAG-Eval reliably detects factual gaps and query\nmismatches, thereby fostering trust in high demand, data centric environments.\nThese findings highlight a scalable path for developing accurate,\nuser-verifiable chatbots that bridge the gap between high-level conversational\nfluency and factual accuracy.", "published": "2025-09-23 16:29:22", "link": "http://arxiv.org/abs/2509.19209v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RELATE: Relation Extraction in Biomedical Abstracts with LLMs and Ontology Constraints", "abstract": "Biomedical knowledge graphs (KGs) are vital for drug discovery and clinical\ndecision support but remain incomplete. Large language models (LLMs) excel at\nextracting biomedical relations, yet their outputs lack standardization and\nalignment with ontologies, limiting KG integration. We introduce RELATE, a\nthree-stage pipeline that maps LLM-extracted relations to standardized ontology\npredicates using ChemProt and the Biolink Model. The pipeline includes: (1)\nontology preprocessing with predicate embeddings, (2) similarity-based\nretrieval enhanced with SapBERT, and (3) LLM-based reranking with explicit\nnegation handling. This approach transforms relation extraction from free-text\noutputs to structured, ontology-constrained representations. On the ChemProt\nbenchmark, RELATE achieves 52% exact match and 94% accuracy@10, and in 2,400\nHEAL Project abstracts, it effectively rejects irrelevant associations (0.4%)\nand identifies negated assertions. RELATE captures nuanced biomedical\nrelationships while ensuring quality for KG augmentation. By combining vector\nsearch with contextual LLM reasoning, RELATE provides a scalable, semantically\naccurate framework for converting unstructured biomedical literature into\nstandardized KGs.", "published": "2025-09-23 14:21:46", "link": "http://arxiv.org/abs/2509.19057v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Single-Branch Network Architectures to Close the Modality Gap in Multimodal Recommendation", "abstract": "Traditional recommender systems rely on collaborative filtering, using past\nuser-item interactions to help users discover new items in a vast collection.\nIn cold start, i.e., when interaction histories of users or items are not\navailable, content-based recommender systems use side information instead.\nHybrid recommender systems (HRSs) often employ multimodal learning to combine\ncollaborative and side information, which we jointly refer to as modalities.\nThough HRSs can provide recommendations when some modalities are missing, their\nquality degrades. In this work, we utilize single-branch neural networks\nequipped with weight sharing, modality sampling, and contrastive loss to\nprovide accurate recommendations even in missing modality scenarios by\nnarrowing the modality gap. We compare these networks with multi-branch\nalternatives and conduct extensive experiments on three datasets. Six\naccuracy-based and four beyond-accuracy-based metrics help assess the\nrecommendation quality for the different training paradigms and their\nhyperparameters in warm-start and missing modality scenarios. We quantitatively\nand qualitatively study the effects of these different aspects on bridging the\nmodality gap. Our results show that single-branch networks achieve competitive\nperformance in warm-start scenarios and are significantly better in missing\nmodality settings. Moreover, our approach leads to closer proximity of an\nitem's modalities in the embedding space. Our full experimental setup is\navailable at https://github.com/hcai-mms/single-branch-networks.", "published": "2025-09-23 08:58:53", "link": "http://arxiv.org/abs/2509.18807v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Robust Denoising Neural Reranker for Recommender Systems", "abstract": "For multi-stage recommenders in industry, a user request would first trigger\na simple and efficient retriever module that selects and ranks a list of\nrelevant items, then calls a slower but more sophisticated deep reranking model\nthat refines the item arrangement before exposure to the user. The latter model\ntypically reranks the item list conditioned on the user's history content and\nthe initial ranking from retrievers. Although this two-stage retrieval-ranking\nframework demonstrates practical effectiveness, the significance of retriever\nscores from the previous stage has been limitedly explored, which is\ninformative. In this work, we first theoretically analyze the limitations of\nusing retriever scores as the rerankers' input directly and argue that the\nreranking task is essentially a noise reduction problem from the retriever\nscores. Following this notion, we derive an adversarial framework, DNR, that\nassociates the denoising reranker with a carefully designed noise generation\nmodule. We extend the conventional score error minimization term with three\naugmented objectives, including: 1) a denoising objective that aims to denoise\nthe noisy retriever scores to align with the user feedback; 2) an adversarial\nretriever score generation objective that improves the exploration in the\nretriever score space; and 3) a distribution regularization term that aims to\nalign the distribution of generated noisy retriever scores with the real ones.\nExtensive experiments are conducted on three public datasets, together with\nanalytical support, validating the effectiveness of the proposed DNR.", "published": "2025-09-23 07:29:52", "link": "http://arxiv.org/abs/2509.18736v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "BloomIntent: Automating Search Evaluation with LLM-Generated Fine-Grained User Intents", "abstract": "If 100 people issue the same search query, they may have 100 different goals.\nWhile existing work on user-centric AI evaluation highlights the importance of\naligning systems with fine-grained user intents, current search evaluation\nmethods struggle to represent and assess this diversity. We introduce\nBloomIntent, a user-centric search evaluation method that uses user intents as\nthe evaluation unit. BloomIntent first generates a set of plausible,\nfine-grained search intents grounded on taxonomies of user attributes and\ninformation-seeking intent types. Then, BloomIntent provides an automated\nevaluation of search results against each intent powered by large language\nmodels. To support practical analysis, BloomIntent clusters semantically\nsimilar intents and summarizes evaluation outcomes in a structured interface.\nWith three technical evaluations, we showed that BloomIntent generated\nfine-grained, evaluable, and realistic intents and produced scalable\nassessments of intent-level satisfaction that achieved 72% agreement with\nexpert evaluators. In a case study (N=4), we showed that BloomIntent supported\nsearch specialists in identifying intents for ambiguous queries, uncovering\nunderserved user needs, and discovering actionable insights for improving\nsearch experiences. By shifting from query-level to intent-level evaluation,\nBloomIntent reimagines how search systems can be assessed -- not only for\nperformance but for their ability to serve a multitude of user goals.", "published": "2025-09-23 04:56:06", "link": "http://arxiv.org/abs/2509.18641v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Scalable Evaluation for Audio Identification via Synthetic Latent Fingerprint Generation", "abstract": "The evaluation of audio fingerprinting at a realistic scale is limited by the\nscarcity of large public music databases. We present an audio-free approach\nthat synthesises latent fingerprints which approximate the distribution of real\nfingerprints. Our method trains a Rectified Flow model on embeddings extracted\nby pre-trained neural audio fingerprinting systems. The synthetic fingerprints\ngenerated using our system act as realistic distractors and enable the\nsimulation of retrieval performance at a large scale without requiring\nadditional audio. We assess the fidelity of synthetic fingerprints by comparing\nthe distributions to real data. We further benchmark the retrieval performances\nacross multiple state-of-the-art audio fingerprinting frameworks by augmenting\nreal reference databases with synthetic distractors, and show that the scaling\ntrends obtained with synthetic distractors closely track those obtained with\nreal distractors. Finally, we scale the synthetic distractor database to model\nretrieval performance for very large databases, providing a practical metric of\nsystem scalability that does not depend on access to audio corpora.", "published": "2025-09-23 04:11:15", "link": "http://arxiv.org/abs/2509.18620v1", "categories": ["cs.SD", "cs.IR", "eess.AS", "H.5.5; I.2.6"], "primary_category": "cs.SD"}
{"title": "The Ranking Blind Spot: Decision Hijacking in LLM-based Text Ranking", "abstract": "Large Language Models (LLMs) have demonstrated strong performance in\ninformation retrieval tasks like passage ranking. Our research examines how\ninstruction-following capabilities in LLMs interact with multi-document\ncomparison tasks, identifying what we term the \"Ranking Blind Spot\", a\ncharacteristic of LLM decision processes during comparative evaluation. We\nanalyze how this ranking blind spot affects LLM evaluation systems through two\napproaches: Decision Objective Hijacking, which alters the evaluation goal in\npairwise ranking systems, and Decision Criteria Hijacking, which modifies\nrelevance standards across ranking schemes. These approaches demonstrate how\ncontent providers could potentially influence LLM-based ranking systems to\naffect document positioning. These attacks aim to force the LLM ranker to\nprefer a specific passage and rank it at the top. Malicious content providers\ncan exploit this weakness, which helps them gain additional exposure by\nattacking the ranker. In our experiment, We empirically show that the proposed\nattacks are effective in various LLMs and can be generalized to multiple\nranking schemes. We apply these attack to realistic examples to show their\neffectiveness. We also found stronger LLMs are more vulnerable to these\nattacks. Our code is available at:\nhttps://github.com/blindspotorg/RankingBlindSpot", "published": "2025-09-23 02:56:38", "link": "http://arxiv.org/abs/2509.18575v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Understand your Users, An Ensemble Learning Framework for Natural Noise Filtering in Recommender Systems", "abstract": "The exponential growth of web content is a major key to the success for\nRecommender Systems. This paper addresses the challenge of defining noise,\nwhich is inherently related to variability in human preferences and behaviors.\nIn classifying changes in user tendencies, we distinguish three kinds of\nphenomena: external factors that directly influence users' sentiment,\nserendipity causing unexpected preference, and incidental interaction perceived\nas noise. To overcome these problems, we present a new framework that\nidentifies noisy ratings. In this context, the proposed framework is modular,\nconsisting of three layers: known natural noise algorithms for item\nclassification, an Ensemble learning model for refined evaluation of the items\nand signature-based noise identification. We further advocate the metrics that\nquantitatively assess serendipity and group validation, offering higher\nrobustness in recommendation accuracy. Our approach aims to provide a cleaner\ntraining dataset that would inherently improve user satisfaction and engagement\nwith Recommender Systems.", "published": "2025-09-23 02:36:27", "link": "http://arxiv.org/abs/2509.18560v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Optimum Spectrum Extension for PAPR Reduction of DFT-s-OFDM", "abstract": "Uplink coverage in cellular networks is constrained by the maximum UE\ntransmit power, making peak-to-average power ratio (PAPR) reduction essential.\nWhile DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves\nsignificantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains\ntoo high for higher-rate transmission. Spectrum extension (SE) combined with\nFDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper\nconsiders FDSS-SE with parametrized FDSS windows spanning a range of possible\npower ripples, as well as arbitrary circular shifts of the subcarrier\ncoefficients. We optimize both the frequency shift and the SE size, and show\nthat there exists an optimal SE size for reducing the PAPR and another one for\nincreasing the rate. Analysis and simulations reveal that both optima largely\ndepend on the window attenuation but are nearly invariant in proportion to the\nbandwidth. While the PAPR-optimal SE size is nearly invariant to the\nconstellation order of regular QAM, the rate-optimal SE size depends also on\nthe SNR. These insights provide practical guidelines for beyond-5G uplink\ncoverage enhancement, highlighting that SE size should be individually\nconfigured according to the user's FDSS window and link quality.", "published": "2025-09-23 14:27:56", "link": "http://arxiv.org/abs/2509.19064v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "1-bit RIS-aided Index Modulation with Quantum Annealing", "abstract": "In this paper, we investigate a new index modulation (IM) scheme for\nreconfigurable intelligent surface (RIS)-assisted communications with 1-bit RIS\nphase resolution. In addition to the traditional modulated symbols, extra bits\nof information are embedded in the binary RIS phase vector by indexing the\ncardinality of the positive phases shifts. To maximize capacity, the IM-based\nRIS vector is selected so as to maximize the signal-to-noise ratio at the\nreceiver. The proposed IM design requires the solution of a quadratic binary\noptimization problem with an equality constraint at the transmitter as well as\na quadratic unconstrained binary optimization (QUBO) problem at the receiver.\nSince commercial solvers cannot directly handle constraints, a penalty method\nthat embeds the equality constraint in the objective function is investigated.\nTo overcome the empirical tuning of the penalty parameter, an iterative\nAugmented Lagrangian optimization technique is also investigated where a QUBO\nproblem is solved at each iteration. The proposed design and associated\nmathematical framework are tested in a real-world quantum annealing device\nprovided by D-WAVE. Rigorous experimental results demonstrate that the D-WAVE\nheuristic efficiently solves the considered combinatorial problems.\nFurthermore, theoretical bounds on the average capacity are provided. Both\nexperimental and theoretical results show that the proposed design outperforms\nconventional counterparts.", "published": "2025-09-23 12:50:41", "link": "http://arxiv.org/abs/2509.18932v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "From Fixed to Fluid: Unlocking the New Potential with Fluid RIS (FRIS)", "abstract": "Owing to its flexible and intelligent electromagnetic signal manipulation,\nthe technology of reconfigurable intelligent surfaces (RISs) has attracted\nwidespread attention. However, the potential of current RISs can only be partly\nunlocked due to their fixed geometry and element patterns. Motivated by the\nconcept of the fluid antenna system (FAS), a novel RIS system, termed fluid RIS\n(FRIS), has been developed. Unlike traditional RISs, FRIS allows the element\npositions or radiation patterns to exhibit ``fluid\" properties, i.e., dynamic\nreconfigurability, to adapt to the wireless environment, offering enhanced\nbeamforming flexibility and environmental adaptability. Given that research on\nFRIS is still in its infancy, this paper provides a comprehensive overview of\nits current developments and future prospects. Specifically, the key features\nof FRIS are first presented, including its classification, fundamental\nmechanisms, and advantages. Next, potential application scenarios of FRIS are\nanalyzed and discussed, followed by two illustrative case studies demonstrating\nits potential. Finally, the main open challenges and future research directions\nrelated to FRIS are highlighted.", "published": "2025-09-23 11:24:35", "link": "http://arxiv.org/abs/2509.18899v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Two-Dimensional Super-Resolution Method for Reconfigurable Intelligent Surface-Assisted Near-Field Localization", "abstract": "Reconfigurable intelligent surface (RIS)-aided localization in the radiating\nnear-field requires range-aware spherical-wave models, which inherently couple\nangles and ranges and thus complicate accurate 3D positioning. Using the\nFresnel approximation, we show that the RIS response can be expressed as the\nelement-wise product of a 2D far-field steering vector and a range-dependent\nquadratic-phase chirp. By modeling these chirp components within a\nlow-dimensional subspace, we reformulate the joint recovery of azimuth,\nelevation, and range under a 2D super-resolution framework, resulting in a 2D\natomic norm minimization (2D-ANM) problem. Solving this via semi-definite\nprogramming (SDP) yields gridless azimuth-elevation estimation and\nhigh-accuracy range recovery. Simulations demonstrate accurate 3D localization\nand enhanced robustness of the proposed scheme, compared with subspace and\ncompressive sensing methods.", "published": "2025-09-23 08:07:08", "link": "http://arxiv.org/abs/2509.18774v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Convex Demixing Approach for Hybrid-Field Channel Estimation of XL-MIMO Systems via Atomic Norm Minimization", "abstract": "Channel estimation is a critical task in extremely large-scale multiple-input\nmultiple-output (XL-MIMO) systems for 6G wireless communications. A\nhybrid-field channel model effectively characterizes the mixed far-field and\nnear-field scattering components in practical XL-MIMO systems. In this paper,\nwe propose a convex demixing approach for hybrid-field channel estimation\nwithin the atomic norm minimization (ANM) framework. By promoting sparsity of\nthe far-field and near-field components directly in the continuous parameter\ndomain, a demixing scheme that minimizes a weighted sum of two atomic norms is\nproposed. We show that the resulting ANM is equivalent to a computationally\nfeasible semi-definite programming (SDP). Numerical experiments on simulated\ndata demonstrate that our method outperforms existing approaches for\nhybrid-field channel estimation.", "published": "2025-09-23 07:48:42", "link": "http://arxiv.org/abs/2509.18752v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Barycentric decompositions for extensive monotone divergences", "abstract": "We study sets of divergences or dissimilarity measures in a generalized\nreal-algebraic setting which includes the cases of classical and quantum\nmultivariate divergences. We show that a special subset of divergences, the\nso-called test spectrum, characterizes the rest of the divergences through\nbarycentres and that the extreme points of relevant convex subsets of general\ndivergences are contained within the test spectrum. Only some special parts of\nthe test spectrum may contain non-extreme elements. We are able to fully\ncharacterize the test spectrum in the case of classical multivariate\ndivergences. The quantum case is much more varied, and we demonstrate that\nessentially all the bivariate and multivariate quantum divergences suggested\npreviously in literature are within the test spectrum and extreme within the\nset of all quantum (multivariate) divergences. This suggests that the\nvariability of quantum divergences is real since all the previously suggested\ndivergences are independent of each other.", "published": "2025-09-23 07:13:31", "link": "http://arxiv.org/abs/2509.18725v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "New constructions of cyclic constant-dimension subspace codes based on Sidon spaces and subspace polynomials", "abstract": "In this paper, two new constructions of Sidon spaces are given by tactfully\nadding new parameters and flexibly varying the number of parameters. Under the\nparameters $ n= (2r+1)k, r \\ge2 $ and $p_0=\\max \\{i\\in \\mathbb{N}^+: \\lfloor\n\\frac{r}{i}\\rfloor>\\lfloor \\frac{r}{i+1} \\rfloor \\}$, the first construction\nproduces a cyclic CDC in $\\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and\nsize $\\frac{\\left((r+\\sum\\limits_{i=2}^{p_0}(\\lfloor \\frac{r}{i}\\rfloor-\\lfloor\n\\frac{r}{i+1} \\rfloor))(q^k-1)(q-1)+r\\right)(q^k-1)^{r-1}(q^n-1)}{q-1}$. Given\nparameters $n=2rk,r\\ge 2$ and if $r=2$, $p_0=1$, otherwise, $p_0=\\max\\{ i\\in\n\\mathbb{N}^+: \\lceil\\frac{r}{i}\\rceil-1>\\lfloor \\frac{r}{i+1} \\rfloor \\}$, a\ncyclic CDC in $\\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and size\n$\\frac{\\left((r-1+\\sum\\limits_{i=2}^{p_0}(\\lceil \\frac{r}{i}\\rceil-\\lfloor\n\\frac{r}{i+1} \\rfloor-1))(q^k-1)(q-1)+r-1\\right)(q^k-1)^{r-2}\\lfloor\n\\frac{q^k-2}{2}\\rfloor(q^n-1)}{q-1}$ is produced by the second construction.\nThe sizes of our cyclic CDCs are larger than the best known results. In\nparticular, in the case of $n=4k$, when $k$ goes to infinity, the ratio between\nthe size of our cyclic CDC and the Sphere-packing bound (Johnson bound) is\napproximately equal to $\\frac{1}{2}$. Moreover, for a prime power $q$ and\npositive integers $k,s$ with $1\\le s< k-1$, a cyclic CDC in $\\mathcal{G}_q(N,\nk)$ of size $e\\frac{q^N-1}{q-1}$ and minimum distance $\\ge 2k-2s$ is provided\nby subspace polynomials, where $N,e$ are positive integers. Our construction\ngeneralizes previous results and, under certain parameters, provides cyclic\nCDCs with larger sizes or more admissible values of $ N $ than constructions\nbased on trinomials.", "published": "2025-09-23 06:38:08", "link": "http://arxiv.org/abs/2509.18704v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Ruled surfaces over finite fields, and some codes over them", "abstract": "In the first part of this article, we consider ruled surfaces defined over a\nfinite field; we introduce invariants for them, and describe some explicit\ncontructions that illustrate possible behaviour of these invariants. In the\nsecond part, we consider evaluation codes on some such surfaces; we first\nestimate their parameters, then we construct asymptotically good families of\nsuch codes, and we show that their asymptotic parameters are better than the\nones of the corresponding product codes. We also consider local properties of\nthese codes.", "published": "2025-09-23 06:28:36", "link": "http://arxiv.org/abs/2509.18698v1", "categories": ["cs.IT", "math.AG", "math.IT", "math.NT"], "primary_category": "cs.IT"}
{"title": "Online Learning for Optimizing AoI-Energy Tradeoff under Unknown Channel Statistics", "abstract": "We consider a real-time monitoring system where a source node (with energy\nlimitations) aims to keep the information status at a destination node as fresh\nas possible by scheduling status update transmissions over a set of channels.\nThe freshness of information at the destination node is measured in terms of\nthe Age of Information (AoI) metric. In this setting, a natural tradeoff exists\nbetween the transmission cost (or equivalently, energy consumption) of the\nsource and the achievable AoI performance at the destination. This tradeoff has\nbeen optimized in the existing literature under the assumption of having a\ncomplete knowledge of the channel statistics. In this work, we develop online\nlearning-based algorithms with finite-time guarantees that optimize this\ntradeoff in the practical scenario where the channel statistics are unknown to\nthe scheduler. In particular, when the channel statistics are known, the\noptimal scheduling policy is first proven to have a threshold-based structure\nwith respect to the value of AoI (i.e., it is optimal to drop updates when the\nAoI value is below some threshold). This key insight was then utilized to\ndevelop the proposed learning algorithms that surprisingly achieve an\norder-optimal regret (i.e., $O(1)$) with respect to the time horizon length.", "published": "2025-09-23 05:15:36", "link": "http://arxiv.org/abs/2509.18654v1", "categories": ["cs.NI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.NI"}
{"title": "Hybrid Neural/Traditional OFDM Receiver with Learnable Decider", "abstract": "Deep learning (DL) methods have emerged as promising solutions for enhancing\nreceiver performance in wireless orthogonal frequency-division multiplexing\n(OFDM) systems, offering significant improvements over traditional estimation\nand detection techniques. However, DL-based receivers often face challenges\nsuch as poor generalization to unseen channel conditions and difficulty in\neffectively tracking rapid channel fluctuations. To address these limitations,\nthis paper proposes a hybrid receiver architecture that integrates the\nstrengths of both traditional and neural receivers. The core innovation is a\ndiscriminator neural network trained to dynamically select the optimal receiver\nwhether it is the traditional or DL-based receiver according on the received\nOFDM block characteristics. This discriminator is trained using labeled pilot\nsignals that encode the comparative performance of both receivers. By including\nanomalous channel scenarios in training, the proposed hybrid receiver achieves\nrobust performance, effectively overcoming the generalization issues inherent\nin standalone DL approaches.", "published": "2025-09-23 02:56:27", "link": "http://arxiv.org/abs/2509.18574v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Functional Information Decomposition: A First-Principles Approach to Analyzing Functional Relationships", "abstract": "Information theory, originating from Shannon's work on communication systems,\nhas become a fundamental tool across neuroscience, genetics, physics, and\nmachine learning. However, the application of information theory is often\nlimited to the simplest case: mutual information between two variables. A\ncentral challenge in extending information theory to multivariate systems is\ndecomposition: understanding how the information that multiple variables\ncollectively provide about a target can be broken down into the distinct\ncontributions that are assignable to individual variables or their\ninteractions. To restate the problem clearly, what is sought after is a\ndecomposition of the mutual information between a set of inputs (or parts) and\nan output (or whole). In this work, we introduce Functional Information\nDecomposition (FID) a new approach to information decomposition that differs\nfrom prior methods by operating on complete functional relationships rather\nthan statistical correlations, enabling precise quantification of independent\nand synergistic contributions.", "published": "2025-09-23 01:32:48", "link": "http://arxiv.org/abs/2509.18522v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Residual Off-Policy RL for Finetuning Behavior Cloning Policies", "abstract": "Recent advances in behavior cloning (BC) have enabled impressive visuomotor\ncontrol policies. However, these approaches are limited by the quality of human\ndemonstrations, the manual effort required for data collection, and the\ndiminishing returns from increasing offline data. In comparison, reinforcement\nlearning (RL) trains an agent through autonomous interaction with the\nenvironment and has shown remarkable success in various domains. Still,\ntraining RL policies directly on real-world robots remains challenging due to\nsample inefficiency, safety concerns, and the difficulty of learning from\nsparse rewards for long-horizon tasks, especially for high-degree-of-freedom\n(DoF) systems. We present a recipe that combines the benefits of BC and RL\nthrough a residual learning framework. Our approach leverages BC policies as\nblack-box bases and learns lightweight per-step residual corrections via\nsample-efficient off-policy RL. We demonstrate that our method requires only\nsparse binary reward signals and can effectively improve manipulation policies\non high-degree-of-freedom (DoF) systems in both simulation and the real world.\nIn particular, we demonstrate, to the best of our knowledge, the first\nsuccessful real-world RL training on a humanoid robot with dexterous hands. Our\nresults demonstrate state-of-the-art performance in various vision-based tasks,\npointing towards a practical pathway for deploying RL in the real world.\nProject website: https://residual-offpolicy-rl.github.io", "published": "2025-09-23 17:59:46", "link": "http://arxiv.org/abs/2509.19301v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT", "abstract": "Large reasoning models (LRMs) spend substantial test-time compute on long\nchain-of-thought (CoT) traces, but what *characterizes* an effective CoT\nremains unclear. While prior work reports gains from lengthening CoTs and\nincreasing review (revisiting earlier steps) via appended *wait* tokens, recent\nstudies suggest that shorter thinking can outperform longer traces. We\ntherefore conduct a systematic evaluation across ten LRMs on math and\nscientific reasoning. Contrary to the \"longer-is-better\" narrative, we find\nthat both naive CoT lengthening and increased review are associated with\n*lower* accuracy.\n  As CoT unfolds step by step, token-level metrics can conflate verbosity with\nprocess quality. We introduce a graph view of CoT to extract structure and\nidentify a single statistic-the *Failed-Step Fraction (FSF)*, the fraction of\nsteps in abandoned branches-that consistently outpredicts length and review\nratio for correctness across models. To probe causality, we design two\ninterventions. First, we rank candidate CoTs by each metric at test time, where\nFSF yields the largest pass@1 gains; second, we edit CoTs to remove failed\nbranches, which significantly improves accuracy, indicating that failed\nbranches bias subsequent reasoning. Taken together, these results characterize\neffective CoTs as those that *fail less* and support *structure-aware*\ntest-time scaling over indiscriminately generating long CoT.", "published": "2025-09-23 17:50:54", "link": "http://arxiv.org/abs/2509.19284v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Gradient Flow Approach to Solving Inverse Problems with Latent Diffusion Models", "abstract": "Solving ill-posed inverse problems requires powerful and flexible priors. We\npropose leveraging pretrained latent diffusion models for this task through a\nnew training-free approach, termed Diffusion-regularized Wasserstein Gradient\nFlow (DWGF). Specifically, we formulate the posterior sampling problem as a\nregularized Wasserstein gradient flow of the Kullback-Leibler divergence in the\nlatent space. We demonstrate the performance of our method on standard\nbenchmarks using StableDiffusion (Rombach et al., 2022) as the prior.", "published": "2025-09-23 17:41:43", "link": "http://arxiv.org/abs/2509.19276v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Discovering strategies for coastal resilience with AI-based prediction and optimization", "abstract": "Tropical storms cause extensive property damage and loss of life, making them\none of the most destructive types of natural hazards. The development of\npredictive models that identify interventions effective at mitigating storm\nimpacts has considerable potential to reduce these adverse outcomes. In this\nstudy, we use an artificial intelligence (AI)-driven approach for optimizing\nintervention schemes that improve resilience to coastal flooding. We combine\nthree different AI models to optimize the selection of intervention types,\nsites, and scales in order to minimize the expected cost of flooding damage in\na given region, including the cost of installing and maintaining interventions.\nOur approach combines data-driven generation of storm surge fields, surrogate\nmodeling of intervention impacts, and the solving of a continuous-armed bandit\nproblem. We applied this methodology to optimize the selection of sea wall and\noyster reef interventions near Tyndall Air Force Base (AFB) in Florida, an area\nthat was catastrophically impacted by Hurricane Michael. Our analysis predicts\nthat intervention optimization could be used to potentially save billions of\ndollars in storm damage, far outpacing greedy or non-optimal solutions.", "published": "2025-09-23 17:21:41", "link": "http://arxiv.org/abs/2509.19263v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Recovering Wasserstein Distance Matrices from Few Measurements", "abstract": "This paper proposes two algorithms for estimating square Wasserstein distance\nmatrices from a small number of entries. These matrices are used to compute\nmanifold learning embeddings like multidimensional scaling (MDS) or Isomap, but\ncontrary to Euclidean distance matrices, are extremely costly to compute. We\nanalyze matrix completion from upper triangular samples and Nystr\\\"{o}m\ncompletion in which $\\mathcal{O}(d\\log(d))$ columns of the distance matrices\nare computed where $d$ is the desired embedding dimension, prove stability of\nMDS under Nystr\\\"{o}m completion, and show that it can outperform matrix\ncompletion for a fixed budget of sample distances. Finally, we show that\nclassification of the OrganCMNIST dataset from the MedMNIST benchmark is stable\non data embedded from the Nystr\\\"{o}m estimation of the distance matrix even\nwhen only 10\\% of the columns are computed.", "published": "2025-09-23 17:11:33", "link": "http://arxiv.org/abs/2509.19250v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Linear Regression under Missing or Corrupted Coordinates", "abstract": "We study multivariate linear regression under Gaussian covariates in two\nsettings, where data may be erased or corrupted by an adversary under a\ncoordinate-wise budget. In the incomplete data setting, an adversary may\ninspect the dataset and delete entries in up to an $\\eta$-fraction of samples\nper coordinate; a strong form of the Missing Not At Random model. In the\ncorrupted data setting, the adversary instead replaces values arbitrarily, and\nthe corruption locations are unknown to the learner. Despite substantial work\non missing data, linear regression under such adversarial missingness remains\npoorly understood, even information-theoretically. Unlike the clean setting,\nwhere estimation error vanishes with more samples, here the optimal error\nremains a positive function of the problem parameters. Our main contribution is\nto characterize this error up to constant factors across essentially the entire\nparameter range. Specifically, we establish novel information-theoretic lower\nbounds on the achievable error that match the error of (computationally\nefficient) algorithms. A key implication is that, perhaps surprisingly, the\noptimal error in the missing data setting matches that in the corruption\nsetting-so knowing the corruption locations offers no general advantage.", "published": "2025-09-23 17:01:43", "link": "http://arxiv.org/abs/2509.19242v1", "categories": ["cs.DS", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.DS"}
{"title": "Stability and Generalization of Adversarial Diffusion Training", "abstract": "Algorithmic stability is an established tool for analyzing generalization.\nWhile adversarial training enhances model robustness, it often suffers from\nrobust overfitting and an enlarged generalization gap. Although recent work has\nestablished the convergence of adversarial training in decentralized networks,\nits generalization properties remain unexplored. This work presents a\nstability-based generalization analysis of adversarial training under the\ndiffusion strategy for convex losses. We derive a bound showing that the\ngeneralization error grows with both the adversarial perturbation strength and\nthe number of training steps, a finding consistent with single-agent case but\nnovel for decentralized settings. Numerical experiments on logistic regression\nvalidate these theoretical predictions.", "published": "2025-09-23 16:55:30", "link": "http://arxiv.org/abs/2509.19234v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Study Design and Demystification of Physics Informed Neural Networks for Power Flow Simulation", "abstract": "In the context of the energy transition, with increasing integration of\nrenewable sources and cross-border electricity exchanges, power grids are\nencountering greater uncertainty and operational risk. Maintaining grid\nstability under varying conditions is a complex task, and power flow simulators\nare commonly used to support operators by evaluating potential actions before\nimplementation. However, traditional physical solvers, while accurate, are\noften too slow for near real-time use. Machine learning models have emerged as\nfast surrogates, and to improve their adherence to physical laws (e.g.,\nKirchhoff's laws), they are often trained with embedded constraints which are\nalso known as physics-informed or hybrid models. This paper presents an\nablation study to demystify hybridization strategies, ranging from\nincorporating physical constraints as regularization terms or unsupervised\nlosses, and exploring model architectures from simple multilayer perceptrons to\nadvanced graph-based networks enabling the direct optimization of physics\nequations. Using our custom benchmarking pipeline for hybrid models called\nLIPS, we evaluate these models across four dimensions: accuracy, physical\ncompliance, industrial readiness, and out-of-distribution generalization. The\nresults highlight how integrating physical knowledge impacts performance across\nthese criteria. All the implementations are reproducible and provided in the\ncorresponding Github page.", "published": "2025-09-23 16:55:13", "link": "http://arxiv.org/abs/2509.19233v1", "categories": ["cs.LG", "I.2.0; I.2.4; I.2.6"], "primary_category": "cs.LG"}
{"title": "Neighbor Embeddings Using Unbalanced Optimal Transport Metrics", "abstract": "This paper proposes the use of the Hellinger--Kantorovich metric from\nunbalanced optimal transport (UOT) in a dimensionality reduction and learning\n(supervised and unsupervised) pipeline. The performance of UOT is compared to\nthat of regular OT and Euclidean-based dimensionality reduction methods on\nseveral benchmark datasets including MedMNIST. The experimental results\ndemonstrate that, on average, UOT shows improvement over both Euclidean and\nOT-based methods as verified by statistical hypothesis tests. In particular, on\nthe MedMNIST datasets, UOT outperforms OT in classification 81\\% of the time.\nFor clustering MedMNIST, UOT outperforms OT 83\\% of the time and outperforms\nboth other metrics 58\\% of the time.", "published": "2025-09-23 16:49:15", "link": "http://arxiv.org/abs/2509.19226v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Video Killed the Energy Budget: Characterizing the Latency and Power Regimes of Open Text-to-Video Models", "abstract": "Recent advances in text-to-video (T2V) generation have enabled the creation\nof high-fidelity, temporally coherent clips from natural language prompts. Yet\nthese systems come with significant computational costs, and their energy\ndemands remain poorly understood. In this paper, we present a systematic study\nof the latency and energy consumption of state-of-the-art open-source T2V\nmodels. We first develop a compute-bound analytical model that predicts scaling\nlaws with respect to spatial resolution, temporal length, and denoising steps.\nWe then validate these predictions through fine-grained experiments on\nWAN2.1-T2V, showing quadratic growth with spatial and temporal dimensions, and\nlinear scaling with the number of denoising steps. Finally, we extend our\nanalysis to six diverse T2V models, comparing their runtime and energy profiles\nunder default settings. Our results provide both a benchmark reference and\npractical insights for designing and deploying more sustainable generative\nvideo systems.", "published": "2025-09-23 16:47:03", "link": "http://arxiv.org/abs/2509.19222v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PPG-Distill: Efficient Photoplethysmography Signals Analysis via Foundation Model Distillation", "abstract": "Photoplethysmography (PPG) is widely used in wearable health monitoring, yet\nlarge PPG foundation models remain difficult to deploy on resource-limited\ndevices. We present PPG-Distill, a knowledge distillation framework that\ntransfers both global and local knowledge through prediction-, feature-, and\npatch-level distillation. PPG-Distill incorporates morphology distillation to\npreserve local waveform patterns and rhythm distillation to capture inter-patch\ntemporal structures. On heart rate estimation and atrial fibrillation\ndetection, PPG-Distill improves student performance by up to 21.8% while\nachieving 7X faster inference and reducing memory usage by 19X, enabling\nefficient PPG analysis on wearables", "published": "2025-09-23 16:35:38", "link": "http://arxiv.org/abs/2509.19215v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AlloyInter: Visualising Alloy Mixture Interpolations in t-SNE Representations", "abstract": "This entry description proposes AlloyInter, a novel system to enable joint\nexploration of input mixtures and output parameters space in the context of the\nSciVis Contest 2025. We propose an interpolation approach, guided by\neXplainable Artificial Intelligence (XAI) based on a learned model ensemble\nthat allows users to discover input mixture ratios by specifying output\nparameter goals that can be iteratively adjusted and improved towards a goal.\nWe strengthen the capabilities of our system by building upon prior research\nwithin the robustness of XAI, as well as combining well-established techniques\nlike manifold learning with interpolation approaches.", "published": "2025-09-23 16:21:52", "link": "http://arxiv.org/abs/2509.19202v1", "categories": ["cs.CE", "cs.LG"], "primary_category": "cs.CE"}
{"title": "A Validation Strategy for Deep Learning Models: Evaluating and Enhancing Robustness", "abstract": "Data-driven models, especially deep learning classifiers often demonstrate\ngreat success on clean datasets. Yet, they remain vulnerable to common data\ndistortions such as adversarial and common corruption perturbations. These\nperturbations can significantly degrade performance, thereby challenging the\noverall reliability of the models. Traditional robustness validation typically\nrelies on perturbed test datasets to assess and improve model performance. In\nour framework, however, we propose a validation approach that extracts \"weak\nrobust\" samples directly from the training dataset via local robustness\nanalysis. These samples, being the most susceptible to perturbations, serve as\nan early and sensitive indicator of the model's vulnerabilities. By evaluating\nmodels on these challenging training instances, we gain a more nuanced\nunderstanding of its robustness, which informs targeted performance\nenhancement. We demonstrate the effectiveness of our approach on models trained\nwith CIFAR-10, CIFAR-100, and ImageNet, highlighting how robustness validation\nguided by weak robust samples can drive meaningful improvements in model\nreliability under adversarial and common corruption scenarios.", "published": "2025-09-23 16:14:14", "link": "http://arxiv.org/abs/2509.19197v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Unveiling the Role of Learning Rate Schedules via Functional Scaling Laws", "abstract": "Scaling laws have played a cornerstone role in guiding the training of large\nlanguage models (LLMs). However, most existing works on scaling laws primarily\nfocus on the final-step loss, overlooking the loss dynamics during the training\nprocess and, crucially, the impact of learning rate schedule (LRS). In this\npaper, we aim to bridge this gap by studying a teacher-student kernel\nregression setup trained via online stochastic gradient descent (SGD).\nLeveraging a novel intrinsic time viewpoint and stochastic differential\nequation (SDE) modeling of SGD, we introduce the Functional Scaling Law (FSL),\nwhich characterizes the evolution of population risk during the training\nprocess for general LRSs. Remarkably, the impact of the LRSs is captured\nthrough an explicit convolution-type functional term, making their effects\nfully tractable. To illustrate the utility of FSL, we analyze three widely used\nLRSs -- constant, exponential decay, and warmup-stable-decay (WSD) -- under\nboth data-limited and compute-limited regimes. We provide theoretical\njustification for widely adopted empirical practices in LLMs pre-training such\nas (i) higher-capacity models are more data- and compute-efficient; (ii)\nlearning rate decay can improve training efficiency; (iii) WSD-like schedules\ncan outperform direct-decay schedules. Lastly, we explore the practical\nrelevance of FSL as a surrogate model for fitting, predicting and optimizing\nthe loss curves in LLM pre-training, with experiments conducted across model\nsizes ranging from 0.1B to 1B parameters. We hope our FSL framework can deepen\nthe understanding of LLM pre-training dynamics and provide insights for\nimproving large-scale model training.", "published": "2025-09-23 16:05:16", "link": "http://arxiv.org/abs/2509.19189v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Circuit Complexity From Physical Constraints: Scaling Limitations of Attention", "abstract": "We argue that the standard circuit complexity measures derived from $NC, AC,\nTC$ provide limited practical information and are now insufficient to further\ndifferentiate model expressivity. To address these new limitations, we define a\nnovel notion of local uniformity and a family of circuit complexity classes\n$RC(\\cdot)$ that capture the fundamental constraints of scaling physical\ncircuits. Through the lens of $RC(\\cdot)$, we show that attention mechanisms\nwith $\\omega(n^{3/2})$ runtime cannot scale to accommodate the entropy of\nincreasingly complex datasets. Our results simultaneously provide a methodology\nfor defining meaningful bounds on transformer expressivity and naturally expose\nthe restricted viability of attention.", "published": "2025-09-23 15:40:36", "link": "http://arxiv.org/abs/2509.19161v1", "categories": ["cs.CC", "cs.LG", "F.1.3"], "primary_category": "cs.CC"}
{"title": "CayleyPy Growth: Efficient growth computations and hundreds of new conjectures on Cayley graphs (Brief version)", "abstract": "This is the third paper of the CayleyPy project applying artificial\nintelligence to problems in group theory. We announce the first public release\nof CayleyPy, an open source Python library for computations with Cayley and\nSchreier graphs. Compared with systems such as GAP and Sage, CayleyPy handles\nmuch larger graphs and performs several orders of magnitude faster.\n  Using CayleyPy we obtained about 200 new conjectures on Cayley and Schreier\ngraphs, focused on diameters and growth. For many Cayley graphs of symmetric\ngroups Sn we observe quasi polynomial diameter formulas: a small set of\nquadratic or linear polynomials indexed by n mod s. We conjecture that this is\na general phenomenon, giving efficient diameter computation despite the problem\nbeing NP hard. We propose a refinement of the Babai type conjecture on\ndiameters of Sn: n^2/2 + 4n upper bounds in the undirected case, compared to\nprevious O(n^2) bounds. We also provide explicit generator families, related to\ninvolutions in a square with whiskers pattern, conjectured to maximize the\ndiameter; search confirms this for all n up to 15. We further conjecture an\nanswer to a question posed by V M Glushkov in 1968 on directed Cayley graphs\ngenerated by a cyclic shift and a transposition.\n  For nilpotent groups we conjecture an improvement of J S Ellenberg's results\non upper unitriangular matrices over Z/pZ, showing linear dependence of\ndiameter on p. Moreover.\n  Some conjectures are LLM friendly, naturally stated as sorting problems\nverifiable by algorithms or Python code. To benchmark path finding we created\nmore than 10 Kaggle datasets. CayleyPy works with arbitrary permutation or\nmatrix groups and includes over 100 predefined generators. Our growth\ncomputation code outperforms GAP and Sage up to 1000 times in speed and size.", "published": "2025-09-23 15:40:36", "link": "http://arxiv.org/abs/2509.19162v1", "categories": ["math.CO", "cs.LG", "math.GR"], "primary_category": "math.CO"}
{"title": "Efficient Reinforcement Learning by Reducing Forgetting with Elephant Activation Functions", "abstract": "Catastrophic forgetting has remained a significant challenge for efficient\nreinforcement learning for decades (Ring 1994, Rivest and Precup 2003). While\nrecent works have proposed effective methods to mitigate this issue, they\nmainly focus on the algorithmic side. Meanwhile, we do not fully understand\nwhat architectural properties of neural networks lead to catastrophic\nforgetting. This study aims to fill this gap by studying the role of activation\nfunctions in the training dynamics of neural networks and their impact on\ncatastrophic forgetting in reinforcement learning setup. Our study reveals\nthat, besides sparse representations, the gradient sparsity of activation\nfunctions also plays an important role in reducing forgetting. Based on this\ninsight, we propose a new class of activation functions, elephant activation\nfunctions, that can generate both sparse outputs and sparse gradients. We show\nthat by simply replacing classical activation functions with elephant\nactivation functions in the neural networks of value-based algorithms, we can\nsignificantly improve the resilience of neural networks to catastrophic\nforgetting, thus making reinforcement learning more sample-efficient and\nmemory-efficient.", "published": "2025-09-23 15:38:01", "link": "http://arxiv.org/abs/2509.19159v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio", "abstract": "Reinforcement Learning (RL) is increasingly utilized to enhance the reasoning\ncapabilities of Large Language Models (LLMs). However, effectively scaling\nthese RL methods presents significant challenges, primarily due to the\ndifficulty in maintaining high AI accelerator utilization without generating\nstale, off-policy data that harms common RL algorithms. This paper introduces\nPipelineRL, an approach designed to achieve a superior trade-off between\nhardware efficiency and data on-policyness for LLM training. PipelineRL employs\nconcurrent asynchronous data generation and model training, distinguished by\nthe novel in-flight weight updates. This mechanism allows the LLM generation\nengine to receive updated model weights with minimal interruption during the\ngeneration of token sequences, thereby maximizing both the accelerator\nutilization and the freshness of training data. Experiments conducted on\nlong-form reasoning tasks using 128 H100 GPUs demonstrate that PipelineRL\nachieves approximately $\\sim 2x$ faster learning compared to conventional RL\nbaselines while maintaining highly on-policy training data. A scalable and\nmodular open-source implementation of PipelineRL is also released as a key\ncontribution.", "published": "2025-09-23 15:15:21", "link": "http://arxiv.org/abs/2509.19128v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics", "abstract": "Large language models (LLMs) excel in many tasks of software engineering, yet\nprogress in leveraging them for vulnerability discovery has stalled in recent\nyears. To understand this phenomenon, we investigate LLMs through the lens of\nclassic code metrics. Surprisingly, we find that a classifier trained solely on\nthese metrics performs on par with state-of-the-art LLMs for vulnerability\ndiscovery. A root-cause analysis reveals a strong correlation and a causal\neffect between LLMs and code metrics: When the value of a metric is changed,\nLLM predictions tend to shift by a corresponding magnitude. This dependency\nsuggests that LLMs operate at a similarly shallow level as code metrics,\nlimiting their ability to grasp complex patterns and fully realize their\npotential in vulnerability discovery. Based on these findings, we derive\nrecommendations on how research should more effectively address this challenge.", "published": "2025-09-23 15:03:05", "link": "http://arxiv.org/abs/2509.19117v1", "categories": ["cs.CR", "cs.LG", "cs.SE"], "primary_category": "cs.CR"}
{"title": "A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Servoing Control for the multicopter Interception", "abstract": "Reinforcement learning-based controller design methods often require\nsubstantial data in the initial training phase. Moreover, the training process\ntends to exhibit strong randomness and slow convergence. It often requires\nconsiderable time or high computational resources. Another class of\nlearning-based method incorporates Lyapunov stability theory to obtain a\ncontrol policy with stability guarantees. However, these methods generally\nrequire an initially stable neural network control policy at the beginning of\ntraining. Evidently, a stable neural network controller can not only serve as\nan initial policy for reinforcement learning, allowing the training to focus on\nimproving controller performance, but also act as an initial state for\nlearning-based Lyapunov control methods. Although stable controllers can be\ndesigned using traditional control theory, designers still need to have a great\ndeal of control design knowledge to address increasingly complicated control\nproblems. The proposed neural network rapid initialization method in this paper\nachieves the initial training of the neural network control policy by\nconstructing datasets that conform to the stability conditions based on the\nsystem model. Furthermore, using the image-based visual servoing control for\nmulticopter interception as a case study, simulations and experiments were\nconducted to validate the effectiveness and practical performance of the\nproposed method. In the experiment, the trained control policy attains a final\ninterception velocity of 15 m/s.", "published": "2025-09-23 14:56:59", "link": "http://arxiv.org/abs/2509.19110v1", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "DRO-REBEL: Distributionally Robust Relative-Reward Regression for Fast and Efficient LLM Alignment", "abstract": "Reinforcement learning with human feedback (RLHF) has become crucial for\naligning Large Language Models (LLMs) with human intent. However, existing\noffline RLHF approaches suffer from overoptimization, where models overfit to\nreward misspecification and drift from preferred behaviors observed during\ntraining. We introduce DRO-REBEL, a unified family of robust REBEL updates with\ntype-$p$ Wasserstein, KL, and $\\chi^2$ ambiguity sets. Using Fenchel duality,\neach update reduces to a simple relative-reward regression, preserving\nscalability and avoiding PPO-style clipping or auxiliary value networks. Under\nstandard linear-reward and log-linear policy classes with a data-coverage\ncondition, we establish $O(n^{-1/4})$ estimation bounds with tighter constants\nthan prior DRO-DPO approaches, and recover the minimax-optimal $O(n^{-1/2})$\nrate via a localized Rademacher complexity analysis. The same analysis closes\nthe gap for Wasserstein-DPO and KL-DPO, showing both also attain optimal\nparametric rates. We derive practical SGD algorithms for all three divergences:\ngradient regularization (Wasserstein), importance weighting (KL), and a fast\n1-D dual solve ($\\chi^2$). Experiments on Emotion Alignment, the large-scale\nArmoRM multi-objective benchmark, and HH-Alignment demonstrate strong\nworst-case robustness across unseen preference mixtures, model sizes, and data\nscales, with $\\chi^2$-REBEL showing consistently strong empirical performance.\nA controlled radius--coverage study validates a no-free-lunch trade-off: radii\nshrinking faster than empirical divergence concentration rates achieve\nminimax-optimal parametric rates but forfeit coverage, while\ncoverage-guaranteeing radii incur $O(n^{-1/4})$ rates.", "published": "2025-09-23 14:49:48", "link": "http://arxiv.org/abs/2509.19104v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Asymptotically Optimal Problem-Dependent Bandit Policies for Transfer Learning", "abstract": "We study the non-contextual multi-armed bandit problem in a transfer learning\nsetting: before any pulls, the learner is given N'_k i.i.d. samples from each\nsource distribution nu'_k, and the true target distributions nu_k lie within a\nknown distance bound d_k(nu_k, nu'_k) <= L_k. In this framework, we first\nderive a problem-dependent asymptotic lower bound on cumulative regret that\nextends the classical Lai-Robbins result to incorporate the transfer parameters\n(d_k, L_k, N'_k). We then propose KL-UCB-Transfer, a simple index policy that\nmatches this new bound in the Gaussian case. Finally, we validate our approach\nvia simulations, showing that KL-UCB-Transfer significantly outperforms the\nno-prior baseline when source and target distributions are sufficiently close.", "published": "2025-09-23 14:47:42", "link": "http://arxiv.org/abs/2509.19098v1", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Diffusion Bridge Variational Inference for Deep Gaussian Processes", "abstract": "Deep Gaussian processes (DGPs) enable expressive hierarchical Bayesian\nmodeling but pose substantial challenges for posterior inference, especially\nover inducing variables. Denoising diffusion variational inference (DDVI)\naddresses this by modeling the posterior as a time-reversed diffusion from a\nsimple Gaussian prior. However, DDVI's fixed unconditional starting\ndistribution remains far from the complex true posterior, resulting in\ninefficient inference trajectories and slow convergence. In this work, we\npropose Diffusion Bridge Variational Inference (DBVI), a principled extension\nof DDVI that initiates the reverse diffusion from a learnable, data-dependent\ninitial distribution. This initialization is parameterized via an amortized\nneural network and progressively adapted using gradients from the ELBO\nobjective, reducing the posterior gap and improving sample efficiency. To\nenable scalable amortization, we design the network to operate on the inducing\ninputs, which serve as structured, low-dimensional summaries of the dataset and\nnaturally align with the inducing variables' shape. DBVI retains the\nmathematical elegance of DDVI, including Girsanov-based ELBOs and reverse-time\nSDEs,while reinterpreting the prior via a Doob-bridged diffusion process. We\nderive a tractable training objective under this formulation and implement DBVI\nfor scalable inference in large-scale DGPs. Across regression, classification,\nand image reconstruction tasks, DBVI consistently outperforms DDVI and other\nvariational baselines in predictive accuracy, convergence speed, and posterior\nquality.", "published": "2025-09-23 14:36:47", "link": "http://arxiv.org/abs/2509.19078v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving Credit Card Fraud Detection through Transformer-Enhanced GAN Oversampling", "abstract": "Detection of credit card fraud is an acute issue of financial security\nbecause transaction datasets are highly lopsided, with fraud cases being only a\ndrop in the ocean. Balancing datasets using the most popular methods of\ntraditional oversampling such as the Synthetic Minority Oversampling Technique\n(SMOTE) generally create simplistic synthetic samples that are not readily\napplicable to complex fraud patterns. Recent industry advances that include\nConditional Tabular Generative Adversarial Networks (CTGAN) and Tabular\nVariational Autoencoders (TVAE) have demonstrated increased efficiency in\ntabular synthesis, yet all these models still exhibit issues with\nhigh-dimensional dependence modelling. Now we will present our hybrid approach\nwhere we use a Generative Adversarial Network (GAN) with a Transformer encoder\nblock to produce realistic fraudulent transactions samples. The GAN\narchitecture allows training realistic generators adversarial, and the\nTransformer allows the model to learn rich feature interactions by\nself-attention. Such a hybrid strategy overcomes the limitations of SMOTE,\nCTGAN, and TVAE by producing a variety of high-quality synthetic minority\nclasses samples. We test our algorithm on the publicly-available Credit Card\nFraud Detection dataset and compare it to conventional and generative\nresampling strategies with a variety of classifiers, such as Logistic\nRegression (LR), Random Forest (RF), Extreme Gradient Boosting (XGBoost), and\nSupport Vector Machine (SVM). Findings indicate that our Transformer-based GAN\nshows substantial gains in Recall, F1-score and Area Under the Receiver\nOperating Characteristic Curve (AUC), which indicates that it is effective in\novercoming the severe class imbalance inherent in the task of fraud detection.", "published": "2025-09-23 14:05:13", "link": "http://arxiv.org/abs/2509.19032v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment", "abstract": "Recent advances in multimodal large language models (LLMs) have led to\nsignificant progress in understanding, generation, and retrieval tasks.\nHowever, current solutions often treat these tasks in isolation or require\ntraining LLMs from scratch, resulting in high computational costs and limited\ngeneralization across modalities. In this work, we present OmniBridge, a\nunified and modular multimodal framework that supports vision-language\nunderstanding, generation, and retrieval within a unified architecture.\nOmniBridge adopts a language-centric design that reuses pretrained LLMs and\nintroduces a lightweight bidirectional latent alignment module. To address the\nchallenge of task interference, we propose a two-stage decoupled training\nstrategy: supervised fine-tuning and latent space alignment for aligning LLM\nbehavior with multimodal reasoning, and semantic-guided diffusion training to\nalign cross-modal latent spaces via learnable query embeddings. Extensive\nexperiments across a wide range of benchmarks demonstrate that OmniBridge\nachieves competitive or state-of-the-art performance in all three tasks.\nMoreover, our results highlight the effectiveness of latent space alignment for\nunifying multimodal modeling under a shared representation space. Code and\nmodels are released at https://github.com/xiao-xt/OmniBridge.", "published": "2025-09-23 13:57:55", "link": "http://arxiv.org/abs/2509.19018v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum Annealing for Minimum Bisection Problem: A Machine Learning-based Approach for Penalty Parameter Tuning", "abstract": "The Minimum Bisection Problem is a well-known NP-hard problem in\ncombinatorial optimization, with practical applications in areas such as\nparallel computing, network design, and machine learning. In this paper, we\nexamine the potential of using D-Wave Systems' quantum annealing solvers to\nsolve the Minimum Bisection Problem, which we formulate as a Quadratic\nUnconstrained Binary Optimization model. A key challenge in this formulation\nlies in choosing an appropriate penalty parameter, as it plays a crucial role\nin ensuring both the quality of the solution and the satisfaction of the\nproblem's constraints. To address this, we introduce a novel machine\nlearning-based approach for adaptive tuning of the penalty parameter.\nSpecifically, we use a Gradient Boosting Regressor model trained to predict\nsuitable penalty parameter values based on structural properties of the input\ngraph, the number of nodes and the graph's density. This method enables the\npenalty parameter to be adjusted dynamically for each specific problem\ninstance, improving the solver's ability to balance the competing goals of\nminimizing the cut size and maintaining equally sized partitions. We test our\napproach on a large dataset of randomly generated Erd\\H{o}s-R\\'enyi graphs with\nup to 4,000 nodes, and we compare the results with classical partitioning\nalgorithms, Metis and Kernighan-Lin. Experimental findings demonstrate that our\nadaptive tuning strategy significantly improves the performance of the quantum\nannealing hybrid solver and consistently outperforms the classical methods\nused, indicating its potential as an alternative for the graph partitioning\nproblem.", "published": "2025-09-23 13:49:18", "link": "http://arxiv.org/abs/2509.19005v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Bayesian Calibration and Model Assessment of Cell Migration Dynamics with Surrogate Model Integration", "abstract": "Computational models provide crucial insights into complex biological\nprocesses such as cancer evolution, but their mechanistic nature often makes\nthem nonlinear and parameter-rich, complicating calibration. We systematically\nevaluate parameter probability distributions in cell migration models using\nBayesian calibration across four complementary strategies: parametric and\nsurrogate models, each with and without explicit model discrepancy. This\napproach enables joint analysis of parameter uncertainty, predictive\nperformance, and interpretability. Applied to a real data experiment of\nglioblastoma progression in microfluidic devices, surrogate models achieve\nhigher computational efficiency and predictive accuracy, whereas parametric\nmodels yield more reliable parameter estimates due to their mechanistic\ngrounding. Incorporating model discrepancy exposes structural limitations,\nclarifying where model refinement is necessary. Together, these comparisons\noffer practical guidance for calibrating and improving computational models of\ncomplex biological systems.", "published": "2025-09-23 13:45:16", "link": "http://arxiv.org/abs/2509.18998v1", "categories": ["math.AP", "cs.LG", "q-bio.CB", "q-bio.QM"], "primary_category": "math.AP"}
{"title": "Theoretical Foundations of Representation Learning using Unlabeled Data: Statistics and Optimization", "abstract": "Representation learning from unlabeled data has been extensively studied in\nstatistics, data science and signal processing with a rich literature on\ntechniques for dimension reduction, compression, multi-dimensional scaling\namong others. However, current deep learning models use new principles for\nunsupervised representation learning that cannot be easily analyzed using\nclassical theories. For example, visual foundation models have found tremendous\nsuccess using self-supervision or denoising/masked autoencoders, which\neffectively learn representations from massive amounts of unlabeled data.\nHowever, it remains difficult to characterize the representations learned by\nthese models and to explain why they perform well for diverse prediction tasks\nor show emergent behavior. To answer these questions, one needs to combine\nmathematical tools from statistics and optimization. This paper provides an\noverview of recent theoretical advances in representation learning from\nunlabeled data and mentions our contributions in this direction.", "published": "2025-09-23 13:45:11", "link": "http://arxiv.org/abs/2509.18997v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CR-Net: Scaling Parameter-Efficient Training with Cross-Layer Low-Rank Structure", "abstract": "Low-rank architectures have become increasingly important for efficient large\nlanguage model (LLM) pre-training, providing substantial reductions in both\nparameter complexity and memory/computational demands. Despite these\nadvantages, current low-rank methods face three critical shortcomings: (1)\ncompromised model performance, (2) considerable computational overhead, and (3)\nlimited activation memory savings. To address these limitations, we propose\nCross-layer Low-Rank residual Network (CR-Net), an innovative\nparameter-efficient framework inspired by our discovery that inter-layer\nactivation residuals possess low-rank properties. CR-Net implements this\ninsight through a dual-path architecture that efficiently reconstructs layer\nactivations by combining previous-layer outputs with their low-rank\ndifferences, thereby maintaining high-rank information with minimal parameters.\nWe further develop a specialized activation recomputation strategy tailored for\nCR-Net that dramatically reduces memory requirements. Extensive pre-training\nexperiments across model scales from 60M to 7B parameters demonstrate that\nCR-Net consistently outperforms state-of-the-art low-rank frameworks while\nrequiring fewer computational resources and less memory.", "published": "2025-09-23 13:43:02", "link": "http://arxiv.org/abs/2509.18993v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning From Simulators: A Theory of Simulation-Grounded Learning", "abstract": "Simulation-Grounded Neural Networks (SGNNs) are predictive models trained\nentirely on synthetic data from mechanistic simulations. They have achieved\nstate-of-the-art performance in domains where real-world labels are limited or\nunobserved, but lack a formal underpinning.\n  We present the foundational theory of simulation-grounded learning. We show\nthat SGNNs implement amortized Bayesian inference under a simulation prior and\nconverge to the Bayes-optimal predictor. We derive generalization bounds under\nmodel misspecification and prove that SGNNs can learn unobservable scientific\nquantities that empirical methods provably cannot. We also formalize a novel\nform of mechanistic interpretability uniquely enabled by SGNNs: by attributing\npredictions to the simulated mechanisms that generated them, SGNNs yield\nposterior-consistent, scientifically grounded explanations.\n  We provide numerical experiments to validate all theoretical predictions.\nSGNNs recover latent parameters, remain robust under mismatch, and outperform\nclassical tools: in a model selection task, SGNNs achieve half the error of AIC\nin distinguishing mechanistic dynamics. These results establish SGNNs as a\nprincipled and practical framework for scientific prediction in data-limited\nregimes.", "published": "2025-09-23 13:39:11", "link": "http://arxiv.org/abs/2509.18990v1", "categories": ["cs.LG", "math.DS"], "primary_category": "cs.LG"}
{"title": "Otters: An Energy-Efficient SpikingTransformer via Optical Time-to-First-Spike Encoding", "abstract": "Spiking neural networks (SNNs) promise high energy efficiency, particularly\nwith time-to-first-spike (TTFS) encoding, which maximizes sparsity by emitting\nat most one spike per neuron. However, such energy advantage is often\nunrealized because inference requires evaluating a temporal decay function and\nsubsequent multiplication with the synaptic weights. This paper challenges this\ncostly approach by repurposing a physical hardware `bug', namely, the natural\nsignal decay in optoelectronic devices, as the core computation of TTFS. We\nfabricated a custom indium oxide optoelectronic synapse, showing how its\nnatural physical decay directly implements the required temporal function. By\ntreating the device's analog output as the fused product of the synaptic weight\nand temporal decay, optoelectronic synaptic TTFS (named Otters) eliminates\nthese expensive digital operations. To use the Otters paradigm in complex\narchitectures like the transformer, which are challenging to train directly due\nto the sparsity issue, we introduce a novel quantized neural network-to-SNN\nconversion algorithm. This complete hardware-software co-design enables our\nmodel to achieve state-of-the-art accuracy across seven GLUE benchmark datasets\nand demonstrates a 1.77$\\times$ improvement in energy efficiency over previous\nleading SNNs, based on a comprehensive analysis of compute, data movement, and\nmemory access costs using energy measurements from a commercial 22nm process.\nOur work thus establishes a new paradigm for energy-efficient SNNs, translating\nfundamental device physics directly into powerful computational primitives. All\ncodes and data are open source.", "published": "2025-09-23 13:23:48", "link": "http://arxiv.org/abs/2509.18968v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Central Limit Theorems for Asynchronous Averaged Q-Learning", "abstract": "This paper establishes central limit theorems for Polyak-Ruppert averaged\nQ-learning under asynchronous updates. We present a non-asymptotic central\nlimit theorem, where the convergence rate in Wasserstein distance explicitly\nreflects the dependence on the number of iterations, state-action space size,\nthe discount factor, and the quality of exploration. In addition, we derive a\nfunctional central limit theorem, showing that the partial-sum process\nconverges weakly to a Brownian motion.", "published": "2025-09-23 13:16:14", "link": "http://arxiv.org/abs/2509.18964v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Lift What You Can: Green Online Learning with Heterogeneous Ensembles", "abstract": "Ensemble methods for stream mining necessitate managing multiple models and\nupdating them as data distributions evolve. Considering the calls for more\nsustainability, established methods are however not sufficiently considerate of\nensemble members' computational expenses and instead overly focus on predictive\ncapabilities. To address these challenges and enable green online learning, we\npropose heterogeneous online ensembles (HEROS). For every training step, HEROS\nchooses a subset of models from a pool of models initialized with diverse\nhyperparameter choices under resource constraints to train. We introduce a\nMarkov decision process to theoretically capture the trade-offs between\npredictive performance and sustainability constraints. Based on this framework,\nwe present different policies for choosing which models to train on incoming\ndata. Most notably, we propose the novel $\\zeta$-policy, which focuses on\ntraining near-optimal models at reduced costs. Using a stochastic model, we\ntheoretically prove that our $\\zeta$-policy achieves near optimal performance\nwhile using fewer resources compared to the best performing policy. In our\nexperiments across 11 benchmark datasets, we find empiric evidence that our\n$\\zeta$-policy is a strong contribution to the state-of-the-art, demonstrating\nhighly accurate performance, in some cases even outperforming competitors, and\nsimultaneously being much more resource-friendly.", "published": "2025-09-23 13:14:37", "link": "http://arxiv.org/abs/2509.18962v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks", "abstract": "This paper introduces a novel framework for Edge Inference (EI) that bypasses\nthe conventional practice of treating the wireless channel as noise. We utilize\nStacked Intelligent Metasurfaces (SIMs) to control wireless propagation,\nenabling the channel itself to perform over-the-air computation. This\neliminates the need for symbol estimation at the receiver, significantly\nreducing computational and communication overhead. Our approach models the\ntransmitter-channel-receiver system as an end-to-end Deep Neural Network (DNN)\nwhere the response of the SIM elements are trainable parameters. To address\nchannel variability, we incorporate a dedicated DNN module responsible for\ndynamically adjusting transmission power leveraging user location information.\nOur performance evaluations showcase that the proposed metasurfaces-integrated\nDNN framework with deep SIM architectures are capable of balancing\nclassification accuracy and power consumption under diverse scenarios, offering\nsignificant energy efficiency improvements.", "published": "2025-09-23 12:13:06", "link": "http://arxiv.org/abs/2509.18906v1", "categories": ["cs.ET", "cs.LG", "eess.SP"], "primary_category": "cs.ET"}
{"title": "Enhancing the Effectiveness and Durability of Backdoor Attacks in Federated Learning through Maximizing Task Distinction", "abstract": "Federated learning allows multiple participants to collaboratively train a\ncentral model without sharing their private data. However, this distributed\nnature also exposes new attack surfaces. In particular, backdoor attacks allow\nattackers to implant malicious behaviors into the global model while\nmaintaining high accuracy on benign inputs. Existing attacks usually rely on\nfixed patterns or adversarial perturbations as triggers, which tightly couple\nthe main and backdoor tasks. This coupling makes them vulnerable to dilution by\nhonest updates and limits their persistence under federated defenses. In this\nwork, we propose an approach to decouple the backdoor task from the main task\nby dynamically optimizing the backdoor trigger within a min-max framework. The\ninner layer maximizes the performance gap between poisoned and benign samples,\nensuring that the contributions of benign users have minimal impact on the\nbackdoor. The outer process injects the adaptive triggers into the local model.\nWe evaluate our method on both computer vision and natural language tasks, and\ncompare it with six backdoor attack methods under six defense algorithms.\nExperimental results show that our method achieves good attack performance and\ncan be easily integrated into existing backdoor attack techniques.", "published": "2025-09-23 11:59:29", "link": "http://arxiv.org/abs/2509.18904v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring Heterophily in Graph-level Tasks", "abstract": "While heterophily has been widely studied in node-level tasks, its impact on\ngraph-level tasks remains unclear. We present the first analysis of heterophily\nin graph-level learning, combining theoretical insights with empirical\nvalidation. We first introduce a taxonomy of graph-level labeling schemes, and\nfocus on motif-based tasks within local structure labeling, which is a popular\nlabeling scheme. Using energy-based gradient flow analysis, we reveal a key\ninsight: unlike frequency-dominated regimes in node-level tasks, motif\ndetection requires mixed-frequency dynamics to remain flexible across multiple\nspectral components. Our theory shows that motif objectives are inherently\nmisaligned with global frequency dominance, demanding distinct architectural\nconsiderations. Experiments on synthetic datasets with controlled heterophily\nand real-world molecular property prediction support our findings, showing that\nfrequency-adaptive model outperform frequency-dominated models. This work\nestablishes a new theoretical understanding of heterophily in graph-level\nlearning and offers guidance for designing effective GNN architectures.", "published": "2025-09-23 11:07:16", "link": "http://arxiv.org/abs/2509.18893v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Confidential LLM Inference: Performance and Cost Across CPU and GPU TEEs", "abstract": "Large Language Models (LLMs) are increasingly deployed on converged Cloud and\nHigh-Performance Computing (HPC) infrastructure. However, as LLMs handle\nconfidential inputs and are fine-tuned on costly, proprietary datasets, their\nheightened security requirements slow adoption in privacy-sensitive sectors\nsuch as healthcare and finance. We investigate methods to address this gap and\npropose Trusted Execution Environments (TEEs) as a solution for securing\nend-to-end LLM inference. We validate their practicality by evaluating these\ncompute-intensive workloads entirely within CPU and GPU TEEs. On the CPU side,\nwe conduct an in-depth study running full Llama2 inference pipelines (7B, 13B,\n70B) inside Intel's TDX and SGX, accelerated by Advanced Matrix Extensions\n(AMX). We derive 12 insights, including that across various data types, batch\nsizes, and input lengths, CPU TEEs impose under 10% throughput and 20% latency\noverheads, further reduced by AMX. We run LLM inference on NVIDIA H100\nConfidential Compute GPUs, contextualizing our CPU findings and observing\nthroughput penalties of 4-8% that diminish as batch and input sizes grow. By\ncomparing performance, cost, and security trade-offs, we show how CPU TEEs can\nbe more cost-effective or secure than their GPU counterparts. To our knowledge,\nour work is the first to comprehensively demonstrate the performance and\npracticality of modern TEEs across both CPUs and GPUs for enabling confidential\nLLMs (cLLMs).", "published": "2025-09-23 10:36:47", "link": "http://arxiv.org/abs/2509.18886v1", "categories": ["cs.PF", "cs.AR", "cs.CR", "cs.LG"], "primary_category": "cs.PF"}
{"title": "Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation", "abstract": "We propose Bilateral Control-Based Imitation Learning via Vision-Language\nFusion for Action Generation (Bi-VLA), a novel framework that extends bilateral\ncontrol-based imitation learning to handle more than one task within a single\nmodel. Conventional bilateral control methods exploit joint angle, velocity,\ntorque, and vision for precise manipulation but require task-specific models,\nlimiting their generality. Bi-VLA overcomes this limitation by utilizing robot\njoint angle, velocity, and torque data from leader-follower bilateral control\nwith visual features and natural language instructions through SigLIP and\nFiLM-based fusion. We validated Bi-VLA on two task types: one requiring\nsupplementary language cues and another distinguishable solely by vision.\nReal-robot experiments showed that Bi-VLA successfully interprets\nvision-language combinations and improves task success rates compared to\nconventional bilateral control-based imitation learning. Our Bi-VLA addresses\nthe single-task limitation of prior bilateral approaches and provides empirical\nevidence that combining vision and language significantly enhances versatility.\nExperimental results validate the effectiveness of Bi-VLA in real-world tasks.\nFor additional material, please visit the website:\nhttps://mertcookimg.github.io/bi-vla/", "published": "2025-09-23 10:02:16", "link": "http://arxiv.org/abs/2509.18865v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Shared-Weights Extender and Gradient Voting for Neural Network Expansion", "abstract": "Expanding neural networks during training is a promising way to augment\ncapacity without retraining larger models from scratch. However, newly added\nneurons often fail to adjust to a trained network and become inactive,\nproviding no contribution to capacity growth. We propose the Shared-Weights\nExtender (SWE), a novel method explicitly designed to prevent inactivity of new\nneurons by coupling them with existing ones for smooth integration. In\nparallel, we introduce the Steepest Voting Distributor (SVoD), a gradient-based\nmethod for allocating neurons across layers during deep network expansion. Our\nextensive benchmarking on four datasets shows that our method can effectively\nsuppress neuron inactivity and achieve better performance compared to other\nexpanding methods and baselines.", "published": "2025-09-23 09:27:47", "link": "http://arxiv.org/abs/2509.18842v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Graph-based Clustering Revisited: A Relaxation of Kernel $k$-Means Perspective", "abstract": "The well-known graph-based clustering methods, including spectral clustering,\nsymmetric non-negative matrix factorization, and doubly stochastic\nnormalization, can be viewed as relaxations of the kernel $k$-means approach.\nHowever, we posit that these methods excessively relax their inherent low-rank,\nnonnegative, doubly stochastic, and orthonormal constraints to ensure numerical\nfeasibility, potentially limiting their clustering efficacy. In this paper,\nguided by our theoretical analyses, we propose \\textbf{Lo}w-\\textbf{R}ank\n\\textbf{D}oubly stochastic clustering (\\textbf{LoRD}), a model that only\nrelaxes the orthonormal constraint to derive a probabilistic clustering\nresults. Furthermore, we theoretically establish the equivalence between\northogonality and block diagonality under the doubly stochastic constraint. By\nintegrating \\textbf{B}lock diagonal regularization into LoRD, expressed as the\nmaximization of the Frobenius norm, we propose \\textbf{B-LoRD}, which further\nenhances the clustering performance. To ensure numerical solvability, we\ntransform the non-convex doubly stochastic constraint into a linear convex\nconstraint through the introduction of a class probability parameter. We\nfurther theoretically demonstrate the gradient Lipschitz continuity of our LoRD\nand B-LoRD enables the proposal of a globally convergent projected gradient\ndescent algorithm for their optimization. Extensive experiments validate the\neffectiveness of our approaches. The code is publicly available at\nhttps://github.com/lwl-learning/LoRD.", "published": "2025-09-23 09:14:39", "link": "http://arxiv.org/abs/2509.18826v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation", "abstract": "Policy mirror descent (PMD) is a general policy optimization framework in\nreinforcement learning, which can cover a wide range of typical policy\noptimization methods by specifying different mirror maps. Existing analysis of\nPMD requires exact or approximate evaluation (for example unbiased estimation\nvia Monte Carlo simulation) of action values solely based on policy. In this\npaper, we consider policy mirror descent with temporal difference evaluation\n(TD-PMD). It is shown that, given the access to exact policy evaluations, the\ndimension-free $O(1/T)$ sublinear convergence still holds for TD-PMD with any\nconstant step size and any initialization. In order to achieve this result, new\nmonotonicity and shift invariance arguments have been developed. The dimension\nfree $\\gamma$-rate linear convergence of TD-PMD is also established provided\nthe step size is selected adaptively. For the two common instances of TD-PMD\n(i.e., TD-PQA and TD-NPG), it is further shown that they enjoy the convergence\nin the policy domain. Additionally, we investigate TD-PMD in the inexact\nsetting and give the sample complexity for it to achieve the last iterate\n$\\varepsilon$-optimality under a generative model, which improves the last\niterate sample complexity for PMD over the dependence on $1/(1-\\gamma)$.", "published": "2025-09-23 09:11:03", "link": "http://arxiv.org/abs/2509.18822v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Training-Free Data Assimilation with GenCast", "abstract": "Data assimilation is widely used in many disciplines such as meteorology,\noceanography, and robotics to estimate the state of a dynamical system from\nnoisy observations. In this work, we propose a lightweight and general method\nto perform data assimilation using diffusion models pre-trained for emulating\ndynamical systems. Our method builds on particle filters, a class of data\nassimilation algorithms, and does not require any further training. As a\nguiding example throughout this work, we illustrate our methodology on GenCast,\na diffusion-based model that generates global ensemble weather forecasts.", "published": "2025-09-23 08:59:44", "link": "http://arxiv.org/abs/2509.18811v1", "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Probabilistic Machine Learning for Uncertainty-Aware Diagnosis of Industrial Systems", "abstract": "Deep neural networks has been increasingly applied in fault diagnostics,\nwhere it uses historical data\n  to capture systems behavior, bypassing the need for high-fidelity physical\nmodels.\n  However, despite their competence in prediction tasks, these models often\nstruggle with\n  the evaluation of their confidence. This matter is particularly\n  important in consistency-based diagnosis where decision logic is highly\nsensitive to false alarms.\n  To address this challenge, this work presents a diagnostic framework that\nuses\n  ensemble probabilistic machine learning to\n  improve diagnostic characteristics of data driven consistency based diagnosis\n  by quantifying and automating the prediction uncertainty.\n  The proposed method is evaluated across several case studies using both\nablation\n  and comparative analyses, showing consistent improvements across a range of\ndiagnostic metrics.", "published": "2025-09-23 08:59:20", "link": "http://arxiv.org/abs/2509.18810v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Diagonal Linear Networks and the Lasso Regularization Path", "abstract": "Diagonal linear networks are neural networks with linear activation and\ndiagonal weight matrices. Their theoretical interest is that their implicit\nregularization can be rigorously analyzed: from a small initialization, the\ntraining of diagonal linear networks converges to the linear predictor with\nminimal 1-norm among minimizers of the training loss. In this paper, we deepen\nthis analysis showing that the full training trajectory of diagonal linear\nnetworks is closely related to the lasso regularization path. In this\nconnection, the training time plays the role of an inverse regularization\nparameter. Both rigorous results and simulations are provided to illustrate\nthis conclusion. Under a monotonicity assumption on the lasso regularization\npath, the connection is exact while in the general case, we show an approximate\nconnection.", "published": "2025-09-23 07:59:25", "link": "http://arxiv.org/abs/2509.18766v1", "categories": ["cs.LG", "math.OC", "stat.ML", "62J07, 68T07", "G.3"], "primary_category": "cs.LG"}
{"title": "MOMEMTO: Patch-based Memory Gate Model in Time Series Foundation Model", "abstract": "Recently reconstruction-based deep models have been widely used for time\nseries anomaly detection, but as their capacity and representation capability\nincrease, these models tend to over-generalize, often reconstructing unseen\nanomalies accurately. Prior works have attempted to mitigate this by\nincorporating a memory architecture that stores prototypes of normal patterns.\nNevertheless, these approaches suffer from high training costs and have yet to\nbe effectively integrated with time series foundation models (TFMs). To address\nthese challenges, we propose \\textbf{MOMEMTO}, a TFM for anomaly detection,\nenhanced with a patch-based memory module to mitigate over-generalization. The\nmemory module is designed to capture representative normal patterns from\nmultiple domains and enables a single model to be jointly fine-tuned across\nmultiple datasets through a multi-domain training strategy. MOMEMTO initializes\nmemory items with latent representations from a pre-trained encoder, organizes\nthem into patch-level units, and updates them via an attention mechanism. We\nevaluate our method using 23 univariate benchmark datasets. Experimental\nresults demonstrate that MOMEMTO, as a single model, achieves higher scores on\nAUC and VUS metrics compared to baseline methods, and further enhances the\nperformance of its backbone TFM, particularly in few-shot learning scenarios.", "published": "2025-09-23 07:48:25", "link": "http://arxiv.org/abs/2509.18751v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Theory of periodic convolutional neural network", "abstract": "We introduce a novel convolutional neural network architecture, termed the\n\\emph{periodic CNN}, which incorporates periodic boundary conditions into the\nconvolutional layers. Our main theoretical contribution is a rigorous\napproximation theorem: periodic CNNs can approximate ridge functions depending\non $d-1$ linear variables in a $d$-dimensional input space, while such\napproximation is impossible in lower-dimensional ridge settings ($d-2$ or fewer\nvariables). This result establishes a sharp characterization of the expressive\npower of periodic CNNs. Beyond the theory, our findings suggest that periodic\nCNNs are particularly well-suited for problems where data naturally admits a\nridge-like structure of high intrinsic dimension, such as image analysis on\nwrapped domains, physics-informed learning, and materials science. The work\nthus both expands the mathematical foundation of CNN approximation theory and\nhighlights a class of architectures with surprising and practically relevant\napproximation capabilities.", "published": "2025-09-23 07:43:02", "link": "http://arxiv.org/abs/2509.18744v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Consistency of Selection Strategies for Fraud Detection", "abstract": "This paper studies how insurers can chose which claims to investigate for\nfraud. Given a prediction model, typically only claims with the highest\npredicted propability of being fraudulent are investigated. We argue that this\ncan lead to inconsistent learning and propose a randomized alternative. More\ngenerally, we draw a parallel with the multi-arm bandit literature and argue\nthat, in the presence of selection, the obtained observations are not iid.\nHence, dependence on past observations should be accounted for when updating\nparameter estimates. We formalize selection in a binary regression framework\nand show that model updating and maximum-likelihood estimation can be\nimplemented as if claims were investigated at random. Then, we define\nconsistency of selection strategies and conjecture sufficient conditions for\nconsistency. Our simulations suggest that the often-used selection strategy can\nbe inconsistent while the proposed randomized alternative is consistent.\nFinally, we compare our randomized selection strategy with Thompson sampling, a\nstandard multi-arm bandit heuristic. Our simulations suggest that the latter\ncan be inefficient in learning low fraud probabilities.", "published": "2025-09-23 07:33:33", "link": "http://arxiv.org/abs/2509.18739v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection", "abstract": "This paper presents a novel approach to e-commerce payment fraud detection by\nintegrating reinforcement learning (RL) with Large Language Models (LLMs). By\nframing transaction risk as a multi-step Markov Decision Process (MDP), RL\noptimizes risk detection across multiple payment stages. Crafting effective\nreward functions, essential for RL model success, typically requires\nsignificant human expertise due to the complexity and variability in design.\nLLMs, with their advanced reasoning and coding capabilities, are well-suited to\nrefine these functions, offering improvements over traditional methods. Our\napproach leverages LLMs to iteratively enhance reward functions, achieving\nbetter fraud detection accuracy and demonstrating zero-shot capability.\nExperiments with real-world data confirm the effectiveness, robustness, and\nresilience of our LLM-enhanced RL framework through long-term evaluations,\nunderscoring the potential of LLMs in advancing industrial RL applications.", "published": "2025-09-23 07:07:16", "link": "http://arxiv.org/abs/2509.18719v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning When to Restart: Nonstationary Newsvendor from Uncensored to Censored Demand", "abstract": "We study nonstationary newsvendor problems under nonparametric demand models\nand general distributional measures of nonstationarity, addressing the\npractical challenges of unknown degree of nonstationarity and demand censoring.\nWe propose a novel distributional-detection-and-restart framework for learning\nin nonstationary environments, and instantiate it through two efficient\nalgorithms for the uncensored and censored demand settings. The algorithms are\nfully adaptive, requiring no prior knowledge of the degree and type of\nnonstationarity, and offer a flexible yet powerful approach to handling both\nabrupt and gradual changes in nonstationary environments. We establish a\ncomprehensive optimality theory for our algorithms by deriving matching regret\nupper and lower bounds under both general and refined structural conditions\nwith nontrivial proof techniques that are of independent interest. Numerical\nexperiments using real-world datasets, including nurse staffing data for\nemergency departments and COVID-19 test demand data, showcase the algorithms'\nsuperior and robust empirical performance. While motivated by the newsvendor\nproblem, the distributional-detection-and-restart framework applies broadly to\na wide class of nonstationary stochastic optimization problems. Managerially,\nour framework provides a practical, easy-to-deploy, and theoretically grounded\nsolution for decision-making under nonstationarity.", "published": "2025-09-23 06:46:37", "link": "http://arxiv.org/abs/2509.18709v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Towards Rational Pesticide Design with Graph Machine Learning Models for Ecotoxicology", "abstract": "This research focuses on rational pesticide design, using graph machine\nlearning to accelerate the development of safer, eco-friendly agrochemicals,\ninspired by in silico methods in drug discovery. With an emphasis on\necotoxicology, the initial contributions include the creation of ApisTox, the\nlargest curated dataset on pesticide toxicity to honey bees. We conducted a\nbroad evaluation of machine learning (ML) models for molecular graph\nclassification, including molecular fingerprints, graph kernels, GNNs, and\npretrained transformers. The results show that methods successful in medicinal\nchemistry often fail to generalize to agrochemicals, underscoring the need for\ndomain-specific models and benchmarks. Future work will focus on developing a\ncomprehensive benchmarking suite and designing ML models tailored to the unique\nchallenges of pesticide discovery.", "published": "2025-09-23 06:38:05", "link": "http://arxiv.org/abs/2509.18703v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Query-Centric Diffusion Policy for Generalizable Robotic Assembly", "abstract": "The robotic assembly task poses a key challenge in building generalist robots\ndue to the intrinsic complexity of part interactions and the sensitivity to\nnoise perturbations in contact-rich settings. The assembly agent is typically\ndesigned in a hierarchical manner: high-level multi-part reasoning and\nlow-level precise control. However, implementing such a hierarchical policy is\nchallenging in practice due to the mismatch between high-level skill queries\nand low-level execution. To address this, we propose the Query-centric\nDiffusion Policy (QDP), a hierarchical framework that bridges high-level\nplanning and low-level control by utilizing queries comprising objects, contact\npoints, and skill information. QDP introduces a query-centric mechanism that\nidentifies task-relevant components and uses them to guide low-level policies,\nleveraging point cloud observations to improve the policy's robustness. We\nconduct comprehensive experiments on the FurnitureBench in both simulation and\nreal-world settings, demonstrating improved performance in skill precision and\nlong-horizon success rate. In the challenging insertion and screwing tasks, QDP\nimproves the skill-wise success rate by over 50% compared to baselines without\nstructured queries.", "published": "2025-09-23 06:10:46", "link": "http://arxiv.org/abs/2509.18686v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Scalable bayesian shadow tomography for quantum property estimation with set transformers", "abstract": "A scalable Bayesian machine learning framework is introduced for estimating\nscalar properties of an unknown quantum state from measurement data, which\nbypasses full density matrix reconstruction. This work is the first to\nintegrate the classical shadows protocol with a permutation-invariant set\ntransformer architecture, enabling the approach to predict and correct bias in\nexisting estimators to approximate the true Bayesian posterior mean.\nMeasurement outcomes are encoded as fixed-dimensional feature vectors, and the\nnetwork outputs a residual correction to a baseline estimator. Scalability to\nlarge quantum systems is ensured by the polynomial dependence of input size on\nsystem size and number of measurements. On Greenberger-Horne-Zeilinger state\nfidelity and second-order R\\'enyi entropy estimation tasks -- using random\nPauli and random Clifford measurements -- this Bayesian estimator always\nachieves lower mean squared error than classical shadows alone, with more than\na 99\\% reduction in the few copy regime.", "published": "2025-09-23 05:46:26", "link": "http://arxiv.org/abs/2509.18674v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering", "abstract": "We introduce a novel framework for clustering a collection of tall matrices\nbased on their column spaces, a problem we term Subspace Clustering of\nSubspaces (SCoS). Unlike traditional subspace clustering methods that assume\nvectorized data, our formulation directly models each data sample as a matrix\nand clusters them according to their underlying subspaces. We establish\nconceptual links to Subspace Clustering and Generalized Canonical Correlation\nAnalysis (GCCA), and clarify key differences that arise in this more general\nsetting. Our approach is based on a Block Term Decomposition (BTD) of a\nthird-order tensor constructed from the input matrices, enabling joint\nestimation of cluster memberships and partially shared subspaces. We provide\nthe first identifiability results for this formulation and propose scalable\noptimization algorithms tailored to large datasets. Experiments on real-world\nhyperspectral imaging datasets demonstrate that our method achieves superior\nclustering accuracy and robustness, especially under high noise and\ninterference, compared to existing subspace clustering techniques. These\nresults highlight the potential of the proposed framework in challenging\nhigh-dimensional applications where structure exists beyond individual data\nvectors.", "published": "2025-09-23 05:12:40", "link": "http://arxiv.org/abs/2509.18653v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Reflect before Act: Proactive Error Correction in Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ninteractive decision-making tasks, but existing methods often struggle with\nerror accumulation and lack robust self-correction mechanisms. We introduce\n\"Reflect before Act\" (REBACT), a novel approach that enhances LLM-based\ndecision-making by introducing a critical reflect step prior to taking the next\naction. This approach allows for immediate error correction, ensuring smooth\naction path and adaptibity to environment feedback. We evaluate REBACT on three\ndiverse interactive environments: ALFWorld, WebShop, and TextCraft. Our results\ndemonstrate that REBACT significantly outperforms strong baselines, improving\nsuccess rates by up to 24% on WebShop (achieving 61%), 6.72% on ALFWorld\n(achieving 98.51%), and 0.5% on TextCraft (achieving 99.5%) using\nClaude3.5-sonnet as the underlying LLM. Further analysis reveals that REBACT's\nperformance improvements are achieved with only a few modification steps,\ndemonstrating its computational efficiency.", "published": "2025-09-23 03:53:45", "link": "http://arxiv.org/abs/2509.18607v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation", "abstract": "Diffusion models are the mainstream approach for time series generation\ntasks. However, existing diffusion models for time series generation require\nretraining the entire framework to introduce specific conditional guidance.\nThere also exists a certain degree of distributional bias between the generated\ndata and the real data, which leads to potential model biases in downstream\ntasks. Additionally, the complexity of diffusion models and the latent spaces\nleads to an uninterpretable inference process. To address these issues, we\npropose the data style-guided diffusion model (DS-Diffusion). In the\nDS-Diffusion, a diffusion framework based on style-guided kernels is developed\nto avoid retraining for specific conditions. The time-information based\nhierarchical denoising mechanism (THD) is developed to reduce the\ndistributional bias between the generated data and the real data. Furthermore,\nthe generated samples can clearly indicate the data style from which they\noriginate. We conduct comprehensive evaluations using multiple public datasets\nto validate our approach. Experimental results show that, compared to the\nstate-of-the-art model such as ImagenTime, the predictive score and the\ndiscriminative score decrease by 5.56% and 61.55%, respectively. The\ndistributional bias between the generated data and the real data is further\nreduced, the inference process is also more interpretable. Moreover, by\neliminating the need to retrain the diffusion model, the flexibility and\nadaptability of the model to specific conditions are also enhanced.", "published": "2025-09-23 03:06:39", "link": "http://arxiv.org/abs/2509.18584v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interaction Topological Transformer for Multiscale Learning in Porous Materials", "abstract": "Porous materials exhibit vast structural diversity and support critical\napplications in gas storage, separations, and catalysis. However, predictive\nmodeling remains challenging due to the multiscale nature of structure-property\nrelationships, where performance is governed by both local chemical\nenvironments and global pore-network topology. These complexities, combined\nwith sparse and unevenly distributed labeled data, hinder generalization across\nmaterial families. We propose the Interaction Topological Transformer (ITT), a\nunified data-efficient framework that leverages novel interaction topology to\ncapture materials information across multiple scales and multiple levels,\nincluding structural, elemental, atomic, and pairwise-elemental organization.\nITT extracts scale-aware features that reflect both compositional and\nrelational structure within complex porous frameworks, and integrates them\nthrough a built-in Transformer architecture that supports joint reasoning\nacross scales. Trained using a two-stage strategy, i.e., self-supervised\npretraining on 0.6 million unlabeled structures followed by supervised\nfine-tuning, ITT achieves state-of-the-art, accurate, and transferable\npredictions for adsorption, transport, and stability properties. This framework\nprovides a principled and scalable path for learning-guided discovery in\nstructurally and chemically diverse porous materials.", "published": "2025-09-23 02:56:05", "link": "http://arxiv.org/abs/2509.18573v1", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia", "abstract": "Dementia is a progressive neurodegenerative disorder with multiple\netiologies, including Alzheimer's disease, Parkinson's disease, frontotemporal\ndementia, and vascular dementia. Its clinical and biological heterogeneity\nmakes diagnosis and subtype differentiation highly challenging. Graph Neural\nNetworks (GNNs) have recently shown strong potential in modeling brain\nconnectivity, but their limited robustness, data scarcity, and lack of\ninterpretability constrain clinical adoption. Explainable Graph Neural Networks\n(XGNNs) have emerged to address these barriers by combining graph-based\nlearning with interpretability, enabling the identification of disease-relevant\nbiomarkers, analysis of brain network disruptions, and provision of transparent\ninsights for clinicians. This paper presents the first comprehensive review\ndedicated to XGNNs in dementia research. We examine their applications across\nAlzheimer's disease, Parkinson's disease, mild cognitive impairment, and\nmulti-disease diagnosis. A taxonomy of explainability methods tailored for\ndementia-related tasks is introduced, alongside comparisons of existing models\nin clinical scenarios. We also highlight challenges such as limited\ngeneralizability, underexplored domains, and the integration of Large Language\nModels (LLMs) for early detection. By outlining both progress and open\nproblems, this review aims to guide future work toward trustworthy, clinically\nmeaningful, and scalable use of XGNNs in dementia research.", "published": "2025-09-23 02:52:00", "link": "http://arxiv.org/abs/2509.18568v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Global Minimizers of Sigmoid Contrastive Loss", "abstract": "The meta-task of obtaining and aligning representations through contrastive\npretraining is steadily gaining importance since its introduction in CLIP and\nALIGN. In this paper we theoretically explain the advantages of synchronizing\nwith trainable inverse temperature and bias under the sigmoid loss, as\nimplemented in the recent SigLIP and SigLIP2 models of Google DeepMind.\nTemperature and bias can drive the loss function to zero for a rich class of\nconfigurations that we call $(\\mathsf{m},\n\\mathsf{b}_{\\mathsf{rel}})$-Constellations. $(\\mathsf{m},\n\\mathsf{b}_{\\mathsf{rel}})$-Constellations are a novel combinatorial object\nrelated to spherical codes and are parametrized by a margin $\\mathsf{m}$ and\nrelative bias $\\mathsf{b}_{\\mathsf{rel}}$. We use our characterization of\nconstellations to theoretically justify the success of SigLIP on retrieval, to\nexplain the modality gap present in SigLIP, and to identify the necessary\ndimension for producing high-quality representations. Finally, we propose a\nreparameterization of the sigmoid loss with explicit relative bias, which\nimproves training dynamics in experiments with synthetic data.", "published": "2025-09-23 02:24:23", "link": "http://arxiv.org/abs/2509.18552v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Symphony-MoE: Harmonizing Disparate Pre-trained Models into a Coherent Mixture-of-Experts", "abstract": "Mixture-of-Experts (MoE) models enable scalable performance by activating\nlarge parameter sets sparsely, minimizing computational overhead. To circumvent\nthe prohibitive cost of training MoEs from scratch, recent work employs\nupcycling, reusing a single pre-trained dense model by replicating its\nfeed-forward network (FFN) layers into experts. However, this limits expert\ndiversity, as all experts originate from a single pre-trained dense model. This\npaper addresses this limitation by constructing powerful MoE models using\nexperts sourced from multiple identically-architected but disparate pre-trained\nmodels (e.g., Llama2-Chat and Code Llama). A key challenge lies in the fact\nthat these source models occupy disparate, dissonant regions of the parameter\nspace, making direct upcycling prone to severe performance degradation. To\novercome this, we propose Symphony-MoE, a novel two-stage framework designed to\nharmonize these models into a single, coherent expert mixture. First, we\nestablish this harmony in a training-free manner: we construct a shared\nbackbone via a layer-aware fusion strategy and, crucially, alleviate parameter\nmisalignment among experts using activation-based functional alignment.\nSubsequently, a single lightweight stage of router training coordinates the\nentire architecture. Experiments demonstrate that our method successfully\nintegrates experts from heterogeneous sources, achieving an MoE model that\nsignificantly surpasses baselines in multi-domain tasks and out-of-distribution\ngeneralization.", "published": "2025-09-23 02:07:14", "link": "http://arxiv.org/abs/2509.18542v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Re-uploading quantum data: A universal function approximator for quantum inputs", "abstract": "Quantum data re-uploading has proved powerful for classical inputs, where\nrepeatedly encoding features into a small circuit yields universal function\napproximation. Extending this idea to quantum inputs remains underexplored, as\nthe information contained in a quantum state is not directly accessible in\nclassical form. We propose and analyze a quantum data re-uploading architecture\nin which a qubit interacts sequentially with fresh copies of an arbitrary input\nstate. The circuit can approximate any bounded continuous function using only\none ancilla qubit and single-qubit measurements. By alternating entangling\nunitaries with mid-circuit resets of the input register, the architecture\nrealizes a discrete cascade of completely positive and trace-preserving maps,\nanalogous to collision models in open quantum system dynamics. Our framework\nprovides a qubit-efficient and expressive approach to designing quantum machine\nlearning models that operate directly on quantum data.", "published": "2025-09-23 01:50:37", "link": "http://arxiv.org/abs/2509.18530v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Reverse-Complement Consistency for DNA Language Models", "abstract": "A fundamental property of DNA is that the reverse complement (RC) of a\nsequence often carries identical biological meaning. However, state-of-the-art\nDNA language models frequently fail to capture this symmetry, producing\ninconsistent predictions for a sequence and its RC counterpart, which\nundermines their reliability. In this work, we introduce Reverse-Complement\nConsistency Regularization (RCCR), a simple and model-agnostic fine-tuning\nobjective that directly penalizes the divergence between a model's prediction\non a sequence and the aligned prediction on its reverse complement. We evaluate\nRCCR across three diverse backbones (Nucleotide Transformer, HyenaDNA,\nDNABERT-2) on a wide range of genomic tasks, including sequence classification,\nscalar regression, and profile prediction. Our experiments show that RCCR\nsubstantially improves RC robustness by dramatically reducing prediction flips\nand errors, all while maintaining or improving task accuracy compared to\nbaselines such as RC data augmentation and test-time averaging. By integrating\na key biological prior directly into the learning process, RCCR produces a\nsingle, intrinsically robust, and computationally efficient model fine-tuning\nrecipe for diverse biology tasks.", "published": "2025-09-23 01:50:20", "link": "http://arxiv.org/abs/2509.18529v1", "categories": ["cs.LG", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Proactive-reactive detection and mitigation of intermittent faults in robot swarms", "abstract": "Intermittent faults are transient errors that sporadically appear and\ndisappear. Although intermittent faults pose substantial challenges to\nreliability and coordination, existing studies of fault tolerance in robot\nswarms focus instead on permanent faults. One reason for this is that\nintermittent faults are prohibitively difficult to detect in the fully\nself-organized ad-hoc networks typical of robot swarms, as their network\ntopologies are transient and often unpredictable. However, in the recently\nintroduced self-organizing nervous systems (SoNS) approach, robot swarms are\nable to self-organize persistent network structures for the first time, easing\nthe problem of detecting intermittent faults. To address intermittent faults in\nrobot swarms that have persistent networks, we propose a novel\nproactive-reactive strategy to detection and mitigation, based on\nself-organized backup layers and distributed consensus in a multiplex network.\nProactively, the robots self-organize dynamic backup paths before faults occur,\nadapting to changes in the primary network topology and the robots' relative\npositions. Reactively, robots use one-shot likelihood ratio tests to compare\ninformation received along different paths in the multiplex network, enabling\nearly fault detection. Upon detection, communication is temporarily rerouted in\na self-organized way, until the detected fault resolves. We validate the\napproach in representative scenarios of faulty positional data occurring during\nformation control, demonstrating that intermittent faults are prevented from\ndisrupting convergence to desired formations, with high fault detection\naccuracy and low rates of false positives.", "published": "2025-09-23 17:06:52", "link": "http://arxiv.org/abs/2509.19246v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations", "abstract": "Vehicles are becoming increasingly automated and interconnected, enabling the\nformation of cooperative intelligent transport systems (C-ITS) and the use of\noffboard services. As a result, cloud-native techniques, such as microservices\nand container orchestration, play an increasingly important role in their\noperation. However, orchestrating applications in a large-scale C-ITS poses\nunique challenges due to the dynamic nature of the environment and the need for\nefficient resource utilization. In this paper, we present a demand-driven\napplication management approach that leverages cloud-native techniques -\nspecifically Kubernetes - to address these challenges. Taking into account the\ndemands originating from different entities within the C-ITS, the approach\nenables the automation of processes, such as deployment, reconfiguration,\nupdate, upgrade, and scaling of microservices. Executing these processes on\ndemand can, for example, reduce computing resource consumption and network\ntraffic. A demand may include a request for provisioning an external supporting\nservice, such as a collective environment model. The approach handles changing\nand new demands by dynamically reconciling them through our proposed\napplication management framework built on Kubernetes and the Robot Operating\nSystem (ROS 2). We demonstrate the operation of our framework in the C-ITS use\ncase of collective environment perception and make the source code of the\nprototypical framework publicly available at\nhttps://github.com/ika-rwth-aachen/application_manager .", "published": "2025-09-23 08:36:08", "link": "http://arxiv.org/abs/2509.18793v1", "categories": ["cs.RO", "cs.MA", "cs.SE"], "primary_category": "cs.RO"}
{"title": "RGDBEK: Randomized Greedy Double Block Extended Kaczmarz Algorithm with Hybrid Parallel Implementation and Applications", "abstract": "Kaczmarz is one of the most prominent iterative solvers for linear systems of\nequations. Despite substantial research progress in recent years, the\nstate-of-the-art Kaczmarz algorithms have not fully resolved the seesaw effect,\na major impediment to convergence stability. Furthermore, while there have been\nadvances in parallelizing the inherently sequential Kaczmarz method, no\nexisting architecture effectively supports initialization-independent\nparallelism that fully leverages both CPU and GPU resources. This paper\nproposes the Randomized Greedy Double Block Extended Kaczmarz (RGDBEK)\nalgorithm, a novel Kaczmarz approach designed for efficient large-scale linear\nsystem solutions. RGDBEK employs a randomized selection strategy for column and\nrow blocks based on residual-derived probability distributions, thereby\nmitigating the traditional seesaw effect and enhancing convergence robustness.\nTheoretical analysis establishes linear convergence of the method under\nstandard assumptions. Extensive numerical experiments on synthetic random\nmatrices and real-world sparse matrices from the SuiteSparse collection\ndemonstrate that RGDBEK outperforms existing Kaczmarz variants, including GRK,\nFDBK, FGBK, and GDBEK, in both iteration counts and computational time. In\naddition, a hybrid parallel CPU-GPU implementation utilizing optimized sparse\nmatrix-vector multiplications via the state-of-the-art storage format improves\nscalability and performance on large sparse problems. Applications in finite\nelement discretizations, image deblurring, and noisy population modeling\ndemonstrate the algorithm's versatility and effectiveness. Future work will\nexplore extending RGDBEK to tensor systems, optimizing parallel parameter\nselection, and reducing communication overhead to further enhance efficiency\nand applicability.", "published": "2025-09-23 17:27:29", "link": "http://arxiv.org/abs/2509.19267v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Reconstruction of a potential parameter in time-fractional diffusion problems via a Kohn--Vogelius type functional: Theoretical aspects", "abstract": "Of concern is the problem of reconstructing a space-dependent potential from\nboundary observations in the Caputo time-fractional diffusion equation,\nutilizing a stable and robust recovery method. We develop an algorithm to\nminimize the Kohn-Vogelius (KV) cost function, which measures the difference\nbetween the solutions of two excitations. The inverse potential problem is\nrecast into an optimization problem, where the objective is to minimize a\nKohn-Vogelius-type functional within a set of admissible potentials. We\nestablish the well-posedness of this optimization problem by proving the\nexistence and uniqueness of a minimizer and demonstrating its stability with\nrespect to perturbations in the boundary data. Furthermore, we analyze the\nFr\\'echet differentiability of the KV functional and prove the Lipschitz\ncontinuity of its gradient. These theoretical results enable the development of\na convergent conjugate gradient algorithm for numerical reconstruction. The\neffectiveness and robustness of the proposed method are confirmed through\nseveral numerical examples in both one and two dimensions, including cases with\nnoisy data.", "published": "2025-09-23 17:18:59", "link": "http://arxiv.org/abs/2509.19260v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A noise-robust Monte Carlo method for electric field calculations in EMC3", "abstract": "One of the main codes to analyze and optimize stellarator configurations is\nthe EMC3 code, which implements a state-of-the-art 3D Monte Carlo plasma edge\ntransport code. However, so far, a self-consistent treatment of the E x B drift\nis absent. This plasma drift is known to significantly impact the particle and\nheat distribution in the plasma edge. It is desirable to incorporate this drift\ninto EMC3 to improve the predictive capabilities of the code. The calculation\nof the E x B drift requires the approximation of the electric field E, which is\nproportional to the gradient of the electric potential $ \\varphi $. In previous\nwork, the gradient was calculated with a least squares method based on a finite\ndifference approximation of the electric potential. However, due to the\nstochastic nature of EMC3, the output plasma fields computed by the code are\ninherently noisy. The finite difference method further amplifies the noise,\nwith the amplification growing as the grid size decreases. We continue from,\nwhich introduced a new noise-robust method for 1D derivatives. We extend the\nnoise-robust method to 2D and apply it to the electric potential. We show that\na PDE can be derived that describes the evolution of the electric field in case\nof a uniform diffusion coefficient. This PDE allows us to approximate the\nelectric field directly with a Monte Carlo simulation, thus avoiding the need\nfor a finite difference approximation. We illustrate the accuracy of the method\nand the noise robustness with a test case.", "published": "2025-09-23 15:49:50", "link": "http://arxiv.org/abs/2509.19178v1", "categories": ["math.NA", "cs.NA", "physics.plasm-ph"], "primary_category": "math.NA"}
{"title": "Regularity estimate and sparse approximation of pathwise robust Duncan-Mortensen-Zakai equation", "abstract": "In this paper, we establish an \\textit{a priori} estimate for arbitrary-order\nderivatives of the solution to the pathwise robust Duncan-Mortensen-Zakai (DMZ)\nequation within the framework of weighted Sobolev spaces. The weight function,\nwhich vanishes on the physical boundary, is crucial for the \\textit{a priori}\nestimate, but introduces a loss of regularity near the boundary. Therefore, we\nemploy the Sobolev inequalities and their weighted analogues to sharpen the\nregularity bound, providing improvements in both classical Sobolev spaces and\nH{\\\"o}lder continuity estimates. The refined regularity estimate reinforces the\nplausibility of the quantized tensor train (QTT) method in [S. Li, Z. Wang, S.\nS.-T. Yau, and Z. Zhang, IEEE Trans. Automat. Control, 68 (2023), pp.\n4405--4412] and provides convergence guarantees of the method. To further\nenhance the capacity of the method to solve the nonlinear filtering problem in\na real-time manner, we reduce the complexity of the method under the assumption\nof a functional polyadic state drift $f$ and observation $h$. Finally, we\nperform numerical simulations to reaffirm our theory. For high-dimensional\ncubic sensor problems, our method demonstrates superior efficiency and accuracy\nin comparison to the particle filter (PF) and the extended Kalman filter (EKF).\nBeyond this, for multi-mode problems, while the PF exhibits a lack of precision\ndue to its stochastic nature and the EKF is constrained by its Gaussian\nassumption, the enhanced method provides an accurate reconstruction of the\nmulti-mode conditional density function.", "published": "2025-09-23 14:44:16", "link": "http://arxiv.org/abs/2509.19093v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "3D Blocking for Matrix-free Smoothers in 2D Variable-Viscosity Stokes Equations with Applications to Geodynamics", "abstract": "We present the design, implementation, and evaluation of optimized\nmatrix-free stencil kernels for multigrid smoothing in the incompressible\nStokes equations with variable viscosity, motivated by geophysical flow\nproblems. We investigate five smoother variants derived from different\noptimisation strategies: Red-Black Gauss-Seidel, Jacobi, fused Jacobi, blocked\nfused Jacobi, and a novel Jacobi smoother with RAS-type temporal blocking, a\nstrategy that applies local iterations on overlapping tiles to improve cache\nreuse. To ensure correctness, we introduce an energy-based residual norm that\nbalances velocity and pressure contributions, and validate all implementations\nusing a high-contrast sinker benchmark representative of realistic geodynamic\nnumerical models. Our performance study on NVIDIA GH200 Grace Hopper nodes of\nthe ALPS supercomputer demonstrates that all smoothers scale well within a\nsingle NUMA domain, but the RAS-Jacobi smoother consistently achieves the best\nperformance at higher core counts. It sustains over 90% weak-scaling efficiency\nup to 64 cores and delivers up to a threefold speedup compared to the C++\nJacobi baseline, owing to improved cache reuse and reduced memory traffic.\nThese results show that temporal blocking, already employed in\ndistributed-memory solvers to reduce communication, can also provide\nsubstantial benefits at the socket and NUMA level. This work highlights the\nimportance of cache-aware stencil design for harnessing modern heterogeneous\narchitectures and lays the groundwork for extending RAS-type temporal blocking\nstrategies to three-dimensional problems and GPU accelerators.", "published": "2025-09-23 14:25:13", "link": "http://arxiv.org/abs/2509.19061v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "65F08, 65N55, 65N22, 76M20", "G.1.8; F.2.1; D.1.3; C.1.4"], "primary_category": "physics.comp-ph"}
{"title": "A Divergence-free Preserving Mixed Finite Element Method for Thermally Driven Active Fluid Model", "abstract": "In this report, we propose a divergence-free preserving mixed finite element\nmethod (FEM) for the system of nonlinear fourth-order thermally driven active\nfluid equations. By introducing two auxiliary variables, we lower the\ncomplexity of the model and enhance the robustness of the algorithm. The\nauxiliary variable $w = \\Delta u$ is used to convert the original fourth-order\nsystem to an equivalent system of second-order equations, thereby easing the\nregularity constraints imposed on standard $H^2$-conforming finite element\nspace. The second variable $\\eta$, analogous to the pressure, helps the scheme\npreserve the divergence-free condition arising from the model. The two-step\nDahlquist-Liniger-Nevanlinna (DLN) time integrator, unconditionally non-linear\nstable and second-order accurate under non-uniform time grids, is combined with\nthe mixed FEM for fully discrete approximation. Due to the fine properties of\nthe DLN scheme, we prove the boundedness of model energy and the associated\nerror estimates under suitable regularity assumptions and mild time\nrestrictions. Additionally, an adaptive time-stepping strategy based on a\nminimum-dissipation criterion is to balance computational costs and time\nefficiency. Several numerical experiments validate the theoretical findings and\ndemonstrate the method's effectiveness and accuracy in simulating complex\nactive fluid dynamics.", "published": "2025-09-23 14:17:45", "link": "http://arxiv.org/abs/2509.19053v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Novel Adaptive Schemes for Hyperbolic Conservation Laws", "abstract": "We introduce new adaptive schemes for the one- and two-dimensional hyperbolic\nsystems of conservation laws. Our schemes are based on an adaption strategy\nrecently introduced in [{\\sc S. Chu, A. Kurganov, and I. Menshov}, Appl. Numer.\nMath., 209 (2025)]. As there, we use a smoothness indicator (SI) to\nautomatically detect ``rough'' parts of the solution and employ in those areas\nthe second-order finite-volume low-dissipation central-upwind scheme with an\novercompressive limiter, which helps to sharply resolve nonlinear shock waves\nand linearly degenerate contact discontinuities. In smooth parts, we replace\nthe limited second-order scheme with a quasi-linear fifth-order (in space and\nthird-order in time) finite-difference scheme, recently proposed in [{\\sc V. A.\nKolotilov, V. V. Ostapenko, and N. A. Khandeeva}, Comput. Math. Math. Phys., 65\n(2025)]. However, direct application of this scheme may generate spurious\noscillations near ``rough'' parts, while excessive use of the overcompressive\nlimiter may cause staircase-like nonphysical structures in smooth areas. To\naddress these issues, we employ the same SI to distinguish contact\ndiscontinuities, treated with the overcompressive limiter, from other ``rough''\nregions, where we switch to the dissipative Minmod2 limiter. Advantage of the\nresulting adaptive schemes are clearly demonstrated on a number of challenging\nnumerical examples.", "published": "2025-09-23 12:30:33", "link": "http://arxiv.org/abs/2509.18908v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Optimality of quasi-Monte Carlo methods and suboptimality of the sparse-grid Gauss--Hermite rule in Gaussian Sobolev spaces", "abstract": "Optimality of several quasi-Monte Carlo methods and suboptimality of the\nsparse-grid quadrature based on the univariate Gauss--Hermite rule is proved in\nthe Sobolev spaces of mixed dominating smoothness of order $\\alpha$, where the\noptimality is in the sense of worst-case convergence rate. For sparse-grid\nGauss--Hermite quadrature, lower and upper bounds are established, with rates\ncoinciding up to a logarithmic factor. The dominant rate is found to be only\n$N^{-\\alpha/2}$ with $N$ function evaluations, although the optimal rate is\nknown to be $N^{-\\alpha}(\\ln N)^{(d-1)/2}$. The lower bound is obtained by\nexploiting the structure of the Gauss--Hermite nodes and is independent of the\nquadrature weights; consequently, no modification of the weights can improve\nthe rate $N^{-\\alpha/2}$. In contrast, several quasi-Monte Carlo methods with a\nchange of variables are shown to achieve the optimal rate, some up to, and one\nincluding, the logarithmic factor.", "published": "2025-09-23 06:52:34", "link": "http://arxiv.org/abs/2509.18712v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Connecting Quantum Computing with Classical Stochastic Simulation", "abstract": "This tutorial paper introduces quantum approaches to Monte Carlo computation\nwith applications in computational finance. We outline the basics of quantum\ncomputing using Grover's algorithm for unstructured search to build intuition.\nWe then move slowly to amplitude estimation problems and applications to\ncounting and Monte Carlo integration, again using Grover-type iterations. A\nhands-on Python/Qiskit implementation illustrates these concepts applied to\nfinance. The paper concludes with a discussion on current challenges in scaling\nquantum simulation techniques.", "published": "2025-09-23 04:02:59", "link": "http://arxiv.org/abs/2509.18614v1", "categories": ["quant-ph", "cs.NA", "math.NA", "q-fin.CP", "stat.CO"], "primary_category": "quant-ph"}
{"title": "Skew Gradient Embedding for Thermodynamically Consistent Systems", "abstract": "We propose a novel Skew Gradient Embedding (SGE) framework for systematically\nreformulating thermodynamically consistent partial differential equation (PDE)\nmodels-capturing both reversible and irreversible processes-as generalized\ngradient flows. These models include a wide spectrum of models in classical\nelectrodynamics, fluid mechanics, quantum mechanics, rheology of complex\nfluids, solid mechanics, and statistical physics. Exploiting the intrinsic\nstructure of generalized gradient flow models, especially, the skew symmetric\ncomponent expressed by the exterior 2-form, we develop a unified stabilization\nstrategy for constructing numerical schemes that either preserve the energy\ndissipation rate or ensure discrete energy stability. This stabilization\nstrategy enables the design of both first- and second-order schemes,\nhighlighting the flexibility and generality of the SGE approach in algorithm\ndevelopment. A key strength of SGE is its flexible treatment of skew-gradient\n(zero-energy-contribution) terms arising from reversible dynamics either\nimplicitly or explicitly. While treated explicitly, it often leads to a natural\ndecoupling of the governing equations in multiphysics systems, thereby\nimproving computational efficiency without compromising stability or accuracy.\nNumerical experiments confirm the robustness, accuracy, and performance\nadvantages of the proposed schemes.", "published": "2025-09-23 03:45:12", "link": "http://arxiv.org/abs/2509.18601v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A new cross approximation for Tucker tensors and its application in Tucker-Anderson Acceleration", "abstract": "This paper proposes two new algorithms related to the Tucker tensor format.\nThe first method is a new cross approximation for Tucker tensors, which we call\nCross$^2$-DEIM. Cross$^2$-DEIM is an iterative method that uses a fiber\nsampling strategy, sampling $O(r)$ fibers in each mode, where $r$ denotes the\ntarget rank. The fibers are selected based on the discrete empirical\ninterpolation method (DEIM). Cross$^2$-DEIM resemblances the Fiber Sampling\nTucker Decomposition (FSTD)2 approximation, and has favorable computational\nscaling compared to existing methods in the literature. We demonstrate good\nperformance of Cross$^2$-DEIM in terms of iteration count and intermediate\nmemory. First we design a fast direct Poisson solver based on Cross$^2$-DEIM\nand the fast Fourier transform. This solver can be used as a stand alone or as\na preconditioner for low-rank solvers for elliptic problems.\n  The second method is a low-rank solver for nonlinear tensor equation in\nTucker format by Anderson acceleration (AA), which we call Tucker-AA. Tucker-AA\nis an extension of low-rank AA (lrAA) proposed in our prior work for low-rank\nsolution to nonlinear matrix equation. We apply Cross$^2$-DEIM with warm-start\nin Tucker-AA to deal with the nonlinearity in the equation. We apply low-rank\noperations in AA, and by an appropriate rank truncation strategy, we are able\nto control the intermediate rank growth. We demonstrated the performance for\nTucker-AA for approximate solutions nonlinear PDEs in 3D.", "published": "2025-09-23 02:27:33", "link": "http://arxiv.org/abs/2509.18554v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Sharp Large Deviations and Gibbs Conditioning for Threshold Models in Portfolio Credit Risk", "abstract": "We obtain sharp large deviation estimates for exceedance probabilities in\ndependent triangular array threshold models with a diverging number of latent\nfactors. The prefactors quantify how latent-factor dependence and tail geometry\nenter at leading order, yielding three regimes: Gaussian or exponential-power\ntails produce polylogarithmic refinements of the Bahadur-Rao $n^{-1/2}$ law;\nregularly varying tails yield index-driven polynomial scaling; and\nbounded-support (endpoint) cases lead to an $n^{-3/2}$ prefactor. We derive\nthese results through Laplace-Olver asymptotics for exponential integrals and\nconditional Bahadur-Rao estimates for the triangular arrays. Using these\nestimates, we establish a Gibbs conditioning principle in total variation:\nconditioned on a large exceedance event, the default indicators become\nasymptotically i.i.d., and the loss-given-default distribution is exponentially\ntilted (with the boundary case handled by an endpoint analysis). As\nillustrations, we obtain second-order approximations for Value-at-Risk and\nExpected Shortfall, clarifying when portfolios operate in the genuine\nlarge-deviation regime. The results provide a transferable set of\ntechniques-localization, curvature, and tilt identification-for sharp\nrare-event analysis in dependent threshold systems.", "published": "2025-09-23 15:30:09", "link": "http://arxiv.org/abs/2509.19151v1", "categories": ["math.PR", "math.ST", "q-fin.MF", "q-fin.PM", "q-fin.RM", "stat.TH", "60F10, 60G70, 62P05, 91G70"], "primary_category": "math.PR"}
{"title": "Fair Volatility: A Framework for Reconceptualizing Financial Risk", "abstract": "Volatility is the canonical measure of financial risk, a role largely\ninherited from Modern Portfolio Theory. Yet, its universality rests on\nrestrictive efficiency assumptions that render volatility, at best, an\nincomplete proxy for true risk. This paper identifies three fundamental\ninconsistencies: (i) volatility is path-independent and blind to temporal\ndependence and non-stationarity; (ii) its relevance collapses in\nderivative-intensive strategies, where volatility often represents opportunity\nrather than risk; and (iii) it lacks an absolute benchmark, providing no\nguidance on what level of volatility is economically ``fair'' in efficient\nmarkets. To address these limitations, we propose a new paradigm that\nreconceptualizes risk in terms of predictability rather than variability.\nBuilding on a general class of stochastic processes, we derive an analytical\nlink between volatility and the Hurst-Holder exponent within the\nMultifractional Process with Random Exponent (MPRE) framework. This\nrelationship yields a formal definition of ``fair volatility'', namely the\nvolatility implied under market efficiency, where prices follow semi-martingale\ndynamics. Extensive empirical analysis on global equity indices supports this\nframework, showing that deviations from fair volatility provide a tractable\nmeasure of market inefficiency, distinguishing between momentum-driven and\nmean-reverting regimes. Our results advance both the theoretical foundations\nand empirical assessment of financial risk, offering a definition of volatility\nthat is efficiency-consistent and economically interpretable.", "published": "2025-09-23 09:20:26", "link": "http://arxiv.org/abs/2509.18837v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Filtering amplitude dependence of correlation dynamics in complex systems: application to the cryptocurrency market", "abstract": "Based on the cryptocurrency market dynamics, this study presents a general\nmethodology for analyzing evolving correlation structures in complex systems\nusing the $q$-dependent detrended cross-correlation coefficient \\rho(q,s). By\nextending traditional metrics, this approach captures correlations at varying\nfluctuation amplitudes and time scales. The method employs $q$-dependent\nminimum spanning trees ($q$MSTs) to visualize evolving network structures.\nUsing minute-by-minute exchange rate data for 140 cryptocurrencies on Binance\n(Jan 2021-Oct 2024), a rolling window analysis reveals significant shifts in\n$q$MSTs, notably around April 2022 during the Terra/Luna crash. Initially\ncentralized around Bitcoin (BTC), the network later decentralized, with\nEthereum (ETH) and others gaining prominence. Spectral analysis confirms BTC's\ndeclining dominance and increased diversification among assets. A key finding\nis that medium-scale fluctuations exhibit stronger correlations than\nlarge-scale ones, with $q$MSTs based on the latter being more decentralized.\nProperly exploiting such facts may offer the possibility of a more flexible\noptimal portfolio construction. Distance metrics highlight that major\ndisruptions amplify correlation differences, leading to fully decentralized\nstructures during crashes. These results demonstrate $q$MSTs' effectiveness in\nuncovering fluctuation-dependent correlations, with potential applications\nbeyond finance, including biology, social and other complex systems.", "published": "2025-09-23 09:10:30", "link": "http://arxiv.org/abs/2509.18820v1", "categories": ["q-fin.ST", "cs.CE", "econ.EM", "physics.data-an", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "Clapping: Removing Per-sample Storage for Pipeline Parallel Distributed Optimization with Communication Compression", "abstract": "Pipeline-parallel distributed optimization is essential for large-scale\nmachine learning but is challenged by significant communication overhead from\ntransmitting high-dimensional activations and gradients between workers.\nExisting approaches often depend on impractical unbiased gradient assumptions\nor incur sample-size memory overhead. This paper introduces Clapping, a\nCommunication compression algorithm with LAzy samPling for Pipeline-parallel\nlearnING. Clapping adopts a lazy sampling strategy that reuses data samples\nacross steps, breaking sample-wise memory barrier and supporting convergence in\nfew-epoch or online training regimes. Clapping comprises two variants including\nClapping-FC and Clapping-FU, both of which achieve convergence without unbiased\ngradient assumption, effectively addressing compression error propagation in\nmulti-worker settings. Numerical experiments validate the performance of\nClapping across different learning tasks.", "published": "2025-09-23 14:02:43", "link": "http://arxiv.org/abs/2509.19029v1", "categories": ["math.OC", "stat.ML"], "primary_category": "math.OC"}
{"title": "Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning", "abstract": "In the field of machine learning, hyperbolic space demonstrates superior\nrepresentation capabilities for hierarchical data compared to conventional\nEuclidean space. This work focuses on the Coarse-To-Fine Few-Shot\nClass-Incremental Learning (C2FSCIL) task. Our study follows the Knowe\napproach, which contrastively learns coarse class labels and subsequently\nnormalizes and freezes the classifier weights of learned fine classes in the\nembedding space. To better interpret the \"coarse-to-fine\" paradigm, we propose\nembedding the feature extractor into hyperbolic space. Specifically, we employ\nthe Poincar\\'e ball model of hyperbolic space, enabling the feature extractor\nto transform input images into feature vectors within the Poincar\\'e ball\ninstead of Euclidean space. We further introduce hyperbolic contrastive loss\nand hyperbolic fully-connected layers to facilitate model optimization and\nclassification in hyperbolic space. Additionally, to enhance performance under\nfew-shot conditions, we implement maximum entropy distribution in hyperbolic\nspace to estimate the probability distribution of fine-class feature vectors.\nThis allows generation of augmented features from the distribution to mitigate\noverfitting during training with limited samples. Experiments on C2FSCIL\nbenchmarks show that our method effectively improves both coarse and fine class\naccuracies.", "published": "2025-09-23 01:12:21", "link": "http://arxiv.org/abs/2509.18504v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Enhanced Survival Trees", "abstract": "We introduce a new survival tree method for censored failure time data that\nincorporates three key advancements over traditional approaches. First, we\ndevelop a more computationally efficient splitting procedure that effectively\nmitigates the end-cut preference problem, and we propose an intersected\nvalidation strategy to reduce the variable selection bias inherent in greedy\nsearches. Second, we present a novel framework for determining tree structures\nthrough fused regularization. In combination with conventional pruning, this\napproach enables the merging of non-adjacent terminal nodes, producing more\nparsimonious and interpretable models. Third, we address inference by\nconstructing valid confidence intervals for median survival times within the\nsubgroups identified by the final tree. To achieve this, we apply\nbootstrap-based bias correction to standard errors. The proposed method is\nassessed through extensive simulation studies and illustrated with data from\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) study.", "published": "2025-09-23 00:54:45", "link": "http://arxiv.org/abs/2509.18494v1", "categories": ["stat.ME", "stat.ML", "62N01, 62G05"], "primary_category": "stat.ME"}
{"title": "Estimating Heterogeneous Causal Effect on Networks via Orthogonal Learning", "abstract": "Estimating causal effects on networks is important for both scientific\nresearch and practical applications. Unlike traditional settings that assume\nthe Stable Unit Treatment Value Assumption (SUTVA), interference allows an\nintervention/treatment on one unit to affect the outcomes of others.\nUnderstanding both direct and spillover effects is critical in fields such as\nepidemiology, political science, and economics. Causal inference on networks\nfaces two main challenges. First, causal effects are typically heterogeneous,\nvarying with unit features and local network structure. Second, connected units\noften exhibit dependence due to network homophily, creating confounding between\nstructural correlations and causal effects. In this paper, we propose a\ntwo-stage method to estimate heterogeneous direct and spillover effects on\nnetworks. The first stage uses graph neural networks to estimate nuisance\ncomponents that depend on the complex network topology. In the second stage, we\nadjust for network confounding using these estimates and infer causal effects\nthrough a novel attention-based interference model. Our approach balances\nexpressiveness and interpretability, enabling downstream tasks such as\nidentifying influential neighborhoods and recovering the sign of spillover\neffects. We integrate the two stages using Neyman orthogonalization and\ncross-fitting, which ensures that errors from nuisance estimation contribute\nonly at higher order. As a result, our causal effect estimates are robust to\nbias and misspecification in modeling causal effects under network\ndependencies.", "published": "2025-09-23 00:41:04", "link": "http://arxiv.org/abs/2509.18484v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MUSHRA-1S: A scalable and sensitive test approach for evaluating top-tier speech processing systems", "abstract": "Evaluating state-of-the-art speech systems necessitates scalable and\nsensitive evaluation methods to detect subtle but unacceptable artifacts.\nStandard MUSHRA is sensitive but lacks scalability, while ACR scales well but\nloses sensitivity and saturates at a high quality. To address this, we\nintroduce MUSHRA 1S, a single-stimulus variant that rates one system at a time\nagainst a fixed anchor and reference. Across our experiments, MUSHRA 1S matches\nstandard MUSHRA more closely than ACR, including in the high-quality regime,\nwhere ACR saturates. MUSHRA 1S also effectively identifies specific deviations\nand reduces range-equalizing biases by fixing context. Overall, MUSHRA 1S\ncombines MUSHRA level sensitivity with ACR like scalability, making it a robust\nand scalable solution for benchmarking top-tier speech processing systems.", "published": "2025-09-23 16:42:31", "link": "http://arxiv.org/abs/2509.19219v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Test-Time Performance of RVQ-based Neural Codecs", "abstract": "The residual vector quantization (RVQ) technique plays a central role in\nrecent advances in neural audio codecs. These models effectively synthesize\nhigh-fidelity audio from a limited number of codes due to the hierarchical\nstructure among quantization levels. In this paper, we propose an encoding\nalgorithm to further enhance the synthesis quality of RVQ-based neural codecs\nat test-time. Firstly, we point out the suboptimal nature of quantized vectors\ngenerated by conventional methods. We demonstrate that quantization error can\nbe mitigated by selecting a different set of codes. Subsequently, we present\nour encoding algorithm, designed to identify a set of discrete codes that\nachieve a lower quantization error. We then apply the proposed method to\npre-trained models and evaluate its efficacy using diverse metrics. Our\nexperimental findings validate that our method not only reduces quantization\nerrors, but also improves synthesis quality.", "published": "2025-09-23 16:02:27", "link": "http://arxiv.org/abs/2509.19186v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On-device Internet of Sounds Sonification with Wavetable Synthesis Techniques for Soil Moisture Monitoring in Water Scarcity Contexts", "abstract": "Sonification, the mapping of data to sound to communicate information about\nthe original data source, is becoming a viable strategy for the sonic\nrepresentation and communication of information derived from the complex flows\nof data exchanged across Internet of Sounds (IoS) networks. This paper presents\nan IoS sonification implementation for monitoring soil moisture levels within\nthe broader context of the globally increasing water scarcity. While previous\nwork has focused on sonifications operating on the applications and services\nlevel of the IoS network infrastructure, this paper explores device-level\nsonification using wavetable synthesis techniques to map sensor data to\nacoustic parameters. An approach to on-device wavetable sonification is\nformalized, and a prototype implementation is presented and explored before the\napproach is contextualised with regard to the soil moisture monitoring tasks.", "published": "2025-09-23 14:47:41", "link": "http://arxiv.org/abs/2509.19097v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Enhancing Noise Robustness for Neural Speech Codecs through Resource-Efficient Progressive Quantization Perturbation Simulation", "abstract": "Noise robustness remains a critical challenge for deploying neural speech\ncodecs in real-world acoustic scenarios where background noise is often\ninevitable. A key observation we make is that even slight input noise\nperturbations can cause unintended shifts in quantized codewords, thereby\ndegrading the quality of reconstructed speech. Motivated by this finding, we\npropose a novel and resource-efficient training strategy to enhance the noise\nrobustness of speech codecs by simulating such perturbations directly at the\nquantization level. Our approach introduces two core mechanisms: (1) a\ndistance-weighted probabilistic top-K sampling strategy that replaces the\nconventional deterministic nearest-neighbor selection in residual vector\nquantization (RVQ); and (2) a progressive training scheme that introduces\nperturbations from the last to the first quantizer in a controlled manner.\nCrucially, our method is trained exclusively on clean speech, eliminating the\nneed for any paired noisy-clean data. Experiments on two advanced neural speech\ncodecs, Encodec and WavTokenizer, demonstrate that the proposed strategy\nsubstantially improves robustness under noisy conditions-for example, boosting\nUTMOS from 3.475 to 3.586 at 15 dB SNR on Encodec-while also enhancing coding\nquality for clean speech.", "published": "2025-09-23 14:00:22", "link": "http://arxiv.org/abs/2509.19025v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "HD-PPT: Hierarchical Decoding of Content- and Prompt-Preference Tokens for Instruction-based TTS", "abstract": "Large Language Model (LLM)-based Text-to-Speech (TTS) models have already\nreached a high degree of naturalness. However, the precision control of TTS\ninference is still challenging. Although instruction-based Text-to-Speech\n(Instruct-TTS) models are proposed, these models still lack fine-grained\ncontrol due to the modality gap between single-level text instructions and\nmultilevel speech tokens. To address this limitation, we propose HD-PPT, a\nframework that transforms speech synthesis into a structured, hierarchical\ntask. To enable fine-grained control, we introduce a novel speech codec to\nextract distinct prompt-preference and content-preference tokens from the\ncomplex speech tokens, supervised by automatic speech recognition (ASR) and\ncross-lingual audio-text pre-training (CLAP) objectives. To bridge the modality\ngap of these tokens, we propose a hierarchical decoding strategy, where the LLM\ngenerates tokens in a structured order: first semantic, then fine-grained\nstyle, and finally complete acoustic representation. Extensive experiments\ndemonstrate that this hierarchical paradigm significantly improves instruction\nadherence and achieves state-of-the-art naturalness, validating our approach\nfor precise and controllable speech synthesis. Audio samples are available at\nhttps://xxh333.github.io/.", "published": "2025-09-23 13:45:56", "link": "http://arxiv.org/abs/2509.19001v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Direct Preference Optimization for Speech Autoregressive Diffusion Models", "abstract": "Autoregressive diffusion models (ARDMs) have recently been applied to speech\ngeneration, achieving state-of-the-art (SOTA) performance in zero-shot\ntext-to-speech. By autoregressively generating continuous speech tokens with\nnext-token diffusion, these models offer a promising alternative to next-token\nprediction, avoiding the technical complexities associated with discrete speech\ntokenization. As a relatively new paradigm, research on reinforcement learning\n(RL)-based fine-tuning of speech ARDMs remains limited. In this paper, we\npropose Autoregressive Diffusion-Direct Preference Optimization (ARDM-DPO) to\nadvance this research. By fine-tuning the recently proposed zero-shot\ntext-to-speech model DiTAR with DPO, we achieve significant improvements in\nterms of speech expressiveness and robustness for long texts.", "published": "2025-09-23 12:47:53", "link": "http://arxiv.org/abs/2509.18928v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Generalizability of Predictive and Generative Speech Enhancement Models to Pathological Speakers", "abstract": "State of the art speech enhancement (SE) models achieve strong performance on\nneurotypical speech, but their effectiveness is substantially reduced for\npathological speech. In this paper, we investigate strategies to address this\ngap for both predictive and generative SE models, including i) training models\nfrom scratch using pathological data, ii) finetuning models pretrained on\nneurotypical speech with additional data from pathological speakers, and iii)\nspeaker specific personalization using only data from the individual\npathological test speaker. Our results show that, despite the limited size of\npathological speech datasets, SE models can be successfully trained or\nfinetuned on such data. Finetuning models with data from several pathological\nspeakers yields the largest performance improvements, while speaker specific\npersonalization is less effective, likely due to the small amount of data\navailable per speaker. These findings highlight the challenges and potential\nstrategies for improving SE performance for pathological speakers.", "published": "2025-09-23 10:57:20", "link": "http://arxiv.org/abs/2509.18890v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Influence of Clean Speech Characteristics on Speech Enhancement Performance", "abstract": "Speech enhancement (SE) performance is known to depend on noise\ncharacteristics and signal to noise ratio (SNR), yet intrinsic properties of\nthe clean speech signal itself remain an underexplored factor. In this work, we\nsystematically analyze how clean speech characteristics influence enhancement\ndifficulty across multiple state of the art SE models, languages, and noise\nconditions. We extract a set of pitch, formant, loudness, and spectral flux\nfeatures from clean speech and compute correlations with objective SE metrics,\nincluding frequency weighted segmental SNR and PESQ. Our results show that\nformant amplitudes are consistently predictive of SE performance, with higher\nand more stable formants leading to larger enhancement gains. We further\ndemonstrate that performance varies substantially even within a single\nspeaker's utterances, highlighting the importance of intraspeaker acoustic\nvariability. These findings provide new insights into SE challenges, suggesting\nthat intrinsic speech characteristics should be considered when designing\ndatasets, evaluation protocols, and enhancement models.", "published": "2025-09-23 10:33:32", "link": "http://arxiv.org/abs/2509.18885v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Towards Evaluating Generative Audio: Insights from Neural Audio Codec Embedding Distances", "abstract": "Neural audio codecs (NACs) achieve low-bitrate compression by learning\ncompact audio representations, which can also serve as features for perceptual\nquality evaluation. We introduce DACe, an enhanced, higher-fidelity version of\nthe Descript Audio Codec (DAC), trained on diverse real and synthetic tonal\ndata with balanced sampling. We systematically compare Fr\\'echet Audio Distance\n(FAD) and Maximum Mean Discrepancy (MMD) on MUSHRA tests across speech, music,\nand mixed content. FAD consistently outperforms MMD, and embeddings from\nhigher-fidelity NACs (such as DACe) show stronger correlations with human\njudgments. While CLAP LAION Music (CLAP-M) and OpenL3 Mel128 (OpenL3-128M)\nembeddings achieve higher correlations, NAC embeddings provide a practical\nzero-shot approach to audio quality assessment, requiring only unencoded audio\nfor training. These results demonstrate the dual utility of NACs for\ncompression and perceptually informed audio evaluation.", "published": "2025-09-23 09:11:50", "link": "http://arxiv.org/abs/2509.18823v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Rethinking the joint estimation of magnitude and phase for time-frequency domain neural vocoders", "abstract": "Time-frequency (T-F) domain-based neural vocoders have shown promising\nresults in synthesizing high-fidelity audio. Nevertheless, it remains unclear\non the mechanism of effectively predicting magnitude and phase targets jointly.\nIn this paper, we start from two representative T-F domain vocoders, namely\nVocos and APNet2, which belong to the single-stream and dual-stream modes for\nmagnitude and phase estimation, respectively. When evaluating their performance\non a large-scale dataset, we accidentally observe severe performance collapse\nof APNet2. To stabilize its performance, in this paper, we introduce three\nsimple yet effective strategies, each targeting the topological space, the\nsource space, and the output space, respectively. Specifically, we modify the\narchitectural topology for better information exchange in the topological\nspace, introduce prior knowledge to facilitate the generation process in the\nsource space, and optimize the backpropagation process for parameter updates\nwith an improved output format in the output space. Experimental results\ndemonstrate that our proposed method effectively facilitates the joint\nestimation of magnitude and phase in APNet2, thus bridging the performance\ndisparities between the single-stream and dual-stream vocoders.", "published": "2025-09-23 08:57:13", "link": "http://arxiv.org/abs/2509.18806v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Group Relative Policy Optimization for Text-to-Speech with Large Language Models", "abstract": "This paper proposes a GRPO-based approach to enhance the performance of large\nlanguage model (LLM)-based text-to-speech (TTS) models by deriving rewards from\nan off-the-shelf automatic speech recognition (ASR) model. Compared to previous\nreinforcement learning methods for LLM-based TTS, our method requires no\ndedicated model for reward computation or training. Moreover, we design a\ncomposite reward function that combines character error rate (CER) with\nnegative log-likelihood (NLL) obtained from the ASR model, providing more\ninformative and accurate reward signals. We apply GRPO fine-tuning to\npre-trained LLM-based TTS models and evaluate their zero-shot TTS performance.\nExperimental results show that the proposed method substantially improves both\nthe intelligibility and naturalness of synthesized speech. Ablation studies and\nfurther analyses confirm the effectiveness of integrating the two reward\ncomponents.", "published": "2025-09-23 08:43:32", "link": "http://arxiv.org/abs/2509.18798v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Enhancing Automatic Chord Recognition through LLM Chain-of-Thought Reasoning", "abstract": "Music Information Retrieval (MIR) encompasses a broad range of computational\ntechniques for analyzing and understanding musical content, with recent deep\nlearning advances driving substantial improvements. Building upon these\nadvances, this paper explores how large language models (LLMs) can serve as an\nintegrative bridge to connect and integrate information from multiple MIR\ntools, with a focus on enhancing automatic chord recognition performance. We\npresent a novel approach that positions text-based LLMs as intelligent\ncoordinators that process and integrate outputs from diverse state-of-the-art\nMIR tools-including music source separation, key detection, chord recognition,\nand beat tracking. Our method converts audio-derived musical information into\ntextual representations, enabling LLMs to perform reasoning and correction\nspecifically for chord recognition tasks. We design a 5-stage chain-of-thought\nframework that allows GPT-4o to systematically analyze, compare, and refine\nchord recognition results by leveraging music-theoretical knowledge to\nintegrate information across different MIR components. Experimental evaluation\non three datasets demonstrates consistent improvements across multiple\nevaluation metrics, with overall accuracy gains of 1-2.77% on the MIREX metric.\nOur findings demonstrate that LLMs can effectively function as integrative\nbridges in MIR pipelines, opening new directions for multi-tool coordination in\nmusic information retrieval tasks.", "published": "2025-09-23 06:34:13", "link": "http://arxiv.org/abs/2509.18700v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Explore the Reinforcement Learning for the LLM based ASR and TTS system", "abstract": "In recent years, large language models (LLMs) have played an important role\nin automatic speech recognition (ASR) and text-to-speech (TTS) systems. While\nreinforcement learning (RL) has significantly enhanced LLM performance in\ntext-based tasks, its application to ASR and TTS remains underexplored due to\nthe complexity of training audio-based models. In this study, we propose a\nlightweight RL framework tailored for audio-based LLMs that can process audio\ninputs and generate audio outputs. Based on this framework, we evaluate the\neffectiveness of reinforcement learning on both ASR and TTS tasks. For the ASR\ntask, we experiment with different rule-based reward functions within the Group\nRelative Policy Optimization (GRPO) framework and investigate the impact of RL\ndata construction. For the TTS task, we compare GRPO with Differentiable Reward\nOptimization (DiffRO) and further combine the two approaches to achieve\nimproved performance. Our experiments demonstrate that RL can significantly\nenhance the performance of both ASR and TTS systems, even with limited training\ndata and a small number of optimization steps.", "published": "2025-09-23 02:52:54", "link": "http://arxiv.org/abs/2509.18569v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SoundCompass: Navigating Target Sound Extraction With Effective Directional Clue Integration In Complex Acoustic Scenes", "abstract": "Recent advances in target sound extraction (TSE) utilize directional clues\nderived from direction of arrival (DoA), which represent an inherent spatial\nproperty of sound available in any acoustic scene. However, previous DoA-based\nmethods rely on hand-crafted features or discrete encodings, which lose\nfine-grained spatial information and limit adaptability. We propose\nSoundCompass, an effective directional clue integration framework centered on a\nSpectral Pairwise INteraction (SPIN) module that captures cross-channel spatial\ncorrelations in the complex spectrogram domain to preserve full spatial\ninformation in multichannel signals. The input feature expressed in terms of\nspatial correlations is fused with a DoA clue represented as spherical\nharmonics (SH) encoding. The fusion is carried out across overlapping frequency\nsubbands, inheriting the benefits reported in the previous band-split\narchitectures. We also incorporate the iterative refinement strategy,\nchain-of-inference (CoI), in the TSE framework, which recursively fuses DoA\nwith sound event activation estimated from the previous inference stage.\nExperiments demonstrate that SoundCompass, combining SPIN, SH embedding, and\nCoI, robustly extracts target sources across diverse signal classes and spatial\nconfigurations.", "published": "2025-09-23 02:36:39", "link": "http://arxiv.org/abs/2509.18561v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "STFT-AECNN: An Attention-Enhanced CNN for Efficient \u03a6-OTDR Event Recognition in IoT-Enabled Distributed Acoustic Sensing", "abstract": "Phase-sensitive optical time-domain reflectometry ({\\Phi}-OTDR) has emerged\nas a promising sensing technology in Internet of Things (IoT) infrastructures,\nenabling large-scale distributed acoustic sensing (DAS) for smart city\nsurveillance, industrial pipeline monitoring, and critical infrastructure\nprotection. However, accurately recognizing events from massive {\\Phi}-OTDR\ndata streams remains challenging, as existing deep learning methods either\ndisrupt the inherent spatiotemporal structure of signals or incur prohibitive\ncomputational costs, limiting their applicability in resource-constrained IoT\nscenarios. To overcome these challenges, we propose a novel STFT-based\nAttention-Enhanced Convolutional Neural Network (STFT-AECNN), which represents\nmulti-channel time-series data as stacked spectrograms to fully exploit their\nspatiotemporal characteristics while enabling efficient 2D CNN processing. A\nSpatial Efficient Attention Module (SEAM) is further introduced to adaptively\nemphasize the most informative channels, and a joint Cross-Entropy and Triplet\nloss is adopted to enhance the discriminability of the learned feature space.\nExtensive experiments on the public BJTU {\\Phi}-OTDR dataset demonstrate that\nSTFT-AECNN achieves a peak accuracy of 99.94% while maintaining high\ncomputational efficiency. These results highlight its potential for real-time,\nscalable, and robust event recognition in IoT-enabled DAS systems, paving the\nway for reliable and intelligent IoT sensing applications.", "published": "2025-09-23 17:48:40", "link": "http://arxiv.org/abs/2509.19281v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Site-Specific Inference Model for Urban Canyon Channels: From Measurements to Modeling", "abstract": "With the rapid development of intelligent transportation and smart city\napplications, urban canyon has become a critical scenario for the design and\nevaluation of wireless communication systems. Due to its unique environmental\nlayout, the channel characteristics in urban canyon are strongly a street\ngeometry and building distribution, thereby exhibiting significant\nsite-specific channel condition. However, this feature has not been well\ncaptured in existing channel models. In this paper, we propose a site-specific\nchannel inference model based on environmental geometry, the model is\nparameterized using sub-6GHz channel measurements. Multipath components (MPCs)\nare extracted and clustered according to geometric propagation, which are\nexplicitly derived from the influence of canyon width, thereby establishing an\ninterpretable mapping between the physical environment and statistical\ncharacteristics of MPCs. A step-by-step implementation scheme is presented.\nSubsequently, the proposed site-specific channel inference model is validated\nby comparing second-order statistics of channels, derived from the model and\nmeasurements. The results show that the proposed model achieves high accuracy\nand robustness in different urban canyon scenarios.", "published": "2025-09-23 17:40:49", "link": "http://arxiv.org/abs/2509.19275v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Faster-Than-Nyquist Signalling - Theoretical Limits on Capacity and Techniques to Approach Capacity", "abstract": "Faster-Than-Nyquist (FTN) Signalling is a non-orthogonal transmission scheme\nthat violates the Nyquist zero-ISI criterion providing higher throughput and\nbetter spectral efficiency than a Nyquist transmission scheme. In this thesis,\nthe inter symbol interference (ISI) introduced by FTN signalling is studied,\nand conditions on pulse shapes and $\\tau$ (time acceleration factor) are\nderived so that the ISI can be avoided completely. Further, these conditions\nare reinforced by investigating the theoretical limits on the capacities of FTN\nsystems. Finally, the use of power allocation and adaptive loading techniques\nare explored in reducing the effect of ISI and increasing the throughput of\northogonal frequency division multiplexing (OFDM) FTN systems. The\nimplementation of these techniques and simulation results are also\ndemonstrated.", "published": "2025-09-23 17:34:40", "link": "http://arxiv.org/abs/2509.19272v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Low-cost Quasi-planar Array Probe for Photoacoustic Imaging", "abstract": "Photoacoustic imaging (PAI) is a novel hybrid imaging technique that combines\nthe benefits of both optical and acoustic imaging modalities, which provides\nfunctional and molecular optical contrasts of deep tissue. Commonly used\nultrasound transducers for PAI include linear and planar arrays, which can\nprovide two-dimensional (2D) and three-dimensional (3D) image reconstruction,\nrespectively. However, linear arrays cannot provide reconstruction of 3D\nimages, which makes it impossible to locate chromophores in 3D space. Although\nplanar array can provide fast 3D imaging in real time, it usually requires\nthousands of analog-to-digital conversion channels for data acquisition, which\nis costly. To fill the gap between 2D and 3D PAI, we propose a quasi-planar\narray that uses double 16-elements-linear arrays arranged in parallel to\nachieve real-time 3D imaging. We first conducted simulation studies to prove\nthat the quasi-planar probe can perform 3D imaging to localize simple\nchromophores. Then, the agarose phantom experiment demonstrated that the probe\ncan reconstruct 3D imaging of multiple absorbers in different depths. A\npotential application of this device is to provide a low-cost 3D PAI solution\nfor fast tracking of needle tip during needle biopsy, which will be further\nexplored in our future work.", "published": "2025-09-23 17:29:37", "link": "http://arxiv.org/abs/2509.19268v1", "categories": ["physics.med-ph", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "On the Performance of THz Wireless Systems over $\u03b1$-$\\mathcal{F}$ Channels with Beam Misalignment and Mobility", "abstract": "This paper investigates the performance of terahertz~(THz) wireless systems\nover the $\\alpha$-$\\mathcal{F}$ fading channels with beam misalignment and\nmobility. New expressions are derived for the probability density, cumulative\ndistribution, and moment generating functions, as well as higher-order moments\nof the instantaneous signal-to-noise ratio. Building upon the aforementioned\nexpressions, we extract novel formulas for the outage probability, symbol error\nprobability, and average channel capacity. Asymptotic metrics are also deduced,\nwhich provide useful insights. Monte Carlo simulations results are presented to\nsupport the derived analytical framework.", "published": "2025-09-23 16:56:12", "link": "http://arxiv.org/abs/2509.19235v1", "categories": ["eess.SP", "math.ST", "stat.TH"], "primary_category": "eess.SP"}
{"title": "Deep Reinforcement Learning for Dynamic Sensing and Communications", "abstract": "Environmental sensing can significantly enhance mmWave communications by\nassisting beam training, yet its benefits must be balanced against the\nassociated sensing costs. To this end, we propose a unified machine learning\nframework that dynamically determines when to sense and leverages sensory data\nfor beam prediction. Specifically, we formulate a joint sensing and beamforming\nproblem that maximizes the av- erage signal-to-noise ratio under an average\nsensing budget. Lyapunov optimization is employed to enforce the sensing\nconstraint, while a deep Q-Network determines the sensing slots. A pretrained\ndeep neural network then maps the sens- ing data to optimal beams in the\ncodebook. Simulations based on the real-world DeepSense dataset demonstrate\nthat the pro- posed approach substantially reduces sensing overhead while\nmaintaining satisfactory communications performance.", "published": "2025-09-23 15:15:42", "link": "http://arxiv.org/abs/2509.19130v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enabling Drone Detection with SWARM Repeater-Assisted MIMO ISAC", "abstract": "As definitions about new architectural aspects, use cases, and standards for\nintegrated sensing and communication (ISAC) continue to appear, cellular\nsystems based on massive multiple-input multiple-output (MIMO) antenna\ntechnology are also experiencing a parallel evolution through the integration\nof novel network components. This evolution should support emerging ISAC use\ncases and services. In particular, this paper explores a recent vision for\ncost-efficient cellular network densification through the deployment of swarms\nof repeaters. Leveraging their ability to retransmit signals instantaneously,\nwe investigate how these repeaters can enhance radar sensing capabilities for\ndrone detection in a swarm repeater-assisted MIMO ISAC system. Our results\ndemonstrate that, by optimizing the gains of repeaters given a sufficient\nmaximum amplification gain, increasing the number of repeaters can lead to\ngains in sensing performance.", "published": "2025-09-23 15:05:51", "link": "http://arxiv.org/abs/2509.19119v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Data-Free Knowledge Distillation for LiDAR-Aided Beam Tracking in MmWave Systems", "abstract": "Multimodal sensing reduces beam training overhead but is constrained by\nmachine learning complexity and dataset demands. To address this, we propose a\ndata-free (DF) knowledge distillation (KD) framework for efficient LiDAR-aided\nmmWave beam tracking, i.e., predicting the best current and future beams.\nSpecifically, we propose a knowledge inversion framework, where a generator\nsynthesizes LiDAR input data from random noise, guided by a loss function\ndefined on the features and outputs of a pre-trained teacher model. The student\nmodel is then trained using the synthetic data and knowledge distilled from the\nteacher. The generator loss combines three terms, called metadata loss,\nactivation loss, and entropy loss. For student training, in addition to the\nstandard Kullback-Leibler divergence loss, we also consider a mean-squared\nerror (MSE) loss between the teacher and student logits. Simulation results\nshow that the proposed DF-KD (slightly) outperforms the teacher in Top-1 and\nTop-5 accuracies. Moreover, we observe that the metadata loss contributes\nsignificantly to the generator performance, and that the MSE loss for the\nstudent can effectively replace the standard KD loss while requiring fewer\nfine-tuned hyperparameters.", "published": "2025-09-23 14:44:03", "link": "http://arxiv.org/abs/2509.19092v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian Convolutional Neural Networks for Prior Learning in Graph Signal Recovery", "abstract": "Graph signal recovery (GSR) is a fundamental problem in graph signal\nprocessing, where the goal is to reconstruct a complete signal defined over a\ngraph from a subset of noisy or missing observations. A central challenge in\nGSR is that the underlying statistical model of the graph signal is often\nunknown or too complex to specify analytically. To address this, we propose a\nflexible, data-driven framework that learns the signal prior directly from\ntraining samples. We develop a Bayesian convolutional neural network (BCNN)\narchitecture that models the prior distribution of graph signals using\ngraph-aware filters based on Chebyshev polynomials. By interpreting the hidden\nlayers of the CNN as Gibbs distributions and employing Gaussian mixture model\n(GMM) nonlinearities, we obtain a closed-form and expressive prior. This prior\nis integrated into a variational Bayesian (VB) inference framework to estimate\nthe posterior distribution of the signal and noise precision. Extensive\nexperiments on synthetic and real-world graph datasets demonstrate that the\nproposed BCNN-GSR algorithm achieves accurate and robust recovery across a\nvariety of signal distributions. The method generalizes well to complex,\nnon-Gaussian signal models and remains computationally efficient, making it\nsuitable for practical large-scale graph recovery tasks.", "published": "2025-09-23 14:21:03", "link": "http://arxiv.org/abs/2509.19056v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quaternion LMS for Graph Signal Recovery", "abstract": "This letter generalizes the Graph Signal Recovery (GSR) problem in Graph\nSignal Processing (GSP) to the Quaternion domain. It extends the Quaternion\nLeast Mean Square (QLMS) in adaptive filtering literature, and Graph LMS (GLMS)\nalgorithm in GSP literature, to an algorithm called Quaternion GLMS (QGLMS).\nThe basic adaptation formula using Quaternion-based algebra is derived.\nMoreover, mean convergence analysis and mean-square convergence analysis are\nmathematically performed. Hence, a sufficient condition on the step-size\nparameter of QGLMS is suggested. Also, simulation results demonstrate the\neffectiveness of the proposed algorithm in graph signal reconstruction.", "published": "2025-09-23 12:35:23", "link": "http://arxiv.org/abs/2509.18918v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Normal mode parameters estimation by a VLA in single-shooting", "abstract": "This paper proposes an orthogonality-constrained modal search (OCMS) method\nfor estimating modal wavenumbers and modal depth functions using a vertical\nlinear array (VLA). Under the assumption of a known sound speed profile, OCMS\nleverages the orthogonality of distinct modal depth functions to extract both\nthe modal depth functions and their corresponding wavenumbers, even when the\nVLA and a monochromatic sound source remain stationary.The performance of OCMS\nis evaluated through numerical simulations under varying signal-to-noise ratios\n(SNRs), different VLA apertures, varying numbers of VLA elements, VLA tilt and\nsound speed profile (SSP) uncertainty. The results demonstrate that OCMS is\nrobust against noise, VLA aperture variations, and changes in the number of VLA\nelements, meanwhile, the algorithm maintains reliable performance when SSP\nuncertainty < 1 m/s and VLA tilt angle <5{\\deg}. Furthermore, the effectiveness\nof OCMS is validated using SwellEx96 experimental data. The relative error\nbetween the modal wavenumbers derived from experimental data and those computed\nvia Kraken is on the order of $10^{-4}$.", "published": "2025-09-23 09:39:52", "link": "http://arxiv.org/abs/2509.18853v1", "categories": ["eess.SP", "physics.ao-ph"], "primary_category": "eess.SP"}
{"title": "Highly Parallel Singular Value Decomposition for Low-Latency MIMO Processing", "abstract": "Singular value decomposition (SVD) is widely used in wireless systems,\nincluding multiple-input multiple-output (MIMO) processing and dimension\nreduction in distributed MIMO (D-MIMO). However, the iterative nature of\ndecomposition methods results in increased execution time as system size grows,\nposing challenges for real-time and low-latency applications. To address this,\nwe analyze the latency of state-of-art SVD methods, and highlight the\nefficiency of a 4-step highly parallel method based on Gram matrix\ntridiagonalization. Furthermore, we develop a time complexity (processing\nlatency) analysis framework with hardware profiling, allowing scalable and\nrealistic evaluation without full implementation. The numerical results\ndemonstrate the superior time efficiency of the selected parallel method,\nparticularly in massive MIMO scenarios.", "published": "2025-09-23 08:43:38", "link": "http://arxiv.org/abs/2509.18799v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Tractable Approximation of Labeled Multi-Object Posterior Densities", "abstract": "Multi-object estimation in state-space models (SSMs) wherein the system state\nis represented as a finite set has attracted significant interest in recent\nyears. In Bayesian inference, the posterior density captures all information on\nthe system trajectory since it considers the past history of states. In most\nmulti-object SSM applications, closed-form multi-object posteriors are not\navailable for non-standard multi-object models. Thus, functional approximation\nis necessary because these posteriors are very high-dimensional. This work\nprovides a tractable multi-scan Generalized Labeled Multi-Bernoulli (GLMB)\napproximation that matches the trajectory cardinality distribution of the\nlabeled multi-object posterior density. The proposed approximation is also\nproven to minimize the Kullback-Leibler divergence over a special class of\nmulti-scan GLMB model. Additionally, we develop a tractable algorithm for\ncomputing the approximate multi-object posteriors over finite windows.\nNumerical experiments, including simulation results on a multi-object SSM with\nsocial force model and uninformative observations, are presented to validate\nthe applicability of the approximation method.", "published": "2025-09-23 08:16:44", "link": "http://arxiv.org/abs/2509.18780v1", "categories": ["stat.ME", "eess.SP"], "primary_category": "stat.ME"}
{"title": "Detection Capability Comparison Between Intensity Detection and Splitting Detection for Rydberg-Atomic Sensors", "abstract": "Rydberg atomic quantum receivers have been seen as novel radio frequency\nmeasurements and the high sensitivity to a large range of frequencies makes it\nattractive for communications reception. However, their unique physical\ncharacteristics enable two fundamental signal readout schemes: intensity-based\ndetection and splitting-based detection. The former measures the electric\nfields through laser intensity, while the latter utilizes Autler-Townes\nsplitting. In this work, we systematically categorize and model existing signal\nreadout methods, classifying them into these two paradigms. Then, we derive the\nmaximum likelihood estimation procedures and corresponding Cram\\'er-Rao lower\nbounds (CRLB) for each detection modality. Through the analysis of the CRLB, we\npropose strategy for both readout schemes to enhance sensitivity and minimize\nestimation variance: acquiring data in regions with maximal slope magnitudes.\nWhile this approach has been implemented in intensity-based detection (e.g.,\nsuperheterodyne schemes), its application to splitting-based detection remains\nunexplored. Implementation of non-uniform frequency scanning, with preferential\nsampling at regions exhibiting maximum peak slopes combined with our proposed\nmaximum likelihood splitting estimation method, achieves significantly reduced\nestimation variance compared to conventional polynomial fitting. The\ncomparative analysis reveals the optimal detection performance of the two\ndetection schemes. This work also contributes to enhancing the accuracy of\nmicrowave calibration. Numerical results reveal that both fundamental signal\nreadout methods achieve lower estimation variance based on our proposed maximum\nlikelihood estimation approach.", "published": "2025-09-23 07:48:43", "link": "http://arxiv.org/abs/2509.18753v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Integrated Cellular and LEO-based Positioning and Synchronization under User Mobility", "abstract": "This paper investigates the localization, synchronization, and speed\nestimation of a mobile user equipment (UE) leveraging integrated terrestrial\nand non-terrestrial networks (NTNs), in particular low Earth orbit (LEO)\nsatellites. We focus on a minimal setup in which the UE received signal from\nonly one base station (BS) and one LEO satellite. We derive a generic signal\nmodel accounting for mobility, clock and frequency offsets, based on which a\nhierarchy of simplified models are proposed and organized by computational\ncomplexity. Estimation algorithms are developed for each model to facilitate\nefficient and accurate parameter recovery. Rigorous simulations validate the\neffectiveness of the proposed models, demonstrating their suitability across\ndiverse scenarios. The findings highlight how the trade-off between complexity\nand performance can be optimized for varying deployment environments and\napplication requirements, offering valuable insights for 6G positioning and\nsynchronization systems under user mobility.", "published": "2025-09-23 07:21:38", "link": "http://arxiv.org/abs/2509.18727v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems", "abstract": "This paper introduces a secure affine frequency division multiplexing\n(SE-AFDM) for wireless communication systems to enhance communication security.\nBesides configuring the parameter c1 to obtain communication reliability under\ndoubly selective channels, we also utilize the time-varying parameter c2 to\nimprove the security of the communications system. The derived input-output\nrelation shows that the legitimate receiver can eliminate the nonlinear impact\nintroduced by the time-varying c2 without losing the bit error rate (BER)\nperformance. Moreover, it is theoretically proved that the eavesdropper cannot\nseparate the time-varying c2 and random information symbols, such that the BER\nperformance of the eavesdropper is severely deteriorated. Meanwhile, the\nanalysis of the effective signal-to-interference-plus-noise ratio (SINR) of the\neavesdropper illustrates that the SINR decreases as the value range of c2\nexpands. Numerical results verify that the proposed SE-AFDM waveform has\nsignificant security while maintaining good BER performance in high-mobility\nscenarios.", "published": "2025-09-23 02:28:05", "link": "http://arxiv.org/abs/2509.18555v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Online Process Reward Leanring for Agentic Reinforcement Learning", "abstract": "Large language models (LLMs) are increasingly trained with reinforcement\nlearning (RL) as autonomous agents that reason and act over long horizons in\ninteractive environments. However, sparse and sometimes unverifiable rewards\nmake temporal credit assignment extremely challenging. Recent work attempts to\nintegrate process supervision into agent learning but suffers from biased\nannotation, reward hacking, high-variance from overly fine-grained signals or\nfailtures when state overlap is rare. We therefore introduce Online Process\nReward Learning (OPRL), a general credit-assignment strategy for agentic RL\nthat integrates seamlessly with standard on-policy algorithms without relying\non additional rollouts or explicit step labels. In OPRL, we optimize an\nimplicit process reward model (PRM) alternately with the agent's policy to\ntransform trajectory preferences into implicit step rewards through a\ntrajectory-based DPO objective. These step rewards are then used to compute\nstep-level advantages, which are combined with episode-level advantages from\noutcome rewards for policy update, creating a self-reinforcing loop.\nTheoretical findings guarantee that the learned step rewards are consistent\nwith trajectory preferences and act as potential-based shaping rewards,\nproviding bounded gradients to stabilize training. Empirically, we evaluate\nOPRL on three distinct agent benmarks, including WebShop and VisualSokoban, as\nwell as open-ended social interactions with unverfiable rewards in SOTOPIA.\nCrucially, OPRL shows superior performance over frontier LLMs and strong RL\nbaselines across domains, achieving state-of-the-art results with higher\nsample-efficiency and lower variance during training. Further analysis also\ndemonstrates the efficient exploration by OPRL using fewer actions,\nunderscoring its potential for agentic learning in real-world scenarios.", "published": "2025-09-23 16:15:42", "link": "http://arxiv.org/abs/2509.19199v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Soft Tokens, Hard Truths", "abstract": "The use of continuous instead of discrete tokens during the Chain-of-Thought\n(CoT) phase of reasoning LLMs has garnered attention recently, based on the\nintuition that a continuous mixture of discrete tokens could simulate a\nsuperposition of several reasoning paths simultaneously. Theoretical results\nhave formally proven that continuous tokens have much greater expressivity and\ncan solve specific problems more efficiently. However, practical use of\ncontinuous tokens has been limited by strong training difficulties: previous\nworks either just use continuous tokens at inference time on a pre-trained\ndiscrete-token model, or must distill the continuous CoT from ground-truth\ndiscrete CoTs and face computational costs that limit the CoT to very few\ntokens.\n  This is the first work introducing a scalable method to learn continuous CoTs\nvia reinforcement learning (RL), without distilling from reference discrete\nCoTs. We use \"soft\" tokens: mixtures of tokens together with noise on the input\nembedding to provide RL exploration. Computational overhead is minimal,\nenabling us to learn continuous CoTs with hundreds of tokens. On math reasoning\nbenchmarks with Llama and Qwen models up to 8B, training with continuous CoTs\nmatch discrete-token CoTs for pass@1 and surpass them for pass@32, showing\ngreater CoT diversity. In systematic comparisons, the best-performing scenario\nis to train with continuous CoT tokens then use discrete tokens for inference,\nmeaning the \"soft\" models can be deployed in a standard way. Finally, we show\ncontinuous CoT RL training better preserves the predictions of the base model\non out-of-domain tasks, thus providing a softer touch to the base model.", "published": "2025-09-23 15:43:47", "link": "http://arxiv.org/abs/2509.19170v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning", "abstract": "Medical imaging provides critical evidence for clinical diagnosis, treatment\nplanning, and surgical decisions, yet most existing imaging models are narrowly\nfocused and require multiple specialized networks, limiting their\ngeneralization. Although large-scale language and multimodal models exhibit\nstrong reasoning and multi-task capabilities, real-world clinical applications\ndemand precise visual grounding, multimodal integration, and chain-of-thought\nreasoning. We introduce Citrus-V, a multimodal medical foundation model that\ncombines image analysis with textual reasoning. The model integrates detection,\nsegmentation, and multimodal chain-of-thought reasoning, enabling pixel-level\nlesion localization, structured report generation, and physician-like\ndiagnostic inference in a single framework. We propose a novel multimodal\ntraining approach and release a curated open-source data suite covering\nreasoning, detection, segmentation, and document understanding tasks.\nEvaluations demonstrate that Citrus-V outperforms existing open-source medical\nmodels and expert-level imaging systems across multiple benchmarks, delivering\na unified pipeline from visual grounding to clinical reasoning and supporting\nprecise lesion quantification, automated reporting, and reliable second\nopinions.", "published": "2025-09-23 14:42:31", "link": "http://arxiv.org/abs/2509.19090v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus", "abstract": "Over the past decade, Computational Linguistics (CL) and Natural Language\nProcessing (NLP) have evolved rapidly, especially with the advent of\nTransformer-based Large Language Models (LLMs). This shift has transformed\nresearch goals and priorities, from Lexical and Semantic Resources to Language\nModelling and Multimodality. In this study, we track the research trends of the\nItalian CL and NLP community through an analysis of the contributions to\nCLiC-it, arguably the leading Italian conference in the field. We compile the\nproceedings from the first 10 editions of the CLiC-it conference (from 2014 to\n2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its\nmetadata, including author provenance, gender, affiliations, and more, as well\nas the content of the papers themselves, which address various topics. Our goal\nis to provide the Italian and international research communities with valuable\ninsights into emerging trends and key developments over time, supporting\ninformed decisions and future directions in the field.", "published": "2025-09-23 14:06:09", "link": "http://arxiv.org/abs/2509.19033v2", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction", "abstract": "Keyphrase extraction is a fundamental task in natural language processing.\nHowever, existing unsupervised prompt-based methods for Large Language Models\n(LLMs) often rely on single-stage inference pipelines with uniform prompting,\nregardless of document length or LLM backbone. Such one-size-fits-all designs\nhinder the full exploitation of LLMs' reasoning and generation capabilities,\nespecially given the complexity of keyphrase extraction across diverse\nscenarios. To address these challenges, we propose MAPEX, the first framework\nthat introduces multi-agent collaboration into keyphrase extraction. MAPEX\ncoordinates LLM-based agents through modules for expert recruitment, candidate\nextraction, topic guidance, knowledge augmentation, and post-processing. A\ndual-path strategy dynamically adapts to document length: knowledge-driven\nextraction for short texts and topic-guided extraction for long texts.\nExtensive experiments on six benchmark datasets across three different LLMs\ndemonstrate its strong generalization and universality, outperforming the\nstate-of-the-art unsupervised method by 2.44% and standard LLM baselines by\n4.01% in F1@5 on average. Code is available at\nhttps://github.com/NKU-LITI/MAPEX.", "published": "2025-09-23 09:00:43", "link": "http://arxiv.org/abs/2509.18813v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models", "abstract": "Large language models (LLMs) have achieved impressive performance across\nnatural language processing (NLP) tasks. As real-world applications\nincreasingly demand longer context windows, continued pretraining and\nsupervised fine-tuning (SFT) on long-context data has become a common approach.\nWhile the effects of data length in continued pretraining have been extensively\nstudied, their implications for SFT remain unclear. In this work, we\nsystematically investigate how SFT data length influences LLM behavior on\nshort-context tasks. Counterintuitively, we find that long-context SFT improves\nshort-context performance, contrary to the commonly observed degradation from\nlong-context pretraining. To uncover the underlying mechanisms of this\nphenomenon, we first decouple and analyze two key components, Multi-Head\nAttention (MHA) and Feed-Forward Network (FFN), and show that both\nindependently benefit from long-context SFT. We further study their interaction\nand reveal a knowledge preference bias: long-context SFT promotes contextual\nknowledge, while short-context SFT favors parametric knowledge, making\nexclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that\nhybrid training mitigates this bias, offering explainable guidance for\nfine-tuning LLMs.", "published": "2025-09-23 07:55:38", "link": "http://arxiv.org/abs/2509.18762v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurofibromas in whole-body MRI", "abstract": "Background and Objectives: Neurofibromatosis type 1 is a genetic disorder\ncharacterized by the development of numerous neurofibromas (NFs) throughout the\nbody. Whole-body MRI (WB-MRI) is the clinical standard for detection and\nlongitudinal surveillance of NF tumor growth. Existing interactive segmentation\nmethods fail to combine high lesion-wise precision with scalability to hundreds\nof lesions. This study proposes a novel interactive segmentation model tailored\nto this challenge.\n  Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation\nmodel that extends the state-of-the-art, transformer-based, promptable Segment\nAnything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was\ntrained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using\nT2-weighted fat-suppressed sequences. The dataset was split at the patient\nlevel into a training set and four test sets (one in-domain and three\nreflecting different domain shift scenarios, e.g., MRI field strength\nvariation, low tumor burden, differences in clinical site and scanner vendor).\n  Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of\n0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC:\n0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained\nunder MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC:\n0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1\nscores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader\nvariability analysis showed model-to-expert agreement (DSC: 0.62-0.68),\ncomparable to inter-expert agreement (DSC: 0.57-0.69).\n  Conclusions: The proposed MOIS-SAM2 enables efficient and scalable\ninteractive segmentation of NFs in WB-MRI with minimal user input and strong\ngeneralization, supporting integration into clinical workflows.", "published": "2025-09-23 17:42:24", "link": "http://arxiv.org/abs/2509.19277v2", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "MAPO: Mixed Advantage Policy Optimization", "abstract": "Recent advances in reinforcement learning for foundation models, such as\nGroup Relative Policy Optimization (GRPO), have significantly improved the\nperformance of foundation models on reasoning tasks. Notably, the advantage\nfunction serves as a central mechanism in GRPO for ranking the trajectory\nimportance. However, existing explorations encounter both advantage reversion\nand advantage mirror problems, which hinder the reasonable advantage allocation\nacross different query samples. In this work, we propose an easy but effective\nGRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the\ntrajectory appears with different certainty and propose the advantage percent\ndeviation for samples with high-certainty trajectories. Furthermore, we\ndynamically reweight the advantage function for samples with varying trajectory\ncertainty, thereby adaptively configuring the advantage function to account for\nsample-specific characteristics. Comparison with related state-of-the-art\nmethods, along with ablation studies on different advantage variants, validates\nthe effectiveness of our approach.", "published": "2025-09-23 09:37:16", "link": "http://arxiv.org/abs/2509.18849v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "COLT: Enhancing Video Large Language Models with Continual Tool Usage", "abstract": "The success of Large Language Models (LLMs) has significantly propelled the\nresearch of video understanding. To harvest the benefits of well-trained expert\nmodels (i.e., tools), video LLMs prioritize the exploration of tool usage\ncapabilities. Existing methods either prompt closed-source LLMs or employ the\ninstruction tuning paradigm for tool-use fine-tuning. These methods, however,\nassume an established repository of fixed tools and struggle to generalize to\nreal-world environments where tool data is perpetually evolving and streaming\nin. To this end, we propose to enhance open-source video LLMs with COntinuaL\nTool usage (termed COLT), which automatically acquires tool-use ability in a\nsuccessive tool stream without suffering 'catastrophic forgetting' of the past\nlearned tools. Specifically, our COLT incorporates a learnable tool codebook as\na tool-specific memory system. Then relevant tools are dynamically selected\nbased on the similarity between user instruction and tool features within the\ncodebook. To unleash the tool usage potential of video LLMs, we collect a\nvideo-centric tool-use instruction tuning dataset VideoToolBench. Extensive\nexperiments on both previous video LLM benchmarks and the tool-use-specific\nVideoToolBench dataset demonstrate the state-of-the-art performance of our\nproposed COLT.", "published": "2025-09-23 07:49:30", "link": "http://arxiv.org/abs/2509.18754v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Do You Need Proprioceptive States in Visuomotor Policies?", "abstract": "Imitation-learning-based visuomotor policies have been widely used in robot\nmanipulation, where both visual observations and proprioceptive states are\ntypically adopted together for precise control. However, in this study, we find\nthat this common practice makes the policy overly reliant on the proprioceptive\nstate input, which causes overfitting to the training trajectories and results\nin poor spatial generalization. On the contrary, we propose the State-free\nPolicy, removing the proprioceptive state input and predicting actions only\nconditioned on visual observations. The State-free Policy is built in the\nrelative end-effector action space, and should ensure the full task-relevant\nvisual observations, here provided by dual wide-angle wrist cameras. Empirical\nresults demonstrate that the State-free policy achieves significantly stronger\nspatial generalization than the state-based policy: in real-world tasks such as\npick-and-place, challenging shirt-folding, and complex whole-body manipulation,\nspanning multiple robot embodiments, the average success rate improves from 0%\nto 85% in height generalization and from 6% to 64% in horizontal\ngeneralization. Furthermore, they also show advantages in data efficiency and\ncross-embodiment adaptation, enhancing their practicality for real-world\ndeployment. Discover more by visiting: https://statefreepolicy.github.io.", "published": "2025-09-23 04:56:59", "link": "http://arxiv.org/abs/2509.18644v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation", "abstract": "We propose Lavida-O, a unified Masked Diffusion Model (MDM) for multimodal\nunderstanding and generation. Unlike existing multimodal MDMs such as MMaDa and\nMuddit which only support simple image-level understanding tasks and\nlow-resolution image generation, Lavida-O presents a single framework that\nenables image-level understanding, object grounding, image editing, and\nhigh-resolution (1024px) text-to-image synthesis. Lavida-O incorporates a novel\nElastic Mixture-of-Transformers (Elastic-MoT) architecture that couples a\nlightweight generation branch with a larger understanding branch, supported by\ntoken compression, universal text conditioning and stratified sampling for\nefficient and high-quality generation. Lavida-O further incorporates planning\nand iterative self-reflection in image generation and editing tasks, seamlessly\nboosting generation quality with its understanding capabilities. Lavida-O\nachieves state-of-the-art performance on a wide range of benchmarks including\nRefCOCO object grounding, GenEval text-to-image generation, and ImgEdit image\nediting, outperforming existing autoregressive models and continuous diffusion\nmodels such as Qwen2.5-VL and FluxKontext-dev, while offering considerable\nspeedup at inference. These advances establish Lavida-O as a new paradigm for\nscalable multimodal reasoning and generation.", "published": "2025-09-23 17:05:46", "link": "http://arxiv.org/abs/2509.19244v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Investigating Traffic Accident Detection Using Multimodal Large Language Models", "abstract": "Traffic safety remains a critical global concern, with timely and accurate\naccident detection essential for hazard reduction and rapid emergency response.\nInfrastructure-based vision sensors offer scalable and efficient solutions for\ncontinuous real-time monitoring, facilitating automated detection of accidents\ndirectly from captured images. This research investigates the zero-shot\ncapabilities of multimodal large language models (MLLMs) for detecting and\ndescribing traffic accidents using images from infrastructure cameras, thus\nminimizing reliance on extensive labeled datasets. Main contributions include:\n(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,\nexplicitly addressing the scarcity of diverse, realistic, infrastructure-based\naccident data through controlled simulations; (2) Comparative performance\nanalysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in accident\nidentification and descriptive capabilities without prior fine-tuning; and (3)\nIntegration of advanced visual analytics, specifically YOLO for object\ndetection, Deep SORT for multi-object tracking, and Segment Anything (SAM) for\ninstance segmentation, into enhanced prompts to improve model accuracy and\nexplainability. Key numerical results show Pixtral as the top performer with an\nF1-score of 71% and 83% recall, while Gemini models gained precision with\nenhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and\nrecall losses. Gemma 3 offered the most balanced performance with minimal\nmetric fluctuation. These findings demonstrate the substantial potential of\nintegrating MLLMs with advanced visual analytics techniques, enhancing their\napplicability in real-world automated traffic monitoring systems.", "published": "2025-09-23 14:47:33", "link": "http://arxiv.org/abs/2509.19096v2", "categories": ["cs.CV", "cs.SE"], "primary_category": "cs.CV"}
{"title": "Human-Interpretable Uncertainty Explanations for Point Cloud Registration", "abstract": "In this paper, we address the point cloud registration problem, where\nwell-known methods like ICP fail under uncertainty arising from sensor noise,\npose-estimation errors, and partial overlap due to occlusion. We develop a\nnovel approach, Gaussian Process Concept Attribution (GP-CA), which not only\nquantifies registration uncertainty but also explains it by attributing\nuncertainty to well-known sources of errors in registration problems. Our\napproach leverages active learning to discover new uncertainty sources in the\nwild by querying informative instances. We validate GP-CA on three publicly\navailable datasets and in our real-world robot experiment. Extensive ablations\nsubstantiate our design choices. Our approach outperforms other\nstate-of-the-art methods in terms of runtime, high sample-efficiency with\nactive learning, and high accuracy. Our real-world experiment clearly\ndemonstrates its applicability. Our video also demonstrates that GP-CA enables\neffective failure-recovery behaviors, yielding more robust robotic perception.", "published": "2025-09-23 08:23:51", "link": "http://arxiv.org/abs/2509.18786v2", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation", "abstract": "Recent works have made notable advancements in enhancing unified models for\ntext-to-image generation through the Chain-of-Thought (CoT). However, these\nreasoning methods separate the processes of understanding and generation, which\nlimits their ability to guide the reasoning of unified models in addressing the\ndeficiencies of their generative capabilities. To this end, we propose a novel\nreasoning framework for unified models, Understanding-in-Generation (UiG),\nwhich harnesses the robust understanding capabilities of unified models to\nreinforce their performance in image generation. The core insight of our UiG is\nto integrate generative guidance by the strong understanding capabilities\nduring the reasoning process, thereby mitigating the limitations of generative\nabilities. To achieve this, we introduce \"Image Editing\" as a bridge to infuse\nunderstanding into the generation process. Initially, we verify the generated\nimage and incorporate the understanding of unified models into the editing\ninstructions. Subsequently, we enhance the generated image step by step,\ngradually infusing the understanding into the generation process. Our UiG\nframework demonstrates a significant performance improvement in text-to-image\ngeneration over existing text-to-image reasoning methods, e.g., a 3.92% gain on\nthe long prompt setting of the TIIF benchmark. The project code:\nhttps://github.com/QC-LY/UiG", "published": "2025-09-23 04:52:39", "link": "http://arxiv.org/abs/2509.18639v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unveiling the Role of Learning Rate Schedules via Functional Scaling Laws", "abstract": "Scaling laws have played a cornerstone role in guiding the training of large\nlanguage models (LLMs). However, most existing works on scaling laws primarily\nfocus on the final-step loss, overlooking the loss dynamics during the training\nprocess and, crucially, the impact of learning rate schedule (LRS). In this\npaper, we aim to bridge this gap by studying a teacher-student kernel\nregression setup trained via online stochastic gradient descent (SGD).\nLeveraging a novel intrinsic time viewpoint and stochastic differential\nequation (SDE) modeling of SGD, we introduce the Functional Scaling Law (FSL),\nwhich characterizes the evolution of population risk during the training\nprocess for general LRSs. Remarkably, the impact of the LRSs is captured\nthrough an explicit convolution-type functional term, making their effects\nfully tractable. To illustrate the utility of FSL, we analyze three widely used\nLRSs -- constant, exponential decay, and warmup-stable-decay (WSD) -- under\nboth data-limited and compute-limited regimes. We provide theoretical\njustification for widely adopted empirical practices in LLMs pre-training such\nas (i) higher-capacity models are more data- and compute-efficient; (ii)\nlearning rate decay can improve training efficiency; (iii) WSD-like schedules\ncan outperform direct-decay schedules. Lastly, we explore the practical\nrelevance of FSL as a surrogate model for fitting, predicting and optimizing\nthe loss curves in LLM pre-training, with experiments conducted across model\nsizes ranging from 0.1B to 1B parameters. We hope our FSL framework can deepen\nthe understanding of LLM pre-training dynamics and provide insights for\nimproving large-scale model training.", "published": "2025-09-23 16:05:16", "link": "http://arxiv.org/abs/2509.19189v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improving Credit Card Fraud Detection through Transformer-Enhanced GAN Oversampling", "abstract": "Detection of credit card fraud is an acute issue of financial security\nbecause transaction datasets are highly lopsided, with fraud cases being only a\ndrop in the ocean. Balancing datasets using the most popular methods of\ntraditional oversampling such as the Synthetic Minority Oversampling Technique\n(SMOTE) generally create simplistic synthetic samples that are not readily\napplicable to complex fraud patterns. Recent industry advances that include\nConditional Tabular Generative Adversarial Networks (CTGAN) and Tabular\nVariational Autoencoders (TVAE) have demonstrated increased efficiency in\ntabular synthesis, yet all these models still exhibit issues with\nhigh-dimensional dependence modelling. Now we will present our hybrid approach\nwhere we use a Generative Adversarial Network (GAN) with a Transformer encoder\nblock to produce realistic fraudulent transactions samples. The GAN\narchitecture allows training realistic generators adversarial, and the\nTransformer allows the model to learn rich feature interactions by\nself-attention. Such a hybrid strategy overcomes the limitations of SMOTE,\nCTGAN, and TVAE by producing a variety of high-quality synthetic minority\nclasses samples. We test our algorithm on the publicly-available Credit Card\nFraud Detection dataset and compare it to conventional and generative\nresampling strategies with a variety of classifiers, such as Logistic\nRegression (LR), Random Forest (RF), Extreme Gradient Boosting (XGBoost), and\nSupport Vector Machine (SVM). Findings indicate that our Transformer-based GAN\nshows substantial gains in Recall, F1-score and Area Under the Receiver\nOperating Characteristic Curve (AUC), which indicates that it is effective in\novercoming the severe class imbalance inherent in the task of fraud detection.", "published": "2025-09-23 14:05:13", "link": "http://arxiv.org/abs/2509.19032v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation", "abstract": "Diffusion models are the mainstream approach for time series generation\ntasks. However, existing diffusion models for time series generation require\nretraining the entire framework to introduce specific conditional guidance.\nThere also exists a certain degree of distributional bias between the generated\ndata and the real data, which leads to potential model biases in downstream\ntasks. Additionally, the complexity of diffusion models and the latent spaces\nleads to an uninterpretable inference process. To address these issues, we\npropose the data style-guided diffusion model (DS-Diffusion). In the\nDS-Diffusion, a diffusion framework based on style-guided kernels is developed\nto avoid retraining for specific conditions. The time-information based\nhierarchical denoising mechanism (THD) is developed to reduce the\ndistributional bias between the generated data and the real data. Furthermore,\nthe generated samples can clearly indicate the data style from which they\noriginate. We conduct comprehensive evaluations using multiple public datasets\nto validate our approach. Experimental results show that, compared to the\nstate-of-the-art model such as ImagenTime, the predictive score and the\ndiscriminative score decrease by 5.56% and 61.55%, respectively. The\ndistributional bias between the generated data and the real data is further\nreduced, the inference process is also more interpretable. Moreover, by\neliminating the need to retrain the diffusion model, the flexibility and\nadaptability of the model to specific conditions are also enhanced.", "published": "2025-09-23 03:06:39", "link": "http://arxiv.org/abs/2509.18584v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On-device Internet of Sounds Sonification with Wavetable Synthesis Techniques for Soil Moisture Monitoring in Water Scarcity Contexts", "abstract": "Sonification, the mapping of data to sound to communicate information about\nthe original data source, is becoming a viable strategy for the sonic\nrepresentation and communication of information derived from the complex flows\nof data exchanged across Internet of Sounds (IoS) networks. This paper presents\nan IoS sonification implementation for monitoring soil moisture levels within\nthe broader context of the globally increasing water scarcity. While previous\nwork has focused on sonifications operating on the applications and services\nlevel of the IoS network infrastructure, this paper explores device-level\nsonification using wavetable synthesis techniques to map sensor data to\nacoustic parameters. An approach to on-device wavetable sonification is\nformalized, and a prototype implementation is presented and explored before the\napproach is contextualised with regard to the soil moisture monitoring tasks.", "published": "2025-09-23 14:47:41", "link": "http://arxiv.org/abs/2509.19097v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Human-AI Narrative Synthesis to Foster Shared Understanding in Civic Decision-Making", "abstract": "Community engagement processes in representative political contexts, like\nschool districts, generate massive volumes of feedback that overwhelm\ntraditional synthesis methods, creating barriers to shared understanding not\nonly between civic leaders and constituents but also among community members.\nTo address these barriers, we developed StoryBuilder, a human-AI collaborative\npipeline that transforms community input into accessible first-person\nnarratives. Using 2,480 community responses from an ongoing school rezoning\nprocess, we generated 124 composite stories and deployed them through a\nmobile-friendly StorySharer interface. Our mixed-methods evaluation combined a\nfour-month field deployment, user studies with 21 community members, and a\ncontrolled experiment examining how narrative composition affects participant\nreactions. Field results demonstrate that narratives helped community members\nrelate across diverse perspectives. In the experiment, experience-grounded\nnarratives generated greater respect and trust than opinion-heavy narratives.\nWe contribute a human-AI narrative synthesis system and insights on its varied\nacceptance and effectiveness in a real-world civic context.", "published": "2025-09-23 23:19:28", "link": "http://arxiv.org/abs/2509.19643v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "AutoSpec: An Agentic Framework for Automatically Drafting Patent Specification", "abstract": "Patents play a critical role in driving technological innovation by granting\ninventors exclusive rights to their inventions. However the process of drafting\na patent application is often expensive and time-consuming, making it a prime\ncandidate for automation. Despite recent advancements in language models,\nseveral challenges hinder the development of robust automated patent drafting\nsystems. First, the information within a patent application is highly\nconfidential, which often prevents the use of closed-source LLMs for automating\nthis task. Second, the process of drafting a patent application is difficult\nfor even the most advanced language models due to their long context, technical\nwriting style, and specialized domain knowledge. To address these challenges,\nwe introduce AutoSpec, a secure, agentic framework for Automatically drafting\npatent Specification. Our approach decomposes the drafting process into a\nsequence of manageable subtasks, each solvable by smaller, open-source language\nmodels enhanced with custom tools tailored for drafting patent specification.\nTo assess our system, we design a novel evaluation protocol in collaboration\nwith experienced patent attorneys. Our automatic and expert evaluations show\nthat AutoSpec outperforms existing baselines on a patent drafting task.", "published": "2025-09-23 23:10:18", "link": "http://arxiv.org/abs/2509.19640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning", "abstract": "Speech summarization is a critical component of spoken content understanding,\nparticularly in the era of rapidly growing spoken and audiovisual data. Recent\nadvances in multi-modal large language models (MLLMs), leveraging the power of\nLLMs, enable generating textual summaries directly from speech without\nintermediate transcriptions, while supporting controllable styles and zero-shot\ngeneralization. However, open-source MLLMs continue to lag behind the\nstate-of-the-art text-based LLMs, limiting their practical deployment for\nspeech summarization. In this work, we present a novel multi-stage\nreinforcement learning training framework to enhance the speech summarization\ncapabilities in MLLMs. Our model delivers substantial improvements over strong\nbaselines, outperforms much larger MLLMs, and significantly narrows the gap\nwith state-of-the-art text-based LLMs.", "published": "2025-09-23 22:45:13", "link": "http://arxiv.org/abs/2509.19631v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Multimodal Language Models with Modality-Specific Experts for Financial Forecasting from Interleaved Sequences of Text and Time Series", "abstract": "Text and time series data offer complementary views of financial markets:\nnews articles provide narrative context about company events, while stock\nprices reflect how markets react to those events. However, despite their\ncomplementary nature, effectively integrating these interleaved modalities for\nimproved forecasting remains challenging. In this work, we propose a unified\nneural architecture that models these interleaved sequences using\nmodality-specific experts, allowing the model to learn unique time series\npatterns, while still enabling joint reasoning across modalities and preserving\npretrained language understanding capabilities. To further improve multimodal\nunderstanding, we introduce a cross-modal alignment framework with a salient\ntoken weighting mechanism that learns to align representations across\nmodalities with a focus on the most informative tokens. We demonstrate the\neffectiveness of our approach on a large-scale financial forecasting task,\nachieving state-of-the-art performance across a wide variety of strong unimodal\nand multimodal baselines. We develop an interpretability method that reveals\ninsights into the value of time series-context and reinforces the design of our\ncross-modal alignment objective. Finally, we demonstrate that these\nimprovements translate to meaningful economic gains in investment simulations.", "published": "2025-09-23 22:40:31", "link": "http://arxiv.org/abs/2509.19628v1", "categories": ["cs.CE", "cs.CL", "q-fin.CP", "I.2.7; J.4"], "primary_category": "cs.CE"}
{"title": "Evaluating Language Translation Models by Playing Telephone", "abstract": "Our ability to efficiently and accurately evaluate the quality of machine\ntranslation systems has been outrun by the effectiveness of current language\nmodels--which limits the potential for further improving these models on more\nchallenging tasks like long-form and literary translation. We propose an\nunsupervised method to generate training data for translation evaluation over\ndifferent document lengths and application domains by repeated rounds of\ntranslation between source and target languages. We evaluate evaluation systems\ntrained on texts mechanically generated using both model rotation and language\ntranslation approaches, demonstrating improved performance over a popular\ntranslation evaluation system (xCOMET) on two different tasks: (i) scoring the\nquality of a given translation against a human reference and (ii) selecting\nwhich of two translations is generationally closer to an original source\ndocument.", "published": "2025-09-23 22:01:52", "link": "http://arxiv.org/abs/2509.19611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models", "abstract": "The embodiment of emotional reactions from body parts contains rich\ninformation about our affective experiences. We propose a framework that\nutilizes state-of-the-art large vision-language models (LVLMs) to generate\nEmbodied LVLM Emotion Narratives (ELENA). These are well-defined, multi-layered\ntext outputs, primarily comprising descriptions that focus on the salient body\nparts involved in emotional reactions. We also employ attention maps and\nobserve that contemporary models exhibit a persistent bias towards the facial\nregion. Despite this limitation, we observe that our employed framework can\neffectively recognize embodied emotions in face-masked images, outperforming\nbaselines without any fine-tuning. ELENA opens a new trajectory for embodied\nemotion analysis across the modality of vision and enriches modeling in an\naffect-aware setting.", "published": "2025-09-23 21:34:57", "link": "http://arxiv.org/abs/2509.19595v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models", "abstract": "We introduce GuessingGame, a protocol for evaluating large language models\n(LLMs) as strategic question-askers in open-ended, open-domain settings. A\nGuesser LLM identifies a hidden object by posing free-form questions to an\nOracle without predefined choices or candidate lists. To measure question\nquality, we propose two information gain (IG) metrics: a Bayesian method that\ntracks belief updates over semantic concepts using LLM-scored relevance, and an\nentropy-based method that filters candidates via ConceptNet. Both metrics are\nmodel-agnostic and support post hoc analysis. Across 858 games with multiple\nmodels and prompting strategies, higher IG strongly predicts efficiency: a\none-standard-deviation IG increase reduces expected game length by 43\\%.\nPrompting constraints guided by IG, such as enforcing question diversity,\nenable weaker models to significantly improve performance. These results show\nthat question-asking in LLMs is both measurable and improvable, and crucial for\ninteractive reasoning.", "published": "2025-09-23 21:31:14", "link": "http://arxiv.org/abs/2509.19593v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation", "abstract": "Speech generation models based on large language models (LLMs) typically\noperate on discrete acoustic codes, which differ fundamentally from text tokens\ndue to their multicodebook structure. At each timestep, models must predict N\ncodebook entries jointly, introducing dependencies that challenge simple\nparallel prediction approaches. Parallel prediction assumes independence among\ncodebooks, yielding efficient decoding but often at the cost of reduced\nfidelity. To address this, hierarchical strategies employ a local transformer\n(LT) to refine predictions and capture intra-timestep dependencies. In this\nwork, we systematically investigate two LT architectures: an autoregressive\ntransformer that generates codebooks sequentially, and a MaskGIT-based\ntransformer that performs iterative masked prediction. Both designs further\nenable frame stacking, where the primary transformer predicts multiple frames\njointly, and the LT decodes their codebooks, offering improvements in speed\nwithout compromising perceptual quality. Through extensive analysis, we\ncharacterize the tradeoffs between parallel and iterative sampling strategies\nacross different throughput and quality regimes. Finally, we propose practical\nguidelines for selecting decoding strategies based on deployment priorities\nsuch as computational efficiency and synthesis fidelity.", "published": "2025-09-23 21:31:00", "link": "http://arxiv.org/abs/2509.19592v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines", "abstract": "Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view\nof the world. For example, Large Language Models (LLMs) based applications such\nas ChatGPT have shown the capability of generating human-like conversation on\nextensive topics. Due to the impressive performance on a variety of\nlanguage-related tasks (e.g., open-domain question answering, translation, and\ndocument summarization), one can envision the far-reaching impacts that can be\nbrought by the LLMs with broader real-world applications (e.g., customer\nservice, education and accessibility, and scientific discovery). Inspired by\ntheir success, this paper will offer an overview of state-of-the-art LLMs and\ntheir integration into a wide range of academic disciplines, including: (1)\narts, letters, and law (e.g., history, philosophy, political science, arts and\narchitecture, law), (2) economics and business (e.g., finance, economics,\naccounting, marketing), and (3) science and engineering (e.g., mathematics,\nphysics and mechanical engineering, chemistry and chemical engineering, life\nsciences and bioengineering, earth sciences and civil engineering, computer\nscience and electrical engineering). Integrating humanity and technology, in\nthis paper, we will explore how LLMs are shaping research and practice in these\nfields, while also discussing key limitations, open challenges, and future\ndirections in the era of generative AI. The review of how LLMs are engaged\nacross disciplines-along with key observations and insights-can help\nresearchers and practitioners interested in exploiting LLMs to advance their\nworks in diverse real-world applications.", "published": "2025-09-23 21:09:24", "link": "http://arxiv.org/abs/2509.19580v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExPe: Exact Positional Encodings for Generative Transformer Models with Extrapolating Capabilities", "abstract": "This paper introduces a novel approach to position embeddings in transformer\nmodels, named \"Exact Positional Embeddings\" (ExPE). An absolute positional\nembedding method that can extrapolate to sequences of lengths longer than the\nones it was trained on. Traditional transformer models rely on absolute or\nrelative position embeddings to incorporate positional information into token\nembeddings, which often struggle with extrapolation to sequences longer than\nthose seen during training. Our proposed method utilizes a novel embedding\nstrategy that encodes exact positional information by overriding specific\ndimensions of the embedding vectors, thereby enabling a more precise\nrepresentation of token positions. The proposed approach not only maintains the\nintegrity of the original embeddings but also enhances the model's ability to\ngeneralize to more extended sequences. In causal language modeling, our ExPE\nembeddings significantly reduce perplexity compared to rotary and sinusoidal\nembeddings, when tested on sequences longer than those used in training.", "published": "2025-09-23 20:51:51", "link": "http://arxiv.org/abs/2509.19569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmented Generation based context discovery for ASR", "abstract": "This work investigates retrieval augmented generation as an efficient\nstrategy for automatic context discovery in context-aware Automatic Speech\nRecognition (ASR) system, in order to improve transcription accuracy in the\npresence of rare or out-of-vocabulary terms. However, identifying the right\ncontext automatically remains an open challenge. This work proposes an\nefficient embedding-based retrieval approach for automatic context discovery in\nASR. To contextualize its effectiveness, two alternatives based on large\nlanguage models (LLMs) are also evaluated: (1) large language model (LLM)-based\ncontext generation via prompting, and (2) post-recognition transcript\ncorrection using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech\ndemonstrate that the proposed approach reduces WER by up to 17% (percentage\ndifference) relative to using no-context, while the oracle context results in a\nreduction of up to 24.1%.", "published": "2025-09-23 20:47:15", "link": "http://arxiv.org/abs/2509.19567v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Uncertainty in Semantic Language Modeling with PIXELS", "abstract": "Pixel-based language models aim to solve the vocabulary bottleneck problem in\nlanguage modeling, but the challenge of uncertainty quantification remains\nopen. The novelty of this work consists of analysing uncertainty and confidence\nin pixel-based language models across 18 languages and 7 scripts, all part of 3\nsemantically challenging tasks. This is achieved through several methods such\nas Monte Carlo Dropout, Transformer Attention, and Ensemble Learning. The\nresults suggest that pixel-based models underestimate uncertainty when\nreconstructing patches. The uncertainty is also influenced by the script, with\nLatin languages displaying lower uncertainty. The findings on ensemble learning\nshow better performance when applying hyperparameter tuning during the named\nentity recognition and question-answering tasks across 16 languages.", "published": "2025-09-23 20:43:50", "link": "http://arxiv.org/abs/2509.19563v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Confidence Calibration in Large Language Model-Based Entity Matching", "abstract": "This research aims to explore the intersection of Large Language Models and\nconfidence calibration in Entity Matching. To this end, we perform an empirical\nstudy to compare baseline RoBERTa confidences for an Entity Matching task\nagainst confidences that are calibrated using Temperature Scaling, Monte Carlo\nDropout and Ensembles. We use the Abt-Buy, DBLP-ACM, iTunes-Amazon and Company\ndatasets. The findings indicate that the proposed modified RoBERTa model\nexhibits a slight overconfidence, with Expected Calibration Error scores\nranging from 0.0043 to 0.0552 across datasets. We find that this overconfidence\ncan be mitigated using Temperature Scaling, reducing Expected Calibration Error\nscores by up to 23.83%.", "published": "2025-09-23 20:29:10", "link": "http://arxiv.org/abs/2509.19557v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do LLMs Encode Frame Semantics? Evidence from Frame Identification", "abstract": "We investigate whether large language models encode latent knowledge of frame\nsemantics, focusing on frame identification, a core challenge in frame semantic\nparsing that involves selecting the appropriate semantic frame for a target\nword in context. Using the FrameNet lexical resource, we evaluate models under\nprompt-based inference and observe that they can perform frame identification\neffectively even without explicit supervision. To assess the impact of\ntask-specific training, we fine-tune the model on FrameNet data, which\nsubstantially improves in-domain accuracy while generalizing well to\nout-of-domain benchmarks. Further analysis shows that the models can generate\nsemantically coherent frame definitions, highlighting the model's internalized\nunderstanding of frame semantics.", "published": "2025-09-23 20:09:32", "link": "http://arxiv.org/abs/2509.19540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning", "abstract": "The scaling of Large Language Models (LLMs) has exposed a critical gap\nbetween their performance on static benchmarks and their fragility in dynamic,\ninformation-rich environments. While models excel at isolated tasks, the\ncomputational limits that govern their reasoning under cognitive load remain\npoorly understood. In this work, we introduce a formal theory of computational\ncognitive load, positing that extraneous, task-irrelevant information (Context\nSaturation) and interference from task-switching (Attentional Residue) are key\nmechanisms that degrade performance. We designed the Interleaved Cognitive\nEvaluation (ICE), a deconfounded benchmark to systematically manipulate these\nload factors on challenging multi-hop reasoning tasks. A comprehensive study (N\n= 10 replications per item across 200 questions) revealed significant\nperformance variations across five instruction-tuned models. Smaller\nopen-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)\nexhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all\nconditions, including clean controls, on this high-intrinsic-load task. In\ncontrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%\naccuracy in control conditions, with a statistically significant degradation\nunder context saturation ($\\beta = -0.003$ per % load, $p < 0.001$). These\nfindings provide preliminary evidence that cognitive load is a key contributor\nto reasoning failures, supporting theories of hallucination-as-guessing under\nuncertainty. We conclude that dynamic, cognitive-aware stress testing, as\nexemplified by the ICE benchmark, is essential for evaluating the true\nresilience and safety of advanced AI systems.", "published": "2025-09-23 19:36:56", "link": "http://arxiv.org/abs/2509.19517v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.AI"}
{"title": "STARQA: A Question Answering Dataset for Complex Analytical Reasoning over Structured Databases", "abstract": "Semantic parsing methods for converting text to SQL queries enable question\nanswering over structured data and can greatly benefit analysts who routinely\nperform complex analytics on vast data stored in specialized relational\ndatabases. Although several benchmarks measure the abilities of text to SQL,\nthe complexity of their questions is inherently limited by the level of\nexpressiveness in query languages and none focus explicitly on questions\ninvolving complex analytical reasoning which require operations such as\ncalculations over aggregate analytics, time series analysis or scenario\nunderstanding. In this paper, we introduce STARQA, the first public\nhuman-created dataset of complex analytical reasoning questions and answers on\nthree specialized-domain databases. In addition to generating SQL directly\nusing LLMs, we evaluate a novel approach (Text2SQLCode) that decomposes the\ntask into a combination of SQL and Python: SQL is responsible for data\nfetching, and Python more naturally performs reasoning. Our results demonstrate\nthat identifying and combining the abilities of SQL and Python is beneficial\ncompared to using SQL alone, yet the dataset still remains quite challenging\nfor the existing state-of-the-art LLMs.", "published": "2025-09-23 19:26:16", "link": "http://arxiv.org/abs/2509.19508v1", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "A Pipeline to Assess Merging Methods via Behavior and Internals", "abstract": "Merging methods combine the weights of multiple language models (LMs) to\nleverage their capacities, such as for domain adaptation. While existing\nstudies investigate merged models from a solely behavioral perspective, we\noffer the first comprehensive view by assessing and connecting their behavior\nand internals. We present a novel evaluation pipeline that first merges\nmultiple parent LMs, and then evaluates the merged models in comparison to the\ninitial ones based on their behavior on downstream tasks, like MMLU, and the\ninternal encoded linguistic competence. We showcase this pipeline by assessing\nthe merging of instruction fine-tuned with math- and code-adapted LMs from the\nQwen2.5 family. Our results show that merging methods impacts behavior and\ninternals differently. While the performance of merged models is typically\nbetween that of the two parent models, their encoded information about\nlinguistic phenomena, particularly in morphology and syntax, can surpass the\nparent models. Moreover, we find weak ranking correlation between this behavior\nand internal evaluation. With our pipeline and initial results, we emphasize\nthe need for more comprehensive evaluations of model merging methods to gain a\nfaithful understanding of their capabilities and reliability, beyond potential\nsuperficial behavioral advances.", "published": "2025-09-23 18:37:32", "link": "http://arxiv.org/abs/2509.19476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Impact of 2D Segmentation Backbones on Point Cloud Predictions Using 4D Radar", "abstract": "LiDAR's dense, sharp point cloud (PC) representations of the surrounding\nenvironment enable accurate perception and significantly improve road safety by\noffering greater scene awareness and understanding. However, LiDAR's high cost\ncontinues to restrict the broad adoption of high-level Autonomous Driving (AD)\nsystems in commercially available vehicles. Prior research has shown progress\ntowards circumventing the need for LiDAR by training a neural network, using\nLiDAR point clouds as ground truth (GT), to produce LiDAR-like 3D point clouds\nusing only 4D Radars. One of the best examples is a neural network created to\ntrain a more efficient radar target detector with a modular 2D convolutional\nneural network (CNN) backbone and a temporal coherence network at its core that\nuses the RaDelft dataset for training (see arXiv:2406.04723). In this work, we\ninvestigate the impact of higher-capacity segmentation backbones on the quality\nof the produced point clouds. Our results show that while very high-capacity\nmodels may actually hurt performance, an optimal segmentation backbone can\nprovide a 23.7% improvement over the state-of-the-art (SOTA).", "published": "2025-09-23 23:21:50", "link": "http://arxiv.org/abs/2509.19644v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "TIMED: Adversarial and Autoregressive Refinement of Diffusion-Based Time Series Generation", "abstract": "Generating high-quality synthetic time series is a fundamental yet\nchallenging task across domains such as forecasting and anomaly detection,\nwhere real data can be scarce, noisy, or costly to collect. Unlike static data\ngeneration, synthesizing time series requires modeling both the marginal\ndistribution of observations and the conditional temporal dependencies that\ngovern sequential dynamics. We propose TIMED, a unified generative framework\nthat integrates a denoising diffusion probabilistic model (DDPM) to capture\nglobal structure via a forward-reverse diffusion process, a supervisor network\ntrained with teacher forcing to learn autoregressive dependencies through\nnext-step prediction, and a Wasserstein critic that provides adversarial\nfeedback to ensure temporal smoothness and fidelity. To further align the real\nand synthetic distributions in feature space, TIMED incorporates a Maximum Mean\nDiscrepancy (MMD) loss, promoting both diversity and sample quality. All\ncomponents are built using masked attention architectures optimized for\nsequence modeling and are trained jointly to effectively capture both\nunconditional and conditional aspects of time series data. Experimental results\nacross diverse multivariate time series benchmarks demonstrate that TIMED\ngenerates more realistic and temporally coherent sequences than\nstate-of-the-art generative models.", "published": "2025-09-23 23:05:40", "link": "http://arxiv.org/abs/2509.19638v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data", "abstract": "Egocentric human experience data presents a vast resource for scaling up\nend-to-end imitation learning for robotic manipulation. However, significant\ndomain gaps in visual appearance, sensor modalities, and kinematics between\nhuman and robot impede knowledge transfer. This paper presents EgoBridge, a\nunified co-training framework that explicitly aligns the policy latent spaces\nbetween human and robot data using domain adaptation. Through a measure of\ndiscrepancy on the joint policy latent features and actions based on Optimal\nTransport (OT), we learn observation representations that not only align\nbetween the human and robot domain but also preserve the action-relevant\ninformation critical for policy learning. EgoBridge achieves a significant\nabsolute policy success rate improvement by 44% over human-augmented\ncross-embodiment baselines in three real-world single-arm and bimanual\nmanipulation tasks. EgoBridge also generalizes to new objects, scenes, and\ntasks seen only in human data, where baselines fail entirely. Videos and\nadditional information can be found at https://ego-bridge.github.io", "published": "2025-09-23 22:34:47", "link": "http://arxiv.org/abs/2509.19626v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Raw-JPEG Adapter: Efficient Raw Image Compression with JPEG", "abstract": "Digital cameras digitize scene light into linear raw representations, which\nthe image signal processor (ISP) converts into display-ready outputs. While raw\ndata preserves full sensor information--valuable for editing and vision\ntasks--formats such as Digital Negative (DNG) require large storage, making\nthem impractical in constrained scenarios. In contrast, JPEG is a widely\nsupported format, offering high compression efficiency and broad compatibility,\nbut it is not well-suited for raw storage. This paper presents RawJPEG Adapter,\na lightweight, learnable, and invertible preprocessing pipeline that adapts raw\nimages for standard JPEG compression. Our method applies spatial and optional\nfrequency-domain transforms, with compact parameters stored in the JPEG comment\nfield, enabling accurate raw reconstruction. Experiments across multiple\ndatasets show that our method achieves higher fidelity than direct JPEG\nstorage, supports other codecs, and provides a favorable trade-off between\ncompression ratio and reconstruction accuracy.", "published": "2025-09-23 22:31:37", "link": "http://arxiv.org/abs/2509.19624v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Parameter-Efficient Multi-Task Learning via Progressive Task-Specific Adaptation", "abstract": "Parameter-efficient fine-tuning methods have emerged as a promising solution\nfor adapting pre-trained models to various downstream tasks. While these\nmethods perform well in single-task learning, extending them to multi-task\nlearning exacerbates common challenges, such as task interference and negative\ntransfer, due to the limited number of trainable parameters. To address these\nissues, we introduce progressive task-specific multi-task adaptation, a novel\nparameter-efficient approach for multi-task learning. This approach introduces\nadapter modules in a pre-trained model such that these modules are shared\nacross all tasks in the initial layers and become progressively more\ntask-specific in the later layers. The motivation is to reduce the conflicts\namong tasks by allowing transfer learning across all tasks in the initial\nlayers and enabling task-specific learning toward the prediction heads.\nAdditionally, we propose a gradient-based approach for computing task\nsimilarity and use this measure to allocate similar tasks to the shared adapter\nmodules. Our task similarity method introduces minimal overhead in the\npipeline. We evaluate our approach by adapting the Swin Transformer for dense\nprediction tasks. Experiments on the PASCAL and NYUD-v2 datasets demonstrate\nthat our approach outperforms a fully fine-tuned multi-task model while\nrequiring only one-fifth of the trainable parameters. This approach achieves\nbetter relative improvement to single-task fine-tuning while reducing the\nnumber of trainable parameters and surpasses the current state-of-the-art\nmethods for parameter-efficient multi-task learning.", "published": "2025-09-23 21:51:04", "link": "http://arxiv.org/abs/2509.19602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthesizing Artifact Dataset for Pixel-level Detection", "abstract": "Artifact detectors have been shown to enhance the performance of\nimage-generative models by serving as reward models during fine-tuning. These\ndetectors enable the generative model to improve overall output fidelity and\naesthetics. However, training the artifact detector requires expensive\npixel-level human annotations that specify the artifact regions. The lack of\nannotated data limits the performance of the artifact detector. A naive\npseudo-labeling approach-training a weak detector and using it to annotate\nunlabeled images-suffers from noisy labels, resulting in poor performance. To\naddress this, we propose an artifact corruption pipeline that automatically\ninjects artifacts into clean, high-quality synthetic images on a predetermined\nregion, thereby producing pixel-level annotations without manual labeling. The\nproposed method enables training of an artifact detector that achieves\nperformance improvements of 13.2% for ConvNeXt and 3.7% for Swin-T, as verified\non human-labeled data, compared to baseline approaches. This work represents an\ninitial step toward scalable pixel-level artifact annotation datasets that\nintegrate world knowledge into artifact detection.", "published": "2025-09-23 21:28:33", "link": "http://arxiv.org/abs/2509.19589v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action", "abstract": "Executing open-ended natural language queries is a core problem in robotics.\nWhile recent advances in imitation learning and vision-language-actions models\n(VLAs) have enabled promising end-to-end policies, these models struggle when\nfaced with complex instructions and new scenes. An alternative is to design an\nexplicit scene representation as a queryable interface between the robot and\nthe world, using query results to guide downstream motion planning. In this\nwork, we present Agentic Scene Policies (ASP), an agentic framework that\nleverages the advanced semantic, spatial, and affordance-based querying\ncapabilities of modern scene representations to implement a capable\nlanguage-conditioned robot policy. ASP can execute open-vocabulary queries in a\nzero-shot manner by explicitly reasoning about object affordances in the case\nof more complex skills. Through extensive experiments, we compare ASP with VLAs\non tabletop manipulation problems and showcase how ASP can tackle room-level\nqueries through affordance-guided navigation, and a scaled-up scene\nrepresentation. (Project page:\nhttps://montrealrobotics.ca/agentic-scene-policies.github.io/)", "published": "2025-09-23 20:56:00", "link": "http://arxiv.org/abs/2509.19571v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "CURE: Centroid-guided Unsupervised Representation Erasure for Facial Recognition Systems", "abstract": "In the current digital era, facial recognition systems offer significant\nutility and have been widely integrated into modern technological\ninfrastructures; however, their widespread use has also raised serious privacy\nconcerns, prompting regulations that mandate data removal upon request. Machine\nunlearning has emerged as a powerful solution to address this issue by\nselectively removing the influence of specific user data from trained models\nwhile preserving overall model performance. However, existing machine\nunlearning techniques largely depend on supervised techniques requiring\nidentity labels, which are often unavailable in privacy-constrained situations\nor in large-scale, noisy datasets. To address this critical gap, we introduce\nCURE (Centroid-guided Unsupervised Representation Erasure), the first\nunsupervised unlearning framework for facial recognition systems that operates\nwithout the use of identity labels, effectively removing targeted samples while\npreserving overall performance. We also propose a novel metric, the Unlearning\nEfficiency Score (UES), which balances forgetting and retention stability,\naddressing shortcomings in the current evaluation metrics. CURE significantly\noutperforms unsupervised variants of existing unlearning methods. Additionally,\nwe conducted quality-aware unlearning by designating low-quality images as the\nforget set, demonstrating its usability and benefits, and highlighting the role\nof image quality in machine unlearning.", "published": "2025-09-23 20:42:40", "link": "http://arxiv.org/abs/2509.19562v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning", "abstract": "Grounding large language models (LLMs) in domain-specific tasks like post-hoc\ndash-cam driving video analysis is challenging due to their general-purpose\ntraining and lack of structured inductive biases. As vision is often the sole\nmodality available for such analysis (i.e., no LiDAR, GPS, etc.), existing\nvideo-based vision-language models (V-VLMs) struggle with spatial reasoning,\ncausal inference, and explainability of events in the input video. To this end,\nwe introduce iFinder, a structured semantic grounding framework that decouples\nperception from reasoning by translating dash-cam videos into a hierarchical,\ninterpretable data structure for LLMs. iFinder operates as a modular,\ntraining-free pipeline that employs pretrained vision models to extract\ncritical cues -- object pose, lane positions, and object trajectories -- which\nare hierarchically organized into frame- and video-level structures. Combined\nwith a three-block prompting strategy, it enables step-wise, grounded reasoning\nfor the LLM to refine a peer V-VLM's outputs and provide accurate reasoning.\nEvaluations on four public dash-cam video benchmarks show that iFinder's\nproposed grounding with domain-specific cues, especially object orientation and\nglobal context, significantly outperforms end-to-end V-VLMs on four zero-shot\ndriving benchmarks, with up to 39% gains in accident reasoning accuracy. By\ngrounding LLMs with driving domain-specific representations, iFinder offers a\nzero-shot, interpretable, and reliable alternative to end-to-end V-VLMs for\npost-hoc driving video understanding.", "published": "2025-09-23 20:25:53", "link": "http://arxiv.org/abs/2509.19552v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation", "abstract": "Training robust bimanual manipulation policies via imitation learning\nrequires demonstration data with broad coverage over robot poses, contacts, and\nscene contexts. However, collecting diverse and precise real-world\ndemonstrations is costly and time-consuming, which hinders scalability. Prior\nworks have addressed this with data augmentation, typically for either\neye-in-hand (wrist camera) setups with RGB inputs or for generating novel\nimages without paired actions, leaving augmentation for eye-to-hand\n(third-person) RGB-D training with new action labels less explored. In this\npaper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data\nAugmentation (ROPA), an offline imitation learning data augmentation method\nthat fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D\nobservations of novel robot poses. Our approach simultaneously generates\ncorresponding joint-space action labels while employing constrained\noptimization to enforce physical consistency through appropriate\ngripper-to-object contact constraints in bimanual scenarios. We evaluate our\nmethod on 5 simulated and 3 real-world tasks. Our results across 2625\nsimulation trials and 300 real-world trials demonstrate that ROPA outperforms\nbaselines and ablations, showing its potential for scalable RGB and RGB-D data\naugmentation in eye-to-hand bimanual manipulation. Our project website is\navailable at: https://ropaaug.github.io/.", "published": "2025-09-23 18:11:53", "link": "http://arxiv.org/abs/2509.19454v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "HUNT: High-Speed UAV Navigation and Tracking in Unstructured Environments via Instantaneous Relative Frames", "abstract": "Search and rescue operations require unmanned aerial vehicles to both\ntraverse unknown unstructured environments at high speed and track targets once\ndetected. Achieving both capabilities under degraded sensing and without global\nlocalization remains an open challenge. Recent works on relative navigation\nhave shown robust tracking by anchoring planning and control to a visible\ndetected object, but cannot address navigation when no target is in the field\nof view. We present HUNT (High-speed UAV Navigation and Tracking), a real-time\nframework that unifies traversal, acquisition, and tracking within a single\nrelative formulation. HUNT defines navigation objectives directly from onboard\ninstantaneous observables such as attitude, altitude, and velocity, enabling\nreactive high-speed flight during search. Once a target is detected, the same\nperception-control pipeline transitions seamlessly to tracking. Outdoor\nexperiments in dense forests, container compounds, and search-and-rescue\noperations with vehicles and mannequins demonstrate robust autonomy where\nglobal methods fail.", "published": "2025-09-23 18:07:10", "link": "http://arxiv.org/abs/2509.19452v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit Claims on Social Media with Dual Encoders and Neural Re-Ranking", "abstract": "Linking implicit scientific claims made on social media to their original\npublications is crucial for evidence-based fact-checking and scholarly\ndiscourse, yet it is hindered by lexical sparsity, very short queries, and\ndomain-specific language. Team AIRwaves ranked second in Subtask 4b of the\nCLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly\noutperforms the competition baseline. The optimized sparse-retrieval\nbaseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To\nsurpass this baseline, a two-stage retrieval pipeline is introduced: (i) a\nfirst stage that uses a dual encoder based on E5-large, fine-tuned using\nin-batch and mined hard negatives and enhanced through chunked tokenization and\nrich document metadata; and (ii) a neural re-ranking stage using a SciBERT\ncross-encoder. Replacing purely lexical matching with neural representations\nlifts performance to MRR@5 = 0.6174, and the complete pipeline further improves\nto MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with\nneural re-rankers delivers a powerful and efficient solution for tweet-to-study\nmatching and provides a practical blueprint for future evidence-retrieval\npipelines.", "published": "2025-09-23 19:26:31", "link": "http://arxiv.org/abs/2509.19509v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Efficient $\\varepsilon$-approximate minimum-entropy couplings", "abstract": "Given $m \\ge 2$ discrete probability distributions over $n$ states each, the\nminimum-entropy coupling is the minimum-entropy joint distribution whose\nmarginals are the same as the input distributions. Computing the\nminimum-entropy coupling is NP-hard, but there has been significant progress in\ndesigning approximation algorithms; prior to this work, the best known\npolynomial-time algorithms attain guarantees of the form $H(\\operatorname{ALG})\n\\le H(\\operatorname{OPT}) + c$, where $c \\approx 0.53$ for $m=2$, and $c\n\\approx 1.22$ for general $m$ [CKQGK '23].\n  A main open question is whether this task is APX-hard, or whether there\nexists a polynomial-time approximation scheme (PTAS). In this work, we design\nan algorithm that produces a coupling with entropy $H(\\operatorname{ALG}) \\le\nH(\\operatorname{OPT}) + \\varepsilon$ in running time\n$n^{O(\\operatorname{poly}(1/\\varepsilon) \\cdot \\operatorname{exp}(m) )}$:\nshowing a PTAS exists for constant $m$.", "published": "2025-09-23 21:44:54", "link": "http://arxiv.org/abs/2509.19598v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Analyzing \u03b1-divergence in Gaussian Rate-Distortion-Perception Theory", "abstract": "The problem of estimating the information rate distortion perception function\n(RDPF), which is a relevant information-theoretic quantity in goal-oriented\nlossy compression and semantic information reconstruction, is investigated\nhere. Specifically, we study the RDPF tradeoff for Gaussian sources subject to\na mean-squared error (MSE) distortion and a perception measure that belongs to\nthe family of {\\alpha} divergences. Assuming a jointly Gaussian RDPF, which\nforms a convex optimization problem, we characterize an upper bound for which\nwe find a parametric solution. We show that evaluating the optimal parameters\nof this parametric solution is equivalent to finding the roots of a reduced\nexponential polynomial of degree {\\alpha}. Additionally, we determine which\ndisjoint sets contain each root, which enables us to evaluate them numerically\nusing the well-known bisection method. Finally, we validate our analytical\nfindings with numerical results and establish connections with existing\nresults.", "published": "2025-09-23 20:56:49", "link": "http://arxiv.org/abs/2509.19572v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Martingale Projections and Quantum Decoherence", "abstract": "We introduce so-called super/sub-martingale projections as a family of\nendomorphisms defined on unions of Polish spaces. Such projections allow us to\nidentify martingales as collections of transformations that relate path-valued\nrandom variables to each other under conditional expectations. In this sense,\nsuper/sub-martingale projections are random functionals that (i) are\nboundedness preserving and (ii) satisfy a conditional expectation criterion\nsimilar to that of the classical martingale theory. As an application to the\ntheory of open quantum systems, we prove (a) that any system-environment\ninteraction that manifests a supermartingale projection on the density matrix\ngives rise to decoherence, and (b) that any system-environment interaction that\nmanifests a submartingale projection gives rise an increase in Shannon-Wiener\ninformation. It follows (c) that martingale projections in an open quantum\nsystem give rise both to quantum decoherence and to information gain.", "published": "2025-09-23 18:52:56", "link": "http://arxiv.org/abs/2509.19491v1", "categories": ["quant-ph", "cs.IT", "math.IT", "math.PR"], "primary_category": "quant-ph"}
{"title": "Knowledge Base-Aware Orchestration: A Dynamic, Privacy-Preserving Method for Multi-Agent Systems", "abstract": "Multi-agent systems (MAS) are increasingly tasked with solving complex,\nknowledge-intensive problems where effective agent orchestration is critical.\nConventional orchestration methods rely on static agent descriptions, which\noften become outdated or incomplete. This limitation leads to inefficient task\nrouting, particularly in dynamic environments where agent capabilities\ncontinuously evolve. We introduce Knowledge Base-Aware (KBA) Orchestration, a\nnovel approach that augments static descriptions with dynamic,\nprivacy-preserving relevance signals derived from each agent's internal\nknowledge base (KB). In the proposed framework, when static descriptions are\ninsufficient for a clear routing decision, the orchestrator prompts the\nsubagents in parallel. Each agent then assesses the task's relevance against\nits private KB, returning a lightweight ACK signal without exposing the\nunderlying data. These collected signals populate a shared semantic cache,\nproviding dynamic indicators of agent suitability for future queries. By\ncombining this novel mechanism with static descriptions, our method achieves\nmore accurate and adaptive task routing preserving agent autonomy and data\nconfidentiality. Benchmarks show that our KBA Orchestration significantly\noutperforms static description-driven methods in routing precision and overall\nsystem efficiency, making it suitable for large-scale systems that require\nhigher accuracy than standard description-driven routing.", "published": "2025-09-23 21:46:38", "link": "http://arxiv.org/abs/2509.19599v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "The Heterogeneous Multi-Agent Challenge", "abstract": "Multi-Agent Reinforcement Learning (MARL) is a growing research area which\ngained significant traction in recent years, extending Deep RL applications to\na much wider range of problems. A particularly challenging class of problems in\nthis domain is Heterogeneous Multi-Agent Reinforcement Learning (HeMARL), where\nagents with different sensors, resources, or capabilities must cooperate based\non local information. The large number of real-world situations involving\nheterogeneous agents makes it an attractive research area, yet underexplored,\nas most MARL research focuses on homogeneous agents (e.g., a swarm of identical\nrobots). In MARL and single-agent RL, standardized environments such as ALE and\nSMAC have allowed to establish recognized benchmarks to measure progress.\nHowever, there is a clear lack of such standardized testbed for cooperative\nHeMARL. As a result, new research in this field often uses simple environments,\nwhere most algorithms perform near optimally, or uses weakly heterogeneous MARL\nenvironments.", "published": "2025-09-23 19:30:30", "link": "http://arxiv.org/abs/2509.19512v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "HPL-MxP Benchmark: Mixed-Precision Algorithms, Iterative Refinement, and Scalable Data Generation", "abstract": "We present a mixed-precision benchmark called HPL-MxP that uses both a\nlower-precision LU factorization with a non-stationary iterative refinement\nbased on GMRES. We evaluate the numerical stability of one of the methods of\ngenerating the input matrix in a scalable fashion and show how the diagonal\nscaling affects the solution quality in terms of the backward-error. Some of\nthe performance results at large scale supercomputing installations produced\nExascale-level compute throughput numbers thus proving the viability of the\nproposed benchmark for evaluating such machines. We also present the potential\nof the benchmark to continue increasing its use with proliferation of hardware\naccelerators for AI workloads whose reliable evaluation continues to pose a\nparticular challenge for the users.", "published": "2025-09-23 22:16:15", "link": "http://arxiv.org/abs/2509.19618v1", "categories": ["math.NA", "cs.NA", "cs.PF"], "primary_category": "math.NA"}
{"title": "Spectral theory of matrix-sequences: perspectives of the GLT analysis and beyond", "abstract": "In recent years there has been a growing attention on distribution results in\nthe sense of Weyl for the collective behavior of eigenvalues and singular\nvalues of matrix-sequences. Starting from the work of Szeg\\\"o regarding the\ncase of Toeplitz matrix-sequences, there has been a wealth of associated\nresults, which culminated in the works of Tilli and of Tyrtyshnikov,\nZamarashkin, and of the author for preconditioned and non-preconditioned\n$r$-block $d$-level Toeplitz matrix-sequences with Lebesgue integrable\ngenerating functions. In the latter the use of matrix-valued linear positive\noperators and related Korovkin theories has been crucial. The subsequent steps\ninduced by the analysis of preconditioning techniques and inspired by the rich\nworld of the (pseudo) differential operators have been studies from the same\nperspective of matrix-sequences with hidden (asymptotic) structure, widely\nstudied in the literature. The widest generalization is represented by the\nnotion of generalized locally Toeplitz matrix-sequences, which have inherent\nhidden structure and which include virtually any approximation via local\nnumerical methods of (systems of) integral equations, partial and fractional\ndifferential equations, also with nonsmooth variable coefficients and irregular\nbounded/unbounded domains/manifolds.\n  In the current work, instead of focusing on a specific type of results,\nstarting from the most recent advances on the topic, we describe shortly a\nseries of open problems, challenges to be developed in the future.", "published": "2025-09-23 20:13:48", "link": "http://arxiv.org/abs/2509.19544v1", "categories": ["math.NA", "cs.NA", "15A18, 15B05, 47B06, 65Mxx, 65Nxx, 47B65, 65F08, 65F10"], "primary_category": "math.NA"}
{"title": "A Note on Fine-Grained Quantum Reductions for Linear Algebraic Problems", "abstract": "We observe that any $T(n)$ time algorithm (quantum or classical) for several\ncentral linear algebraic problems, such as computing $\\det(A)$, $tr(A^3)$, or\n$tr(A^{-1})$ for an $n \\times n$ integer matrix $A$, yields a $O(T(n)) + \\tilde\nO(n^2)$ time \\textit{quantum algorithm} for $n \\times n$ matrix-matrix\nmultiplication. That is, on quantum computers, the complexity of these problems\nis essentially equivalent to that of matrix multiplication. Our results follow\nby first observing that the Bernstein-Vazirani algorithm gives a direct quantum\nreduction from matrix multiplication to computing $tr(ABC)$ for $n \\times n$\ninputs $A,B,C$. We can then reduce $tr(ABC)$ to each of our problems of\ninterest.\n  For the above problems, and many others in linear algebra, their fastest\nknown algorithms require $\\Theta(n^\\omega)$ time, where $\\omega \\approx 2.37$\nis the current exponent of fast matrix multiplication. Our finding shows that\nany improvements beyond this barrier would lead to faster quantum algorithms\nfor matrix multiplication. Our results complement existing reductions from\nmatrix multiplication in algebraic circuits [BCS13], and reductions that work\nfor standard classical algorithms, but are not tight -- i.e., which roughly\nshow that an $O(n^{3-\\delta})$ time algorithm for the problem yields an\n$O(n^{3-\\delta/3})$ matrix multiplication algorithm [WW10].", "published": "2025-09-23 19:48:58", "link": "http://arxiv.org/abs/2509.19528v1", "categories": ["cs.DS", "cs.CC", "cs.NA", "math.NA"], "primary_category": "cs.DS"}
{"title": "Stability of high-order Scott-Vogelius elements for 2D non-Newtonian incompressible flow", "abstract": "We consider the stability of high-order Scott-Vogelius elements for 2D\nnon-Newtonian incompressible flow problems. For elements of degree 4 or higher,\nwe construct a right-inverse of the divergence operator that is stable\nuniformly in the polynomial degree $N$ from $L^p$ to $\\boldsymbol{W}^{1,p}$,\nshow that the associated inf-sup constant is bounded below by a constant that\ndecays at worst like $N^{-3\\left| \\frac{1}{2} - \\frac{1}{p}\\right|}$, and\nconstruct local Fortin operators with stability constants explicit in the\npolynomial degree. We demonstrate these results with several numerical examples\nsuggesting that the $p$-version method can offer superior convergence rates\nover the $h$-version method even in the non-Newtonian setting.", "published": "2025-09-23 18:50:45", "link": "http://arxiv.org/abs/2509.19488v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "PySymmetry: A Sage/Python Framework for the Symmetry Reduction of Linear G-Equivariant Systems", "abstract": "Despite the prevalence of symmetry in scientific linear systems, these\nstructural properties are often underutilized by standard computational\nsoftware. This paper introduces PySymmetry, an open-source Sage/Python\nframework that implements classical representation theory to simplify\nG-equivariant linear systems. PySymmetry uses projection operators to generate\nsymmetry-adapted bases, transforming equivariant operators into a more\nefficient block-diagonal form. Its functionalities include defining and\nreducing representations, calculating multiplicities, and obtaining the\nexplicit block structure.\n  We demonstrate PySymmetry's versatility through three case studies: a\nchemistry application, a numerical benchmark on the non-Hermitian Schr\\\"odinger\nequation that achieved a performance increase of over 17x compared to standard\nmethods, and a symbolic investigation that enabled the first complete\nanalytical classification of a challenging problem in celestial mechanics.\nDesigned for seamless integration with libraries like NumPy and SciPy,\nPySymmetry offers a powerful, user-friendly tool for exploring symmetries in\ntheoretical and applied contexts. ```", "published": "2025-09-23 18:39:15", "link": "http://arxiv.org/abs/2509.19479v1", "categories": ["math.GR", "cs.NA", "cs.SC", "math-ph", "math.MP", "math.NA", "math.RT"], "primary_category": "math.GR"}
{"title": "Quantum Harmonic Analysis and the Structure in Data: Augmentation", "abstract": "In this short note, we study the impact of data augmentation on the\nsmoothness of principal components of high-dimensional datasets. Using tools\nfrom quantum harmonic analysis, we show that eigenfunctions of operators\ncorresponding to augmented data sets lie in the modulation space\n$M^1(\\mathbb{R}^d)$, guaranteeing smoothness and continuity. Numerical examples\non synthetic and audio data confirm the theoretical findings. While interesting\nin itself, the results suggest that manifold learning and feature extraction\nalgorithms can benefit from systematic and informed augmentation principles.", "published": "2025-09-23 18:30:35", "link": "http://arxiv.org/abs/2509.19474v1", "categories": ["math.FA", "cs.LG", "cs.NA", "math.NA"], "primary_category": "math.FA"}
{"title": "THINNs: Thermodynamically Informed Neural Networks", "abstract": "Physics-Informed Neural Networks (PINNs) are a class of deep learning models\naiming to approximate solutions of PDEs by training neural networks to minimize\nthe residual of the equation. Focusing on non-equilibrium fluctuating systems,\nwe propose a physically informed choice of penalization that is consistent with\nthe underlying fluctuation structure, as characterized by a large deviations\nprinciple. This approach yields a novel formulation of PINNs in which the\npenalty term is chosen to penalize improbable deviations, rather than being\nselected heuristically. The resulting thermodynamically consistent extension of\nPINNs, termed THINNs, is subsequently analyzed by establishing analytical a\nposteriori estimates, and providing empirical comparisons to established\npenalization strategies.", "published": "2025-09-23 18:22:47", "link": "http://arxiv.org/abs/2509.19467v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Mamba Modulation: On the Length Generalization of Mamba", "abstract": "The quadratic complexity of the attention mechanism in Transformer models has\nmotivated the development of alternative architectures with sub-quadratic\nscaling, such as state-space models. Among these, Mamba has emerged as a\nleading architecture, achieving state-of-the-art results across a range of\nlanguage modeling tasks. However, Mamba's performance significantly\ndeteriorates when applied to contexts longer than those seen during\npre-training, revealing a sharp sensitivity to context length extension.\nThrough detailed analysis, we attribute this limitation to the\nout-of-distribution behaviour of its state-space dynamics, particularly within\nthe parameterization of the state transition matrix $\\mathbf{A}$. Unlike recent\nworks which attribute this sensitivity to the vanished accumulation of\ndiscretization time steps, $\\exp(-\\sum_{t=1}^N\\Delta_t)$, we establish a\nconnection between state convergence behavior as the input length approaches\ninfinity and the spectrum of the transition matrix $\\mathbf{A}$, offering a\nwell-founded explanation of its role in length extension. Next, to overcome\nthis challenge, we propose an approach that applies spectrum scaling to\npre-trained Mamba models to enable robust long-context generalization by\nselectively modulating the spectrum of $\\mathbf{A}$ matrices in each layer. We\nshow that this can significantly improve performance in settings where simply\nmodulating $\\Delta_t$ fails, validating our insights and providing avenues for\nbetter length generalization of state-space models with structured transition\nmatrices.", "published": "2025-09-23 22:46:19", "link": "http://arxiv.org/abs/2509.19633v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MAGIC: Multi-task Gaussian process for joint imputation and classification in healthcare time series", "abstract": "Time series analysis has emerged as an important tool for improving patient\ndiagnosis and management in healthcare applications. However, these\napplications commonly face two critical challenges: time misalignment and data\nsparsity. Traditional approaches address these issues through a two-step\nprocess of imputation followed by prediction. We propose MAGIC (Multi-tAsk\nGaussian Process for Imputation and Classification), a novel unified framework\nthat simultaneously performs class-informed missing value imputation and label\nprediction within a hierarchical multi-task Gaussian process coupled with\nfunctional logistic regression. To handle intractable likelihood components,\nMAGIC employs Taylor expansion approximations with bounded error analysis, and\nparameter estimation is performed using EM algorithm with block coordinate\noptimization supported by convergence analysis. We validate MAGIC through two\nhealthcare applications: prediction of post-traumatic headache improvement\nfollowing mild traumatic brain injury and prediction of in-hospital mortality\nwithin 48 hours after ICU admission. In both applications, MAGIC achieves\nsuperior predictive accuracy compared to existing methods. The ability to\ngenerate real-time and accurate predictions with limited samples facilitates\nearly clinical assessment and treatment planning, enabling healthcare providers\nto make more informed treatment decisions.", "published": "2025-09-23 21:02:39", "link": "http://arxiv.org/abs/2509.19577v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Stochastic Path Planning in Correlated Obstacle Fields", "abstract": "We introduce the Stochastic Correlated Obstacle Scene (SCOS) problem, a\nnavigation setting with spatially correlated obstacles of uncertain blockage\nstatus, realistically constrained sensors that provide noisy readings and\ncostly disambiguation. Modeling the spatial correlation with Gaussian Random\nField (GRF), we develop Bayesian belief updates that refine blockage\nprobabilities, and use the posteriors to reduce search space for efficiency. To\nfind the optimal traversal policy, we propose a novel two-stage learning\nframework. An offline phase learns a robust base policy via optimistic policy\niteration augmented with information bonus to encourage exploration in\ninformative regions, followed by an online rollout policy with periodic base\nupdates via a Bayesian mechanism for information adaptation. This framework\nsupports both Monte Carlo point estimation and distributional reinforcement\nlearning (RL) to learn full cost distributions, leading to stronger uncertainty\nquantification. We establish theoretical benefits of correlation-aware updating\nand convergence property under posterior sampling. Comprehensive empirical\nevaluations across varying obstacle densities, sensor capabilities demonstrate\nconsistent performance gains over baselines. This framework addresses\nnavigation challenges in environments with adversarial interruptions or\nclustered natural hazards.", "published": "2025-09-23 20:30:35", "link": "http://arxiv.org/abs/2509.19559v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Chiseling: Powerful and Valid Subgroup Selection via Interactive Machine Learning", "abstract": "In regression and causal inference, controlled subgroup selection aims to\nidentify, with inferential guarantees, a subgroup (defined as a subset of the\ncovariate space) on which the average response or treatment effect is above a\ngiven threshold. E.g., in a clinical trial, it may be of interest to find a\nsubgroup with a positive average treatment effect. However, existing methods\neither lack inferential guarantees, heavily restrict the search for the\nsubgroup, or sacrifice efficiency by naive data splitting. We propose a novel\nframework called chiseling that allows the analyst to interactively refine and\ntest a candidate subgroup by iteratively shrinking it. The sole restriction is\nthat the shrinkage direction only depends on the points outside the current\nsubgroup, but otherwise the analyst may leverage any prior information or\nmachine learning algorithm. Despite this flexibility, chiseling controls the\nprobability that the discovered subgroup is null (e.g., has a non-positive\naverage treatment effect) under minimal assumptions: for example, in randomized\nexperiments, this inferential validity guarantee holds under only bounded\nmoment conditions. When applied to a variety of simulated datasets and a real\nsurvey experiment, chiseling identifies substantially better subgroups than\nexisting methods with inferential guarantees.", "published": "2025-09-23 18:52:05", "link": "http://arxiv.org/abs/2509.19490v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Anchored Langevin Algorithms", "abstract": "Standard first-order Langevin algorithms such as the unadjusted Langevin\nalgorithm (ULA) are obtained by discretizing the Langevin diffusion and are\nwidely used for sampling in machine learning because they scale to high\ndimensions and large datasets. However, they face two key limitations: (i) they\nrequire differentiable log-densities, excluding targets with non-differentiable\ncomponents; and (ii) they generally fail to sample heavy-tailed targets. We\npropose anchored Langevin dynamics, a unified approach that accommodates\nnon-differentiable targets and certain classes of heavy-tailed distributions.\nThe method replaces the original potential with a smooth reference potential\nand modifies the Langevin diffusion via multiplicative scaling. We establish\nnon-asymptotic guarantees in the 2-Wasserstein distance to the target\ndistribution and provide an equivalent formulation derived via a random time\nchange of the Langevin diffusion. We provide numerical experiments to\nillustrate the theory and practical performance of our proposed approach.", "published": "2025-09-23 18:11:55", "link": "http://arxiv.org/abs/2509.19455v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation", "abstract": "This paper proposes a deep learning-based framework for near-field nulling\ncontrol beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate\nmulti-user interference (MUI). A dual-estimator architecture comprising two\nfully connected deep neural networks (FCDNNs) is developed to separately\npredict the phase and magnitude components of NCBF weights, using locations of\nboth desired and interfering users. The models are trained on a large dataset\ngenerated via a Linearly Constrained Minimum Variance (LCMV) beamforming\nalgorithm to accommodate diverse user configurations, including both collinear\nand non-collinear scenarios. Illustrative results demonstrate that the proposed\nDNN models achieve high prediction accuracy, with test errors of only 0.067\nradians for phase estimation and 0.206 dB for magnitude estimation. Full-wave\nsimulations incorporating realistic element radiation patterns and\ninter-element coupling confirm the close agreement between the beam patterns\nproduced by the DNN-predicted and LCMV-based NCBF schemes under practical\ndeployment conditions. An average MUI suppression of 36.7 dB is achieved, with\ninterference mitigation exceeding 17.5 dB across all tested cases. The proposed\napproach enables scalable and real-time beam focusing with effective\ninterference suppression, offering a promising solution for future near-field\nmulti-user wireless communications.", "published": "2025-09-23 21:31:34", "link": "http://arxiv.org/abs/2509.19594v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design", "abstract": "The landscape of global navigation satellite systems (GNSS) is expanding with\nthe emergence of low Earth orbit (LEO) constellations such as Pulsar, which are\nexpected to play a key role in the future of positioning, navigation, and\ntiming (PNT). LEO-based systems provide advantages including stronger signals\nfor greater robustness, faster dynamics that aid convergence and multipath\nmitigation, and shorter time to first fix (TTFF) enabled by high data rates.\nThese benefits, however, come with changes in signal behavior and constellation\ngeometry that require careful consideration in receiver design. This paper\ninvestigates Pulsar properties using a GNSS simulator, analyzing parameters\nsuch as satellite pass duration, elevation, Doppler shift, Doppler rate, range,\nand number of satellites in view. Comparisons with GPS highlight the\ndifferences introduced by LEO operation. The analysis examines temporal\nevolution, statistical distributions, and maximum and minimum values. Beyond\nthese statistical insights, the study explores interdependencies between\nparameters and differences across satellites, providing additional perspective.\nEvaluations are performed at multiple latitudes to ensure a worldwide\nperspective, and the impact of applying different elevation masks is discussed\nwhere relevant. Building on these findings, the paper assesses Pulsar's impact\non receiver design from two standpoints: design considerations, addressing\nexpanded Doppler ranges, higher Doppler rates, and unique constellation\nstructure; and design optimizations, exploiting parameter analyses and\ninterdependencies (e.g., Doppler rate vs Doppler) to refine acquisition\nstrategies and applying prediction and prioritization techniques to avoid\nunnecessary computations. Together, these optimizations can reduce acquisition\ntime and lower receiver power consumption.", "published": "2025-09-23 20:24:53", "link": "http://arxiv.org/abs/2509.19551v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces", "abstract": "Individual differences in brain activity hinder the online application of\nelectroencephalogram (EEG)-based brain computer interface (BCI) systems. To\novercome this limitation, this study proposes an online adaptation algorithm\nfor unseen subjects via dual-stage alignment and self-supervision. The\nalignment process begins by applying Euclidean alignment in the EEG data space\nand then updates batch normalization statistics in the representation space.\nMoreover, a self-supervised loss is designed to update the decoder. The loss is\ncomputed by soft pseudo-labels derived from the decoder as a proxy for the\nunknown ground truth, and is calibrated by Shannon entropy to facilitate\nself-supervised training. Experiments across five public datasets and seven\ndecoders show the proposed algorithm can be integrated seamlessly regardless of\nBCI paradigm and decoder architecture. In each iteration, the decoder is\nupdated with a single online trial, which yields average accuracy gains of 4.9%\non steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.\nThese results support fast-calibration operation and show that the proposed\nalgorithm has great potential for BCI applications.", "published": "2025-09-23 07:38:37", "link": "http://arxiv.org/abs/2509.19403v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs", "abstract": "Electroencephalogram (EEG)-based P300 speller brain-computer interfaces\n(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor\ngeneralization, and time-consuming calibration. We propose SpellerSSL, a\nframework that combines self-supervised learning (SSL) with P300 aggregation to\naddress these issues. First, we introduce an aggregation strategy to enhance\nSNR. Second, to achieve generalization in training, we employ a customized 1D\nU-Net backbone and pretrain the model on both cross-domain and in-domain EEG\ndata. The pretrained model is subsequently fine-tuned with a lightweight\nERP-Head classifier for P300 detection, which adapts the learned\nrepresentations to subject-specific data. Our evaluations on calibration time\ndemonstrate that combining the aggregation strategy with SSL significantly\nreduces the calibration burden per subject and improves robustness across\nsubjects. Experimental results show that SSL learns effective EEG\nrepresentations in both in-domain and cross-domain, with in-domain achieving a\nstate-of-the-art character recognition rate of 94% with only 7 repetitions and\nthe highest information transfer rate (ITR) of 21.86 bits/min on the public\nII-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the\nrequired calibration size by 60% while maintaining a comparable character\nrecognition rate. To the best of our knowledge, this is the first study to\napply SSL to P300 spellers, highlighting its potential to improve both\nefficiency and generalization in speller BCIs and paving the way toward an EEG\nfoundation model for P300 speller BCIs.", "published": "2025-09-23 06:28:44", "link": "http://arxiv.org/abs/2509.19401v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG", "abstract": "Myocardial infarction is a critical manifestation of coronary artery disease,\nyet detecting it from single-lead electrocardiogram (ECG) remains challenging\ndue to limited spatial information. An intuitive idea is to convert single-lead\ninto multiple-lead ECG for classification by pre-trained models, but generative\nmethods optimized at the signal level in most cases leave a large latent space\ngap, ultimately degrading diagnostic performance. This naturally raises the\nquestion of whether latent space alignment could help. However, most prior ECG\nalignment methods focus on learning transformation invariance, which mismatches\nthe goal of single-lead detection. To address this issue, we propose SelfMIS, a\nsimple yet effective alignment learning framework to improve myocardial\ninfarction detection from single-lead ECG. Discarding manual data\naugmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead\nECG with their corresponding single-lead segments and directly align them in\nthe latent space. This design shifts the learning objective from pursuing\ntransformation invariance to enriching the single-lead representation,\nexplicitly driving the single-lead ECG encoder to learn a representation\ncapable of inferring global cardiac context from the local signal.\nExperimentally, SelfMIS achieves superior performance over baseline models\nacross nine myocardial infarction types while maintaining a simpler\narchitecture and lower computational overhead, thereby substantiating the\nefficacy of direct latent space alignment. Our code and checkpoint will be\npublicly available after acceptance.", "published": "2025-09-23 03:54:39", "link": "http://arxiv.org/abs/2509.19397v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
