{"title": "Efficient Adaptation of Pretrained Transformers for Abstractive\n  Summarization", "abstract": "Large-scale learning of transformer language models has yielded improvements\non a variety of natural language understanding tasks. Whether they can be\neffectively adapted for summarization, however, has been less explored, as the\nlearned representations are less seamlessly integrated into existing neural\ntext production architectures. In this work, we propose two solutions for\nefficiently adapting pretrained transformer language models as text\nsummarizers: source embeddings and domain-adaptive training. We test these\nsolutions on three abstractive summarization datasets, achieving new state of\nthe art performance on two of them. Finally, we show that these improvements\nare achieved by producing more focused summaries with fewer superfluous and\nthat performance improvements are more pronounced on more abstractive datasets.", "published": "2019-06-01 03:05:31", "link": "http://arxiv.org/abs/1906.00138v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Generation and Encoding of Nested Texts", "abstract": "In this paper we propose a new language model called AGENT, which stands for\nAdversarial Generation and Encoding of Nested Texts. AGENT is designed for\nencoding, generating and refining documents that consist of a long and coherent\ntext, such as an entire book, provided they are hierarchically annotated\n(nested). i.e. divided into sentences, paragraphs and chapters. The core idea\nof our system is learning vector representations for each level of the text\nhierarchy (sentences, paragraphs, etc...), and train each such representation\nto perform 3 tasks: The task of reconstructing the sequence of vectors from a\nlower level that was used to create the representation, and generalized\nversions of the Masked Language Modeling (MLM) and \"Next Sentence Prediction\"\ntasks from BERT Devlin et al. [2018]. Additionally we present a new adversarial\nmodel for long text generation and suggest a way to improve the coherence of\nthe generated text by traversing its vector representation tree.", "published": "2019-06-01 15:01:16", "link": "http://arxiv.org/abs/1906.00238v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COS960: A Chinese Word Similarity Dataset of 960 Word Pairs", "abstract": "Word similarity computation is a widely recognized task in the field of\nlexical semantics. Most proposed tasks test on similarity of word pairs of\nsingle morpheme, while few works focus on words of two morphemes or more\nmorphemes. In this work, we propose COS960, a benchmark dataset with 960 pairs\nof Chinese wOrd Similarity, where all the words have two morphemes in three\nPart of Speech (POS) tags with their human annotated similarity rather than\nrelatedness. We give a detailed description of dataset construction and\nannotation process, and test on a range of word embedding models. The dataset\nof this paper can be obtained from https://github.com/thunlp/COS960.", "published": "2019-06-01 15:37:19", "link": "http://arxiv.org/abs/1906.00247v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to best use Syntax in Semantic Role Labelling", "abstract": "There are many different ways in which external information might be used in\nan NLP task. This paper investigates how external syntactic information can be\nused most effectively in the Semantic Role Labeling (SRL) task. We evaluate\nthree different ways of encoding syntactic parses and three different ways of\ninjecting them into a state-of-the-art neural ELMo-based SRL sequence labelling\nmodel. We show that using a constituency representation as input features\nimproves performance the most, achieving a new state-of-the-art for\nnon-ensemble SRL models on the in-domain CoNLL'05 and CoNLL'12 benchmarks.", "published": "2019-06-01 18:35:12", "link": "http://arxiv.org/abs/1906.00266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"President Vows to Cut <Taxes> Hair\": Dataset and Analysis of Creative\n  Text Editing for Humorous Headlines", "abstract": "We introduce, release, and analyze a new dataset, called Humicroedit, for\nresearch in computational humor. Our publicly available data consists of\nregular English news headlines paired with versions of the same headlines that\ncontain simple replacement edits designed to make them funny. We carefully\ncurated crowdsourced editors to create funny headlines and judges to score a to\na total of 15,095 edited headlines, with five judges per headline. The simple\nedits, usually just a single word replacement, mean we can apply\nstraightforward analysis techniques to determine what makes our edited\nheadlines humorous. We show how the data support classic theories of humor,\nsuch as incongruity, superiority, and setup/punchline. Finally, we develop\nbaseline classifiers that can predict whether or not an edited headline is\nfunny, which is a first step toward automatically generating humorous headlines\nas an approach to creating topical humor.", "published": "2019-06-01 19:17:03", "link": "http://arxiv.org/abs/1906.00274v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Transformer for Unaligned Multimodal Language Sequences", "abstract": "Human language is often multimodal, which comprehends a mixture of natural\nlanguage, facial gestures, and acoustic behaviors. However, two major\nchallenges in modeling such multimodal human language time-series data exist:\n1) inherent data non-alignment due to variable sampling rates for the sequences\nfrom each modality; and 2) long-range dependencies between elements across\nmodalities. In this paper, we introduce the Multimodal Transformer (MulT) to\ngenerically address the above issues in an end-to-end manner without explicitly\naligning the data. At the heart of our model is the directional pairwise\ncrossmodal attention, which attends to interactions between multimodal\nsequences across distinct time steps and latently adapt streams from one\nmodality to another. Comprehensive experiments on both aligned and non-aligned\nmultimodal time-series show that our model outperforms state-of-the-art methods\nby a large margin. In addition, empirical analysis suggests that correlated\ncrossmodal signals are able to be captured by the proposed crossmodal attention\nmechanism in MulT.", "published": "2019-06-01 21:29:20", "link": "http://arxiv.org/abs/1906.00295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Retrieval for Weakly Supervised Open Domain Question Answering", "abstract": "Recent work on open domain question answering (QA) assumes strong supervision\nof the supporting evidence and/or assumes a blackbox information retrieval (IR)\nsystem to retrieve evidence candidates. We argue that both are suboptimal,\nsince gold evidence is not always available, and QA is fundamentally different\nfrom IR. We show for the first time that it is possible to jointly learn the\nretriever and reader from question-answer string pairs and without any IR\nsystem. In this setting, evidence retrieval from all of Wikipedia is treated as\na latent variable. Since this is impractical to learn from scratch, we\npre-train the retriever with an Inverse Cloze Task. We evaluate on open\nversions of five QA datasets. On datasets where the questioner already knows\nthe answer, a traditional IR system such as BM25 is sufficient. On datasets\nwhere a user is genuinely seeking an answer, we show that learned retrieval is\ncrucial, outperforming BM25 by up to 19 points in exact match.", "published": "2019-06-01 22:02:39", "link": "http://arxiv.org/abs/1906.00300v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Turn Beam Search for Neural Dialogue Modeling", "abstract": "In neural dialogue modeling, a neural network is trained to predict the next\nutterance, and at inference time, an approximate decoding algorithm is used to\ngenerate next utterances given previous ones. While this autoregressive\nframework allows us to model the whole conversation during training, inference\nis highly suboptimal, as a wrong utterance can affect future utterances. While\nbeam search yields better results than greedy search does, we argue that it is\nstill greedy in the context of the entire conversation, in that it does not\nconsider future utterances. We propose a novel approach for conversation-level\ninference by explicitly modeling the dialogue partner and running beam search\nacross multiple conversation turns. Given a set of candidates for next\nutterance, we unroll the conversation for a number of turns and identify the\ncandidate utterance in the initial hypothesis set that gives rise to the most\nlikely sequence of future utterances. We empirically validate our approach by\nconducting human evaluation using the Persona-Chat dataset, and find that our\nmulti-turn beam search generates significantly better dialogue responses. We\npropose three approximations to the partner model, and observe that more\ninformed partner models give better performance.", "published": "2019-06-01 03:31:26", "link": "http://arxiv.org/abs/1906.00141v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Promotion of Answer Value Measurement with Domain Effects in Community\n  Question Answering Systems", "abstract": "In the area of community question answering (CQA), answer selection and\nanswer ranking are two tasks which are applied to help users quickly access\nvaluable answers. Existing solutions mainly exploit the syntactic or semantic\ncorrelation between a question and its related answers (Q&A), where the\nmulti-facet domain effects in CQA are still underexplored. In this paper, we\npropose a unified model, Enhanced Attentive Recurrent Neural Network (EARNN),\nfor both answer selection and answer ranking tasks by taking full advantages of\nboth Q&A semantics and multi-facet domain effects (i.e., topic effects and\ntimeliness). Specifically, we develop a serialized LSTM to learn the unified\nrepresentations of Q&A, where two attention mechanisms at either sentence-level\nor word-level are designed for capturing the deep effects of topics. Meanwhile,\nthe emphasis of Q&A can be automatically distinguished. Furthermore, we design\na time-sensitive ranking function to model the timeliness in CQA. To\neffectively train EARNN, a question-dependent pairwise learning strategy is\nalso developed. Finally, we conduct extensive experiments on a real-world\ndataset from Quora. Experimental results validate the effectiveness and\ninterpretability of our proposed EARNN model.", "published": "2019-06-01 05:55:52", "link": "http://arxiv.org/abs/1906.00156v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Siamese recurrent networks learn first-order logic reasoning and exhibit\n  zero-shot compositional generalization", "abstract": "Can neural nets learn logic? We approach this classic question with current\nmethods, and demonstrate that recurrent neural networks can learn to recognize\nfirst order logical entailment relations between expressions. We define an\nartificial language in first-order predicate logic, generate a large dataset of\nsample 'sentences', and use an automatic theorem prover to infer the relation\nbetween random pairs of such sentences. We describe a Siamese neural\narchitecture trained to predict the logical relation, and experiment with\nrecurrent and recursive networks. Siamese Recurrent Networks are surprisingly\nsuccessful at the entailment recognition task, reaching near perfect\nperformance on novel sentences (consisting of known words), and even\noutperforming recursive networks. We report a series of experiments to test the\nability of the models to perform compositional generalization. In particular,\nwe study how they deal with sentences of unseen length, and sentences\ncontaining unseen words. We show that set-ups using LSTMs and GRUs obtain high\nscores on these tests, demonstrating a form of compositionality.", "published": "2019-06-01 08:17:42", "link": "http://arxiv.org/abs/1906.00180v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Biomedical Named Entity Recognition via Reference-Set Augmented\n  Bootstrapping", "abstract": "We present a weakly-supervised data augmentation approach to improve Named\nEntity Recognition (NER) in a challenging domain: extracting biomedical\nentities (e.g., proteins) from the scientific literature. First, we train a\nneural NER (NNER) model over a small seed of fully-labeled examples. Second, we\nuse a reference set of entity names (e.g., proteins in UniProt) to identify\nentity mentions with high precision, but low recall, on an unlabeled corpus.\nThird, we use the NNER model to assign weak labels to the corpus. Finally, we\nretrain our NNER model iteratively over the augmented training set, including\nthe seed, the reference-set examples, and the weakly-labeled examples, which\nimproves model performance. We show empirically that this augmented\nbootstrapping process significantly improves NER performance, and discuss the\nfactors impacting the efficacy of the approach.", "published": "2019-06-01 20:07:11", "link": "http://arxiv.org/abs/1906.00282v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning to Generate Grounded Visual Captions without Localization\n  Supervision", "abstract": "When automatically generating a sentence description for an image or video,\nit often remains unclear how well the generated caption is grounded, that is\nwhether the model uses the correct image regions to output particular words, or\nif the model is hallucinating based on priors in the dataset and/or the\nlanguage model. The most common way of relating image regions with words in\ncaption models is through an attention mechanism over the regions that are used\nas input to predict the next word. The model must therefore learn to predict\nthe attentional weights without knowing the word it should localize. This is\ndifficult to train without grounding supervision since recurrent models can\npropagate past information and there is no explicit signal to force the\ncaptioning model to properly ground the individual decoded words. In this work,\nwe help the model to achieve this via a novel cyclical training regimen that\nforces the model to localize each word in the image after the sentence decoder\ngenerates it, and then reconstruct the sentence from the localized image\nregion(s) to match the ground-truth. Our proposed framework only requires\nlearning one extra fully-connected layer (the localizer), a layer that can be\nremoved at test time. We show that our model significantly improves grounding\naccuracy without relying on grounding supervision or introducing extra\ncomputation during inference, for both image and video captioning tasks. Code\nis available at https://github.com/chihyaoma/cyclical-visual-captioning .", "published": "2019-06-01 20:21:24", "link": "http://arxiv.org/abs/1906.00283v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Super-resolution of Time-series Labels for Bootstrapped Event Detection", "abstract": "Solving real-world problems, particularly with deep learning, relies on the\navailability of abundant, quality data. In this paper we develop a novel\nframework that maximises the utility of time-series datasets that contain only\nsmall quantities of expertly-labelled data, larger quantities of weakly (or\ncoarsely) labelled data and a large volume of unlabelled data. This represents\nscenarios commonly encountered in the real world, such as in crowd-sourcing\napplications. In our work, we use a nested loop using a Kernel Density\nEstimator (KDE) to super-resolve the abundant low-quality data labels, thereby\nenabling effective training of a Convolutional Neural Network (CNN). We\ndemonstrate two key results: a) The KDE is able to super-resolve labels more\naccurately, and with better calibrated probabilities, than well-established\nclassifiers acting as baselines; b) Our CNN, trained on super-resolved labels\nfrom the KDE, achieves an improvement in F1 score of 22.1% over the next best\nbaseline system in our candidate problem domain.", "published": "2019-06-01 16:29:50", "link": "http://arxiv.org/abs/1906.00254v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
