{"title": "Cloze-driven Pretraining of Self-attention Networks", "abstract": "We present a new approach for pretraining a bi-directional transformer model\nthat provides significant performance gains across a variety of language\nunderstanding problems. Our model solves a cloze-style word reconstruction\ntask, where each word is ablated and must be predicted given the rest of the\ntext. Experiments demonstrate large performance gains on GLUE and new state of\nthe art results on NER as well as constituency parsing benchmarks, consistent\nwith the concurrently introduced BERT model. We also present a detailed\nanalysis of a number of factors that contribute to effective pretraining,\nincluding data domain and size, model capacity, and variations on the cloze\nobjective.", "published": "2019-03-19 01:19:06", "link": "http://arxiv.org/abs/1903.07785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Approaches for our Participation to the n2c2 Challenge on Cohort\n  Selection for Clinical Trials", "abstract": "Objective: Natural language processing can help minimize human intervention\nin identifying patients meeting eligibility criteria for clinical trials, but\nthere is still a long way to go to obtain a general and systematic approach\nthat is useful for researchers. We describe two methods taking a step in this\ndirection and present their results obtained during the n2c2 challenge on\ncohort selection for clinical trials. Materials and Methods: The first method\nis a weakly supervised method using an unlabeled corpus (MIMIC) to build a\nsilver standard, by producing semi-automatically a small and very precise set\nof rules to detect some samples of positive and negative patients. This silver\nstandard is then used to train a traditional supervised model. The second\nmethod is a terminology-based approach where a medical expert selects the\nappropriate concepts, and a procedure is defined to search the terms and check\nthe structural or temporal constraints. Results: On the n2c2 dataset containing\nannotated data about 13 selection criteria on 288 patients, we obtained an\noverall F1-measure of 0.8969, which is the third best result out of 45\nparticipant teams, with no statistically significant difference with the\nbest-ranked team. Discussion: Both approaches obtained very encouraging results\nand apply to different types of criteria. The weakly supervised method requires\nexplicit descriptions of positive and negative examples in some reports. The\nterminology-based method is very efficient when medical concepts carry most of\nthe relevant information. Conclusion: It is unlikely that much more annotated\ndata will be soon available for the task of identifying a wide range of patient\nphenotypes. One must focus on weakly or non-supervised learning methods using\nboth structured and unstructured data and relying on a comprehensive\nrepresentation of the patients.", "published": "2019-03-19 08:37:04", "link": "http://arxiv.org/abs/1903.07879v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CVIT-MT Systems for WAT-2018", "abstract": "This document describes the machine translation system used in the\nsubmissions of IIIT-Hyderabad CVIT-MT for the WAT-2018 English-Hindi\ntranslation task. Performance is evaluated on the associated corpus provided by\nthe organizers. We experimented with convolutional sequence to sequence\narchitectures. We also train with additional data obtained through\nbacktranslation.", "published": "2019-03-19 10:18:57", "link": "http://arxiv.org/abs/1903.07917v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "compare-mt: A Tool for Holistic Comparison of Language Generation\n  Systems", "abstract": "In this paper, we describe compare-mt, a tool for holistic analysis and\ncomparison of the results of systems for language generation tasks such as\nmachine translation. The main goal of the tool is to give the user a high-level\nand coherent view of the salient differences between systems that can then be\nused to guide further analysis or system improvement. It implements a number of\ntools to do so, such as analysis of accuracy of generation of particular types\nof words, bucketed histograms of sentence accuracies or counts based on salient\ncharacteristics, and extraction of characteristic $n$-grams for each system. It\nalso has a number of advanced features such as use of linguistic labels, source\nside data, or comparison of log likelihoods for probabilistic models, and also\naims to be easily extensible by users to new types of analysis. The code is\navailable at https://github.com/neulab/compare-mt", "published": "2019-03-19 10:40:23", "link": "http://arxiv.org/abs/1903.07926v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation at Scale: A Case Study for Open Domain\n  Question Answering", "abstract": "Current approaches to Natural Language Generation (NLG) for dialog mainly\nfocus on domain-specific, task-oriented applications (e.g. restaurant booking)\nusing limited ontologies (up to 20 slot types), usually without considering the\nprevious conversation context. Furthermore, these approaches require large\namounts of data for each domain, and do not benefit from examples that may be\navailable for other domains. This work explores the feasibility of applying\nstatistical NLG to scenarios requiring larger ontologies, such as multi-domain\ndialog applications or open-domain question answering (QA) based on knowledge\ngraphs. We model NLG through an Encoder-Decoder framework using a large dataset\nof interactions between real-world users and a conversational agent for\nopen-domain QA. First, we investigate the impact of increasing the number of\nslot types on the generation quality and experiment with different partitions\nof the QA data with progressively larger ontologies (up to 369 slot types).\nSecond, we perform multi-task learning experiments between open-domain QA and\ntask-oriented dialog, and benchmark our model on a popular NLG dataset.\nMoreover, we experiment with using the conversational context as an additional\ninput to improve response generation quality. Our experiments show the\nfeasibility of learning statistical NLG models for open-domain QA with larger\nontologies.", "published": "2019-03-19 16:35:29", "link": "http://arxiv.org/abs/1903.08097v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When redundancy is useful: A Bayesian approach to 'overinformative'\n  referring expressions", "abstract": "Referring is one of the most basic and prevalent uses of language. How do\nspeakers choose from the wealth of referring expressions at their disposal?\nRational theories of language use have come under attack for decades for not\nbeing able to account for the seemingly irrational overinformativeness\nubiquitous in referring expressions. Here we present a novel production model\nof referring expressions within the Rational Speech Act framework that treats\nspeakers as agents that rationally trade off cost and informativeness of\nutterances. Crucially, we relax the assumption that informativeness is computed\nwith respect to a deterministic Boolean semantics, in favor of a\nnon-deterministic continuous semantics. This innovation allows us to capture a\nlarge number of seemingly disparate phenomena within one unified framework: the\nbasic asymmetry in speakers' propensity to overmodify with color rather than\nsize; the increase in overmodification in complex scenes; the increase in\novermodification with atypical features; and the increase in specificity in\nnominal reference as a function of typicality. These findings cast a new light\non the production of referring expressions: rather than being wastefully\noverinformative, reference is usefully redundant.", "published": "2019-03-19 19:49:12", "link": "http://arxiv.org/abs/1903.08237v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bidirectional Recurrent Models for Offensive Tweet Classification", "abstract": "In this paper we propose four deep recurrent architectures to tackle the task\nof offensive tweet detection as well as further classification into targeting\nand subject of said targeting. Our architectures are based on LSTMs and GRUs,\nwe present a simple bidirectional LSTM as a baseline system and then further\nincrease the complexity of the models by adding convolutional layers and\nimplementing a split-process-merge architecture with LSTM and GRU as\nprocessors. Multiple pre-processing techniques were also investigated. The\nvalidation F1-score results from each model are presented for the three\nsubtasks as well as the final F1-score performance on the private competition\ntest set. It was found that model complexity did not necessarily yield better\nresults. Our best-performing model was also the simplest, a bidirectional LSTM;\nclosely followed by a two-branch bidirectional LSTM and GRU architecture.", "published": "2019-03-19 17:31:44", "link": "http://arxiv.org/abs/1903.08808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in\n  Social Media (OffensEval)", "abstract": "We present the results and the main findings of SemEval-2019 Task 6 on\nIdentifying and Categorizing Offensive Language in Social Media (OffensEval).\nThe task was based on a new dataset, the Offensive Language Identification\nDataset (OLID), which contains over 14,000 English tweets. It featured three\nsub-tasks. In sub-task A, the goal was to discriminate between offensive and\nnon-offensive posts. In sub-task B, the focus was on the type of offensive\ncontent in the post. Finally, in sub-task C, systems had to detect the target\nof the offensive posts. OffensEval attracted a large number of participants and\nit was one of the most popular tasks in SemEval-2019. In total, about 800 teams\nsigned up to participate in the task, and 115 of them submitted results, which\nwe present and analyze in this report.", "published": "2019-03-19 20:22:02", "link": "http://arxiv.org/abs/1903.08983v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning Biomedical Metadata with Ontologies Using Clustering and\n  Embeddings", "abstract": "The metadata about scientific experiments published in online repositories\nhave been shown to suffer from a high degree of representational\nheterogeneity---there are often many ways to represent the same type of\ninformation, such as a geographical location via its latitude and longitude. To\nharness the potential that metadata have for discovering scientific data, it is\ncrucial that they be represented in a uniform way that can be queried\neffectively. One step toward uniformly-represented metadata is to normalize the\nmultiple, distinct field names used in metadata (e.g., lat lon, lat and long)\nto describe the same type of value. To that end, we present a new method based\non clustering and embeddings (i.e., vector representations of words) to align\nmetadata field names with ontology terms. We apply our method to biomedical\nmetadata by generating embeddings for terms in biomedical ontologies from the\nBioPortal repository. We carried out a comparative study between our method and\nthe NCBO Annotator, which revealed that our method yields more and\nsubstantially better alignments between metadata and ontology terms.", "published": "2019-03-19 18:31:23", "link": "http://arxiv.org/abs/1903.08206v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Simple, Fast, Accurate Intent Classification and Slot Labeling for\n  Goal-Oriented Dialogue Systems", "abstract": "With the advent of conversational assistants, like Amazon Alexa, Google Now,\netc., dialogue systems are gaining a lot of traction, especially in industrial\nsetting. These systems typically consist of Spoken Language understanding\ncomponent which, in turn, consists of two tasks - Intent Classification (IC)\nand Slot Labeling (SL). Generally, these two tasks are modeled together jointly\nto achieve best performance. However, this joint modeling adds to model\nobfuscation. In this work, we first design framework for a modularization of\njoint IC-SL task to enhance architecture transparency. Then, we explore a\nnumber of self-attention, convolutional, and recurrent models, contributing a\nlarge-scale analysis of modeling paradigms for IC+SL across two datasets.\nFinally, using this framework, we propose a class of 'label-recurrent' models\nthat otherwise non-recurrent, with a 10-dimensional representation of the label\nhistory, and show that our proposed systems are easy to interpret, highly\naccurate (achieving over 30% error reduction in SL over the state-of-the-art on\nthe Snips dataset), as well as fast, at 2x the inference and 2/3 to 1/2 the\ntraining time of comparable recurrent models, thus giving an edge in critical\nreal-world systems.", "published": "2019-03-19 21:58:24", "link": "http://arxiv.org/abs/1903.08268v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Personalized Neural Embeddings for Collaborative Filtering with Text", "abstract": "Collaborative filtering (CF) is a core technique for recommender systems.\nTraditional CF approaches exploit user-item relations (e.g., clicks, likes, and\nviews) only and hence they suffer from the data sparsity issue. Items are\nusually associated with unstructured text such as article abstracts and product\nreviews. We develop a Personalized Neural Embedding (PNE) framework to exploit\nboth interactions and words seamlessly. We learn such embeddings of users,\nitems, and words jointly, and predict user preferences on items based on these\nlearned representations. PNE estimates the probability that a user will like an\nitem by two terms---behavior factors and semantic factors. On two real-world\ndatasets, PNE shows better performance than four state-of-the-art baselines in\nterms of three metrics. We also show that PNE learns meaningful word embeddings\nby visualization.", "published": "2019-03-19 07:05:59", "link": "http://arxiv.org/abs/1903.07860v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
