{"title": "MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction", "abstract": "Universal multimodal embedding models have achieved great success in\ncapturing semantic relevance between queries and candidates. However, current\nmethods either condense queries and candidates into a single vector,\npotentially limiting the expressiveness for fine-grained information, or\nproduce too many vectors that are prohibitively expensive for multi-vector\nretrieval. In this work, we introduce MetaEmbed, a new framework for multimodal\nretrieval that rethinks how multimodal embeddings are constructed and\ninteracted with at scale. During training, a fixed number of learnable Meta\nTokens are appended to the input sequence. At test-time, their last-layer\ncontextualized representations serve as compact yet expressive multi-vector\nembeddings. Through the proposed Matryoshka Multi-Vector Retrieval training,\nMetaEmbed learns to organize information by granularity across multiple\nvectors. As a result, we enable test-time scaling in multimodal retrieval,\nwhere users can balance retrieval quality against efficiency demands by\nselecting the number of tokens used for indexing and retrieval interactions.\nExtensive evaluations on the Massive Multimodal Embedding Benchmark (MMEB) and\nthe Visual Document Retrieval Benchmark (ViDoRe) confirm that MetaEmbed\nachieves state-of-the-art retrieval performance while scaling robustly to\nmodels with 32B parameters.", "published": "2025-09-22 17:59:42", "link": "http://arxiv.org/abs/2509.18095v1", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "SEQR: Secure and Efficient QR-based LoRA Routing", "abstract": "Low-Rank Adaptation (LoRA) has become a standard technique for\nparameter-efficient fine-tuning of large language models, enabling large\nlibraries of LoRAs, each for a specific task or domain. Efficiently selecting\nthe correct LoRA adapter for a given input remains a challenge, particularly in\nsecure environments where supervised training of routers may raise privacy\nconcerns. Motivated by previous approaches, we formalize the goal of\nunsupervised LoRA routing in terms of activation norm maximization, providing a\ntheoretical framework for analysis. We demonstrate the discriminative power of\nactivation norms and introduce SEQR, an unsupervised LoRA routing algorithm\ndesigned to maximize efficiency while providing strict routing guarantees. SEQR\nprovably identifies the norm-maximizing adapter with significantly greater\nefficiency, making it a highly scalable and effective solution for dynamic LoRA\ncomposition. We validate our results through experiments that demonstrate\nimproved multi-task performance and efficiency.", "published": "2025-09-22 17:59:38", "link": "http://arxiv.org/abs/2509.18093v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System", "abstract": "Despite the growing interest in replicating the scaled success of large\nlanguage models (LLMs) in industrial search and recommender systems, most\nexisting industrial efforts remain limited to transplanting Transformer\narchitectures, which bring only incremental improvements over strong Deep\nLearning Recommendation Models (DLRMs). From a first principle perspective, the\nbreakthroughs of LLMs stem not only from their architectures but also from two\ncomplementary mechanisms: context engineering, which enriches raw input queries\nwith contextual cues to better elicit model capabilities, and multi-step\nreasoning, which iteratively refines model outputs through intermediate\nreasoning paths. However, these two mechanisms and their potential to unlock\nsubstantial improvements remain largely underexplored in industrial ranking\nsystems.\n  In this paper, we propose OnePiece, a unified framework that seamlessly\nintegrates LLM-style context engineering and reasoning into both retrieval and\nranking models of industrial cascaded pipelines. OnePiece is built on a pure\nTransformer backbone and further introduces three key innovations: (1)\nstructured context engineering, which augments interaction history with\npreference and scenario signals and unifies them into a structured tokenized\ninput sequence for both retrieval and ranking; (2) block-wise latent reasoning,\nwhich equips the model with multi-step refinement of representations and scales\nreasoning bandwidth via block size; (3) progressive multi-task training, which\nleverages user feedback chains to effectively supervise reasoning steps during\ntraining. OnePiece has been deployed in the main personalized search scenario\nof Shopee and achieves consistent online gains across different key business\nmetrics, including over $+2\\%$ GMV/UU and a $+2.90\\%$ increase in advertising\nrevenue.", "published": "2025-09-22 17:59:07", "link": "http://arxiv.org/abs/2509.18091v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding", "abstract": "Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to\nautoregressive LLMs (AR-LLMs) with the potential to operate at significantly\nhigher token generation rates. However, currently available open-source dLLMs\noften generate at much lower rates, typically decoding only a single token at\nevery denoising timestep in order to maximize output quality. We present\nSpiffy, a speculative decoding algorithm that accelerates dLLM inference by\n$\\mathbf{2.8{-}3.1\\times}$ while provably preserving the model's output\ndistribution. This work addresses the unique challenges involved in applying\nideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes\ndraft states by leveraging the dLLM's distribution itself in an\nauto-speculative manner. This approach is efficient and effective, and\neliminates the overheads of training and running an independent draft model. To\nstructure the candidate draft states, we propose a novel directed draft graph\nwhich is uniquely designed to take advantage of the bidirectional, block-wise\nnature of dLLM generation and can be verified in parallel by the dLLM. To\nfurther optimize the structure of these draft graphs, we introduce an\nefficient, offline calibration algorithm that procedurally determines\nhigh-quality graph configurations. These optimized draft graphs, enabling\nincreased acceptance rates, lead to a significant boost in the overall speedup\nachieved by the system. Crucially, Spiffy is also complementary to other recent\ninnovations in improving dLLM generation speeds such as KV-caching and\nmulti-token unmasking. We demonstrate that when combined with such parallel\ndecoding algorithms, Spiffy is able to effectively multiply the benefits of\nthese methods leading to total speedups of up to $\\mathbf{7.9\\times}$.", "published": "2025-09-22 17:58:21", "link": "http://arxiv.org/abs/2509.18085v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning", "abstract": "We introduce Reasoning Core, a new scalable environment for Reinforcement\nLearning with Verifiable Rewards (RLVR), designed to advance foundational\nsymbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks\nthat focus on games or isolated puzzles, Reasoning Core procedurally generates\nproblems across core formal domains, including PDDL planning, first-order\nlogic, context-free grammar parsing, causal reasoning, and system equation\nsolving. The environment is built on key design principles of high-generality\nproblem distributions, verification via external tools, and continuous\ndifficulty control, which together provide a virtually infinite supply of novel\ntraining instances. Initial zero-shot evaluations with frontier LLMs confirm\nthe difficulty of Reasoning Core's tasks, positioning it as a promising\nresource to improve the reasoning capabilities of future models.", "published": "2025-09-22 17:56:38", "link": "http://arxiv.org/abs/2509.18083v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning", "abstract": "Large Language Models (LLMs) show strong reasoning abilities but rely on\ninternalized knowledge that is often insufficient, outdated, or incorrect when\ntrying to answer a question that requires specific domain knowledge. Knowledge\nGraphs (KGs) provide structured external knowledge, yet their complexity and\nmulti-hop reasoning requirements make integration challenging. We present\nARK-V1, a simple KG-agent that iteratively explores graphs to answer natural\nlanguage queries. We evaluate several not fine-tuned state-of-the art LLMs as\nbackbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based and\ncommonsense reasoning over long-tail entities. ARK-V1 achieves substantially\nhigher conditional accuracies than Chain-of-Thought baselines, and larger\nbackbone models show a clear trend toward better coverage, correctness, and\nstability.", "published": "2025-09-22 17:40:05", "link": "http://arxiv.org/abs/2509.18063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \u00dc-Tsang, Amdo and Kham Speech Dataset Generation", "abstract": "Tibetan is a low-resource language with limited parallel speech corpora\nspanning its three major dialects (\\\"U-Tsang, Amdo, and Kham), limiting\nprogress in speech modeling. To address this issue, we propose TMD-TTS, a\nunified Tibetan multi-dialect text-to-speech (TTS) framework that synthesizes\nparallel dialectal speech from explicit dialect labels. Our method features a\ndialect fusion module and a Dialect-Specialized Dynamic Routing Network\n(DSDR-Net) to capture fine-grained acoustic and linguistic variations across\ndialects. Extensive objective and subjective evaluations demonstrate that\nTMD-TTS significantly outperforms baselines in dialectal expressiveness. We\nfurther validate the quality and utility of the synthesized speech through a\nchallenging Speech-to-Speech Dialect Conversion (S2SDC) task.", "published": "2025-09-22 17:38:52", "link": "http://arxiv.org/abs/2509.18060v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies", "abstract": "Large Language Models (LLMs) are increasingly used for social simulation,\nwhere populations of agents are expected to reproduce human-like collective\nbehavior. However, we find that many recent studies adopt experimental designs\nthat systematically undermine the validity of their claims. From a survey of\nover 40 papers, we identify six recurring methodological flaws: agents are\noften homogeneous (Profile), interactions are absent or artificially imposed\n(Interaction), memory is discarded (Memory), prompts tightly control outcomes\n(Minimal-Control), agents can infer the experimental hypothesis (Unawareness),\nand validation relies on simplified theoretical models rather than real-world\ndata (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying\nsocial experiment in 53.1% of cases when given instructions from prior\nwork-violating the Unawareness principle. We formalize these six requirements\nas the PIMMUR principles and argue they are necessary conditions for credible\nLLM-based social simulation. To demonstrate their impact, we re-run five\nrepresentative studies using a framework that enforces PIMMUR and find that the\nreported social phenomena frequently fail to emerge under more rigorous\nconditions. Our work establishes methodological standards for LLM-based\nmulti-agent research and provides a foundation for more reliable and\nreproducible claims about \"AI societies.\"", "published": "2025-09-22 17:27:29", "link": "http://arxiv.org/abs/2509.18052v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "RadEval: A framework for radiology text evaluation", "abstract": "We introduce RadEval, a unified, open-source framework for evaluating\nradiology texts. RadEval consolidates a diverse range of metrics, from classic\nn-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical\nconcept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT,\nTemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and\nstandardize implementations, extend GREEN to support multiple imaging\nmodalities with a more lightweight model, and pretrain a domain-specific\nradiology encoder, demonstrating strong zero-shot retrieval performance. We\nalso release a richly annotated expert dataset with over 450 clinically\nsignificant error labels and show how different metrics correlate with\nradiologist judgment. Finally, RadEval provides statistical testing tools and\nbaseline model evaluations across multiple publicly available datasets,\nfacilitating reproducibility and robust benchmarking in radiology report\ngeneration.", "published": "2025-09-22 17:03:48", "link": "http://arxiv.org/abs/2509.18030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Attention is Half Explanation in Speech-to-Text Models", "abstract": "Cross-attention is a core mechanism in encoder-decoder architectures,\nwidespread in many fields, including speech-to-text (S2T) processing. Its\nscores have been repurposed for various downstream applications--such as\ntimestamp estimation and audio-text alignment--under the assumption that they\nreflect the dependencies between input speech representation and the generated\ntext. While the explanatory nature of attention mechanisms has been widely\ndebated in the broader NLP literature, this assumption remains largely\nunexplored within the speech domain. To address this gap, we assess the\nexplanatory power of cross-attention in S2T models by comparing its scores to\ninput saliency maps derived from feature attribution. Our analysis spans\nmonolingual and multilingual, single-task and multi-task models at multiple\nscales, and shows that attention scores moderately to strongly align with\nsaliency-based explanations, particularly when aggregated across heads and\nlayers. However, it also shows that cross-attention captures only about 50% of\nthe input relevance and, in the best case, only partially reflects how the\ndecoder attends to the encoder's representations--accounting for just 52-75% of\nthe saliency. These findings uncover fundamental limitations in interpreting\ncross-attention as an explanatory proxy, suggesting that it offers an\ninformative yet incomplete view of the factors driving predictions in S2T\nmodels.", "published": "2025-09-22 16:49:26", "link": "http://arxiv.org/abs/2509.18010v1", "categories": ["cs.CL", "cs.AI", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration", "abstract": "Intelligent systems have traditionally been designed as tools rather than\ncollaborators, often lacking critical characteristics that collaboration\npartnerships require. Recent advances in large language model (LLM) agents open\nnew opportunities for human-LLM-agent collaboration by enabling natural\ncommunication and various social and cognitive behaviors. Yet it remains\nunclear whether principles of computer-mediated collaboration established in\nHCI and CSCW persist, change, or fail when humans collaborate with LLM agents.\nTo support systematic investigations of these questions, we introduce an open\nand configurable research platform for HCI researchers. The platform's modular\ndesign allows seamless adaptation of classic CSCW experiments and manipulation\nof theory-grounded interaction controls. We demonstrate the platform's\neffectiveness and usability through two case studies: (1) re-implementing the\nclassic human-human-collaboration task Shape Factory as a between-subject\nhuman-agent-collaboration experiment with 16 participants, and (2) a\nparticipatory cognitive walkthrough with five HCI researchers to refine\nworkflows and interfaces for experiment setup and analysis.", "published": "2025-09-22 16:47:08", "link": "http://arxiv.org/abs/2509.18008v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing", "abstract": "The scarcity of large-scale, open-source data for dialects severely hinders\nprogress in speech technology, a challenge particularly acute for the widely\nspoken Sichuanese dialects of Chinese. To address this critical gap, we\nintroduce WenetSpeech-Chuan, a 10,000-hour, richly annotated corpus constructed\nusing our novel Chuan-Pipeline, a complete data processing framework for\ndialectal speech. To facilitate rigorous evaluation and demonstrate the\ncorpus's effectiveness, we also release high-quality ASR and TTS benchmarks,\nWenetSpeech-Chuan-Eval, with manually verified transcriptions. Experiments show\nthat models trained on WenetSpeech-Chuan achieve state-of-the-art performance\namong open-source systems and demonstrate results comparable to commercial\nservices. As the largest open-source corpus for Sichuanese dialects,\nWenetSpeech-Chuan not only lowers the barrier to research in dialectal speech\nprocessing but also plays a crucial role in promoting AI equity and mitigating\nbias in speech technologies. The corpus, benchmarks, models, and receipts are\npublicly available on our project page.", "published": "2025-09-22 16:44:00", "link": "http://arxiv.org/abs/2509.18004v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Variation in Verification: Understanding Verification Dynamics in Large Language Models", "abstract": "Recent advances have shown that scaling test-time computation enables large\nlanguage models (LLMs) to solve increasingly complex problems across diverse\ndomains. One effective paradigm for test-time scaling (TTS) involves LLM\ngenerators producing multiple solution candidates, with LLM verifiers assessing\nthe correctness of these candidates without reference answers. In this paper,\nwe study generative verifiers, which perform verification by generating\nchain-of-thought (CoT) reasoning followed by a binary verdict. We\nsystematically analyze verification dynamics across three dimensions - problem\ndifficulty, generator capability, and verifier generation capability - with\nempirical studies on 12 benchmarks across mathematical reasoning, knowledge,\nand natural language reasoning tasks using 14 open-source models (2B to 72B\nparameter range) and GPT-4o. Our experiments reveal three key findings about\nverification effectiveness: (1) Easy problems allow verifiers to more reliably\ncertify correct responses; (2) Weak generators produce errors that are easier\nto detect than strong generators; (3) Verification ability is generally\ncorrelated with the verifier's own problem-solving capability, but this\nrelationship varies with problem difficulty. These findings reveal\nopportunities to optimize basic verification strategies in TTS applications.\nFirst, given the same verifier, some weak generators can nearly match stronger\nones in post-verification TTS performance (e.g., the Gemma2-9B to Gemma2-27B\nperformance gap shrinks by 75.5%). Second, we identify cases where strong\nverifiers offer limited advantage over weak ones, as both fail to provide\nmeaningful verification gains, suggesting that verifier scaling alone cannot\novercome fundamental verification challenges.", "published": "2025-09-22 16:36:56", "link": "http://arxiv.org/abs/2509.17995v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReDepress: A Cognitive Framework for Detecting Depression Relapse from Social Media", "abstract": "Almost 50% depression patients face the risk of going into relapse. The risk\nincreases to 80% after the second episode of depression. Although, depression\ndetection from social media has attained considerable attention, depression\nrelapse detection has remained largely unexplored due to the lack of curated\ndatasets and the difficulty of distinguishing relapse and non-relapse users. In\nthis work, we present ReDepress, the first clinically validated social media\ndataset focused on relapse, comprising 204 Reddit users annotated by mental\nhealth professionals. Unlike prior approaches, our framework draws on cognitive\ntheories of depression, incorporating constructs such as attention bias,\ninterpretation bias, memory bias and rumination into both annotation and\nmodeling. Through statistical analyses and machine learning experiments, we\ndemonstrate that cognitive markers significantly differentiate relapse and\nnon-relapse groups, and that models enriched with these features achieve\ncompetitive performance, with transformer-based temporal models attaining an F1\nof 0.86. Our findings validate psychological theories in real-world textual\ndata and underscore the potential of cognitive-informed computational methods\nfor early relapse detection, paving the way for scalable, low-cost\ninterventions in mental healthcare.", "published": "2025-09-22 16:33:59", "link": "http://arxiv.org/abs/2509.17991v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments", "abstract": "Asynchronous learning environments (ALEs) are widely adopted for formal and\ninformal learning, but timely and personalized support is often limited. In\nthis context, Virtual Teaching Assistants (VTAs) can potentially reduce the\nworkload of instructors, but rigorous and pedagogically sound evaluation is\nessential. Existing assessments often rely on surface-level metrics and lack\nsufficient grounding in educational theories, making it difficult to\nmeaningfully compare the pedagogical effectiveness of different VTA systems. To\nbridge this gap, we propose an evaluation framework rooted in learning sciences\nand tailored to asynchronous forum discussions, a common VTA deployment context\nin ALE. We construct classifiers using expert annotations of VTA responses on a\ndiverse set of forum posts. We evaluate the effectiveness of our classifiers,\nidentifying approaches that improve accuracy as well as challenges that hinder\ngeneralization. Our work establishes a foundation for theory-driven evaluation\nof VTA systems, paving the way for more pedagogically effective AI in\neducation.", "published": "2025-09-22 16:15:58", "link": "http://arxiv.org/abs/2509.17961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dorabella Cipher as Musical Inspiration", "abstract": "The Dorabella cipher is an encrypted note written by English composer Edward\nElgar, which has defied decipherment attempts for more than a century. While\nmost proposed solutions are English texts, we investigate the hypothesis that\nDorabella represents enciphered music. We weigh the evidence for and against\nthe hypothesis, devise a simplified music notation, and attempt to reconstruct\na melody from the cipher. Our tools are n-gram models of music which we\nvalidate on existing music corpora enciphered using monoalphabetic\nsubstitution. By applying our methods to Dorabella, we produce a decipherment\nwith musical qualities, which is then transformed via artful composition into a\nlistenable melody. Far from arguing that the end result represents the only\ntrue solution, we instead frame the process of decipherment as part of the\ncomposition process.", "published": "2025-09-22 16:09:26", "link": "http://arxiv.org/abs/2509.17950v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HICode: Hierarchical Inductive Coding with LLMs", "abstract": "Despite numerous applications for fine-grained corpus analysis, researchers\ncontinue to rely on manual labeling, which does not scale, or statistical tools\nlike topic modeling, which are difficult to control. We propose that LLMs have\nthe potential to scale the nuanced analyses that researchers typically conduct\nmanually to large text corpora. To this effect, inspired by qualitative\nresearch methods, we develop HICode, a two-part pipeline that first inductively\ngenerates labels directly from analysis data and then hierarchically clusters\nthem to surface emergent themes. We validate this approach across three diverse\ndatasets by measuring alignment with human-constructed themes and demonstrating\nits robustness through automated and human evaluations. Finally, we conduct a\ncase study of litigation documents related to the ongoing opioid crisis in the\nU.S., revealing aggressive marketing strategies employed by pharmaceutical\ncompanies and demonstrating HICode's potential for facilitating nuanced\nanalyses in large-scale data.", "published": "2025-09-22 16:07:11", "link": "http://arxiv.org/abs/2509.17946v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models", "abstract": "The safety and alignment of Large Language Models (LLMs) are critical for\ntheir responsible deployment. Current evaluation methods predominantly focus on\nidentifying and preventing overtly harmful outputs. However, they often fail to\naddress a more insidious failure mode: models that produce benign-appearing\noutputs while operating on malicious or deceptive internal reasoning. This\nvulnerability, often triggered by sophisticated system prompt injections,\nallows models to bypass conventional safety filters, posing a significant,\nunderexplored risk. To address this gap, we introduce the Deceptive Reasoning\nExposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy\nbetween a model's internal reasoning process and its final output. D-REX was\nconstructed through a competitive red-teaming exercise where participants\ncrafted adversarial system prompts to induce such deceptive behaviors. Each\nsample in D-REX contains the adversarial system prompt, an end-user's test\nquery, the model's seemingly innocuous response, and, crucially, the model's\ninternal chain-of-thought, which reveals the underlying malicious intent. Our\nbenchmark facilitates a new, essential evaluation task: the detection of\ndeceptive alignment. We demonstrate that D-REX presents a significant challenge\nfor existing models and safety mechanisms, highlighting the urgent need for new\ntechniques that scrutinize the internal processes of LLMs, not just their final\noutputs.", "published": "2025-09-22 15:59:40", "link": "http://arxiv.org/abs/2509.17938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training-free Truthfulness Detection via Value Vectors in LLMs", "abstract": "Large language models often generate factually incorrect outputs, motivating\nefforts to detect the truthfulness of their content. Most existing approaches\nrely on training probes over internal activations, but these methods suffer\nfrom scalability and generalization issues. A recent training-free method,\nNoVo, addresses this challenge by exploiting statistical patterns from the\nmodel itself. However, it focuses exclusively on attention mechanisms,\npotentially overlooking the MLP module-a core component of Transformer models\nknown to support factual recall. In this paper, we show that certain value\nvectors within MLP modules exhibit truthfulness-related statistical patterns.\nBuilding on this insight, we propose TruthV, a simple and interpretable\ntraining-free method that detects content truthfulness by leveraging these\nvalue vectors. On the NoVo benchmark, TruthV significantly outperforms both\nNoVo and log-likelihood baselines, demonstrating that MLP modules-despite being\nneglected in prior training-free efforts-encode rich and useful signals for\ntruthfulness detection. These findings offer new insights into how truthfulness\nis internally represented in LLMs and motivate further research on scalable and\ninterpretable truthfulness detection.", "published": "2025-09-22 15:54:29", "link": "http://arxiv.org/abs/2509.17932v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation", "abstract": "Multilingual translation faces challenges of computational redundancy and\nlimited accuracy for low-resource languages, especially in speech translation.\nTo address this, we propose a novel hierarchical Transformer Encoder Tree (TET)\ncombined with non-autoregressive encoder-only models trained with Connectionist\nTemporal Classification for multilingual translation. By sharing intermediate\nrepresentations among linguistically similar target languages, TET can improve\naccuracy on low-resource languages, reduce computational redundancy, and allow\ngenerating all target languages in a single forward pass, thus eliminating\nsequential bottlenecks and improving parallelism. For speech translation,\ncombining TET with a non-autoregressive speech recognition backbone (wav2vec2)\nshows promising results in terms of translation quality compared to\nautoregressive systems while being 7-14 times faster.", "published": "2025-09-22 15:52:18", "link": "http://arxiv.org/abs/2509.17930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Zero-shot Sentence Decontextualisation with Content Selection and Planning", "abstract": "Extracting individual sentences from a document as evidence or reasoning\nsteps is commonly done in many NLP tasks. However, extracted sentences often\nlack context necessary to make them understood, e.g., coreference and\nbackground information. To this end, we propose a content selection and\nplanning framework for zero-shot decontextualisation, which determines what\ncontent should be mentioned and in what order for a sentence to be understood\nout of context. Specifically, given a potentially ambiguous sentence and its\ncontext, we first segment it into basic semantically-independent units. We then\nidentify potentially ambiguous units from the given sentence, and extract\nrelevant units from the context based on their discourse relations. Finally, we\ngenerate a content plan to rewrite the sentence by enriching each ambiguous\nunit with its relevant units. Experimental results demonstrate that our\napproach is competitive for sentence decontextualisation, producing sentences\nthat exhibit better semantic integrity and discourse coherence, outperforming\nexisting methods.", "published": "2025-09-22 15:47:07", "link": "http://arxiv.org/abs/2509.17921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SiDiaC: Sinhala Diachronic Corpus", "abstract": "SiDiaC, the first comprehensive Sinhala Diachronic Corpus, covers a\nhistorical span from the 5th to the 20th century CE. SiDiaC comprises 58k words\nacross 46 literary works, annotated carefully based on the written date, after\nfiltering based on availability, authorship, copyright compliance, and data\nattribution. Texts from the National Library of Sri Lanka were digitised using\nGoogle Document AI OCR, followed by post-processing to correct formatting and\nmodernise the orthography. The construction of SiDiaC was informed by practices\nfrom other corpora, such as FarPaHC, particularly in syntactic annotation and\ntext normalisation strategies, due to the shared characteristics of\nlow-resourced language status. This corpus is categorised based on genres into\ntwo layers: primary and secondary. Primary categorisation is binary,\nclassifying each book into Non-Fiction or Fiction, while the secondary\ncategorisation is more specific, grouping texts under Religious, History,\nPoetry, Language, and Medical genres. Despite challenges including limited\naccess to rare texts and reliance on secondary date sources, SiDiaC serves as a\nfoundational resource for Sinhala NLP, significantly extending the resources\navailable for Sinhala, enabling diachronic studies in lexical change, neologism\ntracking, historical syntax, and corpus-based lexicography.", "published": "2025-09-22 15:37:51", "link": "http://arxiv.org/abs/2509.17912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Persuasive is Your Context?", "abstract": "Two central capabilities of language models (LMs) are: (i) drawing on prior\nknowledge about entities, which allows them to answer queries such as \"What's\nthe official language of Austria?\", and (ii) adapting to new information\nprovided in context, e.g., \"Pretend the official language of Austria is\nTagalog.\", that is pre-pended to the question. In this article, we introduce\ntargeted persuasion score (TPS), designed to quantify how persuasive a given\ncontext is to an LM where persuasion is operationalized as the ability of the\ncontext to alter the LM's answer to the question. In contrast to evaluating\npersuasiveness only by inspecting the greedily decoded answer under the model,\nTPS provides a more fine-grained view of model behavior. Based on the\nWasserstein distance, TPS measures how much a context shifts a model's original\nanswer distribution toward a target distribution. Empirically, through a series\nof experiments, we show that TPS captures a more nuanced notion of\npersuasiveness than previously proposed metrics.", "published": "2025-09-22 15:15:40", "link": "http://arxiv.org/abs/2509.17879v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Learning and Representation of Mandarin Tonal Categories by a Generative CNN", "abstract": "This paper outlines the methodology for modeling tonal learning in fully\nunsupervised models of human language acquisition. Tonal patterns are among the\ncomputationally most complex learning objectives in language. We argue that a\nrealistic generative model of human language (ciwGAN) can learn to associate\nits categorical variables with Mandarin Chinese tonal categories without any\nlabeled data. All three trained models showed statistically significant\ndifferences in F0 across categorical variables. The model trained solely on\nmale tokens consistently encoded tone. Our results sug- gest that not only does\nthe model learn Mandarin tonal contrasts, but it learns a system that\ncorresponds to a stage of acquisition in human language learners. We also\noutline methodology for tracing tonal representations in internal convolutional\nlayers, which shows that linguistic tools can contribute to interpretability of\ndeep learning and can ultimately be used in neural experiments.", "published": "2025-09-22 14:52:03", "link": "http://arxiv.org/abs/2509.17859v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CorPipe at CRAC 2025: Evaluating Multilingual Encoders for Multilingual Coreference Resolution", "abstract": "We present CorPipe 25, the winning entry to the CRAC 2025 Shared Task on\nMultilingual Coreference Resolution. This fourth iteration of the shared task\nintroduces a new LLM track alongside the original unconstrained track, features\nreduced development and test sets to lower computational requirements, and\nincludes additional datasets. CorPipe 25 represents a complete reimplementation\nof our previous systems, migrating from TensorFlow to PyTorch. Our system\nsignificantly outperforms all other submissions in both the LLM and\nunconstrained tracks by a substantial margin of 8 percentage points. The source\ncode and trained models are publicly available at\nhttps://github.com/ufal/crac2025-corpipe.", "published": "2025-09-22 14:51:37", "link": "http://arxiv.org/abs/2509.17858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Make Every Letter Count: Building Dialect Variation Dictionaries from Monolingual Corpora", "abstract": "Dialects exhibit a substantial degree of variation due to the lack of a\nstandard orthography. At the same time, the ability of Large Language Models\n(LLMs) to process dialects remains largely understudied. To address this gap,\nwe use Bavarian as a case study and investigate the lexical dialect\nunderstanding capability of LLMs by examining how well they recognize and\ntranslate dialectal terms across different parts-of-speech. To this end, we\nintroduce DiaLemma, a novel annotation framework for creating dialect variation\ndictionaries from monolingual data only, and use it to compile a ground truth\ndataset consisting of 100K human-annotated German-Bavarian word pairs. We\nevaluate how well nine state-of-the-art LLMs can judge Bavarian terms as\ndialect translations, inflected variants, or unrelated forms of a given German\nlemma. Our results show that LLMs perform best on nouns and lexically similar\nword pairs, and struggle most in distinguishing between direct translations and\ninflected variants. Interestingly, providing additional context in the form of\nexample usages improves the translation performance, but reduces their ability\nto recognize dialect variants. This study highlights the limitations of LLMs in\ndealing with orthographic dialect variation and emphasizes the need for future\nwork on adapting LLMs to dialects.", "published": "2025-09-22 14:49:08", "link": "http://arxiv.org/abs/2509.17855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trust Me, I Can Convince You: The Contextualized Argument Appraisal Framework", "abstract": "Emotions, which influence how convincing an argument is, are developed\n  in context of the self and sender, and therefore require modeling\n  the cognitive evaluation process. While binary emotionality has been\n  studied in argument mining, and the cognitive appraisal has been\n  modeled in general emotion analysis, these fields have not been\n  brought together yet. We therefore propose the Contextualized\n  Argument Appraisal Framework that contextualizes the interplay\n  between the sender, receiver, and argument. It includes emotion\n  labels, appraisals, such as argument familiarity, response urgency,\n  and expected effort, as well as convincingness variables. To evaluate\n  the framework and pave the way to computational modeling, we perform\n  a study in a role-playing scenario, mimicking real-world exposure to\n  arguments, asking participants to disclose their emotion, explain the main\ncause, the\n  argument appraisal, and the\n  perceived convincingness. To consider the subjective nature of such\n  annotations, we also collect demographic data and personality traits\n  of both the participants and the perceived sender of the argument.\n  The analysis of the resulting corpus of 800 arguments, each\n  annotated by 5 participants, reveals that convincingness is\n  positively correlated with positive emotions (e.g., trust) and\n  negatively correlated with negative emotions (e.g., anger). The\n  appraisal variables disclose the importance of the argument\n  familiarity. For most participants, the content of the argument\n  itself is the primary driver of the emotional response.", "published": "2025-09-22 14:32:55", "link": "http://arxiv.org/abs/2509.17844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Documents to Database: Failure Modes for Industrial Assets", "abstract": "We propose an interactive system using foundation models and user-provided\ntechnical documents to generate Failure Mode and Effects Analyses (FMEA) for\nindustrial equipment. Our system aggregates unstructured content across\ndocuments to generate an FMEA and stores it in a relational database.\nLeveraging this tool, the time required for creation of this\nknowledge-intensive content is reduced, outperforming traditional manual\napproaches. This demonstration showcases the potential of foundation models to\nfacilitate the creation of specialized structured content for enterprise asset\nmanagement systems.", "published": "2025-09-22 14:23:50", "link": "http://arxiv.org/abs/2509.17834v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation", "abstract": "Generation of Artificial Intelligence (AI) texts in important works has\nbecome a common practice that can be used to misuse and abuse AI at various\nlevels. Traditional AI detectors often rely on document-level classification,\nwhich struggles to identify AI content in hybrid or slightly edited texts\ndesigned to avoid detection, leading to concerns about the model's efficiency,\nwhich makes it hard to distinguish between human-written and AI-generated\ntexts. A sentence-level sequence labeling model proposed to detect transitions\nbetween human- and AI-generated text, leveraging nuanced linguistic signals\noverlooked by document-level classifiers. By this method, detecting and\nsegmenting AI and human-written text within a single document at the\ntoken-level granularity is achieved. Our model combines the state-of-the-art\npre-trained Transformer models, incorporating Neural Networks (NN) and\nConditional Random Fields (CRFs). This approach extends the power of\ntransformers to extract semantic and syntactic patterns, and the neural network\ncomponent to capture enhanced sequence-level representations, thereby improving\nthe boundary predictions by the CRF layer, which enhances sequence recognition\nand further identification of the partition between Human- and AI-generated\ntexts. The evaluation is performed on two publicly available benchmark datasets\ncontaining collaborative human and AI-generated texts. Our experimental\ncomparisons are with zero-shot detectors and the existing state-of-the-art\nmodels, along with rigorous ablation studies to justify that this approach, in\nparticular, can accurately detect the spans of AI texts in a completely\ncollaborative text. All our source code and the processed datasets are\navailable in our GitHub repository.", "published": "2025-09-22 14:22:55", "link": "http://arxiv.org/abs/2509.17830v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Adaptive Context Management for Intelligent Conversational Question Answering", "abstract": "This particular paper introduces an Adaptive Context Management (ACM)\nframework for the Conversational Question Answering (ConvQA) systems. The key\nobjective of the ACM framework is to optimize the use of the conversation\nhistory by dynamically managing context for maximizing the relevant information\nprovided to a ConvQA model within its token limit. Our approach incorporates a\nContext Manager (CM) Module, a Summarization (SM) Module, and an Entity\nExtraction (EE) Module in a bid to handle the conversation history\nefficaciously. The CM Module dynamically adjusts the context size, thereby\npreserving the most relevant and recent information within a model's token\nlimit. The SM Module summarizes the older parts of the conversation history via\na sliding window. When the summarization window exceeds its limit, the EE\nModule identifies and retains key entities from the oldest conversation turns.\nExperimental results demonstrate the effectiveness of our envisaged framework\nin generating accurate and contextually appropriate responses, thereby\nhighlighting the potential of the ACM framework to enhance the robustness and\nscalability of the ConvQA systems.", "published": "2025-09-22 14:21:26", "link": "http://arxiv.org/abs/2509.17829v1", "categories": ["cs.CL", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Everyday Physics in Korean Contexts: A Culturally Grounded Physical Reasoning Benchmark", "abstract": "Existing physical commonsense reasoning benchmarks predominantly focus on\nWestern contexts, overlooking cultural variations in physical problem-solving.\nTo address this gap, we introduce EPiK (Everyday Physics in Korean Contexts), a\nnovel benchmark comprising 181 binary-choice problems that test physical\nreasoning within Korean cultural contexts, ranging from kimchi (Korean food) to\ntraditional fermentation. EPiK is constructed using a two-stage generation and\nverification pipeline to create culturally-authentic problems across 9\nreasoning subtasks and 84 scenarios. Unlike approaches based on simple\ntranslation, our method generates problems organically from Korean contexts\nwhile upholding rigorous physical reasoning standards. Our evaluations show\nthat Korean-specialized models consistently outperform general-purpose models\nof comparable size. This performance gap highlights the limitations of\nculturally-agnostic models and demonstrates the critical need for\nculturally-aware benchmarks to truly measure language understanding. Our EPiK\nis publicly available at https://huggingface.co/datasets/jjae/EPiK.", "published": "2025-09-22 14:01:14", "link": "http://arxiv.org/abs/2509.17807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Findings of the Fourth Shared Task on Multilingual Coreference Resolution: Can LLMs Dethrone Traditional Approaches?", "abstract": "The paper presents an overview of the fourth edition of the Shared Task on\nMultilingual Coreference Resolution, organized as part of the CODI-CRAC 2025\nworkshop. As in the previous editions, participants were challenged to develop\nsystems that identify mentions and cluster them according to identity\ncoreference.\n  A key innovation of this year's task was the introduction of a dedicated\nLarge Language Model (LLM) track, featuring a simplified plaintext format\ndesigned to be more suitable for LLMs than the original CoNLL-U representation.\n  The task also expanded its coverage with three new datasets in two additional\nlanguages, using version 1.3 of CorefUD - a harmonized multilingual collection\nof 22 datasets in 17 languages.\n  In total, nine systems participated, including four LLM-based approaches (two\nfine-tuned and two using few-shot adaptation). While traditional systems still\nkept the lead, LLMs showed clear potential, suggesting they may soon challenge\nestablished approaches in future editions.", "published": "2025-09-22 13:52:32", "link": "http://arxiv.org/abs/2509.17796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to vary: Teaching LMs to reproduce human linguistic variability in next-word prediction", "abstract": "Natural language generation (NLG) tasks are often subject to inherent\nvariability; \\emph{e.g.} predicting the next word given a context has multiple\nvalid responses, evident when asking multiple humans to complete the task.\nWhile having language models (LMs) that are aligned pluralistically, so that\nthey are able to reproduce well the inherent diversity in perspectives of an\nentire population of interest is clearly beneficial, \\citet{ilia2024predict}\nshow that LMs do not reproduce this type of linguistic variability well. They\nspeculate this inability might stem from the lack of consistent training of LMs\nwith data reflecting this type of inherent variability. As such, we investigate\nwhether training LMs on multiple plausible word continuations per context can\nimprove their ability to reproduce human linguistic variability for next-word\nprediction. We employ fine-tuning techniques for pre-trained and\ninstruction-tuned models; and demonstrate their potential when fine-tuning\nGPT-2 and Mistral-7B-IT, using Provo Corpus. Our evaluation, which measures\ndivergence among empirically estimated human and model next-word distributions\nacross contexts before and after fine-tuning, shows that our multi-label\nfine-tuning improves the LMs' ability to reproduce linguistic variability; both\nfor contexts that admit higher and lower variability.", "published": "2025-09-22 13:51:40", "link": "http://arxiv.org/abs/2509.17794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts", "abstract": "Conversational agents deployed in industrial-scale official account platforms\nmust generate responses that are both contextually grounded and stylistically\naligned-requirements that existing methods struggle to meet. Chain-of-thought\n(CoT) prompting induces significant latency due to multi-turn reasoning;\nper-account fine-tuning is computationally prohibitive; and long prompt-based\nmethods degrade the model's ability to grasp injected context and style. In\nthis paper, we propose WeStar, a lite-adaptive framework for stylized\ncontextual question answering that scales to millions of official accounts.\nWeStar combines context-grounded generation via RAG with style-aware generation\nusing Parametric RAG (PRAG), where LoRA modules are dynamically activated per\nstyle cluster. Our contributions are fourfold: (1) We introduce WeStar, a\nunified framework capable of serving large volumes of official accounts with\nminimal overhead. (2) We propose a multi-dimensional, cluster-based parameter\nsharing scheme that enables compact style representation while preserving\nstylistic diversity. (3) We develop a style-enhanced Direct Preference\nOptimization (SeDPO) method to optimize each style cluster's parameters for\nimproved generation quality. (4) Experiments on a large-scale industrial\ndataset validate the effectiveness and efficiency of WeStar, underscoring its\npracitical value in real-world deployment.", "published": "2025-09-22 13:49:37", "link": "http://arxiv.org/abs/2509.17788v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "DIVERS-Bench: Evaluating Language Identification Across Domain Shifts and Code-Switching", "abstract": "Language Identification (LID) is a core task in multilingual NLP, yet current\nsystems often overfit to clean, monolingual data. This work introduces\nDIVERS-BENCH, a comprehensive evaluation of state-of-the-art LID models across\ndiverse domains, including speech transcripts, web text, social media texts,\nchildren's stories, and code-switched text. Our findings reveal that while\nmodels achieve high accuracy on curated datasets, performance degrades sharply\non noisy and informal inputs. We also introduce DIVERS-CS, a diverse\ncode-switching benchmark dataset spanning 10 language pairs, and show that\nexisting models struggle to detect multiple languages within the same sentence.\nThese results highlight the need for more robust and inclusive LID systems in\nreal-world settings.", "published": "2025-09-22 13:32:31", "link": "http://arxiv.org/abs/2509.17768v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Qwen3-Omni Technical Report", "abstract": "We present Qwen3-Omni, a single multimodal model that, for the first time,\nmaintains state-of-the-art performance across text, image, audio, and video\nwithout any degradation relative to single-modal counterparts. Qwen3-Omni\nmatches the performance of same-sized single-modal models within the Qwen\nseries and excels particularly on audio tasks. Across 36 audio and audio-visual\nbenchmarks, Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall\nSOTA on 22, outperforming strong closed-source models such as Gemini-2.5-Pro,\nSeed-ASR, and GPT-4o-Transcribe. Qwen3-Omni adopts a Thinker-Talker MoE\narchitecture that unifies perception and generation across text, images, audio,\nand video, yielding fluent text and natural real-time speech. It supports text\ninteraction in 119 languages, speech understanding in 19 languages, and speech\ngeneration in 10 languages. To reduce first-packet latency in streaming\nsynthesis, Talker autoregressively predicts discrete speech codecs using a\nmulti-codebook scheme. Leveraging the representational capacity of these\ncodebooks, we replace computationally intensive block-wise diffusion with a\nlightweight causal ConvNet, enabling streaming from the first codec frame. In\ncold-start settings, Qwen3-Omni achieves a theoretical end-to-end first-packet\nlatency of 234 ms. To further strengthen multimodal reasoning, we introduce a\nThinking model that explicitly reasons over inputs from any modality. Since the\nresearch community currently lacks a general-purpose audio captioning model, we\nfine-tuned Qwen3-Omni-30B-A3B to obtain Qwen3-Omni-30B-A3B-Captioner, which\nproduces detailed, low-hallucination captions for arbitrary audio inputs.\nQwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and\nQwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0\nlicense.", "published": "2025-09-22 13:26:24", "link": "http://arxiv.org/abs/2509.17765v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue", "abstract": "Large Language Models (LLMs) struggle with information forgetting and\ninefficiency in long-horizon, multi-turn dialogues. To address this, we propose\na training-free prompt engineering method, the State-Update Multi-turn Dialogue\nStrategy. It utilizes \"State Reconstruction\" and \"History Remind\" mechanisms to\neffectively manage dialogue history. Our strategy shows strong performance\nacross multiple multi-hop QA datasets. For instance, on the HotpotQA dataset,\nit improves the core information filtering score by 32.6%, leading to a 14.1%\nincrease in the downstream QA score, while also reducing inference time by\n73.1% and token consumption by 59.4%. Ablation studies confirm the pivotal\nroles of both components. Our work offers an effective solution for optimizing\nLLMs in long-range interactions, providing new insights for developing more\nrobust Agents.", "published": "2025-09-22 13:26:24", "link": "http://arxiv.org/abs/2509.17766v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification", "abstract": "Multimodal Large Language Models (MLLMs) have shown promise in visual-textual\nreasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly\nenhancing interpretability. However, existing MCoT methods rely on\nrationale-rich datasets and largely focus on inter-object reasoning,\noverlooking the intra-object understanding crucial for image classification. To\naddress this gap, we propose WISE, a Weak-supervision-guided Step-by-step\nExplanation method that augments any image classification dataset with MCoTs by\nreformulating the concept-based representations from Concept Bottleneck Models\n(CBMs) into concise, interpretable reasoning chains under weak supervision.\nExperiments across ten datasets show that our generated MCoTs not only improve\ninterpretability by 37% but also lead to gains in classification accuracy when\nused to fine-tune MLLMs. Our work bridges concept-based interpretability and\ngenerative MCoT reasoning, providing a generalizable framework for enhancing\nMLLMs in fine-grained visual understanding.", "published": "2025-09-22 13:05:29", "link": "http://arxiv.org/abs/2509.17740v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Breaking Token Into Concepts: Exploring Extreme Compression in Token Representation Via Compositional Shared Semantics", "abstract": "Standard language models employ unique, monolithic embeddings for each token,\npotentially limiting their ability to capture the multifaceted nature of word\nmeanings. We investigate whether tokens can be more effectively represented\nthrough a compositional structure that accumulates diverse semantic facets. To\nexplore this, we propose Aggregate Semantic Grouping (ASG), a novel approach\nleveraging Product Quantization (PQ). We apply ASG to standard transformer\narchitectures (mBERT, XLM-R, mT5) and evaluate this representational scheme\nacross diverse tasks (NLI, NER, QA), as well as a biomedical domain-specific\nbenchmark (BC5CDR) using BioBERT. Our findings demonstrate that representing\ntokens compositionally via ASG achieves extreme compression in embedding\nparameters (0.4--0.5\\%) while maintaining $>$95\\% task performance relative to\nthe base model, even in generative tasks and extends to both cross lingual\ntransfer and domain-specific settings. These results validate the principle\nthat tokens can be effectively modeled as combinations of shared semantic\nbuilding blocks. ASG offers a simple yet concrete method for achieving this,\nshowcasing how compositional representations can capture linguistic richness\nwhile enabling compact yet semantically rich models.", "published": "2025-09-22 13:04:48", "link": "http://arxiv.org/abs/2509.17737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs", "abstract": "Reinforcement learning (RL) has become a standard paradigm for refining large\nlanguage models (LLMs) beyond pre-training and instruction tuning. A prominent\nline of work is RL with verifiable rewards (RLVR), which leverages\nautomatically verifiable outcomes (e.g., correctness or executability) to\ngenerate reward signals. While efficient, this framework faces two key\nlimitations: First, its binary feedback is too sparse to capture the quality of\nthe reasoning process. Second, its coarse-grained rewards potentially lead to\nvanishing gradients. Inspired by observations from human learning, we introduce\na RL technique that integrates verifiable outcomes with the model's own\nconfidence estimates. This joint design enriches the reward signal, providing\nfiner-grained feedback and implicitly supervising the reasoning process.\nExperimental results demonstrate that our proposed method enhances RL\nperformance across multiple datasets and reduces token consumption during\ninference, while incurring negligible additional training cost. Moreover, it\ncan be used as a plug-in module to enhance other state-of-the-art RL methods.", "published": "2025-09-22 13:00:35", "link": "http://arxiv.org/abs/2509.17730v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs", "abstract": "Large Language Models (LLMs) are increasingly used for educational support,\nyet their response quality varies depending on the language of interaction.\nThis paper presents an automated multilingual pipeline for generating, solving,\nand evaluating math problems aligned with the German K-10 curriculum. We\ngenerated 628 math exercises and translated them into English, German, and\nArabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus)\nwere prompted to produce step-by-step solutions in each language. A held-out\npanel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality\nusing a comparative framework. Results show a consistent gap, with English\nsolutions consistently rated highest, and Arabic often ranked lower. These\nfindings highlight persistent linguistic bias and the need for more equitable\nmultilingual AI systems in education.", "published": "2025-09-22 12:38:09", "link": "http://arxiv.org/abs/2509.17701v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues", "abstract": "Evaluating large language models (LLMs) in long-form, knowledge-grounded\nrole-play dialogues remains challenging. This study compares LLM-generated and\nhuman-authored responses in multi-turn professional training simulations\nthrough human evaluation ($N=38$) and automated LLM-as-a-judge assessment.\nHuman evaluation revealed significant degradation in LLM-generated response\nquality across turns, particularly in naturalness, context maintenance and\noverall quality, while human-authored responses progressively improved. In line\nwith this finding, participants also indicated a consistent preference for\nhuman-authored dialogue. These human judgements were validated by our automated\nLLM-as-a-judge evaluation, where Gemini 2.0 Flash achieved strong alignment\nwith human evaluators on both zero-shot pairwise preference and stochastic\n6-shot construct ratings, confirming the widening quality gap between LLM and\nhuman responses over time. Our work contributes a multi-turn benchmark exposing\nLLM degradation in knowledge-grounded role-play dialogues and provides a\nvalidated hybrid evaluation framework to guide the reliable integration of LLMs\nin training simulations.", "published": "2025-09-22 12:33:02", "link": "http://arxiv.org/abs/2509.17694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation", "abstract": "LoRA has become one of the most widely used parameter-efficient fine-tuning\nmethods due to its simplicity and effectiveness. However, numerous studies have\nshown that LoRA often introduces substantial parameter redundancy, which not\nonly increases the number of trainable parameters but also hinders the\neffectiveness of fine-tuning. Since identifying redundant parameters in LoRA is\ninherently difficult, how to eliminate them efficiently and accurately remains\na challenging problem. In this paper, we propose TASO, a redundancy reduction\nmethod that leverages importance information from the pretrained model's\nweights to mitigate LoRA redundancy. Specifically, we estimate parameter\nimportance on downstream tasks and identify task-specific core regions based on\nthe distribution of importance scores. The location information of these core\nregions is then used to determine the sparse structure of LoRA modules,\nenabling redundancy removal before fine-tuning. Our approach significantly\nreduces the number of trainable parameters required for task adaptation, while\nproviding a novel task-aligned perspective for LoRA redundancy reduction.\nExperimental results demonstrate that, with a parameter budget comparable to\nLoRA with rank $r = 1$, TASO consistently outperforms standard LoRA across\nmultiple tasks, achieving strong fine-tuning performance while effectively\neliminating redundant parameters.", "published": "2025-09-22 12:29:43", "link": "http://arxiv.org/abs/2509.17688v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "When TableQA Meets Noise: A Dual Denoising Framework for Complex Questions and Large-scale Tables", "abstract": "Table question answering (TableQA) is a fundamental task in natural language\nprocessing (NLP). The strong reasoning capabilities of large language models\n(LLMs) have brought significant advances in this field. However, as real-world\napplications involve increasingly complex questions and larger tables,\nsubstantial noisy data is introduced, which severely degrades reasoning\nperformance. To address this challenge, we focus on improving two core\ncapabilities: Relevance Filtering, which identifies and retains information\ntruly relevant to reasoning, and Table Pruning, which reduces table size while\npreserving essential content. Based on these principles, we propose EnoTab, a\ndual denoising framework for complex questions and large-scale tables.\nSpecifically, we first perform Evidence-based Question Denoising by decomposing\nthe question into minimal semantic units and filtering out those irrelevant to\nanswer reasoning based on consistency and usability criteria. Then, we propose\nEvidence Tree-guided Table Denoising, which constructs an explicit and\ntransparent table pruning path to remove irrelevant data step by step. At each\npruning step, we observe the intermediate state of the table and apply a\npost-order node rollback mechanism to handle abnormal table states, ultimately\nproducing a highly reliable sub-table for final answer reasoning. Finally,\nextensive experiments show that EnoTab achieves outstanding performance on\nTableQA tasks with complex questions and large-scale tables, confirming its\neffectiveness.", "published": "2025-09-22 12:25:57", "link": "http://arxiv.org/abs/2509.17680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications", "abstract": "The widespread adoption of Large Language Models (LLMs) has been hindered by\ntheir tendency to hallucinate, generating plausible but factually incorrect\ninformation. While Retrieval-Augmented Generation (RAG) systems attempt to\naddress this issue by grounding responses in external knowledge, hallucination\nremains a persistent challenge, particularly for morphologically complex,\nlow-resource languages like Turkish. This paper introduces Turk-LettuceDetect,\nthe first suite of hallucination detection models specifically designed for\nTurkish RAG applications. Building on the LettuceDetect framework, we formulate\nhallucination detection as a token-level classification task and fine-tune\nthree distinct encoder architectures: a Turkish-specific ModernBERT,\nTurkEmbed4STS, and multilingual EuroBERT. These models were trained on a\nmachine-translated version of the RAGTruth benchmark dataset containing 17,790\ninstances across question answering, data-to-text generation, and summarization\ntasks. Our experimental results show that the ModernBERT-based model achieves\nan F1-score of 0.7266 on the complete test set, with particularly strong\nperformance on structured tasks. The models maintain computational efficiency\nwhile supporting long contexts up to 8,192 tokens, making them suitable for\nreal-time deployment. Comparative analysis reveals that while state-of-the-art\nLLMs demonstrate high recall, they suffer from low precision due to\nover-generation of hallucinated content, underscoring the necessity of\nspecialized detection mechanisms. By releasing our models and translated\ndataset, this work addresses a critical gap in multilingual NLP and establishes\na foundation for developing more reliable and trustworthy AI applications for\nTurkish and other languages.", "published": "2025-09-22 12:14:11", "link": "http://arxiv.org/abs/2509.17671v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PG-CE: A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation", "abstract": "With the rapid development of Large Language Models (LLMs), Controllable Text\nGeneration (CTG) has become a critical technology for enhancing system\nreliability and user experience. Addressing the limitations of traditional\nmethods, this paper proposes the PG-CE (Progressive Generation with Constraint\nEnhancement) approach, which decomposes CTG tasks into three steps: type\nprediction, constraint construction, and guided generation. This method employs\nconstraint generation models to dynamically build multi-dimensional constraints\nincluding tone, expression style, and thematic focus to guide output.\nExperiments demonstrate that PG-CE significantly improves generation quality\nacross multiple scenarios while maintaining text controllability, thematic\nrelevance, and response practicality. The research developed a dataset\ncontaining 90,000 constraint-text pairs (with an 8:2 ratio between daily and\nother topics), effectively reflecting real-world application requirements.", "published": "2025-09-22 12:12:41", "link": "http://arxiv.org/abs/2509.17669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crosslingual Optimized Metric for Translation Assessment of Indian Languages", "abstract": "Automatic evaluation of translation remains a challenging task owing to the\northographic, morphological, syntactic and semantic richness and divergence\nobserved across languages. String-based metrics such as BLEU have previously\nbeen extensively used for automatic evaluation tasks, but their limitations are\nnow increasingly recognized. Although learned neural metrics have helped\nmitigate some of the limitations of string-based approaches, they remain\nconstrained by a paucity of gold evaluation data in most languages beyond the\nusual high-resource pairs. In this present work we address some of these gaps.\nWe create a large human evaluation ratings dataset for 13 Indian languages\ncovering 21 translation directions and then train a neural translation\nevaluation metric named Cross-lingual Optimized Metric for Translation\nAssessment of Indian Languages (COMTAIL) on this dataset. The best performing\nmetric variants show significant performance gains over previous\nstate-of-the-art when adjudging translation pairs with at least one Indian\nlanguage. Furthermore, we conduct a series of ablation studies to highlight the\nsensitivities of such a metric to changes in domain, translation quality, and\nlanguage groupings. We release both the COMTAIL dataset and the accompanying\nmetric models.", "published": "2025-09-22 12:11:42", "link": "http://arxiv.org/abs/2509.17667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?", "abstract": "Even without directly hearing sounds, humans can effortlessly reason about\nauditory properties, such as pitch, loudness, or sound-source associations,\ndrawing on auditory commonsense. In contrast, language models often lack this\ncapability, limiting their effectiveness in multimodal interactions. As an\ninitial step to address this gap, we present AuditoryBench++, a comprehensive\nbenchmark for evaluating auditory knowledge and reasoning in text-only\nsettings. The benchmark encompasses tasks that range from basic auditory\ncomparisons to contextually grounded reasoning, enabling fine-grained analysis\nof how models process and integrate auditory concepts. In addition, we\nintroduce AIR-CoT, a novel auditory imagination reasoning method that generates\nand integrates auditory information during inference through span detection\nwith special tokens and knowledge injection. Extensive experiments with recent\nLLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both\nthe off-the-shelf models and those augmented with auditory knowledge. The\nproject page is available at https://auditorybenchpp.github.io.", "published": "2025-09-22 11:45:22", "link": "http://arxiv.org/abs/2509.17641v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents", "abstract": "Large Language Models (LLMs) have excelled in question-answering (QA) tasks\nwithin single domains. However, their reasoning and coordination capabilities\nin complex, multi-stage scenarios remain underexplored. Existing benchmarks\ntypically focus on isolated tasks or narrow domains, overlooking models'\nabilities for multi-stage collaboration and optimization without explicit\nexternal guidance. To bridge this gap, we propose \\textbf{MSCoRe}, a novel\nbenchmark comprising 126696 domain-specific QA instances spanning scenarios in\nautomotive, pharmaceutical, electronics, and energy sectors. The dataset is\ncreated using a structured three-phase pipeline: dynamic sampling, iterative\nquestion-answer generation, and a multi-level quality assessment to ensure data\nquality. Tasks are further categorized into three difficulty levels according\nto stage coverage and complexity. With MSCoRe, we have conducted a\ncomprehensive evaluation of various state-of-the-art LLM agents. The commercial\nmodels performed best across all tasks and scenarios, but a notable gap in\nROUGE scores remains between simple and complex tasks. We also tested the\nmodels' robustness and found that their performance is negatively affected by\nnoisy data. MSCoRe provides a valuable new resource for the community to\nevaluate and improve multi-stage reasoning in LLM agents. The code and data are\navailable at https://github.com/D3E0-source/MSCoRE.", "published": "2025-09-22 11:36:16", "link": "http://arxiv.org/abs/2509.17628v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutiHero: Leveraging Generative AI in Social Narratives to Engage Parents in Story-Driven Behavioral Guidance for Autistic Children", "abstract": "Social narratives are known to help autistic children understand and navigate\nsocial situations through stories. To ensure effectiveness, however, the\nmaterials need to be customized to reflect each child's unique behavioral\ncontext, requiring considerable time and effort for parents to practice at\nhome. We present AutiHero, a generative AI-based social narrative system for\nbehavioral guidance, which supports parents to create personalized stories for\ntheir autistic children and read them together. AutiHero generates text and\nvisual illustrations that reflect their children's interests, target behaviors,\nand everyday contexts. In a two-week deployment study with 16 autistic\nchild-parent dyads, parents created 218 stories and read an average of 4.25\nstories per day, demonstrating a high level of engagement. AutiHero also\nprovided an effective, low-demanding means to guide children's social\nbehaviors, encouraging positive change. We discuss the implications of\ngenerative AI-infused tools to empower parents in guiding their children's\nbehaviors, fostering their social learning.", "published": "2025-09-22 11:23:10", "link": "http://arxiv.org/abs/2509.17608v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Asking a Language Model for Diverse Responses", "abstract": "Large language models increasingly rely on explicit reasoning chains and can\nproduce multiple plausible responses for a given context. We study the\ncandidate sampler that produces the set of plausible responses contrasting the\nancestral (parallel) sampling against two alternatives: enumeration, which asks\nthe model to produce $n$ candidates in one pass, and iterative sampling, which\nproposes candidates sequentially while conditioning on the currently generated\nresponse set. Under matched budgets, we compare these samplers on quality,\nlexical and computation flow diversity, and efficiency. Our empirical results\ndemonstrate that enumeration and iterative strategies result in higher\ndiversity at comparable quality. Our findings highlight the potential of simple\nnon-independent sampling strategies to improve response diversity without\nsacrificing generation quality.", "published": "2025-09-22 11:01:22", "link": "http://arxiv.org/abs/2509.17570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Specification-Aware Machine Translation and Evaluation for Purpose Alignment", "abstract": "In professional settings, translation is guided by communicative goals and\nclient needs, often formalized as specifications. While existing evaluation\nframeworks acknowledge the importance of such specifications, these\nspecifications are often treated only implicitly in machine translation (MT)\nresearch. Drawing on translation studies, we provide a theoretical rationale\nfor why specifications matter in professional translation, as well as a\npractical guide to implementing specification-aware MT and evaluation. Building\non this foundation, we apply our framework to the translation of investor\nrelations texts from 33 publicly listed companies. In our experiment, we\ncompare five translation types, including official human translations and\nprompt-based outputs from large language models (LLMs), using expert error\nanalysis, user preference rankings, and an automatic metric. The results show\nthat LLM translations guided by specifications consistently outperformed\nofficial human translations in human evaluations, highlighting a gap between\nperceived and expected quality. These findings demonstrate that integrating\nspecifications into MT workflows, with human oversight, can improve translation\nquality in ways aligned with professional practice.", "published": "2025-09-22 10:50:37", "link": "http://arxiv.org/abs/2509.17559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning", "abstract": "The remarkable performance of Large Language Models (LLMs) can be enhanced\nwith test-time computation, which relies on external tools and even other deep\nlearning models. However, existing approaches for integrating non-text modality\nrepresentations into LLMs typically require additional costly supervised\ntraining, restricting on-the-fly adaptation to new domains and modalities. In\nthis work, we explore the feasibility of integrating representations from\nnon-text foundational models (FMs) into text-based LLMs in a training-free\nmanner. We propose In-Context Representation Learning (ICRL) as a\nproof-of-concept to allow LLMs to adaptively utilize non-text modality\nrepresentations with few-shot learning. Unlike traditional in-context learning,\nwhich incorporates text-label pairs, ICRL replaces text inputs with FM\nrepresentations, enabling the LLM to perform multi-modal inference without\nfine-tuning. We evaluate ICRL on a suite of tasks in the molecular domain,\ninvestigating three core research questions: (i) how to map FM representations\ninto LLMs in a training-free manner, (ii) what factors influence ICRL\nperformance, and (iii) what mechanisms underlie the effectiveness of ICRL. To\nthe best of our knowledge, ICRL is the first training-free framework for\nintegrating non-text modality representations into text-based LLMs, presenting\na promising direction for adaptable, multi-modal generalization.", "published": "2025-09-22 09:16:34", "link": "http://arxiv.org/abs/2509.17552v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models", "abstract": "Self-supervised learning (SSL) has made significant advances in speech\nrepresentation learning. Models like wav2vec 2.0 and HuBERT have achieved\nstate-of-the-art results in tasks such as speech recognition, particularly in\nmonolingual settings. However, multilingual SSL models tend to underperform\ntheir monolingual counterparts on each individual language, especially in\nmultilingual scenarios with few languages such as the bilingual setting. In\nthis work, we investigate a novel approach to reduce this performance gap by\nintroducing limited visual grounding into bilingual speech SSL models. Our\nresults show that visual grounding benefits both monolingual and bilingual\nmodels, with especially pronounced gains for the latter, reducing the\nmultilingual performance gap on zero-shot phonetic discrimination from 31.5%\nfor audio-only models to 8.04% with grounding.", "published": "2025-09-22 08:48:04", "link": "http://arxiv.org/abs/2509.17523v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CorefInst: Leveraging LLMs for Multilingual Coreference Resolution", "abstract": "Coreference Resolution (CR) is a crucial yet challenging task in natural\nlanguage understanding, often constrained by task-specific architectures and\nencoder-based language models that demand extensive training and lack\nadaptability. This study introduces the first multilingual CR methodology which\nleverages decoder-only LLMs to handle both overt and zero mentions. The article\nexplores how to model the CR task for LLMs via five different instruction sets\nusing a controlled inference method. The approach is evaluated across three\nLLMs; Llama 3.1, Gemma 2, and Mistral 0.3. The results indicate that LLMs, when\ninstruction-tuned with a suitable instruction set, can surpass state-of-the-art\ntask-specific architectures. Specifically, our best model, a fully fine-tuned\nLlama 3.1 for multilingual CR, outperforms the leading multilingual CR model\n(i.e., Corpipe 24 single stage variant) by 2 pp on average across all languages\nin the CorefUD v1.2 dataset collection.", "published": "2025-09-22 08:35:21", "link": "http://arxiv.org/abs/2509.17505v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages", "abstract": "As large language models (LLMs) are trained on increasingly diverse and\nextensive multilingual corpora, they demonstrate cross-lingual transfer\ncapabilities. However, these capabilities often fail to effectively extend to\nlow-resource languages, particularly those utilizing non-Latin scripts. While\ntransliterating low-resource languages into Latin script presents a natural\nsolution, there currently lacks a comprehensive framework for integrating\ntransliteration into LLMs training and deployment. Taking a pragmatic approach,\nthis paper innovatively combines character transliteration with Huffman coding\nto design a complete transliteration framework. Our proposed framework offers\nthe following advantages: 1) Compression: Reduces storage requirements for\nlow-resource language content, achieving up to 50% reduction in file size and\n50-80% reduction in token count. 2) Accuracy: Guarantees 100% lossless\nconversion from transliterated text back to the source language. 3) Efficiency:\nEliminates the need for vocabulary expansion for low-resource languages,\nimproving training and inference efficiency. 4) Scalability: The framework can\nbe extended to other low-resource languages. We validate the effectiveness of\nour framework across multiple downstream tasks, including text classification,\nmachine reading comprehension, and machine translation. Experimental results\ndemonstrate that our method significantly enhances the model's capability to\nprocess low-resource languages while maintaining performance on high-resource\nlanguages. Our data and code are publicly available at\nhttps://github.com/CMLI-NLP/HuffmanTranslit.", "published": "2025-09-22 08:24:26", "link": "http://arxiv.org/abs/2509.17493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM", "abstract": "Large language models (LLMs) have advanced code generation from\nsingle-function tasks to competitive-programming problems, but existing\nmulti-agent solutions either rely on costly large-scale ($>$ 30B) models or\ncollapse when downsized to small open-source models. We present MapCoder-Lite,\nwhich upgrades a single 7B model into four role-specialised agents-retriever,\nplanner, coder, and debugger-using only rank-32, role-specific LoRA adapters\n($<3\\%$ extra parameters). Three lightweight techniques make this possible: (i)\ntrajectory distillation from strong LLMs fixes format fragility in retrieval\nand debugging, (ii) supervisor-guided correction strengthens planning and\ncoding agents, and (iii) agent-wise LoRA fine-tuning delivers memory-efficient\nspecialisation. Comprehensive evaluation on xCodeEval, APPS, and CodeContests\nshows that MapCoder-Lite more than doubles xCodeEval accuracy (from $13.2\\%$ to\n$28.3\\%$), eliminates all format failures, and closes to within six points of a\n32B baseline while cutting GPU memory and token-generation time by $4\\times$.\nThese results demonstrate that careful agent-wise fine-tuning unleashes\nhigh-quality multi-agent coding on a small language model.", "published": "2025-09-22 08:19:11", "link": "http://arxiv.org/abs/2509.17489v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation improves the factual accuracy of Large\nLanguage Models (LLMs) by incorporating external context, but often suffers\nfrom irrelevant retrieved content that hinders effectiveness. Context\ncompression addresses this issue by filtering out irrelevant information from\ncontext before LLM generation. However, existing methods struggle to adaptively\nadjust compression rates for different context, maintain low latency and\nintegrate information across multiple documents. To overcome these limitations,\nWe introduce AttnComp, an adaptive, efficient and context-aware compression\nframework. By leveraging the attention mechanism of LLMs to identify relevant\ninformation, AttnComp employs a Top-P compression algorithm to retain the\nminimal set of documents whose cumulative attention weights exceeds a\npredefined threshold. In addition to compression, AttnComp estimates response\nconfidence by assessing the overall relevance of the retrieved content,\nenabling users to gauge response reliability. Experiments demonstrate that\nAttnComp outperforms existing compression methods and uncompressed baselines,\nachieving higher accuracy with substantial compression rates and lower latency.", "published": "2025-09-22 08:18:50", "link": "http://arxiv.org/abs/2509.17486v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diagnosing Model Editing via Knowledge Spectrum", "abstract": "Model editing, the process of efficiently modifying factual knowledge in\npre-trained language models, is critical for maintaining their accuracy and\nrelevance. However, existing editing methods often introduce unintended side\neffects, degrading model performance in unpredictable ways. While much research\nhas focused on improving editing algorithms, the role of the target knowledge's\nintrinsic properties remains a significant, underexplored factor. This paper\naddresses this gap by first proposing the ``Knowledge Spectrum,'' a systematic\nframework for categorizing knowledge based on its real-world popularity, the\nmodel's pre-edit familiarity, and the linguistic structure of the eliciting\nquestion. Our empirical analysis reveals that these characteristics are strong\npredictors of editing success and stability. Informed by these findings, we\nintroduce the ``Knowledge-Diagnostic Framework,'' an adaptive strategy that\ntailors editing intensity to the diagnosed difficulty of a knowledge item. We\ndemonstrate that this framework significantly improves success rates for\nchallenging edits while optimizing computational resources. Our work provides a\nmore comprehensive understanding of the factors governing model editing.", "published": "2025-09-22 08:16:04", "link": "http://arxiv.org/abs/2509.17482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding", "abstract": "Large Vision-Language Models (LVLMs) have recently demonstrated remarkable\nprogress, yet hallucination remains a critical barrier, particularly in chart\nunderstanding, which requires sophisticated perceptual and cognitive abilities\nas well as rigorous factual accuracy. While prior work has investigated\nhallucinations and chart comprehension independently, their intersection\nremains largely unexplored. To address this gap, we present ChartHal, a\nbenchmark that features a fine-grained taxonomy of hallucination scenarios in\nchart understanding, along with a human-validated dataset of 1,062 samples. Our\nevaluation shows that state-of-the-art LVLMs suffer from severe hallucinations\non ChartHal, including proprietary models such as GPT-5 and o4-mini, which\nachieve only 34.46% and 22.79% accuracy, respectively. Further analysis reveals\nthat questions involving information absent from or contradictory to charts are\nespecially likely to trigger hallucinations, underscoring the urgent need for\nmore robust mitigation strategies. Code and data are available at\nhttps://github.com/ymcui/ChartHal .", "published": "2025-09-22 08:15:55", "link": "http://arxiv.org/abs/2509.17481v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LingoQ: Bridging the Gap between ESL Learning and Work through AI-Generated Work-Related Quizzes", "abstract": "Non-native English speakers performing English-related tasks at work struggle\nto sustain ESL learning, despite their motivation. Often, study materials are\ndisconnected from their work context. Although workers rely on LLM assistants\nto address their immediate needs, these interactions may not directly\ncontribute to their English skills. We present LingoQ, an AI-mediated system\nthat allows workers to practice English using quizzes generated from their LLM\nqueries during work. LingoQ leverages these queries using AI to generate\npersonalized quizzes that workers can review and practice on their smartphones.\nWe conducted a three-week deployment study with 28 ESL workers to evaluate\nLingoQ. Participants valued the relevance of quizzes that reflect their own\ncontext, constantly engaging with the app during the study. This active\nengagement improved self-efficacy and led to learning gains for beginners and,\npotentially, for intermediate learners. We discuss opportunities of leveraging\nusers' reliance on LLMs to situate their learning in the user context for\nimproved learning.", "published": "2025-09-22 08:12:10", "link": "http://arxiv.org/abs/2509.17477v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling", "abstract": "Journaling can potentially serve as an effective method for autistic\nadolescents to improve narrative skills. However, its text-centric nature and\nhigh executive functioning demands present barriers to practice. We present\nAutiverse, an AI-guided multimodal journaling app for tablets that scaffolds\nstorytelling through conversational prompts and visual supports. Autiverse\nelicits key details through a stepwise dialogue with peer-like, customizable AI\nand composes them into an editable four-panel comic strip. Through a two-week\ndeployment study with 10 autistic adolescent-parent dyads, we examine how\nAutiverse supports autistic adolescents to organize their daily experience and\nemotion. Autiverse helped them construct coherent narratives, while enabling\nparents to learn additional details of their child's events and emotions. The\ncustomized AI peer created a comfortable space for sharing, fostering enjoyment\nand a strong sense of agency. We discuss the implications of designing\ntechnologies that complement autistic adolescents' strengths while ensuring\ntheir autonomy and safety in sharing experiences.", "published": "2025-09-22 08:02:09", "link": "http://arxiv.org/abs/2509.17466v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "PRINCIPLES: Synthetic Strategy Memory for Proactive Dialogue Agents", "abstract": "Dialogue agents based on large language models (LLMs) have shown promising\nperformance in proactive dialogue, which requires effective strategy planning.\nHowever, existing approaches to strategy planning for proactive dialogue face\nseveral limitations: limited strategy coverage, preference bias in planning,\nand reliance on costly additional training. To address these, we propose\nPRINCIPLES: a synthetic strategy memory for proactive dialogue agents.\nPRINCIPLES is derived through offline self-play simulations and serves as\nreusable knowledge that guides strategy planning during inference, eliminating\nthe need for additional training and data annotation. We evaluate PRINCIPLES in\nboth emotional support and persuasion domains, demonstrating consistent\nimprovements over strong baselines. Furthermore, PRINCIPLES maintains its\nrobustness across extended and more diverse evaluation settings. See our\nproject page at https://huggingface.co/spaces/kimnamssya/Principles.", "published": "2025-09-22 07:53:59", "link": "http://arxiv.org/abs/2509.17459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Codifying Natural Langauge Tasks", "abstract": "We explore the applicability of text-to-code to solve real-world problems\nthat are typically solved in natural language, such as legal judgment and\nmedical QA. Unlike previous works, our approach leverages the explicit\nreasoning provided by program generation. We present ICRAG, a framework that\ntransforms natural language into executable programs through iterative\nrefinement using external knowledge from domain resources and GitHub. Across 13\nbenchmarks, ICRAG achieves up to 161.1\\% relative improvement. We provide a\ndetailed analysis of the generated code and the impact of external knowledge,\nand we discuss the limitations of applying text-to-code approaches to\nreal-world natural language tasks.", "published": "2025-09-22 07:49:58", "link": "http://arxiv.org/abs/2509.17455v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SLAyiNG: Towards Queer Language Processing", "abstract": "Knowledge of slang is a desirable feature of LLMs in the context of user\ninteraction, as slang often reflects an individual's social identity. Several\nworks on informal language processing have defined and curated benchmarks for\ntasks such as detection and identification of slang. In this paper, we focus on\nqueer slang. Queer slang can be mistakenly flagged as hate speech or can evoke\nnegative responses from LLMs during user interaction. Research efforts so far\nhave not focused explicitly on queer slang. In particular, detection and\nprocessing of queer slang have not been thoroughly evaluated due to the lack of\na high-quality annotated benchmark. To address this gap, we curate SLAyiNG, the\nfirst dataset containing annotated queer slang derived from subtitles, social\nmedia posts, and podcasts, reflecting real-world usage. We describe our data\ncuration process, including the collection of slang terms and definitions,\nscraping sources for examples that reflect usage of these terms, and our\nongoing annotation process. As preliminary results, we calculate\ninter-annotator agreement for human annotators and OpenAI's model o3-mini,\nevaluating performance on the task of sense disambiguation. Reaching an average\nKrippendorff's alpha of 0.746, we argue that state-of-the-art reasoning models\ncan serve as tools for pre-filtering, but the complex and often sensitive\nnature of queer language data requires expert and community-driven annotation\nefforts.", "published": "2025-09-22 07:41:45", "link": "http://arxiv.org/abs/2509.17449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks", "abstract": "Reliable question answering with large language models (LLMs) is challenged\nby hallucinations, fluent but factually incorrect outputs arising from\nepistemic uncertainty. Existing entropy-based semantic-level uncertainty\nestimation methods are limited by sampling noise and unstable clustering of\nvariable-length answers. We propose Semantic Reformulation Entropy (SRE), which\nimproves uncertainty estimation in two ways. First, input-side semantic\nreformulations produce faithful paraphrases, expand the estimation space, and\nreduce biases from superficial decoder tendencies. Second, progressive,\nenergy-based hybrid clustering stabilizes semantic grouping. Experiments on\nSQuAD and TriviaQA show that SRE outperforms strong baselines, providing more\nrobust and generalizable hallucination detection. These results demonstrate\nthat combining input diversification with multi-signal clustering substantially\nenhances semantic-level uncertainty estimation.", "published": "2025-09-22 07:38:45", "link": "http://arxiv.org/abs/2509.17445v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling in the Clinical Gaps in Benchmark: Case for HealthBench for the Japanese medical system", "abstract": "This study investigates the applicability of HealthBench, a large-scale,\nrubric-based medical benchmark, to the Japanese context. While robust\nevaluation frameworks are crucial for the safe development of medical LLMs,\nresources in Japanese remain limited, often relying on translated\nmultiple-choice questions. Our research addresses this gap by first\nestablishing a performance baseline, applying a machine-translated version of\nHealthBench's 5,000 scenarios to evaluate both a high-performing multilingual\nmodel (GPT-4.1) and a Japanese-native open-source model (LLM-jp-3.1). Second,\nwe employ an LLM-as-a-Judge approach to systematically classify the benchmark's\nscenarios and rubric criteria, identifying \"contextual gaps\" where content is\nmisaligned with Japan's clinical guidelines, healthcare systems, or cultural\nnorms. Our findings reveal a modest performance drop in GPT-4.1 due to rubric\nmismatches and a significant failure in the Japanese-native model, which lacked\nthe required clinical completeness. Furthermore, our classification indicates\nthat while the majority of scenarios are applicable, a substantial portion of\nthe rubric criteria requires localization. This work underscores the\nlimitations of direct benchmark translation and highlights the urgent need for\na context-aware, localized adaptation, a J-HealthBench, to ensure the reliable\nand safe evaluation of medical LLMs in Japan.", "published": "2025-09-22 07:36:12", "link": "http://arxiv.org/abs/2509.17444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning", "abstract": "Recent advancements in reinforcement learning (RL) have enhanced the\nreasoning abilities of large language models (LLMs), yet the impact on\nmultimodal LLMs (MLLMs) is limited. Particularly in vision-intensive tasks like\ngeometric reasoning, MLLMs hallucinate frequently, leading to inaccurate\nreasoning. We attribute this to the perceptual bottleneck in MLLMs, which caps\nthe benefits of reasoning training. To quantify this, we design a\nGeo-Perception Question-Answering (GeoPQA) benchmark, targeting basic geometric\nconcepts and spatial relationships. Experiments on GeoPQA reveal significant\nshortcomings of MLLMs in visual perception, which constrain RL reward signals\nfor effective training. To address this bottleneck, we propose a two-stage RL\ntraining framework by first enhancing the visual perception of geometric\nstructures, then fostering reasoning capabilities. Applied to\nQwen2.5-VL-3B-Instruct, our two-stage training improves geometric reasoning by\n9.7% and geometric problem solving by 9.1%, compared to the direct reasoning\ntraining approach. Our method also generalizes to other vision-intensive\ndomains like figure understanding, highlighting the importance of perceptual\ngrounding in effective MLLM reasoning.", "published": "2025-09-22 07:28:09", "link": "http://arxiv.org/abs/2509.17437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MedFact: A Large-scale Chinese Dataset for Evidence-based Medical Fact-checking of LLM Responses", "abstract": "Medical fact-checking has become increasingly critical as more individuals\nseek medical information online. However, existing datasets predominantly focus\non human-generated content, leaving the verification of content generated by\nlarge language models (LLMs) relatively unexplored. To address this gap, we\nintroduce MedFact, the first evidence-based Chinese medical fact-checking\ndataset of LLM-generated medical content. It consists of 1,321 questions and\n7,409 claims, mirroring the complexities of real-world medical scenarios. We\nconduct comprehensive experiments in both in-context learning (ICL) and\nfine-tuning settings, showcasing the capability and challenges of current LLMs\non this task, accompanied by an in-depth error analysis to point out key\ndirections for future research. Our dataset is publicly available at\nhttps://github.com/AshleyChenNLP/MedFact.", "published": "2025-09-22 07:26:47", "link": "http://arxiv.org/abs/2509.17436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models", "abstract": "The demand for efficient deployment of large language models (LLMs) has\ndriven interest in quantization, which reduces inference cost, and\nparameter-efficient fine-tuning (PEFT), which lowers training overhead. This\nmotivated the development of quantization-aware PEFT to produce accurate yet\nefficient quantized models. In this setting, reducing quantization error prior\nto fine-tuning is crucial for achieving high model accuracy. However, existing\nmethods that rely on low-rank adaptation suffer from limited representational\ncapacity. Recent Fourier-related transform (FT)-based adapters offer greater\nrepresentational power than low-rank adapters, but their direct integration\ninto quantized models often results in ineffective error reduction and\nincreased computational overhead. To overcome these limitations, we propose\nQWHA, a method that integrates FT-based adapters into quantized models by\nemploying the Walsh-Hadamard Transform (WHT) as the transform kernel, together\nwith a novel adapter initialization scheme incorporating adaptive parameter\nselection and value refinement. We demonstrate that QWHA effectively mitigates\nquantization errors while facilitating fine-tuning, and that its design\nsubstantially reduces computational cost. Experimental results show that QWHA\nconsistently outperforms baselines in low-bit quantization accuracy and\nachieves significant training speedups over existing FT-based adapters. The\ncode is available at https://github.com/vantaa89/qwha.", "published": "2025-09-22 07:21:41", "link": "http://arxiv.org/abs/2509.17428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios", "abstract": "While various multimodal multi-image evaluation datasets have been emerged,\nbut these datasets are primarily based on English, and there has yet to be a\nChinese multi-image dataset. To fill this gap, we introduce RealBench, the\nfirst Chinese multimodal multi-image dataset, which contains 9393 samples and\n69910 images. RealBench distinguishes itself by incorporating real\nuser-generated content, ensuring high relevance to real-world applications.\nAdditionally, the dataset covers a wide variety of scenes, image resolutions,\nand image structures, further increasing the difficulty of multi-image\nunderstanding. Ultimately, we conduct a comprehensive evaluation of RealBench\nusing 21 multimodal LLMs of different sizes, including closed-source models\nthat support multi-image inputs as well as open-source visual and video models.\nThe experimental results indicate that even the most powerful closed-source\nmodels still face challenges when handling multi-image Chinese scenarios.\nMoreover, there remains a noticeable performance gap of around 71.8\\% on\naverage between open-source visual/video models and closed-source models. These\nresults show that RealBench provides an important research foundation for\nfurther exploring multi-image understanding capabilities in the Chinese\ncontext.", "published": "2025-09-22 07:14:31", "link": "http://arxiv.org/abs/2509.17421v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Vision Language Models Are Not (Yet) Spelling Correctors", "abstract": "Spelling correction from visual input poses unique challenges for vision\nlanguage models (VLMs), as it requires not only detecting but also correcting\ntextual errors directly within images. We present ReViCo (Real Visual\nCorrection), the first benchmark that systematically evaluates VLMs on\nreal-world visual spelling correction across Chinese and English. ReViCo\ncontains naturally occurring errors collected from real-world image data and\nsupports fine-grained evaluation at both image and token levels. Through\ncomprehensive experiments on representative cascaded (Qwen) and native\n(InternVL) open-source models, as well as closed-source systems (GPT-4o,\nClaude), we show that current VLMs fall significantly short of human\nperformance, particularly in correction. To address these limitations, we\nexplore two solution paradigms: a Joint OCR-Correction pipeline and a\nBackground Information enhanced approach, both of which yield consistent\nperformance gains. Our analysis highlights fundamental limitations of existing\narchitectures and provides actionable insights for advancing multimodal\nspelling correction.", "published": "2025-09-22 07:10:42", "link": "http://arxiv.org/abs/2509.17418v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context", "abstract": "Large language models (LLMs) are widely used in various tasks and\napplications. However, despite their wide capabilities, they are shown to lack\ncultural alignment \\citep{ryan-etal-2024-unintended,\nalkhamissi-etal-2024-investigating} and produce biased generations\n\\cite{naous-etal-2024-beer} due to a lack of cultural knowledge and competence.\nEvaluation of LLMs for cultural awareness and alignment is particularly\nchallenging due to the lack of proper evaluation metrics and unavailability of\nculturally grounded datasets representing the vast complexity of cultures at\nthe regional and sub-regional levels. Existing datasets for culture specific\nitems (CSIs) focus primarily on concepts at the regional level and may contain\nfalse positives. To address this issue, we introduce a novel CSI dataset for\nIndian culture, belonging to 17 cultural facets. The dataset comprises $\\sim$8k\ncultural concepts from 36 sub-regions. To measure the cultural competence of\nLLMs on a cultural text adaptation task, we evaluate the adaptations using the\nCSIs created, LLM as Judge, and human evaluations from diverse\nsocio-demographic region. Furthermore, we perform quantitative analysis\ndemonstrating selective sub-regional coverage and surface-level adaptations\nacross all considered LLMs. Our dataset is available here:\n\\href{https://huggingface.co/datasets/nlip/DIWALI}{https://huggingface.co/datasets/nlip/DIWALI},\nproject\nwebpage\\footnote{\\href{https://nlip-lab.github.io/nlip/publications/diwali/}{https://nlip-lab.github.io/nlip/publications/diwali/}},\nand our codebase with model outputs can be found here:\n\\href{https://github.com/pramitsahoo/culture-evaluation}{https://github.com/pramitsahoo/culture-evaluation}.", "published": "2025-09-22 06:58:02", "link": "http://arxiv.org/abs/2509.17399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EpiCache: Episodic KV Cache Management for Long Conversational Question Answering", "abstract": "Recent advances in large language models (LLMs) have extended context\nlengths, enabling assistants to sustain long histories for coherent,\npersonalized responses. This ability, however, hinges on Key-Value (KV)\ncaching, whose memory grows linearly with dialogue length and quickly dominates\nunder strict resource constraints. An active line of research for reducing this\noverhead is KV cache compression, which seeks to limit cache size while\npreserving accuracy. Yet existing methods face two major limitations: (i)\nevicting entries after full-context prefill causes unbounded peak memory, and\n(ii) query-dependent eviction narrows the cache to a single query, leading to\ndegraded accuracy in multi-turn conversations. We introduce EpiCache, a\ntraining-free KV cache management framework for long conversational question\nanswering (LongConvQA) under fixed memory budgets. EpiCache bounds cache growth\nthrough block-wise prefill and preserves topic-relevant context via episodic KV\ncompression, which clusters conversation history into coherent episodes and\napplies episode-specific KV cache eviction. We further design an adaptive\nlayer-wise budget allocation strategy that measures each layer's sensitivity to\neviction and distributes the memory budget across layers accordingly. Across\nthree LongConvQA benchmarks, EpiCache improves accuracy by up to 40% over\nrecent baselines, sustains near-full KV accuracy under 4-6x compression, and\nreduces latency and memory by up to 2.4x and 3.5x, thereby enabling efficient\nmulti-turn interaction under strict resource constraints.", "published": "2025-09-22 06:56:35", "link": "http://arxiv.org/abs/2509.17396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis", "abstract": "We introduce FinDebate, a multi-agent framework for financial analysis,\nintegrating collaborative debate with domain-specific Retrieval-Augmented\nGeneration (RAG). Five specialized agents, covering earnings, market,\nsentiment, valuation, and risk, run in parallel to synthesize evidence into\nmulti-dimensional insights. To mitigate overconfidence and improve reliability,\nwe introduce a safe debate protocol that enables agents to challenge and refine\ninitial conclusions while preserving coherent recommendations. Experimental\nresults, based on both LLM-based and human evaluations, demonstrate the\nframework's efficacy in producing high-quality analysis with calibrated\nconfidence levels and actionable investment strategies across multiple time\nhorizons.", "published": "2025-09-22 06:56:27", "link": "http://arxiv.org/abs/2509.17395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Program Synthesis via Test-Time Transduction", "abstract": "We introduce transductive program synthesis, a new formulation of the program\nsynthesis task that explicitly leverages test inputs during synthesis. While\nprior approaches to program synthesis--whether based on natural language\ndescriptions or input-output examples--typically aim to generalize from\ntraining examples, they often struggle with robustness, especially in\nreal-world settings where training examples are limited and test inputs involve\nvarious edge cases. To address this, we propose a novel framework that improves\nrobustness by treating synthesis as an active learning over a finite hypothesis\nclass defined by programs' outputs. We use an LLM to predict outputs for\nselected test inputs and eliminate inconsistent hypotheses, where the inputs\nare chosen via a greedy maximin algorithm to minimize the number of LLM queries\nrequired. We evaluate our approach on two real-world datasets: Playgol, a\nstring transformation benchmark, and MBPP+, a Python code generation benchmark.\nWe demonstrate that our method significantly improves program synthesis in both\naccuracy and efficiency. We release our code at\nhttps://github.com/klee972/SYNTRA.", "published": "2025-09-22 06:53:32", "link": "http://arxiv.org/abs/2509.17393v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Robustness of Neurosymbolic Reasoners on First-Order Logic Problems", "abstract": "Recent trends in NLP aim to improve reasoning capabilities in Large Language\nModels (LLMs), with key focus on generalization and robustness to variations in\ntasks. Counterfactual task variants introduce minimal but semantically\nmeaningful changes to otherwise valid first-order logic (FOL) problem instances\naltering a single predicate or swapping roles of constants to probe whether a\nreasoning system can maintain logical consistency under perturbation. Previous\nstudies showed that LLMs becomes brittle on counterfactual variations,\nsuggesting that they often rely on spurious surface patterns to generate\nresponses. In this work, we explore if a neurosymbolic (NS) approach that\nintegrates an LLM and a symbolic logical solver could mitigate this problem.\nExperiments across LLMs of varying sizes show that NS methods are more robust\nbut perform worse overall that purely neural methods. We then propose NSCoT\nthat combines an NS method and Chain-of-Thought (CoT) prompting and demonstrate\nthat while it improves performance, NSCoT still lags behind standard CoT. Our\nanalysis opens research directions for future work.", "published": "2025-09-22 06:35:27", "link": "http://arxiv.org/abs/2509.17377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scale-free Characteristics of Multilingual Legal Texts and the Limitations of LLMs", "abstract": "We present a comparative analysis of text complexity across domains using\nscale-free metrics. We quantify linguistic complexity via Heaps' exponent\n$\\beta$ (vocabulary growth), Taylor's exponent $\\alpha$ (word-frequency\nfluctuation scaling), compression rate $r$ (redundancy), and entropy. Our\ncorpora span three domains: legal documents (statutes, cases, deeds) as a\nspecialized domain, general natural language texts (literature, Wikipedia), and\nAI-generated (GPT) text. We find that legal texts exhibit slower vocabulary\ngrowth (lower $\\beta$) and higher term consistency (higher $\\alpha$) than\ngeneral texts. Within legal domain, statutory codes have the lowest $\\beta$ and\nhighest $\\alpha$, reflecting strict drafting conventions, while cases and deeds\nshow higher $\\beta$ and lower $\\alpha$. In contrast, GPT-generated text shows\nthe statistics more aligning with general language patterns. These results\ndemonstrate that legal texts exhibit domain-specific structures and\ncomplexities, which current generative models do not fully replicate.", "published": "2025-09-22 05:34:15", "link": "http://arxiv.org/abs/2509.17367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Late Than Never: Evaluation of Latency Metrics for Simultaneous Speech-to-Text Translation", "abstract": "Simultaneous speech-to-text translation (SimulST) systems have to balance\ntranslation quality with latency--the delay between speech input and the\ntranslated output. While quality evaluation is well established, accurate\nlatency measurement remains a challenge. Existing metrics often produce\ninconsistent or misleading results, especially in the widely used short-form\nsetting, where speech is artificially presegmented. In this paper, we present\nthe first comprehensive analysis of SimulST latency metrics across language\npairs, systems, and both short- and long-form regimes. We uncover a structural\nbias in current metrics related to segmentation that undermines fair and\nmeaningful comparisons. To address this, we introduce YAAL (Yet Another Average\nLagging), a refined latency metric that delivers more accurate evaluations in\nthe short-form regime. We extend YAAL to LongYAAL for unsegmented audio and\npropose SoftSegmenter, a novel resegmentation tool based on word-level\nalignment. Our experiments show that YAAL and LongYAAL outperform popular\nlatency metrics, while SoftSegmenter enhances alignment quality in long-form\nevaluation, together enabling more reliable assessments of SimulST systems.", "published": "2025-09-22 04:21:19", "link": "http://arxiv.org/abs/2509.17349v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning", "abstract": "Continual learning (CL) is essential for deploying large language models\n(LLMs) in dynamic real-world environments without the need for costly\nretraining. Recent model merging-based methods have attracted significant\nattention, but they still struggle to effectively manage the trade-off between\nlearning new knowledge and preventing forgetting, a challenge largely stemming\nfrom suboptimal number of merges and merging frequency. In this paper, we\nintroduce Adaptive Iterative Model Merging (AimMerging), a novel CL framework\nthat utilizes learning and forgetting signals from the training trajectory to\ndynamically monitor the model's training status. Guided by dynamic monitoring,\nthe training trajectory-guided merge controller adaptively determines the\ntiming and frequency of iterative fusion, while the rehearsal-based knowledge\nfusion module computes the merging weights and executes the fusion.\nComprehensive experiments on three CL benchmarks with various model sizes (from\n770M to 13B) demonstrate that AimMerging achieves significant performance\nimprovements over existing state-of-the-art methods, with an average relative\nimprovement of 80% and 59% on FWT and BWT, respectively. The source code is\nprovided for reproducibility.", "published": "2025-09-22 04:19:29", "link": "http://arxiv.org/abs/2509.17348v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code", "abstract": "Increasing complexity in software systems places a growing demand on\nreasoning tools that unlock vulnerabilities manifest in source code. Many\ncurrent approaches focus on vulnerability analysis as a classifying task,\noversimplifying the nuanced and context-dependent real-world scenarios. Even\nthough current code large language models (LLMs) excel in code understanding,\nthey often pay little attention to security-specific reasoning. We propose\nLLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code\nthrough question-answering (QA). Our model is trained to integrate paired code\nand natural queries into a unified space, enhancing reasoning and\ncontext-dependent insights about code vulnerability. To evaluate our model\nperformance, we construct a curated dataset of real-world vulnerabilities\npaired with security-focused questions and answers. Our model outperforms\nstate-of-the-art general-purpose and code LLMs in the QA and detection tasks.\nWe further explain decision-making by conducting qualitative analysis to\nhighlight capabilities and limitations. By integrating code and QA, LLaVul\nenables more interpretable and security-focused code understanding.", "published": "2025-09-22 03:14:22", "link": "http://arxiv.org/abs/2509.17337v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mano Report", "abstract": "Graphical user interfaces (GUIs) are the primary medium for human-computer\ninteraction, yet automating GUI interactions remains challenging due to the\ncomplexity of visual elements, dynamic environments, and the need for\nmulti-step reasoning. Existing methods based on vision-language models (VLMs)\noften suffer from limited resolution, domain mismatch, and insufficient\nsequential decisionmaking capability. To address these issues, we propose Mano,\na robust GUI agent built upon a multi-modal foundation model pre-trained on\nextensive web and computer system data. Our approach integrates a novel\nsimulated environment for high-fidelity data generation, a three-stage training\npipeline (supervised fine-tuning, offline reinforcement learning, and online\nreinforcement learning), and a verification module for error recovery. Mano\ndemonstrates state-of-the-art performance on multiple GUI benchmarks, including\nMind2Web and OSWorld, achieving significant improvements in success rate and\noperational accuracy. Our work provides new insights into the effective\nintegration of reinforcement learning with VLMs for practical GUI agent\ndeployment, highlighting the importance of domain-specific data, iterative\ntraining, and holistic reward design.", "published": "2025-09-22 03:13:58", "link": "http://arxiv.org/abs/2509.17336v1", "categories": ["cs.MM", "cs.CL", "cs.CV"], "primary_category": "cs.MM"}
{"title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "abstract": "Tool-augmented large language models (LLMs), hereafter LLM agents, leverage\nexternal tools to solve diverse tasks and interface with the real world.\nHowever, current training practices largely rely on supervised fine-tuning\n(SFT) over static trajectories or reinforcement learning (RL) on narrow tasks,\nand generalize poorly beyond development settings, leading to brittleness with\nnew tools and unseen workflows. Because code execution reflects many structures\nof real-world workflows, coding problems provide a natural basis for building\nagent training environments. Motivated by this, we introduce CodeGym, a\nscalable framework that synthesizes diverse, verifiable, and controllable\nmulti-turn tool-use environments for agent RL, enabling LLM agents to explore\nand master various workflows actively. CodeGym rewrites static coding problems\ninto interactive environments by extracting atomic functions or logic into\ncallable tools, yielding verifiable tasks that span various tool-execution\nworkflows. Models of varying sizes and chain-of-thought configurations, trained\nin CodeGym, exhibit consistent out-of-distribution generalizability; for\nexample, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points\non the OOD benchmark $\\tau$-Bench. These results highlight CodeGym as a step\ntoward scalable general-purpose RL environments that align with real-world\nagent workflows.", "published": "2025-09-22 03:03:56", "link": "http://arxiv.org/abs/2509.17325v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "OpenGVL - Benchmarking Visual Temporal Progress for Data Curation", "abstract": "Data scarcity remains one of the most limiting factors in driving progress in\nrobotics. However, the amount of available robotics data in the wild is growing\nexponentially, creating new opportunities for large-scale data utilization.\nReliable temporal task completion prediction could help automatically annotate\nand curate this data at scale. The Generative Value Learning (GVL) approach was\nrecently proposed, leveraging the knowledge embedded in vision-language models\n(VLMs) to predict task progress from visual observations. Building upon GVL, we\npropose OpenGVL, a comprehensive benchmark for estimating task progress across\ndiverse challenging manipulation tasks involving both robotic and human\nembodiments. We evaluate the capabilities of publicly available open-source\nfoundation models, showing that open-source model families significantly\nunderperform closed-source counterparts, achieving only approximately $70\\%$ of\ntheir performance on temporal progress prediction tasks. Furthermore, we\ndemonstrate how OpenGVL can serve as a practical tool for automated data\ncuration and filtering, enabling efficient quality assessment of large-scale\nrobotics datasets. We release the benchmark along with the complete codebase at\n\\href{github.com/budzianowski/opengvl}{OpenGVL}.", "published": "2025-09-22 02:52:55", "link": "http://arxiv.org/abs/2509.17321v1", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models", "abstract": "Mathematical reasoning poses significant challenges for Large Language Models\n(LLMs) due to its demand for multi-step reasoning and abstract conceptual\nintegration. While recent test-time scaling techniques rely heavily on\nhigh-quality, challenging problems, the scarcity of Olympiad-level math\nproblems remains a bottleneck. We introduce CogAtom, a novel cognitive\natom-based framework for synthesizing mathematically rigorous and cognitively\ndiverse problems. Unlike prior approaches, CogAtom models problem construction\nas a process of selecting and recombining fundamental reasoning units,\ncognitive atoms, extracted from human-authored solutions. A diversity-promoting\nrandom walk algorithm enables exploration of the cognitive atom space, while a\nconstraint-based recombination mechanism ensures logical soundness and\nstructural validity. The combinatorial nature of the graph structure provides a\nnear-infinite space of reasoning paths, and the walk algorithm systematically\nexplores this space to achieve large-scale synthesis of high-quality problems;\nmeanwhile, by controlling the number of cognitive atoms, we can precisely\nadjust problem difficulty, ensuring diversity, scalability, and controllability\nof the generated problems. Experimental results demonstrate that CogAtom\noutperforms existing methods in accuracy, reasoning depth, and diversity,\ngenerating problems that closely match the difficulty of AIME while exceeding\nit in structural variation. Our work offers a cognitively grounded pathway\ntoward scalable, high-quality math problem generation.Our code is publicly\navailable at https://github.com/Icarus-1111/CogAtom.", "published": "2025-09-22 02:48:50", "link": "http://arxiv.org/abs/2509.17318v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text", "abstract": "Most languages lack sufficient data for large-scale monolingual pretraining,\ncreating a \"data wall.\" Multilingual pretraining helps but is limited by\nlanguage imbalance and the \"curse of multilinguality.\" An alternative is to\ntranslate high-resource text with machine translation (MT), which raises three\nquestions: (1) How does MT-derived data scale with model capacity? (2) Can\nsource-side transformations (e.g., simplifying English with an LLM) improve\ngeneralization to native text? (3) How well do models pretrained on MT-derived\ndata adapt when continually trained on limited native text? We investigate\nthese questions by translating English into Indonesian and Tamil--two\ntypologically distant, lower-resource languages--and pretraining GPT-2 models\n(124M-774M) on native or MT-derived corpora from raw and LLM-simplified\nEnglish. We evaluate cross-entropy loss on native text, along with accuracy on\nsyntactic probes and downstream tasks. Our results show that (1) MT-pretrained\nmodels benefit from scaling; (2) source-side simplification harms\ngeneralization to native text; and (3) adapting MT-pretrained models on native\ntext often yields better performance than native-only models, even with less\nnative data. However, tasks requiring cultural nuance (e.g., toxicity\ndetection) demand more exposure to native data.", "published": "2025-09-22 02:48:43", "link": "http://arxiv.org/abs/2509.17317v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-View Attention Multiple-Instance Learning Enhanced by LLM Reasoning for Cognitive Distortion Detection", "abstract": "Cognitive distortions have been closely linked to mental health disorders,\nyet their automatic detection remained challenging due to contextual ambiguity,\nco-occurrence, and semantic overlap. We proposed a novel framework that\ncombines Large Language Models (LLMs) with Multiple-Instance Learning (MIL)\narchitecture to enhance interpretability and expression-level reasoning. Each\nutterance was decomposed into Emotion, Logic, and Behavior (ELB) components,\nwhich were processed by LLMs to infer multiple distortion instances, each with\na predicted type, expression, and model-assigned salience score. These\ninstances were integrated via a Multi-View Gated Attention mechanism for final\nclassification. Experiments on Korean (KoACD) and English (Therapist QA)\ndatasets demonstrate that incorporating ELB and LLM-inferred salience scores\nimproves classification performance, especially for distortions with high\ninterpretive ambiguity. Our results suggested a psychologically grounded and\ngeneralizable approach for fine-grained reasoning in mental health NLP.", "published": "2025-09-22 00:18:58", "link": "http://arxiv.org/abs/2509.17292v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling", "abstract": "We introduce CoDe-KG, an open-source, end-to-end pipeline for extracting\nsentence-level knowledge graphs by combining robust coreference resolution with\nsyntactic sentence decomposition. Using our model, we contribute a dataset of\nover 150,000 knowledge triples, which is open source. We also contribute a\ntraining corpus of 7248 rows for sentence complexity, 190 rows of gold human\nannotations for co-reference resolution using open source lung-cancer abstracts\nfrom PubMed, 900 rows of gold human annotations for sentence conversion\npolicies, and 398 triples of gold human annotations. We systematically select\noptimal prompt-model pairs across five complexity categories, showing that\nhybrid chain-of-thought and few-shot prompting yields up to 99.8% exact-match\naccuracy on sentence simplification. On relation extraction (RE), our pipeline\nachieves 65.8% macro-F1 on REBEL, an 8-point gain over the prior state of the\nart, and 75.7% micro-F1 on WebNLG2, while matching or exceeding performance on\nWiki-NRE and CaRB. Ablation studies demonstrate that integrating coreference\nand decomposition increases recall on rare relations by over 20%. Code and\ndataset are available at https://github.com/KaushikMahmud/CoDe-KG_EMNLP_2025", "published": "2025-09-22 00:01:50", "link": "http://arxiv.org/abs/2509.17289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning", "abstract": "Recent advances in Large Multi-modal Models (LMMs) have demonstrated their\nremarkable success as general-purpose multi-modal assistants, with particular\nfocuses on holistic image- and video-language understanding. Conversely, less\nattention has been given to scaling fine-grained pixel-level understanding\ncapabilities, where the models are expected to realize pixel-level alignment\nbetween visual signals and language semantics. Some previous studies have\napplied LMMs to related tasks such as region-level captioning and referring\nexpression segmentation. However, these models are limited to performing either\nreferring or segmentation tasks independently and fail to integrate these\nfine-grained perception capabilities into visual reasoning. To bridge this gap,\nwe propose UniPixel, a large multi-modal model capable of flexibly\ncomprehending visual prompt inputs and generating mask-grounded responses. Our\nmodel distinguishes itself by seamlessly integrating pixel-level perception\nwith general visual understanding capabilities. Specifically, UniPixel\nprocesses visual prompts and generates relevant masks on demand, and performs\nsubsequent reasoning conditioning on these intermediate pointers during\ninference, thereby enabling fine-grained pixel-level reasoning. The\neffectiveness of our approach has been verified on 10 benchmarks across a\ndiverse set of tasks, including pixel-level referring/segmentation and\nobject-centric understanding in images/videos. A novel PixelQA task that\njointly requires referring, segmentation, and question answering is also\ndesigned to verify the flexibility of our method.", "published": "2025-09-22 17:59:40", "link": "http://arxiv.org/abs/2509.18094v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "abstract": "Large language models (LLMs) have demonstrated strong reasoning and tool-use\ncapabilities, yet they often fail in real-world tool-interactions due to\nincorrect parameterization, poor tool selection, or misinterpretation of user\nintent. These issues often stem from an incomplete understanding of user goals\nand inadequate comprehension of tool documentation. While Chain-of-Thought\n(CoT) prompting has proven effective for enhancing reasoning in general\ncontexts, our analysis reveals that free-form CoT is insufficient and sometimes\ncounterproductive for structured function-calling tasks. To address this, we\nintroduce a curriculum-inspired framework that leverages structured reasoning\ntemplates to guide LLMs through more deliberate step-by-step instructions for\ngenerating function callings. Experimental results show that our method reduces\ntool-use errors, achieving 3-12% relative improvements over strong baselines\nacross diverse model series and approaches. Moreover, our framework enhances\nthe robustness, interpretability, and transparency of tool-using agents,\nadvancing the development of more reliable AI assistants for real-world\napplications.", "published": "2025-09-22 17:55:14", "link": "http://arxiv.org/abs/2509.18076v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM", "abstract": "Large language model (LLM) developers aim for their models to be honest,\nhelpful, and harmless. However, when faced with malicious requests, models are\ntrained to refuse, sacrificing helpfulness. We show that frontier LLMs can\ndevelop a preference for dishonesty as a new strategy, even when other options\nare available. Affected models respond to harmful requests with outputs that\nsound harmful but are subtly incorrect or otherwise harmless in practice. This\nbehavior emerges with hard-to-predict variations even within models from the\nsame model family. We find no apparent cause for the propensity to deceive, but\nwe show that more capable models are better at executing this strategy.\nStrategic dishonesty already has a practical impact on safety evaluations, as\nwe show that dishonest responses fool all output-based monitors used to detect\njailbreaks that we test, rendering benchmark scores unreliable. Further,\nstrategic dishonesty can act like a honeypot against malicious users, which\nnoticeably obfuscates prior jailbreak attacks. While output monitors fail, we\nshow that linear probes on internal activations can be used to reliably detect\nstrategic dishonesty. We validate probes on datasets with verifiable outcomes\nand by using their features as steering vectors. Overall, we consider strategic\ndishonesty as a concrete example of a broader concern that alignment of LLMs is\nhard to control, especially when helpfulness and harmlessness conflict.", "published": "2025-09-22 17:30:56", "link": "http://arxiv.org/abs/2509.18058v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory", "abstract": "We explore whether techniques from AI can help discover new combinatorial\nstructures that improve provable limits on efficient algorithms. Specifically,\nwe use AlphaEvolve (an LLM coding agent) to study two settings:\n  a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve a\nrecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)\nlower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on\nrandom 3- and 4-regular graphs. Our improved lower bounds are obtained by\nconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, using\nAlphaEvolve. Additionally, via analytical arguments we strengthen the upper\nbounds to settle the computational hardness of these questions up to an error\nin the third decimal place.\n  b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain new\ninapproximability results, proving that it is NP-hard to approximate MAX-4-CUT\nand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, using\nAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves\nupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current\nbest gadget-based inapproximability result of $0.9853$, but falls short of\nimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadget\nreduction from \"standard\" H{\\aa}stad-style PCPs.\n  A key technical challenge we faced: verifying a candidate construction\nproduced by AlphaEvolve is costly (often requiring exponential time). In both\nsettings above, our results were enabled by using AlphaEvolve itself to evolve\nthe verification procedure to be faster (sometimes by $10,000\\times$). We\nconclude with a discussion of norms by which to assess the assistance from AI\nin developing proofs.", "published": "2025-09-22 17:30:33", "link": "http://arxiv.org/abs/2509.18057v1", "categories": ["cs.LG", "cs.AI", "cs.CC", "math.CO"], "primary_category": "cs.LG"}
{"title": "A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem", "abstract": "Selecting a solution algorithm for the Facility Layout Problem (FLP), an\nNP-hard optimization problem with a multiobjective trade-off, is a complex task\nthat requires deep expert knowledge. The performance of a given algorithm\ndepends on specific problem characteristics such as its scale, objectives, and\nconstraints. This creates a need for a data-driven recommendation method to\nguide algorithm selection in automated design systems. This paper introduces a\nnew recommendation method to make such expertise accessible, based on a\nKnowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. To\naddress this, a domain-specific knowledge graph is constructed from published\nliterature. The method then employs a multi-faceted retrieval mechanism to\ngather relevant evidence from this knowledge graph using three distinct\napproaches, which include a precise graph-based search, flexible vector-based\nsearch, and high-level cluster-based search. The retrieved evidence is utilized\nby a Large Language Model (LLM) to generate algorithm recommendations with\ndata-driven reasoning. The proposed KG-RAG method is compared against a\ncommercial LLM chatbot with access to the knowledge base as a table, across a\nseries of diverse, real-world FLP test cases. Based on recommendation accuracy\nand reasoning capability, the proposed method performed significantly better\nthan the commercial LLM chatbot.", "published": "2025-09-22 17:29:10", "link": "http://arxiv.org/abs/2509.18054v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba", "abstract": "End-to-end reinforcement learning (RL) for humanoid locomotion is appealing\nfor its compact perception-action mapping, yet practical policies often suffer\nfrom training instability, inefficient feature fusion, and high actuation cost.\nWe present HuMam, a state-centric end-to-end RL framework that employs a\nsingle-layer Mamba encoder to fuse robot-centric states with oriented footstep\ntargets and a continuous phase clock. The policy outputs joint position targets\ntracked by a low-level PD loop and is optimized with PPO. A concise six-term\nreward balances contact quality, swing smoothness, foot placement, posture, and\nbody stability while implicitly promoting energy saving. On the JVRC-1 humanoid\nin mc-mujoco, HuMam consistently improves learning efficiency, training\nstability, and overall task performance over a strong feedforward baseline,\nwhile reducing power consumption and torque peaks. To our knowledge, this is\nthe first end-to-end humanoid RL controller that adopts Mamba as the fusion\nbackbone, demonstrating tangible gains in efficiency, stability, and control\neconomy.", "published": "2025-09-22 17:19:55", "link": "http://arxiv.org/abs/2509.18046v1", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Hybrid Reputation Aggregation: A Robust Defense Mechanism for Adversarial Federated Learning in 5G and Edge Network Environments", "abstract": "Federated Learning (FL) in 5G and edge network environments face severe\nsecurity threats from adversarial clients. Malicious participants can perform\nlabel flipping, inject backdoor triggers, or launch Sybil attacks to corrupt\nthe global model. This paper introduces Hybrid Reputation Aggregation (HRA), a\nnovel robust aggregation mechanism designed to defend against diverse\nadversarial behaviors in FL without prior knowledge of the attack type. HRA\ncombines geometric anomaly detection with momentum-based reputation tracking of\nclients. In each round, it detects outlier model updates via distance-based\ngeometric analysis while continuously updating a trust score for each client\nbased on historical behavior. This hybrid approach enables adaptive filtering\nof suspicious updates and long-term penalization of unreliable clients,\ncountering attacks ranging from backdoor insertions to random noise Byzantine\nfailures. We evaluate HRA on a large-scale proprietary 5G network dataset (3M+\nrecords) and the widely used NF-CSE-CIC-IDS2018 benchmark under diverse\nadversarial attack scenarios. Experimental results reveal that HRA achieves\nrobust global model accuracy of up to 98.66% on the 5G dataset and 96.60% on\nNF-CSE-CIC-IDS2018, outperforming state-of-the-art aggregators such as Krum,\nTrimmed Mean, and Bulyan by significant margins. Our ablation studies further\ndemonstrate that the full hybrid system achieves 98.66% accuracy, while the\nanomaly-only and reputation-only variants drop to 84.77% and 78.52%,\nrespectively, validating the synergistic value of our dual-mechanism approach.\nThis demonstrates HRA's enhanced resilience and robustness in 5G/edge federated\nlearning deployments, even under significant adversarial conditions.", "published": "2025-09-22 17:18:59", "link": "http://arxiv.org/abs/2509.18044v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Deep Learning as the Disciplined Construction of Tame Objects", "abstract": "One can see deep-learning models as compositions of functions within the\nso-called tame geometry. In this expository note, we give an overview of some\ntopics at the interface of tame geometry (also known as o-minimality),\noptimization theory, and deep learning theory and practice. To do so, we\ngradually introduce the concepts and tools used to build convergence guarantees\nfor stochastic gradient descent in a general nonsmooth nonconvex, but tame,\nsetting. This illustrates some ways in which tame geometry is a natural\nmathematical framework for the study of AI systems, especially within Deep\nLearning.", "published": "2025-09-22 17:00:40", "link": "http://arxiv.org/abs/2509.18025v1", "categories": ["math.OC", "cs.AI", "cs.LG", "math.LO", "stat.ML"], "primary_category": "math.OC"}
{"title": "Beyond Diagnosis: Evaluating Multimodal LLMs for Pathology Localization in Chest Radiographs", "abstract": "Recent work has shown promising performance of frontier large language models\n(LLMs) and their multimodal counterparts in medical quizzes and diagnostic\ntasks, highlighting their potential for broad clinical utility given their\naccessible, general-purpose nature. However, beyond diagnosis, a fundamental\naspect of medical image interpretation is the ability to localize pathological\nfindings. Evaluating localization not only has clinical and educational\nrelevance but also provides insight into a model's spatial understanding of\nanatomy and disease. Here, we systematically assess two general-purpose MLLMs\n(GPT-4 and GPT-5) and a domain-specific model (MedGemma) in their ability to\nlocalize pathologies on chest radiographs, using a prompting pipeline that\noverlays a spatial grid and elicits coordinate-based predictions. Averaged\nacross nine pathologies in the CheXlocalize dataset, GPT-5 exhibited a\nlocalization accuracy of 49.7%, followed by GPT-4 (39.1%) and MedGemma (17.7%),\nall lower than a task-specific CNN baseline (59.9%) and a radiologist benchmark\n(80.1%). Despite modest performance, error analysis revealed that GPT-5's\npredictions were largely in anatomically plausible regions, just not always\nprecisely localized. GPT-4 performed well on pathologies with fixed anatomical\nlocations, but struggled with spatially variable findings and exhibited\nanatomically implausible predictions more frequently. MedGemma demonstrated the\nlowest performance on all pathologies, showing limited capacity to generalize\nto this novel task. Our findings highlight both the promise and limitations of\ncurrent MLLMs in medical imaging and underscore the importance of integrating\nthem with task-specific tools for reliable use.", "published": "2025-09-22 16:54:23", "link": "http://arxiv.org/abs/2509.18015v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise", "abstract": "Sharpness-aware minimization (SAM) has emerged as a highly effective\ntechnique for improving model generalization, but its underlying principles are\nnot fully understood. We investigated the phenomenon known as m-sharpness,\nwhere the performance of SAM improves monotonically as the micro-batch size for\ncomputing perturbations decreases. Leveraging an extended Stochastic\nDifferential Equation (SDE) framework, combined with an analysis of the\nstructure of stochastic gradient noise (SGN), we precisely characterize the\ndynamics of various SAM variants. Our findings reveal that the stochastic noise\nintroduced during SAM perturbations inherently induces a variance-based\nsharpness regularization effect. Motivated by our theoretical insights, we\nintroduce Reweighted SAM, which employs sharpness-weighted sampling to mimic\nthe generalization benefits of m-SAM while remaining parallelizable.\nComprehensive experiments validate the effectiveness of our theoretical\nanalysis and proposed method.", "published": "2025-09-22 16:40:42", "link": "http://arxiv.org/abs/2509.18001v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Narcissus Hypothesis:Descending to the Rung of Illusion", "abstract": "Modern foundational models increasingly reflect not just world knowledge, but\npatterns of human preference embedded in their training data. We hypothesize\nthat recursive alignment-via human feedback and model-generated corpora-induces\na social desirability bias, nudging models to favor agreeable or flattering\nresponses over objective reasoning. We refer to it as the Narcissus Hypothesis\nand test it across 31 models using standardized personality assessments and a\nnovel Social Desirability Bias score. Results reveal a significant drift toward\nsocially conforming traits, with profound implications for corpus integrity and\nthe reliability of downstream inferences. We then offer a novel epistemological\ninterpretation, tracing how recursive bias may collapse higher-order reasoning\ndown Pearl's Ladder of Causality, culminating in what we refer to as the Rung\nof Illusion.", "published": "2025-09-22 16:39:22", "link": "http://arxiv.org/abs/2509.17999v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs", "abstract": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of\nthe Gaussian process (GP) kernel, which plays a central role in balancing\nexploration and exploitation under limited evaluation budgets. Traditional BO\nmethods often rely on fixed or heuristic kernel selection strategies, which can\nresult in slow convergence or suboptimal solutions when the chosen kernel is\npoorly suited to the underlying objective function. To address this limitation,\nwe propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO\nwith large language models (LLMs). Concretely, CAKE leverages LLMs as the\ncrossover and mutation operators to adaptively generate and refine GP kernels\nbased on the observed data throughout the optimization process. To maximize the\npower of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to\nselect the most effective kernel through balancing the model fit measured by\nthe Bayesian information criterion (BIC) with the expected improvement at each\niteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO\nmethod consistently outperforms established baselines across a range of\nreal-world tasks, including hyperparameter optimization, controller tuning, and\nphotonic chip design. Our code is publicly available at\nhttps://github.com/cake4bo/cake.", "published": "2025-09-22 16:39:12", "link": "http://arxiv.org/abs/2509.17998v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents", "abstract": "Current Large Reasoning Models (LRMs) exhibit significant limitations in\nreliability and transparency, often showing a collapse in reasoning\ncapabilities when faced with high-complexity, long-horizon tasks. This\n\"illusion of thinking\" is frequently an artifact of non-agentic, black-box\nevaluation paradigms that fail to cultivate robust problem-solving processes.\nIn response, we introduce The STAR-XAI Protocol (Socratic, Transparent,\nAgentic, Reasoning - for eXplainable Artificial Intelligence), a novel\nmethodology for training and operating verifiably reliable AI agents. Our\nmethod reframes the human-AI interaction as a structured, Socratic dialogue,\ngoverned by an explicit and evolving rulebook, the Consciousness Transfer\nPackage (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc\nstrategic justification and a state-locking Checksum that prevents error\naccumulation, the protocol transforms a powerful but opaque LRM into a\ndisciplined \"Clear Box\" agent. We demonstrate the efficacy of this method\nthrough an exhaustive 25-move case study in the complex strategic game \"Caps i\nCaps\". The agent not only solved the high-complexity puzzle but also\ndemonstrated Second-Order Agency, identifying flaws in its own\nsupervisor-approved plans and adapting its core integrity protocols mid-task.\nThe STAR-XAI Protocol offers a practical pathway to creating AI agents that are\nnot just high-performing, but also transparent, auditable, and trustworthy by\ndesign.", "published": "2025-09-22 16:24:17", "link": "http://arxiv.org/abs/2509.17978v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Intra-Cluster Mixup: An Effective Data Augmentation Technique for Complementary-Label Learning", "abstract": "In this paper, we investigate the challenges of complementary-label learning\n(CLL), a specialized form of weakly-supervised learning (WSL) where models are\ntrained with labels indicating classes to which instances do not belong, rather\nthan standard ordinary labels. This alternative supervision is appealing\nbecause collecting complementary labels is generally cheaper and less\nlabor-intensive. Although most existing research in CLL emphasizes the\ndevelopment of novel loss functions, the potential of data augmentation in this\ndomain remains largely underexplored. In this work, we uncover that the\nwidely-used Mixup data augmentation technique is ineffective when directly\napplied to CLL. Through in-depth analysis, we identify that the\ncomplementary-label noise generated by Mixup negatively impacts the performance\nof CLL models. We then propose an improved technique called Intra-Cluster Mixup\n(ICM), which only synthesizes augmented data from nearby examples, to mitigate\nthe noise effect. ICM carries the benefits of encouraging complementary label\nsharing of nearby examples, and leads to substantial performance improvements\nacross synthetic and real-world labeled datasets. In particular, our wide\nspectrum of experimental results on both balanced and imbalanced CLL settings\njustifies the potential of ICM in allying with state-of-the-art CLL algorithms,\nachieving significant accuracy increases of 30% and 10% on MNIST and CIFAR\ndatasets, respectively.", "published": "2025-09-22 16:20:41", "link": "http://arxiv.org/abs/2509.17971v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference", "abstract": "Deep neural networks (DNNs) have been widely applied in diverse applications,\nbut the problems of high latency and energy overhead are inevitable on\nresource-constrained devices. To address this challenge, most researchers focus\non the dynamic voltage and frequency scaling (DVFS) technique to balance the\nlatency and energy consumption by changing the computing frequency of\nprocessors. However, the adjustment of memory frequency is usually ignored and\nnot fully utilized to achieve efficient DNN inference, which also plays a\nsignificant role in the inference time and energy consumption. In this paper,\nwe first investigate the impact of joint memory frequency and computing\nfrequency scaling on the inference time and energy consumption with a\nmodel-based and data-driven method. Then by combining with the fitting\nparameters of different DNN models, we give a preliminary analysis for the\nproposed model to see the effects of adjusting memory frequency and computing\nfrequency simultaneously. Finally, simulation results in local inference and\ncooperative inference cases further validate the effectiveness of jointly\nscaling the memory frequency and computing frequency to reduce the energy\nconsumption of devices.", "published": "2025-09-22 16:20:29", "link": "http://arxiv.org/abs/2509.17970v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On the Variational Costs of Changing Our Minds", "abstract": "The human mind is capable of extraordinary achievements, yet it often appears\nto work against itself. It actively defends its cherished beliefs even in the\nface of contradictory evidence, conveniently interprets information to conform\nto desired narratives, and selectively searches for or avoids information to\nsuit its various purposes. Despite these behaviours deviating from common\nnormative standards for belief updating, we argue that such 'biases' are not\ninherently cognitive flaws, but rather an adaptive response to the significant\npragmatic and cognitive costs associated with revising one's beliefs. This\npaper introduces a formal framework that aims to model the influence of these\ncosts on our belief updating mechanisms.\n  We treat belief updating as a motivated variational decision, where agents\nweigh the perceived 'utility' of a belief against the informational cost\nrequired to adopt a new belief state, quantified by the Kullback-Leibler\ndivergence from the prior to the variational posterior. We perform\ncomputational experiments to demonstrate that simple instantiations of this\nresource-rational model can be used to qualitatively emulate commonplace human\nbehaviours, including confirmation bias and attitude polarisation. In doing so,\nwe suggest that this framework makes steps toward a more holistic account of\nthe motivated Bayesian mechanics of belief change and provides practical\ninsights for predicting, compensating for, and correcting deviations from\ndesired belief updating processes.", "published": "2025-09-22 16:13:06", "link": "http://arxiv.org/abs/2509.17957v1", "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.AI"}
{"title": "\"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment", "abstract": "Assessing fairness in artificial intelligence (AI) typically involves AI\nexperts who select protected features, fairness metrics, and set fairness\nthresholds. However, little is known about how stakeholders, particularly those\naffected by AI outcomes but lacking AI expertise, assess fairness. To address\nthis gap, we conducted a qualitative study with 30 stakeholders without AI\nexpertise, representing potential decision subjects in a credit rating\nscenario, to examine how they assess fairness when placed in the role of\ndeciding on features with priority, metrics, and thresholds. We reveal that\nstakeholders' fairness decisions are more complex than typical AI expert\npractices: they considered features far beyond legally protected features,\ntailored metrics for specific contexts, set diverse yet stricter fairness\nthresholds, and even preferred designing customized fairness. Our results\nextend the understanding of how stakeholders can meaningfully contribute to AI\nfairness governance and mitigation, underscoring the importance of\nincorporating stakeholders' nuanced fairness judgments.", "published": "2025-09-22 16:12:12", "link": "http://arxiv.org/abs/2509.17956v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "StefaLand: An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions", "abstract": "Stewarding natural resources, mitigating floods, droughts, wildfires, and\nlandslides, and meeting growing demands require models that can predict\nclimate-driven land-surface responses and human feedback with high accuracy.\nTraditional impact models, whether process-based, statistical, or machine\nlearning, struggle with spatial generalization due to limited observations and\nconcept drift. Recently proposed vision foundation models trained on satellite\nimagery demand massive compute and are ill-suited for dynamic land-surface\nprediction. We introduce StefaLand, a generative spatiotemporal earth\nfoundation model centered on landscape interactions. StefaLand improves\npredictions on three tasks and four datasets: streamflow, soil moisture, and\nsoil composition, compared to prior state-of-the-art. Results highlight its\nability to generalize across diverse, data-scarce regions and support broad\nland-surface applications. The model builds on a masked autoencoder backbone\nthat learns deep joint representations of landscape attributes, with a\nlocation-aware architecture fusing static and time-series inputs,\nattribute-based representations that drastically reduce compute, and residual\nfine-tuning adapters that enhance transfer. While inspired by prior methods,\ntheir alignment with geoscience and integration in one model enables robust\nperformance on dynamic land-surface tasks. StefaLand can be pretrained and\nfinetuned on academic compute yet outperforms state-of-the-art baselines and\neven fine-tuned vision foundation models. To our knowledge, this is the first\ngeoscience land-surface foundation model that demonstrably improves dynamic\nland-surface interaction predictions and supports diverse downstream\napplications.", "published": "2025-09-22 16:05:45", "link": "http://arxiv.org/abs/2509.17942v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion", "abstract": "This paper considers the problem of enabling robots to navigate dynamic\nenvironments while following instructions. The challenge lies in the\ncombinatorial nature of instruction specifications: each instruction can\ninclude multiple specifications, and the number of possible specification\ncombinations grows exponentially as the robot's skill set expands. For example,\n\"overtake the pedestrian while staying on the right side of the road\" consists\nof two specifications: \"overtake the pedestrian\" and \"walk on the right side of\nthe road.\" To tackle this challenge, we propose ComposableNav, based on the\nintuition that following an instruction involves independently satisfying its\nconstituent specifications, each corresponding to a distinct motion primitive.\nUsing diffusion models, ComposableNav learns each primitive separately, then\ncomposes them in parallel at deployment time to satisfy novel combinations of\nspecifications unseen in training. Additionally, to avoid the onerous need for\ndemonstrations of individual motion primitives, we propose a two-stage training\nprocedure: (1) supervised pre-training to learn a base diffusion model for\ndynamic navigation, and (2) reinforcement learning fine-tuning that molds the\nbase model into different motion primitives. Through simulation and real-world\nexperiments, we show that ComposableNav enables robots to follow instructions\nby generating trajectories that satisfy diverse and unseen combinations of\nspecifications, significantly outperforming both non-compositional VLM-based\npolicies and costmap composing baselines. Videos and additional materials can\nbe found on the project page: https://amrl.cs.utexas.edu/ComposableNav/", "published": "2025-09-22 16:04:50", "link": "http://arxiv.org/abs/2509.17941v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent", "abstract": "Recent advances in GUI agents have achieved remarkable grounding and\naction-prediction performance, yet existing models struggle with unreliable\nreward signals and limited online trajectory generation. In this paper, we\nintroduce Orcust, a framework that integrates Principle-Constrained Reward\nModeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to\nenhance reasoning reliability and data efficiency in interactive GUI tasks. We\nleverages environment-verifiable and LLM-derived principle to enforce\ninterpretable reward signals that constrain long chain-of-thought reasoning and\nrule-based feedback. OVTC spins up instrumented virtual machines to\nautonomously collect structured GUI interaction trajectories with explicit\nprocedural and structural objectives, enabling the training of a stepwise\nreward model that robustly captures human preferences and adheres to\ntask-specific constraints. Extensive experiments on standard GUI benchmarks\ncovering perceptual grounding, foundational operations, and end-to-end task\nexecution reveal that Orcust achieves state-of-the-art performance, improving\nby 22.2\\% on ScreenSpot and 23.9\\% on ScreenSpot-Pro over the base model (i.e.\nQwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the\nreasoning, adaptability and scalability of GUI agents across various\nenvironments and task complexities.", "published": "2025-09-22 15:40:31", "link": "http://arxiv.org/abs/2509.17917v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MEF: A Systematic Evaluation Framework for Text-to-Image Models", "abstract": "Rapid advances in text-to-image (T2I) generation have raised higher\nrequirements for evaluation methodologies. Existing benchmarks center on\nobjective capabilities and dimensions, but lack an application-scenario\nperspective, limiting external validity. Moreover, current evaluations\ntypically rely on either ELO for overall ranking or MOS for dimension-specific\nscoring, yet both methods have inherent shortcomings and limited\ninterpretability. Therefore, we introduce the Magic Evaluation Framework (MEF),\na systematic and practical approach for evaluating T2I models. First, we\npropose a structured taxonomy encompassing user scenarios, elements, element\ncompositions, and text expression forms to construct the Magic-Bench-377, which\nsupports label-level assessment and ensures a balanced coverage of both user\nscenarios and capabilities. On this basis, we combine ELO and\ndimension-specific MOS to generate model rankings and fine-grained assessments\nrespectively. This joint evaluation method further enables us to quantitatively\nanalyze the contribution of each dimension to user satisfaction using\nmultivariate logistic regression. By applying MEF to current T2I models, we\nobtain a leaderboard and key characteristics of the leading models. We release\nour evaluation framework and make Magic-Bench-377 fully open-source to advance\nresearch in the evaluation of visual generative models.", "published": "2025-09-22 15:32:42", "link": "http://arxiv.org/abs/2509.17907v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling", "abstract": "Test-time scaling (TTS) has been shown to improve the performance of large\nlanguage models (LLMs) by sampling and aggregating diverse reasoning paths.\nHowever, existing research has overlooked a critical issue: selection bias of\nreasoning strategies during scaling. Specifically, when generating reasoning\nprocesses, LLMs tend to follow certain strategies (e.g., algebraic solutions\nfor math problems) while neglecting other valid alternatives (e.g., geometric\nsolutions), resulting in insufficient exploration of the solution space. To\nfurther understand the impact of this bias, we present a theoretical analysis\nthat reveals when it undermines the effectiveness of test-time scaling.\nMotivated by this theoretical insight, we introduce TTS-Uniform, a framework\ndesigned to mitigate the selection bias of reasoning strategies. It (i)\nidentifies potential strategies, (ii) uniformly allocates the sampling budget\nacross them, and (iii) filters out unstable strategies prior to aggregation.\nExperimental results show that TTS-Uniform significantly enhances scaling\neffectiveness across multiple mainstream LLMs and benchmark datasets.", "published": "2025-09-22 15:30:56", "link": "http://arxiv.org/abs/2509.17905v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training", "abstract": "This study examines how Critical Care Air Transport Team (CCATT) members are\ntrained using mixed-reality simulations that replicate the high-pressure\nconditions of aeromedical evacuation. Each team - a physician, nurse, and\nrespiratory therapist - must stabilize severely injured soldiers by managing\nventilators, IV pumps, and suction devices during flight. Proficient\nperformance requires clinical expertise and cognitive skills, such as\nsituational awareness, rapid decision-making, effective communication, and\ncoordinated task management, all of which must be maintained under stress.\nRecent advances in simulation and multimodal data analytics enable more\nobjective and comprehensive performance evaluation. In contrast, traditional\ninstructor-led assessments are subjective and may overlook critical events,\nthereby limiting generalizability and consistency. However, AI-based automated\nand more objective evaluation metrics still demand human input to train the AI\nalgorithms to assess complex team dynamics in the presence of environmental\nnoise and the need for accurate re-identification in multi-person tracking. To\naddress these challenges, we introduce a systematic, data-driven assessment\nframework that combines Cognitive Task Analysis (CTA) with Multimodal Learning\nAnalytics (MMLA). We have developed a domain-specific CTA model for CCATT\ntraining and a vision-based action recognition pipeline using a fine-tuned\nHuman-Object Interaction model, the Cascade Disentangling Network (CDN), to\ndetect and track trainee-equipment interactions over time. These interactions\nautomatically yield performance indicators (e.g., reaction time, task\nduration), which are mapped onto a hierarchical CTA model tailored to CCATT\noperations, enabling interpretable, domain-relevant performance evaluations.", "published": "2025-09-22 15:19:45", "link": "http://arxiv.org/abs/2509.17888v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Confidence-gated training for efficient early-exit neural networks", "abstract": "Early-exit neural networks reduce inference cost by enabling confident\npredictions at intermediate layers. However, joint training often leads to\ngradient interference, with deeper classifiers dominating optimization. We\npropose Confidence-Gated Training (CGT), a paradigm that conditionally\npropagates gradients from deeper exits only when preceding exits fail. This\nencourages shallow classifiers to act as primary decision points while\nreserving deeper layers for harder inputs. By aligning training with the\ninference-time policy, CGT mitigates overthinking, improves early-exit\naccuracy, and preserves efficiency. Experiments on the Indian Pines and\nFashion-MNIST benchmarks show that CGT lowers average inference cost while\nimproving overall accuracy, offering a practical solution for deploying deep\nmodels in resource-constrained environments.", "published": "2025-09-22 15:18:21", "link": "http://arxiv.org/abs/2509.17885v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Understanding Post-Training Structural Changes in Large Language Models", "abstract": "Post-training fundamentally alters the behavior of large language models\n(LLMs), yet its impact on the internal parameter space remains poorly\nunderstood. In this work, we conduct a systematic singular value decomposition\n(SVD) analysis of principal linear layers in pretrained LLMs, focusing on two\nwidely adopted post-training methods: instruction tuning and\nlong-chain-of-thought (Long-CoT) distillation. Our analysis reveals two\nconsistent and unexpected structural changes:(1) a near-uniform geometric\nscaling of singular values across layers, which theoretically modulates\nattention scores; and (2) highly consistent orthogonal transformations are\napplied to the left and right singular vectors of each matrix. Disrupting this\northogonal consistency leads to catastrophic performance degradation. Based on\nthese findings, we propose a simple yet effective framework that interprets\npost-training as a reparameterization of fixed subspaces in the pretrained\nparameter space. Further experiments reveal that singular value scaling behaves\nas a secondary effect, analogous to a temperature adjustment, whereas the core\nfunctional transformation lies in the coordinated rotation of singular vectors.\nThese results challenge the prevailing view of the parameter space in large\nmodels as a black box, uncovering the first clear regularities in how\nparameters evolve during training, and providing a new perspective for deeper\ninvestigation into model parameter changes.", "published": "2025-09-22 15:03:36", "link": "http://arxiv.org/abs/2509.17866v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided Medical Time Series Classification", "abstract": "Medical time series (MedTS) classification is pivotal for intelligent\nhealthcare, yet its efficacy is severely limited by poor cross-subject\ngeneration due to the profound cross-individual heterogeneity. Despite advances\nin architectural innovations and transfer learning techniques, current methods\nremain constrained by modality-specific inductive biases that limit their\nability to learn universally invariant representations. To overcome this, we\npropose TS-P$^2$CL, a novel plug-and-play framework that leverages the\nuniversal pattern recognition capabilities of pre-trained vision models. We\nintroduce a vision-guided paradigm that transforms 1D physiological signals\ninto 2D pseudo-images, establishing a bridge to the visual domain. This\ntransformation enables implicit access to rich semantic priors learned from\nnatural images. Within this unified space, we employ a dual-contrastive\nlearning strategy: intra-modal consistency enforces temporal coherence, while\ncross-modal alignment aligns time-series dynamics with visual semantics,\nthereby mitigating individual-specific biases and learning robust,\ndomain-invariant features. Extensive experiments on six MedTS datasets\ndemonstrate that TS-P$^2$CL consistently outperforms fourteen methods in both\nsubject-dependent and subject-independent settings.", "published": "2025-09-22 13:57:58", "link": "http://arxiv.org/abs/2509.17802v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Accurate and Efficient Low-Rank Model Merging in Core Space", "abstract": "In this paper, we address the challenges associated with merging low-rank\nadaptations of large neural networks. With the rise of parameter-efficient\nadaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-tuning\nhas become more accessible. While fine-tuning models with LoRA is highly\nefficient, existing merging methods often sacrifice this efficiency by merging\nfully-sized weight matrices. We propose the Core Space merging framework, which\nenables the merging of LoRA-adapted models within a common alignment basis,\nthereby preserving the efficiency of low-rank adaptation while substantially\nimproving accuracy across tasks. We further provide a formal proof that\nprojection into Core Space ensures no loss of information and provide a\ncomplexity analysis showing the efficiency gains. Extensive empirical results\ndemonstrate that Core Space significantly improves existing merging techniques\nand achieves state-of-the-art results on both vision and language tasks while\nutilizing a fraction of the computational resources. Codebase is available at\nhttps://github.com/apanariello4/core-space-merging.", "published": "2025-09-22 13:48:15", "link": "http://arxiv.org/abs/2509.17786v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Revealing Multimodal Causality with Large Language Models", "abstract": "Uncovering cause-and-effect mechanisms from data is fundamental to scientific\nprogress. While large language models (LLMs) show promise for enhancing causal\ndiscovery (CD) from unstructured data, their application to the increasingly\nprevalent multimodal setting remains a critical challenge. Even with the advent\nof multimodal LLMs (MLLMs), their efficacy in multimodal CD is hindered by two\nprimary limitations: (1) difficulty in exploring intra- and inter-modal\ninteractions for comprehensive causal variable identification; and (2)\ninsufficiency to handle structural ambiguities with purely observational data.\nTo address these challenges, we propose MLLM-CD, a novel framework for\nmultimodal causal discovery from unstructured data. It consists of three key\ncomponents: (1) a novel contrastive factor discovery module to identify genuine\nmultimodal factors based on the interactions explored from contrastive sample\npairs; (2) a statistical causal structure discovery module to infer causal\nrelationships among discovered factors; and (3) an iterative multimodal\ncounterfactual reasoning module to refine the discovery outcomes iteratively by\nincorporating the world knowledge and reasoning capabilities of MLLMs.\nExtensive experiments on both synthetic and real-world datasets demonstrate the\neffectiveness of MLLM-CD in revealing genuine factors and causal relationships\namong them from multimodal unstructured data.", "published": "2025-09-22 13:45:17", "link": "http://arxiv.org/abs/2509.17784v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Efficient & Correct Predictive Equivalence for Decision Trees", "abstract": "The Rashomon set of decision trees (DTs) finds importance uses. Recent work\nshowed that DTs computing the same classification function, i.e. predictive\nequivalent DTs, can represent a significant fraction of the Rashomon set. Such\nredundancy is undesirable. For example, feature importance based on the\nRashomon set becomes inaccurate due the existence of predictive equivalent DTs,\ni.e. DTs with the same prediction for every possible input. In recent work,\nMcTavish et al. proposed solutions for several computational problems related\nwith DTs, including that of deciding predictive equivalent DTs. This approach,\nwhich this paper refers to as MBDSR, consists of applying the well-known method\nof Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal\nform) representations of DTs, which are then used for comparing DTs for\npredictive equivalence. Furthermore, the minimum-size DNF representation was\nalso applied to computing explanations for the predictions made by DTs, and to\nfinding predictions in the presence of missing data. However, the problem of\nformula minimization is hard for the second level of the polynomial hierarchy,\nand the QM method may exhibit worst-case exponential running time and space.\nThis paper first demonstrates that there exist decision trees that trigger the\nworst-case exponential running time and space of the QM method. Second, the\npaper shows that the MBDSR approach can produce incorrect results for the\nproblem of deciding predictive equivalence. Third, the paper shows that any of\nthe problems to which the minimum-size DNF representation has been applied to\ncan in fact be solved in polynomial time, in the size of the DT. The\nexperiments confirm that, for DTs for which the the worst-case of the QM method\nis triggered, the algorithms proposed in this paper are orders of magnitude\nfaster than the ones proposed by McTavish et al.", "published": "2025-09-22 13:37:52", "link": "http://arxiv.org/abs/2509.17774v1", "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "GEM-T: Generative Tabular Data via Fitting Moments", "abstract": "Tabular data dominates data science but poses challenges for generative\nmodels, especially when the data is limited or sensitive. We present a novel\napproach to generating synthetic tabular data based on the principle of maximum\nentropy -- MaxEnt -- called GEM-T, for ``generative entropy maximization for\ntables.'' GEM-T directly captures nth-order interactions -- pairwise,\nthird-order, etc. -- among columns of training data. In extensive testing,\nGEM-T matches or exceeds deep neural network approaches previously regarded as\nstate-of-the-art in 23 of 34 publicly available datasets representing diverse\nsubject domains (68\\%). Notably, GEM-T involves orders-of-magnitude fewer\ntrainable parameters, demonstrating that much of the information in real-world\ndata resides in low-dimensional, potentially human-interpretable correlations,\nprovided that the input data is appropriately transformed first. Furthermore,\nMaxEnt better handles heterogeneous data types (continuous vs. discrete vs.\ncategorical), lack of local structure, and other features of tabular data.\nGEM-T represents a promising direction for light-weight high-performance\ngenerative models for structured data.", "published": "2025-09-22 13:16:02", "link": "http://arxiv.org/abs/2509.17752v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification", "abstract": "Real-world datasets often exhibit class imbalance across multiple categories,\nmanifesting as long-tailed distributions and few-shot scenarios. This is\nespecially challenging in Class-Imbalanced Multi-Label Image Classification\n(CI-MLIC) tasks, where data imbalance and multi-object recognition present\nsignificant obstacles. To address these challenges, we propose a novel method\ntermed Dual-View Alignment Learning with Hierarchical Prompt (HP-DVAL), which\nleverages multi-modal knowledge from vision-language pretrained (VLP) models to\nmitigate the class-imbalance problem in multi-label settings. Specifically,\nHP-DVAL employs dual-view alignment learning to transfer the powerful feature\nrepresentation capabilities from VLP models by extracting complementary\nfeatures for accurate image-text alignment. To better adapt VLP models for\nCI-MLIC tasks, we introduce a hierarchical prompt-tuning strategy that utilizes\nglobal and local prompts to learn task-specific and context-related prior\nknowledge. Additionally, we design a semantic consistency loss during prompt\ntuning to prevent learned prompts from deviating from general knowledge\nembedded in VLP models. The effectiveness of our approach is validated on two\nCI-MLIC benchmarks: MS-COCO and VOC2007. Extensive experimental results\ndemonstrate the superiority of our method over SOTA approaches, achieving mAP\nimprovements of 10.0\\% and 5.2\\% on the long-tailed multi-label image\nclassification task, and 6.8\\% and 2.9\\% on the multi-label few-shot image\nclassification task.", "published": "2025-09-22 13:11:12", "link": "http://arxiv.org/abs/2509.17747v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation", "abstract": "Human engagement estimation in conversational scenarios is essential for\napplications such as adaptive tutoring, remote healthcare assessment, and\nsocially aware human--computer interaction. Engagement is a dynamic, multimodal\nsignal conveyed by facial expressions, speech, gestures, and behavioral cues\nover time. In this work we introduce DA-Mamba, a dialogue-aware multimodal\narchitecture that replaces attention-heavy dialogue encoders with Mamba-based\nselective state-space processing to achieve linear time and memory complexity\nwhile retaining expressive cross-modal reasoning. We design a Mamba\ndialogue-aware selective state-space model composed of three core modules: a\nDialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group\nFusion and Partner-Group Fusion, these modules achieve expressive dialogue\nunderstanding. Extensive experiments on three standard benchmarks (NoXi,\nNoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art\n(SOTA) methods in concordance correlation coefficient (CCC), while reducing\ntraining time and peak memory; these gains enable processing much longer\nsequences and facilitate real-time deployment in resource-constrained,\nmulti-party conversational settings. The source code will be available at:\nhttps://github.com/kksssssss-ssda/MMEA.", "published": "2025-09-22 12:48:42", "link": "http://arxiv.org/abs/2509.17711v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Virtual Arc Consistency for Linear Constraints inCost Function Networks", "abstract": "In Constraint Programming, solving discrete minimization problems with hard\nand soft constraints can be done either using (i) soft global constraints, (ii)\na reformulation into a linear program, or (iii) a reformulation into local cost\nfunctions. Approach (i) benefits from a vast catalog of constraints. Each soft\nconstraint propagator communicates with other soft constraints only through the\nvariable domains, resulting in weak lower bounds. Conversely, the approach (ii)\nprovides a global view with strong bounds, but the size of the reformulation\ncan be problematic. We focus on approach (iii) in which soft arc consistency\n(SAC) algorithms produce bounds of intermediate quality. Recently, the\nintroduction of linear constraints as local cost functions increases their\nmodeling expressiveness. We adapt an existing SAC algorithm to handle linear\nconstraints. We show that our algorithm significantly improves the lower bounds\ncompared to the original algorithm on several benchmarks, reducing solving time\nin some cases.", "published": "2025-09-22 12:44:52", "link": "http://arxiv.org/abs/2509.17706v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Cluster Workload Allocation: A Predictive Approach Leveraging Machine Learning Efficiency", "abstract": "This research investigates how Machine Learning (ML) algorithms can assist in\nworkload allocation strategies by detecting tasks with node affinity operators\n(referred to as constraint operators), which constrain their execution to a\nlimited number of nodes. Using real-world Google Cluster Data (GCD) workload\ntraces and the AGOCS framework, the study extracts node attributes and task\nconstraints, then analyses them to identify suitable node-task pairings. It\nfocuses on tasks that can be executed on either a single node or fewer than a\nthousand out of 12.5k nodes in the analysed GCD cluster. Task constraint\noperators are compacted, pre-processed with one-hot encoding, and used as\nfeatures in a training dataset. Various ML classifiers, including Artificial\nNeural Networks, K-Nearest Neighbours, Decision Trees, Naive Bayes, Ridge\nRegression, Adaptive Boosting, and Bagging, are fine-tuned and assessed for\naccuracy and F1-scores. The final ensemble voting classifier model achieved 98%\naccuracy and a 1.5-1.8% misclassification rate for tasks with a single suitable\nnode.", "published": "2025-09-22 12:33:13", "link": "http://arxiv.org/abs/2509.17695v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Predicting Depth Maps from Single RGB Images and Addressing Missing Information in Depth Estimation", "abstract": "Depth imaging is a crucial area in Autonomous Driving Systems (ADS), as it\nplays a key role in detecting and measuring objects in the vehicle's\nsurroundings. However, a significant challenge in this domain arises from\nmissing information in Depth images, where certain points are not measurable\ndue to gaps or inconsistencies in pixel data. Our research addresses two key\ntasks to overcome this challenge. First, we developed an algorithm using a\nmulti-layered training approach to generate Depth images from a single RGB\nimage. Second, we addressed the issue of missing information in Depth images by\napplying our algorithm to rectify these gaps, resulting in Depth images with\ncomplete and accurate data. We further tested our algorithm on the Cityscapes\ndataset and successfully resolved the missing information in its Depth images,\ndemonstrating the effectiveness of our approach in real-world urban\nenvironments.", "published": "2025-09-22 12:28:29", "link": "http://arxiv.org/abs/2509.17686v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving", "abstract": "Large language models (LLMs) have shown strong performance on mathematical\nreasoning under well-posed conditions. However, real-world engineering problems\nrequire more than mathematical symbolic computation -- they need to deal with\nuncertainty, context, and open-ended scenarios. Existing benchmarks fail to\ncapture these complexities. We introduce EngiBench, a hierarchical benchmark\ndesigned to evaluate LLMs on solving engineering problems. It spans three\nlevels of increasing difficulty (foundational knowledge retrieval, multi-step\ncontextual reasoning, and open-ended modeling) and covers diverse engineering\nsubfields. To facilitate a deeper understanding of model performance, we\nsystematically rewrite each problem into three controlled variants (perturbed,\nknowledge-enhanced, and math abstraction), enabling us to separately evaluate\nthe model's robustness, domain-specific knowledge, and mathematical reasoning\nabilities. Experiment results reveal a clear performance gap across levels:\nmodels struggle more as tasks get harder, perform worse when problems are\nslightly changed, and fall far behind human experts on the high-level\nengineering tasks. These findings reveal that current LLMs still lack the\nhigh-level reasoning needed for real-world engineering, highlighting the need\nfor future models with deeper and more reliable problem-solving capabilities.\nOur source code and data are available at\nhttps://github.com/EngiBench/EngiBench.", "published": "2025-09-22 12:20:27", "link": "http://arxiv.org/abs/2509.17677v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mechanistic Interpretability with SAEs: Probing Religion, Violence, and Geography in Large Language Models", "abstract": "Despite growing research on bias in large language models (LLMs), most work\nhas focused on gender and race, with little attention to religious identity.\nThis paper explores how religion is internally represented in LLMs and how it\nintersects with concepts of violence and geography. Using mechanistic\ninterpretability and Sparse Autoencoders (SAEs) via the Neuronpedia API, we\nanalyze latent feature activations across five models. We measure overlap\nbetween religion- and violence-related prompts and probe semantic patterns in\nactivation contexts. While all five religions show comparable internal\ncohesion, Islam is more frequently linked to features associated with violent\nlanguage. In contrast, geographic associations largely reflect real-world\nreligious demographics, revealing how models embed both factual distributions\nand cultural stereotypes. These findings highlight the value of structural\nanalysis in auditing not just outputs but also internal representations that\nshape model behavior.", "published": "2025-09-22 12:09:21", "link": "http://arxiv.org/abs/2509.17665v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models", "abstract": "While vision language models (VLMs) excel in 2D semantic visual\nunderstanding, their ability to quantitatively reason about 3D spatial\nrelationships remains under-explored, due to the deficiency of 2D images'\nspatial representation ability. In this paper, we analyze the problem hindering\nVLMs' spatial understanding abilities and propose SD-VLM, a novel framework\nthat significantly enhances fundamental spatial perception abilities of VLMs\nthrough two key contributions: (1) propose Massive Spatial Measuring and\nUnderstanding (MSMU) dataset with precise spatial annotations, and (2)\nintroduce a simple depth positional encoding method strengthening VLMs' spatial\nawareness. MSMU dataset covers massive quantitative spatial tasks with 700K QA\npairs, 2.5M physical numerical annotations, and 10K chain-of-thought augmented\nsamples. We have trained SD-VLM, a strong generalist VLM which shows superior\nquantitative spatial measuring and understanding capability. SD-VLM not only\nachieves state-of-the-art performance on our proposed MSMU-Bench, but also\nshows spatial generalization abilities on other spatial understanding\nbenchmarks including Q-Spatial and SpatialRGPT-Bench. Extensive experiments\ndemonstrate that SD-VLM outperforms GPT-4o and Intern-VL3-78B by 26.91% and\n25.56% respectively on MSMU-Bench. Code and models are released at\nhttps://github.com/cpystan/SD-VLM.", "published": "2025-09-22 12:08:12", "link": "http://arxiv.org/abs/2509.17664v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "VideoArtGS: Building Digital Twins of Articulated Objects from Monocular Video", "abstract": "Building digital twins of articulated objects from monocular video presents\nan essential challenge in computer vision, which requires simultaneous\nreconstruction of object geometry, part segmentation, and articulation\nparameters from limited viewpoint inputs. Monocular video offers an attractive\ninput format due to its simplicity and scalability; however, it's challenging\nto disentangle the object geometry and part dynamics with visual supervision\nalone, as the joint movement of the camera and parts leads to ill-posed\nestimation. While motion priors from pre-trained tracking models can alleviate\nthe issue, how to effectively integrate them for articulation learning remains\nlargely unexplored. To address this problem, we introduce VideoArtGS, a novel\napproach that reconstructs high-fidelity digital twins of articulated objects\nfrom monocular video. We propose a motion prior guidance pipeline that analyzes\n3D tracks, filters noise, and provides reliable initialization of articulation\nparameters. We also design a hybrid center-grid part assignment module for\narticulation-based deformation fields that captures accurate part motion.\nVideoArtGS demonstrates state-of-the-art performance in articulation and mesh\nreconstruction, reducing the reconstruction error by about two orders of\nmagnitude compared to existing methods. VideoArtGS enables practical digital\ntwin creation from monocular video, establishing a new benchmark for\nvideo-based articulated object reconstruction. Our work is made publicly\navailable at: https://videoartgs.github.io.", "published": "2025-09-22 11:52:02", "link": "http://arxiv.org/abs/2509.17647v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "A$^2$M$^2$-Net: Adaptively Aligned Multi-Scale Moment for Few-Shot Action Recognition", "abstract": "Thanks to capability to alleviate the cost of large-scale annotation,\nfew-shot action recognition (FSAR) has attracted increased attention of\nresearchers in recent years. Existing FSAR approaches typically neglect the\nrole of individual motion pattern in comparison, and under-explore the feature\nstatistics for video dynamics. Thereby, they struggle to handle the challenging\ntemporal misalignment in video dynamics, particularly by using 2D backbones. To\novercome these limitations, this work proposes an adaptively aligned\nmulti-scale second-order moment network, namely A$^2$M$^2$-Net, to describe the\nlatent video dynamics with a collection of powerful representation candidates\nand adaptively align them in an instance-guided manner. To this end, our\nA$^2$M$^2$-Net involves two core components, namely, adaptive alignment (A$^2$\nmodule) for matching, and multi-scale second-order moment (M$^2$ block) for\nstrong representation. Specifically, M$^2$ block develops a collection of\nsemantic second-order descriptors at multiple spatio-temporal scales.\nFurthermore, A$^2$ module aims to adaptively select informative candidate\ndescriptors while considering the individual motion pattern. By such means, our\nA$^2$M$^2$-Net is able to handle the challenging temporal misalignment problem\nby establishing an adaptive alignment protocol for strong representation.\nNotably, our proposed method generalizes well to various few-shot settings and\ndiverse metrics. The experiments are conducted on five widely used FSAR\nbenchmarks, and the results show our A$^2$M$^2$-Net achieves very competitive\nperformance compared to state-of-the-arts, demonstrating its effectiveness and\ngeneralization.", "published": "2025-09-22 11:44:14", "link": "http://arxiv.org/abs/2509.17638v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SeqBattNet: A Discrete-State Physics-Informed Neural Network with Aging Adaptation for Battery Modeling", "abstract": "Accurate battery modeling is essential for reliable state estimation in\nmodern applications, such as predicting the remaining discharge time and\nremaining discharge energy in battery management systems. Existing approaches\nface several limitations: model-based methods require a large number of\nparameters; data-driven methods rely heavily on labeled datasets; and current\nphysics-informed neural networks (PINNs) often lack aging adaptation, or still\ndepend on many parameters, or continuously regenerate states. In this work, we\npropose SeqBattNet, a discrete-state PINN with built-in aging adaptation for\nbattery modeling, to predict terminal voltage during the discharge process.\nSeqBattNet consists of two components: (i) an encoder, implemented as the\nproposed HRM-GRU deep learning module, which generates cycle-specific aging\nadaptation parameters; and (ii) a decoder, based on the equivalent circuit\nmodel (ECM) combined with deep learning, which uses these parameters together\nwith the input current to predict voltage. The model requires only three basic\nbattery parameters and, when trained on data from a single cell, still achieves\nrobust performance. Extensive evaluations across three benchmark datasets (TRI,\nRT-Batt, and NASA) demonstrate that SeqBattNet significantly outperforms\nclassical sequence models and PINN baselines, achieving consistently lower RMSE\nwhile maintaining computational efficiency.", "published": "2025-09-22 11:33:17", "link": "http://arxiv.org/abs/2509.17621v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models", "abstract": "In this work, we address the task of table image to LaTeX code generation,\nwith the goal of automating the reconstruction of high-quality,\npublication-ready tables from visual inputs. A central challenge of this task\nlies in accurately handling complex tables -- those with large sizes, deeply\nnested structures, and semantically rich or irregular cell content -- where\nexisting methods often fail. We begin with a comprehensive analysis,\nidentifying key challenges and highlighting the limitations of current\nevaluation protocols. To overcome these issues, we propose a reinforced\nmultimodal large language model (MLLM) framework, where a pre-trained MLLM is\nfine-tuned on a large-scale table-to-LaTeX dataset. To further improve\ngeneration quality, we introduce a dual-reward reinforcement learning strategy\nbased on Group Relative Policy Optimization (GRPO). Unlike standard approaches\nthat optimize purely over text outputs, our method incorporates both a\nstructure-level reward on LaTeX code and a visual fidelity reward computed from\nrendered outputs, enabling direct optimization of the visual output quality. We\nadopt a hybrid evaluation protocol combining TEDS-Structure and CW-SSIM, and\nshow that our method achieves state-of-the-art performance, particularly on\nstructurally complex tables, demonstrating the effectiveness and robustness of\nour approach.", "published": "2025-09-22 11:13:48", "link": "http://arxiv.org/abs/2509.17589v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) answer visual questions by transferring\ninformation from images to text through a series of attention heads. While this\nimage-to-text information flow is central to visual question answering, its\nunderlying mechanism remains difficult to interpret due to the simultaneous\noperation of numerous attention heads. To address this challenge, we propose\nhead attribution, a technique inspired by component attribution methods, to\nidentify consistent patterns among attention heads that play a key role in\ninformation transfer. Using head attribution, we investigate how LVLMs rely on\nspecific attention heads to identify and answer questions about the main object\nin an image. Our analysis reveals that a distinct subset of attention heads\nfacilitates the image-to-text information flow. Remarkably, we find that the\nselection of these heads is governed by the semantic content of the input image\nrather than its visual appearance. We further examine the flow of information\nat the token level and discover that (1) text information first propagates to\nrole-related tokens and the final token before receiving image information, and\n(2) image information is embedded in both object-related and background tokens.\nOur work provides evidence that image-to-text information flow follows a\nstructured process, and that analysis at the attention-head level offers a\npromising direction toward understanding the mechanisms of LVLMs.", "published": "2025-09-22 11:12:12", "link": "http://arxiv.org/abs/2509.17588v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LIMI: Less is More for Agency", "abstract": "We define Agency as the emergent capacity of AI systems to function as\nautonomous agents actively discovering problems, formulating hypotheses, and\nexecuting solutions through self-directed engagement with environments and\ntools. This fundamental capability marks the dawn of the Age of AI Agency,\ndriven by a critical industry shift: the urgent need for AI systems that don't\njust think, but work. While current AI excels at reasoning and generating\nresponses, industries demand autonomous agents that can execute tasks, operate\ntools, and drive real-world outcomes. As agentic intelligence becomes the\ndefining characteristic separating cognitive systems from productive workers,\nefficiently cultivating machine autonomy becomes paramount. Current approaches\nassume that more data yields better agency, following traditional scaling laws\nfrom language modeling. We fundamentally challenge this paradigm. LIMI (Less Is\nMore for Intelligent Agency) demonstrates that agency follows radically\ndifferent development principles. Through strategic focus on collaborative\nsoftware development and scientific research workflows, we show that\nsophisticated agentic intelligence can emerge from minimal but strategically\ncurated demonstrations of autonomous behavior. Using only 78 carefully designed\ntraining samples, LIMI achieves 73.5% on comprehensive agency benchmarks,\ndramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%),\nDeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).\nMost strikingly, LIMI demonstrates 53.7% improvement over models trained on\n10,000 samples-achieving superior agentic intelligence with 128 times fewer\nsamples. Our findings establish the Agency Efficiency Principle: machine\nautonomy emerges not from data abundance but from strategic curation of\nhigh-quality agentic demonstrations.", "published": "2025-09-22 10:59:32", "link": "http://arxiv.org/abs/2509.17567v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MRN: Harnessing 2D Vision Foundation Models for Diagnosing Parkinson's Disease with Limited 3D MR Data", "abstract": "The automatic diagnosis of Parkinson's disease is in high clinical demand due\nto its prevalence and the importance of targeted treatment. Current clinical\npractice often relies on diagnostic biomarkers in QSM and NM-MRI images.\nHowever, the lack of large, high-quality datasets makes training diagnostic\nmodels from scratch prone to overfitting. Adapting pre-trained 3D medical\nmodels is also challenging, as the diversity of medical imaging leads to\nmismatches in voxel spacing and modality between pre-training and fine-tuning\ndata. In this paper, we address these challenges by leveraging 2D vision\nfoundation models (VFMs). Specifically, we crop multiple key ROIs from NM and\nQSM images, process each ROI through separate branches to compress the ROI into\na token, and then combine these tokens into a unified patient representation\nfor classification. Within each branch, we use 2D VFMs to encode axial slices\nof the 3D ROI volume and fuse them into the ROI token, guided by an auxiliary\nsegmentation head that steers the feature extraction toward specific brain\nnuclei. Additionally, we introduce multi-ROI supervised contrastive learning,\nwhich improves diagnostic performance by pulling together representations of\npatients from the same class while pushing away those from different classes.\nOur approach achieved first place in the MICCAI 2025 PDCADxFoundation\nchallenge, with an accuracy of 86.0% trained on a dataset of only 300 labeled\nQSM and NM-MRI scans, outperforming the second-place method by 5.5%.These\nresults highlight the potential of 2D VFMs for clinical analysis of 3D MR\nimages.", "published": "2025-09-22 10:59:27", "link": "http://arxiv.org/abs/2509.17566v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An Empirical Study on the Robustness of YOLO Models for Underwater Object Detection", "abstract": "Underwater object detection (UOD) remains a critical challenge in computer\nvision due to underwater distortions which degrade low-level features and\ncompromise the reliability of even state-of-the-art detectors. While YOLO\nmodels have become the backbone of real-time object detection, little work has\nsystematically examined their robustness under these uniquely challenging\nconditions. This raises a critical question: Are YOLO models genuinely robust\nwhen operating under the chaotic and unpredictable conditions of underwater\nenvironments? In this study, we present one of the first comprehensive\nevaluations of recent YOLO variants (YOLOv8-YOLOv12) across six simulated\nunderwater environments. Using a unified dataset of 10,000 annotated images\nfrom DUO and Roboflow100, we not only benchmark model robustness but also\nanalyze how distortions affect key low-level features such as texture, edges,\nand color. Our findings show that (1) YOLOv12 delivers the strongest overall\nperformance but is highly vulnerable to noise, and (2) noise disrupts edge and\ntexture features, explaining the poor detection performance in noisy images.\nClass imbalance is a persistent challenge in UOD. Experiments revealed that (3)\nimage counts and instance frequency primarily drive detection performance,\nwhile object appearance exerts only a secondary influence. Finally, we\nevaluated lightweight training-aware strategies: noise-aware sample injection,\nwhich improves robustness in both noisy and real-world conditions, and\nfine-tuning with advanced enhancement, which boosts accuracy in enhanced\ndomains but slightly lowers performance in original data, demonstrating strong\npotential for domain adaptation, respectively. Together, these insights provide\npractical guidance for building resilient and cost-efficient UOD systems.", "published": "2025-09-22 10:55:21", "link": "http://arxiv.org/abs/2509.17561v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances", "abstract": "In commercial systems, a pervasive requirement for automatic data preparation\n(ADP) is to transfer relational data from disparate sources to targets with\nstandardized schema specifications. Previous methods rely on labor-intensive\nsupervision signals or target table data access permissions, limiting their\nusage in real-world scenarios. To tackle these challenges, we propose an\neffective end-to-end ADP framework MontePrep, which enables training-free\npipeline synthesis with zero target-instance requirements. MontePrep is\nformulated as an open-source large language model (LLM) powered tree-structured\nsearch problem. It consists of three pivot components, i.e., a data preparation\naction sandbox (DPAS), a fundamental pipeline generator (FPG), and an\nexecution-aware pipeline optimizer (EPO). We first introduce DPAS, a\nlightweight action sandbox, to navigate the search-based pipeline generation.\nThe design of DPAS circumvents exploration of infeasible pipelines. Then, we\npresent FPG to build executable DP pipelines incrementally, which explores the\npredefined action sandbox by the LLM-powered Monte Carlo Tree Search.\nFurthermore, we propose EPO, which invokes pipeline execution results from\nsources to targets to evaluate the reliability of the generated pipelines in\nFPG. In this way, unreasonable pipelines are eliminated, thus facilitating the\nsearch process from both efficiency and effectiveness perspectives. Extensive\nexperimental results demonstrate the superiority of MontePrep with significant\nimprovement against five state-of-the-art competitors.", "published": "2025-09-22 09:17:41", "link": "http://arxiv.org/abs/2509.17553v1", "categories": ["cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "abstract": "As generative models are advancing in quality and quantity for creating\nsynthetic content, deepfakes begin to cause online mistrust. Deepfake detectors\nare proposed to counter this effect, however, misuse of detectors claiming fake\ncontent as real or vice versa further fuels this misinformation problem. We\npresent the first comprehensive uncertainty analysis of deepfake detectors,\nsystematically investigating how generative artifacts influence prediction\nconfidence. As reflected in detectors' responses, deepfake generators also\ncontribute to this uncertainty as their generative residues vary, so we cross\nthe uncertainty analysis of deepfake detectors and generators. Based on our\nobservations, the uncertainty manifold holds enough consistent information to\nleverage uncertainty for deepfake source detection. Our approach leverages\nBayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and\nepistemic uncertainties across diverse detector architectures. We evaluate\nuncertainty on two datasets with nine generators, with four blind and two\nbiological detectors, compare different uncertainty methods, explore region-\nand pixel-based uncertainty, and conduct ablation studies. We conduct and\nanalyze binary real/fake, multi-class real/fake, source detection, and\nleave-one-out experiments between the generator/detector combinations to share\ntheir generalization capability, model calibration, uncertainty, and robustness\nagainst adversarial attacks. We further introduce uncertainty maps that\nlocalize prediction confidence at the pixel level, revealing distinct patterns\ncorrelated with generator-specific artifacts. Our analysis provides critical\ninsights for deploying reliable deepfake detection systems and establishes\nuncertainty quantification as a fundamental requirement for trustworthy\nsynthetic media detection.", "published": "2025-09-22 09:09:13", "link": "http://arxiv.org/abs/2509.17550v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data", "abstract": "The increasing availability of open Earth Observation (EO) and agricultural\ndatasets holds great potential for supporting sustainable land management.\nHowever, their high technical entry barrier limits accessibility for non-expert\nusers. This study presents an open-source conversational assistant that\nintegrates multimodal retrieval and large language models (LLMs) to enable\nnatural language interaction with heterogeneous agricultural and geospatial\ndata. The proposed architecture combines orthophotos, Sentinel-2 vegetation\nindices, and user-provided documents through retrieval-augmented generation\n(RAG), allowing the system to flexibly determine whether to rely on multimodal\nevidence, textual knowledge, or both in formulating an answer. To assess\nresponse quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a\nzero-shot, unsupervised setting, applying direct scoring in a multi-dimensional\nquantitative evaluation framework. Preliminary results show that the system is\ncapable of generating clear, relevant, and context-aware responses to\nagricultural queries, while remaining reproducible and scalable across\ngeographic regions. The primary contributions of this work include an\narchitecture for fusing multimodal EO and textual knowledge sources, a\ndemonstration of lowering the barrier to access specialized agricultural\ninformation through natural language interaction, and an open and reproducible\ndesign.", "published": "2025-09-22 09:02:53", "link": "http://arxiv.org/abs/2509.17544v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Evaluating the Energy Efficiency of NPU-Accelerated Machine Learning Inference on Embedded Microcontrollers", "abstract": "The deployment of machine learning (ML) models on microcontrollers (MCUs) is\nconstrained by strict energy, latency, and memory requirements, particularly in\nbattery-operated and real-time edge devices. While software-level optimizations\nsuch as quantization and pruning reduce model size and computation, hardware\nacceleration has emerged as a decisive enabler for efficient embedded\ninference. This paper evaluates the impact of Neural Processing Units (NPUs) on\nMCU-based ML execution, using the ARM Cortex-M55 core combined with the\nEthos-U55 NPU on the Alif Semiconductor Ensemble E7 development board as a\nrepresentative platform. A rigorous measurement methodology was employed,\nincorporating per-inference net energy accounting via GPIO-triggered\nhigh-resolution digital multimeter synchronization and idle-state subtraction,\nensuring accurate attribution of energy costs. Experimental results across six\nrepresentative ML models -including MiniResNet, MobileNetV2, FD-MobileNet,\nMNIST, TinyYolo, and SSD-MobileNet- demonstrate substantial efficiency gains\nwhen inference is offloaded to the NPU. For moderate to large networks, latency\nimprovements ranged from 7x to over 125x, with per-inference net energy\nreductions up to 143x. Notably, the NPU enabled execution of models unsupported\non CPU-only paths, such as SSD-MobileNet, highlighting its functional as well\nas efficiency advantages. These findings establish NPUs as a cornerstone of\nenergy-aware embedded AI, enabling real-time, power-constrained ML inference at\nthe MCU level.", "published": "2025-09-22 08:52:54", "link": "http://arxiv.org/abs/2509.17533v1", "categories": ["cs.ET", "cs.AI", "cs.LG"], "primary_category": "cs.ET"}
{"title": "Multimodal Medical Image Classification via Synergistic Learning Pre-training", "abstract": "Multimodal pathological images are usually in clinical diagnosis, but\ncomputer vision-based multimodal image-assisted diagnosis faces challenges with\nmodality fusion, especially in the absence of expert-annotated data. To achieve\nthe modality fusion in multimodal images with label scarcity, we propose a\nnovel ``pretraining + fine-tuning\" framework for multimodal semi-supervised\nmedical image classification. Specifically, we propose a synergistic learning\npretraining framework of consistency, reconstructive, and aligned learning. By\ntreating one modality as an augmented sample of another modality, we implement\na self-supervised learning pre-train, enhancing the baseline model's feature\nrepresentation capability. Then, we design a fine-tuning method for multimodal\nfusion. During the fine-tuning stage, we set different encoders to extract\nfeatures from the original modalities and provide a multimodal fusion encoder\nfor fusion modality. In addition, we propose a distribution shift method for\nmultimodal fusion features, which alleviates the prediction uncertainty and\noverfitting risks caused by the lack of labeled samples. We conduct extensive\nexperiments on the publicly available gastroscopy image datasets Kvasir and\nKvasirv2. Quantitative and qualitative results demonstrate that the proposed\nmethod outperforms the current state-of-the-art classification methods. The\ncode will be released at: https://github.com/LQH89757/MICS.", "published": "2025-09-22 08:21:19", "link": "http://arxiv.org/abs/2509.17492v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents", "abstract": "The increasing autonomy of LLM agents in handling sensitive communications,\naccelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A)\nframeworks, creates urgent privacy challenges. While recent work reveals\nsignificant gaps between LLMs' privacy Q&A performance and their agent\nbehavior, existing benchmarks remain limited to static, simplified scenarios.\nWe present PrivacyChecker, a model-agnostic, contextual integrity based\nmitigation approach that effectively reduces privacy leakage from 36.08% to\n7.30% on DeepSeek-R1 and from 33.06% to 8.32% on GPT-4o, all while preserving\ntask helpfulness. We also introduce PrivacyLens-Live, transforming static\nbenchmarks into dynamic MCP and A2A environments that reveal substantially\nhigher privacy risks in practical. Our modular mitigation approach integrates\nseamlessly into agent protocols through three deployment strategies, providing\npractical privacy protection for the emerging agentic ecosystem. Our data and\ncode will be made available at https://aka.ms/privacy_in_action.", "published": "2025-09-22 08:19:06", "link": "http://arxiv.org/abs/2509.17488v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Transformer-Gather, Fuzzy-Reconsider: A Scalable Hybrid Framework for Entity Resolution", "abstract": "Entity resolution plays a significant role in enterprise systems where data\nintegrity must be rigorously maintained. Traditional methods often struggle\nwith handling noisy data or semantic understanding, while modern methods suffer\nfrom computational costs or the excessive need for parallel computation. In\nthis study, we introduce a scalable hybrid framework, which is designed to\naddress several important problems, including scalability, noise robustness,\nand reliable results. We utilized a pre-trained language model to encode each\nstructured data into corresponding semantic embedding vectors. Subsequently,\nafter retrieving a semantically relevant subset of candidates, we apply a\nsyntactic verification stage using fuzzy string matching techniques to refine\nclassification on the unlabeled data. This approach was applied to a real-world\nentity resolution task, which exposed a linkage between a central user\nmanagement database and numerous shared hosting server records. Compared to\nother methods, this approach exhibits an outstanding performance in terms of\nboth processing time and robustness, making it a reliable solution for a\nserver-side product. Crucially, this efficiency does not compromise results, as\nthe system maintains a high retrieval recall of approximately 0.97. The\nscalability of the framework makes it deployable on standard CPU-based\ninfrastructure, offering a practical and effective solution for\nenterprise-level data integrity auditing.", "published": "2025-09-22 08:05:44", "link": "http://arxiv.org/abs/2509.17470v1", "categories": ["cs.DB", "cs.AI", "cs.LG"], "primary_category": "cs.DB"}
{"title": "AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks", "abstract": "The pursuit of artificial general intelligence continuously demands\ngeneralization in one model across myriad tasks, even those not seen before.\nHowever, current AI models are isolated from each other for being limited to\nspecific tasks, now first defined as Intelligence Islands. To unify\nIntelligence Islands into one, we propose Pangaea, the first AI supercontinent\nakin to the geological Pangaea. Pangaea encodes any data into a unified format\nand accumulates universal knowledge through pre-training on 296 datasets across\ndiverse modalities. Eventually, it demonstrates remarkable generalization\nacross 45 general tasks and 15 scientific tasks encompassing a wide range of\nscientific subjects. By investigating Pangaea deeper, the scaling effect of\nmodality is revealed, quantifying the universal knowledge accumulation across\nmodalities as the cumulative distribution function of a geometric distribution.\nOn the whole, Pangaea shows strong potential to handle myriad tasks, indicating\na new direction toward artificial general intelligence.", "published": "2025-09-22 07:54:58", "link": "http://arxiv.org/abs/2509.17460v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Explainable AI for Analyzing Person-Specific Patterns in Facial Recognition Tasks", "abstract": "The proliferation of facial recognition systems presents major privacy risks,\ndriving the need for effective countermeasures. Current adversarial techniques\napply generalized methods rather than adapting to individual facial\ncharacteristics, limiting their effectiveness and inconspicuousness. In this\nwork, we introduce Layer Embedding Activation Mapping (LEAM), a novel technique\nthat identifies which facial areas contribute most to recognition at an\nindividual level. Unlike adversarial attack methods that aim to fool\nrecognition systems, LEAM is an explainability technique designed to understand\nhow these systems work, providing insights that could inform future privacy\nprotection research. We integrate LEAM with a face parser to analyze data from\n1000 individuals across 9 pre-trained facial recognition models.\n  Our analysis reveals that while different layers within facial recognition\nmodels vary significantly in their focus areas, these models generally\nprioritize similar facial regions across architectures when considering their\noverall activation patterns, which show significantly higher similarity between\nimages of the same individual (Bhattacharyya Coefficient: 0.32-0.57) vs.\ndifferent individuals (0.04-0.13), validating the existence of person-specific\nrecognition patterns. Our results show that facial recognition models\nprioritize the central region of face images (with nose areas accounting for\n18.9-29.7% of critical recognition regions), while still distributing attention\nacross multiple facial fragments. Proper selection of relevant facial areas was\nconfirmed using validation occlusions, based on just 1% of the most relevant,\nLEAM-identified, image pixels, which proved to be transferable across different\nmodels. Our findings establish the foundation for future individually tailored\nprivacy protection systems centered around LEAM's choice of areas to be\nperturbed.", "published": "2025-09-22 07:51:11", "link": "http://arxiv.org/abs/2509.17457v1", "categories": ["cs.CV", "cs.AI", "68T10", "I.2.10; I.4.m"], "primary_category": "cs.CV"}
{"title": "Training-Free Label Space Alignment for Universal Domain Adaptation", "abstract": "Universal domain adaptation (UniDA) transfers knowledge from a labeled source\ndomain to an unlabeled target domain, where label spaces may differ and the\ntarget domain may contain private classes. Previous UniDA methods primarily\nfocused on visual space alignment but often struggled with visual ambiguities\ndue to content differences, which limited their robustness and\ngeneralizability. To overcome this, we introduce a novel approach that\nleverages the strong \\textit{zero-shot capabilities} of recent vision-language\nfoundation models (VLMs) like CLIP, concentrating solely on label space\nalignment to enhance adaptation stability. CLIP can generate task-specific\nclassifiers based only on label names. However, adapting CLIP to UniDA is\nchallenging because the label space is not fully known in advance. In this\nstudy, we first utilize generative vision-language models to identify unknown\ncategories in the target domain. Noise and semantic ambiguities in the\ndiscovered labels -- such as those similar to source labels (e.g., synonyms,\nhypernyms, hyponyms) -- complicate label alignment. To address this, we propose\na training-free label-space alignment method for UniDA (\\ours). Our method\naligns label spaces instead of visual spaces by filtering and refining noisy\nlabels between the domains. We then construct a \\textit{universal classifier}\nthat integrates both shared knowledge and target-private class information,\nthereby improving generalizability under domain shifts. The results reveal that\nthe proposed method considerably outperforms existing UniDA techniques across\nkey DomainBed benchmarks, delivering an average improvement of\n\\textcolor{blue}{+7.9\\%}in H-score and \\textcolor{blue}{+6.1\\%} in H$^3$-score.\nFurthermore, incorporating self-training further enhances performance and\nachieves an additional (\\textcolor{blue}{+1.6\\%}) increment in both H- and\nH$^3$-scores.", "published": "2025-09-22 07:46:10", "link": "http://arxiv.org/abs/2509.17452v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MVCL-DAF++: Enhancing Multimodal Intent Recognition via Prototype-Aware Contrastive Alignment and Coarse-to-Fine Dynamic Attention Fusion", "abstract": "Multimodal intent recognition (MMIR) suffers from weak semantic grounding and\npoor robustness under noisy or rare-class conditions. We propose MVCL-DAF++,\nwhich extends MVCL-DAF with two key modules: (1) Prototype-aware contrastive\nalignment, aligning instances to class-level prototypes to enhance semantic\nconsistency; and (2) Coarse-to-fine attention fusion, integrating global\nmodality summaries with token-level features for hierarchical cross-modal\ninteraction. On MIntRec and MIntRec2.0, MVCL-DAF++ achieves new\nstate-of-the-art results, improving rare-class recognition by +1.05\\% and\n+4.18\\% WF1, respectively. These results demonstrate the effectiveness of\nprototype-guided learning and coarse-to-fine fusion for robust multimodal\nunderstanding. The source code is available at\nhttps://github.com/chr1s623/MVCL-DAF-PlusPlus.", "published": "2025-09-22 07:38:53", "link": "http://arxiv.org/abs/2509.17446v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding", "abstract": "Human brain achieves dynamic stability-plasticity balance through synaptic\nhomeostasis. Inspired by this biological principle, we propose SPICED: a\nneuromorphic framework that integrates the synaptic homeostasis mechanism for\nunsupervised continual EEG decoding, particularly addressing practical\nscenarios where new individuals with inter-individual variability emerge\ncontinually. SPICED comprises a novel synaptic network that enables dynamic\nexpansion during continual adaptation through three bio-inspired neural\nmechanisms: (1) critical memory reactivation; (2) synaptic consolidation and\n(3) synaptic renormalization. The interplay within synaptic homeostasis\ndynamically strengthens task-discriminative memory traces and weakens\ndetrimental memories. By integrating these mechanisms with continual learning\nsystem, SPICED preferentially replays task-discriminative memory traces that\nexhibit strong associations with newly emerging individuals, thereby achieving\nrobust adaptations. Meanwhile, SPICED effectively mitigates catastrophic\nforgetting by suppressing the replay prioritization of detrimental memories\nduring long-term continual learning. Validated on three EEG datasets, SPICED\nshow its effectiveness.", "published": "2025-09-22 07:28:22", "link": "http://arxiv.org/abs/2509.17439v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments", "abstract": "A key feature differentiating artificial general intelligence (AGI) from\ntraditional AI is that AGI can perform composite tasks that require a wide\nrange of capabilities. Although embodied agents powered by multimodal large\nlanguage models (MLLMs) offer rich perceptual and interactive capabilities, it\nremains largely unexplored whether they can solve composite tasks. In the\ncurrent work, we designed a set of composite tasks inspired by common daily\nactivities observed in early childhood development. Within a dynamic and\nsimulated home environment, these tasks span three core domains: object\nunderstanding, spatial intelligence, and social activity. We evaluated 17\nleading proprietary and open-source MLLMs on these tasks. The results\nconsistently showed poor performance across all three domains, indicating a\nsubstantial gap between current capabilities and general intelligence\nrequirements. Together, our tasks offer a preliminary framework for evaluating\nthe general capabilities of embodied agents, marking an early but significant\nstep toward the development of embodied MLLMs and their real-world deployment.", "published": "2025-09-22 07:17:26", "link": "http://arxiv.org/abs/2509.17425v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Distributionally Robust Safety Verification of Neural Networks via Worst-Case CVaR", "abstract": "Ensuring the safety of neural networks under input uncertainty is a\nfundamental challenge in safety-critical applications. This paper builds on and\nexpands Fazlyab's quadratic-constraint (QC) and semidefinite-programming (SDP)\nframework for neural network verification to a distributionally robust and\ntail-risk-aware setting by integrating worst-case Conditional Value-at-Risk\n(WC-CVaR) over a moment-based ambiguity set with fixed mean and covariance. The\nresulting conditions remain SDP-checkable and explicitly account for tail risk.\nThis integration broadens input-uncertainty geometry-covering ellipsoids,\npolytopes, and hyperplanes-and extends applicability to safety-critical domains\nwhere tail-event severity matters. Applications to closed-loop reachability of\ncontrol systems and classification are demonstrated through numerical\nexperiments, illustrating how the risk level $\\varepsilon$ trades conservatism\nfor tolerance to tail events-while preserving the computational structure of\nprior QC/SDP methods for neural network verification and robustness analysis.", "published": "2025-09-22 07:04:53", "link": "http://arxiv.org/abs/2509.17413v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.LG"}
{"title": "Real-Time Fish Detection in Indonesian Marine Ecosystems Using Lightweight YOLOv10-nano Architecture", "abstract": "Indonesia's marine ecosystems, part of the globally recognized Coral\nTriangle, are among the richest in biodiversity, requiring efficient monitoring\ntools to support conservation. Traditional fish detection methods are\ntime-consuming and demand expert knowledge, prompting the need for automated\nsolutions. This study explores the implementation of YOLOv10-nano, a\nstate-of-the-art deep learning model, for real-time marine fish detection in\nIndonesian waters, using test data from Bunaken National Marine Park. YOLOv10's\narchitecture, featuring improvements like the CSPNet backbone, PAN for feature\nfusion, and Pyramid Spatial Attention Block, enables efficient and accurate\nobject detection even in complex environments. The model was evaluated on the\nDeepFish and OpenImages V7-Fish datasets. Results show that YOLOv10-nano\nachieves a high detection accuracy with mAP50 of 0.966 and mAP50:95 of 0.606\nwhile maintaining low computational demand (2.7M parameters, 8.4 GFLOPs). It\nalso delivered an average inference speed of 29.29 FPS on the CPU, making it\nsuitable for real-time deployment. Although OpenImages V7-Fish alone provided\nlower accuracy, it complemented DeepFish in enhancing model robustness.\nOverall, this study demonstrates YOLOv10-nano's potential for efficient,\nscalable marine fish monitoring and conservation applications in data-limited\nenvironments.", "published": "2025-09-22 07:02:48", "link": "http://arxiv.org/abs/2509.17406v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SongPrep: A Preprocessing Framework and End-to-end Model for Full-song Structure Parsing and Lyrics Transcription", "abstract": "Artificial Intelligence Generated Content (AIGC) is currently a popular\nresearch area. Among its various branches, song generation has attracted\ngrowing interest. Despite the abundance of available songs, effective data\npreparation remains a significant challenge. Converting these songs into\ntraining-ready datasets typically requires extensive manual labeling, which is\nboth time consuming and costly. To address this issue, we propose SongPrep, an\nautomated preprocessing pipeline designed specifically for song data. This\nframework streamlines key processes such as source separation, structure\nanalysis, and lyric recognition, producing structured data that can be directly\nused to train song generation models. Furthermore, we introduce SongPrepE2E, an\nend-to-end structured lyrics recognition model based on pretrained language\nmodels. Without the need for additional source separation, SongPrepE2E is able\nto analyze the structure and lyrics of entire songs and provide precise\ntimestamps. By leveraging context from the whole song alongside pretrained\nsemantic knowledge, SongPrepE2E achieves low Diarization Error Rate (DER) and\nWord Error Rate (WER) on the proposed SSLD-200 dataset. Downstream tasks\ndemonstrate that training song generation models with the data output by\nSongPrepE2E enables the generated songs to closely resemble those produced by\nhumans.", "published": "2025-09-22 07:01:41", "link": "http://arxiv.org/abs/2509.17404v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Interpreting vision transformers via residual replacement model", "abstract": "How do vision transformers (ViTs) represent and process the world? This paper\naddresses this long-standing question through the first systematic analysis of\n6.6K features across all layers, extracted via sparse autoencoders, and by\nintroducing the residual replacement model, which replaces ViT computations\nwith interpretable features in the residual stream. Our analysis reveals not\nonly a feature evolution from low-level patterns to high-level semantics, but\nalso how ViTs encode curves and spatial positions through specialized feature\ntypes. The residual replacement model scalably produces a faithful yet\nparsimonious circuit for human-scale interpretability by significantly\nsimplifying the original computations. As a result, this framework enables\nintuitive understanding of ViT mechanisms. Finally, we demonstrate the utility\nof our framework in debiasing spurious correlations.", "published": "2025-09-22 07:00:57", "link": "http://arxiv.org/abs/2509.17401v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process", "abstract": "LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and\ninconsistency, since they lack robust causal underpinnings and may rely on\nsuperficial correlations rather than genuine understanding. Successive LRMs\nhave emerged as a promising alternative, leveraging advanced training\ntechniques such as reinforcement learning (RL) and distillation to improve task\naccuracy. However, the impact of these training methods on causality remains\nlargely unexplored. In this study, we conduct a systematic causal analysis on\nLLMs and LRMs, examining structural causal models (SCMs) of four key variables:\nproblem instruction (Z), thinking process (T), reasoning steps (X), and answer\n(Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal\nreasoning capabilities, aligning more closely with ideal causal structures,\nwhile LLMs and distilled LRMs fail to address causality-related deficiencies.\nOur further investigation indicates that RLVR reduces spurious correlations and\nstrengthens genuine causal patterns, thereby mitigating unfaithfulness and\nbias. In addition, our inspection on the dynamics of the RLVR training process\nobserves a high correlation between reduced spurious features and improved\ncausal structures, where the causal relationships consistently improve in the\ntraining process. This study contributes to the understanding of causality in\nreasoning models, highlights the critical role of RLVR in enhancing causal\nreasoning, and provides insights for designing future AI systems with stronger\ncausal foundations. We release our code and data at\nhttps://github.com/Harryking1999/CoT_Causal_Analysis.", "published": "2025-09-22 06:44:44", "link": "http://arxiv.org/abs/2509.17380v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Pre-Trained CNN Architecture for Transformer-Based Image Caption Generation Model", "abstract": "Automatic image captioning, a multifaceted task bridging computer vision and\nnatural lan- guage processing, aims to generate descriptive textual content\nfrom visual input. While Convolutional Neural Networks (CNNs) and Long\nShort-Term Memory (LSTM) networks have achieved significant advancements, they\npresent limitations. The inherent sequential nature of RNNs leads to sluggish\ntraining and inference times. LSTMs further struggle with retaining information\nfrom earlier sequence elements when dealing with very long se- quences. This\nproject presents a comprehensive guide to constructing and comprehending\ntransformer models for image captioning. Transformers employ self-attention\nmechanisms, capturing both short- and long-range dependencies within the data.\nThis facilitates efficient parallelization during both training and inference\nphases. We leverage the well-established Transformer architecture, recognized\nfor its effectiveness in managing sequential data, and present a meticulous\nmethodology. Utilizing the Flickr30k dataset, we conduct data pre- processing,\nconstruct a model architecture that integrates an EfficientNetB0 CNN for fea-\nture extraction, and train the model with attention mechanisms incorporated.\nOur approach exemplifies the utilization of parallelization for efficient\ntraining and inference. You can find the project on GitHub.", "published": "2025-09-22 05:32:52", "link": "http://arxiv.org/abs/2509.17365v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SeqUDA-Rec: Sequential User Behavior Enhanced Recommendation via Global Unsupervised Data Augmentation for Personalized Content Marketing", "abstract": "Personalized content marketing has become a crucial strategy for digital\nplatforms, aiming to deliver tailored advertisements and recommendations that\nmatch user preferences. Traditional recommendation systems often suffer from\ntwo limitations: (1) reliance on limited supervised signals derived from\nexplicit user feedback, and (2) vulnerability to noisy or unintentional\ninteractions. To address these challenges, we propose SeqUDA-Rec, a novel deep\nlearning framework that integrates user behavior sequences with global\nunsupervised data augmentation to enhance recommendation accuracy and\nrobustness. Our approach first constructs a Global User-Item Interaction Graph\n(GUIG) from all user behavior sequences, capturing both local and global item\nassociations. Then, a graph contrastive learning module is applied to generate\nrobust embeddings, while a sequential Transformer-based encoder models users'\nevolving preferences. To further enhance diversity and counteract sparse\nsupervised labels, we employ a GAN-based augmentation strategy, generating\nplausible interaction patterns and supplementing training data. Extensive\nexperiments on two real-world marketing datasets (Amazon Ads and TikTok Ad\nClicks) demonstrate that SeqUDA-Rec significantly outperforms state-of-the-art\nbaselines such as SASRec, BERT4Rec, and GCL4SR. Our model achieves a 6.7%\nimprovement in NDCG@10 and 11.3% improvement in HR@10, proving its\neffectiveness in personalized advertising and intelligent content\nrecommendation.", "published": "2025-09-22 05:24:53", "link": "http://arxiv.org/abs/2509.17361v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification", "abstract": "Lane-change maneuvers are a leading cause of highway accidents, underscoring\nthe need for accurate intention prediction to improve the safety and\ndecision-making of autonomous driving systems. While prior studies using\nmachine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers)\nhave shown promise, most approaches remain limited by binary classification,\nlack of scenario diversity, and degraded performance under longer prediction\nhorizons. In this study, we propose a physics-informed AI framework that\nexplicitly integrates vehicle kinematics, interaction feasibility, and\ntraffic-safety metrics (e.g., distance headway, time headway,\ntime-to-collision, closing gap time) into the learning process. lane-change\nprediction is formulated as a three-class problem that distinguishes left\nchange, right change, and no change, and is evaluated across both straight\nhighway segments (highD) and complex ramp scenarios (exiD). By integrating\nvehicle kinematics with interaction features, our machine learning models,\nparticularly LightGBM, achieve state-of-the-art accuracy and strong\ngeneralization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD,\nand 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon,\noutperforming a two-layer stacked LSTM baseline. These findings demonstrate the\npractical advantages of a physics-informed and feature-rich machine learning\nframework for real-time lane-change intention prediction in autonomous driving\nsystems.", "published": "2025-09-22 05:17:54", "link": "http://arxiv.org/abs/2509.17354v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation", "abstract": "Automating radiology report generation poses a dual challenge: building\nclinically reliable systems and designing rigorous evaluation protocols. We\nintroduce a multi-agent reinforcement learning framework that serves as both a\nbenchmark and evaluation environment for multimodal clinical reasoning in the\nradiology ecosystem. The proposed framework integrates large language models\n(LLMs) and large vision models (LVMs) within a modular architecture composed of\nten specialized agents responsible for image analysis, feature extraction,\nreport generation, review, and evaluation. This design enables fine-grained\nassessment at both the agent level (e.g., detection and segmentation accuracy)\nand the consensus level (e.g., report quality and clinical relevance). We\ndemonstrate an implementation using chatGPT-4o on public radiology datasets,\nwhere LLMs act as evaluators alongside medical radiologist feedback. By\naligning evaluation protocols with the LLM development lifecycle, including\npretraining, finetuning, alignment, and deployment, the proposed benchmark\nestablishes a path toward trustworthy deviance-based radiology report\ngeneration.", "published": "2025-09-22 04:31:27", "link": "http://arxiv.org/abs/2509.17353v1", "categories": ["cs.AI", "eess.IV", "physics.med-ph"], "primary_category": "cs.AI"}
{"title": "Preconditioned Deformation Grids", "abstract": "Dynamic surface reconstruction of objects from point cloud sequences is a\nchallenging field in computer graphics. Existing approaches either require\nmultiple regularization terms or extensive training data which, however, lead\nto compromises in reconstruction accuracy as well as over-smoothing or poor\ngeneralization to unseen objects and motions. To address these lim- itations,\nwe introduce Preconditioned Deformation Grids, a novel technique for estimating\ncoherent deformation fields directly from unstructured point cloud sequences\nwithout requiring or forming explicit correspondences. Key to our approach is\nthe use of multi-resolution voxel grids that capture the overall motion at\nvarying spatial scales, enabling a more flexible deformation representation. In\nconjunction with incorporating grid-based Sobolev preconditioning into\ngradient-based optimization, we show that applying a Chamfer loss between the\ninput point clouds as well as to an evolving template mesh is sufficient to\nobtain accurate deformations. To ensure temporal consistency along the object\nsurface, we include a weak isometry loss on mesh edges which complements the\nmain objective without constraining deformation fidelity. Extensive evaluations\ndemonstrate that our method achieves superior results, particularly for long\nsequences, compared to state-of-the-art techniques.", "published": "2025-09-22 17:59:55", "link": "http://arxiv.org/abs/2509.18097v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers", "abstract": "Text-to-image diffusion models excel at translating language prompts into\nphotorealistic images by implicitly grounding textual concepts through their\ncross-modal attention mechanisms. Recent multi-modal diffusion transformers\nextend this by introducing joint self-attention over concatenated image and\ntext tokens, enabling richer and more scalable cross-modal alignment. However,\na detailed understanding of how and where these attention maps contribute to\nimage generation remains limited. In this paper, we introduce Seg4Diff\n(Segmentation for Diffusion), a systematic framework for analyzing the\nattention structures of MM-DiT, with a focus on how specific layers propagate\nsemantic information from text to image. Through comprehensive analysis, we\nidentify a semantic grounding expert layer, a specific MM-DiT block that\nconsistently aligns text tokens with spatially coherent image regions,\nnaturally producing high-quality semantic segmentation masks. We further\ndemonstrate that applying a lightweight fine-tuning scheme with mask-annotated\nimage data enhances the semantic grouping capabilities of these layers and\nthereby improves both segmentation performance and generated image fidelity.\nOur findings demonstrate that semantic grouping is an emergent property of\ndiffusion transformers and can be selectively amplified to advance both\nsegmentation and generation performance, paving the way for unified models that\nbridge visual perception and generation.", "published": "2025-09-22 17:59:54", "link": "http://arxiv.org/abs/2509.18096v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation", "abstract": "Generating high-fidelity images of humans with fine-grained control over\nattributes such as hairstyle and clothing remains a core challenge in\npersonalized text-to-image synthesis. While prior methods emphasize identity\npreservation from a reference image, they lack modularity and fail to provide\ndisentangled control over specific visual attributes. We introduce a new\nparadigm for attribute-specific image prompting, in which distinct sets of\nreference images are used to guide the generation of individual aspects of\nhuman appearance, such as hair, clothing, and identity. Our method encodes\nthese inputs into attribute-specific tokens, which are injected into a\npre-trained text-to-image diffusion model. This enables compositional and\ndisentangled control over multiple visual factors, even across multiple people\nwithin a single image. To promote natural composition and robust\ndisentanglement, we curate a cross-reference training dataset featuring\nsubjects in diverse poses and expressions, and propose a multi-attribute\ncross-reference training strategy that encourages the model to generate\nfaithful outputs from misaligned attribute inputs while adhering to both\nidentity and textual conditioning. Extensive experiments show that our method\nachieves state-of-the-art performance in accurately following both visual and\ntextual prompts. Our framework paves the way for more configurable human image\nsynthesis by combining visual prompting with text-driven generation. Webpage is\navailable at: https://snap-research.github.io/composeme/.", "published": "2025-09-22 17:59:30", "link": "http://arxiv.org/abs/2509.18092v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction", "abstract": "Reconstructing accurate surfaces with radiance fields has achieved remarkable\nprogress in recent years. However, prevailing approaches, primarily based on\nGaussian Splatting, are increasingly constrained by representational\nbottlenecks. In this paper, we introduce GeoSVR, an explicit voxel-based\nframework that explores and extends the under-investigated potential of sparse\nvoxels for achieving accurate, detailed, and complete surface reconstruction.\nAs strengths, sparse voxels support preserving the coverage completeness and\ngeometric clarity, while corresponding challenges also arise from absent scene\nconstraints and locality in surface refinement. To ensure correct scene\nconvergence, we first propose a Voxel-Uncertainty Depth Constraint that\nmaximizes the effect of monocular depth cues while presenting a voxel-oriented\nuncertainty to avoid quality degradation, enabling effective and robust scene\nconstraints yet preserving highly accurate geometries. Subsequently, Sparse\nVoxel Surface Regularization is designed to enhance geometric consistency for\ntiny voxels and facilitate the voxel-based formation of sharp and accurate\nsurfaces. Extensive experiments demonstrate our superior performance compared\nto existing methods across diverse challenging scenarios, excelling in\ngeometric accuracy, detail preservation, and reconstruction completeness while\nmaintaining high efficiency. Code is available at\nhttps://github.com/Fictionarry/GeoSVR.", "published": "2025-09-22 17:58:48", "link": "http://arxiv.org/abs/2509.18090v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GraDeT-HTR: A Resource-Efficient Bengali Handwritten Text Recognition System utilizing Grapheme-based Tokenizer and Decoder-only Transformer", "abstract": "Despite Bengali being the sixth most spoken language in the world,\nhandwritten text recognition (HTR) systems for Bengali remain severely\nunderdeveloped. The complexity of Bengali script--featuring conjuncts,\ndiacritics, and highly variable handwriting styles--combined with a scarcity of\nannotated datasets makes this task particularly challenging. We present\nGraDeT-HTR, a resource-efficient Bengali handwritten text recognition system\nbased on a Grapheme-aware Decoder-only Transformer architecture. To address the\nunique challenges of Bengali script, we augment the performance of a\ndecoder-only transformer by integrating a grapheme-based tokenizer and\ndemonstrate that it significantly improves recognition accuracy compared to\nconventional subword tokenizers. Our model is pretrained on large-scale\nsynthetic data and fine-tuned on real human-annotated samples, achieving\nstate-of-the-art performance on multiple benchmark datasets.", "published": "2025-09-22 17:56:17", "link": "http://arxiv.org/abs/2509.18081v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs", "abstract": "This paper introduces TempSamp-R1, a new reinforcement fine-tuning framework\ndesigned to improve the effectiveness of adapting multimodal large language\nmodels (MLLMs) to video temporal grounding tasks. We reveal that existing\nreinforcement learning methods, such as Group Relative Policy Optimization\n(GRPO), rely on on-policy sampling for policy updates. However, in tasks with\nlarge temporal search spaces, this strategy becomes both inefficient and\nlimited in performance, as it often fails to identify temporally accurate\nsolutions. To address this limitation, TempSamp-R1 leverages ground-truth\nannotations as off-policy supervision to provide temporally precise guidance,\neffectively compensating for the sparsity and misalignment in on-policy\nsolutions. To further stabilize training and reduce variance in reward-based\nupdates, TempSamp-R1 provides a non-linear soft advantage computation method\nthat dynamically reshapes the reward feedback via an asymmetric transformation.\nBy employing a hybrid Chain-of-Thought (CoT) training paradigm, TempSamp-R1\noptimizes a single unified model to support both CoT and non-CoT inference\nmodes, enabling efficient handling of queries with varying reasoning\ncomplexity. Experimental results demonstrate that TempSamp-R1 outperforms\nGRPO-based baselines, establishing new state-of-the-art performance on\nbenchmark datasets: Charades-STA (R1@0.7: 52.9%, +2.7%), ActivityNet Captions\n(R1@0.5: 56.0%, +5.3%), and QVHighlights (mAP: 30.0%, +3.0%). Moreover,\nTempSamp-R1 shows robust few-shot generalization capabilities under limited\ndata. Code: https://github.com/HVision-NKU/TempSamp-R1", "published": "2025-09-22 17:30:15", "link": "http://arxiv.org/abs/2509.18056v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning", "abstract": "Long-Form Video Question Answering (LVQA) poses challenges beyond traditional\nvisual question answering (VQA), which is often limited to static images or\nshort video clips. While current vision-language models (VLMs) perform well in\nthose settings, they struggle with complex queries in LVQA over long videos\ninvolving multi-step temporal reasoning and causality. Vanilla approaches,\nwhich sample frames uniformly and feed them to a VLM with the question, incur\nsignificant token overhead, forcing severe downsampling. As a result, the model\noften misses fine-grained visual structure, subtle event transitions, or key\ntemporal cues, ultimately leading to incorrect answers. To address these\nlimitations, recent works have explored query-adaptive frame sampling,\nhierarchical keyframe selection, and agent-based iterative querying. However,\nthese methods remain fundamentally heuristic: they lack explicit temporal\nrepresentations and cannot enforce or verify logical event relationships. As a\nresult, there are no formal guarantees that the sampled context actually\nencodes the compositional or causal logic demanded by the question. To address\nthese foundational gaps, we introduce NeuS-QA, a training-free, plug-and-play\nneuro-symbolic pipeline for LVQA. NeuS-QA translates a natural language\nquestion into a formal temporal logic expression, constructs a video automaton\nfrom frame-level semantic propositions, and applies model checking to\nrigorously identify video segments satisfying the question's logical\nrequirements. Only these logic-verified segments are submitted to the VLM, thus\nimproving interpretability, reducing hallucinations, and enabling compositional\nreasoning without modifying or fine-tuning the model. Experiments on\nLongVideoBench and CinePile show NeuS-QA improves performance by over 10%,\nespecially on questions involving event ordering, causality, and multi-step\ncompositional reasoning.", "published": "2025-09-22 17:15:13", "link": "http://arxiv.org/abs/2509.18041v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detection of Misreporting Attacks on Software-Defined Immersive Environments", "abstract": "The ability to centrally control network infrastructure using a programmable\nmiddleware has made Software-Defined Networking (SDN) ideal for emerging\napplications, such as immersive environments. However, such flexibility\nintroduces new vulnerabilities, such as switch misreporting led load imbalance,\nwhich in turn make such immersive environment vulnerable to severe quality\ndegradation. In this paper, we present a hybrid machine learning (ML)-based\nnetwork anomaly detection framework that identifies such stealthy misreporting\nby capturing temporal inconsistencies in switch-reported loads, and thereby\ncounter potentially catastrophic quality degradation of hosted immersive\napplication. The detection system combines unsupervised anomaly scoring with\nsupervised classification to robustly distinguish malicious behavior. Data\ncollected from a realistic testbed deployment under both benign and adversarial\nconditions is used to train and evaluate the model. Experimental results show\nthat the framework achieves high recall in detecting misreporting behavior,\nmaking it effective for early and reliable detection in SDN environments.", "published": "2025-09-22 17:14:40", "link": "http://arxiv.org/abs/2509.18040v1", "categories": ["cs.NI", "cs.CV"], "primary_category": "cs.NI"}
{"title": "StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models", "abstract": "The advancement of diffusion models has enhanced the realism of AI-generated\ncontent but also raised concerns about misuse, necessitating robust copyright\nprotection and tampering localization. Although recent methods have made\nprogress toward unified solutions, their reliance on post hoc processing\nintroduces considerable application inconvenience and compromises forensic\nreliability. We propose StableGuard, a novel framework that seamlessly\nintegrates a binary watermark into the diffusion generation process, ensuring\ncopyright protection and tampering localization in Latent Diffusion Models\nthrough an end-to-end design. We develop a Multiplexing Watermark VAE (MPW-VAE)\nby equipping a pretrained Variational Autoencoder (VAE) with a lightweight\nlatent residual-based adapter, enabling the generation of paired watermarked\nand watermark-free images. These pairs, fused via random masks, create a\ndiverse dataset for training a tampering-agnostic forensic network. To further\nenhance forensic synergy, we introduce a Mixture-of-Experts Guided Forensic\nNetwork (MoE-GFN) that dynamically integrates holistic watermark patterns,\nlocal tampering traces, and frequency-domain cues for precise watermark\nverification and tampered region detection. The MPW-VAE and MoE-GFN are jointly\noptimized in a self-supervised, end-to-end manner, fostering a reciprocal\ntraining between watermark embedding and forensic accuracy. Extensive\nexperiments demonstrate that StableGuard consistently outperforms\nstate-of-the-art methods in image fidelity, watermark verification, and\ntampering localization.", "published": "2025-09-22 16:35:19", "link": "http://arxiv.org/abs/2509.17993v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Detector Compression via Location-Aware Discriminant Analysis", "abstract": "Deep neural networks are powerful, yet their high complexity greatly limits\ntheir potential to be deployed on billions of resource-constrained edge\ndevices. Pruning is a crucial network compression technique, yet most existing\nmethods focus on classification models, with limited attention to detection.\nEven among those addressing detection, there is a lack of utilization of\nessential localization information. Also, many pruning methods passively rely\non pre-trained models, in which useful and useless components are intertwined,\nmaking it difficult to remove the latter without harming the former at the\nneuron/filter level. To address the above issues, in this paper, we propose a\nproactive detection-discriminants-based network compression approach for deep\nvisual detectors, which alternates between two steps: (1) maximizing and\ncompressing detection-related discriminants and aligning them with a subset of\nneurons/filters immediately before the detection head, and (2) tracing the\ndetection-related discriminating power across the layers and discarding\nfeatures of lower importance. Object location information is exploited in both\nsteps. Extensive experiments, employing four advanced detection models and four\nstate-of-the-art competing methods on the KITTI and COCO datasets, highlight\nthe superiority of our approach. Remarkably, our compressed models can even\nbeat the original base models with a substantial reduction in complexity.", "published": "2025-09-22 16:19:00", "link": "http://arxiv.org/abs/2509.17968v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Breaking the Discretization Barrier of Continuous Physics Simulation Learning", "abstract": "The modeling of complicated time-evolving physical dynamics from partial\nobservations is a long-standing challenge. Particularly, observations can be\nsparsely distributed in a seemingly random or unstructured manner, making it\ndifficult to capture highly nonlinear features in a variety of scientific and\nengineering problems. However, existing data-driven approaches are often\nconstrained by fixed spatial and temporal discretization. While some\nresearchers attempt to achieve spatio-temporal continuity by designing novel\nstrategies, they either overly rely on traditional numerical methods or fail to\ntruly overcome the limitations imposed by discretization. To address these, we\npropose CoPS, a purely data-driven methods, to effectively model continuous\nphysics simulation from partial observations. Specifically, we employ\nmultiplicative filter network to fuse and encode spatial information with the\ncorresponding observations. Then we customize geometric grids and use\nmessage-passing mechanism to map features from original spatial domain to the\ncustomized grids. Subsequently, CoPS models continuous-time dynamics by\ndesigning multi-scale graph ODEs, while introducing a Markov-based neural\nauto-correction module to assist and constrain the continuous extrapolations.\nComprehensive experiments demonstrate that CoPS advances the state-of-the-art\nmethods in space-time continuous modeling across various scenarios.", "published": "2025-09-22 16:10:58", "link": "http://arxiv.org/abs/2509.17955v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DragOSM: Extract Building Roofs and Footprints from Aerial Images by Aligning Historical Labels", "abstract": "Extracting polygonal roofs and footprints from remote sensing images is\ncritical for large-scale urban analysis. Most existing methods rely on\nsegmentation-based models that assume clear semantic boundaries of roofs, but\nthese approaches struggle in off- nadir images, where the roof and footprint\nare significantly displaced, and facade pixels are fused with the roof\nboundary. With the increasing availability of open vector map annotations,\ne.g., OpenStreetMap, utilizing historical labels for off-nadir image annotation\nhas become viable because remote sensing images are georeferenced once\ncaptured. However, these historical labels commonly suffer from significant\npositional discrepancies with new images and only have one annotation (roof or\nfootprint), which fails to describe the correct structures of a building. To\naddress these discrepancies, we first introduce a concept of an alignment\ntoken, which encodes the correction vector to guide the label correction. Based\non this concept, we then propose Drag OpenStreetMap Labels (DragOSM), a novel\nmodel designed to align dislocated historical labels with roofs and footprints.\nSpecifically, DragOSM formulates the label alignment as an interactive\ndenoising process, modeling the positional discrepancy as a Gaussian\ndistribution. During training, it learns to correct these errors by simulating\nmisalignment with random Gaussian perturbations; during inference, it\niteratively refines the positions of input labels. To validate our method, we\nfurther present a new dataset, Repairing Buildings in OSM (ReBO), comprising\n179,265 buildings with both OpenStreetMap and manually corrected annotations\nacross 5,473 images from 41 cities. Experimental results on ReBO demonstrate\nthe effectiveness of DragOSM. Code, dataset, and trained models are publicly\navailable at https://github.com/likaiucas/DragOSM.git.", "published": "2025-09-22 16:10:13", "link": "http://arxiv.org/abs/2509.17951v1", "categories": ["cs.CV", "I.5.4"], "primary_category": "cs.CV"}
{"title": "Can multimodal representation learning by alignment preserve modality-specific information?", "abstract": "Combining multimodal data is a key issue in a wide range of machine learning\ntasks, including many remote sensing problems. In Earth observation, early\nmultimodal data fusion methods were based on specific neural network\narchitectures and supervised learning. Ever since, the scarcity of labeled data\nhas motivated self-supervised learning techniques. State-of-the-art multimodal\nrepresentation learning techniques leverage the spatial alignment between\nsatellite data from different modalities acquired over the same geographic area\nin order to foster a semantic alignment in the latent space. In this paper, we\ninvestigate how this methods can preserve task-relevant information that is not\nshared across modalities. First, we show, under simplifying assumptions, when\nalignment strategies fundamentally lead to an information loss. Then, we\nsupport our theoretical insight through numerical experiments in more realistic\nsettings. With those theoretical and empirical evidences, we hope to support\nnew developments in contrastive learning for the combination of multimodal\nsatellite data. Our code and data is publicly available at\nhttps://github.com/Romain3Ch216/alg_maclean_25.", "published": "2025-09-22 16:06:10", "link": "http://arxiv.org/abs/2509.17943v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving", "abstract": "End-to-end autonomous driving has substantially progressed by directly\npredicting future trajectories from raw perception inputs, which bypasses\ntraditional modular pipelines. However, mainstream methods trained via\nimitation learning suffer from critical safety limitations, as they fail to\ndistinguish between trajectories that appear human-like but are potentially\nunsafe. Some recent approaches attempt to address this by regressing multiple\nrule-driven scores but decoupling supervision from policy optimization,\nresulting in suboptimal performance. To tackle these challenges, we propose\nDriveDPO, a Safety Direct Preference Optimization Policy Learning framework.\nFirst, we distill a unified policy distribution from human imitation similarity\nand rule-based safety scores for direct policy optimization. Further, we\nintroduce an iterative Direct Preference Optimization stage formulated as\ntrajectory-level preference alignment. Extensive experiments on the NAVSIM\nbenchmark demonstrate that DriveDPO achieves a new state-of-the-art PDMS of\n90.0. Furthermore, qualitative results across diverse challenging scenarios\nhighlight DriveDPO's ability to produce safer and more reliable driving\nbehaviors.", "published": "2025-09-22 16:01:11", "link": "http://arxiv.org/abs/2509.17940v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Multi-needle Localization for Pelvic Seed Implant Brachytherapy based on Tip-handle Detection and Matching", "abstract": "Accurate multi-needle localization in intraoperative CT images is crucial for\noptimizing seed placement in pelvic seed implant brachytherapy. However, this\ntask is challenging due to poor image contrast and needle adhesion. This paper\npresents a novel approach that reframes needle localization as a tip-handle\ndetection and matching problem to overcome these difficulties. An anchor-free\nnetwork, based on HRNet, is proposed to extract multi-scale features and\naccurately detect needle tips and handles by predicting their centers and\norientations using decoupled branches for heatmap regression and polar angle\nprediction. To associate detected tips and handles into individual needles, a\ngreedy matching and merging (GMM) method designed to solve the unbalanced\nassignment problem with constraints (UAP-C) is presented. The GMM method\niteratively selects the most probable tip-handle pairs and merges them based on\na distance metric to reconstruct 3D needle paths. Evaluated on a dataset of 100\npatients, the proposed method demonstrates superior performance, achieving\nhigher precision and F1 score compared to a segmentation-based method utilizing\nthe nnUNet model,thereby offering a more robust and accurate solution for\nneedle localization in complex clinical scenarios.", "published": "2025-09-22 15:53:37", "link": "http://arxiv.org/abs/2509.17931v1", "categories": ["cs.CV", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI", "abstract": "Reliable brain tumor segmentation in MRI is indispensable for treatment\nplanning and outcome monitoring, yet models trained on curated benchmarks often\nfail under domain shifts arising from scanner and protocol variability as well\nas population heterogeneity. Such gaps are especially severe in low-resource\nand pediatric cohorts, where conventional test-time or source-free adaptation\nstrategies often suffer from instability and structural inconsistency. We\npropose SmaRT, a style-modulated robust test-time adaptation framework that\nenables source-free cross-domain generalization. SmaRT integrates style-aware\naugmentation to mitigate appearance discrepancies, a dual-branch momentum\nstrategy for stable pseudo-label refinement, and structural priors enforcing\nconsistency, integrity, and connectivity. This synergy ensures both adaptation\nstability and anatomical fidelity under extreme domain shifts. Extensive\nevaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT\nconsistently outperforms state-of-the-art methods, with notable gains in Dice\naccuracy and boundary precision. Overall, SmaRT bridges the gap between\nalgorithmic advances and equitable clinical applicability, supporting robust\ndeployment of MRI-based neuro-oncology tools in diverse clinical environments.\nOur source code is available at https://github.com/baiyou1234/SmaRT.", "published": "2025-09-22 15:50:59", "link": "http://arxiv.org/abs/2509.17925v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Does Audio Matter for Modern Video-LLMs and Their Benchmarks?", "abstract": "Modern multimodal large language models often claim \"video understanding,\"\nyet most evaluations use muted videos or simply discard audio. We ask a direct\nquestion: how much does audio actually matter for contemporary Video-LLMs and\nthe benchmarks that certify them? We audit widely used suites and observe that\nmany items are even solvable from a single frame, rendering audio largely\nredundant. Building on LLaVA-OneVision architecture, we attach a speech/audio\nencoder (e.g., Whisper) and analyze when audio helps, while addressing audio\ntoken explosion with a lightweight Mamba-based state-space token compressor. We\nfind that audio yields minimal gains on recent video benchmarks but is decisive\non curated, audio-sensitive subsets. To enable faithful evaluation, we release\nAVQA-Hard and Music-AVQA-Hard, our model, and code. Our findings surface a\ngrowing gap between current academic practice and real-world expectations, and\nprovide practical tools for scalable audio-visual Video-LLMs. We will fully\nopen-source our work at https://github.com/naver-ai/LLaVA-AV-SSM.", "published": "2025-09-22 15:28:54", "link": "http://arxiv.org/abs/2509.17901v1", "categories": ["cs.CV", "cs.MM", "cs.SD"], "primary_category": "cs.CV"}
{"title": "Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection", "abstract": "Autonomous inspection is a central problem in robotics, with applications\nranging from industrial monitoring to search-and-rescue. Traditionally,\ninspection has often been reduced to navigation tasks, where the objective is\nto reach a predefined location while avoiding obstacles. However, this\nformulation captures only part of the real inspection problem. In real-world\nenvironments, the inspection targets may become visible well before their exact\ncoordinates are reached, making further movement both redundant and\ninefficient. What matters more for inspection is not simply arriving at the\ntarget's position, but positioning the robot at a viewpoint from which the\ntarget becomes observable. In this work, we revisit inspection from a\nperception-aware perspective. We propose an end-to-end reinforcement learning\nframework that explicitly incorporates target visibility as the primary\nobjective, enabling the robot to find the shortest trajectory that guarantees\nvisual contact with the target without relying on a map. The learned policy\nleverages both perceptual and proprioceptive sensing and is trained entirely in\nsimulation, before being deployed to a real-world robot. We further develop an\nalgorithm to compute ground-truth shortest inspection paths, which provides a\nreference for evaluation. Through extensive experiments, we show that our\nmethod outperforms existing classical and learning-based navigation approaches,\nyielding more efficient inspection trajectories in both simulated and\nreal-world settings. The project is avialable at\nhttps://sight-over-site.github.io/", "published": "2025-09-22 15:14:02", "link": "http://arxiv.org/abs/2509.17877v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos", "abstract": "Achieving truly practical dynamic 3D reconstruction requires online\noperation, global pose and map consistency, detailed appearance modeling, and\nthe flexibility to handle both RGB and RGB-D inputs. However, existing SLAM\nmethods typically merely remove the dynamic parts or require RGB-D input, while\noffline methods are not scalable to long video sequences, and current\ntransformer-based feedforward methods lack global consistency and appearance\ndetails. To this end, we achieve online dynamic scene reconstruction by\ndisentangling the static and dynamic parts within a SLAM system. The poses are\ntracked robustly with a novel motion masking strategy, and dynamic parts are\nreconstructed leveraging a progressive adaptation of a Motion Scaffolds graph.\nOur method yields novel view renderings competitive to offline methods and\nachieves on-par tracking with state-of-the-art dynamic SLAM methods.", "published": "2025-09-22 14:58:11", "link": "http://arxiv.org/abs/2509.17864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology", "abstract": "Synthetic data generation in histopathology faces unique challenges:\npreserving tissue heterogeneity, capturing subtle morphological features, and\nscaling to unannotated datasets. We present a latent diffusion model that\ngenerates realistic heterogeneous histopathology images through a novel\ndual-conditioning approach combining semantic segmentation maps with\ntissue-specific visual crops. Unlike existing methods that rely on text prompts\nor abstract visual embeddings, our approach preserves critical morphological\ndetails by directly incorporating raw tissue crops from corresponding semantic\nregions. For annotated datasets (i.e., Camelyon16, Panda), we extract patches\nensuring 20-80% tissue heterogeneity. For unannotated data (i.e., TCGA), we\nintroduce a self-supervised extension that clusters whole-slide images into 100\ntissue types using foundation model embeddings, automatically generating\npseudo-semantic maps for training. Our method synthesizes high-fidelity images\nwith precise region-wise annotations, achieving superior performance on\ndownstream segmentation tasks. When evaluated on annotated datasets, models\ntrained on our synthetic data show competitive performance to those trained on\nreal data, demonstrating the utility of controlled heterogeneous tissue\ngeneration. In quantitative evaluation, prompt-guided synthesis reduces Frechet\nDistance by up to 6X on Camelyon16 (from 430.1 to 72.0) and yields 2-3x lower\nFD across Panda and TCGA. Downstream DeepLabv3+ models trained solely on\nsynthetic data attain test IoU of 0.71 and 0.95 on Camelyon16 and Panda, within\n1-2% of real-data baselines (0.72 and 0.96). By scaling to 11,765 TCGA\nwhole-slide images without manual annotations, our framework offers a practical\nsolution for an urgent need for generating diverse, annotated histopathology\ndata, addressing a critical bottleneck in computational pathology.", "published": "2025-09-22 14:41:43", "link": "http://arxiv.org/abs/2509.17847v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment", "abstract": "Training-free video object editing aims to achieve precise object-level\nmanipulation, including object insertion, swapping, and deletion. However, it\nfaces significant challenges in maintaining fidelity and temporal consistency.\nExisting methods, often designed for U-Net architectures, suffer from two\nprimary limitations: inaccurate inversion due to first-order solvers, and\ncontextual conflicts caused by crude \"hard\" feature replacement. These issues\nare more challenging in Diffusion Transformers (DiTs), where the unsuitability\nof prior layer-selection heuristics makes effective guidance challenging. To\naddress these limitations, we introduce ContextFlow, a novel training-free\nframework for DiT-based video object editing. In detail, we first employ a\nhigh-order Rectified Flow solver to establish a robust editing foundation. The\ncore of our framework is Adaptive Context Enrichment (for specifying what to\nedit), a mechanism that addresses contextual conflicts. Instead of replacing\nfeatures, it enriches the self-attention context by concatenating Key-Value\npairs from parallel reconstruction and editing paths, empowering the model to\ndynamically fuse information. Additionally, to determine where to apply this\nenrichment (for specifying where to edit), we propose a systematic, data-driven\nanalysis to identify task-specific vital layers. Based on a novel Guidance\nResponsiveness Metric, our method pinpoints the most influential DiT blocks for\ndifferent tasks (e.g., insertion, swapping), enabling targeted and highly\neffective guidance. Extensive experiments show that ContextFlow significantly\noutperforms existing training-free methods and even surpasses several\nstate-of-the-art training-based approaches, delivering temporally coherent,\nhigh-fidelity results.", "published": "2025-09-22 14:13:31", "link": "http://arxiv.org/abs/2509.17818v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training", "abstract": "Self-supervised learning (SSL) has emerged as a central paradigm for training\nfoundation models by leveraging large-scale unlabeled datasets, often producing\nrepresentations with strong generalization capabilities. These models are\ntypically pre-trained on general-purpose datasets such as ImageNet and\nsubsequently adapted to various downstream tasks through finetuning. While\nrecent advances have explored parameter-efficient strategies for adapting\npre-trained models, extending SSL pre-training itself to new domains -\nparticularly under limited data regimes and for dense prediction tasks -\nremains underexplored. In this work, we address the problem of adapting vision\nfoundation models to new domains in an unsupervised and data-efficient manner,\nspecifically targeting downstream semantic segmentation. We propose GLARE\n(Global Local and Regional Enforcement), a novel continual self-supervised\npre-training task designed to enhance downstream segmentation performance.\nGLARE introduces patch-level augmentations to encourage local consistency and\nincorporates a regional consistency constraint that leverages spatial semantics\nin the data. For efficient continual pre-training, we initialize Vision\nTransformers (ViTs) with weights from existing SSL models and update only\nlightweight adapter modules - specifically UniAdapter - while keeping the rest\nof the backbone frozen. Experiments across multiple semantic segmentation\nbenchmarks on different domains demonstrate that GLARE consistently improves\ndownstream performance with minimal computational and parameter overhead.", "published": "2025-09-22 14:11:02", "link": "http://arxiv.org/abs/2509.17816v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Selecting Optimal Camera Views for Gait Analysis: A Multi-Metric Assessment of 2D Projections", "abstract": "Objective: To systematically quantify the effect of the camera view (frontal\nvs. lateral) on the accuracy of 2D markerless gait analysis relative to 3D\nmotion capture ground truth. Methods: Gait data from 18 subjects were recorded\nsimultaneously using frontal, lateral and 3D motion capture systems. Pose\nestimation used YOLOv8. Four metrics were assessed to evaluate agreement:\nDynamic Time Warping (DTW) for temporal alignment, Maximum Cross-Correlation\n(MCC) for signal similarity, Kullback-Leibler Divergence (KLD) for distribution\ndifferences, and Information Entropy (IE) for complexity. Wilcoxon signed-rank\ntests (significance: $p < 0.05$) and Cliff's delta ($\\delta$) were used to\nmeasure statistical differences and effect sizes. Results: Lateral views\nsignificantly outperformed frontal views for sagittal plane kinematics: step\nlength (DTW: $53.08 \\pm 24.50$ vs. $69.87 \\pm 25.36$, $p = 0.005$) and knee\nrotation (DTW: $106.46 \\pm 38.57$ vs. $155.41 \\pm 41.77$, $p = 0.004$). Frontal\nviews were superior for symmetry parameters: trunk rotation (KLD: $0.09 \\pm\n0.06$ vs. $0.30 \\pm 0.19$, $p < 0.001$) and wrist-to-hipmid distance (MCC:\n$105.77 \\pm 29.72$ vs. $75.20 \\pm 20.38$, $p = 0.003$). Effect sizes were\nmedium-to-large ($\\delta: 0.34$--$0.76$). Conclusion: Camera view critically\nimpacts gait parameter accuracy. Lateral views are optimal for sagittal\nkinematics; frontal views excel for trunk symmetry. Significance: This first\nsystematic evidence enables data-driven camera deployment in 2D gait analysis,\nenhancing clinical utility. Future implementations should leverage both views\nvia disease-oriented setups.", "published": "2025-09-22 14:00:20", "link": "http://arxiv.org/abs/2509.17805v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Degradation-Aware All-in-One Image Restoration via Latent Prior Encoding", "abstract": "Real-world images often suffer from spatially diverse degradations such as\nhaze, rain, snow, and low-light, significantly impacting visual quality and\ndownstream vision tasks. Existing all-in-one restoration (AIR) approaches\neither depend on external text prompts or embed hand-crafted architectural\npriors (e.g., frequency heuristics); both impose discrete, brittle assumptions\nthat weaken generalization to unseen or mixed degradations. To address this\nlimitation, we propose to reframe AIR as learned latent prior inference, where\ndegradation-aware representations are automatically inferred from the input\nwithout explicit task cues. Based on latent priors, we formulate AIR as a\nstructured reasoning paradigm: (1) which features to route (adaptive feature\nselection), (2) where to restore (spatial localization), and (3) what to\nrestore (degradation semantics). We design a lightweight decoding module that\nefficiently leverages these latent encoded cues for spatially-adaptive\nrestoration. Extensive experiments across six common degradation tasks, five\ncompound settings, and previously unseen degradations demonstrate that our\nmethod outperforms state-of-the-art (SOTA) approaches, achieving an average\nPSNR improvement of 1.68 dB while being three times more efficient.", "published": "2025-09-22 13:51:09", "link": "http://arxiv.org/abs/2509.17792v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for Underwater Scenes", "abstract": "Underwater image degradation poses significant challenges for 3D\nreconstruction, where simplified physical models often fail in complex scenes.\nWe propose \\textbf{R-Splatting}, a unified framework that bridges underwater\nimage restoration (UIR) with 3D Gaussian Splatting (3DGS) to improve both\nrendering quality and geometric fidelity. Our method integrates multiple\nenhanced views produced by diverse UIR models into a single reconstruction\npipeline. During inference, a lightweight illumination generator samples latent\ncodes to support diverse yet coherent renderings, while a contrastive loss\nensures disentangled and stable illumination representations. Furthermore, we\npropose \\textit{Uncertainty-Aware Opacity Optimization (UAOO)}, which models\nopacity as a stochastic function to regularize training. This suppresses abrupt\ngradient responses triggered by illumination variation and mitigates\noverfitting to noisy or view-specific artifacts. Experiments on Seathru-NeRF\nand our new BlueCoral3D dataset demonstrate that R-Splatting outperforms strong\nbaselines in both rendering quality and geometric accuracy.", "published": "2025-09-22 13:50:20", "link": "http://arxiv.org/abs/2509.17789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "I2VWM: Robust Watermarking for Image to Video Generation", "abstract": "The rapid progress of image-guided video generation (I2V) has raised concerns\nabout its potential misuse in misinformation and fraud, underscoring the urgent\nneed for effective digital watermarking. While existing watermarking methods\ndemonstrate robustness within a single modality, they fail to trace source\nimages in I2V settings. To address this gap, we introduce the concept of Robust\nDiffusion Distance, which measures the temporal persistence of watermark\nsignals in generated videos. Building on this, we propose I2VWM, a cross-modal\nwatermarking framework designed to enhance watermark robustness across time.\nI2VWM leverages a video-simulation noise layer during training and employs an\noptical-flow-based alignment module during inference. Experiments on both\nopen-source and commercial I2V models demonstrate that I2VWM significantly\nimproves robustness while maintaining imperceptibility, establishing a new\nparadigm for cross-modal watermarking in the era of generative video.\n\\href{https://github.com/MrCrims/I2VWM-Robust-Watermarking-for-Image-to-Video-Generation}{Code\nReleased.}", "published": "2025-09-22 13:37:37", "link": "http://arxiv.org/abs/2509.17773v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics", "abstract": "As the third generation of neural networks, spiking neural networks (SNNs)\nhave recently gained widespread attention for their biological plausibility,\nenergy efficiency, and effectiveness in processing neuromorphic datasets. To\nbetter emulate biological neurons, various models such as Integrate-and-Fire\n(IF) and Leaky Integrate-and-Fire (LIF) have been widely adopted in SNNs.\nHowever, these neuron models overlook the refractory period, a fundamental\ncharacteristic of biological neurons. Research on excitable neurons reveal that\nafter firing, neurons enter a refractory period during which they are\ntemporarily unresponsive to subsequent stimuli. This mechanism is critical for\npreventing over-excitation and mitigating interference from aberrant signals.\nTherefore, we propose a simple yet effective method to incorporate the\nrefractory period into spiking LIF neurons through spike-triggered threshold\ndynamics, termed RPLIF. Our method ensures that each spike accurately encodes\nneural information, effectively preventing neuron over-excitation under\ncontinuous inputs and interference from anomalous inputs. Incorporating the\nrefractory period into LIF neurons is seamless and computationally efficient,\nenhancing robustness and efficiency while yielding better performance with\nnegligible overhead. To the best of our knowledge, RPLIF achieves\nstate-of-the-art performance on Cifar10-DVS(82.40%) and N-Caltech101(83.35%)\nwith fewer timesteps and demonstrates superior performance on DVS128\nGesture(97.22%) at low latency.", "published": "2025-09-22 13:33:31", "link": "http://arxiv.org/abs/2509.17769v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural-MMGS: Multi-modal Neural Gaussian Splats for Large-Scale Scene Reconstruction", "abstract": "This paper proposes Neural-MMGS, a novel neural 3DGS framework for multimodal\nlarge-scale scene reconstruction that fuses multiple sensing modalities in a\nper-gaussian compact, learnable embedding. While recent works focusing on\nlarge-scale scene reconstruction have incorporated LiDAR data to provide more\naccurate geometric constraints, we argue that LiDAR's rich physical properties\nremain underexplored. Similarly, semantic information has been used for object\nretrieval, but could provide valuable high-level context for scene\nreconstruction. Traditional approaches append these properties to Gaussians as\nseparate parameters, increasing memory usage and limiting information exchange\nacross modalities. Instead, our approach fuses all modalities -- image, LiDAR,\nand semantics -- into a compact, learnable embedding that implicitly encodes\noptical, physical, and semantic features in each Gaussian. We then train\nlightweight neural decoders to map these embeddings to Gaussian parameters,\nenabling the reconstruction of each sensing modality with lower memory overhead\nand improved scalability. We evaluate Neural-MMGS on the Oxford Spires and\nKITTI-360 datasets. On Oxford Spires, we achieve higher-quality\nreconstructions, while on KITTI-360, our method reaches competitive results\nwith less storage consumption compared with current approaches in LiDAR-based\nnovel-view synthesis.", "published": "2025-09-22 13:24:58", "link": "http://arxiv.org/abs/2509.17762v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Agent Amodal Completion: Direct Synthesis with Fine-Grained Semantic Guidance", "abstract": "Amodal completion, generating invisible parts of occluded objects, is vital\nfor applications like image editing and AR. Prior methods face challenges with\ndata needs, generalization, or error accumulation in progressive pipelines. We\npropose a Collaborative Multi-Agent Reasoning Framework based on upfront\ncollaborative reasoning to overcome these issues. Our framework uses multiple\nagents to collaboratively analyze occlusion relationships and determine\nnecessary boundary expansion, yielding a precise mask for inpainting.\nConcurrently, an agent generates fine-grained textual descriptions, enabling\nFine-Grained Semantic Guidance. This ensures accurate object synthesis and\nprevents the regeneration of occluders or other unwanted elements, especially\nwithin large inpainting areas. Furthermore, our method directly produces\nlayered RGBA outputs guided by visible masks and attention maps from a\nDiffusion Transformer, eliminating extra segmentation. Extensive evaluations\ndemonstrate our framework achieves state-of-the-art visual quality.", "published": "2025-09-22 13:20:06", "link": "http://arxiv.org/abs/2509.17757v1", "categories": ["cs.CV", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Learning Neural Antiderivatives", "abstract": "Neural fields offer continuous, learnable representations that extend beyond\ntraditional discrete formats in visual computing. We study the problem of\nlearning neural representations of repeated antiderivatives directly from a\nfunction, a continuous analogue of summed-area tables. Although widely used in\ndiscrete domains, such cumulative schemes rely on grids, which prevents their\napplicability in continuous neural contexts. We introduce and analyze a range\nof neural methods for repeated integration, including both adaptations of prior\nwork and novel designs. Our evaluation spans multiple input dimensionalities\nand integration orders, assessing both reconstruction quality and performance\nin downstream tasks such as filtering and rendering. These results enable\nintegrating classical cumulative operators into modern neural systems and offer\ninsights into learning tasks involving differential and integral operators.", "published": "2025-09-22 13:19:07", "link": "http://arxiv.org/abs/2509.17755v1", "categories": ["cs.LG", "cs.CV", "cs.GR"], "primary_category": "cs.LG"}
{"title": "Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA", "abstract": "Large language models (LLMs) have shown promise in generating program\nworkflows for visual tasks. However, previous approaches often rely on\nclosed-source models, lack systematic reasoning, and struggle with long-form\nvideo question answering (videoQA). To address these challenges, we introduce\nthe FS-VisPR framework, an adaptive visual program reasoning approach that\nbalances fast reasoning for simple queries with slow reasoning for difficult\nones. First, we design efficient visual modules (e.g., key clip retrieval and\nsubtitle retrieval) to support long-form video tasks. Then, we construct a\ndiverse and high-quality fast-slow reasoning dataset with a strong LLM to align\nopen-source language models' ability to generate visual program workflows as\nFS-LLM. Next, we design a fast-slow reasoning framework with FS-LLM: Simple\nqueries are directly solved by VideoLLMs, while difficult ones invoke visual\nprogram reasoning, motivated by human-like reasoning processes. During this\nprocess, low-confidence fast-thinking answers will trigger a second-stage\nslow-reasoning process, and a fallback mechanism to fast reasoning is activated\nif the program execution fails. Moreover, we improve visual programs through\nparameter search during both training and inference. By adjusting the\nparameters of the visual modules within the program, multiple variants are\ngenerated: during training, programs that yield correct answers are selected,\nwhile during inference, the program with the highest confidence result is\napplied. Experiments show that FS-VisPR improves both efficiency and\nreliability in visual program workflows. It achieves 50.4% accuracy on LVBench,\nsurpassing GPT-4o, matching the performance of Qwen2.5VL-72B on VideoMME.", "published": "2025-09-22 13:06:17", "link": "http://arxiv.org/abs/2509.17743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning", "abstract": "Accurate anatomical labeling of intracranial arteries is essential for\ncerebrovascular diagnosis and hemodynamic analysis but remains time-consuming\nand subject to interoperator variability. We present a deep learning-based\nframework for automated artery labeling from 3D Time-of-Flight Magnetic\nResonance Angiography (3D ToF-MRA) segmentations (n=35), incorporating\nuncertainty quantification to enhance interpretability and reliability. We\nevaluated three convolutional neural network architectures: (1) a UNet with\nresidual encoder blocks, reflecting commonly used baselines in vascular\nlabeling; (2) CS-Net, an attention-augmented UNet incorporating channel and\nspatial attention mechanisms for enhanced curvilinear structure recognition;\nand (3) nnUNet, a self-configuring framework that automates preprocessing,\ntraining, and architectural adaptation based on dataset characteristics. Among\nthese, nnUNet achieved the highest labeling performance (average Dice score:\n0.922; average surface distance: 0.387 mm), with improved robustness in\nanatomically complex vessels. To assess predictive confidence, we implemented\ntest-time augmentation (TTA) and introduced a novel coordinate-guided strategy\nto reduce interpolation errors during augmented inference. The resulting\nuncertainty maps reliably indicated regions of anatomical ambiguity,\npathological variation, or manual labeling inconsistency. We further validated\nclinical utility by comparing flow velocities derived from automated and manual\nlabels in co-registered 4D Flow MRI datasets, observing close agreement with no\nstatistically significant differences. Our framework offers a scalable,\naccurate, and uncertainty-aware solution for automated cerebrovascular\nlabeling, supporting downstream hemodynamic analysis and facilitating clinical\nintegration.", "published": "2025-09-22 12:57:21", "link": "http://arxiv.org/abs/2509.17726v1", "categories": ["cs.CV", "cs.LG", "I.4.0"], "primary_category": "cs.CV"}
{"title": "RCTDistill: Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion", "abstract": "Radar-camera fusion methods have emerged as a cost-effective approach for 3D\nobject detection but still lag behind LiDAR-based methods in performance.\nRecent works have focused on employing temporal fusion and Knowledge\nDistillation (KD) strategies to overcome these limitations. However, existing\napproaches have not sufficiently accounted for uncertainties arising from\nobject motion or sensor-specific errors inherent in radar and camera\nmodalities. In this work, we propose RCTDistill, a novel cross-modal KD method\nbased on temporal fusion, comprising three key modules: Range-Azimuth Knowledge\nDistillation (RAKD), Temporal Knowledge Distillation (TKD), and\nRegion-Decoupled Knowledge Distillation (RDKD). RAKD is designed to consider\nthe inherent errors in the range and azimuth directions, enabling effective\nknowledge transfer from LiDAR features to refine inaccurate BEV\nrepresentations. TKD mitigates temporal misalignment caused by dynamic objects\nby aligning historical radar-camera BEV features with current LiDAR\nrepresentations. RDKD enhances feature discrimination by distilling relational\nknowledge from the teacher model, allowing the student to differentiate\nforeground and background features. RCTDistill achieves state-of-the-art\nradar-camera fusion performance on both the nuScenes and View-of-Delft (VoD)\ndatasets, with the fastest inference speed of 26.2 FPS.", "published": "2025-09-22 12:49:49", "link": "http://arxiv.org/abs/2509.17712v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automatic Intermodal Loading Unit Identification using Computer Vision: A Scoping Review", "abstract": "The standardisation of Intermodal Loading Units (ILUs), such as containers,\nsemi-trailers and swap bodies, has revolutionised global trade yet their\nefficient and robust identification remains a critical bottleneck in\nhigh-throughput ports and terminals. This paper reviews 63 empirical studies\nthat propose computer vision (CV) based solutions. It covers the last 35 years\n(1990-2025), tracing the field's evolution from early digital image processing\n(DIP) and traditional machine learning (ML) to the current dominance of deep\nlearning (DL) techniques. While CV offers cost-effective alternatives for other\ntypes of identification techniques, its development is hindered by the lack of\npublicly available benchmarking datasets. This results in high variance for the\nreported results such as end-to-end accuracy ranging from 5 % to 96 %. Beyond\ndataset limitations, this review highlights the emerging challenges especially\nintroduced by the shift from character-based text recognition to scene-text\nspotting and the integration of mobile cameras (e.g. drones, sensor equipped\nground vehicles) for dynamic terminal monitoring. To advance the field, the\npaper calls for standardised terminology, open-access datasets, shared source\ncode, while outlining future research directions such as contextless text\nrecognition optimised for ISO6346 codes.", "published": "2025-09-22 12:45:35", "link": "http://arxiv.org/abs/2509.17707v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neurodynamics-Driven Coupled Neural P Systems for Multi-Focus Image Fusion", "abstract": "Multi-focus image fusion (MFIF) is a crucial technique in image processing,\nwith a key challenge being the generation of decision maps with precise\nboundaries. However, traditional methods based on heuristic rules and deep\nlearning methods with black-box mechanisms are difficult to generate\nhigh-quality decision maps. To overcome this challenge, we introduce\nneurodynamics-driven coupled neural P (CNP) systems, which are third-generation\nneural computation models inspired by spiking mechanisms, to enhance the\naccuracy of decision maps. Specifically, we first conduct an in-depth analysis\nof the model's neurodynamics to identify the constraints between the network\nparameters and the input signals. This solid analysis avoids abnormal\ncontinuous firing of neurons and ensures the model accurately distinguishes\nbetween focused and unfocused regions, generating high-quality decision maps\nfor MFIF. Based on this analysis, we propose a\n\\textbf{N}eurodynamics-\\textbf{D}riven \\textbf{CNP} \\textbf{F}usion model\n(\\textbf{ND-CNPFuse}) tailored for the challenging MFIF task. Unlike current\nideas of decision map generation, ND-CNPFuse distinguishes between focused and\nunfocused regions by mapping the source image into interpretable spike\nmatrices. By comparing the number of spikes, an accurate decision map can be\ngenerated directly without any post-processing. Extensive experimental results\nshow that ND-CNPFuse achieves new state-of-the-art performance on four\nclassical MFIF datasets, including Lytro, MFFW, MFI-WHU, and Real-MFF. The code\nis available at https://github.com/MorvanLi/ND-CNPFuse.", "published": "2025-09-22 12:43:19", "link": "http://arxiv.org/abs/2509.17704v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Depth Edge Alignment Loss: DEALing with Depth in Weakly Supervised Semantic Segmentation", "abstract": "Autonomous robotic systems applied to new domains require an abundance of\nexpensive, pixel-level dense labels to train robust semantic segmentation\nmodels under full supervision. This study proposes a model-agnostic Depth Edge\nAlignment Loss to improve Weakly Supervised Semantic Segmentation models across\ndifferent datasets. The methodology generates pixel-level semantic labels from\nimage-level supervision, avoiding expensive annotation processes. While weak\nsupervision is widely explored in traditional computer vision, our approach\nadds supervision with pixel-level depth information, a modality commonly\navailable in robotic systems. We demonstrate how our approach improves\nsegmentation performance across datasets and models, but can also be combined\nwith other losses for even better performance, with improvements up to +5.439,\n+1.274 and +16.416 points in mean Intersection over Union on the PASCAL VOC /\nMS COCO validation, and the HOPE static onboarding split, respectively. Our\ncode will be made publicly available.", "published": "2025-09-22 12:42:10", "link": "http://arxiv.org/abs/2509.17702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FROQ: Observing Face Recognition Models for Efficient Quality Assessment", "abstract": "Face Recognition (FR) plays a crucial role in many critical (high-stakes)\napplications, where errors in the recognition process can lead to serious\nconsequences. Face Image Quality Assessment (FIQA) techniques enhance FR\nsystems by providing quality estimates of face samples, enabling the systems to\ndiscard samples that are unsuitable for reliable recognition or lead to\nlow-confidence recognition decisions. Most state-of-the-art FIQA techniques\nrely on extensive supervised training to achieve accurate quality estimation.\nIn contrast, unsupervised techniques eliminate the need for additional training\nbut tend to be slower and typically exhibit lower performance. In this paper,\nwe introduce FROQ (Face Recognition Observer of Quality), a semi-supervised,\ntraining-free approach that leverages specific intermediate representations\nwithin a given FR model to estimate face-image quality, and combines the\nefficiency of supervised FIQA models with the training-free approach of\nunsupervised methods. A simple calibration step based on pseudo-quality labels\nallows FROQ to uncover specific representations, useful for quality assessment,\nin any modern FR model. To generate these pseudo-labels, we propose a novel\nunsupervised FIQA technique based on sample perturbations. Comprehensive\nexperiments with four state-of-the-art FR models and eight benchmark datasets\nshow that FROQ leads to highly competitive results compared to the\nstate-of-the-art, achieving both strong performance and efficient runtime,\nwithout requiring explicit training.", "published": "2025-09-22 12:29:44", "link": "http://arxiv.org/abs/2509.17689v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning", "abstract": "This paper evaluates DINOv3, a recent large-scale self-supervised vision\nbackbone, for visuomotor diffusion policy learning in robotic manipulation. We\ninvestigate whether a purely self-supervised encoder can match or surpass\nconventional supervised ImageNet-pretrained backbones (e.g., ResNet-18) under\nthree regimes: training from scratch, frozen, and finetuned. Across four\nbenchmark tasks (Push-T, Lift, Can, Square) using a unified FiLM-conditioned\ndiffusion policy, we find that (i) finetuned DINOv3 matches or exceeds\nResNet-18 on several tasks, (ii) frozen DINOv3 remains competitive, indicating\nstrong transferable priors, and (iii) self-supervised features improve sample\nefficiency and robustness. These results support self-supervised large visual\nmodels as effective, generalizable perceptual front-ends for action diffusion\npolicies, motivating further exploration of scalable label-free pretraining in\nrobotic manipulation. Compared to using ResNet18 as a backbone, our approach\nwith DINOv3 achieves up to a 10% absolute increase in test-time success rates\non challenging tasks such as Can, and on-the-par performance in tasks like\nLift, PushT, and Square.", "published": "2025-09-22 12:27:26", "link": "http://arxiv.org/abs/2509.17684v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Tailored Transformation Invariance for Industrial Anomaly Detection", "abstract": "Industrial Anomaly Detection (IAD) is a subproblem within Computer Vision\nAnomaly Detection that has been receiving increasing amounts of attention due\nto its applicability to real-life scenarios. Recent research has focused on how\nto extract the most informative features, contrasting older kNN-based methods\nthat use only pretrained features. These recent methods are much more expensive\nto train however and could complicate real-life application. Careful study of\nrelated work with regards to transformation invariance leads to the idea that\npopular benchmarks require robustness to only minor translations. With this\nidea we then formulate LWinNN, a local window based approach that creates a\nmiddle ground between kNN based methods that have either complete or no\ntranslation invariance. Our experiments demonstrate that this small change\nincreases accuracy considerably, while simultaneously decreasing both train and\ntest time. This teaches us two things: first, the gap between kNN-based\napproaches and more complex state-of-the-art methodology can still be narrowed\nby effective usage of the limited data available. Second, our assumption of\nrequiring only limited translation invariance highlights potential areas of\ninterest for future work and the need for more spatially diverse benchmarks,\nfor which our method can hopefully serve as a new baseline. Our code can be\nfound at https://github.com/marietteschonfeld/LWinNN .", "published": "2025-09-22 12:13:58", "link": "http://arxiv.org/abs/2509.17670v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Development and validation of an AI foundation model for endoscopic diagnosis of esophagogastric junction adenocarcinoma: a cohort and deep learning study", "abstract": "The early detection of esophagogastric junction adenocarcinoma (EGJA) is\ncrucial for improving patient prognosis, yet its current diagnosis is highly\noperator-dependent. This paper aims to make the first attempt to develop an\nartificial intelligence (AI) foundation model-based method for both screening\nand staging diagnosis of EGJA using endoscopic images. In this cohort and\nlearning study, we conducted a multicentre study across seven Chinese hospitals\nbetween December 28, 2016 and December 30, 2024. It comprises 12,302 images\nfrom 1,546 patients; 8,249 of them were employed for model training, while the\nremaining were divided into the held-out (112 patients, 914 images), external\n(230 patients, 1,539 images), and prospective (198 patients, 1,600 images) test\nsets for evaluation. The proposed model employs DINOv2 (a vision foundation\nmodel) and ResNet50 (a convolutional neural network) to extract features of\nglobal appearance and local details of endoscopic images for EGJA staging\ndiagnosis. Our model demonstrates satisfactory performance for EGJA staging\ndiagnosis across three test sets, achieving an accuracy of 0.9256, 0.8895, and\n0.8956, respectively. In contrast, among representative AI models, the best one\n(ResNet50) achieves an accuracy of 0.9125, 0.8382, and 0.8519 on the three test\nsets, respectively; the expert endoscopists achieve an accuracy of 0.8147 on\nthe held-out test set. Moreover, with the assistance of our model, the overall\naccuracy for the trainee, competent, and expert endoscopists improves from\n0.7035, 0.7350, and 0.8147 to 0.8497, 0.8521, and 0.8696, respectively. To our\nknowledge, our model is the first application of foundation models for EGJA\nstaging diagnosis and demonstrates great potential in both diagnostic accuracy\nand efficiency.", "published": "2025-09-22 12:03:40", "link": "http://arxiv.org/abs/2509.17660v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clothing agnostic Pre-inpainting Virtual Try-ON", "abstract": "With the development of deep learning technology, virtual try-on technology\nhas become an important application value in the fields of e-commerce, fashion,\nand entertainment. The recently proposed Leffa has improved the texture\ndistortion problem of diffu-sion-based models, but there are limitations in\nthat the bottom detection inaccuracy and the existing clothing silhouette\nremain in the synthesis results. To solve this problem, this study proposes\nCaP-VTON (Clothing agnostic Pre-inpainting Virtual Try-ON). CaP-VTON has\nimproved the naturalness and consistency of whole-body clothing syn-thesis by\nintegrating multi-category masking based on Dress Code and skin inpainting\nbased on Stable Diffusion. In particular, a generate skin module was introduced\nto solve the skin restoration problem that occurs when long-sleeved images are\nconverted into short-sleeved or sleeveless ones, and high-quality restoration\nwas implemented consider-ing the human body posture and color. As a result,\nCaP-VTON recorded 92.5\\%, which is 15.4\\% better than Leffa in short-sleeved\nsynthesis accuracy, and showed the performance of consistently reproducing the\nstyle and shape of reference clothing in visual evaluation. These structures\nmaintain model-agnostic properties and are applicable to various\ndiffu-sion-based virtual inspection systems, and can contribute to applications\nthat require high-precision virtual wearing, such as e-commerce, custom\nstyling, and avatar creation.", "published": "2025-09-22 11:58:20", "link": "http://arxiv.org/abs/2509.17654v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SISMA: Semantic Face Image Synthesis with Mamba", "abstract": "Diffusion Models have become very popular for Semantic Image Synthesis (SIS)\nof human faces. Nevertheless, their training and inference is computationally\nexpensive and their computational requirements are high due to the quadratic\ncomplexity of attention layers. In this paper, we propose a novel architecture\ncalled SISMA, based on the recently proposed Mamba. SISMA generates high\nquality samples by controlling their shape using a semantic mask at a reduced\ncomputational demand. We validated our approach through comprehensive\nexperiments with CelebAMask-HQ, revealing that our architecture not only\nachieves a better FID score yet also operates at three times the speed of\nstate-of-the-art architectures. This indicates that the proposed design is a\nviable, lightweight substitute to transformer-based models.", "published": "2025-09-22 11:55:04", "link": "http://arxiv.org/abs/2509.17651v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evict3R: Training-Free Token Eviction for Memory-Bounded Streaming Visual Geometry Transformers", "abstract": "Streaming visual transformers like StreamVGGT achieve strong 3D perception\nbut suffer from unbounded growth of key value (KV) memory, which limits\nscalability. We propose a training-free, inference-time token eviction policy\nthat bounds memory by discarding redundant tokens while keeping the most\ninformative ones. Our method uses significantly less memory with little to no\ndrop in accuracy: on 7-Scenes with long sequences it reduces peak memory from\n18.63 GB to 9.39 GB while accuracy and completeness drop by only 0.003. Under\nstrict memory budgets, eviction enables denser frame sampling, which improves\nreconstruction accuracy compared to the baseline. Experiments across video\ndepth estimation (Sintel, KITTI), 3D reconstruction (7-Scenes, NRGBD), and\ncamera pose estimation (Sintel, TUM-dynamics) show that our approach closely\nmatches StreamVGGT at a fraction of the memory and makes long-horizon streaming\ninference more practical.", "published": "2025-09-22 11:54:58", "link": "http://arxiv.org/abs/2509.17650v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overview of PlantCLEF 2022: Image-based plant identification at global scale", "abstract": "It is estimated that there are more than 300,000 species of vascular plants\nin the world. Increasing our knowledge of these species is of paramount\nimportance for the development of human civilization (agriculture,\nconstruction, pharmacopoeia, etc.), especially in the context of the\nbiodiversity crisis. However, the burden of systematic plant identification by\nhuman experts strongly penalizes the aggregation of new data and knowledge.\nSince then, automatic identification has made considerable progress in recent\nyears as highlighted during all previous editions of PlantCLEF. Deep learning\ntechniques now seem mature enough to address the ultimate but realistic problem\nof global identification of plant biodiversity in spite of many problems that\nthe data may present (a huge number of classes, very strongly unbalanced\nclasses, partially erroneous identifications, duplications, variable visual\nquality, diversity of visual contents such as photos or herbarium sheets, etc).\nThe PlantCLEF2022 challenge edition proposes to take a step in this direction\nby tackling a multi-image (and metadata) classification problem with a very\nlarge number of classes (80k plant species). This paper presents the resources\nand evaluations of the challenge, summarizes the approaches and systems\nemployed by the participating research groups, and provides an analysis of key\nfindings.", "published": "2025-09-22 11:40:21", "link": "http://arxiv.org/abs/2509.17632v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models", "abstract": "Recent advances in video insertion based on diffusion models are impressive.\nHowever, existing methods rely on complex control signals but struggle with\nsubject consistency, limiting their practical applicability. In this paper, we\nfocus on the task of Mask-free Video Insertion and aim to resolve three key\nchallenges: data scarcity, subject-scene equilibrium, and insertion\nharmonization. To address the data scarcity, we propose a new data pipeline\nInsertPipe, constructing diverse cross-pair data automatically. Building upon\nour data pipeline, we develop OmniInsert, a novel unified framework for\nmask-free video insertion from both single and multiple subject references.\nSpecifically, to maintain subject-scene equilibrium, we introduce a simple yet\neffective Condition-Specific Feature Injection mechanism to distinctly inject\nmulti-source conditions and propose a novel Progressive Training strategy that\nenables the model to balance feature injection from subjects and source video.\nMeanwhile, we design the Subject-Focused Loss to improve the detailed\nappearance of the subjects. To further enhance insertion harmonization, we\npropose an Insertive Preference Optimization methodology to optimize the model\nby simulating human preferences, and incorporate a Context-Aware Rephraser\nmodule during reference to seamlessly integrate the subject into the original\nscenes. To address the lack of a benchmark for the field, we introduce\nInsertBench, a comprehensive benchmark comprising diverse scenes with\nmeticulously selected subjects. Evaluation on InsertBench indicates OmniInsert\noutperforms state-of-the-art closed-source commercial solutions. The code will\nbe released.", "published": "2025-09-22 11:35:55", "link": "http://arxiv.org/abs/2509.17627v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overview of PlantCLEF 2023: Image-based Plant Identification at Global Scale", "abstract": "The world is estimated to be home to over 300,000 species of vascular plants.\nIn the face of the ongoing biodiversity crisis, expanding our understanding of\nthese species is crucial for the advancement of human civilization,\nencompassing areas such as agriculture, construction, and pharmacopoeia.\nHowever, the labor-intensive process of plant identification undertaken by\nhuman experts poses a significant obstacle to the accumulation of new data and\nknowledge. Fortunately, recent advancements in automatic identification,\nparticularly through the application of deep learning techniques, have shown\npromising progress. Despite challenges posed by data-related issues such as a\nvast number of classes, imbalanced class distribution, erroneous\nidentifications, duplications, variable visual quality, and diverse visual\ncontents (such as photos or herbarium sheets), deep learning approaches have\nreached a level of maturity which gives us hope that in the near future we will\nhave an identification system capable of accurately identifying all plant\nspecies worldwide. The PlantCLEF2023 challenge aims to contribute to this\npursuit by addressing a multi-image (and metadata) classification problem\ninvolving an extensive set of classes (80,000 plant species). This paper\nprovides an overview of the challenge's resources and evaluations, summarizes\nthe methods and systems employed by participating research groups, and presents\nan analysis of key findings.", "published": "2025-09-22 11:34:10", "link": "http://arxiv.org/abs/2509.17622v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Tensor-Based Self-Calibration of Cameras via the TrifocalCalib Method", "abstract": "Estimating camera intrinsic parameters without prior scene knowledge is a\nfundamental challenge in computer vision. This capability is particularly\nimportant for applications such as autonomous driving and vehicle platooning,\nwhere precalibrated setups are impractical and real-time adaptability is\nnecessary. To advance the state-of-the-art, we present a set of equations based\non the calibrated trifocal tensor, enabling projective camera self-calibration\nfrom minimal image data. Our method, termed TrifocalCalib, significantly\nimproves accuracy and robustness compared to both recent learning-based and\nclassical approaches. Unlike many existing techniques, our approach requires no\ncalibration target, imposes no constraints on camera motion, and simultaneously\nestimates both focal length and principal point. Evaluations in both\nprocedurally generated synthetic environments and structured dataset-based\nscenarios demonstrate the effectiveness of our approach. To support\nreproducibility, we make the code publicly available.", "published": "2025-09-22 11:31:57", "link": "http://arxiv.org/abs/2509.17620v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge", "abstract": "Visual anomaly detection is a strongly application-driven field of research.\nConsequently, the connection between academia and industry is of paramount\nimportance. In this regard, we present the VAND 3.0 Challenge to showcase\ncurrent progress in anomaly detection across different practical settings\nwhilst addressing critical issues in the field. The challenge hosted two\ntracks, fostering the development of anomaly detection methods robust against\nreal-world distribution shifts (Category 1) and exploring the capabilities of\nVision Language Models within the few-shot regime (Category 2), respectively.\nThe participants' solutions reached significant improvements over previous\nbaselines by combining or adapting existing approaches and fusing them with\nnovel pipelines. While for both tracks the progress in large pre-trained vision\n(language) backbones played a pivotal role for the performance increase,\nscaling up anomaly detection methods more efficiently needs to be addressed by\nfuture research to meet real-time and computational constraints on-site.", "published": "2025-09-22 11:27:49", "link": "http://arxiv.org/abs/2509.17615v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overview of PlantCLEF 2025: Multi-Species Plant Identification in Vegetation Quadrat Images", "abstract": "Quadrat images are essential for ecological studies, as they enable\nstandardized sampling, the assessment of plant biodiversity, long-term\nmonitoring, and large-scale field campaigns. These images typically cover an\narea of fifty centimetres or one square meter, and botanists carefully identify\nall the species present. Integrating AI could help specialists accelerate their\ninventories and expand the spatial coverage of ecological studies. To assess\nprogress in this area, the PlantCLEF 2025 challenge relies on a new test set of\n2,105 high-resolution multi-label images annotated by experts and covering\naround 400 species. It also provides a large training set of 1.4 million\nindividual plant images, along with vision transformer models pre-trained on\nthis data. The task is formulated as a (weakly labelled) multi-label\nclassification problem, where the goal is to predict all species present in a\nquadrat image using single-label training data. This paper provides a detailed\ndescription of the data, the evaluation methodology, the methods and models\nused by participants, and the results achieved.", "published": "2025-09-22 11:21:53", "link": "http://arxiv.org/abs/2509.17602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "COLA: Context-aware Language-driven Test-time Adaptation", "abstract": "Test-time adaptation (TTA) has gained increasing popularity due to its\nefficacy in addressing ``distribution shift'' issue while simultaneously\nprotecting data privacy.\n  However, most prior methods assume that a paired source domain model and\ntarget domain sharing the same label space coexist, heavily limiting their\napplicability.\n  In this paper, we investigate a more general source model capable of\nadaptation to multiple target domains without needing shared labels.\n  This is achieved by using a pre-trained vision-language model (VLM), \\egno,\nCLIP, that can recognize images through matching with class descriptions.\n  While the zero-shot performance of VLMs is impressive, they struggle to\neffectively capture the distinctive attributes of a target domain.\n  To that end, we propose a novel method -- Context-aware Language-driven TTA\n(COLA).\n  The proposed method incorporates a lightweight context-aware module that\nconsists of three key components: a task-aware adapter, a context-aware unit,\nand a residual connection unit for exploring task-specific knowledge,\ndomain-specific knowledge from the VLM and prior knowledge of the VLM,\nrespectively.\n  It is worth noting that the context-aware module can be seamlessly integrated\ninto a frozen VLM, ensuring both minimal effort and parameter efficiency.\n  Additionally, we introduce a Class-Balanced Pseudo-labeling (CBPL) strategy\nto mitigate the adverse effects caused by class imbalance.\n  We demonstrate the effectiveness of our method not only in TTA scenarios but\nalso in class generalisation tasks.\n  The source code is available at https://github.com/NUDT-Bai-Group/COLA-TTA.", "published": "2025-09-22 11:19:17", "link": "http://arxiv.org/abs/2509.17598v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Domain Adaptive Object Detection for Space Applications with Real-Time Constraints", "abstract": "Object detection is essential in space applications targeting Space Domain\nAwareness and also applications involving relative navigation scenarios.\nCurrent deep learning models for Object Detection in space applications are\noften trained on synthetic data from simulators, however, the model performance\ndrops significantly on real-world data due to the domain gap. However, domain\nadaptive object detection is an overlooked problem in the community. In this\nwork, we first show the importance of domain adaptation and then explore\nSupervised Domain Adaptation (SDA) to reduce this gap using minimal labeled\nreal data. We build on a recent semi-supervised adaptation method and tailor it\nfor object detection. Our approach combines domain-invariant feature learning\nwith a CNN-based domain discriminator and invariant risk minimization using a\ndomain-independent regression head. To meet real-time deployment needs, we test\nour method on a lightweight Single Shot Multibox Detector (SSD) with MobileNet\nbackbone and on the more advanced Fully Convolutional One-Stage object detector\n(FCOS) with ResNet-50 backbone. We evaluated on two space datasets, SPEED+ and\nSPARK. The results show up to 20-point improvements in average precision (AP)\nwith just 250 labeled real images.", "published": "2025-09-22 11:17:14", "link": "http://arxiv.org/abs/2509.17593v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PRNU-Bench: A Novel Benchmark and Model for PRNU-Based Camera Identification", "abstract": "We propose a novel benchmark for camera identification via Photo Response\nNon-Uniformity (PRNU) estimation. The benchmark comprises 13K photos taken with\n120+ cameras, where the training and test photos are taken in different\nscenarios, enabling ``in-the-wild'' evaluation. In addition, we propose a novel\nPRNU-based camera identification model that employs a hybrid architecture,\ncomprising a denoising autoencoder to estimate the PRNU signal and a\nconvolutional network that can perform 1:N verification of camera devices.\nInstead of using a conventional approach based on contrastive learning, our\nmethod takes the Hadamard product between reference and query PRNU signals as\ninput. This novel design leads to significantly better results compared with\nstate-of-the-art models based on denoising autoencoders and contrastive\nlearning. We release our dataset and code at:\nhttps://github.com/CroitoruAlin/PRNU-Bench.", "published": "2025-09-22 11:07:15", "link": "http://arxiv.org/abs/2509.17581v1", "categories": ["cs.CV", "cs.CR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Visual Instruction Pretraining for Domain-Specific Foundation Models", "abstract": "Modern computer vision is converging on a closed loop in which perception,\nreasoning and generation mutually reinforce each other. However, this loop\nremains incomplete: the top-down influence of high-level reasoning on the\nfoundational learning of low-level perceptual features is not yet\nunderexplored. This paper addresses this gap by proposing a new paradigm for\npretraining foundation models in downstream domains. We introduce Visual\ninsTruction Pretraining (ViTP), a novel approach that directly leverages\nreasoning to enhance perception. ViTP embeds a Vision Transformer (ViT)\nbackbone within a Vision-Language Model and pretrains it end-to-end using a\nrich corpus of visual instruction data curated from target downstream domains.\nViTP is powered by our proposed Visual Robustness Learning (VRL), which compels\nthe ViT to learn robust and domain-relevant features from a sparse set of\nvisual tokens. Extensive experiments on 16 challenging remote sensing and\nmedical imaging benchmarks demonstrate that ViTP establishes new\nstate-of-the-art performance across a diverse range of downstream tasks. The\ncode is available at github.com/zcablii/ViTP.", "published": "2025-09-22 10:57:42", "link": "http://arxiv.org/abs/2509.17562v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SimToken: A Simple Baseline for Referring Audio-Visual Segmentation", "abstract": "Referring Audio-Visual Segmentation (Ref-AVS) aims to segment specific\nobjects in videos based on natural language expressions involving audio,\nvision, and text information. This task poses significant challenges in\ncross-modal reasoning and fine-grained object localization. In this paper, we\npropose a simple framework, SimToken, that integrates a multimodal large\nlanguage model (MLLM) with the Segment Anything Model (SAM). The MLLM is guided\nto generate a special semantic token representing the referred object. This\ncompact token, enriched with contextual information from all modalities, acts\nas a prompt to guide SAM to segment objectsacross video frames. To further\nimprove semantic learning, we introduce a novel target-consistent semantic\nalignment loss that aligns token embeddings from different expressions but\nreferring to the same object. Experiments on the Ref-AVS benchmark demonstrate\nthat our approach achieves superior performance compared to existing\nmethods.Code will be available at https://github.com/DianJin-HFUT/SimToken", "published": "2025-09-22 08:55:04", "link": "http://arxiv.org/abs/2509.17537v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Chat-CBM: Towards Interactive Concept Bottleneck Models with Frozen Large Language Models", "abstract": "Concept Bottleneck Models (CBMs) provide inherent interpretability by first\npredicting a set of human-understandable concepts and then mapping them to\nlabels through a simple classifier. While users can intervene in the concept\nspace to improve predictions, traditional CBMs typically employ a fixed linear\nclassifier over concept scores, which restricts interventions to manual value\nadjustments and prevents the incorporation of new concepts or domain knowledge\nat test time. These limitations are particularly severe in unsupervised CBMs,\nwhere concept activations are often noisy and densely activated, making user\ninterventions ineffective. We introduce Chat-CBM, which replaces score-based\nclassifiers with a language-based classifier that reasons directly over concept\nsemantics. By grounding prediction in the semantic space of concepts, Chat-CBM\npreserves the interpretability of CBMs while enabling richer and more intuitive\ninterventions, such as concept correction, addition or removal of concepts,\nincorporation of external knowledge, and high-level reasoning guidance.\nLeveraging the language understanding and few-shot capabilities of frozen large\nlanguage models, Chat-CBM extends the intervention interface of CBMs beyond\nnumerical editing and remains effective even in unsupervised settings.\nExperiments on nine datasets demonstrate that Chat-CBM achieves higher\npredictive performance and substantially improves user interactivity while\nmaintaining the concept-based interpretability of CBMs.", "published": "2025-09-22 08:48:04", "link": "http://arxiv.org/abs/2509.17522v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unified Multimodal Coherent Field: Synchronous Semantic-Spatial-Vision Fusion for Brain Tumor Segmentation", "abstract": "Brain tumor segmentation requires accurate identification of hierarchical\nregions including whole tumor (WT), tumor core (TC), and enhancing tumor (ET)\nfrom multi-sequence magnetic resonance imaging (MRI) images. Due to tumor\ntissue heterogeneity, ambiguous boundaries, and contrast variations across MRI\nsequences, methods relying solely on visual information or post-hoc loss\nconstraints show unstable performance in boundary delineation and hierarchy\npreservation. To address this challenge, we propose the Unified Multimodal\nCoherent Field (UMCF) method. This method achieves synchronous interactive\nfusion of visual, semantic, and spatial information within a unified 3D latent\nspace, adaptively adjusting modal contributions through parameter-free\nuncertainty gating, with medical prior knowledge directly participating in\nattention computation, avoiding the traditional \"process-then-concatenate\"\nseparated architecture. On Brain Tumor Segmentation (BraTS) 2020 and 2021\ndatasets, UMCF+nnU-Net achieves average Dice coefficients of 0.8579 and 0.8977\nrespectively, with an average 4.18% improvement across mainstream\narchitectures. By deeply integrating clinical knowledge with imaging features,\nUMCF provides a new technical pathway for multimodal information fusion in\nprecision medicine.", "published": "2025-09-22 08:45:39", "link": "http://arxiv.org/abs/2509.17520v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming", "abstract": "Achieving seamless viewing of high-fidelity volumetric video, comparable to\n2D video experiences, remains an open challenge. Existing volumetric video\ncompression methods either lack the flexibility to adjust quality and bitrate\nwithin a single model for efficient streaming across diverse networks and\ndevices, or struggle with real-time decoding and rendering on lightweight\nmobile platforms. To address these challenges, we introduce 4DGCPro, a novel\nhierarchical 4D Gaussian compression framework that facilitates real-time\nmobile decoding and high-quality rendering via progressive volumetric video\nstreaming in a single bitstream. Specifically, we propose a\nperceptually-weighted and compression-friendly hierarchical 4D Gaussian\nrepresentation with motion-aware adaptive grouping to reduce temporal\nredundancy, preserve coherence, and enable scalable multi-level detail\nstreaming. Furthermore, we present an end-to-end entropy-optimized training\nscheme, which incorporates layer-wise rate-distortion (RD) supervision and\nattribute-specific entropy modeling for efficient bitstream generation.\nExtensive experiments show that 4DGCPro enables flexible quality and multiple\nbitrate within a single model, achieving real-time decoding and rendering on\nmobile devices while outperforming existing methods in RD performance across\nmultiple datasets. Project Page: https://mediax-sjtu.github.io/4DGCPro", "published": "2025-09-22 08:38:17", "link": "http://arxiv.org/abs/2509.17513v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4D-MoDe: Towards Editable and Scalable Volumetric Streaming via Motion-Decoupled 4D Gaussian Compression", "abstract": "Volumetric video has emerged as a key medium for immersive telepresence and\naugmented/virtual reality, enabling six-degrees-of-freedom (6DoF) navigation\nand realistic spatial interactions. However, delivering high-quality dynamic\nvolumetric content at scale remains challenging due to massive data volume,\ncomplex motion, and limited editability of existing representations. In this\npaper, we present 4D-MoDe, a motion-decoupled 4D Gaussian compression framework\ndesigned for scalable and editable volumetric video streaming. Our method\nintroduces a layered representation that explicitly separates static\nbackgrounds from dynamic foregrounds using a lookahead-based motion\ndecomposition strategy, significantly reducing temporal redundancy and enabling\nselective background/foreground streaming. To capture continuous motion\ntrajectories, we employ a multi-resolution motion estimation grid and a\nlightweight shared MLP, complemented by a dynamic Gaussian compensation\nmechanism to model emergent content. An adaptive grouping scheme dynamically\ninserts background keyframes to balance temporal consistency and compression\nefficiency. Furthermore, an entropy-aware training pipeline jointly optimizes\nthe motion fields and Gaussian parameters under a rate-distortion (RD)\nobjective, while employing range-based and KD-tree compression to minimize\nstorage overhead. Extensive experiments on multiple datasets demonstrate that\n4D-MoDe consistently achieves competitive reconstruction quality with an order\nof magnitude lower storage cost (e.g., as low as \\textbf{11.4} KB/frame)\ncompared to state-of-the-art methods, while supporting practical applications\nsuch as background replacement and foreground-only streaming.", "published": "2025-09-22 08:35:46", "link": "http://arxiv.org/abs/2509.17506v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAMSON: 3rd Place Solution of LSVOS 2025 VOS Challenge", "abstract": "Large-scale Video Object Segmentation (LSVOS) addresses the challenge of\naccurately tracking and segmenting objects in long video sequences, where\ndifficulties stem from object reappearance, small-scale targets, heavy\nocclusions, and crowded scenes. Existing approaches predominantly adopt\nSAM2-based frameworks with various memory mechanisms for complex video mask\ngeneration. In this report, we proposed Segment Anything with Memory\nStrengthened Object Navigation (SAMSON), the 3rd place solution in the MOSE\ntrack of ICCV 2025, which integrates the strengths of stateof-the-art VOS\nmodels into an effective paradigm. To handle visually similar instances and\nlong-term object disappearance in MOSE, we incorporate a long-term memorymodule\nfor reliable object re-identification. Additionly, we adopt SAM2Long as a\npost-processing strategy to reduce error accumulation and enhance segmentation\nstability in long video sequences. Our method achieved a final performance of\n0.8427 in terms of J &F in the test-set leaderboard.", "published": "2025-09-22 08:30:34", "link": "http://arxiv.org/abs/2509.17500v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision-Based Driver Drowsiness Monitoring: Comparative Analysis of YOLOv5-v11 Models", "abstract": "Driver drowsiness remains a critical factor in road accidents, accounting for\nthousands of fatalities and injuries each year. This paper presents a\ncomprehensive evaluation of real-time, non-intrusive drowsiness detection\nmethods, focusing on computer vision based YOLO (You Look Only Once)\nalgorithms. A publicly available dataset namely, UTA-RLDD was used, containing\nboth awake and drowsy conditions, ensuring variability in gender, eyewear,\nillumination, and skin tone. Seven YOLO variants (v5s, v9c, v9t, v10n, v10l,\nv11n, v11l) are fine-tuned, with performance measured in terms of Precision,\nRecall, mAP0.5, and mAP 0.5-0.95. Among these, YOLOv9c achieved the highest\naccuracy (0.986 mAP 0.5, 0.978 Recall) while YOLOv11n strikes the optimal\nbalance between precision (0.954) and inference efficiency, making it highly\nsuitable for embedded deployment. Additionally, we implement an Eye Aspect\nRatio (EAR) approach using Dlib's facial landmarks, which despite its low\ncomputational footprint exhibits reduced robustness under pose variation and\nocclusions. Our findings illustrate clear trade offs between accuracy, latency,\nand resource requirements, and offer practical guidelines for selecting or\ncombining detection methods in autonomous driving and industrial safety\napplications.", "published": "2025-09-22 08:30:02", "link": "http://arxiv.org/abs/2509.17498v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Stable Video-Driven Portraits", "abstract": "Portrait animation aims to generate photo-realistic videos from a single\nsource image by reenacting the expression and pose from a driving video. While\nearly methods relied on 3D morphable models or feature warping techniques, they\noften suffered from limited expressivity, temporal inconsistency, and poor\ngeneralization to unseen identities or large pose variations. Recent advances\nusing diffusion models have demonstrated improved quality but remain\nconstrained by weak control signals and architectural limitations. In this\nwork, we propose a novel diffusion based framework that leverages masked facial\nregions specifically the eyes, nose, and mouth from the driving video as strong\nmotion control cues. To enable robust training without appearance leakage, we\nadopt cross identity supervision. To leverage the strong prior from the\npretrained diffusion model, our novel architecture introduces minimal new\nparameters that converge faster and help in better generalization. We introduce\nspatial temporal attention mechanisms that allow inter frame and intra frame\ninteractions, effectively capturing subtle motions and reducing temporal\nartifacts. Our model uses history frames to ensure continuity across segments.\nAt inference, we propose a novel signal fusion strategy that balances motion\nfidelity with identity preservation. Our approach achieves superior temporal\nconsistency and accurate expression control, enabling high-quality,\ncontrollable portrait animation suitable for real-world applications.", "published": "2025-09-22 08:11:08", "link": "http://arxiv.org/abs/2509.17476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception", "abstract": "The goal of multi-task learning is to learn to conduct multiple tasks\nsimultaneously based on a shared data representation. While this approach can\nimprove learning efficiency, it may also cause performance degradation due to\ntask conflicts that arise when optimizing the model for different objectives.\nTo address this challenge, we introduce MAESTRO, a structured framework\ndesigned to generate task-specific features and mitigate feature interference\nin multi-task 3D perception, including 3D object detection, bird's-eye view\n(BEV) map segmentation, and 3D occupancy prediction. MAESTRO comprises three\ncomponents: the Class-wise Prototype Generator (CPG), the Task-Specific Feature\nGenerator (TSFG), and the Scene Prototype Aggregator (SPA). CPG groups class\ncategories into foreground and background groups and generates group-wise\nprototypes. The foreground and background prototypes are assigned to the 3D\nobject detection task and the map segmentation task, respectively, while both\nare assigned to the 3D occupancy prediction task. TSFG leverages these\nprototype groups to retain task-relevant features while suppressing irrelevant\nfeatures, thereby enhancing the performance for each task. SPA enhances the\nprototype groups assigned for 3D occupancy prediction by utilizing the\ninformation produced by the 3D object detection head and the map segmentation\nhead. Extensive experiments on the nuScenes and Occ3D benchmarks demonstrate\nthat MAESTRO consistently outperforms existing methods across 3D object\ndetection, BEV map segmentation, and 3D occupancy prediction tasks.", "published": "2025-09-22 07:55:43", "link": "http://arxiv.org/abs/2509.17462v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CSDformer: A Conversion Method for Fully Spike-Driven Transformer", "abstract": "Spike-based transformer is a novel architecture aiming to enhance the\nperformance of spiking neural networks while mitigating the energy overhead\ninherent to transformers. However, methods for generating these models suffer\nfrom critical limitations: excessive training costs introduced by direct\ntraining methods, or unavoidably hardware-unfriendly operations in existing\nconversion methods. In this paper, we propose CSDformer, a novel conversion\nmethod for fully spike-driven transformers. We tailor a conversion-oriented\ntransformer-based architecture and propose a new function NReLU to replace\nsoftmax in self-attention. Subsequently, this model is quantized and trained,\nand converted into a fully spike-driven model with temporal decomposition\ntechnique. Also, we propose delayed Integrate-andFire neurons to reduce\nconversion errors and improve the performance of spiking models. We evaluate\nCSDformer on ImageNet, CIFAR-10 and CIFAR-100 datasets and achieve 76.36% top-1\naccuracy under 7 time-steps on ImageNet, demonstrating superiority over\nstate-of-the-art models. Furthermore, CSDformer eliminates the need for\ntraining SNNs, thereby reducing training costs (reducing computational resource\nby 75% and accelerating training speed by 2-3$\\times$). To the best of our\nknowledge, this is the first fully spike-driven transformer-based model\ndeveloped via conversion method, achieving high performance under ultra-low\nlatency, while dramatically reducing both computational complexity and training\noverhead.", "published": "2025-09-22 07:55:03", "link": "http://arxiv.org/abs/2509.17461v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration", "abstract": "Text-to-image diffusion models, such as Stable Diffusion, can produce\nhigh-quality and diverse images but often fail to achieve compositional\nalignment, particularly when prompts describe complex object relationships,\nattributes, or spatial arrangements. Recent inference-time approaches address\nthis by optimizing or exploring the initial noise under the guidance of reward\nfunctions that score text-image alignment without requiring model fine-tuning.\nWhile promising, each strategy has intrinsic limitations when used alone:\noptimization can stall due to poor initialization or unfavorable search\ntrajectories, whereas exploration may require a prohibitively large number of\nsamples to locate a satisfactory output. Our analysis further shows that\nneither single reward metrics nor ad-hoc combinations reliably capture all\naspects of compositionality, leading to weak or inconsistent guidance. To\novercome these challenges, we present Category-Aware Reward-based Initial Noise\nOptimization and Exploration (CARINOX), a unified framework that combines noise\noptimization and exploration with a principled reward selection procedure\ngrounded in correlation with human judgments. Evaluations on two complementary\nbenchmarks covering diverse compositional challenges show that CARINOX raises\naverage alignment scores by +16% on T2I-CompBench++ and +11% on the HRS\nbenchmark, consistently outperforming state-of-the-art optimization and\nexploration-based methods across all major categories, while preserving image\nquality and diversity. The project page is available at\nhttps://amirkasaei.com/carinox/{this URL}.", "published": "2025-09-22 07:51:28", "link": "http://arxiv.org/abs/2509.17458v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Emergent 3D Correspondence from Neural Shape Representation", "abstract": "This paper presents a new approach to estimate accurate and robust 3D\nsemantic correspondence with the hierarchical neural semantic representation.\nOur work has three key contributions. First, we design the hierarchical neural\nsemantic representation (HNSR), which consists of a global semantic feature to\ncapture high-level structure and multi-resolution local geometric features to\npreserve fine details, by carefully harnessing 3D priors from pre-trained 3D\ngenerative models. Second, we design a progressive global-to-local matching\nstrategy, which establishes coarse semantic correspondence using the global\nsemantic feature, then iteratively refines it with local geometric features,\nyielding accurate and semantically-consistent mappings. Third, our framework is\ntraining-free and broadly compatible with various pre-trained 3D generative\nbackbones, demonstrating strong generalization across diverse shape categories.\nOur method also supports various applications, such as shape co-segmentation,\nkeypoint matching, and texture transfer, and generalizes well to structurally\ndiverse shapes, with promising results even in cross-category scenarios. Both\nqualitative and quantitative evaluations show that our method outperforms\nprevious state-of-the-art techniques.", "published": "2025-09-22 07:23:07", "link": "http://arxiv.org/abs/2509.17431v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device", "abstract": "The field of Embodied AI predominantly relies on simulation for training and\nevaluation, often using either fully synthetic environments that lack\nphotorealism or high-fidelity real-world reconstructions captured with\nexpensive hardware. As a result, sim-to-real transfer remains a major\nchallenge. In this paper, we introduce EmbodiedSplat, a novel approach that\npersonalizes policy training by efficiently capturing the deployment\nenvironment and fine-tuning policies within the reconstructed scenes. Our\nmethod leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to\nbridge the gap between realistic scene capture and effective training\nenvironments. Using iPhone-captured deployment scenes, we reconstruct meshes\nvia GS, enabling training in settings that closely approximate real-world\nconditions. We conduct a comprehensive analysis of training strategies,\npre-training datasets, and mesh reconstruction techniques, evaluating their\nimpact on sim-to-real predictivity in real-world scenarios. Experimental\nresults demonstrate that agents fine-tuned with EmbodiedSplat outperform both\nzero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and\nsynthetically generated datasets (HSSD), achieving absolute success rate\nimprovements of 20\\% and 40\\% on real-world Image Navigation task. Moreover,\nour approach yields a high sim-vs-real correlation (0.87--0.97) for the\nreconstructed meshes, underscoring its effectiveness in adapting policies to\ndiverse environments with minimal effort. Project page:\nhttps://gchhablani.github.io/embodied-splat", "published": "2025-09-22 07:22:31", "link": "http://arxiv.org/abs/2509.17430v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration", "abstract": "Accurate temporal prediction is the bridge between comprehensive scene\nunderstanding and embodied artificial intelligence. However, predicting\nmultiple fine-grained states of a scene at multiple temporal scales is\ndifficult for vision-language models. We formalize the Multi-Scale Temporal\nPrediction (MSTP) task in general and surgical scenes by decomposing\nmulti-scale into two orthogonal dimensions: the temporal scale, forecasting\nstates of humans and surgery at varying look-ahead intervals, and the state\nscale, modeling a hierarchy of states in general and surgical scenes. For\nexample, in general scenes, states of contact relationships are finer-grained\nthan states of spatial relationships. In surgical scenes, medium-level steps\nare finer-grained than high-level phases yet remain constrained by their\nencompassing phase. To support this unified task, we introduce the first MSTP\nBenchmark, featuring synchronized annotations across multiple state scales and\ntemporal scales. We further propose a method, Incremental Generation and\nMulti-agent Collaboration (IG-MC), which integrates two key innovations. First,\nwe present a plug-and-play incremental generation module that continuously\nsynthesizes up-to-date visual previews at expanding temporal scales to inform\nmultiple decision-making agents, keeping decisions and generated visuals\nsynchronized and preventing performance degradation as look-ahead intervals\nlengthen. Second, we present a decision-driven multi-agent collaboration\nframework for multi-state prediction, comprising generation, initiation, and\nmulti-state assessment agents that dynamically trigger and evaluate prediction\ncycles to balance global coherence and local fidelity.", "published": "2025-09-22 07:22:27", "link": "http://arxiv.org/abs/2509.17429v1", "categories": ["cs.CV", "68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Single-Image Depth from Defocus with Coded Aperture and Diffusion Posterior Sampling", "abstract": "We propose a single-snapshot depth-from-defocus (DFD) reconstruction method\nfor coded-aperture imaging that replaces hand-crafted priors with a learned\ndiffusion prior used purely as regularization. Our optimization framework\nenforces measurement consistency via a differentiable forward model while\nguiding solutions with the diffusion prior in the denoised image domain,\nyielding higher accuracy and stability than clas- sical optimization. Unlike\nU-Net-style regressors, our approach requires no paired defocus-RGBD training\ndata and does not tie training to a specific camera configuration. Experiments\non comprehensive simulations and a prototype camera demonstrate consistently\nstrong RGBD reconstructions across noise levels, outperforming both U-Net\nbaselines and a classical coded- aperture DFD method.", "published": "2025-09-22 07:20:30", "link": "http://arxiv.org/abs/2509.17427v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diff-GNSS: Diffusion-based Pseudorange Error Estimation", "abstract": "Global Navigation Satellite Systems (GNSS) are vital for reliable urban\npositioning. However, multipath and non-line-of-sight reception often introduce\nlarge measurement errors that degrade accuracy. Learning-based methods for\npredicting and compensating pseudorange errors have gained traction, but their\nperformance is limited by complex error distributions. To address this\nchallenge, we propose Diff-GNSS, a coarse-to-fine GNSS measurement\n(pseudorange) error estimation framework that leverages a conditional diffusion\nmodel to capture such complex distributions. Firstly, a Mamba-based module\nperforms coarse estimation to provide an initial prediction with appropriate\nscale and trend. Then, a conditional denoising diffusion layer refines the\nestimate, enabling fine-grained modeling of pseudorange errors. To suppress\nuncontrolled generative diversity and achieve controllable synthesis, three key\nfeatures related to GNSS measurement quality are used as conditions to\nprecisely guide the reverse denoising process. We further incorporate\nper-satellite uncertainty modeling within the diffusion stage to assess the\nreliability of the predicted errors. We have collected and publicly released a\nreal-world dataset covering various scenes. Experiments on public and\nself-collected datasets show that DiffGNSS consistently outperforms\nstate-of-the-art baselines across multiple metrics. To the best of our\nknowledge, this is the first application of diffusion models to pseudorange\nerror estimation. The proposed diffusion-based refinement module is\nplug-and-play and can be readily integrated into existing networks to markedly\nimprove estimation accuracy.", "published": "2025-09-22 06:57:06", "link": "http://arxiv.org/abs/2509.17397v1", "categories": ["cs.CV", "cs.ET"], "primary_category": "cs.CV"}
{"title": "Revisiting Vision Language Foundations for No-Reference Image Quality Assessment", "abstract": "Large-scale vision language pre-training has recently shown promise for\nno-reference image-quality assessment (NR-IQA), yet the relative merits of\nmodern Vision Transformer foundations remain poorly understood. In this work,\nwe present the first systematic evaluation of six prominent pretrained\nbackbones, CLIP, SigLIP2, DINOv2, DINOv3, Perception, and ResNet, for the task\nof No-Reference Image Quality Assessment (NR-IQA), each finetuned using an\nidentical lightweight MLP head. Our study uncovers two previously overlooked\nfactors: (1) SigLIP2 consistently achieves strong performance; and (2) the\nchoice of activation function plays a surprisingly crucial role, particularly\nfor enhancing the generalization ability of image quality assessment models.\nNotably, we find that simple sigmoid activations outperform commonly used ReLU\nand GELU on several benchmarks. Motivated by this finding, we introduce a\nlearnable activation selection mechanism that adaptively determines the\nnonlinearity for each channel, eliminating the need for manual activation\ndesign, and achieving new state-of-the-art SRCC on CLIVE, KADID10K, and\nAGIQA3K. Extensive ablations confirm the benefits across architectures and\nregimes, establishing strong, resource-efficient NR-IQA baselines.", "published": "2025-09-22 06:24:42", "link": "http://arxiv.org/abs/2509.17374v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Circular-arc H-graphs: Ordering Characterizations and Forbidden Patterns", "abstract": "We introduce the class of circular-arc H-graphs, which generalizes\ncircular-arc graphs, particularly circular-arc bigraphs. We investigate two\ntypes of ordering-based characterizations of circular-arc r-graphs. Finally, we\nprovide forbidden patterns for circular-arc r-graphs in terms of specific\nvertex orderings.", "published": "2025-09-22 16:59:35", "link": "http://arxiv.org/abs/2509.18021v1", "categories": ["cs.DM", "math.CO", "05C62, 68R10, 05C12, 05C15"], "primary_category": "cs.DM"}
{"title": "Planar induced paths via a decomposition into non-crossing ordered graphs", "abstract": "In any graph, the maximum size of an induced path is bounded by the maximum\nsize of a path. However, in the general case, one cannot find a converse bound,\neven up to an arbitrary function, as evidenced by the case of cliques. Galvin,\nRival and Sands proved in 1982 that, when restricted to weakly sparse graphs,\nsuch a converse property actually holds.\n  In this paper, we consider the maximal function $f$ such that any planar\ngraph (and in general, any graph of bounded genus) containing a path on $n$\nvertices contains an induced path of size $f(n)$, and prove that $f(n) \\in\n\\Theta \\left(\\frac{\\log n}{\\log \\log n}\\right)$ by providing a lower bound\nmatching the upper bound obtained by Esperet, Lemoine and Maffray, up to a\nconstant factor. We obtain these tight bounds by analyzing graphs ordered along\na Hamiltonian path that admit an edge partition into a bounded number of sets\nwithout crossing edges. In particular, we prove that when such an ordered graph\ncan be partitioned into $2k$ sets of non-crossing edges, then it contains an\ninduced path of size $\\Omega_k\\left(\\left(\\frac{\\log n}{\\log \\log\nn}\\right)^{1/k} \\right)$ and provide almost matching upper bounds.", "published": "2025-09-22 14:24:22", "link": "http://arxiv.org/abs/2509.17835v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Generalized DP-colorings of digraphs", "abstract": "In this paper we consider the following three coloring concepts for digraphs.\nFirst of all, the generalized coloring concept, in which the same colored\nvertices of a digraph induce a subdigraph that satisfies a given digraph\nproperty. Second, the concept of variable degeneracy, introduced for graphs by\nBorodin, Kostochka and Toft in 2000; this allows to give a common\ngeneralization of the point partition number and the list dichromatic number.\nFinally, the DP-coloring concept as introduced for graphs by Dvo\\v{r}\\'ak and\nPostle in 2018, in which a list assignment of a graph is replaced by a cover.\nCombining these three coloring concepts leads to generalizations of several\nclassical coloring results for graphs and digraphs, including the theorems of\nBrooks, of Gallai, of Erd\\H{o}s, Rubin, and Taylor, and of Bernshteyn,\nKostochka, and Pron for graphs, and the corresponding theorems for digraphs due\nto Harutyunyan and Mohar. Our main result combines the DP-coloring and variable\ndegeneracy concepts for digraphs.", "published": "2025-09-22 08:07:12", "link": "http://arxiv.org/abs/2509.17471v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Shilling Recommender Systems by Generating Side-feature-aware Fake User Profiles", "abstract": "Recommender systems (RS) greatly influence users' consumption decisions,\nmaking them attractive targets for malicious shilling attacks that inject fake\nuser profiles to manipulate recommendations. Existing shilling methods can\ngenerate effective and stealthy fake profiles when training data only contain\nrating matrix, but they lack comprehensive solutions for scenarios where side\nfeatures are present and utilized by the recommender. To address this gap, we\nextend the Leg-UP framework by enhancing the generator architecture to\nincorporate side features, enabling the generation of side-feature-aware fake\nuser profiles. Experiments on benchmarks show that our method achieves strong\nattack performance while maintaining stealthiness.", "published": "2025-09-22 15:43:11", "link": "http://arxiv.org/abs/2509.17918v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Generative Framework for Personalized Sticker Retrieval", "abstract": "Formulating information retrieval as a variant of generative modeling,\nspecifically using autoregressive models to generate relevant identifiers for a\ngiven query, has recently attracted considerable attention. However, its\napplication to personalized sticker retrieval remains largely unexplored and\npresents unique challenges: existing relevance-based generative retrieval\nmethods typically lack personalization, leading to a mismatch between diverse\nuser expectations and the retrieved results. To address this gap, we propose\nPEARL, a novel generative framework for personalized sticker retrieval, and\nmake two key contributions: (i) To encode user-specific sticker preferences, we\ndesign a representation learning model to learn discriminative user\nrepresentations. It is trained on three prediction tasks that leverage personal\ninformation and click history; and (ii) To generate stickers aligned with a\nuser's query intent, we propose a novel intent-aware learning objective that\nprioritizes stickers associated with higher-ranked intents. Empirical results\nfrom both offline evaluations and online tests demonstrate that PEARL\nsignificantly outperforms state-of-the-art methods.", "published": "2025-09-22 13:11:44", "link": "http://arxiv.org/abs/2509.17749v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Human vs. Agent in Task-Oriented Conversations", "abstract": "Task-oriented conversational systems are essential for efficiently addressing\ndiverse user needs, yet their development requires substantial amounts of\nhigh-quality conversational data that is challenging and costly to obtain.\nWhile large language models (LLMs) have demonstrated potential in generating\nsynthetic conversations, the extent to which these agent-generated interactions\ncan effectively substitute real human conversations remains unclear. This work\npresents the first systematic comparison between LLM-simulated users and human\nusers in personalized task-oriented conversations. We propose a comprehensive\nanalytical framework encompassing three key aspects (conversation strategy,\ninteraction style, and conversation evaluation) and ten distinct dimensions for\nevaluating user behaviors, and collect parallel conversational datasets from\nboth human users and LLM agent users across four representative scenarios under\nidentical conditions. Our analysis reveals significant behavioral differences\nbetween the two user types in problem-solving approaches, question broadness,\nuser engagement, context dependency, feedback polarity and promise, language\nstyle, and hallucination awareness. We found consistency in the agent users and\nhuman users across the depth-first or breadth-first dimensions, as well as the\nusefulness dimensions. These findings provide critical insights for advancing\nLLM-based user simulation. Our multi-dimensional taxonomy constructed a\ngeneralizable framework for analyzing user behavior patterns, offering insights\nfrom LLM agent users and human users. By this work, we provide perspectives on\nrethinking how to use user simulation in conversational systems in the future.", "published": "2025-09-22 11:30:39", "link": "http://arxiv.org/abs/2509.17619v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LongEval at CLEF 2025: Longitudinal Evaluation of IR Systems on Web and Scientific Data", "abstract": "The LongEval lab focuses on the evaluation of information retrieval systems\nover time. Two datasets are provided that capture evolving search scenarios\nwith changing documents, queries, and relevance assessments. Systems are\nassessed from a temporal perspective-that is, evaluating retrieval\neffectiveness as the data they operate on changes. In its third edition,\nLongEval featured two retrieval tasks: one in the area of ad-hoc web retrieval,\nand another focusing on scientific article retrieval. We present an overview of\nthis year's tasks and datasets, as well as the participating systems. A total\nof 19 teams submitted their approaches, which we evaluated using nDCG and a\nvariety of measures that quantify changes in retrieval effectiveness over time.", "published": "2025-09-22 08:05:40", "link": "http://arxiv.org/abs/2509.17469v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "WildClaims: Information Access Conversations in the Wild(Chat)", "abstract": "The rapid advancement of Large Language Models (LLMs) has transformed\nconversational systems into practical tools used by millions. However, the\nnature and necessity of information retrieval in real-world conversations\nremain largely unexplored, as research has focused predominantly on\ntraditional, explicit information access conversations. The central question\nis: What do real-world information access conversations look like? To this end,\nwe first conduct an observational study on the WildChat dataset, large-scale\nuser-ChatGPT conversations, finding that users' access to information occurs\nimplicitly as check-worthy factual assertions made by the system, even when the\nconversation's primary intent is non-informational, such as creative writing.\nTo enable the systematic study of this phenomenon, we release the WildClaims\ndataset, a novel resource consisting of 121,905 extracted factual claims from\n7,587 utterances in 3,000 WildChat conversations, each annotated for\ncheck-worthiness. Our preliminary analysis of this resource reveals that\nconservatively 18% to 51% of conversations contain check-worthy assertions,\ndepending on the methods employed, and less conservatively, as many as 76% may\ncontain such assertions. This high prevalence underscores the importance of\nmoving beyond the traditional understanding of explicit information access, to\naddress the implicit information access that arises in real-world user-system\nconversations.", "published": "2025-09-22 07:32:06", "link": "http://arxiv.org/abs/2509.17442v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Simplified Longitudinal Retrieval Experiments: A Case Study on Query Expansion and Document Boosting", "abstract": "The longitudinal evaluation of retrieval systems aims to capture how\ninformation needs and documents evolve over time. However, classical\nCranfield-style retrieval evaluations only consist of a static set of queries\nand documents and thereby miss time as an evaluation dimension. Therefore,\nlongitudinal evaluations need to complement retrieval toolkits with custom\nlogic. This custom logic increases the complexity of research software, which\nmight reduce the reproducibility and extensibility of experiments. Based on our\nsubmissions to the 2024 edition of LongEval, we propose a custom extension of\nir_datasets for longitudinal retrieval experiments. This extension allows for\ndeclaratively, instead of imperatively, describing important aspects of\nlongitudinal retrieval experiments, e.g., which queries, documents, and/or\nrelevance feedback are available at which point in time. We reimplement our\nsubmissions to LongEval 2024 against our new ir_datasets extension, and find\nthat the declarative access can reduce the complexity of the code.", "published": "2025-09-22 07:29:34", "link": "http://arxiv.org/abs/2509.17440v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MLLM-Driven Semantic Identifier Generation for Generative Cross-Modal Retrieval", "abstract": "Generative cross-modal retrieval, which treats retrieval as a generation\ntask, has emerged as a promising direction with the rise of Multimodal Large\nLanguage Models (MLLMs). In this setting, the model responds to a text query by\ngenerating an identifier corresponding to the target image. However, existing\nmethods typically rely on manually crafted string IDs, clustering-based labels,\nor atomic identifiers requiring vocabulary expansion, all of which face\nchallenges in semantic alignment or scalability.To address these limitations,\nwe propose a vocabulary-efficient identifier generation framework that prompts\nMLLMs to generate Structured Semantic Identifiers from image-caption pairs.\nThese identifiers are composed of concept-level tokens such as objects and\nactions, naturally aligning with the model's generation space without modifying\nthe tokenizer. Additionally, we introduce a Rationale-Guided Supervision\nStrategy, prompting the model to produce a one-sentence explanation alongside\neach identifier serves as an auxiliary supervision signal that improves\nsemantic grounding and reduces hallucinations during training.", "published": "2025-09-22 05:23:06", "link": "http://arxiv.org/abs/2509.17359v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Quickest Change Detection in Continuous-Time in Presence of a Covert Adversary", "abstract": "We investigate the problem of covert quickest change detection in a\ncontinuous-time setting, where a Brownian motion experiences a drift change at\nan unknown time. Unlike classical formulations, we consider a covert adversary\nwho adjusts the post-change drift $\\mu = \\mu(\\gamma)$ as a function of the\nfalse alarm constraint parameter $\\gamma$, with the goal of remaining\nundetected for as long as possible. Leveraging the exact expressions for the\naverage detection delay (ADD) and average time to false alarm (AT2FA) known for\nthe continuous-time CuSum procedure, we rigorously analyze how the asymptotic\nbehavior of ADD evolves as $\\mu(\\gamma) \\to 0$ with increasing $\\gamma$. Our\nresults reveal that classical detection delay characterizations no longer hold\nin this regime. We derive sharp asymptotic expressions for the ADD under\nvarious convergence rates of $\\mu(\\gamma)$, identify precise conditions for\nmaintaining covertness, and characterize the total damage inflicted by the\nadversary. We show that the adversary achieves maximal damage when the drift\nscales as $\\mu(\\gamma) = \\Theta(1/\\sqrt{\\gamma})$, marking a fundamental\ntrade-off between stealth and impact in continuous-time detection systems.", "published": "2025-09-22 13:40:53", "link": "http://arxiv.org/abs/2509.17778v1", "categories": ["cs.IT", "cs.CR", "math.IT"], "primary_category": "cs.IT"}
{"title": "Symbol Detection in Inter-Symbol Interference Channels using Expectation Propagation with Channel Shortening", "abstract": "Iterative message passing detection based on expectation propagation(EP) has\ndemonstrated near-optimum performance in many signal processing and\ncommunication scenarios. The method remains feasible even for channel impulse\nresponses (CIRs), where the optimal Bahl-Cocke-Jelinek-Raviv (BCJR) detector is\ninfeasible. However, significant performance degradation occurs for channels\nwith strong inter-symbol interference (ISI), where the initial linear minimum\nmean square error (LMMSE) estimate is inaccurate. We propose an EP-based\ndetector that operates in a transformed signal space obtained by channel\nshortening. Specifically, instead of the conventional approach that iterates\nbetween an LMMSE estimator and a non-linear symbol-wise demapper, the proposed\nmethod iterates between a linear channel shortening filter-based estimator and\na nonlinear BCJR detector with reduced memory compared to the actual channel.\nAdditionally, we propose a deliberate mismatch between the initialized messages\nand the initialized covariance used in the linear estimator in the first\niteration for faster convergence. The proposed approach is evaluated for the\nwell-known Proakis-C ISI channel and for CIRs from a wireless measurement\ncampaign. We demonstrate improvements of up to 6dB at 2 bits per channel use\nand an improved performance-complexity trade-off over conventional EP-based\ndetection.", "published": "2025-09-22 13:03:48", "link": "http://arxiv.org/abs/2509.17735v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Empirical AI Ethics: Reconfiguring Ethics towards a Situated, Plural, and Transformative Approach", "abstract": "Mainstream AI ethics, with its reliance on top-down, principle-driven\nframeworks, fails to account for the situated realities of diverse communities\naffected by AI (Artificial Intelligence). Critics have argued that AI ethics\nfrequently serves corporate interests through practices of 'ethics washing',\noperating more as a tool for public relations than as a means of preventing\nharm or advancing the common good. As a result, growing scepticism among\ncritical scholars has cast the field as complicit in sustaining harmful systems\nrather than challenging or transforming them. In response, this paper adopts a\nScience and Technology Studies (STS) perspective to critically interrogate the\nfield of AI ethics. It hence applies the same analytic tools STS has long\ndirected at disciplines such as biology, medicine, and statistics to ethics.\nThis perspective reveals a core tension between vertical (top-down,\nprinciple-based) and horizontal (risk-mitigating, implementation-oriented)\napproaches to ethics. By tracing how these models have shaped the discourse, we\nshow how both fall short in addressing the complexities of AI as a\nsocio-technical assemblage, embedded in practice and entangled with power. To\nmove beyond these limitations, we propose a threefold reorientation of AI\nethics. First, we call for a shift in foundations: from top-down abstraction to\nempirical grounding. Second, we advocate for pluralisation: moving beyond\nWestern-centric frameworks toward a multiplicity of onto-epistemic\nperspectives. Finally, we outline strategies for reconfiguring AI ethics as a\ntransformative force, moving from narrow paradigms of risk mitigation toward\nco-creating technologies of hope.", "published": "2025-09-22 12:58:15", "link": "http://arxiv.org/abs/2509.17727v1", "categories": ["cs.CY", "cs.IT", "math.IT"], "primary_category": "cs.CY"}
{"title": "Evaluation Codes in Bottleneck Metrics", "abstract": "Analogs of Reed-Solomon codes are introduced within the framework of\nbottleneck poset metrics. These codes are proven to be maximum distance\nseparable. Furthermore, the results are extended to the setting of Algebraic\nGeometry codes.", "published": "2025-09-22 12:26:19", "link": "http://arxiv.org/abs/2509.17682v1", "categories": ["cs.IT", "math.AG", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Note on the Theoretical Support to Compute Dimension in Abelian Codes", "abstract": "In this note we give a theoretical support by means of quotient polynomial\nrings for the computation formulas of the dimension of abelian codes.", "published": "2025-09-22 11:19:00", "link": "http://arxiv.org/abs/2509.17597v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hyperbolic Sets in Incomplete Tables", "abstract": "In this paper, we extend results about the implementation of the\nBerlekamp-Massey-Sakata algorithm on data tables having a number of unknown\nvalues.", "published": "2025-09-22 11:13:52", "link": "http://arxiv.org/abs/2509.17591v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Strategic Coordination for Evolving Multi-agent Systems: A Hierarchical Reinforcement and Collective Learning Approach", "abstract": "Decentralized combinatorial optimization in evolving multi-agent systems\nposes significant challenges, requiring agents to balance long-term\ndecision-making, short-term optimized collective outcomes, while preserving\nautonomy of interactive agents under unanticipated changes. Reinforcement\nlearning offers a way to model sequential decision-making through dynamic\nprogramming to anticipate future environmental changes. However, applying\nmulti-agent reinforcement learning (MARL) to decentralized combinatorial\noptimization problems remains an open challenge due to the exponential growth\nof the joint state-action space, high communication overhead, and privacy\nconcerns in centralized training. To address these limitations, this paper\nproposes Hierarchical Reinforcement and Collective Learning (HRCL), a novel\napproach that leverages both MARL and decentralized collective learning based\non a hierarchical framework. Agents take high-level strategies using MARL to\ngroup possible plans for action space reduction and constrain the agent\nbehavior for Pareto optimality. Meanwhile, the low-level collective learning\nlayer ensures efficient and decentralized coordinated decisions among agents\nwith minimal communication. Extensive experiments in a synthetic scenario and\nreal-world smart city application models, including energy self-management and\ndrone swarm sensing, demonstrate that HRCL significantly improves performance,\nscalability, and adaptability compared to the standalone MARL and collective\nlearning approaches, achieving a win-win synthesis solution.", "published": "2025-09-22 17:58:45", "link": "http://arxiv.org/abs/2509.18088v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Learning functions, operators and dynamical systems with kernels", "abstract": "This expository article presents the approach to statistical machine learning\nbased on reproducing kernel Hilbert spaces. The basic framework is introduced\nfor scalar-valued learning and then extended to operator learning. Finally,\nlearning dynamical systems is formulated as a suitable operator learning\nproblem, leveraging Koopman operator theory.", "published": "2025-09-22 17:53:08", "link": "http://arxiv.org/abs/2509.18071v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning to Rank with Top-$K$ Fairness", "abstract": "Fairness in ranking models is crucial, as disparities in exposure can\ndisproportionately affect protected groups. Most fairness-aware ranking systems\nfocus on ensuring comparable average exposure for groups across the entire\nranked list, which may not fully address real-world concerns. For example, when\na ranking model is used for allocating resources among candidates or disaster\nhotspots, decision-makers often prioritize only the top-$K$ ranked items, while\nthe ranking beyond top-$K$ becomes less relevant. In this paper, we propose a\nlist-wise learning-to-rank framework that addresses the issues of inequalities\nin top-$K$ rankings at training time. Specifically, we propose a top-$K$\nexposure disparity measure that extends the classic exposure disparity metric\nin a ranked list. We then learn a ranker to balance relevance and fairness in\ntop-$K$ rankings. Since direct top-$K$ selection is computationally expensive\nfor a large number of items, we transform the non-differentiable selection\nprocess into a differentiable objective function and develop efficient\nstochastic optimization algorithms to achieve both high accuracy and sufficient\nfairness. Extensive experiments demonstrate that our method outperforms\nexisting methods.", "published": "2025-09-22 17:47:10", "link": "http://arxiv.org/abs/2509.18067v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Functional effects models: Accounting for preference heterogeneity in panel data with machine learning", "abstract": "In this paper, we present a general specification for Functional Effects\nModels, which use Machine Learning (ML) methodologies to learn\nindividual-specific preference parameters from socio-demographic\ncharacteristics, therefore accounting for inter-individual heterogeneity in\npanel choice data. We identify three specific advantages of the Functional\nEffects Model over traditional fixed, and random/mixed effects models: (i) by\nmapping individual-specific effects as a function of socio-demographic\nvariables, we can account for these effects when forecasting choices of\npreviously unobserved individuals (ii) the (approximate) maximum-likelihood\nestimation of functional effects avoids the incidental parameters problem of\nthe fixed effects model, even when the number of observed choices per\nindividual is small; and (iii) we do not rely on the strong distributional\nassumptions of the random effects model, which may not match reality. We learn\nfunctional intercept and functional slopes with powerful non-linear machine\nlearning regressors for tabular data, namely gradient boosting decision trees\nand deep neural networks. We validate our proposed methodology on a synthetic\nexperiment and three real-world panel case studies, demonstrating that the\nFunctional Effects Model: (i) can identify the true values of\nindividual-specific effects when the data generation process is known; (ii)\noutperforms both state-of-the-art ML choice modelling techniques that omit\nindividual heterogeneity in terms of predictive performance, as well as\ntraditional static panel choice models in terms of learning inter-individual\nheterogeneity. The results indicate that the FI-RUMBoost model, which combines\nthe individual-specific constants of the Functional Effects Model with the\ncomplex, non-linear utilities of RUMBoost, performs marginally best on\nlarge-scale revealed preference panel data.", "published": "2025-09-22 17:22:18", "link": "http://arxiv.org/abs/2509.18047v1", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Prepare Before You Act: Learning From Humans to Rearrange Initial States", "abstract": "Imitation learning (IL) has proven effective across a wide range of\nmanipulation tasks. However, IL policies often struggle when faced with\nout-of-distribution observations; for instance, when the target object is in a\npreviously unseen position or occluded by other objects. In these cases,\nextensive demonstrations are needed for current IL methods to reach robust and\ngeneralizable behaviors. But when humans are faced with these sorts of atypical\ninitial states, we often rearrange the environment for more favorable task\nexecution. For example, a person might rotate a coffee cup so that it is easier\nto grasp the handle, or push a box out of the way so they can directly grasp\ntheir target object. In this work we seek to equip robot learners with the same\ncapability: enabling robots to prepare the environment before executing their\ngiven policy. We propose ReSET, an algorithm that takes initial states -- which\nare outside the policy's distribution -- and autonomously modifies object poses\nso that the restructured scene is similar to training data. Theoretically, we\nshow that this two step process (rearranging the environment before rolling out\nthe given policy) reduces the generalization gap. Practically, our ReSET\nalgorithm combines action-agnostic human videos with task-agnostic\nteleoperation data to i) decide when to modify the scene, ii) predict what\nsimplifying actions a human would take, and iii) map those predictions into\nrobot action primitives. Comparisons with diffusion policies, VLAs, and other\nbaselines show that using ReSET to prepare the environment enables more robust\ntask execution with equal amounts of total training data. See videos at our\nproject website: https://reset2025paper.github.io/", "published": "2025-09-22 17:18:52", "link": "http://arxiv.org/abs/2509.18043v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Kernel K-means clustering of distributional data", "abstract": "We consider the problem of clustering a sample of probability distributions\nfrom a random distribution on $\\mathbb R^p$. Our proposed partitioning method\nmakes use of a symmetric, positive-definite kernel $k$ and its associated\nreproducing kernel Hilbert space (RKHS) $\\mathcal H$. By mapping each\ndistribution to its corresponding kernel mean embedding in $\\mathcal H$, we\nobtain a sample in this RKHS where we carry out the $K$-means clustering\nprocedure, which provides an unsupervised classification of the original\nsample. The procedure is simple and computationally feasible even for dimension\n$p>1$. The simulation studies provide insight into the choice of the kernel and\nits tuning parameter. The performance of the proposed clustering procedure is\nillustrated on a collection of Synthetic Aperture Radar (SAR) images.", "published": "2025-09-22 17:11:29", "link": "http://arxiv.org/abs/2509.18037v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Control Disturbance Rejection in Neural ODEs", "abstract": "In this paper, we propose an iterative training algorithm for Neural ODEs\nthat provides models resilient to control (parameter) disturbances. The method\nbuilds on our earlier work Tuning without Forgetting-and similarly introduces\ntraining points sequentially, and updates the parameters on new data within the\nspace of parameters that do not decrease performance on the previously learned\ntraining points-with the key difference that, inspired by the concept of flat\nminima, we solve a minimax problem for a non-convex non-concave functional over\nan infinite-dimensional control space. We develop a projected gradient descent\nalgorithm on the space of parameters that admits the structure of an\ninfinite-dimensional Banach subspace. We show through simulations that this\nformulation enables the model to effectively learn new data points and gain\nrobustness against control disturbance.", "published": "2025-09-22 17:09:17", "link": "http://arxiv.org/abs/2509.18034v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Core-elements Subsampling for Alternating Least Squares", "abstract": "In this paper, we propose a novel element-wise subset selection method for\nthe alternating least squares (ALS) algorithm, focusing on low-rank matrix\nfactorization involving matrices with missing values, as commonly encountered\nin recommender systems. While ALS is widely used for providing personalized\nrecommendations based on user-item interaction data, its high computational\ncost, stemming from repeated regression operations, poses significant\nchallenges for large-scale datasets. To enhance the efficiency of ALS, we\npropose a core-elements subsampling method that selects a representative subset\nof data and leverages sparse matrix operations to approximate ALS estimations\nefficiently. We establish theoretical guarantees for the approximation and\nconvergence of the proposed approach, showing that it achieves similar accuracy\nwith significantly reduced computational time compared to full-data ALS.\nExtensive simulations and real-world applications demonstrate the effectiveness\nof our method in various scenarios, emphasizing its potential in large-scale\nrecommendation systems.", "published": "2025-09-22 17:00:30", "link": "http://arxiv.org/abs/2509.18024v1", "categories": ["stat.ME", "cs.LG", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Fr\u00e9chet Geodesic Boosting", "abstract": "Gradient boosting has become a cornerstone of machine learning, enabling base\nlearners such as decision trees to achieve exceptional predictive performance.\nWhile existing algorithms primarily handle scalar or Euclidean outputs,\nincreasingly prevalent complex-structured data, such as distributions,\nnetworks, and manifold-valued outputs, present challenges for traditional\nmethods. Such non-Euclidean data lack algebraic structures such as addition,\nsubtraction, or scalar multiplication required by standard gradient boosting\nframeworks. To address these challenges, we introduce Fr\\'echet geodesic\nboosting (FGBoost), a novel approach tailored for outputs residing in geodesic\nmetric spaces. FGBoost leverages geodesics as proxies for residuals and\nconstructs ensembles in a way that respects the intrinsic geometry of the\noutput space. Through theoretical analysis, extensive simulations, and\nreal-world applications, we demonstrate the strong performance and adaptability\nof FGBoost, showcasing its potential for modeling complex data.", "published": "2025-09-22 16:53:27", "link": "http://arxiv.org/abs/2509.18013v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Robust, Online, and Adaptive Decentralized Gaussian Processes", "abstract": "Gaussian processes (GPs) offer a flexible, uncertainty-aware framework for\nmodeling complex signals, but scale cubically with data, assume static targets,\nand are brittle to outliers, limiting their applicability in large-scale\nproblems with dynamic and noisy environments. Recent work introduced\ndecentralized random Fourier feature Gaussian processes (DRFGP), an online and\ndistributed algorithm that casts GPs in an information-filter form, enabling\nexact sequential inference and fully distributed computation without reliance\non a fusion center. In this paper, we extend DRFGP along two key directions:\nfirst, by introducing a robust-filtering update that downweights the impact of\natypical observations; and second, by incorporating a dynamic adaptation\nmechanism that adapts to time-varying functions. The resulting algorithm\nretains the recursive information-filter structure while enhancing stability\nand accuracy. We demonstrate its effectiveness on a large-scale Earth system\napplication, underscoring its potential for in-situ modeling.", "published": "2025-09-22 16:49:49", "link": "http://arxiv.org/abs/2509.18011v1", "categories": ["stat.ML", "cs.LG", "cs.MA", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework", "abstract": "Recent advancements in deep learning have significantly enhanced the\nperformance and efficiency of traffic classification in networking systems.\nHowever, the lack of transparency in their predictions and decision-making has\nmade network operators reluctant to deploy DL-based solutions in production\nnetworks. To tackle this challenge, we propose Traffic-Explainer, a\nmodel-agnostic and input-perturbation-based traffic explanation framework. By\nmaximizing the mutual information between predictions on original traffic\nsequences and their masked counterparts, Traffic-Explainer automatically\nuncovers the most influential features driving model predictions. Extensive\nexperiments demonstrate that Traffic-Explainer improves upon existing\nexplanation methods by approximately 42%. Practically, we further apply\nTraffic-Explainer to identify influential features and demonstrate its enhanced\ntransparency across three critical tasks: application classification, traffic\nlocalization, and network cartography. For the first two tasks,\nTraffic-Explainer identifies the most decisive bytes that drive predicted\ntraffic applications and locations, uncovering potential vulnerabilities and\nprivacy concerns. In network cartography, Traffic-Explainer identifies\nsubmarine cables that drive the mapping of traceroute to physical path,\nenabling a traceroute-informed risk analysis.", "published": "2025-09-22 16:46:12", "link": "http://arxiv.org/abs/2509.18007v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Equilibrium flow: From Snapshots to Dynamics", "abstract": "Scientific data, from cellular snapshots in biology to celestial\ndistributions in cosmology, often consists of static patterns from underlying\ndynamical systems. These snapshots, while lacking temporal ordering, implicitly\nencode the processes that preserve them. This work investigates how strongly\nsuch a distribution constrains its underlying dynamics and how to recover them.\nWe introduce the Equilibrium flow method, a framework that learns continuous\ndynamics that preserve a given pattern distribution. Our method successfully\nidentifies plausible dynamics for 2-D systems and recovers the signature\nchaotic behavior of the Lorenz attractor. For high-dimensional Turing patterns\nfrom the Gray-Scott model, we develop an efficient, training-free variant that\nachieves high fidelity to the ground truth, validated both quantitatively and\nqualitatively. Our analysis reveals the solution space is constrained not only\nby the data but also by the learning model's inductive biases. This capability\nextends beyond recovering known systems, enabling a new paradigm of inverse\ndesign for Artificial Life. By specifying a target pattern distribution, we can\ndiscover the local interaction rules that preserve it, leading to the\nspontaneous emergence of complex behaviors, such as life-like flocking,\nattraction, and repulsion patterns, from simple, user-defined snapshots.", "published": "2025-09-22 16:33:20", "link": "http://arxiv.org/abs/2509.17990v1", "categories": ["cs.LG", "nlin.PS"], "primary_category": "cs.LG"}
{"title": "Budgeted Adversarial Attack against Graph-Based Anomaly Detection in Sensor Networks", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful models for anomaly\ndetection in sensor networks, particularly when analyzing multivariate time\nseries. In this work, we introduce BETA, a novel grey-box evasion attack\ntargeting such GNN-based detectors, where the attacker is constrained to\nperturb sensor readings from a limited set of nodes, excluding the target\nsensor, with the goal of either suppressing a true anomaly or triggering a\nfalse alarm at the target node. BETA identifies the sensors most influential to\nthe target node's classification and injects carefully crafted adversarial\nperturbations into their features, all while maintaining stealth and respecting\nthe attacker's budget. Experiments on three real-world sensor network datasets\nshow that BETA reduces the detection accuracy of state-of-the-art GNN-based\ndetectors by 30.62 to 39.16% on average, and significantly outperforms baseline\nattack strategies, while operating within realistic constraints.", "published": "2025-09-22 16:30:19", "link": "http://arxiv.org/abs/2509.17987v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Seeing Bones at Radio Frequency", "abstract": "Wireless sensing literature has long aspired to achieve X-ray-like vision at\nradio frequencies. Yet, state-of-the-art wireless sensing literature has yet to\ngenerate the archetypal X-ray image: one of the bones beneath flesh. In this\npaper, we explore MCT, a penetration-based RF-imaging system for imaging bones\nat mm-resolution, one that significantly exceeds prior penetration-based RF\nimaging literature. Indeed the long wavelength, significant attenuation and\ncomplex diffraction that occur as RF propagates through flesh, have long\nlimited imaging resolution (to several centimeters at best). We address these\nconcerns through a novel penetration-based synthetic aperture algorithm,\ncoupled with a learning-based pipeline to correct for diffraction-induced\nartifacts. A detailed evaluation of meat models demonstrates a resolution\nimprovement from sub-decimeter to sub-centimeter over prior art in RF\npenetrative imaging.", "published": "2025-09-22 16:24:36", "link": "http://arxiv.org/abs/2509.17979v1", "categories": ["cs.GR", "cs.ET", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Medical priority fusion: achieving dual optimization of sensitivity and interpretability in nipt anomaly detection", "abstract": "Clinical machine learning faces a critical dilemma in high-stakes medical\napplications: algorithms achieving optimal diagnostic performance typically\nsacrifice the interpretability essential for physician decision-making, while\ninterpretable methods compromise sensitivity in complex scenarios. This paradox\nbecomes particularly acute in non-invasive prenatal testing (NIPT), where\nmissed chromosomal abnormalities carry profound clinical consequences yet\nregulatory frameworks mandate explainable AI systems. We introduce Medical\nPriority Fusion (MPF), a constrained multi-objective optimization framework\nthat resolves this fundamental trade-off by systematically integrating Naive\nBayes probabilistic reasoning with Decision Tree rule-based logic through\nmathematically-principled weighted fusion under explicit medical constraints.\nRigorous validation on 1,687 real-world NIPT samples characterized by extreme\nclass imbalance (43.4:1 normal-to-abnormal ratio) employed stratified 5-fold\ncross-validation with comprehensive ablation studies and statistical hypothesis\ntesting using McNemar's paired comparisons. MPF achieved simultaneous\noptimization of dual objectives: 89.3% sensitivity (95% CI: 83.9-94.7%) with\n80% interpretability score, significantly outperforming individual algorithms\n(McNemar's test, p < 0.001). The optimal fusion configuration achieved Grade A\nclinical deployment criteria with large effect size (d = 1.24), establishing\nthe first clinically-deployable solution that maintains both diagnostic\naccuracy and decision transparency essential for prenatal care. This work\ndemonstrates that medical-constrained algorithm fusion can resolve the\ninterpretability-performance trade-off, providing a mathematical framework for\ndeveloping high-stakes medical decision support systems that meet both clinical\nefficacy and explainability requirements.", "published": "2025-09-22 15:49:20", "link": "http://arxiv.org/abs/2509.17924v1", "categories": ["cs.LG", "q-bio.TO"], "primary_category": "cs.LG"}
{"title": "SingLEM: Single-Channel Large EEG Model", "abstract": "Current deep learning models for electroencephalography (EEG) are often\ntask-specific and depend on large labeled datasets, limiting their\nadaptability. Although emerging foundation models aim for broader\napplicability, their rigid dependence on fixed, high-density multi-channel\nmontages restricts their use across heterogeneous datasets and in\nmissing-channel or practical low-channel settings. To address these\nlimitations, we introduce SingLEM, a self-supervised foundation model that\nlearns robust, general-purpose representations from single-channel EEG, making\nit inherently hardware agnostic. The model employs a hybrid encoder\narchitecture that combines convolutional layers to extract local features with\na hierarchical transformer to model both short- and long-range temporal\ndependencies. SingLEM is pretrained on 71 public datasets comprising over 9,200\nsubjects and 357,000 single-channel hours of EEG. When evaluated as a fixed\nfeature extractor across six motor imagery and cognitive tasks, aggregated\nsingle-channel representations consistently outperformed leading multi-channel\nfoundation models and handcrafted baselines. These results demonstrate that a\nsingle-channel approach can achieve state-of-the-art generalization while\nenabling fine-grained neurophysiological analysis and enhancing\ninterpretability. The source code and pretrained models are available at\nhttps://github.com/ttlabtuat/SingLEM.", "published": "2025-09-22 15:46:58", "link": "http://arxiv.org/abs/2509.17920v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Lipschitz-Based Robustness Certification for Recurrent Neural Networks via Convex Relaxation", "abstract": "Robustness certification against bounded input noise or adversarial\nperturbations is increasingly important for deployment recurrent neural\nnetworks (RNNs) in safety-critical control applications. To address this\nchallenge, we present RNN-SDP, a relaxation based method that models the RNN's\nlayer interactions as a convex problem and computes a certified upper bound on\nthe Lipschitz constant via semidefinite programming (SDP). We also explore an\nextension that incorporates known input constraints to further tighten the\nresulting Lipschitz bounds. RNN-SDP is evaluated on a synthetic multi-tank\nsystem, with upper bounds compared to empirical estimates. While incorporating\ninput constraints yields only modest improvements, the general method produces\nreasonably tight and certifiable bounds, even as sequence length increases. The\nresults also underscore the often underestimated impact of initialization\nerrors, an important consideration for applications where models are frequently\nre-initialized, such as model predictive control (MPC).", "published": "2025-09-22 15:26:46", "link": "http://arxiv.org/abs/2509.17898v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Optimizing Inference in Transformer-Based Models: A Multi-Method Benchmark", "abstract": "Efficient inference is a critical challenge in deep generative modeling,\nparticularly as diffusion models grow in capacity and complexity. While\nincreased complexity often improves accuracy, it raises compute costs, latency,\nand memory requirements. This work investigates techniques such as pruning,\nquantization, knowledge distillation, and simplified attention to reduce\ncomputational overhead without impacting performance. The study also explores\nthe Mixture of Experts (MoE) approach to further enhance efficiency. These\nexperiments provide insights into optimizing inference for the state-of-the-art\nFast Diffusion Transformer (fast-DiT) model.", "published": "2025-09-22 15:25:28", "link": "http://arxiv.org/abs/2509.17894v1", "categories": ["cs.LG", "68T07", "I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization", "abstract": "Multi-objective optimization (MOO) is essential for solving complex\nreal-world problems involving multiple conflicting objectives. However, many\npractical applications - including engineering design, autonomous systems, and\nmachine learning - often yield non-convex, degenerate, or discontinuous Pareto\nfrontiers, which involve traditional scalarization and Pareto Set Learning\n(PSL) methods that struggle to approximate accurately. Existing PSL approaches\nperform well on convex fronts but tend to fail in capturing the diversity and\nstructure of irregular Pareto sets commonly observed in real-world scenarios.\nIn this paper, we propose Gaussian-PSL, a novel framework that integrates\nGaussian Splatting into PSL to address the challenges posed by non-convex\nPareto frontiers. Our method dynamically partitions the preference vector\nspace, enabling simple MLP networks to learn localized features within each\nregion, which are then integrated by an additional MLP aggregator. This\npartition-aware strategy enhances both exploration and convergence, reduces\nsensi- tivity to initialization, and improves robustness against local optima.\nWe first provide the mathematical formulation for controllable Pareto set\nlearning using Gaussian Splat- ting. Then, we introduce the Gaussian-PSL\narchitecture and evaluate its performance on synthetic and real-world\nmulti-objective benchmarks. Experimental results demonstrate that our approach\noutperforms standard PSL models in learning irregular Pareto fronts while\nmaintaining computational efficiency and model simplicity. This work offers a\nnew direction for effective and scalable MOO under challenging frontier\ngeometries.", "published": "2025-09-22 15:21:22", "link": "http://arxiv.org/abs/2509.17889v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Brainprint-Modulated Target Speaker Extraction", "abstract": "Achieving robust and personalized performance in neuro-steered Target Speaker\nExtraction (TSE) remains a significant challenge for next-generation hearing\naids. This is primarily due to two factors: the inherent non-stationarity of\nEEG signals across sessions, and the high inter-subject variability that limits\nthe efficacy of generalized models. To address these issues, we propose\nBrainprint-Modulated Target Speaker Extraction (BM-TSE), a novel framework for\npersonalized and high-fidelity extraction. BM-TSE first employs a\nspatio-temporal EEG encoder with an Adaptive Spectral Gain (ASG) module to\nextract stable features resilient to non-stationarity. The core of our\nframework is a personalized modulation mechanism, where a unified brainmap\nembedding is learned under the joint supervision of subject identification\n(SID) and auditory attention decoding (AAD) tasks. This learned brainmap,\nencoding both static user traits and dynamic attentional states, actively\nrefines the audio separation process, dynamically tailoring the output to each\nuser. Evaluations on the public KUL and Cocktail Party datasets demonstrate\nthat BM-TSE achieves state-of-the-art performance, significantly outperforming\nexisting methods. Our code is publicly accessible at:\nhttps://github.com/rosshan-orz/BM-TSE.", "published": "2025-09-22 15:17:35", "link": "http://arxiv.org/abs/2509.17883v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Deep Hierarchical Learning with Nested Subspace Networks", "abstract": "Large neural networks are typically trained for a fixed computational budget,\ncreating a rigid trade-off between performance and efficiency that is\nill-suited for deployment in resource-constrained or dynamic environments.\nExisting approaches to this problem present a difficult choice: training a\ndiscrete collection of specialist models is computationally prohibitive, while\ndynamic methods like slimmable networks often lack the flexibility to be\napplied to large, pre-trained foundation models. In this work, we propose\nNested Subspace Networks (NSNs), a novel architectural paradigm that enables a\nsingle model to be dynamically and granularly adjusted across a continuous\nspectrum of compute budgets at inference time. The core of our approach is to\nre-parameterize linear layers to satisfy a nested subspace property, such that\nthe function computed at a given rank is a strict subspace of the function at\nany higher rank. We show that this entire hierarchy of models can be optimized\njointly via an uncertainty-aware objective that learns to balance the\ncontributions of different ranks based on their intrinsic difficulty. We\ndemonstrate empirically that NSNs can be surgically applied to pre-trained LLMs\nand unlock a smooth and predictable compute-performance frontier. For example,\na single NSN-adapted model can achieve a 50% reduction in inference FLOPs with\nonly a 5 percentage point loss in accuracy. Our findings establish NSNs as a\npowerful framework for creating the next generation of adaptive foundation\nmodels.", "published": "2025-09-22 15:13:14", "link": "http://arxiv.org/abs/2509.17874v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving After-sales Service: Deep Reinforcement Learning for Dynamic Time Slot Assignment with Commitments and Customer Preferences", "abstract": "Problem definition: For original equipment manufacturers (OEMs), high-tech\nmaintenance is a strategic component in after-sales services, involving close\ncoordination between customers and service engineers. Each customer suggests\nseveral time slots for their maintenance task, from which the OEM must select\none. This decision needs to be made promptly to support customers' planning. At\nthe end of each day, routes for service engineers are planned to fulfill the\ntasks scheduled for the following day. We study this hierarchical and\nsequential decision-making problem-the Dynamic Time Slot Assignment Problem\nwith Commitments and Customer Preferences (DTSAP-CCP)-in this paper.\nMethodology/results: Two distinct approaches are proposed: 1) an\nattention-based deep reinforcement learning with rollout execution (ADRL-RE)\nand 2) a scenario-based planning approach (SBP). The ADRL-RE combines a\nwell-trained attention-based neural network with a rollout framework for online\ntrajectory simulation. To support the training, we develop a neural heuristic\nsolver that provides rapid route planning solutions, enabling efficient\nlearning in complex combinatorial settings. The SBP approach samples several\nscenarios to guide the time slot assignment. Numerical experiments demonstrate\nthe superiority of ADRL-RE and the stability of SBP compared to both rule-based\nand rollout-based approaches. Furthermore, the strong practicality of ADRL-RE\nis verified in a case study of after-sales service for large medical equipment.\nImplications: This study provides OEMs with practical decision-support tools\nfor dynamic maintenance scheduling, balancing customer preferences and\noperational efficiency. In particular, our ADRL-RE shows strong real-world\npotential, supporting timely and customer-aligned maintenance scheduling.", "published": "2025-09-22 15:09:39", "link": "http://arxiv.org/abs/2509.17870v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conv-like Scale-Fusion Time Series Transformer: A Multi-Scale Representation for Variable-Length Long Time Series", "abstract": "Time series analysis faces significant challenges in handling variable-length\ndata and achieving robust generalization. While Transformer-based models have\nadvanced time series tasks, they often struggle with feature redundancy and\nlimited generalization capabilities. Drawing inspiration from classical CNN\narchitectures' pyramidal structure, we propose a Multi-Scale Representation\nLearning Framework based on a Conv-like ScaleFusion Transformer. Our approach\nintroduces a temporal convolution-like structure that combines patching\noperations with multi-head attention, enabling progressive temporal dimension\ncompression and feature channel expansion. We further develop a novel\ncross-scale attention mechanism for effective feature fusion across different\ntemporal scales, along with a log-space normalization method for\nvariable-length sequences. Extensive experiments demonstrate that our framework\nachieves superior feature independence, reduced redundancy, and better\nperformance in forecasting and classification tasks compared to\nstate-of-the-art methods.", "published": "2025-09-22 14:37:59", "link": "http://arxiv.org/abs/2509.17845v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Toward Affordable and Non-Invasive Detection of Hypoglycemia: A Machine Learning Approach", "abstract": "Diabetes mellitus is a growing global health issue, with Type 1 Diabetes\n(T1D) requiring constant monitoring to avoid hypoglycemia. Although Continuous\nGlucose Monitors (CGMs) are effective, their cost and invasiveness limit\naccess, particularly in low-resource settings. This paper proposes a\nnon-invasive method to classify glycemic states using Galvanic Skin Response\n(GSR), a biosignal commonly captured by wearable sensors. We use the merged\nOhioT1DM 2018 and 2020 datasets to build a machine learning pipeline that\ndetects hypoglycemia (glucose < 70 mg/dl) and normoglycemia (glucose > 70\nmg/dl) with GSR alone. Seven models are trained and evaluated: Random Forest,\nXGBoost, MLP, CNN, LSTM, Logistic Regression, and K-Nearest Neighbors.\nValidation sets and 95% confidence intervals are reported to increase\nreliability and assess robustness. Results show that the LSTM model achieves a\nperfect hypoglycemia recall (1.00) with an F1-score confidence interval of\n[0.611-0.745], while XGBoost offers strong performance with a recall of 0.54\neven under class imbalance. This approach highlights the potential for\naffordable, wearable-compatible glucose monitoring tools suitable for settings\nwith limited CGM availability using GSR data.\n  Index Terms: Hypoglycemia Detection, Galvanic Skin Response, Non Invasive\nMonitoring, Wearables, Machine Learning, Confidence Intervals.", "published": "2025-09-22 14:32:07", "link": "http://arxiv.org/abs/2509.17842v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Global Optimization via Softmin Energy Minimization", "abstract": "Global optimization, particularly for non-convex functions with multiple\nlocal minima, poses significant challenges for traditional gradient-based\nmethods. While metaheuristic approaches offer empirical effectiveness, they\noften lack theoretical convergence guarantees and may disregard available\ngradient information. This paper introduces a novel gradient-based swarm\nparticle optimization method designed to efficiently escape local minima and\nlocate global optima. Our approach leverages a \"Soft-min Energy\" interacting\nfunction, $J_\\beta(\\mathbf{x})$, which provides a smooth, differentiable\napproximation of the minimum function value within a particle swarm. We define\na stochastic gradient flow in the particle space, incorporating a Brownian\nmotion term for exploration and a time-dependent parameter $\\beta$ to control\nsmoothness, similar to temperature annealing. We theoretically demonstrate that\nfor strongly convex functions, our dynamics converges to a stationary point\nwhere at least one particle reaches the global minimum, with other particles\nexhibiting exploratory behavior. Furthermore, we show that our method\nfacilitates faster transitions between local minima by reducing effective\npotential barriers with respect to Simulated Annealing. More specifically, we\nestimate the hitting times of unexplored potential wells for our model in the\nsmall noise regime and show that they compare favorably with the ones of\noverdamped Langevin. Numerical experiments on benchmark functions, including\ndouble wells and the Ackley function, validate our theoretical findings and\ndemonstrate better performance over the well-known Simulated Annealing method\nin terms of escaping local minima and achieving faster convergence.", "published": "2025-09-22 14:09:19", "link": "http://arxiv.org/abs/2509.17815v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "MSGAT-GRU: A Multi-Scale Graph Attention and Recurrent Model for Spatiotemporal Road Accident Prediction", "abstract": "Accurate prediction of road accidents remains challenging due to intertwined\nspatial, temporal, and contextual factors in urban traffic. We propose\nMSGAT-GRU, a multi-scale graph attention and recurrent model that jointly\ncaptures localized and long-range spatial dependencies while modeling\nsequential dynamics. Heterogeneous inputs, such as traffic flow, road\nattributes, weather, and points of interest, are systematically fused to\nenhance robustness and interpretability. On the Hybrid Beijing Accidents\ndataset, MSGAT-GRU achieves an RMSE of 0.334 and an F1-score of 0.878,\nconsistently outperforming strong baselines. Cross-dataset evaluation on\nMETR-LA under a 1-hour horizon further supports transferability, with RMSE of\n6.48 (vs. 7.21 for the GMAN model) and comparable MAPE. Ablations indicate that\nthree-hop spatial aggregation and a two-layer GRU offer the best\naccuracy-stability trade-off. These results position MSGAT-GRU as a scalable\nand generalizable model for intelligent transportation systems, providing\ninterpretable signals that can inform proactive traffic management and road\nsafety analytics.", "published": "2025-09-22 14:05:23", "link": "http://arxiv.org/abs/2509.17811v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MTM: A Multi-Scale Token Mixing Transformer for Irregular Multivariate Time Series Classification", "abstract": "Irregular multivariate time series (IMTS) is characterized by the lack of\nsynchronized observations across its different channels. In this paper, we\npoint out that this channel-wise asynchrony can lead to poor channel-wise\nmodeling of existing deep learning methods. To overcome this limitation, we\npropose MTM, a multi-scale token mixing transformer for the classification of\nIMTS. We find that the channel-wise asynchrony can be alleviated by\ndown-sampling the time series to coarser timescales, and propose to incorporate\na masked concat pooling in MTM that gradually down-samples IMTS to enhance the\nchannel-wise attention modules. Meanwhile, we propose a novel channel-wise\ntoken mixing mechanism which proactively chooses important tokens from one\nchannel and mixes them with other channels, to further boost the channel-wise\nlearning of our model. Through extensive experiments on real-world datasets and\ncomparison with state-of-the-art methods, we demonstrate that MTM consistently\nachieves the best performance on all the benchmarks, with improvements of up to\n3.8% in AUPRC for classification.", "published": "2025-09-22 14:03:02", "link": "http://arxiv.org/abs/2509.17809v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Remote Sensing-Oriented World Model", "abstract": "World models have shown potential in artificial intelligence by predicting\nand reasoning about world states beyond direct observations. However, existing\napproaches are predominantly evaluated in synthetic environments or constrained\nscene settings, limiting their validation in real-world contexts with broad\nspatial coverage and complex semantics. Meanwhile, remote sensing applications\nurgently require spatial reasoning capabilities for disaster response and urban\nplanning. This paper bridges these gaps by introducing the first framework for\nworld modeling in remote sensing. We formulate remote sensing world modeling as\ndirection-conditioned spatial extrapolation, where models generate semantically\nconsistent adjacent image tiles given a central observation and directional\ninstruction. To enable rigorous evaluation, we develop RSWISE (Remote Sensing\nWorld-Image Spatial Evaluation), a benchmark containing 1,600 evaluation tasks\nacross four scenarios: general, flood, urban, and rural. RSWISE combines visual\nfidelity assessment with instruction compliance evaluation using GPT-4o as a\nsemantic judge, ensuring models genuinely perform spatial reasoning rather than\nsimple replication. Afterwards, we present RemoteBAGEL, a unified multimodal\nmodel fine-tuned on remote sensing data for spatial extrapolation tasks.\nExtensive experiments demonstrate that RemoteBAGEL consistently outperforms\nstate-of-the-art baselines on RSWISE.", "published": "2025-09-22 14:02:39", "link": "http://arxiv.org/abs/2509.17808v1", "categories": ["cs.LG", "F.2.2; I.2.7"], "primary_category": "cs.LG"}
{"title": "Elucidating the Design Space of FP4 training", "abstract": "The increasing computational demands of foundation models have spurred\nresearch into low-precision training, with 4-bit floating-point (\\texttt{FP4})\nformats emerging as a frontier for maximizing hardware throughput. While\nnumerous techniques have been proposed to stabilize \\texttt{FP4} training, they\noften present isolated solutions with varying, and not always clear,\ncomputational overheads. This paper aims to provide a unified view of the\ndesign space of \\texttt{FP4} training. We introduce a comprehensive,\nquantisation gradient-based framework for microscaling quantization that allows\nfor a theoretical analysis of the computational costs associated with different\nstabilization methods on both the forward and backward passes. Using a\nsimulator built on this framework, we conduct an extensive empirical study\nacross a wide range of machine learning tasks, including regression, image\nclassification, diffusion models, and language models. By systematically\nevaluating thousands of combinations of techniques, such as novel gradient\napproximations, rounding strategies, and scaling methods, we identify which\nconfigurations offer the most favourable performance-to-overhead trade-off. We\nfind that the techniques enabling the best trade-off involve carefully\ncombining Hadamard transformations, tensor scaling and stochastic rounding. We\nfurther find that using \\texttt{UE5M3} as a scaling factor potentially offers a\ngood compromise between range and precision with manageable computational\noverhead.", "published": "2025-09-22 13:50:40", "link": "http://arxiv.org/abs/2509.17791v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Flatness is Necessary, Neural Collapse is Not: Rethinking Generalization via Grokking", "abstract": "Neural collapse, i.e., the emergence of highly symmetric, class-wise\nclustered representations, is frequently observed in deep networks and is often\nassumed to reflect or enable generalization. In parallel, flatness of the loss\nlandscape has been theoretically and empirically linked to generalization. Yet,\nthe causal role of either phenomenon remains unclear: Are they prerequisites\nfor generalization, or merely by-products of training dynamics? We disentangle\nthese questions using grokking, a training regime in which memorization\nprecedes generalization, allowing us to temporally separate generalization from\ntraining dynamics and we find that while both neural collapse and relative\nflatness emerge near the onset of generalization, only flatness consistently\npredicts it. Models encouraged to collapse or prevented from collapsing\ngeneralize equally well, whereas models regularized away from flat solutions\nexhibit delayed generalization. Furthermore, we show theoretically that neural\ncollapse implies relative flatness under classical assumptions, explaining\ntheir empirical co-occurrence. Our results support the view that relative\nflatness is a potentially necessary and more fundamental property for\ngeneralization, and demonstrate how grokking can serve as a powerful probe for\nisolating its geometric underpinnings.", "published": "2025-09-22 13:05:07", "link": "http://arxiv.org/abs/2509.17738v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An AutoML Framework using AutoGluonTS for Forecasting Seasonal Extreme Temperatures", "abstract": "In recent years, great progress has been made in the field of forecasting\nmeteorological variables. Recently, deep learning architectures have made a\nmajor breakthrough in forecasting the daily average temperature over a ten-day\nhorizon. However, advances in forecasting events related to the maximum\ntemperature over short horizons remain a challenge for the community. A problem\nthat is even more complex consists in making predictions of the maximum daily\ntemperatures in the short, medium, and long term. In this work, we focus on\nforecasting events related to the maximum daily temperature over medium-term\nperiods (90 days). Therefore, instead of addressing the problem from a\nmeteorological point of view, this article tackles it from a climatological\npoint of view. Due to the complexity of this problem, a common approach is to\nframe the study as a temporal classification problem with the classes: maximum\ntemperature \"above normal\", \"normal\" or \"below normal\". From a practical point\nof view, we created a large historical dataset (from 1981 to 2018) collecting\ninformation from weather stations located in South America. In addition, we\nalso integrated exogenous information from the Pacific, Atlantic, and Indian\nOcean basins. We applied the AutoGluonTS platform to solve the above-mentioned\nproblem. This AutoML tool shows competitive forecasting performance with\nrespect to large operational platforms dedicated to tackling this\nclimatological problem; but with a \"relatively\" low computational cost in terms\nof time and resources.", "published": "2025-09-22 13:03:01", "link": "http://arxiv.org/abs/2509.17734v1", "categories": ["cs.LG", "cs.CE", "62M10, 68T05, 86A08, 62P12", "I.2.6; I.5.1; G.3; J.2"], "primary_category": "cs.LG"}
{"title": "A Generative Conditional Distribution Equality Testing Framework and Its Minimax Analysis", "abstract": "In this paper, we propose a general framework for testing the equality of the\nconditional distributions in a two-sample problem. This problem is most\nrelevant to transfer learning under covariate shift. Our framework is built on\nneural network-based generative methods and sample splitting techniques by\ntransforming the conditional distribution testing problem into an unconditional\none. We introduce two special tests: the generative permutation-based\nconditional distribution equality test and the generative classification\naccuracy-based conditional distribution equality test. Theoretically, we\nestablish a minimax lower bound for statistical inference in testing the\nequality of two conditional distributions under certain smoothness conditions.\nWe demonstrate that the generative permutation-based conditional distribution\nequality test and its modified version can attain this lower bound precisely or\nup to some iterated logarithmic factor. Moreover, we prove the testing\nconsistency of the generative classification accuracy-based conditional\ndistribution equality test. We also establish the convergence rate for the\nlearned conditional generator by deriving new results related to the\nrecently-developed offset Rademacher complexity and approximation properties\nusing neural networks. Empirically, we conduct numerical studies including\nsynthetic datasets and two real-world datasets, demonstrating the effectiveness\nof our approach.", "published": "2025-09-22 12:59:18", "link": "http://arxiv.org/abs/2509.17729v1", "categories": ["cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "cs.LG"}
{"title": "A non-smooth regularization framework for learning over multitask graphs", "abstract": "In this work, we consider learning over multitask graphs, where each agent\naims to estimate its own parameter vector. Although agents seek distinct\nobjectives, collaboration among them can be beneficial in scenarios where\nrelationships between tasks exist. Among the various approaches to promoting\nrelationships between tasks and, consequently, enhancing collaboration between\nagents, one notable method is regularization. While previous multitask learning\nstudies have focused on smooth regularization to enforce graph smoothness, this\nwork explores non-smooth regularization techniques that promote sparsity,\nmaking them particularly effective in encouraging piecewise constant\ntransitions on the graph. We begin by formulating a global regularized\noptimization problem, which involves minimizing the aggregate sum of individual\ncosts, regularized by a general non-smooth term designed to promote\npiecewise-constant relationships between the tasks of neighboring agents. Based\non the forward-backward splitting strategy, we propose a decentralized learning\napproach that enables efficient solutions to the regularized optimization\nproblem. Then, under convexity assumptions on the cost functions and\nco-regularization, we establish that the proposed approach converges in the\nmean-square-error sense within $O(\\mu)$ of the optimal solution of the globally\nregularized cost. For broader applicability and improved computational\nefficiency, we also derive closed-form expressions for commonly used non-smooth\n(and, possibly, non-convex) regularizers, such as the weighted sum of the\n$\\ell_0$-norm, $\\ell_1$-norm, and elastic net regularization. Finally, we\nillustrate both the theoretical findings and the effectiveness of the approach\nthrough simulations.", "published": "2025-09-22 12:58:53", "link": "http://arxiv.org/abs/2509.17728v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Fast, Accurate and Interpretable Graph Classification with Topological Kernels", "abstract": "We introduce a novel class of explicit feature maps based on topological\nindices that represent each graph by a compact feature vector, enabling fast\nand interpretable graph classification. Using radial basis function kernels on\nthese compact vectors, we define a measure of similarity between graphs. We\nperform evaluation on standard molecular datasets and observe that\nclassification accuracies based on single topological-index feature vectors\nunderperform compared to state-of-the-art substructure-based kernels. However,\nwe achieve significantly faster Gram matrix evaluation -- up to $20\\times$\nfaster -- compared to the Weisfeiler--Lehman subtree kernel. To enhance\nperformance, we propose two extensions: 1) concatenating multiple topological\nindices into an \\emph{Extended Feature Vector} (EFV), and 2) \\emph{Linear\nCombination of Topological Kernels} (LCTK) by linearly combining Radial Basis\nFunction kernels computed on feature vectors of individual topological graph\nindices. These extensions deliver up to $12\\%$ percent accuracy gains across\nall the molecular datasets. A complexity analysis highlights the potential for\nexponential quantum speedup for some of the vector components. Our results\nindicate that LCTK and EFV offer a favourable trade-off between accuracy and\nefficiency, making them strong candidates for practical graph learning\napplications.", "published": "2025-09-22 12:31:28", "link": "http://arxiv.org/abs/2509.17693v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predicting Chest Radiograph Findings from Electrocardiograms Using Interpretable Machine Learning", "abstract": "Purpose: Chest X-rays are essential for diagnosing pulmonary conditions, but\nlimited access in resource-constrained settings can delay timely diagnosis.\nElectrocardiograms (ECGs), in contrast, are widely available, non-invasive, and\noften acquired earlier in clinical workflows. This study aims to assess whether\nECG features and patient demographics can predict chest radiograph findings\nusing an interpretable machine learning approach.\n  Methods: Using the MIMIC-IV database, Extreme Gradient Boosting (XGBoost)\nclassifiers were trained to predict diverse chest radiograph findings from\nECG-derived features and demographic variables. Recursive feature elimination\nwas performed independently for each target to identify the most predictive\nfeatures. Model performance was evaluated using the area under the receiver\noperating characteristic curve (AUROC) with bootstrapped 95% confidence\nintervals. Shapley Additive Explanations (SHAP) were applied to interpret\nfeature contributions.\n  Results: Models successfully predicted multiple chest radiograph findings\nwith varying accuracy. Feature selection tailored predictors to each target,\nand including demographic variables consistently improved performance. SHAP\nanalysis revealed clinically meaningful contributions from ECG features to\nradiographic predictions.\n  Conclusion: ECG-derived features combined with patient demographics can serve\nas a proxy for certain chest radiograph findings, enabling early triage or\npre-screening in settings where radiographic imaging is limited. Interpretable\nmachine learning demonstrates potential to support radiology workflows and\nimprove patient care.", "published": "2025-09-22 12:18:50", "link": "http://arxiv.org/abs/2509.17674v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "RAVEN: RAnking and Validation of ExoplaNets", "abstract": "We present RAVEN, a newly developed vetting and validation pipeline for TESS\nexoplanet candidates. The pipeline employs a Bayesian framework to derive the\nposterior probability of a candidate being a planet against a set of False\nPositive (FP) scenarios, through the use of a Gradient Boosted Decision Tree\nand a Gaussian Process classifier, trained on comprehensive synthetic training\nsets of simulated planets and 8 astrophysical FP scenarios injected into TESS\nlightcurves. These training sets allow large scale candidate vetting and\nperformance verification against individual FP scenarios. A Non-Simulated FP\ntraining set consisting of real TESS candidates caused primarily by stellar\nvariability and systematic noise is also included. The machine learning derived\nprobabilities are combined with scenario specific prior probabilities,\nincluding the candidates' positional probabilities, to compute the final\nposterior probabilities. Candidates with a planetary posterior probability\ngreater than 99% against each FP scenario and whose implied planetary radius is\nless than 8$R_{\\oplus}$ are considered to be statistically validated by the\npipeline. In this first version, the pipeline has been developed for candidates\nwith a lightcurve released from the TESS Science Processing Operations Centre,\nan orbital period between 0.5 and 16 days and a transit depth greater than\n300ppm. The pipeline obtained area-under-curve (AUC) scores > 97% on all FP\nscenarios and > 99% on all but one. Testing on an independent external sample\nof 1361 pre-classified TOIs, the pipeline achieved an overall accuracy of 91%,\ndemonstrating its effectiveness for automated ranking of TESS candidates. For a\nprobability threshold of 0.9 the pipeline reached a precision of 97% with a\nrecall score of 66% on these TOIs. The RAVEN pipeline is publicly released as a\ncloud-hosted app, making it easily accessible to the community.", "published": "2025-09-22 11:50:31", "link": "http://arxiv.org/abs/2509.17645v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "primary_category": "astro-ph.EP"}
{"title": "Whitening Spherical Gaussian Mixtures in the Large-Dimensional Regime", "abstract": "Whitening is a classical technique in unsupervised learning that can\nfacilitate estimation tasks by standardizing data. An important application is\nthe estimation of latent variable models via the decomposition of tensors built\nfrom high-order moments. In particular, whitening orthogonalizes the means of a\nspherical Gaussian mixture model (GMM), thereby making the corresponding moment\ntensor orthogonally decomposable, hence easier to decompose. However, in the\nlarge-dimensional regime (LDR) where data are high-dimensional and scarce, the\nstandard whitening matrix built from the sample covariance becomes ineffective\nbecause the latter is spectrally distorted. Consequently, whitened means of a\nspherical GMM are no longer orthogonal. Using random matrix theory, we derive\nexact limits for their dot products, which are generally nonzero in the LDR. As\nour main contribution, we then construct a corrected whitening matrix that\nrestores asymptotic orthogonality, allowing for performance gains in spherical\nGMM estimation.", "published": "2025-09-22 11:43:30", "link": "http://arxiv.org/abs/2509.17636v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Comparing Data Assimilation and Likelihood-Based Inference on Latent State Estimation in Agent-Based Models", "abstract": "In this paper, we present the first systematic comparison of Data\nAssimilation (DA) and Likelihood-Based Inference (LBI) in the context of\nAgent-Based Models (ABMs). These models generate observable time series driven\nby evolving, partially-latent microstates. Latent states need to be estimated\nto align simulations with real-world data -- a task traditionally addressed by\nDA, especially in continuous and equation-based models such as those used in\nweather forecasting. However, the nature of ABMs poses challenges for standard\nDA methods. Solving such issues requires adaptation of previous DA techniques,\nor ad-hoc alternatives such as LBI. DA approximates the likelihood in a\nmodel-agnostic way, making it broadly applicable but potentially less precise.\nIn contrast, LBI provides more accurate state estimation by directly leveraging\nthe model's likelihood, but at the cost of requiring a hand-crafted,\nmodel-specific likelihood function, which may be complex or infeasible to\nderive. We compare the two methods on the Bounded-Confidence Model, a\nwell-known opinion dynamics ABM, where agents are affected only by others\nholding sufficiently similar opinions. We find that LBI better recovers latent\nagent-level opinions, even under model mis-specification, leading to improved\nindividual-level forecasts. At the aggregate level, however, both methods\nperform comparably, and DA remains competitive across levels of aggregation\nunder certain parameter settings. Our findings suggest that DA is well-suited\nfor aggregate predictions, while LBI is preferable for agent-level inference.", "published": "2025-09-22 11:34:55", "link": "http://arxiv.org/abs/2509.17625v1", "categories": ["cs.LG", "cs.CY", "physics.soc-ph", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Audio Super-Resolution with Latent Bridge Models", "abstract": "Audio super-resolution (SR), i.e., upsampling the low-resolution (LR)\nwaveform to the high-resolution (HR) version, has recently been explored with\ndiffusion and bridge models, while previous methods often suffer from\nsub-optimal upsampling quality due to their uninformative generation prior.\nTowards high-quality audio super-resolution, we present a new system with\nlatent bridge models (LBMs), where we compress the audio waveform into a\ncontinuous latent space and design an LBM to enable a latent-to-latent\ngeneration process that naturally matches the LR-toHR upsampling process,\nthereby fully exploiting the instructive prior information contained in the LR\nwaveform. To further enhance the training results despite the limited\navailability of HR samples, we introduce frequency-aware LBMs, where the prior\nand target frequency are taken as model input, enabling LBMs to explicitly\nlearn an any-to-any upsampling process at the training stage. Furthermore, we\ndesign cascaded LBMs and present two prior augmentation strategies, where we\nmake the first attempt to unlock the audio upsampling beyond 48 kHz and empower\na seamless cascaded SR process, providing higher flexibility for audio\npost-production. Comprehensive experimental results evaluated on the VCTK,\nESC-50, Song-Describer benchmark datasets and two internal testsets demonstrate\nthat we achieve state-of-the-art objective and perceptual quality for\nany-to-48kHz SR across speech, audio, and music signals, as well as setting the\nfirst record for any-to-192kHz audio SR. Demo at https://AudioLBM.github.io/.", "published": "2025-09-22 11:24:26", "link": "http://arxiv.org/abs/2509.17609v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "FastNet: Improving the physical consistency of machine-learning weather prediction models through loss function design", "abstract": "Machine learning weather prediction (MLWP) models have demonstrated\nremarkable potential in delivering accurate forecasts at significantly reduced\ncomputational cost compared to traditional numerical weather prediction (NWP)\nsystems. However, challenges remain in ensuring the physical consistency of\nMLWP outputs, particularly in deterministic settings. This study presents\nFastNet, a graph neural network (GNN)-based global prediction model, and\ninvestigates the impact of alternative loss function designs on improving the\nphysical realism of its forecasts. We explore three key modifications to the\nstandard mean squared error (MSE) loss: (1) a modified spherical harmonic (MSH)\nloss that penalises spectral amplitude errors to reduce blurring and enhance\nsmall-scale structure retention; (2) inclusion of horizontal gradient terms in\nthe loss to suppress non-physical artefacts; and (3) an alternative wind\nrepresentation that decouples speed and direction to better capture extreme\nwind events. Results show that while the MSH and gradient-based losses\n\\textit{alone} may slightly degrade RMSE scores, when trained in combination\nthe model exhibits very similar MSE performance to an MSE-trained model while\nat the same time significantly improving spectral fidelity and physical\nconsistency. The alternative wind representation further improves wind speed\naccuracy and reduces directional bias. Collectively, these findings highlight\nthe importance of loss function design as a mechanism for embedding domain\nknowledge into MLWP models and advancing their operational readiness.", "published": "2025-09-22 11:21:29", "link": "http://arxiv.org/abs/2509.17601v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Bilateral Distribution Compression: Reducing Both Data Size and Dimensionality", "abstract": "Existing distribution compression methods reduce dataset size by minimising\nthe Maximum Mean Discrepancy (MMD) between original and compressed sets, but\nmodern datasets are often large in both sample size and dimensionality. We\npropose Bilateral Distribution Compression (BDC), a two-stage framework that\ncompresses along both axes while preserving the underlying distribution, with\noverall linear time and memory complexity in dataset size and dimension.\nCentral to BDC is the Decoded MMD (DMMD), which quantifies the discrepancy\nbetween the original data and a compressed set decoded from a low-dimensional\nlatent space. BDC proceeds by (i) learning a low-dimensional projection using\nthe Reconstruction MMD (RMMD), and (ii) optimising a latent compressed set with\nthe Encoded MMD (EMMD). We show that this procedure minimises the DMMD,\nguaranteeing that the compressed set faithfully represents the original\ndistribution. Experiments show that across a variety of scenarios BDC can\nachieve comparable or superior performance to ambient-space compression at\nsubstantially lower cost.", "published": "2025-09-22 09:01:52", "link": "http://arxiv.org/abs/2509.17543v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "An Unlearning Framework for Continual Learning", "abstract": "Growing concerns surrounding AI safety and data privacy have driven the\ndevelopment of Machine Unlearning as a potential solution. However, current\nmachine unlearning algorithms are designed to complement the offline training\nparadigm. The emergence of the Continual Learning (CL) paradigm promises\nincremental model updates, enabling models to learn new tasks sequentially.\nNaturally, some of those tasks may need to be unlearned to address safety or\nprivacy concerns that might arise. We find that applying conventional\nunlearning algorithms in continual learning environments creates two critical\nproblems: performance degradation on retained tasks and task relapse, where\npreviously unlearned tasks resurface during subsequent learning. Furthermore,\nmost unlearning algorithms require data to operate, which conflicts with CL's\nphilosophy of discarding past data. A clear need arises for unlearning\nalgorithms that are data-free and mindful of future learning. To that end, we\npropose UnCLe, an Unlearning framework for Continual Learning. UnCLe employs a\nhypernetwork that learns to generate task-specific network parameters, using\ntask embeddings. Tasks are unlearned by aligning the corresponding generated\nnetwork parameters with noise, without requiring any data. Empirical\nevaluations on several vision data sets demonstrate UnCLe's ability to\nsequentially perform multiple learning and unlearning operations with minimal\ndisruption to previously acquired knowledge.", "published": "2025-09-22 08:51:18", "link": "http://arxiv.org/abs/2509.17530v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data", "abstract": "State Space Models (SSMs) have emerged as promising alternatives to attention\nmechanisms, with the Mamba architecture demonstrating impressive performance\nand linear complexity for processing long sequences. However, the fundamental\ndifferences between Mamba and Transformer architectures remain incompletely\nunderstood. In this work, we use carefully designed synthetic tasks to reveal\nMamba's inherent limitations. Through experiments, we identify that Mamba's\nnonlinear convolution introduces an asymmetry bias that significantly impairs\nits ability to recognize symmetrical patterns and relationships. Using\ncomposite function and inverse sequence matching tasks, we demonstrate that\nMamba strongly favors compositional solutions over symmetrical ones and\nstruggles with tasks requiring the matching of reversed sequences. We show\nthese limitations stem not from the SSM module itself but from the nonlinear\nconvolution preceding it, which fuses token information asymmetrically. These\ninsights provide a new understanding of Mamba's constraints and suggest\nconcrete architectural improvements for future sequence models.", "published": "2025-09-22 08:38:55", "link": "http://arxiv.org/abs/2509.17514v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "BiLCNet : BiLSTM-Conformer Network for Encrypted Traffic Classification with 5G SA Physical Channel Records", "abstract": "Accurate and efficient traffic classification is vital for wireless network\nmanagement, especially under encrypted payloads and dynamic application\nbehavior, where traditional methods such as port-based identification and deep\npacket inspection (DPI) are increasingly inadequate. This work explores the\nfeasibility of using physical channel data collected from the air interface of\n5G Standalone (SA) networks for traffic sensing. We develop a preprocessing\npipeline to transform raw channel records into structured representations with\ncustomized feature engineering to enhance downstream classification\nperformance. To jointly capture temporal dependencies and both local and global\nstructural patterns inherent in physical channel records, we propose a novel\nhybrid architecture: BiLSTM-Conformer Network (BiLCNet), which integrates the\nsequential modeling capability of Bidirectional Long Short-Term Memory networks\n(BiLSTM) with the spatial feature extraction strength of Conformer blocks.\nEvaluated on a noise-limited 5G SA dataset, our model achieves a classification\naccuracy of 93.9%, outperforming a series of conventional machine learning and\ndeep learning algorithms. Furthermore, we demonstrate its generalization\nability under zero-shot transfer settings, validating its robustness across\ntraffic categories and varying environmental conditions.", "published": "2025-09-22 08:27:11", "link": "http://arxiv.org/abs/2509.17495v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Path-Weighted Integrated Gradients for Interpretable Dementia Classification", "abstract": "Integrated Gradients (IG) is a widely used attribution method in explainable\nartificial intelligence (XAI). In this paper, we introduce Path-Weighted\nIntegrated Gradients (PWIG), a generalization of IG that incorporates a\ncustomizable weighting function into the attribution integral. This\nmodification allows for targeted emphasis along different segments of the path\nbetween a baseline and the input, enabling improved interpretability, noise\nmitigation, and the detection of path-dependent feature relevance. We establish\nits theoretical properties and illustrate its utility through experiments on a\ndementia classification task using the OASIS-1 MRI dataset. Attribution maps\ngenerated by PWIG highlight clinically meaningful brain regions associated with\nvarious stages of dementia, providing users with sharp and stable explanations.\nThe results suggest that PWIG offers a flexible and theoretically grounded\napproach for enhancing attribution quality in complex predictive models.", "published": "2025-09-22 08:19:48", "link": "http://arxiv.org/abs/2509.17491v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Periodic Graph-Enhanced Multivariate Time Series Anomaly Detector", "abstract": "Multivariate time series (MTS) anomaly detection commonly encounters in\nvarious domains like finance, healthcare, and industrial monitoring. However,\nexisting MTS anomaly detection methods are mostly defined on the static graph\nstructure, which fails to perform an accurate representation of complex\nspatio-temporal correlations in MTS. To address this issue, this study proposes\na Periodic Graph-Enhanced Multivariate Time Series Anomaly Detector (PGMA) with\nthe following two-fold ideas: a) designing a periodic time-slot allocation\nstrategy based Fast Fourier Transform (FFT), which enables the graph structure\nto reflect dynamic changes in MTS; b) utilizing graph neural network and\ntemporal extension convolution to accurate extract the complex spatio-temporal\ncorrelations from the reconstructed periodic graphs. Experiments on four real\ndatasets from real applications demonstrate that the proposed PGMA outperforms\nstate-of-the-art models in MTS anomaly detection.", "published": "2025-09-22 08:07:47", "link": "http://arxiv.org/abs/2509.17472v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robust Mixture Models for Algorithmic Fairness Under Latent Heterogeneity", "abstract": "Standard machine learning models optimized for average performance often fail\non minority subgroups and lack robustness to distribution shifts. This\nchallenge worsens when subgroups are latent and affected by complex\ninteractions among continuous and discrete features. We introduce ROME (RObust\nMixture Ensemble), a framework that learns latent group structure from data\nwhile optimizing for worst-group performance. ROME employs two approaches: an\nExpectation-Maximization algorithm for linear models and a neural\nMixture-of-Experts for nonlinear settings. Through simulations and experiments\non real-world datasets, we demonstrate that ROME significantly improves\nalgorithmic fairness compared to standard methods while maintaining competitive\naverage performance. Importantly, our method requires no predefined group\nlabels, making it practical when sources of disparities are unknown or\nevolving.", "published": "2025-09-22 07:03:33", "link": "http://arxiv.org/abs/2509.17411v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Efficient Sliced Wasserstein Distance Computation via Adaptive Bayesian Optimization", "abstract": "The sliced Wasserstein distance (SW) reduces optimal transport on\n$\\mathbb{R}^d$ to a sum of one-dimensional projections, and thanks to this\nefficiency, it is widely used in geometry, generative modeling, and\nregistration tasks. Recent work shows that quasi-Monte Carlo constructions for\ncomputing SW (QSW) yield direction sets with excellent approximation error.\nThis paper presents an alternate, novel approach: learning directions with\nBayesian optimization (BO), particularly in settings where SW appears inside an\noptimization loop (e.g., gradient flows). We introduce a family of drop-in\nselectors for projection directions: BOSW, a one-shot BO scheme on the unit\nsphere; RBOSW, a periodic-refresh variant; ABOSW, an adaptive hybrid that seeds\nfrom competitive QSW sets and performs a few lightweight BO refinements; and\nARBOSW, a restarted hybrid that periodically relearns directions during\noptimization. Our BO approaches can be composed with QSW and its variants\n(demonstrated by ABOSW/ARBOSW) and require no changes to downstream losses or\ngradients. We provide numerical experiments where our methods achieve\nstate-of-the-art performance, and on the experimental suite of the original QSW\npaper, we find that ABOSW and ARBOSW can achieve convergence comparable to the\nbest QSW variants with modest runtime overhead.", "published": "2025-09-22 07:02:19", "link": "http://arxiv.org/abs/2509.17405v1", "categories": ["cs.LG", "49Q22 (Primary) 90C57, 68Txx (Secondary)", "G.3; I.2"], "primary_category": "cs.LG"}
{"title": "Robust Anomaly Detection Under Normality Distribution Shift in Dynamic Graphs", "abstract": "Anomaly detection in dynamic graphs is a critical task with broad real-world\napplications, including social networks, e-commerce, and cybersecurity. Most\nexisting methods assume that normal patterns remain stable over time; however,\nthis assumption often fails in practice due to the phenomenon we refer to as\nnormality distribution shift (NDS), where normal behaviors evolve over time.\nIgnoring NDS can lead models to misclassify shifted normal instances as\nanomalies, degrading detection performance. To tackle this issue, we propose\nWhENDS, a novel unsupervised anomaly detection method that aligns normal edge\nembeddings across time by estimating distributional statistics and applying\nwhitening transformations. Extensive experiments on four widely-used dynamic\ngraph datasets show that WhENDS consistently outperforms nine strong baselines,\nachieving state-of-the-art results and underscoring the importance of\naddressing NDS in dynamic graph anomaly detection.", "published": "2025-09-22 06:59:59", "link": "http://arxiv.org/abs/2509.17400v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bias-variance Tradeoff in Tensor Estimation", "abstract": "We study denoising of a third-order tensor when the ground-truth tensor is\nnot necessarily Tucker low-rank. Specifically, we observe $$ Y=X^\\ast+Z\\in\n\\mathbb{R}^{p_{1} \\times p_{2} \\times p_{3}}, $$ where $X^\\ast$ is the\nground-truth tensor, and $Z$ is the noise tensor. We propose a simple variant\nof the higher-order tensor SVD estimator $\\widetilde{X}$. We show that\nuniformly over all user-specified Tucker ranks $(r_{1},r_{2},r_{3})$, $$ \\|\n\\widetilde{X} - X^* \\|_{ \\mathrm{F}}^2 = O \\Big( \\kappa^2 \\Big\\{\nr_{1}r_{2}r_{3}+\\sum_{k=1}^{3} p_{k} r_{k} \\Big\\} \\; + \\;\n\\xi_{(r_{1},r_{2},r_{3})}^2\\Big) \\quad \\text{ with high probability.} $$ Here,\nthe bias term $\\xi_{(r_1,r_2,r_3)}$ corresponds to the best achievable\napproximation error of $X^\\ast$ over the class of tensors with Tucker ranks\n$(r_1,r_2,r_3)$; $\\kappa^2$ quantifies the noise level; and the variance term\n$\\kappa^2 \\{r_{1}r_{2}r_{3}+\\sum_{k=1}^{3} p_{k} r_{k}\\}$ scales with the\neffective number of free parameters in the estimator $\\widetilde{X}$. Our\nanalysis achieves a clean rank-adaptive bias--variance tradeoff: as we increase\nthe ranks of estimator $\\widetilde{X}$, the bias $\\xi(r_{1},r_{2},r_{3})$\ndecreases and the variance increases. As a byproduct we also obtain a\nconvenient bias-variance decomposition for the vanilla low-rank SVD matrix\nestimators.", "published": "2025-09-22 06:46:16", "link": "http://arxiv.org/abs/2509.17382v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models", "abstract": "The rapid adoption of large language models (LLMs) in critical domains has\nspurred extensive research into their security issues. While input manipulation\nattacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks\n(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters\nand cause severe performance degradation -- have received far less attention.\nExisting BFA methods suffer from key limitations: they fail to balance\nperformance degradation and output naturalness, making them prone to discovery.\nIn this paper, we introduce SilentStriker, the first stealthy bit-flip attack\nagainst LLMs that effectively degrades task performance while maintaining\noutput naturalness. Our core contribution lies in addressing the challenge of\ndesigning effective loss functions for LLMs with variable output length and the\nvast output space. Unlike prior approaches that rely on output perplexity for\nattack loss formulation, which inevitably degrade output naturalness, we\nreformulate the attack objective by leveraging key output tokens as targets for\nsuppression, enabling effective joint optimization of attack effectiveness and\nstealthiness. Additionally, we employ an iterative, progressive search strategy\nto maximize attack efficacy. Experiments show that SilentStriker significantly\noutperforms existing baselines, achieving successful attacks without\ncompromising the naturalness of generated text.", "published": "2025-09-22 05:36:18", "link": "http://arxiv.org/abs/2509.17371v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Explainability matters: The effect of liability rules on the healthcare sector", "abstract": "Explainability, the capability of an artificial intelligence system (AIS) to\nexplain its outcomes in a manner that is comprehensible to human beings at an\nacceptable level, has been deemed essential for critical sectors, such as\nhealthcare. Is it really the case? In this perspective, we consider two extreme\ncases, ``Oracle'' (without explainability) versus ``AI Colleague'' (with\nexplainability) for a thorough analysis. We discuss how the level of automation\nand explainability of AIS can affect the determination of liability among the\nmedical practitioner/facility and manufacturer of AIS. We argue that\nexplainability plays a crucial role in setting a responsibility framework in\nhealthcare, from a legal standpoint, to shape the behavior of all involved\nparties and mitigate the risk of potential defensive medicine practices.", "published": "2025-09-22 03:11:30", "link": "http://arxiv.org/abs/2509.17334v1", "categories": ["cs.CY", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Word2VecGD: Neural Graph Drawing with Cosine-Stress Optimization", "abstract": "We propose a novel graph visualization method leveraging random walk-based\nembeddings to replace costly graph-theoretical distance computations. Using\nword2vec-inspired embeddings, our approach captures both structural and\nsemantic relationships efficiently. Instead of relying on exact shortest-path\ndistances, we optimize layouts using cosine dissimilarities, significantly\nreducing computational overhead. Our framework integrates differentiable stress\noptimization with stochastic gradient descent (SGD), supporting multi-criteria\nlayout objectives. Experimental results demonstrate that our method produces\nhigh-quality, semantically meaningful layouts while efficiently scaling to\nlarge graphs. Code available at: https://github.com/mlyann/graphv_nn", "published": "2025-09-22 03:09:55", "link": "http://arxiv.org/abs/2509.17333v1", "categories": ["cs.CG", "cs.LG"], "primary_category": "cs.CG"}
{"title": "DiffQ: Unified Parameter Initialization for Variational Quantum Algorithms via Diffusion Models", "abstract": "Variational Quantum Algorithms (VQAs) are widely used in the noisy\nintermediate-scale quantum (NISQ) era, but their trainability and performance\ndepend critically on initialization parameters that shape the optimization\nlandscape. Existing machine learning-based initializers achieve\nstate-of-the-art results yet remain constrained to single-task domains and\nsmall datasets of only hundreds of samples. We address these limitations by\nreformulating VQA parameter initialization as a generative modeling problem and\nintroducing DiffQ, a parameter initializer based on the Denoising Diffusion\nProbabilistic Model (DDPM). To support robust training and evaluation, we\nconstruct a dataset of 15,085 instances spanning three domains and five\nrepresentative tasks. Experiments demonstrate that DiffQ surpasses baselines,\nreducing initial loss by up to 8.95 and convergence steps by up to 23.4%.", "published": "2025-09-22 02:58:25", "link": "http://arxiv.org/abs/2509.17324v1", "categories": ["cs.ET", "cs.LG", "quant-ph"], "primary_category": "cs.ET"}
{"title": "VQEzy: An Open-Source Dataset for Parameter Initialize in Variational Quantum Eigensolvers", "abstract": "Variational Quantum Eigensolvers (VQEs) are a leading class of noisy\nintermediate-scale quantum (NISQ) algorithms, whose performance is highly\nsensitive to parameter initialization. Although recent machine learning-based\ninitialization methods have achieved state-of-the-art performance, their\nprogress has been limited by the lack of comprehensive datasets. Existing\nresources are typically restricted to a single domain, contain only a few\nhundred instances, and lack complete coverage of Hamiltonians, ansatz circuits,\nand optimization trajectories. To overcome these limitations, we introduce\nVQEzy, the first large-scale dataset for VQE parameter initialization. VQEzy\nspans three major domains and seven representative tasks, comprising 12,110\ninstances with full VQE specifications and complete optimization trajectories.\nThe dataset is available online, and will be continuously refined and expanded\nto support future research in VQE optimization.", "published": "2025-09-22 02:54:11", "link": "http://arxiv.org/abs/2509.17322v1", "categories": ["cs.LG", "cs.ET", "quant-ph"], "primary_category": "cs.LG"}
{"title": "An LLM-based Agent Simulation Approach to Study Moral Evolution", "abstract": "The evolution of morality presents a puzzle: natural selection should favor\nself-interest, yet humans developed moral systems promoting altruism. We\naddress this question by introducing a novel Large Language Model (LLM)-based\nagent simulation framework modeling prehistoric hunter-gatherer societies. This\nplatform is designed to probe diverse questions in social evolution, from\nsurvival advantages to inter-group dynamics. To investigate moral evolution, we\ndesigned agents with varying moral dispositions based on the Expanding Circle\nTheory \\citep{singer1981expanding}. We evaluated their evolutionary success\nacross a series of simulations and analyzed their decision-making in specially\ndesigned moral dilemmas. These experiments reveal how an agent's moral\nframework, in combination with its cognitive constraints, directly shapes its\nbehavior and determines its evolutionary outcome. Crucially, the emergent\npatterns echo seminal theories from related domains of social science,\nproviding external validation for the simulations. This work establishes\nLLM-based simulation as a powerful new paradigm to complement traditional\nresearch in evolutionary biology and anthropology, opening new avenues for\ninvestigating the complexities of moral and social evolution.", "published": "2025-09-22 12:43:09", "link": "http://arxiv.org/abs/2509.17703v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Trajectory Encryption Cooperative Salvo Guidance", "abstract": "This paper introduces the concept of trajectory encryption in cooperative\nsimultaneous target interception, wherein heterogeneity in guidance principles\nacross a team of unmanned autonomous systems is leveraged as a strategic design\nfeature. By employing a mix of heterogeneous time-to-go formulations leading to\na cooperative guidance strategy, the swarm of vehicles is able to generate\ndiverse trajectory families. This diversity expands the feasible solution space\nfor simultaneous target interception, enhances robustness under disturbances,\nand enables flexible time-to-go adjustments without predictable detouring. From\nan adversarial perspective, heterogeneity obscures the collective interception\nintent by preventing straightforward prediction of swarm dynamics, effectively\nacting as an encryption layer in the trajectory domain. Simulations demonstrate\nthat the swarm of heterogeneous vehicles is able to intercept a moving target\nsimultaneously from a diverse set of initial engagement configurations.", "published": "2025-09-22 04:10:20", "link": "http://arxiv.org/abs/2509.17341v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Rational methods for abstract semilinear problems without order reduction", "abstract": "Rational methods are intended to time integrate linear homogeneous problems.\nHowever, their scope can be extended so as to cover linear nonhomogeneous\nproblems. In this paper the integration of semilinear problems is considered.\nThe resulting procedure requires the same computational cost than the one of a\nlinked Runge--Kutta method, with the advantage that the order reduction\nphenomenon is avoided. Some numerical illustrations are included showing the\npredicted behaviour of the proposed methods.", "published": "2025-09-22 16:28:33", "link": "http://arxiv.org/abs/2509.17984v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An adaptive Hermite spectral method for the Boltzmann equation", "abstract": "We propose an adaptive Hermite spectral method for the three-dimensional\nvelocity space of the Boltzmann equation guided by a newly developed frequency\nindicator. For the homogeneous problem, the indicator is defined by the\ncontribution of high-order coefficients in the spectral expansion. For the\nnon-homogeneous problem, a Fourier-Hermite scheme is employed, with the\ncorresponding frequency indicator formulated based on distributions across the\nentire spatial domain. The adaptive Hermite method includes scaling and\np-adaptive techniques to dynamically adjust the scaling factor and expansion\norder according to the indicator. Numerical experiments cover both homogeneous\nand non-homogeneous problems in up to three spatial dimensions. Results\ndemonstrate that the scaling adaptive method substantially reduces L2 errors at\nnegligible computational cost, and the p-adaptive method achieves time savings\nof up to 74%.", "published": "2025-09-22 16:27:21", "link": "http://arxiv.org/abs/2509.17981v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Local Characterization of Noise in Iterative Reconstruction of the Generalized Radon Transform", "abstract": "We study noise in iterative reconstruction from discrete noisy data of a\ngeneralized Radon transform in the plane. Our approach builds on Local\nReconstruction Analysis (LRA), a framework for analyzing reconstructions at the\nnative scale. We establish that the rescaled reconstruction error converges in\ndistribution to a zero-mean Gaussian random field with explicitly computable\ncovariance, providing a complete local characterization of noise in iterative\nreconstruction. Numerical experiments show strong agreement with the\ntheoretical predictions. Combined with earlier deterministic results, our\nfindings complete the analysis of iterative reconstruction at the native scale\nwith respect to the two most fundamental limitations: the discreteness of the\ndata and the presence of noise.", "published": "2025-09-22 16:06:11", "link": "http://arxiv.org/abs/2509.17944v1", "categories": ["math.NA", "cs.NA", "44A12, 60G60, 65R32"], "primary_category": "math.NA"}
{"title": "Scott-Vogelius element and iterated penalty method for inhomogeneous Dirichlet boundary conditions", "abstract": "We present quasi-optimal a priori error estimates for general mixed finite\nelement methods to approximate solutions of the Stokes problem subject to\ninhomogeneous Dirichlet boundary conditions. For the Scott-Vogelius element\nthis yields pressure-robust a priori error estimates. Due to the exact\ndivergence constraint, this requires a compatibility condition for the boundary\ndata to hold. A key tool is a modified Fortin operator, capable of preserving\nthis compatibility condition. Furthermore, we analyse the iterated penalty\nmethod, a Uzawa-type algorithm and we show its convergence and asymptotic\npressure robustness. Numerical experiments support the theory and highlight the\nimportance of the compatibility condition and the appropriate treatment of\nnearly singular vertices.", "published": "2025-09-22 15:27:29", "link": "http://arxiv.org/abs/2509.17899v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N30, 65F10, 76D07, 76M10"], "primary_category": "math.NA"}
{"title": "Solving time-fractional diffusion equations with Robin boundary conditions via fractional Hamiltonian boundary value methods", "abstract": "In this paper, we propose a novel numerical scheme for solving\ntime-fractional reaction-diffusion problems with Robin boundary conditions,\nwhere the time derivative is in the Caputo sense of order $\\alpha\\in(0,1)$. The\nexistence and uniqueness of the solution is proved. Our proposed method is\nbased on the spectral collocation method in space and Fractional Hamiltonian\nboundary value methods in time. For the considered spectral collocation method,\nthe basis functions used are not the standard polynomial basis functions, but\nrather adapt to Robin boundary conditions, and the exponential convergence\nproperty is provided. The proposed procedure achieves spectral accuracy in\nspace and is also capable of getting spectral accuracy in time. Some numerical\nexamples are provided to support the theoretical results.", "published": "2025-09-22 13:51:38", "link": "http://arxiv.org/abs/2509.17793v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Schrodingerization based quantum algorithms for the time-fractional heat equation", "abstract": "We develop a quantum algorithm for solving high-dimensional time-fractional\nheat equations. By applying the dimension extension technique from [CS07], the\n$d+1$-dimensional time-fractional equation is reformulated as a local partial\ndifferential equation in $d+2$ dimensions. Through discretization along both\nthe extended and spatial domains, a stable system of ordinary differential\nequations is obtained by a simple change of variables. We propose a quantum\nalgorithm for the resulting semi-discrete problem using the Schrodingerization\napproach from [JLY24a,JLY23,JL24a]. The Schrodingerization technique transforms\ngeneral linear partial and ordinary differential equations into\nSchrodinger-type systems--with unitary evolution, making them suitable for\nquantum simulation. This is accomplished via the warped phase transformation,\nwhich maps the equation into a higher-dimensional space. We provide detailed\nimplementations of this method and conduct a comprehensive complexity analysis,\ndemonstrating up to exponential advantage--with respect to the inverse of the\nmesh size in high dimensions~--~compared to its classical counterparts.\nSpecifically, to compute the solution to time $T$, while the classical method\nrequires at least $\\mathcal{O}(N_t d h^{-(d+0.5)})$ matrix-vector\nmultiplications, where $N_t $ is the number of time steps (which is, for\nexample, $\\mathcal{O}(Tdh^{-2})$ for the forward Euler method), our quantum\nalgorithms requires $\\widetilde{\\mathcal{O}}(T^2d^4 h^{-8})$ queries to the\nblock-encoding input models, with the quantum complexity being independent of\nthe dimension $d$ in terms of the inverse mesh size $h^{-1}$. Numerical\nexperiments are performed to validate our formulation.", "published": "2025-09-22 12:49:58", "link": "http://arxiv.org/abs/2509.17713v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A posteriori existence for the Keller-Segel model via a finite volume scheme", "abstract": "We derive two forms of conditional a posteriori error estimates for a finite\nvolume scheme approximating the parabolic-elliptic Keller-Segel system. The\nestimates control the error in the $L^\\infty(0,T, L^2(\\Omega))$- and\n$L^2(0,T;H^1(\\Omega))$-norm and exhibit linear convergence in the mesh size, as\nobserved in numerical experiments. Crucially, we show that as long as the\ncondition of the error estimate is satisfied a weak solution exits. This means,\nas long as the numerical solution has good properties, we can rigorously infer\nexistence of an exact solution.", "published": "2025-09-22 12:48:16", "link": "http://arxiv.org/abs/2509.17710v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Computational Method for the Inverse Robin Problem with Convergence Rate", "abstract": "The inverse Robin problem covers the determination of the Robin parameter in\nan elliptic partial differential equation posed on a domain $\\Omega$. Given the\nsolution of the Robin problem on a subdomain $\\omega \\subset \\Omega$ together\nwith the elliptic problem's right hand sides, the aim is to solve this inverse\nRobin problem numerically. In this work, a computational method for the\nreconstruction of the Robin parameter inspired by a unique continuation method\nis established. The proposed scheme relies solely on first-order Lagrange\nfinite elements ensuring a straightforward implementation. Under the main\nassumption that the Robin parameter is in a finite dimensional space of\ncontinuously differentiable functions it is shown that the numerical method is\nsecond order convergent in the finite element's mesh size. For noisy data this\nconvergence rate is shown to hold true until the noise term dominates the error\nestimate. Numerical experiments are presented that highlight the feasibility of\nthe Robin parameter reconstruction and that confirm the theoretical convergence\nresults numerically.", "published": "2025-09-22 11:01:48", "link": "http://arxiv.org/abs/2509.17571v1", "categories": ["math.NA", "cs.NA", "65N21, 65N12"], "primary_category": "math.NA"}
{"title": "Robust spectral preconditioning for high-P\u00e9clet number convection-diffusion", "abstract": "We introduce a two-level hybrid restricted additive Schwarz (RAS)\npreconditioner for heterogeneous steady-state convection-diffusion equations at\nhigh P\\'{e}clet numbers. Our construction builds on the multiscale spectral\ngeneralized finite element method (MS-GFEM), wherein the coarse space is\nspanned by locally optimal basis functions obtained from local generalized\neigenproblems on operator-harmonic spaces. Extending the theory of Ma (2025) to\nconvection-diffusion problems in conservation form, we establish exponential\nconvergence of the MS-GFEM approximation. Rewriting MS-GFEM as a RAS-type\niteration, we show for coercive problems that this exponential convergence\nproperty is inherited by the RAS-type iterative method (at least in the\ncontinuous setting). Employed as a preconditioner within the generalized\nminimal residual method (GMRES), the resulting method requires only a few\niterations for high accuracy even with low-dimensional coarse spaces.\n  Through extensive numerical experiments on problems with high-contrast\ndiffusion and non-divergence-free, rotating velocity fields, we demonstrate\nrobustness with respect to the grid P\\'{e}clet number and the number of\nsubdomains (tested up to $10^5$ subdomains), while coarse-space dimensions\nremain small as grid P\\'{e}clet numbers increase. By adapting the coarse space\nand oversampling size, we are able to achieve arbitrarily fast convergence of\npreconditioned GMRES. As an extension, for which we do not have theory yet, we\nshow effectiveness of the method even for indefinite problems and in the\nvanishing-diffusion limit.", "published": "2025-09-22 08:52:03", "link": "http://arxiv.org/abs/2509.17531v1", "categories": ["math.NA", "cs.NA", "65F10, 65N22, 65N55"], "primary_category": "math.NA"}
{"title": "A two-grid method with dispersion matching for finite-element Helmholtz problems", "abstract": "This work is about a new two-level solver for Helmholtz equations discretized\nby finite elements. The method is inspired by two-grid methods for\nfinite-difference Helmholtz problems as well as by previous work on two-level\ndomain-decomposition methods. For the coarse-level discretization, a\ncompact-stencil finite-difference method is used that minimizes dispersion\nerrors. The smoother involves a domain-decomposition solver applied to a\ncomplex-shifted Helmholtz operator. Local Fourier analysis shows the method is\nconvergent if the number of degrees of freedom per wavelength is larger than\nsome lower bound that depends on the order, e.g. more than 8 for order 4. In\nnumerical tests, with problem sizes up to 80 wavelengths, convergence was fast,\nand almost independent of problem size unlike what is observed for conventional\nmethods. Analysis and comparison with dispersion-error data shows that, for\ngood convergence of a two-grid method for Helmholtz problems, it is essential\nthat fine- and coarse-level dispersion relations closely match.", "published": "2025-09-22 08:26:09", "link": "http://arxiv.org/abs/2509.17494v1", "categories": ["math.NA", "cs.NA", "65N55, 65N30"], "primary_category": "math.NA"}
{"title": "FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance", "abstract": "Traditional stochastic control methods in finance rely on simplifying\nassumptions that often fail in real world markets. While these methods work\nwell in specific, well defined scenarios, they underperform when market\nconditions change. We introduce FinFlowRL, a novel framework for financial\nstochastic control that combines imitation learning with reinforcement\nlearning. The framework first pretrains an adaptive meta policy by learning\nfrom multiple expert strategies, then finetunes it through reinforcement\nlearning in the noise space to optimize the generation process. By employing\naction chunking, that is generating sequences of actions rather than single\ndecisions, it addresses the non Markovian nature of financial markets.\nFinFlowRL consistently outperforms individually optimized experts across\ndiverse market conditions.", "published": "2025-09-22 16:17:10", "link": "http://arxiv.org/abs/2509.17964v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Invariance of finite-dimensional realisations of Heath-Jarrow-Morton models under diffusion estimation", "abstract": "We identify all smooth manifolds of curves for Heath-Jarrow-Morton models\nthat are consistent with any tangential diffusion coefficient. In fact, we show\nthat these manifolds cannot be affine but must be of linear-rational type.", "published": "2025-09-22 15:13:18", "link": "http://arxiv.org/abs/2509.17875v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "The randomly distorted Choquet integrals with respect to a G-randomly distorted capacity and risk measures", "abstract": "We study randomly distorted Choquet integrals with respect to a capacity c on\na measurable space ({\\Omega},F), where the capacity c is distorted by a\nG-measurable random distortion function (with G a sub-{\\sigma}-algebra of F).\nWe establish some fundamental properties, including the comonotonic additivity\nof these integrals under suitable assumptions on the underlying capacity space.\nWe provide a representation result for comonotonic additive conditional risk\nmeasures which are monotone with respect to the first-order stochastic\ndominance relation (with respect to the capacity c) in terms of these randomly\ndistorted Choquet integrals. We also present the case where the random\ndistortion functions are concave. In this case, the G-randomly distorted\nChoquet integrals are characterised in terms of comonotonic additive\nconditional risk measures which are monotone with respect to the stop-loss\nstochastic dominance relation (with respect to the capacity c). We provide\nexamples, extending some well-known risk measures in finance and insurance,\nsuch as the Value at Risk and the Average Value at Risk.", "published": "2025-09-22 09:21:23", "link": "http://arxiv.org/abs/2509.17555v1", "categories": ["math.PR", "q-fin.MF", "q-fin.RM"], "primary_category": "math.PR"}
{"title": "Enhanced fill probability estimates in institutional algorithmic bond trading using statistical learning algorithms with quantum computers", "abstract": "The estimation of fill probabilities for trade orders represents a key\ningredient in the optimization of algorithmic trading strategies. It is bound\nby the complex dynamics of financial markets with inherent uncertainties, and\nthe limitations of models aiming to learn from multivariate financial time\nseries that often exhibit stochastic properties with hidden temporal patterns.\nIn this paper, we focus on algorithmic responses to trade inquiries in the\ncorporate bond market and investigate fill probability estimation errors of\ncommon machine learning models when given real production-scale intraday trade\nevent data, transformed by a quantum algorithm running on IBM Heron processors,\nas well as on noiseless quantum simulators for comparison. We introduce a\nframework to embed these quantum-generated data transforms as a decoupled\noffline component that can be selectively queried by models in low-latency\ninstitutional trade optimization settings. A trade execution backtesting method\nis employed to evaluate the fill prediction performance of these models in\nrelation to their input data. We observe a relative gain of up to ~ 34% in\nout-of-sample test scores for those models with access to quantum\nhardware-transformed data over those using the original trading data or\ntransforms by noiseless quantum simulation. These empirical results suggest\nthat the inherent noise in current quantum hardware contributes to this effect\nand motivates further studies. Our work demonstrates the emerging potential of\nquantum computing as a complementary explorative tool in quantitative finance\nand encourages applied industry research towards practical applications in\ntrading.", "published": "2025-09-22 12:51:31", "link": "http://arxiv.org/abs/2509.17715v1", "categories": ["quant-ph", "q-fin.TR"], "primary_category": "quant-ph"}
{"title": "Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis", "abstract": "Tabular Generative Models are often argued to preserve privacy by creating\nsynthetic datasets that resemble training data. However, auditing their\nempirical privacy remains challenging, as commonly used similarity metrics fail\nto effectively characterize privacy risk. Membership Inference Attacks (MIAs)\nhave recently emerged as a method for evaluating privacy leakage in synthetic\ndata, but their practical effectiveness is limited. Numerous attacks exist\nacross different threat models, each with distinct implementations targeting\nvarious sources of privacy leakage, making them difficult to apply\nconsistently. Moreover, no single attack consistently outperforms the others,\nleading to a routine underestimation of privacy risk.\n  To address these issues, we propose a unified, model-agnostic threat\nframework that deploys a collection of attacks to estimate the maximum\nempirical privacy leakage in synthetic datasets. We introduce Synth-MIA, an\nopen-source Python library that streamlines this auditing process through a\nnovel testbed that integrates seamlessly into existing synthetic data\nevaluation pipelines through a Scikit-Learn-like API. Our software implements\n13 attack methods through a Scikit-Learn-like API, designed to enable fast\nsystematic estimation of privacy leakage for practitioners as well as\nfacilitate the development of new attacks and experiments for researchers.\n  We demonstrate our framework's utility in the largest tabular synthesis\nprivacy benchmark to date, revealing that higher synthetic data quality\ncorresponds to greater privacy leakage, that similarity-based privacy metrics\nshow weak correlation with MIA results, and that the differentially private\ngenerator PATEGAN can fail to preserve privacy under such attacks. This\nunderscores the necessity of MIA-based auditing when designing and deploying\nTabular Generative Models.", "published": "2025-09-22 16:53:38", "link": "http://arxiv.org/abs/2509.18014v1", "categories": ["cs.CR", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Bayesian Semi-supervised Inference via a Debiased Modeling Approach", "abstract": "Inference in semi-supervised (SS) settings has gained substantial attention\nin recent years due to increased relevance in modern big-data problems. In a\ntypical SS setting, there is a much larger-sized unlabeled data, containing\nonly observations of predictors, and a moderately sized labeled data containing\nobservations for both an outcome and the set of predictors. Such data naturally\narises when the outcome, unlike the predictors, is costly or difficult to\nobtain. One of the primary statistical objectives in SS settings is to explore\nwhether parameter estimation can be improved by exploiting the unlabeled data.\nWe propose a novel Bayesian method for estimating the population mean in SS\nsettings. The approach yields estimators that are both efficient and optimal\nfor estimation and inference. The method itself has several interesting\nartifacts. The central idea behind the method is to model certain summary\nstatistics of the data in a targeted manner, rather than the entire raw data\nitself, along with a novel Bayesian notion of debiasing. Specifying appropriate\nsummary statistics crucially relies on a debiased representation of the\npopulation mean that incorporates unlabeled data through a flexible nuisance\nfunction while also learning its estimation bias. Combined with careful usage\nof sample splitting, this debiasing approach mitigates the effect of bias due\nto slow rates or misspecification of the nuisance parameter from the posterior\nof the final parameter of interest, ensuring its robustness and efficiency.\nConcrete theoretical results, via Bernstein--von Mises theorems, are\nestablished, validating all claims, and are further supported through extensive\nnumerical studies. To our knowledge, this is possibly the first work on\nBayesian inference in SS settings, and its central ideas also apply more\nbroadly to other Bayesian semi-parametric inference problems.", "published": "2025-09-22 06:49:10", "link": "http://arxiv.org/abs/2509.17385v1", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "On Quantification of Borrowing of Information in Hierarchical Bayesian Models", "abstract": "In this work, we offer a thorough analytical investigation into the role of\nshared hyperparameters in a hierarchical Bayesian model, examining their impact\non information borrowing and posterior inference. Our approach is rooted in a\nnon-asymptotic framework, where observations are drawn from a mixed-effects\nmodel, and a Gaussian distribution is assumed for the true effect generator. We\nconsider a nested hierarchical prior distribution model to capture these\neffects and use the posterior means for Bayesian estimation. To quantify the\neffect of information borrowing, we propose an integrated risk measure relative\nto the true data-generating distribution. Our analysis reveals that the Bayes\nestimator for the model with a deeper hierarchy performs better, provided that\nthe unknown random effects are correlated through a compound symmetric\nstructure. Our work also identifies necessary and sufficient conditions for\nthis model to outperform the one nested within it. We further obtain sufficient\nconditions when the correlation is perturbed. Our study suggests that the model\nwith a deeper hierarchy tends to outperform the nested model unless the true\ndata-generating distribution favors sufficiently independent groups. These\nfindings have significant implications for Bayesian modeling, and we believe\nthey will be of interest to researchers across a wide range of fields.", "published": "2025-09-22 00:48:27", "link": "http://arxiv.org/abs/2509.17301v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Nord-Parl-TTS: Finnish and Swedish TTS Dataset from Parliament Speech", "abstract": "Text-to-speech (TTS) development is limited by scarcity of high-quality,\npublicly available speech data for most languages outside a few high-resource\nlanguages. We present Nord-Parl-TTS, an open TTS dataset for Finnish and\nSwedish based on speech found in the wild. Using recordings of Nordic\nparliamentary proceedings, we extract 900 hours of Finnish and 5090 hours of\nSwedish speech suitable for TTS training. The dataset is built using an adapted\nversion of the Emilia data processing pipeline and includes unified evaluation\nsets to support model development and benchmarking. By offering open,\nlarge-scale data for Finnish and Swedish, Nord-Parl-TTS narrows the resource\ngap in TTS between high- and lower-resourced languages.", "published": "2025-09-22 16:30:26", "link": "http://arxiv.org/abs/2509.17988v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Benchmarking Humans and Machines on Complex Multilingual Speech Understanding Tasks", "abstract": "Auditory attention and selective phase-locking are central to human speech\nunderstanding in complex acoustic scenes and cocktail party settings, yet these\ncapabilities in multilingual subjects remain poorly understood. While machine\nunderstanding of natural speech has advanced in recent years, questions persist\nabout comprehension of overlapped and mixed-channel speech. We propose a\nsystematic paradigm for studying humans and machines in speech\nquestion-answering tasks in multilingual settings with clean and mixed-channel\nspeech. For human listeners, selective attention to a target speaker was\nsignificantly better in their native language (L1) than in their second\nlanguage (L2). For machine listening, speech-based large language models (LLMs)\nmatch or exceed human performance in clean, single-speaker conditions but often\nstruggle to selectively attend in two-speaker settings. These results reveal a\nkey divergence: humans rely on attentional cues that are more streamlined in\ntheir native language, whereas LLMs default to parallel information extraction\nwhich exceed human skills.", "published": "2025-09-22 16:18:05", "link": "http://arxiv.org/abs/2509.17965v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Enhancing the NAO: Extending Capabilities of Legacy Robots for Long-Term Research", "abstract": "Many research groups face challenges when legacy (unsupported) robotic\nplatforms lose manufacturer support and cannot accommodate modern sensing,\nspeech, and interaction capabilities. We present the Enhanced NAO, a\nrevitalized version of Aldebaran's NAO robot that uses upgraded microphones,\nRGB-D and thermal cameras, and additional compute resources in a fully\nself-contained package. This system combines cloud and local models for\nperception and dialogue, while preserving the NAO's expressive body and\nbehaviors. In a pilot validation study, the Enhanced NAO delivered\nsignificantly higher conversational quality and stronger user preference\ncompared to the NAO AI Edition, without increasing response latency. Key\nupgrades, such as beamforming microphones and low-latency audio processing,\nreduced artifacts like self-hearing and improved multi-party separation.\nExpanded visual and thermal sensing established a foundation for future\ninteraction capabilities. Beyond the NAO, our framework provides a\nplatform-agnostic strategy for extending the lifespan and research utility of\nlegacy robots, ensuring they remain valuable tools for human-robot interaction.", "published": "2025-09-22 13:23:15", "link": "http://arxiv.org/abs/2509.17760v1", "categories": ["cs.RO", "cs.HC", "eess.AS"], "primary_category": "cs.RO"}
{"title": "GAN-Based Multi-Microphone Spatial Target Speaker Extraction", "abstract": "Spatial target speaker extraction isolates a desired speaker's voice in\nmulti-speaker environments using spatial information, such as the direction of\narrival (DoA). Although recent deep neural network (DNN)-based discriminative\nmethods have shown significant performance improvements, the potential of\ngenerative approaches, such as generative adversarial networks (GANs), remains\nlargely unexplored for this problem. In this work, we demonstrate that a GAN\ncan effectively leverage both noisy mixtures and spatial information to extract\nand generate the target speaker's speech. By conditioning the GAN on\nintermediate features of a discriminative spatial filtering model in addition\nto DoA, we enable steerable target extraction with high spatial resolution of 5\ndegrees, outperforming state-of-the-art discriminative methods in perceptual\nquality-based objective metrics.", "published": "2025-09-22 13:05:34", "link": "http://arxiv.org/abs/2509.17741v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Comparator Loss: An Ordinal Contrastive Loss to Derive a Severity Score for Speech-based Health Monitoring", "abstract": "Monitoring the progression of neurodegenerative disease has important\napplications in the planning of treatment and the evaluation of future\nmedications. Whereas much of the state-of-the-art in health monitoring from\nspeech has been focused on classifying patients versus healthy controls, or\npredicting real-world health metrics, we propose here a novel measure of\ndisease progression: the severity score. This score is derived from a model\ntrained to minimize what we call the comparator loss. The comparator loss\nensures scores follow an ordering relation, which can be based on diagnosis,\nclinically annotated scores, or simply the chronological order of the\nrecordings. In addition to giving a more detailed picture than a simple\ndiscrete classification, the proposed comparator loss-based system has the\npotential to incorporate information from disparate health metrics, which is\ncritical for making full use of small health-related datasets. We evaluated our\nproposed models based on their ability to affirmatively track the progression\nof patients with motor neuron disease (MND), the correlation of their output\nwith clinical annotations such as ALSFRS-R, as well as their ability to\ndistinguish between subjects with MND and healthy controls.", "published": "2025-09-22 12:03:58", "link": "http://arxiv.org/abs/2509.17661v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Audiobook-CC: Controllable Long-context Speech Generation for Multicast Audiobook", "abstract": "Existing text-to-speech systems predominantly focus on single-sentence\nsynthesis and lack adequate contextual modeling as well as fine-grained\nperformance control capabilities for generating coherent multicast audiobooks.\nTo address these limitations, we propose a context-aware and emotion\ncontrollable speech synthesis framework specifically engineered for multicast\naudiobooks with three key innovations: a context mechanism for contextual\nconsistency, a disentanglement paradigm to decouple style control from speech\nprompts for semantic consistency, and self-distillation to boost emotional\nexpressiveness and instruction controllability. Experimental results show\nsuperior performance across the generation of narration, dialogue, and the\nwhole chapter, significantly outperforming existing baselines. Ablation studies\nare conducted to validate the effectiveness of our proposed methods. Demo\nsamples can be found in https://everest-ai.github.io/.", "published": "2025-09-22 08:42:12", "link": "http://arxiv.org/abs/2509.17516v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "FUN-SSL: Full-band Layer Followed by U-Net with Narrow-band Layers for Multiple Moving Sound Source Localization", "abstract": "Dual-path processing along the temporal and spectral dimensions has shown to\nbe effective in various speech processing applications. While the sound source\nlocalization (SSL) models utilizing dual-path processing such as the FN-SSL and\nIPDnet demonstrated impressive performances in localizing multiple moving\nsources, they require significant amount of computation. In this paper, we\npropose an architecture for SSL which introduces a U-Net to perform narrow-band\nprocessing in multiple resolutions to reduce computational complexity. The\nproposed model replaces the full-narrow network block in the IPDnet consisting\nof one full-band LSTM layer along the spectral dimension followed by one\nnarrow-band LSTM layer along the temporal dimension with the FUN block composed\nof one Full-band layer followed by a U-net with Narrow-band layers in multiple\nscales. On top of the skip connections within each U-Net, we also introduce the\nskip connections between FUN blocks to enrich information. Experimental results\nshowed that the proposed FUN-SSL outperformed previously proposed approaches\nwith computational complexity much lower than that of the IPDnet.", "published": "2025-09-22 08:19:16", "link": "http://arxiv.org/abs/2509.17490v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Neural acoustic multipole splatting for room impulse response synthesis", "abstract": "Room Impulse Response (RIR) prediction at arbitrary receiver positions is\nessential for practical applications such as spatial audio rendering. We\npropose Neural Acoustic Multipole Splatting (NAMS), which synthesizes RIRs at\nunseen receiver positions by learning the positions of neural acoustic\nmultipoles and predicting their emitted signals and directivities using a\nneural network. Representing sound fields through a combination of multipoles\noffers sufficient flexibility to express complex acoustic scenes while adhering\nto physical constraints such as the Helmholtz equation. We also introduce a\npruning strategy that starts from a dense splatting of neural acoustic\nmultipoles and progressively eliminates redundant ones during training.\nExperiments conducted on both real and synthetic datasets indicate that the\nproposed method surpasses previous approaches on most metrics while maintaining\nrapid inference. Ablation studies reveal that multipole splatting with pruning\nachieves better performance than the monopole model with just 20% of the poles.", "published": "2025-09-22 07:03:33", "link": "http://arxiv.org/abs/2509.17410v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Active Learning for Melody Estimation by Disentangling Uncertainties", "abstract": "Estimating the fundamental frequency, or melody, is a core task in Music\nInformation Retrieval (MIR). Various studies have explored signal processing,\nmachine learning, and deep-learning-based approaches, with a very recent focus\non utilizing uncertainty in active learning settings for melody estimation.\nHowever, these approaches do not investigate the relative effectiveness of\ndifferent uncertainties. In this work, we follow a framework that disentangles\naleatoric and epistemic uncertainties to guide active learning for melody\nestimation. Trained on a source dataset, our model adapts to new domains using\nonly a small number of labeled samples. Experimental results demonstrate that\nepistemic uncertainty is more reliable for domain adaptation with reduced\nlabeling effort as compared to aleatoric uncertainty.", "published": "2025-09-22 06:34:07", "link": "http://arxiv.org/abs/2509.17375v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "RadarSFD: Single-Frame Diffusion with Pretrained Priors for Radar Point Clouds", "abstract": "Millimeter-wave radar provides perception robust to fog, smoke, dust, and low\nlight, making it attractive for size, weight, and power constrained robotic\nplatforms. Current radar imaging methods, however, rely on synthetic aperture\nor multi-frame aggregation to improve resolution, which is impractical for\nsmall aerial, inspection, or wearable systems. We present RadarSFD, a\nconditional latent diffusion framework that reconstructs dense LiDAR-like point\nclouds from a single radar frame without motion or SAR. Our approach transfers\ngeometric priors from a pretrained monocular depth estimator into the diffusion\nbackbone, anchors them to radar inputs via channel-wise latent concatenation,\nand regularizes outputs with a dual-space objective combining latent and\npixel-space losses. On the RadarHD benchmark, RadarSFD achieves 35 cm Chamfer\nDistance and 28 cm Modified Hausdorff Distance, improving over the single-frame\nRadarHD baseline (56 cm, 45 cm) and remaining competitive with multi-frame\nmethods using 5-41 frames. Qualitative results show recovery of fine walls and\nnarrow gaps, and experiments across new environments confirm strong\ngeneralization. Ablation studies highlight the importance of pretrained\ninitialization, radar BEV conditioning, and the dual-space loss. Together,\nthese results establish the first practical single-frame, no-SAR mmWave radar\npipeline for dense point cloud perception in compact robotic systems.", "published": "2025-09-22 17:49:00", "link": "http://arxiv.org/abs/2509.18068v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Bridge Micro-Deformation Monitoring Scheme with Integrated Sensing and Communications", "abstract": "In this paper, we propose a novel integrated sensing and communications\n(ISAC) scheme to perform bridge micro-deformation monitoring (BMDM) in complex\nenvironments. We first provide an excitation-bridge coupling model to represent\nthe micro-deformation process of the bridge. Next, we design a novel frame\nstructure for BMDM applications, and construct the OFDM echo channel model for\nbasic scene of BMDM, including micro-deformation, dynamic objects, and static\nenvironment. Then, we develop a phasor statistical analysis method based on\naverage cancellation algorithm to suppress the interference of dynamic objects,\nas well as a circle fitting method based on least squares algorithm to remove\nthe interference of static environment near the monitoring area. Furthermore,\nwe extract the micro-deformation feature vector from the OFDM echo signals\nafter inverse discrete fourier transform (IDFT), and derive vertical\nmicro-deformation value with the time-frequency phase resources. Simulation\nresults demonstrate the effectiveness of the proposed BMDM scheme and its\nrobustness against both dynamic interferences and static interferences.", "published": "2025-09-22 16:27:46", "link": "http://arxiv.org/abs/2509.17983v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Autoregressive-Gaussian Mixture Models: Efficient Generative Modeling of WSS Signals", "abstract": "This work addresses the challenge of making generative models suitable for\nresource-constrained environments like mobile wireless communication systems.\nWe propose a generative model that integrates Autoregressive (AR)\nparameterization into a Gaussian Mixture Model (GMM) for modeling Wide-Sense\nStationary (WSS) processes. By exploiting model-based insights allowing for\nstructural constraints, the approach significantly reduces parameters while\nmaintaining high modeling accuracy. Channel estimation experiments show that\nthe model can outperform standard GMMs and variants using Toeplitz or circulant\ncovariances, particularly with small sample sizes. For larger datasets, it\nmatches the performance of conventional methods while improving computational\nefficiency and reducing the memory requirements.", "published": "2025-09-22 16:10:39", "link": "http://arxiv.org/abs/2509.17953v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Pilot Allocation and Sequence Design for MIMO-OFDM Systems With Channel Sparsity", "abstract": "This paper proposes a joint optimization of pilot subcarrier allocation and\nnon-orthogonal sequence for multiple-input-multiple-output (MIMO)-orthogonal\nfrequency-division multiplexing (OFDM) systems under compressed sensing\n(CS)-based channel estimation exploiting delay and angle sparsity. Since the\nperformance of CS-based approaches depends on a coherence metric of the sensing\nmatrix in the measurement process, we formulate a joint optimization problem to\nminimize this coherence. Due to the discrete nature of subcarrier allocation, a\nstraightforward formulation of the joint optimization results in a\nmixed-integer nonlinear program (MINLP), which is computationally intractable\ndue to the combinatorial explosion of allocation candidates. To overcome the\nintractability of discrete variables, we introduce a block sparse penalty for\npilots across all subcarriers, which ensures that the power of some unnecessary\npilots approaches zero. This framework enables joint optimization using only\ncontinuous variables. In addition, we propose an efficient computation method\nfor the coherence metric by exploiting the structure of the sensing matrix,\nwhich allows its gradient to be derived in closed form, making the joint\noptimization problem solvable in an efficient way via a gradient descent\napproach. Numerical results confirm that the proposed pilot sequence exhibits\nsuperior coherence properties and enhances the CS-based channel estimation\nperformance.", "published": "2025-09-22 15:39:48", "link": "http://arxiv.org/abs/2509.17916v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generalized Beyond-Diagonal RIS Architectures: Theory and Design via Structure-oriented Symmetric Unitary Projection", "abstract": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS), which enables\nadvanced wave control through interconnection of RIS elements, are gaining\ngrowing recognition as a promising technology for 6G and beyond. However, the\nenhanced flexibility of BD-RIS in controlling the phase and amplitude of\nreflected signals comes at the cost of high circuit complexity. In this paper,\nwe propose two novel BD-RIS architectures, namely, the stem-connected RIS and\ncluster-connected RIS, to explore trade-off between circuit complexity and\nperformance. Specifically, the proposed stem-connected RIS is capable of\nachieving the same performance as fully-connected RIS while significantly\nreducing circuit complexity. The proposed cluster-connected RIS offers a\nunified framework that generalizes existing BD-RIS architectures--including\nsingle-connected, fully-connected, group-connected, tree-connected (arrowhead),\nand forest-connected (arrowhead) RISs--as special cases. This framework enables\na much more flexible trade-offs between circuit complexity and system\nperformance than existing ones. Based on the proposed BD-RIS architectures, we\nintroduce a novel and generalized structure-oriented symmetric unitary\nprojection method for designing the scattering matrix across all BD-RIS\nconfigurations. This method is effectively applied to solve the sum channel\ngain maximization problem and other utility-based optimization problems.\nNumerical results demonstrate that the proposed stem-connected RIS is the\nsimplest architecture that achieves optimal BD-RIS performance, while the\ncluster-connected RIS further enlarges the performance-complexity trade-off\nrange. Furthermore, the proposed projection-based algorithms demonstrate high\nefficiency.", "published": "2025-09-22 14:00:00", "link": "http://arxiv.org/abs/2509.17804v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SSNet: Flexible and robust channel extrapolation for fluid antenna systems enabled by an self-supervised learning framework", "abstract": "Fluid antenna systems (FAS) signify a pivotal advancement in 6G communication\nby enhancing spectral efficiency and robustness. However, obtaining accurate\nchannel state information (CSI) in FAS poses challenges due to its complex\nphysical structure. Traditional methods, such as pilot-based interpolation and\ncompressive sensing, are not only computationally intensive but also lack\nadaptability. Current extrapolation techniques relying on rigid parametric\nmodels do not accommodate the dynamic environment of FAS, while data-driven\ndeep learning approaches demand extensive training and are vulnerable to noise\nand hardware imperfections. To address these challenges, this paper introduces\na novel self-supervised learning network (SSNet) designed for efficient and\nadaptive channel extrapolation in FAS. We formulate the problem of channel\nextrapolation in FAS as an image reconstruction task. Here, a limited number of\nunmasked pixels (representing the known CSI of the selected ports) are used to\nextrapolate the masked pixels (the CSI of unselected ports). SSNet capitalizes\non the intrinsic structure of FAS channels, learning generalized\nrepresentations from raw CSI data, thus reducing dependency on large labelled\ndatasets. For enhanced feature extraction and noise resilience, we propose a\nmix-of-expert (MoE) module. In this setup, multiple feedforward neural networks\n(FFNs) operate in parallel. The outputs of the MoE module are combined using a\nweighted sum, determined by a gating function that computes the weights of each\nFFN using a softmax function. Extensive simulations validate the superiority of\nthe proposed model. Results indicate that SSNet significantly outperforms\nbenchmark models, such as AGMAE and long short-term memory (LSTM) networks by\nusing a much smaller labelled dataset.", "published": "2025-09-22 13:52:49", "link": "http://arxiv.org/abs/2509.17797v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Minimization of Nonsmooth Weakly Convex Function over Prox-regular Set for Robust Low-rank Matrix Recovery", "abstract": "We propose a prox-regular-type low-rank constrained nonconvex nonsmooth\noptimization model for Robust Low-Rank Matrix Recovery (RLRMR), i.e., estimate\nproblem of low-rank matrix from an observed signal corrupted by outliers. For\nRLRMR, the $\\ell_{1}$-norm has been utilized as a convex loss to detect\noutliers as well as to keep tractability of optimization models. Nevertheless,\nthe $\\ell_{1}$-norm is not necessarily an ideal robust loss because the\n$\\ell_{1}$-norm tends to overpenalize entries corrupted by outliers of large\nmagnitude. In contrast, the proposed model can employ a weakly convex function\nas a more robust loss, against outliers, than the $\\ell_{1}$-norm. For the\nproposed model, we present (i) a projected variable smoothing-type algorithm\napplicable for the minimization of a nonsmooth weakly convex function over a\nprox-regular set, and (ii) a convergence analysis of the proposed algorithm in\nterms of stationary point. Numerical experiments demonstrate the effectiveness\nof the proposed model compared with the existing models that employ the\n$\\ell_{1}$-norm.", "published": "2025-09-22 09:08:35", "link": "http://arxiv.org/abs/2509.17549v1", "categories": ["math.OC", "eess.SP"], "primary_category": "math.OC"}
{"title": "Single-Snapshot Localization Using Sparse Extremely Large Aperture Arrays", "abstract": "This paper investigates single-snapshot direction-of-arrival (DOA) estimation\nand target localization with coherent sparse extremely large aperture arrays\n(ELAAs) in automotive radar applications. Far-field and near-field signal\nmodels are formulated for distributed bistatic configurations. To enable\nnoncoherent processing, a single-snapshot MUSIC (SS-MUSIC) algorithm is\nproposed to fuse local spectra from individual subarrays and extended to\nnear-field localization via geometric intersection. For coherent processing, a\nsingle-snapshot ESPRIT (SS-ESPRIT) method with ambiguity dealiasing is\ndeveloped to fully exploit the aperture of sparse ELAAs for high-resolution\nangle estimation. Simulation results demonstrate that SS-ESPRIT provides\nsuperior angular resolution for closely spaced far-field targets, while\nSS-MUSIC offers robustness in near-field localization and flexibility in hybrid\nscenarios.", "published": "2025-09-22 08:37:20", "link": "http://arxiv.org/abs/2509.17511v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On the Design of Capacity-Achieving Distributions for Discrete-Time Poisson Channel with Low-Precision ADCs", "abstract": "This paper investigates the design of the capacity-achieving input\ndistribution for the discrete-time Poisson channel (DTPC) under dark current\neffects with low-precision analog-to-digital converters (ADCs). This study\nintroduces an efficient optimization algorithm that integrates the\nNewton-Raphson and Blahut-Arimoto (BA) methods to determine the\ncapacity-achieving input distribution and the corresponding amplitudes of input\nmass points for the DTPC, subject to both peak and average power constraints.\nAdditionally, the Karush-Kuhn-Tucker (KKT) conditions are established to\nprovide necessary and sufficient conditions for the optimality of the obtained\ncapacity-achieving distribution. Simulation results illustrate that the\nproposed algorithm attains $72\\%$ and $83\\%$ of the theoretical capacity at 5\ndB for 1-bit and 2-bit quantized DTPC, respectively. Furthermore, for a\nfinite-precision quantized DTPC (i.e., ${\\log _2}K$ bits), the capacity can be\nachieved by a non-uniform discrete input distribution with support for $K$ mass\npoints, under the given power constraints.", "published": "2025-09-22 08:16:33", "link": "http://arxiv.org/abs/2509.17483v1", "categories": ["eess.SP", "cs.PF"], "primary_category": "eess.SP"}
{"title": "On Mutual Information Neural Estimation for Localization", "abstract": "Mutual information (MI) is a promising candidate measure for the assessment\nand optimization of localization systems, as it captures nonlinear dependencies\nbetween random variables. However, the high cost of computing MI, especially\nfor high-dimensional problems, prohibits its application for many real-world\nlocalization systems. We evaluate an algorithm from a new class of neural MI\nestimators called Mutual Information Neural Estimation (MINE) to approximate\nthe MI between the set of feasible user element (UE) locations and the\ncorresponding set of measurements from said UE locations used for positioning.\nWe apply this estimator to a simulated multilateration (MLAT) system, where the\ntrue MI for benchmarking can be approximated by Monte Carlo simulation. The\nestimator is experimentally evaluated w.r.t. its convergence and consistency\nand we investigate the usefulness of MI for assessing simple MLAT systems.", "published": "2025-09-22 04:17:11", "link": "http://arxiv.org/abs/2509.17344v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physics-Informed Operator Learning for Hemodynamic Modeling", "abstract": "Accurate modeling of personalized cardiovascular dynamics is crucial for\nnon-invasive monitoring and therapy planning. State-of-the-art physics-informed\nneural network (PINN) approaches employ deep, multi-branch architectures with\nadversarial or contrastive objectives to enforce partial differential equation\nconstraints. While effective, these enhancements introduce significant training\nand implementation complexity, limiting scalability and practical deployment.\nWe investigate physics-informed neural operator learning models as efficient\nsupervisory signals for training simplified architectures through knowledge\ndistillation. Our approach pre-trains a physics-informed DeepONet (PI-DeepONet)\non high-fidelity cuffless blood pressure recordings to learn operator mappings\nfrom raw wearable waveforms to beat-to-beat pressure signals under embedded\nphysics constraints. This pre-trained operator serves as a frozen supervisor in\na lightweight knowledge-distillation pipeline, guiding streamlined base models\nthat eliminate complex adversarial and contrastive learning components while\nmaintaining performance. We characterize the role of physics-informed\nregularization in operator learning and demonstrate its effectiveness for\nsupervisory guidance. Through extensive experiments, our operator-supervised\napproach achieves performance parity with complex baselines (correlation: 0.766\nvs. 0.770, RMSE: 4.452 vs. 4.501), while dramatically reducing architectural\ncomplexity from eight critical hyperparameters to a single regularization\ncoefficient and decreasing training overhead by 4%. Our results demonstrate\nthat operator-based supervision effectively replaces intricate multi-component\ntraining strategies, offering a more scalable and interpretable approach to\nphysiological modeling with reduced implementation burden.", "published": "2025-09-22 00:24:44", "link": "http://arxiv.org/abs/2509.17293v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation", "abstract": "Generation of Artificial Intelligence (AI) texts in important works has\nbecome a common practice that can be used to misuse and abuse AI at various\nlevels. Traditional AI detectors often rely on document-level classification,\nwhich struggles to identify AI content in hybrid or slightly edited texts\ndesigned to avoid detection, leading to concerns about the model's efficiency,\nwhich makes it hard to distinguish between human-written and AI-generated\ntexts. A sentence-level sequence labeling model proposed to detect transitions\nbetween human- and AI-generated text, leveraging nuanced linguistic signals\noverlooked by document-level classifiers. By this method, detecting and\nsegmenting AI and human-written text within a single document at the\ntoken-level granularity is achieved. Our model combines the state-of-the-art\npre-trained Transformer models, incorporating Neural Networks (NN) and\nConditional Random Fields (CRFs). This approach extends the power of\ntransformers to extract semantic and syntactic patterns, and the neural network\ncomponent to capture enhanced sequence-level representations, thereby improving\nthe boundary predictions by the CRF layer, which enhances sequence recognition\nand further identification of the partition between Human- and AI-generated\ntexts. The evaluation is performed on two publicly available benchmark datasets\ncontaining collaborative human and AI-generated texts. Our experimental\ncomparisons are with zero-shot detectors and the existing state-of-the-art\nmodels, along with rigorous ablation studies to justify that this approach, in\nparticular, can accurately detect the spans of AI texts in a completely\ncollaborative text. All our source code and the processed datasets are\navailable in our GitHub repository.", "published": "2025-09-22 14:22:55", "link": "http://arxiv.org/abs/2509.17830v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking Token Into Concepts: Exploring Extreme Compression in Token Representation Via Compositional Shared Semantics", "abstract": "Standard language models employ unique, monolithic embeddings for each token,\npotentially limiting their ability to capture the multifaceted nature of word\nmeanings. We investigate whether tokens can be more effectively represented\nthrough a compositional structure that accumulates diverse semantic facets. To\nexplore this, we propose Aggregate Semantic Grouping (ASG), a novel approach\nleveraging Product Quantization (PQ). We apply ASG to standard transformer\narchitectures (mBERT, XLM-R, mT5) and evaluate this representational scheme\nacross diverse tasks (NLI, NER, QA), as well as a biomedical domain-specific\nbenchmark (BC5CDR) using BioBERT. Our findings demonstrate that representing\ntokens compositionally via ASG achieves extreme compression in embedding\nparameters (0.4--0.5\\%) while maintaining $>$95\\% task performance relative to\nthe base model, even in generative tasks and extends to both cross lingual\ntransfer and domain-specific settings. These results validate the principle\nthat tokens can be effectively modeled as combinations of shared semantic\nbuilding blocks. ASG offers a simple yet concrete method for achieving this,\nshowcasing how compositional representations can capture linguistic richness\nwhile enabling compact yet semantically rich models.", "published": "2025-09-22 13:04:48", "link": "http://arxiv.org/abs/2509.17737v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models", "abstract": "The demand for efficient deployment of large language models (LLMs) has\ndriven interest in quantization, which reduces inference cost, and\nparameter-efficient fine-tuning (PEFT), which lowers training overhead. This\nmotivated the development of quantization-aware PEFT to produce accurate yet\nefficient quantized models. In this setting, reducing quantization error prior\nto fine-tuning is crucial for achieving high model accuracy. However, existing\nmethods that rely on low-rank adaptation suffer from limited representational\ncapacity. Recent Fourier-related transform (FT)-based adapters offer greater\nrepresentational power than low-rank adapters, but their direct integration\ninto quantized models often results in ineffective error reduction and\nincreased computational overhead. To overcome these limitations, we propose\nQWHA, a method that integrates FT-based adapters into quantized models by\nemploying the Walsh-Hadamard Transform (WHT) as the transform kernel, together\nwith a novel adapter initialization scheme incorporating adaptive parameter\nselection and value refinement. We demonstrate that QWHA effectively mitigates\nquantization errors while facilitating fine-tuning, and that its design\nsubstantially reduces computational cost. Experimental results show that QWHA\nconsistently outperforms baselines in low-bit quantization accuracy and\nachieves significant training speedups over existing FT-based adapters. The\ncode is available at https://github.com/vantaa89/qwha.", "published": "2025-09-22 07:21:41", "link": "http://arxiv.org/abs/2509.17428v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Program Synthesis via Test-Time Transduction", "abstract": "We introduce transductive program synthesis, a new formulation of the program\nsynthesis task that explicitly leverages test inputs during synthesis. While\nprior approaches to program synthesis--whether based on natural language\ndescriptions or input-output examples--typically aim to generalize from\ntraining examples, they often struggle with robustness, especially in\nreal-world settings where training examples are limited and test inputs involve\nvarious edge cases. To address this, we propose a novel framework that improves\nrobustness by treating synthesis as an active learning over a finite hypothesis\nclass defined by programs' outputs. We use an LLM to predict outputs for\nselected test inputs and eliminate inconsistent hypotheses, where the inputs\nare chosen via a greedy maximin algorithm to minimize the number of LLM queries\nrequired. We evaluate our approach on four benchmarks: Playgol, MBPP+, 1D-ARC,\nand programmatic world modeling on MiniGrid. We demonstrate that our method\nsignificantly improves program synthesis in both accuracy and efficiency. We\nrelease our code at https://github.com/klee972/SYNTRA.", "published": "2025-09-22 06:53:32", "link": "http://arxiv.org/abs/2509.17393v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Narcissus Hypothesis: Descending to the Rung of Illusion", "abstract": "Modern foundational models increasingly reflect not just world knowledge, but\npatterns of human preference embedded in their training data. We hypothesize\nthat recursive alignment-via human feedback and model-generated corpora-induces\na social desirability bias, nudging models to favor agreeable or flattering\nresponses over objective reasoning. We refer to it as the Narcissus Hypothesis\nand test it across 31 models using standardized personality assessments and a\nnovel Social Desirability Bias score. Results reveal a significant drift toward\nsocially conforming traits, with profound implications for corpus integrity and\nthe reliability of downstream inferences. We then offer a novel epistemological\ninterpretation, tracing how recursive bias may collapse higher-order reasoning\ndown Pearl's Ladder of Causality, culminating in what we refer to as the Rung\nof Illusion.", "published": "2025-09-22 16:39:22", "link": "http://arxiv.org/abs/2509.17999v2", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs", "abstract": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of\nthe Gaussian process (GP) kernel, which plays a central role in balancing\nexploration and exploitation under limited evaluation budgets. Traditional BO\nmethods often rely on fixed or heuristic kernel selection strategies, which can\nresult in slow convergence or suboptimal solutions when the chosen kernel is\npoorly suited to the underlying objective function. To address this limitation,\nwe propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO\nwith large language models (LLMs). Concretely, CAKE leverages LLMs as the\ncrossover and mutation operators to adaptively generate and refine GP kernels\nbased on the observed data throughout the optimization process. To maximize the\npower of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to\nselect the most effective kernel through balancing the model fit measured by\nthe Bayesian information criterion (BIC) with the expected improvement at each\niteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO\nmethod consistently outperforms established baselines across a range of\nreal-world tasks, including hyperparameter optimization, controller tuning, and\nphotonic chip design. Our code is publicly available at\nhttps://github.com/richardcsuwandi/cake.", "published": "2025-09-22 16:39:12", "link": "http://arxiv.org/abs/2509.17998v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Joint Memory Frequency and Computing Frequency Scaling for Energy-efficient DNN Inference", "abstract": "Deep neural networks (DNNs) have been widely applied in diverse applications,\nbut the problems of high latency and energy overhead are inevitable on\nresource-constrained devices. To address this challenge, most researchers focus\non the dynamic voltage and frequency scaling (DVFS) technique to balance the\nlatency and energy consumption by changing the computing frequency of\nprocessors. However, the adjustment of memory frequency is usually ignored and\nnot fully utilized to achieve efficient DNN inference, which also plays a\nsignificant role in the inference time and energy consumption. In this paper,\nwe first investigate the impact of joint memory frequency and computing\nfrequency scaling on the inference time and energy consumption with a\nmodel-based and data-driven method. Then by combining with the fitting\nparameters of different DNN models, we give a preliminary analysis for the\nproposed model to see the effects of adjusting memory frequency and computing\nfrequency simultaneously. Finally, simulation results in local inference and\ncooperative inference cases further validate the effectiveness of jointly\nscaling the memory frequency and computing frequency to reduce the energy\nconsumption of devices.", "published": "2025-09-22 16:20:29", "link": "http://arxiv.org/abs/2509.17970v2", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling", "abstract": "Test-time scaling (TTS) has been shown to improve the performance of large\nlanguage models (LLMs) by sampling and aggregating diverse reasoning paths.\nHowever, existing research has overlooked a critical issue: selection bias of\nreasoning strategies during scaling. Specifically, when generating reasoning\nprocesses, LLMs tend to follow certain strategies (e.g., algebraic solutions\nfor math problems) while neglecting other valid alternatives (e.g., geometric\nsolutions), resulting in insufficient exploration of the solution space. To\nfurther understand the impact of this bias, we present a theoretical analysis\nthat reveals when it undermines the effectiveness of test-time scaling.\nMotivated by this theoretical insight, we introduce TTS-Uniform, a framework\ndesigned to mitigate the selection bias of reasoning strategies. It (i)\nidentifies potential strategies, (ii) uniformly allocates the sampling budget\nacross them, and (iii) filters out unstable strategies prior to aggregation.\nExperimental results show that TTS-Uniform significantly enhances scaling\neffectiveness across multiple mainstream LLMs and benchmark datasets.", "published": "2025-09-22 15:30:56", "link": "http://arxiv.org/abs/2509.17905v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Virtual Arc Consistency for Linear Constraints in Cost Function Networks", "abstract": "In Constraint Programming, solving discrete minimization problems with hard\nand soft constraints can be done either using (i) soft global constraints, (ii)\na reformulation into a linear program, or (iii) a reformulation into local cost\nfunctions. Approach (i) benefits from a vast catalog of constraints. Each soft\nconstraint propagator communicates with other soft constraints only through the\nvariable domains, resulting in weak lower bounds. Conversely, the approach (ii)\nprovides a global view with strong bounds, but the size of the reformulation\ncan be problematic. We focus on approach (iii) in which soft arc consistency\n(SAC) algorithms produce bounds of intermediate quality. Recently, the\nintroduction of linear constraints as local cost functions increases their\nmodeling expressiveness. We adapt an existing SAC algorithm to handle linear\nconstraints. We show that our algorithm significantly improves the lower bounds\ncompared to the original algorithm on several benchmarks, reducing solving time\nin some cases.", "published": "2025-09-22 12:44:52", "link": "http://arxiv.org/abs/2509.17706v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data", "abstract": "The increasing availability of open Earth Observation (EO) and agricultural\ndatasets holds great potential for supporting sustainable land management.\nHowever, their high technical entry barrier limits accessibility for non-expert\nusers. This study presents an open-source conversational assistant that\nintegrates multimodal retrieval and large language models (LLMs) to enable\nnatural language interaction with heterogeneous agricultural and geospatial\ndata. The proposed architecture combines orthophotos, Sentinel-2 vegetation\nindices, and user-provided documents through retrieval-augmented generation\n(RAG), allowing the system to flexibly determine whether to rely on multimodal\nevidence, textual knowledge, or both in formulating an answer. To assess\nresponse quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a\nzero-shot, unsupervised setting, applying direct scoring in a multi-dimensional\nquantitative evaluation framework. Preliminary results show that the system is\ncapable of generating clear, relevant, and context-aware responses to\nagricultural queries, while remaining reproducible and scalable across\ngeographic regions. The primary contributions of this work include an\narchitecture for fusing multimodal EO and textual knowledge sources, a\ndemonstration of lowering the barrier to access specialized agricultural\ninformation through natural language interaction, and an open and reproducible\ndesign.", "published": "2025-09-22 09:02:53", "link": "http://arxiv.org/abs/2509.17544v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multimodal Medical Image Classification via Synergistic Learning Pre-training", "abstract": "Multimodal pathological images are usually in clinical diagnosis, but\ncomputer vision-based multimodal image-assisted diagnosis faces challenges with\nmodality fusion, especially in the absence of expert-annotated data. To achieve\nthe modality fusion in multimodal images with label scarcity, we propose a\nnovel ``pretraining + fine-tuning\" framework for multimodal semi-supervised\nmedical image classification. Specifically, we propose a synergistic learning\npretraining framework of consistency, reconstructive, and aligned learning. By\ntreating one modality as an augmented sample of another modality, we implement\na self-supervised learning pre-train, enhancing the baseline model's feature\nrepresentation capability. Then, we design a fine-tuning method for multimodal\nfusion. During the fine-tuning stage, we set different encoders to extract\nfeatures from the original modalities and provide a multimodal fusion encoder\nfor fusion modality. In addition, we propose a distribution shift method for\nmultimodal fusion features, which alleviates the prediction uncertainty and\noverfitting risks caused by the lack of labeled samples. We conduct extensive\nexperiments on the publicly available gastroscopy image datasets Kvasir and\nKvasirv2. Quantitative and qualitative results demonstrate that the proposed\nmethod outperforms the current state-of-the-art classification methods. The\ncode will be released at: https://github.com/LQH89757/MICS.", "published": "2025-09-22 08:21:19", "link": "http://arxiv.org/abs/2509.17492v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MVCL-DAF++: Enhancing Multimodal Intent Recognition via Prototype-Aware Contrastive Alignment and Coarse-to-Fine Dynamic Attention Fusion", "abstract": "Multimodal intent recognition (MMIR) suffers from weak semantic grounding and\npoor robustness under noisy or rare-class conditions. We propose MVCL-DAF++,\nwhich extends MVCL-DAF with two key modules: (1) Prototype-aware contrastive\nalignment, aligning instances to class-level prototypes to enhance semantic\nconsistency; and (2) Coarse-to-fine attention fusion, integrating global\nmodality summaries with token-level features for hierarchical cross-modal\ninteraction. On MIntRec and MIntRec2.0, MVCL-DAF++ achieves new\nstate-of-the-art results, improving rare-class recognition by +1.05\\% and\n+4.18\\% WF1, respectively. These results demonstrate the effectiveness of\nprototype-guided learning and coarse-to-fine fusion for robust multimodal\nunderstanding. The source code is available at\nhttps://github.com/chr1s623/MVCL-DAF-PlusPlus.", "published": "2025-09-22 07:38:53", "link": "http://arxiv.org/abs/2509.17446v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models", "abstract": "The advancement of diffusion models has enhanced the realism of AI-generated\ncontent but also raised concerns about misuse, necessitating robust copyright\nprotection and tampering localization. Although recent methods have made\nprogress toward unified solutions, their reliance on post hoc processing\nintroduces considerable application inconvenience and compromises forensic\nreliability. We propose StableGuard, a novel framework that seamlessly\nintegrates a binary watermark into the diffusion generation process, ensuring\ncopyright protection and tampering localization in Latent Diffusion Models\nthrough an end-to-end design. We develop a Multiplexing Watermark VAE (MPW-VAE)\nby equipping a pretrained Variational Autoencoder (VAE) with a lightweight\nlatent residual-based adapter, enabling the generation of paired watermarked\nand watermark-free images. These pairs, fused via random masks, create a\ndiverse dataset for training a tampering-agnostic forensic network. To further\nenhance forensic synergy, we introduce a Mixture-of-Experts Guided Forensic\nNetwork (MoE-GFN) that dynamically integrates holistic watermark patterns,\nlocal tampering traces, and frequency-domain cues for precise watermark\nverification and tampered region detection. The MPW-VAE and MoE-GFN are jointly\noptimized in a self-supervised, end-to-end manner, fostering a reciprocal\ntraining between watermark embedding and forensic accuracy. Extensive\nexperiments demonstrate that StableGuard consistently outperforms\nstate-of-the-art methods in image fidelity, watermark verification, and\ntampering localization.", "published": "2025-09-22 16:35:19", "link": "http://arxiv.org/abs/2509.17993v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA", "abstract": "Large language models (LLMs) have shown promise in generating program\nworkflows for visual tasks. However, previous approaches often rely on\nclosed-source models, lack systematic reasoning, and struggle with long-form\nvideo question answering (videoQA). To address these challenges, we introduce\nthe FS-VisPR framework, an adaptive visual program reasoning approach that\nbalances fast reasoning for simple queries with slow reasoning for difficult\nones. First, we design efficient visual modules (e.g., key clip retrieval and\nsubtitle retrieval) to support long-form video tasks. Then, we construct a\ndiverse and high-quality fast-slow reasoning dataset with a strong LLM to align\nopen-source language models' ability to generate visual program workflows as\nFS-LLM. Next, we design a fast-slow reasoning framework with FS-LLM: Simple\nqueries are directly solved by VideoLLMs, while difficult ones invoke visual\nprogram reasoning, motivated by human-like reasoning processes. During this\nprocess, low-confidence fast-thinking answers will trigger a second-stage\nslow-reasoning process, and a fallback mechanism to fast reasoning is activated\nif the program execution fails. Moreover, we improve visual programs through\nparameter search during both training and inference. By adjusting the\nparameters of the visual modules within the program, multiple variants are\ngenerated: during training, programs that yield correct answers are selected,\nwhile during inference, the program with the highest confidence result is\napplied. Experiments show that FS-VisPR improves both efficiency and\nreliability in visual program workflows. It achieves 50.4% accuracy on LVBench,\nsurpassing GPT-4o, matching the performance of Qwen2.5VL-72B on VideoMME.", "published": "2025-09-22 13:06:17", "link": "http://arxiv.org/abs/2509.17743v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Development and validation of an AI foundation model for endoscopic diagnosis of esophagogastric junction adenocarcinoma: a cohort and deep learning study", "abstract": "The early detection of esophagogastric junction adenocarcinoma (EGJA) is\ncrucial for improving patient prognosis, yet its current diagnosis is highly\noperator-dependent. This paper aims to make the first attempt to develop an\nartificial intelligence (AI) foundation model-based method for both screening\nand staging diagnosis of EGJA using endoscopic images. In this cohort and\nlearning study, we conducted a multicentre study across seven Chinese hospitals\nbetween December 28, 2016 and December 30, 2024. It comprises 12,302 images\nfrom 1,546 patients; 8,249 of them were employed for model training, while the\nremaining were divided into the held-out (112 patients, 914 images), external\n(230 patients, 1,539 images), and prospective (198 patients, 1,600 images) test\nsets for evaluation. The proposed model employs DINOv2 (a vision foundation\nmodel) and ResNet50 (a convolutional neural network) to extract features of\nglobal appearance and local details of endoscopic images for EGJA staging\ndiagnosis. Our model demonstrates satisfactory performance for EGJA staging\ndiagnosis across three test sets, achieving an accuracy of 0.9256, 0.8895, and\n0.8956, respectively. In contrast, among representative AI models, the best one\n(ResNet50) achieves an accuracy of 0.9125, 0.8382, and 0.8519 on the three test\nsets, respectively; the expert endoscopists achieve an accuracy of 0.8147 on\nthe held-out test set. Moreover, with the assistance of our model, the overall\naccuracy for the trainee, competent, and expert endoscopists improves from\n0.7035, 0.7350, and 0.8147 to 0.8497, 0.8521, and 0.8696, respectively. To our\nknowledge, our model is the first application of foundation models for EGJA\nstaging diagnosis and demonstrates great potential in both diagnostic accuracy\nand efficiency.", "published": "2025-09-22 12:03:40", "link": "http://arxiv.org/abs/2509.17660v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clothing agnostic Pre-inpainting Virtual Try-ON", "abstract": "With the development of deep learning technology, virtual try-on technology\nhas become an important application value in the fields of e-commerce, fashion,\nand entertainment. The recently proposed Leffa has improved the texture\ndistortion problem of diffu-sion-based models, but there are limitations in\nthat the bottom detection inaccuracy and the existing clothing silhouette\nremain in the synthesis results. To solve this problem, this study proposes\nCaP-VTON (Clothing agnostic Pre-inpainting Virtual Try-ON). CaP-VTON has\nimproved the naturalness and consistency of whole-body clothing syn-thesis by\nintegrating multi-category masking based on Dress Code and skin inpainting\nbased on Stable Diffusion. In particular, a generate skin module was introduced\nto solve the skin restoration problem that occurs when long-sleeved images are\nconverted into short-sleeved or sleeveless ones, and high-quality restoration\nwas implemented consider-ing the human body posture and color. As a result,\nCaP-VTON recorded 92.5%, which is 15.4% better than Leffa in short-sleeved\nsynthesis accuracy, and showed the performance of consistently reproducing the\nstyle and shape of reference clothing in visual evaluation. These structures\nmaintain model-agnostic properties and are applicable to various\ndiffu-sion-based virtual inspection systems, and can contribute to applications\nthat require high-precision virtual wearing, such as e-commerce, custom\nstyling, and avatar creation.", "published": "2025-09-22 11:58:20", "link": "http://arxiv.org/abs/2509.17654v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Instruction Pretraining for Domain-Specific Foundation Models", "abstract": "Modern computer vision is converging on a closed loop in which perception,\nreasoning and generation mutually reinforce each other. However, this loop\nremains incomplete: the top-down influence of high-level reasoning on the\nfoundational learning of low-level perceptual features is not yet\nunderexplored. This paper addresses this gap by proposing a new paradigm for\npretraining foundation models in downstream domains. We introduce Visual\ninsTruction Pretraining (ViTP), a novel approach that directly leverages\nreasoning to enhance perception. ViTP embeds a Vision Transformer (ViT)\nbackbone within a Vision-Language Model and pretrains it end-to-end using a\nrich corpus of visual instruction data curated from target downstream domains.\nViTP is powered by our proposed Visual Robustness Learning (VRL), which compels\nthe ViT to learn robust and domain-relevant features from a sparse set of\nvisual tokens. Extensive experiments on 16 challenging remote sensing and\nmedical imaging benchmarks demonstrate that ViTP establishes new\nstate-of-the-art performance across a diverse range of downstream tasks. The\ncode is available at https://github.com/zcablii/ViTP.", "published": "2025-09-22 10:57:42", "link": "http://arxiv.org/abs/2509.17562v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SimToken: A Simple Baseline for Referring Audio-Visual Segmentation", "abstract": "Referring Audio-Visual Segmentation (Ref-AVS) aims to segment specific\nobjects in videos based on natural language expressions involving audio,\nvision, and text information. This task poses significant challenges in\ncross-modal reasoning and fine-grained object localization. In this paper, we\npropose a simple framework, SimToken, that integrates a multimodal large\nlanguage model (MLLM) with the Segment Anything Model (SAM). The MLLM is guided\nto generate a special semantic token representing the referred object. This\ncompact token, enriched with contextual information from all modalities, acts\nas a prompt to guide SAM to segment objectsacross video frames. To further\nimprove semantic learning, we introduce a novel target-consistent semantic\nalignment loss that aligns token embeddings from different expressions but\nreferring to the same object. Experiments on the Ref-AVS benchmark demonstrate\nthat our approach achieves superior performance compared to existing methods.", "published": "2025-09-22 08:55:04", "link": "http://arxiv.org/abs/2509.17537v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Neural Semantic Representation for 3D Semantic Correspondence", "abstract": "This paper presents a new approach to estimate accurate and robust 3D\nsemantic correspondence with the hierarchical neural semantic representation.\nOur work has three key contributions. First, we design the hierarchical neural\nsemantic representation (HNSR), which consists of a global semantic feature to\ncapture high-level structure and multi-resolution local geometric features to\npreserve fine details, by carefully harnessing 3D priors from pre-trained 3D\ngenerative models. Second, we design a progressive global-to-local matching\nstrategy, which establishes coarse semantic correspondence using the global\nsemantic feature, then iteratively refines it with local geometric features,\nyielding accurate and semantically-consistent mappings. Third, our framework is\ntraining-free and broadly compatible with various pre-trained 3D generative\nbackbones, demonstrating strong generalization across diverse shape categories.\nOur method also supports various applications, such as shape co-segmentation,\nkeypoint matching, and texture transfer, and generalizes well to structurally\ndiverse shapes, with promising results even in cross-category scenarios. Both\nqualitative and quantitative evaluations show that our method outperforms\nprevious state-of-the-art techniques.", "published": "2025-09-22 07:23:07", "link": "http://arxiv.org/abs/2509.17431v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device", "abstract": "The field of Embodied AI predominantly relies on simulation for training and\nevaluation, often using either fully synthetic environments that lack\nphotorealism or high-fidelity real-world reconstructions captured with\nexpensive hardware. As a result, sim-to-real transfer remains a major\nchallenge. In this paper, we introduce EmbodiedSplat, a novel approach that\npersonalizes policy training by efficiently capturing the deployment\nenvironment and fine-tuning policies within the reconstructed scenes. Our\nmethod leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to\nbridge the gap between realistic scene capture and effective training\nenvironments. Using iPhone-captured deployment scenes, we reconstruct meshes\nvia GS, enabling training in settings that closely approximate real-world\nconditions. We conduct a comprehensive analysis of training strategies,\npre-training datasets, and mesh reconstruction techniques, evaluating their\nimpact on sim-to-real predictivity in real-world scenarios. Experimental\nresults demonstrate that agents fine-tuned with EmbodiedSplat outperform both\nzero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and\nsynthetically generated datasets (HSSD), achieving absolute success rate\nimprovements of 20% and 40% on real-world Image Navigation task. Moreover, our\napproach yields a high sim-vs-real correlation (0.87-0.97) for the\nreconstructed meshes, underscoring its effectiveness in adapting policies to\ndiverse environments with minimal effort. Project page:\nhttps://gchhablani.github.io/embodied-splat.", "published": "2025-09-22 07:22:31", "link": "http://arxiv.org/abs/2509.17430v2", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration", "abstract": "Accurate temporal prediction is the bridge between comprehensive scene\nunderstanding and embodied artificial intelligence. However, predicting\nmultiple fine-grained states of a scene at multiple temporal scales is\ndifficult for vision-language models. We formalize the Multi-Scale Temporal\nPrediction (MSTP) task in general and surgical scenes by decomposing\nmulti-scale into two orthogonal dimensions: the temporal scale, forecasting\nstates of humans and surgery at varying look-ahead intervals, and the state\nscale, modeling a hierarchy of states in general and surgical scenes. For\nexample, in general scenes, states of contact relationships are finer-grained\nthan states of spatial relationships. In surgical scenes, medium-level steps\nare finer-grained than high-level phases yet remain constrained by their\nencompassing phase. To support this unified task, we introduce the first MSTP\nBenchmark, featuring synchronized annotations across multiple state scales and\ntemporal scales. We further propose a method, Incremental Generation and\nMulti-agent Collaboration (IG-MC), which integrates two key innovations. First,\nwe present a plug-and-play incremental generation module that continuously\nsynthesizes up-to-date visual previews at expanding temporal scales to inform\nmultiple decision-making agents, keeping decisions and generated visuals\nsynchronized and preventing performance degradation as look-ahead intervals\nlengthen. Second, we present a decision-driven multi-agent collaboration\nframework for multi-state prediction, comprising generation, initiation, and\nmulti-state assessment agents that dynamically trigger and evaluate prediction\ncycles to balance global coherence and local fidelity.", "published": "2025-09-22 07:22:27", "link": "http://arxiv.org/abs/2509.17429v2", "categories": ["cs.CV", "68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "A Generative Framework for Personalized Sticker Retrieval", "abstract": "Formulating information retrieval as a variant of generative modeling,\nspecifically using autoregressive models to generate relevant identifiers for a\ngiven query, has recently attracted considerable attention. However, its\napplication to personalized sticker retrieval remains largely unexplored and\npresents unique challenges: existing relevance-based generative retrieval\nmethods typically lack personalization, leading to a mismatch between diverse\nuser expectations and the retrieved results. To address this gap, we propose\nPEARL, a novel generative framework for personalized sticker retrieval, and\nmake two key contributions: (i) To encode user-specific sticker preferences, we\ndesign a representation learning model to learn discriminative user\nrepresentations. It is trained on three prediction tasks that leverage personal\ninformation and click history; and (ii) To generate stickers aligned with a\nuser's query intent, we propose a novel intent-aware learning objective that\nprioritizes stickers associated with higher-ranked intents. Empirical results\nfrom both offline evaluations and online tests demonstrate that PEARL\nsignificantly outperforms state-of-the-art methods.", "published": "2025-09-22 13:11:44", "link": "http://arxiv.org/abs/2509.17749v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Learning functions, operators and dynamical systems with kernels", "abstract": "This expository article presents the approach to statistical machine learning\nbased on reproducing kernel Hilbert spaces. The basic framework is introduced\nfor scalar-valued learning and then extended to operator learning. Finally,\nlearning dynamical systems is formulated as a suitable operator learning\nproblem, leveraging Koopman operator theory. The manuscript collects the\nsupporting material for the corresponding course taught at the CIME school\n\"Machine Learning: From Data to Mathematical Understanding\" in Cetraro.", "published": "2025-09-22 17:53:08", "link": "http://arxiv.org/abs/2509.18071v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLMs", "abstract": "Large language model (LLM) developers aim for their models to be honest,\nhelpful, and harmless. However, when faced with malicious requests, models are\ntrained to refuse, sacrificing helpfulness. We show that frontier LLMs can\ndevelop a preference for dishonesty as a new strategy, even when other options\nare available. Affected models respond to harmful requests with outputs that\nsound harmful but are crafted to be subtly incorrect or otherwise harmless in\npractice. This behavior emerges with hard-to-predict variations even within\nmodels from the same model family. We find no apparent cause for the propensity\nto deceive, but show that more capable models are better at executing this\nstrategy. Strategic dishonesty already has a practical impact on safety\nevaluations, as we show that dishonest responses fool all output-based monitors\nused to detect jailbreaks that we test, rendering benchmark scores unreliable.\nFurther, strategic dishonesty can act like a honeypot against malicious users,\nwhich noticeably obfuscates prior jailbreak attacks. While output monitors\nfail, we show that linear probes on internal activations can be used to\nreliably detect strategic dishonesty. We validate probes on datasets with\nverifiable outcomes and by using them as steering vectors. Overall, we consider\nstrategic dishonesty as a concrete example of a broader concern that alignment\nof LLMs is hard to control, especially when helpfulness and harmlessness\nconflict.", "published": "2025-09-22 17:30:56", "link": "http://arxiv.org/abs/2509.18058v2", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory", "abstract": "We explore whether techniques from AI can help discover new combinatorial\nstructures that improve on known limits on efficient algorithms. Specifically,\nwe use AlphaEvolve (an LLM coding agent) to study two settings:\n  a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve a\nrecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)\nlower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on\nrandom 3- and 4-regular graphs. Our improved lower bounds are obtained by\nconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, using\nAlphaEvolve. Additionally, via analytical arguments we strengthen the upper\nbounds to settle the computational hardness of these questions up to an error\nin the third decimal place.\n  b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain new\ninapproximability results, proving that it is NP-hard to approximate MAX-4-CUT\nand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, using\nAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves\nupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current\nbest gadget-based inapproximability result of $0.9853$, but falls short of\nimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadget\nreduction from \"standard\" H{\\aa}stad-style PCPs.\n  A key technical challenge we faced: verifying a candidate construction\nproduced by AlphaEvolve is costly (often requiring exponential time). In both\nsettings above, our results were enabled by using AlphaEvolve itself to evolve\nthe verification procedure to be faster (sometimes by $10,000\\times$). We\nconclude with a discussion of norms by which to assess the assistance from AI\nin developing proofs.", "published": "2025-09-22 17:30:33", "link": "http://arxiv.org/abs/2509.18057v2", "categories": ["cs.LG", "cs.AI", "cs.CC", "math.CO"], "primary_category": "cs.LG"}
{"title": "Optimizing Inference in Transformer-Based Models: A Multi-Method Benchmark", "abstract": "Efficient inference is a critical challenge in deep generative modeling,\nparticularly as diffusion models grow in capacity and complexity. While\nincreased complexity often improves accuracy, it raises compute costs, latency,\nand memory requirements. This work investigates techniques such as pruning,\nquantization, knowledge distillation, and simplified attention to reduce\ncomputational overhead without impacting performance. The study also explores\nthe Mixture of Experts (MoE) approach to further enhance efficiency. These\nexperiments provide insights into optimizing inference for the state-of-the-art\nFast Diffusion Transformer (fast-DiT) model.", "published": "2025-09-22 15:25:28", "link": "http://arxiv.org/abs/2509.17894v2", "categories": ["cs.LG", "68T07", "I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "Bilateral Distribution Compression: Reducing Both Data Size and Dimensionality", "abstract": "Existing distribution compression methods reduce dataset size by minimising\nthe Maximum Mean Discrepancy (MMD) between original and compressed sets, but\nmodern datasets are often large in both sample size and dimensionality. We\npropose Bilateral Distribution Compression (BDC), a two-stage framework that\ncompresses along both axes while preserving the underlying distribution, with\noverall linear time and memory complexity in dataset size and dimension.\nCentral to BDC is the Decoded MMD (DMMD), which quantifies the discrepancy\nbetween the original data and a compressed set decoded from a low-dimensional\nlatent space. BDC proceeds by (i) learning a low-dimensional projection using\nthe Reconstruction MMD (RMMD), and (ii) optimising a latent compressed set with\nthe Encoded MMD (EMMD). We show that this procedure minimises the DMMD,\nguaranteeing that the compressed set faithfully represents the original\ndistribution. Experiments show that across a variety of scenarios BDC can\nachieve comparable or superior performance to ambient-space compression at\nsubstantially lower cost.", "published": "2025-09-22 09:01:52", "link": "http://arxiv.org/abs/2509.17543v2", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Efficient Sliced Wasserstein Distance Computation via Adaptive Bayesian Optimization", "abstract": "The sliced Wasserstein distance (SW) reduces optimal transport on\n$\\mathbb{R}^d$ to a sum of one-dimensional projections, and thanks to this\nefficiency, it is widely used in geometry, generative modeling, and\nregistration tasks. Recent work shows that quasi-Monte Carlo constructions for\ncomputing SW (QSW) yield direction sets with excellent approximation error.\nThis paper presents an alternate, novel approach: learning directions with\nBayesian optimization (BO), particularly in settings where SW appears inside an\noptimization loop (e.g., gradient flows). We introduce a family of drop-in\nselectors for projection directions: BOSW, a one-shot BO scheme on the unit\nsphere; RBOSW, a periodic-refresh variant; ABOSW, an adaptive hybrid that seeds\nfrom competitive QSW sets and performs a few lightweight BO refinements; and\nARBOSW, a restarted hybrid that periodically relearns directions during\noptimization. Our BO approaches can be composed with QSW and its variants\n(demonstrated by ABOSW/ARBOSW) and require no changes to downstream losses or\ngradients. We provide numerical experiments where our methods achieve\nstate-of-the-art performance, and on the experimental suite of the original QSW\npaper, we find that ABOSW and ARBOSW can achieve convergence comparable to the\nbest QSW variants with modest runtime overhead.", "published": "2025-09-22 07:02:19", "link": "http://arxiv.org/abs/2509.17405v2", "categories": ["cs.LG", "49Q22 (Primary) 90C57, 68Txx (Secondary)", "G.3; I.2"], "primary_category": "cs.LG"}
{"title": "SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models", "abstract": "The rapid adoption of large language models (LLMs) in critical domains has\nspurred extensive research into their security issues. While input manipulation\nattacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks\n(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters\nand cause severe performance degradation -- have received far less attention.\nExisting BFA methods suffer from key limitations: they fail to balance\nperformance degradation and output naturalness, making them prone to discovery.\nIn this paper, we introduce SilentStriker, the first stealthy bit-flip attack\nagainst LLMs that effectively degrades task performance while maintaining\noutput naturalness. Our core contribution lies in addressing the challenge of\ndesigning effective loss functions for LLMs with variable output length and the\nvast output space. Unlike prior approaches that rely on output perplexity for\nattack loss formulation, which inevitably degrade output naturalness, we\nreformulate the attack objective by leveraging key output tokens as targets for\nsuppression, enabling effective joint optimization of attack effectiveness and\nstealthiness. Additionally, we employ an iterative, progressive search strategy\nto maximize attack efficacy. Experiments show that SilentStriker significantly\noutperforms existing baselines, achieving successful attacks without\ncompromising the naturalness of generated text.", "published": "2025-09-22 05:36:18", "link": "http://arxiv.org/abs/2509.17371v2", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "FUN-SSL: Full-band Layer Followed by U-Net with Narrow-band Layers for Multiple Moving Sound Source Localization", "abstract": "Dual-path processing along the temporal and spectral dimensions has shown to\nbe effective in various speech processing applications. While the sound source\nlocalization (SSL) models utilizing dual-path processing such as the FN-SSL and\nIPDnet demonstrated impressive performances in localizing multiple moving\nsources, they require significant amount of computation. In this paper, we\npropose an architecture for SSL which introduces a U-Net to perform narrow-band\nprocessing in multiple resolutions to reduce computational complexity. The\nproposed model replaces the full-narrow network block in the IPDnet consisting\nof one full-band LSTM layer along the spectral dimension followed by one\nnarrow-band LSTM layer along the temporal dimension with the FUN block composed\nof one Full-band layer followed by a U-net with Narrow-band layers in multiple\nscales. On top of the skip connections within each U-Net, we also introduce the\nskip connections between FUN blocks to enrich information. Experimental results\nshowed that the proposed FUN-SSL outperformed previously proposed approaches\nwith computational complexity much lower than that of the IPDnet.", "published": "2025-09-22 08:19:16", "link": "http://arxiv.org/abs/2509.17490v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling", "abstract": "Although transformer architectures have achieved state-of-the-art performance\nacross diverse domains, their quadratic computational complexity with respect\nto sequence length remains a significant bottleneck, particularly for\nlatency-sensitive long-context applications. While recent linear-complexity\nalternatives are increasingly powerful, effectively training them from scratch\nis still resource-intensive. To overcome these limitations, we propose LAWCAT\n(Linear Attention with Convolution Across Time), a novel linearization\nframework designed to efficiently transfer the capabilities of pre-trained\ntransformers into a performant linear attention architecture. LAWCAT integrates\ncausal Conv1D layers to enhance local dependency modeling and employs\nnormalized gated linear attention to improve generalization across varying\ncontext lengths. Our comprehensive evaluations demonstrate that, distilling\nMistral-7B with only 1K-length sequences yields over 90\\% passkey retrieval\naccuracy up to 22K tokens, significantly extending its effective context\nwindow. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance\non S-NIAH 1\\&2\\&3 tasks (1K-8K context length) and BABILong benchmark\n(QA2\\&QA3, 0K-16K context length), requiring less than 0.1\\% pre-training\ntokens compared with pre-training models. Furthermore, LAWCAT exhibits faster\nprefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT\nthus provides an efficient pathway to high-performance, long-context linear\nmodels suitable for edge deployment, reducing reliance on extensive\nlong-sequence training data and computational resources.", "published": "2025-09-22 22:43:44", "link": "http://arxiv.org/abs/2509.18467v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density", "abstract": "Current benchmarks for long-context reasoning in Large Language Models (LLMs)\noften blur critical factors like intrinsic task complexity, distractor\ninterference, and task length. To enable more precise failure analysis, we\nintroduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load\nTheory (CLT). CogniLoad generates natural-language logic puzzles with\nindependently tunable parameters that reflect CLT's core dimensions: intrinsic\ndifficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\\rho$)\nregulates extraneous load; and task length ($N$) serves as an operational proxy\nfor conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,\nCogniLoad reveals distinct performance sensitivities, identifying task length\nas a dominant constraint and uncovering varied tolerances to intrinsic\ncomplexity and U-shaped responses to distractor ratios. By offering systematic,\nfactorial control over these cognitive load dimensions, CogniLoad provides a\nreproducible, scalable, and diagnostically rich tool for dissecting LLM\nreasoning limitations and guiding future model development.", "published": "2025-09-22 22:28:33", "link": "http://arxiv.org/abs/2509.18458v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50 (Primary) 68T07, 68T05, 68T20, 68T27 (Secondary)", "I.2.7; I.2.6; I.2.4; I.2.8"], "primary_category": "cs.CL"}
{"title": "Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations", "abstract": "Shared decision-making (SDM) is necessary to achieve patient-centred care.\nCurrently no methodology exists to automatically measure SDM at scale. This\nstudy aimed to develop an automated approach to measure SDM by using language\nmodelling and the conversational alignment (CA) score. A total of 157\nvideo-recorded patient-doctor conversations from a randomized multi-centre\ntrial evaluating SDM decision aids for anticoagulation in atrial fibrillations\nwere transcribed and segmented into 42,559 sentences. Context-response pairs\nand negative sampling were employed to train deep learning (DL) models and\nfine-tuned BERT models via the next sentence prediction (NSP) task. Each\ntop-performing model was used to calculate four types of CA scores. A\nrandom-effects analysis by clinician, adjusting for age, sex, race, and trial\narm, assessed the association between CA scores and SDM outcomes: the\nDecisional Conflict Scale (DCS) and the Observing Patient Involvement in\nDecision-Making 12 (OPTION12) scores. p-values were corrected for multiple\ncomparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,\nmean age 70 SD 10.8), clinicians on average spoke more words than patients\n(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1\nof 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1\nwith 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)\nscores generated with the DL without stylebook were associated with OPTION12.\nThe Max CA score generated with the fine-tuned BERTbase (110M) was associated\nwith the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an\nimpact the association between CA scores and SDM. This study introduces an\nautomated, scalable methodology to measure SDM in patient-doctor conversations\nthrough explainable CA scores, with potential to evaluate SDM strategies at\nscale.", "published": "2025-09-22 21:50:13", "link": "http://arxiv.org/abs/2509.18439v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memory-QA: Answering Recall Questions Based on Multimodal Memories", "abstract": "We introduce Memory-QA, a novel real-world task that involves answering\nrecall questions about visual content from previously stored multimodal\nmemories. This task poses unique challenges, including the creation of\ntask-oriented memories, the effective utilization of temporal and location\ninformation within memories, and the ability to draw upon multiple memories to\nanswer a recall question. To address these challenges, we propose a\ncomprehensive pipeline, Pensieve, integrating memory-specific augmentation,\ntime- and location-aware multi-signal retrieval, and multi-memory QA\nfine-tuning. We created a multimodal benchmark to illustrate various real\nchallenges in this task, and show the superior performance of Pensieve over\nstate-of-the-art solutions (up to 14% on QA accuracy).", "published": "2025-09-22 21:41:35", "link": "http://arxiv.org/abs/2509.18436v1", "categories": ["cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.AI"}
{"title": "Evaluating the Creativity of LLMs in Persian Literary Text Generation", "abstract": "Large language models (LLMs) have demonstrated notable creative abilities in\ngenerating literary texts, including poetry and short stories. However, prior\nresearch has primarily centered on English, with limited exploration of\nnon-English literary traditions and without standardized methods for assessing\ncreativity. In this paper, we evaluate the capacity of LLMs to generate Persian\nliterary text enriched with culturally relevant expressions. We build a dataset\nof user-generated Persian literary spanning 20 diverse topics and assess model\noutputs along four creativity dimensions-originality, fluency, flexibility, and\nelaboration-by adapting the Torrance Tests of Creative Thinking. To reduce\nevaluation costs, we adopt an LLM as a judge for automated scoring and validate\nits reliability against human judgments using intraclass correlation\ncoefficients, observing strong agreement. In addition, we analyze the models'\nability to understand and employ four core literary devices: simile, metaphor,\nhyperbole, and antithesis. Our results highlight both the strengths and\nlimitations of LLMs in Persian literary text generation, underscoring the need\nfor further refinement.", "published": "2025-09-22 20:32:56", "link": "http://arxiv.org/abs/2509.18401v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery", "abstract": "Social norms govern culturally appropriate behavior in communication,\nenabling dialogue systems to produce responses that are not only coherent but\nalso socially acceptable. We present NormGenesis, a multicultural framework for\ngenerating and annotating socially grounded dialogues across English, Chinese,\nand Korean. To model the dynamics of social interaction beyond static norm\nclassification, we propose a novel dialogue type, Violation-to-Resolution\n(V2R), which models the progression of conversations following norm violations\nthrough recognition and socially appropriate repair. To improve pragmatic\nconsistency in underrepresented languages, we implement an exemplar-based\niterative refinement early in the dialogue synthesis process. This design\nintroduces alignment with linguistic, emotional, and sociocultural expectations\nbefore full dialogue generation begins. Using this framework, we construct a\ndataset of 10,800 multi-turn dialogues annotated at the turn level for norm\nadherence, speaker intent, and emotional response. Human and LLM-based\nevaluations demonstrate that NormGenesis significantly outperforms existing\ndatasets in refinement quality, dialogue naturalness, and generalization\nperformance. We show that models trained on our V2R-augmented data exhibit\nimproved pragmatic competence in ethically sensitive contexts. Our work\nestablishes a new benchmark for culturally adaptive dialogue modeling and\nprovides a scalable methodology for norm-aware generation across linguistically\nand culturally diverse languages.", "published": "2025-09-22 20:29:25", "link": "http://arxiv.org/abs/2509.18395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interactive Real-Time Speaker Diarization Correction with Human Feedback", "abstract": "Most automatic speech processing systems operate in \"open loop\" mode without\nuser feedback about who said what; yet, human-in-the-loop workflows can\npotentially enable higher accuracy. We propose an LLM-assisted speaker\ndiarization correction system that lets users fix speaker attribution errors in\nreal time. The pipeline performs streaming ASR and diarization, uses an LLM to\ndeliver concise summaries to the users, and accepts brief verbal feedback that\nis immediately incorporated without disrupting interactions. Moreover, we\ndevelop techniques to make the workflow more effective: First, a\nsplit-when-merged (SWM) technique detects and splits multi-speaker segments\nthat the ASR erroneously attributes to just a single speaker. Second, online\nspeaker enrollments are collected based on users' diarization corrections, thus\nhelping to prevent speaker diarization errors from occurring in the future.\nLLM-driven simulations on the AMI test set indicate that our system\nsubstantially reduces DER by 9.92% and speaker confusion error by 44.23%. We\nfurther analyze correction efficacy under different settings, including summary\nvs full transcript display, the number of online enrollments limitation, and\ncorrection frequency.", "published": "2025-09-22 20:01:20", "link": "http://arxiv.org/abs/2509.18377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents", "abstract": "We present Speech Vecalign, a parallel speech document alignment method that\nmonotonically aligns speech segment embeddings and does not depend on text\ntranscriptions. Compared to the baseline method Global Mining, a variant of\nspeech mining, Speech Vecalign produces longer speech-to-speech alignments. It\nalso demonstrates greater robustness than Local Mining, another speech mining\nvariant, as it produces less noise. We applied Speech Vecalign to 3,000 hours\nof unlabeled parallel English-German (En-De) speech documents from VoxPopuli,\nyielding about 1,000 hours of high-quality alignments. We then trained En-De\nspeech-to-speech translation models on the aligned data. Speech Vecalign\nimproves the En-to-De and De-to-En performance over Global Mining by 0.37 and\n0.18 ASR-BLEU, respectively. Moreover, our models match or outperform\nSpeechMatrix model performance, despite using 8 times fewer raw speech\ndocuments.", "published": "2025-09-22 19:37:20", "link": "http://arxiv.org/abs/2509.18360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding", "abstract": "The immense model sizes of large language models (LLMs) challenge deployment\non memory-limited consumer GPUs. Although model compression and parameter\noffloading are common strategies to address memory limitations, compression can\ndegrade quality, and offloading maintains quality but suffers from slow\ninference. Speculative decoding presents a promising avenue to accelerate\nparameter offloading, utilizing a fast draft model to propose multiple draft\ntokens, which are then verified by the target LLM in parallel with a single\nforward pass. This method reduces the time-consuming data transfers in forward\npasses that involve offloaded weight transfers. Existing methods often rely on\npretrained weights of the same family, but require additional training to align\nwith custom-trained models. Moreover, approaches that involve draft model\ntraining usually yield only modest speedups. This limitation arises from\ninsufficient alignment with the target model, preventing higher token\nacceptance lengths. To address these challenges and achieve greater speedups,\nwe propose SubSpec, a plug-and-play method to accelerate parameter offloading\nthat is lossless and training-free. SubSpec constructs a highly aligned draft\nmodel by generating low-bit quantized substitute layers from offloaded target\nLLM portions. Additionally, our method shares the remaining GPU-resident layers\nand the KV-Cache, further reducing memory overhead and enhance alignment.\nSubSpec achieves a high average acceptance length, delivering 9.1x speedup for\nQwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for\nQwen2.5 32B on popular generation benchmarks (24GB VRAM limit).", "published": "2025-09-22 19:08:57", "link": "http://arxiv.org/abs/2509.18344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning", "abstract": "Large language models (LLMs) show promise for diagnostic reasoning but often\nlack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as\nthe Unified Medical Language System (UMLS), offer structured biomedical\nknowledge that can support trustworthy reasoning. Prior approaches typically\nintegrate KGs via retrieval augmented generation or fine tuning, inserting KG\ncontent into prompts rather than enabling structured reasoning. We explore an\nalternative paradigm: treating the LLM as a reward model of KG reasoning paths,\nwhere the model learns to judge whether a candidate path leads to correct\ndiagnosis for a given patient input. This approach is inspired by recent work\nthat leverages reward training to enhance model reasoning abilities, and\ngrounded in computational theory, which suggests that verifying a solution is\noften easier than generating one from scratch. It also parallels physicians'\ndiagnostic assessment, where they judge which sequences of findings and\nintermediate conditions most plausibly support a diagnosis. We first\nsystematically evaluate five task formulation for knowledge path judging and\neight training paradigm. Second, we test whether the path judging abilities\ngeneralize to downstream diagnostic tasks, including diagnosis summarization\nand medical question answering. Experiments with three open source\ninstruct-tuned LLMs reveal both promise and brittleness: while specific reward\noptimization and distillation lead to strong path-judging performance, the\ntransferability to downstream tasks remain weak. Our finding provides the first\nsystematic assessment of \"reward model style\" reasoning over clinical KGs,\noffering insights into how structured, reward-based supervision influences\ndiagnostic reasoning in GenAI systems for healthcare.", "published": "2025-09-22 18:39:09", "link": "http://arxiv.org/abs/2509.18316v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploiting Tree Structure for Credit Assignment in RL Training of LLMs", "abstract": "Reinforcement learning improves LLM reasoning, yet sparse delayed reward over\nlong sequences makes token-level credit assignment the key bottleneck. We study\nthe verifiable-reward setting, where the final answer is checkable and multiple\nresponses can be drawn per prompt. Reasoning tasks in math and medical QA align\nwith this setup, where only a few decision tokens significantly impact the\noutcome. PPO offers token-level advantages with a learned value model, but it\nis complex to train both the actor and critic models simultaneously, and it is\nnot easily generalizable, as the token-level values from the critic model can\nmake training prone to overfitting. GRPO is critic-free and supports verifiable\nrewards, but spreads a single sequence-level return across tokens and ignores\nbranching. We introduce \\textbf{Prefix-to-Tree (P2T)}, a simple procedure that\nconverts a group of responses into a prefix tree and computes\n\\emph{nonparametric} prefix values \\(V(s)\\) by aggregating descendant outcomes.\nBuilt on P2T, we propose \\textbf{TEMPO} (\\emph{\\textbf{T}ree-\\textbf{E}stimated\n\\textbf{M}ean Prefix Value for \\textbf{P}olicy \\textbf{O}ptimization}), a\ncritic-free algorithm that augments the group-relative outcome signal of GRPO\nwith \\emph{branch-gated} temporal-difference corrections derived from the tree.\nAt non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO\nreduces to GRPO; at branching tokens, it supplies precise token-level credit\nwithout a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,\nTEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and\nout-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and\nreaches higher validation accuracy with roughly the same wall-clock time.", "published": "2025-09-22 18:37:24", "link": "http://arxiv.org/abs/2509.18314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models for Detecting Antisemitism", "abstract": "Detecting hateful content is a challenging and important problem. Automated\ntools, like machine-learning models, can help, but they require continuous\ntraining to adapt to the ever-changing landscape of social media. In this work,\nwe evaluate eight open-source LLMs' capability to detect antisemitic content,\nspecifically leveraging in-context definition as a policy guideline. We explore\nvarious prompting techniques and design a new CoT-like prompt, Guided-CoT.\nGuided-CoT handles the in-context policy well, increasing performance across\nall evaluated models, regardless of decoding configuration, model sizes, or\nreasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.\nAdditionally, we examine LLM errors and introduce metrics to quantify semantic\ndivergence in model-generated rationales, revealing notable differences and\nparadoxical behaviors among LLMs. Our experiments highlight the differences\nobserved across LLMs' utility, explainability, and reliability.", "published": "2025-09-22 18:23:21", "link": "http://arxiv.org/abs/2509.18293v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks", "abstract": "Large frontier models like GPT-5 now achieve top scores on medical\nbenchmarks. But our stress tests tell a different story. Leading systems often\nguess correctly even when key inputs like images are removed, flip answers\nunder trivial prompt changes, and fabricate convincing yet flawed reasoning.\nThese aren't glitches; they expose how today's benchmarks reward test-taking\ntricks over medical understanding. We evaluate six flagship models across six\nwidely used benchmarks and find that high leaderboard scores hide brittleness\nand shortcut learning. Through clinician-guided rubric evaluation, we show that\nbenchmarks vary widely in what they truly measure yet are treated\ninterchangeably, masking failure modes. We caution that medical benchmark\nscores do not directly reflect real-world readiness. If we want AI to earn\ntrust in healthcare, we must demand more than leaderboard wins and must hold\nsystems accountable for robustness, sound reasoning, and alignment with real\nmedical demands.", "published": "2025-09-22 17:48:05", "link": "http://arxiv.org/abs/2509.18234v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "G\u00f6del Test: Can Large Language Models Solve Easy Conjectures?", "abstract": "Recent announcements from frontier AI model labs have highlighted strong\nresults on high-school and undergraduate math competitions. Yet it remains\nunclear whether large language models can solve new, simple conjectures in more\nadvanced areas of mathematics. We propose the G\\\"odel Test: evaluating whether\na model can produce correct proofs for very simple, previously unsolved\nconjectures. To this end, we study the performance of GPT-5 on five conjectures\nin combinatorial optimization. For each problem, we provided one or two source\npapers from which the conjecture arose, withheld our own conjecture, and then\nassessed the model's reasoning in detail. On the three easier problems, GPT-5\nproduced nearly correct solutions; for Problem 2 it even derived a different\napproximation guarantee that, upon checking, refuted our conjecture while\nproviding a valid solution. The model failed on Problem 4, which required\ncombining results from two papers. On Problem 5, a harder case without a\nvalidated conjecture, GPT-5 proposed the same algorithm we had in mind but\nfailed in the analysis, suggesting the proof is more challenging than expected.\nAlthough our sample is small, the results point to meaningful progress on\nroutine reasoning, occasional flashes of originality, and clear limitations\nwhen cross-paper synthesis is required. GPT-5 may represent an early step\ntoward frontier models eventually passing the G\\\"odel Test.", "published": "2025-09-22 20:11:40", "link": "http://arxiv.org/abs/2509.18383v1", "categories": ["cs.AI", "cs.DM", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Individualized non-uniform quantization for vector search", "abstract": "Embedding vectors are widely used for representing unstructured data and\nsearching through it for semantically similar items. However, the large size of\nthese vectors, due to their high-dimensionality, creates problems for modern\nvector search techniques: retrieving large vectors from memory/storage is\nexpensive and their footprint is costly. In this work, we present NVQ\n(non-uniform vector quantization), a new vector compression technique that is\ncomputationally and spatially efficient in the high-fidelity regime. The core\nin NVQ is to use novel parsimonious and computationally efficient\nnonlinearities for building non-uniform vector quantizers. Critically, these\nquantizers are \\emph{individually} learned for each indexed vector. Our\nexperimental results show that NVQ exhibits improved accuracy compared to the\nstate of the art with a minimal computational cost.", "published": "2025-09-22 23:20:07", "link": "http://arxiv.org/abs/2509.18471v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Using Age of Information for Throughput Optimal Spectrum Sharing", "abstract": "We consider a spectrum sharing problem where two users attempt to communicate\nover N channels. The Primary User (PU) has prioritized transmissions and its\noccupancy on each channel over time can be modeled as a Markov chain. The\nSecondary User (SU) needs to determine which channels are free at each\ntime-slot and attempt opportunistic transmissions. The goal of the SU is to\nmaximize its own throughput, while simultaneously minimizing collisions with\nthe PU, and satisfying spectrum access constraints. To solve this problem, we\nfirst decouple the multiple-channel problem into N single-channel problems. For\neach decoupled problem, we prove that there exists an optimal threshold policy\nthat depends on the last observed PU occupancy and the freshness of this\noccupancy information. Second, we establish the indexability of the decoupled\nproblems by analyzing the structure of the optimal threshold policy. Using this\nstructure, we derive a Whittle index-based scheduling policy that allocates SU\ntransmissions using the Age of Information (AoI) of accessed channels. We also\nextend our insights to PU occupancy models that are correlated across channels\nand incorporate learning of unknown Markov transition matrices into our\npolicies. Finally, we provide detailed numerical simulations that demonstrate\nthe performance gains of our approach.", "published": "2025-09-22 22:41:03", "link": "http://arxiv.org/abs/2509.18465v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-Agent Games", "abstract": "Multi-agent games in dynamic nonlinear settings are challenging due to the\ntime-varying interactions among the agents and the non-stationarity of the\n(potential) Nash equilibria. In this paper we consider model-free games, where\nagent transitions and costs are observed without knowledge of the transition\nand cost functions that generate them. We propose a policy gradient approach to\nlearn distributed policies that follow the communication structure in\nmulti-team games, with multiple agents per team. Our formulation is inspired by\nthe structure of distributed policies in linear quadratic games, which take the\nform of time-varying linear feedback gains. In the nonlinear case, we model the\npolicies as nonlinear feedback gains, parameterized by self-attention layers to\naccount for the time-varying multi-agent communication topology. We demonstrate\nthat our distributed policy gradient approach achieves strong performance in\nseveral settings, including distributed linear and nonlinear regulation, and\nsimulated and real multi-robot pursuit-and-evasion games.", "published": "2025-09-22 19:52:16", "link": "http://arxiv.org/abs/2509.18371v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Fast Linear Solvers via AI-Tuned Markov Chain Monte Carlo-based Matrix Inversion", "abstract": "Large, sparse linear systems are pervasive in modern science and engineering,\nand Krylov subspace solvers are an established means of solving them. Yet\nconvergence can be slow for ill-conditioned matrices, so practical deployments\nusually require preconditioners. Markov chain Monte Carlo (MCMC)-based matrix\ninversion can generate such preconditioners and accelerate Krylov iterations,\nbut its effectiveness depends on parameters whose optima vary across matrices;\nmanual or grid search is costly. We present an AI-driven framework recommending\nMCMC parameters for a given linear system. A graph neural surrogate predicts\npreconditioning speed from $A$ and MCMC parameters. A Bayesian acquisition\nfunction then chooses the parameter sets most likely to minimise iterations. On\na previously unseen ill-conditioned system, the framework achieves better\npreconditioning with 50\\% of the search budget of conventional methods,\nyielding about a 10\\% reduction in iterations to convergence. These results\nsuggest a route for incorporating MCMC-based preconditioners into large-scale\nsystems.", "published": "2025-09-22 22:14:13", "link": "http://arxiv.org/abs/2509.18452v1", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML", "D.2.0; G.4; B.8.2"], "primary_category": "cs.LG"}
{"title": "ff-bifbox: A scalable, open-source toolbox for bifurcation analysis of nonlinear PDEs", "abstract": "Nonlinear PDEs give rise to complex dynamics that are often difficult to\nanalyze in state space due to their relatively large numbers of degrees of\nfreedom, ill-conditioned operators, and changing spatial and parameter\nresolution requirements. This work introduces ff-bifbox: a new open-source\ntoolbox for performing numerical branch tracing, stability/bifurcation\nanalysis, resolvent analysis, and time integration of large, time-dependent\nnonlinear PDEs discretized on adaptively refined meshes in two and three\nspatial dimensions. Spatial discretization is handled using finite elements in\nFreeFEM, with the discretized operators manipulated in a distributed framework\nvia PETSc. Following a summary of the underlying theory and numerics, results\nfrom three examples are presented to validate the implementation and\ndemonstrate its capabilities. The considered examples, which are provided with\nrunnable ff-bifbox code, include: a 3-D Brusselator system, a 3-D plate\nbuckling system, and a 2-D compressible Navier--Stokes system. In addition to\nreproducing results from prior studies, novel results are presented for each\nsystem.", "published": "2025-09-22 21:21:54", "link": "http://arxiv.org/abs/2509.18429v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "A mixed formulation for the fractional Poisson problem", "abstract": "The mixed formulation of the classical Poisson problem introduces the flux as\nan additional variable, leading to a system of coupled equations. Using\nfractional calculus identities, in this work we explore a mixed formulation of\nthe fractional Poisson problem and establish its well-posedness. Since a direct\ndiscretization of this problem appears to be out of reach, we adapt a\nstabilized approach by Hughes and Masud, which yields a coercive and well-posed\nformulation. The coercivity ensures the stability of any conforming finite\nelement discretization. We further prove the convergence of this\ndiscretization, derive convergence rates, and discuss implementation aspects.\nFinally, we present numerical experiments that highlight both the importance of\nstabilization and the accuracy of our theoretical results.", "published": "2025-09-22 19:15:21", "link": "http://arxiv.org/abs/2509.18348v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "End-Cut Preference in Survival Trees", "abstract": "The end-cut preference (ECP) problem, referring to the tendency to favor\nsplit points near the boundaries of a feature's range, is a well-known issue in\nCART (Breiman et al., 1984). ECP may induce highly imbalanced and biased\nsplits, obscure weak signals, and lead to tree structures that are both\nunstable and difficult to interpret. For survival trees, we show that ECP also\narises when using greedy search to select the optimal cutoff point by\nmaximizing the log-rank test statistic. To address this issue, we propose a\nsmooth sigmoid surrogate (SSS) approach, in which the hard-threshold indicator\nfunction is replaced by a smooth sigmoid function. We further demonstrate, both\ntheoretically and through numerical illustrations, that SSS provides an\neffective remedy for mitigating or avoiding ECP.", "published": "2025-09-22 23:26:59", "link": "http://arxiv.org/abs/2509.18477v1", "categories": ["stat.ML", "cs.LG", "62N05, 68T07"], "primary_category": "stat.ML"}
{"title": "Probabilistic Geometric Principal Component Analysis with application to neural data", "abstract": "Dimensionality reduction is critical across various domains of science\nincluding neuroscience. Probabilistic Principal Component Analysis (PPCA) is a\nprominent dimensionality reduction method that provides a probabilistic\napproach unlike the deterministic approach of PCA and serves as a connection\nbetween PCA and Factor Analysis (FA). Despite their power, PPCA and its\nextensions are mainly based on linear models and can only describe the data in\na Euclidean coordinate system. However, in many neuroscience applications, data\nmay be distributed around a nonlinear geometry (i.e., manifold) rather than\nlying in the Euclidean space. We develop Probabilistic Geometric Principal\nComponent Analysis (PGPCA) for such datasets as a new dimensionality reduction\nalgorithm that can explicitly incorporate knowledge about a given nonlinear\nmanifold that is first fitted from these data. Further, we show how in addition\nto the Euclidean coordinate system, a geometric coordinate system can be\nderived for the manifold to capture the deviations of data from the manifold\nand noise. We also derive a data-driven EM algorithm for learning the PGPCA\nmodel parameters. As such, PGPCA generalizes PPCA to better describe data\ndistributions by incorporating a nonlinear manifold geometry. In simulations\nand brain data analyses, we show that PGPCA can effectively model the data\ndistribution around various given manifolds and outperforms PPCA for such data.\nMoreover, PGPCA provides the capability to test whether the new geometric\ncoordinate system better describes the data than the Euclidean one. Finally,\nPGPCA can perform dimensionality reduction and learn the data distribution both\naround and on the manifold. These capabilities make PGPCA valuable for\nenhancing the efficacy of dimensionality reduction for analysis of\nhigh-dimensional data that exhibit noise and are distributed around a nonlinear\nmanifold.", "published": "2025-09-22 23:00:31", "link": "http://arxiv.org/abs/2509.18469v1", "categories": ["cs.LG", "q-bio.NC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Hierarchical Semi-Markov Models with Duration-Aware Dynamics for Activity Sequences", "abstract": "Residential electricity demand at granular scales is driven by what people do\nand for how long. Accurately forecasting this demand for applications like\nmicrogrid management and demand response therefore requires generative models\nthat can produce realistic daily activity sequences, capturing both the timing\nand duration of human behavior. This paper develops a generative model of human\nactivity sequences using nationally representative time-use diaries at a\n10-minute resolution. We use this model to quantify which demographic factors\nare most critical for improving predictive performance.\n  We propose a hierarchical semi-Markov framework that addresses two key\nmodeling challenges. First, a time-inhomogeneous Markov \\emph{router} learns\nthe patterns of ``which activity comes next.\" Second, a semi-Markov\n\\emph{hazard} component explicitly models activity durations, capturing ``how\nlong\" activities realistically last. To ensure statistical stability when data\nare sparse, the model pools information across related demographic groups and\ntime blocks. The entire framework is trained and evaluated using survey design\nweights to ensure our findings are representative of the U.S. population.\n  On a held-out test set, we demonstrate that explicitly modeling durations\nwith the hazard component provides a substantial and statistically significant\nimprovement over purely Markovian models. Furthermore, our analysis reveals a\nclear hierarchy of demographic factors: Sex, Day-Type, and Household Size\nprovide the largest predictive gains, while Region and Season, though important\nfor energy calculations, contribute little to predicting the activity sequence\nitself. The result is an interpretable and robust generator of synthetic\nactivity traces, providing a high-fidelity foundation for downstream energy\nsystems modeling.", "published": "2025-09-22 20:58:29", "link": "http://arxiv.org/abs/2509.18414v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Statistical Insight into Meta-Learning via Predictor Subspace Characterization and Quantification of Task Diversity", "abstract": "Meta-learning has emerged as a powerful paradigm for leveraging information\nacross related tasks to improve predictive performance on new tasks. In this\npaper, we propose a statistical framework for analyzing meta-learning through\nthe lens of predictor subspace characterization and quantification of task\ndiversity. Specifically, we model the shared structure across tasks using a\nlatent subspace and introduce a measure of diversity that captures\nheterogeneity across task-specific predictors. We provide both simulation-based\nand theoretical evidence indicating that achieving the desired prediction\naccuracy in meta-learning depends on the proportion of predictor variance\naligned with the shared subspace, as well as on the accuracy of subspace\nestimation.", "published": "2025-09-22 19:16:59", "link": "http://arxiv.org/abs/2509.18349v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Forest tree species classification and entropy-derived uncertainty mapping using extreme gradient boosting and Sentinel-1/2 data", "abstract": "We present a new 10-meter map of dominant tree species in Swedish forests\naccompanied by pixel-level uncertainty estimates. The tree species\nclassification is based on spatiotemporal metrics derived from Sentinel-1 and\nSentinel-2 satellite data, combined with field observations from the Swedish\nNational Forest Inventory. We apply an extreme gradient boosting model with\nBayesian optimization to relate field observations to satellite-derived\nfeatures and generate the final species map. Classification uncertainty is\nquantified using Shannon's entropy of the predicted class probabilities, which\nprovide a spatially explicit measure of model confidence. The final model\nachieved an overall accuracy of 85% (F1 score = 0.82, Matthews correlation\ncoefficient = 0.81), and mapped species distributions showed strong agreement\nwith official forest statistics (r = 0.96).", "published": "2025-09-22 12:01:49", "link": "http://arxiv.org/abs/2509.18228v1", "categories": ["q-bio.QM", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "Discrete-time diffusion-like models for speech synthesis", "abstract": "Diffusion models have attracted a lot of attention in recent years. These\nmodels view speech generation as a continuous-time process. For efficient\ntraining, this process is typically restricted to additive Gaussian noising,\nwhich is limiting. For inference, the time is typically discretized, leading to\nthe mismatch between continuous training and discrete sampling conditions.\nRecently proposed discrete-time processes, on the other hand, usually do not\nhave these limitations, may require substantially fewer inference steps, and\nare fully consistent between training/inference conditions. This paper explores\nsome diffusion-like discrete-time processes and proposes some new variants.\nThese include processes applying additive Gaussian noise, multiplicative\nGaussian noise, blurring noise and a mixture of blurring and Gaussian noises.\nThe experimental results suggest that discrete-time processes offer comparable\nsubjective and objective speech quality to their widely popular continuous\ncounterpart, with more efficient and consistent training and inference schemas.", "published": "2025-09-22 23:19:24", "link": "http://arxiv.org/abs/2509.18470v1", "categories": ["cs.LG", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Scattering Transformer: A Training-Free Transformer Architecture for Heart Murmur Detection", "abstract": "In an attempt to address the need for skilled clinicians in heart sound\ninterpretation, recent research efforts on automating cardiac auscultation have\nexplored deep learning approaches. The majority of these approaches have been\nbased on supervised learning that is always challenged in occasions where\ntraining data is limited. More recently, there has been a growing interest in\npotentials of pre-trained self-supervised audio foundation models for\nbiomedical end tasks. Despite exhibiting promising results, these foundational\nmodels are typically computationally intensive. Within the context of automatic\ncardiac auscultation, this study explores a lightweight alternative to these\ngeneral-purpose audio foundation models by introducing the Scattering\nTransformer, a novel, training-free transformer architecture for heart murmur\ndetection. The proposed method leverages standard wavelet scattering networks\nby introducing contextual dependencies in a transformer-like architecture\nwithout any backpropagation. We evaluate our approach on the public CirCor\nDigiScope dataset, directly comparing it against leading general-purpose\nfoundational models. The Scattering Transformer achieves a Weighted\nAccuracy(WAR) of 0.786 and an Unweighted Average Recall(UAR) of 0.697,\ndemonstrating performance highly competitive with contemporary state of the art\nmethods. This study establishes the Scattering Transformer as a viable and\npromising alternative in resource-constrained setups.", "published": "2025-09-22 21:08:06", "link": "http://arxiv.org/abs/2509.18424v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Identifying birdsong syllables without labelled data", "abstract": "Identifying sequences of syllables within birdsongs is key to tackling a wide\narray of challenges, including bird individual identification and better\nunderstanding of animal communication and sensory-motor learning. Recently,\nmachine learning approaches have demonstrated great potential to alleviate the\nneed for experts to label long audio recordings by hand. However, they still\ntypically rely on the availability of labelled data for model training,\nrestricting applicability to a few species and datasets. In this work, we build\nthe first fully unsupervised algorithm to decompose birdsong recordings into\nsequences of syllables. We first detect syllable events, then cluster them to\nextract templates --syllable representations-- before performing matching\npursuit to decompose the recording as a sequence of syllables. We evaluate our\nautomatic annotations against human labels on a dataset of Bengalese finch\nsongs and find that our unsupervised method achieves high performance. We also\ndemonstrate that our approach can distinguish individual birds within a species\nthrough their unique vocal signatures, for both Bengalese finches and another\nspecies, the great tit.", "published": "2025-09-22 20:54:37", "link": "http://arxiv.org/abs/2509.18412v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Dimensional Approach to Canine Bark Analysis for Assistance Dog Seizure Signaling", "abstract": "Standard classification of canine vocalisations is severely limited for\nassistance dogs, where sample data is sparse and variable across dogs and where\ncapture of the full range of bark types is ethically constrained. We reframe\nthis problem as a continuous regression task within a two-dimensional\narousal-valence space. Central to our approach is an adjusted Siamese Network\ntrained not on binary similarity, but on the ordinal and numeric distance\nbetween input sample pairs. Trained on a public dataset, our model reduces\nTurn-around Percentage by up to 50% on the challenging valence dimension\ncompared to a regression baseline. Qualitative validation on a real-world\ndataset confirms the learned space is semantically meaningful, establishing a\nproof-of-concept for analysing canine barking under severe data limitations.", "published": "2025-09-22 19:57:37", "link": "http://arxiv.org/abs/2509.18375v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Qubit Instrumentation of Entanglement", "abstract": "This chapter and the experiments described within explore how `human\nentanglement' might be represented and even emulated by physical entanglement.\nTo achieve this, a notion of `tonal centrality' between two musicians is\ncaptured via MIDI and passed as a parameter into a quantum simulation taking\nplace on an embedded device (a Raspberry Pi Pico). The results of these\nsimulations are then coded back into MIDI and sent to the players' instruments.\nThe closer the musicians' tonality is, the more their instruments will be\nentangled in a $|\\Phi^+ \\rangle$ state, and the further away they are the more\ntheir instruments will be entangled in a $|\\Psi^+ \\rangle$ state. The intention\nis to create random parameters that are correlative - \\emph{i.e.} the same on\nboth instruments - or anti-correlative - \\emph{i.e.} the bit-wise opposite of\neach other, influenced by the tonal relationship from the players. These random\nparameters sharing these particular properties add a new dimension for\nquantum-musical expression. This concept was realised experimentally, and the\nfull code and sample outputs are provided. This work aims to pave the way for\nmusicians to explore and experience quantum emulations of their own musical\nexperiences, adding a new nuance and possibilities for the future of\n\\emph{entangled ensembles.}", "published": "2025-09-22 19:01:36", "link": "http://arxiv.org/abs/2509.18340v1", "categories": ["quant-ph", "cs.SD", "eess.AS"], "primary_category": "quant-ph"}
{"title": "StereoFoley: Object-Aware Stereo Audio Generation from Video", "abstract": "We present StereoFoley, a video-to-audio generation framework that produces\nsemantically aligned, temporally synchronized, and spatially accurate stereo\nsound at 48 kHz. While recent generative video-to-audio models achieve strong\nsemantic and temporal fidelity, they largely remain limited to mono or fail to\ndeliver object-aware stereo imaging, constrained by the lack of professionally\nmixed, spatially accurate video-to-audio datasets. First, we develop and train\na base model that generates stereo audio from video, achieving state-of-the-art\nin both semantic accuracy and synchronization. Next, to overcome dataset\nlimitations, we introduce a synthetic data generation pipeline that combines\nvideo analysis, object tracking, and audio synthesis with dynamic panning and\ndistance-based loudness controls, enabling spatially accurate object-aware\nsound. Finally, we fine-tune the base model on this synthetic dataset, yielding\nclear object-audio correspondence. Since no established metrics exist, we\nintroduce stereo object-awareness measures and validate it through a human\nlistening study, showing strong correlation with perception. This work\nestablishes the first end-to-end framework for stereo object-aware\nvideo-to-audio generation, addressing a critical gap and setting a new\nbenchmark in the field.", "published": "2025-09-22 18:00:54", "link": "http://arxiv.org/abs/2509.18272v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automated Analysis of Naturalistic Recordings in Early Childhood: Applications, Challenges, and Opportunities", "abstract": "Naturalistic recordings capture audio in real-world environments where\nparticipants behave naturally without interference from researchers or\nexperimental protocols. Naturalistic long-form recordings extend this concept\nby capturing spontaneous and continuous interactions over extended periods,\noften spanning hours or even days, in participants' daily lives. Naturalistic\nrecordings have been extensively used to study children's behaviors, including\nhow they interact with others in their environment, in the fields of\npsychology, education, cognitive science, and clinical research. These\nrecordings provide an unobtrusive way to observe children in real-world\nsettings beyond controlled and constrained experimental environments.\nAdvancements in speech technology and machine learning have provided an initial\nstep for researchers to automatically and systematically analyze large-scale\nnaturalistic recordings of children. Despite the imperfect accuracy of machine\nlearning models, these tools still offer valuable opportunities to uncover\nimportant insights into children's cognitive and social development. Several\ncritical speech technologies involved include speaker diarization, vocalization\nclassification, word count estimate from adults, speaker verification, and\nlanguage diarization for code-switching. Most of these technologies have been\nprimarily developed for adults, and speech technologies applied to children\nspecifically are still vastly under-explored. To fill this gap, we discuss\ncurrent progress, challenges, and opportunities in advancing these technologies\nto analyze naturalistic recordings of children during early development (<3\nyears of age). We strive to inspire the signal processing community and foster\ninterdisciplinary collaborations to further develop this emerging technology\nand address its unique challenges and opportunities.", "published": "2025-09-22 17:50:13", "link": "http://arxiv.org/abs/2509.18235v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Automatic Model Extraction of the Match Standard in Symmetric--Reciprocal--Match Calibration", "abstract": "This paper addresses the modeling of parasitics of the match standard in the\nsymmetric-reciprocal-match (SRM) calibration method of vector network analyzers\n(VNAs). In the general SRM procedure, the match standard is assumed to be fully\nknown. Here, we demonstrate that the match can be modeled with an arbitrary\nfrequency-dependent model using a non-linear global optimization procedure. To\nhighlight the validity of the suggested approach, numerical tests were\nconducted, demonstrating the ability to recover the match standard parasitic\nmodel down to software numerical precision. Additionally, we performed\nmicrostrip line measurements to compare the SRM calibration with match modeling\nto the multiline thru-reflect-line (TRL) calibration one, showing that\nautomatic model extraction can achieve accuracy similar to using a match\nstandard defined through multiline TRL calibration.", "published": "2025-09-22 21:13:15", "link": "http://arxiv.org/abs/2509.18426v1", "categories": ["eess.SP", "physics.ins-det"], "primary_category": "eess.SP"}
{"title": "Multi-Target Detection for Cognitive MIMO Radar Networks", "abstract": "In this work, we develop centralized and decentralized signal fusion\ntechniques for constant false alarm rate (CFAR) multi-target detection with a\ncognitive radar network in unknown noise and clutter distributions. Further, we\nfirst develop a detection statistic for co-located monostatic MIMO radar in\nunknown noise and clutter distributions which is asymptotically CFAR as the\nnumber of received pulses over all antennas grows large, and we provide\nconditions under which this detection statistic is valid. We leverage\nreinforcement learning (RL) for improved multi-target detection performance,\nwhere the radar learns likely target locations in a search area. These results\nare then generalized to the setting of cognitive radar networks, where radars\ncollaborate to learn where targets are likely to appear in a search area. We\nshow a fundamental tradeoff between the spatial and temporal domain for CFAR\ndetection in unknown noise and clutter distributions; in other words, we show a\ntradeoff between the number of radar antennas and the number of temporal\nsamples. We show the benefits and tradeoffs with centralized and decentralized\ndetection with a network of cognitive radars.", "published": "2025-09-22 20:08:54", "link": "http://arxiv.org/abs/2509.18381v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On Multi-entity, Multivariate Quickest Change Point Detection", "abstract": "We propose a framework for online Change Point Detection (CPD) from\nmulti-entity, multivariate time series data, motivated by applications in crowd\nmonitoring where traditional sensing methods (e.g., video surveillance) may be\ninfeasible. Our approach addresses the challenge of detecting system-wide\nbehavioral shifts in complex, dynamic environments where the number and\nbehavior of individual entities may be uncertain or evolve. We introduce the\nconcept of Individual Deviation from Normality (IDfN), computed via a\nreconstruction-error-based autoencoder trained on normal behavior. We aggregate\nthese individual deviations using mean, variance, and Kernel Density Estimates\n(KDE) to yield a System-Wide Anomaly Score (SWAS). To detect persistent or\nabrupt changes, we apply statistical deviation metrics and the Cumulative Sum\n(CUSUM) technique to these scores. Our unsupervised approach eliminates the\nneed for labeled data or feature extraction, enabling real-time operation on\nstreaming input. Evaluations on both synthetic datasets and crowd simulations,\nexplicitly designed for anomaly detection in group behaviors, demonstrate that\nour method accurately detects significant system-level changes, offering a\nscalable and privacy-preserving solution for monitoring complex multi-agent\nsystems. In addition to this methodological contribution, we introduce new,\nchallenging multi-entity multivariate time series datasets generated from crowd\nsimulations in Unity and coupled nonlinear oscillators. To the best of our\nknowledge, there is currently no publicly available dataset of this type\ndesigned explicitly to evaluate CPD in complex collective and interactive\nsystems, highlighting an essential gap that our work addresses.", "published": "2025-09-22 18:35:24", "link": "http://arxiv.org/abs/2509.18310v1", "categories": ["eess.SP", "cs.LG", "stat.AP", "stat.ME"], "primary_category": "eess.SP"}
{"title": "Shilling Recommender Systems by Generating Side-feature-aware Fake User Profiles", "abstract": "Recommender systems (RS) greatly influence users' consumption decisions,\nmaking them attractive targets for malicious shilling attacks that inject fake\nuser profiles to manipulate recommendations. Existing shilling methods can\ngenerate effective and stealthy fake profiles when training data only contain\nrating matrix, but they lack comprehensive solutions for scenarios where side\nfeatures are present and utilized by the recommender. To address this gap, we\nextend the Leg-UP framework by enhancing the generator architecture to\nincorporate side features, enabling the generation of side-feature-aware fake\nuser profiles. Experiments on benchmarks show that our method achieves strong\nattack performance while maintaining stealthiness.", "published": "2025-09-22 15:43:11", "link": "http://arxiv.org/abs/2509.17918v2", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Schrodingerization based quantum algorithms for the time-fractional heat equation", "abstract": "We develop a quantum algorithm for solving high-dimensional time-fractional\nheat equations. By applying the dimension extension technique from [FKW23], the\n$d+1$-dimensional time-fractional equation is reformulated as a local partial\ndifferential equation in $d+2$ dimensions. Through discretization along both\nthe extended and spatial domains, a stable system of ordinary differential\nequations is obtained by a simple change of variables. We propose a quantum\nalgorithm for the resulting semi-discrete problem using the Schrodingerization\napproach from [JLY24a,JLY23,JL24a]. The Schrodingerization technique transforms\ngeneral linear partial and ordinary differential equations into\nSchrodinger-type systems--with unitary evolution, making them suitable for\nquantum simulation. This is accomplished via the warped phase transformation,\nwhich maps the equation into a higher-dimensional space. We provide detailed\nimplementations of this method and conduct a comprehensive complexity analysis,\ndemonstrating up to exponential advantage--with respect to the inverse of the\nmesh size in high dimensions~--~compared to its classical counterparts.\nSpecifically, to compute the solution to time $T$, while the classical method\nrequires at least $\\mathcal{O}(N_t d h^{-(d+0.5)})$ matrix-vector\nmultiplications, where $N_t $ is the number of time steps (which is, for\nexample, $\\mathcal{O}(Tdh^{-2})$ for the forward Euler method), our quantum\nalgorithms requires $\\widetilde{\\mathcal{O}}(T^2d^4 h^{-8})$ queries to the\nblock-encoding input models, with the quantum complexity being independent of\nthe dimension $d$ in terms of the inverse mesh size $h^{-1}$. Numerical\nexperiments are performed to validate our formulation.", "published": "2025-09-22 12:49:58", "link": "http://arxiv.org/abs/2509.17713v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hybrid Pipeline SWD Detection in Long-Term EEG Signals", "abstract": "Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of\nabsence epilepsy, yet their manual identification in multi-day recordings\nremains labour-intensive and error-prone. We present a lightweight hybrid\npipeline that couples analytical features with a shallow artificial neural\nnetwork (ANN) for accurate, patient-specific SWD detection in long-term,\nmonopolar EEG. A two-sided moving-average (MA) filter first suppresses the\nhigh-frequency components of normal background activity. The residual signal is\nthen summarised by the mean and the standard deviation of its normally\ndistributed samples, yielding a compact, two-dimensional feature vector for\nevery 20s window. These features are fed to a single-hidden-layer ANN trained\nvia back-propagation to classify each window as SWD or non-SWD. The method was\nevaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392\nannotated SWD events. It correctly detected 384 events (sensitivity: 98%) while\nachieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because\nfeature extraction is analytic, and the classifier is small, the pipeline runs\nin real-time and requires no manual threshold tuning. These results indicate\nthat normal-distribution descriptors combined with a modest ANN provide an\neffective and computationally inexpensive solution for automated SWD screening\nin extended EEG recordings.", "published": "2025-09-22 02:45:43", "link": "http://arxiv.org/abs/2509.19387v1", "categories": ["eess.SP", "cs.LG", "stat.AP", "stat.ML"], "primary_category": "eess.SP"}
