{"title": "Prompted Opinion Summarization with GPT-3.5", "abstract": "Large language models have shown impressive performance across a wide variety\nof tasks, including text summarization. In this paper, we show that this strong\nperformance extends to opinion summarization. We explore several pipeline\nmethods for applying GPT-3.5 to summarize a large collection of user reviews in\na prompted fashion. To handle arbitrarily large numbers of user reviews, we\nexplore recursive summarization as well as methods for selecting salient\ncontent to summarize through supervised clustering or extraction. On two\ndatasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and\na generic summarization dataset of Amazon and Yelp reviews (FewSum), we show\nthat GPT-3.5 models achieve very strong performance in human evaluation. We\nargue that standard evaluation metrics do not reflect this, and introduce three\nnew metrics targeting faithfulness, factuality, and genericity to contrast\nthese different methods.", "published": "2022-11-29 04:06:21", "link": "http://arxiv.org/abs/2211.15914v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BotSIM: An End-to-End Bot Simulation Toolkit for Commercial\n  Task-Oriented Dialog Systems", "abstract": "We introduce BotSIM, a modular, open-source Bot SIMulation environment with\ndialog generation, user simulation and conversation analytics capabilities.\nBotSIM aims to serve as a one-stop solution for large-scale data-efficient\nend-to-end evaluation, diagnosis and remediation of commercial task-oriented\ndialog (TOD) systems to significantly accelerate commercial bot development and\nevaluation, reduce cost and time-to-market. BotSIM adopts a layered design\ncomprising the infrastructure layer, the adaptor layer and the application\nlayer. The infrastructure layer hosts key models and components to support\nBotSIM's major functionalities via a streamlined\n\"generation-simulation-remediation\" pipeline. The adaptor layer is used to\nextend BotSIM to accommodate new bot platforms. The application layer provides\na suite of command line tools and a Web App to significantly lower the entry\nbarrier for BotSIM users such as bot admins or practitioners. In this report,\nwe focus on the technical designs of various system components. A detailed case\nstudy using Einstein BotBuilder is also presented to show how to apply BotSIM\npipeline for bot evaluation and remediation. The detailed system descriptions\ncan be found in our system demo paper. The toolkit is available at:\nhttps://github.com/salesforce/BotSIM .", "published": "2022-11-29 04:13:25", "link": "http://arxiv.org/abs/2211.15916v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extending the Subwording Model of Multilingual Pretrained Models for New\n  Languages", "abstract": "Multilingual pretrained models are effective for machine translation and\ncross-lingual processing because they contain multiple languages in one model.\nHowever, they are pretrained after their tokenizers are fixed; therefore it is\ndifficult to change the vocabulary after pretraining. When we extend the\npretrained models to new languages, we must modify the tokenizers\nsimultaneously. In this paper, we add new subwords to the SentencePiece\ntokenizer to apply a multilingual pretrained model to new languages (Inuktitut\nin this paper). In our experiments, we segmented Inuktitut sentences into\nsubwords without changing the segmentation of already pretrained languages, and\napplied the mBART-50 pretrained model to English-Inuktitut translation.", "published": "2022-11-29 06:55:34", "link": "http://arxiv.org/abs/2211.15965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Democratizing Machine Learning for Interdisciplinary Scholars: Report on\n  Organizing the NLP+CSS Online Tutorial Series", "abstract": "Many scientific fields -- including biology, health, education, and the\nsocial sciences -- use machine learning (ML) to help them analyze data at an\nunprecedented scale. However, ML researchers who develop advanced methods\nrarely provide detailed tutorials showing how to apply these methods. Existing\ntutorials are often costly to participants, presume extensive programming\nknowledge, and are not tailored to specific application fields. In an attempt\nto democratize ML methods, we organized a year-long, free, online tutorial\nseries targeted at teaching advanced natural language processing (NLP) methods\nto computational social science (CSS) scholars. Two organizers worked with\nfifteen subject matter experts to develop one-hour presentations with hands-on\nPython code for a range of ML methods and use cases, from data pre-processing\nto analyzing temporal variation of language change. Although live participation\nwas more limited than expected, a comparison of pre- and post-tutorial surveys\nshowed an increase in participants' perceived knowledge of almost one point on\na 7-point Likert scale. Furthermore, participants asked thoughtful questions\nduring tutorials and engaged readily with tutorial content afterwards, as\ndemonstrated by 10K~total views of posted tutorial recordings. In this report,\nwe summarize our organizational efforts and distill five principles for\ndemocratizing ML+X tutorials. We hope future organizers improve upon these\nprinciples and continue to lower barriers to developing ML skills for\nresearchers of all fields.", "published": "2022-11-29 07:06:45", "link": "http://arxiv.org/abs/2211.15971v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Neural Discourse Deixis Resolution in Dialogue", "abstract": "We adapt Lee et al.'s (2018) span-based entity coreference model to the task\nof end-to-end discourse deixis resolution in dialogue, specifically by\nproposing extensions to their model that exploit task-specific characteristics.\nThe resulting model, dd-utt, achieves state-of-the-art results on the four\ndatasets in the CODI-CRAC 2021 shared task.", "published": "2022-11-29 07:27:36", "link": "http://arxiv.org/abs/2211.15980v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Generalized Open Information Extraction", "abstract": "Open Information Extraction (OpenIE) facilitates the open-domain discovery of\ntextual facts. However, the prevailing solutions evaluate OpenIE models on\nin-domain test sets aside from the training corpus, which certainly violates\nthe initial task principle of domain-independence. In this paper, we propose to\nadvance OpenIE towards a more realistic scenario: generalizing over unseen\ntarget domains with different data distributions from the source training\ndomains, termed Generalized OpenIE. For this purpose, we first introduce GLOBE,\na large-scale human-annotated multi-domain OpenIE benchmark, to examine the\nrobustness of recent OpenIE models to domain shifts, and the relative\nperformance degradation of up to 70% implies the challenges of generalized\nOpenIE. Then, we propose DragonIE, which explores a minimalist graph expression\nof textual fact: directed acyclic graph, to improve the OpenIE generalization.\nExtensive experiments demonstrate that DragonIE beats the previous methods in\nboth in-domain and out-of-domain settings by as much as 6.0% in F1 score\nabsolutely, but there is still ample room for improvement.", "published": "2022-11-29 07:33:44", "link": "http://arxiv.org/abs/2211.15987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Textual Enhanced Contrastive Learning for Solving Math Word Problems", "abstract": "Solving math word problems is the task that analyses the relation of\nquantities and requires an accurate understanding of contextual natural\nlanguage information. Recent studies show that current models rely on shallow\nheuristics to predict solutions and could be easily misled by small textual\nperturbations. To address this problem, we propose a Textual Enhanced\nContrastive Learning framework, which enforces the models to distinguish\nsemantically similar examples while holding different mathematical logic. We\nadopt a self-supervised manner strategy to enrich examples with subtle textual\nvariance by textual reordering or problem re-construction. We then retrieve the\nhardest to differentiate samples from both equation and textual perspectives\nand guide the model to learn their representations. Experimental results show\nthat our method achieves state-of-the-art on both widely used benchmark\ndatasets and also exquisitely designed challenge datasets in English and\nChinese. \\footnote{Our code and data is available at\n\\url{https://github.com/yiyunya/Textual_CL_MWP}", "published": "2022-11-29 08:44:09", "link": "http://arxiv.org/abs/2211.16022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Substitutability as Unsupervised Dependency Syntax", "abstract": "Syntax is a latent hierarchical structure which underpins the robust and\ncompositional nature of human language. In this work, we explore the hypothesis\nthat syntactic dependencies can be represented in language model attention\ndistributions and propose a new method to induce these structures\ntheory-agnostically. Instead of modeling syntactic relations as defined by\nannotation schemata, we model a more general property implicit in the\ndefinition of dependency relations, syntactic substitutability. This property\ncaptures the fact that words at either end of a dependency can be substituted\nwith words from the same category. Substitutions can be used to generate a set\nof syntactically invariant sentences whose representations are then used for\nparsing. We show that increasing the number of substitutions used improves\nparsing accuracy on natural data. On long-distance subject-verb agreement\nconstructions, our method achieves 79.5% recall compared to 8.9% using a\nprevious method. Our method also provides improvements when transferred to a\ndifferent parsing setup, demonstrating that it generalizes.", "published": "2022-11-29 09:01:37", "link": "http://arxiv.org/abs/2211.16031v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Penalizing Confident Predictions on Largely Perturbed Inputs Does Not\n  Improve Out-of-Distribution Generalization in Question Answering", "abstract": "Question answering (QA) models are shown to be insensitive to large\nperturbations to inputs; that is, they make correct and confident predictions\neven when given largely perturbed inputs from which humans can not correctly\nderive answers. In addition, QA models fail to generalize to other domains and\nadversarial test sets, while humans maintain high accuracy. Based on these\nobservations, we assume that QA models do not use intended features necessary\nfor human reading but rely on spurious features, causing the lack of\ngeneralization ability. Therefore, we attempt to answer the question: If the\noverconfident predictions of QA models for various types of perturbations are\npenalized, will the out-of-distribution (OOD) generalization be improved? To\nprevent models from making confident predictions on perturbed inputs, we first\nfollow existing studies and maximize the entropy of the output probability for\nperturbed inputs. However, we find that QA models trained to be sensitive to a\ncertain perturbation type are often insensitive to unseen types of\nperturbations. Thus, we simultaneously maximize the entropy for the four\nperturbation types (i.e., word- and sentence-level shuffling and deletion) to\nfurther close the gap between models and humans. Contrary to our expectations,\nalthough models become sensitive to the four types of perturbations, we find\nthat the OOD generalization is not improved. Moreover, the OOD generalization\nis sometimes degraded after entropy maximization. Making unconfident\npredictions on largely perturbed inputs per se may be beneficial to gaining\nhuman trust. However, our negative results suggest that researchers should pay\nattention to the side effect of entropy maximization.", "published": "2022-11-29 11:06:48", "link": "http://arxiv.org/abs/2211.16093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI Submission in WMT22 General Task", "abstract": "We present the CUNI-Bergamot submission for the WMT22 General translation\ntask. We compete in English$\\rightarrow$Czech direction. Our submission further\nexplores block backtranslation techniques. Compared to the previous work, we\nmeasure performance in terms of COMET score and named entities translation\naccuracy. We evaluate performance of MBR decoding compared to traditional mixed\nbacktranslation training and we show a possible synergy when using both of the\ntechniques simultaneously. The results show that both approaches are effective\nmeans of improving translation quality and they yield even better results when\ncombined.", "published": "2022-11-29 13:06:09", "link": "http://arxiv.org/abs/2211.16174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Which Shortcut Solution Do Question Answering Models Prefer to Learn?", "abstract": "Question answering (QA) models for reading comprehension tend to learn\nshortcut solutions rather than the solutions intended by QA datasets. QA models\nthat have learned shortcut solutions can achieve human-level performance in\nshortcut examples where shortcuts are valid, but these same behaviors degrade\ngeneralization potential on anti-shortcut examples where shortcuts are invalid.\nVarious methods have been proposed to mitigate this problem, but they do not\nfully take the characteristics of shortcuts themselves into account. We assume\nthat the learnability of shortcuts, i.e., how easy it is to learn a shortcut,\nis useful to mitigate the problem. Thus, we first examine the learnability of\nthe representative shortcuts on extractive and multiple-choice QA datasets.\nBehavioral tests using biased training sets reveal that shortcuts that exploit\nanswer positions and word-label correlations are preferentially learned for\nextractive and multiple-choice QA, respectively. We find that the more\nlearnable a shortcut is, the flatter and deeper the loss landscape is around\nthe shortcut solution in the parameter space. We also find that the\navailability of the preferred shortcuts tends to make the task easier to\nperform from an information-theoretic viewpoint. Lastly, we experimentally show\nthat the learnability of shortcuts can be utilized to construct an effective QA\ntraining set; the more learnable a shortcut is, the smaller the proportion of\nanti-shortcut examples required to achieve comparable performance on shortcut\nand anti-shortcut examples. We claim that the learnability of shortcuts should\nbe considered when designing mitigation methods.", "published": "2022-11-29 13:57:59", "link": "http://arxiv.org/abs/2211.16220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring the Measuring Tools: An Automatic Evaluation of Semantic\n  Metrics for Text Corpora", "abstract": "The ability to compare the semantic similarity between text corpora is\nimportant in a variety of natural language processing applications. However,\nstandard methods for evaluating these metrics have yet to be established. We\npropose a set of automatic and interpretable measures for assessing the\ncharacteristics of corpus-level semantic similarity metrics, allowing sensible\ncomparison of their behavior. We demonstrate the effectiveness of our\nevaluation measures in capturing fundamental characteristics by evaluating them\non a collection of classical and state-of-the-art metrics. Our measures\nrevealed that recently-developed metrics are becoming better in identifying\nsemantic distributional mismatch while classical metrics are more sensitive to\nperturbations in the surface text levels.", "published": "2022-11-29 14:47:07", "link": "http://arxiv.org/abs/2211.16259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TyDiP: A Dataset for Politeness Classification in Nine Typologically\n  Diverse Languages", "abstract": "We study politeness phenomena in nine typologically diverse languages.\nPoliteness is an important facet of communication and is sometimes argued to be\ncultural-specific, yet existing computational linguistic study is limited to\nEnglish. We create TyDiP, a dataset containing three-way politeness annotations\nfor 500 examples in each language, totaling 4.5K examples. We evaluate how well\nmultilingual models can identify politeness levels -- they show a fairly robust\nzero-shot transfer ability, yet fall short of estimated human accuracy\nsignificantly. We further study mapping the English politeness strategy lexicon\ninto nine languages via automatic translation and lexicon induction, analyzing\nwhether each strategy's impact stays consistent across languages. Lastly, we\nempirically study the complicated relationship between formality and politeness\nthrough transfer experiments. We hope our dataset will support various research\nquestions and applications, from evaluating multilingual models to constructing\npolite multilingual agents.", "published": "2022-11-29 18:58:15", "link": "http://arxiv.org/abs/2211.16496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding Neural Entity Alignment with Compatibility", "abstract": "Entity Alignment (EA) aims to find equivalent entities between two Knowledge\nGraphs (KGs). While numerous neural EA models have been devised, they are\nmainly learned using labelled data only. In this work, we argue that different\nentities within one KG should have compatible counterparts in the other KG due\nto the potential dependencies among the entities. Making compatible predictions\nthus should be one of the goals of training an EA model along with fitting the\nlabelled data: this aspect however is neglected in current methods. To power\nneural EA models with compatibility, we devise a training framework by\naddressing three problems: (1) how to measure the compatibility of an EA model;\n(2) how to inject the property of being compatible into an EA model; (3) how to\noptimise parameters of the compatibility model. Extensive experiments on\nwidely-used datasets demonstrate the advantages of integrating compatibility\nwithin EA models. In fact, state-of-the-art neural EA models trained within our\nframework using just 5\\% of the labelled data can achieve comparable\neffectiveness with supervised training using 20\\% of the labelled data.", "published": "2022-11-29 00:05:08", "link": "http://arxiv.org/abs/2211.15833v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs", "abstract": "Existing knowledge graph (KG) embedding models have primarily focused on\nstatic KGs. However, real-world KGs do not remain static, but rather evolve and\ngrow in tandem with the development of KG applications. Consequently, new facts\nand previously unseen entities and relations continually emerge, necessitating\nan embedding model that can quickly learn and transfer new knowledge through\ngrowth. Motivated by this, we delve into an expanding field of KG embedding in\nthis paper, i.e., lifelong KG embedding. We consider knowledge transfer and\nretention of the learning on growing snapshots of a KG without having to learn\nembeddings from scratch. The proposed model includes a masked KG autoencoder\nfor embedding learning and update, with an embedding transfer strategy to\ninject the learned knowledge into the new entity and relation embeddings, and\nan embedding regularization method to avoid catastrophic forgetting. To\ninvestigate the impacts of different aspects of KG growth, we construct four\ndatasets to evaluate the performance of lifelong KG embedding. Experimental\nresults show that the proposed model outperforms the state-of-the-art inductive\nand lifelong embedding baselines.", "published": "2022-11-29 00:43:44", "link": "http://arxiv.org/abs/2211.15845v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compressing Cross-Lingual Multi-Task Models at Qualtrics", "abstract": "Experience management is an emerging business area where organizations focus\non understanding the feedback of customers and employees in order to improve\ntheir end-to-end experiences. This results in a unique set of machine learning\nproblems to help understand how people feel, discover issues they care about,\nand find which actions need to be taken on data that are different in content\nand distribution from traditional NLP domains. In this paper, we present a case\nstudy of building text analysis applications that perform multiple\nclassification tasks efficiently in 12 languages in the nascent business area\nof experience management. In order to scale up modern ML methods on experience\ndata, we leverage cross lingual and multi-task modeling techniques to\nconsolidate our models into a single deployment to avoid overhead. We also make\nuse of model compression and model distillation to reduce overall inference\nlatency and hardware cost to the level acceptable for business needs while\nmaintaining model prediction quality. Our findings show that multi-task\nmodeling improves task performance for a subset of experience management tasks\nin both XLM-R and mBert architectures. Among the compressed architectures we\nexplored, we found that MiniLM achieved the best compression/performance\ntradeoff. Our case study demonstrates a speedup of up to 15.61x with 2.60%\naverage task degradation (or 3.29x speedup with 1.71% degradation) and\nestimated savings of 44% over using the original full-size model. These results\ndemonstrate a successful scaling up of text classification for the challenging\nnew area of ML for experience management.", "published": "2022-11-29 04:46:27", "link": "http://arxiv.org/abs/2211.15927v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "DiffG-RL: Leveraging Difference between State and Common Sense", "abstract": "Taking into account background knowledge as the context has always been an\nimportant part of solving tasks that involve natural language. One\nrepresentative example of such tasks is text-based games, where players need to\nmake decisions based on both description text previously shown in the game, and\ntheir own background knowledge about the language and common sense. In this\nwork, we investigate not simply giving common sense, as can be seen in prior\nresearch, but also its effective usage. We assume that a part of the\nenvironment states different from common sense should constitute one of the\ngrounds for action selection. We propose a novel agent, DiffG-RL, which\nconstructs a Difference Graph that organizes the environment states and common\nsense by means of interactive objects with a dedicated graph encoder. DiffG-RL\nalso contains a framework for extracting the appropriate amount and\nrepresentation of common sense from the source to support the construction of\nthe graph. We validate DiffG-RL in experiments with text-based games that\nrequire common sense and show that it outperforms baselines by 17% of scores.\nThe code is available at https://github.com/ibm/diffg-rl", "published": "2022-11-29 07:53:55", "link": "http://arxiv.org/abs/2211.16002v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diverse Multi-Answer Retrieval with Determinantal Point Processes", "abstract": "Often questions provided to open-domain question answering systems are\nambiguous. Traditional QA systems that provide a single answer are incapable of\nanswering ambiguous questions since the question may be interpreted in several\nways and may have multiple distinct answers. In this paper, we address\nmulti-answer retrieval which entails retrieving passages that can capture\nmajority of the diverse answers to the question. We propose a re-ranking based\napproach using Determinantal point processes utilizing BERT as kernels. Our\nmethod jointly considers query-passage relevance and passage-passage\ncorrelation to retrieve passages that are both query-relevant and diverse.\nResults demonstrate that our re-ranking technique outperforms state-of-the-art\nmethod on the AmbigQA dataset.", "published": "2022-11-29 08:54:05", "link": "http://arxiv.org/abs/2211.16029v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Dependency-aware Self-training for Entity Alignment", "abstract": "Entity Alignment (EA), which aims to detect entity mappings (i.e. equivalent\nentity pairs) in different Knowledge Graphs (KGs), is critical for KG fusion.\nNeural EA methods dominate current EA research but still suffer from their\nreliance on labelled mappings. To solve this problem, a few works have explored\nboosting the training of EA models with self-training, which adds confidently\npredicted mappings into the training data iteratively. Though the effectiveness\nof self-training can be glimpsed in some specific settings, we still have very\nlimited knowledge about it. One reason is the existing works concentrate on\ndevising EA models and only treat self-training as an auxiliary tool. To fill\nthis knowledge gap, we change the perspective to self-training to shed light on\nit. In addition, the existing self-training strategies have limited impact\nbecause they introduce either much False Positive noise or a low quantity of\nTrue Positive pseudo mappings. To improve self-training for EA, we propose\nexploiting the dependencies between entities, a particularity of EA, to\nsuppress the noise without hurting the recall of True Positive mappings.\nThrough extensive experiments, we show that the introduction of dependency\nmakes the self-training strategy for EA reach a new level. The value of\nself-training in alleviating the reliance on annotation is actually much higher\nthan what has been realised. Furthermore, we suggest future study on smart data\nannotation to break the ceiling of EA performance.", "published": "2022-11-29 11:24:14", "link": "http://arxiv.org/abs/2211.16101v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Few-shot Query-Focused Summarization with Prefix-Merging", "abstract": "Query-focused summarization has been considered as an important extension for\ntext summarization. It aims to generate a concise highlight for a given query.\nDifferent from text summarization, query-focused summarization has long been\nplagued by the problem of lacking high-quality large-scale datasets. In this\npaper, we investigate the idea that whether we can integrate and transfer the\nknowledge of text summarization and question answering to assist the few-shot\nlearning in query-focused summarization. Here, we propose prefix-merging, a\nprefix-based pretraining strategy for few-shot learning in query-focused\nsummarization. Drawn inspiration from prefix-tuning, we are allowed to\nintegrate the task knowledge from text summarization and question answering\ninto a properly designed prefix and apply the merged prefix to query-focused\nsummarization. With only a small amount of trainable parameters, prefix-merging\noutperforms fine-tuning on query-focused summarization. We further discuss the\ninfluence of different prefix designs and propose a visualized explanation for\nhow prefix-merging works.", "published": "2022-11-29 12:48:37", "link": "http://arxiv.org/abs/2211.16164v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learnings from Technological Interventions in a Low Resource Language:\n  Enhancing Information Access in Gondi", "abstract": "The primary obstacle to developing technologies for low-resource languages is\nthe lack of representative, usable data. In this paper, we report the\ndeployment of technology-driven data collection methods for creating a corpus\nof more than 60,000 translations from Hindi to Gondi, a low-resource vulnerable\nlanguage spoken by around 2.3 million tribal people in south and central India.\nDuring this process, we help expand information access in Gondi across 2\ndifferent dimensions (a) The creation of linguistic resources that can be used\nby the community, such as a dictionary, children's stories, Gondi translations\nfrom multiple sources and an Interactive Voice Response (IVR) based mass\nawareness platform; (b) Enabling its use in the digital domain by developing a\nHindi-Gondi machine translation model, which is compressed by nearly 4 times to\nenable it's edge deployment on low-resource edge devices and in areas of little\nto no internet connectivity. We also present preliminary evaluations of\nutilizing the developed machine translation model to provide assistance to\nvolunteers who are involved in collecting more data for the target language.\nThrough these interventions, we not only created a refined and evaluated corpus\nof 26,240 Hindi-Gondi translations that was used for building the translation\nmodel but also engaged nearly 850 community members who can help take Gondi\nonto the internet.", "published": "2022-11-29 13:03:37", "link": "http://arxiv.org/abs/2211.16172v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "AutoCAD: Automatically Generating Counterfactuals for Mitigating\n  Shortcut Learning", "abstract": "Recent studies have shown the impressive efficacy of counterfactually\naugmented data (CAD) for reducing NLU models' reliance on spurious features and\nimproving their generalizability. However, current methods still heavily rely\non human efforts or task-specific designs to generate counterfactuals, thereby\nimpeding CAD's applicability to a broad range of NLU tasks. In this paper, we\npresent AutoCAD, a fully automatic and task-agnostic CAD generation framework.\nAutoCAD first leverages a classifier to unsupervisedly identify rationales as\nspans to be intervened, which disentangles spurious and causal features. Then,\nAutoCAD performs controllable generation enhanced by unlikelihood training to\nproduce diverse counterfactuals. Extensive evaluations on multiple\nout-of-domain and challenge benchmarks demonstrate that AutoCAD consistently\nand significantly boosts the out-of-distribution performance of powerful\npre-trained models across different NLU tasks, which is comparable or even\nbetter than previous state-of-the-art human-in-the-loop or task-specific CAD\nmethods. The code is publicly available at https://github.com/thu-coai/AutoCAD.", "published": "2022-11-29 13:39:53", "link": "http://arxiv.org/abs/2211.16202v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Evaluating Unsupervised Text Classification: Zero-shot and\n  Similarity-based Approaches", "abstract": "Text classification of unseen classes is a challenging Natural Language\nProcessing task and is mainly attempted using two different types of\napproaches. Similarity-based approaches attempt to classify instances based on\nsimilarities between text document representations and class description\nrepresentations. Zero-shot text classification approaches aim to generalize\nknowledge gained from a training task by assigning appropriate labels of\nunknown classes to text documents. Although existing studies have already\ninvestigated individual approaches to these categories, the experiments in\nliterature do not provide a consistent comparison. This paper addresses this\ngap by conducting a systematic evaluation of different similarity-based and\nzero-shot approaches for text classification of unseen classes. Different\nstate-of-the-art approaches are benchmarked on four text classification\ndatasets, including a new dataset from the medical domain. Additionally, novel\nSimCSE and SBERT-based baselines are proposed, as other baselines used in\nexisting work yield weak classification results and are easily outperformed.\nFinally, the novel similarity-based Lbl2TransformerVec approach is presented,\nwhich outperforms previous state-of-the-art approaches in unsupervised text\nclassification. Our experiments show that similarity-based approaches\nsignificantly outperform zero-shot approaches in most cases. Additionally,\nusing SimCSE or SBERT embeddings instead of simpler text representations\nincreases similarity-based classification results even further.", "published": "2022-11-29 15:14:47", "link": "http://arxiv.org/abs/2211.16285v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Chaining Simultaneous Thoughts for Numerical Reasoning", "abstract": "Given that rich information is hidden behind ubiquitous numbers in text,\nnumerical reasoning over text should be an essential skill of AI systems. To\nderive precise equations to solve numerical reasoning problems, previous work\nfocused on modeling the structures of equations, and has proposed various\nstructured decoders. Though structure modeling proves to be effective, these\nstructured decoders construct a single equation in a pre-defined autoregressive\norder, potentially placing an unnecessary restriction on how a model should\ngrasp the reasoning process. Intuitively, humans may have numerous pieces of\nthoughts popping up in no pre-defined order; thoughts are not limited to the\nproblem at hand, and can even be concerned with other related problems. By\ncomparing diverse thoughts and chaining relevant pieces, humans are less prone\nto errors. In this paper, we take this inspiration and propose CANTOR, a\nnumerical reasoner that models reasoning steps using a directed acyclic graph\nwhere we produce diverse reasoning steps simultaneously without pre-defined\ndecoding dependencies, and compare and chain relevant ones to reach a solution.\nExtensive experiments demonstrated the effectiveness of CANTOR under both\nfully-supervised and weakly-supervised settings.", "published": "2022-11-29 18:52:06", "link": "http://arxiv.org/abs/2211.16482v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving astroBERT using Semantic Textual Similarity", "abstract": "The NASA Astrophysics Data System (ADS) is an essential tool for researchers\nthat allows them to explore the astronomy and astrophysics scientific\nliterature, but it has yet to exploit recent advances in natural language\nprocessing. At ADASS 2021, we introduced astroBERT, a machine learning language\nmodel tailored to the text used in astronomy papers in ADS. In this work we:\n  - announce the first public release of the astroBERT language model;\n  - show how astroBERT improves over existing public language models on\nastrophysics specific tasks;\n  - and detail how ADS plans to harness the unique structure of scientific\npapers, the citation graph and citation context, to further improve astroBERT.", "published": "2022-11-29 16:15:32", "link": "http://arxiv.org/abs/2212.00744v1", "categories": ["cs.CL", "astro-ph.IM"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Learning for Joint Intent and Slot Labeling", "abstract": "It is expensive and difficult to obtain the large number of sentence-level\nintent and token-level slot label annotations required to train neural network\n(NN)-based Natural Language Understanding (NLU) components of task-oriented\ndialog systems, especially for the many real world tasks that have a large and\ngrowing number of intents and slot types. While zero shot learning approaches\nthat require no labeled examples -- only features and auxiliary information --\nhave been proposed only for slot labeling, we show that one can profitably\nperform joint zero-shot intent classification and slot labeling. We demonstrate\nthe value of capturing dependencies between intents and slots, and between\ndifferent slots in an utterance in the zero shot setting. We describe NN\narchitectures that translate between word and sentence embedding spaces, and\ndemonstrate that these modifications are required to enable zero shot learning\nfor this task. We show a substantial improvement over strong baselines and\nexplain the intuition behind each architectural modification through\nvisualizations and ablation studies.", "published": "2022-11-29 01:58:25", "link": "http://arxiv.org/abs/2212.07922v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ClueWeb22: 10 Billion Web Documents with Visual and Semantic Information", "abstract": "ClueWeb22, the newest iteration of the ClueWeb line of datasets, provides 10\nbillion web pages affiliated with rich information. Its design was influenced\nby the need for a high quality, large scale web corpus to support a range of\nacademic and industry research, for example, in information systems,\nretrieval-augmented AI systems, and model pretraining. Compared with earlier\nClueWeb corpora, the ClueWeb22 corpus is larger, more varied, of\nhigher-quality, and aligned with the document distributions in commercial web\nsearch. Besides raw HTML, ClueWeb22 includes rich information about the web\npages provided by industry-standard document understanding systems, including\nthe visual representation of pages rendered by a web browser, parsed HTML\nstructure information from a neural network parser, and pre-processed cleaned\ndocument text to lower the barrier to entry. Many of these signals have been\nwidely used in industry but are available to the research community for the\nfirst time at this scale.", "published": "2022-11-29 00:49:40", "link": "http://arxiv.org/abs/2211.15848v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Evaluating and reducing the distance between synthetic and real speech\n  distributions", "abstract": "While modern Text-to-Speech (TTS) systems can produce natural-sounding\nspeech, they remain unable to reproduce the full diversity found in natural\nspeech data. We consider the distribution of all possible real speech samples\nthat could be generated by these speakers alongside the distribution of all\nsynthetic samples that could be generated for the same set of speakers, using a\nparticular TTS system. We set out to quantify the distance between real and\nsynthetic speech via a range of utterance-level statistics related to\nproperties of the speaker, speech prosody and acoustic environment. Differences\nin the distribution of these statistics are evaluated using the Wasserstein\ndistance. We reduce these distances by providing ground-truth values at\ngeneration time, and quantify the improvements to the overall distribution\ndistance, approximated using an automatic speech recognition system. Our best\nsystem achieves a 10\\% reduction in distribution distance.", "published": "2022-11-29 09:50:24", "link": "http://arxiv.org/abs/2211.16049v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Neural Transducer Training: Reduced Memory Consumption with Sample-wise\n  Computation", "abstract": "The neural transducer is an end-to-end model for automatic speech recognition\n(ASR). While the model is well-suited for streaming ASR, the training process\nremains challenging. During training, the memory requirements may quickly\nexceed the capacity of state-of-the-art GPUs, limiting batch size and sequence\nlengths. In this work, we analyze the time and space complexity of a typical\ntransducer training setup. We propose a memory-efficient training method that\ncomputes the transducer loss and gradients sample by sample. We present\noptimizations to increase the efficiency and parallelism of the sample-wise\nmethod. In a set of thorough benchmarks, we show that our sample-wise method\nsignificantly reduces memory usage, and performs at competitive speed when\ncompared to the default batched computation. As a highlight, we manage to\ncompute the transducer loss and gradients for a batch size of 1024, and audio\nlength of 40 seconds, using only 6 GB of memory.", "published": "2022-11-29 14:57:23", "link": "http://arxiv.org/abs/2211.16270v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Controllable speech synthesis by learning discrete phoneme-level\n  prosodic representations", "abstract": "In this paper, we present a novel method for phoneme-level prosody control of\nF0 and duration using intuitive discrete labels. We propose an unsupervised\nprosodic clustering process which is used to discretize phoneme-level F0 and\nduration features from a multispeaker speech dataset. These features are fed as\nan input sequence of prosodic labels to a prosody encoder module which augments\nan autoregressive attention-based text-to-speech model. We utilize various\nmethods in order to improve prosodic control range and coverage, such as\naugmentation, F0 normalization, balanced clustering for duration and\nspeaker-independent clustering. The final model enables fine-grained\nphoneme-level prosody control for all speakers contained in the training set,\nwhile maintaining the speaker identity. Instead of relying on reference\nutterances for inference, we introduce a prior prosody encoder which learns the\nstyle of each speaker and enables speech synthesis without the requirement of\nreference audio. We also fine-tune the multispeaker model to unseen speakers\nwith limited amounts of data, as a realistic application scenario and show that\nthe prosody control capabilities are maintained, verifying that the\nspeaker-independent prosodic clustering is effective. Experimental results show\nthat the model has high output speech quality and that the proposed method\nallows efficient prosody control within each speaker's range despite the\nvariability that a multispeaker setting introduces.", "published": "2022-11-29 15:43:36", "link": "http://arxiv.org/abs/2211.16307v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Coder Reviewer Reranking for Code Generation", "abstract": "Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.", "published": "2022-11-29 18:56:33", "link": "http://arxiv.org/abs/2211.16490v1", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Abstract Visual Reasoning with Tangram Shapes", "abstract": "We introduce KiloGram, a resource for studying abstract visual reasoning in\nhumans and machines. Drawing on the history of tangram puzzles as stimuli in\ncognitive science, we build a richly annotated dataset that, with >1k distinct\nstimuli, is orders of magnitude larger and more diverse than prior resources.\nIt is both visually and linguistically richer, moving beyond whole shape\ndescriptions to include segmentation maps and part labels. We use this resource\nto evaluate the abstract visual reasoning capacities of recent multi-modal\nmodels. We observe that pre-trained weights demonstrate limited abstract\nreasoning, which dramatically improves with fine-tuning. We also observe that\nexplicitly describing parts aids abstract reasoning for both humans and models,\nespecially when jointly encoding the linguistic and visual inputs. KiloGram is\navailable at https://lil.nlp.cornell.edu/kilogram .", "published": "2022-11-29 18:57:06", "link": "http://arxiv.org/abs/2211.16492v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Soft Alignment Objectives for Robust Adaptation of Language Generation", "abstract": "Domain adaptation allows generative language models to address specific flaws\ncaused by the domain shift of their application. However, the traditional\nadaptation by further training on in-domain data rapidly weakens the model's\nability to generalize to other domains, making the open-ended deployments of\nthe adapted models prone to errors. This work introduces novel training\nobjectives built upon a semantic similarity of the predicted tokens to the\nreference.\n  Our results show that (1) avoiding the common assumption of a single correct\nprediction by constructing the training target from tokens' semantic similarity\ncan mitigate catastrophic forgetting during domain adaptation, while (2)\npreserving the quality of the adaptation, (3) with negligible additions to\ncompute costs.\n  In the broader context, the objectives grounded in a continuous token\nsimilarity pioneer the exploration of the middle ground between the efficient\nbut na\\\"{\\i}ve exact-match token-level objectives and expressive but\ncomputationally- and resource-intensive sequential objectives.", "published": "2022-11-29 19:23:04", "link": "http://arxiv.org/abs/2211.16550v2", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "SPARTAN: Sparse Hierarchical Memory for Parameter-Efficient Transformers", "abstract": "Fine-tuning pre-trained language models (PLMs) achieves impressive\nperformance on a range of downstream tasks, and their sizes have consequently\nbeen getting bigger. Since a different copy of the model is required for each\ntask, this paradigm is infeasible for storage-constrained edge devices like\nmobile phones. In this paper, we propose SPARTAN, a parameter efficient (PE)\nand computationally fast architecture for edge devices that adds hierarchically\norganized sparse memory after each Transformer layer. SPARTAN freezes the PLM\nparameters and fine-tunes only its memory, thus significantly reducing storage\ncosts by re-using the PLM backbone for different tasks. SPARTAN contains two\nlevels of memory, with only a sparse subset of parents being chosen in the\nfirst level for each input, and children cells corresponding to those parents\nbeing used to compute an output representation. This sparsity combined with\nother architecture optimizations improves SPARTAN's throughput by over 90%\nduring inference on a Raspberry Pi 4 when compared to PE baselines (adapters)\nwhile also outperforming the latter by 0.1 points on the GLUE benchmark.\nFurther, it can be trained 34% faster in a few-shot setting, while performing\nwithin 0.9 points of adapters. Qualitative analysis shows that different parent\ncells in SPARTAN specialize in different topics, thus dividing responsibility\nefficiently.", "published": "2022-11-29 23:59:20", "link": "http://arxiv.org/abs/2211.16634v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better Transcription of UK Supreme Court Hearings", "abstract": "Transcription of legal proceedings is very important to enable access to\njustice. However, speech transcription is an expensive and slow process. In\nthis paper we describe part of a combined research and industrial project for\nbuilding an automated transcription tool designed specifically for the Justice\nsector in the UK. We explain the challenges involved in transcribing court room\nhearings and the Natural Language Processing (NLP) techniques we employ to\ntackle these challenges. We will show that fine-tuning a generic off-the-shelf\npre-trained Automatic Speech Recognition (ASR) system with an in-domain\nlanguage model as well as infusing common phrases extracted with a collocation\ndetection model can improve not only the Word Error Rate (WER) of the\ntranscribed hearings but avoid critical errors that are specific of the legal\njargon and terminology commonly used in British courts.", "published": "2022-11-29 17:02:00", "link": "http://arxiv.org/abs/2211.17094v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Model Extraction Attack against Self-supervised Speech Models", "abstract": "Self-supervised learning (SSL) speech models generate meaningful\nrepresentations of given clips and achieve incredible performance across\nvarious downstream tasks. Model extraction attack (MEA) often refers to an\nadversary stealing the functionality of the victim model with only query\naccess. In this work, we study the MEA problem against SSL speech model with a\nsmall number of queries. We propose a two-stage framework to extract the model.\nIn the first stage, SSL is conducted on the large-scale unlabeled corpus to\npre-train a small speech model. Secondly, we actively sample a small portion of\nclips from the unlabeled corpus and query the target model with these clips to\nacquire their representations as labels for the small model's second-stage\ntraining. Experiment results show that our sampling methods can effectively\nextract the target model without knowing any information about its model\narchitecture.", "published": "2022-11-29 09:28:05", "link": "http://arxiv.org/abs/2211.16044v2", "categories": ["cs.SD", "cs.CL", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Proactive Moderation of Online Discussions: Existing Practices and the\n  Potential for Algorithmic Support", "abstract": "To address the widespread problem of uncivil behavior, many online discussion\nplatforms employ human moderators to take action against objectionable content,\nsuch as removing it or placing sanctions on its authors. This reactive paradigm\nof taking action against already-posted antisocial content is currently the\nmost common form of moderation, and has accordingly underpinned many recent\nefforts at introducing automation into the moderation process. Comparatively\nless work has been done to understand other moderation paradigms -- such as\nproactively discouraging the emergence of antisocial behavior rather than\nreacting to it -- and the role algorithmic support can play in these paradigms.\nIn this work, we investigate such a proactive framework for moderation in a\ncase study of a collaborative setting: Wikipedia Talk Pages. We employ a mixed\nmethods approach, combining qualitative and design components for a holistic\nanalysis. Through interviews with moderators, we find that despite a lack of\ntechnical and social support, moderators already engage in a number of\nproactive moderation behaviors, such as preemptively intervening in\nconversations to keep them on track. Further, we explore how automation could\nassist with this existing proactive moderation workflow by building a prototype\ntool, presenting it to moderators, and examining how the assistance it provides\nmight fit into their workflow. The resulting feedback uncovers both strengths\nand drawbacks of the prototype tool and suggests concrete steps towards further\ndeveloping such assisting technology so it can most effectively support\nmoderators in their existing proactive moderation workflow.", "published": "2022-11-29 19:00:02", "link": "http://arxiv.org/abs/2211.16525v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "MMSpeech: Multi-modal Multi-task Encoder-Decoder Pre-training for Speech\n  Recognition", "abstract": "In this paper, we propose a novel multi-modal multi-task encoder-decoder\npre-training framework (MMSpeech) for Mandarin automatic speech recognition\n(ASR), which employs both unlabeled speech and text data. The main difficulty\nin speech-text joint pre-training comes from the significant difference between\nspeech and text modalities, especially for Mandarin speech and text. Unlike\nEnglish and other languages with an alphabetic writing system, Mandarin uses an\nideographic writing system where character and sound are not tightly mapped to\none another. Therefore, we propose to introduce the phoneme modality into\npre-training, which can help capture modality-invariant information between\nMandarin speech and text. Specifically, we employ a multi-task learning\nframework including five self-supervised and supervised tasks with speech and\ntext data. For end-to-end pre-training, we introduce self-supervised\nspeech-to-pseudo-codes (S2C) and phoneme-to-text (P2T) tasks utilizing\nunlabeled speech and text data, where speech-pseudo-codes pairs and\nphoneme-text pairs are a supplement to the supervised speech-text pairs. To\ntrain the encoder to learn better speech representation, we introduce\nself-supervised masked speech prediction (MSP) and supervised phoneme\nprediction (PP) tasks to learn to map speech into phonemes. Besides, we\ndirectly add the downstream supervised speech-to-text (S2T) task into the\npre-training process, which can further improve the pre-training performance\nand achieve better recognition results even without fine-tuning. Experiments on\nAISHELL-1 show that our proposed method achieves state-of-the-art performance,\nwith a more than 40% relative improvement compared with other pre-training\nmethods.", "published": "2022-11-29 13:16:09", "link": "http://arxiv.org/abs/2212.00500v1", "categories": ["cs.MM", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Neural Vocoder Feature Estimation for Dry Singing Voice Separation", "abstract": "Singing voice separation (SVS) is a task that separates singing voice audio\nfrom its mixture with instrumental audio. Previous SVS studies have mainly\nemployed the spectrogram masking method which requires a large dimensionality\nin predicting the binary masks. In addition, they focused on extracting a vocal\nstem that retains the wet sound with the reverberation effect. This result may\nhinder the reusability of the isolated singing voice. This paper addresses the\nissues by predicting mel-spectrogram of dry singing voices from the mixed audio\nas neural vocoder features and synthesizing the singing voice waveforms from\nthe neural vocoder. We experimented with two separation methods. One is\npredicting binary masks in the mel-spectrogram domain and the other is directly\npredicting the mel-spectrogram. Furthermore, we add a singing voice detector to\nidentify the singing voice segments over time more explicitly. We measured the\nmodel performance in terms of audio, dereverberation, separation, and overall\nquality. The results show that our proposed model outperforms state-of-the-art\nsinging voice separation models in both objective and subjective evaluation\nexcept the audio quality.", "published": "2022-11-29 06:16:05", "link": "http://arxiv.org/abs/2211.15948v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Speech Phase Prediction based on Parallel Estimation Architecture\n  and Anti-Wrapping Losses", "abstract": "This paper presents a novel speech phase prediction model which predicts\nwrapped phase spectra directly from amplitude spectra by neural networks. The\nproposed model is a cascade of a residual convolutional network and a parallel\nestimation architecture. The parallel estimation architecture is composed of\ntwo parallel linear convolutional layers and a phase calculation formula,\nimitating the process of calculating the phase spectra from the real and\nimaginary parts of complex spectra and strictly restricting the predicted phase\nvalues to the principal value interval. To avoid the error expansion issue\ncaused by phase wrapping, we design anti-wrapping training losses defined\nbetween the predicted wrapped phase spectra and natural ones by activating the\ninstantaneous phase error, group delay error and instantaneous angular\nfrequency error using an anti-wrapping function. Experimental results show that\nour proposed neural speech phase prediction model outperforms the iterative\nGriffin-Lim algorithm and other neural network-based method, in terms of both\nreconstructed speech quality and generation speed.", "published": "2022-11-29 07:16:24", "link": "http://arxiv.org/abs/2211.15974v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hiding speaker's sex in speech using zero-evidence speaker\n  representation in an analysis/synthesis pipeline", "abstract": "The use of modern vocoders in an analysis/synthesis pipeline allows us to\ninvestigate high-quality voice conversion that can be used for privacy\npurposes. Here, we propose to transform the speaker embedding and the pitch in\norder to hide the sex of the speaker. ECAPA-TDNN-based speaker representation\nfed into a HiFiGAN vocoder is protected using a neural-discriminant analysis\napproach, which is consistent with the zero-evidence concept of privacy. This\napproach significantly reduces the information in speech related to the\nspeaker's sex while preserving speech content and some consistency in the\nresulting protected voices.", "published": "2022-11-29 10:20:31", "link": "http://arxiv.org/abs/2211.16065v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On Word Error Rate Definitions and their Efficient Computation for\n  Multi-Speaker Speech Recognition Systems", "abstract": "We propose a general framework to compute the word error rate (WER) of ASR\nsystems that process recordings containing multiple speakers at their input and\nthat produce multiple output word sequences (MIMO). Such ASR systems are\ntypically required, e.g., for meeting transcription. We provide an efficient\nimplementation based on a dynamic programming search in a multi-dimensional\nLevenshtein distance tensor under the constraint that a reference utterance\nmust be matched consistently with one hypothesis output. This also results in\nan efficient implementation of the ORC WER which previously suffered from\nexponential complexity. We give an overview of commonly used WER definitions\nfor multi-speaker scenarios and show that they are specializations of the above\nMIMO WER tuned to particular application scenarios. We conclude with a\ndiscussion of the pros and cons of the various WER definitions and a\nrecommendation when to use which.", "published": "2022-11-29 11:35:13", "link": "http://arxiv.org/abs/2211.16112v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Analysis of constant-Q filterbank based representations for speech\n  emotion recognition", "abstract": "This work analyzes the constant-Q filterbank-based time-frequency\nrepresentations for speech emotion recognition (SER). Constant-Q filterbank\nprovides non-linear spectro-temporal representation with higher frequency\nresolution at low frequencies. Our investigation reveals how the increased\nlow-frequency resolution benefits SER. The time-domain comparative analysis\nbetween short-term mel-frequency spectral coefficients (MFSCs) and constant-Q\nfilterbank-based features, namely constant-Q transform (CQT) and continuous\nwavelet transform (CWT), reveals that constant-Q representations provide higher\ntime-invariance at low-frequencies. This provides increased robustness against\nemotion irrelevant temporal variations in pitch, especially for low-arousal\nemotions. The corresponding frequency-domain analysis over different emotion\nclasses shows better resolution of pitch harmonics in constant-Q-based\ntime-frequency representations than MFSC. These advantages of constant-Q\nrepresentations are further consolidated by SER performance in the extensive\nevaluation of features over four publicly available databases with six advanced\ndeep neural network architectures as the back-end classifiers. Our inferences\nin this study hint toward the suitability and potentiality of constant-Q\nfeatures for SER.", "published": "2022-11-29 16:45:47", "link": "http://arxiv.org/abs/2211.16363v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OK Computer Analysis: An Audio Corpus Study of Radiohead", "abstract": "The application of music information retrieval techniques in popular music\nstudies has great promise. In the present work, a corpus of Radiohead songs\nacross their career from 1992 to 2017 are subjected to automated audio\nanalysis. We examine findings from a number of granularities and perspectives,\nincluding within song and between song examination of both timbral-rhythmic and\nharmonic features. Chronological changes include possible career spanning\neffects for a band's releases such as slowing tempi and reduced brightness, and\nthe timbral markers of Radiohead's expanding approach to instrumental resources\nmost identified with the Kid A and Amnesiac era. We conclude with a discussion\nhighlighting some challenges for this approach, and the potential for a field\nof audio file based career analysis.", "published": "2022-11-29 00:08:31", "link": "http://arxiv.org/abs/2211.15834v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JaCappella Corpus: A Japanese a Cappella Vocal Ensemble Corpus", "abstract": "We construct a corpus of Japanese a cappella vocal ensembles (jaCappella\ncorpus) for vocal ensemble separation and synthesis. It consists of 35\ncopyright-cleared vocal ensemble songs and their audio recordings of individual\nvoice parts. These songs were arranged from out-of-copyright Japanese\nchildren's songs and have six voice parts (lead vocal, soprano, alto, tenor,\nbass, and vocal percussion). They are divided into seven subsets, each of which\nfeatures typical characteristics of a music genre such as jazz and enka. The\nvariety in genre and voice part match vocal ensembles recently widespread in\nsocial media services such as YouTube, although the main targets of\nconventional vocal ensemble datasets are choral singing made up of soprano,\nalto, tenor, and bass. Experimental evaluation demonstrates that our corpus is\na challenging resource for vocal ensemble separation. Our corpus is available\non our project page (https://tomohikonakamura.github.io/jaCappella_corpus/).", "published": "2022-11-29 08:52:29", "link": "http://arxiv.org/abs/2211.16028v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
