{"title": "Hierarchical Reinforced Trader (HRT): A Bi-Level Approach for Optimizing Stock Selection and Execution", "abstract": "Leveraging Deep Reinforcement Learning (DRL) in automated stock trading has\nshown promising results, yet its application faces significant challenges,\nincluding the curse of dimensionality, inertia in trading actions, and\ninsufficient portfolio diversification. Addressing these challenges, we\nintroduce the Hierarchical Reinforced Trader (HRT), a novel trading strategy\nemploying a bi-level Hierarchical Reinforcement Learning framework. The HRT\nintegrates a Proximal Policy Optimization (PPO)-based High-Level Controller\n(HLC) for strategic stock selection with a Deep Deterministic Policy Gradient\n(DDPG)-based Low-Level Controller (LLC) tasked with optimizing trade executions\nto enhance portfolio value. In our empirical analysis, comparing the HRT agent\nwith standalone DRL models and the S&P 500 benchmark during both bullish and\nbearish market conditions, we achieve a positive and higher Sharpe ratio. This\nadvancement not only underscores the efficacy of incorporating hierarchical\nstructures into DRL strategies but also mitigates the aforementioned\nchallenges, paving the way for designing more profitable and robust trading\nalgorithms in complex markets.", "published": "2024-10-19 01:29:38", "link": "http://arxiv.org/abs/2410.14927v1", "categories": ["q-fin.TR", "cs.CE", "cs.LG"], "primary_category": "q-fin.TR"}
