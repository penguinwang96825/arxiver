{"title": "Asset pricing under model uncertainty with finite time and states", "abstract": "In this study, we consider the asset pricing under model uncertainty with\nfinite time and under a family of probability, and explore its relationship\nwith risk neutral probability meastates structure. For the single-period\nsecurities model, we give a novel definition of arbitrage sure. Focusing on the\nfinancial market with short sales prohibitions, we separately investigate the\nnecessary and sufficient conditions for no-arbitrage asset pricing based on\nnonlinear expectation which composed with a family of probability. When each\nlinear expectation driven by the probability in the family of probability\nbecomes martingale measure, the necessary and sufficient conditions are same,\nand coincide with the existing results. Furthermore, we expand the main results\nof single-period securities model to the case of multi-period securities model.\nBy-product, we obtain the superhedging prices of contingent claim under model\nuncertainty.", "published": "2024-08-23 13:12:02", "link": "http://arxiv.org/abs/2408.13048v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Causal Hierarchy in the Financial Market Network -- Uncovered by the Helmholtz-Hodge-Kodaira Decomposition", "abstract": "Granger causality can uncover the cause and effect relationships in financial\nnetworks. However, such networks can be convoluted and difficult to interpret,\nbut the Helmholtz-Hodge-Kodaira decomposition can split them into a rotational\nand gradient component which reveals the hierarchy of Granger causality flow.\nUsing Kenneth French's business sector return time series, it is revealed that\nduring the Covid crisis, precious metals and pharmaceutical products are causal\ndrivers of the financial network. Moreover, the estimated Granger causality\nnetwork shows a high connectivity during crisis which means that the research\npresented here can be especially useful to better understand crises in the\nmarket by revealing the dominant drivers of the crisis dynamics.", "published": "2024-08-23 05:09:10", "link": "http://arxiv.org/abs/2408.12839v1", "categories": ["q-fin.ST", "physics.data-an", "stat.AP"], "primary_category": "q-fin.ST"}
{"title": "Controllable Financial Market Generation with Diffusion Guided Meta Agent", "abstract": "Order flow modeling stands as the most fundamental and essential financial\ntask, as orders embody the minimal unit within a financial market. However,\ncurrent approaches often result in unsatisfactory fidelity in generating order\nflow, and their generation lacks controllability, thereby limiting their\napplication scenario. In this paper, we advocate incorporating controllability\ninto the market generation process, and propose a Diffusion Guided meta\nAgent(DiGA) model to address the problem. Specifically, we utilize a diffusion\nmodel to capture dynamics of market state represented by time-evolving\ndistribution parameters about mid-price return rate and order arrival rate, and\ndefine a meta agent with financial economic priors to generate orders from the\ncorresponding distributions. Extensive experimental results demonstrate that\nour method exhibits outstanding controllability and fidelity in generation.\nFurthermore, we validate DiGA's effectiveness as generative environment for\ndownstream financial applications.", "published": "2024-08-23 11:15:36", "link": "http://arxiv.org/abs/2408.12991v2", "categories": ["cs.CE", "q-fin.TR"], "primary_category": "cs.CE"}
{"title": "Quality or Quantity? On Data Scale and Diversity in Adapting Large\n  Language Models for Low-Resource Translation", "abstract": "Despite the recent popularity of Large Language Models (LLMs) in Machine\nTranslation (MT), their performance in low-resource languages (LRLs) still lags\nsignificantly behind Neural Machine Translation (NMT) models. In this work, we\nexplore what it would take to adapt LLMs for the low-resource setting.\nParticularly, we re-examine the role of two factors: a) the importance and\napplication of parallel data, and b) diversity in Supervised Fine-Tuning (SFT).\nRecently, parallel data has seen reduced use in adapting LLMs for MT, while\ndata diversity has been embraced to promote transfer across languages and\ntasks. However, for low-resource LLM-MT, we show that the opposite is true for\nboth considerations: a) parallel data is critical during both pre-training and\nSFT; b) diversity tends to cause interference instead of transfer. Our\nexperiments with three LLMs across two low-resourced language groups --\nIndigenous American and North-East Indian -- reveal consistent trends,\nunderscoring the generalizability of our findings. We believe these insights\nwill be valuable for scaling to massively multilingual LLM-MT models that can\neffectively serve LRLs.", "published": "2024-08-23 00:59:38", "link": "http://arxiv.org/abs/2408.12780v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounding Fallacies Misrepresenting Scientific Publications in Evidence", "abstract": "Health-related misinformation claims often falsely cite a credible biomedical\npublication as evidence. These publications only superficially seem to support\nthe false claim, when logical fallacies are applied. In this work, we aim to\ndetect and to highlight such fallacies, which requires assessing the exact\ncontent of the misrepresented publications. To achieve this, we introduce\nMissciPlus, an extension of the fallacy detection dataset Missci. MissciPlus\nextends Missci by grounding the applied fallacies in real-world passages from\nmisrepresented studies. This creates a realistic test-bed for detecting and\nverbalizing fallacies under real-world input conditions, and enables new and\nrealistic passage-retrieval tasks. MissciPlus is the first logical fallacy\ndataset which pairs the real-world misrepresented evidence with incorrect\nclaims, identical to the input to evidence-based fact-checking models. With\nMissciPlus, we i) benchmark retrieval models in identifying passages that\nsupport claims only with fallacious reasoning, ii) evaluate how well LLMs\nverbalize fallacious reasoning based on misrepresented scientific passages, and\niii) assess the effectiveness of fact-checking models in refuting claims that\nmisrepresent biomedical research. Our findings show that current fact-checking\nmodels struggle to use misrepresented scientific passages to refute\nmisinformation. Moreover, these passages can mislead LLMs into accepting false\nclaims as true.", "published": "2024-08-23 03:16:26", "link": "http://arxiv.org/abs/2408.12812v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction", "abstract": "Human mobility prediction is essential for applications like urban planning\nand transportation management, yet it remains challenging due to the complex,\noften implicit, intentions behind human behavior. Existing models predominantly\nfocus on spatiotemporal patterns, paying less attention to the underlying\nintentions that govern movements. Recent advancements in large language models\n(LLMs) offer a promising alternative research angle for integrating commonsense\nreasoning into mobility prediction. However, it is a non-trivial problem\nbecause LLMs are not natively built for mobility intention inference, and they\nalso face scalability issues and integration difficulties with spatiotemporal\nmodels. To address these challenges, we propose a novel LIMP (LLMs for\nIntent-ware Mobility Prediction) framework. Specifically, LIMP introduces an\n\"Analyze-Abstract-Infer\" (A2I) agentic workflow to unleash LLM's commonsense\nreasoning power for mobility intention inference. Besides, we design an\nefficient fine-tuning scheme to transfer reasoning power from commercial LLM to\nsmaller-scale, open-source language model, ensuring LIMP's scalability to\nmillions of mobility records. Moreover, we propose a transformer-based\nintention-aware mobility prediction model to effectively harness the intention\ninference ability of LLM. Evaluated on two real-world datasets, LIMP\nsignificantly outperforms baseline models, demonstrating improved accuracy in\nnext-location prediction and effective intention inference. The\ninterpretability of intention-aware mobility prediction highlights our LIMP\nframework's potential for real-world applications. Codes and data can be found\nin https://github.com/tsinghua-fib-lab/LIMP .", "published": "2024-08-23 04:28:56", "link": "http://arxiv.org/abs/2408.12832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Internal and External Knowledge Interactive Refinement Framework for\n  Knowledge-Intensive Question Answering", "abstract": "Recent works have attempted to integrate external knowledge into LLMs to\naddress the limitations and potential factual errors in LLM-generated content.\nHowever, how to retrieve the correct knowledge from the large amount of\nexternal knowledge imposes a challenge. To this end, we empirically observe\nthat LLMs have already encoded rich knowledge in their pretrained parameters\nand utilizing these internal knowledge improves the retrieval of external\nknowledge when applying them to knowledge-intensive tasks. In this paper, we\npropose a new internal and external knowledge interactive refinement paradigm\ndubbed IEKR to utilize internal knowledge in LLM to help retrieve relevant\nknowledge from the external knowledge base, as well as exploit the external\nknowledge to refine the hallucination of generated internal knowledge. By\nsimply adding a prompt like 'Tell me something about' to the LLMs, we try to\nreview related explicit knowledge and insert them with the query into the\nretriever for external retrieval. The external knowledge is utilized to\ncomplement the internal knowledge into input of LLM for answers. We conduct\nexperiments on 3 benchmark datasets in knowledge-intensive question answering\ntask with different LLMs and domains, achieving the new state-of-the-art.\nFurther analysis shows the effectiveness of different modules in our approach.", "published": "2024-08-23 10:52:57", "link": "http://arxiv.org/abs/2408.12979v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks:\n  Explainable Metrics and Diverse Prompt Templates", "abstract": "LLM-as-a-Judge has been widely applied to evaluate and compare different LLM\nalignmnet approaches (e.g., RLHF and DPO). However, concerns regarding its\nreliability have emerged, due to LLM judges' biases and inconsistent\ndecision-making. Previous research has developed evaluation frameworks to\nassess reliability of LLM judges and their alignment with human preferences.\nHowever, the employed evaluation metrics often lack adequate explainability and\nfail to address LLM internal inconsistency. Additionally, existing studies\ninadequately explore the impact of various prompt templates when applying\nLLM-as-a-Judge methods, leading to potentially inconsistent comparisons between\ndifferent alignment algorithms. In this work, we systematically evaluate\nLLM-as-a-Judge on alignment tasks by defining more theoretically interpretable\nevaluation metrics and explicitly mitigating LLM internal inconsistency from\nreliability metrics. We develop an open-source framework to evaluate, compare,\nand visualize the reliability and alignment of LLM judges, which facilitates\npractitioners to choose LLM judges for alignment tasks. In the experiments, we\nexamine effects of diverse prompt templates on LLM-judge reliability and also\ndemonstrate our developed framework by comparing various LLM judges on two\ncommon alignment datasets (i.e., TL;DR Summarization and HH-RLHF-Helpfulness).\nOur results indicate a significant impact of prompt templates on LLM judge\nperformance, as well as a mediocre alignment level between the tested LLM\njudges and human evaluators.", "published": "2024-08-23 11:49:01", "link": "http://arxiv.org/abs/2408.13006v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In-Context Learning with Reinforcement Learning for Incomplete Utterance\n  Rewriting", "abstract": "In-context learning (ICL) of large language models (LLMs) has attracted\nincreasing attention in the community where LLMs make predictions only based on\ninstructions augmented with a few examples. Existing example selection methods\nfor ICL utilize sparse or dense retrievers and derive effective performance.\nHowever, these methods do not utilize direct feedback of LLM to train the\nretriever and the examples selected can not necessarily improve the analogy\nability of LLM. To tackle this, we propose our policy-based reinforcement\nlearning framework for example selection (RLS), which consists of a language\nmodel (LM) selector and an LLM generator. The LM selector encodes the candidate\nexamples into dense representations and selects the top-k examples into the\ndemonstration for LLM. The outputs of LLM are adopted to compute the reward and\npolicy gradient to optimize the LM selector. We conduct experiments on\ndifferent datasets and significantly outperform existing example selection\nmethods. Moreover, our approach shows advantages over supervised finetuning\n(SFT) models in few shot setting. Further experiments show the balance of\nabundance and the similarity with the test case of examples is important for\nICL performance of LLM.", "published": "2024-08-23 12:32:12", "link": "http://arxiv.org/abs/2408.13028v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of child development facts and myths using text mining\n  techniques and classification models", "abstract": "The rapid dissemination of misinformation on the internet complicates the\ndecision-making process for individuals seeking reliable information,\nparticularly parents researching child development topics. This misinformation\ncan lead to adverse consequences, such as inappropriate treatment of children\nbased on myths. While previous research has utilized text-mining techniques to\npredict child abuse cases, there has been a gap in the analysis of child\ndevelopment myths and facts. This study addresses this gap by applying text\nmining techniques and classification models to distinguish between myths and\nfacts about child development, leveraging newly gathered data from publicly\navailable websites. The research methodology involved several stages. First,\ntext mining techniques were employed to pre-process the data, ensuring enhanced\naccuracy. Subsequently, the structured data was analysed using six robust\nMachine Learning (ML) classifiers and one Deep Learning (DL) model, with two\nfeature extraction techniques applied to assess their performance across three\ndifferent training-testing splits. To ensure the reliability of the results,\ncross-validation was performed using both k-fold and leave-one-out methods.\nAmong the classification models tested, Logistic Regression (LR) demonstrated\nthe highest accuracy, achieving a 90% accuracy with the Bag-of-Words (BoW)\nfeature extraction technique. LR stands out for its exceptional speed and\nefficiency, maintaining low testing time per statement (0.97 microseconds).\nThese findings suggest that LR, when combined with BoW, is effective in\naccurately classifying child development information, thus providing a valuable\ntool for combating misinformation and assisting parents in making informed\ndecisions.", "published": "2024-08-23 14:16:54", "link": "http://arxiv.org/abs/2408.13091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lessons in co-creation: the inconvenient truths of inclusive sign\n  language technology development", "abstract": "In the era of AI-driven language technologies, there is a growing demand for\nthe participation and leadership of deaf communities in sign language\ntechnology development, often framed as co-creation. This paper, developed\nthrough collaborative and iterative dialogue between the authors with data from\ninformal participant observations, examines the involvement of the European\nUnion of the Deaf in two EU Horizon 2020 projects, EASIER and SignON. These\nprojects aimed to develop mobile translation applications between signed and\nspoken languages, bringing together predominantly hearing, non-signing\ntechnology experts with predominantly hearing sign language academics and\norganizations representing deaf end users in large multi-partner consortia.\nWhile co-creation is sometimes presented as the best or required way to do\nresearch or even as emancipatory, it frequently masks systemic issues of power\nimbalances and tokenism. Drawing from EUD's experiences of these projects, we\nhighlight several inconvenient truths of co-creation, and propose seven lessons\nfor future initiatives: recognizing deaf partners' invisible labour as work,\nmanaging expectations about technologies, cripping co-creation processes,\nexploring alternative methods to mitigate co-creation fatigue, seeking\nintersectional feedback, ensuring co-creation is not just virtue signalling,\nand fostering deaf leadership in AI sign language research. We argue for\nco-creation as a transformative activity that fundamentally alters the status\nquo and levels the playing field. This necessitates increasing the number of\ndeaf researchers and enhancing AI literacy among deaf communities. Without\nthese critical transformative actions, co-creation risks merely paying lip\nservice to deaf communities.", "published": "2024-08-23 15:43:34", "link": "http://arxiv.org/abs/2408.13171v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating\n  the Hallucination for Path Planning", "abstract": "Spatial reasoning in Large Language Models (LLMs) is the foundation for\nembodied intelligence. However, even in simple maze environments, LLMs still\nencounter challenges in long-term path-planning, primarily influenced by their\nspatial hallucination and context inconsistency hallucination by long-term\nreasoning. To address this challenge, this study proposes an innovative model,\nSpatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To\naddress the spatial hallucination of LLMs, we propose the Spatial-to-Relational\napproach, which transforms spatial prompts into entity relations and paths\nrepresenting entity relation chains. This approach fully taps the potential of\nLLMs in terms of sequential thinking. As a result, we design a path-planning\nalgorithm based on Q-learning to mitigate the context inconsistency\nhallucination, which enhances the reasoning ability of LLMs. Using the Q-value\nof state-action as auxiliary information for prompts, we correct the\nhallucinations of LLMs, thereby guiding LLMs to learn the optimal path.\nFinally, we propose a reverse curriculum learning technique based on LLMs to\nfurther mitigate the context inconsistency hallucination. LLMs can rapidly\naccumulate successful experiences by reducing task difficulty and leveraging\nthem to tackle more complex tasks. We performed comprehensive experiments based\non Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our\nS2RCQL achieved a 23%--40% improvement in both success and optimality rates\ncompared with advanced prompt engineering.", "published": "2024-08-23 16:02:54", "link": "http://arxiv.org/abs/2408.13184v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-specific long text classification from sparse relevant\n  information", "abstract": "Large Language Models have undoubtedly revolutionized the Natural Language\nProcessing field, the current trend being to promote one-model-for-all tasks\n(sentiment analysis, translation, etc.). However, the statistical mechanisms at\nwork in the larger language models struggle to exploit the relevant information\nwhen it is very sparse, when it is a weak signal. This is the case, for\nexample, for the classification of long domain-specific documents, when the\nrelevance relies on a single relevant word or on very few relevant words from\ntechnical jargon. In the medical domain, it is essential to determine whether a\ngiven report contains critical information about a patient's condition. This\ncritical information is often based on one or few specific isolated terms. In\nthis paper, we propose a hierarchical model which exploits a short list of\npotential target terms to retrieve candidate sentences and represent them into\nthe contextualized embedding of the target term(s) they contain. A pooling of\nthe term(s) embedding(s) entails the document representation to be classified.\nWe evaluate our model on one public medical document benchmark in English and\non one private French medical dataset. We show that our narrower hierarchical\nmodel is better than larger language models for retrieving relevant long\ndocuments in a domain-specific context.", "published": "2024-08-23 17:54:19", "link": "http://arxiv.org/abs/2408.13253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating LLM Applications in E-Commerce", "abstract": "The emergence of Large Language Models (LLMs) has revolutionized natural\nlanguage processing in various applications especially in e-commerce. One\ncrucial step before the application of such LLMs in these fields is to\nunderstand and compare the performance in different use cases in such tasks.\nThis paper explored the efficacy of LLMs in the e-commerce domain, focusing on\ninstruction-tuning an open source LLM model with public e-commerce datasets of\nvarying sizes and comparing the performance with the conventional models\nprevalent in industrial applications. We conducted a comprehensive comparison\nbetween LLMs and traditional pre-trained language models across specific tasks\nintrinsic to the e-commerce domain, namely classification, generation,\nsummarization, and named entity recognition (NER). Furthermore, we examined the\neffectiveness of the current niche industrial application of very large LLM,\nusing in-context learning, in e-commerce specific tasks. Our findings indicate\nthat few-shot inference with very large LLMs often does not outperform\nfine-tuning smaller pre-trained models, underscoring the importance of\ntask-specific model optimization.Additionally, we investigated different\ntraining methodologies such as single-task training, mixed-task training, and\nLoRA merging both within domain/tasks and between different tasks. Through\nrigorous experimentation and analysis, this paper offers valuable insights into\nthe potential effectiveness of LLMs to advance natural language processing\ncapabilities within the e-commerce industry.", "published": "2024-08-23 00:57:37", "link": "http://arxiv.org/abs/2408.12779v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Preference Consistency Matters: Enhancing Preference Learning in\n  Language Models with Automated Self-Curation of Training Corpora", "abstract": "Inconsistent annotations in training corpora, particularly within preference\nlearning datasets, pose challenges in developing advanced language models.\nThese inconsistencies often arise from variability among annotators and\ninherent multi-dimensional nature of the preferences. To address these issues,\nwe introduce a self-curation method that preprocesses annotated datasets by\nleveraging proxy models trained directly on them. Our method enhances\npreference learning by automatically detecting and selecting consistent\nannotations. We validate the proposed approach through extensive\ninstruction-following tasks, demonstrating performance improvements of up to\n33\\% across various learning algorithms and proxy capabilities. This work\noffers a straightforward and reliable solution to address preference\ninconsistencies without relying on heuristics, serving as an initial step\ntoward the development of more advanced preference learning methodologies. Code\nis available at https://github.com/Self-Curation/ .", "published": "2024-08-23 02:27:14", "link": "http://arxiv.org/abs/2408.12799v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CLLMFS: A Contrastive Learning enhanced Large Language Model Framework\n  for Few-Shot Named Entity Recognition", "abstract": "Few-shot Named Entity Recognition (NER), the task of identifying named\nentities with only a limited amount of labeled data, has gained increasing\nsignificance in natural language processing. While existing methodologies have\nshown some effectiveness, such as enriching label semantics through various\nprompting modes or employing metric learning techniques, their performance\nexhibits limited robustness across diverse domains due to the lack of rich\nknowledge in their pre-trained models. To address this issue, we propose\nCLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework\nfor Few-Shot Named Entity Recognition, achieving promising results with limited\ntraining data. Considering the impact of LLM's internal representations on\ndownstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive\nlearning mechanisms specifically tailored for few-shot NER. By enhancing the\nmodel's internal representations, CLLMFS effectively improves both entity\nboundary awareness ability and entity recognition accuracy. Our method has\nachieved state-of-the-art performance improvements on F1-score ranging from\n2.58\\% to 97.74\\% over existing best-performing methods across several\nrecognized benchmarks. Furthermore, through cross-domain NER experiments\nconducted on multiple datasets, we have further validated the robust\ngeneralization capability of our method. Our code will be released in the near\nfuture.", "published": "2024-08-23 04:44:05", "link": "http://arxiv.org/abs/2408.12834v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Faceted Question Complexity Estimation Targeting Topic\n  Domain-Specificity", "abstract": "Question difficulty estimation remains a multifaceted challenge in\neducational and assessment settings. Traditional approaches often focus on\nsurface-level linguistic features or learner comprehension levels, neglecting\nthe intricate interplay of factors contributing to question complexity. This\npaper presents a novel framework for domain-specific question difficulty\nestimation, leveraging a suite of NLP techniques and knowledge graph analysis.\nWe introduce four key parameters: Topic Retrieval Cost, Topic Salience, Topic\nCoherence, and Topic Superficiality, each capturing a distinct facet of\nquestion complexity within a given subject domain. These parameters are\noperationalized through topic modelling, knowledge graph analysis, and\ninformation retrieval techniques. A model trained on these features\ndemonstrates the efficacy of our approach in predicting question difficulty. By\noperationalizing these parameters, our framework offers a novel approach to\nquestion complexity estimation, paving the way for more effective question\ngeneration, assessment design, and adaptive learning systems across diverse\nacademic disciplines.", "published": "2024-08-23 05:40:35", "link": "http://arxiv.org/abs/2408.12850v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Causal-Guided Active Learning for Debiasing Large Language Models", "abstract": "Although achieving promising performance, recent analyses show that current\ngenerative large language models (LLMs) may still capture dataset biases and\nutilize them for generation, leading to poor generalizability and harmfulness\nof LLMs. However, due to the diversity of dataset biases and the\nover-optimization problem, previous prior-knowledge-based debiasing methods and\nfine-tuning-based debiasing methods may not be suitable for current LLMs. To\naddress this issue, we explore combining active learning with the causal\nmechanisms and propose a casual-guided active learning (CAL) framework, which\nutilizes LLMs itself to automatically and autonomously identify informative\nbiased samples and induce the bias patterns. Then a cost-effective and\nefficient in-context learning based method is employed to prevent LLMs from\nutilizing dataset biases during generation. Experimental results show that CAL\ncan effectively recognize typical biased instances and induce various bias\npatterns for debiasing LLMs.", "published": "2024-08-23 09:46:15", "link": "http://arxiv.org/abs/2408.12942v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Contrastive In-Context Learning", "abstract": "The rapid growth of Large Language Models (LLMs) usage has highlighted the\nimportance of gradient-free in-context learning (ICL). However, interpreting\ntheir inner workings remains challenging. This paper introduces a novel\nmultimodal contrastive in-context learning framework to enhance our\nunderstanding of ICL in LLMs. First, we present a contrastive learning-based\ninterpretation of ICL in real-world settings, marking the distance of the\nkey-value representation as the differentiator in ICL. Second, we develop an\nanalytical framework to address biases in multimodal input formatting for\nreal-world datasets. We demonstrate the effectiveness of ICL examples where\nbaseline performance is poor, even when they are represented in unseen formats.\nLastly, we propose an on-the-fly approach for ICL (Anchored-by-Text ICL) that\ndemonstrates effectiveness in detecting hateful memes, a task where typical ICL\nstruggles due to resource limitations. Extensive experiments on multimodal\ndatasets reveal that our approach significantly improves ICL performance across\nvarious scenarios, such as challenging tasks and resource-constrained\nenvironments. Moreover, it provides valuable insights into the mechanisms of\nin-context learning in LLMs. Our findings have important implications for\ndeveloping more interpretable, efficient, and robust multimodal AI systems,\nespecially in challenging tasks and resource-constrained environments.", "published": "2024-08-23 10:10:01", "link": "http://arxiv.org/abs/2408.12959v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedDec: A Dataset for Extracting Medical Decisions from Discharge\n  Summaries", "abstract": "Medical decisions directly impact individuals' health and well-being.\nExtracting decision spans from clinical notes plays a crucial role in\nunderstanding medical decision-making processes. In this paper, we develop a\nnew dataset called \"MedDec\", which contains clinical notes of eleven different\nphenotypes (diseases) annotated by ten types of medical decisions. We introduce\nthe task of medical decision extraction, aiming to jointly extract and classify\ndifferent types of medical decisions within clinical notes. We provide a\ncomprehensive analysis of the dataset, develop a span detection model as a\nbaseline for this task, evaluate recent span detection approaches, and employ a\nfew metrics to measure the complexity of data samples. Our findings shed light\non the complexities inherent in clinical decision extraction and enable future\nwork in this area of research. The dataset and code are available through\nhttps://github.com/CLU-UML/MedDec.", "published": "2024-08-23 10:54:44", "link": "http://arxiv.org/abs/2408.12980v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis\n  on Textual Reviews", "abstract": "Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural Language\nProcessing (NLP) that focuses on extracting sentiments related to specific\naspects within a text, offering deep insights into customer opinions.\nTraditional sentiment analysis methods, while useful for determining overall\nsentiment, often miss the implicit opinions about particular product or service\nfeatures. This paper presents a comprehensive review of the evolution of ABSA\nmethodologies, from lexicon-based approaches to machine learning and deep\nlearning techniques. We emphasize the recent advancements in Transformer-based\nmodels, particularly Bidirectional Encoder Representations from Transformers\n(BERT) and its variants, which have set new benchmarks in ABSA tasks. We\nfocused on finetuning Llama and Mistral models, building hybrid models using\nthe SetFit framework, and developing our own model by exploiting the strengths\nof state-of-the-art (SOTA) Transformer-based models for aspect term extraction\n(ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct -\nDeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1\nfor aspect sentiment classification. We utilize datasets from different domains\nto evaluate our model's performance. Our experiments indicate that the proposed\nhybrid model significantly improves the accuracy and reliability of sentiment\nanalysis across all experimented domains. As per our findings, our hybrid model\nInstruct - DeBERTa is the best-performing model for the joint task of ATE and\nASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasets\nseparately. By addressing the limitations of existing methodologies, our\napproach provides a robust solution for understanding detailed consumer\nfeedback, thus offering valuable insights for businesses aiming to enhance\ncustomer satisfaction and product development.", "published": "2024-08-23 16:31:07", "link": "http://arxiv.org/abs/2408.13202v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt\n  Tuning through Modular Prompt Composition", "abstract": "In recent years, multi-task prompt tuning has garnered considerable attention\nfor its inherent modularity and potential to enhance parameter-efficient\ntransfer learning across diverse tasks. This paper aims to analyze and improve\nthe performance of multiple tasks by facilitating the transfer of knowledge\nbetween their corresponding prompts in a multi-task setting. Our proposed\napproach decomposes the prompt for each target task into a combination of\nshared prompts (source prompts) and a task-specific prompt (private prompt).\nDuring training, the source prompts undergo fine-tuning and are integrated with\nthe private prompt to drive the target prompt for each task. We present and\ncompare multiple methods for combining source prompts to construct the target\nprompt, analyzing the roles of both source and private prompts within each\nmethod. We investigate their contributions to task performance and offer\nflexible, adjustable configurations based on these insights to optimize\nperformance. Our empirical findings clearly showcase improvements in accuracy\nand robustness compared to the conventional practice of prompt tuning and\nrelated works. Notably, our results substantially outperform other methods in\nthe field in few-shot settings, demonstrating superior performance in various\ntasks across GLUE benchmark, among other tasks. This achievement is attained\nwith a significantly reduced amount of training data, making our method a\npromising one for few-shot settings.", "published": "2024-08-23 17:01:51", "link": "http://arxiv.org/abs/2408.13227v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Exploring Bias and Prediction Metrics to Characterise the Fairness of\n  Machine Learning for Equity-Centered Public Health Decision-Making: A\n  Narrative Review", "abstract": "Background: The rapid advancement of Machine Learning (ML) represents novel\nopportunities to enhance public health research, surveillance, and\ndecision-making. However, there is a lack of comprehensive understanding of\nalgorithmic bias, systematic errors in predicted population health outcomes,\nresulting from the public health application of ML. The objective of this\nnarrative review is to explore the types of bias generated by ML and\nquantitative metrics to assess these biases.\n  Methods : We performed search on PubMed, MEDLINE, IEEE (Institute of\nElectrical and Electronics Engineers), ACM (Association for Computing\nMachinery) Digital Library, Science Direct, and Springer Nature. We used\nkeywords to identify studies describing types of bias and metrics to measure\nthese in the domain of ML and public and population health published in English\nbetween 2008 and 2023, inclusive.\n  Results: A total of 72 articles met the inclusion criteria. Our review\nidentified the commonly described types of bias and quantitative metrics to\nassess these biases from an equity perspective.\n  Conclusion : The review will help formalize the evaluation framework for ML\non public health from an equity perspective.", "published": "2024-08-23 14:47:10", "link": "http://arxiv.org/abs/2408.13295v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An\n  Exhaustive Review of Technologies, Research, Best Practices, Applied Research\n  Challenges and Opportunities", "abstract": "This report examines the fine-tuning of Large Language Models (LLMs),\nintegrating theoretical insights with practical applications. It outlines the\nhistorical evolution of LLMs from traditional Natural Language Processing (NLP)\nmodels to their pivotal role in AI. A comparison of fine-tuning methodologies,\nincluding supervised, unsupervised, and instruction-based approaches,\nhighlights their applicability to different tasks. The report introduces a\nstructured seven-stage pipeline for fine-tuning LLMs, spanning data\npreparation, model initialization, hyperparameter tuning, and model deployment.\nEmphasis is placed on managing imbalanced datasets and optimization techniques.\nParameter-efficient methods like Low-Rank Adaptation (LoRA) and Half\nFine-Tuning are explored for balancing computational efficiency with\nperformance. Advanced techniques such as memory fine-tuning, Mixture of Experts\n(MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized\nnetworks and multi-agent collaboration. The report also examines novel\napproaches like Proximal Policy Optimization (PPO) and Direct Preference\nOptimization (DPO), which align LLMs with human preferences, alongside pruning\nand routing optimizations to improve efficiency. Further sections cover\nvalidation frameworks, post-deployment monitoring, and inference optimization,\nwith attention to deploying LLMs on distributed and cloud-based platforms.\nEmerging areas such as multimodal LLMs, fine-tuning for audio and speech, and\nchallenges related to scalability, privacy, and accountability are also\naddressed. This report offers actionable insights for researchers and\npractitioners navigating LLM fine-tuning in an evolving landscape.", "published": "2024-08-23 14:48:02", "link": "http://arxiv.org/abs/2408.13296v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LCA and energy efficiency in buildings: mapping more than twenty years\n  of research", "abstract": "Research on Life Cycle Assessment (LCA) is being conducted in various\nsectors, from analyzing building materials and components to comprehensive\nevaluations of entire structures. However, reviews of the existing literature\nhave been unable to provide a comprehensive overview of research in this field,\nleaving scholars without a definitive guideline for future investigations. This\npaper aims to fill this gap, mapping more than twenty years of research. Using\nan innovative methodology that combines social network analysis and text\nmining, the paper examined 8024 scientific abstracts. The authors identified\nseven key thematic groups, building and sustainability clusters (BSCs). To\nassess their significance in the broader discourse on building and\nsustainability, the semantic brand score (SBS) indicator was applied.\nAdditionally, building and sustainability trends were tracked, focusing on the\nLCA concept. The major research topics mainly relate to building materials and\nenergy efficiency. In addition to presenting an innovative approach to\nreviewing extensive literature domains, the article also provides insights into\nemerging and underdeveloped themes, outlining crucial future research\ndirections.", "published": "2024-08-23 08:43:25", "link": "http://arxiv.org/abs/2409.00065v1", "categories": ["cs.DL", "cs.CL", "I.2.7"], "primary_category": "cs.DL"}
{"title": "An alternative formulation of attention pooling function in translation", "abstract": "The aim of this paper is to present an alternative formulation of the\nattention scoring function in translation tasks. Generally speaking, language\nis deeply structured, and this is reflected in the attention scoring matrix. We\nexploit this property to define the attention pooling function, taking this\naspect into account. In the first chapters, we introduce the attention\nmechanism in mathematical terms and explain its limitations and alternative\nformulations. Next, we focus on the experimental session that led to the\nalternative formulation. Essentially, we guide queries and keys to interact in\na specific manner, encoding the distinct roles of attention heads and directing\nvalues on where to seek context. In mathematical terms, we can think of this\nformula as projecting the attention scores matrix, say $H$, onto the space of\nband matrices with fixed bandwidth. This convex subspace is clearly\nfinite-dimensional and therefore closed. As a consequence, the projection on\nthis space is well-posed and unique. However, at the price of losing the\nuniqueness of the projection (i.e., the best approximation for $H$), we defined\na new space consisting of band matrices plus error sparse matrices. We prove\nthat this is a compact subspace which guarantees the existence of a matrix that\nbest approximates $H$. We conclude the thesis by validating the new formula,\nnamely calculating how well the new formula for attention scores approximates\nthe original one. Additionally, we explore the impact of different parameters\nsuch as w (context windows) and num-pos (number of relevant words in a\nsentence). These analyses provide deeper insights into how languages are\nprocessed and translated, revealing nuances in the roles of context and word\nrelevance.", "published": "2024-08-23 14:42:00", "link": "http://arxiv.org/abs/2409.00068v1", "categories": ["cs.CL", "math.OC", "68T01, 68T07"], "primary_category": "cs.CL"}
{"title": "Learning to Plan Long-Term for Language Modeling", "abstract": "Modern language models predict the next token in the sequence by considering\nthe past text through a powerful function such as attention. However, language\nmodels have no explicit mechanism that allows them to spend computation time\nfor planning long-distance future text, leading to a suboptimal token\nprediction. In this paper, we propose a planner that predicts a latent plan for\nmany sentences into the future. By sampling multiple plans at once, we\ncondition the language model on an accurate approximation of the distribution\nof text continuations, which leads to better next token prediction accuracy. In\neffect, this allows trading computation time for prediction accuracy.", "published": "2024-08-23 21:18:10", "link": "http://arxiv.org/abs/2409.00070v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VALE: A Multimodal Visual and Language Explanation Framework for Image\n  Classifiers using eXplainable AI and Language Models", "abstract": "Deep Neural Networks (DNNs) have revolutionized various fields by enabling\ntask automation and reducing human error. However, their internal workings and\ndecision-making processes remain obscure due to their black box nature.\nConsequently, the lack of interpretability limits the application of these\nmodels in high-risk scenarios. To address this issue, the emerging field of\neXplainable Artificial Intelligence (XAI) aims to explain and interpret the\ninner workings of DNNs. Despite advancements, XAI faces challenges such as the\nsemantic gap between machine and human understanding, the trade-off between\ninterpretability and performance, and the need for context-specific\nexplanations. To overcome these limitations, we propose a novel multimodal\nframework named VALE Visual and Language Explanation. VALE integrates\nexplainable AI techniques with advanced language models to provide\ncomprehensive explanations. This framework utilizes visual explanations from\nXAI tools, an advanced zero-shot image segmentation model, and a visual\nlanguage model to generate corresponding textual explanations. By combining\nvisual and textual explanations, VALE bridges the semantic gap between machine\noutputs and human interpretation, delivering results that are more\ncomprehensible to users. In this paper, we conduct a pilot study of the VALE\nframework for image classification tasks. Specifically, Shapley Additive\nExplanations (SHAP) are used to identify the most influential regions in\nclassified images. The object of interest is then extracted using the Segment\nAnything Model (SAM), and explanations are generated using state-of-the-art\npre-trained Vision-Language Models (VLMs). Extensive experimental studies are\nperformed on two datasets: the ImageNet dataset and a custom underwater SONAR\nimage dataset, demonstrating VALEs real-world applicability in underwater image\nclassification.", "published": "2024-08-23 03:02:11", "link": "http://arxiv.org/abs/2408.12808v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "68T07 (Primary) 68T45, 68U10 (Secondary)", "I.4.8; I.2.10; I.5.4"], "primary_category": "cs.CV"}
{"title": "Memory-Efficient LLM Training with Online Subspace Descent", "abstract": "Recently, a wide range of memory-efficient LLM training algorithms have\ngained substantial popularity. These methods leverage the low-rank structure of\ngradients to project optimizer states into a subspace using projection matrix\nfound by singular value decomposition (SVD). However, convergence of these\nalgorithms is highly dependent on the update rules of their projection matrix.\nIn this work, we provide the \\emph{first} convergence guarantee for arbitrary\nupdate rules of projection matrix. This guarantee is generally applicable to\noptimizers that can be analyzed with Hamiltonian Descent, including most common\nones, such as LION, Adam. Inspired by our theoretical understanding, we propose\nOnline Subspace Descent, a new family of subspace descent optimizer without\nSVD. Instead of updating the projection matrix with eigenvectors, Online\nSubspace Descent updates the projection matrix with online PCA. Online Subspace\nDescent is flexible and introduces only minimum overhead to training. We show\nthat for the task of pretraining LLaMA models ranging from 60M to 7B parameters\non the C4 dataset, Online Subspace Descent achieves lower perplexity and better\ndownstream tasks performance than state-of-the-art low-rank training methods\nacross different settings and narrows the gap with full-rank baselines.", "published": "2024-08-23 05:54:53", "link": "http://arxiv.org/abs/2408.12857v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model\n  with Multimodal Capabilities", "abstract": "In the field of multimodal large language models (MLLMs), common methods\ntypically involve unfreezing the language model during training to foster\nprofound visual understanding. However, the fine-tuning of such models with\nvision-language data often leads to a diminution of their natural language\nprocessing (NLP) capabilities. To avoid this performance degradation, a\nstraightforward solution is to freeze the language model while developing\nmultimodal competencies. Unfortunately, previous works have not attained\nsatisfactory outcomes. Building on the strategy of freezing the language model,\nwe conduct thorough structural exploration and introduce the Inner-Adaptor\nArchitecture (IAA). Specifically, the architecture incorporates multiple\nmultimodal adaptors at varying depths within the large language model to\nfacilitate direct interaction with the inherently text-oriented transformer\nlayers, thereby enabling the frozen language model to acquire multimodal\ncapabilities. Unlike previous approaches of freezing language models that\nrequire large-scale aligned data, our proposed architecture is able to achieve\nsuperior performance on small-scale datasets. We conduct extensive experiments\nto improve the general multimodal capabilities and visual grounding abilities\nof the MLLM. Our approach remarkably outperforms previous state-of-the-art\nmethods across various vision-language benchmarks without sacrificing\nperformance on NLP tasks. Code and models are available at\nhttps://github.com/360CVGroup/Inner-Adaptor-Architecture.", "published": "2024-08-23 08:10:13", "link": "http://arxiv.org/abs/2408.12902v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Open Llama2 Model for the Lithuanian Language", "abstract": "In this paper, we propose and describe the first open Llama2 large language\nmodels (LLMs) for the Lithuanian language, including an accompanying\nquestion/answer (Q/A) dataset and translations of popular LLM benchmarks. We\nprovide a brief review of open regional LLMs and detailed information on the\nproposed LLMs and their training process. We also conduct an empirical\nevaluation, comparing the perplexities of the proposed LLMs with those of other\nmodern open LLMs. In addition, benchmarking the proposed LLMs against language\nunderstanding tasks reveals that high-quality pretraining datasets may be\nessential for achieving models that perform efficiently on these benchmarks.\nThe full realisations of the described LLMs are available in the accompanying\nopen repository~\\url{https://huggingface.co/neurotechnology}.", "published": "2024-08-23 10:18:39", "link": "http://arxiv.org/abs/2408.12963v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing\n  Tasks", "abstract": "Prompting has become a practical method for utilizing pre-trained language\nmodels (LMs). This approach offers several advantages. It allows an LM to adapt\nto new tasks with minimal training and parameter updates, thus achieving\nefficiency in both storage and computation. Additionally, prompting modifies\nonly the LM's inputs and harnesses the generative capabilities of language\nmodels to address various downstream tasks in a unified manner. This\nsignificantly reduces the need for human labor in designing task-specific\nmodels. These advantages become even more evident as the number of tasks served\nby the LM scales up. Motivated by the strengths of prompting, we are the first\nto explore the potential of prompting speech LMs in the domain of speech\nprocessing. Recently, there has been a growing interest in converting speech\ninto discrete units for language modeling. Our pioneer research demonstrates\nthat these quantized speech units are highly versatile within our unified\nprompting framework. Not only can they serve as class labels, but they also\ncontain rich phonetic information that can be re-synthesized back into speech\nsignals for speech generation tasks. Specifically, we reformulate speech\nprocessing tasks into speech-to-unit generation tasks. As a result, we can\nseamlessly integrate tasks such as speech classification, sequence generation,\nand speech generation within a single, unified prompting framework. The\nexperiment results show that the prompting method can achieve competitive\nperformance compared to the strong fine-tuning method based on self-supervised\nlearning models with a similar number of trainable parameters. The prompting\nmethod also shows promising results in the few-shot setting. Moreover, with the\nadvanced speech LMs coming into the stage, the proposed prompting framework\nattains great potential.", "published": "2024-08-23 13:00:10", "link": "http://arxiv.org/abs/2408.13040v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large\n  Language Models and Deep Learning Methods", "abstract": "Accurate forecasting of the EUR/USD exchange rate is crucial for investors,\nbusinesses, and policymakers. This paper proposes a novel framework, IUS, that\nintegrates unstructured textual data from news and analysis with structured\ndata on exchange rates and financial indicators to enhance exchange rate\nprediction. The IUS framework employs large language models for sentiment\npolarity scoring and exchange rate movement classification of texts. These\ntextual features are combined with quantitative features and input into a\nCausality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then\nused to forecast the EUR/USD exchange rate. Experiments demonstrate that the\nproposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE\nby 9.56% compared to the best performing baseline. Results also show the\nbenefits of data fusion, with the combination of unstructured and structured\ndata yielding higher accuracy than structured data alone. Furthermore, feature\nselection using the top 12 important quantitative features combined with the\ntextual features proves most effective. The proposed IUS framework and\nOptuna-Bi-LSTM model provide a powerful new approach for exchange rate\nforecasting through multi-source data integration.", "published": "2024-08-23 16:46:36", "link": "http://arxiv.org/abs/2408.13214v1", "categories": ["q-fin.CP", "cs.AI", "cs.CE", "cs.CL"], "primary_category": "q-fin.CP"}
{"title": "Multi-Layer Transformers Gradient Can be Approximated in Almost Linear\n  Time", "abstract": "The computational complexity of the self-attention mechanism in popular\ntransformer architectures poses significant challenges for training and\ninference, and becomes the bottleneck for long inputs. Is it possible to\nsignificantly reduce the quadratic time complexity of computing the gradients\nin multi-layer transformer models? This paper proves that a novel fast\napproximation method can calculate the gradients in almost linear time\n$n^{1+o(1)}$ where $n$ is the input sequence length, while it maintains a\npolynomially small approximation error $1 / \\mathrm{poly}(n)$ across the entire\nmodel. Our theory holds for general loss functions and when the multi-layer\ntransformer model contains many practical sub-modules, such as residual\nconnection, casual mask, and multi-head attention. By improving the efficiency\nof gradient computation, we hope that this work will facilitate more effective\ntraining and deployment of long-context language models based on our\ntheoretical results.", "published": "2024-08-23 17:16:43", "link": "http://arxiv.org/abs/2408.13233v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Which Prosodic Features Matter Most for Pragmatics?", "abstract": "We investigate which prosodic features matter most in conveying prosodic\nfunctions. We use the problem of predicting human perceptions of pragmatic\nsimilarity among utterance pairs to evaluate the utility of prosodic features\nof different types. We find, for example, that duration-related features are\nmore important than pitch-related features, and that utterance-initial features\nare more important than utterance-final features. Further, failure analysis\nindicates that modeling using pitch features only often fails to handle\nimportant pragmatic functions, and suggests that several generally-neglected\nacoustic and prosodic features are pragmatically significant, including\nnasality and vibrato. These findings can guide future basic research in\nprosody, and suggest how to improve speech synthesis evaluation, among other\napplications.", "published": "2024-08-23 17:29:05", "link": "http://arxiv.org/abs/2408.13240v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LalaEval: A Holistic Human Evaluation Framework for Domain-Specific\n  Large Language Models", "abstract": "This paper introduces LalaEval, a holistic framework designed for the human\nevaluation of domain-specific large language models (LLMs). LalaEval proposes a\ncomprehensive suite of end-to-end protocols that cover five main components\nincluding domain specification, criteria establishment, benchmark dataset\ncreation, construction of evaluation rubrics, and thorough analysis and\ninterpretation of evaluation outcomes. This initiative aims to fill a crucial\nresearch gap by providing a systematic methodology for conducting standardized\nhuman evaluations within specific domains, a practice that, despite its\nwidespread application, lacks substantial coverage in the literature and human\nevaluation are often criticized to be less reliable due to subjective factors,\nso standardized procedures adapted to the nuanced requirements of specific\ndomains or even individual organizations are in great need. Furthermore, the\npaper demonstrates the framework's application within the logistics industry,\npresenting domain-specific evaluation benchmarks, datasets, and a comparative\nanalysis of LLMs for the logistics domain use, highlighting the framework's\ncapacity to elucidate performance differences and guide model selection and\ndevelopment for domain-specific LLMs. Through real-world deployment, the paper\nunderscores the framework's effectiveness in advancing the field of\ndomain-specific LLM evaluation, thereby contributing significantly to the\nongoing discussion on LLMs' practical utility and performance in\ndomain-specific applications.", "published": "2024-08-23 19:12:45", "link": "http://arxiv.org/abs/2408.13338v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Power Scheduler: A Batch Size and Token Number Agnostic Learning Rate\n  Scheduler", "abstract": "Finding the optimal learning rate for language model pretraining is a\nchallenging task. This is not only because there is a complicated correlation\nbetween learning rate, batch size, number of training tokens, model size, and\nother hyperparameters but also because it is prohibitively expensive to perform\na hyperparameter search for large language models with Billions or Trillions of\nparameters. Recent studies propose using small proxy models and small corpus to\nperform hyperparameter searches and transposing the optimal parameters to large\nmodels and large corpus. While the zero-shot transferability is theoretically\nand empirically proven for model size related hyperparameters, like depth and\nwidth, the zero-shot transfer from small corpus to large corpus is\nunderexplored. In this paper, we study the correlation between optimal learning\nrate, batch size, and number of training tokens for the recently proposed WSD\nscheduler. After thousands of small experiments, we found a power-law\nrelationship between variables and demonstrated its transferability across\nmodel sizes. Based on the observation, we propose a new learning rate\nscheduler, Power scheduler, that is agnostic about the number of training\ntokens and batch size. The experiment shows that combining the Power scheduler\nwith Maximum Update Parameterization (muP) can consistently achieve impressive\nperformance with one set of hyperparameters regardless of the number of\ntraining tokens, batch size, model size, and even model architecture. Our 3B\ndense and MoE models trained with the Power scheduler achieve comparable\nperformance as state-of-the-art small language models. We open-source these\npretrained models at https://ibm.biz/BdKhLa.", "published": "2024-08-23 20:22:20", "link": "http://arxiv.org/abs/2408.13359v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations\n  of Research Papers", "abstract": "This paper presents CodeRefine, a novel framework for automatically\ntransforming research paper methodologies into functional code using Large\nLanguage Models (LLMs). Our multi-step approach first extracts and summarizes\nkey text chunks from papers, analyzes their code relevance, and creates a\nknowledge graph using a predefined ontology. Code is then generated from this\nstructured representation and enhanced through a proposed retrospective\nretrieval-augmented generation approach. CodeRefine addresses the challenge of\nbridging theoretical research and practical implementation, offering a more\naccurate alternative to LLM zero-shot prompting. Evaluations on diverse\nscientific papers demonstrate CodeRefine's ability to improve code\nimplementation from the paper, potentially accelerating the adoption of\ncutting-edge algorithms in real-world applications.", "published": "2024-08-23 20:51:04", "link": "http://arxiv.org/abs/2408.13366v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A New Era in Computational Pathology: A Survey on Foundation and\n  Vision-Language Models", "abstract": "Recent advances in deep learning have completely transformed the domain of\ncomputational pathology (CPath). More specifically, it has altered the\ndiagnostic workflow of pathologists by integrating foundation models (FMs) and\nvision-language models (VLMs) in their assessment and decision-making process.\nThe limitations of existing deep learning approaches in CPath can be overcome\nby FMs through learning a representation space that can be adapted to a wide\nvariety of downstream tasks without explicit supervision. Deploying VLMs allow\npathology reports written in natural language be used as rich semantic\ninformation sources to improve existing models as well as generate predictions\nin natural language form. In this survey, a holistic and systematic overview of\nrecent innovations in FMs and VLMs in CPath is presented. Furthermore, the\ntools, datasets and training schemes for these models are summarized in\naddition to categorizing them into distinct groups. This extensive survey\nhighlights the current trends in CPath and its possible revolution through the\nuse of FMs and VLMs in the future.", "published": "2024-08-23 16:33:57", "link": "http://arxiv.org/abs/2408.14496v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Phrasing for UX: Enhancing Information Engagement through Computational\n  Linguistics and Creative Analytics", "abstract": "This study explores the relationship between textual features and Information\nEngagement (IE) on digital platforms. It highlights the impact of computational\nlinguistics and analytics on user interaction. The READ model is introduced to\nquantify key predictors like representativeness, ease of use, affect, and\ndistribution, which forecast engagement levels. The model's effectiveness is\nvalidated through AB testing and randomized trials, showing strong predictive\nperformance in participation (accuracy: 0.94), perception (accuracy: 0.85),\nperseverance (accuracy: 0.81), and overall IE (accuracy: 0.97).\n  While participation metrics are strong, perception and perseverance show\nslightly lower recall and F1-scores, indicating some challenges. The study\ndemonstrates that modifying text based on the READ model's insights leads to\nsignificant improvements. For example, increasing representativeness and\npositive affect boosts selection rates by 11 percent, raises evaluation\naverages from 3.98 to 4.46, and improves retention rates by 11 percent. These\nfindings highlight the importance of linguistic factors in IE, providing a\nframework for enhancing digital text engagement. The research offers practical\nstrategies applicable to fields like education, health, and media.", "published": "2024-08-23 00:33:47", "link": "http://arxiv.org/abs/2409.00064v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs", "abstract": "LLM app ecosystems are quickly maturing and supporting a wide range of use\ncases, which requires them to collect excessive user data. Given that the LLM\napps are developed by third-parties and that anecdotal evidence suggests LLM\nplatforms currently do not strictly enforce their policies, user data shared\nwith arbitrary third-parties poses a significant privacy risk. In this paper we\naim to bring transparency in data practices of LLM apps. As a case study, we\nstudy OpenAI's GPT app ecosystem. We develop an LLM-based framework to conduct\nthe static analysis of natural language-based source code of GPTs and their\nActions (external services) to characterize their data collection practices.\nOur findings indicate that Actions collect expansive data about users,\nincluding sensitive information prohibited by OpenAI, such as passwords. We\nfind that some Actions, including related to advertising and analytics, are\nembedded in multiple GPTs, which allow them to track user activities across\nGPTs. Additionally, co-occurrence of Actions exposes as much as 9.5x more data\nto them, than it is exposed to individual Actions. Lastly, we develop an\nLLM-based privacy policy analysis framework to automatically check the\nconsistency of data collection by Actions with disclosures in their privacy\npolicies. Our measurements indicate that the disclosures for most of the\ncollected data types are omitted in privacy policies, with only 5.8% of Actions\nclearly disclosing their data collection practices.", "published": "2024-08-23 17:42:06", "link": "http://arxiv.org/abs/2408.13247v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CR"}
{"title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for\n  Drug-Target Interaction Prediction", "abstract": "Advancements in large language models (LLMs) allow them to address diverse\nquestions using human-like interfaces. Still, limitations in their training\nprevent them from answering accurately in scenarios that could benefit from\nmultiple perspectives. Multi-agent systems allow the resolution of questions to\nenhance result consistency and reliability. While drug-target interaction (DTI)\nprediction is important for drug discovery, existing approaches face challenges\ndue to complex biological systems and the lack of interpretability needed for\nclinical applications. DrugAgent is a multi-agent LLM system for DTI prediction\nthat combines multiple specialized perspectives with transparent reasoning. Our\nsystem adapts and extends existing multi-agent frameworks by (1) applying\ncoordinator-based architecture to the DTI domain, (2) integrating\ndomain-specific data sources, including ML predictions, knowledge graphs, and\nliterature evidence, and (3) incorporating Chain-of-Thought (CoT) and ReAct\n(Reason+Act) frameworks for transparent DTI reasoning. We conducted\ncomprehensive experiments using a kinase inhibitor dataset, where our\nmulti-agent LLM method outperformed the non-reasoning multi-agent model (GPT-4o\nmini) by 45% in F1 score (0.514 vs 0.355). Through ablation studies, we\ndemonstrated the contributions of each agent, with the AI agent being the most\nimpactful, followed by the KG agent and search agent. Most importantly, our\napproach provides detailed, human-interpretable reasoning for each prediction\nby combining evidence from multiple sources - a critical feature for biomedical\napplications where understanding the rationale behind predictions is essential\nfor clinical decision-making and regulatory compliance. Code is available at\nhttps://anonymous.4open.science/r/DrugAgent-B2EA.", "published": "2024-08-23 21:24:59", "link": "http://arxiv.org/abs/2408.13378v4", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Inference-Adaptive Neural Steering for Real-Time Area-Based Sound Source\n  Separation", "abstract": "We propose a novel Neural Steering technique that adapts the target area of a\nspatial-aware multi-microphone sound source separation algorithm during\ninference without the necessity of retraining the deep neural network (DNN). To\nachieve this, we first train a DNN aiming to retain speech within a target\nregion, defined by an angular span, while suppressing sound sources stemming\nfrom other directions. Afterward, a phase shift is applied to the microphone\nsignals, allowing us to shift the center of the target area during inference at\nnegligible additional cost in computational complexity. Further, we show that\nthe proposed approach performs well in a wide variety of acoustic scenarios,\nincluding several speakers inside and outside the target area and additional\nnoise. More precisely, the proposed approach performs on par with DNNs trained\nexplicitly for the steered target area in terms of DNSMOS and SI-SDR.", "published": "2024-08-23 10:59:14", "link": "http://arxiv.org/abs/2408.12982v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "NEST: Self-supervised Fast Conformer as All-purpose Seasoning to Speech\n  Processing Tasks", "abstract": "Self-supervised learning has been proved to benefit a wide range of speech\nprocessing tasks, such as speech recognition/translation, speaker verification\nand diarization, etc. However, most of current approaches are computationally\nexpensive. In this paper, we propose a simplified and more efficient\nself-supervised learning framework termed as NeMo Encoder for Speech Tasks\n(NEST). Specifically, we adopt the FastConformer architecture with 8x\nsub-sampling rate, which is faster than Transformer or Conformer architectures.\nInstead of clustering-based quantization, we use fixed random projection for\nits simplicity and effectiveness. We also implement a generalized noisy speech\naugmentation that teaches the model to disentangle the main speaker from noise\nor other speakers. Experiments show that \\model improves over existing\nself-supervised models and achieves new state-of-the-art performance on a\nvariety of speech processing tasks, such as speech recognition/translation,\nspeaker diarization, spoken language understanding, etc. Code and checkpoints\nare publicly available via NVIDIA NeMo framework.", "published": "2024-08-23 14:32:18", "link": "http://arxiv.org/abs/2408.13106v6", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Uncertainty-Aware Mean Opinion Score Prediction", "abstract": "Mean Opinion Score (MOS) prediction has made significant progress in specific\ndomains. However, the unstable performance of MOS prediction models across\ndiverse samples presents ongoing challenges in the practical application of\nthese systems. In this paper, we point out that the absence of uncertainty\nmodeling is a significant limitation hindering MOS prediction systems from\napplying to the real and open world. We analyze the sources of uncertainty in\nthe MOS prediction task and propose to establish an uncertainty-aware MOS\nprediction system that models aleatory uncertainty and epistemic uncertainty by\nheteroscedastic regression and Monte Carlo dropout separately. The experimental\nresults show that the system captures uncertainty well and is capable of\nperforming selective prediction and out-of-domain detection. Such capabilities\nsignificantly enhance the practical utility of MOS systems in diverse real and\nopen-world environments.", "published": "2024-08-23 04:24:40", "link": "http://arxiv.org/abs/2408.12829v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "On Class Separability Pitfalls In Audio-Text Contrastive Zero-Shot\n  Learning", "abstract": "Recent advances in audio-text cross-modal contrastive learning have shown its\npotential towards zero-shot learning. One possibility for this is by projecting\nitem embeddings from pre-trained backbone neural networks into a cross-modal\nspace in which item similarity can be calculated in either domain. This process\nrelies on a strong unimodal pre-training of the backbone networks, and on a\ndata-intensive training task for the projectors. These two processes can be\nbiased by unintentional data leakage, which can arise from using supervised\nlearning in pre-training or from inadvertently training the cross-modal\nprojection using labels from the zero-shot learning evaluation. In this study,\nwe show that a significant part of the measured zero-shot learning accuracy is\ndue to strengths inherited from the audio and text backbones, that is, they are\nnot learned in the cross-modal domain and are not transferred from one modality\nto another.", "published": "2024-08-23 13:52:56", "link": "http://arxiv.org/abs/2408.13068v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EAViT: External Attention Vision Transformer for Audio Classification", "abstract": "This paper presents the External Attention Vision Transformer (EAViT) model,\na novel approach designed to enhance audio classification accuracy. As digital\naudio resources proliferate, the demand for precise and efficient audio\nclassification systems has intensified, driven by the need for improved\nrecommendation systems and user personalization in various applications,\nincluding music streaming platforms and environmental sound recognition.\nAccurate audio classification is crucial for organizing vast audio libraries\ninto coherent categories, enabling users to find and interact with their\npreferred audio content more effectively. In this study, we utilize the GTZAN\ndataset, which comprises 1,000 music excerpts spanning ten diverse genres. Each\n30-second audio clip is segmented into 3-second excerpts to enhance dataset\nrobustness and mitigate overfitting risks, allowing for more granular feature\nanalysis. The EAViT model integrates multi-head external attention (MEA)\nmechanisms into the Vision Transformer (ViT) framework, effectively capturing\nlong-range dependencies and potential correlations between samples. This\nexternal attention (EA) mechanism employs learnable memory units that enhance\nthe network's capacity to process complex audio features efficiently. The study\ndemonstrates that EAViT achieves a remarkable overall accuracy of 93.99%,\nsurpassing state-of-the-art models.", "published": "2024-08-23 16:31:06", "link": "http://arxiv.org/abs/2408.13201v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Toward Improving Synthetic Audio Spoofing Detection Robustness via\n  Meta-Learning and Disentangled Training With Adversarial Examples", "abstract": "Advances in automatic speaker verification (ASV) promote research into the\nformulation of spoofing detection systems for real-world applications. The\nperformance of ASV systems can be degraded severely by multiple types of\nspoofing attacks, namely, synthetic speech (SS), voice conversion (VC), replay,\ntwins and impersonation, especially in the case of unseen synthetic spoofing\nattacks. A reliable and robust spoofing detection system can act as a security\ngate to filter out spoofing attacks instead of having them reach the ASV\nsystem. A weighted additive angular margin loss is proposed to address the data\nimbalance issue, and different margins has been assigned to improve\ngeneralization to unseen spoofing attacks in this study. Meanwhile, we\nincorporate a meta-learning loss function to optimize differences between the\nembeddings of support versus query set in order to learn a\nspoofing-category-independent embedding space for utterances. Furthermore, we\ncraft adversarial examples by adding imperceptible perturbations to spoofing\nspeech as a data augmentation strategy, then we use an auxiliary batch\nnormalization (BN) to guarantee that corresponding normalization statistics are\nperformed exclusively on the adversarial examples. Additionally, A simple\nattention module is integrated into the residual block to refine the feature\nextraction process. Evaluation results on the Logical Access (LA) track of the\nASVspoof 2019 corpus provides confirmation of our proposed approaches'\neffectiveness in terms of a pooled EER of 0.87%, and a min t-DCF of 0.0277.\nThese advancements offer effective options to reduce the impact of spoofing\nattacks on voice recognition/authentication systems.", "published": "2024-08-23 19:26:54", "link": "http://arxiv.org/abs/2408.13341v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Disentangled Training with Adversarial Examples For Robust\n  Small-footprint Keyword Spotting", "abstract": "A keyword spotting (KWS) engine that is continuously running on device is\nexposed to various speech signals that are usually unseen before. It is a\nchallenging problem to build a small-footprint and high-performing KWS model\nwith robustness under different acoustic environments. In this paper, we\nexplore how to effectively apply adversarial examples to improve KWS\nrobustness. We propose datasource-aware disentangled learning with adversarial\nexamples to reduce the mismatch between the original and adversarial data as\nwell as the mismatch across original training datasources. The KWS model\narchitecture is based on depth-wise separable convolution and a simple\nattention module. Experimental results demonstrate that the proposed learning\nstrategy improves false reject rate by $40.31%$ at $1%$ false accept rate on\nthe internal dataset, compared to the strongest baseline without using\nadversarial examples. Our best-performing system achieves $98.06%$ accuracy on\nthe Google Speech Commands V1 dataset.", "published": "2024-08-23 20:03:51", "link": "http://arxiv.org/abs/2408.13355v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Contrastive Learning and Self-Training for Multimodal Emotion\n  Recognition with Limited Labeled Samples", "abstract": "The Multimodal Emotion Recognition challenge MER2024 focuses on recognizing\nemotions using audio, language, and visual signals. In this paper, we present\nour submission solutions for the Semi-Supervised Learning Sub-Challenge\n(MER2024-SEMI), which tackles the issue of limited annotated data in emotion\nrecognition. Firstly, to address the class imbalance, we adopt an oversampling\nstrategy. Secondly, we propose a modality representation combinatorial\ncontrastive learning (MR-CCL) framework on the trimodal input data to establish\nrobust initial models. Thirdly, we explore a self-training approach to expand\nthe training set. Finally, we enhance prediction robustness through a\nmulti-classifier weighted soft voting strategy. Our proposed method is\nvalidated to be effective on the MER2024-SEMI Challenge, achieving a weighted\naverage F-score of 88.25% and ranking 6th on the leaderboard. Our project is\navailable at https://github.com/WooyoohL/MER2024-SEMI.", "published": "2024-08-23 11:33:54", "link": "http://arxiv.org/abs/2409.04447v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
