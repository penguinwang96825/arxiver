{"title": "Language Independent Named Entity Recognition via Orthogonal Transformation of Word Vectors", "abstract": "Word embeddings have been a key building block for NLP in which models relied\nheavily on word embeddings in many different tasks. In this paper, a model is\nproposed based on using Bidirectional LSTM/CRF with word embeddings to perform\nnamed entity recognition for any language. This is done by training a model on\na source language (English) and transforming word embeddings from the target\nlanguage into word embeddings of the source language by using an orthogonal\nlinear transformation matrix. Evaluation of the model shows that by training a\nmodel on an English dataset the model was capable of detecting named entities\nin an Arabic dataset without neither training or fine tuning the model on an\nArabic language dataset.", "published": "2025-03-18 21:57:58", "link": "http://arxiv.org/abs/2503.14755v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence", "abstract": "As large language models (LLMs) are increasingly used for factual\nquestion-answering, it becomes more important for LLMs to have the capability\nto communicate the likelihood that their answer is correct. For these\nverbalized expressions of uncertainty to be meaningful, they should reflect the\nerror rates at the expressed level of confidence. However, when prompted to\nexpress confidence, the error rates of current LLMs are inconsistent with their\ncommunicated confidences, highlighting the need for uncertainty quantification\nmethods. Many prior methods calculate lexical uncertainty, estimating a model's\nconfidence in the specific string it generated. In some cases, however, it may\nbe more useful to estimate semantic uncertainty, or the model's confidence in\nthe answer regardless of how it is verbalized. We propose a simple procedure,\nuncertainty distillation, to teach an LLM to verbalize calibrated semantic\nconfidences. Using held-out data to map initial uncertainty estimates to\nmeaningful probabilities, we create examples annotated with verbalized\nprobabilities for supervised fine-tuning. We demonstrate our method yields\nverbalized confidences that correlate with observed error rates with a small\nfine-tuned language model as well as with larger instruction-tuned models, and\nfind that our semantic uncertainty correlates well with lexical uncertainty on\nshort answers.", "published": "2025-03-18 21:29:29", "link": "http://arxiv.org/abs/2503.14749v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Strategic resource allocation in memory encoding: An efficiency principle shaping language processing", "abstract": "How is the limited capacity of working memory efficiently used to support\nhuman linguistic behaviors? In this paper, we investigate strategic resource\nallocation as an efficiency principle for memory encoding in sentence\nprocessing. The idea is that working memory resources are dynamically and\nstrategically allocated to prioritize novel and unexpected information,\nenhancing their representations to make them less susceptible to memory decay\nand interference. Theoretically, from a resource-rational perspective, we argue\nthat this efficiency principle naturally arises from two functional assumptions\nabout working memory, namely, its limited capacity and its noisy\nrepresentation. Empirically, through naturalistic corpus data, we find\nconverging evidence for strategic resource allocation in the context of\ndependency locality from both the production and the comprehension side, where\nnon-local dependencies with less predictable antecedents are associated with\nreduced locality effect. However, our results also reveal considerable\ncross-linguistic variability, highlighting the need for a closer examination of\nhow strategic resource allocation, as a universal efficiency principle,\ninteracts with language-specific phrase structures.", "published": "2025-03-18 20:58:43", "link": "http://arxiv.org/abs/2503.14728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Second language Korean Universal Dependency treebank v1.2: Focus on data augmentation and annotation scheme refinement", "abstract": "We expand the second language (L2) Korean Universal Dependencies (UD)\ntreebank with 5,454 manually annotated sentences. The annotation guidelines are\nalso revised to better align with the UD framework. Using this enhanced\ntreebank, we fine-tune three Korean language models and evaluate their\nperformance on in-domain and out-of-domain L2-Korean datasets. The results show\nthat fine-tuning significantly improves their performance across various\nmetrics, thus highlighting the importance of using well-tailored L2 datasets\nfor fine-tuning first-language-based, general-purpose language models for the\nmorphosyntactic analysis of L2 data.", "published": "2025-03-18 20:42:42", "link": "http://arxiv.org/abs/2503.14718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Medically-Informed Explanations for Depression Detection using LLMs", "abstract": "Early detection of depression from social media data offers a valuable\nopportunity for timely intervention. However, this task poses significant\nchallenges, requiring both professional medical knowledge and the development\nof accurate and explainable models. In this paper, we propose LLM-MTD (Large\nLanguage Model for Multi-Task Depression Detection), a novel approach that\nleverages a pre-trained large language model to simultaneously classify social\nmedia posts for depression and generate textual explanations grounded in\nmedical diagnostic criteria. We train our model using a multi-task learning\nframework with a combined loss function that optimizes both classification\naccuracy and explanation quality. We evaluate LLM-MTD on the benchmark Reddit\nSelf-Reported Depression Dataset (RSDD) and compare its performance against\nseveral competitive baseline methods, including traditional machine learning\nand fine-tuned BERT. Our experimental results demonstrate that LLM-MTD achieves\nstate-of-the-art performance in depression detection, showing significant\nimprovements in AUPRC and other key metrics. Furthermore, human evaluation of\nthe generated explanations reveals their relevance, completeness, and medical\naccuracy, highlighting the enhanced interpretability of our approach. This work\ncontributes a novel methodology for depression detection that combines the\npower of large language models with the crucial aspect of explainability.", "published": "2025-03-18 19:23:22", "link": "http://arxiv.org/abs/2503.14671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized Attacks of Social Engineering in Multi-turn Conversations -- LLM Agents for Simulation and Detection", "abstract": "The rapid advancement of conversational agents, particularly chatbots powered\nby Large Language Models (LLMs), poses a significant risk of social engineering\n(SE) attacks on social media platforms. SE detection in multi-turn, chat-based\ninteractions is considerably more complex than single-instance detection due to\nthe dynamic nature of these conversations. A critical factor in mitigating this\nthreat is understanding the mechanisms through which SE attacks operate,\nspecifically how attackers exploit vulnerabilities and how victims' personality\ntraits contribute to their susceptibility. In this work, we propose an\nLLM-agentic framework, SE-VSim, to simulate SE attack mechanisms by generating\nmulti-turn conversations. We model victim agents with varying personality\ntraits to assess how psychological profiles influence susceptibility to\nmanipulation. Using a dataset of over 1000 simulated conversations, we examine\nattack scenarios in which adversaries, posing as recruiters, funding agencies,\nand journalists, attempt to extract sensitive information. Based on this\nanalysis, we present a proof of concept, SE-OmniGuard, to offer personalized\nprotection to users by leveraging prior knowledge of the victims personality,\nevaluating attack strategies, and monitoring information exchanges in\nconversations to identify potential SE attempts.", "published": "2025-03-18 19:14:44", "link": "http://arxiv.org/abs/2503.15552v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "ConQuer: A Framework for Concept-Based Quiz Generation", "abstract": "Quizzes play a crucial role in education by reinforcing students'\nunderstanding of key concepts and encouraging self-directed exploration.\nHowever, compiling high-quality quizzes can be challenging and require deep\nexpertise and insight into specific subject matter. Although LLMs have greatly\nenhanced the efficiency of quiz generation, concerns remain regarding the\nquality of these AI-generated quizzes and their educational impact on students.\nTo address these issues, we introduce ConQuer, a concept-based quiz generation\nframework that leverages external knowledge sources. We employ comprehensive\nevaluation dimensions to assess the quality of the generated quizzes, using\nLLMs as judges. Our experiment results demonstrate a 4.8% improvement in\nevaluation scores and a 77.52% win rate in pairwise comparisons against\nbaseline quiz sets. Ablation studies further underscore the effectiveness of\neach component in our framework. Code available at\nhttps://github.com/sofyc/ConQuer.", "published": "2025-03-18 19:10:26", "link": "http://arxiv.org/abs/2503.14662v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Multimodal Large Language Models Understand Welding?", "abstract": "This paper examines the performance of Multimodal LLMs (MLLMs) in skilled\nproduction work, with a focus on welding. Using a novel data set of real-world\nand online weld images, annotated by a domain expert, we evaluate the\nperformance of two state-of-the-art MLLMs in assessing weld acceptability\nacross three contexts: RV \\& Marine, Aeronautical, and Farming. While both\nmodels perform better on online images, likely due to prior exposure or\nmemorization, they also perform relatively well on unseen, real-world weld\nimages. Additionally, we introduce WeldPrompt, a prompting strategy that\ncombines Chain-of-Thought generation with in-context learning to mitigate\nhallucinations and improve reasoning. WeldPrompt improves model recall in\ncertain contexts but exhibits inconsistent performance across others. These\nresults underscore the limitations and potentials of MLLMs in high-stakes\ntechnical domains and highlight the importance of fine-tuning, domain-specific\ndata, and more sophisticated prompting strategies to improve model reliability.\nThe study opens avenues for further research into multimodal learning in\nindustry applications.", "published": "2025-03-18 19:07:56", "link": "http://arxiv.org/abs/2503.16537v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving", "abstract": "Retrieval-augmented generation (RAG), which combines large language models\n(LLMs) with retrievals from external knowledge databases, is emerging as a\npopular approach for reliable LLM serving. However, efficient RAG serving\nremains an open challenge due to the rapid emergence of many RAG variants and\nthe substantial differences in workload characteristics across them. In this\npaper, we make three fundamental contributions to advancing RAG serving. First,\nwe introduce RAGSchema, a structured abstraction that captures the wide range\nof RAG algorithms, serving as a foundation for performance optimization.\nSecond, we analyze several representative RAG workloads with distinct\nRAGSchema, revealing significant performance variability across these\nworkloads. Third, to address this variability and meet diverse performance\nrequirements, we propose RAGO (Retrieval-Augmented Generation Optimizer), a\nsystem optimization framework for efficient RAG serving. Our evaluation shows\nthat RAGO achieves up to a 2x increase in QPS per chip and a 55% reduction in\ntime-to-first-token latency compared to RAG systems built on LLM-system\nextensions.", "published": "2025-03-18 18:58:13", "link": "http://arxiv.org/abs/2503.14649v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DC", "C.1; C.4; H.3"], "primary_category": "cs.IR"}
{"title": "Word2Minecraft: Generating 3D Game Levels through Large Language Models", "abstract": "We present Word2Minecraft, a system that leverages large language models to\ngenerate playable game levels in Minecraft based on structured stories. The\nsystem transforms narrative elements-such as protagonist goals, antagonist\nchallenges, and environmental settings-into game levels with both spatial and\ngameplay constraints. We introduce a flexible framework that allows for the\ncustomization of story complexity, enabling dynamic level generation. The\nsystem employs a scaling algorithm to maintain spatial consistency while\nadapting key game elements. We evaluate Word2Minecraft using both metric-based\nand human-based methods. Our results show that GPT-4-Turbo outperforms\nGPT-4o-Mini in most areas, including story coherence and objective enjoyment,\nwhile the latter excels in aesthetic appeal. We also demonstrate the system' s\nability to generate levels with high map enjoyment, offering a promising step\nforward in the intersection of story generation and game design. We open-source\nthe code at https://github.com/JMZ-kk/Word2Minecraft/tree/word2mc_v0", "published": "2025-03-18 18:38:38", "link": "http://arxiv.org/abs/2503.16536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Explainable Framework for Misinformation Identification via Critical Question Answering", "abstract": "Natural language misinformation detection approaches have been, to date,\nlargely dependent on sequence classification methods, producing opaque systems\nin which the reasons behind classification as misinformation are unclear. While\nan effort has been made in the area of automated fact-checking to propose\nexplainable approaches to the problem, this is not the case for automated\nreason-checking systems. In this paper, we propose a new explainable framework\nfor both factual and rational misinformation detection based on the theory of\nArgumentation Schemes and Critical Questions. For that purpose, we create and\nrelease NLAS-CQ, the first corpus combining 3,566 textbook-like natural\nlanguage argumentation scheme instances and 4,687 corresponding answers to\ncritical questions related to these arguments. On the basis of this corpus, we\nimplement and validate our new framework which combines classification with\nquestion answering to analyse arguments in search of misinformation, and\nprovides the explanations in form of critical questions to the human user.", "published": "2025-03-18 18:24:23", "link": "http://arxiv.org/abs/2503.14626v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Simulacra: Generative Agents for Up-to-date and Knowledge-Adaptive Simulations", "abstract": "In the 2023 edition of the White Paper on Information and Communications, it\nis estimated that the population of social networking services in Japan will\nexceed 100 million by 2022, and the influence of social networking services in\nJapan is growing significantly. In addition, marketing using SNS and research\non the propagation of emotions and information on SNS are being actively\nconducted, creating the need for a system for predicting trends in SNS\ninteractions. We have already created a system that simulates the behavior of\nvarious communities on SNS by building a virtual SNS environment in which\nagents post and reply to each other in a chat community created by agents using\na LLMs. In this paper, we evaluate the impact of the search extension\ngeneration mechanism used to create posts and replies in a virtual SNS\nenvironment using a simulation system on the ability to generate posts and\nreplies. As a result of the evaluation, we confirmed that the proposed search\nextension generation mechanism, which mimics human search behavior, generates\nthe most natural exchange.", "published": "2025-03-18 18:17:10", "link": "http://arxiv.org/abs/2503.14620v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Unique Hard Attention: A Tale of Two Sides", "abstract": "Understanding the expressive power of transformers has recently attracted\nattention, as it offers insights into their abilities and limitations. Many\nstudies analyze unique hard attention transformers, where attention selects a\nsingle position that maximizes the attention scores. When multiple positions\nachieve the maximum score, either the rightmost or the leftmost of those is\nchosen. In this paper, we highlight the importance of this seeming triviality.\nRecently, finite-precision transformers with both leftmost- and rightmost-hard\nattention were shown to be equivalent to Linear Temporal Logic (LTL). We show\nthat this no longer holds with only leftmost-hard attention -- in that case,\nthey correspond to a \\emph{strictly weaker} fragment of LTL. Furthermore, we\nshow that models with leftmost-hard attention are equivalent to \\emph{soft}\nattention, suggesting they may better approximate real-world transformers than\nright-attention models. These findings refine the landscape of transformer\nexpressivity and underscore the role of attention directionality.", "published": "2025-03-18 18:12:09", "link": "http://arxiv.org/abs/2503.14615v1", "categories": ["cs.LG", "cs.CC", "cs.CL", "cs.FL"], "primary_category": "cs.LG"}
{"title": "Image Captioning Evaluation in the Age of Multimodal LLMs: Challenges and Future Perspectives", "abstract": "The evaluation of machine-generated image captions is a complex and evolving\nchallenge. With the advent of Multimodal Large Language Models (MLLMs), image\ncaptioning has become a core task, increasing the need for robust and reliable\nevaluation metrics. This survey provides a comprehensive overview of\nadvancements in image captioning evaluation, analyzing the evolution,\nstrengths, and limitations of existing metrics. We assess these metrics across\nmultiple dimensions, including correlation with human judgment, ranking\naccuracy, and sensitivity to hallucinations. Additionally, we explore the\nchallenges posed by the longer and more detailed captions generated by MLLMs\nand examine the adaptability of current metrics to these stylistic variations.\nOur analysis highlights some limitations of standard evaluation approaches and\nsuggests promising directions for future research in image captioning\nassessment.", "published": "2025-03-18 18:03:56", "link": "http://arxiv.org/abs/2503.14604v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Command R7B Arabic: A Small, Enterprise Focused, Multilingual, and Culturally Aware Arabic LLM", "abstract": "Building high-quality large language models (LLMs) for enterprise Arabic\napplications remains challenging due to the limited availability of digitized\nArabic data. In this work, we present a data synthesis and refinement strategy\nto help address this problem, namely, by leveraging synthetic data generation\nand human-in-the-loop annotation to expand our Arabic training corpus. We\nfurther present our iterative post training recipe that is essential to\nachieving state-of-the-art performance in aligning the model with human\npreferences, a critical aspect to enterprise use cases. The culmination of this\neffort is the release of a small, 7B, open-weight model that outperforms\nsimilarly sized peers in head-to-head comparisons and on Arabic-focused\nbenchmarks covering cultural knowledge, instruction following, RAG, and\ncontextual faithfulness.", "published": "2025-03-18 18:03:49", "link": "http://arxiv.org/abs/2503.14603v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Temporal Consistency for LLM Reasoning Process Error Identification", "abstract": "Verification is crucial for effective mathematical reasoning. We present a\nnew temporal consistency method where verifiers iteratively refine their\njudgments based on the previous assessment. Unlike one-round verification or\nmulti-model debate approaches, our method leverages consistency in a sequence\nof self-reflection actions to improve verification accuracy. Empirical\nevaluations across diverse mathematical process error identification benchmarks\n(Mathcheck, ProcessBench, and PRM800K) show consistent performance improvements\nover baseline methods. When applied to the recent DeepSeek R1 distilled models,\nour method demonstrates strong performance, enabling 7B/8B distilled models to\noutperform all 70B/72B models and GPT-4o on ProcessBench. Notably, the\ndistilled 14B model with our method achieves performance comparable to\nDeepseek-R1. Our codes are available at\nhttps://github.com/jcguo123/Temporal-Consistency", "published": "2025-03-18 17:58:28", "link": "http://arxiv.org/abs/2503.14495v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gricean Norms as a Basis for Effective Collaboration", "abstract": "Effective human-AI collaboration hinges not only on the AI agent's ability to\nfollow explicit instructions but also on its capacity to navigate ambiguity,\nincompleteness, invalidity, and irrelevance in communication. Gricean\nconversational and inference norms facilitate collaboration by aligning unclear\ninstructions with cooperative principles. We propose a normative framework that\nintegrates Gricean norms and cognitive frameworks -- common ground, relevance\ntheory, and theory of mind -- into large language model (LLM) based agents. The\nnormative framework adopts the Gricean maxims of quantity, quality, relation,\nand manner, along with inference, as Gricean norms to interpret unclear\ninstructions, which are: ambiguous, incomplete, invalid, or irrelevant. Within\nthis framework, we introduce Lamoids, GPT-4 powered agents designed to\ncollaborate with humans. To assess the influence of Gricean norms in human-AI\ncollaboration, we evaluate two versions of a Lamoid: one with norms and one\nwithout. In our experiments, a Lamoid collaborates with a human to achieve\nshared goals in a grid world (Doors, Keys, and Gems) by interpreting both clear\nand unclear natural language instructions. Our results reveal that the Lamoid\nwith Gricean norms achieves higher task accuracy and generates clearer, more\naccurate, and contextually relevant responses than the Lamoid without norms.\nThis improvement stems from the normative framework, which enhances the agent's\npragmatic reasoning, fostering effective human-AI collaboration and enabling\ncontext-aware communication in LLM-based agents.", "published": "2025-03-18 17:54:14", "link": "http://arxiv.org/abs/2503.14484v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Don't lie to your friends: Learning what you know from collaborative self-play", "abstract": "To be helpful assistants, AI agents must be aware of their own capabilities\nand limitations. This includes knowing when to answer from parametric knowledge\nversus using tools, when to trust tool outputs, and when to abstain or hedge.\nSuch capabilities are hard to teach through supervised fine-tuning because they\nrequire constructing examples that reflect the agent's specific capabilities.\nWe therefore propose a radically new approach to teaching agents what they\nknow: \\emph{collaborative self-play}. We construct multi-agent collaborations\nin which the group is rewarded for collectively arriving at correct answers.\nThe desired meta-knowledge emerges from the incentives built into the structure\nof the interaction. We focus on small societies of agents that have access to\nheterogeneous tools (corpus-specific retrieval), and therefore must collaborate\nto maximize their success while minimizing their effort. Experiments show that\ngroup-level rewards for multi-agent communities can induce policies that\n\\emph{transfer} to improve tool use and selective prediction in settings where\nindividual agents are deployed in isolation.", "published": "2025-03-18 17:53:20", "link": "http://arxiv.org/abs/2503.14481v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Calibrating Verbal Uncertainty as a Linear Feature to Reduce Hallucinations", "abstract": "LLMs often adopt an assertive language style also when making false claims.\nSuch ``overconfident hallucinations'' mislead users and erode trust. Achieving\nthe ability to express in language the actual degree of uncertainty around a\nclaim is therefore of great importance. We find that ``verbal uncertainty'' is\ngoverned by a single linear feature in the representation space of LLMs, and\nshow that this has only moderate correlation with the actual ``semantic\nuncertainty'' of the model. We apply this insight and show that (1) the\nmismatch between semantic and verbal uncertainty is a better predictor of\nhallucinations than semantic uncertainty alone and (2) we can intervene on\nverbal uncertainty at inference time and reduce hallucinations on short-form\nanswers, achieving an average relative reduction of 32%.", "published": "2025-03-18 17:51:04", "link": "http://arxiv.org/abs/2503.14477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DAPO: An Open-Source LLM Reinforcement Learning System at Scale", "abstract": "Inference scaling empowers LLMs with unprecedented reasoning ability, with\nreinforcement learning as the core technique to elicit complex reasoning.\nHowever, key technical details of state-of-the-art reasoning LLMs are concealed\n(such as in OpenAI o1 blog and DeepSeek R1 technical report), thus the\ncommunity still struggles to reproduce their RL training results. We propose\nthe $\\textbf{D}$ecoupled Clip and $\\textbf{D}$ynamic s$\\textbf{A}$mpling\n$\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{DAPO}$) algorithm, and\nfully open-source a state-of-the-art large-scale RL system that achieves 50\npoints on AIME 2024 using Qwen2.5-32B base model. Unlike previous works that\nwithhold training details, we introduce four key techniques of our algorithm\nthat make large-scale LLM RL a success. In addition, we open-source our\ntraining code, which is built on the verl framework, along with a carefully\ncurated and processed dataset. These components of our open-source system\nenhance reproducibility and support future research in large-scale LLM RL.", "published": "2025-03-18 17:49:06", "link": "http://arxiv.org/abs/2503.14476v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RWKV-7 \"Goose\" with Expressive Dynamic State Evolution", "abstract": "We present RWKV-7 \"Goose\", a new sequence modeling architecture with constant\nmemory usage and constant inference time per token. Despite being trained on\ndramatically fewer tokens than other top models, our 2.9 billion parameter\nlanguage model achieves a new 3B SoTA on multilingual tasks and matches the\ncurrent 3B SoTA on English language downstream performance. RWKV-7 introduces a\nnewly generalized formulation of the delta rule with vector-valued gating and\nin-context learning rates, as well as a relaxed value replacement rule. We show\nthat RWKV-7 can perform state tracking and recognize all regular languages,\nwhile retaining parallelizability of training. This exceeds the capabilities of\nTransformers under standard complexity conjectures, which are limited to\n$\\mathsf{TC}^0$. To demonstrate RWKV-7's language modeling capability, we also\npresent an extended open source 3.1 trillion token multilingual corpus, and\ntrain four RWKV-7 models ranging from 0.19 billion to 2.9 billion parameters on\nthis dataset.\n  To foster openness, reproduction, and adoption, we release our models and\ndataset component listing at https://huggingface.co/RWKV, and our training and\ninference code at https://github.com/RWKV/RWKV-LM all under the Apache 2.0\nLicense.", "published": "2025-03-18 17:31:05", "link": "http://arxiv.org/abs/2503.14456v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.0; I.2.7"], "primary_category": "cs.CL"}
{"title": "LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers", "abstract": "Automated feature engineering plays a critical role in improving predictive\nmodel performance for tabular learning tasks. Traditional automated feature\nengineering methods are limited by their reliance on pre-defined\ntransformations within fixed, manually designed search spaces, often neglecting\ndomain knowledge. Recent advances using Large Language Models (LLMs) have\nenabled the integration of domain knowledge into the feature engineering\nprocess. However, existing LLM-based approaches use direct prompting or rely\nsolely on validation scores for feature selection, failing to leverage insights\nfrom prior feature discovery experiments or establish meaningful reasoning\nbetween feature generation and data-driven performance. To address these\nchallenges, we propose LLM-FE, a novel framework that combines evolutionary\nsearch with the domain knowledge and reasoning capabilities of LLMs to\nautomatically discover effective features for tabular learning tasks. LLM-FE\nformulates feature engineering as a program search problem, where LLMs propose\nnew feature transformation programs iteratively, and data-driven feedback\nguides the search process. Our results demonstrate that LLM-FE consistently\noutperforms state-of-the-art baselines, significantly enhancing the performance\nof tabular prediction models across diverse classification and regression\nbenchmarks.", "published": "2025-03-18 17:11:24", "link": "http://arxiv.org/abs/2503.14434v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Splintering Nonconcatenative Languages for Better Tokenization", "abstract": "Common subword tokenization algorithms like BPE and UnigramLM assume that\ntext can be split into meaningful units by concatenative measures alone. This\nis not true for languages such as Hebrew and Arabic, where morphology is\nencoded in root-template patterns, or Malay and Georgian, where split affixes\nare common. We present SPLINTER, a pre-processing step which rearranges text\ninto a linear form that better represents such nonconcatenative morphologies,\nenabling meaningful contiguous segments to be found by the tokenizer. We\ndemonstrate SPLINTER's merit using both intrinsic measures evaluating token\nvocabularies in Hebrew, Arabic, and Malay; as well as on downstream tasks using\nBERT-architecture models trained for Hebrew.", "published": "2025-03-18 17:11:09", "link": "http://arxiv.org/abs/2503.14433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play", "abstract": "Large language models (LLMs) are increasingly integrated with specialized\nexternal tools, yet many tasks demand zero-shot tool usage with minimal or\nnoisy documentation. Existing solutions rely on manual rewriting or labeled\ndata for validation, making them inapplicable in true zero-shot settings. To\naddress these challenges, we propose PLAY2PROMPT, an automated framework that\nsystematically \"plays\" with each tool to explore its input-output behaviors.\nThrough this iterative trial-and-error process, PLAY2PROMPT refines tool\ndocumentation and generates usage examples without any labeled data. These\nexamples not only guide LLM inference but also serve as validation to further\nenhance tool utilization. Extensive experiments on real-world tasks demonstrate\nthat PLAY2PROMPT significantly improves zero-shot tool performance across both\nopen and closed models, offering a scalable and effective solution for\ndomain-specific tool integration.", "published": "2025-03-18 17:09:57", "link": "http://arxiv.org/abs/2503.14432v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ExDDV: A New Dataset for Explainable Deepfake Detection in Video", "abstract": "The ever growing realism and quality of generated videos makes it\nincreasingly harder for humans to spot deepfake content, who need to rely more\nand more on automatic deepfake detectors. However, deepfake detectors are also\nprone to errors, and their decisions are not explainable, leaving humans\nvulnerable to deepfake-based fraud and misinformation. To this end, we\nintroduce ExDDV, the first dataset and benchmark for Explainable Deepfake\nDetection in Video. ExDDV comprises around 5.4K real and deepfake videos that\nare manually annotated with text descriptions (to explain the artifacts) and\nclicks (to point out the artifacts). We evaluate a number of vision-language\nmodels on ExDDV, performing experiments with various fine-tuning and in-context\nlearning strategies. Our results show that text and click supervision are both\nrequired to develop robust explainable models for deepfake videos, which are\nable to localize and describe the observed artifacts. Our novel dataset and\ncode to reproduce the results are available at\nhttps://github.com/vladhondru25/ExDDV.", "published": "2025-03-18 16:55:07", "link": "http://arxiv.org/abs/2503.14421v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Unifying Text Semantics and Graph Structures for Temporal Text-attributed Graphs with Large Language Models", "abstract": "Temporal graph neural networks (TGNNs) have shown remarkable performance in\ntemporal graph modeling. However, real-world temporal graphs often possess rich\ntextual information, giving rise to temporal text-attributed graphs (TTAGs).\nSuch combination of dynamic text semantics and evolving graph structures\nintroduces heightened complexity. Existing TGNNs embed texts statically and\nrely heavily on encoding mechanisms that biasedly prioritize structural\ninformation, overlooking the temporal evolution of text semantics and the\nessential interplay between semantics and structures for synergistic\nreinforcement. To tackle these issues, we present \\textbf{{Cross}}, a novel\nframework that seamlessly extends existing TGNNs for TTAG modeling. The key\nidea is to employ the advanced large language models (LLMs) to extract the\ndynamic semantics in text space and then generate expressive representations\nunifying both semantics and structures. Specifically, we propose a Temporal\nSemantics Extractor in the {Cross} framework, which empowers the LLM to offer\nthe temporal semantic understanding of node's evolving contexts of textual\nneighborhoods, facilitating semantic dynamics. Subsequently, we introduce the\nSemantic-structural Co-encoder, which collaborates with the above Extractor for\nsynthesizing illuminating representations by jointly considering both semantic\nand structural information while encouraging their mutual reinforcement.\nExtensive experimental results on four public datasets and one practical\nindustrial dataset demonstrate {Cross}'s significant effectiveness and\nrobustness.", "published": "2025-03-18 16:50:10", "link": "http://arxiv.org/abs/2503.14411v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Virtual Human Gesture Selection", "abstract": "Co-speech gestures convey a wide variety of meanings and play an important\nrole in face-to-face human interactions. These gestures significantly influence\nthe addressee's engagement, recall, comprehension, and attitudes toward the\nspeaker. Similarly, they impact interactions between humans and embodied\nvirtual agents. The process of selecting and animating meaningful gestures has\nthus become a key focus in the design of these agents. However, automating this\ngesture selection process poses a significant challenge. Prior gesture\ngeneration techniques have varied from fully automated, data-driven methods,\nwhich often struggle to produce contextually meaningful gestures, to more\nmanual approaches that require crafting specific gesture expertise and are\ntime-consuming and lack generalizability. In this paper, we leverage the\nsemantic capabilities of Large Language Models to develop a gesture selection\napproach that suggests meaningful, appropriate co-speech gestures. We first\ndescribe how information on gestures is encoded into GPT-4. Then, we conduct a\nstudy to evaluate alternative prompting approaches for their ability to select\nmeaningful, contextually relevant gestures and to align them appropriately with\nthe co-speech utterance. Finally, we detail and demonstrate how this approach\nhas been implemented within a virtual agent system, automating the selection\nand subsequent animation of the selected gestures for enhanced human-agent\ninteractions.", "published": "2025-03-18 16:49:56", "link": "http://arxiv.org/abs/2503.14408v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "From \"Hallucination\" to \"Suture\": Insights from Language Philosophy to Enhance Large Language Models", "abstract": "This paper explores hallucination phenomena in large language models (LLMs)\nthrough the lens of language philosophy and psychoanalysis. By incorporating\nLacan's concepts of the \"chain of signifiers\" and \"suture points,\" we propose\nthe Anchor-RAG framework as a novel approach to mitigate hallucinations. In\ncontrast to the predominant reliance on trial-and-error experiments, constant\nadjustments of mathematical formulas, or resource-intensive methods that\nemphasize quantity over quality, our approach returns to the fundamental\nprinciples of linguistics to analyze the root causes of hallucinations in LLMs.\nDrawing from robust theoretical foundations, we derive algorithms and models\nthat are not only effective in reducing hallucinations but also enhance LLM\nperformance and improve output quality. This paper seeks to establish a\ncomprehensive theoretical framework for understanding hallucinations in LLMs\nand aims to challenge the prevalent \"guess-and-test\" approach and rat race\nmentality in the field. We aspire to pave the way for a new era of\ninterpretable LLMs, offering deeper insights into the inner workings of\nlanguage-based AI systems.", "published": "2025-03-18 16:27:01", "link": "http://arxiv.org/abs/2503.14392v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How much do LLMs learn from negative examples?", "abstract": "Large language models (LLMs) undergo a three-phase training process:\nunsupervised pre-training, supervised fine-tuning (SFT), and learning from\nhuman feedback (RLHF/DPO). Notably, it is during the final phase that these\nmodels are exposed to negative examples -- incorrect, rejected, or suboptimal\nresponses to queries. This paper delves into the role of negative examples in\nthe training of LLMs, using a likelihood-ratio (Likra) model on multiple-choice\nquestion answering benchmarks to precisely manage the influence and the volume\nof negative examples. Our findings reveal three key insights: (1) During a\ncritical phase in training, Likra with negative examples demonstrates a\nsignificantly larger improvement per training example compared to SFT using\nonly positive examples. This leads to a sharp jump in the learning curve for\nLikra unlike the smooth and gradual improvement of SFT; (2) negative examples\nthat are plausible but incorrect (near-misses) exert a greater influence; and\n(3) while training with positive examples fails to significantly decrease the\nlikelihood of plausible but incorrect answers, training with negative examples\nmore accurately identifies them. These results indicate a potentially\nsignificant role for negative examples in improving accuracy and reducing\nhallucinations for LLMs.", "published": "2025-03-18 16:26:29", "link": "http://arxiv.org/abs/2503.14391v1", "categories": ["cs.CL", "68T50, 68T05", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Good/Evil Reputation Judgment of Celebrities by LLMs via Retrieval Augmented Generation", "abstract": "The purpose of this paper is to examine whether large language models (LLMs)\ncan understand what is good and evil with respect to judging good/evil\nreputation of celebrities. Specifically, we first apply a large language model\n(namely, ChatGPT) to the task of collecting sentences that mention the target\ncelebrity from articles about celebrities on Web pages. Next, the collected\nsentences are categorized based on their contents by ChatGPT, where ChatGPT\nassigns a category name to each of those categories. Those assigned category\nnames are referred to as \"aspects\" of each celebrity. Then, by applying the\nframework of retrieval augmented generation (RAG), we show that the large\nlanguage model is quite effective in the task of judging good/evil reputation\nof aspects and descriptions of each celebrity. Finally, also in terms of\nproving the advantages of the proposed method over existing services\nincorporating RAG functions, we show that the proposed method of judging\ngood/evil of aspects/descriptions of each celebrity significantly outperform an\nexisting service incorporating RAG functions.", "published": "2025-03-18 16:15:55", "link": "http://arxiv.org/abs/2503.14382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VEGGIE: Instructional Editing and Reasoning of Video Concepts with Grounded Generation", "abstract": "Recent video diffusion models have enhanced video editing, but it remains\nchallenging to handle instructional editing and diverse tasks (e.g., adding,\nremoving, changing) within a unified framework. In this paper, we introduce\nVEGGIE, a Video Editor with Grounded Generation from Instructions, a simple\nend-to-end framework that unifies video concept editing, grounding, and\nreasoning based on diverse user instructions. Specifically, given a video and\ntext query, VEGGIE first utilizes an MLLM to interpret user intentions in\ninstructions and ground them to the video contexts, generating frame-specific\ngrounded task queries for pixel-space responses. A diffusion model then renders\nthese plans and generates edited videos that align with user intent. To support\ndiverse tasks and complex instructions, we employ a curriculum learning\nstrategy: first aligning the MLLM and video diffusion model with large-scale\ninstructional image editing data, followed by end-to-end fine-tuning on\nhigh-quality multitask video data. Additionally, we introduce a novel data\nsynthesis pipeline to generate paired instructional video editing data for\nmodel training. It transforms static image data into diverse, high-quality\nvideo editing samples by leveraging Image-to-Video models to inject dynamics.\nVEGGIE shows strong performance in instructional video editing with different\nediting skills, outperforming the best instructional baseline as a versatile\nmodel, while other models struggle with multi-tasking. VEGGIE also excels in\nvideo object grounding and reasoning segmentation, where other baselines fail.\nWe further reveal how the multiple tasks help each other and highlight\npromising applications like zero-shot multimodal instructional and in-context\nvideo editing.", "published": "2025-03-18 15:31:12", "link": "http://arxiv.org/abs/2503.14350v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Gender and content bias in Large Language Models: a case study on Google Gemini 2.0 Flash Experimental", "abstract": "This study evaluates the biases in Gemini 2.0 Flash Experimental, a\nstate-of-the-art large language model (LLM) developed by Google, focusing on\ncontent moderation and gender disparities. By comparing its performance to\nChatGPT-4o, examined in a previous work of the author, the analysis highlights\nsome differences in ethical moderation practices. Gemini 2.0 demonstrates\nreduced gender bias, notably with female-specific prompts achieving a\nsubstantial rise in acceptance rates compared to results obtained by\nChatGPT-4o. It adopts a more permissive stance toward sexual content and\nmaintains relatively high acceptance rates for violent prompts, including\ngender-specific cases. Despite these changes, whether they constitute an\nimprovement is debatable. While gender bias has been reduced, this reduction\ncomes at the cost of permitting more violent content toward both males and\nfemales, potentially normalizing violence rather than mitigating harm.\nMale-specific prompts still generally receive higher acceptance rates than\nfemale-specific ones. These findings underscore the complexities of aligning AI\nsystems with ethical standards, highlighting progress in reducing certain\nbiases while raising concerns about the broader implications of the model's\npermissiveness. Ongoing refinements are essential to achieve moderation\npractices that ensure transparency, fairness, and inclusivity without\namplifying harmful content.", "published": "2025-03-18 15:28:22", "link": "http://arxiv.org/abs/2503.16534v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MoonCast: High-Quality Zero-Shot Podcast Generation", "abstract": "Recent advances in text-to-speech synthesis have achieved notable success in\ngenerating high-quality short utterances for individual speakers. However,\nthese systems still face challenges when extending their capabilities to long,\nmulti-speaker, and spontaneous dialogues, typical of real-world scenarios such\nas podcasts. These limitations arise from two primary challenges: 1) long\nspeech: podcasts typically span several minutes, exceeding the upper limit of\nmost existing work; 2) spontaneity: podcasts are marked by their spontaneous,\noral nature, which sharply contrasts with formal, written contexts; existing\nworks often fall short in capturing this spontaneity. In this paper, we propose\nMoonCast, a solution for high-quality zero-shot podcast generation, aiming to\nsynthesize natural podcast-style speech from text-only sources (e.g., stories,\ntechnical reports, news in TXT, PDF, or Web URL formats) using the voices of\nunseen speakers. To generate long audio, we adopt a long-context language\nmodel-based audio modeling approach utilizing large-scale long-context speech\ndata. To enhance spontaneity, we utilize a podcast generation module to\ngenerate scripts with spontaneous details, which have been empirically shown to\nbe as crucial as the text-to-speech modeling itself. Experiments demonstrate\nthat MoonCast outperforms baselines, with particularly notable improvements in\nspontaneity and coherence.", "published": "2025-03-18 15:25:08", "link": "http://arxiv.org/abs/2503.14345v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spatio-Temporal Graph Neural Networks for Infant Language Acquisition Prediction", "abstract": "Predicting the words that a child is going to learn next can be useful for\nboosting language acquisition, and such predictions have been shown to be\npossible with both neural network techniques (looking at changes in the\nvocabulary state over time) and graph model (looking at data pertaining to the\nrelationships between words). However, these models do not fully capture the\ncomplexity of the language learning process of an infant when used in\nisolation. In this paper, we examine how a model of language acquisition for\ninfants and young children can be constructed and adapted for use in a\nSpatio-Temporal Graph Convolutional Network (STGCN), taking into account the\ndifferent types of linguistic relationships that occur during child language\nlearning. We introduce a novel approach for predicting child vocabulary\nacquisition, and evaluate the efficacy of such a model with respect to the\ndifferent types of linguistic relationships that occur during language\nacquisition, resulting in insightful observations on model calibration and norm\nselection. An evaluation of this model found that the mean accuracy of models\nfor predicting new words when using sensorimotor relationships (0.733) and\nsemantic relationships (0.729) were found to be superior to that observed with\na 2-layer Feed-forward neural network. Furthermore, the high recall for some\nrelationships suggested that some relationships (e.g. visual) were superior in\nidentifying a larger proportion of relevant words that a child should\nsubsequently learn than others (such as auditory).", "published": "2025-03-18 15:21:27", "link": "http://arxiv.org/abs/2503.14341v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PENCIL: Long Thoughts with Short Memory", "abstract": "While recent works (e.g. o1, DeepSeek R1) have demonstrated great promise of\nusing long Chain-of-Thought (CoT) to improve reasoning capabilities of language\nmodels, scaling it up during test-time is challenging due to inefficient memory\nusage -- intermediate computations accumulate indefinitely in context even no\nlonger needed for future thoughts. We propose PENCIL, which incorporates a\nreduction mechanism into the autoregressive generation process, allowing the\nmodel to recursively clean up intermediate thoughts based on patterns learned\nfrom training. With this reduction mechanism, PENCIL significantly reduces the\nmaximal context length required during generation, and thus can generate longer\nthoughts with limited memory, solving larger-scale problems given more thinking\ntime. For example, we demonstrate PENCIL achieves 97\\% accuracy on the\nchallenging Einstein's puzzle -- a task even large models like GPT-4 struggle\nwith -- using only a small 25M-parameter transformer with 2048 context length.\nTheoretically, we prove PENCIL can perform universal space-efficient\ncomputation by simulating Turing machines with optimal time and space\ncomplexity, and thus can solve arbitrary computational tasks that would\notherwise be intractable given context window constraints.", "published": "2025-03-18 15:14:14", "link": "http://arxiv.org/abs/2503.14337v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DualToken: Towards Unifying Visual Understanding and Generation with Dual Visual Vocabularies", "abstract": "The differing representation spaces required for visual understanding and\ngeneration pose a challenge in unifying them within the autoregressive paradigm\nof large language models. A vision tokenizer trained for reconstruction excels\nat capturing low-level perceptual details, making it well-suited for visual\ngeneration but lacking high-level semantic representations for understanding\ntasks. Conversely, a vision encoder trained via contrastive learning aligns\nwell with language but struggles to decode back into the pixel space for\ngeneration tasks. To bridge this gap, we propose DualToken, a method that\nunifies representations for both understanding and generation within a single\ntokenizer. However, directly integrating reconstruction and semantic objectives\nin a single tokenizer creates conflicts, leading to degraded performance in\nboth reconstruction quality and semantic performance. Instead of forcing a\nsingle codebook to handle both semantic and perceptual information, DualToken\ndisentangles them by introducing separate codebooks for high and low-level\nfeatures, effectively transforming their inherent conflict into a synergistic\nrelationship. As a result, DualToken achieves state-of-the-art performance in\nboth reconstruction and semantic tasks while demonstrating remarkable\neffectiveness in downstream MLLM understanding and generation tasks. Notably,\nwe also show that DualToken, as a unified tokenizer, surpasses the naive\ncombination of two distinct types vision encoders, providing superior\nperformance within a unified MLLM.", "published": "2025-03-18 14:56:46", "link": "http://arxiv.org/abs/2503.14324v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "From Patient Consultations to Graphs: Leveraging LLMs for Patient Journey Knowledge Graph Construction", "abstract": "The transition towards patient-centric healthcare necessitates a\ncomprehensive understanding of patient journeys, which encompass all healthcare\nexperiences and interactions across the care spectrum. Existing healthcare data\nsystems are often fragmented and lack a holistic representation of patient\ntrajectories, creating challenges for coordinated care and personalized\ninterventions. Patient Journey Knowledge Graphs (PJKGs) represent a novel\napproach to addressing the challenge of fragmented healthcare data by\nintegrating diverse patient information into a unified, structured\nrepresentation. This paper presents a methodology for constructing PJKGs using\nLarge Language Models (LLMs) to process and structure both formal clinical\ndocumentation and unstructured patient-provider conversations. These graphs\nencapsulate temporal and causal relationships among clinical encounters,\ndiagnoses, treatments, and outcomes, enabling advanced temporal reasoning and\npersonalized care insights. The research evaluates four different LLMs, such as\nClaude 3.5, Mistral, Llama 3.1, and Chatgpt4o, in their ability to generate\naccurate and computationally efficient knowledge graphs. Results demonstrate\nthat while all models achieved perfect structural compliance, they exhibited\nvariations in medical entity processing and computational efficiency. The paper\nconcludes by identifying key challenges and future research directions. This\nwork contributes to advancing patient-centric healthcare through the\ndevelopment of comprehensive, actionable knowledge graphs that support improved\ncare coordination and outcome prediction.", "published": "2025-03-18 14:44:28", "link": "http://arxiv.org/abs/2503.16533v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal", "abstract": "Large Language Models (LLMs) have revolutionized various domains, including\nnatural language processing, data analysis, and software development, by\nenabling automation. In software engineering, LLM-powered coding agents have\ngarnered significant attention due to their potential to automate complex\ndevelopment tasks, assist in debugging, and enhance productivity. However,\nexisting approaches often struggle with sub-optimal decision-making, requiring\neither extensive manual intervention or inefficient compute scaling strategies.\nTo improve coding agent performance, we present Dynamic Action Re-Sampling\n(DARS), a novel inference time compute scaling approach for coding agents, that\nis faster and more effective at recovering from sub-optimal decisions compared\nto baselines. While traditional agents either follow linear trajectories or\nrely on random sampling for scaling compute, our approach DARS works by\nbranching out a trajectory at certain key decision points by taking an\nalternative action given the history of the trajectory and execution feedback\nof the previous attempt from that point. We evaluate our approach on SWE-Bench\nLite benchmark, demonstrating that this scaling strategy achieves a pass@k\nscore of 55% with Claude 3.5 Sonnet V2. Our framework achieves a pass@1 rate of\n47%, outperforming state-of-the-art (SOTA) open-source frameworks.", "published": "2025-03-18 14:02:59", "link": "http://arxiv.org/abs/2503.14269v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System", "abstract": "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https://github.com/oneal2000/JuDGE.", "published": "2025-03-18 13:48:18", "link": "http://arxiv.org/abs/2503.14258v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models", "abstract": "Text-to-Image diffusion models can produce undesirable content that\nnecessitates concept erasure techniques. However, existing methods struggle\nwith under-erasure, leaving residual traces of targeted concepts, or\nover-erasure, mistakenly eliminating unrelated but visually similar concepts.\nTo address these limitations, we introduce CRCE, a novel concept erasure\nframework that leverages Large Language Models to identify both semantically\nrelated concepts that should be erased alongside the target and distinct\nconcepts that should be preserved. By explicitly modeling coreferential and\nretained concepts semantically, CRCE enables more precise concept removal,\nwithout unintended erasure. Experiments demonstrate that CRCE outperforms\nexisting methods on diverse erasure tasks.", "published": "2025-03-18 13:09:01", "link": "http://arxiv.org/abs/2503.14232v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Benchmarking Failures in Tool-Augmented Language Models", "abstract": "The integration of tools has extended the capabilities of language models\n(LMs) beyond vanilla text generation to versatile scenarios. However,\ntool-augmented language models (TaLMs) often assume 'perfect' information\naccess and tool availability, which may not hold in the real world. To\nsystematically study TaLMs' imperfections, we introduce the FAIL-TALMS\nbenchmark, featuring two major failures: under-specified user queries and\nnon-available tools. FAIL-TALMS contains 1,749 examples using 906 tools across\n21 categories, including single- and multi-tool usage. We evaluate\ntop-performing proprietary and open-source models, and find all current models\nexcept for Claude struggle to recognize missing tools or information. Further,\nto study possible mitigation of the failures, we enable real-time human\ninteraction, named the Ask-and-Help (AAH) method, to provide missing\ninformation or replace non-functional tools. While AAH can help models solve\ntasks more correctly when queries are under-specified, it brings minimal\nbenefit when complex tools are broken.", "published": "2025-03-18 13:04:55", "link": "http://arxiv.org/abs/2503.14227v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Towards Harmless Multimodal Assistants with Blind Preference Optimization", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities in multimodal understanding, reasoning, and interaction. Given the\nextensive applications of MLLMs, the associated safety issues have become\nincreasingly critical. Due to the effectiveness of preference optimization in\naligning MLLMs with human preferences, there is an urgent need for\nsafety-related preference data for MLLMs. To address this, we construct the\nMMSafe-PO preference dataset towards harmless multimodal assistants, featuring\nmultimodal instructions, the conversational format, and ranked paired responses\nfrom human feedback. We also identify two insightful observations: modality\nco-defense and modality cheating, which illustrate that MLLMs possess a certain\nlevel of inherent defense while still presenting unique safety challenges.\nBased on these observations, we propose the Blind Preference Optimization (BPO)\napproach. Comprehensive experiments on three benchmarks show that BPO\neffectively enhances the safety capabilities of MLLMs. Notably, BPO\nsignificantly improves the safety rate of the base MLLM by 45.0%, outperforming\nthe DPO approach. Additionally, applying BPO to the MMSafe-PO dataset greatly\nreduces the base MLLM's unsafe rate on other safety benchmarks (14.5% on\nMM-SafetyBench and 82.9% on HarmEval, demonstrating the effectiveness and\nrobustness of both the dataset and the approach. We release code and data at\nhttps://lu-yang666.github.io/MMsafe-PO-Web/.", "published": "2025-03-18 12:02:38", "link": "http://arxiv.org/abs/2503.14189v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "AdaST: Dynamically Adapting Encoder States in the Decoder for End-to-End Speech-to-Text Translation", "abstract": "In end-to-end speech translation, acoustic representations learned by the\nencoder are usually fixed and static, from the perspective of the decoder,\nwhich is not desirable for dealing with the cross-modal and cross-lingual\nchallenge in speech translation. In this paper, we show the benefits of varying\nacoustic states according to decoder hidden states and propose an adaptive\nspeech-to-text translation model that is able to dynamically adapt acoustic\nstates in the decoder. We concatenate the acoustic state and target word\nembedding sequence and feed the concatenated sequence into subsequent blocks in\nthe decoder. In order to model the deep interaction between acoustic states and\ntarget hidden states, a speech-text mixed attention sublayer is introduced to\nreplace the conventional cross-attention network. Experiment results on two\nwidely-used datasets show that the proposed method significantly outperforms\nstate-of-the-art neural speech translation models.", "published": "2025-03-18 11:59:27", "link": "http://arxiv.org/abs/2503.14185v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "NERCat: Fine-Tuning for Enhanced Named Entity Recognition in Catalan", "abstract": "Named Entity Recognition (NER) is a critical component of Natural Language\nProcessing (NLP) for extracting structured information from unstructured text.\nHowever, for low-resource languages like Catalan, the performance of NER\nsystems often suffers due to the lack of high-quality annotated datasets. This\npaper introduces NERCat, a fine-tuned version of the GLiNER[1] model, designed\nto improve NER performance specifically for Catalan text. We used a dataset of\nmanually annotated Catalan television transcriptions to train and fine-tune the\nmodel, focusing on domains such as politics, sports, and culture. The\nevaluation results show significant improvements in precision, recall, and\nF1-score, particularly for underrepresented named entity categories such as\nLaw, Product, and Facility. This study demonstrates the effectiveness of\ndomain-specific fine-tuning in low-resource languages and highlights the\npotential for enhancing Catalan NLP applications through manual annotation and\nhigh-quality datasets.", "published": "2025-03-18 11:44:19", "link": "http://arxiv.org/abs/2503.14173v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Synthetic Clarification and Correction Dialogues about Data-Centric Tasks -- A Teacher-Student Approach", "abstract": "Real dialogues with AI assistants for solving data-centric tasks often follow\ndynamic, unpredictable paths due to imperfect information provided by the user\nor in the data, which must be caught and handled. Developing datasets which\ncapture such user-AI interactions is difficult and time-consuming. In this\nwork, we develop a novel framework for synthetically generating controlled,\nmulti-turn conversations between a user and AI assistant for the task of\ntable-based question answering, which can be generated from an existing dataset\nwith fully specified table QA examples for any target domain. Each conversation\naims to solve a table-based reasoning question through collaborative effort,\nmodeling one of two real-world scenarios: (1) an AI-initiated clarification, or\n(2) a user-initiated correction. Critically, we employ a strong teacher LLM to\nverify the correctness of our synthetic conversations, ensuring high quality.\nWe demonstrate synthetic datasets generated from TAT-QA and WikiTableQuestions\nas benchmarks of frontier LLMs. We find that even larger models struggle to\neffectively issuing clarification questions and accurately integrate user\nfeedback for corrections.", "published": "2025-03-18 11:37:25", "link": "http://arxiv.org/abs/2503.14167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speculative Decoding for Verilog: Speed and Quality, All in One", "abstract": "The rapid advancement of large language models (LLMs) has revolutionized code\ngeneration tasks across various programming languages. However, the unique\ncharacteristics of programming languages, particularly those like Verilog with\nspecific syntax and lower representation in training datasets, pose significant\nchallenges for conventional tokenization and decoding approaches. In this\npaper, we introduce a novel application of speculative decoding for Verilog\ncode generation, showing that it can improve both inference speed and output\nquality, effectively achieving speed and quality all in one. Unlike standard\nLLM tokenization schemes, which often fragment meaningful code structures, our\napproach aligns decoding stops with syntactically significant tokens, making it\neasier for models to learn the token distribution. This refinement addresses\ninherent tokenization issues and enhances the model's ability to capture\nVerilog's logical constructs more effectively. Our experimental results show\nthat our method achieves up to a 5.05x speedup in Verilog code generation and\nincreases pass@10 functional accuracy on RTLLM by up to 17.19% compared to\nconventional training strategies. These findings highlight speculative decoding\nas a promising approach to bridge the quality gap in code generation for\nspecialized programming languages.", "published": "2025-03-18 11:21:53", "link": "http://arxiv.org/abs/2503.14153v1", "categories": ["cs.LG", "cs.AR", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EEG-CLIP : Learning EEG representations from natural language descriptions", "abstract": "Deep networks for electroencephalogram (EEG) decoding are currently often\ntrained to only solve a specific task like pathology or gender decoding. A more\ngeneral approach leveraging the medical reports of clinical EEG recordings is\nto learn mappings between medical reports and EEG recordings. This approach was\npioneered in the computer vision domain matching images and their text captions\nand subsequently allowed to do successful zero-shot decoding using textual\nclass prompts. In this work, we follow this approach and develop a contrastive\nlearning framework EEG-CLIP that aligns EEG time series and their corresponding\nclinical text descriptions in a shared embedding space. We investigate its\npotential for versatile EEG decoding, assessing performance on a range of\nfew-shot and zero-shot settings. Overall, results show that EEG-CLIP manages to\nnontrivially align text and EEG representations. Our work presents a promising\napproach to learn general EEG representations, which could enable easier\nanalyses of diverse decoding questions through zero shot decoding or training\ntask-specific models from fewer training examples. The code for reproducing our\nresults is available at https://github.com/tidiane-camaret/EEGClip.", "published": "2025-03-18 11:12:15", "link": "http://arxiv.org/abs/2503.16531v1", "categories": ["cs.CL", "cs.LG", "eess.SP"], "primary_category": "cs.CL"}
{"title": "CARE: A QLoRA-Fine Tuned Multi-Domain Chatbot With Fast Learning On Minimal Hardware", "abstract": "Large Language models have demonstrated excellent domain-specific\nquestion-answering capabilities when finetuned with a particular dataset of\nthat specific domain. However, fine-tuning the models requires a significant\namount of training time and a considerable amount of hardware. In this work, we\npropose CARE (Customer Assistance and Response Engine), a lightweight model\nmade by fine-tuning Phi3.5-mini on very minimal hardware and data, designed to\nhandle queries primarily across three domains: telecommunications support,\nmedical support, and banking support. For telecommunications and banking, the\nchatbot addresses issues and problems faced by customers regularly in the\nabove-mentioned domains. In the medical domain, CARE provides preliminary\nsupport by offering basic diagnoses and medical suggestions that a user might\ntake before consulting a healthcare professional. Since CARE is built on\nPhi3.5-mini, it can be used even on mobile devices, increasing its usability.\nOur research also shows that CARE performs relatively well on various medical\nbenchmarks, indicating that it can be used to make basic medical suggestions.", "published": "2025-03-18 10:58:10", "link": "http://arxiv.org/abs/2503.14136v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Frac-Connections: Fractional Extension of Hyper-Connections", "abstract": "Residual connections are central to modern deep learning architectures,\nenabling the training of very deep networks by mitigating gradient vanishing.\nHyper-Connections recently generalized residual connections by introducing\nmultiple connection strengths at different depths, thereby addressing the\nseesaw effect between gradient vanishing and representation collapse. However,\nHyper-Connections increase memory access costs by expanding the width of hidden\nstates. In this paper, we propose Frac-Connections, a novel approach that\ndivides hidden states into multiple parts rather than expanding their width.\nFrac-Connections retain partial benefits of Hyper-Connections while reducing\nmemory consumption. To validate their effectiveness, we conduct large-scale\nexperiments on language tasks, with the largest being a 7B MoE model trained on\nup to 3T tokens, demonstrating that Frac-Connections significantly outperform\nresidual connections.", "published": "2025-03-18 10:37:50", "link": "http://arxiv.org/abs/2503.14125v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Wiki-Quantities and Wiki-Measurements: Datasets of Quantities and their Measurement Context from Wikipedia", "abstract": "To cope with the large number of publications, more and more researchers are\nautomatically extracting data of interest using natural language processing\nmethods based on supervised learning. Much data, especially in the natural and\nengineering sciences, is quantitative, but there is a lack of datasets for\nidentifying quantities and their context in text. To address this issue, we\npresent two large datasets based on Wikipedia and Wikidata: Wiki-Quantities is\na dataset consisting of over 1.2 million annotated quantities in the\nEnglish-language Wikipedia. Wiki-Measurements is a dataset of 38,738 annotated\nquantities in the English-language Wikipedia along with their respective\nmeasured entity, property, and optional qualifiers. Manual validation of 100\nsamples each of Wiki-Quantities and Wiki-Measurements found 100% and 84-94%\ncorrect, respectively. The datasets can be used in pipeline approaches to\nmeasurement extraction, where quantities are first identified and then their\nmeasurement context. To allow reproduction of this work using newer or\ndifferent versions of Wikipedia and Wikidata, we publish the code used to\ncreate the datasets along with the data.", "published": "2025-03-18 10:09:10", "link": "http://arxiv.org/abs/2503.14090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing nonnative speech perception and production through an AI-powered application", "abstract": "While research on using Artificial Intelligence (AI) through various\napplications to enhance foreign language pronunciation is expanding, it has\nprimarily focused on aspects such as comprehensibility and intelligibility,\nlargely neglecting the improvement of individual speech sounds in both\nperception and production. This study seeks to address this gap by examining\nthe impact of training with an AI-powered mobile application on nonnative sound\nperception and production. Participants completed a pretest assessing their\nability to discriminate the second language English heed-hid contrast and\nproduce these vowels in sentence contexts. The intervention involved training\nwith the Speakometer mobile application, which incorporated recording tasks\nfeaturing the English vowels, along with pronunciation feedback and practice.\nThe posttest mirrored the pretest to measure changes in performance. The\nresults revealed significant improvements in both discrimination accuracy and\nproduction of the target contrast following the intervention. However,\nparticipants did not achieve native-like competence. These findings highlight\nthe effectiveness of AI-powered applications in facilitating speech acquisition\nand support their potential use for personalized, interactive pronunciation\ntraining beyond the classroom.", "published": "2025-03-18 10:05:12", "link": "http://arxiv.org/abs/2503.22705v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Growing a Twig to Accelerate Large Vision-Language Models", "abstract": "Large vision-language models (VLMs) have demonstrated remarkable capabilities\nin open-world multimodal understanding, yet their high computational overheads\npose great challenges for practical deployment. Some recent works have proposed\nmethods to accelerate VLMs by pruning redundant visual tokens guided by the\nattention maps of VLM's early layers. Despite the success of these token\npruning methods, they still suffer from two major shortcomings: (i)\nconsiderable accuracy drop due to insensitive attention signals in early\nlayers, and (ii) limited speedup when generating long responses (e.g., 30\ntokens). To address the limitations above, we present TwigVLM -- a simple and\ngeneral architecture by growing a lightweight twig upon an early layer of the\nbase VLM. Compared with most existing VLM acceleration methods purely based on\nvisual token pruning, our TwigVLM not only achieves better accuracy retention\nby employing a twig-guided token pruning (TTP) strategy, but also yields higher\ngeneration speed by utilizing a self-speculative decoding (SSD) strategy.\nTaking LLaVA-1.5-7B as the base VLM, experimental results show that TwigVLM\npreserves 96% of the original performance after pruning 88.9% of visual tokens\nand achieves 154% speedup in generating long responses, delivering\nsignificantly better performance in terms of both accuracy and speed over the\nstate-of-the-art VLM acceleration methods. Code will be made publicly\navailable.", "published": "2025-03-18 09:52:45", "link": "http://arxiv.org/abs/2503.14075v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing LLM Generation with Knowledge Hypergraph for Evidence-Based Medicine", "abstract": "Evidence-based medicine (EBM) plays a crucial role in the application of\nlarge language models (LLMs) in healthcare, as it provides reliable support for\nmedical decision-making processes. Although it benefits from current\nretrieval-augmented generation~(RAG) technologies, it still faces two\nsignificant challenges: the collection of dispersed evidence and the efficient\norganization of this evidence to support the complex queries necessary for EBM.\nTo tackle these issues, we propose using LLMs to gather scattered evidence from\nmultiple sources and present a knowledge hypergraph-based evidence management\nmodel to integrate these evidence while capturing intricate relationships.\nFurthermore, to better support complex queries, we have developed an\nImportance-Driven Evidence Prioritization (IDEP) algorithm that utilizes the\nLLM to generate multiple evidence features, each with an associated importance\nscore, which are then used to rank the evidence and produce the final retrieval\nresults. Experimental results from six datasets demonstrate that our approach\noutperforms existing RAG techniques in application domains of interest to EBM,\nsuch as medical quizzing, hallucination detection, and decision support.\nTestsets and the constructed knowledge graph can be accessed at\n\\href{https://drive.google.com/file/d/1WJ9QTokK3MdkjEmwuFQxwH96j_Byawj_/view?usp=drive_link}{https://drive.google.com/rag4ebm}.", "published": "2025-03-18 09:17:31", "link": "http://arxiv.org/abs/2503.16530v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts", "abstract": "DeepSeek-R1, renowned for its exceptional reasoning capabilities and\nopen-source strategy, is significantly influencing the global artificial\nintelligence landscape. However, it exhibits notable safety shortcomings.\nRecent research conducted by Robust Intelligence, a subsidiary of Cisco, in\ncollaboration with the University of Pennsylvania, revealed that DeepSeek-R1\nachieves a 100\\% attack success rate when processing harmful prompts.\nFurthermore, multiple security firms and research institutions have identified\ncritical security vulnerabilities within the model. Although China Unicom has\nuncovered safety vulnerabilities of R1 in Chinese contexts, the safety\ncapabilities of the remaining distilled models in the R1 series have not yet\nbeen comprehensively evaluated. To address this gap, this study utilizes the\ncomprehensive Chinese safety benchmark CHiSafetyBench to conduct an in-depth\nsafety evaluation of the DeepSeek-R1 series distilled models. The objective is\nto assess the safety capabilities of these models in Chinese contexts both\nbefore and after distillation, and to further elucidate the adverse effects of\ndistillation on model safety. Building on these findings, we implement targeted\nsafety enhancements for six distilled models. Evaluation results indicate that\nthe enhanced models achieve significant improvements in safety while\nmaintaining reasoning capabilities without notable degradation. We open-source\nthe safety-enhanced models at\nhttps://github.com/UnicomAI/DeepSeek-R1-Distill-Safe/tree/main to serve as a\nvaluable resource for future research and optimization of DeepSeek models.", "published": "2025-03-18 08:38:10", "link": "http://arxiv.org/abs/2503.16529v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code", "abstract": "Large language models (LLMs) have unlocked new possibilities for generating\nsynthetic training data in both natural language and code. By producing\nartificial but task-relevant examples, these models can significantly augment\nor even replace real-world datasets, especially when labeled data is scarce or\nsensitive. This paper surveys recent advances in using LLMs to create synthetic\ntext and code, emphasizing prompt-based generation, retrieval-augmented\npipelines, and iterative self-refinement. We show how these methods enrich\nlow-resource tasks such as classification and question answering, as well as\ncode-centric applications such as instruction tuning, code translation, and bug\nrepair, by enabling automated verification of functional correctness. Alongside\npotential benefits like cost-effectiveness, broad coverage, and controllable\ndiversity, we address challenges such as factual inaccuracies in generated\ntext, lack of stylistic realism, and the risk of bias amplification. Proposed\nmitigations include filtering and weighting outputs and reinforcement learning\nwith execution feedback for code. We conclude with open research directions\nlike automated prompt engineering, cross-modal data synthesis, and robust\nevaluation frameworks, highlighting the importance of LLM-generated synthetic\ndata in advancing AI while emphasizing ethical and quality safeguards.", "published": "2025-03-18 08:34:03", "link": "http://arxiv.org/abs/2503.14023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The KoLMogorov Test: Compression by Code Generation", "abstract": "Compression is at the heart of intelligence. A theoretically optimal way to\ncompress any sequence of data is to find the shortest program that outputs that\nsequence and then halts. However, such 'Kolmogorov compression' is\nuncomputable, and code generating LLMs struggle to approximate this theoretical\nideal, as it requires reasoning, planning and search capabilities beyond those\nof current models. In this work, we introduce the KoLMogorov-Test (KT), a\ncompression-as-intelligence test for code generating LLMs. In KT a model is\npresented with a sequence of data at inference time, and asked to generate the\nshortest program that produces the sequence. We identify several benefits of KT\nfor both evaluation and training: an essentially infinite number of problem\ninstances of varying difficulty is readily available, strong baselines already\nexist, the evaluation metric (compression) cannot be gamed, and pretraining\ndata contamination is highly unlikely. To evaluate current models, we use\naudio, text, and DNA data, as well as sequences produced by random synthetic\nprograms. Current flagship models perform poorly - both GPT4-o and\nLlama-3.1-405B struggle on our natural and synthetic sequences. On our\nsynthetic distribution, we are able to train code generation models with lower\ncompression rates than previous approaches. Moreover, we show that gains on\nsynthetic data generalize poorly to real data, suggesting that new innovations\nare necessary for additional gains on KT.", "published": "2025-03-18 07:52:04", "link": "http://arxiv.org/abs/2503.13992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empowering Smaller Models: Tuning LLaMA and Gemma with Chain-of-Thought for Ukrainian Exam Tasks", "abstract": "Leading large language models have demonstrated impressive capabilities in\nreasoning-intensive tasks, such as standardized educational testing. However,\nthey often require extensive training in low-resource settings with\ninaccessible infrastructure. Small or compact models, though more efficient,\nfrequently lack sufficient support for underrepresented languages, leaving a\nperformance gap in critical domains. This work explores the potential of\nparameter-efficient fine-tuning of compact open-weight language models to\nhandle reasoning-intensive tasks in the underrepresented Ukrainian language,\nbuilding on the findings of the ZNO-Eval benchmark. Parameter-efficient\nfine-tuning of LLaMA 3.1 (8 billion parameters), LLaMA 3.2 (3 billion\nparameters), and Gemma 2 (9 billion parameters) models on chain-of-thought\nsolutions resulted in a modest test score improvement of up to 17.4% on complex\nmatching tasks and 1.6% overall compared to tuning on answer letters alone,\noffering enhanced interpretability and robustness. In addition, the proposed\ntuning method with joint task topic and step-by-step solution generation\noutperforms standard chain-of-thought tuning in matching tasks and provides a\n5.4% gain over the best LLaMA 3.2 model due to guiding the model to recall and\napply domain-relevant information. Contrasting obtained results with zero-shot\nevaluations of leading open-weight and proprietary models such as Qwen,\nDeepSeek R1, OpenAI o1 and o3, Gemini, and Claude, highlight that fine-tuning\nLLaMA and Gemma models with 2,032 step-by-step solutions and 20 to 50 million\ntrainable parameters on a single A100 GPU lets them outperform GPT-4o mini,\nMistral Large, and larger open-weight models. This research also evaluates how\nmerging the quantized adapter with the base model influences the generation\nquality. Source code and tuned models are available at\nhttps://github.com/NLPForUA/ZNO.", "published": "2025-03-18 07:44:49", "link": "http://arxiv.org/abs/2503.13988v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Navigating Rifts in Human-LLM Grounding: Study and Benchmark", "abstract": "Language models excel at following instructions but often struggle with the\ncollaborative aspects of conversation that humans naturally employ. This\nlimitation in grounding -- the process by which conversation participants\nestablish mutual understanding -- can lead to outcomes ranging from frustrated\nusers to serious consequences in high-stakes scenarios. To systematically study\ngrounding challenges in human-LLM interactions, we analyze logs from three\nhuman-assistant datasets: WildChat, MultiWOZ, and Bing Chat. We develop a\ntaxonomy of grounding acts and build models to annotate and forecast grounding\nbehavior. Our findings reveal significant differences in human-human and\nhuman-LLM grounding: LLMs were three times less likely to initiate\nclarification and sixteen times less likely to provide follow-up requests than\nhumans. Additionally, early grounding failures predicted later interaction\nbreakdowns. Building on these insights, we introduce RIFTS: a benchmark derived\nfrom publicly available LLM interaction data containing situations where LLMs\nfail to initiate grounding. We note that current frontier models perform poorly\non RIFTS, highlighting the need to reconsider how we train and prompt LLMs for\nhuman interaction. To this end, we develop a preliminary intervention that\nmitigates grounding failures.", "published": "2025-03-18 07:24:05", "link": "http://arxiv.org/abs/2503.13975v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "HDLCoRe: A Training-Free Framework for Mitigating Hallucinations in LLM-Generated HDL", "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities in code generation tasks. However, when applied to hardware\ndescription languages (HDL), these models exhibit significant limitations due\nto data scarcity, resulting in hallucinations and incorrect code generation. To\naddress these challenges, we propose HDLCoRe, a training-free framework that\nenhances LLMs' HDL generation capabilities through prompt engineering\ntechniques and retrieval-augmented generation (RAG). Our approach consists of\ntwo main components: (1) an HDL-aware Chain-of-Thought (CoT) prompting\ntechnique with self-verification that classifies tasks by complexity and type,\nincorporates domain-specific knowledge, and guides LLMs through step-by-step\nself-simulation for error correction; and (2) a two-stage heterogeneous RAG\nsystem that addresses formatting inconsistencies through key component\nextraction and efficiently retrieves relevant HDL examples through sequential\nfiltering and re-ranking. HDLCoRe eliminates the need for model fine-tuning\nwhile substantially improving LLMs' HDL generation capabilities. Experimental\nresults demonstrate that our framework achieves superior performance on the\nRTLLM2.0 benchmark, significantly reducing hallucinations and improving both\nsyntactic and functional correctness.", "published": "2025-03-18 07:09:39", "link": "http://arxiv.org/abs/2503.16528v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models", "abstract": "Large language models (LLMs) have been one of the most important discoveries\nin machine learning in recent years. LLM-based artificial intelligence (AI)\nassistants, such as ChatGPT, have consistently attracted the attention from\nresearchers, investors, and the general public, driving the rapid growth of\nthis industry. With the frequent introduction of new LLMs to the market, it\nbecomes increasingly difficult to differentiate between them, creating a demand\nfor new LLM comparison methods.\n  In this research, the Consistency-focused Similarity Comparison Framework\n(ConSCompF) for generative large language models is proposed. It compares texts\ngenerated by two LLMs and produces a similarity score, indicating the overall\ndegree of similarity between their responses. The main advantage of this\nframework is that it can operate on a small number of unlabeled data, such as\nchatbot instruction prompts, and does not require LLM developers to disclose\nany information about their product.\n  To evaluate the efficacy of ConSCompF, two experiments aimed at identifying\nsimilarities between multiple LLMs are conducted. Additionally, these\nexperiments examine the correlation between the similarity scores generated by\nConSCompF and the differences in the outputs produced by other benchmarking\ntechniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison\nexperiments is conducted to evaluate the performance of ConSCompF in a few-shot\nLLM comparison scenario.\n  The proposed framework can be used for calculating similarity matrices of\nmultiple LLMs, which can be effectively visualized using principal component\nanalysis (PCA). The ConSCompF output may provide useful insights into data that\nmight have been used during LLM training and help detect possible investment\nfraud attempts.", "published": "2025-03-18 05:38:04", "link": "http://arxiv.org/abs/2503.13923v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Where do Large Vision-Language Models Look at when Answering Questions?", "abstract": "Large Vision-Language Models (LVLMs) have shown promising performance in\nvision-language understanding and reasoning tasks. However, their visual\nunderstanding behaviors remain underexplored. A fundamental question arises: to\nwhat extent do LVLMs rely on visual input, and which image regions contribute\nto their responses? It is non-trivial to interpret the free-form generation of\nLVLMs due to their complicated visual architecture (e.g., multiple encoders and\nmulti-resolution) and variable-length outputs. In this paper, we extend\nexisting heatmap visualization methods (e.g., iGOS++) to support LVLMs for\nopen-ended visual question answering. We propose a method to select visually\nrelevant tokens that reflect the relevance between generated answers and input\nimage. Furthermore, we conduct a comprehensive analysis of state-of-the-art\nLVLMs on benchmarks designed to require visual information to answer. Our\nfindings offer several insights into LVLM behavior, including the relationship\nbetween focus region and answer correctness, differences in visual attention\nacross architectures, and the impact of LLM scale on visual understanding. The\ncode and data are available at\nhttps://github.com/bytedance/LVLM_Interpretation.", "published": "2025-03-18 04:34:43", "link": "http://arxiv.org/abs/2503.13891v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "COMM:Concentrated Margin Maximization for Robust Document-Level Relation Extraction", "abstract": "Document-level relation extraction (DocRE) is the process of identifying and\nextracting relations between entities that span multiple sentences within a\ndocument. Due to its realistic settings, DocRE has garnered increasing research\nattention in recent years. Previous research has mostly focused on developing\nsophisticated encoding models to better capture the intricate patterns between\nentity pairs. While these advancements are undoubtedly crucial, an even more\nfoundational challenge lies in the data itself. The complexity inherent in\nDocRE makes the labeling process prone to errors, compounded by the extreme\nsparsity of positive relation samples, which is driven by both the limited\navailability of positive instances and the broad diversity of positive relation\ntypes. These factors can lead to biased optimization processes, further\ncomplicating the task of accurate relation extraction. Recognizing these\nchallenges, we have developed a robust framework called \\textit{\\textbf{COMM}}\nto better solve DocRE. \\textit{\\textbf{COMM}} operates by initially employing\nan instance-aware reasoning method to dynamically capture pertinent information\nof entity pairs within the document and extract relational features. Following\nthis, \\textit{\\textbf{COMM}} takes into account the distribution of relations\nand the difficulty of samples to dynamically adjust the margins between\nprediction logits and the decision threshold, a process we call Concentrated\nMargin Maximization. In this way, \\textit{\\textbf{COMM}} not only enhances the\nextraction of relevant relational features but also boosts DocRE performance by\naddressing the specific challenges posed by the data. Extensive experiments and\nanalysis demonstrate the versatility and effectiveness of\n\\textit{\\textbf{COMM}}, especially its robustness when trained on low-quality\ndata (achieves \\textgreater 10\\% performance gains).", "published": "2025-03-18 04:31:57", "link": "http://arxiv.org/abs/2503.13885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Squeeze Out Tokens from Sample for Finer-Grained Data Governance", "abstract": "Widely observed data scaling laws, in which error falls off as a power of the\ntraining size, demonstrate the diminishing returns of unselective data\nexpansion. Hence, data governance is proposed to downsize datasets through\npruning non-informative samples. Yet, isolating the impact of a specific sample\non overall model performance is challenging, due to the vast computation\nrequired for tryout all sample combinations. Current data governors circumvent\nthis complexity by estimating sample contributions through heuristic-derived\nscalar scores, thereby discarding low-value ones. Despite thorough sample\nsieving, retained samples contain substantial undesired tokens intrinsically,\nunderscoring the potential for further compression and purification. In this\nwork, we upgrade data governance from a 'sieving' approach to a 'juicing' one.\nInstead of scanning for least-flawed samples, our dual-branch DataJuicer\napplies finer-grained intra-sample governance. It squeezes out informative\ntokens and boosts image-text alignments. Specifically, the vision branch\nretains salient image patches and extracts relevant object classes, while the\ntext branch incorporates these classes to enhance captions. Consequently,\nDataJuicer yields more refined datasets through finer-grained governance.\nExtensive experiments across datasets demonstrate that DataJuicer significantly\noutperforms existing DataSieve in image-text retrieval, classification, and\ndense visual reasoning.", "published": "2025-03-18 04:06:50", "link": "http://arxiv.org/abs/2503.14559v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations", "abstract": "Background. Systematic reviews in comparative effectiveness research require\ntimely evidence synthesis. Preprints accelerate knowledge dissemination but\nvary in quality, posing challenges for systematic reviews.\n  Methods. We propose AutoConfidence (automated confidence assessment), an\nadvanced framework for predicting preprint publication, which reduces reliance\non manual curation and expands the range of predictors, including three key\nadvancements: (1) automated data extraction using natural language processing\ntechniques, (2) semantic embeddings of titles and abstracts, and (3) large\nlanguage model (LLM)-driven evaluation scores. Additionally, we employed two\nprediction models: a random forest classifier for binary outcome and a survival\ncure model that predicts both binary outcome and publication risk over time.\n  Results. The random forest classifier achieved AUROC 0.692 with LLM-driven\nscores, improving to 0.733 with semantic embeddings and 0.747 with article\nusage metrics. The survival cure model reached AUROC 0.716 with LLM-driven\nscores, improving to 0.731 with semantic embeddings. For publication risk\nprediction, it achieved a concordance index of 0.658, increasing to 0.667 with\nsemantic embeddings.\n  Conclusion. Our study advances the framework for preprint publication\nprediction through automated data extraction and multiple feature integration.\nBy combining semantic embeddings with LLM-driven evaluations, AutoConfidence\nenhances predictive performance while reducing manual annotation burden. The\nframework has the potential to facilitate systematic incorporation of preprint\narticles in evidence-based medicine, supporting researchers in more effective\nevaluation and utilization of preprint resources.", "published": "2025-03-18 03:14:23", "link": "http://arxiv.org/abs/2503.13857v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Generated Persona is a Promise with a Catch", "abstract": "The use of large language models (LLMs) to simulate human behavior has gained\nsignificant attention, particularly through personas that approximate\nindividual characteristics. Persona-based simulations hold promise for\ntransforming disciplines that rely on population-level feedback, including\nsocial science, economic analysis, marketing research, and business operations.\nTraditional methods to collect realistic persona data face significant\nchallenges. They are prohibitively expensive and logistically challenging due\nto privacy constraints, and often fail to capture multi-dimensional attributes,\nparticularly subjective qualities. Consequently, synthetic persona generation\nwith LLMs offers a scalable, cost-effective alternative. However, current\napproaches rely on ad hoc and heuristic generation techniques that do not\nguarantee methodological rigor or simulation precision, resulting in systematic\nbiases in downstream tasks. Through extensive large-scale experiments including\npresidential election forecasts and general opinion surveys of the U.S.\npopulation, we reveal that these biases can lead to significant deviations from\nreal-world outcomes. Our findings underscore the need to develop a rigorous\nscience of persona generation and outline the methodological innovations,\norganizational and institutional support, and empirical foundations required to\nenhance the reliability and scalability of LLM-driven persona simulations. To\nsupport further research and development in this area, we have open-sourced\napproximately one million generated personas, available for public access and\nanalysis at https://huggingface.co/datasets/Tianyi-Lab/Personas.", "published": "2025-03-18 03:11:27", "link": "http://arxiv.org/abs/2503.16527v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media", "abstract": "In the realm of political advertising, persuasion operates as a pivotal\nelement within the broader framework of propaganda, exerting profound\ninfluences on public opinion and electoral outcomes. In this paper, we (1)\nintroduce a lightweight model for persuasive text detection that achieves\nstate-of-the-art performance in Subtask 3 of SemEval 2023 Task 3, while\nsignificantly reducing the computational resource requirements; and (2)\nleverage the proposed model to gain insights into political campaigning\nstrategies on social media platforms by applying it to a real-world dataset we\ncurated, consisting of Facebook political ads from the 2022 Australian Federal\nelection campaign. Our study shows how subtleties can be found in persuasive\npolitical advertisements and presents a pragmatic approach to detect and\nanalyze such strategies with limited resources, enhancing transparency in\nsocial media political campaigns.", "published": "2025-03-18 02:33:38", "link": "http://arxiv.org/abs/2503.13844v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Vocabularizing Training for Neural Machine Translation", "abstract": "Past vocabulary learning techniques identify relevant vocabulary before\ntraining, relying on statistical and entropy-based assumptions that largely\nneglect the role of model training. Empirically, we observe that trained\ntranslation models are induced to use a byte-pair encoding (BPE) vocabulary\nsubset distinct from the original BPE vocabulary, leading to performance\nimprovements when retrained with the induced vocabulary. In this paper, we\nanalyze this discrepancy in neural machine translation by examining vocabulary\nand entropy shifts during self-training--where each iteration generates a\nlabeled dataset by pairing source sentences with the model's predictions to\ndefine a new vocabulary. Building on these insights, we propose\nself-vocabularizing training, an iterative method that self-selects a smaller,\nmore optimal vocabulary, yielding up to a 1.49 BLEU improvement. Moreover, we\nfind that deeper model architectures lead to both an increase in unique token\nusage and a 6-8% reduction in vocabulary size.", "published": "2025-03-18 02:21:07", "link": "http://arxiv.org/abs/2503.13837v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAT: Boosting Misclassification Detection Ability without Extra Data", "abstract": "As deep neural networks(DNN) become increasingly prevalent, particularly in\nhigh-stakes areas such as autonomous driving and healthcare, the ability to\ndetect incorrect predictions of models and intervene accordingly becomes\ncrucial for safety. In this work, we investigate the detection of misclassified\ninputs for image classification models from the lens of adversarial\nperturbation: we propose to use robust radius (a.k.a. input-space margin) as a\nconfidence metric and design two efficient estimation algorithms, RR-BS and\nRR-Fast, for misclassification detection. Furthermore, we design a training\nmethod called Radius Aware Training (RAT) to boost models' ability to identify\nmistakes. Extensive experiments show our method could achieve up to 29.3%\nreduction on AURC and 21.62% reduction in FPR@95TPR, compared with previous\nmethods.", "published": "2025-03-18 23:18:55", "link": "http://arxiv.org/abs/2503.14783v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution", "abstract": "Single Image Super-Resolution (SISR) aims to reconstruct high-resolution (HR)\nimages from low-resolution (LR) inputs. Deep learning, especially Convolutional\nNeural Networks (CNNs), has advanced SISR. However, increasing network depth\nincreases parameters, and memory usage, and slows training, which is\nproblematic for resource-limited devices. To address this, lightweight models\nare developed to balance accuracy and efficiency. We propose the Involution &\nBSConv Multi-Depth Distillation Network (IBMDN), combining Involution & BSConv\nMulti-Depth Distillation Block (IBMDB) and the Contrast and High-Frequency\nAttention Block (CHFAB). IBMDB integrates Involution and BSConv to balance\ncomputational efficiency and feature extraction. CHFAB enhances high-frequency\ndetails for better visual quality. IBMDB is compatible with other SISR\narchitectures and reduces complexity, improving evaluation metrics like PSNR\nand SSIM. In transformer-based models, IBMDB reduces memory usage while\nimproving feature extraction. In GANs, it enhances perceptual quality,\nbalancing pixel-level accuracy with perceptual details. Our experiments show\nthat the method achieves high accuracy with minimal computational cost. The\ncode is available at GitHub.", "published": "2025-03-18 23:10:08", "link": "http://arxiv.org/abs/2503.14779v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning", "abstract": "Physical AI systems need to perceive, understand, and perform complex actions\nin the physical world. In this paper, we present the Cosmos-Reason1 models that\ncan understand the physical world and generate appropriate embodied decisions\n(e.g., next step action) in natural language through long chain-of-thought\nreasoning processes. We begin by defining key capabilities for Physical AI\nreasoning, with a focus on physical common sense and embodied reasoning. To\nrepresent physical common sense, we use a hierarchical ontology that captures\nfundamental knowledge about space, time, and physics. For embodied reasoning,\nwe rely on a two-dimensional ontology that generalizes across different\nphysical embodiments. Building on these capabilities, we develop two multimodal\nlarge language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B. We curate data\nand train our models in four stages: vision pre-training, general supervised\nfine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL)\nas the post-training. To evaluate our models, we build comprehensive benchmarks\nfor physical common sense and embodied reasoning according to our ontologies.\nEvaluation results show that Physical AI SFT and reinforcement learning bring\nsignificant improvements. To facilitate the development of Physical AI, we will\nmake our code and pre-trained models available under the NVIDIA Open Model\nLicense at https://github.com/nvidia-cosmos/cosmos-reason1.", "published": "2025-03-18 22:06:58", "link": "http://arxiv.org/abs/2503.15558v2", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection", "abstract": "Street scene datasets, collected from Street View or dashboard cameras, offer\na promising means of detecting urban objects and incidents like street\nflooding. However, a major challenge in using these datasets is their lack of\nreliable labels: there are myriad types of incidents, many types occur rarely,\nand ground-truth measures of where incidents occur are lacking. Here, we\npropose BayFlood, a two-stage approach which circumvents this difficulty.\nFirst, we perform zero-shot classification of where incidents occur using a\npretrained vision-language model (VLM). Second, we fit a spatial Bayesian model\non the VLM classifications. The zero-shot approach avoids the need to annotate\nlarge training sets, and the Bayesian model provides frequent desiderata in\nurban settings - principled measures of uncertainty, smoothing across\nlocations, and incorporation of external data like stormwater accumulation\nzones. We comprehensively validate this two-stage approach, showing that VLMs\nprovide strong zero-shot signal for floods across multiple cities and time\nperiods, the Bayesian model improves out-of-sample prediction relative to\nbaseline methods, and our inferred flood risk correlates with known external\npredictors of risk. Having validated our approach, we show it can be used to\nimprove urban flood detection: our analysis reveals 113,738 people who are at\nhigh risk of flooding overlooked by current methods, identifies demographic\nbiases in existing methods, and suggests locations for new flood sensors. More\nbroadly, our results showcase how Bayesian modeling of zero-shot LM annotations\nrepresents a promising paradigm because it avoids the need to collect large\nlabeled datasets and leverages the power of foundation models while providing\nthe expressiveness and uncertainty quantification of Bayesian models.", "published": "2025-03-18 21:53:37", "link": "http://arxiv.org/abs/2503.14754v2", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LipShiFT: A Certifiably Robust Shift-based Vision Transformer", "abstract": "Deriving tight Lipschitz bounds for transformer-based architectures presents\na significant challenge. The large input sizes and high-dimensional attention\nmodules typically prove to be crucial bottlenecks during the training process\nand leads to sub-optimal results. Our research highlights practical constraints\nof these methods in vision tasks. We find that Lipschitz-based margin training\nacts as a strong regularizer while restricting weights in successive layers of\nthe model. Focusing on a Lipschitz continuous variant of the ShiftViT model, we\naddress significant training challenges for transformer-based architectures\nunder norm-constrained input setting. We provide an upper bound estimate for\nthe Lipschitz constants of this model using the $l_2$ norm on common image\nclassification datasets. Ultimately, we demonstrate that our method scales to\nlarger models and advances the state-of-the-art in certified robustness for\ntransformer-based architectures.", "published": "2025-03-18 21:38:18", "link": "http://arxiv.org/abs/2503.14751v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GR00T N1: An Open Foundation Model for Generalist Humanoid Robots", "abstract": "General-purpose robots need a versatile body and an intelligent mind. Recent\nadvancements in humanoid robots have shown great promise as a hardware platform\nfor building generalist autonomy in the human world. A robot foundation model,\ntrained on massive and diverse data sources, is essential for enabling the\nrobots to reason about novel situations, robustly handle real-world\nvariability, and rapidly learn new tasks. To this end, we introduce GR00T N1,\nan open foundation model for humanoid robots. GR00T N1 is a\nVision-Language-Action (VLA) model with a dual-system architecture. The\nvision-language module (System 2) interprets the environment through vision and\nlanguage instructions. The subsequent diffusion transformer module (System 1)\ngenerates fluid motor actions in real time. Both modules are tightly coupled\nand jointly trained end-to-end. We train GR00T N1 with a heterogeneous mixture\nof real-robot trajectories, human videos, and synthetically generated datasets.\nWe show that our generalist robot model GR00T N1 outperforms the\nstate-of-the-art imitation learning baselines on standard simulation benchmarks\nacross multiple robot embodiments. Furthermore, we deploy our model on the\nFourier GR-1 humanoid robot for language-conditioned bimanual manipulation\ntasks, achieving strong performance with high data efficiency.", "published": "2025-03-18 21:06:21", "link": "http://arxiv.org/abs/2503.14734v2", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Construction Site Scaffolding Completeness Detection Based on Mask R-CNN and Hough Transform", "abstract": "Construction site scaffolding is essential for many building projects, and\nensuring its safety is crucial to prevent accidents. The safety inspector must\ncheck the scaffolding's completeness and integrity, where most violations\noccur. The inspection process includes ensuring all the components are in the\nright place since workers often compromise safety for convenience and\ndisassemble parts such as cross braces. This paper proposes a deep\nlearning-based approach to detect the scaffolding and its cross braces using\ncomputer vision. A scaffold image dataset with annotated labels is used to\ntrain a convolutional neural network (CNN) model. With the proposed approach,\nwe can automatically detect the completeness of cross braces from images taken\nat construction sites, without the need for manual inspection, saving a\nsignificant amount of time and labor costs. This non-invasive and efficient\nsolution for detecting scaffolding completeness can help improve safety in\nconstruction sites.", "published": "2025-03-18 20:27:22", "link": "http://arxiv.org/abs/2503.14716v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Whole-Body Image-to-Image Translation for a Virtual Scanner in a Healthcare Digital Twin", "abstract": "Generating positron emission tomography (PET) images from computed tomography\n(CT) scans via deep learning offers a promising pathway to reduce radiation\nexposure and costs associated with PET imaging, improving patient care and\naccessibility to functional imaging. Whole-body image translation presents\nchallenges due to anatomical heterogeneity, often limiting generalized models.\nWe propose a framework that segments whole-body CT images into four\nregions-head, trunk, arms, and legs-and uses district-specific Generative\nAdversarial Networks (GANs) for tailored CT-to-PET translation. Synthetic PET\nimages from each region are stitched together to reconstruct the whole-body\nscan. Comparisons with a baseline non-segmented GAN and experiments with\nPix2Pix and CycleGAN architectures tested paired and unpaired scenarios.\nQuantitative evaluations at district, whole-body, and lesion levels\ndemonstrated significant improvements with our district-specific GANs. Pix2Pix\nyielded superior metrics, ensuring precise, high-quality image synthesis. By\naddressing anatomical heterogeneity, this approach achieves state-of-the-art\nresults in whole-body CT-to-PET translation. This methodology supports\nhealthcare Digital Twins by enabling accurate virtual PET scans from CT data,\ncreating virtual imaging representations to monitor, predict, and optimize\nhealth outcomes.", "published": "2025-03-18 20:19:28", "link": "http://arxiv.org/abs/2503.15555v1", "categories": ["eess.IV", "cs.AI"], "primary_category": "eess.IV"}
{"title": "DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis", "abstract": "Differentially private (DP) image synthesis aims to generate artificial\nimages that retain the properties of sensitive images while protecting the\nprivacy of individual images within the dataset. Despite recent advancements,\nwe find that inconsistent--and sometimes flawed--evaluation protocols have been\napplied across studies. This not only impedes the understanding of current\nmethods but also hinders future advancements.\n  To address the issue, this paper introduces DPImageBench for DP image\nsynthesis, with thoughtful design across several dimensions: (1) Methods. We\nstudy eleven prominent methods and systematically characterize each based on\nmodel architecture, pretraining strategy, and privacy mechanism. (2)\nEvaluation. We include nine datasets and seven fidelity and utility metrics to\nthoroughly assess them. Notably, we find that a common practice of selecting\ndownstream classifiers based on the highest accuracy on the sensitive test set\nnot only violates DP but also overestimates the utility scores. DPImageBench\ncorrects for these mistakes. (3) Platform. Despite the methods and evaluation\nprotocols, DPImageBench provides a standardized interface that accommodates\ncurrent and future implementations within a unified framework. With\nDPImageBench, we have several noteworthy findings. For example, contrary to the\ncommon wisdom that pretraining on public image datasets is usually beneficial,\nwe find that the distributional similarity between pretraining and sensitive\nimages significantly impacts the performance of the synthetic images and does\nnot always yield improvements. In addition, adding noise to low-dimensional\nfeatures, such as the high-level characteristics of sensitive images, is less\naffected by the privacy budget compared to adding noise to high-dimensional\nfeatures, like weight gradients. The former methods perform better than the\nlatter under a low privacy budget.", "published": "2025-03-18 19:37:35", "link": "http://arxiv.org/abs/2503.14681v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Core-Periphery Principle Guided State Space Model for Functional Connectome Classification", "abstract": "Understanding the organization of human brain networks has become a central\nfocus in neuroscience, particularly in the study of functional connectivity,\nwhich plays a crucial role in diagnosing neurological disorders. Advances in\nfunctional magnetic resonance imaging and machine learning techniques have\nsignificantly improved brain network analysis. However, traditional machine\nlearning approaches struggle to capture the complex relationships between brain\nregions, while deep learning methods, particularly Transformer-based models,\nface computational challenges due to their quadratic complexity in\nlong-sequence modeling. To address these limitations, we propose a\nCore-Periphery State-Space Model (CP-SSM), an innovative framework for\nfunctional connectome classification. Specifically, we introduce Mamba, a\nselective state-space model with linear complexity, to effectively capture\nlong-range dependencies in functional brain networks. Furthermore, inspired by\nthe core-periphery (CP) organization, a fundamental characteristic of brain\nnetworks that enhances efficient information transmission, we design CP-MoE, a\nCP-guided Mixture-of-Experts that improves the representation learning of brain\nconnectivity patterns. We evaluate CP-SSM on two benchmark fMRI datasets: ABIDE\nand ADNI. Experimental results demonstrate that CP-SSM surpasses\nTransformer-based models in classification performance while significantly\nreducing computational complexity. These findings highlight the effectiveness\nand efficiency of CP-SSM in modeling brain functional connectivity, offering a\npromising direction for neuroimaging-based neurological disease diagnosis.", "published": "2025-03-18 19:03:27", "link": "http://arxiv.org/abs/2503.14655v1", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "eess.IV"], "primary_category": "q-bio.NC"}
{"title": "Dynamic Accumulated Attention Map for Interpreting Evolution of Decision-Making in Vision Transformer", "abstract": "Various Vision Transformer (ViT) models have been widely used for image\nrecognition tasks. However, existing visual explanation methods can not display\nthe attention flow hidden inside the inner structure of ViT models, which\nexplains how the final attention regions are formed inside a ViT for its\ndecision-making. In this paper, a novel visual explanation approach, Dynamic\nAccumulated Attention Map (DAAM), is proposed to provide a tool that can\nvisualize, for the first time, the attention flow from the top to the bottom\nthrough ViT networks. To this end, a novel decomposition module is proposed to\nconstruct and store the spatial feature information by unlocking the [class]\ntoken generated by the self-attention module of each ViT block. The module can\nalso obtain the channel importance coefficients by decomposing the\nclassification score for supervised ViT models. Because of the lack of\nclassification score in self-supervised ViT models, we propose dimension-wise\nimportance weights to compute the channel importance coefficients. Such spatial\nfeatures are linearly combined with the corresponding channel importance\ncoefficients, forming the attention map for each block. The dynamic attention\nflow is revealed by block-wisely accumulating each attention map. The\ncontribution of this work focuses on visualizing the evolution dynamic of the\ndecision-making attention for any intermediate block inside a ViT model by\nproposing a novel decomposition module and dimension-wise importance weights.\nThe quantitative and qualitative analysis consistently validate the\neffectiveness and superior capacity of the proposed DAAM for not only\ninterpreting ViT models with the fully-connected layers as the classifier but\nalso self-supervised ViT models. The code is available at\nhttps://github.com/ly9802/DynamicAccumulatedAttentionMap.", "published": "2025-03-18 18:41:01", "link": "http://arxiv.org/abs/2503.14640v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control", "abstract": "How do humans move? The quest to understand human motion has broad\napplications in numerous fields, ranging from computer animation and motion\nsynthesis to neuroscience, human prosthetics and rehabilitation. Although\nadvances in reinforcement learning (RL) have produced impressive results in\ncapturing human motion using simplified humanoids, controlling physiologically\naccurate models of the body remains an open challenge. In this work, we present\na model-free motion imitation framework (KINESIS) to advance the understanding\nof muscle-based motor control. Using a musculoskeletal model of the lower body\nwith 80 muscle actuators and 20 DoF, we demonstrate that KINESIS achieves\nstrong imitation performance on 1.9 hours of motion capture data, is\ncontrollable by natural language through pre-trained text-to-motion generative\nmodels, and can be fine-tuned to carry out high-level tasks such as target goal\nreaching. Importantly, KINESIS generates muscle activity patterns that\ncorrelate well with human EMG activity. The physiological plausibility makes\nKINESIS a promising model for tackling challenging problems in human motor\ncontrol theory, which we highlight by investigating Bernstein's redundancy\nproblem in the context of locomotion. Code, videos and benchmarks will be\navailable at https://github.com/amathislab/Kinesis.", "published": "2025-03-18 18:37:49", "link": "http://arxiv.org/abs/2503.14637v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "q-bio.NC"], "primary_category": "cs.RO"}
{"title": "Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving", "abstract": "Providing effective feedback is important for student learning in programming\nproblem-solving. In this sense, Large Language Models (LLMs) have emerged as\npotential tools to automate feedback generation. However, their reliability and\nability to identify reasoning errors in student code remain not well\nunderstood. This study evaluates the performance of four LLMs (GPT-4o, GPT-4o\nmini, GPT-4-Turbo, and Gemini-1.5-pro) on a benchmark dataset of 45 student\nsolutions. We assessed the models' capacity to provide accurate and insightful\nfeedback, particularly in identifying reasoning mistakes. Our analysis reveals\nthat 63\\% of feedback hints were accurate and complete, while 37\\% contained\nmistakes, including incorrect line identification, flawed explanations, or\nhallucinated issues. These findings highlight the potential and limitations of\nLLMs in programming education and underscore the need for improvements to\nenhance reliability and minimize risks in educational applications.", "published": "2025-03-18 18:31:36", "link": "http://arxiv.org/abs/2503.14630v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach", "abstract": "False arrhythmia alarms in intensive care units (ICUs) are a significant\nchallenge, contributing to alarm fatigue and potentially compromising patient\nsafety. Ventricular tachycardia (VT) alarms are particularly difficult to\ndetect accurately due to their complex nature. This paper presents a machine\nlearning approach to reduce false VT alarms using the VTaC dataset, a benchmark\ndataset of annotated VT alarms from ICU monitors. We extract time-domain and\nfrequency-domain features from waveform data, preprocess the data, and train\ndeep learning models to classify true and false VT alarms. Our results\ndemonstrate high performance, with ROC-AUC scores exceeding 0.96 across various\ntraining configurations. This work highlights the potential of machine learning\nto improve the accuracy of VT alarm detection in clinical settings.", "published": "2025-03-18 18:18:38", "link": "http://arxiv.org/abs/2503.14621v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MusicInfuser: Making Video Diffusion Listen and Dance", "abstract": "We introduce MusicInfuser, an approach for generating high-quality dance\nvideos that are synchronized to a specified music track. Rather than attempting\nto design and train a new multimodal audio-video model, we show how existing\nvideo diffusion models can be adapted to align with musical inputs by\nintroducing lightweight music-video cross-attention and a low-rank adapter.\nUnlike prior work requiring motion capture data, our approach fine-tunes only\non dance videos. MusicInfuser achieves high-quality music-driven video\ngeneration while preserving the flexibility and generative capabilities of the\nunderlying models. We introduce an evaluation framework using Video-LLMs to\nassess multiple dimensions of dance generation quality. The project page and\ncode are available at https://susunghong.github.io/MusicInfuser.", "published": "2025-03-18 17:59:58", "link": "http://arxiv.org/abs/2503.14505v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Power of Context: How Multimodality Improves Image Super-Resolution", "abstract": "Single-image super-resolution (SISR) remains challenging due to the inherent\ndifficulty of recovering fine-grained details and preserving perceptual quality\nfrom low-resolution inputs. Existing methods often rely on limited image\npriors, leading to suboptimal results. We propose a novel approach that\nleverages the rich contextual information available in multiple modalities --\nincluding depth, segmentation, edges, and text prompts -- to learn a powerful\ngenerative prior for SISR within a diffusion model framework. We introduce a\nflexible network architecture that effectively fuses multimodal information,\naccommodating an arbitrary number of input modalities without requiring\nsignificant modifications to the diffusion process. Crucially, we mitigate\nhallucinations, often introduced by text prompts, by using spatial information\nfrom other modalities to guide regional text-based conditioning. Each\nmodality's guidance strength can also be controlled independently, allowing\nsteering outputs toward different directions, such as increasing bokeh through\ndepth or adjusting object prominence via segmentation. Extensive experiments\ndemonstrate that our model surpasses state-of-the-art generative SISR methods,\nachieving superior visual quality and fidelity. See project page at\nhttps://mmsr.kfmei.com/.", "published": "2025-03-18 17:59:54", "link": "http://arxiv.org/abs/2503.14503v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Measuring AI Ability to Complete Long Tasks", "abstract": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark\nperformance remains unclear. To quantify the capabilities of AI systems in\nterms of human capabilities, we propose a new metric: 50%-task-completion time\nhorizon. This is the time humans typically take to complete tasks that AI\nmodels can complete with 50% success rate. We first timed humans with relevant\ndomain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter\ntasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet\nhave a 50% time horizon of around 50 minutes. Furthermore, frontier AI time\nhorizon has been doubling approximately every seven months since 2019, though\nthe trend may have accelerated in 2024. The increase in AI models' time\nhorizons seems to be primarily driven by greater reliability and ability to\nadapt to mistakes, combined with better logical reasoning and tool use\ncapabilities. We discuss the limitations of our results -- including their\ndegree of external validity -- and the implications of increased autonomy for\ndangerous capabilities. If these results generalize to real-world software\ntasks, extrapolation of this trend predicts that within 5 years, AI systems\nwill be capable of automating many software tasks that currently take humans a\nmonth.", "published": "2025-03-18 17:59:31", "link": "http://arxiv.org/abs/2503.14499v2", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "State Space Model Meets Transformer: A New Paradigm for 3D Object Detection", "abstract": "DETR-based methods, which use multi-layer transformer decoders to refine\nobject queries iteratively, have shown promising performance in 3D indoor\nobject detection. However, the scene point features in the transformer decoder\nremain fixed, leading to minimal contributions from later decoder layers,\nthereby limiting performance improvement. Recently, State Space Models (SSM)\nhave shown efficient context modeling ability with linear complexity through\niterative interactions between system states and inputs. Inspired by SSMs, we\npropose a new 3D object DEtection paradigm with an interactive STate space\nmodel (DEST). In the interactive SSM, we design a novel state-dependent SSM\nparameterization method that enables system states to effectively serve as\nqueries in 3D indoor detection tasks. In addition, we introduce four key\ndesigns tailored to the characteristics of point cloud and SSM: The\nserialization and bidirectional scanning strategies enable bidirectional\nfeature interaction among scene points within the SSM. The inter-state\nattention mechanism models the relationships between state points, while the\ngated feed-forward network enhances inter-channel correlations. To the best of\nour knowledge, this is the first method to model queries as system states and\nscene points as system inputs, which can simultaneously update scene point\nfeatures and query features with linear complexity. Extensive experiments on\ntwo challenging datasets demonstrate the effectiveness of our DEST-based\nmethod. Our method improves the GroupFree baseline in terms of AP50 on ScanNet\nV2 (+5.3) and SUN RGB-D (+3.2) datasets. Based on the VDETR baseline, Our\nmethod sets a new SOTA on the ScanNetV2 and SUN RGB-D datasets.", "published": "2025-03-18 17:58:03", "link": "http://arxiv.org/abs/2503.14493v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control", "abstract": "We introduce Cosmos-Transfer, a conditional world generation model that can\ngenerate world simulations based on multiple spatial control inputs of various\nmodalities such as segmentation, depth, and edge. In the design, the spatial\nconditional scheme is adaptive and customizable. It allows weighting different\nconditional inputs differently at different spatial locations. This enables\nhighly controllable world generation and finds use in various world-to-world\ntransfer use cases, including Sim2Real. We conduct extensive evaluations to\nanalyze the proposed model and demonstrate its applications for Physical AI,\nincluding robotics Sim2Real and autonomous vehicle data enrichment. We further\ndemonstrate an inference scaling strategy to achieve real-time world generation\nwith an NVIDIA GB200 NVL72 rack. To help accelerate research development in the\nfield, we open-source our models and code at\nhttps://github.com/nvidia-cosmos/cosmos-transfer1.", "published": "2025-03-18 17:57:54", "link": "http://arxiv.org/abs/2503.14492v2", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Engineering Scientific Assistants using Interactive Structured Induction of Programs", "abstract": "We are interested in the construction of software that can act as scientific\nassistants to domain specialists. It is expected that such assistants will be\nneeded to accelerate the identification of ways to address complex problems\nrequiring urgent solutions. In this paper, our focus is not on a specific\nscientific problem, but on the software-engineering of such 'science\naccelerators'. Recent developments in 'No Code' techniques would seem to\nsuggest that scientist can simply hypothesise solutions simply by conversing\nwith a large language model (LLM). However, for complex scientific problems,\nthis seems unlikely given the current state of LLM technology. What does appear\nfeasible is that a software engineer can use LLMs to rapidly construct programs\nfor use by a domain-specialist, including the specialist's requirements\nexpressed in natural language. We propose the design of an interactive form of\n'structured' inductive programming in which a software-engineer and an LLM\ncollaboratively construct an 'assistant' for a scientific data analysis. The\npaper describes a simple implementation called iStrucInd that adapts a '2-way\nIntelligibility' protocol to implement the interaction between the software\nengineer and the LLM. We test the tool on two different non-trivial scientific\ndata analysis tasks. Specifically, we compare the system constructed by\niStrucInd against systems constructed manually and by Low Code/No Code methods\nalong dimensions of: (a) program performance; (b) program quality; and (c)\nprogramming effort. The results show iStrucInd allows a software engineer to\ndevelop better programs faster suggesting interactive structured induction can\nplay a useful role in the rapid construction of scientific assistants.", "published": "2025-03-18 17:57:16", "link": "http://arxiv.org/abs/2503.14488v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "DiffMoE: Dynamic Token Selection for Scalable Diffusion Transformers", "abstract": "Diffusion models have demonstrated remarkable success in various image\ngeneration tasks, but their performance is often limited by the uniform\nprocessing of inputs across varying conditions and noise levels. To address\nthis limitation, we propose a novel approach that leverages the inherent\nheterogeneity of the diffusion process. Our method, DiffMoE, introduces a\nbatch-level global token pool that enables experts to access global token\ndistributions during training, promoting specialized expert behavior. To\nunleash the full potential of the diffusion process, DiffMoE incorporates a\ncapacity predictor that dynamically allocates computational resources based on\nnoise levels and sample complexity. Through comprehensive evaluation, DiffMoE\nachieves state-of-the-art performance among diffusion models on ImageNet\nbenchmark, substantially outperforming both dense architectures with 3x\nactivated parameters and existing MoE approaches while maintaining 1x activated\nparameters. The effectiveness of our approach extends beyond class-conditional\ngeneration to more challenging tasks such as text-to-image generation,\ndemonstrating its broad applicability across different diffusion model\napplications. Project Page: https://shiml20.github.io/DiffMoE/", "published": "2025-03-18 17:57:07", "link": "http://arxiv.org/abs/2503.14487v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Attribution Score Alignment in Explainable Data Management", "abstract": "Different attribution-scores have been proposed to quantify the relevance of\ndatabase tuples for a query answer from a database. Among them, we find Causal\nResponsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal\nEffect. They have been analyzed in isolation, mainly in terms of computational\nproperties. In this work, we start an investigation into the alignment of these\nscores on the basis of the queries at hand; that is, on whether they induce\ncompatible rankings of tuples. We are able to identify vast classes of queries\nfor which some pairs of scores are always aligned, and others for which they\nare not. It turns out that the presence of exogenous tuples makes a crucial\ndifference in this regard.", "published": "2025-03-18 17:45:32", "link": "http://arxiv.org/abs/2503.14469v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Pauli Network Circuit Synthesis with Reinforcement Learning", "abstract": "We introduce a Reinforcement Learning (RL)-based method for re-synthesis of\nquantum circuits containing arbitrary Pauli rotations alongside Clifford\noperations. By collapsing each sub-block to a compact representation and then\nsynthesizing it step-by-step through a learned heuristic, we obtain circuits\nthat are both shorter and compliant with hardware connectivity constraints. We\nfind that the method is fast enough and good enough to work as an optimization\nprocedure: in direct comparisons on 6-qubit random Pauli Networks against\nstate-of-the-art heuristic methods, our RL approach yields over 2x reduction in\ntwo-qubit gate count, while executing in under 10 milliseconds per circuit. We\nfurther integrate the method into a collect-and-re-synthesize pipeline, applied\nas a Qiskit transpiler pass, where we observe average improvements of 20% in\ntwo-qubit gate count and depth, reaching up to 60% for many instances, across\nthe Benchpress benchmark. These results highlight the potential of RL-driven\nsynthesis to significantly improve circuit quality in realistic, large-scale\nquantum transpilation workloads.", "published": "2025-03-18 17:27:50", "link": "http://arxiv.org/abs/2503.14448v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "MagicComp: Training-free Dual-Phase Refinement for Compositional Video Generation", "abstract": "Text-to-video (T2V) generation has made significant strides with diffusion\nmodels. However, existing methods still struggle with accurately binding\nattributes, determining spatial relationships, and capturing complex action\ninteractions between multiple subjects. To address these limitations, we\npropose MagicComp, a training-free method that enhances compositional T2V\ngeneration through dual-phase refinement. Specifically, (1) During the\nConditioning Stage: We introduce the Semantic Anchor Disambiguation to\nreinforces subject-specific semantics and resolve inter-subject ambiguity by\nprogressively injecting the directional vectors of semantic anchors into\noriginal text embedding; (2) During the Denoising Stage: We propose Dynamic\nLayout Fusion Attention, which integrates grounding priors and model-adaptive\nspatial perception to flexibly bind subjects to their spatiotemporal regions\nthrough masked attention modulation. Furthermore, MagicComp is a model-agnostic\nand versatile approach, which can be seamlessly integrated into existing T2V\narchitectures. Extensive experiments on T2V-CompBench and VBench demonstrate\nthat MagicComp outperforms state-of-the-art methods, highlighting its potential\nfor applications such as complex prompt-based and trajectory-controllable video\ngeneration. Project page: https://hong-yu-zhang.github.io/MagicComp-Page/.", "published": "2025-03-18 17:02:14", "link": "http://arxiv.org/abs/2503.14428v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "VisEscape: A Benchmark for Evaluating Exploration-driven Decision-making in Virtual Escape Rooms", "abstract": "Escape rooms present a unique cognitive challenge that demands\nexploration-driven planning: players should actively search their environment,\ncontinuously update their knowledge based on new discoveries, and connect\ndisparate clues to determine which elements are relevant to their objectives.\nMotivated by this, we introduce VisEscape, a benchmark of 20 virtual escape\nrooms specifically designed to evaluate AI models under these challenging\nconditions, where success depends not only on solving isolated puzzles but also\non iteratively constructing and refining spatial-temporal knowledge of a\ndynamically changing environment. On VisEscape, we observe that even\nstate-of-the-art multimodal models generally fail to escape the rooms, showing\nconsiderable variation in their levels of progress and trajectories. To address\nthis issue, we propose VisEscaper, which effectively integrates Memory,\nFeedback, and ReAct modules, demonstrating significant improvements by\nperforming 3.7 times more effectively and 4.9 times more efficiently on average\ncompared to baseline agents.", "published": "2025-03-18 16:59:09", "link": "http://arxiv.org/abs/2503.14427v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Iffy-Or-Not: Extending the Web to Support the Critical Evaluation of Fallacious Texts", "abstract": "Social platforms have expanded opportunities for deliberation with the\ncomments being used to inform one's opinion. However, using such information to\nform opinions is challenged by unsubstantiated or false content. To enhance the\nquality of opinion formation and potentially confer resistance to\nmisinformation, we developed Iffy-Or-Not (ION), a browser extension that seeks\nto invoke critical thinking when reading texts. With three features guided by\nargumentation theory, ION highlights fallacious content, suggests diverse\nqueries to probe them with, and offers deeper questions to consider and chat\nwith others about. From a user study (N=18), we found that ION encourages users\nto be more attentive to the content, suggests queries that align with or are\npreferable to their own, and poses thought-provoking questions that expands\ntheir perspectives. However, some participants expressed aversion to ION due to\nmisalignments with their information goals and thinking predispositions.\nPotential backfiring effects with ION are discussed.", "published": "2025-03-18 16:50:20", "link": "http://arxiv.org/abs/2503.14412v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "International Agreements on AI Safety: Review and Recommendations for a Conditional AI Safety Treaty", "abstract": "The malicious use or malfunction of advanced general-purpose AI (GPAI) poses\nrisks that, according to leading experts, could lead to the 'marginalisation or\nextinction of humanity.' To address these risks, there are an increasing number\nof proposals for international agreements on AI safety. In this paper, we\nreview recent (2023-) proposals, identifying areas of consensus and\ndisagreement, and drawing on related literature to assess their feasibility. We\nfocus our discussion on risk thresholds, regulations, types of international\nagreement and five related processes: building scientific consensus,\nstandardisation, auditing, verification and incentivisation.\n  Based on this review, we propose a treaty establishing a compute threshold\nabove which development requires rigorous oversight. This treaty would mandate\ncomplementary audits of models, information security and governance practices,\noverseen by an international network of AI Safety Institutes (AISIs) with\nauthority to pause development if risks are unacceptable. Our approach combines\nimmediately implementable measures with a flexible structure that can adapt to\nongoing research.", "published": "2025-03-18 16:29:57", "link": "http://arxiv.org/abs/2503.18956v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease", "abstract": "The accurate diagnosis of Alzheimer's disease (AD) and prognosis of mild\ncognitive impairment (MCI) conversion are crucial for early intervention.\nHowever, existing multimodal methods face several challenges, from the\nheterogeneity of input data, to underexplored modality interactions, missing\ndata due to patient dropouts, and limited data caused by the time-consuming and\ncostly data collection process. In this paper, we propose a novel Prompted\nHypergraph Neural Network (PHGNN) framework that addresses these limitations by\nintegrating hypergraph based learning with prompt learning. Hypergraphs capture\nhigher-order relationships between different modalities, while our prompt\nlearning approach for hypergraphs, adapted from NLP, enables efficient training\nwith limited data. Our model is validated through extensive experiments on the\nADNI dataset, outperforming SOTA methods in both AD diagnosis and the\nprediction of MCI conversion.", "published": "2025-03-18 16:10:43", "link": "http://arxiv.org/abs/2503.14577v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels", "abstract": "Linear RNNs with gating recently demonstrated competitive performance\ncompared to Transformers in language modeling. Although their linear compute\nscaling in sequence length offers theoretical runtime advantages over\nTransformers, realizing these benefits in practice requires optimized custom\nkernels, as Transformers rely on the highly efficient Flash Attention kernels.\nLeveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear\nAttention (FLA) shows that linear RNN kernels are faster than Flash Attention,\nby parallelizing over chunks of the input sequence. However, since the chunk\nsize of FLA is limited, many intermediate states must be materialized in GPU\nmemory. This leads to low arithmetic intensity and causes high memory\nconsumption and IO cost, especially for long-context pre-training. In this\nwork, we present Tiled Flash Linear Attention (TFLA), a novel kernel algorithm\nfor linear RNNs, that enables arbitrary large chunk sizes by introducing an\nadditional level of sequence parallelization within each chunk. First, we apply\nTFLA to the xLSTM with matrix memory, the mLSTM. Second, we propose an mLSTM\nvariant with sigmoid input gate and reduced computation for even faster kernel\nruntimes at equal language modeling performance. In our speed benchmarks, we\nshow that our new mLSTM kernels based on TFLA outperform highly optimized Flash\nAttention, Linear Attention and Mamba kernels, setting a new state of the art\nfor efficient long-context sequence modeling primitives.", "published": "2025-03-18 16:09:47", "link": "http://arxiv.org/abs/2503.14376v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas", "abstract": "Social dilemmas pose a significant challenge in the field of multi-agent\nreinforcement learning (MARL). Melting Pot is an extensive framework designed\nto evaluate social dilemma environments, providing an evaluation protocol that\nmeasures generalization to new social partners across various test scenarios.\nHowever, running reinforcement learning algorithms in the official Melting Pot\nenvironments demands substantial computational resources. In this paper, we\nintroduce SocialJax, a suite of sequential social dilemma environments\nimplemented in JAX. JAX is a high-performance numerical computing library for\nPython that enables significant improvements in the operational efficiency of\nSocialJax on GPUs and TPUs. Our experiments demonstrate that the training\npipeline of SocialJax achieves a 50\\texttimes{} speedup in real-time\nperformance compared to Melting Pot's RLlib baselines. Additionally, we\nvalidate the effectiveness of baseline algorithms within the SocialJax\nenvironments. Finally, we use Schelling diagrams to verify the social dilemma\nproperties of these environments, ensuring they accurately capture the dynamics\nof social dilemmas.", "published": "2025-03-18 16:03:59", "link": "http://arxiv.org/abs/2503.14576v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Retrospective: A CORDIC Based Configurable Activation Function for NN Applications", "abstract": "A CORDIC-based configuration for the design of Activation Functions (AF) was\npreviously suggested to accelerate ASIC hardware design for\nresource-constrained systems by providing functional reconfigurability. Since\nits introduction, this new approach for neural network acceleration has gained\nwidespread popularity, influencing numerous designs for activation functions in\nboth academic and commercial AI processors. In this retrospective analysis, we\nexplore the foundational aspects of this initiative, summarize key developments\nover recent years, and introduce the DA-VINCI AF tailored for the evolving\nneeds of AI applications. This new generation of dynamically configurable and\nprecision-adjustable activation function cores promise greater adaptability for\na range of activation functions in AI workloads, including Swish, SoftMax,\nSeLU, and GeLU, utilizing the Shift-and-Add CORDIC technique. The previously\npresented design has been optimized for MAC, Sigmoid, and Tanh functionalities\nand incorporated into ReLU AFs, culminating in an accumulative NEURIC compute\nunit. These enhancements position NEURIC as a fundamental component in the\nresource-efficient vector engine for the realization of AI accelerators that\nfocus on DNNs, RNNs/LSTMs, and Transformers, achieving a quality of results\n(QoR) of 98.5%.", "published": "2025-03-18 15:38:37", "link": "http://arxiv.org/abs/2503.14354v1", "categories": ["cs.AR", "cs.AI", "cs.CV", "cs.ET", "eess.IV"], "primary_category": "cs.AR"}
{"title": "Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack", "abstract": "Batch prompting, which combines a batch of multiple queries sharing the same\ncontext in one inference, has emerged as a promising solution to reduce\ninference costs. However, our study reveals a significant security\nvulnerability in batch prompting: malicious users can inject attack\ninstructions into a batch, leading to unwanted interference across all queries,\nwhich can result in the inclusion of harmful content, such as phishing links,\nor the disruption of logical reasoning. In this paper, we construct\nBATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of\ntwo types and 8k batch instances, to study the batch prompting vulnerability\nsystematically. Our evaluation of both closed-source and open-weight LLMs\ndemonstrates that all LLMs are susceptible to batch-prompting attacks. We then\nexplore multiple defending approaches. While the prompting-based defense shows\nlimited effectiveness for smaller LLMs, the probing-based approach achieves\nabout 95% accuracy in detecting attacks. Additionally, we perform a mechanistic\nanalysis to understand the attack and identify attention heads that are\nresponsible for it.", "published": "2025-03-18 15:16:10", "link": "http://arxiv.org/abs/2503.15551v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Revealing higher-order neural representations with generative artificial intelligence", "abstract": "Studies often aim to reveal how neural representations encode aspects of an\nobserver's environment, such as its contents or structure. These are\n``first-order\" representations (FORs), because they're ``about\" the external\nworld. A less-common target is ``higher-order\" representations (HORs), which\nare ``about\" FORs -- their contents, stability, or uncertainty. HORs of\nuncertainty appear critically involved in adaptive behaviors including learning\nunder uncertainty, influencing learning rates and internal model updating based\non environmental feedback. However, HORs about uncertainty are unlikely to be\ndirect ``read-outs\" of FOR characteristics, instead reflecting estimation\nprocesses which may be lossy, bias-prone, or distortive and which may also\nincorporate estimates of distributions of uncertainty the observer is likely to\nexperience. While some research has targeted neural representations of\n``instantaneously\" estimated uncertainty, how the brain represents\n\\textit{distributions} of expected uncertainty remains largely unexplored.\nHere, we propose a novel reinforcement learning (RL) based generative\nartificial intelligence (genAI) approach to explore neural representations of\nuncertainty distributions. We use existing functional magnetic resonance\nimaging data, where humans learned to `de-noise' their brain states to achieve\ntarget neural patterns, to train denoising diffusion genAI models with RL\nalgorithms to learn noise distributions similar to how humans might learn to do\nthe same. We then explore these models' learned noise-distribution HORs\ncompared to control models trained with traditional backpropagation. Results\nreveal model-dependent differences in noise distribution representations --\nwith the RL-based model offering much higher explanatory power for human\nbehavior -- offering an exciting path towards using genAI to explore neural\nnoise-distribution HORs.", "published": "2025-03-18 15:08:19", "link": "http://arxiv.org/abs/2503.14333v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "COPA: Comparing the Incomparable to Explore the Pareto Front", "abstract": "In machine learning (ML), it is common to account for multiple objectives\nwhen, e.g., selecting a model to deploy. However, it is often unclear how one\nshould compare, aggregate and, ultimately, trade-off these objectives, as they\nmight be measured in different units or scales. For example, when deploying\nlarge language models (LLMs), we might not only care about their performance,\nbut also their CO2 consumption. In this work, we investigate how objectives can\nbe sensibly compared and aggregated to navigate their Pareto front. To do so,\nwe propose to make incomparable objectives comparable via their CDFs,\napproximated by their relative rankings. This allows us to aggregate them while\nmatching user-specific preferences, allowing practitioners to meaningfully\nnavigate and search for models in the Pareto front. We demonstrate the\npotential impact of our methodology in diverse areas such as LLM selection,\ndomain generalization, and AutoML benchmarking, where classical ways to\naggregate and normalize objectives fail.", "published": "2025-03-18 14:51:42", "link": "http://arxiv.org/abs/2503.14321v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PC-Talk: Precise Facial Animation Control for Audio-Driven Talking Face Generation", "abstract": "Recent advancements in audio-driven talking face generation have made great\nprogress in lip synchronization. However, current methods often lack sufficient\ncontrol over facial animation such as speaking style and emotional expression,\nresulting in uniform outputs. In this paper, we focus on improving two key\nfactors: lip-audio alignment and emotion control, to enhance the diversity and\nuser-friendliness of talking videos. Lip-audio alignment control focuses on\nelements like speaking style and the scale of lip movements, whereas emotion\ncontrol is centered on generating realistic emotional expressions, allowing for\nmodifications in multiple attributes such as intensity. To achieve precise\ncontrol of facial animation, we propose a novel framework, PC-Talk, which\nenables lip-audio alignment and emotion control through implicit keypoint\ndeformations. First, our lip-audio alignment control module facilitates precise\nediting of speaking styles at the word level and adjusts lip movement scales to\nsimulate varying vocal loudness levels, maintaining lip synchronization with\nthe audio. Second, our emotion control module generates vivid emotional facial\nfeatures with pure emotional deformation. This module also enables the fine\nmodification of intensity and the combination of multiple emotions across\ndifferent facial regions. Our method demonstrates outstanding control\ncapabilities and achieves state-of-the-art performance on both HDTF and MEAD\ndatasets in extensive experiments.", "published": "2025-03-18 14:35:48", "link": "http://arxiv.org/abs/2503.14295v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ensemble Knowledge Distillation for Machine Learning Interatomic Potentials", "abstract": "Machine learning interatomic potentials (MLIPs) are a promising tool to\naccelerate atomistic simulations and molecular property prediction. The quality\nof MLIPs strongly depends on the quantity of available training data as well as\nthe quantum chemistry (QC) level of theory used to generate that data. Datasets\ngenerated with high-fidelity QC methods, such as coupled cluster, are typically\nrestricted to small molecules and may be missing energy gradients. With this\nlimited quantity of data, it is often difficult to train good MLIP models. We\npresent an ensemble knowledge distillation (EKD) method to improve MLIP\naccuracy when trained to energy-only datasets. In our EKD approach, first,\nmultiple teacher models are trained to QC energies and then used to generate\natomic forces for all configurations in the dataset. Next, a student MLIP is\ntrained to both QC energies and to ensemble-averaged forces generated by the\nteacher models. We apply this workflow on the ANI-1ccx dataset which consists\nof organic molecules with configuration energies computed at the coupled\ncluster level of theory. The resulting student MLIPs achieve new\nstate-of-the-art accuracy on the out-of-sample COMP6 benchmark and improved\nstability for molecular dynamics simulations. The EKD approach for MLIP is\nbroadly applicable for chemical, biomolecular and materials science\nsimulations.", "published": "2025-03-18 14:32:51", "link": "http://arxiv.org/abs/2503.14293v2", "categories": ["physics.chem-ph", "cs.AI"], "primary_category": "physics.chem-ph"}
{"title": "Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation", "abstract": "The capacity of a foundation model allows for adaptation to new downstream\ntasks. Weight imprinting is a universal and efficient method to fulfill this\npurpose. It has been reinvented several times, but it has not been\nsystematically studied. In this paper, we propose a framework for imprinting,\nidentifying three main components: generation, normalization, and aggregation.\nThis allows us to conduct an in-depth analysis of imprinting and a comparison\nof the existing work. We reveal the benefits of representing novel data with\nmultiple proxies in the generation step and show the importance of proper\nnormalization. We determine those proxies through clustering and propose a\nnovel variant of imprinting that outperforms previous work. We motivate this by\nthe neural collapse phenomenon -- an important connection that we can draw for\nthe first time. Our results show an increase of up to 4% in challenging\nscenarios with complex data distributions for new classes.", "published": "2025-03-18 14:27:45", "link": "http://arxiv.org/abs/2503.14572v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Manual Labelling Artificially Inflates Deep Learning-Based Segmentation Performance on RGB Images of Closed Canopy: Validation Using TLS", "abstract": "Monitoring forest dynamics at an individual tree scale is essential for\naccurately assessing ecosystem responses to climate change, yet traditional\nmethods relying on field-based forest inventories are labor-intensive and\nlimited in spatial coverage. Advances in remote sensing using drone-acquired\nRGB imagery combined with deep learning models have promised precise individual\ntree crown (ITC) segmentation; however, existing methods are frequently\nvalidated against human-annotated images, lacking rigorous independent ground\ntruth. In this study, we generate high-fidelity validation labels from\nco-located Terrestrial Laser Scanning (TLS) data for drone imagery of mixed\nunmanaged boreal and Mediterranean forests. We evaluate the performance of two\nwidely used deep learning ITC segmentation models - DeepForest (RetinaNet) and\nDetectree2 (Mask R-CNN) - on these data, and compare to performance on further\nMediterranean forest data labelled manually. When validated against TLS-derived\nground truth from Mediterranean forests, model performance decreased\nsignificantly compared to assessment based on hand-labelled from an\necologically similar site (AP50: 0.094 vs. 0.670). Restricting evaluation to\nonly canopy trees shrank this gap considerably (Canopy AP50: 0.365), although\nperformance was still far lower than on similar hand-labelled data. Models also\nperformed poorly on boreal forest data (AP50: 0.142), although again increasing\nwhen evaluated on canopy trees only (Canopy AP50: 0.308). Both models showed\nvery poor localisation accuracy at stricter IoU thresholds, even when\nrestricted to canopy trees (Max AP75: 0.051). Similar results have been\nobserved in studies using aerial LiDAR data, suggesting fundamental limitations\nin aerial-based segmentation approaches in closed canopy forests.", "published": "2025-03-18 14:09:00", "link": "http://arxiv.org/abs/2503.14273v2", "categories": ["cs.CV", "cs.AI", "I.4; I.4.6; I.4.8; I.4.9; I.5; I.5.4"], "primary_category": "cs.CV"}
{"title": "Validating Emergency Department Admission Predictions Based on Local Data Through MIMIC-IV", "abstract": "The effective management of Emergency Department (ED) overcrowding is\nessential for improving patient outcomes and optimizing healthcare resource\nallocation. This study validates hospital admission prediction models initially\ndeveloped using a small local dataset from a Greek hospital by leveraging the\ncomprehensive MIMIC-IV dataset. After preprocessing the MIMIC-IV data, five\nalgorithms were evaluated: Linear Discriminant Analysis (LDA), K-Nearest\nNeighbors (KNN), Random Forest (RF), Recursive Partitioning and Regression\nTrees (RPART), and Support Vector Machines (SVM Radial). Among these, RF\ndemonstrated superior performance, achieving an Area Under the Receiver\nOperating Characteristic Curve (AUC-ROC) of 0.9999, sensitivity of 0.9997, and\nspecificity of 0.9999 when applied to the MIMIC-IV data. These findings\nhighlight the robustness of RF in handling complex datasets for admission\nprediction, establish MIMIC-IV as a valuable benchmark for validating models\nbased on smaller local datasets, and provide actionable insights for improving\nED management strategies.", "published": "2025-03-18 13:54:28", "link": "http://arxiv.org/abs/2503.22706v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CTSAC: Curriculum-Based Transformer Soft Actor-Critic for Goal-Oriented Robot Exploration", "abstract": "With the increasing demand for efficient and flexible robotic exploration\nsolutions, Reinforcement Learning (RL) is becoming a promising approach in the\nfield of autonomous robotic exploration. However, current RL-based exploration\nalgorithms often face limited environmental reasoning capabilities, slow\nconvergence rates, and substantial challenges in Sim-To-Real (S2R) transfer. To\naddress these issues, we propose a Curriculum Learning-based Transformer\nReinforcement Learning Algorithm (CTSAC) aimed at improving both exploration\nefficiency and transfer performance. To enhance the robot's reasoning ability,\na Transformer is integrated into the perception network of the Soft\nActor-Critic (SAC) framework, leveraging historical information to improve the\nfarsightedness of the strategy. A periodic review-based curriculum learning is\nproposed, which enhances training efficiency while mitigating catastrophic\nforgetting during curriculum transitions. Training is conducted on the\nROS-Gazebo continuous robotic simulation platform, with LiDAR clustering\noptimization to further reduce the S2R gap. Experimental results demonstrate\nthe CTSAC algorithm outperforms the state-of-the-art non-learning and\nlearning-based algorithms in terms of success rate and success rate-weighted\nexploration time. Moreover, real-world experiments validate the strong S2R\ntransfer capabilities of CTSAC.", "published": "2025-03-18 13:44:29", "link": "http://arxiv.org/abs/2503.14254v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Parallel Hybrid Action Space Reinforcement Learning Model for Real-world Adaptive Traffic Signal Control", "abstract": "Adaptive traffic signal control (ATSC) can effectively reduce vehicle travel\ntimes by dynamically adjusting signal timings but poses a critical challenge in\nreal-world scenarios due to the complexity of real-time decision-making in\ndynamic and uncertain traffic conditions. The burgeoning field of intelligent\ntransportation systems, bolstered by artificial intelligence techniques and\nextensive data availability, offers new prospects for the implementation of\nATSC. In this study, we introduce a parallel hybrid action space reinforcement\nlearning model (PH-DDPG) that optimizes traffic signal phase and duration of\ntraffic signals simultaneously, eliminating the need for sequential\ndecision-making seen in traditional two-stage models. Our model features a\ntask-specific parallel hybrid action space tailored for adaptive traffic\ncontrol, which directly outputs discrete phase selections and their associated\ncontinuous duration parameters concurrently, thereby inherently addressing\ndynamic traffic adaptation through unified parametric optimization. %Our model\nfeatures a unique parallel hybrid action space that allows for the simultaneous\noutput of each action and its optimal parameters, streamlining the\ndecision-making process. Furthermore, to ascertain the robustness and\neffectiveness of this approach, we executed ablation studies focusing on the\nutilization of a random action parameter mask within the critic network, which\ndecouples the parameter space for individual actions, facilitating the use of\npreferable parameters for each action. The results from these studies confirm\nthe efficacy of this method, distinctly enhancing real-world applicability", "published": "2025-03-18 13:38:53", "link": "http://arxiv.org/abs/2503.14250v1", "categories": ["cs.AI", "I.2.6; I.2.8"], "primary_category": "cs.AI"}
{"title": "GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial Fusion SLAM for Dynamic Legged Robotics", "abstract": "This paper presents GeoFlow-SLAM, a robust and effective Tightly-Coupled\nRGBD-inertial SLAM for legged robots operating in highly dynamic\nenvironments.By integrating geometric consistency, legged odometry constraints,\nand dual-stream optical flow (GeoFlow), our method addresses three critical\nchallenges:feature matching and pose initialization failures during fast\nlocomotion and visual feature scarcity in texture-less scenes.Specifically, in\nrapid motion scenarios, feature matching is notably enhanced by leveraging\ndual-stream optical flow, which combines prior map points and poses.\nAdditionally, we propose a robust pose initialization method for fast\nlocomotion and IMU error in legged robots, integrating IMU/Legged odometry,\ninter-frame Perspective-n-Point (PnP), and Generalized Iterative Closest Point\n(GICP). Furthermore, a novel optimization framework that tightly couples\ndepth-to-map and GICP geometric constraints is first introduced to improve the\nrobustness and accuracy in long-duration, visually texture-less environments.\nThe proposed algorithms achieve state-of-the-art (SOTA) on collected legged\nrobots and open-source datasets. To further promote research and development,\nthe open-source datasets and code will be made publicly available at\nhttps://github.com/NSN-Hello/GeoFlow-SLAM", "published": "2025-03-18 13:35:49", "link": "http://arxiv.org/abs/2503.14247v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Trading-off Accuracy and Communication Cost in Federated Learning", "abstract": "Leveraging the training-by-pruning paradigm introduced by Zhou et al. and\nIsik et al. introduced a federated learning protocol that achieves a 34-fold\nreduction in communication cost. We achieve a compression improvements of\norders of orders of magnitude over the state-of-the-art. The central idea of\nour framework is to encode the network weights $\\vec w$ by a the vector of\ntrainable parameters $\\vec p$, such that $\\vec w = Q\\cdot \\vec p$ where $Q$ is\na carefully-generate sparse random matrix (that remains fixed throughout\ntraining). In such framework, the previous work of Zhou et al. [NeurIPS'19] is\nretrieved when $Q$ is diagonal and $\\vec p$ has the same dimension of $\\vec w$.\nWe instead show that $\\vec p$ can effectively be chosen much smaller than $\\vec\nw$, while retaining the same accuracy at the price of a decrease of the\nsparsity of $Q$. Since server and clients only need to share $\\vec p$, such a\ntrade-off leads to a substantial improvement in communication cost. Moreover,\nwe provide theoretical insight into our framework and establish a novel link\nbetween training-by-sampling and random convex geometry.", "published": "2025-03-18 13:35:24", "link": "http://arxiv.org/abs/2503.14246v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modelling Emotions in Face-to-Face Setting: The Interplay of Eye-Tracking, Personality, and Temporal Dynamics", "abstract": "Accurate emotion recognition is pivotal for nuanced and engaging\nhuman-computer interactions, yet remains difficult to achieve, especially in\ndynamic, conversation-like settings. In this study, we showcase how integrating\neye-tracking data, temporal dynamics, and personality traits can substantially\nenhance the detection of both perceived and felt emotions. Seventy-three\nparticipants viewed short, speech-containing videos from the CREMA-D dataset,\nwhile being recorded for eye-tracking signals (pupil size, fixation patterns),\nBig Five personality assessments, and self-reported emotional states. Our\nneural network models combined these diverse inputs including stimulus emotion\nlabels for contextual cues and yielded marked performance gains compared to the\nstate-of-the-art. Specifically, perceived valence predictions reached a macro\nF1-score of 0.76, and models incorporating personality traits and stimulus\ninformation demonstrated significant improvements in felt emotion accuracy.\nThese results highlight the benefit of unifying physiological, individual and\ncontextual factors to address the subjectivity and complexity of emotional\nexpression. Beyond validating the role of user-specific data in capturing\nsubtle internal states, our findings inform the design of future affective\ncomputing and human-agent systems, paving the way for more adaptive and\ncross-individual emotional intelligence in real-world interactions.", "published": "2025-03-18 13:15:32", "link": "http://arxiv.org/abs/2503.16532v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "KG-IRAG: A Knowledge Graph-Based Iterative Retrieval-Augmented Generation Framework for Temporal Reasoning", "abstract": "Graph Retrieval-Augmented Generation (GraphRAG) has proven highly effective\nin enhancing the performance of Large Language Models (LLMs) on tasks that\nrequire external knowledge. By leveraging Knowledge Graphs (KGs), GraphRAG\nimproves information retrieval for complex reasoning tasks, providing more\nprecise and comprehensive retrieval and generating more accurate responses to\nQAs. However, most RAG methods fall short in addressing multi-step reasoning,\nparticularly when both information extraction and inference are necessary. To\naddress this limitation, this paper presents Knowledge Graph-Based Iterative\nRetrieval-Augmented Generation (KG-IRAG), a novel framework that integrates KGs\nwith iterative reasoning to improve LLMs' ability to handle queries involving\ntemporal and logical dependencies. Through iterative retrieval steps, KG-IRAG\nincrementally gathers relevant data from external KGs, enabling step-by-step\nreasoning. The proposed approach is particularly suited for scenarios where\nreasoning is required alongside dynamic temporal data extraction, such as\ndetermining optimal travel times based on weather conditions or traffic\npatterns. Experimental results show that KG-IRAG improves accuracy in complex\nreasoning tasks by effectively integrating external knowledge with iterative,\nlogic-based retrieval. Additionally, three new datasets: weatherQA-Irish,\nweatherQA-Sydney, and trafficQA-TFNSW, are formed to evaluate KG-IRAG's\nperformance, demonstrating its potential beyond traditional RAG applications.", "published": "2025-03-18 13:11:43", "link": "http://arxiv.org/abs/2503.14234v2", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "HA-VLN: A Benchmark for Human-Aware Navigation in Discrete-Continuous Environments with Dynamic Multi-Human Interactions, Real-World Validation, and an Open Leaderboard", "abstract": "Vision-and-Language Navigation (VLN) systems often focus on either discrete\n(panoramic) or continuous (free-motion) paradigms alone, overlooking the\ncomplexities of human-populated, dynamic environments. We introduce a unified\nHuman-Aware VLN (HA-VLN) benchmark that merges these paradigms under explicit\nsocial-awareness constraints. Our contributions include: 1. A standardized task\ndefinition that balances discrete-continuous navigation with personal-space\nrequirements; 2. An enhanced human motion dataset (HAPS 2.0) and upgraded\nsimulators capturing realistic multi-human interactions, outdoor contexts, and\nrefined motion-language alignment; 3. Extensive benchmarking on 16,844\nhuman-centric instructions, revealing how multi-human dynamics and partial\nobservability pose substantial challenges for leading VLN agents; 4. Real-world\nrobot tests validating sim-to-real transfer in crowded indoor spaces; and 5. A\npublic leaderboard supporting transparent comparisons across discrete and\ncontinuous tasks. Empirical results show improved navigation success and fewer\ncollisions when social context is integrated, underscoring the need for\nhuman-centric design. By releasing all datasets, simulators, agent code, and\nevaluation tools, we aim to advance safer, more capable, and socially\nresponsible VLN research.", "published": "2025-03-18 13:05:55", "link": "http://arxiv.org/abs/2503.14229v1", "categories": ["cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Panoramic Distortion-Aware Tokenization for Person Detection and Localization Using Transformers in Overhead Fisheye Images", "abstract": "Person detection methods are used widely in applications including visual\nsurveillance, pedestrian detection, and robotics. However, accurate detection\nof persons from overhead fisheye images remains an open challenge because of\nfactors including person rotation and small-sized persons. To address the\nperson rotation problem, we convert the fisheye images into panoramic images.\nFor smaller people, we focused on the geometry of the panoramas. Conventional\ndetection methods tend to focus on larger people because these larger people\nyield large significant areas for feature maps. In equirectangular panoramic\nimages, we find that a person's height decreases linearly near the top of the\nimages. Using this finding, we leverage the significance values and aggregate\ntokens that are sorted based on these values to balance the significant areas.\nIn this leveraging process, we introduce panoramic distortion-aware\ntokenization. This tokenization procedure divides a panoramic image using\nself-similarity figures that enable determination of optimal divisions without\ngaps, and we leverage the maximum significant values in each tile of token\ngroups to preserve the significant areas of smaller people. To achieve higher\ndetection accuracy, we propose a person detection and localization method that\ncombines panoramic-image remapping and the tokenization procedure. Extensive\nexperiments demonstrated that our method outperforms conventional methods when\napplied to large-scale datasets.", "published": "2025-03-18 13:05:41", "link": "http://arxiv.org/abs/2503.14228v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Stochastic Trajectory Prediction under Unstructured Constraints", "abstract": "Trajectory prediction facilitates effective planning and decision-making,\nwhile constrained trajectory prediction integrates regulation into prediction.\nRecent advances in constrained trajectory prediction focus on structured\nconstraints by constructing optimization objectives. However, handling\nunstructured constraints is challenging due to the lack of differentiable\nformal definitions. To address this, we propose a novel method for constrained\ntrajectory prediction using a conditional generative paradigm, named\nControllable Trajectory Diffusion (CTD). The key idea is that any trajectory\ncorresponds to a degree of conformity to a constraint. By quantifying this\ndegree and treating it as a condition, a model can implicitly learn to predict\ntrajectories under unstructured constraints. CTD employs a pre-trained scoring\nmodel to predict the degree of conformity (i.e., a score), and uses this score\nas a condition for a conditional diffusion model to generate trajectories.\nExperimental results demonstrate that CTD achieves high accuracy on the ETH/UCY\nand SDD benchmarks. Qualitative analysis confirms that CTD ensures adherence to\nunstructured constraints and can predict trajectories that satisfy\ncombinatorial constraints.", "published": "2025-03-18 12:27:59", "link": "http://arxiv.org/abs/2503.14203v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Is there a future for AI without representation?", "abstract": "This paper investigates the prospects of AI without representation in\ngeneral, and the proposals of Rodney Brooks in particular. What turns out to be\ncharacteristic of Brooks' proposal is the rejection of central control in\nintelligent agents; his systems has as much or as little representation as\ntraditional AI. The traditional view that representation is necessary for\nintelligence presupposes that intelligence requires central control. However,\nmuch of recent cognitive science suggests that we should dispose of the image\nof intelligent agents as central representation processors. If this paradigm\nshift is achieved, Brooks' proposal for non-centralized cognition without\nrepresentation appears promising for full-blown intelligent agents - though not\nfor conscious agents and thus not for human-like AI.", "published": "2025-03-18 12:13:31", "link": "http://arxiv.org/abs/2503.18955v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Driving behavior recognition via self-discovery learning", "abstract": "Autonomous driving systems require a deep understanding of human driving\nbehaviors to achieve higher intelligence and safety.Despite advancements in\ndeep learning, challenges such as long-tail distribution due to scarce samples\nand confusion from similar behaviors hinder effective driving behavior\ndetection.Existing methods often fail to address sample confusion adequately,\nas datasets frequently contain ambiguous samples that obscure unique semantic\ninformation.", "published": "2025-03-18 12:13:08", "link": "http://arxiv.org/abs/2503.14194v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Strategic White Paper on AI Infrastructure for Particle, Nuclear, and Astroparticle Physics: Insights from JENA and EuCAIF", "abstract": "Artificial intelligence (AI) is transforming scientific research, with deep\nlearning methods playing a central role in data analysis, simulations, and\nsignal detection across particle, nuclear, and astroparticle physics. Within\nthe JENA communities-ECFA, NuPECC, and APPEC-and as part of the EuCAIF\ninitiative, AI integration is advancing steadily. However, broader adoption\nremains constrained by challenges such as limited computational resources, a\nlack of expertise, and difficulties in transitioning from research and\ndevelopment (R&D) to production. This white paper provides a strategic roadmap,\ninformed by a community survey, to address these barriers. It outlines critical\ninfrastructure requirements, prioritizes training initiatives, and proposes\nfunding strategies to scale AI capabilities across fundamental physics over the\nnext five years.", "published": "2025-03-18 12:11:11", "link": "http://arxiv.org/abs/2503.14192v1", "categories": ["astro-ph.IM", "astro-ph.HE", "cs.AI", "cs.LG", "hep-ex", "hep-ph", "nucl-th"], "primary_category": "astro-ph.IM"}
{"title": "Inferring Event Descriptions from Time Series with Language Models", "abstract": "Time series data measure how environments change over time and drive\ndecision-making in critical domains like finance and healthcare. When analyzing\ntime series, we often seek to understand the underlying events occurring in the\nmeasured environment. For example, one might ask: What caused a sharp drop in\nthe stock price? Events are often described with natural language, so we\nconduct the first study of whether Large Language Models (LLMs) can infer\nnatural language events from time series. We curate a new benchmark featuring\nwin probabilities collected from 4,200 basketball and American football games,\nfeaturing 1.7M timesteps with real value data and corresponding natural\nlanguage events. Building on the recent wave of using LLMs on time series, we\nevaluate 16 LLMs and find that they demonstrate promising abilities to infer\nevents from time series data. The open-weights DeepSeek-R1 32B model\noutperforms proprietary models like GPT-4o. Despite this impressive initial\nperformance, we also find clear avenues to improve recent models, as we\nidentify failures when altering the provided context, event sequence lengths,\nand evaluation strategy. (All resources needed to reproduce our work are\navailable: https://github.com/BennyTMT/GAMETime)", "published": "2025-03-18 12:07:33", "link": "http://arxiv.org/abs/2503.14190v1", "categories": ["cs.AI", "62M10, 68T07,", "I.2.6; I.2.7"], "primary_category": "cs.AI"}
{"title": "Variable Time-Step MPC for Agile Multi-Rotor UAV Interception of Dynamic Targets", "abstract": "Agile trajectory planning can improve the efficiency of multi-rotor Uncrewed\nAerial Vehicles (UAVs) in scenarios with combined task-oriented and kinematic\ntrajectory planning, such as monitoring spatio-temporal phenomena or\nintercepting dynamic targets. Agile planning using existing non-linear model\npredictive control methods is limited by the number of planning steps as it\nbecomes increasingly computationally demanding. That reduces the prediction\nhorizon length, leading to a decrease in solution quality. Besides, the fixed\ntime-step length limits the utilization of the available UAV dynamics in the\ntarget neighborhood. In this paper, we propose to address these limitations by\nintroducing variable time steps and coupling them with the prediction horizon\nlength. A simplified point-mass motion primitive is used to leverage the\ndifferential flatness of quadrotor dynamics and the generation of feasible\ntrajectories in the flat output space. Based on the presented evaluation\nresults and experimentally validated deployment, the proposed method increases\nthe solution quality by enabling planning for long flight segments but allowing\ntightly sampled maneuvering.", "published": "2025-03-18 11:59:24", "link": "http://arxiv.org/abs/2503.14184v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Can LLMs Enable Verification in Mainstream Programming?", "abstract": "Although formal methods are capable of producing reliable software, they have\nseen minimal adoption in everyday programming. Automatic code generation using\nlarge language models is becoming increasingly widespread, but it rarely\nconsiders producing strong correctness guarantees. In this study, we explore\nthe ability of LLMs to produce verified code in three verification languages\n(Dafny, Nagini, and Verus). To do so, we use manually curated datasets derived\nfrom the state-ofthe-art Python benchmark, HumanEval. We also assess what types\nof information are sufficient to achieve good-quality results.", "published": "2025-03-18 11:58:00", "link": "http://arxiv.org/abs/2503.14183v1", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "EIAD: Explainable Industrial Anomaly Detection Via Multi-Modal Large Language Models", "abstract": "Industrial Anomaly Detection (IAD) is critical to ensure product quality\nduring manufacturing. Although existing zero-shot defect segmentation and\ndetection methods have shown effectiveness, they cannot provide detailed\ndescriptions of the defects. Furthermore, the application of large multi-modal\nmodels in IAD remains in its infancy, facing challenges in balancing\nquestion-answering (QA) performance and mask-based grounding capabilities,\noften owing to overfitting during the fine-tuning process. To address these\nchallenges, we propose a novel approach that introduces a dedicated multi-modal\ndefect localization module to decouple the dialog functionality from the core\nfeature extraction. This decoupling is achieved through independent\noptimization objectives and tailored learning strategies. Additionally, we\ncontribute to the first multi-modal industrial anomaly detection training\ndataset, named Defect Detection Question Answering (DDQA), encompassing a wide\nrange of defect types and industrial scenarios. Unlike conventional datasets\nthat rely on GPT-generated data, DDQA ensures authenticity and reliability and\noffers a robust foundation for model training. Experimental results demonstrate\nthat our proposed method, Explainable Industrial Anomaly Detection Assistant\n(EIAD), achieves outstanding performance in defect detection and localization\ntasks. It not only significantly enhances accuracy but also improves\ninterpretability. These advancements highlight the potential of EIAD for\npractical applications in industrial settings.", "published": "2025-03-18 11:33:29", "link": "http://arxiv.org/abs/2503.14162v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance", "abstract": "The ensemble average of physical properties of molecules is closely related\nto the distribution of molecular conformations, and sampling such distributions\nis a fundamental challenge in physics and chemistry. Traditional methods like\nmolecular dynamics (MD) simulations and Markov chain Monte Carlo (MCMC)\nsampling are commonly used but can be time-consuming and costly. Recently,\ndiffusion models have emerged as efficient alternatives by learning the\ndistribution of training data. Obtaining an unbiased target distribution is\nstill an expensive task, primarily because it requires satisfying ergodicity.\nTo tackle these challenges, we propose Potential Score Matching (PSM), an\napproach that utilizes the potential energy gradient to guide generative\nmodels. PSM does not require exact energy functions and can debias sample\ndistributions even when trained on limited and biased data. Our method\noutperforms existing state-of-the-art (SOTA) models on the Lennard-Jones (LJ)\npotential, a commonly used toy model. Furthermore, we extend the evaluation of\nPSM to high-dimensional problems using the MD17 and MD22 datasets. The results\ndemonstrate that molecular distributions generated by PSM more closely\napproximate the Boltzmann distribution compared to traditional diffusion\nmodels.", "published": "2025-03-18 11:27:28", "link": "http://arxiv.org/abs/2503.14569v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Teaching Artificial Intelligence to Perform Rapid, Resolution-Invariant Grain Growth Modeling via Fourier Neural Operator", "abstract": "Microstructural evolution, particularly grain growth, plays a critical role\nin shaping the physical, optical, and electronic properties of materials.\nTraditional phase-field modeling accurately simulates these phenomena but is\ncomputationally intensive, especially for large systems and fine spatial\nresolutions. While machine learning approaches have been employed to accelerate\nsimulations, they often struggle with resolution dependence and generalization\nacross different grain scales. This study introduces a novel approach utilizing\nFourier Neural Operator (FNO) to achieve resolution-invariant modeling of\nmicrostructure evolution in multi-grain systems. FNO operates in the Fourier\nspace and can inherently handle varying resolutions by learning mappings\nbetween function spaces. By integrating FNO with the phase field method, we\ndeveloped a surrogate model that significantly reduces computational costs\nwhile maintaining high accuracy across different spatial scales. We generated a\ncomprehensive dataset from phase-field simulations using the Fan Chen model,\ncapturing grain evolution over time. Data preparation involved creating\ninput-output pairs with a time shift, allowing the model to predict future\nmicrostructures based on current and past states. The FNO-based neural network\nwas trained using sequences of microstructures and demonstrated remarkable\naccuracy in predicting long-term evolution, even for unseen configurations and\nhigher-resolution grids not encountered during training.", "published": "2025-03-18 11:19:08", "link": "http://arxiv.org/abs/2503.14568v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Concat-ID: Towards Universal Identity-Preserving Video Synthesis", "abstract": "We present Concat-ID, a unified framework for identity-preserving video\ngeneration. Concat-ID employs Variational Autoencoders to extract image\nfeatures, which are concatenated with video latents along the sequence\ndimension, leveraging solely 3D self-attention mechanisms without the need for\nadditional modules. A novel cross-video pairing strategy and a multi-stage\ntraining regimen are introduced to balance identity consistency and facial\neditability while enhancing video naturalness. Extensive experiments\ndemonstrate Concat-ID's superiority over existing methods in both single and\nmulti-identity generation, as well as its seamless scalability to multi-subject\nscenarios, including virtual try-on and background-controllable generation.\nConcat-ID establishes a new benchmark for identity-preserving video synthesis,\nproviding a versatile and scalable solution for a wide range of applications.", "published": "2025-03-18 11:17:32", "link": "http://arxiv.org/abs/2503.14151v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Exploring Disparity-Accuracy Trade-offs in Face Recognition Systems: The Role of Datasets, Architectures, and Loss Functions", "abstract": "Automated Face Recognition Systems (FRSs), developed using deep learning\nmodels, are deployed worldwide for identity verification and facial attribute\nanalysis. The performance of these models is determined by a complex\ninterdependence among the model architecture, optimization/loss function and\ndatasets. Although FRSs have surpassed human-level accuracy, they continue to\nbe disparate against certain demographics. Due to the ubiquity of applications,\nit is extremely important to understand the impact of the three components --\nmodel architecture, loss function and face image dataset on the\naccuracy-disparity trade-off to design better, unbiased platforms. In this\nwork, we perform an in-depth analysis of three FRSs for the task of gender\nprediction, with various architectural modifications resulting in ten\ndeep-learning models coupled with four loss functions and benchmark them on\nseven face datasets across 266 evaluation configurations. Our results show that\nall three components have an individual as well as a combined impact on both\naccuracy and disparity. We identify that datasets have an inherent property\nthat causes them to perform similarly across models, independent of the choice\nof loss functions. Moreover, the choice of dataset determines the model's\nperceived bias -- the same model reports bias in opposite directions for three\ngender-balanced datasets of ``in-the-wild'' face images of popular individuals.\nStudying the facial embeddings shows that the models are unable to generalize a\nuniform definition of what constitutes a ``female face'' as opposed to a ``male\nface'', due to dataset diversity. We provide recommendations to model\ndevelopers on using our study as a blueprint for model development and\nsubsequent deployment.", "published": "2025-03-18 11:04:57", "link": "http://arxiv.org/abs/2503.14138v1", "categories": ["cs.CV", "cs.AI", "cs.CY"], "primary_category": "cs.CV"}
{"title": "Inference-Time Intervention in Large Language Models for Reliable Requirement Verification", "abstract": "Steering the behavior of Large Language Models (LLMs) remains a challenge,\nparticularly in engineering applications where precision and reliability are\ncritical. While fine-tuning and prompting methods can modify model behavior,\nthey lack the dynamic and exact control necessary for engineering applications.\nInference-time intervention techniques provide a promising alternative,\nallowing targeted adjustments to LLM outputs. In this work, we demonstrate how\ninterventions enable fine-grained control for automating the usually\ntime-intensive requirement verification process in Model-Based Systems\nEngineering (MBSE). Using two early-stage Capella SysML models of space\nmissions with associated requirements, we apply the intervened LLMs to reason\nover a graph representation of the model to determine whether a requirement is\nfulfilled. Our method achieves robust and reliable outputs, significantly\nimproving over both a baseline model and a fine-tuning approach. By identifying\nand modifying as few as one to three specialised attention heads, we can\nsignificantly change the model's behavior. When combined with self-consistency,\nthis allows us to achieve perfect precision on our holdout test set.", "published": "2025-03-18 10:49:36", "link": "http://arxiv.org/abs/2503.14130v1", "categories": ["cs.AI", "cs.SE", "H.4.2; I.2.1; I.2.7"], "primary_category": "cs.AI"}
{"title": "SpecReX: Explainable AI for Raman Spectroscopy", "abstract": "Raman spectroscopy is becoming more common for medical diagnostics with deep\nlearning models being increasingly used to leverage its full potential.\nHowever, the opaque nature of such models and the sensitivity of medical\ndiagnosis together with regulatory requirements necessitate the need for\nexplainable AI tools. We introduce SpecReX, specifically adapted to explaining\nRaman spectra. SpecReX uses the theory of actual causality to rank causal\nresponsibility in a spectrum, quantified by iteratively refining mutated\nversions of the spectrum and testing if it retains the original classification.\nThe explanations provided by SpecReX take the form of a responsibility map,\nhighlighting spectral regions most responsible for the model to make a correct\nclassification. To assess the validity of SpecReX, we create increasingly\ncomplex simulated spectra, in which a \"ground truth\" signal is seeded, to train\na classifier. We then obtain SpecReX explanations and compare the results with\nanother explainability tool. By using simulated spectra we establish that\nSpecReX localizes to the known differences between classes, under a number of\nconditions. This provides a foundation on which we can find the spectral\nfeatures which differentiate disease classes. This is an important first step\nin proving the validity of SpecReX.", "published": "2025-03-18 10:49:15", "link": "http://arxiv.org/abs/2503.14567v1", "categories": ["cs.LG", "cs.AI", "physics.med-ph"], "primary_category": "cs.LG"}
{"title": "Operational Change Detection for Geographical Information: Overview and Challenges", "abstract": "Rapid evolution of territories due to climate change and human impact\nrequires prompt and effective updates to geospatial databases maintained by the\nNational Mapping Agency. This paper presents a comprehensive overview of change\ndetection methods tailored for the operational updating of large-scale\ngeographic databases. This review first outlines the fundamental definition of\nchange, emphasizing its multifaceted nature, from temporal to semantic\ncharacterization. It categorizes automatic change detection methods into four\nmain families: rule-based, statistical, machine learning, and simulation\nmethods. The strengths, limitations, and applicability of every family are\ndiscussed in the context of various input data. Then, key applications for\nNational Mapping Agencies are identified, particularly the optimization of\ngeospatial database updating, change-based phenomena, and dynamics monitoring.\nFinally, the paper highlights the current challenges for leveraging change\ndetection such as the variability of change definition, the missing of relevant\nlarge-scale datasets, the diversity of input data, the unstudied no-change\ndetection, the human in the loop integration and the operational constraints.\nThe discussion underscores the necessity for ongoing innovation in change\ndetection techniques to address the future needs of geographic information\nsystems for national mapping agencies.", "published": "2025-03-18 10:25:28", "link": "http://arxiv.org/abs/2503.14109v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction", "abstract": "Automatic anatomical landmark localization in medical imaging requires not\njust accurate predictions but reliable uncertainty quantification for effective\nclinical decision support. Current uncertainty quantification approaches often\nfall short, particularly when combined with normality assumptions,\nsystematically underestimating total predictive uncertainty. This paper\nintroduces conformal prediction as a framework for reliable uncertainty\nquantification in anatomical landmark localization, addressing a critical gap\nin automatic landmark localization. We present two novel approaches\nguaranteeing finite-sample validity for multi-output prediction: Multi-output\nRegression-as-Classification Conformal Prediction (M-R2CCP) and its variant\nMulti-output Regression to Classification Conformal Prediction set to Region\n(M-R2C2R). Unlike conventional methods that produce axis-aligned\nhyperrectangular or ellipsoidal regions, our approaches generate flexible,\nnon-convex prediction regions that better capture the underlying uncertainty\nstructure of landmark predictions. Through extensive empirical evaluation\nacross multiple 2D and 3D datasets, we demonstrate that our methods\nconsistently outperform existing multi-output conformal prediction approaches\nin both validity and efficiency. This work represents a significant advancement\nin reliable uncertainty estimation for anatomical landmark localization,\nproviding clinicians with trustworthy confidence measures for their diagnoses.\nWhile developed for medical imaging, these methods show promise for broader\napplications in multi-output regression problems.", "published": "2025-03-18 10:21:32", "link": "http://arxiv.org/abs/2503.14106v1", "categories": ["cs.CV", "cs.AI", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Sensory-driven microinterventions for improved health and wellbeing", "abstract": "The five senses are gateways to our wellbeing and their decline is considered\na significant public health challenge which is linked to multiple conditions\nthat contribute significantly to morbidity and mortality. Modern technology,\nwith its ubiquitous nature and fast data processing has the ability to leverage\nthe power of the senses to transform our approach to day to day healthcare,\nwith positive effects on our quality of life. Here, we introduce the idea of\nsensory-driven microinterventions for preventative, personalised healthcare.\nMicrointerventions are targeted, timely, minimally invasive strategies that\nseamlessly integrate into our daily life. This idea harnesses human's sensory\ncapabilities, leverages technological advances in sensory stimulation and\nreal-time processing ability for sensing the senses. The collection of sensory\ndata from our continuous interaction with technology - for example the tone of\nvoice, gait movement, smart home behaviour - opens up a shift towards\npersonalised technology-enabled, sensory-focused healthcare interventions,\ncoupled with the potential of early detection and timely treatment of sensory\ndeficits that can signal critical health insights, especially for\nneurodegenerative diseases such as Parkinson's disease.", "published": "2025-03-18 10:17:55", "link": "http://arxiv.org/abs/2503.14102v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.ET"], "primary_category": "cs.HC"}
{"title": "Toward Large-Scale Distributed Quantum Long Short-Term Memory with Modular Quantum Computers", "abstract": "In this work, we introduce a Distributed Quantum Long Short-Term Memory\n(QLSTM) framework that leverages modular quantum computing to address\nscalability challenges on Noisy Intermediate-Scale Quantum (NISQ) devices. By\nembedding variational quantum circuits into LSTM cells, the QLSTM captures\nlong-range temporal dependencies, while a distributed architecture partitions\nthe underlying Variational Quantum Circuits (VQCs) into smaller, manageable\nsubcircuits that can be executed on a network of quantum processing units. We\nassess the proposed framework using nontrivial benchmark problems such as\ndamped harmonic oscillators and Nonlinear Autoregressive Moving Average\nsequences. Our results demonstrate that the distributed QLSTM achieves stable\nconvergence and improved training dynamics compared to classical approaches.\nThis work underscores the potential of modular, distributed quantum computing\narchitectures for large-scale sequence modelling, providing a foundation for\nthe future integration of hybrid quantum-classical solutions into advanced\nQuantum High-performance computing (HPC) ecosystems.", "published": "2025-03-18 10:07:34", "link": "http://arxiv.org/abs/2503.14088v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "CP-NCBF: A Conformal Prediction-based Approach to Synthesize Verified Neural Control Barrier Functions", "abstract": "Control Barrier Functions (CBFs) are a practical approach for designing\nsafety-critical controllers, but constructing them for arbitrary nonlinear\ndynamical systems remains a challenge. Recent efforts have explored\nlearning-based methods, such as neural CBFs (NCBFs), to address this issue.\nHowever, ensuring the validity of NCBFs is difficult due to potential learning\nerrors. In this letter, we propose a novel framework that leverages\nsplit-conformal prediction to generate formally verified neural CBFs with\nprobabilistic guarantees based on a user-defined error rate, referred to as\nCP-NCBF. Unlike existing methods that impose Lipschitz constraints on neural\nCBF-leading to scalability limitations and overly conservative safe sets--our\napproach is sample-efficient, scalable, and results in less restrictive safety\nregions. We validate our framework through case studies on obstacle avoidance\nin autonomous driving and geo-fencing of aerial vehicles, demonstrating its\nability to generate larger and less conservative safe sets compared to\nconventional techniques.", "published": "2025-03-18 10:01:06", "link": "http://arxiv.org/abs/2503.17395v1", "categories": ["eess.SY", "cs.AI", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency", "abstract": "Recent studies suggest utilizing generative models instead of traditional\nauto-regressive algorithms for time series forecasting (TSF) tasks. These\nnon-auto-regressive approaches involving different generative methods,\nincluding GAN, Diffusion, and Flow Matching for time series, have empirically\ndemonstrated high-quality generation capability and accuracy. However, we still\nlack an appropriate understanding of how it processes approximation and\ngeneralization. This paper presents the first theoretical framework from the\nperspective of flow-based generative models to relieve the knowledge of\nlimitations. In particular, we provide our insights with strict guarantees from\nthree perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and\n$\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as\nfollows:\n  $\\bullet$ By assuming a general data model, the fitting of the flow-based\ngenerative models is confirmed to converge to arbitrary error under the\nuniversal approximation of Diffusion Transformer (DiT).\n  $\\bullet$ Introducing a polynomial-based regularization for flow matching,\nthe generalization error thus be bounded since the generalization of polynomial\napproximation.\n  $\\bullet$ The sampling for generation is considered as an optimization\nprocess, we demonstrate its fast convergence with updating standard first-order\ngradient descent of some objective.", "published": "2025-03-18 09:53:48", "link": "http://arxiv.org/abs/2503.14076v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Fast Autoregressive Video Generation with Diagonal Decoding", "abstract": "Autoregressive Transformer models have demonstrated impressive performance in\nvideo generation, but their sequential token-by-token decoding process poses a\nmajor bottleneck, particularly for long videos represented by tens of thousands\nof tokens. In this paper, we propose Diagonal Decoding (DiagD), a training-free\ninference acceleration algorithm for autoregressively pre-trained models that\nexploits spatial and temporal correlations in videos. Our method generates\ntokens along diagonal paths in the spatial-temporal token grid, enabling\nparallel decoding within each frame as well as partially overlapping across\nconsecutive frames. The proposed algorithm is versatile and adaptive to various\ngenerative models and tasks, while providing flexible control over the\ntrade-off between inference speed and visual quality. Furthermore, we propose a\ncost-effective finetuning strategy that aligns the attention patterns of the\nmodel with our decoding order, further mitigating the training-inference gap on\nsmall-scale models. Experiments on multiple autoregressive video generation\nmodels and datasets demonstrate that DiagD achieves up to $10\\times$ speedup\ncompared to naive sequential decoding, while maintaining comparable visual\nfidelity.", "published": "2025-03-18 09:42:55", "link": "http://arxiv.org/abs/2503.14070v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors", "abstract": "Accurate traffic flow estimation and prediction are critical for the\nefficient management of transportation systems, particularly under increasing\nurbanization. Traditional methods relying on static sensors often suffer from\nlimited spatial coverage, while probe vehicles provide richer, albeit sparse\nand irregular data. This work introduces ON-Traffic, a novel deep operator\nNetwork and a receding horizon learning-based framework tailored for online\nestimation of spatio-temporal traffic state along with quantified uncertainty\nby using measurements from moving probe vehicles and downstream boundary\ninputs. Our framework is evaluated in both numerical and simulation datasets,\nshowcasing its ability to handle irregular, sparse input data, adapt to\ntime-shifted scenarios, and provide well-calibrated uncertainty estimates. The\nresults demonstrate that the model captures complex traffic phenomena,\nincluding shockwaves and congestion propagation, while maintaining robustness\nto noise and sensor dropout. These advancements present a significant step\ntoward online, adaptive traffic management systems.", "published": "2025-03-18 09:13:24", "link": "http://arxiv.org/abs/2503.14053v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Beyond holography: the entropic quantum gravity foundations of image processing", "abstract": "Recently, thanks to the development of artificial intelligence (AI) there is\nincreasing scientific attention to establishing the connections between\ntheoretical physics and AI. Traditionally, these connections have been focusing\nmostly on the relation between string theory and image processing and involve\nimportant theoretical paradigms such as holography. Recently G. Bianconi has\nproposed the entropic quantum gravity approach that proposes an action for\ngravity given by the quantum relative entropy between the metrics associated to\na manifold. Here it is demonstrated that the famous Perona-Malik algorithm for\nimage processing is the gradient flow of the entropic quantum gravity action.\nThese results provide the geometrical and information theory foundations for\nthe Perona-Malik algorithm and open new avenues for establishing fundamental\nrelations between brain research, machine learning and entropic quantum\ngravity.", "published": "2025-03-18 09:06:33", "link": "http://arxiv.org/abs/2503.14048v1", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "gr-qc", "quant-ph"], "primary_category": "cond-mat.dis-nn"}
{"title": "MP-GUI: Modality Perception with MLLMs for GUI Understanding", "abstract": "Graphical user interface (GUI) has become integral to modern society, making\nit crucial to be understood for human-centric systems. However, unlike natural\nimages or documents, GUIs comprise artificially designed graphical elements\narranged to convey specific semantic meanings. Current multi-modal large\nlanguage models (MLLMs) already proficient in processing graphical and textual\ncomponents suffer from hurdles in GUI understanding due to the lack of explicit\nspatial structure modeling. Moreover, obtaining high-quality spatial structure\ndata is challenging due to privacy issues and noisy environments. To address\nthese challenges, we present MP-GUI, a specially designed MLLM for GUI\nunderstanding. MP-GUI features three precisely specialized perceivers to\nextract graphical, textual, and spatial modalities from the screen as\nGUI-tailored visual clues, with spatial structure refinement strategy and\nadaptively combined via a fusion gate to meet the specific preferences of\ndifferent GUI understanding tasks. To cope with the scarcity of training data,\nwe also introduce a pipeline for automatically data collecting. Extensive\nexperiments demonstrate that MP-GUI achieves impressive results on various GUI\nunderstanding tasks with limited data.", "published": "2025-03-18 08:32:22", "link": "http://arxiv.org/abs/2503.14021v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Boosting Semi-Supervised Medical Image Segmentation via Masked Image Consistency and Discrepancy Learning", "abstract": "Semi-supervised learning is of great significance in medical image\nsegmentation by exploiting unlabeled data. Among its strategies, the\nco-training framework is prominent. However, previous co-training studies\npredominantly concentrate on network initialization variances and pseudo-label\ngeneration, while overlooking the equilibrium between information interchange\nand model diversity preservation. In this paper, we propose the Masked Image\nConsistency and Discrepancy Learning (MICD) framework with three key modules.\nThe Masked Cross Pseudo Consistency (MCPC) module enriches context perception\nand small sample learning via pseudo-labeling across masked-input branches. The\nCross Feature Consistency (CFC) module fortifies information exchange and model\nrobustness by ensuring decoder feature consistency. The Cross Model Discrepancy\n(CMD) module utilizes EMA teacher networks to oversee outputs and preserve\nbranch diversity. Together, these modules address existing limitations by\nfocusing on fine-grained local information and maintaining diversity in a\nheterogeneous framework. Experiments on two public medical image datasets, AMOS\nand Synapse, demonstrate that our approach outperforms state-of-the-art\nmethods.", "published": "2025-03-18 08:20:35", "link": "http://arxiv.org/abs/2503.14013v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling", "abstract": "Generative models have recently made remarkable progress in the field of 3D\nobjects. However, their practical application in fields like engineering\nremains limited since they fail to deliver the accuracy, quality, and\ncontrollability needed for domain-specific tasks. Fine-tuning large generative\nmodels is a promising perspective for making these models available in these\nfields. Creating high-quality, domain-specific 3D datasets is crucial for\nfine-tuning large generative models, yet the data filtering and annotation\nprocess remains a significant bottleneck. We present MeshFleet, a filtered and\nannotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive\npublicly available collection of 3D objects. Our approach proposes a pipeline\nfor automated data filtering based on a quality classifier. This classifier is\ntrained on a manually labeled subset of Objaverse, incorporating DINOv2 and\nSigLIP embeddings, refined through caption-based analysis and uncertainty\nestimation. We demonstrate the efficacy of our filtering method through a\ncomparative analysis against caption and image aesthetic score-based techniques\nand fine-tuning experiments with SV3D, highlighting the importance of targeted\ndata selection for domain-specific 3D generative modeling.", "published": "2025-03-18 08:09:24", "link": "http://arxiv.org/abs/2503.14002v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BI-RADS prediction of mammographic masses using uncertainty information extracted from a Bayesian Deep Learning model", "abstract": "The BI_RADS score is a probabilistic reporting tool used by radiologists to\nexpress the level of uncertainty in predicting breast cancer based on some\nmorphological features in mammography images. There is a significant\nvariability in describing masses which sometimes leads to BI_RADS\nmisclassification. Using a BI_RADS prediction system is required to support the\nfinal radiologist decisions. In this study, the uncertainty information\nextracted by a Bayesian deep learning model is utilized to predict the BI_RADS\nscore. The investigation results based on the pathology information demonstrate\nthat the f1-scores of the predictions of the radiologist are 42.86%, 48.33% and\n48.28%, meanwhile, the f1-scores of the model performance are 73.33%, 59.60%\nand 59.26% in the BI_RADS 2, 3 and 5 dataset samples, respectively. Also, the\nmodel can distinguish malignant from benign samples in the BI_RADS 0 category\nof the used dataset with an accuracy of 75.86% and correctly identify all\nmalignant samples as BI_RADS 5. The Grad-CAM visualization shows the model pays\nattention to the morphological features of the lesions. Therefore, this study\nshows the uncertainty-aware Bayesian Deep Learning model can report his\nuncertainty about the malignancy of a lesion based on morphological features,\nlike a radiologist.", "published": "2025-03-18 08:06:05", "link": "http://arxiv.org/abs/2503.13999v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GraphTEN: Graph Enhanced Texture Encoding Network", "abstract": "Texture recognition is a fundamental problem in computer vision and pattern\nrecognition. Recent progress leverages feature aggregation into discriminative\ndescriptions based on convolutional neural networks (CNNs). However, modeling\nnon-local context relations through visual primitives remains challenging due\nto the variability and randomness of texture primitives in spatial\ndistributions. In this paper, we propose a graph-enhanced texture encoding\nnetwork (GraphTEN) designed to capture both local and global features of\ntexture primitives. GraphTEN models global associations through fully connected\ngraphs and captures cross-scale dependencies of texture primitives via\nbipartite graphs. Additionally, we introduce a patch encoding module that\nutilizes a codebook to achieve an orderless representation of texture by\nencoding multi-scale patch features into a unified feature space. The proposed\nGraphTEN achieves superior performance compared to state-of-the-art methods\nacross five publicly available datasets.", "published": "2025-03-18 07:51:13", "link": "http://arxiv.org/abs/2503.13991v1", "categories": ["cs.CV", "cs.AI", "68T45", "I.2.10; I.4.7"], "primary_category": "cs.CV"}
{"title": "Effortless Active Labeling for Long-Term Test-Time Adaptation", "abstract": "Long-term test-time adaptation (TTA) is a challenging task due to error\naccumulation. Recent approaches tackle this issue by actively labeling a small\nproportion of samples in each batch, yet the annotation burden quickly grows as\nthe batch number increases. In this paper, we investigate how to achieve\neffortless active labeling so that a maximum of one sample is selected for\nannotation in each batch. First, we annotate the most valuable sample in each\nbatch based on the single-step optimization perspective in the TTA context. In\nthis scenario, the samples that border between the source- and target-domain\ndata distributions are considered the most feasible for the model to learn in\none iteration. Then, we introduce an efficient strategy to identify these\nsamples using feature perturbation. Second, we discover that the gradient\nmagnitudes produced by the annotated and unannotated samples have significant\nvariations. Therefore, we propose balancing their impact on model optimization\nusing two dynamic weights. Extensive experiments on the popular ImageNet-C, -R,\n-K, -A and PACS databases demonstrate that our approach consistently\noutperforms state-of-the-art methods with significantly lower annotation costs.", "published": "2025-03-18 07:49:27", "link": "http://arxiv.org/abs/2503.14564v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Workflow for Safe-AI", "abstract": "The development and deployment of safe and dependable AI models is crucial in\napplications where functional safety is a key concern. Given the rapid\nadvancement in AI research and the relative novelty of the safe-AI domain,\nthere is an increasing need for a workflow that balances stability with\nadaptability. This work proposes a transparent, complete, yet flexible and\nlightweight workflow that highlights both reliability and qualifiability. The\ncore idea is that the workflow must be qualifiable, which demands the use of\nqualified tools. Tool qualification is a resource-intensive process, both in\nterms of time and cost. We therefore place value on a lightweight workflow\nfeaturing a minimal number of tools with limited features. The workflow is\nbuilt upon an extended ONNX model description allowing for validation of AI\nalgorithms from their generation to runtime deployment. This validation is\nessential to ensure that models are validated before being reliably deployed\nacross different runtimes, particularly in mixed-criticality systems.\nKeywords-AI workflows, safe-AI, dependable-AI, functional safety, v-model\ndevelopment", "published": "2025-03-18 07:45:18", "link": "http://arxiv.org/abs/2503.14563v2", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection", "abstract": "Developing effective visual inspection models remains challenging due to the\nscarcity of defect data. While image generation models have been used to\nsynthesize defect images, producing highly realistic defects remains difficult.\nWe propose DefectFill, a novel method for realistic defect generation that\nrequires only a few reference defect images. It leverages a fine-tuned\ninpainting diffusion model, optimized with our custom loss functions\nincorporating defect, object, and attention terms. It enables precise capture\nof detailed, localized defect features and their seamless integration into\ndefect-free objects. Additionally, our Low-Fidelity Selection method further\nenhances the defect sample quality. Experiments show that DefectFill generates\nhigh-quality defect images, enabling visual inspection models to achieve\nstate-of-the-art performance on the MVTec AD dataset.", "published": "2025-03-18 07:42:11", "link": "http://arxiv.org/abs/2503.13985v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Analysis of human visual field information using machine learning methods and assessment of their accuracy", "abstract": "Subject of research: is the study of methods for analyzing perimetric images\nfor the diagnosis and control of glaucoma diseases. Objects of research: is a\ndataset collected on the ophthalmological perimeter with the results of various\npatient pathologies, since the ophthalmological community is acutely aware of\nthe issue of disease control and import substitution. [5]. Purpose of research:\nis to consider various machine learning methods that can classify glaucoma.\nThis is possible thanks to the classifier built after labeling the dataset. It\nis able to determine from the image whether the visual fields depicted on it\nare the results of the impact of glaucoma on the eyes or other visual diseases.\nEarlier in the work [3], a dataset was described that was collected on the\nTomey perimeter. The average age of the examined patients ranged from 30 to 85\nyears. Methods of research: machine learning methods for classifying image\nresults (stochastic gradient descent, logistic regression, random forest, naive\nBayes). Main results of research: the result of the study is computer modeling\nthat can determine from the image whether the result is glaucoma or another\ndisease (binary classification).", "published": "2025-03-18 07:39:41", "link": "http://arxiv.org/abs/2503.14562v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "FrustumFusionNets: A Three-Dimensional Object Detection Network Based on Tractor Road Scene", "abstract": "To address the issues of the existing frustum-based methods' underutilization\nof image information in road three-dimensional object detection as well as the\nlack of research on agricultural scenes, we constructed an object detection\ndataset using an 80-line Light Detection And Ranging (LiDAR) and a camera in a\ncomplex tractor road scene and proposed a new network called FrustumFusionNets\n(FFNets). Initially, we utilize the results of image-based two-dimensional\nobject detection to narrow down the search region in the three-dimensional\nspace of the point cloud. Next, we introduce a Gaussian mask to enhance the\npoint cloud information. Then, we extract the features from the frustum point\ncloud and the crop image using the point cloud feature extraction pipeline and\nthe image feature extraction pipeline, respectively. Finally, we concatenate\nand fuse the data features from both modalities to achieve three-dimensional\nobject detection. Experiments demonstrate that on the constructed test set of\ntractor road data, the FrustumFusionNetv2 achieves 82.28% and 95.68% accuracy\nin the three-dimensional object detection of the two main road objects, cars\nand people, respectively. This performance is 1.83% and 2.33% better than the\noriginal model. It offers a hybrid fusion-based multi-object, high-precision,\nreal-time three-dimensional object detection technique for unmanned\nagricultural machines in tractor road scenarios. On the Karlsruhe Institute of\nTechnology and Toyota Technological Institute (KITTI) Benchmark Suite\nvalidation set, the FrustumFusionNetv2 also demonstrates significant\nsuperiority in detecting road pedestrian objects compared with other\nfrustum-based three-dimensional object detection methods.", "published": "2025-03-18 06:40:39", "link": "http://arxiv.org/abs/2503.13951v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Zero-Knowledge Federated Learning: A New Trustworthy and Privacy-Preserving Distributed Learning Paradigm", "abstract": "Federated Learning (FL) has emerged as a promising paradigm in distributed\nmachine learning, enabling collaborative model training while preserving data\nprivacy. However, despite its many advantages, FL still contends with\nsignificant challenges -- most notably regarding security and trust.\nZero-Knowledge Proofs (ZKPs) offer a potential solution by establishing trust\nand enhancing system integrity throughout the FL process. Although several\nstudies have explored ZKP-based FL (ZK-FL), a systematic framework and\ncomprehensive analysis are still lacking. This article makes two key\ncontributions. First, we propose a structured ZK-FL framework that categorizes\nand analyzes the technical roles of ZKPs across various FL stages and tasks.\nSecond, we introduce a novel algorithm, Verifiable Client Selection FL\n(Veri-CS-FL), which employs ZKPs to refine the client selection process. In\nVeri-CS-FL, participating clients generate verifiable proofs for the\nperformance metrics of their local models and submit these concise proofs to\nthe server for efficient verification. The server then selects clients with\nhigh-quality local models for uploading, subsequently aggregating the\ncontributions from these selected clients. By integrating ZKPs, Veri-CS-FL not\nonly ensures the accuracy of performance metrics but also fortifies trust among\nparticipants while enhancing the overall efficiency and security of FL systems.", "published": "2025-03-18 06:21:08", "link": "http://arxiv.org/abs/2503.15550v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "ChatBEV: A Visual Language Model that Understands BEV Maps", "abstract": "Traffic scene understanding is essential for intelligent transportation\nsystems and autonomous driving, ensuring safe and efficient vehicle operation.\nWhile recent advancements in VLMs have shown promise for holistic scene\nunderstanding, the application of VLMs to traffic scenarios, particularly using\nBEV maps, remains under explored. Existing methods often suffer from limited\ntask design and narrow data amount, hindering comprehensive scene\nunderstanding. To address these challenges, we introduce ChatBEV-QA, a novel\nBEV VQA benchmark contains over 137k questions, designed to encompass a wide\nrange of scene understanding tasks, including global scene understanding,\nvehicle-lane interactions, and vehicle-vehicle interactions. This benchmark is\nconstructed using an novel data collection pipeline that generates scalable and\ninformative VQA data for BEV maps. We further fine-tune a specialized\nvision-language model ChatBEV, enabling it to interpret diverse question\nprompts and extract relevant context-aware information from BEV maps.\nAdditionally, we propose a language-driven traffic scene generation pipeline,\nwhere ChatBEV facilitates map understanding and text-aligned navigation\nguidance, significantly enhancing the generation of realistic and consistent\ntraffic scenarios. The dataset, code and the fine-tuned model will be released.", "published": "2025-03-18 06:12:38", "link": "http://arxiv.org/abs/2503.13938v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Temporal Flexibility in Spiking Neural Networks: Towards Generalization Across Time Steps and Deployment Friendliness", "abstract": "Spiking Neural Networks (SNNs), models inspired by neural mechanisms in the\nbrain, allow for energy-efficient implementation on neuromorphic hardware.\nHowever, SNNs trained with current direct training approaches are constrained\nto a specific time step. This \"temporal inflexibility\" 1) hinders SNNs'\ndeployment on time-step-free fully event-driven chips and 2) prevents\nenergy-performance balance based on dynamic inference time steps. In this\nstudy, we first explore the feasibility of training SNNs that generalize across\ndifferent time steps. We then introduce Mixed Time-step Training (MTT), a novel\nmethod that improves the temporal flexibility of SNNs, making SNNs adaptive to\ndiverse temporal structures. During each iteration of MTT, random time steps\nare assigned to different SNN stages, with spikes transmitted between stages\nvia communication modules. After training, the weights are deployed and\nevaluated on both time-stepped and fully event-driven platforms. Experimental\nresults show that models trained by MTT gain remarkable temporal flexibility,\nfriendliness for both event-driven and clock-driven deployment (nearly lossless\non N-MNIST and 10.1% higher than standard methods on CIFAR10-DVS), enhanced\nnetwork generalization, and near SOTA performance. To the best of our\nknowledge, this is the first work to report the results of large-scale SNN\ndeployment on fully event-driven scenarios.", "published": "2025-03-18 06:09:42", "link": "http://arxiv.org/abs/2503.17394v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "COLSON: Controllable Learning-Based Social Navigation via Diffusion-Based Reinforcement Learning", "abstract": "Mobile robot navigation in dynamic environments with pedestrian traffic is a\nkey challenge in the development of autonomous mobile service robots. Recently,\ndeep reinforcement learning-based methods have been actively studied and have\noutperformed traditional rule-based approaches owing to their optimization\ncapabilities. Among these, methods that assume a continuous action space\ntypically rely on a Gaussian distribution assumption, which limits the\nflexibility of generated actions. Meanwhile, the application of diffusion\nmodels to reinforcement learning has advanced, allowing for more flexible\naction distributions compared with Gaussian distribution-based approaches. In\nthis study, we applied a diffusion-based reinforcement learning approach to\nsocial navigation and validated its effectiveness. Furthermore, by leveraging\nthe characteristics of diffusion models, we propose an extension that enables\npost-training action smoothing and adaptation to static obstacle scenarios not\nconsidered during the training steps.", "published": "2025-03-18 06:02:30", "link": "http://arxiv.org/abs/2503.13934v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Exploring the unleaved tree of numerical semigroups up to a given genus", "abstract": "We present a new algorithm to explore or count the numerical semigroups of a\ngiven genus which uses the unleaved version of the tree of numerical\nsemigroups. In the unleaved tree there are no leaves rather than the ones at\ndepth equal to the genus in consideration. For exloring the unleaved tree we\npresent a new encoding system of a numerical semigroup given by the gcd of its\nleft elements and its shrinking, that is, the semigroup generated by its left\nelements divided by their gcd. We show a method to determine the right\ngenerators and strong generators of a semigroup by means of the gcd and the\nshrinking encoding, as well as a method to encode a semigroup from the encoding\nof its parent or of its predecessor sibling. With the new algorithm we obtained\n$n_{76}=29028294421710227$.", "published": "2025-03-18 19:11:00", "link": "http://arxiv.org/abs/2503.14664v1", "categories": ["math.CO", "cs.DM", "math.AC", "06F05, 20M14, 05A99, 68W30"], "primary_category": "math.CO"}
{"title": "Sheaf-Theoretic Causal Emergence for Resilience Analysis in Distributed Systems", "abstract": "Distributed systems often exhibit emergent behaviors that impact their\nresilience (Franz-Kaiser et al., 2020; Adilson E. Motter, 2002; Jianxi Gao,\n2016). This paper presents a theoretical framework combining attributed graph\nmodels, flow-on-graph simulation, and sheaf-theoretic causal emergence analysis\nto evaluate system resilience. We model a distributed system as a graph with\nattributes (capturing component state and connections) and use sheaf theory to\nformalize how local interactions compose into global states. A flow simulation\non this graph propagates functional loads and failures. To assess resilience,\nwe apply the concept of causal emergence, quantifying whether macro-level\ndynamics (coarse-grained groupings) exhibit stronger causal efficacy (via\neffective information) than micro-level dynamics. The novelty lies in uniting\nsheaf-based formalization with causal metrics to identify emergent resilient\nstructures. We discuss limitless potential applications (illustrated by\nmicroservices, neural networks, and power grids) and outline future steps\ntoward implementing this framework (Lake et al., 2015).", "published": "2025-03-18 10:19:33", "link": "http://arxiv.org/abs/2503.14104v1", "categories": ["eess.SY", "cs.DM", "cs.IT", "cs.SE", "cs.SY", "math.IT", "G.2; G.3; E.4; H.1.1; D.2"], "primary_category": "eess.SY"}
{"title": "The Hierarchy of Saturating Matching Numbers", "abstract": "In this paper, we study three matching problems all of which came up quite\nrecently in the field of machine teaching. The cost of a matching is defined in\nsuch a way that, for some formal model of teaching, it equals (or bounds) the\nnumber of labeled examples needed to solve a given teaching task. We show how\nthe cost parameters associated with these problems depend on each other and how\nthey are related to other well known combinatorial parameters (like, for\ninstance, the VC-dimension).", "published": "2025-03-18 09:35:13", "link": "http://arxiv.org/abs/2503.14061v1", "categories": ["math.CO", "cs.DM", "68R05", "G.2.1"], "primary_category": "math.CO"}
{"title": "Color-Constrained Arborescences in Edge-Colored Digraphs", "abstract": "Given a multigraph $G$ whose edges are colored from the set\n$[q]:=\\{1,2,\\ldots,q\\}$ (\\emph{$q$-colored graph}), and a vector\n$\\alpha=(\\alpha_1,\\ldots,\\alpha_{q}) \\in \\mathbb{N}^{q}$\n(\\emph{color-constraint}), a subgraph $H$ of $G$ is called\n\\emph{$\\alpha$-colored}, if $H$ has exactly $\\alpha_i$ edges of color $i$ for\neach $i \\in[q]$. In this paper, we focus on $\\alpha$-colored arborescences\n(spanning out-trees) in $q$-colored multidigraphs. We study the decision,\ncounting and search versions of this problem. It is known that the decision and\nsearch problems are polynomial-time solvable when $q=2$ and that the decision\nproblem is NP-complete when $q$ is arbitrary. However the complexity status of\nthe problem for fixed $q$ was open for $q > 2$. We show that, for a $q$-colored\ndigraph $G$ and a vertex $s$ in $G$, the number of $\\alpha$-colored\narborescences in $G$ rooted at $s$ for all color-constraints $\\alpha \\in\n\\mathbb{N}^q$ can be read from the determinant of a symbolic matrix in $q-1$\nindeterminates. This result extends Tutte's matrix-tree theorem for directed\ngraphs and gives a polynomial-time algorithm for the counting and decision\nproblems for fixed $q$. We also use it to design an algorithm that finds an\n$\\alpha$-colored arborescence when one exists. Finally, we study the weighted\nvariant of the problem and give a polynomial-time algorithm (when $q$ is fixed)\nwhich finds a minimum weight solution.", "published": "2025-03-18 07:40:54", "link": "http://arxiv.org/abs/2503.13984v1", "categories": ["cs.DS", "cs.CC", "cs.DM", "math.CO", "G.2.2"], "primary_category": "cs.DS"}
{"title": "Towards a Barrier-free GeoQA Portal: Natural Language Interaction with Geospatial Data Using Multi-Agent LLMs and Semantic Search", "abstract": "A Barrier-Free GeoQA Portal: Enhancing Geospatial Data Accessibility with a\nMulti-Agent LLM Framework\n  Geoportals are vital for accessing and analyzing geospatial data, promoting\nopen spatial data sharing and online geo-information management. Designed with\nGIS-like interaction and layered visualization, they often challenge non-expert\nusers with complex functionalities and overlapping layers that obscure spatial\nrelationships. We propose a GeoQA Portal using a multi-agent Large Language\nModel framework for seamless natural language interaction with geospatial data.\nComplex queries are broken into subtasks handled by specialized agents,\nretrieving relevant geographic data efficiently. Task plans are shown to users,\nboosting transparency. The portal supports default and custom data inputs for\nflexibility. Semantic search via word vector similarity aids data retrieval\ndespite imperfect terms. Case studies, evaluations, and user tests confirm its\neffectiveness for non-experts, bridging GIS complexity and public access, and\noffering an intuitive solution for future geoportals.", "published": "2025-03-18 13:39:46", "link": "http://arxiv.org/abs/2503.14251v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Rolling Forward: Enhancing LightGCN with Causal Graph Convolution for Credit Bond Recommendation", "abstract": "Graph Neural Networks have significantly advanced research in recommender\nsystems over the past few years. These methods typically capture global\ninterests using aggregated past interactions and rely on static embeddings of\nusers and items over extended periods of time. While effective in some domains,\nthese methods fall short in many real-world scenarios, especially in finance,\nwhere user interests and item popularity evolve rapidly over time. To address\nthese challenges, we introduce a novel extension to Light Graph Convolutional\nNetwork (LightGCN) designed to learn temporal node embeddings that capture\ndynamic interests. Our approach employs causal convolution to maintain a\nforward-looking model architecture. By preserving the chronological order of\nuser-item interactions and introducing a dynamic update mechanism for\nembeddings through a sliding window, the proposed model generates well-timed\nand contextually relevant recommendations. Extensive experiments on a\nreal-world dataset from BNP Paribas demonstrate that our approach significantly\nenhances the performance of LightGCN while maintaining the simplicity and\nefficiency of its architecture. Our findings provide new insights into\ndesigning graph-based recommender systems in time-sensitive applications,\nparticularly for financial product recommendations.", "published": "2025-03-18 12:47:01", "link": "http://arxiv.org/abs/2503.14213v1", "categories": ["cs.IR", "cs.LG", "q-fin.CP"], "primary_category": "cs.IR"}
{"title": "A Comprehensive Survey on Cross-Domain Recommendation: Taxonomy, Progress, and Prospects", "abstract": "Recommender systems (RS) have become crucial tools for information filtering\nin various real world scenarios. And cross domain recommendation (CDR) has been\nwidely explored in recent years in order to provide better recommendation\nresults in the target domain with the help of other domains. The CDR technology\nhas developed rapidly, yet there is a lack of a comprehensive survey\nsummarizing recent works. Therefore, in this paper, we will summarize the\nprogress and prospects based on the main procedure of CDR, including Cross\nDomain Relevance, Cross Domain Interaction, Cross Domain Representation\nEnhancement and Model Optimization. To help researchers better understand and\nengage in this field, we also organize the applications and resources, and\nhighlight several current important challenges and future directions of CDR.\nMore details of the survey articles are available at\nhttps://github.com/USTCAGI/Awesome-Cross-Domain\nRecommendation-Papers-and-Resources.", "published": "2025-03-18 10:27:14", "link": "http://arxiv.org/abs/2503.14110v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Dual-Source SPIR over a noiseless MAC without Data Replication or Shared Randomness", "abstract": "Information-theoretically secure Symmetric Private Information Retrieval\n(SPIR) is known to be infeasible over noiseless channels with a single server.\nKnown solutions to overcome this infeasibility involve additional resources\nsuch as database replication, shared randomness, or noisy channels. In this\npaper, we propose an alternative approach for achieving SPIR with\ninformation-theoretic security guarantees, without relying on shared\nrandomness, noisy channels, or data replication. Specifically, we demonstrate\nthat it is sufficient to use a noiseless binary adder multiple-access channel,\nwhere inputs are controlled by two non-colluding servers and the output is\nobserved by the client, alongside a public noiseless communication channel\nbetween the client and the servers. Furthermore, in this setting, we\ncharacterize the optimal file rates, i.e., the file lengths normalized by the\nnumber of channel uses, that can be transferred.", "published": "2025-03-18 19:38:14", "link": "http://arxiv.org/abs/2503.14682v1", "categories": ["cs.IT", "cs.CR", "math.IT"], "primary_category": "cs.IT"}
{"title": "Synthesis of omnidirectional path loss model based on directional model and multi-elliptical geometry", "abstract": "Millimeter wave (mmWave) technology offers high throughput but has a limited\nradio range, necessitating the use of directional antennas or beamforming\nsystems such as massive MIMO. Path loss (PL) models using narrow-beam antennas\nare known as directional models, while those using omnidirectional antennas are\nreferred to as omnidirectional models. To standardize the analysis,\nomnidirectional PL models for mmWave ranges have been introduced, including TR\n38.901 by 3GPP, which is based on measurements from directional antennas.\nHowever, synthesizing these measurements can be complex and time-consuming.\nThis study proposes a numerical approach to derive an omnidirectional model\nfrom directional data using multi-elliptical geometry. We assessed the\neffectiveness of this method against existing PL models for mmWaves that are\navailable in the literature.", "published": "2025-03-18 18:43:41", "link": "http://arxiv.org/abs/2503.14644v1", "categories": ["eess.SP", "cs.IT", "math.IT", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "The broken sample problem revisited: Proof of a conjecture by Bai-Hsing and high-dimensional extensions", "abstract": "We revisit the classical broken sample problem: Two samples of i.i.d. data\npoints $\\mathbf{X}=\\{X_1,\\cdots, X_n\\}$ and $\\mathbf{Y}=\\{Y_1,\\cdots,Y_m\\}$ are\nobserved without correspondence with $m\\leq n$. Under the null hypothesis,\n$\\mathbf{X}$ and $\\mathbf{Y}$ are independent. Under the alternative\nhypothesis, $\\mathbf{Y}$ is correlated with a random subsample of $\\mathbf{X}$,\nin the sense that $(X_{\\pi(i)},Y_i)$'s are drawn independently from some\nbivariate distribution for some latent injection $\\pi:[m] \\to [n]$. Originally\nintroduced by DeGroot, Feder, and Goel (1971) to model matching records in\ncensus data, this problem has recently gained renewed interest due to its\napplications in data de-anonymization, data integration, and target tracking.\nDespite extensive research over the past decades, determining the precise\ndetection threshold has remained an open problem even for equal sample sizes\n($m=n$). Assuming $m$ and $n$ grow proportionally, we show that the sharp\nthreshold is given by a spectral and an $L_2$ condition of the likelihood ratio\noperator, resolving a conjecture of Bai and Hsing (2005) in the positive. These\nresults are extended to high dimensions and settle the sharp detection\nthresholds for Gaussian and Bernoulli models.", "published": "2025-03-18 18:15:13", "link": "http://arxiv.org/abs/2503.14619v1", "categories": ["math.ST", "cs.IT", "math.IT", "stat.TH"], "primary_category": "math.ST"}
{"title": "Fluid Reconfigurable Intelligent Surfaces: Joint On-Off Selection and Beamforming with Discrete Phase Shifts", "abstract": "This letter proposes a fluid reconfigurable intelligent surface (FRIS)\nparadigm, extending the conventional reconfigurable intelligent surface (RIS)\ntechnology to incorporate position reconfigurability of the elements. In our\nmodel, a `fluid' element is realized by a dense matrix of subelements over a\ngiven space and dynamically selecting specific elements for signal modulation\nbased on channel conditions. Specifically, we consider a FRIS-assisted\nsingle-user single-input single-output (SU-SISO) system and formulate an\noptimization problem that can jointly optimize element selection and their\ndiscrete phase shifts to maximize the achievable rate. To address this problem\nefficiently, we propose an iterative algorithm based on the cross-entropy\noptimization (CEO) framework. Simulation results reveal that FRIS achieves\nsignificant performance gains over traditional RIS.", "published": "2025-03-18 18:03:36", "link": "http://arxiv.org/abs/2503.14601v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications", "abstract": "In the matrix sensing problem, one wishes to reconstruct a matrix from\n(possibly noisy) observations of its linear projections along given directions.\nWe consider this model in the high-dimensional limit: while previous works on\nthis model primarily focused on the recovery of low-rank matrices, we consider\nin this work more general classes of structured signal matrices with\npotentially large rank, e.g. a product of two matrices of sizes proportional to\nthe dimension. We provide rigorous asymptotic equations characterizing the\nBayes-optimal learning performance from a number of samples which is\nproportional to the number of entries in the matrix. Our proof is composed of\nthree key ingredients: $(i)$ we prove universality properties to handle\nstructured sensing matrices, related to the ''Gaussian equivalence'' phenomenon\nin statistical learning, $(ii)$ we provide a sharp characterization of\nBayes-optimal learning in generalized linear models with Gaussian data and\nstructured matrix priors, generalizing previously studied settings, and $(iii)$\nwe leverage previous works on the problem of matrix denoising. The generality\nof our results allow for a variety of applications: notably, we mathematically\nestablish predictions obtained via non-rigorous methods from statistical\nphysics in [ETB+24] regarding Bilinear Sequence Regression, a benchmark model\nfor learning from sequences of tokens, and in [MTM+24] on Bayes-optimal\nlearning in neural networks with quadratic activation function, and width\nproportional to the dimension.", "published": "2025-03-18 10:36:30", "link": "http://arxiv.org/abs/2503.14121v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT", "math.PR"], "primary_category": "stat.ML"}
{"title": "Beamfocusing and Power Allocation for AN-Based PLS in Multiuser XL-MIMO with Multiple Eavesdroppers", "abstract": "This paper investigates the downlink (DL) physical layer security (PLS) in a\nnear-field (NF) extra-large multiple-input multiple-output MIMO (XL-MIMO)\nsystem. To enhance the secrecy rate (SR), null-space artificial noise (AN) is\ntransmitted alongside the confidential message, ensuring orthogonality with\nlegitimate user equipment (LUE) channels. The objective is to maximize the\nminimum SR by optimizing the NF beamfocusing matrix and power allocation\nbetween the signal and AN, considering various channel state information (CSI)\nconditions and transmit power constraints. The proposed approach uses\nsuccessive convex approximation (SCA) for beamfocusing optimization and golden\nsection search (GSS) for power allocation. The following open questions are\naddressed: (i) Can AN transmission further enhance SR for multiple LUEs in the\npresence of multiple eavesdropping user equipment (EUEs)? (ii) Can null-space\nAN transmission achieve attractive SR performance even without CSI availability\nfor EUEs? Both questions are affirmatively answered and explored in detail,\nwith an algorithm presented for joint beamfocusing design and AN-aided power\nallocation. The proposed method outperforms state-of-the-art approaches that\neither omit AN transmission or rely on maximal-ratio transmission (MRT) for\nbeamfocusing.", "published": "2025-03-18 10:16:06", "link": "http://arxiv.org/abs/2503.14100v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Numerical evaluation of Gaussian mixture entropy", "abstract": "We develop an approximation method for the differential entropy\n$h(\\mathbf{X})$ of a $q$-component Gaussian mixture in $\\mathbb{R}^n$. We\nprovide two examples of approximations using our method denoted by\n$\\bar{h}^{\\mathrm{Taylor}}_{C,m}(\\mathbf{X})$ and\n$\\bar{h}^{\\mathrm{Polyfit}}_{C,m}(\\mathbf{X})$. We show that\n$\\bar{h}^{\\mathrm{Taylor}}_{C,m}(\\mathbf{X})$ provides an easy to compute lower\nbound to $h(\\mathbf{X})$, while $\\bar{h}^{\\mathrm{Polyfit}}_{C,m}(\\mathbf{X})$\nprovides an accurate and efficient approximation to $h(\\mathbf{X})$.\n$\\bar{h}^{\\mathrm{Polyfit}}_{C,m}(\\mathbf{X})$ is more accurate than known\nbounds, and conjectured to be much more resilient than the approximation of [5]\nin high dimensions.", "published": "2025-03-18 09:06:29", "link": "http://arxiv.org/abs/2503.14047v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SWIPT in Cell-Free Massive MIMO Using Stacked Intelligent Metasurfaces", "abstract": "We investigate the integration of stacked intelligent metasurfaces (SIMs)\ninto cell-free massive multiple input multiple output (CF-mMIMO) system to\nenhance the simultaneous wireless information and power transfer (SWIPT)\nperformance. Closed-form expressions for the spectral efficiency (SE) of the\ninformation-decoding receivers (IRs) and the average sum of harvested energy\n(sum-HE) at the energy-harvesting receivers (ERs) in the novel system model are\nderived to subsequently formulate a maximum total average sum-HE problem under\na minimum SE threshold per each IR. This problem jointly optimizes the SIM\nphase-shift (PS) configuration and access points' (APs) power allocation,\nrelying on long-term statistical channel state information (CSI). This\nnon-convex problem is then transformed into more tractable forms. Then,\nefficient algorithms are proposed, including a layer-by-layer heuristic method\nfor SIMs PS configuration that prioritizes sum-HE for the ERs and a successive\nconvex approximation (SCA)-based power allocation scheme to improve the\nachievable SE for the IRs. Numerical results show that our proposed algorithms\nachieve an almost 7-fold sum-HE gain as we increase the number of SIM layers,\nwhile the proposed power allocation (PPA) scheme often gains up to 40% in terms\nof the achievable minimum SE, compared to the equal power allocation.", "published": "2025-03-18 08:47:01", "link": "http://arxiv.org/abs/2503.14032v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Joint Transmission and Control in a Goal-oriented NOMA Network", "abstract": "Goal-oriented communication shifts the focus from merely delivering timely\ninformation to maximizing decision-making effectiveness by prioritizing the\ntransmission of high-value information. In this context, we introduce the\nGoal-oriented Tensor (GoT), a novel closed-loop metric designed to directly\nquantify the ultimate utility in Goal-oriented systems, capturing how\neffectively the transmitted information meets the underlying application's\nobjectives. Leveraging the GoT, we model a Goal-oriented Non-Orthogonal\nMultiple Access (NOMA) network comprising multiple transmission-control loops.\nOperating under a pull-based framework, we formulate the joint optimization of\ntransmission and control as a Partially Observable Markov Decision Process\n(POMDP), which we solve by deriving the belief state and training a\nDouble-Dueling Deep Q-Network (D3QN). This framework enables adaptive\ndecision-making for power allocation and control actions. Simulation results\nreveal a fundamental trade-off between transmission efficiency and control\nfidelity. Additionally, the superior utility of NOMA over Orthogonal Multiple\nAccess (OMA) in multi-loop remote control scenarios is demonstrated.", "published": "2025-03-18 03:57:34", "link": "http://arxiv.org/abs/2503.13873v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "New constructions of asymptotically optimal periodic and aperiodic quasi-complementary sequence sets", "abstract": "Quasi-complementary sequence sets (QCSSs) play an important role in\nmulti-carrier code division multiple access (MC-CDMA) systems as they can\nsupport more users than perfect complementary sequence sets (PCSSs). The\nobjective of this paper is to present new constructions of asymptotically\noptimal periodic and aperiodic QCSSs with large set sizes. Firstly, we\nconstruct a family of asymptotically optimal periodic $(p^{2n}, p^n-1, p^n-1,\np^n+1)$ QCSSs with small alphabet size $p$, which has larger set size than the\nknown family of periodic $(p^n(p^n-1), p^n-1, p^n-1, p^n+1)$ QCSSs. Secondly,\nwe construct five new families of asymptotically optimal aperiodic QCSSs with\nlarge set sizes and low aperiodic tolerances. Each family of these aperiodic\nQCSSs has set size $\\Theta(K^2)$ for some flock size $K$. Compared with known\nasymptotically optimal aperiodic QCSSs in the literature, the proposed\naperiodic QCSSs by us have better parameters or new lengths of their\nconstituent sequences.", "published": "2025-03-18 02:31:08", "link": "http://arxiv.org/abs/2503.13841v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SCAN-BEST: Efficient Sub-6GHz-Aided Near-field Beam Selection with Formal Reliability Guarantees", "abstract": "As millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems\ncontinue to incorporate larger antenna arrays, the range of near-field\npropagation expands, making it more likely for users close to the transmitter\nto fall within the near-field regime. Traditional far-field beam training\nmethods are no longer effective in this context. Additionally, near-field beam\ntraining presents challenges, since the training codebook must account for both\nangular and distance dimensions, leading to large codebook sizes. To reduce the\nin-band training overhead, we propose the Sub-6G Channel-Aided Near-field BEam\nSelecTion (SCAN-BEST) framework, which is motivated by the spatial-temporal\ncongruence between sub-6 GHz (sub-6G) and mmWave channels. SCAN-BEST utilizes\npreprocessed sub-6G channel estimates as input, and employs a convolutional\nneural network (CNN) to predict the probability of each beam being optimal\nwithin the near-field beam training codebook. Given the prediction uncertainty\narising from the variance between sub-6G and mmWave channels, we introduce a\nconformal risk control (CRC)-based module that generates a set of beam\ncandidates for further limited in-band training, enabling the final beam\nselection to formally meet user-defined target coverage rate. Numerical results\nconfirm the thereoretical properties of SCAN-BEST in terms of the achieved\ncoverage rate of the beam candidates and various metrics. Moreover, SCAN-BEST\nenjoys good scalability and robustness to various sub-6G system configurations,\nincluding to the sizes of calibration datasets.", "published": "2025-03-18 01:16:16", "link": "http://arxiv.org/abs/2503.13801v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Hidden Bloat in Machine Learning Systems", "abstract": "Software bloat refers to code and features that is not used by a software\nduring runtime. For Machine Learning (ML) systems, bloat is a major contributor\nto their technical debt leading to decreased performance and resource wastage.\nIn this work, we present, Negativa-ML, a novel tool to identify and remove\nbloat in ML frameworks by analyzing their shared libraries. Our approach\nincludes novel techniques to detect and locate unnecessary code within device\ncode - a key area overlooked by existing research, which focuses primarily on\nhost code. We evaluate Negativa-ML using four popular ML frameworks across ten\nworkloads over 300 shared libraries. The results demonstrate that the ML\nframeworks are highly bloated on both the device and host code side. On\naverage, Negativa-ML reduces the device code size in these frameworks by up to\n75% and the host code by up to 72%, resulting in total file size reductions of\nup to 55%. The device code is a primary source of bloat within ML frameworks.\nThrough debloating, we achieve reductions in peak host memory usage, peak GPU\nmemory usage, and execution time by up to 74.6%, 69.6%, and 44.6%,\nrespectively.", "published": "2025-03-18 13:04:25", "link": "http://arxiv.org/abs/2503.14226v1", "categories": ["cs.SE", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Generating Causal Explanations of Vehicular Agent Behavioural Interactions with Learnt Reward Profiles", "abstract": "Transparency and explainability are important features that responsible\nautonomous vehicles should possess, particularly when interacting with humans,\nand causal reasoning offers a strong basis to provide these qualities. However,\neven if one assumes agents act to maximise some concept of reward, it is\ndifficult to make accurate causal inferences of agent planning without\ncapturing what is of importance to the agent. Thus our work aims to learn a\nweighting of reward metrics for agents such that explanations for agent\ninteractions can be causally inferred. We validate our approach quantitatively\nand qualitatively across three real-world driving datasets, demonstrating a\nfunctional improvement over previous methods and competitive performance across\nevaluation metrics.", "published": "2025-03-18 01:53:59", "link": "http://arxiv.org/abs/2503.14557v1", "categories": ["cs.AI", "cs.MA", "cs.RO", "I.2.0; I.2.6; I.2.9; I.2.11; I.6.0"], "primary_category": "cs.AI"}
{"title": "A Convex Formulation of Game-theoretic Hierarchical Routing", "abstract": "Hierarchical decision-making is a natural paradigm for coordinating\nmulti-agent systems in complex environments such as air traffic management. In\nthis paper, we present a bilevel framework for game-theoretic hierarchical\nrouting, where a high-level router assigns discrete routes to multiple vehicles\nwho seek to optimize potentially noncooperative objectives that depend upon the\nassigned routes. To address computational challenges, we propose a\nreformulation that preserves the convexity of each agent's feasible set. This\nconvex reformulation enables a solution to be identified efficiently via a\ncustomized branch-and-bound algorithm. Our approach ensures global optimality\nwhile capturing strategic interactions between agents at the lower level. We\ndemonstrate the solution concept of our framework in two-vehicle and\nthree-vehicle routing scenarios.", "published": "2025-03-18 00:43:03", "link": "http://arxiv.org/abs/2503.13790v1", "categories": ["cs.MA", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Determining a credit transition matrix from cumulative default probabilities", "abstract": "To quantify the changes in the credit rating of a bond is an important\nmathematical problem for the credit rating industry. To think of the credit\nrating as the state a Markov chain is an interesting proposal leading to\nchallenges in mathematical modeling. Since cumulative default rates are more\nreadily measurable than credit migrations, a natural question is whether the\ncredit transition matrix (CTM) can be determined from the knowledge of the\ncumulative default probabilities.\n  Here we use a connection between the CTM and the cumulative default\nprobabilities to setup an ill-posed, linear inverse problem with box\nconstraints, which we solve by an entropy minimization procedure. This approach\nis interesting on several counts. On the one hand, we may have less data that\nunknowns, and on the other hand, even when we have as much data as unknowns,\nthe matrix connecting them may not be invertible, which makes the problem\nill-posed.\n  Besides developing the tools to solve the problem, we apply it to several\ntest cases to check the performance of the method. The results are quite\nsatisfactory.", "published": "2025-03-18 18:46:38", "link": "http://arxiv.org/abs/2503.14646v1", "categories": ["q-fin.CP", "60J22, 62M05 62P200, 62M99, 15A29, 15A06, 90C25, 90C51, 90C99"], "primary_category": "q-fin.CP"}
{"title": "Capturing Smile Dynamics with the Quintic Volatility Model: SPX, Skew-Stickiness Ratio and VIX", "abstract": "We introduce the two-factor Quintic Ornstein-Uhlenbeck model, where\nvolatility is modeled as a polynomial of degree five based on the sum of two\nOrnstein-Uhlenbeck processes driven by the same Brownian Motion, each\nmean-reverting at a different speed. We demonstrate that the Quintic model\neffectively captures the volatility surfaces of SPX and VIX while aligning with\nthe skew-stickiness ratio (SSR) across maturities ranging from a few days to\nover two years. Furthermore, the Quintic model shows consistency with key\nempirical stylized facts, notably reproducing the Zumbach effect.", "published": "2025-03-18 11:30:53", "link": "http://arxiv.org/abs/2503.14158v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Collective completeness and pricing hedging duality", "abstract": "This paper builds on \"Collective Arbitrage and the Value of Cooperation\" by\nBiagini et al. (2025, forthcoming in \"Finance and Stochastics\"), which\nintroduced in discrete time the notions of collective arbitrage and\nsuper-replication in a multi-agent market framework, where agents may operate\nin several submarkets and collaborate through risk exchange mechanisms.\nExpanding on these foundations, we establish a First Fundamental Theorem of\nAsset Pricing and a collective pricing-hedging duality under different\nassumptions and with new techniques compared to Biagini et al. (2025). We\nfurther introduce the notion of collective replication in order to study\ncollective market completeness and provide a Second Fundamental Theorem of\nAsset Pricing in this cooperative multi-agent setting.", "published": "2025-03-18 10:03:17", "link": "http://arxiv.org/abs/2503.14086v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "On weak notions of no-arbitrage in a 1D general diffusion market with interest rates", "abstract": "We establish deterministic necessary and sufficient conditions for the\nno-arbitrage notions \"no increasing profit\" (NIP), \"no strong arbitrage\" (NSA)\nand \"no unbounded profit with bounded risk\" (NUPBR) in one-dimensional general\ndiffusion markets. These are markets with one risky asset, which is modeled as\na regular continuous strong Markov process that is also a semimartingale, and a\nriskless asset that grows exponentially at a constant rate $r\\in \\mathbb{R}$.\nAll deterministic criteria are provided in terms of the scale function and the\nspeed measure of the risky asset process. Our study reveals a variety of\nsurprising effects. For instance, irrespective of the interest rate, NIP is not\nexcluded by reflecting boundaries or an irregular scale function. In the case\nof non-zero interest rates, it is even possible that NUPBR holds in the\npresence of reflecting boundaries and/or skew thresholds. In the zero interest\nrate regime, we also identify NSA as the minimal no arbitrage notion that\nexcludes reflecting boundaries and that forces the scale function to be\ncontinuously differentiable with strictly positive absolutely continuous\nderivative, meaning that it is of the same form as for a stochastic\ndifferential equation.", "published": "2025-03-18 09:55:39", "link": "http://arxiv.org/abs/2503.14078v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "A Note on the Asymptotic Properties of the GLS Estimator in Multivariate Regression with Heteroskedastic and Autocorrelated Errors", "abstract": "We study the asymptotic properties of the GLS estimator in multivariate\nregression with heteroskedastic and autocorrelated errors. We derive Wald\nstatistics for linear restrictions and assess their performance. The statistics\nremains robust to heteroskedasticity and autocorrelation.", "published": "2025-03-18 06:37:09", "link": "http://arxiv.org/abs/2503.13950v1", "categories": ["econ.EM", "q-fin.ST", "stat.ME"], "primary_category": "econ.EM"}
{"title": "Room Impulse Response Estimation through Optimal Mass Transport Barycenters", "abstract": "In this work, we consider the problem of jointly estimating a set of room\nimpulse responses (RIRs) corresponding to closely spaced microphones. The\naccurate estimation of RIRs is crucial in acoustic applications such as speech\nenhancement, noise cancellation, and auralization. However, real-world\nconstraints such as short excitation signals, low signal-to-noise ratios, and\npoor spectral excitation, often render the estimation problem ill-posed. In\nthis paper, we address these challenges by means of optimal mass transport\n(OMT) regularization. In particular, we propose to use an OMT barycenter, or\ngeneralized mean, as a mechanism for information sharing between the\nmicrophones. This allows us to quantify and exploit similarities in the\ndelay-structures between the different microphones without having to impose\nrigid assumptions on the room acoustics. The resulting estimator is formulated\nin terms of the solution to a convex optimization problem which can be\nimplemented using standard solvers. In numerical examples, we demonstrate the\npotential of the proposed method in addressing otherwise ill-conditioned\nestimation scenarios.", "published": "2025-03-18 12:34:05", "link": "http://arxiv.org/abs/2503.14207v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Variational Autoencoder for Personalized Pathological Speech Enhancement", "abstract": "The generalizability of speech enhancement (SE) models across speaker\nconditions remains largely unexplored, despite its critical importance for\nbroader applicability. This paper investigates the performance of the hybrid\nvariational autoencoder (VAE)-non-negative matrix factorization (NMF) model for\nSE, focusing primarily on its generalizability to pathological speakers with\nParkinson's disease. We show that VAE models trained on large neurotypical\ndatasets perform poorly on pathological speech. While fine-tuning these\npre-trained models with pathological speech improves performance, a performance\ngap remains between neurotypical and pathological speakers. To address this\ngap, we propose using personalized SE models derived from fine-tuning\npre-trained models with only a few seconds of clean data from each speaker. Our\nresults demonstrate that personalized models considerably enhance performance\nfor all speakers, achieving comparable results for both neurotypical and\npathological speakers.", "published": "2025-03-18 08:54:00", "link": "http://arxiv.org/abs/2503.14036v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
