{"title": "TabEAno: Table to Knowledge Graph Entity Annotation", "abstract": "In the Open Data era, a large number of table resources have been made available on the Web and data portals. However, it is difficult to directly utilize such data due to the ambiguity of entities, name variations, heterogeneous schema, missing, or incomplete metadata. To address these issues, we propose a novel approach, namely TabEAno, to semantically annotate table rows toward knowledge graph entities. Specifically, we introduce a \"two-cells\" lookup strategy bases on the assumption that there is an existing logical relation occurring in the knowledge graph between the two closed cells in the same row of the table. Despite the simplicity of the approach, TabEAno outperforms the state of the art approaches in the two standard datasets e.g, T2D, Limaye with, and in the large-scale Wikipedia tables dataset.", "published": "2020-10-05 07:39:02", "link": "http://arxiv.org/abs/2010.01829v1", "categories": ["cs.AI", "cs.DB"], "primary_category": "cs.AI"}
{"title": "DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) offer a promising alternative to traditional deep learning frameworks, since they provide higher computational efficiency due to event-driven information processing. SNNs distribute the analog values of pixel intensities into binary spikes over time. However, the most widely used input coding schemes, such as Poisson based rate-coding, do not leverage the additional temporal learning capability of SNNs effectively. Moreover, these SNNs suffer from high inference latency which is a major bottleneck to their deployment. To overcome this, we propose a scalable time-based encoding scheme that utilizes the Discrete Cosine Transform (DCT) to reduce the number of timesteps required for inference. DCT decomposes an image into a weighted sum of sinusoidal basis images. At each time step, the Hadamard product of the DCT coefficients and a single frequency base, taken in order, is given to an accumulator that generates spikes upon crossing a threshold. We use the proposed scheme to learn DCT-SNN, a low-latency deep SNN with leaky-integrate-and-fire neurons, trained using surrogate gradient descent based backpropagation. We achieve top-1 accuracy of 89.94%, 68.3% and 52.43% on CIFAR-10, CIFAR-100 and TinyImageNet, respectively using VGG architectures. Notably, DCT-SNN performs inference with 2-14X reduced latency compared to other state-of-the-art SNNs, while achieving comparable accuracy to their standard deep learning counterparts. The dimension of the transform allows us to control the number of timesteps required for inference. Additionally, we can trade-off accuracy with latency in a principled manner by dropping the highest frequency components during inference.", "published": "2020-10-05 05:55:34", "link": "http://arxiv.org/abs/2010.01795v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Is Information Theory Inherently a Theory of Causation?", "abstract": "Information theory gives rise to a novel method for causal skeleton discovery by expressing associations between variables as tensors. This tensor-based approach reduces the dimensionality of the data needed to test for conditional independence, e.g., for systems comprising three variables, the causal skeleton can be determined using pair-wise determined tensors. To arrive at this result, an additional information measure, path information, is proposed.", "published": "2020-10-05 11:41:27", "link": "http://arxiv.org/abs/2010.01932v4", "categories": ["stat.ML", "cs.IT", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning to Localise Automated Vehicles in Challenging Environments using Inertial Navigation Systems (INS)", "abstract": "An algorithm based on Artificial Neural Networks is proposed in this paper to improve the accuracy of Inertial Navigation System (INS)/ Global Navigation Satellite System (GNSS) integrated navigation during the absence of GNSS signals. The INS which can be used to continuously position autonomous vehicles during GNSS signal losses around urban canyons, bridges, tunnels and trees, suffers from unbounded exponential error drifts cascaded over time during the integration of the gyroscope and double integration of the accelerometer to displacement. More so, the error drift is characterised by a pattern dependent on time. The Input Delay Neural Network (IDNN) has the ability to learn the error drift over time [1] and possesses the quality of being more computationally efficient than the Recurrent Neural Network (RNN), Long Short-Term Memory, and the Gated Recurrent Unit Network. Furthermore published literatures focus on travel routes which do not take complex driving scenarios into consideration, we therefore investigate in this paper the performance of the proposed algorithm on challenging scenarios, such as hard brake, roundabouts, sharp cornering, successive left and right turns and quick changes in vehicular acceleration across numerous test sequences. The results obtained show that the Neural Network-based approaches are able to provide up to 89.55 % improvement on the INS displacement estimation and 93.35 % on the INS orientation rate estimation.", "published": "2020-10-05 22:09:44", "link": "http://arxiv.org/abs/2010.02363v1", "categories": ["eess.SP", "eess.SY"], "primary_category": "eess.SP"}
