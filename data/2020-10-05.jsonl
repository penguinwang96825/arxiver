{"title": "Transformer-Based Neural Text Generation with Syntactic Guidance", "abstract": "We study the problem of using (partial) constituency parse trees as syntactic\nguidance for controlled text generation. Existing approaches to this problem\nuse recurrent structures, which not only suffer from the long-term dependency\nproblem but also falls short in modeling the tree structure of the syntactic\nguidance. We propose to leverage the parallelism of Transformer to better\nincorporate parse trees. Our method first expands a partial template\nconstituency parse tree to a full-fledged parse tree tailored for the input\nsource text, and then uses the expanded tree to guide text generation. The\neffectiveness of our model in this process hinges upon two new attention\nmechanisms: 1) a path attention mechanism that forces one node to attend to\nonly other nodes located in its path in the syntax tree to better incorporate\nsyntax guidance; 2) a multi-encoder attention mechanism that allows the decoder\nto dynamically attend to information from multiple encoders. Our experiments in\nthe controlled paraphrasing task show that our method outperforms SOTA models\nboth semantically and syntactically, improving the best baseline's BLEU score\nfrom 11.83 to 26.27.", "published": "2020-10-05 01:33:58", "link": "http://arxiv.org/abs/2010.01737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Unsupervised Domain Adaptation with Adversarially Trained\n  Language Models", "abstract": "Recent work has shown the importance of adaptation of broad-coverage\ncontextualised embedding models on the domain of the target task of interest.\nCurrent self-supervised adaptation methods are simplistic, as the training\nsignal comes from a small percentage of \\emph{randomly} masked-out tokens. In\nthis paper, we show that careful masking strategies can bridge the knowledge\ngap of masked language models (MLMs) about the domains more effectively by\nallocating self-supervision where it is needed. Furthermore, we propose an\neffective training strategy by adversarially masking out those tokens which are\nharder to reconstruct by the underlying MLM. The adversarial objective leads to\na challenging combinatorial optimisation problem over \\emph{subsets} of tokens,\nwhich we tackle efficiently through relaxation to a variational lowerbound and\ndynamic programming. On six unsupervised domain adaptation tasks involving\nnamed entity recognition, our method strongly outperforms the random masking\nstrategy and achieves up to +1.64 F1 score improvements.", "published": "2020-10-05 01:49:47", "link": "http://arxiv.org/abs/2010.01739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Second-Order NLP Adversarial Examples", "abstract": "Adversarial example generation methods in NLP rely on models like language\nmodels or sentence encoders to determine if potential adversarial examples are\nvalid. In these methods, a valid adversarial example fools the model being\nattacked, and is determined to be semantically or syntactically valid by a\nsecond model. Research to date has counted all such examples as errors by the\nattacked model. We contend that these adversarial examples may not be flaws in\nthe attacked model, but flaws in the model that determines validity. We term\nsuch invalid inputs second-order adversarial examples. We propose the\nconstraint robustness curve and associated metric ACCS as tools for evaluating\nthe robustness of a constraint to second-order adversarial examples. To\ngenerate this curve, we design an adversarial attack to run directly on the\nsemantic similarity models. We test on two constraints, the Universal Sentence\nEncoder (USE) and BERTScore. Our findings indicate that such second-order\nexamples exist, but are typically less common than first-order adversarial\nexamples in state-of-the-art models. They also indicate that USE is effective\nas constraint on NLP adversarial examples, while BERTScore is nearly\nineffectual. Code for running the experiments in this paper is available at\nhttps://github.com/jxmorris12/second-order-adversarial-examples.", "published": "2020-10-05 04:32:38", "link": "http://arxiv.org/abs/2010.01770v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving AMR Parsing with Sequence-to-Sequence Pre-training", "abstract": "In the literature, the research on abstract meaning representation (AMR)\nparsing is much restricted by the size of human-curated dataset which is\ncritical to build an AMR parser with good performance. To alleviate such data\nsize restriction, pre-trained models have been drawing more and more attention\nin AMR parsing. However, previous pre-trained models, like BERT, are\nimplemented for general purpose which may not work as expected for the specific\ntask of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq)\nAMR parsing and propose a seq2seq pre-training approach to build pre-trained\nmodels in both single and joint way on three relevant tasks, i.e., machine\ntranslation, syntactic parsing, and AMR parsing itself. Moreover, we extend the\nvanilla fine-tuning method to a multi-task learning fine-tuning method that\noptimizes for the performance of AMR parsing while endeavors to preserve the\nresponse of pre-trained models. Extensive experimental results on two English\nbenchmark datasets show that both the single and joint pre-trained models\nsignificantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0),\nwhich reaches the state of the art. The result is very encouraging since we\nachieve this with seq2seq models rather than complex models. We make our code\nand model available at https://github.com/xdqkid/S2S-AMR-Parser.", "published": "2020-10-05 04:32:47", "link": "http://arxiv.org/abs/2010.01771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Reference-Free Summary Quality Evaluation via Contrastive\n  Learning", "abstract": "Evaluation of a document summarization system has been a critical factor to\nimpact the success of the summarization task. Previous approaches, such as\nROUGE, mainly consider the informativeness of the assessed summary and require\nhuman-generated references for each test summary. In this work, we propose to\nevaluate the summary qualities without reference summaries by unsupervised\ncontrastive learning. Specifically, we design a new metric which covers both\nlinguistic qualities and semantic informativeness based on BERT. To learn the\nmetric, for each summary, we construct different types of negative samples with\nrespect to different aspects of the summary qualities, and train our model with\na ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our\nnew evaluation method outperforms other metrics even without reference\nsummaries. Furthermore, we show that our method is general and transferable\nacross datasets.", "published": "2020-10-05 05:04:14", "link": "http://arxiv.org/abs/2010.01781v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pruning Redundant Mappings in Transformer Models via Spectral-Normalized\n  Identity Prior", "abstract": "Traditional (unstructured) pruning methods for a Transformer model focus on\nregularizing the individual weights by penalizing them toward zero. In this\nwork, we explore spectral-normalized identity priors (SNIP), a structured\npruning approach that penalizes an entire residual module in a Transformer\nmodel toward an identity mapping. Our method identifies and discards\nunimportant non-linear mappings in the residual connections by applying a\nthresholding operator on the function norm. It is applicable to any structured\nmodule, including a single attention head, an entire attention block, or a\nfeed-forward subnetwork. Furthermore, we introduce spectral normalization to\nstabilize the distribution of the post-activation values of the Transformer\nlayers, further improving the pruning effectiveness of the proposed\nmethodology. We conduct experiments with BERT on 5 GLUE benchmark tasks to\ndemonstrate that SNIP achieves effective pruning results while maintaining\ncomparable performance. Specifically, we improve the performance over the\nstate-of-the-art by 0.5 to 1.0% on average at 50% compression ratio.", "published": "2020-10-05 05:40:56", "link": "http://arxiv.org/abs/2010.01791v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Frailty of Universal POS Tags for Neural UD Parsers", "abstract": "We present an analysis on the effect UPOS accuracy has on parsing\nperformance. Results suggest that leveraging UPOS tags as features for neural\nparsers requires a prohibitively high tagging accuracy and that the use of gold\ntags offers a non-linear increase in performance, suggesting some sort of\nexceptionality. We also investigate what aspects of predicted UPOS tags impact\nparsing accuracy the most, highlighting some potentially meaningful linguistic\nfacets of the problem.", "published": "2020-10-05 07:40:35", "link": "http://arxiv.org/abs/2010.01830v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Regularizing Dialogue Generation by Imitating Implicit Scenarios", "abstract": "Human dialogues are scenario-based and appropriate responses generally relate\nto the latent context knowledge entailed by the specific scenario. To enable\nresponses that are more meaningful and context-specific, we propose to improve\ngenerative dialogue systems from the scenario perspective, where both dialogue\nhistory and future conversation are taken into account to implicitly\nreconstruct the scenario knowledge. More importantly, the conversation\nscenarios are further internalized using imitation learning framework, where\nthe conventional dialogue model that has no access to future conversations is\neffectively regularized by transferring the scenario knowledge contained in\nhierarchical supervising signals from the scenario-based dialogue model, so\nthat the future conversation is not required in actual inference. Extensive\nevaluations show that our approach significantly outperforms state-of-the-art\nbaselines on diversity and relevance, and expresses scenario-specific\nknowledge.", "published": "2020-10-05 10:10:19", "link": "http://arxiv.org/abs/2010.01893v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PUM at SemEval-2020 Task 12: Aggregation of Transformer-based models'\n  features for offensive language recognition", "abstract": "In this paper, we describe the PUM team's entry to the SemEval-2020 Task 12.\nCreating our solution involved leveraging two well-known pretrained models used\nin natural language processing: BERT and XLNet, which achieve state-of-the-art\nresults in multiple NLP tasks. The models were fine-tuned for each subtask\nseparately and features taken from their hidden layers were combined and fed\ninto a fully connected neural network. The model using aggregated Transformer\nfeatures can serve as a powerful tool for offensive language identification\nproblem. Our team was ranked 7th out of 40 in Sub-task C - Offense target\nidentification with 64.727% macro F1-score and 64th out of 85 in Sub-task A -\nOffensive language identification (89.726% F1-score).", "published": "2020-10-05 10:25:29", "link": "http://arxiv.org/abs/2010.01897v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse\n  Knowledge Graph", "abstract": "Multi-hop reasoning has been widely studied in recent years to seek an\neffective and interpretable method for knowledge graph (KG) completion. Most\nprevious reasoning methods are designed for dense KGs with enough paths between\nentities, but cannot work well on those sparse KGs that only contain sparse\npaths for reasoning. On the one hand, sparse KGs contain less information,\nwhich makes it difficult for the model to choose correct paths. On the other\nhand, the lack of evidential paths to target entities also makes the reasoning\nprocess difficult. To solve these problems, we propose a multi-hop reasoning\nmodel named DacKGR over sparse KGs, by applying novel dynamic anticipation and\ncompletion strategies: (1) The anticipation strategy utilizes the latent\nprediction of embedding-based models to make our model perform more potential\npath search over sparse KGs. (2) Based on the anticipation information, the\ncompletion strategy dynamically adds edges as additional actions during the\npath search, which further alleviates the sparseness problem of KGs. The\nexperimental results on five datasets sampled from Freebase, NELL and Wikidata\nshow that our method outperforms state-of-the-art baselines. Our codes and\ndatasets can be obtained from https://github.com/THU-KEG/DacKGR", "published": "2020-10-05 10:28:03", "link": "http://arxiv.org/abs/2010.01899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Context or Names? An Empirical Study on Neural Relation\n  Extraction", "abstract": "Neural models have achieved remarkable success on relation extraction (RE)\nbenchmarks. However, there is no clear understanding which type of information\naffects existing RE models to make decisions and how to further improve the\nperformance of these models. To this end, we empirically study the effect of\ntwo main information sources in text: textual context and entity mentions\n(names). We find that (i) while context is the main source to support the\npredictions, RE models also heavily rely on the information from entity\nmentions, most of which is type information, and (ii) existing datasets may\nleak shallow heuristics via entity mentions and thus contribute to the high\nperformance on RE benchmarks. Based on the analyses, we propose an\nentity-masked contrastive pre-training framework for RE to gain a deeper\nunderstanding on both textual context and type information while avoiding rote\nmemorization of entities or use of superficial cues in mentions. We carry out\nextensive experiments to support our views, and show that our framework can\nimprove the effectiveness and robustness of neural models in different RE\nscenarios. All the code and datasets are released at\nhttps://github.com/thunlp/RE-Context-or-Names.", "published": "2020-10-05 11:21:59", "link": "http://arxiv.org/abs/2010.01923v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "X-SRL: A Parallel Cross-Lingual Semantic Role Labeling Dataset", "abstract": "Even though SRL is researched for many languages, major improvements have\nmostly been obtained for English, for which more resources are available. In\nfact, existing multilingual SRL datasets contain disparate annotation styles or\ncome from different domains, hampering generalization in multilingual learning.\nIn this work, we propose a method to automatically construct an SRL corpus that\nis parallel in four languages: English, French, German, Spanish, with unified\npredicate and role annotations that are fully comparable across languages. We\napply high-quality machine translation to the English CoNLL-09 dataset and use\nmultilingual BERT to project its high-quality annotations to the target\nlanguages. We include human-validated test sets that we use to measure the\nprojection quality, and show that projection is denser and more precise than a\nstrong baseline. Finally, we train different SOTA models on our novel corpus\nfor mono- and multilingual SRL, showing that the multilingual annotations\nimprove performance especially for the weaker languages.", "published": "2020-10-05 13:34:20", "link": "http://arxiv.org/abs/2010.01998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Fully Hyperbolic Neural Model for Hierarchical Multi-Class\n  Classification", "abstract": "Label inventories for fine-grained entity typing have grown in size and\ncomplexity. Nonetheless, they exhibit a hierarchical structure. Hyperbolic\nspaces offer a mathematically appealing approach for learning hierarchical\nrepresentations of symbolic data. However, it is not clear how to integrate\nhyperbolic components into downstream tasks. This is the first work that\nproposes a fully hyperbolic model for multi-class multi-label classification,\nwhich performs all operations in hyperbolic space. We evaluate the proposed\nmodel on two challenging datasets and compare to different baselines that\noperate under Euclidean assumptions. Our hyperbolic model infers the latent\nhierarchy from the class distribution, captures implicit hyponymic relations in\nthe inventory, and shows performance on par with state-of-the-art methods on\nfine-grained classification with remarkable reduction of the parameter size. A\nthorough analysis sheds light on the impact of each component in the final\nprediction and showcases its ease of integration with Euclidean layers.", "published": "2020-10-05 14:42:56", "link": "http://arxiv.org/abs/2010.02053v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Gauravarora@HASOC-Dravidian-CodeMix-FIRE2020: Pre-training ULMFiT on\n  Synthetically Generated Code-Mixed Data for Hate Speech Detection", "abstract": "This paper describes the system submitted to Dravidian-Codemix-HASOC2020:\nHate Speech and Offensive Content Identification in Dravidian languages\n(Tamil-English and Malayalam-English). The task aims to identify offensive\nlanguage in code-mixed dataset of comments/posts in Dravidian languages\ncollected from social media. We participated in both Sub-task A, which aims to\nidentify offensive content in mixed-script (mixture of Native and Roman script)\nand Sub-task B, which aims to identify offensive content in Roman script, for\nDravidian languages. In order to address these tasks, we proposed pre-training\nULMFiT on synthetically generated code-mixed data, generated by modelling\ncode-mixed data generation as a Markov process using Markov chains. Our model\nachieved 0.88 weighted F1-score for code-mixed Tamil-English language in\nSub-task B and got 2nd rank on the leader-board. Additionally, our model\nachieved 0.91 weighted F1-score (4th Rank) for mixed-script Malayalam-English\nin Sub-task A and 0.74 weighted F1-score (5th Rank) for code-mixed\nMalayalam-English language in Sub-task B.", "published": "2020-10-05 15:25:47", "link": "http://arxiv.org/abs/2010.02094v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PublishInCovid19 at WNUT 2020 Shared Task-1: Entity Recognition in Wet\n  Lab Protocols using Structured Learning Ensemble and Contextualised\n  Embeddings", "abstract": "In this paper, we describe the approach that we employed to address the task\nof Entity Recognition over Wet Lab Protocols -- a shared task in EMNLP\nWNUT-2020 Workshop. Our approach is composed of two phases. In the first phase,\nwe experiment with various contextualised word embeddings (like Flair,\nBERT-based) and a BiLSTM-CRF model to arrive at the best-performing\narchitecture. In the second phase, we create an ensemble composed of eleven\nBiLSTM-CRF models. The individual models are trained on random train-validation\nsplits of the complete dataset. Here, we also experiment with different output\nmerging schemes, including Majority Voting and Structured Learning Ensembling\n(SLE). Our final submission achieved a micro F1-score of 0.8175 and 0.7757 for\nthe partial and exact match of the entity spans, respectively. We were ranked\nfirst and second, in terms of partial and exact match, respectively.", "published": "2020-10-05 16:45:30", "link": "http://arxiv.org/abs/2010.02142v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speakers Fill Lexical Semantic Gaps with Context", "abstract": "Lexical ambiguity is widespread in language, allowing for the reuse of\neconomical word forms and therefore making language more efficient. If\nambiguous words cannot be disambiguated from context, however, this gain in\nefficiency might make language less clear -- resulting in frequent\nmiscommunication. For a language to be clear and efficiently encoded, we posit\nthat the lexical ambiguity of a word type should correlate with how much\ninformation context provides about it, on average. To investigate whether this\nis the case, we operationalise the lexical ambiguity of a word as the entropy\nof meanings it can take, and provide two ways to estimate this -- one which\nrequires human annotation (using WordNet), and one which does not (using BERT),\nmaking it readily applicable to a large number of languages. We validate these\nmeasures by showing that, on six high-resource languages, there are significant\nPearson correlations between our BERT-based estimate of ambiguity and the\nnumber of synonyms a word has in WordNet (e.g. $\\rho = 0.40$ in English). We\nthen test our main hypothesis -- that a word's lexical ambiguity should\nnegatively correlate with its contextual uncertainty -- and find significant\ncorrelations on all 18 typologically diverse languages we analyse. This\nsuggests that, in the presence of ambiguity, speakers compensate by making\ncontexts more informative.", "published": "2020-10-05 17:19:10", "link": "http://arxiv.org/abs/2010.02172v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Helpfulness of Learning Materials with Inference-Based\n  Learner-Like Agent", "abstract": "Many English-as-a-second language learners have trouble using near-synonym\nwords (e.g., small vs.little; briefly vs.shortly) correctly, and often look for\nexample sentences to learn how two nearly synonymous terms differ. Prior work\nuses hand-crafted scores to recommend sentences but has difficulty in adopting\nsuch scores to all the near-synonyms as near-synonyms differ in various ways.\nWe notice that the helpfulness of the learning material would reflect on the\nlearners' performance. Thus, we propose the inference-based learner-like agent\nto mimic learner behavior and identify good learning materials by examining the\nagent's performance. To enable the agent to behave like a learner, we leverage\nentailment modeling's capability of inferring answers from the provided\nmaterials. Experimental results show that the proposed agent is equipped with\ngood learner-like behavior to achieve the best performance in both\nfill-in-the-blank (FITB) and good example sentence selection tasks. We further\nconduct a classroom user study with college ESL learners. The results of the\nuser study show that the proposed agent can find out example sentences that\nhelp students learn more easily and efficiently. Compared to other models, the\nproposed agent improves the score of more than 17% of students after learning.", "published": "2020-10-05 17:24:57", "link": "http://arxiv.org/abs/2010.02179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-training Improves Pre-training for Natural Language Understanding", "abstract": "Unsupervised pre-training has led to much recent progress in natural language\nunderstanding. In this paper, we study self-training as another way to leverage\nunlabeled data through semi-supervised learning. To obtain additional data for\na specific task, we introduce SentAugment, a data augmentation method which\ncomputes task-specific query embeddings from labeled data to retrieve sentences\nfrom a bank of billions of unlabeled sentences crawled from the web. Unlike\nprevious semi-supervised methods, our approach does not require in-domain\nunlabeled data and is therefore more generally applicable. Experiments show\nthat self-training is complementary to strong RoBERTa baselines on a variety of\ntasks. Our augmentation approach leads to scalable and effective self-training\nwith improvements of up to 2.6% on standard text classification benchmarks.\nFinally, we also show strong gains on knowledge-distillation and few-shot\nlearning.", "published": "2020-10-05 17:52:25", "link": "http://arxiv.org/abs/2010.02194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acrostic Poem Generation", "abstract": "We propose a new task in the area of computational creativity: acrostic poem\ngeneration in English. Acrostic poems are poems that contain a hidden message;\ntypically, the first letter of each line spells out a word or short phrase. We\ndefine the task as a generation task with multiple constraints: given an input\nword, 1) the initial letters of each line should spell out the provided word,\n2) the poem's semantics should also relate to it, and 3) the poem should\nconform to a rhyming scheme. We further provide a baseline model for the task,\nwhich consists of a conditional neural language model in combination with a\nneural rhyming model. Since no dedicated datasets for acrostic poem generation\nexist, we create training data for our task by first training a separate topic\nprediction model on a small set of topic-annotated poems and then predicting\ntopics for additional poems. Our experiments show that the acrostic poems\ngenerated by our baseline are received well by humans and do not lose much\nquality due to the additional constraints. Last, we confirm that poems\ngenerated by our model are indeed closely related to the provided prompts, and\nthat pretraining on Wikipedia can boost performance.", "published": "2020-10-05 18:00:15", "link": "http://arxiv.org/abs/2010.02239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPLAT: Speech-Language Joint Pre-Training for Spoken Language\n  Understanding", "abstract": "Spoken language understanding (SLU) requires a model to analyze input\nacoustic signal to understand its linguistic content and make predictions. To\nboost the models' performance, various pre-training methods have been proposed\nto learn rich representations from large-scale unannotated speech and text.\nHowever, the inherent disparities between the two modalities necessitate a\nmutual analysis. In this paper, we propose a novel semi-supervised learning\nframework, SPLAT, to jointly pre-train the speech and language modules. Besides\nconducting a self-supervised masked language modeling task on the two\nindividual modules using unpaired speech and text, SPLAT aligns representations\nfrom the two modules in a shared latent space using a small amount of paired\nspeech and text. Thus, during fine-tuning, the speech module alone can produce\nrepresentations carrying both acoustic information and contextual semantic\nknowledge of an input acoustic signal. Experimental results verify the\neffectiveness of our approach on various SLU tasks. For example, SPLAT improves\nthe previous state-of-the-art performance on the Spoken SQuAD dataset by more\nthan 10%.", "published": "2020-10-05 19:29:49", "link": "http://arxiv.org/abs/2010.02295v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAIR: Planning and Iterative Refinement in Pre-trained Transformers for\n  Long Text Generation", "abstract": "Pre-trained Transformers have enabled impressive breakthroughs in generating\nlong and fluent text, yet their outputs are often \"rambling\" without coherently\narranged content. In this work, we present a novel content-controlled text\ngeneration framework, PAIR, with planning and iterative refinement, which is\nbuilt upon a large model, BART. We first adapt the BERT model to automatically\nconstruct the content plans, consisting of keyphrase assignments and their\ncorresponding sentence-level positions. The BART model is employed for\ngeneration without modifying its structure. We then propose a refinement\nalgorithm to gradually enhance the generation quality within the\nsequence-to-sequence framework. Evaluation with automatic metrics shows that\nadding planning consistently improves the generation quality on three distinct\ndomains, with an average of 20 BLEU points and 12 METEOR points improvements.\nIn addition, human judges rate our system outputs to be more relevant and\ncoherent than comparisons without planning.", "published": "2020-10-05 19:45:03", "link": "http://arxiv.org/abs/2010.02301v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational Document Prediction to Assist Customer Care Agents", "abstract": "A frequent pattern in customer care conversations is the agents responding\nwith appropriate webpage URLs that address users' needs. We study the task of\npredicting the documents that customer care agents can use to facilitate users'\nneeds. We also introduce a new public dataset which supports the aforementioned\nproblem. Using this dataset and two others, we investigate state-of-the art\ndeep learning (DL) and information retrieval (IR) models for the task.\nAdditionally, we analyze the practicality of such systems in terms of inference\ntime complexity. Our show that an hybrid IR+DL approach provides the best of\nboth worlds.", "published": "2020-10-05 19:53:41", "link": "http://arxiv.org/abs/2010.02305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis for Reinforcement Learning", "abstract": "While reinforcement learning (RL) has been successful in natural language\nprocessing (NLP) domains such as dialogue generation and text-based games, it\ntypically faces the problem of sparse rewards that leads to slow or no\nconvergence. Traditional methods that use text descriptions to extract only a\nstate representation ignore the feedback inherently present in them. In\ntext-based games, for example, descriptions like \"Good Job! You ate the food}\"\nindicate progress, and descriptions like \"You entered a new room\" indicate\nexploration. Positive and negative cues like these can be converted to rewards\nthrough sentiment analysis. This technique converts the sparse reward problem\ninto a dense one, which is easier to solve. Furthermore, this can enable\nreinforcement learning without rewards, in which the agent learns entirely from\nthese intrinsic sentiment rewards. This framework is similar to intrinsic\nmotivation, where the environment does not necessarily provide the rewards, but\nthe agent analyzes and realizes them by itself. We find that providing dense\nrewards in text-based games using sentiment analysis improves performance under\nsome conditions.", "published": "2020-10-05 20:15:51", "link": "http://arxiv.org/abs/2010.02316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial\n  Text Generation", "abstract": "NLP models are shown to suffer from robustness issues, i.e., a model's\nprediction can be easily changed under small perturbations to the input. In\nthis work, we present a Controlled Adversarial Text Generation (CAT-Gen) model\nthat, given an input text, generates adversarial texts through controllable\nattributes that are known to be invariant to task labels. For example, in order\nto attack a model for sentiment classification over product reviews, we can use\nthe product categories as the controllable attribute which would not change the\nsentiment of the reviews. Experiments on real-world NLP datasets demonstrate\nthat our method can generate more diverse and fluent adversarial texts,\ncompared to many existing adversarial text generation approaches. We further\nuse our generated adversarial examples to improve models through adversarial\ntraining, and we demonstrate that our generated attacks are more robust against\nmodel re-training and different model architectures.", "published": "2020-10-05 21:07:45", "link": "http://arxiv.org/abs/2010.02338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inference Strategies for Machine Translation with Conditional Masking", "abstract": "Conditional masked language model (CMLM) training has proven successful for\nnon-autoregressive and semi-autoregressive sequence generation tasks, such as\nmachine translation. Given a trained CMLM, however, it is not clear what the\nbest inference strategy is. We formulate masked inference as a factorization of\nconditional probabilities of partial sequences, show that this does not harm\nperformance, and investigate a number of simple heuristics motivated by this\nperspective. We identify a thresholding strategy that has advantages over the\nstandard \"mask-predict\" algorithm, and provide analyses of its behavior on\nmachine translation tasks.", "published": "2020-10-05 21:50:09", "link": "http://arxiv.org/abs/2010.02352v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating representations of verb bias in neural language models", "abstract": "Languages typically provide more than one grammatical construction to express\ncertain types of messages. A speaker's choice of construction is known to\ndepend on multiple factors, including the choice of main verb -- a phenomenon\nknown as \\emph{verb bias}. Here we introduce DAIS, a large benchmark dataset\ncontaining 50K human judgments for 5K distinct sentence pairs in the English\ndative alternation. This dataset includes 200 unique verbs and systematically\nvaries the definiteness and length of arguments. We use this dataset, as well\nas an existing corpus of naturally occurring data, to evaluate how well recent\nneural language models capture human preferences. Results show that larger\nmodels perform better than smaller models, and transformer architectures (e.g.\nGPT-2) tend to out-perform recurrent architectures (e.g. LSTMs) even under\ncomparable parameter and training settings. Additional analyses of internal\nfeature representations suggest that transformers may better integrate specific\nlexical information with grammatical constructions.", "published": "2020-10-05 22:39:08", "link": "http://arxiv.org/abs/2010.02375v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Grounding for Multimodal Speech Recognition", "abstract": "Multimodal automatic speech recognition systems integrate information from\nimages to improve speech recognition quality, by grounding the speech in the\nvisual context. While visual signals have been shown to be useful for\nrecovering entities that have been masked in the audio, these models should be\ncapable of recovering a broader range of word types. Existing systems rely on\nglobal visual features that represent the entire image, but localizing the\nrelevant regions of the image will make it possible to recover a larger set of\nwords, such as adjectives and verbs. In this paper, we propose a model that\nuses finer-grained visual information from different parts of the image, using\nautomatic object proposals. In experiments on the Flickr8K Audio Captions\nCorpus, we find that our model improves over approaches that use global visual\nfeatures, that the proposals enable the model to recover entities and other\nrelated words, such as adjectives, and that improvements are due to the model's\nability to localize the correct proposals.", "published": "2020-10-05 23:06:24", "link": "http://arxiv.org/abs/2010.02384v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis for Roman Urdu Text over Social Media, a Comparative\n  Study", "abstract": "In present century, data volume is increasing enormously. The data could be\nin form for image, text, voice, and video. One factor in this huge growth of\ndata is usage of social media where everyone is posting data on daily basis\nduring chatting, exchanging information, and uploading their personal and\nofficial credential. Research of sentiments seeks to uncover abstract knowledge\nin Published texts in which users communicate their emotions and thoughts about\nshared content, including blogs, news and social networks. Roman Urdu is the\none of most dominant language on social networks in Pakistan and India. Roman\nUrdu is among the varieties of the world's third largest Urdu language but yet\nnot sufficient work has been done in this language. In this article we\naddressed the prior concepts and strategies used to examine the sentiment of\nthe roman Urdu text and reported their results as well.", "published": "2020-10-05 16:19:00", "link": "http://arxiv.org/abs/2010.16408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MCMH: Learning Multi-Chain Multi-Hop Rules for Knowledge Graph Reasoning", "abstract": "Multi-hop reasoning approaches over knowledge graphs infer a missing\nrelationship between entities with a multi-hop rule, which corresponds to a\nchain of relationships. We extend existing works to consider a generalized form\nof multi-hop rules, where each rule is a set of relation chains. To learn such\ngeneralized rules efficiently, we propose a two-step approach that first\nselects a small set of relation chains as a rule and then evaluates the\nconfidence of the target relationship by jointly scoring the selected chains. A\ngame-theoretical framework is proposed to this end to simultaneously optimize\nthe rule selection and prediction steps. Empirical results show that our\nmulti-chain multi-hop (MCMH) rules result in superior results compared to the\nstandard single-chain approaches, justifying both our formulation of\ngeneralized rules and the effectiveness of the proposed learning framework.", "published": "2020-10-05 01:32:20", "link": "http://arxiv.org/abs/2010.01735v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Effects of Knowledge-Augmented Data in Word Embeddings", "abstract": "This paper investigates techniques for knowledge injection into word\nembeddings learned from large corpora of unannotated data. These\nrepresentations are trained with word cooccurrence statistics and do not\ncommonly exploit syntactic and semantic information from linguistic knowledge\nbases, which potentially limits their transferability to domains with differing\nlanguage distributions or usages. We propose a novel approach for linguistic\nknowledge injection through data augmentation to learn word embeddings that\nenforce semantic relationships from the data, and systematically evaluate the\nimpact it has on the resulting representations. We show our knowledge\naugmentation approach improves the intrinsic characteristics of the learned\nembeddings while not significantly altering their results on a downstream text\nclassification task.", "published": "2020-10-05 02:14:13", "link": "http://arxiv.org/abs/2010.01745v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Corpora Evaluation and System Bias Detection in Multi-document\n  Summarization", "abstract": "Multi-document summarization (MDS) is the task of reflecting key points from\nany set of documents into a concise text paragraph. In the past, it has been\nused to aggregate news, tweets, product reviews, etc. from various sources.\nOwing to no standard definition of the task, we encounter a plethora of\ndatasets with varying levels of overlap and conflict between participating\ndocuments. There is also no standard regarding what constitutes summary\ninformation in MDS. Adding to the challenge is the fact that new systems report\nresults on a set of chosen datasets, which might not correlate with their\nperformance on the other datasets. In this paper, we study this heterogeneous\ntask with the help of a few widely used MDS corpora and a suite of\nstate-of-the-art models. We make an attempt to quantify the quality of\nsummarization corpus and prescribe a list of points to consider while proposing\na new MDS corpus. Next, we analyze the reason behind the absence of an MDS\nsystem which achieves superior performance across all corpora. We then observe\nthe extent to which system metrics are influenced, and bias is propagated due\nto corpus properties. The scripts to reproduce the experiments in this work are\navailable at https://github.com/LCS2-IIITD/summarization_bias.git.", "published": "2020-10-05 05:25:43", "link": "http://arxiv.org/abs/2010.01786v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Linguistic Profiling of a Neural Language Model", "abstract": "In this paper we investigate the linguistic knowledge learned by a Neural\nLanguage Model (NLM) before and after a fine-tuning process and how this\nknowledge affects its predictions during several classification problems. We\nuse a wide set of probing tasks, each of which corresponds to a distinct\nsentence-level feature extracted from different levels of linguistic\nannotation. We show that BERT is able to encode a wide range of linguistic\ncharacteristics, but it tends to lose this information when trained on specific\ndownstream tasks. We also find that BERT's capacity to encode different kind of\nlinguistic properties has a positive influence on its predictions: the more it\nstores readable linguistic information of a sentence, the higher will be its\ncapacity of predicting the expected label assigned to that sentence.", "published": "2020-10-05 09:09:01", "link": "http://arxiv.org/abs/2010.01869v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Pilot Study of Text-to-SQL Semantic Parsing for Vietnamese", "abstract": "Semantic parsing is an important NLP task. However, Vietnamese is a\nlow-resource language in this research area. In this paper, we present the\nfirst public large-scale Text-to-SQL semantic parsing dataset for Vietnamese.\nWe extend and evaluate two strong semantic parsing baselines EditSQL (Zhang et\nal., 2019) and IRNet (Guo et al., 2019) on our dataset. We compare the two\nbaselines with key configurations and find that: automatic Vietnamese word\nsegmentation improves the parsing results of both baselines; the normalized\npointwise mutual information (NPMI) score (Bouma, 2009) is useful for schema\nlinking; latent syntactic features extracted from a neural dependency parser\nfor Vietnamese also improve the results; and the monolingual language model\nPhoBERT for Vietnamese (Nguyen and Nguyen, 2020) helps produce higher\nperformances than the recent best multilingual language model XLM-R (Conneau et\nal., 2020).", "published": "2020-10-05 09:54:51", "link": "http://arxiv.org/abs/2010.01891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Semantic Capacity of Terms", "abstract": "We introduce and study semantic capacity of terms. For example, the semantic\ncapacity of artificial intelligence is higher than that of linear regression\nsince artificial intelligence possesses a broader meaning scope. Understanding\nsemantic capacity of terms will help many downstream tasks in natural language\nprocessing. For this purpose, we propose a two-step model to investigate\nsemantic capacity of terms, which takes a large text corpus as input and can\nevaluate semantic capacity of terms if the text corpus can provide enough\nco-occurrence information of terms. Extensive experiments in three fields\ndemonstrate the effectiveness and rationality of our model compared with\nwell-designed baselines and human-level evaluations.", "published": "2020-10-05 10:26:36", "link": "http://arxiv.org/abs/2010.01898v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Grammar of Emergent Languages", "abstract": "In this paper, we consider the syntactic properties of languages emerged in\nreferential games, using unsupervised grammar induction (UGI) techniques\noriginally designed to analyse natural language. We show that the considered\nUGI techniques are appropriate to analyse emergent languages and we then study\nif the languages that emerge in a typical referential game setup exhibit\nsyntactic structure, and to what extent this depends on the maximum message\nlength and number of symbols that the agents are allowed to use. Our\nexperiments demonstrate that a certain message length and vocabulary size are\nrequired for structure to emerge, but they also illustrate that more\nsophisticated game scenarios are required to obtain syntactic properties more\nakin to those observed in human language. We argue that UGI techniques should\nbe part of the standard toolkit for analysing emergent languages and release a\ncomprehensive library to facilitate such analysis for future researchers.", "published": "2020-10-05 15:06:27", "link": "http://arxiv.org/abs/2010.02069v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Spot The Bot: A Robust and Efficient Framework for the Evaluation of\n  Conversational Dialogue Systems", "abstract": "The lack of time-efficient and reliable evaluation methods hamper the\ndevelopment of conversational dialogue systems (chatbots). Evaluations\nrequiring humans to converse with chatbots are time and cost-intensive, put\nhigh cognitive demands on the human judges, and yield low-quality results. In\nthis work, we introduce \\emph{Spot The Bot}, a cost-efficient and robust\nevaluation framework that replaces human-bot conversations with conversations\nbetween bots. Human judges then only annotate for each entity in a conversation\nwhether they think it is human or not (assuming there are humans participants\nin these conversations). These annotations then allow us to rank chatbots\nregarding their ability to mimic the conversational behavior of humans. Since\nwe expect that all bots are eventually recognized as such, we incorporate a\nmetric that measures which chatbot can uphold human-like behavior the longest,\ni.e., \\emph{Survival Analysis}. This metric has the ability to correlate a\nbot's performance to certain of its characteristics (e.g., \\ fluency or\nsensibleness), yielding interpretable results. The comparably low cost of our\nframework allows for frequent evaluations of chatbots during their evaluation\ncycle. We empirically validate our claims by applying \\emph{Spot The Bot} to\nthree domains, evaluating several state-of-the-art chatbots, and drawing\ncomparisons to related work. The framework is released as a ready-to-use tool.", "published": "2020-10-05 16:37:52", "link": "http://arxiv.org/abs/2010.02140v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Pareto Probing: Trading Off Accuracy for Complexity", "abstract": "The question of how to probe contextual word representations for linguistic\nstructure in a way that is both principled and useful has seen significant\nattention recently in the NLP literature. In our contribution to this\ndiscussion, we argue for a probe metric that reflects the fundamental trade-off\nbetween probe complexity and performance: the Pareto hypervolume. To measure\ncomplexity, we present a number of parametric and non-parametric metrics. Our\nexperiments using Pareto hypervolume as an evaluation metric show that probes\noften do not conform to our expectations -- e.g., why should the non-contextual\nfastText representations encode more morpho-syntactic information than the\ncontextual BERT representations? These results suggest that common, simplistic\nprobing tasks, such as part-of-speech labeling and dependency arc labeling, are\ninadequate to evaluate the linguistic structure encoded in contextual word\nrepresentations. This leads us to propose full dependency parsing as a probing\ntask. In support of our suggestion that harder probing tasks are necessary, our\nexperiments with dependency parsing reveal a wide gap in syntactic knowledge\nbetween contextual and non-contextual representations.", "published": "2020-10-05 17:27:31", "link": "http://arxiv.org/abs/2010.02180v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Generalize for Sequential Decision Making", "abstract": "We consider problems of making sequences of decisions to accomplish tasks,\ninteracting via the medium of language. These problems are often tackled with\nreinforcement learning approaches. We find that these models do not generalize\nwell when applied to novel task domains. However, the large amount of\ncomputation necessary to adequately train and explore the search space of\nsequential decision making, under a reinforcement learning paradigm, precludes\nthe inclusion of large contextualized language models, which might otherwise\nenable the desired generalization ability. We introduce a teacher-student\nimitation learning methodology and a means of converting a reinforcement\nlearning model into a natural language understanding model. Together, these\nmethodologies enable the introduction of contextualized language models into\nthe sequential decision making problem space. We show that models can learn\nfaster and generalize more, leveraging both the imitation learning and the\nreformulation. Our models exceed teacher performance on various held-out\ndecision problems, by up to 7% on in-domain problems and 24% on out-of-domain\nproblems.", "published": "2020-10-05 18:00:03", "link": "http://arxiv.org/abs/2010.02229v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedFilter: Improving Extraction of Task-relevant Utterances from\n  Doctor-Patient Conversations through Integration of Discourse Structure and\n  Ontological Knowledge", "abstract": "Information extraction from conversational data is particularly challenging\nbecause the task-centric nature of conversation allows for effective\ncommunication of implicit information by humans, but is challenging for\nmachines. The challenges may differ between utterances depending on the role of\nthe speaker within the conversation, especially when relevant expertise is\ndistributed asymmetrically across roles. Further, the challenges may also\nincrease over the conversation as more shared context is built up through\ninformation communicated implicitly earlier in the dialogue. In this paper, we\npropose the novel modeling approach MedFilter, which addresses these insights\nin order to increase performance at identifying and categorizing task-relevant\nutterances, and in so doing, positively impacts performance at a downstream\ninformation extraction task. We evaluate this approach on a corpus of nearly\n7,000 doctor-patient conversations where MedFilter is used to identify\nmedically relevant contributions to the discussion (achieving a 10% improvement\nover SOTA baselines in terms of area under the PR curve). Identifying\ntask-relevant utterances benefits downstream medical processing, achieving\nimprovements of 15%, 105%, and 23% respectively for the extraction of symptoms,\nmedications, and complaints.", "published": "2020-10-05 18:01:38", "link": "http://arxiv.org/abs/2010.02246v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Ensemble Approach for Automatic Structuring of Radiology Reports", "abstract": "Automatic structuring of electronic medical records is of high demand for\nclinical workflow solutions to facilitate extraction, storage, and querying of\npatient care information. However, developing a scalable solution is extremely\nchallenging, specifically for radiology reports, as most healthcare institutes\nuse either no template or department/institute specific templates. Moreover,\nradiologists' reporting style varies from one to another as sentences are\ntelegraphic and do not follow general English grammar rules. We present an\nensemble method that consolidates the predictions of three models, capturing\nvarious attributes of textual information for automatic labeling of sentences\nwith section labels. These three models are: 1) Focus Sentence model, capturing\ncontext of the target sentence; 2) Surrounding Context model, capturing the\nneighboring context of the target sentence; and finally, 3) Formatting/Layout\nmodel, aimed at learning report formatting cues. We utilize Bi-directional\nLSTMs, followed by sentence encoders, to acquire the context. Furthermore, we\ndefine several features that incorporate the structure of reports. We compare\nour proposed approach against multiple baselines and state-of-the-art\napproaches on a proprietary dataset as well as 100 manually annotated radiology\nnotes from the MIMIC-III dataset, which we are making publicly available. Our\nproposed approach significantly outperforms other approaches by achieving 97.1%\naccuracy.", "published": "2020-10-05 18:11:23", "link": "http://arxiv.org/abs/2010.02256v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effects of Naturalistic Variation in Goal-Oriented Dialog", "abstract": "Existing benchmarks used to evaluate the performance of end-to-end neural\ndialog systems lack a key component: natural variation present in human\nconversations. Most datasets are constructed through crowdsourcing, where the\ncrowd workers follow a fixed template of instructions while enacting the role\nof a user/agent. This results in straight-forward, somewhat routine, and mostly\ntrouble-free conversations, as crowd workers do not think to represent the full\nrange of actions that occur naturally with real users. In this work, we\ninvestigate the impact of naturalistic variation on two goal-oriented datasets:\nbAbI dialog task and Stanford Multi-Domain Dataset (SMD). We also propose new\nand more effective testbeds for both datasets, by introducing naturalistic\nvariation by the user. We observe that there is a significant drop in\nperformance (more than 60% in Ent. F1 on SMD and 85% in per-dialog accuracy on\nbAbI task) of recent state-of-the-art end-to-end neural methods such as BossNet\nand GLMP on both datasets.", "published": "2020-10-05 18:13:45", "link": "http://arxiv.org/abs/2010.02260v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation", "abstract": "Data-to-text generation has recently attracted substantial interests due to\nits wide applications. Existing methods have shown impressive performance on an\narray of tasks. However, they rely on a significant amount of labeled data for\neach task, which is costly to acquire and thus limits their application to new\ntasks and domains. In this paper, we propose to leverage pre-training and\ntransfer learning to address this issue. We propose a knowledge-grounded\npre-training (KGPT), which consists of two parts, 1) a general\nknowledge-grounded generation model to generate knowledge-enriched text. 2) a\npre-training paradigm on a massive knowledge-grounded text corpus crawled from\nthe web. The pre-trained model can be fine-tuned on various data-to-text\ngeneration tasks to generate task-specific text. We adopt three settings,\nnamely fully-supervised, zero-shot, few-shot to evaluate its effectiveness.\nUnder the fully-supervised setting, our model can achieve remarkable gains over\nthe known baselines. Under zero-shot setting, our model without seeing any\nexamples achieves over 30 ROUGE-L on WebNLG while all other baselines fail.\nUnder the few-shot setting, our model only needs about one-fifteenth as many\nlabeled examples to achieve the same level of performance as baseline models.\nThese experiments consistently prove the strong generalization ability of our\nproposed framework https://github.com/wenhuchen/KGPT.", "published": "2020-10-05 19:59:05", "link": "http://arxiv.org/abs/2010.02307v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SeqMix: Augmenting Active Sequence Labeling via Sequence Mixup", "abstract": "Active learning is an important technique for low-resource sequence labeling\ntasks. However, current active sequence labeling methods use the queried\nsamples alone in each iteration, which is an inefficient way of leveraging\nhuman annotations. We propose a simple but effective data augmentation method\nto improve the label efficiency of active sequence labeling. Our method,\nSeqMix, simply augments the queried samples by generating extra labeled\nsequences in each iteration. The key difficulty is to generate plausible\nsequences along with token-level labels. In SeqMix, we address this challenge\nby performing mixup for both sequences and token-level labels of the queried\nsamples. Furthermore, we design a discriminator during sequence mixup, which\njudges whether the generated sequences are plausible or not. Our experiments on\nNamed Entity Recognition and Event Detection tasks show that SeqMix can improve\nthe standard active sequence labeling method by $2.27\\%$--$3.75\\%$ in terms of\n$F_1$ scores. The code and data for SeqMix can be found at\nhttps://github.com/rz-zhang/SeqMix", "published": "2020-10-05 20:27:14", "link": "http://arxiv.org/abs/2010.02322v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "We Don't Speak the Same Language: Interpreting Polarization through\n  Machine Translation", "abstract": "Polarization among US political parties, media and elites is a widely studied\ntopic. Prominent lines of prior research across multiple disciplines have\nobserved and analyzed growing polarization in social media. In this paper, we\npresent a new methodology that offers a fresh perspective on interpreting\npolarization through the lens of machine translation. With a novel proposition\nthat two sub-communities are speaking in two different \\emph{languages}, we\ndemonstrate that modern machine translation methods can provide a simple yet\npowerful and interpretable framework to understand the differences between two\n(or more) large-scale social media discussion data sets at the granularity of\nwords. Via a substantial corpus of 86.6 million comments by 6.5 million users\non over 200,000 news videos hosted by YouTube channels of four prominent US\nnews networks, we demonstrate that simple word-level and phrase-level\ntranslation pairs can reveal deep insights into the current political divide --\nwhat is \\emph{black lives matter} to one can be \\emph{all lives matter} to the\nother.", "published": "2020-10-05 21:16:30", "link": "http://arxiv.org/abs/2010.02339v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Understanding the Mechanics of SPIGOT: Surrogate Gradients for Latent\n  Structure Learning", "abstract": "Latent structure models are a powerful tool for modeling language data: they\ncan mitigate the error propagation and annotation bottleneck in pipeline\nsystems, while simultaneously uncovering linguistic insights about the data.\nOne challenge with end-to-end training of these models is the argmax operation,\nwhich has null gradient. In this paper, we focus on surrogate gradients, a\npopular strategy to deal with this problem. We explore latent structure\nlearning through the angle of pulling back the downstream learning objective.\nIn this paradigm, we discover a principled motivation for both the\nstraight-through estimator (STE) as well as the recently-proposed SPIGOT - a\nvariant of STE for structured models. Our perspective leads to new algorithms\nin the same family. We empirically compare the known and the novel pulled-back\nestimators against the popular alternatives, yielding new insight for\npractitioners and revealing intriguing failure cases.", "published": "2020-10-05 21:56:00", "link": "http://arxiv.org/abs/2010.02357v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interactive Fiction Game Playing as Multi-Paragraph Reading\n  Comprehension with Reinforcement Learning", "abstract": "Interactive Fiction (IF) games with real human-written natural language texts\nprovide a new natural evaluation for language understanding techniques. In\ncontrast to previous text games with mostly synthetic texts, IF games pose\nlanguage understanding challenges on the human-written textual descriptions of\ndiverse and sophisticated game worlds and language generation challenges on the\naction command generation from less restricted combinatorial space. We take a\nnovel perspective of IF game solving and re-formulate it as Multi-Passage\nReading Comprehension (MPRC) tasks. Our approaches utilize the context-query\nattention mechanisms and the structured prediction in MPRC to efficiently\ngenerate and evaluate action outputs and apply an object-centric historical\nobservation retrieval strategy to mitigate the partial observability of the\ntextual observations. Extensive experiments on the recent IF benchmark\n(Jericho) demonstrate clear advantages of our approaches achieving high winning\nrates and low data requirements compared to all previous approaches. Our source\ncode is available at: https://github.com/XiaoxiaoGuo/rcdqn.", "published": "2020-10-05 23:09:20", "link": "http://arxiv.org/abs/2010.02386v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mixup-Transformer: Dynamic Data Augmentation for NLP Tasks", "abstract": "Mixup is the latest data augmentation technique that linearly interpolates\ninput examples and the corresponding labels. It has shown strong effectiveness\nin image classification by interpolating images at the pixel level. Inspired by\nthis line of research, in this paper, we explore i) how to apply mixup to\nnatural language processing tasks since text data can hardly be mixed in the\nraw format; ii) if mixup is still effective in transformer-based learning\nmodels, e.g., BERT. To achieve the goal, we incorporate mixup to\ntransformer-based pre-trained architecture, named \"mixup-transformer\", for a\nwide range of NLP tasks while keeping the whole end-to-end training system. We\nevaluate the proposed framework by running extensive experiments on the GLUE\nbenchmark. Furthermore, we also examine the performance of mixup-transformer in\nlow-resource scenarios by reducing the training data with a certain ratio. Our\nstudies show that mixup is a domain-independent data augmentation technique to\npre-trained language models, resulting in significant performance improvement\nfor transformer-based models.", "published": "2020-10-05 23:37:30", "link": "http://arxiv.org/abs/2010.02394v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Generalized Constraint Approach to Bilingual Dictionary Induction for\n  Low-Resource Language Families", "abstract": "The lack or absence of parallel and comparable corpora makes bilingual\nlexicon extraction a difficult task for low-resource languages. The pivot\nlanguage and cognate recognition approaches have been proven useful for\ninducing bilingual lexicons for such languages. We propose constraint-based\nbilingual lexicon induction for closely-related languages by extending\nconstraints from the recent pivot-based induction technique and further\nenabling multiple symmetry assumption cycles to reach many more cognates in the\ntransgraph. We further identify cognate synonyms to obtain many-to-many\ntranslation pairs. This paper utilizes four datasets: one Austronesian\nlow-resource language and three Indo-European high-resource languages. We use\nthree constraint-based methods from our previous work, the Inverse Consultation\nmethod and translation pairs generated from the Cartesian product of input\ndictionaries as baselines. We evaluate our result using the metrics of\nprecision, recall and F-score. Our customizable approach allows the user to\nconduct cross-validation to predict the optimal hyperparameters (cognate\nthreshold and cognate synonym threshold) with various combinations of\nheuristics and the number of symmetry assumption cycles to gain the highest\nF-score. Our proposed methods have statistically significant improvement of\nprecision and F-score compared to our previous constraint-based methods. The\nresults show that our method demonstrates the potential to complement other\nbilingual dictionary creation methods like word alignment models using parallel\ncorpora for high-resource languages while well handling low-resource languages.", "published": "2020-10-05 23:41:04", "link": "http://arxiv.org/abs/2010.02395v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GenAug: Data Augmentation for Finetuning Text Generators", "abstract": "In this paper, we investigate data augmentation for text generation, which we\ncall GenAug. Text generation and language modeling are important tasks within\nnatural language processing, and are especially challenging for low-data\nregimes. We propose and evaluate various augmentation methods, including some\nthat incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp\nReviews. We also examine the relationship between the amount of augmentation\nand the quality of the generated text. We utilize several metrics that evaluate\nimportant aspects of the generated text including its diversity and fluency.\nOur experiments demonstrate that insertion of character-level synthetic noise\nand keyword replacement with hypernyms are effective augmentation methods, and\nthat the quality of generations improves to a peak at approximately three times\nthe amount of original data.", "published": "2020-10-05 05:46:39", "link": "http://arxiv.org/abs/2010.01794v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PMI-Masking: Principled masking of correlated spans", "abstract": "Masking tokens uniformly at random constitutes a common flaw in the\npretraining of Masked Language Models (MLMs) such as BERT. We show that such\nuniform masking allows an MLM to minimize its training objective by latching\nonto shallow local signals, leading to pretraining inefficiency and suboptimal\ndownstream performance. To address this flaw, we propose PMI-Masking, a\nprincipled masking strategy based on the concept of Pointwise Mutual\nInformation (PMI), which jointly masks a token n-gram if it exhibits high\ncollocation over the corpus. PMI-Masking motivates, unifies, and improves upon\nprior more heuristic approaches that attempt to address the drawback of random\nuniform token masking, such as whole-word masking, entity/phrase masking, and\nrandom-span masking. Specifically, we show experimentally that PMI-Masking\nreaches the performance of prior masking approaches in half the training time,\nand consistently improves performance at the end of training.", "published": "2020-10-05 07:19:52", "link": "http://arxiv.org/abs/2010.01825v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Discern: Discourse-Aware Entailment Reasoning Network for Conversational\n  Machine Reading", "abstract": "Document interpretation and dialog understanding are the two major challenges\nfor conversational machine reading. In this work, we propose Discern, a\ndiscourse-aware entailment reasoning network to strengthen the connection and\nenhance the understanding for both document and dialog. Specifically, we split\nthe document into clause-like elementary discourse units (EDU) using a\npre-trained discourse segmentation model, and we train our model in a\nweakly-supervised manner to predict whether each EDU is entailed by the user\nfeedback in a conversation. Based on the learned EDU and entailment\nrepresentations, we either reply to the user our final decision\n\"yes/no/irrelevant\" of the initial question, or generate a follow-up question\nto inquiry more information. Our experiments on the ShARC benchmark (blind,\nheld-out test set) show that Discern achieves state-of-the-art results of 78.3%\nmacro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question\ngeneration. Code and models are released at\nhttps://github.com/Yifan-Gao/Discern.", "published": "2020-10-05 07:49:51", "link": "http://arxiv.org/abs/2010.01838v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"LazImpa\": Lazy and Impatient neural agents learn to communicate\n  efficiently", "abstract": "Previous work has shown that artificial neural agents naturally develop\nsurprisingly non-efficient codes. This is illustrated by the fact that in a\nreferential game involving a speaker and a listener neural networks optimizing\naccurate transmission over a discrete channel, the emergent messages fail to\nachieve an optimal length. Furthermore, frequent messages tend to be longer\nthan infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA)\nobserved in all natural languages. Here, we show that near-optimal and\nZLA-compatible messages can emerge, but only if both the speaker and the\nlistener are modified. We hence introduce a new communication system,\n\"LazImpa\", where the speaker is made increasingly lazy, i.e. avoids long\nmessages, and the listener impatient, i.e.,~seeks to guess the intended content\nas soon as possible.", "published": "2020-10-05 09:25:53", "link": "http://arxiv.org/abs/2010.01878v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "I.2", "I.2"], "primary_category": "cs.CL"}
{"title": "A Spherical Hidden Markov Model for Semantics-Rich Human Mobility\n  Modeling", "abstract": "We study the problem of modeling human mobility from semantic trace data,\nwherein each GPS record in a trace is associated with a text message that\ndescribes the user's activity. Existing methods fall short in unveiling human\nmovement regularities, because they either do not model the text data at all or\nsuffer from text sparsity severely. We propose SHMM, a multi-modal spherical\nhidden Markov model for semantics-rich human mobility modeling. Under the\nhidden Markov assumption, SHMM models the generation process of a given trace\nby jointly considering the observed location, time, and text at each step of\nthe trace. The distinguishing characteristic of SHMM is the text modeling part.\nWe use fixed-size vector representations to encode the semantics of the text\nmessages, and model the generation of the l2-normalized text embeddings on a\nunit sphere with the von Mises-Fisher (vMF) distribution. Compared with other\nalternatives like multi-variate Gaussian, our choice of the vMF distribution\nnot only incurs much fewer parameters, but also better leverages the\ndiscriminative power of text embeddings in a directional metric space. The\nparameter inference for the vMF distribution is non-trivial since it involves\nfunctional inversion of ratios of Bessel functions. We theoretically prove\nthat: 1) the classical Expectation-Maximization algorithm can work with vMF\ndistributions; and 2) while closed-form solutions are hard to be obtained for\nthe M-step, Newton's method is guaranteed to converge to the optimal solution\nwith quadratic convergence rate. We have performed extensive experiments on\nboth synthetic and real-life data. The results on synthetic data verify our\ntheoretical analysis; while the results on real-life data demonstrate that SHMM\nlearns meaningful semantics-rich mobility models, outperforms state-of-the-art\nmobility models for next location prediction, and incurs lower training cost.", "published": "2020-10-05 13:18:38", "link": "http://arxiv.org/abs/2010.01986v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Modulated Fusion using Transformer for Linguistic-Acoustic Emotion\n  Recognition", "abstract": "This paper aims to bring a new lightweight yet powerful solution for the task\nof Emotion Recognition and Sentiment Analysis. Our motivation is to propose two\narchitectures based on Transformers and modulation that combine the linguistic\nand acoustic inputs from a wide range of datasets to challenge, and sometimes\nsurpass, the state-of-the-art in the field. To demonstrate the efficiency of\nour models, we carefully evaluate their performances on the IEMOCAP, MOSI,\nMOSEI and MELD dataset. The experiments can be directly replicated and the code\nis fully open for future researches.", "published": "2020-10-05 14:46:20", "link": "http://arxiv.org/abs/2010.02057v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining The Efficacy of Counterfactually Augmented Data", "abstract": "In attempts to produce ML models less reliant on spurious patterns in NLP\ndatasets, researchers have recently proposed curating counterfactually\naugmented data (CAD) via a human-in-the-loop process in which given some\ndocuments and their (initial) labels, humans must revise the text to make a\ncounterfactual label applicable. Importantly, edits that are not necessary to\nflip the applicable label are prohibited. Models trained on the augmented data\nappear, empirically, to rely less on semantically irrelevant words and to\ngeneralize better out of domain. While this work draws loosely on causal\nthinking, the underlying causal model (even at an abstract level) and the\nprinciples underlying the observed out-of-domain improvements remain unclear.\nIn this paper, we introduce a toy analog based on linear Gaussian models,\nobserving interesting relationships between causal models, measurement noise,\nout-of-domain generalization, and reliance on spurious signals. Our analysis\nprovides some insights that help to explain the efficacy of CAD. Moreover, we\ndevelop the hypothesis that while adding noise to causal features should\ndegrade both in-domain and out-of-domain performance, adding noise to\nnon-causal features should lead to relative improvements in out-of-domain\nperformance. This idea inspires a speculative test for determining whether a\nfeature attribution technique has identified the causal spans. If adding noise\n(e.g., by random word flips) to the highlighted spans degrades both in-domain\nand out-of-domain performance on a battery of challenge datasets, but adding\nnoise to the complement gives improvements out-of-domain, it suggests we have\nidentified causal spans. We present a large-scale empirical study comparing\nspans edited to create CAD to those selected by attention and saliency maps.\nAcross numerous domains and models, we find that the hypothesized phenomenon is\npronounced for CAD.", "published": "2020-10-05 15:57:07", "link": "http://arxiv.org/abs/2010.02114v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Lifelong Language Knowledge Distillation", "abstract": "It is challenging to perform lifelong language learning (LLL) on a stream of\ndifferent tasks without any performance degradation comparing to the multi-task\ncounterparts. To address this issue, we present Lifelong Language Knowledge\nDistillation (L2KD), a simple but efficient method that can be easily applied\nto existing LLL architectures in order to mitigate the degradation.\nSpecifically, when the LLL model is trained on a new task, we assign a teacher\nmodel to first learn the new task, and pass the knowledge to the LLL model via\nknowledge distillation. Therefore, the LLL model can better adapt to the new\ntask while keeping the previously learned knowledge. Experiments show that the\nproposed L2KD consistently improves previous state-of-the-art models, and the\ndegradation comparing to multi-task models in LLL tasks is well mitigated for\nboth sequence generation and text classification tasks.", "published": "2020-10-05 16:10:11", "link": "http://arxiv.org/abs/2010.02123v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models", "abstract": "Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified.", "published": "2020-10-05 16:55:39", "link": "http://arxiv.org/abs/2010.02150v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Knowledge Association with Hyperbolic Knowledge Graph Embeddings", "abstract": "Capturing associations for knowledge graphs (KGs) through entity alignment,\nentity type inference and other related tasks benefits NLP applications with\ncomprehensive knowledge representations. Recent related methods built on\nEuclidean embeddings are challenged by the hierarchical structures and\ndifferent scales of KGs. They also depend on high embedding dimensions to\nrealize enough expressiveness. Differently, we explore with low-dimensional\nhyperbolic embeddings for knowledge association. We propose a hyperbolic\nrelational graph neural network for KG embedding and capture knowledge\nassociations with a hyperbolic transformation. Extensive experiments on entity\nalignment and type inference demonstrate the effectiveness and efficiency of\nour method.", "published": "2020-10-05 17:11:35", "link": "http://arxiv.org/abs/2010.02162v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InfoBERT: Improving Robustness of Language Models from An Information\n  Theoretic Perspective", "abstract": "Large-scale language models such as BERT have achieved state-of-the-art\nperformance across a wide range of NLP tasks. Recent studies, however, show\nthat such BERT-based models are vulnerable facing the threats of textual\nadversarial attacks. We aim to address this problem from an\ninformation-theoretic perspective, and propose InfoBERT, a novel learning\nframework for robust fine-tuning of pre-trained language models. InfoBERT\ncontains two mutual-information-based regularizers for model training: (i) an\nInformation Bottleneck regularizer, which suppresses noisy mutual information\nbetween the input and the feature representation; and (ii) a Robust Feature\nregularizer, which increases the mutual information between local robust\nfeatures and global features. We provide a principled way to theoretically\nanalyze and improve the robustness of representation learning for language\nmodels in both standard and adversarial training. Extensive experiments\ndemonstrate that InfoBERT achieves state-of-the-art robust accuracy over\nseveral adversarial datasets on Natural Language Inference (NLI) and Question\nAnswering (QA) tasks. Our code is available at\nhttps://github.com/AI-secure/InfoBERT.", "published": "2020-10-05 20:49:26", "link": "http://arxiv.org/abs/2010.02329v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Participatory Research for Low-resourced Machine Translation: A Case\n  Study in African Languages", "abstract": "Research in NLP lacks geographic diversity, and the question of how NLP can\nbe scaled to low-resourced languages has not yet been adequately solved.\n\"Low-resourced\"-ness is a complex problem going beyond data availability and\nreflects systemic problems in society. In this paper, we focus on the task of\nMachine Translation (MT), that plays a crucial role for information\naccessibility and communication worldwide. Despite immense improvements in MT\nover the past decade, MT is centered around a few high-resourced languages. As\nMT researchers cannot solve the problem of low-resourcedness alone, we propose\nparticipatory research as a means to involve all necessary agents required in\nthe MT development process. We demonstrate the feasibility and scalability of\nparticipatory research with a case study on MT for African languages. Its\nimplementation leads to a collection of novel translation datasets, MT\nbenchmarks for over 30 languages, with human evaluations for a third of them,\nand enables participants without formal training to make a unique scientific\ncontribution. Benchmarks, models, data, code, and evaluation results are\nreleased under https://github.com/masakhane-io/masakhane-mt.", "published": "2020-10-05 21:50:38", "link": "http://arxiv.org/abs/2010.02353v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Neural Topic Models using Knowledge Distillation", "abstract": "Topic models are often used to identify human-interpretable topics to help\nmake sense of large document collections. We use knowledge distillation to\ncombine the best attributes of probabilistic topic models and pretrained\ntransformers. Our modular method can be straightforwardly applied with any\nneural topic model to improve topic quality, which we demonstrate using two\nmodels having disparate architectures, obtaining state-of-the-art topic\ncoherence. We show that our adaptable framework not only improves performance\nin the aggregate over all estimated topics, as is commonly reported, but also\nin head-to-head comparisons of aligned topics.", "published": "2020-10-05 22:49:16", "link": "http://arxiv.org/abs/2010.02377v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Plan Optimization to Bilingual Dictionary Induction for Low-Resource\n  Language Families", "abstract": "Creating bilingual dictionary is the first crucial step in enriching\nlow-resource languages. Especially for the closely-related ones, it has been\nshown that the constraint-based approach is useful for inducing bilingual\nlexicons from two bilingual dictionaries via the pivot language. However, if\nthere are no available machine-readable dictionaries as input, we need to\nconsider manual creation by bilingual native speakers. To reach a goal of\ncomprehensively create multiple bilingual dictionaries, even if we already have\nseveral existing machine-readable bilingual dictionaries, it is still difficult\nto determine the execution order of the constraint-based approach to reducing\nthe total cost. Plan optimization is crucial in composing the order of\nbilingual dictionaries creation with the consideration of the methods and their\ncosts. We formalize the plan optimization for creating bilingual dictionaries\nby utilizing Markov Decision Process (MDP) with the goal to get a more accurate\nestimation of the most feasible optimal plan with the least total cost before\nfully implementing the constraint-based bilingual lexicon induction. We model a\nprior beta distribution of bilingual lexicon induction precision with language\nsimilarity and polysemy of the topology as $\\alpha$ and $\\beta$ parameters. It\nis further used to model cost function and state transition probability. We\nestimated the cost of all investment plan as a baseline for evaluating the\nproposed MDP-based approach with total cost as an evaluation metric. After\nutilizing the posterior beta distribution in the first batch of experiments to\nconstruct the prior beta distribution in the second batch of experiments, the\nresult shows 61.5\\% of cost reduction compared to the estimated all investment\nplan and 39.4\\% of cost reduction compared to the estimated MDP optimal plan.\nThe MDP-based proposal outperformed the baseline on the total cost.", "published": "2020-10-05 23:43:40", "link": "http://arxiv.org/abs/2010.02396v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Streaming Approach For Efficient Batched Beam Search", "abstract": "We propose an efficient batching strategy for variable-length decoding on GPU\narchitectures. During decoding, when candidates terminate or are pruned\naccording to heuristics, our streaming approach periodically \"refills\" the\nbatch before proceeding with a selected subset of candidates. We apply our\nmethod to variable-width beam search on a state-of-the-art machine translation\nmodel. Our method decreases runtime by up to 71% compared to a fixed-width beam\nsearch baseline and 17% compared to a variable-width baseline, while matching\nbaselines' BLEU. Finally, experiments show that our method can speed up\ndecoding in other domains, such as semantic and syntactic parsing.", "published": "2020-10-05 17:13:34", "link": "http://arxiv.org/abs/2010.02164v3", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG", "cs.PF"], "primary_category": "cs.CL"}
{"title": "JSSS: free Japanese speech corpus for summarization and simplification", "abstract": "In this paper, we construct a new Japanese speech corpus for speech-based\nsummarization and simplification, \"JSSS\" (pronounced \"j-triple-s\"). Given the\nsuccess of reading-style speech synthesis from short-form sentences, we aim to\ndesign more difficult tasks for delivering information to humans. Our corpus\ncontains voices recorded for two tasks that have a role in providing\ninformation under constraints: duration-constrained text-to-speech\nsummarization and speaking-style simplification. It also contains utterances of\nlong-form sentences as an optional task. This paper describes how we designed\nthe corpus, which is available on our project page.", "published": "2020-10-05 05:46:10", "link": "http://arxiv.org/abs/2010.01793v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "High-resolution Piano Transcription with Pedals by Regressing Onset and\n  Offset Times", "abstract": "Automatic music transcription (AMT) is the task of transcribing audio\nrecordings into symbolic representations. Recently, neural network-based\nmethods have been applied to AMT, and have achieved state-of-the-art results.\nHowever, many previous systems only detect the onset and offset of notes\nframe-wise, so the transcription resolution is limited to the frame hop size.\nThere is a lack of research on using different strategies to encode onset and\noffset targets for training. In addition, previous AMT systems are sensitive to\nthe misaligned onset and offset labels of audio recordings. Furthermore, there\nare limited researches on sustain pedal transcription on large-scale datasets.\nIn this article, we propose a high-resolution AMT system trained by regressing\nprecise onset and offset times of piano notes. At inference, we propose an\nalgorithm to analytically calculate the precise onset and offset times of piano\nnotes and pedal events. We show that our AMT system is robust to the misaligned\nonset and offset labels compared to previous systems. Our proposed system\nachieves an onset F1 of 96.72% on the MAESTRO dataset, outperforming previous\nonsets and frames system of 94.80%. Our system achieves a pedal onset F1 score\nof 91.86\\%, which is the first benchmark result on the MAESTRO dataset. We have\nreleased the source code and checkpoints of our work at\nhttps://github.com/bytedance/piano_transcription.", "published": "2020-10-05 06:57:11", "link": "http://arxiv.org/abs/2010.01815v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "D3Net: Densely connected multidilated DenseNet for music source\n  separation", "abstract": "Music source separation involves a large input field to model a long-term\ndependence of an audio signal. Previous convolutional neural network\n(CNN)-based approaches address the large input field modeling using\nsequentially down- and up-sampling feature maps or dilated convolution. In this\npaper, we claim the importance of a rapid growth of a receptive field and a\nsimultaneous modeling of multi-resolution data in a single convolution layer,\nand propose a novel CNN architecture called densely connected dilated DenseNet\n(D3Net). D3Net involves a novel multi-dilated convolution that has different\ndilation factors in a single layer to model different resolutions\nsimultaneously. By combining the multi-dilated convolution with DenseNet\narchitecture, D3Net avoids the aliasing problem that exists when we naively\nincorporate the dilated convolution in DenseNet. Experimental results on\nMUSDB18 dataset show that D3Net achieves state-of-the-art performance with an\naverage signal to distortion ratio (SDR) of 6.01 dB.", "published": "2020-10-05 01:03:08", "link": "http://arxiv.org/abs/2010.01733v4", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
