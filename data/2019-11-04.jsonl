{"title": "On the Effectiveness of the Pooling Methods for Biomedical Relation\n  Extraction with Deep Learning", "abstract": "Deep learning models have achieved state-of-the-art performances on many\nrelation extraction datasets. A common element in these deep learning models\ninvolves the pooling mechanisms where a sequence of hidden vectors is\naggregated to generate a single representation vector, serving as the features\nto perform prediction for RE. Unfortunately, the models in the literature tend\nto employ different strategies to perform pooling for RE, leading to the\nchallenge to determine the best pooling mechanism for this problem, especially\nin the biomedical domain. In order to answer this question, in this work, we\nconduct a comprehensive study to evaluate the effectiveness of different\npooling mechanisms for the deep learning models in biomedical RE. The\nexperimental results suggest that dependency-based pooling is the best pooling\nstrategy for RE in the biomedical domain, yielding the state-of-the-art\nperformance on two benchmark datasets for this problem.", "published": "2019-11-04 07:15:05", "link": "http://arxiv.org/abs/1911.01055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emergence of Numeric Concepts in Multi-Agent Autonomous Communication", "abstract": "With the rapid development of deep learning, most of current state-of-the-art\ntechniques in natural langauge processing are based on deep learning models\ntrained with argescaled static textual corpora. However, we human beings learn\nand understand in a different way. Thus, grounded language learning argues that\nmodels need to learn and understand language by the experience and perceptions\nobtained by interacting with enviroments, like how humans do. With the help of\ndeep reinforcement learning techniques, there are already lots of works\nfocusing on facilitating the emergence of communication protocols that have\ncompositionalities like natural languages among computational agents\npopulation. Unlike these works, we, on the other hand, focus on the numeric\nconcepts which correspond to abstractions in cognition and function words in\nnatural language. Based on a specifically designed language game, we verify\nthat computational agents are capable of transmitting numeric concepts during\nautonomous communication, and the emergent communication protocols can reflect\nthe underlying structure of meaning space. Although their encodeing method is\nnot compositional like natural languages from a perspective of human beings,\nthe emergent languages can be generalised to unseen inputs and, more\nimportantly, are easier for models to learn. Besides, iterated learning can\nhelp further improving the compositionality of the emergent languages, under\nthe measurement of topological similarity. Furthermore, we experiment another\nrepresentation method, i.e. directly encode numerals into concatenations of\none-hot vectors, and find that the emergent languages would become\ncompositional like human natural languages. Thus, we argue that there are 2\nimportant factors for the emergence of compositional languages.", "published": "2019-11-04 09:58:23", "link": "http://arxiv.org/abs/1911.01098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysing Coreference in Transformer Outputs", "abstract": "We analyse coreference phenomena in three neural machine translation systems\ntrained with different data settings with or without access to explicit intra-\nand cross-sentential anaphoric information. We compare system performance on\ntwo different genres: news and TED talks. To do this, we manually annotate (the\npossibly incorrect) coreference chains in the MT outputs and evaluate the\ncoreference chain translations. We define an error typology that aims to go\nfurther than pronoun translation adequacy and includes types such as incorrect\nword selection or missing words. The features of coreference chains in\nautomatic translations are also compared to those of the source texts and human\ntranslations. The analysis shows stronger potential translationese effects in\nmachine translated outputs than in human translations.", "published": "2019-11-04 13:25:26", "link": "http://arxiv.org/abs/1911.01188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Explanations with Neural Execution Tree", "abstract": "While deep neural networks have achieved impressive performance on a range of\nNLP tasks, these data-hungry models heavily rely on labeled data, which\nrestricts their applications in scenarios where data annotation is expensive.\nNatural language (NL) explanations have been demonstrated very useful\nadditional supervision, which can provide sufficient domain knowledge for\ngenerating more labeled data over new instances, while the annotation time only\ndoubles. However, directly applying them for augmenting model learning\nencounters two challenges: (1) NL explanations are unstructured and inherently\ncompositional, which asks for a modularized model to represent their semantics,\n(2) NL explanations often have large numbers of linguistic variants, resulting\nin low recall and limited generalization ability. In this paper, we propose a\nnovel Neural Execution Tree (NExT) framework to augment training data for text\nclassification using NL explanations. After transforming NL explanations into\nexecutable logical forms by semantic parsing, NExT generalizes different types\nof actions specified by the logical forms for labeling data instances, which\nsubstantially increases the coverage of each NL explanation. Experiments on two\nNLP tasks (relation extraction and sentiment analysis) demonstrate its\nsuperiority over baseline methods. Its extension to multi-hop question\nanswering achieves performance gain with light annotation effort.", "published": "2019-11-04 17:31:02", "link": "http://arxiv.org/abs/1911.01352v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Predictive Engagement: An Efficient Metric For Automatic Evaluation of\n  Open-Domain Dialogue Systems", "abstract": "User engagement is a critical metric for evaluating the quality of\nopen-domain dialogue systems. Prior work has focused on conversation-level\nengagement by using heuristically constructed features such as the number of\nturns and the total time of the conversation. In this paper, we investigate the\npossibility and efficacy of estimating utterance-level engagement and define a\nnovel metric, {\\em predictive engagement}, for automatic evaluation of\nopen-domain dialogue systems. Our experiments demonstrate that (1) human\nannotators have high agreement on assessing utterance-level engagement scores;\n(2) conversation-level engagement scores can be predicted from properly\naggregated utterance-level engagement scores. Furthermore, we show that the\nutterance-level engagement scores can be learned from data. These scores can\nimprove automatic evaluation metrics for open-domain dialogue systems, as shown\nby correlation with human judgements. This suggests that predictive engagement\ncan be used as a real-time feedback for training better dialogue models.", "published": "2019-11-04 19:21:48", "link": "http://arxiv.org/abs/1911.01456v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Failure of Aspect Sentiment Classifiers and an Adaptive Re-weighting\n  Solution", "abstract": "Aspect-based sentiment classification (ASC) is an important task in\nfine-grained sentiment analysis.~Deep supervised ASC approaches typically model\nthis task as a pair-wise classification task that takes an aspect and a\nsentence containing the aspect and outputs the polarity of the aspect in that\nsentence. However, we discovered that many existing approaches fail to learn an\neffective ASC classifier but more like a sentence-level sentiment classifier\nbecause they have difficulty to handle sentences with different polarities for\ndifferent aspects.~This paper first demonstrates this problem using several\nstate-of-the-art ASC models. It then proposes a novel and general adaptive\nre-weighting (ARW) scheme to adjust the training to dramatically improve ASC\nfor such complex sentences. Experimental results show that the proposed\nframework is effective \\footnote{The dataset and code are available at\n\\url{https://github.com/howardhsu/ASC_failure}.}.", "published": "2019-11-04 19:27:50", "link": "http://arxiv.org/abs/1911.01460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emerging Cross-lingual Structure in Pretrained Language Models", "abstract": "We study the problem of multilingual masked language modeling, i.e. the\ntraining of a single model on concatenated text from multiple languages, and\npresent a detailed study of several factors that influence why these models are\nso effective for cross-lingual transfer. We show, contrary to what was\npreviously hypothesized, that transfer is possible even when there is no shared\nvocabulary across the monolingual corpora and also when the text comes from\nvery different domains. The only requirement is that there are some shared\nparameters in the top layers of the multi-lingual encoder. To better understand\nthis result, we also show that representations from independently trained\nmodels in different languages can be aligned post-hoc quite effectively,\nstrongly suggesting that, much like for non-contextual word embeddings, there\nare universal latent symmetries in the learned embedding spaces. For\nmultilingual masked language modeling, these symmetries seem to be\nautomatically discovered and aligned during the joint training process.", "published": "2019-11-04 19:41:13", "link": "http://arxiv.org/abs/1911.01464v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BAS: An Answer Selection Method Using BERT Language Model", "abstract": "In recent years, Question Answering systems have become more popular and\nwidely used by users. Despite the increasing popularity of these systems, the\ntheir performance is not even sufficient for textual data and requires further\nresearch. These systems consist of several parts that one of them is the Answer\nSelection component. This component detects the most relevant answer from a\nlist of candidate answers. The methods presented in previous researches have\nattempted to provide an independent model to undertake the answer-selection\ntask. An independent model cannot comprehend the syntactic and semantic\nfeatures of questions and answers with a small training dataset. To fill this\ngap, language models can be employed in implementing the answer selection part.\nThis action enables the model to have a better understanding of the language in\norder to understand questions and answers better than previous works. In this\nresearch, we will present the \"BAS\" (BERT Answer Selection) that uses the BERT\nlanguage model to comprehend language. The empirical results of applying the\nmodel on the TrecQA Raw, TrecQA Clean, and WikiQA datasets demonstrate that\nusing a robust language model such as BERT can enhance the performance. Using a\nmore robust classifier also enhances the effect of the language model on the\nanswer selection component. The results demonstrate that language comprehension\nis an essential requirement in natural language processing tasks such as\nanswer-selection.", "published": "2019-11-04 23:16:47", "link": "http://arxiv.org/abs/1911.01528v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Holistic Natural Language Generation Framework for the Semantic Web", "abstract": "With the ever-growing generation of data for the Semantic Web comes an\nincreasing demand for this data to be made available to non-semantic Web\nexperts. One way of achieving this goal is to translate the languages of the\nSemantic Web into natural language. We present LD2NL, a framework for\nverbalizing the three key languages of the Semantic Web, i.e., RDF, OWL, and\nSPARQL. Our framework is based on a bottom-up approach to verbalization. We\nevaluated LD2NL in an open survey with 86 persons. Our results suggest that our\nframework can generate verbalizations that are close to natural languages and\nthat can be easily understood by non-experts. Therewith, it enables non-domain\nexperts to interpret Semantic Web data with more than 91\\% of the accuracy of\ndomain experts.", "published": "2019-11-04 14:35:59", "link": "http://arxiv.org/abs/1911.01248v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "A Novel Approach to Enhance the Performance of Semantic Search in\n  Bengali using Neural Net and other Classification Techniques", "abstract": "Search has for a long time been an important tool for users to retrieve\ninformation. Syntactic search is matching documents or objects containing\nspecific keywords like user-history, location, preference etc. to improve the\nresults. However, it is often possible that the query and the best answer have\nno term or very less number of terms in common and syntactic search can not\nperform properly in such cases. Semantic search, on the other hand, resolves\nthese issues but suffers from lack of annotation, absence of WordNet in case of\nlow resource languages. In this work, we have demonstrated an end to end\nprocedure to improve the performance of semantic search using semi-supervised\nand unsupervised learning algorithms. An available Bengali repository was\nchosen to have seven types of semantic properties primarily to develop the\nsystem. Performance has been tested using Support Vector Machine, Naive Bayes,\nDecision Tree and Artificial Neural Network (ANN). Our system has achieved the\nefficiency to predict the correct semantics using knowledge base over the time\nof learning. A repository containing around a million sentences, a product of\nTDIL project of Govt. of India, was used to test our system at first instance.\nThen the testing has been done for other languages. Being a cognitive system it\nmay be very useful for improving user satisfaction in e-Governance or\nm-Governance in the multilingual environment and also for other applications.", "published": "2019-11-04 14:47:33", "link": "http://arxiv.org/abs/1911.01256v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Examining UK drill music through sentiment trajectory analysis", "abstract": "This paper presents how techniques from natural language processing can be\nused to examine the sentiment trajectories of gang-related drill music in the\nUnited Kingdom (UK). This work is important because key public figures are\nloosely making controversial linkages between drill music and recent\nescalations in youth violence in London. Thus, this paper examines the dynamic\nuse of sentiment in gang-related drill music lyrics. The findings suggest two\ndistinct sentiment use patterns and statistical analyses revealed that lyrics\nwith a markedly positive tone attract more views and engagement on YouTube than\nnegative ones. Our work provides the first empirical insights into the language\nuse of London drill music, and it can, therefore, be used in future studies and\nby policymakers to help understand the alleged drill-gang nexus.", "published": "2019-11-04 16:39:21", "link": "http://arxiv.org/abs/1911.01324v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "On Compositionality in Neural Machine Translation", "abstract": "We investigate two specific manifestations of compositionality in Neural\nMachine Translation (NMT) : (1) Productivity - the ability of the model to\nextend its predictions beyond the observed length in training data and (2)\nSystematicity - the ability of the model to systematically recombine known\nparts and rules. We evaluate a standard Sequence to Sequence model on tests\ndesigned to assess these two properties in NMT. We quantitatively demonstrate\nthat inadequate temporal processing, in the form of poor encoder\nrepresentations is a bottleneck for both Productivity and Systematicity. We\npropose a simple pre-training mechanism which alleviates model performance on\nthe two properties and leads to a significant improvement in BLEU scores.", "published": "2019-11-04 21:31:36", "link": "http://arxiv.org/abs/1911.01497v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Metric Learning for Dynamic Text Classification", "abstract": "Traditional text classifiers are limited to predicting over a fixed set of\nlabels. However, in many real-world applications the label set is frequently\nchanging. For example, in intent classification, new intents may be added over\ntime while others are removed. We propose to address the problem of dynamic\ntext classification by replacing the traditional, fixed-size output layer with\na learned, semantically meaningful metric space. Here the distances between\ntextual inputs are optimized to perform nearest-neighbor classification across\noverlapping label sets. Changing the label set does not involve removing\nparameters, but rather simply adding or removing support points in the metric\nspace. Then the learned metric can be fine-tuned with only a few additional\ntraining examples. We demonstrate that this simple strategy is robust to\nchanges in the label space. Furthermore, our results show that learning a\nnon-Euclidean metric can improve performance in the low data regime, suggesting\nthat further work on metric spaces may benefit low-resource research.", "published": "2019-11-04 04:27:29", "link": "http://arxiv.org/abs/1911.01026v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "What does a network layer hear? Analyzing hidden representations of\n  end-to-end ASR through speech synthesis", "abstract": "End-to-end speech recognition systems have achieved competitive results\ncompared to traditional systems. However, the complex transformations involved\nbetween layers given highly variable acoustic signals are hard to analyze. In\nthis paper, we present our ASR probing model, which synthesizes speech from\nhidden representations of end-to-end ASR to examine the information maintain\nafter each layer calculation. Listening to the synthesized speech, we observe\ngradual removal of speaker variability and noise as the layer goes deeper,\nwhich aligns with the previous studies on how deep network functions in speech\nrecognition. This paper is the first study analyzing the end-to-end speech\nrecognition model by demonstrating what each layer hears. Speaker verification\nand speech enhancement measurements on synthesized speech are also conducted to\nconfirm our observation further.", "published": "2019-11-04 10:07:13", "link": "http://arxiv.org/abs/1911.01102v1", "categories": ["cs.CL", "cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Spherical Text Embedding", "abstract": "Unsupervised text embedding has shown great power in a wide range of NLP\ntasks. While text embeddings are typically learned in the Euclidean space,\ndirectional similarity is often more effective in tasks such as word similarity\nand document clustering, which creates a gap between the training stage and\nusage stage of text embedding. To close this gap, we propose a spherical\ngenerative model based on which unsupervised word and paragraph embeddings are\njointly learned. To learn text embeddings in the spherical space, we develop an\nefficient optimization algorithm with convergence guarantee based on Riemannian\noptimization. Our model enjoys high efficiency and achieves state-of-the-art\nperformances on various text embedding tasks including word similarity and\ndocument clustering.", "published": "2019-11-04 18:36:12", "link": "http://arxiv.org/abs/1911.01196v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Affective Behaviour Analysis of On-line User Interactions: Are On-line\n  Support Groups more Therapeutic than Twitter?", "abstract": "The increase in the prevalence of mental health problems has coincided with a\ngrowing popularity of health related social networking sites. Regardless of\ntheir therapeutic potential, On-line Support Groups (OSGs) can also have\nnegative effects on patients. In this work we propose a novel methodology to\nautomatically verify the presence of therapeutic factors in social networking\nwebsites by using Natural Language Processing (NLP) techniques. The methodology\nis evaluated on On-line asynchronous multi-party conversations collected from\nan OSG and Twitter. The results of the analysis indicate that therapeutic\nfactors occur more frequently in OSG conversations than in Twitter\nconversations. Moreover, the analysis of OSG conversations reveals that the\nusers of that platform are supportive, and interactions are likely to lead to\nthe improvement of their emotional state. We believe that our method provides a\nstepping stone towards automatic analysis of emotional states of users of\nonline platforms. Possible applications of the method include provision of\nguidelines that highlight potential implications of using such platforms on\nusers' mental health, and/or support in the analysis of their impact on\nspecific individuals.", "published": "2019-11-04 17:59:18", "link": "http://arxiv.org/abs/1911.01371v1", "categories": ["cs.HC", "cs.CL", "cs.SI"], "primary_category": "cs.HC"}
{"title": "VASTA: A Vision and Language-assisted Smartphone Task Automation System", "abstract": "We present VASTA, a novel vision and language-assisted Programming By\nDemonstration (PBD) system for smartphone task automation. Development of a\nrobust PBD automation system requires overcoming three key challenges: first,\nhow to make a particular demonstration robust to positional and visual changes\nin the user interface (UI) elements; secondly, how to recognize changes in the\nautomation parameters to make the demonstration as generalizable as possible;\nand thirdly, how to recognize from the user utterance what automation the user\nwishes to carry out. To address the first challenge, VASTA leverages\nstate-of-the-art computer vision techniques, including object detection and\noptical character recognition, to accurately label interactions demonstrated by\na user, without relying on the underlying UI structures. To address the second\nand third challenges, VASTA takes advantage of advanced natural language\nunderstanding algorithms for analyzing the user utterance to trigger the VASTA\nautomation scripts, and to determine the automation parameters for\ngeneralization. We run an initial user study that demonstrates the\neffectiveness of VASTA at clustering user utterances, understanding changes in\nthe automation parameters, detecting desired UI elements, and, most\nimportantly, automating various tasks. A demo video of the system is available\nhere: http://y2u.be/kr2xE-FixjI", "published": "2019-11-04 20:21:32", "link": "http://arxiv.org/abs/1911.01474v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "abstract": "Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.", "published": "2019-11-04 20:57:54", "link": "http://arxiv.org/abs/1911.01485v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "pyannote.audio: neural building blocks for speaker diarization", "abstract": "We introduce pyannote.audio, an open-source toolkit written in Python for\nspeaker diarization. Based on PyTorch machine learning framework, it provides a\nset of trainable end-to-end neural building blocks that can be combined and\njointly optimized to build speaker diarization pipelines. pyannote.audio also\ncomes with pre-trained models covering a wide range of domains for voice\nactivity detection, speaker change detection, overlapped speech detection, and\nspeaker embedding -- reaching state-of-the-art performance for most of them.", "published": "2019-11-04 14:46:31", "link": "http://arxiv.org/abs/1911.01255v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Voice Biometrics Security: Extrapolating False Alarm Rate via\n  Hierarchical Bayesian Modeling of Speaker Verification Scores", "abstract": "How secure automatic speaker verification (ASV) technology is? More\nconcretely, given a specific target speaker, how likely is it to find another\nperson who gets falsely accepted as that target? This question may be addressed\nempirically by studying naturally confusable pairs of speakers within a large\nenough corpus. To this end, one might expect to find at least some speaker\npairs that are indistinguishable from each other in terms of ASV. To a certain\nextent, such aim is mirrored in the standardized ASV evaluation benchmarks.\nHowever, the number of speakers in such evaluation benchmarks represents only a\nsmall fraction of all possible human voices, making it challenging to\nextrapolate performance beyond a given corpus. Furthermore, the impostors used\nin performance evaluation are usually selected randomly. A potentially more\nmeaningful definition of an impostor - at least in the context of\nsecurity-driven ASV applications - would be closest (most confusable) other\nspeaker to a given target.\n  We put forward a novel performance assessment framework to address both the\ninadequacy of the random-impostor evaluation model and the size limitation of\nevaluation corpora by addressing ASV security against closest impostors on\narbitrarily large datasets. The framework allows one to make a prediction of\nthe safety of given ASV technology, in its current state, for arbitrarily large\nspeaker database size consisting of virtual (sampled) speakers. As a\nproof-of-concept, we analyze the performance of two state-of-the-art ASV\nsystems, based on i-vector and x-vector speaker embeddings (as implemented in\nthe popular Kaldi toolkit), on the recent VoxCeleb 1 & 2 corpora. We found that\nneither the i-vector or x-vector system is immune to increased false alarm rate\nat increased impostor database size.", "published": "2019-11-04 13:13:45", "link": "http://arxiv.org/abs/1911.01182v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Supervised online diarization with sample mean loss for multi-domain\n  data", "abstract": "Recently, a fully supervised speaker diarization approach was proposed\n(UIS-RNN) which models speakers using multiple instances of a parameter-sharing\nrecurrent neural network. In this paper we propose qualitative modifications to\nthe model that significantly improve the learning efficiency and the overall\ndiarization performance. In particular, we introduce a novel loss function, we\ncalled Sample Mean Loss and we present a better modelling of the speaker turn\nbehaviour, by devising an analytical expression to compute the probability of a\nnew speaker joining the conversation. In addition, we demonstrate that our\nmodel can be trained on fixed-length speech segments, removing the need for\nspeaker change information in inference. Using x-vectors as input features, we\nevaluate our proposed approach on the multi-domain dataset employed in the\nDIHARD II challenge: our online method improves with respect to the original\nUIS-RNN and achieves similar performance to an offline agglomerative clustering\nbaseline using PLDA scoring.", "published": "2019-11-04 15:01:30", "link": "http://arxiv.org/abs/1911.01266v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker-invariant Affective Representation Learning via Adversarial\n  Training", "abstract": "Representation learning for speech emotion recognition is challenging due to\nlabeled data sparsity issue and lack of gold standard references. In addition,\nthere is much variability from input speech signals, human subjective\nperception of the signals and emotion label ambiguity. In this paper, we\npropose a machine learning framework to obtain speech emotion representations\nby limiting the effect of speaker variability in the speech signals.\nSpecifically, we propose to disentangle the speaker characteristics from\nemotion through an adversarial training network in order to better represent\nemotion. Our method combines the gradient reversal technique with an entropy\nloss function to remove such speaker information. Our approach is evaluated on\nboth IEMOCAP and CMU-MOSEI datasets. We show that our method improves speech\nemotion classification and increases generalization to unseen speakers.", "published": "2019-11-04 23:35:19", "link": "http://arxiv.org/abs/1911.01533v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
