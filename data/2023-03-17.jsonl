{"title": "Learning towards Selective Data Augmentation for Dialogue Generation", "abstract": "As it is cumbersome and expensive to acquire a huge amount of data for\ntraining neural dialog models, data augmentation is proposed to effectively\nutilize existing training samples. However, current data augmentation\ntechniques on the dialog generation task mostly augment all cases in the\ntraining dataset without considering the intrinsic attributes between different\ncases. We argue that not all cases are beneficial for augmentation task, and\nthe cases suitable for augmentation should obey the following two attributes:\n(1) low-quality (the dialog model cannot generate a high-quality response for\nthe case), (2) representative (the case should represent the property of the\nwhole dataset). Herein, we explore this idea by proposing a Selective Data\nAugmentation framework (SDA) for the response generation task. SDA employs a\ndual adversarial network to select the lowest quality and most representative\ndata points for augmentation in one stage. Extensive experiments conducted on\ntwo publicly available datasets, i.e., DailyDialog and OpenSubtitles, show that\nour framework can improve the response generation performance with respect to\nvarious metrics.", "published": "2023-03-17 01:26:39", "link": "http://arxiv.org/abs/2303.09719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trained on 100 million words and still in shape: BERT meets British\n  National Corpus", "abstract": "While modern masked language models (LMs) are trained on ever larger corpora,\nwe here explore the effects of down-scaling training to a modestly-sized but\nrepresentative, well-balanced, and publicly available English text source --\nthe British National Corpus. We show that pre-training on this carefully\ncurated corpus can reach better performance than the original BERT model. We\nargue that this type of corpora has great potential as a language modeling\nbenchmark. To showcase this potential, we present fair, reproducible and\ndata-efficient comparative studies of LMs, in which we evaluate several\ntraining objectives and model architectures and replicate previous empirical\nresults in a systematic way. We propose an optimized LM architecture called\nLTG-BERT.", "published": "2023-03-17 09:53:33", "link": "http://arxiv.org/abs/2303.09859v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memotion 3: Dataset on Sentiment and Emotion Analysis of Codemixed\n  Hindi-English Memes", "abstract": "Memes are the new-age conveyance mechanism for humor on social media sites.\nMemes often include an image and some text. Memes can be used to promote\ndisinformation or hatred, thus it is crucial to investigate in details. We\nintroduce Memotion 3, a new dataset with 10,000 annotated memes. Unlike other\nprevalent datasets in the domain, including prior iterations of Memotion,\nMemotion 3 introduces Hindi-English Codemixed memes while prior works in the\narea were limited to only the English memes. We describe the Memotion task, the\ndata collection and the dataset creation methodologies. We also provide a\nbaseline for the task. The baseline code and dataset will be made available at\nhttps://github.com/Shreyashm16/Memotion-3.0", "published": "2023-03-17 11:13:30", "link": "http://arxiv.org/abs/2303.09892v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "More Robust Schema-Guided Dialogue State Tracking via Tree-Based\n  Paraphrase Ranking", "abstract": "The schema-guided paradigm overcomes scalability issues inherent in building\ntask-oriented dialogue (TOD) agents with static ontologies. Instead of\noperating on dialogue context alone, agents have access to hierarchical schemas\ncontaining task-relevant natural language descriptions. Fine-tuned language\nmodels excel at schema-guided dialogue state tracking (DST) but are sensitive\nto the writing style of the schemas. We explore methods for improving the\nrobustness of DST models. We propose a framework for generating synthetic\nschemas which uses tree-based ranking to jointly optimise lexical diversity and\nsemantic faithfulness. The generalisation of strong baselines is improved when\naugmenting their training data with prompts generated by our framework, as\ndemonstrated by marked improvements in average joint goal accuracy (JGA) and\nschema sensitivity (SS) on the SGD-X benchmark.", "published": "2023-03-17 11:43:08", "link": "http://arxiv.org/abs/2303.09905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CHAMPAGNE: Learning Real-world Conversation from Large-Scale Web Videos", "abstract": "Visual information is central to conversation: body gestures and physical\nbehaviour, for example, contribute to meaning that transcends words alone. To\ndate, however, most neural conversational models are limited to just text. We\nintroduce CHAMPAGNE, a generative model of conversations that can account for\nvisual contexts. To train CHAMPAGNE, we collect and release YTD-18M, a\nlarge-scale corpus of 18M video-based dialogues. YTD-18M is constructed from\nweb videos: crucial to our data collection pipeline is a pretrained language\nmodel that converts error-prone automatic transcripts to a cleaner dialogue\nformat while maintaining meaning. Human evaluation reveals that YTD-18M is more\nsensible and specific than prior resources (MMDialog, 1M dialogues), while\nmaintaining visual-groundedness. Experiments demonstrate that 1) CHAMPAGNE\nlearns to conduct conversation from YTD-18M; and 2) when fine-tuned, it\nachieves state-of-the-art results on four vision-language tasks focused on\nreal-world conversations. We release data, models, and code.", "published": "2023-03-17 01:10:33", "link": "http://arxiv.org/abs/2303.09713v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoLT5: Faster Long-Range Transformers with Conditional Computation", "abstract": "Many natural language processing tasks benefit from long inputs, but\nprocessing long documents with Transformers is expensive -- not only due to\nquadratic attention complexity but also from applying feedforward and\nprojection layers to every token. However, not all tokens are equally\nimportant, especially for longer documents. We propose CoLT5, a long-input\nTransformer model that builds on this intuition by employing conditional\ncomputation, devoting more resources to important tokens in both feedforward\nand attention layers. We show that CoLT5 achieves stronger performance than\nLongT5 with much faster training and inference, achieving SOTA on the\nlong-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably\nmake use of extremely long inputs, showing strong gains up to 64k input length.", "published": "2023-03-17 03:28:17", "link": "http://arxiv.org/abs/2303.09752v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through\n  Dependency Parsing", "abstract": "We present our work on Track 2 in the Dialog System Technology Challenges 11\n(DSTC11). DSTC11-Track2 aims to provide a benchmark for zero-shot,\ncross-domain, intent-set induction. In the absence of in-domain training\ndataset, robust utterance representation that can be used across domains is\nnecessary to induce users' intentions. To achieve this, we leveraged a\nmulti-domain dialogue dataset to fine-tune the language model and proposed\nextracting Verb-Object pairs to remove the artifacts of unnecessary\ninformation. Furthermore, we devised the method that generates each cluster's\nname for the explainability of clustered results. Our approach achieved 3rd\nplace in the precision score and showed superior accuracy and normalized mutual\ninformation (NMI) score than the baseline model on various domain datasets.", "published": "2023-03-17 08:12:36", "link": "http://arxiv.org/abs/2303.09827v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Direct and indirect evidence of compression of word lengths. Zipf's law\n  of abbreviation revisited", "abstract": "Zipf's law of abbreviation, the tendency of more frequent words to be\nshorter, is one of the most solid candidates for a linguistic universal, in the\nsense that it has the potential for being exceptionless or with a number of\nexceptions that is vanishingly small compared to the number of languages on\nEarth. Since Zipf's pioneering research, this law has been viewed as a\nmanifestation of a universal principle of communication, i.e. the minimization\nof word lengths, to reduce the effort of communication. Here we revisit the\nconcordance of written language with the law of abbreviation. Crucially, we\nprovide wider evidence that the law holds also in speech (when word length is\nmeasured in time), in particular in 46 languages from 14 linguistic families.\nAgreement with the law of abbreviation provides indirect evidence of\ncompression of languages via the theoretical argument that the law of\nabbreviation is a prediction of optimal coding. Motivated by the need of direct\nevidence of compression, we derive a simple formula for a random baseline\nindicating that word lengths are systematically below chance, across linguistic\nfamilies and writing systems, and independently of the unit of measurement\n(length in characters or duration in time). Our work paves the way to measure\nand compare the degree of optimality of word lengths in languages.", "published": "2023-03-17 17:12:18", "link": "http://arxiv.org/abs/2303.10128v2", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Feedback Effect in User Interaction with Intelligent Assistants: Delayed\n  Engagement, Adaption and Drop-out", "abstract": "With the growing popularity of intelligent assistants (IAs), evaluating IA\nquality becomes an increasingly active field of research. This paper identifies\nand quantifies the feedback effect, a novel component in IA-user interactions:\nhow the capabilities and limitations of the IA influence user behavior over\ntime. First, we demonstrate that unhelpful responses from the IA cause users to\ndelay or reduce subsequent interactions in the short term via an observational\nstudy. Next, we expand the time horizon to examine behavior changes and show\nthat as users discover the limitations of the IA's understanding and functional\ncapabilities, they learn to adjust the scope and wording of their requests to\nincrease the likelihood of receiving a helpful response from the IA. Our\nfindings highlight the impact of the feedback effect at both the micro and meso\nlevels. We further discuss its macro-level consequences: unsatisfactory\ninteractions continuously reduce the likelihood and diversity of future user\nengagements in a feedback loop.", "published": "2023-03-17 21:39:33", "link": "http://arxiv.org/abs/2303.10255v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Transformers and Ensemble methods: A solution for Hate Speech Detection\n  in Arabic languages", "abstract": "This paper describes our participation in the shared task of hate speech\ndetection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our\nexperiments evaluate the performance of six transformer models and their\ncombination using 2 ensemble approaches. The best results on the training set,\nin a five-fold cross validation scenario, were obtained by using the ensemble\napproach based on the majority vote. The evaluation of this approach on the\ntest set resulted in an F1-score of 0.60 and an Accuracy of 0.86.", "published": "2023-03-17 08:02:54", "link": "http://arxiv.org/abs/2303.09823v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive\n  Pre-Training of Transformers for Few- and Zero-shot Framing Detection", "abstract": "This paper presents the winning system for the zero-shot Spanish framing\ndetection task, which also achieves competitive places in eight additional\nlanguages. The challenge of the framing detection task lies in identifying a\nset of 14 frames when only a few or zero samples are available, i.e., a\nmultilingual multi-label few- or zero-shot setting. Our developed solution\nemploys a pre-training procedure based on multilingual Transformers using a\nlabel-aware contrastive loss function. In addition to describing the system, we\nperform an embedding space analysis and ablation study to demonstrate how our\npre-training procedure supports framing detection to advance computational\nframing analysis.", "published": "2023-03-17 11:33:06", "link": "http://arxiv.org/abs/2303.09901v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.7; J.7"], "primary_category": "cs.CL"}
{"title": "Investigating the Role of Attribute Context in Vision-Language Models\n  for Object Recognition and Detection", "abstract": "Vision-language alignment learned from image-caption pairs has been shown to\nbenefit tasks like object recognition and detection. Methods are mostly\nevaluated in terms of how well object class names are learned, but captions\nalso contain rich attribute context that should be considered when learning\nobject alignment. It is unclear how methods use this context in learning, as\nwell as whether models succeed when tasks require attribute and object\nunderstanding. To address this gap, we conduct extensive analysis of the role\nof attributes in vision-language models. We specifically measure model\nsensitivity to the presence and meaning of attribute context, gauging influence\non object embeddings through unsupervised phrase grounding and classification\nvia description methods. We further evaluate the utility of attribute context\nin training for open-vocabulary object detection, fine-grained text-region\nretrieval, and attribution tasks. Our results show that attribute context can\nbe wasted when learning alignment for detection, attribute meaning is not\nadequately considered in embeddings, and describing classes by only their\nattributes is ineffective. A viable strategy that we find to increase benefits\nfrom attributes is contrastive training with adjective-based negative captions.", "published": "2023-03-17 16:14:37", "link": "http://arxiv.org/abs/2303.10093v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Conversational Tree Search: A New Hybrid Dialog Task", "abstract": "Conversational interfaces provide a flexible and easy way for users to seek\ninformation that may otherwise be difficult or inconvenient to obtain. However,\nexisting interfaces generally fall into one of two categories: FAQs, where\nusers must have a concrete question in order to retrieve a general answer, or\ndialogs, where users must follow a predefined path but may receive a\npersonalized answer. In this paper, we introduce Conversational Tree Search\n(CTS) as a new task that bridges the gap between FAQ-style information\nretrieval and task-oriented dialog, allowing domain-experts to define dialog\ntrees which can then be converted to an efficient dialog policy that learns\nonly to ask the questions necessary to navigate a user to their goal. We\ncollect a dataset for the travel reimbursement domain and demonstrate a\nbaseline as well as a novel deep Reinforcement Learning architecture for this\ntask. Our results show that the new architecture combines the positive aspects\nof both the FAQ and dialog system used in the baseline and achieves higher goal\ncompletion while skipping unnecessary questions.", "published": "2023-03-17 19:50:51", "link": "http://arxiv.org/abs/2303.10227v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can AI-Generated Text be Reliably Detected?", "abstract": "Large Language Models (LLMs) perform impressively well in various\napplications. However, the potential for misuse of these models in activities\nsuch as plagiarism, generating fake news, and spamming has raised concern about\ntheir responsible use. Consequently, the reliable detection of AI-generated\ntext has become a critical area of research. AI text detectors have shown to be\neffective under their specific settings. In this paper, we stress-test the\nrobustness of these AI text detectors in the presence of an attacker. We\nintroduce recursive paraphrasing attack to stress test a wide range of\ndetection schemes, including the ones using the watermarking as well as neural\nnetwork-based detectors, zero shot classifiers, and retrieval-based detectors.\nOur experiments conducted on passages, each approximately 300 tokens long,\nreveal the varying sensitivities of these detectors to our attacks. Our\nfindings indicate that while our recursive paraphrasing method can\nsignificantly reduce detection rates, it only slightly degrades text quality in\nmany cases, highlighting potential vulnerabilities in current detection systems\nin the presence of an attacker. Additionally, we investigate the susceptibility\nof watermarked LLMs to spoofing attacks aimed at misclassifying human-written\ntext as AI-generated. We demonstrate that an attacker can infer hidden AI text\nsignatures without white-box access to the detection method, potentially\nleading to reputational risks for LLM developers. Finally, we provide a\ntheoretical framework connecting the AUROC of the best possible detector to the\nTotal Variation distance between human and AI text distributions. This analysis\noffers insights into the fundamental challenges of reliable detection as\nlanguage models continue to advance. Our code is publicly available at\nhttps://github.com/vinusankars/Reliability-of-AI-text-detectors.", "published": "2023-03-17 17:53:19", "link": "http://arxiv.org/abs/2303.11156v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Practical and Ethical Challenges of Large Language Models in Education:\n  A Systematic Scoping Review", "abstract": "Educational technology innovations leveraging large language models (LLMs)\nhave shown the potential to automate the laborious process of generating and\nanalysing textual content. While various innovations have been developed to\nautomate a range of educational tasks (e.g., question generation, feedback\nprovision, and essay grading), there are concerns regarding the practicality\nand ethicality of these innovations. Such concerns may hinder future research\nand the adoption of LLMs-based innovations in authentic educational contexts.\nTo address this, we conducted a systematic scoping review of 118 peer-reviewed\npapers published since 2017 to pinpoint the current state of research on using\nLLMs to automate and support educational tasks. The findings revealed 53 use\ncases for LLMs in automating education tasks, categorised into nine main\ncategories: profiling/labelling, detection, grading, teaching support,\nprediction, knowledge representation, feedback, content generation, and\nrecommendation. Additionally, we also identified several practical and ethical\nchallenges, including low technological readiness, lack of replicability and\ntransparency, and insufficient privacy and beneficence considerations. The\nfindings were summarised into three recommendations for future studies,\nincluding updating existing innovations with state-of-the-art models (e.g.,\nGPT-3/4), embracing the initiative of open-sourcing models/systems, and\nadopting a human-centred approach throughout the developmental process. As the\nintersection of AI and education is continuously evolving, the findings of this\nstudy can serve as an essential reference point for researchers, allowing them\nto leverage the strengths, learn from the limitations, and uncover potential\nresearch opportunities enabled by ChatGPT and other generative AI models.", "published": "2023-03-17 18:14:46", "link": "http://arxiv.org/abs/2303.13379v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Magnitude-Corrected and Time-Aligned Interpolation of Head-Related\n  Transfer Functions", "abstract": "Head-related transfer functions (HRTFs) are essential for virtual acoustic\nrealities, as they contain all cues for localizing sound sources in\nthree-dimensional space. Acoustic measurements are one way to obtain\nhigh-quality HRTFs. To reduce measurement time, cost, and complexity of\nmeasurement systems, a promising approach is to capture only a few HRTFs on a\nsparse sampling grid and then upsample them to a dense HRTF set by\ninterpolation. However, HRTF interpolation is challenging because small changes\nin source position can result in significant changes in the HRTF phase and\nmagnitude response. Previous studies greatly improved the interpolation by\ntime-aligning the HRTFs in preprocessing, but magnitude interpolation errors,\nespecially in contralateral regions, remain a problem. Building upon the\ntime-alignment approaches, we propose an additional post-interpolation\nmagnitude correction derived from a frequency-smoothed HRTF representation.\nEmploying all 96 individual simulated HRTF sets of the HUTUBS database, we show\nthat the magnitude correction significantly reduces interpolation errors\ncompared to state-of-the-art interpolation methods applying only time\nalignment. Our analysis shows that when upsampling very sparse HRTF sets, the\nsubject-averaged magnitude error in the critical higher frequency range is up\nto 1.5 dB lower when averaged over all directions and even up to 4 dB lower in\nthe contralateral region. As a result, the interaural level differences in the\nupsampled HRTFs are considerably improved. The proposed algorithm thus has the\npotential to further reduce the minimum number of HRTFs required for\nperceptually transparent interpolation.", "published": "2023-03-17 13:39:41", "link": "http://arxiv.org/abs/2303.09966v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Configurable EBEN: Extreme Bandwidth Extension Network to enhance\n  body-conducted speech capture", "abstract": "This paper presents a configurable version of Extreme Bandwidth Extension\nNetwork (EBEN), a Generative Adversarial Network (GAN) designed to improve\naudio captured with body-conduction microphones. We show that although these\nmicrophones significantly reduce environmental noise, this insensitivity to\nambient noise happens at the expense of the bandwidth of the speech signal\nacquired by the wearer of the devices. The obtained captured signals therefore\nrequire the use of signal enhancement techniques to recover the full-bandwidth\nspeech. EBEN leverages a configurable multiband decomposition of the raw\ncaptured signal. This decomposition allows the data time domain dimensions to\nbe reduced and the full band signal to be better controlled. The multiband\nrepresentation of the captured signal is processed through a U-Net-like model,\nwhich combines feature and adversarial losses to generate an enhanced speech\nsignal. We also benefit from this original representation in the proposed\nconfigurable discriminators architecture. The configurable EBEN approach can\nachieve state-of-the-art enhancement results on synthetic data with a\nlightweight generator that allows real-time processing.", "published": "2023-03-17 14:31:24", "link": "http://arxiv.org/abs/2303.10008v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
