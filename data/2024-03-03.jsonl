{"title": "Improving Cross-lingual Representation for Semantic Retrieval with\n  Code-switching", "abstract": "Semantic Retrieval (SR) has become an indispensable part of the FAQ system in\nthe task-oriented question-answering (QA) dialogue scenario. The demands for a\ncross-lingual smart-customer-service system for an e-commerce platform or some\nparticular business conditions have been increasing recently. Most previous\nstudies exploit cross-lingual pre-trained models (PTMs) for multi-lingual\nknowledge retrieval directly, while some others also leverage the continual\npre-training before fine-tuning PTMs on the downstream tasks. However, no\nmatter which schema is used, the previous work ignores to inform PTMs of some\nfeatures of the downstream task, i.e. train their PTMs without providing any\nsignals related to SR. To this end, in this work, we propose an Alternative\nCross-lingual PTM for SR via code-switching. We are the first to utilize the\ncode-switching approach for cross-lingual SR. Besides, we introduce the novel\ncode-switched continual pre-training instead of directly using the PTMs on the\nSR tasks. The experimental results show that our proposed approach consistently\noutperforms the previous SOTA methods on SR and semantic textual similarity\n(STS) tasks with three business corpora and four open datasets in 20+\nlanguages.", "published": "2024-03-03 01:47:52", "link": "http://arxiv.org/abs/2403.01364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantity Matters: Towards Assessing and Mitigating Number Hallucination\n  in Large Vision-Language Models", "abstract": "Large-scale vision-language models have demonstrated impressive skill in\nhandling tasks that involve both areas. Nevertheless, these models frequently\nexperience significant issues with generating inaccurate information, which is\nhallucination. In this study, we concentrate on a specific type of\nhallucination-number hallucination, referring to models incorrectly identifying\nthe number of certain objects in pictures. We perform quantitative evaluations\nregarding number hallucination, showing it to be critical in major open-source\nlarge vision-language models. Furthermore, we utilizes two related tasks to\nconduct an in-depth analysis of number hallucination, revealing the severe\ninner and outer inconsistency among all tasks. Based on this examination, we\ndevise a training approach aimed at improving consistency to reduce number\nhallucinations, which leads to an 8% enhancement in performance over direct\nfinetuning methods. Our code and dataset will be released to the community.", "published": "2024-03-03 02:31:11", "link": "http://arxiv.org/abs/2403.01373v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Question-Answer Generation for Long-Tail Knowledge", "abstract": "Pretrained Large Language Models (LLMs) have gained significant attention for\naddressing open-domain Question Answering (QA). While they exhibit high\naccuracy in answering questions related to common knowledge, LLMs encounter\ndifficulties in learning about uncommon long-tail knowledge (tail entities).\nSince manually constructing QA datasets demands substantial human resources,\nthe types of existing QA datasets are limited, leaving us with a scarcity of\ndatasets to study the performance of LLMs on tail entities. In this paper, we\npropose an automatic approach to generate specialized QA datasets for tail\nentities and present the associated research challenges. We conduct extensive\nexperiments by employing pretrained LLMs on our newly generated long-tail QA\ndatasets, comparing their performance with and without external resources\nincluding Wikipedia and Wikidata knowledge graphs.", "published": "2024-03-03 03:06:31", "link": "http://arxiv.org/abs/2403.01382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Right for Right Reasons: Large Language Models for Verifiable\n  Commonsense Knowledge Graph Question Answering", "abstract": "Knowledge Graph Question Answering (KGQA) methods seek to answer Natural\nLanguage questions using the relational information stored in Knowledge Graphs\n(KGs). With the recent advancements of Large Language Models (LLMs) and their\nremarkable reasoning abilities, there is a growing trend to leverage them for\nKGQA. However, existing methodologies have only focused on answering factual\nquestions, e.g., \"In which city was Silvio Berlusconi's first wife born?\",\nleaving questions involving commonsense reasoning that real-world users may\npose more often, e.g., \"Do I need separate visas to see the Venus of Willendorf\nand attend the Olympics this summer?\" unaddressed. In this work, we first\nobserve that existing LLM-based methods for KGQA struggle with hallucination on\nsuch questions, especially on queries targeting long-tail entities (e.g.,\nnon-mainstream and recent entities), thus hindering their applicability in\nreal-world applications especially since their reasoning processes are not\neasily verifiable. In response, we propose Right for Right Reasons (R3), a\ncommonsense KGQA methodology that allows for a verifiable reasoning procedure\nby axiomatically surfacing intrinsic commonsense knowledge of LLMs and\ngrounding every factual reasoning step on KG triples. Through experimental\nevaluations across three different tasks--question answering, claim\nverification, and preference matching--our findings showcase R3 as a superior\napproach, outperforming existing methodologies and notably reducing instances\nof hallucination and reasoning errors.", "published": "2024-03-03 04:22:13", "link": "http://arxiv.org/abs/2403.01390v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring\n  Commonsense Reasoning and Long-Tail Knowledge", "abstract": "Knowledge graph question answering (KGQA) is a well-established field that\nseeks to provide factual answers to natural language (NL) questions by\nleveraging knowledge graphs (KGs). However, existing KGQA datasets suffer from\ntwo significant limitations: (1) no existing KGQA dataset requires commonsense\nreasoning to arrive at an answer and (2) existing KGQA datasets focus on\npopular entities for which large language models (LLMs) can directly answer\nwithout hallucinating and without leveraging the KG. In this work, we seek a\nnovel KGQA dataset that supports commonsense reasoning and focuses on long-tail\nentities (e.g., non-mainstream and recent entities) where LLMs frequently\nhallucinate, and thus create the need for novel methodologies that leverage the\nKG for factual and attributable commonsense inference. We create a novel\nCommonsense Reasoning (CR) and Long-Tail (LT) KGQA dataset with two subtasks --\nquestion answering and claim verification -- that address both limitations (1)\nand (2). We construct CR-LT-KGQA by building extensions to existing reasoning\ndatasets StrategyQA and CREAK over Wikidata. While existing KGQA methods are\nnot applicable due to their lack of commonsense inference support, baseline\nevaluation of LLMs on CR-LT KGQA demonstrate a high rate of hallucination.\nThus, CR-LT KGQA poses significant challenges for hallucination-prone LLMs,\nhence paving the way for future commonsense KGQA research to provide accurate\nand factual answers for long-tail entities in the era of LLMs.", "published": "2024-03-03 04:47:01", "link": "http://arxiv.org/abs/2403.01395v1", "categories": ["cs.CL", "I.2.4, I.2.7"], "primary_category": "cs.CL"}
{"title": "What Is Missing in Multilingual Visual Reasoning and How to Fix It", "abstract": "NLP models today strive for supporting multiple languages and modalities,\nimproving accessibility for diverse users. In this paper, we evaluate their\nmultilingual, multimodal capabilities by testing on a visual reasoning task. We\nobserve that proprietary systems like GPT-4V obtain the best performance on\nthis task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits\nsimilar performance between English and other languages, indicating the\npotential for equitable system development across languages. Our analysis on\nmodel failures reveals three key aspects that make this task challenging:\nmultilinguality, complex reasoning, and multimodality. To address these\nchallenges, we propose three targeted interventions including a translate-test\napproach to tackle multilinguality, a visual programming approach to break down\ncomplex reasoning, and a method that leverages image captioning to address\nmultimodality. Our interventions achieve the best open performance on this task\nin a zero-shot setting, boosting open models LLaVA-v1.5-13B by 13.4%,\nLLaVA-v1.6-34B by 20.3%, and Qwen-VL by 16.7%, while also minorly improving\nGPT-4V's performance.", "published": "2024-03-03 05:45:27", "link": "http://arxiv.org/abs/2403.01404v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OVEL: Large Language Model as Memory Manager for Online Video Entity\n  Linking", "abstract": "In recent years, multi-modal entity linking (MEL) has garnered increasing\nattention in the research community due to its significance in numerous\nmulti-modal applications. Video, as a popular means of information\ntransmission, has become prevalent in people's daily lives. However, most\nexisting MEL methods primarily focus on linking textual and visual mentions or\noffline videos's mentions to entities in multi-modal knowledge bases, with\nlimited efforts devoted to linking mentions within online video content. In\nthis paper, we propose a task called Online Video Entity Linking OVEL, aiming\nto establish connections between mentions in online videos and a knowledge base\nwith high accuracy and timeliness. To facilitate the research works of OVEL, we\nspecifically concentrate on live delivery scenarios and construct a live\ndelivery entity linking dataset called LIVE. Besides, we propose an evaluation\nmetric that considers timelessness, robustness, and accuracy. Furthermore, to\neffectively handle OVEL task, we leverage a memory block managed by a Large\nLanguage Model and retrieve entity candidates from the knowledge base to\naugment LLM performance on memory management. The experimental results prove\nthe effectiveness and efficiency of our method.", "published": "2024-03-03 06:47:51", "link": "http://arxiv.org/abs/2403.01411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular\n  Knowledge", "abstract": "Language Models (LMs) memorize a vast amount of factual knowledge, exhibiting\nstrong performance across diverse tasks and domains. However, it has been\nobserved that the performance diminishes when dealing with less-popular or\nlow-frequency concepts and entities, for example in domain specific\napplications. The two prominent approaches to enhance the performance of LMs on\nlow-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning\n(FT) over synthetic data. This paper explores and evaluates the impact of RAG\nand FT on customizing LMs in handling low-frequency entities on question\nanswering tasks. We conduct extensive experiments on twelve LMs of varying size\nand type and different fine tuning, data augmentation, and retrieval models.\nOur findings indicate that while FT boosts the performance across entities of\nvarying popularity, RAG surpasses FT by a large margin particularly for least\npopular factual knowledge. Additionally, the success of both RAG and FT\napproaches is amplified by improving retrieval and data augmentation\ntechniques. Fine tuning, while beneficial for small LMs, requires extensive\nresources. To address this issue, we propose the new Stimulus RAG approach that\nsurpasses the effectiveness of fine tuning based approaches, thereby\neliminating the need for the costly data augmentation and fine tuning step for\nenriching LMs with less popular factual knowledge. The code is available at\n\\url{https://github.com/informagi/RAGvsFT}.", "published": "2024-03-03 08:07:55", "link": "http://arxiv.org/abs/2403.01432v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answerability in Retrieval-Augmented Open-Domain Question Answering", "abstract": "The performance of Open-Domain Question Answering (ODQA) retrieval systems\ncan exhibit sub-optimal behavior, providing text excerpts with varying degrees\nof irrelevance. Unfortunately, many existing ODQA datasets lack examples\nspecifically targeting the identification of irrelevant text excerpts. Previous\nattempts to address this gap have relied on a simplistic approach of pairing\nquestions with random text excerpts. This paper aims to investigate the\neffectiveness of models trained using this randomized strategy, uncovering an\nimportant limitation in their ability to generalize to irrelevant text excerpts\nwith high semantic overlap. As a result, we observed a substantial decrease in\npredictive accuracy, from 98% to 1%. To address this limitation, we discovered\nan efficient approach for training models to recognize such excerpts. By\nleveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a\nnearly perfect (~100%) accuracy when confronted with these challenging text\nexcerpts.", "published": "2024-03-03 09:55:35", "link": "http://arxiv.org/abs/2403.01461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean\n  Healthcare Professional Licensing Examinations", "abstract": "We present KorMedMCQA, the first Korean Medical Multiple-Choice Question\nAnswering benchmark, derived from professional healthcare licensing\nexaminations conducted in Korea between 2012 and 2024. The dataset contains\n7,469 questions from examinations for doctor, nurse, pharmacist, and dentist,\ncovering a wide range of medical disciplines. We evaluate the performance of 59\nlarge language models, spanning proprietary and open-source models,\nmultilingual and Korean-specialized models, and those fine-tuned for clinical\napplications. Our results show that applying Chain of Thought (CoT) reasoning\ncan enhance the model performance by up to 4.5% compared to direct answering\napproaches. We also investigate whether MedQA, one of the most widely used\nmedical benchmarks derived from the U.S. Medical Licensing Examination, can\nserve as a reliable proxy for evaluating model performance in other regions-in\nthis case, Korea. Our correlation analysis between model scores on KorMedMCQA\nand MedQA reveals that these two benchmarks align no better than benchmarks\nfrom entirely different domains (e.g., MedQA and MMLU-Pro). This finding\nunderscores the substantial linguistic and clinical differences between Korean\nand U.S. medical contexts, reinforcing the need for region-specific medical QA\nbenchmarks. To support ongoing research in Korean healthcare AI, we publicly\nrelease the KorMedMCQA via Huggingface.", "published": "2024-03-03 10:31:49", "link": "http://arxiv.org/abs/2403.01469v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Infusing Knowledge into Large Language Models with Contextual Prompts", "abstract": "Knowledge infusion is a promising method for enhancing Large Language Models\nfor domain-specific NLP tasks rather than pre-training models over large data\nfrom scratch. These augmented LLMs typically depend on additional pre-training\nor knowledge prompts from an existing knowledge graph, which is impractical in\nmany applications. In contrast, knowledge infusion directly from relevant\ndocuments is more generalisable and alleviates the need for structured\nknowledge graphs while also being useful for entities that are usually not\nfound in any knowledge graph. With this motivation, we propose a simple yet\ngeneralisable approach for knowledge infusion by generating prompts from the\ncontext in the input text. Our experiments show the effectiveness of our\napproach which we evaluate by probing the fine-tuned LLMs.", "published": "2024-03-03 11:19:26", "link": "http://arxiv.org/abs/2403.01481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fantastic Semantics and Where to Find Them: Investigating Which Layers\n  of Generative LLMs Reflect Lexical Semantics", "abstract": "Large language models have achieved remarkable success in general language\nunderstanding tasks. However, as a family of generative methods with the\nobjective of next token prediction, the semantic evolution with the depth of\nthese models are not fully explored, unlike their predecessors, such as\nBERT-like architectures. In this paper, we specifically investigate the\nbottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by\nprobing its hidden states at the end of each layer using a contextualized word\nidentification task. Our experiments show that the representations in lower\nlayers encode lexical semantics, while the higher layers, with weaker semantic\ninduction, are responsible for prediction. This is in contrast to models with\ndiscriminative objectives, such as mask language modeling, where the higher\nlayers obtain better lexical semantics. The conclusion is further supported by\nthe monotonic increase in performance via the hidden states for the last\nmeaningless symbols, such as punctuation, in the prompting strategy. Our codes\nare available at https://github.com/RyanLiut/LLM_LexSem.", "published": "2024-03-03 13:14:47", "link": "http://arxiv.org/abs/2403.01509v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Comprehensive Vietnamese Retrieval-Augmented Generation and\n  Large Language Models", "abstract": "This paper presents our contributions towards advancing the state of\nVietnamese language understanding and generation through the development and\ndissemination of open datasets and pre-trained models for Vietnamese\nRetrieval-Augmented Generation (RAG) and Large Language Models (LLMs).", "published": "2024-03-03 21:24:35", "link": "http://arxiv.org/abs/2403.01616v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-level Product Category Prediction through Text Classification", "abstract": "This article investigates applying advanced machine learning models,\nspecifically LSTM and BERT, for text classification to predict multiple\ncategories in the retail sector. The study demonstrates how applying data\naugmentation techniques and the focal loss function can significantly enhance\naccuracy in classifying products into multiple categories using a robust\nBrazilian retail dataset. The LSTM model, enriched with Brazilian word\nembedding, and BERT, known for its effectiveness in understanding complex\ncontexts, were adapted and optimized for this specific task. The results showed\nthat the BERT model, with an F1 Macro Score of up to $99\\%$ for segments,\n$96\\%$ for categories and subcategories and $93\\%$ for name products,\noutperformed LSTM in more detailed categories. However, LSTM also achieved high\nperformance, especially after applying data augmentation and focal loss\ntechniques. These results underscore the effectiveness of NLP techniques in\nretail and highlight the importance of the careful selection of modelling and\npreprocessing strategies. This work contributes significantly to the field of\nNLP in retail, providing valuable insights for future research and practical\napplications.", "published": "2024-03-03 23:10:36", "link": "http://arxiv.org/abs/2403.01638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModelWriter: Text & Model-Synchronized Document Engineering Platform", "abstract": "The ModelWriter platform provides a generic framework for automated\ntraceability analysis. In this paper, we demonstrate how this framework can be\nused to trace the consistency and completeness of technical documents that\nconsist of a set of System Installation Design Principles used by Airbus to\nensure the correctness of aircraft system installation. We show in particular,\nhow the platform allows the integration of two types of reasoning: reasoning\nabout the meaning of text using semantic parsing and description logic theorem\nproving; and reasoning about document structure using first-order relational\nlogic and finite model finding for traceability analysis.", "published": "2024-03-03 01:26:12", "link": "http://arxiv.org/abs/2403.01359v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Logic Rules as Explanations for Legal Case Retrieval", "abstract": "In this paper, we address the issue of using logic rules to explain the\nresults from legal case retrieval. The task is critical to legal case retrieval\nbecause the users (e.g., lawyers or judges) are highly specialized and require\nthe system to provide logical, faithful, and interpretable explanations before\nmaking legal decisions. Recently, research efforts have been made to learn\nexplainable legal case retrieval models. However, these methods usually select\nrationales (key sentences) from the legal cases as explanations, failing to\nprovide faithful and logically correct explanations. In this paper, we propose\nNeural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that\nexplicitly conducts reasoning on the matching of legal cases through learning\ncase-level and law-level logic rules. The learned rules are then integrated\ninto the retrieval process in a neuro-symbolic manner. Benefiting from the\nlogic and interpretable nature of the logic rules, NS-LCR is equipped with\nbuilt-in faithful explainability. We also show that NS-LCR is a model-agnostic\nframework that can be plugged in for multiple legal retrieval models. To\nshowcase NS-LCR's superiority, we enhance existing benchmarks by adding\nmanually annotated logic rules and introducing a novel explainability metric\nusing Large Language Models (LLMs). Our comprehensive experiments reveal\nNS-LCR's effectiveness for ranking, alongside its proficiency in delivering\nreliable explanations for legal case retrieval.", "published": "2024-03-03 09:22:21", "link": "http://arxiv.org/abs/2403.01457v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Align-to-Distill: Trainable Attention Alignment for Knowledge\n  Distillation in Neural Machine Translation", "abstract": "The advent of scalable deep models and large datasets has improved the\nperformance of Neural Machine Translation. Knowledge Distillation (KD) enhances\nefficiency by transferring knowledge from a teacher model to a more compact\nstudent model. However, KD approaches to Transformer architecture often rely on\nheuristics, particularly when deciding which teacher layers to distill from. In\nthis paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to\naddress the feature mapping problem by adaptively aligning student attention\nheads with their teacher counterparts during training. The Attention Alignment\nModule in A2D performs a dense head-by-head comparison between student and\nteacher attention heads across layers, turning the combinatorial mapping\nheuristics into a learning problem. Our experiments show the efficacy of A2D,\ndemonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb\nand WMT-2014 En->De, respectively, compared to Transformer baselines.", "published": "2024-03-03 11:13:44", "link": "http://arxiv.org/abs/2403.01479v3", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Revisiting Dynamic Evaluation: Online Adaptation for Large Language\n  Models", "abstract": "We consider the problem of online fine tuning the parameters of a language\nmodel at test time, also known as dynamic evaluation. While it is generally\nknown that this approach improves the overall predictive performance,\nespecially when considering distributional shift between training and\nevaluation data, we here emphasize the perspective that online adaptation turns\nparameters into temporally changing states and provides a form of\ncontext-length extension with memory in weights, more in line with the concept\nof memory in neuroscience. We pay particular attention to the speed of\nadaptation (in terms of sample efficiency),sensitivity to the overall\ndistributional drift, and the computational overhead for performing gradient\ncomputations and parameter updates. Our empirical study provides insights on\nwhen online adaptation is particularly interesting. We highlight that with\nonline adaptation the conceptual distinction between in-context learning and\nfine tuning blurs: both are methods to condition the model on previously\nobserved tokens.", "published": "2024-03-03 14:03:48", "link": "http://arxiv.org/abs/2403.01518v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Small Models are LLM Knowledge Triggers on Medical Tabular Prediction", "abstract": "Recent development in large language models (LLMs) has demonstrated\nimpressive domain proficiency on unstructured textual or multi-modal tasks.\nHowever, despite with intrinsic world knowledge, their application on\nstructured tabular data prediction still lags behind, primarily due to the\nnumerical insensitivity and modality discrepancy that brings a gap between LLM\nreasoning and statistical tabular learning. Unlike textual or vision data\n(e.g., electronic clinical notes or medical imaging data), tabular data is\noften presented in heterogeneous numerical values (e.g., CBC reports). This\nubiquitous data format requires intensive expert annotation, and its numerical\nnature limits LLMs' capability to effectively transfer untapped domain\nexpertise. In this paper, we propose SERSAL, a general self-prompting method by\nsynergy learning with small models to enhance LLM tabular prediction in an\nunsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as\noriginal soft noisy annotations, which are dynamically leveraged to teach a\nbetter small student model. Reversely, the outcomes from the trained small\nmodel are used to teach the LLM to further refine its real capability. This\nprocess can be repeatedly applied to gradually distill refined knowledge for\ncontinuous progress. Comprehensive experiments on widely used medical domain\ntabular datasets show that, without access to gold labels, applying SERSAL to\nOpenAI GPT reasoning process attains substantial improvement compared to\nlinguistic prompting methods, which serves as an orthogonal direction for\ntabular LLM, and increasing prompting bonus is observed as more powerful LLMs\nappear.", "published": "2024-03-03 17:35:52", "link": "http://arxiv.org/abs/2403.01570v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Neural Machine Translation of Low-Resource Languages: Corpus\n  Development, Human Evaluation and Explainable AI Architectures", "abstract": "In the current machine translation (MT) landscape, the Transformer\narchitecture stands out as the gold standard, especially for high-resource\nlanguage pairs. This research delves into its efficacy for low-resource\nlanguage pairs including both the English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi language pairs. Notably, the study identifies\nthe optimal hyperparameters and subword model type to significantly improve the\ntranslation quality of Transformer models for low-resource language pairs.\n  The scarcity of parallel datasets for low-resource languages can hinder MT\ndevelopment. To address this, gaHealth was developed, the first bilingual\ncorpus of health data for the Irish language. Focusing on the health domain,\nmodels developed using this in-domain dataset exhibited very significant\nimprovements in BLEU score when compared with models from the LoResMT2021\nShared Task. A subsequent human evaluation using the multidimensional quality\nmetrics error taxonomy showcased the superior performance of the Transformer\nsystem in reducing both accuracy and fluency errors compared to an RNN-based\ncounterpart.\n  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source\napplications streamlined for the development, fine-tuning, and deployment of\nneural machine translation models. These tools considerably simplify the setup\nand evaluation process, making MT more accessible to both developers and\ntranslators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes\neco-friendly natural language processing research by highlighting the\nenvironmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM\ndemonstrated advancements in translation performance for two low-resource\nlanguage pairs: English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021\nShared Task.", "published": "2024-03-03 18:08:30", "link": "http://arxiv.org/abs/2403.01580v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking Down the Defenses: A Comparative Survey of Attacks on Large\n  Language Models", "abstract": "Large Language Models (LLMs) have become a cornerstone in the field of\nNatural Language Processing (NLP), offering transformative capabilities in\nunderstanding and generating human-like text. However, with their rising\nprominence, the security and vulnerability aspects of these models have\ngarnered significant attention. This paper presents a comprehensive survey of\nthe various forms of attacks targeting LLMs, discussing the nature and\nmechanisms of these attacks, their potential impacts, and current defense\nstrategies. We delve into topics such as adversarial attacks that aim to\nmanipulate model outputs, data poisoning that affects model training, and\nprivacy concerns related to training data exploitation. The paper also explores\nthe effectiveness of different attack methodologies, the resilience of LLMs\nagainst these attacks, and the implications for model integrity and user trust.\nBy examining the latest research, we provide insights into the current\nlandscape of LLM vulnerabilities and defense mechanisms. Our objective is to\noffer a nuanced understanding of LLM attacks, foster awareness within the AI\ncommunity, and inspire robust solutions to mitigate these risks in future\ndevelopments.", "published": "2024-03-03 04:46:21", "link": "http://arxiv.org/abs/2403.04786v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Ever-Evolving Memory by Blending and Refining the Past", "abstract": "For a human-like chatbot, constructing a long-term memory is crucial.\nHowever, current large language models often lack this capability, leading to\ninstances of missing important user information or redundantly asking for the\nsame information, thereby diminishing conversation quality. To effectively\nconstruct memory, it is crucial to seamlessly connect past and present\ninformation, while also possessing the ability to forget obstructive\ninformation. To address these challenges, we propose CREEM, a novel memory\nsystem for long-term conversation. Improving upon existing approaches that\nconstruct memory based solely on current sessions, CREEM blends past memories\nduring memory formation. Additionally, we introduce a refining process to\nhandle redundant or outdated information. Unlike traditional paradigms, we view\nresponding and memory construction as inseparable tasks. The blending process,\nwhich creates new memories, also serves as a reasoning step for response\ngeneration by informing the connection between past and present. Through\nevaluation, we demonstrate that CREEM enhances both memory and response\nqualities in multi-session personalized dialogues.", "published": "2024-03-03 08:12:59", "link": "http://arxiv.org/abs/2403.04787v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Compressibility of Quantized Large Language Models", "abstract": "Deploying Large Language Models (LLMs) on edge or mobile devices offers\nsignificant benefits, such as enhanced data privacy and real-time processing\ncapabilities. However, it also faces critical challenges due to the substantial\nmemory requirement of LLMs. Quantization is an effective way of reducing the\nmodel size while maintaining good performance. However, even after\nquantization, LLMs may still be too big to fit entirely into the limited memory\nof edge or mobile devices and have to be partially loaded from the storage to\ncomplete the inference. In this case, the I/O latency of model loading becomes\nthe bottleneck of the LLM inference latency. In this work, we take a\npreliminary step of studying applying data compression techniques to reduce\ndata movement and thus speed up the inference of quantized LLM on\nmemory-constrained devices. In particular, we discussed the compressibility of\nquantized LLMs, the trade-off between the compressibility and performance of\nquantized LLMs, and opportunities to optimize both of them jointly.", "published": "2024-03-03 03:27:07", "link": "http://arxiv.org/abs/2403.01384v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate\n  Models for IRT Assessment", "abstract": "Item difficulty plays a crucial role in adaptive testing. However, few works\nhave focused on generating questions of varying difficulty levels, especially\nfor multiple-choice (MC) cloze tests. We propose training pre-trained language\nmodels (PLMs) as surrogate models to enable item response theory (IRT)\nassessment, avoiding the need for human test subjects. We also propose two\nstrategies to control the difficulty levels of both the gaps and the\ndistractors using ranking rules to reduce invalid distractors. Experimentation\non a benchmark dataset demonstrates that our proposed framework and methods can\neffectively control and evaluate the difficulty levels of MC cloze tests.", "published": "2024-03-03 09:18:05", "link": "http://arxiv.org/abs/2403.01456v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service\n  Copyright Protection", "abstract": "Embedding as a Service (EaaS) has become a widely adopted solution, which\noffers feature extraction capabilities for addressing various downstream tasks\nin Natural Language Processing (NLP). Prior studies have shown that EaaS can be\nprone to model extraction attacks; nevertheless, this concern could be\nmitigated by adding backdoor watermarks to the text embeddings and subsequently\nverifying the attack models post-publication. Through the analysis of the\nrecent watermarking strategy for EaaS, EmbMarker, we design a novel CSE\n(Clustering, Selection, Elimination) attack that removes the backdoor watermark\nwhile maintaining the high utility of embeddings, indicating that the previous\nwatermarking approach can be breached. In response to this new threat, we\npropose a new protocol to make the removal of watermarks more challenging by\nincorporating multiple possible watermark directions. Our defense approach,\nWARDEN, notably increases the stealthiness of watermarks and has been\nempirically shown to be effective against CSE attack.", "published": "2024-03-03 10:39:27", "link": "http://arxiv.org/abs/2403.01472v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Leveraging Biomolecule and Natural Language through Multi-Modal\n  Learning: A Survey", "abstract": "The integration of biomolecular modeling with natural language (BL) has\nemerged as a promising interdisciplinary area at the intersection of artificial\nintelligence, chemistry and biology. This approach leverages the rich,\nmultifaceted descriptions of biomolecules contained within textual data sources\nto enhance our fundamental understanding and enable downstream computational\ntasks such as biomolecule property prediction. The fusion of the nuanced\nnarratives expressed through natural language with the structural and\nfunctional specifics of biomolecules described via various molecular modeling\ntechniques opens new avenues for comprehensively representing and analyzing\nbiomolecules. By incorporating the contextual language data that surrounds\nbiomolecules into their modeling, BL aims to capture a holistic view\nencompassing both the symbolic qualities conveyed through language as well as\nquantitative structural characteristics. In this review, we provide an\nextensive analysis of recent advancements achieved through cross modeling of\nbiomolecules and natural language. (1) We begin by outlining the technical\nrepresentations of biomolecules employed, including sequences, 2D graphs, and\n3D structures. (2) We then examine in depth the rationale and key objectives\nunderlying effective multi-modal integration of language and molecular data\nsources. (3) We subsequently survey the practical applications enabled to date\nin this developing research area. (4) We also compile and summarize the\navailable resources and datasets to facilitate future work. (5) Looking ahead,\nwe identify several promising research directions worthy of further exploration\nand investment to continue advancing the field. The related resources and\ncontents are updating in\n\\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.", "published": "2024-03-03 14:59:47", "link": "http://arxiv.org/abs/2403.01528v2", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "In-Context Sharpness as Alerts: An Inner Representation Perspective for\n  Hallucination Mitigation", "abstract": "Large language models (LLMs) frequently hallucinate and produce factual\nerrors, yet our understanding of why they make these errors remains limited. In\nthis study, we delve into the underlying mechanisms of LLM hallucinations from\nthe perspective of inner representations, and discover a salient pattern\nassociated with hallucinations: correct generations tend to have sharper\ncontext activations in the hidden states of the in-context tokens, compared to\nthe incorrect ones. Leveraging this insight, we propose an entropy-based metric\nto quantify the ``sharpness'' among the in-context hidden states and\nincorporate it into the decoding process to formulate a constrained decoding\napproach. Experiments on various knowledge-seeking and hallucination benchmarks\ndemonstrate our approach's consistent effectiveness, for example, achieving up\nto an 8.6 point improvement on TruthfulQA. We believe this study can improve\nour understanding of hallucinations and serve as a practical solution for\nhallucination mitigation.", "published": "2024-03-03 15:53:41", "link": "http://arxiv.org/abs/2403.01548v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional\n  Videos", "abstract": "We study the problem of procedure planning in instructional videos, which\naims to make a goal-oriented sequence of action steps given partial visual\nstate observations. The motivation of this problem is to learn a structured and\nplannable state and action space. Recent works succeeded in sequence modeling\nof steps with only sequence-level annotations accessible during training, which\noverlooked the roles of states in the procedures. In this work, we point out\nthat State CHangEs MAtter (SCHEMA) for procedure planning in instructional\nvideos. We aim to establish a more structured state space by investigating the\ncausal relations between steps and states in procedures. Specifically, we\nexplicitly represent each step as state changes and track the state changes in\nprocedures. For step representation, we leveraged the commonsense knowledge in\nlarge language models (LLMs) to describe the state changes of steps via our\ndesigned chain-of-thought prompting. For state change tracking, we align visual\nstate observations with language state descriptions via cross-modal contrastive\nlearning, and explicitly model the intermediate states of the procedure using\nLLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV\nbenchmark datasets demonstrate that our proposed SCHEMA model achieves\nstate-of-the-art performance and obtains explainable visualizations.", "published": "2024-03-03 19:53:06", "link": "http://arxiv.org/abs/2403.01599v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Cost-Effective Attention Mechanisms for Low Resource Settings: Necessity\n  & Sufficiency of Linear Transformations", "abstract": "From natural language processing to vision, Scaled Dot Product Attention\n(SDPA) is the backbone of most modern deep learning applications.\nUnfortunately, its memory and computational requirements can be prohibitive in\nlow-resource settings. In this paper, we improve its efficiency without\nsacrificing its versatility. We propose three attention variants where we\nremove consecutive linear transformations or add a novel one, and evaluate them\non a range of standard NLP and vision tasks. Our proposed models are\nsubstantially lighter than standard SDPA (and have 25-50% fewer parameters). We\nshow that the performance cost of these changes is negligible relative to size\nreduction and that in one case (Super Attention) we succeed in outperforming\nSDPA by up to 10% while improving its speed and reducing its parameters by 25%.", "published": "2024-03-03 23:40:35", "link": "http://arxiv.org/abs/2403.01643v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "68T07 (Primary) 68T45, 68T50, 68T10, 15A03, 15A04 (Secondary)", "I.2.6; I.2.7; I.2.10; I.4.0; I.5.0; I.7.0"], "primary_category": "cs.LG"}
{"title": "SyllabusQA: A Course Logistics Question Answering Dataset", "abstract": "Automated teaching assistants and chatbots have significant potential to\nreduce the workload of human instructors, especially for logistics-related\nquestion answering, which is important to students yet repetitive for\ninstructors. However, due to privacy concerns, there is a lack of publicly\navailable datasets. We introduce SyllabusQA, an open-source dataset with 63\nreal course syllabi covering 36 majors, containing 5,078 open-ended course\nlogistics-related question-answer pairs that are diverse in both question types\nand answer formats. Since many logistics-related questions contain critical\ninformation like the date of an exam, it is important to evaluate the\nfactuality of answers. We benchmark several strong baselines on this task, from\nlarge language model prompting to retrieval-augmented generation. We introduce\nFact-QA, an LLM-based (GPT-4) evaluation metric to evaluate the factuality of\npredicted answers. We find that despite performing close to humans on\ntraditional metrics of textual similarity, there remains a significant gap\nbetween automated approaches and humans in terms of fact precision.", "published": "2024-03-03 03:01:14", "link": "http://arxiv.org/abs/2403.14666v2", "categories": ["cs.CY", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CY"}
{"title": "When SMILES have Language: Drug Classification using Text Classification\n  Methods on Drug SMILES Strings", "abstract": "Complex chemical structures, like drugs, are usually defined by SMILES\nstrings as a sequence of molecules and bonds. These SMILES strings are used in\ndifferent complex machine learning-based drug-related research and\nrepresentation works. Escaping from complex representation, in this work, we\npose a single question: What if we treat drug SMILES as conventional sentences\nand engage in text classification for drug classification? Our experiments\naffirm the possibility with very competitive scores. The study explores the\nnotion of viewing each atom and bond as sentence components, employing basic\nNLP methods to categorize drug types, proving that complex problems can also be\nsolved with simpler perspectives. The data and code are available here:\nhttps://github.com/azminewasi/Drug-Classification-NLP.", "published": "2024-03-03 11:09:32", "link": "http://arxiv.org/abs/2403.12984v2", "categories": ["q-bio.BM", "cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "q-bio.BM"}
{"title": "a-DCF: an architecture agnostic metric with application to\n  spoofing-robust speaker verification", "abstract": "Spoofing detection is today a mainstream research topic. Standard metrics can\nbe applied to evaluate the performance of isolated spoofing detection solutions\nand others have been proposed to support their evaluation when they are\ncombined with speaker detection. These either have well-known deficiencies or\nrestrict the architectural approach to combine speaker and spoof detectors. In\nthis paper, we propose an architecture-agnostic detection cost function\n(a-DCF). A generalisation of the original DCF used widely for the assessment of\nautomatic speaker verification (ASV), the a-DCF is designed for the evaluation\nof spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions\nin a Bayes risk sense, with explicitly defined class priors and detection cost\nmodel. We demonstrate the merit of the a-DCF through the benchmarking\nevaluation of architecturally-heterogeneous spoofing-robust ASV solutions.", "published": "2024-03-03 00:58:27", "link": "http://arxiv.org/abs/2403.01355v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech\n  Enhancement", "abstract": "Self-supervised learned models have been found to be very effective for\ncertain speech tasks such as automatic speech recognition, speaker\nidentification, keyword spotting and others. While the features are undeniably\nuseful in speech recognition and associated tasks, their utility in speech\nenhancement systems is yet to be firmly established, and perhaps not properly\nunderstood. In this paper, we investigate the uses of SSL representations for\nsingle-channel speech enhancement in challenging conditions and find that they\nadd very little value for the enhancement task. Our constraints are designed\naround on-device real-time speech enhancement -- model is causal, the compute\nfootprint is small. Additionally, we focus on low SNR conditions where such\nmodels struggle to provide good enhancement. In order to systematically examine\nhow SSL representations impact performance of such enhancement models, we\npropose a variety of techniques to utilize these embeddings which include\ndifferent forms of knowledge-distillation and pre-training.", "published": "2024-03-03 02:05:17", "link": "http://arxiv.org/abs/2403.01369v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice\n  Conversion", "abstract": "In this paper, we propose Prosody-aware VITS (PAVITS) for emotional voice\nconversion (EVC), aiming to achieve two major objectives of EVC: high content\nnaturalness and high emotional naturalness, which are crucial for meeting the\ndemands of human perception. To improve the content naturalness of converted\naudio, we have developed an end-to-end EVC architecture inspired by the high\naudio quality of VITS. By seamlessly integrating an acoustic converter and\nvocoder, we effectively address the common issue of mismatch between emotional\nprosody training and run-time conversion that is prevalent in existing EVC\nmodels. To further enhance the emotional naturalness, we introduce an emotion\ndescriptor to model the subtle prosody variations of different speech emotions.\nAdditionally, we propose a prosody predictor, which predicts prosody features\nfrom text based on the provided emotion label. Notably, we introduce a prosody\nalignment loss to establish a connection between latent prosody features from\ntwo distinct modalities, ensuring effective training. Experimental results show\nthat the performance of PAVITS is superior to the state-of-the-art EVC methods.\nSpeech Samples are available at https://jeremychee4.github.io/pavits4EVC/ .", "published": "2024-03-03 12:07:19", "link": "http://arxiv.org/abs/2403.01494v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
