{"title": "Scalable knowledge base completion with superposition memories", "abstract": "We present Harmonic Memory Networks (HMem), a neural architecture for\nknowledge base completion that models entities as weighted sums of pairwise\nbindings between an entity's neighbors and corresponding relations. Since\nentities are modeled as aggregated neighborhoods, representations of unseen\nentities can be generated on the fly. We demonstrate this with two new\ndatasets: WNGen and FBGen. Experiments show that the model is SOTA on\nbenchmarks, and flexible enough to evolve without retraining as the knowledge\ngraph grows.", "published": "2021-10-24 03:18:04", "link": "http://arxiv.org/abs/2110.12341v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributed neural encoding of binding to thematic roles", "abstract": "A framework and method are proposed for the study of constituent composition\nin fMRI. The method produces estimates of neural patterns encoding complex\nlinguistic structures, under the assumption that the contributions of\nindividual constituents are additive. Like usual techniques for modeling\ncompositional structure in fMRI, the proposed method employs pattern\nsuperposition to synthesize complex structures from their parts. Unlike these\ntechniques, superpositions are sensitive to the structural positions of\nconstituents, making them irreducible to structure-indiscriminate\n(\"bag-of-words\") models of composition. Reanalyzing data from a study by\nFrankland and Greene (2015), it is shown that comparison of neural predictive\nmodels with differing specifications can illuminate aspects of neural\nrepresentational contents that are not apparent when composition is not\nmodelled. The results indicate that the neural instantiations of the binding of\nfillers to thematic roles in a sentence are non-orthogonal, and therefore\nspatially overlapping.", "published": "2021-10-24 03:26:30", "link": "http://arxiv.org/abs/2110.12342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Team Enigma at ArgMining-EMNLP 2021: Leveraging Pre-trained Language\n  Models for Key Point Matching", "abstract": "We present the system description for our submission towards the Key Point\nAnalysis Shared Task at ArgMining 2021. Track 1 of the shared task requires\nparticipants to develop methods to predict the match score between each pair of\narguments and keypoints, provided they belong to the same topic under the same\nstance. We leveraged existing state of the art pre-trained language models\nalong with incorporating additional data and features extracted from the inputs\n(topics, key points, and arguments) to improve performance. We were able to\nachieve mAP strict and mAP relaxed score of 0.872 and 0.966 respectively in the\nevaluation phase, securing 5th place on the leaderboard. In the post evaluation\nphase, we achieved a mAP strict and mAP relaxed score of 0.921 and 0.982\nrespectively. All the codes to generate reproducible results on our models are\navailable on Github.", "published": "2021-10-24 07:10:39", "link": "http://arxiv.org/abs/2110.12370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transliterating Kurdish texts in Latin into Persian-Arabic script", "abstract": "Kurdish is written in different scripts. The two most popular scripts are\nLatin and Persian-Arabic. However, not all Kurdish readers are familiar with\nboth mentioned scripts that could be resolved by automatic transliterators. So\nfar, the developed tools mostly transliterate Persian-Arabic scripts into\nLatin. We present a transliterator to transliterate Kurdish texts in Latin into\nPersian-Arabic script. We also discuss the issues that should be considered in\nthe transliteration process. The tool is a part of Kurdish BLARK, and it is\npublicly available for non-commercial use", "published": "2021-10-24 07:28:39", "link": "http://arxiv.org/abs/2110.12374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Extraction of Sentencing Decisions from Court Cases in the\n  Hebrew Language", "abstract": "We present the task of Automated Punishment Extraction (APE) in sentencing\ndecisions from criminal court cases in Hebrew. Addressing APE will enable the\nidentification of sentencing patterns and constitute an important stepping\nstone for many follow up legal NLP applications in Hebrew, including the\nprediction of sentencing decisions. We curate a dataset of sexual assault\nsentencing decisions and a manually-annotated evaluation dataset, and implement\nrule-based and supervised models. We find that while supervised models can\nidentify the sentence containing the punishment with good accuracy, rule-based\napproaches outperform them on the full APE task. We conclude by presenting a\nfirst analysis of sentencing patterns in our dataset and analyze common models'\nerrors, indicating avenues for future work, such as distinguishing between\nprobation and actual imprisonment punishment. We will make all our resources\navailable upon request, including data, annotation, and first benchmark models.", "published": "2021-10-24 08:01:41", "link": "http://arxiv.org/abs/2110.12383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the Impact of UGC Specificities on Translation Quality", "abstract": "This work takes a critical look at the evaluation of user-generated content\nautomatic translation, the well-known specificities of which raise many\nchallenges for MT. Our analyses show that measuring the average-case\nperformance using a standard metric on a UGC test set falls far short of giving\na reliable image of the UGC translation quality. That is why we introduce a new\ndata set for the evaluation of UGC translation in which UGC specificities have\nbeen manually annotated using a fine-grained typology. Using this data set, we\nconduct several experiments to measure the impact of different kinds of UGC\nspecificities on translation quality, more precisely than previously possible.", "published": "2021-10-24 23:25:29", "link": "http://arxiv.org/abs/2110.12551v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noisy UGC Translation at the Character Level: Revisiting Open-Vocabulary\n  Capabilities and Robustness of Char-Based Models", "abstract": "This work explores the capacities of character-based Neural Machine\nTranslation to translate noisy User-Generated Content (UGC) with a strong focus\non exploring the limits of such approaches to handle productive UGC phenomena,\nwhich almost by definition, cannot be seen at training time. Within a strict\nzero-shot scenario, we first study the detrimental impact on translation\nperformance of various user-generated content phenomena on a small annotated\ndataset we developed, and then show that such models are indeed incapable of\nhandling unknown letters, which leads to catastrophic translation failure once\nsuch characters are encountered. We further confirm this behavior with a\nsimple, yet insightful, copy task experiment and highlight the importance of\nreducing the vocabulary size hyper-parameter to increase the robustness of\ncharacter-based models for machine translation.", "published": "2021-10-24 23:25:54", "link": "http://arxiv.org/abs/2110.12552v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Traditional Poetry Generating System Based on Deep Learning", "abstract": "Chinese traditional poetry is an important intangible cultural heritage of\nChina and an artistic carrier of thought, culture, spirit and emotion. However,\ndue to the strict rules of ancient poetry, it is very difficult to write poetry\nby machine. This paper proposes an automatic generation method of Chinese\ntraditional poetry based on deep learning technology, which extracts keywords\nfrom each poem and matches them with the previous text to make the poem conform\nto the theme, and when a user inputs a paragraph of text, the machine obtains\nthe theme and generates poem sentence by sentence. Using the classic word2vec\nmodel as the preprocessing model, the Chinese characters which are not\nunderstood by the computer are transformed into matrix for processing.\nBi-directional Long Short-Term Memory is used as the neural network model to\ngenerate Chinese characters one by one and make the meaning of Chinese\ncharacters as accurate as possible. At the same time, TF-IDF and TextRank are\nused to extract keywords. Using the attention mechanism based encoding-decoding\nmodel, we can solve practical problems by transforming the model, and\nstrengthen the important information of long-distance information, so as to\ngrasp the key points without losing important information. In the aspect of\nemotion judgment, Long Short-Term Memory network is used. The final result\nshows that it can get good poetry outputs according to the user input text.", "published": "2021-10-24 02:43:03", "link": "http://arxiv.org/abs/2110.12335v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Think about it! Improving defeasible reasoning by first modeling the\n  question scenario", "abstract": "Defeasible reasoning is the mode of reasoning where conclusions can be\noverturned by taking into account new evidence. Existing cognitive science\nliterature on defeasible reasoning suggests that a person forms a mental model\nof the problem scenario before answering questions. Our research goal asks\nwhether neural models can similarly benefit from envisioning the question\nscenario before answering a defeasible query. Our approach is, given a\nquestion, to have a model first create a graph of relevant influences, and then\nleverage that graph as an additional input when answering the question. Our\nsystem, CURIOUS, achieves a new state-of-the-art on three different defeasible\nreasoning datasets. This result is significant as it illustrates that\nperformance can be improved by guiding a system to \"think about\" a question and\nexplicitly model the scenario, rather than answering reflexively. Code, data,\nand pre-trained models are located at https://github.com/madaan/thinkaboutit.", "published": "2021-10-24 04:13:52", "link": "http://arxiv.org/abs/2110.12349v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Sentence Punctuation for Collaborative Commentary Generation in Esports\n  Live-Streaming", "abstract": "To solve the existing sentence punctuation problem for collaborative\ncommentary generation in Esports live-streaming, this paper presents two\nstrategies for sentence punctuation for text sequences of game commentary, that\nis, punctuating sentences by two or three text sequence(s) originally\npunctuated by Youtube to obtain a complete sentence of commentary. We conducted\ncomparative experiments utilizing and fine-tuning a state-of-the-art\npre-trained generative language model among two strategies and the baseline to\ngenerate collaborative commentary. Both objective evaluations by automatic\nmetrics and subjective analyses showed that our strategy of punctuating\nsentences by two text sequences outperformed the baseline.", "published": "2021-10-24 11:26:29", "link": "http://arxiv.org/abs/2110.12416v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Abstractified Multi-instance Learning (AMIL) for Biomedical Relation\n  Extraction", "abstract": "Relation extraction in the biomedical domain is a challenging task due to a\nlack of labeled data and a long-tail distribution of fact triples. Many works\nleverage distant supervision which automatically generates labeled data by\npairing a knowledge graph with raw textual data. Distant supervision produces\nnoisy labels and requires additional techniques, such as multi-instance\nlearning (MIL), to denoise the training signal. However, MIL requires multiple\ninstances of data and struggles with very long-tail datasets such as those\nfound in the biomedical domain. In this work, we propose a novel reformulation\nof MIL for biomedical relation extraction that abstractifies biomedical\nentities into their corresponding semantic types. By grouping entities by\ntypes, we are better able to take advantage of the benefits of MIL and further\ndenoise the training signal. We show this reformulation, which we refer to as\nabstractified multi-instance learning (AMIL), improves performance in\nbiomedical relationship extraction. We also propose a novel relationship\nembedding architecture that further improves model performance.", "published": "2021-10-24 17:49:20", "link": "http://arxiv.org/abs/2110.12501v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improved Goal Oriented Dialogue via Utterance Generation and Look Ahead", "abstract": "Goal oriented dialogue systems have become a prominent customer-care\ninteraction channel for most businesses. However, not all interactions are\nsmooth, and customer intent misunderstanding is a major cause of dialogue\nfailure. We show that intent prediction can be improved by training a deep\ntext-to-text neural model to generate successive user utterances from unlabeled\ndialogue data. For that, we define a multi-task training regime that utilizes\nsuccessive user-utterance generation to improve the intent prediction. Our\napproach achieves the reported improvement due to two complementary factors:\nFirst, it uses a large amount of unlabeled dialogue data for an auxiliary\ngeneration task. Second, it uses the generated user utterance as an additional\nsignal for the intent prediction model. Lastly, we present a novel look-ahead\napproach that uses user utterance generation to improve intent prediction in\ninference time. Specifically, we generate counterfactual successive user\nutterances for conversations with ambiguous predicted intents, and disambiguate\nthe prediction by reassessing the concatenated sequence of available and\ngenerated utterances.", "published": "2021-10-24 11:12:48", "link": "http://arxiv.org/abs/2110.12412v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive Multimodal and Multisensory Empathic Technologies for Enhanced\n  Human Communication", "abstract": "As digital social platforms and mobile technologies are becoming more\nprevalent and robust, the use of Artificial Intelligence (AI) in facilitating\nhuman communication will grow. This, in turn, will pave the way for the\ndevelopment of intuitive, adaptive, and effective empathic AI interfaces that\nbetter address the needs of socially and culturally diverse communities. I\nbelieve such developments must consider a principled framework that includes\nthe human perceptual senses in the digital design process right from the start,\nfor a more accurate, as well as a more aesthetic, memorable, and soothing\nexperience. In this position paper, I suggest features, identify some\nchallenges that need to be addressed in the process, and propose some future\nresearch directions that I think should be part of the design and\nimplementation. Such an approach will allow various communities of practice to\ninvestigate the areas of intersection between artificial intelligence, on one\nside, and human communication, perceptual needs and social and cultural values,\non the other.", "published": "2021-10-24 16:50:37", "link": "http://arxiv.org/abs/2110.15054v1", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "CoVA: Context-aware Visual Attention for Webpage Information Extraction", "abstract": "Webpage information extraction (WIE) is an important step to create knowledge\nbases. For this, classical WIE methods leverage the Document Object Model (DOM)\ntree of a website. However, use of the DOM tree poses significant challenges as\ncontext and appearance are encoded in an abstract manner. To address this\nchallenge we propose to reformulate WIE as a context-aware Webpage Object\nDetection task. Specifically, we develop a Context-aware Visual Attention-based\n(CoVA) detection pipeline which combines appearance features with syntactical\nstructure from the DOM tree. To study the approach we collect a new large-scale\ndataset of e-commerce websites for which we manually annotate every web element\nwith four labels: product price, product title, product image and background.\nOn this dataset we show that the proposed CoVA approach is a new challenging\nbaseline which improves upon prior state-of-the-art methods.", "published": "2021-10-24 00:21:46", "link": "http://arxiv.org/abs/2110.12320v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Quantum Computer Music: Foundations and Initial Experiments", "abstract": "Quantum computing is a nascent technology, which is advancing rapidly. There\nis a long history of research into using computers for music. Nowadays\ncomputers are absolutely essential for the music economy. Thus, it is very\nlikely that quantum computers will impact the music industry in time to come.\nThis chapter lays the foundations of the new field of 'Quantum Computer Music'.\nIt begins with an introduction to algorithmic computer music and methods to\nprogram computers to generate music, such as Markov chains and random walks.\nThen, it presents quantum computing versions of those methods. The discussions\nare supported by detailed explanations of quantum computing concepts and\nwalk-through examples. A bespoke generative music algorithm is presented, the\nBasak-Miranda algorithm, which leverages a property of quantum mechanics known\nas constructive and destructive interference to operate a musical Markov chain.\nAn Appendix introducing the fundamentals of quantum computing deemed necessary\nto understand the chapter and a link to access Jupyter Notebooks with examples\nare also provided.", "published": "2021-10-24 10:56:07", "link": "http://arxiv.org/abs/2110.12408v1", "categories": ["cs.ET", "cs.SD", "eess.AS", "quant-ph"], "primary_category": "cs.ET"}
{"title": "Discrete Acoustic Space for an Efficient Sampling in Neural\n  Text-To-Speech", "abstract": "We present a Split Vector Quantized Variational Autoencoder (SVQ-VAE)\narchitecture using a split vector quantizer for NTTS, as an enhancement to the\nwell-known Variational Autoencoder (VAE) and Vector Quantized Variational\nAutoencoder (VQ-VAE) architectures. Compared to these previous architectures,\nour proposed model retains the benefits of using an utterance-level bottleneck,\nwhile keeping significant representation power and a discretized latent space\nsmall enough for efficient prediction from text. We train the model on\nrecordings in the expressive task-oriented dialogues domain and show that\nSVQ-VAE achieves a statistically significant improvement in naturalness over\nthe VAE and VQ-VAE models. Furthermore, we demonstrate that the SVQ-VAE latent\nacoustic space is predictable from text, reducing the gap between the standard\nconstant vector synthesis and vocoded recordings by 32%.", "published": "2021-10-24 22:15:01", "link": "http://arxiv.org/abs/2110.12539v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Speaker Representation with Semi-supervised Learning approach\n  for Speaker Profiling", "abstract": "Speaker profiling, which aims to estimate speaker characteristics such as age\nand height, has a wide range of applications inforensics, recommendation\nsystems, etc. In this work, we propose a semisupervised learning approach to\nmitigate the issue of low training data for speaker profiling. This is done by\nutilizing external corpus with speaker information to train a better\nrepresentation which can help to improve the speaker profiling systems.\nSpecifically, besides the standard supervised learning path, the proposed\nframework has two more paths: (1) an unsupervised speaker representation\nlearning path that helps to capture the speaker information; (2) a consistency\ntraining path that helps to improve the robustness of the system by enforcing\nit to produce similar predictions for utterances of the same speaker.The\nproposed approach is evaluated on the TIMIT and NISP datasets for age, height,\nand gender estimation, while the Librispeech is used as the unsupervised\nexternal corpus. Trained both on single-task and multi-task settings, our\napproach was able to achieve state-of-the-art results on age estimation on the\nTIMIT Test dataset with Root Mean Square Error(RMSE) of6.8 and 7.4 years and\nMean Absolute Error(MAE) of 4.8 and5.0 years for male and female speakers\nrespectively.", "published": "2021-10-24 20:44:45", "link": "http://arxiv.org/abs/2110.13653v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
