{"title": "Automatic Detection of Reuses and Citations in Literary Texts", "abstract": "For more than forty years now, modern theories of literature (Compagnon,\n1979) insist on the role of paraphrases, rewritings, citations, reciprocal\nborrowings and mutual contributions of any kinds. The notions of\nintertextuality, transtextuality, hypertextuality/hypotextuality, were\nintroduced in the seventies and eighties to approach these phenomena. The\ncareful analysis of these references is of particular interest in evaluating\nthe distance that the creator voluntarily introduces with his/her masters.\nPhoebus is collaborative project that makes computer scientists from the\nUniversity Pierre and Marie Curie (LIP6-UPMC) collaborate with the literary\nteams of Paris-Sorbonne University with the aim to develop efficient tools for\nliterary studies that take advantage of modern computer science techniques. In\nthis context, we have developed a piece of software that automatically detects\nand explores networks of textual reuses in classical literature. This paper\ndescribes the principles on which is based this program, the significant\nresults that have already been obtained and the perspectives for the near\nfuture.", "published": "2014-04-11 04:36:05", "link": "http://arxiv.org/abs/1404.2997v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Pagination: It's what you say, not how long it takes to say it", "abstract": "Pagination - the process of determining where to break an article across\npages in a multi-article layout is a common layout challenge for most\ncommercially printed newspapers and magazines. To date, no one has created an\nalgorithm that determines a minimal pagination break point based on the content\nof the article. Existing approaches for automatic multi-article layout focus\nexclusively on maximizing content (number of articles) and optimizing aesthetic\npresentation (e.g., spacing between articles). However, disregarding the\nsemantic information within the article can lead to overly aggressive cutting,\nthereby eliminating key content and potentially confusing the reader, or\nsetting too generous of a break point, thereby leaving in superfluous content\nand making automatic layout more difficult. This is one of the remaining\nchallenges on the path from manual layouts to fully automated processes that\nstill ensure article content quality. In this work, we present a new approach\nto calculating a document minimal break point for the task of pagination. Our\napproach uses a statistical language model to predict minimal break points\nbased on the semantic content of an article. We then compare 4 novel candidate\napproaches, and 4 baselines (currently in use by layout algorithms). Results\nfrom this experiment show that one of our approaches strongly outperforms the\nbaselines and alternatives. Results from a second study suggest that humans are\nnot able to agree on a single \"best\" break point. Therefore, this work shows\nthat a semantic-based lower bound break point prediction is necessary for ideal\nautomated document synthesis within a real-world context.", "published": "2014-04-11 21:50:02", "link": "http://arxiv.org/abs/1404.3233v1", "categories": ["cs.CL", "cs.IR", "I.7.2; I.7.4"], "primary_category": "cs.CL"}
{"title": "On the Ground Validation of Online Diagnosis with Twitter and Medical\n  Records", "abstract": "Social media has been considered as a data source for tracking disease.\nHowever, most analyses are based on models that prioritize strong correlation\nwith population-level disease rates over determining whether or not specific\nindividual users are actually sick. Taking a different approach, we develop a\nnovel system for social-media based disease detection at the individual level\nusing a sample of professionally diagnosed individuals. Specifically, we\ndevelop a system for making an accurate influenza diagnosis based on an\nindividual's publicly available Twitter data. We find that about half (17/35 =\n48.57%) of the users in our sample that were sick explicitly discuss their\ndisease on Twitter. By developing a meta classifier that combines text\nanalysis, anomaly detection, and social network analysis, we are able to\ndiagnose an individual with greater than 99% accuracy even if she does not\ndiscuss her health.", "published": "2014-04-11 07:55:51", "link": "http://arxiv.org/abs/1404.3026v1", "categories": ["cs.SI", "cs.CL", "cs.LG", "I.2.1"], "primary_category": "cs.SI"}
{"title": "Targeting HIV-related Medication Side Effects and Sentiment Using\n  Twitter Data", "abstract": "We present a descriptive analysis of Twitter data. Our study focuses on\nextracting the main side effects associated with HIV treatments. The crux of\nour work was the identification of personal tweets referring to HIV. We\nsummarize our results in an infographic aimed at the general public. In\naddition, we present a measure of user sentiment based on hand-rated tweets.", "published": "2014-04-11 02:33:17", "link": "http://arxiv.org/abs/1404.3610v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
