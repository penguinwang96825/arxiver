{"title": "Open Intent Discovery through Unsupervised Semantic Clustering and\n  Dependency Parsing", "abstract": "Intent understanding plays an important role in dialog systems, and is\ntypically formulated as a supervised learning problem. However, it is\nchallenging and time-consuming to design the intents for a new domain from\nscratch, which usually requires a lot of manual effort of domain experts. This\npaper presents an unsupervised two-stage approach to discover intents and\ngenerate meaningful intent labels automatically from a collection of unlabeled\nutterances in a domain. In the first stage, we aim to generate a set of\nsemantically coherent clusters where the utterances within each cluster convey\nthe same intent. We obtain the utterance representation from various\npre-trained sentence embeddings and present a metric of balanced score to\ndetermine the optimal number of clusters in K-means clustering for balanced\ndatasets. In the second stage, the objective is to generate an intent label\nautomatically for each cluster. We extract the ACTION-OBJECT pair from each\nutterance using a dependency parser and take the most frequent pair within each\ncluster, e.g., book-restaurant, as the generated intent label. We empirically\nshow that the proposed unsupervised approach can generate meaningful intent\nlabels automatically and achieve high precision and recall in utterance\nclustering and intent discovery.", "published": "2021-04-25 09:36:23", "link": "http://arxiv.org/abs/2104.12114v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Post-Editing for Vietnamese", "abstract": "Automatic post-editing (APE) is an important remedy for reducing errors of\nraw translated texts that are produced by machine translation (MT) systems or\nsoftware-aided translation. In this paper, we present a systematic approach to\ntackle the APE task for Vietnamese. Specifically, we construct the first\nlarge-scale dataset of 5M Vietnamese translated and corrected sentence pairs.\nWe then apply strong neural MT models to handle the APE task, using our\nconstructed dataset. Experimental results from both automatic and human\nevaluations show the effectiveness of the neural MT models in handling the\nVietnamese APE task.", "published": "2021-04-25 10:59:31", "link": "http://arxiv.org/abs/2104.12128v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Offensive Expressions of Opinion in Context", "abstract": "Classic information extraction techniques consist in building questions and\nanswers about the facts. Indeed, it is still a challenge to subjective\ninformation extraction systems to identify opinions and feelings in context. In\nsentiment-based NLP tasks, there are few resources to information extraction,\nabove all offensive or hateful opinions in context. To fill this important gap,\nthis short paper provides a new cross-lingual and contextual offensive lexicon,\nwhich consists of explicit and implicit offensive and swearing expressions of\nopinion, which were annotated in two different classes: context dependent and\ncontext-independent offensive. In addition, we provide markers to identify hate\nspeech. Annotation approach was evaluated at the expression-level and achieves\nhigh human inter-annotator agreement. The provided offensive lexicon is\navailable in Portuguese and English languages.", "published": "2021-04-25 18:35:39", "link": "http://arxiv.org/abs/2104.12227v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XLM-T: Multilingual Language Models in Twitter for Sentiment Analysis\n  and Beyond", "abstract": "Language models are ubiquitous in current NLP, and their multilingual\ncapacity has recently attracted considerable attention. However, current\nanalyses have almost exclusively focused on (multilingual variants of) standard\nbenchmarks, and have relied on clean pre-training and task-specific corpora as\nmultilingual signals. In this paper, we introduce XLM-T, a model to train and\nevaluate multilingual language models in Twitter. In this paper we provide: (1)\na new strong multilingual baseline consisting of an XLM-R (Conneau et al. 2020)\nmodel pre-trained on millions of tweets in over thirty languages, alongside\nstarter code to subsequently fine-tune on a target task; and (2) a set of\nunified sentiment analysis Twitter datasets in eight different languages and a\nXLM-T model fine-tuned on them.", "published": "2021-04-25 20:28:53", "link": "http://arxiv.org/abs/2104.12250v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual-Lexicon Approach for Abusive Language Detection", "abstract": "Since a lexicon-based approach is more elegant scientifically, explaining the\nsolution components and being easier to generalize to other applications, this\npaper provides a new approach for offensive language and hate speech detection\non social media. Our approach embodies a lexicon of implicit and explicit\noffensive and swearing expressions annotated with contextual information. Due\nto the severity of the social media abusive comments in Brazil, and the lack of\nresearch in Portuguese, Brazilian Portuguese is the language used to validate\nthe models. Nevertheless, our method may be applied to any other language. The\nconducted experiments show the effectiveness of the proposed approach,\noutperforming the current baseline methods for the Portuguese language.", "published": "2021-04-25 21:34:51", "link": "http://arxiv.org/abs/2104.12265v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reranking Machine Translation Hypotheses with Structured and Web-based\n  Language Models", "abstract": "In this paper, we investigate the use of linguistically motivated and\ncomputationally efficient structured language models for reranking N-best\nhypotheses in a statistical machine translation system. These language models,\ndeveloped from Constraint Dependency Grammar parses, tightly integrate\nknowledge of words, morphological and lexical features, and syntactic\ndependency constraints. Two structured language models are applied for N-best\nrescoring, one is an almost-parsing language model, and the other utilizes more\nsyntactic features by explicitly modeling syntactic dependencies between words.\nWe also investigate effective and efficient language modeling methods to use\nN-grams extracted from up to 1 teraword of web documents. We apply all these\nlanguage models for N-best re-ranking on the NIST and DARPA GALE program 2006\nand 2007 machine translation evaluation tasks and find that the combination of\nthese language models increases the BLEU score up to 1.6% absolutely on blind\ntest sets.", "published": "2021-04-25 22:09:03", "link": "http://arxiv.org/abs/2104.12277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "User Preference-aware Fake News Detection", "abstract": "Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.", "published": "2021-04-25 21:19:24", "link": "http://arxiv.org/abs/2104.12259v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "A Comprehensive Attempt to Research Statement Generation", "abstract": "For a researcher, writing a good research statement is crucial but costs a\nlot of time and effort. To help researchers, in this paper, we propose the\nresearch statement generation (RSG) task which aims to summarize one's research\nachievements and help prepare a formal research statement. For this task, we\nconduct a comprehensive attempt including corpus construction, method design,\nand performance evaluation. First, we construct an RSG dataset with 62 research\nstatements and the corresponding 1,203 publications. Due to the limitation of\nour resources, we propose a practical RSG method which identifies a\nresearcher's research directions by topic modeling and clustering techniques\nand extracts salient sentences by a neural text summarizer. Finally,\nexperiments show that our method outperforms all the baselines with better\ncontent coverage and coherence.", "published": "2021-04-25 03:57:00", "link": "http://arxiv.org/abs/2104.14339v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Potential Idiomatic Expression (PIE)-English: Corpus for Classes of\n  Idioms", "abstract": "We present a fairly large, Potential Idiomatic Expression (PIE) dataset for\nNatural Language Processing (NLP) in English. The challenges with NLP systems\nwith regards to tasks such as Machine Translation (MT), word sense\ndisambiguation (WSD) and information retrieval make it imperative to have a\nlabelled idioms dataset with classes such as it is in this work. To the best of\nthe authors' knowledge, this is the first idioms corpus with classes of idioms\nbeyond the literal and the general idioms classification. In particular, the\nfollowing classes are labelled in the dataset: metaphor, simile, euphemism,\nparallelism, personification, oxymoron, paradox, hyperbole, irony and literal.\nWe obtain an overall inter-annotator agreement (IAA) score, between two\nindependent annotators, of 88.89%. Many past efforts have been limited in the\ncorpus size and classes of samples but this dataset contains over 20,100\nsamples with almost 1,200 cases of idioms (with their meanings) from 10 classes\n(or senses). The corpus may also be extended by researchers to meet specific\nneeds. The corpus has part of speech (PoS) tagging from the NLTK library.\nClassification experiments performed on the corpus to obtain a baseline and\ncomparison among three common models, including the BERT model, give good\nresults. We also make publicly available the corpus and the relevant codes for\nworking with it for NLP tasks.", "published": "2021-04-25 13:05:29", "link": "http://arxiv.org/abs/2105.03280v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformers to Fight the COVID-19 Infodemic", "abstract": "The massive spread of false information on social media has become a global\nrisk especially in a global pandemic situation like COVID-19. False information\ndetection has thus become a surging research topic in recent months.\nNLP4IF-2021 shared task on fighting the COVID-19 infodemic has been organised\nto strengthen the research in false information detection where the\nparticipants are asked to predict seven different binary labels regarding false\ninformation in a tweet. The shared task has been organised in three languages;\nArabic, Bulgarian and English. In this paper, we present our approach to tackle\nthe task objective using transformers. Overall, our approach achieves a 0.707\nmean F1 score in Arabic, 0.578 mean F1 score in Bulgarian and 0.864 mean F1\nscore in English ranking 4th place in all the languages.", "published": "2021-04-25 16:49:23", "link": "http://arxiv.org/abs/2104.12201v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Bi-Encoder LSTM Model For Learning Unstructured Dialogs", "abstract": "Creating a data-driven model that is trained on a large dataset of\nunstructured dialogs is a crucial step in developing Retrieval-based Chatbot\nsystems. This paper presents a Long Short Term Memory (LSTM) based architecture\nthat learns unstructured multi-turn dialogs and provides results on the task of\nselecting the best response from a collection of given responses. Ubuntu Dialog\nCorpus Version 2 was used as the corpus for training. We show that our model\nachieves 0.8%, 1.0% and 0.3% higher accuracy for Recall@1, Recall@2 and\nRecall@5 respectively than the benchmark model. We also show results on\nexperiments performed by using several similarity functions, model\nhyper-parameters and word embeddings on the proposed architecture", "published": "2021-04-25 21:37:35", "link": "http://arxiv.org/abs/2104.12269v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Bridging the gap between streaming and non-streaming ASR systems\n  bydistilling ensembles of CTC and RNN-T models", "abstract": "Streaming end-to-end automatic speech recognition (ASR) systems are widely\nused in everyday applications that require transcribing speech to text in\nreal-time. Their minimal latency makes them suitable for such tasks. Unlike\ntheir non-streaming counterparts, streaming models are constrained to be causal\nwith no future context and suffer from higher word error rates (WER). To\nimprove streaming models, a recent study [1] proposed to distill a\nnon-streaming teacher model on unsupervised utterances, and then train a\nstreaming student using the teachers' predictions. However, the performance gap\nbetween teacher and student WERs remains high. In this paper, we aim to close\nthis gap by using a diversified set of non-streaming teacher models and\ncombining them using Recognizer Output Voting Error Reduction (ROVER). In\nparticular, we show that, despite being weaker than RNN-T models, CTC models\nare remarkable teachers. Further, by fusing RNN-T and CTC models together, we\nbuild the strongest teachers. The resulting student models drastically improve\nupon streaming models of previous work [1]: the WER decreases by 41% on\nSpanish, 27% on Portuguese, and 13% on French.", "published": "2021-04-25 19:20:34", "link": "http://arxiv.org/abs/2104.14346v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "abstract": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "published": "2021-04-25 05:00:53", "link": "http://arxiv.org/abs/2105.09284v1", "categories": ["cs.MM", "cs.CL", "cs.LG", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.MM"}
{"title": "Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis", "abstract": "Speech synthesis and music audio generation from symbolic input differ in\nmany aspects but share some similarities. In this study, we investigate how\ntext-to-speech synthesis techniques can be used for piano MIDI-to-audio\nsynthesis tasks. Our investigation includes Tacotron and neural source-filter\nwaveform models as the basic components, with which we build MIDI-to-audio\nsynthesis systems in similar ways to TTS frameworks. We also include reference\nsystems using conventional sound modeling techniques such as sample-based and\nphysical-modeling-based methods. The subjective experimental results\ndemonstrate that the investigated TTS components can be applied to piano\nMIDI-to-audio synthesis with minor modifications. The results also reveal the\nperformance bottleneck -- while the waveform model can synthesize high quality\npiano sound given natural acoustic features, the conversion from MIDI to\nacoustic features is challenging. The full MIDI-to-audio synthesis system is\nstill inferior to the sample-based or physical-modeling-based approaches, but\nwe encourage TTS researchers to test their TTS models for this new task and\nimprove the performance.", "published": "2021-04-25 23:59:00", "link": "http://arxiv.org/abs/2104.12292v6", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Adaptive Learning based Generative Adversarial Network for One-To-One\n  Voice Conversion", "abstract": "Voice Conversion (VC) emerged as a significant domain of research in the\nfield of speech synthesis in recent years due to its emerging application in\nvoice-assisting technology, automated movie dubbing, and speech-to-singing\nconversion to name a few. VC basically deals with the conversion of vocal style\nof one speaker to another speaker while keeping the linguistic contents\nunchanged. VC task is performed through a three-stage pipeline consisting of\nspeech analysis, speech feature mapping, and speech reconstruction. Nowadays\nthe Generative Adversarial Network (GAN) models are widely in use for speech\nfeature mapping from source to target speaker. In this paper, we propose an\nadaptive learning-based GAN model called ALGAN-VC for an efficient one-to-one\nVC of speakers. Our ALGAN-VC framework consists of some approaches to improve\nthe speech quality and voice similarity between source and target speakers. The\nmodel incorporates a Dense Residual Network (DRN) like architecture to the\ngenerator network for efficient speech feature learning, for source to target\nspeech feature conversion. We also integrate an adaptive learning mechanism to\ncompute the loss function for the proposed model. Moreover, we use a boosted\nlearning rate approach to enhance the learning capability of the proposed\nmodel. The model is trained by using both forward and inverse mapping\nsimultaneously for a one-to-one VC. The proposed model is tested on Voice\nConversion Challenge (VCC) 2016, 2018, and 2020 datasets as well as on our\nself-prepared speech dataset, which has been recorded in Indian regional\nlanguages and in English. A subjective and objective evaluation of the\ngenerated speech samples indicated that the proposed model elegantly performed\nthe voice conversion task by achieving high speaker similarity and adequate\nspeech quality.", "published": "2021-04-25 13:44:32", "link": "http://arxiv.org/abs/2104.12159v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
