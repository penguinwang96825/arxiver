{"title": "Dynamic Sliding Window for Meeting Summarization", "abstract": "Recently abstractive spoken language summarization raises emerging research\ninterest, and neural sequence-to-sequence approaches have brought significant\nperformance improvement. However, summarizing long meeting transcripts remains\nchallenging. Due to the large length of source contents and targeted summaries,\nneural models are prone to be distracted on the context, and produce summaries\nwith degraded quality. Moreover, pre-trained language models with input length\nlimitations cannot be readily applied to long sequences. In this work, we first\nanalyze the linguistic characteristics of meeting transcripts on a\nrepresentative corpus, and find that the sentences comprising the summary\ncorrelate with the meeting agenda. Based on this observation, we propose a\ndynamic sliding window strategy for meeting summarization. Experimental results\nshow that performance benefit from the proposed method, and outputs obtain\nhigher factual consistency than the base model.", "published": "2021-08-31 05:39:48", "link": "http://arxiv.org/abs/2108.13629v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discretized Integrated Gradients for Explaining Language Models", "abstract": "As a prominent attribution-based explanation algorithm, Integrated Gradients\n(IG) is widely adopted due to its desirable explanation axioms and the ease of\ngradient computation. It measures feature importance by averaging the model's\noutput gradient interpolated along a straight-line path in the input data\nspace. However, such straight-line interpolated points are not representative\nof text data due to the inherent discreteness of the word embedding space. This\nquestions the faithfulness of the gradients computed at the interpolated points\nand consequently, the quality of the generated explanations. Here we propose\nDiscretized Integrated Gradients (DIG), which allows effective attribution\nalong non-linear interpolation paths. We develop two interpolation strategies\nfor the discrete word embedding space that generates interpolation points that\nlie close to actual words in the embedding space, yielding more faithful\ngradient computation. We demonstrate the effectiveness of DIG over IG through\nexperimental and human evaluations on multiple sentiment classification\ndatasets. We provide the source code of DIG to encourage reproducible research.", "published": "2021-08-31 07:36:34", "link": "http://arxiv.org/abs/2108.13654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MELM: Data Augmentation with Masked Entity Language Modeling for\n  Low-Resource NER", "abstract": "Data augmentation is an effective solution to data scarcity in low-resource\nscenarios. However, when applied to token-level tasks such as NER, data\naugmentation methods often suffer from token-label misalignment, which leads to\nunsatsifactory performance. In this work, we propose Masked Entity Language\nModeling (MELM) as a novel data augmentation framework for low-resource NER. To\nalleviate the token-label misalignment issue, we explicitly inject NER labels\ninto sentence context, and thus the fine-tuned MELM is able to predict masked\nentity tokens by explicitly conditioning on their labels. Thereby, MELM\ngenerates high-quality augmented data with novel entities, which provides rich\nentity regularity knowledge and boosts NER performance. When training data from\nmultiple languages are available, we also integrate MELM with code-mixing for\nfurther improvement. We demonstrate the effectiveness of MELM on monolingual,\ncross-lingual and multilingual NER across various low-resource levels.\nExperimental results show that our MELM presents substantial improvement over\nthe baseline methods.", "published": "2021-08-31 07:37:43", "link": "http://arxiv.org/abs/2108.13655v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Rule Generation for Time Expression Normalization", "abstract": "The understanding of time expressions includes two sub-tasks: recognition and\nnormalization. In recent years, significant progress has been made in the\nrecognition of time expressions while research on normalization has lagged\nbehind. Existing SOTA normalization methods highly rely on rules or grammars\ndesigned by experts, which limits their performance on emerging corpora, such\nas social media texts. In this paper, we model time expression normalization as\na sequence of operations to construct the normalized temporal value, and we\npresent a novel method called ARTime, which can automatically generate\nnormalization rules from training data without expert interventions.\nSpecifically, ARTime automatically captures possible operation sequences from\nannotated data and generates normalization rules on time expressions with\ncommon surface forms. The experimental results show that ARTime can\nsignificantly surpass SOTA methods on the Tweets benchmark, and achieves\ncompetitive results with existing expert-engineered rule methods on the\nTempEval-3 benchmark.", "published": "2021-08-31 07:44:38", "link": "http://arxiv.org/abs/2108.13658v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness\n  Trade-off in Abstractive Summarization", "abstract": "Despite recent progress in abstractive summarization, systems still suffer\nfrom faithfulness errors. While prior work has proposed models that improve\nfaithfulness, it is unclear whether the improvement comes from an increased\nlevel of extractiveness of the model outputs as one naive way to improve\nfaithfulness is to make summarization models more extractive. In this work, we\npresent a framework for evaluating the effective faithfulness of summarization\nsystems, by generating a faithfulnessabstractiveness trade-off curve that\nserves as a control at different operating points on the abstractiveness\nspectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as\nwell as a recently proposed method for improving faithfulness, are both worse\nthan the control at the same level of abstractiveness. Finally, we learn a\nselector to identify the most faithful and abstractive summary for a given\ndocument, and show that this system can attain higher faithfulness scores in\nhuman evaluations while being more abstractive than the baseline system on two\ndatasets. Moreover, we show that our system is able to achieve a better\nfaithfulness-abstractiveness trade-off than the control at the same level of\nabstractiveness.", "published": "2021-08-31 08:48:25", "link": "http://arxiv.org/abs/2108.13684v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection", "abstract": "Knowledge-grounded dialogue is a task of generating a fluent and informative\nresponse based on both conversation context and a collection of external\nknowledge, in which knowledge selection plays an important role and attracts\nmore and more research interest. However, most existing models either select\nonly one knowledge or use all knowledge for responses generation. The former\nmay lose valuable information in discarded knowledge, while the latter may\nbring a lot of noise. At the same time, many approaches need to train the\nknowledge selector with knowledge labels that indicate ground-truth knowledge,\nbut these labels are difficult to obtain and require a large number of manual\nannotations. Motivated by these issues, we propose Knoformer, a dialogue\nresponse generation model based on reinforcement learning, which can\nautomatically select one or more related knowledge from the knowledge pool and\ndoes not need knowledge labels during training. Knoformer is evaluated on two\nknowledge-guided conversation datasets, and achieves state-of-the-art\nperformance.", "published": "2021-08-31 08:53:08", "link": "http://arxiv.org/abs/2108.13686v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Plan-then-Generate: Controlled Data-to-Text Generation via Planning", "abstract": "Recent developments in neural networks have led to the advance in\ndata-to-text generation. However, the lack of ability of neural models to\ncontrol the structure of generated output can be limiting in certain real-world\napplications. In this study, we propose a novel Plan-then-Generate (PlanGen)\nframework to improve the controllability of neural data-to-text models.\nExtensive experiments and analyses are conducted on two benchmark datasets,\nToTTo and WebNLG. The results show that our model is able to control both the\nintra-sentence and inter-sentence structure of the generated output.\nFurthermore, empirical comparisons against previous state-of-the-art methods\nshow that our model improves the generation quality as well as the output\ndiversity as judged by human and automatic evaluations.", "published": "2021-08-31 10:53:32", "link": "http://arxiv.org/abs/2108.13740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enjoy the Salience: Towards Better Transformer-based Faithful\n  Explanations with Word Salience", "abstract": "Pretrained transformer-based models such as BERT have demonstrated\nstate-of-the-art predictive performance when adapted into a range of natural\nlanguage processing tasks. An open problem is how to improve the faithfulness\nof explanations (rationales) for the predictions of these models. In this\npaper, we hypothesize that salient information extracted a priori from the\ntraining data can complement the task-specific information learned by the model\nduring fine-tuning on a downstream task. In this way, we aim to help BERT not\nto forget assigning importance to informative input tokens when making\npredictions by proposing SaLoss; an auxiliary loss function for guiding the\nmulti-head attention mechanism during training to be close to salient\ninformation extracted a priori using TextRank. Experiments for explanation\nfaithfulness across five datasets, show that models trained with SaLoss\nconsistently provide more faithful explanations across four different feature\nattribution methods compared to vanilla BERT. Using the rationales extracted\nfrom vanilla BERT and SaLoss models to train inherently faithful classifiers,\nwe further show that the latter result in higher predictive performance in\ndownstream tasks.", "published": "2021-08-31 11:21:30", "link": "http://arxiv.org/abs/2108.13759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues", "abstract": "The goal of dialogue relation extraction (DRE) is to identify the relation\nbetween two entities in a given dialogue. During conversations, speakers may\nexpose their relations to certain entities by explicit or implicit clues, such\nevidences called \"triggers\". However, trigger annotations may not be always\navailable for the target data, so it is challenging to leverage such\ninformation for enhancing the performance. Therefore, this paper proposes to\nlearn how to identify triggers from the data with trigger annotations and then\ntransfers the trigger-finding capability to other datasets for better\nperformance. The experiments show that the proposed approach is capable of\nimproving relation extraction performance of unseen relations and also\ndemonstrate the transferability of our proposed trigger-finding model across\ndifferent domains and datasets.", "published": "2021-08-31 13:04:08", "link": "http://arxiv.org/abs/2108.13811v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Open-Domain Question Answering", "abstract": "Open-domain Question Answering (ODQA) has achieved significant results in\nterms of supervised learning manner. However, data annotation cannot also be\nirresistible for its huge demand in an open domain. Though unsupervised QA or\nunsupervised Machine Reading Comprehension (MRC) has been tried more or less,\nunsupervised ODQA has not been touched according to our best knowledge. This\npaper thus pioneers the work of unsupervised ODQA by formally introducing the\ntask and proposing a series of key data construction methods. Our exploration\nin this work inspiringly shows unsupervised ODQA can reach up to 86%\nperformance of supervised ones.", "published": "2021-08-31 13:19:52", "link": "http://arxiv.org/abs/2108.13817v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thermostat: A Large Collection of NLP Model Explanations and Analysis\n  Tools", "abstract": "In the language domain, as in other domains, neural explainability takes an\never more important role, with feature attribution methods on the forefront.\nMany such methods require considerable computational resources and expert\nknowledge about implementation details and parameter choices. To facilitate\nresearch, we present Thermostat which consists of a large collection of model\nexplanations and accompanying analysis tools. Thermostat allows easy access to\nover 200k explanations for the decisions of prominent state-of-the-art models\nspanning across different NLP tasks, generated with multiple explainers. The\ndataset took over 10k GPU hours (> one year) to compile; compute time that the\ncommunity now saves. The accompanying software tools allow to analyse\nexplanations instance-wise but also accumulatively on corpus level. Users can\ninvestigate and compare models, datasets and explainers without the need to\norchestrate implementation details. Thermostat is fully open source,\ndemocratizes explainability research in the language domain, circumvents\nredundant computations and increases comparability and replicability.", "published": "2021-08-31 16:42:35", "link": "http://arxiv.org/abs/2108.13961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Generative Approach for Mitigating Structural Biases in Natural\n  Language Inference", "abstract": "Many natural language inference (NLI) datasets contain biases that allow\nmodels to perform well by only using a biased subset of the input, without\nconsidering the remainder features. For instance, models are able to make a\nclassification decision by only using the hypothesis, without learning the true\nrelationship between it and the premise. These structural biases lead\ndiscriminative models to learn unintended superficial features and to\ngeneralize poorly out of the training distribution. In this work, we\nreformulate the NLI task as a generative task, where a model is conditioned on\nthe biased subset of the input and the label and generates the remaining subset\nof the input. We show that by imposing a uniform prior, we obtain a provably\nunbiased model. Through synthetic experiments, we find that this approach is\nhighly robust to large amounts of bias. We then demonstrate empirically on two\ntypes of natural bias that this approach leads to fully unbiased models in\npractice. However, we find that generative models are difficult to train and\nthey generally perform worse than discriminative baselines. We highlight the\ndifficulty of the generative modeling task in the context of NLI as a cause for\nthis worse performance. Finally, by fine-tuning the generative model with a\ndiscriminative objective, we reduce the performance gap between the generative\nmodel and the discriminative baseline, while allowing for a small amount of\nbias.", "published": "2021-08-31 17:59:45", "link": "http://arxiv.org/abs/2108.14006v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Sentence Bottleneck Autoencoders from Transformer Language Models", "abstract": "Representation learning for text via pretraining a language model on a large\ncorpus has become a standard starting point for building NLP systems. This\napproach stands in contrast to autoencoders, also trained on raw text, but with\nthe objective of learning to encode each input as a vector that allows full\nreconstruction. Autoencoders are attractive because of their latent space\nstructure and generative properties. We therefore explore the construction of a\nsentence-level autoencoder from a pretrained, frozen transformer language\nmodel. We adapt the masked language modeling objective as a generative,\ndenoising one, while only training a sentence bottleneck and a single-layer\nmodified transformer decoder. We demonstrate that the sentence representations\ndiscovered by our model achieve better quality than previous methods that\nextract representations from pretrained transformers on text similarity tasks,\nstyle transfer (an example of controlled generation), and single-sentence\nclassification tasks in the GLUE benchmark, while using fewer parameters than\nlarge pretrained models.", "published": "2021-08-31 19:39:55", "link": "http://arxiv.org/abs/2109.00055v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interactive Machine Comprehension with Dynamic Knowledge Graphs", "abstract": "Interactive machine reading comprehension (iMRC) is machine comprehension\ntasks where knowledge sources are partially observable. An agent must interact\nwith an environment sequentially to gather necessary knowledge in order to\nanswer a question. We hypothesize that graph representations are good inductive\nbiases, which can serve as an agent's memory mechanism in iMRC tasks. We\nexplore four different categories of graphs that can capture text information\nat various levels. We describe methods that dynamically build and update these\ngraphs during information gathering, as well as neural models to encode graph\nrepresentations in RL agents. Extensive experiments on iSQuAD suggest that\ngraph representations can result in significant performance improvements for RL\nagents.", "published": "2021-08-31 21:05:22", "link": "http://arxiv.org/abs/2109.00077v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AraT5: Text-to-Text Transformers for Arabic Language Generation", "abstract": "Transfer learning with a unified Transformer framework (T5) that converts all\nlanguage problems into a text-to-text format was recently proposed as a simple\nand effective transfer learning approach. Although a multilingual version of\nthe T5 model (mT5) was also introduced, it is not clear how well it can fare on\nnon-English tasks involving diverse data. To investigate this question, we\napply mT5 on a language with a wide variety of dialects--Arabic. For\nevaluation, we introduce a novel benchmark for ARabic language GENeration\n(ARGEN), covering seven important tasks. For model comparison, we pre-train\nthree powerful Arabic T5-style models and evaluate them on ARGEN. Although\npre-trained with ~49 less data, our new models perform significantly better\nthan mT5 on all ARGEN tasks (in 52 out of 59 test sets) and set several new\nSOTAs. Our models also establish new SOTA on the recently-proposed, large\nArabic language understanding evaluation benchmark ARLUE (Abdul-Mageed et al.,\n2021). Our new models are publicly available. We also link to ARGEN datasets\nthrough our repository: https://github.com/UBC-NLP/araT5.", "published": "2021-08-31 02:02:10", "link": "http://arxiv.org/abs/2109.12068v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "T3-Vis: a visual analytic framework for Training and fine-Tuning\n  Transformers in NLP", "abstract": "Transformers are the dominant architecture in NLP, but their training and\nfine-tuning is still very challenging. In this paper, we present the design and\nimplementation of a visual analytic framework for assisting researchers in such\nprocess, by providing them with valuable insights about the model's intrinsic\nproperties and behaviours. Our framework offers an intuitive overview that\nallows the user to explore different facets of the model (e.g., hidden states,\nattention) through interactive visualization, and allows a suite of built-in\nalgorithms that compute the importance of model components and different parts\nof the input sequence. Case studies and feedback from a user focus group\nindicate that the framework is useful, and suggest several improvements.", "published": "2021-08-31 02:20:46", "link": "http://arxiv.org/abs/2108.13587v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Text Classification of Transliterated Hindi and Malayalam", "abstract": "Transliteration is very common on social media, but transliterated text is\nnot adequately handled by modern neural models for various NLP tasks. In this\nwork, we combine data augmentation approaches with a Teacher-Student training\nscheme to address this issue in a cross-lingual transfer setting for\nfine-tuning state-of-the-art pre-trained multilingual language models such as\nmBERT and XLM-R. We evaluate our method on transliterated Hindi and Malayalam,\nalso introducing new datasets for benchmarking on real-world scenarios: one on\nsentiment classification in transliterated Malayalam, and another on crisis\ntweet classification in transliterated Hindi and Malayalam (related to the 2013\nNorth India and 2018 Kerala floods). Our method yielded an average improvement\nof +5.6% on mBERT and +4.7% on XLM-R in F1 scores over their strong baselines.", "published": "2021-08-31 05:13:17", "link": "http://arxiv.org/abs/2108.13620v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided\n  Adaptive Memory", "abstract": "Lip reading, aiming to recognize spoken sentences according to the given\nvideo of lip movements without relying on the audio stream, has attracted great\ninterest due to its application in many scenarios. Although prior works that\nexplore lip reading have obtained salient achievements, they are all trained in\na non-simultaneous manner where the predictions are generated requiring access\nto the full video. To breakthrough this constraint, we study the task of\nsimultaneous lip reading and devise SimulLR, a simultaneous lip Reading\ntransducer with attention-guided adaptive memory from three aspects: (1) To\naddress the challenge of monotonic alignments while considering the syntactic\nstructure of the generated sentences under simultaneous setting, we build a\ntransducer-based model and design several effective training strategies\nincluding CTC pre-training, model warm-up and curriculum learning to promote\nthe training of the lip reading transducer. (2) To learn better spatio-temporal\nrepresentations for simultaneous encoder, we construct a truncated 3D\nconvolution and time-restricted self-attention layer to perform the\nframe-to-frame interaction within a video segment containing fixed number of\nframes. (3) The history information is always limited due to the storage in\nreal-time scenarios, especially for massive video data. Therefore, we devise a\nnovel attention-guided adaptive memory to organize semantic information of\nhistory segments and enhance the visual representations with acceptable\ncomputation-aware latency. The experiments show that the SimulLR achieves the\ntranslation speedup 9.10$\\times$ compared with the state-of-the-art\nnon-simultaneous methods, and also obtains competitive results, which indicates\nthe effectiveness of our proposed methods.", "published": "2021-08-31 05:54:16", "link": "http://arxiv.org/abs/2108.13630v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Explaining Classes through Word Attribution", "abstract": "In recent years, several methods have been proposed for explaining individual\npredictions of deep learning models, yet there has been little study of how to\naggregate these predictions to explain how such models view classes as a whole\nin text classification tasks. In this work, we propose a method for explaining\nclasses using deep learning models and the Integrated Gradients feature\nattribution technique by aggregating explanations of individual examples in\ntext classification to general descriptions of the classes. We demonstrate the\napproach on Web register (genre) classification using the XML-R model and the\nCorpus of Online Registers of English (CORE), finding that the method\nidentifies plausible and discriminative keywords characterizing all but the\nsmallest class.", "published": "2021-08-31 07:22:29", "link": "http://arxiv.org/abs/2108.13653v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gray Cycles of Maximum Length Related to k-Character Substitutions", "abstract": "Given a word binary relation $\\tau$ we define a $\\tau$-Gray cycle over a\nfinite language X to be a permutation w [i] 0$\\le$i$\\le$|X|--1 of X such that\neach word wi is an image of the previous word wi--1 by $\\tau$. In that\nframework, we introduce the complexity measure $\\lambda$(n), equal to the\nlargest cardinality of a language X having words of length at most n, and such\nthat a $\\tau$-Gray cycle over X exists. The present paper is concerned with the\nrelation $\\tau$ = $\\sigma$ k , the so-called k-character substitution, where\n(u, v) belongs to $\\sigma$ k if, and only if, the Hamming distance of u and v\nis k. We compute the bound $\\lambda$(n) for all cases of the alphabet\ncardinality and the argument n.", "published": "2021-08-31 07:49:15", "link": "http://arxiv.org/abs/2108.13659v2", "categories": ["cs.CL", "cs.DM"], "primary_category": "cs.CL"}
{"title": "Task-Oriented Dialogue System as Natural Language Generation", "abstract": "In this paper, we propose to formulate the task-oriented dialogue system as\nthe purely natural language generation task, so as to fully leverage the\nlarge-scale pre-trained models like GPT-2 and simplify complicated\ndelexicalization prepossessing. However, directly applying this method heavily\nsuffers from the dialogue entity inconsistency caused by the removal of\ndelexicalized tokens, as well as the catastrophic forgetting problem of the\npre-trained model during fine-tuning, leading to unsatisfactory performance. To\nalleviate these problems, we design a novel GPT-Adapter-CopyNet network, which\nincorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve\nbetter performance on transfer learning and dialogue entity generation.\nExperimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ\ndataset demonstrate that our proposed approach significantly outperforms\nbaseline models with a remarkable performance on automatic and human\nevaluations.", "published": "2021-08-31 08:36:42", "link": "http://arxiv.org/abs/2108.13679v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Monolingual versus Multilingual BERTology for Vietnamese Extractive\n  Multi-Document Summarization", "abstract": "Recent researches have demonstrated that BERT shows potential in a wide range\nof natural language processing tasks. It is adopted as an encoder for many\nstate-of-the-art automatic summarizing systems, which achieve excellent\nperformance. However, so far, there is not much work done for Vietnamese. In\nthis paper, we showcase how BERT can be implemented for extractive text\nsummarization in Vietnamese on multi-document. We introduce a novel comparison\nbetween different multilingual and monolingual BERT models. The experiment\nresults indicate that monolingual models produce promising results compared to\nother multilingual models and previous text summarizing models for Vietnamese.", "published": "2021-08-31 10:54:32", "link": "http://arxiv.org/abs/2108.13741v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The five Is: Key principles for interpretable and safe conversational AI", "abstract": "In this position paper, we present five key principles, namely\ninterpretability, inherent capability to explain, independent data, interactive\nlearning, and inquisitiveness, for the development of conversational AI that,\nunlike the currently popular black box approaches, is transparent and\naccountable. At present, there is a growing concern with the use of black box\nstatistical language models: While displaying impressive average performance,\nsuch systems are also prone to occasional spectacular failures, for which there\nis no clear remedy. In an effort to initiate a discussion on possible\nalternatives, we outline and exemplify how our five principles enable the\ndevelopment of conversational AI systems that are transparent and thus safer\nfor use. We also present some of the challenges inherent in the implementation\nof those principles.", "published": "2021-08-31 11:38:48", "link": "http://arxiv.org/abs/2108.13766v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T42, 68T01, 68T05", "I.2.7; I.2.0; I.2.6"], "primary_category": "cs.CL"}
{"title": "Contrastive Domain Adaptation for Question Answering using Limited Text\n  Corpora", "abstract": "Question generation has recently shown impressive results in customizing\nquestion answering (QA) systems to new domains. These approaches circumvent the\nneed for manually annotated training data from the new domain and, instead,\ngenerate synthetic question-answer pairs that are used for training. However,\nexisting methods for question generation rely on large amounts of synthetically\ngenerated datasets and costly computational resources, which render these\ntechniques widely inaccessible when the text corpora is of limited size. This\nis problematic as many niche domains rely on small text corpora, which\nnaturally restricts the amount of synthetic data that can be generated. In this\npaper, we propose a novel framework for domain adaptation called contrastive\ndomain adaptation for QA (CAQA). Specifically, CAQA combines techniques from\nquestion generation and domain-invariant learning to answer out-of-domain\nquestions in settings with limited text corpora. Here, we train a QA system on\nboth source data and generated data from the target domain with a contrastive\nadaptation loss that is incorporated in the training objective. By combining\ntechniques from question generation and domain-invariant learning, our model\nachieved considerable improvements compared to state-of-the-art baselines.", "published": "2021-08-31 14:05:55", "link": "http://arxiv.org/abs/2108.13854v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning", "abstract": "\\textbf{P}re-\\textbf{T}rained \\textbf{M}odel\\textbf{s} have been widely\napplied and recently proved vulnerable under backdoor attacks: the released\npre-trained weights can be maliciously poisoned with certain triggers. When the\ntriggers are activated, even the fine-tuned model will predict pre-defined\nlabels, causing a security threat. These backdoors generated by the poisoning\nmethods can be erased by changing hyper-parameters during fine-tuning or\ndetected by finding the triggers. In this paper, we propose a stronger\nweight-poisoning attack method that introduces a layerwise weight poisoning\nstrategy to plant deeper backdoors; we also introduce a combinatorial trigger\nthat cannot be easily detected. The experiments on text classification tasks\nshow that previous defense methods cannot resist our weight-poisoning method,\nwhich indicates that our method can be widely applied and may provide hints for\nfuture model robustness studies.", "published": "2021-08-31 14:47:37", "link": "http://arxiv.org/abs/2108.13888v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Like Article, Like Audience: Enforcing Multimodal Correlations for\n  Disinformation Detection", "abstract": "User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.", "published": "2021-08-31 14:50:16", "link": "http://arxiv.org/abs/2108.13892v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset", "abstract": "The MS MARCO ranking dataset has been widely used for training deep learning\nmodels for IR tasks, achieving considerable effectiveness on diverse zero-shot\nscenarios. However, this type of resource is scarce in languages other than\nEnglish. In this work, we present mMARCO, a multilingual version of the MS\nMARCO passage ranking dataset comprising 13 languages that was created using\nmachine translation. We evaluated mMARCO by finetuning monolingual and\nmultilingual reranking models, as well as a multilingual dense retrieval model\non this dataset. We also evaluated models finetuned using the mMARCO dataset in\na zero-shot scenario on Mr. TyDi dataset, demonstrating that multilingual\nmodels finetuned on our translated dataset achieve superior effectiveness to\nmodels finetuned on the original English version alone. Our experiments also\nshow that a distilled multilingual reranker is competitive with non-distilled\nmodels while having 5.4 times fewer parameters. Lastly, we show a positive\ncorrelation between translation quality and retrieval effectiveness, providing\nevidence that improvements in translation methods might lead to improvements in\nmultilingual information retrieval. The translated datasets and finetuned\nmodels are available at https://github.com/unicamp-dl/mMARCO.", "published": "2021-08-31 14:53:37", "link": "http://arxiv.org/abs/2108.13897v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sense representations for Portuguese: experiments with sense embeddings\n  and deep neural language models", "abstract": "Sense representations have gone beyond word representations like Word2Vec,\nGloVe and FastText and achieved innovative performance on a wide range of\nnatural language processing tasks. Although very useful in many applications,\nthe traditional approaches for generating word embeddings have a strict\ndrawback: they produce a single vector representation for a given word ignoring\nthe fact that ambiguous words can assume different meanings. In this paper, we\nexplore unsupervised sense representations which, different from traditional\nword embeddings, are able to induce different senses of a word by analyzing its\ncontextual semantics in a text. The unsupervised sense representations\ninvestigated in this paper are: sense embeddings and deep neural language\nmodels. We present the first experiments carried out for generating sense\nembeddings for Portuguese. Our experiments show that the sense embedding model\n(Sense2vec) outperformed traditional word embeddings in syntactic and semantic\nanalogies task, proving that the language resource generated here can improve\nthe performance of NLP tasks in Portuguese. We also evaluated the performance\nof pre-trained deep neural language models (ELMo and BERT) in two transfer\nlearning approaches: feature based and fine-tuning, in the semantic textual\nsimilarity task. Our experiments indicate that the fine tuned Multilingual and\nPortuguese BERT language models were able to achieve better accuracy than the\nELMo model and baselines.", "published": "2021-08-31 18:07:01", "link": "http://arxiv.org/abs/2109.00025v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Effectiveness of Deep Networks in NLP using BiDAF as an example\n  architecture", "abstract": "Question Answering with NLP has progressed through the evolution of advanced\nmodel architectures like BERT and BiDAF and earlier word, character, and\ncontext-based embeddings. As BERT has leapfrogged the accuracy of models, an\nelement of the next frontier can be the introduction of deep networks and an\neffective way to train them. In this context, I explored the effectiveness of\ndeep networks focussing on the model encoder layer of BiDAF. BiDAF with its\nheterogeneous layers provides the opportunity not only to explore the\neffectiveness of deep networks but also to evaluate whether the refinements\nmade in lower layers are additive to the refinements made in the upper layers\nof the model architecture. I believe the next greatest model in NLP will in\nfact fold in a solid language modeling like BERT with a composite architecture\nwhich will bring in refinements in addition to generic language modeling and\nwill have a more extensive layered architecture. I experimented with the Bypass\nnetwork, Residual Highway network, and DenseNet architectures. In addition, I\nevaluated the effectiveness of ensembling the last few layers of the network. I\nalso studied the difference character embeddings make in adding them to the\nword embeddings, and whether the effects are additive with deep networks. My\nstudies indicate that deep networks are in fact effective in giving a boost.\nAlso, the refinements in the lower layers like embeddings are passed on\nadditively to the gains made through deep networks.", "published": "2021-08-31 20:50:18", "link": "http://arxiv.org/abs/2109.00074v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Program Merge Conflict Resolution via Neural Transformers", "abstract": "Collaborative software development is an integral part of the modern software\ndevelopment life cycle, essential to the success of large-scale software\nprojects. When multiple developers make concurrent changes around the same\nlines of code, a merge conflict may occur. Such conflicts stall pull requests\nand continuous integration pipelines for hours to several days, seriously\nhurting developer productivity. To address this problem, we introduce\nMergeBERT, a novel neural program merge framework based on token-level\nthree-way differencing and a transformer encoder model. By exploiting the\nrestricted nature of merge conflict resolutions, we reformulate the task of\ngenerating the resolution sequence as a classification task over a set of\nprimitive merge patterns extracted from real-world merge commit data. Our model\nachieves 63-68% accuracy for merge resolution synthesis, yielding nearly a 3x\nperformance improvement over existing semi-structured, and 2x improvement over\nneural program merge tools. Finally, we demonstrate that MergeBERT is\nsufficiently flexible to work with source code files in Java, JavaScript,\nTypeScript, and C# programming languages. To measure the practical use of\nMergeBERT, we conduct a user study to evaluate MergeBERT suggestions with 25\ndevelopers from large OSS projects on 122 real-world conflicts they\nencountered. Results suggest that in practice, MergeBERT resolutions would be\naccepted at a higher rate than estimated by automatic metrics for precision and\naccuracy. Additionally, we use participant feedback to identify future avenues\nfor improvement of MergeBERT.", "published": "2021-08-31 21:37:53", "link": "http://arxiv.org/abs/2109.00084v4", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "It's not Rocket Science : Interpreting Figurative Language in Narratives", "abstract": "Figurative language is ubiquitous in English. Yet, the vast majority of NLP\nresearch focuses on literal language. Existing text representations by design\nrely on compositionality, while figurative language is often non-compositional.\nIn this paper, we study the interpretation of two non-compositional figurative\nlanguages (idioms and similes). We collected datasets of fictional narratives\ncontaining a figurative expression along with crowd-sourced plausible and\nimplausible continuations relying on the correct interpretation of the\nexpression. We then trained models to choose or generate the plausible\ncontinuation. Our experiments show that models based solely on pre-trained\nlanguage models perform substantially worse than humans on these tasks. We\nadditionally propose knowledge-enhanced models, adopting human strategies for\ninterpreting figurative language types : inferring meaning from the context and\nrelying on the constituent words' literal meanings. The knowledge-enhanced\nmodels improve the performance on both the discriminative and generative tasks,\nfurther bridging the gap from human performance.", "published": "2021-08-31 21:46:35", "link": "http://arxiv.org/abs/2109.00087v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Task Triplet Loss for Named Entity Recognition using Supplementary\n  Text", "abstract": "Retail item data contains many different forms of text like the title of an\nitem, the description of an item, item name and reviews. It is of interest to\nidentify the item name in the other forms of text using a named entity tagger.\nHowever, the title of an item and its description are syntactically different\n(but semantically similar) in that the title is not necessarily a well formed\nsentence while the description is made up of well formed sentences. In this\nwork, we use a triplet loss to contrast the embeddings of the item title with\nthe description to establish a proof of concept. We find that using the triplet\nloss in a multi-task NER algorithm improves both the precision and recall by a\nsmall percentage. While the improvement is small, we think it is a step in the\nright direction of using various forms of text in a multi-task algorithm. In\naddition to precision and recall, the multi task triplet loss method is also\nfound to significantly improve the exact match accuracy i.e. the accuracy of\ntagging the entire set of tokens in the text with correct tags.", "published": "2021-08-31 01:13:33", "link": "http://arxiv.org/abs/2109.13736v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Does Adversarial Fine-Tuning Benefit BERT?", "abstract": "Adversarial training (AT) is one of the most reliable methods for defending\nagainst adversarial attacks in machine learning. Variants of this method have\nbeen used as regularization mechanisms to achieve SOTA results on NLP\nbenchmarks, and they have been found to be useful for transfer learning and\ncontinual learning. We search for the reasons for the effectiveness of AT by\ncontrasting vanilla and adversarially fine-tuned BERT models. We identify\npartial preservation of BERT's syntactic abilities during fine-tuning as the\nkey to the success of AT. We observe that adversarially fine-tuned models\nremain more faithful to BERT's language modeling behavior and are more\nsensitive to the word order. As concrete examples of syntactic abilities, an\nadversarially fine-tuned model could have an advantage of up to 38% on anaphora\nagreement and up to 11% on dependency parsing. Our analysis demonstrates that\nvanilla fine-tuning oversimplifies the sentence representation by focusing\nheavily on a small subset of words. AT, however, moderates the effect of these\ninfluential words and encourages representational diversity. This allows for a\nmore hierarchical representation of a sentence and leads to the mitigation of\nBERT's loss of syntactic abilities.", "published": "2021-08-31 03:39:06", "link": "http://arxiv.org/abs/2108.13602v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TNNT: The Named Entity Recognition Toolkit", "abstract": "Extraction of categorised named entities from text is a complex task given\nthe availability of a variety of Named Entity Recognition (NER) models and the\nunstructured information encoded in different source document formats.\nProcessing the documents to extract text, identifying suitable NER models for a\ntask, and obtaining statistical information is important in data analysis to\nmake informed decisions. This paper presents TNNT, a toolkit that automates the\nextraction of categorised named entities from unstructured information encoded\nin source documents, using diverse state-of-the-art Natural Language Processing\n(NLP) tools and NER models. TNNT integrates 21 different NER models as part of\na Knowledge Graph Construction Pipeline (KGCP) that takes a document set as\ninput and processes it based on the defined settings, applying the selected\nblocks of NER models to output the results. The toolkit generates all results\nwith an integrated summary of the extracted entities, enabling enhanced data\nanalysis to support the KGCP, and also, to aid further NLP tasks.", "published": "2021-08-31 09:24:16", "link": "http://arxiv.org/abs/2108.13700v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SE"], "primary_category": "cs.CL"}
{"title": "A Search Engine for Discovery of Scientific Challenges and Directions", "abstract": "Keeping track of scientific challenges, advances and emerging directions is a\nfundamental part of research. However, researchers face a flood of papers that\nhinders discovery of important knowledge. In biomedicine, this directly impacts\nhuman lives. To address this problem, we present a novel task of extraction and\nsearch of scientific challenges and directions, to facilitate rapid knowledge\ndiscovery. We construct and release an expert-annotated corpus of texts sampled\nfrom full-length papers, labeled with novel semantic categories that generalize\nacross many types of challenges and directions. We focus on a large corpus of\ninterdisciplinary work relating to the COVID-19 pandemic, ranging from\nbiomedicine to areas such as AI and economics. We apply a model trained on our\ndata to identify challenges and directions across the corpus and build a\ndedicated search engine. In experiments with 19 researchers and clinicians\nusing our system, we outperform a popular scientific search engine in assisting\nknowledge discovery. Finally, we show that models trained on our resource\ngeneralize to the wider biomedical domain and to AI papers, highlighting its\nbroad utility. We make our data, model and search engine publicly available.\nhttps://challenges.apps.allenai.org/", "published": "2021-08-31 11:08:20", "link": "http://arxiv.org/abs/2108.13751v3", "categories": ["cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Network psychometrics and cognitive network science open new ways for\n  detecting, understanding and tackling the complexity of math anxiety: A\n  review", "abstract": "Math anxiety is a clinical pathology impairing cognitive processing in\nmath-related contexts. Originally thought to affect only inexperienced,\nlow-achieving students, recent investigations show how math anxiety is vastly\ndiffused even among high-performing learners. This review of data-informed\nstudies outlines math anxiety as a complex system that: (i) cripples\nwell-being, self-confidence and information processing on both conscious and\nsubconscious levels, (ii) can be transmitted by social interactions, like a\npathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of\nstudents in 63 out of 64 worldwide educational systems but correlates weakly\nwith academic performance, and (iv) poses a concrete threat to students'\nwell-being, computational literacy and career prospects in science. These\npatterns underline the crucial need to go beyond performance for estimating\nmath anxiety. Recent advances with network psychometrics and cognitive network\nscience provide ideal frameworks for detecting, interpreting and intervening\nupon such clinical condition. Merging education research, psychology and data\nscience, the approaches reviewed here reconstruct psychological constructs as\ncomplex systems, represented either as multivariate correlation models (e.g.\ngraph exploratory analysis) or as cognitive networks of semantic/emotional\nassociations (e.g. free association networks or forma mentis networks). Not\nonly can these interconnected networks detect otherwise hidden levels of math\nanxiety but - more crucially - they can unveil the specific layout of\ninteracting factors, e.g. key sources and targets, behind math anxiety in a\ngiven cohort. As discussed here, these network approaches open concrete ways\nfor unveiling students' perceptions, emotions and mental well-being, and can\nenable future powerful data-informed interventions untangling math anxiety.", "published": "2021-08-31 12:43:43", "link": "http://arxiv.org/abs/2108.13800v1", "categories": ["cs.SI", "cs.CL", "math.HO", "physics.soc-ph"], "primary_category": "cs.SI"}
{"title": "When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions", "abstract": "Scenario-based question answering (SQA) requires retrieving and reading\nparagraphs from a large corpus to answer a question which is contextualized by\na long scenario description. Since a scenario contains both keyphrases for\nretrieval and much noise, retrieval for SQA is extremely difficult. Moreover,\nit can hardly be supervised due to the lack of relevance labels of paragraphs\nfor SQA. To meet the challenge, in this paper we propose a joint\nretriever-reader model called JEEVES where the retriever is implicitly\nsupervised only using QA labels via a novel word weighting mechanism. JEEVES\nsignificantly outperforms a variety of strong baselines on multiple-choice\nquestions in three SQA datasets.", "published": "2021-08-31 14:32:04", "link": "http://arxiv.org/abs/2108.13875v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The emojification of sentiment on social media: Collection and analysis\n  of a longitudinal Twitter sentiment dataset", "abstract": "Social media, as a means for computer-mediated communication, has been\nextensively used to study the sentiment expressed by users around events or\ntopics. There is however a gap in the longitudinal study of how sentiment\nevolved in social media over the years. To fill this gap, we develop TM-Senti,\na new large-scale, distantly supervised Twitter sentiment dataset with over 184\nmillion tweets and covering a time period of over seven years. We describe and\nassess our methodology to put together a large-scale, emoticon- and emoji-based\nlabelled sentiment analysis dataset, along with an analysis of the resulting\ndataset. Our analysis highlights interesting temporal changes, among others in\nthe increasing use of emojis over emoticons. We publicly release the dataset\nfor further research in tasks including sentiment analysis and text\nclassification of tweets. The dataset can be fully rehydrated including tweet\nmetadata and without missing tweets thanks to the archive of tweets publicly\navailable on the Internet Archive, which the dataset is based on.", "published": "2021-08-31 14:54:46", "link": "http://arxiv.org/abs/2108.13898v3", "categories": ["cs.SI", "cs.CL", "cs.DL"], "primary_category": "cs.SI"}
{"title": "Robust Retrieval Augmented Generation for Zero-shot Slot Filling", "abstract": "Automatically inducing high quality knowledge graphs from a given collection\nof documents still remains a challenging problem in AI. One way to make headway\nfor this problem is through advancements in a related task known as slot\nfilling. In this task, given an entity query in form of [Entity, Slot, ?], a\nsystem is asked to fill the slot by generating or extracting the missing value\nexploiting evidence extracted from relevant passage(s) in the given document\ncollection. The recent works in the field try to solve this task in an\nend-to-end fashion using retrieval-based language models. In this paper, we\npresent a novel approach to zero-shot slot filling that extends dense passage\nretrieval with hard negatives and robust training procedures for retrieval\naugmented generation models. Our model reports large improvements on both T-REx\nand zsRE slot filling datasets, improving both passage retrieval and slot value\ngeneration, and ranking at the top-1 position in the KILT leaderboard.\nMoreover, we demonstrate the robustness of our system showing its domain\nadaptation capability on a new variant of the TACRED dataset for slot filling,\nthrough a combination of zero/few-shot learning. We release the source code and\npre-trained models.", "published": "2021-08-31 15:51:27", "link": "http://arxiv.org/abs/2108.13934v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Effective Sequence-to-Sequence Dialogue State Tracking", "abstract": "Sequence-to-sequence models have been applied to a wide variety of NLP tasks,\nbut how to properly use them for dialogue state tracking has not been\nsystematically investigated. In this paper, we study this problem from the\nperspectives of pre-training objectives as well as the formats of context\nrepresentations. We demonstrate that the choice of pre-training objective makes\na significant difference to the state tracking quality. In particular, we find\nthat masked span prediction is more effective than auto-regressive language\nmodeling. We also explore using Pegasus, a span prediction-based pre-training\nobjective for text summarization, for the state tracking model. We found that\npre-training for the seemingly distant summarization task works surprisingly\nwell for dialogue state tracking. In addition, we found that while recurrent\nstate context representation works also reasonably well, the model may have a\nhard time recovering from earlier mistakes. We conducted experiments on the\nMultiWOZ 2.1-2.4, WOZ 2.0, and DSTC2 datasets with consistent observations.", "published": "2021-08-31 17:27:59", "link": "http://arxiv.org/abs/2108.13990v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Working Memory Connections for LSTM", "abstract": "Recurrent Neural Networks with Long Short-Term Memory (LSTM) make use of\ngating mechanisms to mitigate exploding and vanishing gradients when learning\nlong-term dependencies. For this reason, LSTMs and other gated RNNs are widely\nadopted, being the standard de facto for many sequence modeling tasks. Although\nthe memory cell inside the LSTM contains essential information, it is not\nallowed to influence the gating mechanism directly. In this work, we improve\nthe gate potential by including information coming from the internal cell\nstate. The proposed modification, named Working Memory Connection, consists in\nadding a learnable nonlinear projection of the cell content into the network\ngates. This modification can fit into the classical LSTM gates without any\nassumption on the underlying task, being particularly effective when dealing\nwith longer sequences. Previous research effort in this direction, which goes\nback to the early 2000s, could not bring a consistent improvement over vanilla\nLSTM. As part of this paper, we identify a key issue tied to previous\nconnections that heavily limits their effectiveness, hence preventing a\nsuccessful integration of the knowledge coming from the internal cell state. We\nshow through extensive experimental evaluation that Working Memory Connections\nconstantly improve the performance of LSTMs on a variety of tasks. Numerical\nresults suggest that the cell state contains useful information that is worth\nincluding in the gate structure.", "published": "2021-08-31 18:01:30", "link": "http://arxiv.org/abs/2109.00020v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Machine-Learning media bias", "abstract": "We present an automated method for measuring media bias. Inferring which\nnewspaper published a given article, based only on the frequencies with which\nit uses different phrases, leads to a conditional probability distribution\nwhose analysis lets us automatically map newspapers and phrases into a bias\nspace. By analyzing roughly a million articles from roughly a hundred\nnewspapers for bias in dozens of news topics, our method maps newspapers into a\ntwo-dimensional bias landscape that agrees well with previous bias\nclassifications based on human judgement. One dimension can be interpreted as\ntraditional left-right bias, the other as establishment bias. This means that\nalthough news bias is inherently political, its measurement need not be.", "published": "2021-08-31 18:06:32", "link": "http://arxiv.org/abs/2109.00024v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Improving Multimodal fusion via Mutual Dependency Maximisation", "abstract": "Multimodal sentiment analysis is a trending area of research, and the\nmultimodal fusion is one of its most active topic. Acknowledging humans\ncommunicate through a variety of channels (i.e visual, acoustic, linguistic),\nmultimodal systems aim at integrating different unimodal representations into a\nsynthetic one. So far, a consequent effort has been made on developing complex\narchitectures allowing the fusion of these modalities. However, such systems\nare mainly trained by minimising simple losses such as $L_1$ or cross-entropy.\nIn this work, we investigate unexplored penalties and propose a set of new\nobjectives that measure the dependency between modalities. We demonstrate that\nour new penalties lead to a consistent improvement (up to $4.3$ on accuracy)\nacross a large variety of state-of-the-art models on two well-known sentiment\nanalysis datasets: \\texttt{CMU-MOSI} and \\texttt{CMU-MOSEI}. Our method not\nonly achieves a new SOTA on both datasets but also produces representations\nthat are more robust to modality drops. Finally, a by-product of our methods\nincludes a statistical network which can be used to interpret the high\ndimensional representations learnt by the model.", "published": "2021-08-31 06:26:26", "link": "http://arxiv.org/abs/2109.00922v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Efficient conformer: Progressive downsampling and grouped attention for\n  automatic speech recognition", "abstract": "The recently proposed Conformer architecture has shown state-of-the-art\nperformances in Automatic Speech Recognition by combining convolution with\nattention to model both local and global dependencies. In this paper, we study\nhow to reduce the Conformer architecture complexity with a limited computing\nbudget, leading to a more efficient architecture design that we call Efficient\nConformer. We introduce progressive downsampling to the Conformer encoder and\npropose a novel attention mechanism named grouped attention, allowing us to\nreduce attention complexity from $O(n^{2}d)$ to $O(n^{2}d / g)$ for sequence\nlength $n$, hidden dimension $d$ and group size parameter $g$. We also\nexperiment the use of strided multi-head self-attention as a global\ndownsampling operation. Our experiments are performed on the LibriSpeech\ndataset with CTC and RNN-Transducer losses. We show that within the same\ncomputing budget, the proposed architecture achieves better performances with\nfaster training and decoding compared to the Conformer. Our 13M parameters CTC\nmodel achieves competitive WERs of 3.6%/9.0% without using a language model and\n2.7%/6.7% with an external n-gram language model on the test-clean/test-other\nsets while being 29% faster than our CTC Conformer baseline at inference and\n36% faster to train.", "published": "2021-08-31 07:48:06", "link": "http://arxiv.org/abs/2109.01163v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Automated Mining of Leaderboards for Empirical AI Research", "abstract": "With the rapid growth of research publications, empowering scientists to keep\noversight over the scientific progress is of paramount importance. In this\nregard, the Leaderboards facet of information organization provides an overview\non the state-of-the-art by aggregating empirical results from various studies\naddressing the same research challenge. Crowdsourcing efforts like\nPapersWithCode among others are devoted to the construction of Leaderboards\npredominantly for various subdomains in Artificial Intelligence. Leaderboards\nprovide machine-readable scholarly knowledge that has proven to be directly\nuseful for scientists to keep track of research progress. The construction of\nLeaderboards could be greatly expedited with automated text mining.\n  This study presents a comprehensive approach for generating Leaderboards for\nknowledge-graph-based scholarly information organization. Specifically, we\ninvestigate the problem of automated Leaderboard construction using\nstate-of-the-art transformer models, viz. Bert, SciBert, and XLNet. Our\nanalysis reveals an optimal approach that significantly outperforms existing\nbaselines for the task with evaluation scores above 90% in F1. This, in turn,\noffers new state-of-the-art results for Leaderboard extraction. As a result, a\nvast share of empirical AI research can be organized in the next-generation\ndigital libraries as knowledge graphs.", "published": "2021-08-31 10:00:52", "link": "http://arxiv.org/abs/2109.13089v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Structured Prediction in NLP -- A survey", "abstract": "Over the last several years, the field of Structured prediction in NLP has\nhad seen huge advancements with sophisticated probabilistic graphical models,\nenergy-based networks, and its combination with deep learning-based approaches.\nThis survey provides a brief of major techniques in structured prediction and\nits applications in the NLP domains like parsing, sequence labeling, text\ngeneration, and sequence to sequence tasks. We also deep-dived into\nenergy-based and attention-based techniques in structured prediction,\nidentified some relevant open issues and gaps in the current state-of-the-art\nresearch, and have come up with some detailed ideas for future research in\nthese fields.", "published": "2021-08-31 07:01:09", "link": "http://arxiv.org/abs/2110.02057v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LightNER: A Lightweight Tuning Paradigm for Low-resource NER via\n  Pluggable Prompting", "abstract": "Most NER methods rely on extensive labeled data for model training, which\nstruggles in the low-resource scenarios with limited training data. Existing\ndominant approaches usually suffer from the challenge that the target domain\nhas different label sets compared with a resource-rich source domain, which can\nbe concluded as class transfer and domain transfer. In this paper, we propose a\nlightweight tuning paradigm for low-resource NER via pluggable prompting\n(LightNER). Specifically, we construct the unified learnable verbalizer of\nentity categories to generate the entity span sequence and entity categories\nwithout any label-specific classifiers, thus addressing the class transfer\nissue. We further propose a pluggable guidance module by incorporating\nlearnable parameters into the self-attention layer as guidance, which can\nre-modulate the attention and adapt pre-trained weights. Note that we only tune\nthose inserted module with the whole parameter of the pre-trained language\nmodel fixed, thus, making our approach lightweight and flexible for\nlow-resource scenarios and can better transfer knowledge across domains.\nExperimental results show that LightNER can obtain comparable performance in\nthe standard supervised setting and outperform strong baselines in low-resource\nsettings. Code is in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/ner/few-shot.", "published": "2021-08-31 15:01:49", "link": "http://arxiv.org/abs/2109.00720v5", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Maximum F1-score training for end-to-end mispronunciation detection and\n  diagnosis of L2 English speech", "abstract": "End-to-end (E2E) neural models are increasingly attracting attention as a\npromising modeling approach for mispronunciation detection and diagnosis (MDD).\nTypically, these models are trained by optimizing a cross-entropy criterion,\nwhich corresponds to improving the log-likelihood of the training data.\nHowever, there is a discrepancy between the objectives of model training and\nthe MDD evaluation, since the performance of an MDD model is commonly evaluated\nin terms of F1-score instead of phone or word error rate (PER/WER). In view of\nthis, we in this paper explore the use of a discriminative objective function\nfor training E2E MDD models, which aims to maximize the expected F1-score\ndirectly. A series of experiments conducted on the L2-ARCTIC dataset show that\nour proposed method can yield considerable performance improvements in relation\nto some state-of-the-art E2E MDD approaches and the celebrated GOP method.", "published": "2021-08-31 13:19:13", "link": "http://arxiv.org/abs/2108.13816v4", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Neural Sequence-to-Sequence Speech Synthesis Using a Hidden Semi-Markov\n  Model Based Structured Attention Mechanism", "abstract": "This paper proposes a novel Sequence-to-Sequence (Seq2Seq) model integrating\nthe structure of Hidden Semi-Markov Models (HSMMs) into its attention\nmechanism. In speech synthesis, it has been shown that methods based on Seq2Seq\nmodels using deep neural networks can synthesize high quality speech under the\nappropriate conditions. However, several essential problems still have\nremained, i.e., requiring large amounts of training data due to an excessive\ndegree for freedom in alignment (mapping function between two sequences), and\nthe difficulty in handling duration due to the lack of explicit duration\nmodeling. The proposed method defines a generative models to realize the\nsimultaneous optimization of alignments and model parameters based on the\nVariational Auto-Encoder (VAE) framework, and provides monotonic alignments and\nexplicit duration modeling based on the structure of HSMM. The proposed method\ncan be regarded as an integration of Hidden Markov Model (HMM) based speech\nsynthesis and deep learning based speech synthesis using Seq2Seq models,\nincorporating both the benefits. Subjective evaluation experiments showed that\nthe proposed method obtained higher mean opinion scores than Tacotron 2 on\nrelatively small amount of training data.", "published": "2021-08-31 17:12:04", "link": "http://arxiv.org/abs/2108.13985v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Music Demixing Challenge 2021", "abstract": "Music source separation has been intensively studied in the last decade and\ntremendous progress with the advent of deep learning could be observed.\nEvaluation campaigns such as MIREX or SiSEC connected state-of-the-art models\nand corresponding papers, which can help researchers integrate the best\npractices into their models. In recent years, the widely used MUSDB18 dataset\nplayed an important role in measuring the performance of music source\nseparation. While the dataset made a considerable contribution to the\nadvancement of the field, it is also subject to several biases resulting from a\nfocus on Western pop music and a limited number of mixing engineers being\ninvolved. To address these issues, we designed the Music Demixing (MDX)\nChallenge on a crowd-based machine learning competition platform where the task\nis to separate stereo songs into four instrument stems (Vocals, Drums, Bass,\nOther). The main differences compared with the past challenges are 1) the\ncompetition is designed to more easily allow machine learning practitioners\nfrom other disciplines to participate, 2) evaluation is done on a hidden test\nset created by music professionals dedicated exclusively to the challenge to\nassure the transparency of the challenge, i.e., the test set is not accessible\nfrom anyone except the challenge organizers, and 3) the dataset provides a\nwider range of music genres and involved a greater number of mixing engineers.\nIn this paper, we provide the details of the datasets, baselines, evaluation\nmetrics, evaluation results, and technical challenges for future competitions.", "published": "2021-08-31 00:12:48", "link": "http://arxiv.org/abs/2108.13559v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-Supervised Learning Based Domain Adaptation for Robust Speaker\n  Verification", "abstract": "Large performance degradation is often observed for speaker ver-ification\nsystems when applied to a new domain dataset. Givenan unlabeled target-domain\ndataset, unsupervised domain adaptation(UDA) methods, which usually leverage\nadversarial training strate-gies, are commonly used to bridge the performance\ngap caused bythe domain mismatch. However, such adversarial training\nstrategyonly uses the distribution information of target domain data and cannot\nensure the performance improvement on the target domain. Inthis paper, we\nincorporate self-supervised learning strategy to the un-supervised domain\nadaptation system and proposed a self-supervisedlearning based domain\nadaptation approach (SSDA). Compared tothe traditional UDA method, the new SSDA\ntraining strategy canfully leverage the potential label information from target\ndomainand adapt the speaker discrimination ability from source\ndomainsimultaneously. We evaluated the proposed approach on the Vox-Celeb\n(labeled source domain) and CnCeleb (unlabeled target do-main) datasets, and\nthe best SSDA system obtains 10.2% Equal ErrorRate (EER) on the CnCeleb dataset\nwithout using any speaker labelson CnCeleb, which also can achieve the\nstate-of-the-art results onthis corpus.", "published": "2021-08-31 13:55:32", "link": "http://arxiv.org/abs/2108.13843v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adversarial Example Devastation and Detection on Speech Recognition\n  System by Adding Random Noise", "abstract": "An automatic speech recognition (ASR) system based on a deep neural network\nis vulnerable to attack by an adversarial example, especially if the\ncommand-dependent ASR fails. A defense method against adversarial examples is\nproposed to improve the robustness and security of the ASR system. We propose\nan algorithm of devastation and detection on adversarial examples that can\nattack current advanced ASR systems. We choose an advanced text- and\ncommand-dependent ASR system as our target, generating adversarial examples by\nan optimization-based attack on text-dependent ASR and the GA-based algorithm\non command-dependent ASR. The method is based on input transformation of\nadversarial examples. Different random intensities and kinds of noise are added\nto adversarial examples to devastate the perturbation previously added to\nnormal examples. Experimental results show that the method performs well. For\nthe devastation of examples, the original speech similarity after adding noise\ncan reach 99.68%, the similarity of adversarial examples can reach zero, and\nthe detection rate of adversarial examples can reach 94%.", "published": "2021-08-31 00:32:25", "link": "http://arxiv.org/abs/2108.13562v3", "categories": ["cs.SD", "cs.CR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic non-invasive Cough Detection based on Accelerometer and Audio\n  Signals", "abstract": "We present an automatic non-invasive way of detecting cough events based on\nboth accelerometer and audio signals.\n  The acceleration signals are captured by a smartphone firmly attached to the\npatient's bed, using its integrated accelerometer.\n  The audio signals are captured simultaneously by the same smartphone using an\nexternal microphone.\n  We have compiled a manually-annotated dataset containing such\nsimultaneously-captured acceleration and audio signals for approximately 6000\ncough and 68000 non-cough events from 14 adult male patients in a tuberculosis\nclinic.\n  LR, SVM and MLP are evaluated as baseline classifiers and compared with deep\narchitectures such as CNN, LSTM, and Resnet50 using a leave-one-out\ncross-validation scheme.\n  We find that the studied classifiers can use either acceleration or audio\nsignals to distinguish between coughing and other activities including\nsneezing, throat-clearing, and movement on the bed with high accuracy.\n  However, in all cases, the deep neural networks outperform the shallow\nclassifiers by a clear margin and the Resnet50 offers the best performance by\nachieving an AUC exceeding 0.98 and 0.99 for acceleration and audio signals\nrespectively.\n  While audio-based classification consistently offers a better performance\nthan acceleration-based classification, we observe that the difference is very\nsmall for the best systems.\n  Since the acceleration signal requires less processing power, and since the\nneed to record audio is sidestepped and thus privacy is inherently secured, and\nsince the recording device is attached to the bed and not worn, an\naccelerometer-based highly accurate non-invasive cough detector may represent a\nmore convenient and readily accepted method in long-term cough monitoring.", "published": "2021-08-31 22:44:56", "link": "http://arxiv.org/abs/2109.00103v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
