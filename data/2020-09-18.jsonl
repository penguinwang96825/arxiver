{"title": "Unsupervised Parallel Corpus Mining on Web Data", "abstract": "With a large amount of parallel data, neural machine translation systems are\nable to deliver human-level performance for sentence-level translation.\nHowever, it is costly to label a large amount of parallel data by humans. In\ncontrast, there is a large-scale of parallel corpus created by humans on the\nInternet. The major difficulty to utilize them is how to filter them out from\nthe noise website environments. Current parallel data mining methods all\nrequire labeled parallel data as the training source. In this paper, we present\na pipeline to mine the parallel corpus from the Internet in an unsupervised\nmanner. On the widely used WMT'14 English-French and WMT'16 English-German\nbenchmarks, the machine translator trained with the data extracted by our\npipeline achieves very close performance to the supervised results. On the\nWMT'16 English-Romanian and Romanian-English benchmarks, our system produces\nnew state-of-the-art results, 39.81 and 38.95 BLEU scores, even compared with\nsupervised approaches.", "published": "2020-09-18 02:38:01", "link": "http://arxiv.org/abs/2009.08595v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "fastHan: A BERT-based Multi-Task Toolkit for Chinese NLP", "abstract": "We present fastHan, an open-source toolkit for four basic tasks in Chinese\nnatural language processing: Chinese word segmentation (CWS), Part-of-Speech\n(POS) tagging, named entity recognition (NER), and dependency parsing. The\nbackbone of fastHan is a multi-task model based on a pruned BERT, which uses\nthe first 8 layers in BERT. We also provide a 4-layer base model compressed\nfrom the 8-layer model. The joint-model is trained and evaluated on 13 corpora\nof four tasks, yielding near state-of-the-art (SOTA) performance in dependency\nparsing and NER, achieving SOTA performance in CWS and POS. Besides, fastHan's\ntransferability is also strong, performing much better than popular\nsegmentation tools on a non-training corpus. To better meet the need of\npractical application, we allow users to use their own labeled data to further\nfine-tune fastHan. In addition to its small size and excellent performance,\nfastHan is user-friendly. Implemented as a python package, fastHan isolates\nusers from the internal technical details and is convenient to use. The project\nis released on Github.", "published": "2020-09-18 05:41:52", "link": "http://arxiv.org/abs/2009.08633v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical GPT with Congruent Transformers for Multi-Sentence Language\n  Models", "abstract": "We report a GPT-based multi-sentence language model for dialogue generation\nand document understanding. First, we propose a hierarchical GPT which consists\nof three blocks, i.e., a sentence encoding block, a sentence generating block,\nand a sentence decoding block. The sentence encoding and decoding blocks are\nbasically the encoder-decoder blocks of the standard Transformers, which work\non each sentence independently. The sentence generating block is inserted\nbetween the encoding and decoding blocks, and generates the next sentence\nembedding vector from the previous sentence embedding vectors. We believe it is\nthe way human make conversation and understand paragraphs and documents. Since\neach sentence may consist of fewer words, the sentence encoding and decoding\nTransformers can use much smaller dimensional embedding vectors. Secondly, we\nnote the attention in the Transformers utilizes the inner-product similarity\nmeasure. Therefore, to compare the two vectors in the same space, we set the\ntransform matrices for queries and keys to be the same. Otherwise, the\nsimilarity concept is incongruent. We report experimental results to show that\nthese two modifications increase the language model performance for tasks with\nmultiple sentences.", "published": "2020-09-18 05:55:37", "link": "http://arxiv.org/abs/2009.08636v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The birth of Romanian BERT", "abstract": "Large-scale pretrained language models have become ubiquitous in Natural\nLanguage Processing. However, most of these models are available either in\nhigh-resource languages, in particular English, or as multilingual models that\ncompromise performance on individual languages for coverage. This paper\nintroduces Romanian BERT, the first purely Romanian transformer-based language\nmodel, pretrained on a large text corpus. We discuss corpus composition and\ncleaning, the model training process, as well as an extensive evaluation of the\nmodel on various Romanian datasets. We open source not only the model itself,\nbut also a repository that contains information on how to obtain the corpus,\nfine-tune and use this model in production (with practical examples), and how\nto fully replicate the evaluation process.", "published": "2020-09-18 09:30:48", "link": "http://arxiv.org/abs/2009.08712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FarsTail: A Persian Natural Language Inference Dataset", "abstract": "Natural language inference (NLI) is known as one of the central tasks in\nnatural language processing (NLP) which encapsulates many fundamental aspects\nof language understanding. With the considerable achievements of data-hungry\ndeep learning methods in NLP tasks, a great amount of effort has been devoted\nto develop more diverse datasets for different languages. In this paper, we\npresent a new dataset for the NLI task in the Persian language, also known as\nFarsi, which is one of the dominant languages in the Middle East. This dataset,\nnamed FarsTail, includes 10,367 samples which are provided in both the Persian\nlanguage as well as the indexed format to be useful for non-Persian\nresearchers. The samples are generated from 3,539 multiple-choice questions\nwith the least amount of annotator interventions in a way similar to the\nSciTail dataset. A carefully designed multi-step process is adopted to ensure\nthe quality of the dataset. We also present the results of traditional and\nstate-of-the-art methods on FarsTail including different embedding methods such\nas word2vec, fastText, ELMo, BERT, and LASER, as well as different modeling\napproaches such as DecompAtt, ESIM, HBMP, and ULMFiT to provide a solid\nbaseline for the future research. The best obtained test accuracy is 83.38%\nwhich shows that there is a big room for improving the current methods to be\nuseful for real-world NLP applications in different languages. We also\ninvestigate the extent to which the models exploit superficial clues, also\nknown as dataset biases, in FarsTail, and partition the test set into easy and\nhard subsets according to the success of biased models. The dataset is\navailable at https://github.com/dml-qom/FarsTail", "published": "2020-09-18 13:04:04", "link": "http://arxiv.org/abs/2009.08820v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Presenting Simultaneous Translation in Limited Space", "abstract": "Some methods of automatic simultaneous translation of a long-form speech\nallow revisions of outputs, trading accuracy for low latency. Deploying these\nsystems for users faces the problem of presenting subtitles in a limited space,\nsuch as two lines on a television screen. The subtitles must be shown promptly,\nincrementally, and with adequate time for reading. We provide an algorithm for\nsubtitling. Furthermore, we propose a way how to estimate the overall usability\nof the combination of automatic translation and subtitling by measuring the\nquality, latency, and stability on a test set, and propose an improved measure\nfor translation latency.", "published": "2020-09-18 18:37:03", "link": "http://arxiv.org/abs/2009.09016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COMET: A Neural Framework for MT Evaluation", "abstract": "We present COMET, a neural framework for training multilingual machine\ntranslation evaluation models which obtains new state-of-the-art levels of\ncorrelation with human judgements. Our framework leverages recent breakthroughs\nin cross-lingual pretrained language modeling resulting in highly multilingual\nand adaptable MT evaluation models that exploit information from both the\nsource input and a target-language reference translation in order to more\naccurately predict MT quality. To showcase our framework, we train three models\nwith different types of human judgements: Direct Assessments, Human-mediated\nTranslation Edit Rate and Multidimensional Quality Metrics. Our models achieve\nnew state-of-the-art performance on the WMT 2019 Metrics shared task and\ndemonstrate robustness to high-performing systems.", "published": "2020-09-18 18:54:15", "link": "http://arxiv.org/abs/2009.09025v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tradeoffs in Sentence Selection Techniques for Open-Domain Question\n  Answering", "abstract": "Current methods in open-domain question answering (QA) usually employ a\npipeline of first retrieving relevant documents, then applying strong reading\ncomprehension (RC) models to that retrieved text. However, modern RC models are\ncomplex and expensive to run, so techniques to prune the space of retrieved\ntext are critical to allow this approach to scale. In this paper, we focus on\napproaches which apply an intermediate sentence selection step to address this\nissue, and investigate the best practices for this approach. We describe two\ngroups of models for sentence selection: QA-based approaches, which run a\nfull-fledged QA system to identify answer candidates, and retrieval-based\nmodels, which find parts of each passage specifically related to each question.\nWe examine trade-offs between processing speed and task performance in these\ntwo approaches, and demonstrate an ensemble module that represents a hybrid of\nthe two. From experiments on Open-SQuAD and TriviaQA, we show that very\nlightweight QA models can do well at this task, but retrieval-based models are\nfaster still. An ensemble module we describe balances between the two and\ngeneralizes well cross-domain.", "published": "2020-09-18 23:39:15", "link": "http://arxiv.org/abs/2009.09120v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MUTANT: A Training Paradigm for Out-of-Distribution Generalization in\n  Visual Question Answering", "abstract": "While progress has been made on the visual question answering leaderboards,\nmodels often utilize spurious correlations and priors in datasets under the\ni.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples\nhas emerged as a proxy for generalization. In this paper, we present MUTANT, a\ntraining paradigm that exposes the model to perceptually similar, yet\nsemantically distinct mutations of the input, to improve OOD generalization,\nsuch as the VQA-CP challenge. Under this paradigm, models utilize a\nconsistency-constrained training objective to understand the effect of semantic\nchanges in input (question-image pair) on the output (answer). Unlike existing\nmethods on VQA-CP, MUTANT does not rely on the knowledge about the nature of\ntrain and test answer distributions. MUTANT establishes a new state-of-the-art\naccuracy on VQA-CP with a $10.57\\%$ improvement. Our work opens up avenues for\nthe use of semantic input mutations for OOD generalization in question\nanswering.", "published": "2020-09-18 00:22:54", "link": "http://arxiv.org/abs/2009.08566v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "NEU at WNUT-2020 Task 2: Data Augmentation To Tell BERT That Death Is\n  Not Necessarily Informative", "abstract": "Millions of people around the world are sharing COVID-19 related information\non social media platforms. Since not all the information shared on the social\nmedia is useful, a machine learning system to identify informative posts can\nhelp users in finding relevant information. In this paper, we present a BERT\nclassifier system for W-NUT2020 Shared Task 2: Identification of Informative\nCOVID-19 English Tweets. Further, we show that BERT exploits some easy signals\nto identify informative tweets, and adding simple patterns to uninformative\ntweets drastically degrades BERT performance. In particular, simply adding 10\ndeaths to tweets in dev set, reduces BERT F1- score from 92.63 to 7.28. We also\npropose a simple data augmentation technique that helps in improving the\nrobustness and generalization ability of the BERT classifier.", "published": "2020-09-18 02:16:49", "link": "http://arxiv.org/abs/2009.08590v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards Full-line Code Completion with Neural Language Models", "abstract": "A code completion system suggests future code elements to developers given a\npartially-complete code snippet. Code completion is one of the most useful\nfeatures in Integrated Development Environments (IDEs). Currently, most code\ncompletion techniques predict a single token at a time. In this paper, we take\na further step and discuss the probability of directly completing a whole line\nof code instead of a single token. We believe suggesting longer code sequences\ncan further improve the efficiency of developers. Recently neural language\nmodels have been adopted as a preferred approach for code completion, and we\nbelieve these models can still be applied to full-line code completion with a\nfew improvements. We conduct our experiments on two real-world python corpora\nand evaluate existing neural models based on source code tokens or syntactical\nactions. The results show that neural language models can achieve acceptable\nresults on our tasks, with significant room for improvements.", "published": "2020-09-18 03:12:13", "link": "http://arxiv.org/abs/2009.08603v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "RECON: Relation Extraction using Knowledge Graph Context in a Graph\n  Neural Network", "abstract": "In this paper, we present a novel method named RECON, that automatically\nidentifies relations in a sentence (sentential relation extraction) and aligns\nto a knowledge graph (KG). RECON uses a graph neural network to learn\nrepresentations of both the sentence as well as facts stored in a KG, improving\nthe overall extraction quality. These facts, including entity attributes\n(label, alias, description, instance-of) and factual triples, have not been\ncollectively used in the state of the art methods. We evaluate the effect of\nvarious forms of representing the KG context on the performance of RECON. The\nempirical evaluation on two standard relation extraction datasets shows that\nRECON significantly outperforms all state of the art methods on NYT Freebase\nand Wikidata datasets. RECON reports 87.23 F1 score (Vs 82.29 baseline) on\nWikidata dataset whereas on NYT Freebase, reported values are 87.5(P@10) and\n74.1(P@30) compared to the previous baseline scores of 81.3(P@10) and\n63.1(P@30).", "published": "2020-09-18 09:02:31", "link": "http://arxiv.org/abs/2009.08694v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Principal Components of the Meaning", "abstract": "In this paper we argue that (lexical) meaning in science can be represented\nin a 13 dimension Meaning Space. This space is constructed using principal\ncomponent analysis (singular decomposition) on the matrix of word category\nrelative information gains, where the categories are those used by the Web of\nScience, and the words are taken from a reduced word set from texts in the Web\nof Science. We show that this reduced word set plausibly represents all texts\nin the corpus, so that the principal component analysis has some objective\nmeaning with respect to the corpus. We argue that 13 dimensions is adequate to\ndescribe the meaning of scientific texts, and hypothesise about the qualitative\nmeaning of the principal components.", "published": "2020-09-18 14:28:32", "link": "http://arxiv.org/abs/2009.08859v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Image Captioning with Attention for Smart Local Tourism using\n  EfficientNet", "abstract": "Smart systems have been massively developed to help humans in various tasks.\nDeep Learning technologies push even further in creating accurate assistant\nsystems due to the explosion of data lakes. One of the smart system tasks is to\ndisseminate users needed information. This is crucial in the tourism sector to\npromote local tourism destinations. In this research, we design a model of\nlocal tourism specific image captioning, which later will support the\ndevelopment of AI-powered systems that assist various users. The model is\ndeveloped using a visual Attention mechanism and uses the state-of-the-art\nfeature extractor architecture EfficientNet. A local tourism dataset is\ncollected and is used in the research, along with two different kinds of\ncaptions. Captions that describe the image literally and captions that\nrepresent human logical responses when seeing the image. This is done to make\nthe captioning model more humane when implemented in the assistance system. We\ncompared the performance of two different models using EfficientNet\narchitectures (B0 and B4) with other well known VGG16 and InceptionV3. The best\nBLEU scores we get are 73.39 and 24.51 for the training set and the validation\nset respectively, using EfficientNetB0. The captioning result using the\ndeveloped model shows that the model can produce logical caption for local\ntourism-related images", "published": "2020-09-18 15:47:25", "link": "http://arxiv.org/abs/2009.08899v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generating similes effortlessly like a Pro: A Style Transfer Approach\n  for Simile Generation", "abstract": "Literary tropes, from poetry to stories, are at the crux of human imagination\nand communication. Figurative language such as a simile go beyond plain\nexpressions to give readers new insights and inspirations. In this paper, we\ntackle the problem of simile generation. Generating a simile requires proper\nunderstanding for effective mapping of properties between two concepts. To this\nend, we first propose a method to automatically construct a parallel corpus by\ntransforming a large number of similes collected from Reddit to their literal\ncounterpart using structured common sense knowledge. We then propose to\nfine-tune a pretrained sequence to sequence model, BART~\\cite{lewis2019bart},\non the literal-simile pairs to gain generalizability, so that we can generate\nnovel similes given a literal sentence. Experiments show that our approach\ngenerates $88\\%$ novel similes that do not share properties with the training\ndata. Human evaluation on an independent set of literal statements shows that\nour model generates similes better than two literary experts\n\\textit{37\\%}\\footnote{We average 32.6\\% and 41.3\\% for 2 humans.} of the\ntimes, and three baseline systems including a recent metaphor generation model\n\\textit{71\\%}\\footnote{We average 82\\% ,63\\% and 68\\% for three baselines.} of\nthe times when compared pairwise.\\footnote{The simile in the title is generated\nby our best model. Input: Generating similes effortlessly, output: Generating\nsimiles \\textit{like a Pro}.} We also show how replacing literal sentences with\nsimiles from our best model in machine generated stories improves evocativeness\nand leads to better acceptance by human judges.", "published": "2020-09-18 17:37:13", "link": "http://arxiv.org/abs/2009.08942v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple and Effective Self-Supervised Contrastive Learning Framework\n  for Aspect Detection", "abstract": "Unsupervised aspect detection (UAD) aims at automatically extracting\ninterpretable aspects and identifying aspect-specific segments (such as\nsentences) from online reviews. However, recent deep learning-based topic\nmodels, specifically aspect-based autoencoder, suffer from several problems,\nsuch as extracting noisy aspects and poorly mapping aspects discovered by\nmodels to the aspects of interest. To tackle these challenges, in this paper,\nwe first propose a self-supervised contrastive learning framework and an\nattention-based model equipped with a novel smooth self-attention (SSA) module\nfor the UAD task in order to learn better representations for aspects and\nreview segments. Secondly, we introduce a high-resolution selective mapping\n(HRSMap) method to efficiently assign aspects discovered by the model to\naspects of interest. We also propose using a knowledge distilling technique to\nfurther improve the aspect detection performance. Our methods outperform\nseveral recent unsupervised and weakly supervised approaches on publicly\navailable benchmark user review datasets. Aspect interpretation results show\nthat extracted aspects are meaningful, have good coverage, and can be easily\nmapped to aspects of interest. Ablation studies and attention weight\nvisualization also demonstrate the effectiveness of SSA and the knowledge\ndistilling method.", "published": "2020-09-18 22:13:49", "link": "http://arxiv.org/abs/2009.09107v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "An Interpretable and Uncertainty Aware Multi-Task Framework for\n  Multi-Aspect Sentiment Analysis", "abstract": "In recent years, several online platforms have seen a rapid increase in the\nnumber of review systems that request users to provide aspect-level feedback.\nDocument-level Multi-aspect Sentiment Classification (DMSC), where the goal is\nto predict the ratings/sentiment from a review at an individual aspect level,\nhas become a challenging and imminent problem. To tackle this challenge, we\npropose a deliberate self-attention-based deep neural network model, namely\nFEDAR, for the DMSC problem, which can achieve competitive performance while\nalso being able to interpret the predictions made. FEDAR is equipped with a\nhighway word embedding layer to transfer knowledge from pre-trained word\nembeddings, an RNN encoder layer with output features enriched by pooling and\nfactorization techniques, and a deliberate self-attention layer. In addition,\nwe also propose an Attention-driven Keywords Ranking (AKR) method, which can\nautomatically discover aspect keywords and aspect-level opinion keywords from\nthe review corpus based on the attention weights. These keywords are\nsignificant for rating predictions by FEDAR. Since crowdsourcing annotation can\nbe an alternate way to recover missing ratings of reviews, we propose a\nLEcture-AuDience (LEAD) strategy to estimate model uncertainty in the context\nof multi-task learning, so that valuable human resources can focus on the most\nuncertain predictions. Our extensive set of experiments on five different\nopen-domain DMSC datasets demonstrate the superiority of the proposed FEDAR and\nLEAD models. We further introduce two new DMSC datasets in the healthcare\ndomain and benchmark different baseline models and our models on them.\nAttention weights visualization results and visualization of aspect and opinion\nkeywords demonstrate the interpretability of our model and the effectiveness of\nour AKR method.", "published": "2020-09-18 22:32:39", "link": "http://arxiv.org/abs/2009.09112v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Will it Unblend?", "abstract": "Natural language processing systems often struggle with out-of-vocabulary\n(OOV) terms, which do not appear in training data. Blends, such as\n\"innoventor\", are one particularly challenging class of OOV, as they are formed\nby fusing together two or more bases that relate to the intended meaning in\nunpredictable manners and degrees. In this work, we run experiments on a novel\ndataset of English OOV blends to quantify the difficulty of interpreting the\nmeanings of blends by large-scale contextual language models such as BERT. We\nfirst show that BERT's processing of these blends does not fully access the\ncomponent meanings, leaving their contextual representations semantically\nimpoverished. We find this is mostly due to the loss of characters resulting\nfrom blend formation. Then, we assess how easily different models can recognize\nthe structure and recover the origin of blends, and find that context-aware\nembedding systems outperform character-level and context-free embeddings,\nalthough their results are still far from satisfactory.", "published": "2020-09-18 23:59:15", "link": "http://arxiv.org/abs/2009.09123v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting\n  Local Structures", "abstract": "Understanding a medical conversation between a patient and a physician poses\na unique natural language understanding challenge since it combines elements of\nstandard open ended conversation with very domain specific elements that\nrequire expertise and medical knowledge. Summarization of medical conversations\nis a particularly important aspect of medical conversation understanding since\nit addresses a very real need in medical practice: capturing the most important\naspects of a medical encounter so that they can be used for medical decision\nmaking and subsequent follow ups.\n  In this paper we present a novel approach to medical conversation\nsummarization that leverages the unique and independent local structures\ncreated when gathering a patient's medical history. Our approach is a variation\nof the pointer generator network where we introduce a penalty on the generator\ndistribution, and we explicitly model negations. The model also captures\nimportant properties of medical conversations such as medical knowledge coming\nfrom standardized medical ontologies better than when those concepts are\nintroduced explicitly. Through evaluation by doctors, we show that our approach\nis preferred on twice the number of summaries to the baseline pointer generator\nmodel and captures most or all of the information in 80% of the conversations\nmaking it a realistic alternative to costly manual summarization by medical\nexperts.", "published": "2020-09-18 07:35:44", "link": "http://arxiv.org/abs/2009.08666v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Looking Beyond Sentence-Level Natural Language Inference for Downstream\n  Tasks", "abstract": "In recent years, the Natural Language Inference (NLI) task has garnered\nsignificant attention, with new datasets and models achieving near human-level\nperformance on it. However, the full promise of NLI -- particularly that it\nlearns knowledge that should be generalizable to other downstream NLP tasks --\nhas not been realized. In this paper, we study this unfulfilled promise from\nthe lens of two downstream tasks: question answering (QA), and text\nsummarization. We conjecture that a key difference between the NLI datasets and\nthese downstream tasks concerns the length of the premise; and that creating\nnew long premise NLI datasets out of existing QA datasets is a promising avenue\nfor training a truly generalizable NLI model. We validate our conjecture by\nshowing competitive results on the task of QA and obtaining the best reported\nresults on the task of Checking Factual Correctness of Summaries.", "published": "2020-09-18 21:44:35", "link": "http://arxiv.org/abs/2009.09099v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "X-DC: Explainable Deep Clustering based on Learnable Spectrogram\n  Templates", "abstract": "Deep neural networks (DNNs) have achieved substantial predictive performance\nin various speech processing tasks. Particularly, it has been shown that a\nmonaural speech separation task can be successfully solved with a DNN-based\nmethod called deep clustering (DC), which uses a DNN to describe the process of\nassigning a continuous vector to each time-frequency (TF) bin and measure how\nlikely each pair of TF bins is to be dominated by the same speaker. In DC, the\nDNN is trained so that the embedding vectors for the TF bins dominated by the\nsame speaker are forced to get close to each other. One concern regarding DC is\nthat the embedding process described by a DNN has a black-box structure, which\nis usually very hard to interpret. The potential weakness owing to the\nnon-interpretable black-box structure is that it lacks the flexibility of\naddressing the mismatch between training and test conditions (caused by\nreverberation, for instance). To overcome this limitation, in this paper, we\npropose the concept of explainable deep clustering (X-DC), whose network\narchitecture can be interpreted as a process of fitting learnable spectrogram\ntemplates to an input spectrogram followed by Wiener filtering. During\ntraining, the elements of the spectrogram templates and their activations are\nconstrained to be non-negative, which facilitates the sparsity of their values\nand thus improves interpretability. The main advantage of this framework is\nthat it naturally allows us to incorporate a model adaptation mechanism into\nthe network thanks to its physically interpretable structure. We experimentally\nshow that the proposed X-DC enables us to visualize and understand the clues\nfor the model to determine the embedding vectors while achieving speech\nseparation performance comparable to that of the original DC models.", "published": "2020-09-18 07:26:52", "link": "http://arxiv.org/abs/2009.08661v3", "categories": ["eess.AS", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Optimizing Speech Emotion Recognition using Manta-Ray Based Feature\n  Selection", "abstract": "Emotion recognition from audio signals has been regarded as a challenging\ntask in signal processing as it can be considered as a collection of static and\ndynamic classification tasks. Recognition of emotions from speech data has been\nheavily relied upon end-to-end feature extraction and classification using\nmachine learning models, though the absence of feature selection and\noptimization have restrained the performance of these methods. Recent studies\nhave shown that Mel Frequency Cepstral Coefficients (MFCC) have been emerged as\none of the most relied feature extraction methods, though it circumscribes the\naccuracy of classification with a very small feature dimension. In this paper,\nwe propose that the concatenation of features, extracted by using different\nexisting feature extraction methods can not only boost the classification\naccuracy but also expands the possibility of efficient feature selection. We\nhave used Linear Predictive Coding (LPC) apart from the MFCC feature extraction\nmethod, before feature merging. Besides, we have performed a novel application\nof Manta Ray optimization in speech emotion recognition tasks that resulted in\na state-of-the-art result in this field. We have evaluated the performance of\nour model using SAVEE and Emo-DB, two publicly available datasets. Our proposed\nmethod outperformed all the existing methods in speech emotion analysis and\nresulted in a decent result in these two datasets with a classification\naccuracy of 97.06% and 97.68% respectively.", "published": "2020-09-18 16:09:34", "link": "http://arxiv.org/abs/2009.08909v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
