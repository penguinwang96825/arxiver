{"title": "Sentiment Analysis at SEPLN (TASS)-2019: Sentiment Analysis at Tweet\n  level using Deep Learning", "abstract": "This paper describes the system submitted to \"Sentiment Analysis at SEPLN\n(TASS)-2019\" shared task. The task includes sentiment analysis of Spanish\ntweets, where the tweets are in different dialects spoken in Spain, Peru, Costa\nRica, Uruguay and Mexico. The tweets are short (up to 240 characters) and the\nlanguage is informal, i.e., it contains misspellings, emojis, onomatopeias etc.\nSentiment analysis includes classification of the tweets into 4 classes, viz.,\nPositive, Negative, Neutral and None. For preparing the proposed system, we use\nDeep Learning networks like LSTMs.", "published": "2019-08-01 10:52:26", "link": "http://arxiv.org/abs/1908.00321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JUCBNMT at WMT2018 News Translation Task: Character Based Neural Machine\n  Translation of Finnish to English", "abstract": "In the current work, we present a description of the system submitted to WMT\n2018 News Translation Shared task. The system was created to translate news\ntext from Finnish to English. The system used a Character Based Neural Machine\nTranslation model to accomplish the given task. The current paper documents the\npreprocessing steps, the description of the submitted system and the results\nproduced using the same. Our system garnered a BLEU score of 12.9.", "published": "2019-08-01 10:57:31", "link": "http://arxiv.org/abs/1908.00323v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visualizing RNN States with Predictive Semantic Encodings", "abstract": "Recurrent Neural Networks are an effective and prevalent tool used to model\nsequential data such as natural language text. However, their deep nature and\nmassive number of parameters pose a challenge for those intending to study\nprecisely how they work. We present a visual technique that gives a high level\nintuition behind the semantics of the hidden states within Recurrent Neural\nNetworks. This semantic encoding allows for hidden states to be compared\nthroughout the model independent of their internal details. The proposed\ntechnique is displayed in a proof of concept visualization tool which is\ndemonstrated to visualize the natural language processing task of language\nmodelling.", "published": "2019-08-01 19:24:59", "link": "http://arxiv.org/abs/1908.00588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JUMT at WMT2019 News Translation Task: A Hybrid approach to Machine\n  Translation for Lithuanian to English", "abstract": "In the current work, we present a description of the system submitted to WMT\n2019 News Translation Shared task. The system was created to translate news\ntext from Lithuanian to English. To accomplish the given task, our system used\na Word Embedding based Neural Machine Translation model to post edit the\noutputs generated by a Statistical Machine Translation model. The current paper\ndocuments the architecture of our model, descriptions of the various modules\nand the results produced using the same. Our system garnered a BLEU score of\n17.6.", "published": "2019-08-01 11:03:51", "link": "http://arxiv.org/abs/1908.01349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media", "abstract": "Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools.", "published": "2019-08-01 00:28:57", "link": "http://arxiv.org/abs/1908.00153v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Convolutional Auto-encoding of Sentence Topics for Image Paragraph\n  Generation", "abstract": "Image paragraph generation is the task of producing a coherent story (usually\na paragraph) that describes the visual content of an image. The problem\nnevertheless is not trivial especially when there are multiple descriptive and\ndiverse gists to be considered for paragraph generation, which often happens in\nreal images. A valid question is how to encapsulate such gists/topics that are\nworthy of mention from an image, and then describe the image from one topic to\nanother but holistically with a coherent structure. In this paper, we present a\nnew design --- Convolutional Auto-Encoding (CAE) that purely employs\nconvolutional and deconvolutional auto-encoding framework for topic modeling on\nthe region-level features of an image. Furthermore, we propose an architecture,\nnamely CAE plus Long Short-Term Memory (dubbed as CAE-LSTM), that novelly\nintegrates the learnt topics in support of paragraph generation. Technically,\nCAE-LSTM capitalizes on a two-level LSTM-based paragraph generation framework\nwith attention mechanism. The paragraph-level LSTM captures the inter-sentence\ndependency in a paragraph, while sentence-level LSTM is to generate one\nsentence which is conditioned on each learnt topic. Extensive experiments are\nconducted on Stanford image paragraph dataset, and superior results are\nreported when comparing to state-of-the-art approaches. More remarkably,\nCAE-LSTM increases CIDEr performance from 20.93% to 25.15%.", "published": "2019-08-01 07:58:50", "link": "http://arxiv.org/abs/1908.00249v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Simple and Effective Text Matching with Richer Alignment Features", "abstract": "In this paper, we present a fast and strong neural approach for general\npurpose text matching applications. We explore what is sufficient to build a\nfast and well-performed text matching model and propose to keep three key\nfeatures available for inter-sequence alignment: original point-wise features,\nprevious aligned features, and contextual features while simplifying all the\nremaining components. We conduct experiments on four well-studied benchmark\ndatasets across tasks of natural language inference, paraphrase identification\nand answer selection. The performance of our model is on par with the\nstate-of-the-art on all datasets with much fewer parameters and the inference\nspeed is at least 6 times faster compared with similarly performed ones.", "published": "2019-08-01 10:07:07", "link": "http://arxiv.org/abs/1908.00300v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MSnet: A BERT-based Network for Gendered Pronoun Resolution", "abstract": "The pre-trained BERT model achieves a remarkable state of the art across a\nwide range of tasks in natural language processing. For solving the gender bias\nin gendered pronoun resolution task, I propose a novel neural network model\nbased on the pre-trained BERT. This model is a type of mention score classifier\nand uses an attention mechanism with no parameters to compute the contextual\nrepresentation of entity span, and a vector to represent the triple-wise\nsemantic similarity among the pronoun and the entities. In stage 1 of the\ngendered pronoun resolution task, a variant of this model, trained in the\nfine-tuning approach, reduced the multi-class logarithmic loss to 0.3033 in the\n5-fold cross-validation of training set and 0.2795 in testing set. Besides,\nthis variant won the 2nd place with a score at 0.17289 in stage 2 of the task.\nThe code in this paper is available at:\nhttps://github.com/ziliwang/MSnet-for-Gendered-PronounResolution", "published": "2019-08-01 10:27:29", "link": "http://arxiv.org/abs/1908.00308v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dolphin: A Spoken Language Proficiency Assessment System for Elementary\n  Education", "abstract": "Spoken language proficiency is critically important for children's growth and\npersonal development. Due to the limited and imbalanced educational resources\nin China, elementary students barely have chances to improve their oral\nlanguage skills in classes. Verbal fluency tasks (VFTs) were invented to let\nthe students practice their spoken language proficiency after school. VFTs are\nsimple but concrete math related questions that ask students to not only report\nanswers but speak out the entire thinking process. In spite of the great\nsuccess of VFTs, they bring a heavy grading burden to elementary teachers. To\nalleviate this problem, we develop Dolphin, a spoken language proficiency\nassessment system for Chinese elementary education. Dolphin is able to\nautomatically evaluate both phonological fluency and semantic relevance of\nstudents' VFT answers. We conduct a wide range of offline and online\nexperiments to demonstrate the effectiveness of Dolphin. In our offline\nexperiments, we show that Dolphin improves both phonological fluency and\nsemantic relevance evaluation performance when compared to state-of-the-art\nbaselines on real-world educational data sets. In our online A/B experiments,\nwe test Dolphin with 183 teachers from 2 major cities (Hangzhou and Xi'an) in\nChina for 10 weeks and the results show that VFT assignments grading coverage\nis improved by 22\\%.", "published": "2019-08-01 12:31:49", "link": "http://arxiv.org/abs/1908.00358v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tree-Transformer: A Transformer-Based Method for Correction of\n  Tree-Structured Data", "abstract": "Many common sequential data sources, such as source code and natural\nlanguage, have a natural tree-structured representation. These trees can be\ngenerated by fitting a sequence to a grammar, yielding a hierarchical ordering\nof the tokens in the sequence. This structure encodes a high degree of\nsyntactic information, making it ideal for problems such as grammar correction.\nHowever, little work has been done to develop neural networks that can operate\non and exploit tree-structured data. In this paper we present the\nTree-Transformer \\textemdash{} a novel neural network architecture designed to\ntranslate between arbitrary input and output trees. We applied this\narchitecture to correction tasks in both the source code and natural language\ndomains. On source code, our model achieved an improvement of $25\\%$\n$\\text{F}0.5$ over the best sequential method. On natural language, we achieved\ncomparable results to the most complex state of the art systems, obtaining a\n$10\\%$ improvement in recall on the CoNLL 2014 benchmark and the highest to\ndate $\\text{F}0.5$ score on the AESW benchmark of $50.43$.", "published": "2019-08-01 15:05:41", "link": "http://arxiv.org/abs/1908.00449v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Semantic Concept Spaces: Guided Topic Model Refinement using\n  Word-Embedding Projections", "abstract": "We present a framework that allows users to incorporate the semantics of\ntheir domain knowledge for topic model refinement while remaining\nmodel-agnostic. Our approach enables users to (1) understand the semantic space\nof the model, (2) identify regions of potential conflicts and problems, and (3)\nreadjust the semantic relation of concepts based on their understanding,\ndirectly influencing the topic modeling. These tasks are supported by an\ninteractive visual analytics workspace that uses word-embedding projections to\ndefine concept regions which can then be refined. The user-refined concepts are\nindependent of a particular document collection and can be transferred to\nrelated corpora. All user interactions within the concept space directly affect\nthe semantic relations of the underlying vector space model, which, in turn,\nchange the topic modeling. In addition to direct manipulation, our system\nguides the users' decision-making process through recommended interactions that\npoint out potential improvements. This targeted refinement aims at minimizing\nthe feedback required for an efficient human-in-the-loop process. We confirm\nthe improvements achieved through our approach in two user studies that show\ntopic model quality improvements through our visual knowledge externalization\nand learning process.", "published": "2019-08-01 16:02:04", "link": "http://arxiv.org/abs/1908.00475v1", "categories": ["cs.HC", "cs.CL", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Reinforcement Learning for Personalized Dialogue Management", "abstract": "Language systems have been of great interest to the research community and\nhave recently reached the mass market through various assistant platforms on\nthe web. Reinforcement Learning methods that optimize dialogue policies have\nseen successes in past years and have recently been extended into methods that\npersonalize the dialogue, e.g. take the personal context of users into account.\nThese works, however, are limited to personalization to a single user with whom\nthey require multiple interactions and do not generalize the usage of context\nacross users. This work introduces a problem where a generalized usage of\ncontext is relevant and proposes two Reinforcement Learning (RL)-based\napproaches to this problem. The first approach uses a single learner and\nextends the traditional POMDP formulation of dialogue state with features that\ndescribe the user context. The second approach segments users by context and\nthen employs a learner per context. We compare these approaches in a benchmark\nof existing non-RL and RL-based methods in three established and one novel\napplication domain of financial product recommendation. We compare the\ninfluence of context and training experiences on performance and find that\nlearning approaches generally outperform a handcrafted gold standard.", "published": "2019-08-01 09:19:27", "link": "http://arxiv.org/abs/1908.00286v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Joint Acoustic-Phonetic Word Embeddings", "abstract": "Most speech recognition tasks pertain to mapping words across two modalities:\nacoustic and orthographic. In this work, we suggest learning encoders that map\nvariable-length, acoustic or phonetic, sequences that represent words into\nfixed-dimensional vectors in a shared latent space; such that the distance\nbetween two word vectors represents how closely the two words sound. Instead of\ndirectly learning the distances between word vectors, we employ weak\nsupervision and model a binary classification task to predict whether two\ninputs, one of each modality, represent the same word given a distance\nthreshold. We explore various deep-learning models, bimodal contrastive losses,\nand techniques for mining hard negative examples such as the semi-supervised\ntechnique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for\nthe binary classification task.", "published": "2019-08-01 16:42:47", "link": "http://arxiv.org/abs/1908.00493v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Contrastive Reasons Detection and Clustering from Online Polarized\n  Debate", "abstract": "This work tackles the problem of unsupervised modeling and extraction of the\nmain contrastive sentential reasons conveyed by divergent viewpoints on\npolarized issues. It proposes a pipeline approach centered around the detection\nand clustering of phrases, assimilated to argument facets using a novel Phrase\nAuthor Interaction Topic-Viewpoint model. The evaluation is based on the\ninformativeness, the relevance and the clustering accuracy of extracted\nreasons. The pipeline approach shows a significant improvement over\nstate-of-the-art methods in contrastive summarization on online debate\ndatasets.", "published": "2019-08-01 22:42:36", "link": "http://arxiv.org/abs/1908.00648v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Interactive Learning for Identifying Relevant Tweets to Support\n  Real-time Situational Awareness", "abstract": "Various domain users are increasingly leveraging real-time social media data\nto gain rapid situational awareness. However, due to the high noise in the\ndeluge of data, effectively determining semantically relevant information can\nbe difficult, further complicated by the changing definition of relevancy by\neach end user for different events. The majority of existing methods for short\ntext relevance classification fail to incorporate users' knowledge into the\nclassification process. Existing methods that incorporate interactive user\nfeedback focus on historical datasets. Therefore, classifiers cannot be\ninteractively retrained for specific events or user-dependent needs in\nreal-time. This limits real-time situational awareness, as streaming data that\nis incorrectly classified cannot be corrected immediately, permitting the\npossibility for important incoming data to be incorrectly classified as well.\nWe present a novel interactive learning framework to improve the classification\nprocess in which the user iteratively corrects the relevancy of tweets in\nreal-time to train the classification model on-the-fly for immediate predictive\nimprovements. We computationally evaluate our classification model adapted to\nlearn at interactive rates. Our results show that our approach outperforms\nstate-of-the-art machine learning models. In addition, we integrate our\nframework with the extended Social Media Analytics and Reporting Toolkit\n(SMART) 2.0 system, allowing the use of our interactive learning framework\nwithin a visual analytics system tailored for real-time situational awareness.\nTo demonstrate our framework's effectiveness, we provide domain expert feedback\nfrom first responders who used the extended SMART 2.0 system.", "published": "2019-08-01 09:01:19", "link": "http://arxiv.org/abs/1908.02588v2", "categories": ["cs.SI", "cs.CL", "cs.HC", "cs.LG", "stat.ML"], "primary_category": "cs.SI"}
