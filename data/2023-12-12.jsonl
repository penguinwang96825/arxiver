{"title": "Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an\n  In-Context Attack", "abstract": "Recent developments in balancing the usefulness and safety of Large Language\nModels (LLMs) have raised a critical question: Are mainstream NLP tasks\nadequately aligned with safety consideration? Our study, focusing on\nsafety-sensitive documents obtained through adversarial attacks, reveals\nsignificant disparities in the safety alignment of various NLP tasks. For\ninstance, LLMs can effectively summarize malicious long documents but often\nrefuse to translate them. This discrepancy highlights a previously unidentified\nvulnerability: attacks exploiting tasks with weaker safety alignment, like\nsummarization, can potentially compromise the integrity of tasks traditionally\ndeemed more robust, such as translation and question-answering (QA). Moreover,\nthe concurrent use of multiple NLP tasks with lesser safety alignment increases\nthe risk of LLMs inadvertently processing harmful content. We demonstrate these\nvulnerabilities in various safety-aligned LLMs, particularly Llama2 models,\nGemini and GPT-4, indicating an urgent need for strengthening safety alignments\nacross a broad spectrum of NLP tasks.", "published": "2023-12-12 01:39:29", "link": "http://arxiv.org/abs/2312.06924v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Content-Localization based Neural Machine Translation for Informal\n  Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic", "abstract": "Resources in high-resource languages have not been efficiently exploited in\nlow-resource languages to solve language-dependent research problems. Spanish\nand French are considered high resource languages in which an adequate level of\ndata resources for informal online social behavior modeling, is observed.\nHowever, a machine translation system to access those data resources and\ntransfer their context and tone to a low-resource language like dialectal\nArabic, does not exist. In response, we propose a framework that localizes\ncontents of high-resource languages to a low-resource language/dialects by\nutilizing AI power. To the best of our knowledge, we are the first work to\nprovide a parallel translation dataset from/to informal Spanish and French\nto/from informal Arabic dialects. Using this, we aim to enrich the\nunder-resource-status dialectal Arabic and fast-track the research of diverse\nonline social behaviors within and across smart cities in different\ngeo-regions. The experimental results have illustrated the capability of our\nproposed solution in exploiting the resources between high and low resource\nlanguages and dialects. Not only this, but it has also been proven that\nignoring dialects within the same language could lead to misleading analysis of\nonline social behavior.", "published": "2023-12-12 01:42:41", "link": "http://arxiv.org/abs/2312.06926v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Factual Error Correction by Learning to Inject Factual Errors", "abstract": "Factual error correction (FEC) aims to revise factual errors in false claims\nwith minimal editing, making them faithful to the provided evidence. This task\nis crucial for alleviating the hallucination problem encountered by large\nlanguage models. Given the lack of paired data (i.e., false claims and their\ncorresponding correct claims), existing methods typically adopt the\nmask-then-correct paradigm. This paradigm relies solely on unpaired false\nclaims and correct claims, thus being referred to as distantly supervised\nmethods. These methods require a masker to explicitly identify factual errors\nwithin false claims before revising with a corrector. However, the absence of\npaired data to train the masker makes accurately pinpointing factual errors\nwithin claims challenging. To mitigate this, we propose to improve FEC by\nLearning to Inject Factual Errors (LIFE), a three-step distantly supervised\nmethod: mask-corrupt-correct. Specifically, we first train a corruptor using\nthe mask-then-corrupt procedure, allowing it to deliberately introduce factual\nerrors into correct text. The corruptor is then applied to correct claims,\ngenerating a substantial amount of paired data. After that, we filter out\nlow-quality data, and use the remaining data to train a corrector. Notably, our\ncorrector does not require a masker, thus circumventing the bottleneck\nassociated with explicit factual error identification. Our experiments on a\npublic dataset verify the effectiveness of LIFE in two key aspects: Firstly, it\noutperforms the previous best-performing distantly supervised method by a\nnotable margin of 10.59 points in SARI Final (19.3% improvement). Secondly,\neven compared to ChatGPT prompted with in-context examples, LIFE achieves a\nsuperiority of 7.16 points in SARI Final.", "published": "2023-12-12 08:02:06", "link": "http://arxiv.org/abs/2312.07049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual large language models leak human stereotypes across\n  language boundaries", "abstract": "Multilingual large language models have gained prominence for their\nproficiency in processing and generating text across languages. Like their\nmonolingual counterparts, multilingual models are likely to pick up on\nstereotypes and other social biases present in their training data. In this\npaper, we study a phenomenon we term stereotype leakage, which refers to how\ntraining a model multilingually may lead to stereotypes expressed in one\nlanguage showing up in the models' behaviour in another. We propose a\nmeasurement framework for stereotype leakage and investigate its effect across\nEnglish, Russian, Chinese, and Hindi and with GPT-3.5, mT5, and mBERT. Our\nfindings show a noticeable leakage of positive, negative, and non-polar\nassociations across all languages. We find that of these models, GPT-3.5\nexhibits the most stereotype leakage, and Hindi is the most susceptible to\nleakage effects. WARNING: This paper contains model outputs which could be\noffensive in nature.", "published": "2023-12-12 10:24:17", "link": "http://arxiv.org/abs/2312.07141v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Verbreitungsmechanismen sch\u00e4digender Sprache im Netz: Anatomie zweier\n  Shitstorms", "abstract": "In this working paper, we turn our attention to two exemplary, cross-media\nshitstorms directed against well-known individuals from the business world.\nBoth have in common, first, the trigger, a controversial statement by the\nperson who thereby becomes the target of the shitstorm, and second, the\nidentity of this target as relatively privileged: cis-male, white, successful.\nWe examine the spread of the outrage wave across two media at a time and test\nthe applicability of computational linguistic methods for analyzing its time\ncourse. Assuming that harmful language spreads like a virus in digital space,\nwe are primarily interested in the events and constellations that lead to the\nuse of harmful language, and whether and how a linguistic formation of \"tribes\"\noccurs. Our research therefore focuses, first, on the distribution of\nlinguistic features within the overall shitstorm: are individual words or\nphrases increasingly used after their introduction, and through which pathways\nthey spread. Second, we ask whether \"tribes,\" for example, one group of\nsupporters and one of opponents of the target, have a distinguished linguistic\nform. Our hypothesis is that supporters remain equally active over time, while\nthe dynamic \"ripple\" effect of the shitstorm is based on the varying\nparticipation of opponents.", "published": "2023-12-12 12:00:04", "link": "http://arxiv.org/abs/2312.07194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toxic language detection: a systematic review of Arabic datasets", "abstract": "The detection of toxic language in the Arabic language has emerged as an\nactive area of research in recent years, and reviewing the existing datasets\nemployed for training the developed solutions has become a pressing need. This\npaper offers a comprehensive survey of Arabic datasets focused on online toxic\nlanguage. We systematically gathered a total of 54 available datasets and their\ncorresponding papers and conducted a thorough analysis, considering 18 criteria\nacross four primary dimensions: availability details, content, annotation\nprocess, and reusability. This analysis enabled us to identify existing gaps\nand make recommendations for future research works. For the convenience of the\nresearch community, the list of the analysed datasets is maintained in a GitHub\nrepository (https://github.com/Imene1/Arabic-toxic-language).", "published": "2023-12-12 12:43:01", "link": "http://arxiv.org/abs/2312.07228v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The GUA-Speech System Description for CNVSRC Challenge 2023", "abstract": "This study describes our system for Task 1 Single-speaker Visual Speech\nRecognition (VSR) fixed track in the Chinese Continuous Visual Speech\nRecognition Challenge (CNVSRC) 2023. Specifically, we use intermediate\nconnectionist temporal classification (Inter CTC) residual modules to relax the\nconditional independence assumption of CTC in our model. Then we use a\nbi-transformer decoder to enable the model to capture both past and future\ncontextual information. In addition, we use Chinese characters as the modeling\nunits to improve the recognition accuracy of our model. Finally, we use a\nrecurrent neural network language model (RNNLM) for shallow fusion in the\ninference stage. Experiments show that our system achieves a character error\nrate (CER) of 38.09% on the Eval set which reaches a relative CER reduction of\n21.63% over the official baseline, and obtains a second place in the challenge.", "published": "2023-12-12 13:35:33", "link": "http://arxiv.org/abs/2312.07254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Equipping Transformer with the Ability of Systematic\n  Compositionality", "abstract": "One of the key factors in language productivity and human cognition is the\nability of systematic compositionality, which refers to understanding composed\nunseen examples of seen primitives. However, recent evidence reveals that the\nTransformers have difficulty generalizing the composed context based on the\nseen primitives. To this end, we take the first step to propose a\ncompositionality-aware Transformer called CAT and two novel pre-training tasks\nto facilitate systematic compositionality. We tentatively provide a successful\nimplementation of a multi-layer CAT on the basis of the especially popular\nBERT. The experimental results demonstrate that CAT outperforms baselines on\ncompositionality-aware tasks with minimal impact on the effectiveness on\nstandardized language understanding tasks.", "published": "2023-12-12 13:57:57", "link": "http://arxiv.org/abs/2312.07280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mathematical Language Models: A Survey", "abstract": "In recent years, there has been remarkable progress in leveraging Language\nModels (LMs), encompassing Pre-trained Language Models (PLMs) and Large-scale\nLanguage Models (LLMs), within the domain of mathematics. This paper conducts a\ncomprehensive survey of mathematical LMs, systematically categorizing pivotal\nresearch endeavors from two distinct perspectives: tasks and methodologies. The\nlandscape reveals a large number of proposed mathematical LLMs, which are\nfurther delineated into instruction learning, tool-based methods, fundamental\nCoT techniques, advanced CoT methodologies and multi-modal methods. To\ncomprehend the benefits of mathematical LMs more thoroughly, we carry out an\nin-depth contrast of their characteristics and performance. In addition, our\nsurvey entails the compilation of over 60 mathematical datasets, including\ntraining datasets, benchmark datasets, and augmented datasets. Addressing the\nprimary challenges and delineating future trajectories within the field of\nmathematical LMs, this survey is poised to facilitate and inspire future\ninnovation among researchers invested in advancing this domain.", "published": "2023-12-12 01:39:16", "link": "http://arxiv.org/abs/2312.07622v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLM find the green circle? Investigation and Human-guided tool\n  manipulation for compositional generalization", "abstract": "The meaning of complex phrases in natural language is composed of their\nindividual components. The task of compositional generalization evaluates a\nmodel's ability to understand new combinations of components. Previous studies\ntrained smaller, task-specific models, which exhibited poor generalization.\nWhile large language models (LLMs) exhibit impressive generalization abilities\non many tasks through in-context learning (ICL), their potential for\ncompositional generalization remains unexplored. In this paper, we first\nempirically investigate prevailing ICL methods in compositional generalization.\nWe find that they struggle with complex compositional questions due to\ncumulative errors in long reasoning steps and intricate logic required for\ntool-making. Consequently, we propose a human-guided tool manipulation\nframework (HTM) that generates tools for sub-questions and integrates multiple\ntools. Our method enhances the effectiveness of tool creation and usage with\nminimal human effort. Experiments show that our method achieves\nstate-of-the-art performance on two compositional generalization benchmarks and\noutperforms existing methods on the most challenging test split by 70%.", "published": "2023-12-12 22:11:17", "link": "http://arxiv.org/abs/2312.07763v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "READ: Recurrent Adapter with Partial Video-Language Alignment for\n  Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling", "abstract": "Fully fine-tuning pretrained large-scale transformer models has become a\npopular paradigm for video-language modeling tasks, such as temporal language\ngrounding and video-language summarization. With a growing number of tasks and\nlimited training data, such full fine-tuning approach leads to costly model\nstorage and unstable training. To overcome these shortcomings, we introduce\nlightweight adapters to the pre-trained model and only update them at\nfine-tuning time. However, existing adapters fail to capture intrinsic temporal\nrelations among video frames or textual words. Moreover, they neglect the\npreservation of critical task-related information that flows from the raw\nvideo-language input into the adapter's low-dimensional space. To address these\nissues, we first propose a novel REcurrent ADapter (READ) that employs\nrecurrent computation to enable temporal modeling capability. Second, we\npropose Partial Video-Language Alignment (PVLA) objective via the use of\npartial optimal transport to maintain task-related information flowing into our\nREAD modules. We validate our READ framework through extensive experiments\nwhere READ significantly outperforms all existing fine-tuning strategies on\nmultiple low-resource temporal language grounding and video-language\nsummarization benchmarks. The code, model, and data have been made available at\nhttps://nguyentthong.github.io/READ.", "published": "2023-12-12 03:09:30", "link": "http://arxiv.org/abs/2312.06950v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SM70: A Large Language Model for Medical Devices", "abstract": "We are introducing SM70, a 70 billion-parameter Large Language Model that is\nspecifically designed for SpassMed's medical devices under the brand name\n'JEE1' (pronounced as G1 and means 'Life'). This large language model provides\nmore accurate and safe responses to medical-domain questions. To fine-tune\nSM70, we used around 800K data entries from the publicly available dataset\nMedAlpaca. The Llama2 70B open-sourced model served as the foundation for SM70,\nand we employed the QLoRA technique for fine-tuning. The evaluation is\nconducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE\n- each representing a unique aspect of medical knowledge and reasoning. The\nperformance of SM70 is contrasted with other notable LLMs, including Llama2\n70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a\ncomparative understanding of its capabilities within the medical domain. Our\nresults indicate that SM70 outperforms several established models in these\ndatasets, showcasing its proficiency in handling a range of medical queries,\nfrom fact-based questions derived from PubMed abstracts to complex clinical\ndecision-making scenarios. The robust performance of SM70, particularly in the\nUSMLE and PUBMEDQA datasets, suggests its potential as an effective tool in\nclinical decision support and medical information retrieval. Despite its\npromising results, the paper also acknowledges the areas where SM70 lags behind\nthe most advanced model, GPT 4, thereby highlighting the need for further\ndevelopment, especially in tasks demanding extensive medical knowledge and\nintricate reasoning.", "published": "2023-12-12 04:25:26", "link": "http://arxiv.org/abs/2312.06974v1", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "Alignment for Honesty", "abstract": "Recent research has made significant strides in aligning large language\nmodels (LLMs) with helpfulness and harmlessness. In this paper, we argue for\nthe importance of alignment for \\emph{honesty}, ensuring that LLMs proactively\nrefuse to answer questions when they lack knowledge, while still not being\noverly conservative. However, a pivotal aspect of alignment for honesty\ninvolves discerning an LLM's knowledge boundaries, which demands comprehensive\nsolutions in terms of metric development, benchmark creation, and training\nmethodologies. We address these challenges by first establishing a precise\nproblem definition and defining ``honesty'' inspired by the Analects of\nConfucius. This serves as a cornerstone for developing metrics that effectively\nmeasure an LLM's honesty by quantifying its progress post-alignment.\nFurthermore, we introduce a flexible training framework which is further\ninstantiated by several efficient fine-tuning techniques that emphasize honesty\nwithout sacrificing performance on other tasks. Our extensive experiments\nreveal that these aligned models show a marked increase in honesty, as\nindicated by our proposed metrics. We open-source all relevant resources to\nfacilitate future research at\n\\url{https://github.com/GAIR-NLP/alignment-for-honesty}.", "published": "2023-12-12 06:10:42", "link": "http://arxiv.org/abs/2312.07000v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic Corrective Self-Distillation for Better Fine-Tuning of\n  Pretrained Models", "abstract": "We tackle the challenging issue of aggressive fine-tuning encountered during\nthe process of transfer learning of pre-trained language models (PLMs) with\nlimited labeled downstream data. This problem primarily results in a decline in\nperformance on the subsequent task. Inspired by the adaptive boosting method in\ntraditional machine learning, we present an effective dynamic corrective\nself-distillation (DCS) approach to improve the fine-tuning of the PLMs. Our\ntechnique involves performing a self-distillation mechanism where, at each\niteration, the student model actively adapts and corrects itself by dynamically\nadjusting the weights assigned to individual data points. This iterative\nself-correcting process significantly enhances the overall fine-tuning\ncapability of PLMs, leading to improved performance and robustness. We\nconducted comprehensive evaluations using the GLUE benchmark demonstrating the\nefficacy of our method in enhancing the fine-tuning process for various PLMs\nacross diverse downstream tasks.", "published": "2023-12-12 07:26:36", "link": "http://arxiv.org/abs/2312.07028v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking Compression: Reduced Order Modelling of Latent Features in\n  Large Language Models", "abstract": "Due to the substantial scale of Large Language Models (LLMs), the direct\napplication of conventional compression methodologies proves impractical. The\ncomputational demands associated with even minimal gradient updates present\nchallenges, particularly on consumer-grade hardware. This paper introduces an\ninnovative approach for the parametric and practical compression of LLMs based\non reduced order modelling, which entails low-rank decomposition within the\nfeature space and re-parameterization in the weight space. Notably, this\ncompression technique operates in a layer-wise manner, obviating the need for a\nGPU device and enabling the compression of billion-scale models within\nstringent constraints of both memory and time. Our method represents a\nsignificant advancement in model compression by leveraging matrix\ndecomposition, demonstrating superior efficacy compared to the prevailing\nstate-of-the-art structured pruning method.", "published": "2023-12-12 07:56:57", "link": "http://arxiv.org/abs/2312.07046v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DiffuVST: Narrating Fictional Scenes with Global-History-Guided\n  Denoising Models", "abstract": "Recent advances in image and video creation, especially AI-based image\nsynthesis, have led to the production of numerous visual scenes that exhibit a\nhigh level of abstractness and diversity. Consequently, Visual Storytelling\n(VST), a task that involves generating meaningful and coherent narratives from\na collection of images, has become even more challenging and is increasingly\ndesired beyond real-world imagery. While existing VST techniques, which\ntypically use autoregressive decoders, have made significant progress, they\nsuffer from low inference speed and are not well-suited for synthetic scenes.\nTo this end, we propose a novel diffusion-based system DiffuVST, which models\nthe generation of a series of visual descriptions as a single conditional\ndenoising process. The stochastic and non-autoregressive nature of DiffuVST at\ninference time allows it to generate highly diverse narratives more\nefficiently. In addition, DiffuVST features a unique design with bi-directional\ntext history guidance and multimodal adapter modules, which effectively improve\ninter-sentence coherence and image-to-text fidelity. Extensive experiments on\nthe story generation task covering four fictional visual-story datasets\ndemonstrate the superiority of DiffuVST over traditional autoregressive models\nin terms of both text quality and inference speed.", "published": "2023-12-12 08:40:38", "link": "http://arxiv.org/abs/2312.07066v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "BED: Bi-Encoder-Decoder Model for Canonical Relation Extraction", "abstract": "Canonical relation extraction aims to extract relational triples from\nsentences, where the triple elements (entity pairs and their relationship) are\nmapped to the knowledge base. Recently, methods based on the encoder-decoder\narchitecture are proposed and achieve promising results. However, these methods\ncannot well utilize the entity information, which is merely used as augmented\ntraining data. Moreover, they are incapable of representing novel entities,\nsince no embeddings have been learned for them. In this paper, we propose a\nnovel framework, Bi-Encoder-Decoder (BED), to solve the above issues.\nSpecifically, to fully utilize entity information, we employ an encoder to\nencode semantics of this information, leading to high-quality entity\nrepresentations. For novel entities, given a trained entity encoder, their\nrepresentations can be easily generated. Experimental results on two datasets\nshow that, our method achieves a significant performance improvement over the\nprevious state-of-the-art and handle novel entities well without retraining.", "published": "2023-12-12 09:14:55", "link": "http://arxiv.org/abs/2312.07088v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classifying complex documents: comparing bespoke solutions to large\n  language models", "abstract": "Here we search for the best automated classification approach for a set of\ncomplex legal documents. Our classification task is not trivial: our aim is to\nclassify ca 30,000 public courthouse records from 12 states and 267 counties at\ntwo different levels using nine sub-categories. Specifically, we investigated\nwhether a fine-tuned large language model (LLM) can achieve the accuracy of a\nbespoke custom-trained model, and what is the amount of fine-tuning necessary.", "published": "2023-12-12 11:38:09", "link": "http://arxiv.org/abs/2312.07182v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation of Clinical Text: An Empirical Investigation\n  into Multilingual Pre-Trained Language Models and Transfer-Learning", "abstract": "We conduct investigations on clinical text machine translation by examining\nmultilingual neural network models using deep learning such as Transformer\nbased structures. Furthermore, to address the language resource imbalance\nissue, we also carry out experiments using a transfer learning methodology\nbased on massive multilingual pre-trained language models (MMPLMs). The\nexperimental results on three subtasks including 1) clinical case (CC), 2)\nclinical terminology (CT), and 3) ontological concept (OC) show that our models\nachieved top-level performances in the ClinSpEn-2022 shared task on\nEnglish-Spanish clinical domain data. Furthermore, our expert-based human\nevaluations demonstrate that the small-sized pre-trained language model (PLM)\nwon over the other two extra-large language models by a large margin, in the\nclinical domain fine-tuning, which finding was never reported in the field.\nFinally, the transfer learning method works well in our experimental setting\nusing the WMT21fb model to accommodate a new language space Spanish that was\nnot seen at the pre-training stage within WMT21fb itself, which deserves more\nexploitation for clinical knowledge transformation, e.g. to investigate into\nmore languages. These research findings can shed some light on domain-specific\nmachine translation development, especially in clinical and healthcare fields.\nFurther research projects can be carried out based on our work to improve\nhealthcare text analytics and knowledge transformation. Our data will be openly\navailable for research purposes at https://github.com/HECTA-UoM/ClinicalNMT", "published": "2023-12-12 13:26:42", "link": "http://arxiv.org/abs/2312.07250v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GIST: Improving Parameter Efficient Fine Tuning via Knowledge\n  Interaction", "abstract": "The Parameter-Efficient Fine-Tuning (PEFT) method, which adjusts or\nintroduces fewer trainable parameters to calibrate pre-trained models on\ndownstream tasks, has become a recent research interest. However, existing PEFT\nmethods within the traditional fine-tiuning framework have two main\nshortcomings: 1) They overlook the explicit association between trainable\nparameters and downstream task knowledge. 2) They neglect the interaction\nbetween the intrinsic task-agnostic knowledge of pre-trained models and the\ntask-specific knowledge in downstream tasks. To address this gap, we propose a\nnovel fine-tuning framework, named GIST, in a plug-and-play manner.\nSpecifically, our framework first introduces a trainable token, called the Gist\ntoken, when applying PEFT methods on downstream tasks. This token serves as an\naggregator of the task-specific knowledge learned by the PEFT methods and forms\nan explicit association with downstream knowledge. Furthermore, to facilitate\nexplicit interaction between task-agnostic and task-specific knowledge, we\nintroduce the concept of Knowledge Interaction via a Bidirectional\nKullback-Leibler Divergence objective. As a result, PEFT methods within our\nframework can make the pre-trained model understand downstream tasks more\ncomprehensively by leveraging the knowledge interaction. Extensive experiments\ndemonstrate the universality and scalability of our framework. Notably, on the\nVTAB-1K benchmark, we employ the Adapter (a prevalent PEFT method) within our\nGIST framework and achieve a performance boost of 2.25%, with an increase of\nonly 0.8K parameters. The Code will be released.", "published": "2023-12-12 13:35:41", "link": "http://arxiv.org/abs/2312.07255v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "SCCA: Shifted Cross Chunk Attention for long contextual semantic\n  expansion", "abstract": "Sparse attention as a efficient method can significantly decrease the\ncomputation cost, but current sparse attention tend to rely on window self\nattention which block the global information flow. For this problem, we present\nShifted Cross Chunk Attention (SCCA), using different KV shifting strategy to\nextend respective field in each attention layer. Except, we combine Dilated\nAttention(DA) and Dilated Neighborhood Attention(DNA) to present Shifted\nDilated Attention(SDA). Both SCCA and SDA can accumulate attention results in\nmulti head attention to obtain approximate respective field in full attention.\nIn this paper, we conduct language modeling experiments using different pattern\nof SCCA and combination of SCCA and SDA. The proposed shifted cross chunk\nattention (SCCA) can effectively extend large language models (LLMs) to longer\ncontext combined with Positional interpolation(PI) and LoRA than current sparse\nattention. Notably, SCCA adopts LLaMA2 7B from 4k context to 8k in single V100.\nThis attention pattern can provide a Plug-and-play fine-tuning method to extend\nmodel context while retaining their original architectures, and is compatible\nwith most existing techniques.", "published": "2023-12-12 14:24:54", "link": "http://arxiv.org/abs/2312.07305v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Simple Recipe for Contrastively Pre-training Video-First Encoders\n  Beyond 16 Frames", "abstract": "Understanding long, real-world videos requires modeling of long-range visual\ndependencies. To this end, we explore video-first architectures, building on\nthe common paradigm of transferring large-scale, image--text models to video\nvia shallow temporal fusion. However, we expose two limitations to the\napproach: (1) decreased spatial capabilities, likely due to poor\nvideo--language alignment in standard video datasets, and (2) higher memory\nconsumption, bottlenecking the number of frames that can be processed. To\nmitigate the memory bottleneck, we systematically analyze the memory/accuracy\ntrade-off of various efficient methods: factorized attention,\nparameter-efficient image-to-video adaptation, input masking, and\nmulti-resolution patchification. Surprisingly, simply masking large portions of\nthe video (up to 75%) during contrastive pre-training proves to be one of the\nmost robust ways to scale encoders to videos up to 4.3 minutes at 1 FPS. Our\nsimple approach for training long video-to-text models, which scales to 1B\nparameters, does not add new architectural complexity and is able to outperform\nthe popular paradigm of using much larger LLMs as an information aggregator\nover segment-based information on benchmarks with long-range temporal\ndependencies (YouCook2, EgoSchema).", "published": "2023-12-12 16:10:19", "link": "http://arxiv.org/abs/2312.07395v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models", "abstract": "Recently, the evaluation of Large Language Models has emerged as a popular\narea of research. The three crucial questions for LLM evaluation are ``what,\nwhere, and how to evaluate''. However, the existing research mainly focuses on\nthe first two questions, which are basically what tasks to give the LLM during\ntesting and what kind of knowledge it should deal with. As for the third\nquestion, which is about what standards to use, the types of evaluators, how to\nscore, and how to rank, there hasn't been much discussion. In this paper, we\nanalyze evaluation methods by comparing various criteria with both manual and\nautomatic evaluation, utilizing onsite, crowd-sourcing, public annotators and\nGPT-4, with different scoring methods and ranking systems. We propose a new\ndataset, LLMEval and conduct evaluations on 20 LLMs. A total of 2,186\nindividuals participated, leading to the generation of 243,337 manual\nannotations and 57,511 automatic evaluation results. We perform comparisons and\nanalyses of different settings and conduct 10 conclusions that can provide some\ninsights for evaluating LLM in the future. The dataset and the results are\npublicly available at https://github.com/llmeval .", "published": "2023-12-12 16:14:43", "link": "http://arxiv.org/abs/2312.07398v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis\n  Framework with Prompt-Generated Rationales", "abstract": "Machine reasoning has made great progress in recent years owing to large\nlanguage models (LLMs). In the clinical domain, however, most NLP-driven\nprojects mainly focus on clinical classification or reading comprehension, and\nunder-explore clinical reasoning for disease diagnosis due to the expensive\nrationale annotation with clinicians. In this work, we present a\n\"reasoning-aware\" diagnosis framework that rationalizes the diagnostic process\nvia prompt-based learning in a time- and labor-efficient manner, and learns to\nreason over the prompt-generated rationales. Specifically, we address the\nclinical reasoning for disease diagnosis, where the LLM generates diagnostic\nrationales providing its insight on presented patient data and the reasoning\npath towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT). We\nempirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive\nexperiments and analyses on both rationale generation and disease diagnosis in\nvarious settings. We further propose a novel set of criteria for evaluating\nmachine-generated rationales' potential for real-world clinical settings,\nfacilitating and benefiting future research in this area.", "published": "2023-12-12 16:14:45", "link": "http://arxiv.org/abs/2312.07399v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ICL Markup: Structuring In-Context Learning using Soft-Token Tags", "abstract": "Large pretrained language models (LLMs) can be rapidly adapted to a wide\nvariety of tasks via a text-to-text approach, where the instruction and input\nare fed to the model in natural language. Combined with in-context learning\n(ICL), this paradigm is impressively flexible and powerful. However, it also\nburdens users with an overwhelming number of choices, many of them arbitrary.\nInspired by markup languages like HTML, we contribute a method of using\nsoft-token tags to compose prompt templates. This approach reduces arbitrary\ndecisions and streamlines the application of ICL. Our method is a form of\nmeta-learning for ICL; it learns these tags in advance during a\nparameter-efficient fine-tuning ``warm-up'' process. The tags can subsequently\nbe used in templates for ICL on new, unseen tasks without any additional\nfine-tuning. Our experiments with this approach yield promising initial\nresults, improving LLM performance on important enterprise applications such as\nfew-shot and open-world intent detection, as well as text classification in\nnews and legal domains.", "published": "2023-12-12 16:25:05", "link": "http://arxiv.org/abs/2312.07405v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Faster k-Nearest-Neighbor Machine Translation", "abstract": "Recent works have proven the effectiveness of k-nearest-neighbor machine\ntranslation(a.k.a kNN-MT) approaches to produce remarkable improvement in\ncross-domain translations. However, these models suffer from heavy retrieve\noverhead on the entire datastore when decoding each token. We observe that\nduring the decoding phase, about 67% to 84% of tokens are unvaried after\nsearching over the corpus datastore, which means most of the tokens cause\nfutile retrievals and introduce unnecessary computational costs by initiating\nk-nearest-neighbor searches. We consider this phenomenon is explainable in\nlinguistics and propose a simple yet effective multi-layer perceptron (MLP)\nnetwork to predict whether a token should be translated jointly by the neural\nmachine translation model and probabilities produced by the kNN or just by the\nneural model. The results show that our method succeeds in reducing redundant\nretrieval operations and significantly reduces the overhead of kNN retrievals\nby up to 53% at the expense of a slight decline in translation quality.\nMoreover, our method could work together with all existing kNN-MT systems. This\nwork has been accepted for publication in the jornal Advances in Artificial\nIntelligence and Machine Learning (ISSN: 2582-9793). The final published\nversion can be found at DOI: https://dx.doi.org/10.54364/AAIML.2024.41111", "published": "2023-12-12 16:41:29", "link": "http://arxiv.org/abs/2312.07419v2", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Comparable Demonstrations are Important in In-Context Learning: A Novel\n  Perspective on Demonstration Selection", "abstract": "In-Context Learning (ICL) is an important paradigm for adapting Large\nLanguage Models (LLMs) to downstream tasks through a few demonstrations.\nDespite the great success of ICL, the limitation of the demonstration number\nmay lead to demonstration bias, i.e. the input-label mapping induced by LLMs\nmisunderstands the task's essence. Inspired by human experience, we attempt to\nmitigate such bias through the perspective of the inter-demonstration\nrelationship. Specifically, we construct Comparable Demonstrations (CDs) by\nminimally editing the texts to flip the corresponding labels, in order to\nhighlight the task's essence and eliminate potential spurious correlations\nthrough the inter-demonstration comparison. Through a series of experiments on\nCDs, we find that (1) demonstration bias does exist in LLMs, and CDs can\nsignificantly reduce such bias; (2) CDs exhibit good performance in ICL,\nespecially in out-of-distribution scenarios. In summary, this study explores\nthe ICL mechanisms from a novel perspective, providing a deeper insight into\nthe demonstration selection strategy for ICL.", "published": "2023-12-12 18:05:46", "link": "http://arxiv.org/abs/2312.07476v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy\n  and Reasoning Ability", "abstract": "While there are numerous benchmarks comparing the performance of modern\nlanguage models (LMs), end-task evaluations often conflate notions of *factual\naccuracy* (\"truth\") and *reasoning ability* (\"rationality\", or \"honesty\" in the\nsense of correctly reporting implications of beliefs). Our goal is a dataset\nthat clearly distinguishes these two notions. Our approach is to leverage and\nextend a collection of human-annotated *entailment trees*, engineered to\nexpress both good and bad chains of reasoning, and using a mixture of true and\nfalse facts, in particular including counterfactual examples, to avoid belief\nbias (also known as the \"content effect\"). The resulting dataset, called BaRDa,\ncontains 3000 entailments (1787 valid, 1213 invalid), using 6681 true and 2319\nfalse statements. Testing on four GPT-series models,\nGPT3(curie)/GPT3(davinici)/3.5/4, we find factual accuracy (truth) scores of\n74.1/80.6/82.6/87.1 and reasoning accuracy scores of 63.1/78.0/71.8/79.2. This\nshows the clear progression of models towards improved factual accuracy and\nentailment reasoning, and the dataset provides a new benchmark that more\ncleanly separates and quantifies these two notions.", "published": "2023-12-12 18:55:43", "link": "http://arxiv.org/abs/2312.07527v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sentiment analysis in Tourism: Fine-tuning BERT or sentence embeddings\n  concatenation?", "abstract": "Undoubtedly that the Bidirectional Encoder representations from Transformers\nis the most powerful technique in making Natural Language Processing tasks such\nas Named Entity Recognition, Question & Answers or Sentiment Analysis, however,\nthe use of traditional techniques remains a major potential for the improvement\nof recent models, in particular word tokenization techniques and embeddings,\nbut also the improvement of neural network architectures which are now the core\nof each architecture. recent. In this paper, we conduct a comparative study\nbetween Fine-Tuning the Bidirectional Encoder Representations from Transformers\nand a method of concatenating two embeddings to boost the performance of a\nstacked Bidirectional Long Short-Term Memory-Bidirectional Gated Recurrent\nUnits model; these two approaches are applied in the context of sentiment\nanalysis of shopping places in Morocco. A search for the best learning rate was\nmade at the level of the two approaches, and a comparison of the best\noptimizers was made for each sentence embedding combination with regard to the\nsecond approach.", "published": "2023-12-12 23:23:23", "link": "http://arxiv.org/abs/2312.07797v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking the Instruction Quality: LIFT is What You Need", "abstract": "Instruction tuning, a specialized technique to enhance large language model\n(LLM) performance via instruction datasets, relies heavily on the quality of\nemployed data. Existing quality improvement methods alter instruction data\nthrough dataset expansion or curation. However, the expansion method risks data\nredundancy, potentially compromising LLM performance, while the curation\napproach confines the LLM's potential to the original dataset. Our aim is to\nsurpass the original data quality without encountering these shortcomings. To\nachieve this, we propose LIFT (LLM Instruction Fusion Transfer), a novel and\nversatile paradigm designed to elevate the instruction quality to new heights.\nLIFT strategically broadens data distribution to encompass more high-quality\nsubspaces and eliminates redundancy, concentrating on high-quality segments\nacross overall data subspaces. Experimental results demonstrate that, even with\na limited quantity of high-quality instruction data selected by our paradigm,\nLLMs not only consistently uphold robust performance across various tasks but\nalso surpass some state-of-the-art results, highlighting the significant\nimprovement in instruction quality achieved by our paradigm.", "published": "2023-12-12 03:30:21", "link": "http://arxiv.org/abs/2312.11508v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Natural Language Processing-Based Classification and Mode-Based\n  Ranking of Musculoskeletal Disorder Risk Factors", "abstract": "This research delves into Musculoskeletal Disorder (MSD) risk factors, using\na blend of Natural Language Processing (NLP) and mode-based ranking. The aim is\nto refine understanding, classification, and prioritization for focused\nprevention and treatment. Eight NLP models are evaluated, combining pre-trained\ntransformers, cosine similarity, and distance metrics to categorize factors\ninto personal, biomechanical, workplace, psychological, and organizational\nclasses. BERT with cosine similarity achieves 28% accuracy; sentence\ntransformer with Euclidean, Bray-Curtis, and Minkowski distances scores 100%.\nWith 10-fold cross-validation, statistical tests ensure robust results. Survey\ndata and mode-based ranking determine severity hierarchy, aligning with the\nliterature. \"Working posture\" is the most severe, highlighting posture's role.\nSurvey insights emphasize \"Job insecurity,\" \"Effort reward imbalance,\" and\n\"Poor employee facility\" as significant contributors. Rankings offer actionable\ninsights for MSD prevention. The study suggests targeted interventions,\nworkplace improvements, and future research directions. This integrated NLP and\nranking approach enhances MSD comprehension and informs occupational health\nstrategies.", "published": "2023-12-12 19:34:23", "link": "http://arxiv.org/abs/2312.11517v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SEOpinion: Summarization and Exploration Opinion of E-Commerce Websites", "abstract": "E-Commerce (EC) websites provide a large amount of useful information that\nexceed human cognitive processing ability. In order to help customers in\ncomparing alternatives when buying a product, previous studies designed opinion\nsummarization systems based on customer reviews. They ignored templates'\ninformation provided by manufacturers, although these descriptive information\nhave much product aspects or characteristics. Therefore, this paper proposes a\nmethodology coined as SEOpinion (Summa-rization and Exploration of Opinions)\nwhich provides a summary for the product aspects and spots opinion(s) regarding\nthem, using a combination of templates' information with the customer reviews\nin two main phases. First, the Hierarchical Aspect Extraction (HAE) phase\ncreates a hierarchy of product aspects from the template. Subsequently, the\nHierarchical Aspect-based Opinion Summarization (HAOS) phase enriches this\nhierarchy with customers' opinions; to be shown to other potential buyers. To\ntest the feasibility of using Deep Learning-based BERT techniques with our\napproach, we have created a corpus by gathering information from the top five\nEC websites for laptops. The experimental results show that Recurrent Neural\nNetwork (RNN) achieves better results (77.4% and 82.6% in terms of F1-measure\nfor the first and second phase) than the Convolutional Neural Network (CNN) and\nthe Support Vector Machine (SVM) technique.", "published": "2023-12-12 15:45:58", "link": "http://arxiv.org/abs/2312.14171v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Learning-based Sentiment Classification: A Comparative Survey", "abstract": "Recently, Deep Learning (DL) approaches have been applied to solve the\nSentiment Classification (SC) problem, which is a core task in reviews mining\nor Sentiment Analysis (SA). The performances of these approaches are affected\nby different factors. This paper addresses these factors and classifies them\ninto three categories: data preparation based factors, feature representation\nbased factors and the classification techniques based factors. The paper is a\ncomprehensive literature-based survey that compares the performance of more\nthan 100 DL-based SC approaches by using 21 public datasets of reviews given by\ncustomers within three specific application domains (products, movies and\nrestaurants). These 21 datasets have different characteristics\n(balanced/imbalanced, size, etc.) to give a global vision for our study. The\ncomparison explains how the proposed factors quantitatively affect the\nperformance of the studied DL-based SC approaches.", "published": "2023-12-12 15:57:44", "link": "http://arxiv.org/abs/2312.17253v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large language models in healthcare and medical domain: A review", "abstract": "The deployment of large language models (LLMs) within the healthcare sector\nhas sparked both enthusiasm and apprehension. These models exhibit the\nremarkable capability to provide proficient responses to free-text queries,\ndemonstrating a nuanced understanding of professional medical knowledge. This\ncomprehensive survey delves into the functionalities of existing LLMs designed\nfor healthcare applications, elucidating the trajectory of their development,\nstarting from traditional Pretrained Language Models (PLMs) to the present\nstate of LLMs in healthcare sector. First, we explore the potential of LLMs to\namplify the efficiency and effectiveness of diverse healthcare applications,\nparticularly focusing on clinical language understanding tasks. These tasks\nencompass a wide spectrum, ranging from named entity recognition and relation\nextraction to natural language inference, multi-modal medical applications,\ndocument classification, and question-answering. Additionally, we conduct an\nextensive comparison of the most recent state-of-the-art LLMs in the healthcare\ndomain, while also assessing the utilization of various open-source LLMs and\nhighlighting their significance in healthcare applications. Furthermore, we\npresent the essential performance metrics employed to evaluate LLMs in the\nbiomedical domain, shedding light on their effectiveness and limitations.\nFinally, we summarize the prominent challenges and constraints faced by large\nlanguage models in the healthcare sector, offering a holistic perspective on\ntheir potential benefits and shortcomings. This review provides a comprehensive\nexploration of the current landscape of LLMs in healthcare, addressing their\nrole in transforming medical applications and the areas that warrant further\nresearch and development.", "published": "2023-12-12 20:54:51", "link": "http://arxiv.org/abs/2401.06775v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Context Matters: Data-Efficient Augmentation of Large Language Models\n  for Scientific Applications", "abstract": "In this paper, we explore the challenges inherent to Large Language Models\n(LLMs) like GPT-4, particularly their propensity for hallucinations, logic\nmistakes, and incorrect conclusions when tasked with answering complex\nquestions. The capacity of LLMs to present erroneous answers in a coherent and\nsemantically rigorous manner further complicates the detection of factual\ninaccuracies. This issue is especially pronounced in fields that require\nspecialized expertise. Our work delves into these challenges, aiming to enhance\nthe understanding and mitigation of such errors, thereby contributing to the\nimprovement of LLM accuracy and reliability in scientific and other specialized\ndomains. Our findings reveal a non-linear relationship between the context's\nrelevancy and the answers' measured quality. In addition, we demonstrate that\nwith the correct calibration, it is possible to automate the grading procedure\n-- a finding suggesting that, at least to some degree, the LLMs can be used to\nself-examine the quality of their own performance. Finally, we describe an\nexperimental platform that can be seen as a proof-of-concept of the techniques\ndescribed in this work.", "published": "2023-12-12 08:43:20", "link": "http://arxiv.org/abs/2312.07069v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs Perform Poorly at Concept Extraction in Cyber-security Research\n  Literature", "abstract": "The cybersecurity landscape evolves rapidly and poses threats to\norganizations. To enhance resilience, one needs to track the latest\ndevelopments and trends in the domain. It has been demonstrated that standard\nbibliometrics approaches show their limits in such a fast-evolving domain. For\nthis purpose, we use large language models (LLMs) to extract relevant knowledge\nentities from cybersecurity-related texts. We use a subset of arXiv preprints\non cybersecurity as our data and compare different LLMs in terms of entity\nrecognition (ER) and relevance. The results suggest that LLMs do not produce\ngood knowledge entities that reflect the cybersecurity context, but our results\nshow some potential for noun extractors. For this reason, we developed a noun\nextractor boosted with some statistical analysis to extract specific and\nrelevant compound nouns from the domain. Later, we tested our model to identify\ntrends in the LLM domain. We observe some limitations, but it offers promising\nresults to monitor the evolution of emergent trends.", "published": "2023-12-12 09:39:03", "link": "http://arxiv.org/abs/2312.07110v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-supervised Adaptive Pre-training of Multilingual Speech Models for\n  Language and Dialect Identification", "abstract": "Pre-trained Transformer-based speech models have shown striking performance\nwhen fine-tuned on various downstream tasks such as automatic speech\nrecognition and spoken language identification (SLID). However, the problem of\ndomain mismatch remains a challenge in this area, where the domain of the\npre-training data might differ from that of the downstream labeled data used\nfor fine-tuning. In multilingual tasks such as SLID, the pre-trained speech\nmodel may not support all the languages in the downstream task. To address this\nchallenge, we propose self-supervised adaptive pre-training (SAPT) to adapt the\npre-trained model to the target domain and languages of the downstream task. We\napply SAPT to the XLSR-128 model and investigate the effectiveness of this\napproach for the SLID task. First, we demonstrate that SAPT improves XLSR\nperformance on the FLEURS benchmark with substantial gains up to 40.1% for\nunder-represented languages. Second, we apply SAPT on four different datasets\nin a few-shot learning setting, showing that our approach improves the sample\nefficiency of XLSR during fine-tuning. Our experiments provide strong empirical\nevidence that continual adaptation via self-supervision improves downstream\nperformance for multilingual speech models.", "published": "2023-12-12 14:58:08", "link": "http://arxiv.org/abs/2312.07338v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Cross-modal Contrastive Learning with Asymmetric Co-attention Network\n  for Video Moment Retrieval", "abstract": "Video moment retrieval is a challenging task requiring fine-grained\ninteractions between video and text modalities. Recent work in image-text\npretraining has demonstrated that most existing pretrained models suffer from\ninformation asymmetry due to the difference in length between visual and\ntextual sequences. We question whether the same problem also exists in the\nvideo-text domain with an auxiliary need to preserve both spatial and temporal\ninformation. Thus, we evaluate a recently proposed solution involving the\naddition of an asymmetric co-attention network for video grounding tasks.\nAdditionally, we incorporate momentum contrastive loss for robust,\ndiscriminative representation learning in both modalities. We note that the\nintegration of these supplementary modules yields better performance compared\nto state-of-the-art models on the TACoS dataset and comparable results on\nActivityNet Captions, all while utilizing significantly fewer parameters with\nrespect to baseline.", "published": "2023-12-12 17:00:46", "link": "http://arxiv.org/abs/2312.07435v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in\n  Generative Language Models", "abstract": "Current datasets for unwanted social bias auditing are limited to studying\nprotected demographic features such as race and gender. In this work, we\nintroduce a comprehensive benchmark that is meant to capture the amplification\nof social bias, via stigmas, in generative language models. Taking inspiration\nfrom social science research, we start with a documented list of 93 US-centric\nstigmas and curate a question-answering (QA) dataset which involves simple\nsocial situations. Our benchmark, SocialStigmaQA, contains roughly 10K prompts,\nwith a variety of prompt styles, carefully constructed to systematically test\nfor both social bias and model robustness. We present results for\nSocialStigmaQA with two open source generative language models and we find that\nthe proportion of socially biased output ranges from 45% to 59% across a\nvariety of decoding strategies and prompting styles. We demonstrate that the\ndeliberate design of the templates in our benchmark (e.g., adding biasing text\nto the prompt or using different verbs that change the answer that indicates\nbias) impacts the model tendencies to generate socially biased output.\nAdditionally, through manual evaluation, we discover problematic patterns in\nthe generated chain-of-thought output that range from subtle bias to lack of\nreasoning.\n  Warning: This paper contains examples of text which are toxic, biased, and\npotentially harmful.", "published": "2023-12-12 18:27:44", "link": "http://arxiv.org/abs/2312.07492v4", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interfacing Foundation Models' Embeddings", "abstract": "Foundation models possess strong capabilities in reasoning and memorizing\nacross modalities. To further unleash the power of foundation models, we\npresent FIND, a generalized interface for aligning foundation models'\nembeddings with unified image and dataset-level understanding spanning modality\nand granularity. As shown in the teaser figure, a lightweight transformer\ninterface without tuning any foundation model weights is enough for\nsegmentation, grounding, and retrieval in an interleaved manner. The proposed\ninterface has the following favorable attributes: (1) Generalizable. It applies\nto various tasks spanning retrieval, segmentation, etc., under the same\narchitecture and weights. (2) Interleavable. With the benefit of multi-task\nmulti-modal training, the proposed interface creates an interleaved shared\nembedding space. (3) Extendable. The proposed interface is adaptive to new\ntasks, and new models. In light of the interleaved embedding space, we\nintroduce FIND-Bench, which introduces new training and evaluation annotations\nto the COCO dataset for interleaved segmentation and retrieval. We are the\nfirst work aligning foundations models' embeddings for interleave\nunderstanding. Meanwhile, our approach achieves state-of-the-art performance on\nFIND-Bench and competitive performance on standard retrieval and segmentation\nsettings.", "published": "2023-12-12 18:58:02", "link": "http://arxiv.org/abs/2312.07532v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "diff History for Neural Language Agents", "abstract": "Neural Language Models (LMs) offer an exciting solution for general-purpose\nembodied control. However, a key technical issue arises when using an LM-based\ncontroller: environment observations must be converted to text, which coupled\nwith history, results in long and verbose textual prompts. As a result, prior\nwork in LM agents is limited to restricted domains with small observation size\nas well as minimal needs for interaction history or instruction tuning. In this\npaper, we introduce diff history, a simple and highly effective solution to\nthese issues. By applying the Unix diff command on consecutive text\nobservations in the interaction histories used to prompt LM policies, we can\nboth abstract away redundant information and focus the content of textual\ninputs on the salient changes in the environment. On NetHack, an unsolved video\ngame that requires long-horizon reasoning for decision-making, LMs tuned with\ndiff history match state-of-the-art performance for neural agents while needing\n1800x fewer training examples compared to prior work. Even on the simpler\nBabyAI-Text environment with concise text observations, we find that although\ndiff history increases the length of prompts, the representation it provides\noffers a 25% improvement in the efficiency of low-sample instruction tuning.\nFurther, we show that diff history scales favorably across different tuning\ndataset sizes. We open-source our code and data to\nhttps://diffhistory.github.io.", "published": "2023-12-12 18:59:30", "link": "http://arxiv.org/abs/2312.07540v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor", "abstract": "Existing open-vocabulary image segmentation methods require a fine-tuning\nstep on mask labels and/or image-text datasets. Mask labels are\nlabor-intensive, which limits the number of categories in segmentation\ndatasets. Consequently, the vocabulary capacity of pre-trained VLMs is severely\nreduced after fine-tuning. However, without fine-tuning, VLMs trained under\nweak image-text supervision tend to make suboptimal mask predictions. To\nalleviate these issues, we introduce a novel recurrent framework that\nprogressively filters out irrelevant texts and enhances mask quality without\ntraining efforts. The recurrent unit is a two-stage segmenter built upon a\nfrozen VLM. Thus, our model retains the VLM's broad vocabulary space and equips\nit with segmentation ability. Experiments show that our method outperforms not\nonly the training-free counterparts, but also those fine-tuned with millions of\ndata samples, and sets the new state-of-the-art records for both zero-shot\nsemantic and referring segmentation. Concretely, we improve the current record\nby 28.8, 16.0, and 6.9 mIoU on Pascal VOC, COCO Object, and Pascal Context.", "published": "2023-12-12 19:00:04", "link": "http://arxiv.org/abs/2312.07661v3", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "FULL-W2V: Fully Exploiting Data Reuse for W2V on GPU-Accelerated Systems", "abstract": "Word2Vec remains one of the highly-impactful innovations in the field of\nNatural Language Processing (NLP) that represents latent grammatical and\nsyntactical information in human text with dense vectors in a low dimension.\nWord2Vec has high computational cost due to the algorithm's inherent\nsequentiality, intensive memory accesses, and the large vocabularies it\nrepresents. While prior studies have investigated technologies to explore\nparallelism and improve memory system performance, they struggle to effectively\ngain throughput on powerful GPUs.\n  We identify memory data access and latency as the primary bottleneck in prior\nworks on GPUs, which prevents highly optimized kernels from attaining the\narchitecture's peak performance. We present a novel algorithm, FULL-W2V, which\nmaximally exploits the opportunities for data reuse in the W2V algorithm and\nleverages GPU architecture and resources to reduce access to low memory levels\nand improve temporal locality. FULL-W2V is capable of reducing accesses to GPU\nglobal memory significantly, e.g., by more than 89\\%, compared to prior\nstate-of-the-art GPU implementations, resulting in significant performance\nimprovement that scales across successive hardware generations. Our prototype\nimplementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to\nVolta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards\nwith the same embedding quality. In-depth analysis indicates that the reduction\nof memory accesses through register and shared memory caching and\nhigh-throughput shared memory reduction leads to a significantly improved\narithmetic intensity. FULL-W2V can potentially benefit many applications in NLP\nand other domains.", "published": "2023-12-12 21:22:07", "link": "http://arxiv.org/abs/2312.07743v1", "categories": ["cs.LG", "cs.CL", "cs.DC", "I.2.7; D.1.3; G.4"], "primary_category": "cs.LG"}
{"title": "Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge\n  Gaps", "abstract": "The paper presents a methodology for uncovering knowledge gaps on the\ninternet using the Retrieval Augmented Generation (RAG) model. By simulating\nuser search behaviour, the RAG system identifies and addresses gaps in\ninformation retrieval systems. The study demonstrates the effectiveness of the\nRAG system in generating relevant suggestions with a consistent accuracy of\n93%. The methodology can be applied in various fields such as scientific\ndiscovery, educational enhancement, research development, market analysis,\nsearch engine optimisation, and content development. The results highlight the\nvalue of identifying and understanding knowledge gaps to guide future\nendeavours.", "published": "2023-12-12 23:22:57", "link": "http://arxiv.org/abs/2312.07796v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Exploring Graph Based Approaches for Author Name Disambiguation", "abstract": "In many applications, such as scientific literature management, researcher\nsearch, social network analysis and etc, Name Disambiguation (aiming at\ndisambiguating WhoIsWho) has been a challenging problem. In addition, the\ngrowth of scientific literature makes the problem more difficult and urgent.\nAlthough name disambiguation has been extensively studied in academia and\nindustry, the problem has not been solved well due to the clutter of data and\nthe complexity of the same name scenario. In this work, we aim to explore\nmodels that can perform the task of name disambiguation using the network\nstructure that is intrinsic to the problem and present an analysis of the\nmodels.", "published": "2023-12-12 12:13:22", "link": "http://arxiv.org/abs/2312.08388v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Toward a Reinforcement-Learning-Based System for Adjusting Medication to\n  Minimize Speech Disfluency", "abstract": "We propose a reinforcement learning (RL)-based system that would\nautomatically prescribe a hypothetical patient medication that may help the\npatient with their mental health-related speech disfluency, and adjust the\nmedication and the dosages in response to zero-cost frequent measurement of the\nfluency of the patient. We demonstrate the components of the system: a module\nthat detects and evaluates speech disfluency on a large dataset we built, and\nan RL algorithm that automatically finds good combinations of medications. To\nsupport the two modules, we collect data on the effect of psychiatric\nmedications for speech disfluency from the literature, and build a plausible\npatient simulation system. We demonstrate that the RL system is, under some\ncircumstances, able to converge to a good medication regime. We collect and\nlabel a dataset of people with possible speech disfluency and demonstrate our\nmethods using that dataset. Our work is a proof of concept: we show that there\nis promise in the idea of using automatic data collection to address speech\ndisfluency.", "published": "2023-12-12 04:58:11", "link": "http://arxiv.org/abs/2312.11509v4", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ComplexityNet: Increasing LLM Inference Efficiency by Learning Task\n  Complexity", "abstract": "We present ComplexityNet, a streamlined language model designed for assessing\ntask complexity. This model predicts the likelihood of accurate output by\nvarious language models, each with different capabilities. Our initial\napplication of ComplexityNet involves the Mostly Basic Python Problems (MBPP)\ndataset. We pioneered the creation of the first set of labels to define task\ncomplexity. ComplexityNet achieved a notable 79% accuracy in determining task\ncomplexity, a significant improvement over the 34% accuracy of the original,\nnon fine-tuned model. Furthermore, ComplexityNet effectively reduces\ncomputational resource usage by 90% compared to using the highest complexity\nmodel, while maintaining a high code generation accuracy of 86.7%. This study\ndemonstrates that fine-tuning smaller models to categorize tasks based on their\ncomplexity can lead to a more balanced trade-off between accuracy and\nefficiency in the use of Large Language Models. Our findings suggest a\npromising direction for optimizing LLM applications, especially in\nresource-constrained environments.", "published": "2023-12-12 05:38:55", "link": "http://arxiv.org/abs/2312.11511v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory", "abstract": "Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nsubstantial computational and memory requirements present challenges,\nespecially for devices with limited DRAM capacity. This paper tackles the\nchallenge of efficiently running LLMs that exceed the available DRAM capacity\nby storing the model parameters in flash memory, but bringing them on demand to\nDRAM. Our method involves constructing an inference cost model that takes into\naccount the characteristics of flash memory, guiding us to optimize in two\ncritical areas: reducing the volume of data transferred from flash and reading\ndata in larger, more contiguous chunks. Within this hardware-informed\nframework, we introduce two principal techniques. First, \"windowing\"\nstrategically reduces data transfer by reusing previously activated neurons,\nand second, \"row-column bundling\", tailored to the sequential data access\nstrengths of flash memory, increases the size of data chunks read from flash\nmemory. These methods collectively enable running models up to twice the size\nof the available DRAM, with a 4-5x and 20-25x increase in inference speed\ncompared to naive loading approaches in CPU and GPU, respectively. Our\nintegration of sparsity awareness, context-adaptive loading, and a\nhardware-oriented design paves the way for effective inference of LLMs on\ndevices with limited memory.", "published": "2023-12-12 18:57:08", "link": "http://arxiv.org/abs/2312.11514v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "w2v-SELD: A Sound Event Localization and Detection Framework for\n  Self-Supervised Spatial Audio Pre-Training", "abstract": "Sound Event Detection and Localization (SELD) constitutes a complex task that\ndepends on extensive multichannel audio recordings with annotated sound events\nand their respective locations. In this paper, we introduce a self-supervised\napproach for SELD adapted from the pre-training methodology of wav2vec 2.0,\nwhich learns representations directly from raw audio data, eliminating the need\nfor supervision. By applying this approach to SELD, we can leverage a\nsubstantial amount of unlabeled 3D audio data to learn robust representations\nof sound events and their locations. Our method comprises two primary stages:\npre-training and fine-tuning. In the pre-training phase, unlabeled 3D audio\ndatasets are utilized to train our w2v-SELD model, capturing intricate\nhigh-level features and contextual information inherent in audio signals.\nSubsequently, in the fine-tuning stage, a smaller dataset with labeled SELD\ndata fine-tunes the pre-trained model. Experimental results on benchmark\ndatasets demonstrate the effectiveness of the proposed self-supervised approach\nfor SELD. The model surpasses baseline systems provided with the datasets and\nachieves competitive performance comparable to state-of-the-art supervised\nmethods. The code and pre-trained parameters of our w2v-SELD model are\navailable in this repository.", "published": "2023-12-12 00:37:24", "link": "http://arxiv.org/abs/2312.06907v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust End-to-End Diarization with Domain Adaptive Training and\n  Multi-Task Learning", "abstract": "Due to the scarcity of publicly available diarization data, the model\nperformance can be improved by training a single model with data from different\ndomains. In this work, we propose to incorporate domain information to train a\nsingle end-to-end diarization model for multiple domains. First, we employ\ndomain adaptive training with parameter-efficient adapters for on-the-fly model\nreconfiguration. Second, we introduce an auxiliary domain classification task\nto make the diarization model more domain-aware. For seen domains, the\ncombination of our proposed methods reduces the absolute DER from 17.66% to\n16.59% when compared with the baseline. During inference, adapters from\nground-truth domains are not available for unseen domains. We demonstrate our\nmodel exhibits a stronger generalizability to unseen domains when adapters are\nremoved. For two unseen domains, this improves the DER performance from 39.91%\nto 23.09% and 25.32% to 18.76% over the baseline, respectively.", "published": "2023-12-12 10:15:12", "link": "http://arxiv.org/abs/2312.07136v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "NeuroHeed+: Improving Neuro-steered Speaker Extraction with Joint\n  Auditory Attention Detection", "abstract": "Neuro-steered speaker extraction aims to extract the listener's\nbrain-attended speech signal from a multi-talker speech signal, in which the\nattention is derived from the cortical activity. This activity is usually\nrecorded using electroencephalography (EEG) devices. Though promising, current\nmethods often have a high speaker confusion error, where the interfering\nspeaker is extracted instead of the attended speaker, degrading the listening\nexperience. In this work, we aim to reduce the speaker confusion error in the\nneuro-steered speaker extraction model through a jointly fine-tuned auxiliary\nauditory attention detection model. The latter reinforces the consistency\nbetween the extracted target speech signal and the EEG representation, and also\nimproves the EEG representation. Experimental results show that the proposed\nnetwork significantly outperforms the baseline in terms of speaker confusion\nand overall signal quality in two-talker scenarios.", "published": "2023-12-12 18:45:35", "link": "http://arxiv.org/abs/2312.07513v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LSTM-CNN Network for Audio Signature Analysis in Noisy Environments", "abstract": "There are multiple applications to automatically count people and specify\ntheir gender at work, exhibitions, malls, sales, and industrial usage. Although\ncurrent speech detection methods are supposed to operate well, in most\nsituations, in addition to genders, the number of current speakers is unknown\nand the classification methods are not suitable due to many possible classes.\nIn this study, we focus on a long-short-term memory convolutional neural\nnetwork (LSTM-CNN) to extract time and / or frequency-dependent features of the\nsound data to estimate the number / gender of simultaneous active speakers at\neach frame in noisy environments. Considering the maximum number of speakers as\n10, we have utilized 19000 audio samples with diverse combinations of males,\nfemales, and background noise in public cities, industrial situations, malls,\nexhibitions, workplaces, and nature for learning purposes. This proof of\nconcept shows promising performance with training/validation MSE values of\nabout 0.019/0.017 in detecting count and gender.", "published": "2023-12-12 08:26:20", "link": "http://arxiv.org/abs/2312.07059v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "More than Vanilla Fusion: a Simple, Decoupling-free, Attention Module\n  for Multimodal Fusion Based on Signal Theory", "abstract": "The vanilla fusion methods still dominate a large percentage of mainstream\naudio-visual tasks. However, the effectiveness of vanilla fusion from a\ntheoretical perspective is still worth discussing. Thus, this paper reconsiders\nthe signal fused in the multimodal case from a bionics perspective and proposes\na simple, plug-and-play, attention module for vanilla fusion based on\nfundamental signal theory and uncertainty theory. In addition, previous work on\nmultimodal dynamic gradient modulation still relies on decoupling the\nmodalities. So, a decoupling-free gradient modulation scheme has been designed\nin conjunction with the aforementioned attention module, which has various\nadvantages over the decoupled one. Experiment results show that just a few\nlines of code can achieve up to 2.0% performance improvements to several\nmultimodal classification methods. Finally, quantitative evaluation of other\nfusion tasks reveals the potential for additional application scenarios.", "published": "2023-12-12 12:22:36", "link": "http://arxiv.org/abs/2312.07212v1", "categories": ["cs.MM", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Reacting like Humans: Incorporating Intrinsic Human Behaviors into NAO\n  through Sound-Based Reactions to Fearful and Shocking Events for Enhanced\n  Sociability", "abstract": "Robots' acceptability among humans and their sociability can be significantly\nenhanced by incorporating human-like reactions. Humans can react to\nenvironmental events very quickly and without thinking. An instance where\nhumans show natural reactions is when they encounter a sudden and loud sound\nthat startles or frightens them. During such moments, individuals may\ninstinctively move their hands, turn toward the origin of the sound, and try to\ndetermine the event's cause. This inherent behavior motivated us to explore\nthis less-studied part of social robotics. In this work, a multi-modal system\ncomposed of an action generator, sound classifier, and YOLO object detector was\ndesigned to sense the environment and, in the presence of sudden loud sounds,\nshow natural human fear reactions; and finally, locate the fear-causing sound\nsource in the environment. These valid generated motions and inferences could\nimitate intrinsic human reactions and enhance the sociability of robots. For\nmotion generation, a model based on LSTM and MDN networks was proposed to\nsynthesize various motions. Also, in the case of sound detection, a transfer\nlearning model was preferred that used the spectrogram of the sound signals as\nits input. After developing individual models for sound detection, motion\ngeneration, and image recognition, they were integrated into a comprehensive\n\"fear\" module implemented on the NAO robot. Finally, the fear module was tested\nin practical application and two groups of experts and non-experts (in the\nrobotics area) filled out a questionnaire to evaluate the performance of the\nrobot. We indicated that the proposed module could convince the participants\nthat the Nao robot acts and reasons like a human when a sudden and loud sound\nis in the robot's peripheral environment, and additionally showed that\nnon-experts have higher expectations about social robots and their performance.", "published": "2023-12-12 19:06:44", "link": "http://arxiv.org/abs/2312.07671v2", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SD", "eess.AS", "eess.IV", "68T40"], "primary_category": "cs.RO"}
