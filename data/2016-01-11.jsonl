{"title": "Argumentation Mining in User-Generated Web Discourse", "abstract": "The goal of argumentation mining, an evolving research field in computational\nlinguistics, is to design methods capable of analyzing people's argumentation.\nIn this article, we go beyond the state of the art in several ways. (i) We deal\nwith actual Web data and take up the challenges given by the variety of\nregisters, multiple domains, and unrestricted noisy user-generated Web\ndiscourse. (ii) We bridge the gap between normative argumentation theories and\nargumentation phenomena encountered in actual data by adapting an argumentation\nmodel tested in an extensive annotation study. (iii) We create a new gold\nstandard corpus (90k tokens in 340 documents) and experiment with several\nmachine learning methods to identify argument components. We offer the data,\nsource codes, and annotation guidelines to the community under free licenses.\nOur findings show that argumentation mining in user-generated Web discourse is\na feasible but challenging task.", "published": "2016-01-11 11:28:49", "link": "http://arxiv.org/abs/1601.02403v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effects of Age, Gender and Region on Non-standard Linguistic\n  Variation in Online Social Networks", "abstract": "We present a corpus-based analysis of the effects of age, gender and region\nof origin on the production of both \"netspeak\" or \"chatspeak\" features and\nregional speech features in Flemish Dutch posts that were collected from a\nBelgian online social network platform. The present study shows that combining\nquantitative and qualitative approaches is essential for understanding\nnon-standard linguistic variation in a CMC corpus. It also presents a\nmethodology that enables the systematic study of this variation by including\nall non-standard words in the corpus. The analyses resulted in a convincing\nillustration of the Adolescent Peak Principle. In addition, our approach\nrevealed an intriguing correlation between the use of regional speech features\nand chatspeak features.", "published": "2016-01-11 13:02:59", "link": "http://arxiv.org/abs/1601.02431v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trans-gram, Fast Cross-lingual Word-embeddings", "abstract": "We introduce Trans-gram, a simple and computationally-efficient method to\nsimultaneously learn and align wordembeddings for a variety of languages, using\nonly monolingual data and a smaller set of sentence-aligned data. We use our\nnew method to compute aligned wordembeddings for twenty-one languages using\nEnglish as a pivot language. We show that some linguistic features are aligned\nacross languages for which we do not have aligned data, even though those\nproperties do not exist in the pivot language. We also achieve state of the art\nresults on standard cross-lingual text classification and word translation\ntasks.", "published": "2016-01-11 16:12:32", "link": "http://arxiv.org/abs/1601.02502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Environmental Noise Embeddings for Robust Speech Recognition", "abstract": "We propose a novel deep neural network architecture for speech recognition\nthat explicitly employs knowledge of the background environmental noise within\na deep neural network acoustic model. A deep neural network is used to predict\nthe acoustic environment in which the system in being used. The discriminative\nembedding generated at the bottleneck layer of this network is then\nconcatenated with traditional acoustic features as input to a deep neural\nnetwork acoustic model. Through a series of experiments on Resource Management,\nCHiME-3 task, and Aurora4, we show that the proposed approach significantly\nimproves speech recognition accuracy in noisy and highly reverberant\nenvironments, outperforming multi-condition training, noise-aware training,\ni-vector framework, and multi-task learning on both in-domain noise and unseen\nnoise.", "published": "2016-01-11 18:38:18", "link": "http://arxiv.org/abs/1601.02553v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating gated recurrent neural networks for speech synthesis", "abstract": "Recently, recurrent neural networks (RNNs) as powerful sequence models have\nre-emerged as a potential acoustic model for statistical parametric speech\nsynthesis (SPSS). The long short-term memory (LSTM) architecture is\nparticularly attractive because it addresses the vanishing gradient problem in\nstandard RNNs, making them easier to train. Although recent studies have\ndemonstrated that LSTMs can achieve significantly better performance on SPSS\nthan deep feed-forward neural networks, little is known about why. Here we\nattempt to answer two questions: a) why do LSTMs work well as a sequence model\nfor SPSS; b) which component (e.g., input gate, output gate, forget gate) is\nmost important. We present a visual analysis alongside a series of experiments,\nresulting in a proposal for a simplified architecture. The simplified\narchitecture has significantly fewer parameters than an LSTM, thus reducing\ngeneration complexity considerably without degrading quality.", "published": "2016-01-11 17:54:53", "link": "http://arxiv.org/abs/1601.02539v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Evaluating the Performance of a Speech Recognition based System", "abstract": "Speech based solutions have taken center stage with growth in the services\nindustry where there is a need to cater to a very large number of people from\nall strata of the society. While natural language speech interfaces are the\ntalk in the research community, yet in practice, menu based speech solutions\nthrive. Typically in a menu based speech solution the user is required to\nrespond by speaking from a closed set of words when prompted by the system. A\nsequence of human speech response to the IVR prompts results in the completion\nof a transaction. A transaction is deemed successful if the speech solution can\ncorrectly recognize all the spoken utterances of the user whenever prompted by\nthe system. The usual mechanism to evaluate the performance of a speech\nsolution is to do an extensive test of the system by putting it to actual\npeople use and then evaluating the performance by analyzing the logs for\nsuccessful transactions. This kind of evaluation could lead to dissatisfied\ntest users especially if the performance of the system were to result in a poor\ntransaction completion rate. To negate this the Wizard of Oz approach is\nadopted during evaluation of a speech system. Overall this kind of evaluations\nis an expensive proposition both in terms of time and cost. In this paper, we\npropose a method to evaluate the performance of a speech solution without\nactually putting it to people use. We first describe the methodology and then\nshow experimentally that this can be used to identify the performance\nbottlenecks of the speech solution even before the system is actually used thus\nsaving evaluation time and expenses.", "published": "2016-01-11 18:01:56", "link": "http://arxiv.org/abs/1601.02543v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
