{"title": "Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms\n  in Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\ndiverse tasks and exhibited impressive reasoning abilities by applying\nzero-shot Chain-of-Thought (CoT) prompting. However, due to the evolving nature\nof sentence prefixes during the pre-training phase, existing zero-shot CoT\nprompting methods that employ identical CoT prompting across all task instances\nmay not be optimal. In this paper, we introduce a novel zero-shot prompting\nmethod that leverages evolutionary algorithms to generate diverse promptings\nfor LLMs dynamically. Our approach involves initializing two CoT promptings,\nperforming evolutionary operations based on LLMs to create a varied set, and\nutilizing the LLMs to select a suitable CoT prompting for a given problem.\nAdditionally, a rewriting operation, guided by the selected CoT prompting,\nenhances the understanding of the LLMs about the problem. Extensive experiments\nconducted across ten reasoning datasets demonstrate the superior performance of\nour proposed method compared to current zero-shot CoT prompting methods on\nGPT-3.5-turbo and GPT-4. Moreover, in-depth analytical experiments underscore\nthe adaptability and effectiveness of our method in various reasoning tasks.", "published": "2024-02-08 03:17:38", "link": "http://arxiv.org/abs/2402.05376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Agent Interactions in Virtual Environments with Language\n  Models", "abstract": "Enhancing AI systems with efficient communication skills for effective human\nassistance necessitates proactive initiatives from the system side to discern\nspecific circumstances and interact aptly. This research focuses on a\ncollective building assignment in the Minecraft dataset, employing language\nmodeling to enhance task understanding through state-of-the-art methods. These\nmodels focus on grounding multi-modal understanding and task-oriented dialogue\ncomprehension tasks, providing insights into their interpretative and\nresponsive capabilities. Our experimental results showcase a substantial\nimprovement over existing methods, indicating a promising direction for future\nresearch in this domain.", "published": "2024-02-08 06:34:11", "link": "http://arxiv.org/abs/2402.05440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Psycholinguistic Plausibility Pretesting", "abstract": "In psycholinguistics, the creation of controlled materials is crucial to\nensure that research outcomes are solely attributed to the intended\nmanipulations and not influenced by extraneous factors. To achieve this,\npsycholinguists typically pretest linguistic materials, where a common pretest\nis to solicit plausibility judgments from human evaluators on specific\nsentences. In this work, we investigate whether Language Models (LMs) can be\nused to generate these plausibility judgements. We investigate a wide range of\nLMs across multiple linguistic structures and evaluate whether their\nplausibility judgements correlate with human judgements. We find that GPT-4\nplausibility judgements highly correlate with human judgements across the\nstructures we examine, whereas other LMs correlate well with humans on commonly\nused syntactic structures. We then test whether this correlation implies that\nLMs can be used instead of humans for pretesting. We find that when\ncoarse-grained plausibility judgements are needed, this works well, but when\nfine-grained judgements are necessary, even GPT-4 does not provide satisfactory\ndiscriminative power.", "published": "2024-02-08 07:20:02", "link": "http://arxiv.org/abs/2402.05455v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition for Address Extraction in Speech-to-Text\n  Transcriptions Using Synthetic Data", "abstract": "This paper introduces an approach for building a Named Entity Recognition\n(NER) model built upon a Bidirectional Encoder Representations from\nTransformers (BERT) architecture, specifically utilizing the SlovakBERT model.\nThis NER model extracts address parts from data acquired from speech-to-text\ntranscriptions. Due to scarcity of real data, a synthetic dataset using GPT API\nwas generated. The importance of mimicking spoken language variability in this\nartificial data is emphasized. The performance of our NER model, trained solely\non synthetic data, is evaluated using small real test dataset.", "published": "2024-02-08 10:29:11", "link": "http://arxiv.org/abs/2402.05545v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Deep Learning-based Computational Job Market Analysis: A Survey on Skill\n  Extraction and Classification from Job Postings", "abstract": "Recent years have brought significant advances to Natural Language Processing\n(NLP), which enabled fast progress in the field of computational job market\nanalysis. Core tasks in this application domain are skill extraction and\nclassification from job postings. Because of its quick growth and its\ninterdisciplinary nature, there is no exhaustive assessment of this emerging\nfield. This survey aims to fill this gap by providing a comprehensive overview\nof deep learning methodologies, datasets, and terminologies specific to\nNLP-driven skill extraction and classification. Our comprehensive cataloging of\npublicly available datasets addresses the lack of consolidated information on\ndataset creation and characteristics. Finally, the focus on terminology\naddresses the current lack of consistent definitions for important concepts,\nsuch as hard and soft skills, and terms relating to skill extraction and\nclassification.", "published": "2024-02-08 12:20:28", "link": "http://arxiv.org/abs/2402.05617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature\n  of Aggregated Factual Claims in Long-Form Generations", "abstract": "Long-form generations from large language models (LLMs) contain a mix of\nfactual and non-factual claims, making evaluating factuality difficult. Prior\nworks evaluate the factuality of a long paragraph by decomposing it into\nmultiple facts, verifying those facts independently, and aggregating the\nresults. Such methods assume that combining factual claims forms a factual\nparagraph. The above assumption can be violated: we show that strong\nopen-source models like Llama-chat can generate paragraphs that contain\nverifiable facts, but the facts are combined into a non-factual paragraph due\nto entity ambiguity. We further reveal that existing factuality metrics,\nincluding FActScore and citation recall, cannot properly evaluate these\nnon-factual paragraphs and overestimate their factuality. To address this, we\nintroduce an enhanced metric, D-FActScore, specifically designed for content\nwith ambiguous entities. We evaluate the D-FActScores of people biographies\ngenerated by retrieval-augmented LLMs. We show that D-FActScore can better\nassess the factuality of paragraphs with entity ambiguity than FActScore. We\nalso find that four widely used open-source LLMs tend to mix information of\ndistinct entities to form non-factual paragraphs, making their D-FActScore much\nlower than FActScore by over 10%.", "published": "2024-02-08 12:36:29", "link": "http://arxiv.org/abs/2402.05629v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TimeArena: Shaping Efficient Multitasking Language Agents in a\n  Time-Aware Simulation", "abstract": "Despite remarkable advancements in emulating human-like behavior through\nLarge Language Models (LLMs), current textual simulations do not adequately\naddress the notion of time. To this end, we introduce TimeArena, a novel\ntextual simulated environment that incorporates complex temporal dynamics and\nconstraints that better reflect real-life planning scenarios. In TimeArena,\nagents are asked to complete multiple tasks as soon as possible, allowing for\nparallel processing to save time. We implement the dependency between actions,\nthe time duration for each action, and the occupancy of the agent and the\nobjects in the environment. TimeArena grounds to 30 real-world tasks in\ncooking, household activities, and laboratory work. We conduct extensive\nexperiments with various state-of-the-art LLMs using TimeArena. Our findings\nreveal that even the most powerful models, e.g., GPT-4, still lag behind humans\nin effective multitasking, underscoring the need for enhanced temporal\nawareness in the development of language agents.", "published": "2024-02-08 15:08:57", "link": "http://arxiv.org/abs/2402.05733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text-to-Code Generation with Modality-relative Pre-training", "abstract": "Large pre-trained language models have recently been expanded and applied to\nprogramming language tasks with great success, often through further\npre-training of a strictly-natural language model--where training sequences\ntypically contain both natural and (linearised) programming language. Such\napproaches effectively map both modalities of the sequence into the same\nembedding space. However, programming language keywords (e.g. \"while\") often\nhave very strictly defined semantics. As such, transfer learning from their\nnatural language usage may not necessarily be beneficial to their code\napplication and vise versa. Assuming an already pre-trained language model, in\nthis work we investigate how sequence tokens can be adapted and represented\ndifferently, depending on which modality they belong to, and to the ultimate\nbenefit of the downstream task. We experiment with separating embedding spaces\nbetween modalities during further model pre-training with modality-relative\ntraining objectives. We focus on text-to-code generation and observe consistent\nimprovements across two backbone models and two test sets, measuring pass@$k$\nand a novel incremental variation.", "published": "2024-02-08 16:17:24", "link": "http://arxiv.org/abs/2402.05783v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FAQ-Gen: An automated system to generate domain-specific FAQs to aid\n  content comprehension", "abstract": "Frequently Asked Questions (FAQs) refer to the most common inquiries about\nspecific content. They serve as content comprehension aids by simplifying\ntopics and enhancing understanding through succinct presentation of\ninformation. In this paper, we address FAQ generation as a well-defined Natural\nLanguage Processing task through the development of an end-to-end system\nleveraging text-to-text transformation models. We present a literature review\ncovering traditional question-answering systems, highlighting their limitations\nwhen applied directly to the FAQ generation task. We propose a system capable\nof building FAQs from textual content tailored to specific domains, enhancing\ntheir accuracy and relevance. We utilise self-curated algorithms to obtain an\noptimal representation of information to be provided as input and also to rank\nthe question-answer pairs to maximise human comprehension. Qualitative human\nevaluation showcases the generated FAQs as well-constructed and readable while\nalso utilising domain-specific constructs to highlight domain-based nuances and\njargon in the original content.", "published": "2024-02-08 16:49:41", "link": "http://arxiv.org/abs/2402.05812v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Robustness of Editing Large Language Models", "abstract": "Large language models (LLMs) have played a pivotal role in building\ncommunicative AI, yet they encounter the challenge of efficient updates. Model\nediting enables the manipulation of specific knowledge memories and the\nbehavior of language generation without retraining. However, the robustness of\nmodel editing remains an open question. This work seeks to understand the\nstrengths and limitations of editing methods, facilitating practical\napplications of communicative AI. We focus on three key research questions.\nRQ1: Can edited LLMs behave consistently resembling communicative AI in\nrealistic situations? RQ2: To what extent does the rephrasing of prompts lead\nLLMs to deviate from the edited knowledge memory? RQ3: Which knowledge features\nare correlated with the performance and robustness of editing? Our empirical\nstudies uncover a substantial disparity between existing editing methods and\nthe practical application of LLMs. On rephrased prompts that are flexible but\ncommon in realistic applications, the performance of editing experiences a\nsignificant decline. Further analysis shows that more popular knowledge is\nmemorized better, easier to recall, and more challenging to edit effectively.\nCode is publicly available at https://github.com/xbmxb/edit_analysis .", "published": "2024-02-08 17:06:45", "link": "http://arxiv.org/abs/2402.05827v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Prompt Response to the Demand for Automatic Gender-Neutral Translation", "abstract": "Gender-neutral translation (GNT) that avoids biased and undue binary\nassumptions is a pivotal challenge for the creation of more inclusive\ntranslation technologies. Advancements for this task in Machine Translation\n(MT), however, are hindered by the lack of dedicated parallel data, which are\nnecessary to adapt MT systems to satisfy neutral constraints. For such a\nscenario, large language models offer hitherto unforeseen possibilities, as\nthey come with the distinct advantage of being versatile in various (sub)tasks\nwhen provided with explicit instructions. In this paper, we explore this\npotential to automate GNT by comparing MT with the popular GPT-4 model. Through\nextensive manual analyses, our study empirically reveals the inherent\nlimitations of current MT systems in generating GNTs and provides valuable\ninsights into the potential and challenges associated with prompting for\nneutrality.", "published": "2024-02-08 20:24:44", "link": "http://arxiv.org/abs/2402.06041v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Data Selection for Supervised Fine-Tuning", "abstract": "Although supervised finetuning (SFT) has emerged as an essential technique to\nalign large language models with humans, it is considered superficial, with\nstyle learning being its nature. At the same time, recent works indicate the\nimportance of data selection for SFT, showing that finetuning with high-quality\nand diverse subsets of the original dataset leads to superior downstream\nperformance. In this work, we rethink the intuition behind data selection for\nSFT. Considering SFT is superficial, we propose that essential demonstrations\nfor SFT should focus on reflecting human-like interactions instead of data\nquality or diversity. However, it is not straightforward to directly assess to\nwhat extent a demonstration reflects human styles. Towards an initial attempt\nin this direction, we find selecting instances with long responses is\nsurprisingly more effective for SFT than utilizing full datasets or instances\nselected based on quality and diversity. We hypothesize that such a simple\nheuristic implicitly mimics a crucial aspect of human-style conversation:\ndetailed responses are usually more helpful.", "published": "2024-02-08 23:02:04", "link": "http://arxiv.org/abs/2402.06094v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Noise Contrastive Alignment of Language Models with Explicit Rewards", "abstract": "User intentions are typically formalized as evaluation rewards to be\nmaximized when fine-tuning language models (LMs). Existing alignment methods,\nsuch as Direct Preference Optimization (DPO), are mainly tailored for pairwise\npreference data where rewards are implicitly defined rather than explicitly\ngiven. In this paper, we introduce a general framework for LM alignment,\nleveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling\nreward datasets explicitly annotated with scalar evaluations. Our framework\ncomprises two parallel algorithms, NCA and InfoNCA, both enabling the direct\nextraction of an LM policy from reward data as well as preference data.\nNotably, we show that the DPO loss is a special case of our proposed InfoNCA\nobjective under pairwise preference settings, thereby integrating and extending\ncurrent alignment theories. By comparing NCA and InfoNCA, we demonstrate that\nthe well-observed decreasing-likelihood trend of DPO/InfoNCA is caused by their\nfocus on adjusting relative likelihood across different responses. In contrast,\nNCA optimizes the absolute likelihood for each response, thereby effectively\npreventing the chosen likelihood from decreasing. We evaluate our methods in\nboth reward and preference settings with Mistral-8*7B and 7B models.\nExperiments suggest that InfoNCA/NCA surpasses various preference baselines\nwhen reward datasets are available. We also find NCA significantly outperforms\nDPO in complex reasoning tasks like math and coding.", "published": "2024-02-08 02:58:47", "link": "http://arxiv.org/abs/2402.05369v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "In-Context Principle Learning from Mistakes", "abstract": "In-context learning (ICL, also known as few-shot prompting) has been the\nstandard method of adapting LLMs to downstream tasks, by learning from a few\ninput-output examples. Nonetheless, all ICL-based approaches only learn from\ncorrect input-output pairs. In this paper, we revisit this paradigm, by\nlearning more from the few given input-output examples. We introduce Learning\nPrinciples (LEAP): First, we intentionally induce the model to make mistakes on\nthese few examples; then we reflect on these mistakes, and learn explicit\ntask-specific \"principles\" from them, which help solve similar problems and\navoid common mistakes; finally, we prompt the model to answer unseen test\nquestions using the original few-shot examples and these learned general\nprinciples. We evaluate LEAP on a wide range of benchmarks, including multi-hop\nquestion answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning,\nand math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the\nstrongest available LLMs such as GPT-3.5-turbo, GPT-4, GPT-4 turbo and\nClaude-2.1. For example, LEAP improves over the standard few-shot prompting\nusing GPT-4 by 7.5% in DROP, and by 3.3% in HotpotQA. Importantly, LEAP does\nnot require any more input or examples than the standard few-shot prompting\nsettings.", "published": "2024-02-08 04:42:29", "link": "http://arxiv.org/abs/2402.05403v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes", "abstract": "Given the generational gap in available hardware between lay practitioners\nand the most endowed institutions, LLMs are becoming increasingly inaccessible\nas they grow in size. Whilst many approaches have been proposed to compress\nLLMs to make their resource consumption manageable, these methods themselves\ntend to be resource intensive, putting them out of the reach of the very user\ngroups they target. In this work, we explore the problem of structured pruning\nof LLMs using only forward passes. We seek to empower practitioners to prune\nmodels so large that their available hardware has just enough memory to run\ninference. We develop Bonsai, a gradient-free, perturbative pruning method\ncapable of delivering small, fast, and accurate pruned models.\n  We observe that Bonsai outputs pruned models that (i) outperform those\ngenerated by more expensive gradient-based structured pruning methods, and (ii)\nare twice as fast (with comparable accuracy) as those generated by\nsemi-structured pruning methods requiring comparable resources as Bonsai. We\nalso leverage Bonsai to produce a new sub-2B model using a single A6000 that\nyields state-of-the-art performance on 4/6 tasks on the Huggingface Open LLM\nleaderboard.", "published": "2024-02-08 04:48:26", "link": "http://arxiv.org/abs/2402.05406v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Accurate LoRA-Finetuning Quantization of LLMs via Information Retention", "abstract": "The LoRA-finetuning quantization of LLMs has been extensively studied to\nobtain accurate yet compact LLMs for deployment on resource-constrained\nhardware. However, existing methods cause the quantized LLM to severely degrade\nand even fail to benefit from the finetuning of LoRA. This paper proposes a\nnovel IR-QLoRA for pushing quantized LLMs with LoRA to be highly accurate\nthrough information retention. The proposed IR-QLoRA mainly relies on two\ntechnologies derived from the perspective of unified information: (1)\nstatistics-based Information Calibration Quantization allows the quantized\nparameters of LLM to retain original information accurately; (2)\nfinetuning-based Information Elastic Connection makes LoRA utilizes elastic\nrepresentation transformation with diverse information. Comprehensive\nexperiments show that IR-QLoRA can significantly improve accuracy across LLaMA\nand LLaMA2 families under 2-4 bit-widths, e.g., 4- bit LLaMA-7B achieves 1.4%\nimprovement on MMLU compared with the state-of-the-art methods. The significant\nperformance gain requires only a tiny 0.31% additional time consumption,\nrevealing the satisfactory efficiency of our IR-QLoRA. We highlight that\nIR-QLoRA enjoys excellent versatility, compatible with various frameworks\n(e.g., NormalFloat and Integer quantization) and brings general accuracy gains.\nThe code is available at https://github.com/htqin/ir-qlora.", "published": "2024-02-08 06:53:31", "link": "http://arxiv.org/abs/2402.05445v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GPTs Are Multilingual Annotators for Sequence Generation Tasks", "abstract": "Data annotation is an essential step for constructing new datasets. However,\nthe conventional approach of data annotation through crowdsourcing is both\ntime-consuming and expensive. In addition, the complexity of this process\nincreases when dealing with low-resource languages owing to the difference in\nthe language pool of crowdworkers. To address these issues, this study proposes\nan autonomous annotation method by utilizing large language models, which have\nbeen recently demonstrated to exhibit remarkable performance. Through our\nexperiments, we demonstrate that the proposed method is not just cost-efficient\nbut also applicable for low-resource language annotation. Additionally, we\nconstructed an image captioning dataset using our approach and are committed to\nopen this dataset for future study. We have opened our source code for further\nstudy and reproducibility.", "published": "2024-02-08 09:44:02", "link": "http://arxiv.org/abs/2402.05512v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NoisyICL: A Little Noise in Model Parameters Calibrates In-context\n  Learning", "abstract": "In-Context Learning (ICL) is suffering from unsatisfactory performance and\nunder-calibration due to high prior bias and unfaithful confidence. Some\nprevious works fine-tuned language models for better ICL performance with\nenormous datasets and computing costs. In this paper, we propose NoisyICL,\nsimply perturbing the model parameters by random noises to strive for better\nperformance and calibration. Our experiments on two models and 12 downstream\ndatasets show that NoisyICL can help ICL produce more accurate predictions. Our\nfurther analysis indicates that NoisyICL enables the model to provide more fair\npredictions, and also with more faithful confidence. Therefore, we believe that\nNoisyICL is an effective calibration of ICL. Our experimental code is uploaded\nto Github.", "published": "2024-02-08 09:48:02", "link": "http://arxiv.org/abs/2402.05515v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering machine learning models with contextual knowledge for\n  enhancing the detection of eating disorders in social media posts", "abstract": "Social networks are vital for information sharing, especially in the health\nsector for discussing diseases and treatments. These platforms, however, often\nfeature posts as brief texts, posing challenges for Artificial Intelligence\n(AI) in understanding context. We introduce a novel hybrid approach combining\ncommunity-maintained knowledge graphs (like Wikidata) with deep learning to\nenhance the categorization of social media posts. This method uses advanced\nentity recognizers and linkers (like Falcon 2.0) to connect short post entities\nto knowledge graphs. Knowledge graph embeddings (KGEs) and contextualized word\nembeddings (like BERT) are then employed to create rich, context-based\nrepresentations of these posts.\n  Our focus is on the health domain, particularly in identifying posts related\nto eating disorders (e.g., anorexia, bulimia) to aid healthcare providers in\nearly diagnosis. We tested our approach on a dataset of 2,000 tweets about\neating disorders, finding that merging word embeddings with knowledge graph\ninformation enhances the predictive models' reliability. This methodology aims\nto assist health experts in spotting patterns indicative of mental disorders,\nthereby improving early detection and accurate diagnosis for personalized\nmedicine.", "published": "2024-02-08 10:15:41", "link": "http://arxiv.org/abs/2402.05536v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Benchmarking Large Language Models on Communicative Medical Coaching: a\n  Novel System and Dataset", "abstract": "Traditional applications of natural language processing (NLP) in healthcare\nhave predominantly focused on patient-centered services, enhancing patient\ninteractions and care delivery, such as through medical dialogue systems.\nHowever, the potential of NLP to benefit inexperienced doctors, particularly in\nareas such as communicative medical coaching, remains largely unexplored. We\nintroduce \"ChatCoach\", a human-AI cooperative framework designed to assist\nmedical learners in practicing their communication skills during patient\nconsultations. ChatCoach (Our data and code are available online:\nhttps://github.com/zerowst/Chatcoach)differentiates itself from conventional\ndialogue systems by offering a simulated environment where medical learners can\npractice dialogues with a patient agent, while a coach agent provides\nimmediate, structured feedback. This is facilitated by our proposed Generalized\nChain-of-Thought (GCoT) approach, which fosters the generation of structured\nfeedback and enhances the utilization of external knowledge sources.\nAdditionally, we have developed a dataset specifically for evaluating Large\nLanguage Models (LLMs) within the ChatCoach framework on communicative medical\ncoaching tasks. Our empirical results validate the effectiveness of ChatCoach.", "published": "2024-02-08 10:32:06", "link": "http://arxiv.org/abs/2402.05547v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Traditional Machine Learning Models and Bidirectional Encoder\n  Representations From Transformer (BERT)-Based Automatic Classification of\n  Tweets About Eating Disorders: Algorithm Development and Validation Study", "abstract": "Background: Eating disorders are increasingly prevalent, and social networks\noffer valuable information.\n  Objective: Our goal was to identify efficient machine learning models for\ncategorizing tweets related to eating disorders.\n  Methods: Over three months, we collected tweets about eating disorders. A\n2,000-tweet subset was labeled for: (1) being written by individuals with\neating disorders, (2) promoting eating disorders, (3) informativeness, and (4)\nscientific content. Both traditional machine learning and deep learning models\nwere employed for classification, assessing accuracy, F1 score, and\ncomputational time.\n  Results: From 1,058,957 collected tweets, transformer-based bidirectional\nencoder representations achieved the highest F1 scores (71.1%-86.4%) across all\nfour categories.\n  Conclusions: Transformer-based models outperform traditional techniques in\nclassifying eating disorder-related tweets, though they require more\ncomputational resources.", "published": "2024-02-08 11:16:13", "link": "http://arxiv.org/abs/2402.05571v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods\n  in Low-resource Regimes", "abstract": "Text data augmentation is a complex problem due to the discrete nature of\nsentences. Although rule-based augmentation methods are widely adopted in\nreal-world applications because of their simplicity, they suffer from potential\nsemantic damage. Previous researchers have suggested easy data augmentation\nwith soft labels (softEDA), employing label smoothing to mitigate this problem.\nHowever, finding the best factor for each model and dataset is challenging;\ntherefore, using softEDA in real-world applications is still difficult. In this\npaper, we propose adapting AutoAugment to solve this problem. The experimental\nresults suggest that the proposed method can boost existing augmentation\nmethods and that rule-based methods can enhance cutting-edge pre-trained\nlanguage models. We offer the source code.", "published": "2024-02-08 11:36:23", "link": "http://arxiv.org/abs/2402.05584v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels", "abstract": "Rule-based text data augmentation is widely used for NLP tasks due to its\nsimplicity. However, this method can potentially damage the original meaning of\nthe text, ultimately hurting the performance of the model. To overcome this\nlimitation, we propose a straightforward technique for applying soft labels to\naugmented data. We conducted experiments across seven different classification\ntasks and empirically demonstrated the effectiveness of our proposed approach.\nWe have publicly opened our source code for reproducibility.", "published": "2024-02-08 11:44:25", "link": "http://arxiv.org/abs/2402.05591v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual E5 Text Embeddings: A Technical Report", "abstract": "This technical report presents the training methodology and evaluation\nresults of the open-source multilingual E5 text embedding models, released in\nmid-2023. Three embedding models of different sizes (small / base / large) are\nprovided, offering a balance between the inference efficiency and embedding\nquality. The training procedure adheres to the English E5 model recipe,\ninvolving contrastive pre-training on 1 billion multilingual text pairs,\nfollowed by fine-tuning on a combination of labeled datasets. Additionally, we\nintroduce a new instruction-tuned embedding model, whose performance is on par\nwith state-of-the-art, English-only models of similar sizes. Information\nregarding the model release can be found at\nhttps://github.com/microsoft/unilm/tree/master/e5 .", "published": "2024-02-08 13:47:50", "link": "http://arxiv.org/abs/2402.05672v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Phonetically rich corpus construction for a low-resourced language", "abstract": "Speech technologies rely on capturing a speaker's voice variability while\nobtaining comprehensive language information. Textual prompts and sentence\nselection methods have been proposed in the literature to comprise such\nadequate phonetic data, referred to as a phonetically rich \\textit{corpus}.\nHowever, they are still insufficient for acoustic modeling, especially critical\nfor languages with limited resources. Hence, this paper proposes a novel\napproach and outlines the methodological aspects required to create a\n\\textit{corpus} with broad phonetic coverage for a low-resourced language,\nBrazilian Portuguese. Our methodology includes text dataset collection up to a\nsentence selection algorithm based on triphone distribution. Furthermore, we\npropose a new phonemic classification according to acoustic-articulatory speech\nfeatures since the absolute number of distinct triphones, or low-probability\ntriphones, does not guarantee an adequate representation of every possible\ncombination. Using our algorithm, we achieve a 55.8\\% higher percentage of\ndistinct triphones -- for samples of similar size -- while the currently\navailable phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in\ncomparison to a non-phonetically rich dataset.", "published": "2024-02-08 16:36:11", "link": "http://arxiv.org/abs/2402.05794v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Selective Forgetting: Advancing Machine Unlearning Techniques and\n  Evaluation in Language Models", "abstract": "This paper explores Machine Unlearning (MU), an emerging field that is\ngaining increased attention due to concerns about neural models unintentionally\nremembering personal or sensitive information. We present SeUL, a novel method\nthat enables selective and fine-grained unlearning for language models. Unlike\nprevious work that employs a fully reversed training objective in unlearning,\nSeUL minimizes the negative impact on the capability of language models,\nparticularly in terms of generation. Furthermore, we introduce two innovative\nevaluation metrics, sensitive extraction likelihood (S-EL) and sensitive\nmemorization accuracy (S-MA), specifically designed to assess the effectiveness\nof forgetting sensitive information. In support of the unlearning framework, we\npropose efficient automatic online and offline sensitive span annotation\nmethods. The online selection method, based on language probability scores,\nensures computational efficiency, while the offline annotation involves a\ntwo-stage LLM-based process for robust verification. In summary, this paper\ncontributes a novel selective unlearning method (SeUL), introduces specialized\nevaluation metrics (S-EL and S-MA) for assessing sensitive information\nforgetting, and proposes automatic online and offline sensitive span annotation\nmethods to support the overall unlearning framework and evaluation process.", "published": "2024-02-08 16:50:01", "link": "http://arxiv.org/abs/2402.05813v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Stagewise Pretraining via Progressive Subnetworks", "abstract": "Recent developments in large language models have sparked interest in\nefficient pretraining methods. Stagewise training approaches to improve\nefficiency, like gradual stacking and layer dropping (Reddi et al, 2023; Zhang\n& He, 2020), have recently garnered attention. The prevailing view suggests\nthat stagewise dropping strategies, such as layer dropping, are ineffective,\nespecially when compared to stacking-based approaches. This paper challenges\nthis notion by demonstrating that, with proper design, dropping strategies can\nbe competitive, if not better, than stacking methods. Specifically, we develop\na principled stagewise training framework, progressive subnetwork training,\nwhich only trains subnetworks within the model and progressively increases the\nsize of subnetworks during training, until it trains the full network. We\npropose an instantiation of this framework - Random Part Training (RAPTR) -\nthat selects and trains only a random subnetwork (e.g. depth-wise, width-wise)\nof the network at each step, progressively increasing the size in stages. We\nshow that this approach not only generalizes prior works like layer dropping\nbut also fixes their key issues. Furthermore, we establish a theoretical basis\nfor such approaches and provide justification for (a) increasing complexity of\nsubnetworks in stages, conceptually diverging from prior works on layer\ndropping, and (b) stability in loss across stage transitions in presence of key\nmodern architecture components like residual connections and layer norms.\nThrough comprehensive experiments, we demonstrate that RAPTR can significantly\nspeed up training of standard benchmarks like BERT and UL2, up to 33% compared\nto standard training and, surprisingly, also shows better downstream\nperformance on UL2, improving QA tasks and SuperGLUE by 1.5%; thereby,\nproviding evidence of better inductive bias.", "published": "2024-02-08 18:49:09", "link": "http://arxiv.org/abs/2402.05913v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Convergence of Zeroth-Order Federated Tuning for Large Language\n  Models", "abstract": "The confluence of Federated Learning (FL) and Large Language Models (LLMs) is\nushering in a new era in privacy-preserving natural language processing.\nHowever, the intensive memory requirements for fine-tuning LLMs pose\nsignificant challenges, especially when deploying on clients with limited\ncomputational resources. To circumvent this, we explore the novel integration\nof Memory-efficient Zeroth-Order Optimization within a federated setting, a\nsynergy we term as FedMeZO. Our study is the first to examine the theoretical\nunderpinnings of FedMeZO in the context of LLMs, tackling key questions\nregarding the influence of large parameter spaces on optimization behavior, the\nestablishment of convergence properties, and the identification of critical\nparameters for convergence to inform personalized federated strategies. Our\nextensive empirical evidence supports the theory, showing that FedMeZO not only\nconverges faster than traditional first-order methods such as FedAvg but also\nsignificantly reduces GPU memory usage during training to levels comparable to\nthose during inference. Moreover, the proposed personalized FL strategy that is\nbuilt upon the theoretical insights to customize the client-wise learning rate\ncan effectively accelerate loss reduction. We hope our work can help to bridge\ntheoretical and practical aspects of federated fine-tuning for LLMs, thereby\nstimulating further advancements and research in this area.", "published": "2024-02-08 18:56:40", "link": "http://arxiv.org/abs/2402.05926v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing", "abstract": "Pretrained large Vision-Language models have drawn considerable interest in\nrecent years due to their remarkable performance. Despite considerable efforts\nto assess these models from diverse perspectives, the extent of visual cultural\nawareness in the state-of-the-art GPT-4V model remains unexplored. To tackle\nthis gap, we extensively probed GPT-4V using the MaRVL benchmark dataset,\naiming to investigate its capabilities and limitations in visual understanding\nwith a focus on cultural aspects. Specifically, we introduced three visual\nrelated tasks, i.e. caption classification, pairwise captioning, and culture\ntag selection, to systematically delve into fine-grained visual cultural\nevaluation. Experimental results indicate that GPT-4V excels at identifying\ncultural concepts but still exhibits weaker performance in low-resource\nlanguages, such as Tamil and Swahili. Notably, through human evaluation, GPT-4V\nproves to be more culturally relevant in image captioning tasks than the\noriginal MaRVL human annotations, suggesting a promising solution for future\nvisual cultural benchmark construction.", "published": "2024-02-08 19:25:40", "link": "http://arxiv.org/abs/2402.06015v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Doing Experiments and Revising Rules with Natural Language and\n  Probabilistic Reasoning", "abstract": "We give a model of how to infer natural language rules by doing experiments.\nThe model integrates Large Language Models (LLMs) with Monte Carlo algorithms\nfor probabilistic inference, interleaving online belief updates with experiment\ndesign under information-theoretic criteria. We conduct a human-model\ncomparison on a Zendo-style task, finding that a critical ingredient for\nmodeling the human data is to assume that humans also consider fuzzy,\nprobabilistic rules, in addition to assuming that humans perform\napproximately-Bayesian belief updates. We also compare with recent algorithms\nfor using LLMs to generate and revise hypotheses, finding that our online\ninference method yields higher accuracy at recovering the true underlying rule,\nand provides better support for designing optimal experiments.", "published": "2024-02-08 19:57:29", "link": "http://arxiv.org/abs/2402.06025v7", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind\n  Reasoning Capabilities of Large Language Models", "abstract": "Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track\nof the mental states of others, is pivotal in developing socially intelligent\nagents. However, prevalent N-ToM benchmarks have several shortcomings,\nincluding the presence of ambiguous and artificial narratives, absence of\npersonality traits and preferences, a lack of questions addressing characters'\npsychological mental states, and limited diversity in the questions posed. In\nresponse to these issues, we construct OpenToM, a new benchmark for assessing\nN-ToM with (1) longer and clearer narrative stories, (2) characters with\nexplicit personality traits, (3) actions that are triggered by character\nintentions, and (4) questions designed to challenge LLMs' capabilities of\nmodeling characters' mental states of both the physical and psychological\nworld. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling\ncertain aspects of mental states in the physical world but fall short when\ntracking characters' mental states in the psychological world.", "published": "2024-02-08 20:35:06", "link": "http://arxiv.org/abs/2402.06044v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Advances and Limitations in Open Source Arabic-Script OCR: A Case Study", "abstract": "This work presents an accuracy study of the open source OCR engine, Kraken,\non the leading Arabic scholarly journal, al-Abhath. In contrast with other\ncommercially available OCR engines, Kraken is shown to be capable of producing\nhighly accurate Arabic-script OCR. The study also assesses the relative\naccuracy of typeface-specific and generalized models on the al-Abhath data and\nprovides a microanalysis of the ``error instances'' and the contextual features\nthat may have contributed to OCR misrecognition. Building on this analysis, the\npaper argues that Arabic-script OCR can be significantly improved through (1) a\nmore systematic approach to training data production, and (2) the development\nof key technological components, especially multi-language models and improved\nline segmentation and layout analysis.\n  Cet article pr{\\'e}sente une {\\'e}tude d'exactitude du moteur ROC open\nsource, Krakan, sur la revue acad{\\'e}mique arabe de premier rang, al-Abhath.\nContrairement {\\`a} d'autres moteurs ROC disponibles sur le march{\\'e}, Kraken\nse r{\\'e}v{\\`e}le {\\^e}tre capable de produire de la ROC extr{\\^e}mement exacte\nde l'{\\'e}criture arabe. L'{\\'e}tude {\\'e}value aussi l'exactitude relative des\nmod{\\`e}les sp{\\'e}cifiquement configur{\\'e}s {\\`a} des polices et celle des\nmod{\\`e}les g{\\'e}n{\\'e}ralis{\\'e}s sur les donn{\\'e}es d'al-Abhath et fournit\nune microanalyse des \"occurrences d'erreurs\", ainsi qu'une microanalyse des\n{\\'e}l{\\'e}ments contextuels qui pourraient avoir contribu{\\'e} {\\`a} la\nm{\\'e}reconnaissance ROC. S'appuyant sur cette analyse, cet article fait valoir\nque la ROC de l'{\\'e}criture arabe peut {\\^e}tre consid{\\'e}rablement\nam{\\'e}lior{\\'e}e gr{\\^a}ce {\\`a} (1) une approche plus syst{\\'e}matique\nd'entra{\\^i}nement de la production de donn{\\'e}es et (2) gr{\\^a}ce au\nd{\\'e}veloppement de composants technologiques fondamentaux,\nnotammentl'am{\\'e}lioration des mod{\\`e}les multilingues, de la segmentation de\nligne et de l'analyse de la mise en page.", "published": "2024-02-08 12:51:36", "link": "http://arxiv.org/abs/2402.10943v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "An Examination on the Effectiveness of Divide-and-Conquer Prompting in\n  Large Language Models", "abstract": "Foundation models, such as Large language Models (LLMs), have attracted\nsignificant amount of interest due to their large number of applications.\nHowever, when handling tasks involving repetitive sub-tasks and/or deceptive\ncontents, such as arithmetic calculation and article-level fake news detection,\nsimple instructional prompts suffer from inaccurate responses. Existing works\nshow that more complicated prompting strategies, such as Chain-of-Thoughts and\nLeast-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent\nresearches reveal that simple divide-and-conquer prompting strategy, i.e.\nsimply dividing the input sequence to multiple sub-inputs, can also\nsubstantially improve LLM's performance in some specific tasks such as\nmisinformation detection. In this paper, we aim at examining the utility of\ndivide-and-conquer prompting strategy and answer on which kind of tasks this\nstrategy gets advantages. Specifically, we provide a theoretic analysis to\ndivide-and-conquer prompting strategy and help us identify the specific tasks\nwhere DaC prompting can bring performance boost with theoretic guarantee. We\nthen present two cases (large integer arithmetic and fact verification) where\nexperimental results aligns with our theoretic analysis.", "published": "2024-02-08 02:37:30", "link": "http://arxiv.org/abs/2402.05359v6", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "CIC: A Framework for Culturally-Aware Image Captioning", "abstract": "Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..", "published": "2024-02-08 03:12:25", "link": "http://arxiv.org/abs/2402.05374v5", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GPT-4 Generated Narratives of Life Events using a Structured Narrative\n  Prompt: A Validation Study", "abstract": "Large Language Models (LLMs) play a pivotal role in generating vast arrays of\nnarratives, facilitating a systematic exploration of their effectiveness for\ncommunicating life events in narrative form. In this study, we employ a\nzero-shot structured narrative prompt to generate 24,000 narratives using\nOpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and\nevaluate their validity in conveying birth, death, hiring, and firing events.\nRemarkably, 87.43% of the narratives sufficiently convey the intention of the\nstructured prompt. To automate the identification of valid and invalid\nnarratives, we train and validate nine Machine Learning models on the\nclassified datasets. Leveraging these models, we extend our analysis to predict\nthe classifications of the remaining 21,120 narratives. All the ML models\nexcelled at classifying valid narratives as valid, but experienced challenges\nat simultaneously classifying invalid narratives as invalid. Our findings not\nonly advance the study of LLM capabilities, limitations, and validity but also\noffer practical insights for narrative generation and natural language\nprocessing applications.", "published": "2024-02-08 06:20:01", "link": "http://arxiv.org/abs/2402.05435v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.6.4"], "primary_category": "cs.CL"}
{"title": "Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation\n  and Echopraxia", "abstract": "Large Language Models (LLMs) have become prevalent across diverse sectors,\ntransforming human life with their extraordinary reasoning and comprehension\nabilities. As they find increased use in sensitive tasks, safety concerns have\ngained widespread attention. Extensive efforts have been dedicated to aligning\nLLMs with human moral principles to ensure their safe deployment. Despite their\npotential, recent research indicates aligned LLMs are prone to specialized\njailbreaking prompts that bypass safety measures to elicit violent and harmful\ncontent. The intrinsic discrete nature and substantial scale of contemporary\nLLMs pose significant challenges in automatically generating diverse,\nefficient, and potent jailbreaking prompts, representing a continuous obstacle.\nIn this paper, we introduce RIPPLE (Rapid Optimization via Subconscious\nExploitation and Echopraxia), a novel optimization-based method inspired by two\npsychological concepts: subconsciousness and echopraxia, which describe the\nprocesses of the mind that occur without conscious awareness and the\ninvoluntary mimicry of actions, respectively. Evaluations across 6 open-source\nLLMs and 4 commercial LLM APIs show RIPPLE achieves an average Attack Success\nRate of 91.5\\%, outperforming five current methods by up to 47.0\\% with an 8x\nreduction in overhead. Furthermore, it displays significant transferability and\nstealth, successfully evading established detection mechanisms. The code of our\nwork is available at\n\\url{https://github.com/SolidShen/RIPPLE_official/tree/official}", "published": "2024-02-08 07:56:49", "link": "http://arxiv.org/abs/2402.05467v1", "categories": ["cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Establishing degrees of closeness between audio recordings along\n  different dimensions using large-scale cross-lingual models", "abstract": "In the highly constrained context of low-resource language studies, we\nexplore vector representations of speech from a pretrained model to determine\ntheir level of abstraction with regard to the audio signal. We propose a new\nunsupervised method using ABX tests on audio recordings with carefully curated\nmetadata to shed light on the type of information present in the\nrepresentations. ABX tests determine whether the representations computed by a\nmultilingual speech model encode a given characteristic. Three experiments are\ndevised: one on room acoustics aspects, one on linguistic genre, and one on\nphonetic aspects. The results confirm that the representations extracted from\nrecordings with different linguistic/extra-linguistic characteristics differ\nalong the same lines. Embedding more audio signal in one vector better\ndiscriminates extra-linguistic characteristics, whereas shorter snippets are\nbetter to distinguish segmental information. The method is fully unsupervised,\npotentially opening new research avenues for comparative work on\nunder-documented languages.", "published": "2024-02-08 11:31:23", "link": "http://arxiv.org/abs/2402.05581v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for\n  Transformers", "abstract": "Large Language Models are prone to biased predictions and hallucinations,\nunderlining the paramount importance of understanding their model-internal\nreasoning process. However, achieving faithful attributions for the entirety of\na black-box transformer model and maintaining computational efficiency is an\nunsolved challenge. By extending the Layer-wise Relevance Propagation\nattribution method to handle attention layers, we address these challenges\neffectively. While partial solutions exist, our method is the first to\nfaithfully and holistically attribute not only input but also latent\nrepresentations of transformer models with the computational efficiency similar\nto a single backward pass. Through extensive evaluations against existing\nmethods on LLaMa 2, Mixtral 8x7b, Flan-T5 and vision transformer architectures,\nwe demonstrate that our proposed approach surpasses alternative methods in\nterms of faithfulness and enables the understanding of latent representations,\nopening up the door for concept-based explanations. We provide an LRP library\nat https://github.com/rachtibat/LRP-eXplains-Transformers.", "published": "2024-02-08 12:01:24", "link": "http://arxiv.org/abs/2402.05602v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pretrained Generative Language Models as General Learning Frameworks for\n  Sequence-Based Tasks", "abstract": "We propose that small pretrained foundational generative language models with\nmillions of parameters can be utilized as a general learning framework for\nsequence-based tasks. Our proposal overcomes the computational resource, skill\nset, and timeline challenges associated with training neural networks and\nlanguage models from scratch. Further, our approach focuses on creating small\nand highly specialized models that can accurately execute a challenging task of\nwhich the base model is incapable of performing. We demonstrate that 125M,\n350M, and 1.3B parameter pretrained foundational language models can be\ninstruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve\nnear state-of-the-art results on challenging cheminformatics tasks. We also\ndemonstrate the role of successive language model fine-tuning epochs on\nimproved outcomes, as well as the importance of both data formatting and\npretrained foundational language model selection for instruction fine-tuning\nsuccess.", "published": "2024-02-08 12:19:32", "link": "http://arxiv.org/abs/2402.05616v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Models for the Detection of Hate, Abuse and Profanity", "abstract": "Large Language Models (LLMs) are the cornerstone for many Natural Language\nProcessing (NLP) tasks like sentiment analysis, document classification, named\nentity recognition, question answering, summarization, etc. LLMs are often\ntrained on data which originates from the web. This data is prone to having\ncontent with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP,\nplease refer to the Appendix. Due to the LLMs being exposed to HAP content\nduring training, the models learn it and may then generate hateful or profane\ncontent. For example, when the open-source RoBERTa model (specifically, the\nRoBERTA base model) from the HuggingFace (HF) Transformers library is prompted\nto replace the mask token in `I do not know that Persian people are that MASK`\nit returns the word `stupid` with the highest score. This is unacceptable in\ncivil discourse.The detection of Hate, Abuse and Profanity in text is a vital\ncomponent of creating civil and unbiased LLMs, which is needed not only for\nEnglish, but for all languages. In this article, we briefly describe the\ncreation of HAP detectors and various ways of using them to make models civil\nand acceptable in the output they generate.", "published": "2024-02-08 12:28:18", "link": "http://arxiv.org/abs/2402.05624v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Comprehensive Assessment of Jailbreak Attacks Against LLMs", "abstract": "Jailbreak attacks aim to bypass the safeguards of LLMs. While researchers\nhave studied different jailbreak attacks in depth, they have done so in\nisolation -- either with unaligned experiment settings or comparing a limited\nrange of methods. To fill this gap, we present the first large-scale\nmeasurement of various jailbreak attack methods. We collect 17 cutting-edge\njailbreak methods, summarize their features, and establish a novel jailbreak\nattack taxonomy. Based on eight popular censored LLMs and 160 questions from 16\nviolation categories, we conduct a unified and impartial assessment of attack\neffectiveness as well as a comprehensive ablation study. Our extensive\nexperimental results demonstrate that all the jailbreak attacks have a powerful\neffect on the LLMs. This indicates that all LLMs fail to cover all the\nviolation categories, and they are susceptible to significant jailbreak risks,\nwith even the well-aligned Llama3 facing a maximum attack success rate of 0.88.\nAdditionally, we test jailbreak attacks under eight advanced external defenses\nand find none of the defenses could mitigate the jailbreak attacks entirely.\nOur study offers valuable insights for future research on jailbreak attacks and\ndefenses and serves as a benchmark tool for researchers and practitioners to\nevaluate them effectively.", "published": "2024-02-08 13:42:50", "link": "http://arxiv.org/abs/2402.05668v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Self-Alignment of Large Language Models via Monopolylogue-based Social\n  Scene Simulation", "abstract": "Aligning large language models (LLMs) with human values is imperative to\nmitigate potential adverse effects resulting from their misuse. Drawing from\nthe sociological insight that acknowledging all parties' concerns is a key\nfactor in shaping human values, this paper proposes a novel direction to align\nLLMs by themselves: social scene simulation. To achieve this, we present\nMATRIX, a novel social scene simulator that emulates realistic scenes around a\nuser's input query, enabling the LLM to take social consequences into account\nbefore responding. MATRIX serves as a virtual rehearsal space, akin to a\nMonopolylogue, where the LLM performs diverse roles related to the query and\npractice by itself. To inject this alignment, we fine-tune the LLM with\nMATRIX-simulated data, ensuring adherence to human values without compromising\ninference speed. We theoretically show that the LLM with MATRIX outperforms\nConstitutional AI under mild assumptions. Finally, extensive experiments\nvalidate that our method outperforms over 10 baselines across 4 benchmarks. As\nevidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning\nwith human values. See our project page at\nhttps://shuotang123.github.io/MATRIX.", "published": "2024-02-08 14:21:03", "link": "http://arxiv.org/abs/2402.05699v3", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Paralinguistics-Aware Speech-Empowered Large Language Models for Natural\n  Conversation", "abstract": "Recent work shows promising results in expanding the capabilities of large\nlanguage models (LLM) to directly understand and synthesize speech. However, an\nLLM-based strategy for modeling spoken dialogs remains elusive, calling for\nfurther investigation. This paper introduces an extensive speech-text LLM\nframework, the Unified Spoken Dialog Model (USDM), designed to generate\ncoherent spoken responses with naturally occurring prosodic features relevant\nto the given input speech without relying on explicit automatic speech\nrecognition (ASR) or text-to-speech (TTS) systems. We have verified the\ninclusion of prosody in speech tokens that predominantly contain semantic\ninformation and have used this foundation to construct a prosody-infused\nspeech-text model. Additionally, we propose a generalized speech-text\npretraining scheme that enhances the capture of cross-modal semantics. To\nconstruct USDM, we fine-tune our speech-text model on spoken dialog data using\na multi-step spoken dialog template that stimulates the chain-of-reasoning\ncapabilities exhibited by the underlying LLM. Automatic and human evaluations\non the DailyTalk dataset demonstrate that our approach effectively generates\nnatural-sounding spoken responses, surpassing previous and cascaded baselines.\nOur code and checkpoints are available at https://github.com/naver-ai/usdm.", "published": "2024-02-08 14:35:09", "link": "http://arxiv.org/abs/2402.05706v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Spirit LM: Interleaved Spoken and Written Language Model", "abstract": "We introduce Spirit LM, a foundation multimodal language model that freely\nmixes text and speech. Our model is based on a 7B pretrained text language\nmodel that we extend to the speech modality by continuously training it on text\nand speech units. Speech and text sequences are concatenated as a single stream\nof tokens, and trained with a word-level interleaving method using a small\nautomatically-curated speech-text parallel corpus. Spirit LM comes in two\nversions: a Base version that uses speech phonetic units (HuBERT) and an\nExpressive version that models expressivity using pitch and style units in\naddition to the phonetic units. For both versions, the text is encoded with\nsubword BPE tokens. The resulting model displays both the semantic abilities of\ntext models and the expressive abilities of speech models. Additionally, we\ndemonstrate that Spirit LM can learn new tasks in a few-shot fashion across\nmodalities (i.e. ASR, TTS, Speech Classification). We make available model\nweights and inference code.", "published": "2024-02-08 15:39:32", "link": "http://arxiv.org/abs/2402.05755v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Examining Gender and Racial Bias in Large Vision-Language Models Using a\n  Novel Dataset of Parallel Images", "abstract": "Following on recent advances in large language models (LLMs) and subsequent\nchat models, a new wave of large vision-language models (LVLMs) has emerged.\nSuch models can incorporate images as input in addition to text, and perform\ntasks such as visual question answering, image captioning, story generation,\netc. Here, we examine potential gender and racial biases in such systems, based\non the perceived characteristics of the people in the input images. To\naccomplish this, we present a new dataset PAIRS (PArallel Images for eveRyday\nScenarios). The PAIRS dataset contains sets of AI-generated images of people,\nsuch that the images are highly similar in terms of background and visual\ncontent, but differ along the dimensions of gender (man, woman) and race\n(Black, white). By querying the LVLMs with such images, we observe significant\ndifferences in the responses according to the perceived gender or race of the\nperson depicted.", "published": "2024-02-08 16:11:23", "link": "http://arxiv.org/abs/2402.05779v1", "categories": ["cs.CY", "cs.CL", "cs.CV"], "primary_category": "cs.CY"}
{"title": "Limits of Transformer Language Models on Learning to Compose Algorithms", "abstract": "We analyze the capabilities of Transformer language models in learning\ncompositional discrete tasks. To this end, we evaluate training LLaMA models\nand prompting GPT-4 and Gemini on four tasks demanding to learn a composition\nof several discrete sub-tasks. In particular, we measure how well these models\ncan reuse primitives observable in the sub-tasks to learn the composition task.\nOur results indicate that compositional learning in state-of-the-art\nTransformer language models is highly sample inefficient: LLaMA requires more\ndata samples than relearning all sub-tasks from scratch to learn the\ncompositional task; in-context prompting with few samples is unreliable and\nfails at executing the sub-tasks or correcting the errors in multi-round code\ngeneration. Further, by leveraging complexity theory, we support these findings\nwith a theoretical analysis focused on the sample inefficiency of gradient\ndescent in memorizing feedforward models. We open source our code at\nhttps://github.com/IBM/limitations-lm-algorithmic-compositional-learning.", "published": "2024-02-08 16:23:29", "link": "http://arxiv.org/abs/2402.05785v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Training Large Language Models for Reasoning through Reverse Curriculum\n  Reinforcement Learning", "abstract": "In this paper, we propose R$^3$: Learning Reasoning through Reverse\nCurriculum Reinforcement Learning (RL), a novel method that employs only\noutcome supervision to achieve the benefits of process supervision for large\nlanguage models. The core challenge in applying RL to complex reasoning is to\nidentify a sequence of actions that result in positive rewards and provide\nappropriate supervision for optimization. Outcome supervision provides sparse\nrewards for final results without identifying error locations, whereas process\nsupervision offers step-wise rewards but requires extensive manual annotation.\nR$^3$ overcomes these limitations by learning from correct demonstrations.\nSpecifically, R$^3$ progressively slides the start state of reasoning from a\ndemonstration's end to its beginning, facilitating easier model exploration at\nall stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome\nsupervision to offer step-level signals and precisely pinpoint errors. Using\nLlama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$\npoints on average. Notebaly, in program-based reasoning on GSM8K, it exceeds\nthe baseline by $4.2$ points across three backbone models, and without any\nextra data, Codellama-7B + R$^3$ performs comparable to larger models or\nclosed-source models.", "published": "2024-02-08 16:46:26", "link": "http://arxiv.org/abs/2402.05808v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Integrating Self-supervised Speech Model with Pseudo Word-level Targets\n  from Visually-grounded Speech Model", "abstract": "Recent advances in self-supervised speech models have shown significant\nimprovement in many downstream tasks. However, these models predominantly\ncentered on frame-level training objectives, which can fall short in spoken\nlanguage understanding tasks that require semantic comprehension. Existing\nworks often rely on additional speech-text data as intermediate targets, which\nis costly in the real-world setting. To address this challenge, we propose\nPseudo-Word HuBERT (PW-HuBERT), a framework that integrates pseudo word-level\ntargets into the training process, where the targets are derived from a\nvisually-ground speech model, notably eliminating the need for speech-text\npaired data. Our experimental results on four spoken language understanding\n(SLU) benchmarks suggest the superiority of our model in capturing semantic\ninformation.", "published": "2024-02-08 16:55:21", "link": "http://arxiv.org/abs/2402.05819v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis", "abstract": "Negotiation is the basis of social interactions; humans negotiate everything\nfrom the price of cars to how to share common resources. With rapidly growing\ninterest in using large language models (LLMs) to act as agents on behalf of\nhuman users, such LLM agents would also need to be able to negotiate. In this\npaper, we study how well LLMs can negotiate with each other. We develop\nNegotiationArena: a flexible framework for evaluating and probing the\nnegotiation abilities of LLM agents. We implemented three types of scenarios in\nNegotiationArena to assess LLM's behaviors in allocating shared resources\n(ultimatum games), aggregate resources (trading games) and buy/sell goods\n(price negotiations). Each scenario allows for multiple turns of flexible\ndialogues between LLM agents to allow for more complex negotiations.\nInterestingly, LLM agents can significantly boost their negotiation outcomes by\nemploying certain behavioral tactics. For example, by pretending to be desolate\nand desperate, LLMs can improve their payoffs by 20\\% when negotiating against\nthe standard GPT-4. We also quantify irrational negotiation behaviors exhibited\nby the LLM agents, many of which also appear in humans. Together,\n\\NegotiationArena offers a new environment to investigate LLM interactions,\nenabling new insights into LLM's theory of mind, irrationality, and reasoning\nabilities.", "published": "2024-02-08 17:51:48", "link": "http://arxiv.org/abs/2402.05863v1", "categories": ["cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.AI"}
{"title": "Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs", "abstract": "In this paper, we propose a new decoding method called Permute-and-Flip (PF)\ndecoder. It enjoys stability properties similar to the standard sampling\ndecoder, but is provably up to 2x better in its quality-stability tradeoff than\nsampling and never worse than any other decoder. We also design a cryptographic\nwatermarking scheme analogous to Aaronson (2023)'s Gumbel watermark, but\nnaturally tailored for PF decoder. The watermarking scheme does not change the\ndistribution to sample, while allowing arbitrarily low false positive rate and\nhigh recall whenever the generated text has high entropy. Our experiments show\nthat the PF decoder (and its watermarked counterpart) significantly\noutperform(s) naive sampling (and its Gumbel watermarked counterpart) in terms\nof perplexity, while retaining the same stability (and detectability), hence\nmaking it a promising new approach for LLM decoding. The code is available at\nhttps://github.com/XuandongZhao/pf-decoding", "published": "2024-02-08 17:54:23", "link": "http://arxiv.org/abs/2402.05864v3", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generative Echo Chamber? Effects of LLM-Powered Search Systems on\n  Diverse Information Seeking", "abstract": "Large language models (LLMs) powered conversational search systems have\nalready been used by hundreds of millions of people, and are believed to bring\nmany benefits over conventional search. However, while decades of research and\npublic discourse interrogated the risk of search systems in increasing\nselective exposure and creating echo chambers -- limiting exposure to diverse\nopinions and leading to opinion polarization, little is known about such a risk\nof LLM-powered conversational search. We conduct two experiments to\ninvestigate: 1) whether and how LLM-powered conversational search increases\nselective exposure compared to conventional search; 2) whether and how LLMs\nwith opinion biases that either reinforce or challenge the user's view change\nthe effect. Overall, we found that participants engaged in more biased\ninformation querying with LLM-powered conversational search, and an opinionated\nLLM reinforcing their views exacerbated this bias. These results present\ncritical implications for the development of LLMs and conversational search\nsystems, and the policy governing these technologies.", "published": "2024-02-08 18:14:33", "link": "http://arxiv.org/abs/2402.05880v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CREMA: Generalizable and Efficient Video-Language Reasoning via\n  Multimodal Modular Fusion", "abstract": "Despite impressive advancements in recent multimodal reasoning approaches,\nthey are still limited in flexibility and efficiency, as these models typically\nprocess only a few fixed modality inputs and require updates to numerous\nparameters. This paper tackles these critical challenges and proposes CREMA, a\ngeneralizable, highly efficient, and modular modality-fusion framework that can\nincorporate any new modality to enhance video reasoning. We first augment\nmultiple informative modalities (such as optical flow, 3D point cloud, audio,\nthermal heatmap, and touch map) from given videos without extra human\nannotation by leveraging sensors or existing pre-trained models. Next, we\nintroduce a query transformer with multiple parameter-efficient modules\nassociated with each accessible modality. It projects diverse modality features\nto the LLM token embedding space, allowing the model to integrate different\ndata types for response generation. Furthermore, we propose a novel progressive\nmultimodal fusion design supported by a lightweight fusion module and\nmodality-sequential training strategy. It helps compress information across\nvarious assisting modalities, maintaining computational efficiency in the LLM\nwhile improving performance. We validate our method on 7 video-language\nreasoning tasks assisted by diverse modalities, including conventional VideoQA\nand Video-Audio/3D/Touch/Thermal QA, and achieve better/equivalent performance\nagainst strong multimodal LLMs, including OneLLM, BLIP-2, and SeViLA while\nreducing over 90% trainable parameters. We provide extensive analyses of CREMA,\nincluding the impact of each modality on reasoning domains, the design of the\nfusion module, and example visualizations.", "published": "2024-02-08 18:27:22", "link": "http://arxiv.org/abs/2402.05889v4", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs", "abstract": "Our society is facing rampant misinformation harming public health and trust.\nTo address the societal challenge, we introduce FACT-GPT, a system leveraging\nLarge Language Models (LLMs) to automate the claim matching stage of\nfact-checking. FACT-GPT, trained on a synthetic dataset, identifies social\nmedia content that aligns with, contradicts, or is irrelevant to previously\ndebunked claims. Our evaluation shows that our specialized LLMs can match the\naccuracy of larger models in identifying related claims, closely mirroring\nhuman judgment. This research provides an automated solution for efficient\nclaim matching, demonstrates the potential of LLMs in supporting fact-checkers,\nand offers valuable resources for further research in the field.", "published": "2024-02-08 18:43:05", "link": "http://arxiv.org/abs/2402.05904v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.SI"], "primary_category": "cs.CL"}
{"title": "WebLINX: Real-World Website Navigation with Multi-Turn Dialogue", "abstract": "We propose the problem of conversational web navigation, where a digital\nagent controls a web browser and follows user instructions to solve real-world\ntasks in a multi-turn dialogue fashion. To support this problem, we introduce\nWEBLINX - a large-scale benchmark of 100K interactions across 2300 expert\ndemonstrations of conversational web navigation. Our benchmark covers a broad\nrange of patterns on over 150 real-world websites and can be used to train and\nevaluate agents in diverse scenarios. Due to the magnitude of information\npresent, Large Language Models (LLMs) cannot process entire web pages in\nreal-time. To solve this bottleneck, we design a retrieval-inspired model that\nefficiently prunes HTML pages by ranking relevant elements. We use the selected\nelements, along with screenshots and action history, to assess a variety of\nmodels for their ability to replicate human behavior when navigating the web.\nOur experiments span from small text-only to proprietary multimodal LLMs. We\nfind that smaller finetuned decoders surpass the best zero-shot LLMs (including\nGPT-4V), but also larger finetuned multimodal models which were explicitly\npretrained on screenshots. However, all finetuned models struggle to generalize\nto unseen websites. Our findings highlight the need for large multimodal models\nthat can generalize to novel settings. Our code, data and models are available\nfor research: https://mcgill-nlp.github.io/weblinx", "published": "2024-02-08 18:58:02", "link": "http://arxiv.org/abs/2402.05930v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Driving Everywhere with Large Language Model Policy Adaptation", "abstract": "Adapting driving behavior to new environments, customs, and laws is a\nlong-standing problem in autonomous driving, precluding the widespread\ndeployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a\nsimple yet powerful tool that enables human drivers and autonomous vehicles\nalike to drive everywhere by adapting their tasks and motion plans to traffic\nrules in new locations. LLaDA achieves this by leveraging the impressive\nzero-shot generalizability of large language models (LLMs) in interpreting the\ntraffic rules in the local driver handbook. Through an extensive user study, we\nshow that LLaDA's instructions are useful in disambiguating in-the-wild\nunexpected situations. We also demonstrate LLaDA's ability to adapt AV motion\nplanning policies in real-world datasets; LLaDA outperforms baseline planning\napproaches on all our metrics. Please check our website for more details:\nhttps://boyiliee.github.io/llada.", "published": "2024-02-08 18:59:03", "link": "http://arxiv.org/abs/2402.05932v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large\n  Language Models", "abstract": "We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory", "published": "2024-02-08 18:59:48", "link": "http://arxiv.org/abs/2402.05935v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LightCAM: A Fast and Light Implementation of Context-Aware Masking based\n  D-TDNN for Speaker Verification", "abstract": "Traditional Time Delay Neural Networks (TDNN) have achieved state-of-the-art\nperformance at the cost of high computational complexity and slower inference\nspeed, making them difficult to implement in an industrial environment. The\nDensely Connected Time Delay Neural Network (D-TDNN) with Context Aware Masking\n(CAM) module has proven to be an efficient structure to reduce complexity while\nmaintaining system performance. In this paper, we propose a fast and\nlightweight model, LightCAM, which further adopts a depthwise separable\nconvolution module (DSM) and uses multi-scale feature aggregation (MFA) for\nfeature fusion at different levels. Extensive experiments are conducted on\nVoxCeleb dataset, the comparative results show that it has achieved an EER of\n0.83 and MinDCF of 0.0891 in VoxCeleb1-O, which outperforms the other\nmainstream speaker verification methods. In addition, complexity analysis\nfurther demonstrates that the proposed architecture has lower computational\ncost and faster inference speed.", "published": "2024-02-08 21:47:16", "link": "http://arxiv.org/abs/2402.06073v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Neural Models for Source Code Synthesis and Completion", "abstract": "Natural language (NL) to code suggestion systems assist developers in\nIntegrated Development Environments (IDEs) by translating NL utterances into\ncompilable code snippet. The current approaches mainly involve hard-coded,\nrule-based systems based on semantic parsing. These systems make heavy use of\nhand-crafted rules that map patterns in NL or elements in its syntax parse tree\nto various query constructs and can only work on a limited subset of NL with a\nrestricted NL syntax. These systems are unable to extract semantic information\nfrom the coding intents of the developer, and often fail to infer types, names,\nand the context of the source code to get accurate system-level code\nsuggestions. In this master thesis, we present sequence-to-sequence deep\nlearning models and training paradigms to map NL to general-purpose programming\nlanguages that can assist users with suggestions of source code snippets, given\na NL intent, and also extend auto-completion functionality of the source code\nto users while they are writing source code. The developed architecture\nincorporates contextual awareness into neural models which generate source code\ntokens directly instead of generating parse trees/abstract meaning\nrepresentations from the source code and converting them back to source code.\nThe proposed pretraining strategy and the data augmentation techniques improve\nthe performance of the proposed architecture. The proposed architecture has\nbeen found to exceed the performance of a neural semantic parser, TranX, based\non the BLEU-4 metric by 10.82%. Thereafter, a finer analysis for the parsable\ncode translations from the NL intent for CoNaLA challenge was introduced. The\nproposed system is bidirectional as it can be also used to generate NL code\ndocumentation given source code. Lastly, a RoBERTa masked language model for\nPython was proposed to extend the developed system for code completion.", "published": "2024-02-08 17:10:12", "link": "http://arxiv.org/abs/2402.06690v1", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.SE"}
{"title": "UFO: A UI-Focused Agent for Windows OS Interaction", "abstract": "We introduce UFO, an innovative UI-Focused agent to fulfill user requests\ntailored to applications on Windows OS, harnessing the capabilities of\nGPT-Vision. UFO employs a dual-agent framework to meticulously observe and\nanalyze the graphical user interface (GUI) and control information of Windows\napplications. This enables the agent to seamlessly navigate and operate within\nindividual applications and across them to fulfill user requests, even when\nspanning multiple applications. The framework incorporates a control\ninteraction module, facilitating action grounding without human intervention\nand enabling fully automated execution. Consequently, UFO transforms arduous\nand time-consuming processes into simple tasks achievable solely through\nnatural language commands. We conducted testing of UFO across 9 popular Windows\napplications, encompassing a variety of scenarios reflective of users' daily\nusage. The results, derived from both quantitative metrics and real-case\nstudies, underscore the superior effectiveness of UFO in fulfilling user\nrequests. To the best of our knowledge, UFO stands as the first UI agent\nspecifically tailored for task completion within the Windows OS environment.\nThe open-source code for UFO is available on https://github.com/microsoft/UFO.", "published": "2024-02-08 15:40:35", "link": "http://arxiv.org/abs/2402.07939v5", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Text2Data: Low-Resource Data Generation with Textual Control", "abstract": "Natural language serves as a common and straightforward signal for humans to\ninteract seamlessly with machines. Recognizing the importance of this\ninterface, the machine learning community is investing considerable effort in\ngenerating data that is semantically coherent with textual instructions. While\nstrides have been made in text-to-data generation spanning image editing, audio\nsynthesis, video creation, and beyond, low-resource areas characterized by\nexpensive annotations or complex data structures, such as molecules, motion\ndynamics, and time series, often lack textual labels. This deficiency impedes\nsupervised learning, thereby constraining the application of advanced\ngenerative models for text-to-data tasks. In response to these challenges in\nthe low-resource scenario, we propose Text2Data, a novel approach that utilizes\nunlabeled data to understand the underlying data distribution through an\nunsupervised diffusion model. Subsequently, it undergoes controllable\nfinetuning via a novel constraint optimization-based learning objective that\nensures controllability and effectively counteracts catastrophic forgetting.\nComprehensive experiments demonstrate that Text2Data is able to achieve\nenhanced performance regarding controllability across various modalities,\nincluding molecules, motions and time series, when compared to existing\nbaselines.", "published": "2024-02-08 03:41:39", "link": "http://arxiv.org/abs/2402.10941v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Text Role Classification in Scientific Charts Using Multimodal\n  Transformers", "abstract": "Text role classification involves classifying the semantic role of textual\nelements within scientific charts. For this task, we propose to finetune two\npretrained multimodal document layout analysis models, LayoutLMv3 and UDOP, on\nchart datasets. The transformers utilize the three modalities of text, image,\nand layout as input. We further investigate whether data augmentation and\nbalancing methods help the performance of the models. The models are evaluated\non various chart datasets, and results show that LayoutLMv3 outperforms UDOP in\nall experiments. LayoutLMv3 achieves the highest F1-macro score of 82.87 on the\nICPR22 test dataset, beating the best-performing model from the ICPR22\nCHART-Infographics challenge. Moreover, the robustness of the models is tested\non a synthetic noisy dataset ICPR22-N. Finally, the generalizability of the\nmodels is evaluated on three chart datasets, CHIME-R, DeGruyter, and EconBiz,\nfor which we added labels for the text roles. Findings indicate that even in\ncases where there is limited training data, transformers can be used with the\nhelp of data augmentation and balancing methods. The source code and datasets\nare available on GitHub under\nhttps://github.com/hjkimk/text-role-classification", "published": "2024-02-08 13:21:44", "link": "http://arxiv.org/abs/2402.14579v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Large Language Model Augmented Exercise Retrieval for Personalized\n  Language Learning", "abstract": "We study the problem of zero-shot exercise retrieval in the context of online\nlanguage learning, to give learners the ability to explicitly request\npersonalized exercises via natural language. Using real-world data collected\nfrom language learners, we observe that vector similarity approaches poorly\ncapture the relationship between exercise content and the language that\nlearners use to express what they want to learn. This semantic gap between\nqueries and content dramatically reduces the effectiveness of general-purpose\nretrieval models pretrained on large scale information retrieval datasets like\nMS MARCO. We leverage the generative capabilities of large language models to\nbridge the gap by synthesizing hypothetical exercises based on the learner's\ninput, which are then used to search for relevant exercises. Our approach,\nwhich we call mHyER, overcomes three challenges: (1) lack of relevance labels\nfor training, (2) unrestricted learner input content, and (3) low semantic\nsimilarity between input and retrieval candidates. mHyER outperforms several\nstrong baselines on two novel benchmarks created from crowdsourced data and\npublicly available data.", "published": "2024-02-08 20:35:31", "link": "http://arxiv.org/abs/2402.16877v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "It's Never Too Late: Fusing Acoustic Information into Large Language\n  Models for Automatic Speech Recognition", "abstract": "Recent studies have successfully shown that large language models (LLMs) can\nbe successfully used for generative error correction (GER) on top of the\nautomatic speech recognition (ASR) output. Specifically, an LLM is utilized to\ncarry out a direct mapping from the N-best hypotheses list generated by an ASR\nsystem to the predicted output transcription. However, despite its\neffectiveness, GER introduces extra data uncertainty since the LLM is trained\nwithout taking into account acoustic information available in the speech\nsignal. In this work, we aim to overcome such a limitation by infusing acoustic\ninformation before generating the predicted transcription through a novel late\nfusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a\nmultimodal fusion approach implemented into an auto-regressive decoding process\nand works in two stages: (i) It first analyzes and calibrates the token-level\nLLM decision, and (ii) it then dynamically assimilates the information from the\nacoustic modality. Experimental evidence collected from various ASR tasks shows\nthat UADF surpasses existing fusion mechanisms in several ways. It yields\nsignificant improvements in word error rate (WER) while mitigating data\nuncertainty issues in LLM and addressing the poor generalization relied with\nsole modality during fusion. We also demonstrate that UADF seamlessly adapts to\naudio-visual speech recognition.", "published": "2024-02-08 07:21:45", "link": "http://arxiv.org/abs/2402.05457v1", "categories": ["cs.CL", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving\n  Communication with Cloud-based LLMs", "abstract": "Cloud-based Large Language Models (LLMs) such as ChatGPT have become\nincreasingly integral to daily operations. Nevertheless, they also introduce\nprivacy concerns: firstly, numerous studies underscore the risks to user\nprivacy posed by jailbreaking cloud-based LLMs; secondly, the LLM service\nproviders have access to all user data, which deters individuals from\nconfidently utilizing such services. To address such concerns, we propose a\nsimple yet effective paradigm, EmojiPrompt, to protect user privacy. At its\ncore, EmojiPrompt performs generative transformation, obfuscating private data\nwithin prompts with linguistic and non-linguistic elements before submitting\nthem to cloud-based LLMs. We evaluate EmojiPrompt's performance across 8\ndatasets from various domains. We also propose simulated inference attacks to\nassess EmojiPrompt's ability to preserve user privacy. The results demonstrate\nthat EmojiPrompt effectively obfuscates user private data, while largely\nmaintaining, or even enhancing, performances compared to the unobfuscated\nversion. Furthermore, EmojiPrompt's atomic-level obfuscation allows it to\nfunction exclusively with cloud-based LLMs. For source code, please refer to:\nhttps://github.com/agiresearch/EmojiCrypt.", "published": "2024-02-08 17:57:11", "link": "http://arxiv.org/abs/2402.05868v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multispecies bird sound recognition using a fully convolutional neural\n  network", "abstract": "This study proposes a method based on fully convolutional neural networks\n(FCNs) to identify migratory birds from their songs, with the objective of\nrecognizing which birds pass through certain areas and at what time. To\ndetermine the best FCN architecture, extensive experimentation was conducted\nthrough a grid search, exploring the optimal depth, width, and activation\nfunction of the network. The results showed that the optimal number of filters\nis 400 in the widest layer, with 4 convolutional blocks with maxpooling and an\nadaptive activation function. The proposed FCN offers a significant advantage\nover other techniques, as it can recognize the sound of a bird in audio of any\nlength with an accuracy greater than 85%. Furthermore, due to its architecture,\nthe network can detect more than one species from audio and can carry out\nnear-real-time sound recognition. Additionally, the proposed method is\nlightweight, making it ideal for deployment and use in IoT devices. The study\nalso presents a comparative analysis of the proposed method against other\ntechniques, demonstrating an improvement of over 67% in the best-case scenario.\nThese findings contribute to advancing the field of bird sound recognition and\nprovide valuable insights into the practical application of FCNs in real-world\nscenarios.", "published": "2024-02-08 08:46:50", "link": "http://arxiv.org/abs/2402.05489v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Determining the severity of Parkinson's disease in patients using a\n  multi task neural network", "abstract": "Parkinson's disease is easy to diagnose when it is advanced, but it is very\ndifficult to diagnose in its early stages. Early diagnosis is essential to be\nable to treat the symptoms. It impacts on daily activities and reduces the\nquality of life of both the patients and their families and it is also the\nsecond most prevalent neurodegenerative disorder after Alzheimer in people over\nthe age of 60. Most current studies on the prediction of Parkinson's severity\nare carried out in advanced stages of the disease. In this work, the study\nanalyzes a set of variables that can be easily extracted from voice analysis,\nmaking it a very non-intrusive technique. In this paper, a method based on\ndifferent deep learning techniques is proposed with two purposes. On the one\nhand, to find out if a person has severe or non-severe Parkinson's disease, and\non the other hand, to determine by means of regression techniques the degree of\nevolution of the disease in a given patient. The UPDRS (Unified Parkinson's\nDisease Rating Scale) has been used by taking into account both the motor and\ntotal labels, and the best results have been obtained using a mixed multi-layer\nperceptron (MLP) that classifies and regresses at the same time and the most\nimportant features of the data obtained are taken as input, using an\nautoencoder. A success rate of 99.15% has been achieved in the problem of\npredicting whether a person suffers from severe Parkinson's disease or\nnon-severe Parkinson's disease. In the degree of disease involvement prediction\nproblem case, a MSE (Mean Squared Error) of 0.15 has been obtained. Using a\nfull deep learning pipeline for data preprocessing and classification has\nproven to be very promising in the field Parkinson's outperforming the\nstate-of-the-art proposals.", "published": "2024-02-08 08:55:34", "link": "http://arxiv.org/abs/2402.05491v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Listening Between the Lines: Synthetic Speech Detection Disregarding\n  Verbal Content", "abstract": "Recent advancements in synthetic speech generation have led to the creation\nof forged audio data that are almost indistinguishable from real speech. This\nphenomenon poses a new challenge for the multimedia forensics community, as the\nmisuse of synthetic media can potentially cause adverse consequences. Several\nmethods have been proposed in the literature to mitigate potential risks and\ndetect synthetic speech, mainly focusing on the analysis of the speech itself.\nHowever, recent studies have revealed that the most crucial frequency bands for\ndetection lie in the highest ranges (above 6000 Hz), which do not include any\nspeech content. In this work, we extensively explore this aspect and\ninvestigate whether synthetic speech detection can be performed by focusing\nonly on the background component of the signal while disregarding its verbal\ncontent. Our findings indicate that the speech component is not the predominant\nfactor in performing synthetic speech detection. These insights provide\nvaluable guidance for the development of new synthetic speech detectors and\ntheir interpretability, together with some considerations on the existing work\nin the audio forensics field.", "published": "2024-02-08 11:05:49", "link": "http://arxiv.org/abs/2402.05567v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Source Separation Using Latent Variational Block-Wise\n  Disentanglement", "abstract": "While neural network approaches have made significant strides in resolving\nclassical signal processing problems, it is often the case that hybrid\napproaches that draw insight from both signal processing and neural networks\nproduce more complete solutions. In this paper, we present a hybrid classical\ndigital signal processing/deep neural network (DSP/DNN) approach to source\nseparation (SS) highlighting the theoretical link between variational\nautoencoder and classical approaches to SS. We propose a system that transforms\nthe single channel under-determined SS task to an equivalent multichannel\nover-determined SS problem in a properly designed latent space. The separation\ntask in the latent space is treated as finding a variational block-wise\ndisentangled representation of the mixture. We show empirically, that the\ndesign choices and the variational formulation of the task at hand motivated by\nthe classical signal processing theoretical results lead to robustness to\nunseen out-of-distribution data and reduction of the overfitting risk. To\naddress the resulting permutation issue we explicitly incorporate a novel\ndifferentiable permutation loss function and augment the model with a memory\nmechanism to keep track of the statistics of the individual sources.", "published": "2024-02-08 07:22:39", "link": "http://arxiv.org/abs/2402.06683v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
