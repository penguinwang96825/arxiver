{"title": "Extracting Parallel Paragraphs from Common Crawl", "abstract": "Most of the current methods for mining parallel texts from the web assume\nthat web pages of web sites share same structure across languages. We believe\nthat there still exists a non-negligible amount of parallel data spread across\nsources not satisfying this assumption. We propose an approach based on a\ncombination of bivec (a bilingual extension of word2vec) and locality-sensitive\nhashing which allows us to efficiently identify pairs of parallel segments\nlocated anywhere on pages of a given web domain, regardless their structure. We\nvalidate our method on realigning segments from a large parallel corpus.\nAnother experiment with real-world data provided by Common Crawl Foundation\nconfirms that our solution scales to hundreds of terabytes large set of\nweb-crawled data.", "published": "2018-04-27 09:33:49", "link": "http://arxiv.org/abs/1804.10413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weaver: Deep Co-Encoding of Questions and Documents for Machine Reading", "abstract": "This paper aims at improving how machines can answer questions directly from\ntext, with the focus of having models that can answer correctly multiple types\nof questions and from various types of texts, documents or even from large\ncollections of them. To that end, we introduce the Weaver model that uses a new\nway to relate a question to a textual context by weaving layers of recurrent\nnetworks, with the goal of making as few assumptions as possible as to how the\ninformation from both question and context should be combined to form the\nanswer. We show empirically on six datasets that Weaver performs well in\nmultiple conditions. For instance, it produces solid results on the very\npopular SQuAD dataset (Rajpurkar et al., 2016), solves almost all bAbI tasks\n(Weston et al., 2015) and greatly outperforms state-of-the-art methods for open\ndomain question answering from text (Chen et al., 2017).", "published": "2018-04-27 13:24:11", "link": "http://arxiv.org/abs/1804.10490v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Coverage and Runtime Complexity for Exact Inference in\n  Non-Projective Transition-Based Dependency Parsers", "abstract": "We generalize Cohen, G\\'omez-Rodr\\'iguez, and Satta's (2011) parser to a\nfamily of non-projective transition-based dependency parsers allowing\npolynomial-time exact inference. This includes novel parsers with better\ncoverage than Cohen et al. (2011), and even a variant that reduces time\ncomplexity to $O(n^6)$, improving over the known bounds in exact inference for\nnon-projective transition-based parsing. We hope that this piece of theoretical\nwork inspires design of novel transition systems with better coverage and\nbetter run-time guarantees.\n  Code available at https://github.com/tzshi/nonproj-dp-variants-naacl2018", "published": "2018-04-27 17:59:15", "link": "http://arxiv.org/abs/1804.10615v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Improving Entity Linking by Modeling Latent Relations between Mentions", "abstract": "Entity linking involves aligning textual mentions of named entities to their\ncorresponding entries in a knowledge base. Entity linking systems often exploit\nrelations between textual mentions in a document (e.g., coreference) to decide\nif the linking decisions are compatible. Unlike previous approaches, which\nrelied on supervised systems or heuristics to predict these relations, we treat\nrelations as latent variables in our neural entity-linking model. We induce the\nrelations without any supervision while optimizing the entity-linking system in\nan end-to-end fashion. Our multi-relational model achieves the best reported\nscores on the standard benchmark (AIDA-CoNLL) and substantially outperforms its\nrelation-agnostic version. Its training also converges much faster, suggesting\nthat the injected structural bias helps to explain regularities in the training\ndata.", "published": "2018-04-27 18:28:24", "link": "http://arxiv.org/abs/1804.10637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Unsupervised Word Sense Disambiguation System for Under-Resourced\n  Languages", "abstract": "In this paper, we present Watasense, an unsupervised system for word sense\ndisambiguation. Given a sentence, the system chooses the most relevant sense of\neach input word with respect to the semantic similarity between the given\nsentence and the synset constituting the sense of the target word. Watasense\nhas two modes of operation. The sparse mode uses the traditional vector space\nmodel to estimate the most similar word sense corresponding to its context. The\ndense mode, instead, uses synset embeddings to cope with the sparsity problem.\nWe describe the architecture of the present system and also conduct its\nevaluation on three different lexical semantic resources for Russian. We found\nthat the dense mode substantially outperforms the sparse one on all datasets\naccording to the adjusted Rand index.", "published": "2018-04-27 20:44:49", "link": "http://arxiv.org/abs/1804.10686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Customized Image Narrative Generation via Interactive Visual Question\n  Generation and Answering", "abstract": "Image description task has been invariably examined in a static manner with\nqualitative presumptions held to be universally applicable, regardless of the\nscope or target of the description. In practice, however, different viewers may\npay attention to different aspects of the image, and yield different\ndescriptions or interpretations under various contexts. Such diversity in\nperspectives is difficult to derive with conventional image description\ntechniques. In this paper, we propose a customized image narrative generation\ntask, in which the users are interactively engaged in the generation process by\nproviding answers to the questions. We further attempt to learn the user's\ninterest via repeating such interactive stages, and to automatically reflect\nthe interest in descriptions for new images. Experimental results demonstrate\nthat our model can generate a variety of descriptions from single image that\ncover a wider range of topics than conventional models, while being\ncustomizable to the target user of interaction.", "published": "2018-04-27 11:27:45", "link": "http://arxiv.org/abs/1805.00460v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Auto-Detection of Safety Issues in Baby Products", "abstract": "Every year, thousands of people receive consumer product related injuries.\nResearch indicates that online customer reviews can be processed to\nautonomously identify product safety issues. Early identification of safety\nissues can lead to earlier recalls, and thus fewer injuries and deaths. A\ndataset of product reviews from Amazon.com was compiled, along with\n\\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer\nProduct Safety Commission (CPSC) and European Commission Rapid Alert system. A\nsystem was built to clean the collected text and to extract relevant features.\nDimensionality reduction was performed by computing feature relevance through a\nRandom Forest and discarding features with low information gain. Various\nclassifiers were analyzed, including Logistic Regression, SVMs,\nNa{\\\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation\nwith various features and classifier combinations resulted in a logistic\nregression model with 66\\% precision in the top 50 reviews surfaced. This\nclassifier outperforms all benchmarks set by related literature and consumer\nproduct safety professionals.", "published": "2018-04-27 15:33:50", "link": "http://arxiv.org/abs/1805.09772v2", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Simulating dysarthric speech for training data augmentation in clinical\n  speech applications", "abstract": "Training machine learning algorithms for speech applications requires large,\nlabeled training data sets. This is problematic for clinical applications where\nobtaining such data is prohibitively expensive because of privacy concerns or\nlack of access. As a result, clinical speech applications are typically\ndeveloped using small data sets with only tens of speakers. In this paper, we\npropose a method for simulating training data for clinical applications by\ntransforming healthy speech to dysarthric speech using adversarial training. We\nevaluate the efficacy of our approach using both objective and subjective\ncriteria. We present the transformed samples to five experienced\nspeech-language pathologists (SLPs) and ask them to identify the samples as\nhealthy or dysarthric. The results reveal that the SLPs identify the\ntransformed speech as dysarthric 65% of the time. In a pilot classification\nexperiment, we show that by using the simulated speech samples to balance an\nexisting dataset, the classification accuracy improves by about 10% after data\naugmentation.", "published": "2018-04-27 02:20:24", "link": "http://arxiv.org/abs/1804.10325v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Speech Denoising with Vector Space Projections", "abstract": "We propose an algorithm to denoise speakers from a single microphone in the\npresence of non-stationary and dynamic noise. Our approach is inspired by the\nrecent success of neural network models separating speakers from other speakers\nand singers from instrumental accompaniment. Unlike prior art, we leverage\nembedding spaces produced with source-contrastive estimation, a technique\nderived from negative sampling techniques in natural language processing, while\nsimultaneously obtaining a continuous inference mask. Our embedding space\ndirectly optimizes for the discrimination of speaker and noise by jointly\nmodeling their characteristics. This space is generalizable in that it is not\nspeaker or noise specific and is capable of denoising speech even if the model\nhas not seen the speaker in the training set. Parameters are trained with dual\nobjectives: one that promotes a selective bandpass filter that eliminates noise\nat time-frequency positions that exceed signal power, and another that\nproportionally splits time-frequency content between signal and noise. We\ncompare to state of the art algorithms as well as traditional sparse\nnon-negative matrix factorization solutions. The resulting algorithm avoids\nsevere computational burden by providing a more intuitive and easily optimized\napproach, while achieving competitive accuracy.", "published": "2018-04-27 20:08:38", "link": "http://arxiv.org/abs/1804.10669v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
