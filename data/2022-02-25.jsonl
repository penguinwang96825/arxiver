{"title": "Deep neural networks for fine-grained surveillance of overdose mortality", "abstract": "Surveillance of drug overdose deaths relies on death certificates for\nidentification of the substances that caused death. Drugs and drug classes can\nbe identified through the International Classification of Diseases, 10th\nRevision (ICD-10) codes present on death certificates. However, ICD-10 codes do\nnot always provide high levels of specificity in drug identification. To\nachieve more fine-grained identification of substances on a death certificate,\nthe free-text cause of death section, completed by the medical certifier, must\nbe analyzed. Current methods for analyzing free-text death certificates rely\nsolely on look-up tables for identifying specific substances, which must be\nfrequently updated and maintained. To improve identification of drugs on death\ncertificates, a deep learning named-entity recognition model was developed,\nwhich achieved an F1-score of 99.13%. This model can identify new drug\nmisspellings and novel substances that are not present on current surveillance\nlook-up tables, enhancing the surveillance of drug overdose deaths.", "published": "2022-02-25 01:04:26", "link": "http://arxiv.org/abs/2202.12448v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "APEACH: Attacking Pejorative Expressions with Analysis on\n  Crowd-Generated Hate Speech Evaluation Datasets", "abstract": "In hate speech detection, developing training and evaluation datasets across\nvarious domains is the critical issue. Whereas, major approaches crawl social\nmedia texts and hire crowd-workers to annotate the data. Following this\nconvention often restricts the scope of pejorative expressions to a single\ndomain lacking generalization. Sometimes domain overlap between training corpus\nand evaluation set overestimate the prediction performance when pretraining\nlanguage models on low-data language. To alleviate these problems in Korean, we\npropose APEACH that asks unspecified users to generate hate speech examples\nfollowed by minimal post-labeling. We find that APEACH can collect useful\ndatasets that are less sensitive to the lexical overlaps between the\npretraining corpus and the evaluation set, thereby properly measuring the model\nperformance.", "published": "2022-02-25 02:04:38", "link": "http://arxiv.org/abs/2202.12459v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks", "abstract": "This paper focuses on the Data Augmentation for low-resource Natural Language\nUnderstanding (NLU) tasks. We propose Prompt-based D}ata Augmentation model\n(PromDA) which only trains small-scale Soft Prompt (i.e., a set of trainable\nvectors) in the frozen Pre-trained Language Models (PLMs). This avoids human\neffort in collecting unlabeled in-domain data and maintains the quality of\ngenerated synthetic data. In addition, PromDA generates synthetic data via two\ndifferent views and filters out the low-quality data using NLU models.\nExperiments on four benchmarks show that synthetic data produced by PromDA\nsuccessfully boost up the performance of NLU models which consistently\noutperform several competitive baseline models, including a state-of-the-art\nsemi-supervised model using unlabeled in-domain data. The synthetic data from\nPromDA are also complementary with unlabeled in-domain data. The NLU models can\nbe further improved when they are combined for training.", "published": "2022-02-25 05:09:27", "link": "http://arxiv.org/abs/2202.12499v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Screening Gender Transfer in Neural Machine Translation", "abstract": "This paper aims at identifying the information flow in state-of-the-art\nmachine translation systems, taking as example the transfer of gender when\ntranslating from French into English. Using a controlled set of examples, we\nexperiment several ways to investigate how gender information circulates in a\nencoder-decoder architecture considering both probing techniques as well as\ninterventions on the internal representations used in the MT system. Our\nresults show that gender information can be found in all token representations\nbuilt by the encoder and the decoder and lead us to conclude that there are\nmultiple pathways for gender transfer.", "published": "2022-02-25 09:05:31", "link": "http://arxiv.org/abs/2202.12568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mining Naturally-occurring Corrections and Paraphrases from Wikipedia's\n  Revision History", "abstract": "Naturally-occurring instances of linguistic phenomena are important both for\ntraining and for evaluating automatic processes on text. When available in\nlarge quantities, they also prove interesting material for linguistic studies.\nIn this article, we present a new resource built from Wikipedia's revision\nhistory, called WiCoPaCo (Wikipedia Correction and Paraphrase Corpus), which\ncontains numerous editings by human contributors, including various corrections\nand rewritings. We discuss the main motivations for building such a resource,\ndescribe how it was built and present initial applications on French.", "published": "2022-02-25 09:24:38", "link": "http://arxiv.org/abs/2202.12575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JParaCrawl v3.0: A Large-scale English-Japanese Parallel Corpus", "abstract": "Most current machine translation models are mainly trained with parallel\ncorpora, and their translation accuracy largely depends on the quality and\nquantity of the corpora. Although there are billions of parallel sentences for\na few language pairs, effectively dealing with most language pairs is difficult\ndue to a lack of publicly available parallel corpora. This paper creates a\nlarge parallel corpus for English-Japanese, a language pair for which only\nlimited resources are available, compared to such resource-rich languages as\nEnglish-German. It introduces a new web-based English-Japanese parallel corpus\nnamed JParaCrawl v3.0. Our new corpus contains more than 21 million unique\nparallel sentence pairs, which is more than twice as many as the previous\nJParaCrawl v2.0 corpus. Through experiments, we empirically show how our new\ncorpus boosts the accuracy of machine translation models on various domains.\nThe JParaCrawl v3.0 corpus will eventually be publicly available online for\nresearch purposes.", "published": "2022-02-25 10:52:00", "link": "http://arxiv.org/abs/2202.12607v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the data requirements of probing", "abstract": "As large and powerful neural language models are developed, researchers have\nbeen increasingly interested in developing diagnostic tools to probe them.\nThere are many papers with conclusions of the form \"observation X is found in\nmodel Y\", using their own datasets with varying sizes. Larger probing datasets\nbring more reliability, but are also expensive to collect. There is yet to be a\nquantitative method for estimating reasonable probing dataset sizes. We tackle\nthis omission in the context of comparing two probing configurations: after we\nhave collected a small dataset from a pilot study, how many additional data\nsamples are sufficient to distinguish two different configurations? We present\na novel method to estimate the required number of data samples in such\nexperiments and, across several case studies, we verify that our estimations\nhave sufficient statistical power. Our framework helps to systematically\nconstruct probing datasets to diagnose neural NLP models.", "published": "2022-02-25 16:27:06", "link": "http://arxiv.org/abs/2202.12801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Reality of Multi-Lingual Machine Translation", "abstract": "Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the\nbenefits and perils of using more than two languages in machine translation\nsystems. While focused on the particular task of sequence-to-sequence\nprocessing and multi-task learning, the book targets somewhat beyond the area\nof natural language processing. Machine translation is for us a prime example\nof deep learning applications where human skills and learning capabilities are\ntaken as a benchmark that many try to match and surpass. We document that some\nof the gains observed in multi-lingual translation may result from simpler\neffects than the assumed cross-lingual transfer of knowledge.\n  In the first, rather general part, the book will lead you through the\nmotivation for multi-linguality, the versatility of deep neural networks\nespecially in sequence-to-sequence tasks to complications of this learning. We\nconclude the general part with warnings against too optimistic and unjustified\nexplanations of the gains that neural networks demonstrate.\n  In the second part, we fully delve into multi-lingual models, with a\nparticularly careful examination of transfer learning as one of the more\nstraightforward approaches utilizing additional languages. The recent\nmulti-lingual techniques, including massive models, are surveyed and practical\naspects of deploying systems for many languages are discussed. The conclusion\nhighlights the open problem of machine understanding and reminds of two ethical\naspects of building large-scale models: the inclusivity of research and its\necological trace.", "published": "2022-02-25 16:44:06", "link": "http://arxiv.org/abs/2202.12814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Morphology Without Borders: Clause-Level Morphology", "abstract": "Morphological tasks use large multi-lingual datasets that organize words into\ninflection tables, which then serve as training and evaluation data for various\ntasks. However, a closer inspection of these data reveals profound\ncross-linguistic inconsistencies, that arise from the lack of a clear\nlinguistic and operational definition of what is a word, and that severely\nimpair the universality of the derived tasks. To overcome this deficiency, we\npropose to view morphology as a clause-level phenomenon, rather than\nword-level. It is anchored in a fixed yet inclusive set of features, that\nencapsulates all functions realized in a saturated clause. We deliver\nMightyMorph, a novel dataset for clause-level morphology covering 4\ntypologically-different languages: English, German, Turkish and Hebrew. We use\nthis dataset to derive 3 clause-level morphological tasks: inflection,\nreinflection and analysis. Our experiments show that the clause-level tasks are\nsubstantially harder than the respective word-level tasks, while having\ncomparable complexity across languages. Furthermore, redefining morphology to\nthe clause-level provides a neat interface with contextualized language models\n(LMs) and allows assessing the morphological knowledge encoded in these models\nand their usability for morphological tasks. Taken together, this work opens up\nnew horizons in the study of computational morphology, leaving ample space for\nstudying neural morphology cross-linguistically.", "published": "2022-02-25 17:20:28", "link": "http://arxiv.org/abs/2202.12832v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asyncval: A Toolkit for Asynchronously Validating Dense Retriever\n  Checkpoints during Training", "abstract": "The process of model checkpoint validation refers to the evaluation of the\nperformance of a model checkpoint executed on a held-out portion of the\ntraining data while learning the hyperparameters of the model, and is used to\navoid over-fitting and determine when the model has converged so as to stop\ntraining. A simple and efficient strategy to validate deep learning checkpoints\nis the addition of validation loops to execute during training. However, the\nvalidation of dense retrievers (DR) checkpoints is not as trivial -- and the\naddition of validation loops is not efficient. This is because, in order to\naccurately evaluate the performance of a DR checkpoint, the whole document\ncorpus needs to be encoded into vectors using the current checkpoint before any\nactual retrieval operation for checkpoint validation can be performed. This\ncorpus encoding process can be very time-consuming if the document corpus\ncontains millions of documents (e.g., 8.8m for MS MARCO and 21m for Natural\nQuestions). Thus, a naive use of validation loops during training will\nsignificantly increase training time. To address this issue, in this demo\npaper, we propose Asyncval: a Python-based toolkit for efficiently validating\nDR checkpoints during training. Instead of pausing the training loop for\nvalidating DR checkpoints, Asyncval decouples the validation loop from the\ntraining loop, uses another GPU to automatically validate new DR checkpoints\nand thus permits to perform validation asynchronously from training. Asyncval\nalso implements a range of different corpus subset sampling strategies for\nvalidating DR checkpoints; these strategies allow to further speed up the\nvalidation process. We provide an investigation of these methods in terms of\ntheir impact on validation time and validation fidelity. Asyncval is made\navailable as an open-source project at https://github.com/ielab/asyncval.", "published": "2022-02-25 06:07:58", "link": "http://arxiv.org/abs/2202.12510v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Exploring Multi-Modal Representations for Ambiguity Detection &\n  Coreference Resolution in the SIMMC 2.0 Challenge", "abstract": "Anaphoric expressions, such as pronouns and referential descriptions, are\nsituated with respect to the linguistic context of prior turns, as well as, the\nimmediate visual environment. However, a speaker's referential descriptions do\nnot always uniquely identify the referent, leading to ambiguities in need of\nresolution through subsequent clarificational exchanges. Thus, effective\nAmbiguity Detection and Coreference Resolution are key to task success in\nConversational AI. In this paper, we present models for these two tasks as part\nof the SIMMC 2.0 Challenge (Kottur et al. 2021). Specifically, we use TOD-BERT\nand LXMERT based models, compare them to a number of baselines and provide\nablation experiments. Our results show that (1) language models are able to\nexploit correlations in the data to detect ambiguity; and (2) unimodal\ncoreference resolution models can avoid the need for a vision component,\nthrough the use of smart object representations.", "published": "2022-02-25 12:10:02", "link": "http://arxiv.org/abs/2202.12645v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning\n  Work?", "abstract": "Large language models (LMs) are able to in-context learn -- perform a new\ntask via inference alone by conditioning on a few input-label pairs\n(demonstrations) and making predictions for new inputs. However, there has been\nlittle understanding of how the model learns and which aspects of the\ndemonstrations contribute to end task performance. In this paper, we show that\nground truth demonstrations are in fact not required -- randomly replacing\nlabels in the demonstrations barely hurts performance on a range of\nclassification and multi-choce tasks, consistently over 12 different models\nincluding GPT-3. Instead, we find that other aspects of the demonstrations are\nthe key drivers of end task performance, including the fact that they provide a\nfew examples of (1) the label space, (2) the distribution of the input text,\nand (3) the overall format of the sequence. Together, our analysis provides a\nnew way of understanding how and why in-context learning works, while opening\nup new questions about how much can be learned from large language models\nthrough inference alone.", "published": "2022-02-25 17:25:19", "link": "http://arxiv.org/abs/2202.12837v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge\n  Graph Completion", "abstract": "Knowledge graphs store a large number of factual triples while they are still\nincomplete, inevitably. The previous knowledge graph completion (KGC) models\npredict missing links between entities merely relying on fact-view data,\nignoring the valuable commonsense knowledge. The previous knowledge graph\nembedding (KGE) techniques suffer from invalid negative sampling and the\nuncertainty of fact-view link prediction, limiting KGC's performance. To\naddress the above challenges, we propose a novel and scalable Commonsense-Aware\nKnowledge Embedding (CAKE) framework to automatically extract commonsense from\nfactual triples with entity concepts. The generated commonsense augments\neffective self-supervision to facilitate both high-quality negative sampling\n(NS) and joint commonsense and fact-view link prediction. Experimental results\non the KGC task demonstrate that assembling our framework could enhance the\nperformance of the original KGE models, and the proposed commonsense-aware NS\nmodule is superior to other NS techniques. Besides, our proposed framework\ncould be easily adaptive to various KGE models and explain the predicted\nresults.", "published": "2022-02-25 03:30:22", "link": "http://arxiv.org/abs/2202.13785v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Deep Understanding based Multi-Document Machine Reading Comprehension", "abstract": "Most existing multi-document machine reading comprehension models mainly\nfocus on understanding the interactions between the input question and\ndocuments, but ignore following two kinds of understandings. First, to\nunderstand the semantic meaning of words in the input question and documents\nfrom the perspective of each other. Second, to understand the supporting cues\nfor a correct answer from the perspective of intra-document and\ninter-documents. Ignoring these two kinds of important understandings would\nmake the models oversee some important information that may be helpful for\ninding correct answers. To overcome this deiciency, we propose a deep\nunderstanding based model for multi-document machine reading comprehension. It\nhas three cascaded deep understanding modules which are designed to understand\nthe accurate semantic meaning of words, the interactions between the input\nquestion and documents, and the supporting cues for the correct answer. We\nevaluate our model on two large scale benchmark datasets, namely TriviaQA Web\nand DuReader. Extensive experiments show that our model achieves\nstate-of-the-art results on both datasets.", "published": "2022-02-25 12:56:02", "link": "http://arxiv.org/abs/2204.03494v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NeuralKG: An Open Source Library for Diverse Representation Learning of\n  Knowledge Graphs", "abstract": "NeuralKG is an open-source Python-based library for diverse representation\nlearning of knowledge graphs. It implements three different series of Knowledge\nGraph Embedding (KGE) methods, including conventional KGEs, GNN-based KGEs, and\nRule-based KGEs. With a unified framework, NeuralKG successfully reproduces\nlink prediction results of these methods on benchmarks, freeing users from the\nlaborious task of reimplementing them, especially for some methods originally\nwritten in non-python programming languages. Besides, NeuralKG is highly\nconfigurable and extensible. It provides various decoupled modules that can be\nmixed and adapted to each other. Thus with NeuralKG, developers and researchers\ncan quickly implement their own designed models and obtain the optimal training\nmethods to achieve the best performance efficiently. We built an website in\nhttp://neuralkg.zjukg.cn to organize an open and shared KG representation\nlearning community. The source code is all publicly released at\nhttps://github.com/zjukg/NeuralKG.", "published": "2022-02-25 09:13:13", "link": "http://arxiv.org/abs/2202.12571v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Survey of Multilingual Models for Automatic Speech Recognition", "abstract": "Although Automatic Speech Recognition (ASR) systems have achieved human-like\nperformance for a few languages, the majority of the world's languages do not\nhave usable systems due to the lack of large speech datasets to train these\nmodels. Cross-lingual transfer is an attractive solution to this problem,\nbecause low-resource languages can potentially benefit from higher-resource\nlanguages either through transfer learning, or being jointly trained in the\nsame multilingual model. The problem of cross-lingual transfer has been well\nstudied in ASR, however, recent advances in Self Supervised Learning are\nopening up avenues for unlabeled speech data to be used in multilingual ASR\nmodels, which can pave the way for improved performance on low-resource\nlanguages. In this paper, we survey the state of the art in multilingual ASR\nmodels that are built with cross-lingual transfer in mind. We present best\npractices for building multilingual models from research across diverse\nlanguages and techniques, discuss open questions and provide recommendations\nfor future work.", "published": "2022-02-25 09:31:40", "link": "http://arxiv.org/abs/2202.12576v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Language technology practitioners as language managers: arbitrating data\n  bias and predictive bias in ASR", "abstract": "Despite the fact that variation is a fundamental characteristic of natural\nlanguage, automatic speech recognition systems perform systematically worse on\nnon-standardised and marginalised language varieties. In this paper we use the\nlens of language policy to analyse how current practices in training and\ntesting ASR systems in industry lead to the data bias giving rise to these\nsystematic error differences. We believe that this is a useful perspective for\nspeech and language technology practitioners to understand the origins and\nharms of algorithmic bias, and how they can mitigate it. We also propose a\nre-framing of language resources as (public) infrastructure which should not\nsolely be designed for markets, but for, and with meaningful cooperation of,\nspeech communities.", "published": "2022-02-25 10:37:52", "link": "http://arxiv.org/abs/2202.12603v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Deep Learning, Natural Language Processing, and Explainable Artificial\n  Intelligence in the Biomedical Domain", "abstract": "In this article, we first give an introduction to artificial intelligence and\nits applications in biology and medicine in Section 1. Deep learning methods\nare then described in Section 2. We narrow down the focus of the study on\ntextual data in Section 3, where natural language processing and its\napplications in the biomedical domain are described. In Section 4, we give an\nintroduction to explainable artificial intelligence and discuss the importance\nof explainability of artificial intelligence systems, especially in the\nbiomedical domain.", "published": "2022-02-25 13:30:51", "link": "http://arxiv.org/abs/2202.12678v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "DataLab: A Platform for Data Analysis and Intervention", "abstract": "Despite data's crucial role in machine learning, most existing tools and\nresearch tend to focus on systems on top of existing data rather than how to\ninterpret and manipulate data. In this paper, we propose DataLab, a unified\ndata-oriented platform that not only allows users to interactively analyze the\ncharacteristics of data, but also provides a standardized interface for\ndifferent data processing operations. Additionally, in view of the ongoing\nproliferation of datasets, \\toolname has features for dataset recommendation\nand global vision analysis that help researchers form a better view of the data\necosystem. So far, DataLab covers 1,715 datasets and 3,583 of its transformed\nversion (e.g., hyponyms replacement), where 728 datasets support various\nanalyses (e.g., with respect to gender bias) with the help of 140M samples\nannotated by 318 feature functions. DataLab is under active development and\nwill be supported going forward. We have released a web platform, web API,\nPython SDK, PyPI published package and online documentation, which hopefully,\ncan meet the diverse needs of researchers.", "published": "2022-02-25 18:32:19", "link": "http://arxiv.org/abs/2202.12875v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning English with Peppa Pig", "abstract": "Recent computational models of the acquisition of spoken language via\ngrounding in perception exploit associations between the spoken and visual\nmodalities and learn to represent speech and visual data in a joint vector\nspace. A major unresolved issue from the point of ecological validity is the\ntraining data, typically consisting of images or videos paired with spoken\ndescriptions of what is depicted. Such a setup guarantees an unrealistically\nstrong correlation between speech and the visual data. In the real world the\ncoupling between the linguistic and the visual modality is loose, and often\nconfounded by correlations with non-semantic aspects of the speech signal. Here\nwe address this shortcoming by using a dataset based on the children's cartoon\nPeppa Pig. We train a simple bi-modal architecture on the portion of the data\nconsisting of dialog between characters, and evaluate on segments containing\ndescriptive narrations. Despite the weak and confounded signal in this training\ndata our model succeeds at learning aspects of the visual semantics of spoken\nlanguage.", "published": "2022-02-25 19:14:35", "link": "http://arxiv.org/abs/2202.12917v2", "categories": ["cs.CL", "cs.AI", "eess.AS", "eess.IV"], "primary_category": "cs.CL"}
{"title": "Harmonic gated compensation network plus for ICASSP 2022 DNS CHALLENGE", "abstract": "The harmonic structure of speech is resistant to noise, but the harmonics may\nstill be partially masked by noise. Therefore, we previously proposed a\nharmonic gated compensation network (HGCN) to predict the full harmonic\nlocations based on the unmasked harmonics and process the result of a coarse\nenhancement module to recover the masked harmonics. In addition, the auditory\nloudness loss function is used to train the network. For the DNS Challenge, we\nupdate HGCN with the following aspects, resulting in HGCN+. First, a high-band\nmodule is employed to help the model handle full-band signals. Second, cosine\nis used to model the harmonic structure more accurately. Then, the dual-path\nencoder and dual-path rnn (DPRNN) are introduced to take full advantage of the\nfeatures. Finally, a gated residual linear structure replaces the gated\nconvolution in the compensation module to increase the receptive field of\nfrequency. The experimental results show that each updated module brings\nperformance improvement to the model. HGCN+ also outperforms the referenced\nmodels on both wide-band and full-band test sets.", "published": "2022-02-25 12:07:14", "link": "http://arxiv.org/abs/2202.12643v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Neural Network for Automatic Assessment of Dysphonia", "abstract": "The purpose of this work is to contribute to the understanding and\nimprovement of deep neural networks in the field of vocal quality. A neural\nnetwork that predicts the perceptual assessment of overall severity of\ndysphonia in GRBAS scale is obtained. The design focuses on amplitude\nperturbations, frequency perturbations, and noise. Results are compared with\nperformance of human raters on the same data. Both the precision and the mean\nabsolute error of the neural network are close to human intra-rater\nperformance, exceeding inter-rater performance.", "published": "2022-02-25 20:13:32", "link": "http://arxiv.org/abs/2202.12957v1", "categories": ["eess.AS", "cs.SD", "q-bio.QM"], "primary_category": "eess.AS"}
