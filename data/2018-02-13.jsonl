{"title": "Sentence Boundary Detection for French with Subword-Level Information\n  Vectors and Convolutional Neural Networks", "abstract": "In this work we tackle the problem of sentence boundary detection applied to\nFrench as a binary classification task (\"sentence boundary\" or \"not sentence\nboundary\"). We combine convolutional neural networks with subword-level\ninformation vectors, which are word embedding representations learned from\nWikipedia that take advantage of the words morphology; so each word is\nrepresented as a bag of their character n-grams.\n  We decide to use a big written dataset (French Gigaword) instead of standard\nsize transcriptions to train and evaluate the proposed architectures with the\nintention of using the trained models in posterior real life ASR\ntranscriptions.\n  Three different architectures are tested showing similar results; general\naccuracy for all models overpasses 0.96. All three models have good F1 scores\nreaching values over 0.97 regarding the \"not sentence boundary\" class. However,\nthe \"sentence boundary\" class reflects lower scores decreasing the F1 metric to\n0.778 for one of the models.\n  Using subword-level information vectors seem to be very effective leading to\nconclude that the morphology of words encoded in the embeddings representations\nbehave like pixels in an image making feasible the use of convolutional neural\nnetwork architectures.", "published": "2018-02-13 11:04:07", "link": "http://arxiv.org/abs/1802.04559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Network Features Based Co-hyponymy Detection", "abstract": "Distinguishing lexical relations has been a long term pursuit in natural\nlanguage processing (NLP) domain. Recently, in order to detect lexical\nrelations like hypernymy, meronymy, co-hyponymy etc., distributional semantic\nmodels are being used extensively in some form or the other. Even though a lot\nof efforts have been made for detecting hypernymy relation, the problem of\nco-hyponymy detection has been rarely investigated. In this paper, we are\nproposing a novel supervised model where various network measures have been\nutilized to identify co-hyponymy relation with high accuracy performing better\nor at par with the state-of-the-art models.", "published": "2018-02-13 13:22:19", "link": "http://arxiv.org/abs/1802.04609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Examining the Tip of the Iceberg: A Data Set for Idiom Translation", "abstract": "Neural Machine Translation (NMT) has been widely used in recent years with\nsignificant improvements for many language pairs. Although state-of-the-art NMT\nsystems are generating progressively better translations, idiom translation\nremains one of the open challenges in this field. Idioms, a category of\nmultiword expressions, are an interesting language phenomenon where the overall\nmeaning of the expression cannot be composed from the meanings of its parts. A\nfirst important challenge is the lack of dedicated data sets for learning and\nevaluating idiom translation. In this paper we address this problem by creating\nthe first large-scale data set for idiom translation. Our data set is\nautomatically extracted from a widely used German-English translation corpus\nand includes, for each language direction, a targeted evaluation set where all\nsentences contain idioms and a regular training corpus where sentences\nincluding idioms are marked. We release this data set and use it to perform\npreliminary NMT experiments as the first step towards better idiom translation.", "published": "2018-02-13 15:25:21", "link": "http://arxiv.org/abs/1802.04681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Short Survey on Sense-Annotated Corpora", "abstract": "Large sense-annotated datasets are increasingly necessary for training deep\nsupervised systems in Word Sense Disambiguation. However, gathering\nhigh-quality sense-annotated data for as many instances as possible is a\nlaborious and expensive task. This has led to the proliferation of automatic\nand semi-automatic methods for overcoming the so-called knowledge-acquisition\nbottleneck. In this short survey we present an overview of sense-annotated\ncorpora, annotated either manually- or (semi)automatically, that are currently\navailable for different languages and featuring distinct lexical resources as\ninventory of senses, i.e. WordNet, Wikipedia, BabelNet. Furthermore, we provide\nthe reader with general statistics of each dataset and an analysis of their\nspecific features.", "published": "2018-02-13 17:10:54", "link": "http://arxiv.org/abs/1802.04744v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"How Was Your Weekend?\" A Generative Model of Phatic Conversation", "abstract": "Unspoken social rules, such as those that govern choosing a proper discussion\ntopic and when to change discussion topics, guide conversational behaviors. We\npropose a computational model of conversation that can follow or break such\nrules, with participant agents that respond accordingly. Additionally, we\ndemonstrate an application of the model: the Experimental Social Tutor (EST), a\nfirst step toward a social skills training tool that generates human-readable\nconversation and a conversational guideline at each point in the dialogue.\nFinally, we discuss the design and results of a pilot study evaluating the EST.\nResults show that our model is capable of producing conversations that follow\nsocial norms.", "published": "2018-02-13 01:43:44", "link": "http://arxiv.org/abs/1802.04425v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attention based Sentence Extraction from Scientific Articles using\n  Pseudo-Labeled data", "abstract": "In this work, we present a weakly supervised sentence extraction technique\nfor identifying important sentences in scientific papers that are worthy of\ninclusion in the abstract. We propose a new attention based deep learning\narchitecture that jointly learns to identify important content, as well as the\ncue phrases that are indicative of summary worthy sentences. We propose a new\ncontext embedding technique for determining the focus of a given paper using\ntopic models and use it jointly with an LSTM based sequence encoder to learn\nattention weights across the sentence words. We use a collection of articles\npublicly available through ACL anthology for our experiments. Our system\nachieves a performance that is better, in terms of several ROUGE metrics, as\ncompared to several state of art extractive techniques. It also generates more\ncoherent summaries and preserves the overall structure of the document.", "published": "2018-02-13 15:13:28", "link": "http://arxiv.org/abs/1802.04675v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Structured-based Curriculum Learning for End-to-end English-Japanese\n  Speech Translation", "abstract": "Sequence-to-sequence attentional-based neural network architectures have been\nshown to provide a powerful model for machine translation and speech\nrecognition. Recently, several works have attempted to extend the models for\nend-to-end speech translation task. However, the usefulness of these models\nwere only investigated on language pairs with similar syntax and word order\n(e.g., English-French or English-Spanish). In this work, we focus on end-to-end\nspeech translation tasks on syntactically distant language pairs (e.g.,\nEnglish-Japanese) that require distant word reordering.\n  To guide the encoder-decoder attentional model to learn this difficult\nproblem, we propose a structured-based curriculum learning strategy.\n  Unlike conventional curriculum learning that gradually emphasizes difficult\ndata examples, we formalize learning strategies from easier network structures\nto more difficult network structures. Here, we start the training with\nend-to-end encoder-decoder for speech recognition or text-based machine\ntranslation task then gradually move to end-to-end speech translation task. The\nexperiment results show that the proposed approach could provide significant\nimprovements in comparison with the one without curriculum learning.", "published": "2018-02-13 11:33:27", "link": "http://arxiv.org/abs/1802.06003v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Phased Microphone Array for Sound Source Localization with Deep Learning", "abstract": "To phased microphone array for sound source localization, algorithm with both\nhigh computational efficiency and high precision is a persistent pursuit. In\nthis paper convolutional neural network (CNN) a kind of deep learning is\npreliminarily applied as a new algorithm. At high frequency CNN can reconstruct\nthe sound localizations with excellent spatial resolution as good as DAMAS,\nwithin a very short time as short as conventional beamforming. This exciting\nresult means that CNN perfectly finds source distribution directly from\ncross-spectral matrix without given propagation function in advance, and thus\nCNN deserves to be further explored as a new algorithm.", "published": "2018-02-13 06:53:48", "link": "http://arxiv.org/abs/1802.04479v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Enhancement of Noisy Speech with Low Speech Distortion Based on\n  Probabilistic Geometric Spectral Subtraction", "abstract": "A speech enhancement method based on probabilistic geometric approach to\nspectral subtraction (PGA) performed on short time magnitude spectrum is\npresented in this paper. A confidence parameter of noise estimation is\nintroduced in the gain function of the proposed method to prevent subtraction\nof the overestimated and underestimated noise, which not only removes the noise\nefficiently but also prevents the speech distortion. The noise compensated\nmagnitude spectrum is then recombined with the unchanged phase spectrum to\nproduce a modified complex spectrum prior to synthesize an enhanced frame.\nExtensive simulations are carried out using the speech files available in the\nNOIZEUS database in order to evaluate the performance of the proposed method.", "published": "2018-02-13 01:32:34", "link": "http://arxiv.org/abs/1802.05125v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Close Miking Empirical Practice Verification: A Source Separation\n  Approach", "abstract": "Close miking represents a widely employed practice of placing a microphone\nvery near to the sound source in order to capture more direct sound and\nminimize any pickup of ambient sound, including other, concurrently active\nsources. It is used by the audio engineering community for decades for audio\nrecording, based on a number of empirical rules that were evolved during the\nrecording practice itself. But can this empirical knowledge and close miking\npractice be systematically verified? In this work we aim to address this\nquestion based on an analytic methodology that employs techniques and metrics\noriginating from the sound source separation evaluation field. In particular,\nwe apply a quantitative analysis of the source separation capabilities of the\nclose miking technique. The analysis is applied on a recording dataset obtained\nat multiple positions of a typical musical hall, multiple distances between the\nmicrophone and the sound source multiple microphone types and multiple level\ndifferences between the sound source and the ambient acoustic component. For\nall the above cases we compute the Source to Interference Ratio (SIR) metric.\nThe results obtained clearly demonstrate an optimum close-miking performance\nthat matches the current empirical knowledge of professional audio recording.", "published": "2018-02-13 09:42:46", "link": "http://arxiv.org/abs/1802.05132v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
