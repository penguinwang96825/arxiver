{"title": "From Spatial Relations to Spatial Configurations", "abstract": "Spatial Reasoning from language is essential for natural language\nunderstanding. Supporting it requires a representation scheme that can capture\nspatial phenomena encountered in language as well as in images and videos.\nExisting spatial representations are not sufficient for describing spatial\nconfigurations used in complex tasks. This paper extends the capabilities of\nexisting spatial representation languages and increases coverage of the\nsemantic aspects that are needed to ground the spatial meaning of natural\nlanguage text in the world. Our spatial relation language is able to represent\na large, comprehensive set of spatial concepts crucial for reasoning and is\ndesigned to support the composition of static and dynamic spatial\nconfigurations. We integrate this language with the Abstract Meaning\nRepresentation(AMR) annotation schema and present a corpus annotated by this\nextended AMR. To exhibit the applicability of our representation scheme, we\nannotate text taken from diverse datasets and show how we extend the\ncapabilities of existing spatial representation languages with the fine-grained\ndecomposition of semantics and blend it seamlessly with AMRs of sentences and\ndiscourse representations as a whole.", "published": "2020-07-19 02:11:53", "link": "http://arxiv.org/abs/2007.09557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Overview of Natural Language State Representation for Reinforcement\n  Learning", "abstract": "A suitable state representation is a fundamental part of the learning process\nin Reinforcement Learning. In various tasks, the state can either be described\nby natural language or be natural language itself. This survey outlines the\nstrategies used in the literature to build natural language state\nrepresentations. We appeal for more linguistically interpretable and grounded\nrepresentations, careful justification of design decisions and evaluation of\nthe effectiveness of different approaches.", "published": "2020-07-19 20:15:55", "link": "http://arxiv.org/abs/2007.09774v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Referring Expression Comprehension: A Survey of Methods and Datasets", "abstract": "Referring expression comprehension (REC) aims to localize a target object in\nan image described by a referring expression phrased in natural language.\nDifferent from the object detection task that queried object labels have been\npre-defined, the REC problem only can observe the queries during the test. It\nthus more challenging than a conventional computer vision problem. This task\nhas attracted a lot of attention from both computer vision and natural language\nprocessing community, and several lines of work have been proposed, from\nCNN-RNN model, modular network to complex graph-based model. In this survey, we\nfirst examine the state of the art by comparing modern approaches to the\nproblem. We classify methods by their mechanism to encode the visual and\ntextual modalities. In particular, we examine the common approach of joint\nembedding images and expressions to a common feature space. We also discuss\nmodular architectures and graph-based models that interface with structured\ngraph representation. In the second part of this survey, we review the datasets\navailable for training and evaluating REC systems. We then group results\naccording to the datasets, backbone models, settings so that they can be fairly\ncompared. Finally, we discuss promising future directions for the field, in\nparticular the compositional referring expression comprehension that requires\nlonger reasoning chain to address.", "published": "2020-07-19 01:45:02", "link": "http://arxiv.org/abs/2007.09554v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Meta-learning for Few-shot Natural Language Processing: A Survey", "abstract": "Few-shot natural language processing (NLP) refers to NLP tasks that are\naccompanied with merely a handful of labeled examples. This is a real-world\nchallenge that an AI system must learn to handle. Usually we rely on collecting\nmore auxiliary information or developing a more efficient learning algorithm.\nHowever, the general gradient-based optimization in high capacity models, if\ntraining from scratch, requires many parameter-updating steps over a large\nnumber of labeled examples to perform well (Snell et al., 2017). If the target\ntask itself cannot provide more information, how about collecting more tasks\nequipped with rich annotations to help the model learning? The goal of\nmeta-learning is to train a model on a variety of tasks with rich annotations,\nsuch that it can solve a new task using only a few labeled samples. The key\nidea is to train the model's initial parameters such that the model has maximal\nperformance on a new task after the parameters have been updated through zero\nor a couple of gradient steps. There are already some surveys for\nmeta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales\net al., 2020). Nevertheless, this paper focuses on NLP domain, especially\nfew-shot applications. We try to provide clearer definitions, progress summary\nand some common datasets of applying meta-learning to few-shot NLP.", "published": "2020-07-19 06:36:41", "link": "http://arxiv.org/abs/2007.09604v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Political Framing: US COVID19 Blame Game", "abstract": "Through the use of Twitter, framing has become a prominent presidential\ncampaign tool for politically active users. Framing is used to influence\nthoughts by evoking a particular perspective on an event. In this paper, we\nshow that the COVID19 pandemic rather than being viewed as a public health\nissue, political rhetoric surrounding it is mostly shaped through a blame frame\n(blame Trump, China, or conspiracies) and a support frame (support candidates)\nbacking the agenda of Republican and Democratic users in the lead up to the\n2020 presidential campaign. We elucidate the divergences between supporters of\nboth parties on Twitter via the use of frames. Additionally, we show how\nframing is used to positively or negatively reinforce users' thoughts. We look\nat how Twitter can efficiently be used to identify frames for topics through a\nreproducible pipeline.", "published": "2020-07-19 12:00:25", "link": "http://arxiv.org/abs/2007.09655v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "One-Shot Learning for Language Modelling", "abstract": "Humans can infer a great deal about the meaning of a word, using the syntax\nand semantics of surrounding words even if it is their first time reading or\nhearing it. We can also generalise the learned concept of the word to new\ntasks. Despite great progress in achieving human-level performance in certain\ntasks (Silver et al., 2016), learning from one or few examples remains a key\nchallenge in machine learning, and has not thoroughly been explored in Natural\nLanguage Processing (NLP).\n  In this work we tackle the problem of oneshot learning for an NLP task by\nemploying ideas from recent developments in machine learning: embeddings,\nattention mechanisms (softmax) and similarity measures (cosine, Euclidean,\nPoincare, and Minkowski). We adapt the framework suggested in matching networks\n(Vinyals et al., 2016), and explore the effectiveness of the aforementioned\nmethods in one, two and three-shot learning problems on the task of predicting\nmissing word explored in (Vinyals et al., 2016) by using the WikiText-2\ndataset. Our work contributes in two ways: Our first contribution is that we\nexplore the effectiveness of different distance metrics on k-shot learning, and\nshow that there is no single best distance metric for k-shot learning, which\nchallenges common belief. We found that the performance of a distance metric\ndepends on the number of shots used during training. The second contribution of\nour work is that we establish a benchmark for one, two, and three-shot learning\non a language task with a publicly available dataset that can be used to\nbenchmark against in future research.", "published": "2020-07-19 14:33:03", "link": "http://arxiv.org/abs/2007.09679v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks", "abstract": "BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.", "published": "2020-07-19 19:13:20", "link": "http://arxiv.org/abs/2007.09757v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Spatial Relations through Multiple Modalities", "abstract": "Recognizing spatial relations and reasoning about them is essential in\nmultiple applications including navigation, direction giving and human-computer\ninteraction in general. Spatial relations between objects can either be\nexplicit -- expressed as spatial prepositions, or implicit -- expressed by\nspatial verbs such as moving, walking, shifting, etc. Both these, but implicit\nrelations in particular, require significant common sense understanding. In\nthis paper, we introduce the task of inferring implicit and explicit spatial\nrelations between two entities in an image. We design a model that uses both\ntextual and visual information to predict the spatial relations, making use of\nboth positional and size information of objects and image embeddings. We\ncontrast our spatial model with powerful language models and show how our\nmodeling complements the power of these, improving prediction accuracy and\ncoverage and facilitates dealing with unseen subjects, objects and relations.", "published": "2020-07-19 01:35:08", "link": "http://arxiv.org/abs/2007.09551v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Length-Controllable Image Captioning", "abstract": "The last decade has witnessed remarkable progress in the image captioning\ntask; however, most existing methods cannot control their captions,\n\\emph{e.g.}, choosing to describe the image either roughly or in detail. In\nthis paper, we propose to use a simple length level embedding to endow them\nwith this ability. Moreover, due to their autoregressive nature, the\ncomputational complexity of existing models increases linearly as the length of\nthe generated captions grows. Thus, we further devise a non-autoregressive\nimage captioning approach that can generate captions in a length-irrelevant\ncomplexity. We verify the merit of the proposed length level embedding on three\nmodels: two state-of-the-art (SOTA) autoregressive models with different types\nof decoder, as well as our proposed non-autoregressive model, to show its\ngeneralization ability. In the experiments, our length-controllable image\ncaptioning models not only achieve SOTA performance on the challenging MS COCO\ndataset but also generate length-controllable and diverse image captions.\nSpecifically, our non-autoregressive model outperforms the autoregressive\nbaselines in terms of controllability and diversity, and also significantly\nimproves the decoding efficiency for long captions. Our code and models are\nreleased at \\textcolor{magenta}{\\texttt{https://github.com/bearcatt/LaBERT}}.", "published": "2020-07-19 03:40:51", "link": "http://arxiv.org/abs/2007.09580v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Reinforcement Communication Learning in Different Social Network\n  Structures", "abstract": "Social network structure is one of the key determinants of human language\nevolution. Previous work has shown that the network of social interactions\nshapes decentralized learning in human groups, leading to the emergence of\ndifferent kinds of communicative conventions. We examined the effects of social\nnetwork organization on the properties of communication systems emerging in\ndecentralized, multi-agent reinforcement learning communities. We found that\nthe global connectivity of a social network drives the convergence of\npopulations on shared and symmetric communication systems, preventing the\nagents from forming many local \"dialects\". Moreover, the agent's degree is\ninversely related to the consistency of its use of communicative conventions.\nThese results show the importance of the basic properties of social network\nstructure on reinforcement communication learning and suggest a new\ninterpretation of findings on human convergence on word conventions.", "published": "2020-07-19 23:57:30", "link": "http://arxiv.org/abs/2007.09820v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Meta-learning with Latent Space Clustering in Generative Adversarial\n  Network for Speaker Diarization", "abstract": "The performance of most speaker diarization systems with x-vector embeddings\nis both vulnerable to noisy environments and lacks domain robustness. Earlier\nwork on speaker diarization using generative adversarial network (GAN) with an\nencoder network (ClusterGAN) to project input x-vectors into a latent space has\nshown promising performance on meeting data. In this paper, we extend the\nClusterGAN network to improve diarization robustness and enable rapid\ngeneralization across various challenging domains. To this end, we fetch the\npre-trained encoder from the ClusterGAN and fine-tune it by using prototypical\nloss (meta-ClusterGAN or MCGAN) under the meta-learning paradigm. Experiments\nare conducted on CALLHOME telephonic conversations, AMI meeting data, DIHARD II\n(dev set) which includes challenging multi-domain corpus, and two\nchild-clinician interaction corpora (ADOS, BOSCC) related to the autism\nspectrum disorder domain. Extensive analyses of the experimental data are done\nto investigate the effectiveness of the proposed ClusterGAN and MCGAN\nembeddings over x-vectors. The results show that the proposed embeddings with\nnormalized maximum eigengap spectral clustering (NME-SC) back-end consistently\noutperform Kaldi state-of-the-art z-vector diarization system. Finally, we\nemploy embedding fusion with x-vectors to provide further improvement in\ndiarization performance. We achieve a relative diarization error rate (DER)\nimprovement of 6.67% to 53.93% on the aforementioned datasets using the\nproposed fused embeddings over x-vectors. Besides, the MCGAN embeddings provide\nbetter performance in the number of speakers estimation and short speech\nsegment diarization as compared to x-vectors and ClusterGAN in telephonic data.", "published": "2020-07-19 09:33:40", "link": "http://arxiv.org/abs/2007.09635v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
