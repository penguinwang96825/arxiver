{"title": "Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics", "abstract": "We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.", "published": "2024-11-21 17:39:23", "link": "http://arxiv.org/abs/2412.00036v3", "categories": ["q-fin.CP", "cs.AI", "cs.CE", "q-fin.PM"], "primary_category": "q-fin.CP"}
{"title": "Wavelet Analysis of Cryptocurrencies -- Non-Linear Dynamics in High Frequency Domains", "abstract": "In this study, we perform some analysis for the probability distributions in\nthe space of frequency and time variables. However, in the domain of high\nfrequencies, it behaves in such a way as the highly non-linear dynamics. The\nwavelet analysis is a powerful tool to perform such analysis in order to search\nfor the characteristics of frequency variations over time for the prices of\nmajor cryptocurrencies. In fact, the wavelet analysis is found to be quite\nuseful as it examine the validity of the efficient market hypothesis in the\nweak form, especially for the presence of the cyclical persistence at different\nfrequencies. If we could find some cyclical persistence at different\nfrequencies, that means that there exist some intrinsic causal relationship for\nsome given investment horizons defined by some chosen sampling scales. This is\none of the characteristic results of the wavelet analysis in the time-frequency\ndomains.", "published": "2024-11-21 12:12:30", "link": "http://arxiv.org/abs/2411.14058v1", "categories": ["q-fin.GN", "econ.GN", "q-fin.CP", "q-fin.EC", "q-fin.ST"], "primary_category": "q-fin.GN"}
{"title": "Analytical Formula for Fractional-Order Conditional Moments of Nonlinear Drift CEV Process with Regime Switching: Hybrid Approach with Applications", "abstract": "This paper introduces an analytical formula for the fractional-order\nconditional moments of nonlinear drift constant elasticity of variance\n(NLD-CEV) processes under regime switching, governed by continuous-time\nfinite-state irreducible Markov chains. By employing a hybrid system approach,\nwe derive exact closed-form expressions for these moments across arbitrary\nfractional orders and regime states, thereby enhancing the analytical\ntractability of NLD-CEV models under stochastic regimes. Our methodology hinges\non formulating and solving a complex system of interconnected partial\ndifferential equations derived from the Feynman-Kac formula for switching\ndiffusions. To illustrate the practical relevance of our approach, Monte Carlo\nsimulations for process with Markovian switching are applied to validate the\naccuracy and computational efficiency of the analytical formulas. Furthermore,\nwe apply our findings for the valuation of financial derivatives within a\ndynamic nonlinear mean-reverting regime-switching framework, which demonstrates\nsignificant improvements over traditional methods. This work offers substantial\ncontributions to financial modeling and derivative pricing by providing a\nrobust tool for practitioners and researchers who are dealing with complex\nstochastic environments.", "published": "2024-11-21 08:36:52", "link": "http://arxiv.org/abs/2411.13937v2", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Multiscale Markowitz", "abstract": "Traditional Markowitz portfolio optimization constrains daily portfolio\nvariance to a target value, optimising returns, Sharpe or variance within this\nconstraint. However, this approach overlooks the relationship between variance\nat different time scales, typically described by $\\sigma(\\Delta t) \\propto\n(\\Delta t)^{H}$ where $H$ is the Hurst exponent, most of the time assumed to be\n\\(\\frac{1}{2}\\). This paper introduces a multifrequency optimization framework\nthat allows investors to specify target portfolio variance across a range of\nfrequencies, characterized by a target Hurst exponent $H_{target}$, or optimize\nthe portfolio at multiple time scales. By incorporating this scaling behavior,\nwe enable a more nuanced and comprehensive risk management strategy that aligns\nwith investor preferences at various time scales. This approach effectively\nmanages portfolio risk across multiple frequencies and adapts to different\nmarket conditions, providing a robust tool for dynamic asset allocation. This\novercomes some of the traditional limitations of Markowitz, when it comes to\ndealing with crashes, regime changes, volatility clustering or multifractality\nin markets. We illustrate this concept with a toy example and discuss the\npractical implementation for assets with varying scaling behaviors.", "published": "2024-11-21 02:37:54", "link": "http://arxiv.org/abs/2411.13792v1", "categories": ["q-fin.PM", "nlin.CD", "q-fin.MF"], "primary_category": "q-fin.PM"}
{"title": "Forecasting the Price of Rice in Banda Aceh after Covid-19", "abstract": "This research aims to predict the price of rice in Banda Aceh after the\noccurrence of Covid-19. The last observation carried forward (LOCF) imputation\ntechnique has been used to solve the problem of missing values from this\nresearch data. Furthermore, the technique used to forecast rice prices in Banda\nAceh is auto-ARIMA which is the best ARIMA model based on AIC, AICC, or BIC\nvalues. The results of this research show that the ARIMA model (0,0,5) is the\nbest model to predict the prices of lower quality rice I (BKB1), lower quality\nrice II (BKB2), medium quality rice I (BKM1), medium quality rice II (BKM2),\nsuper quality rice I (BKS1), and super quality rice II (BKS2). Based on this\nmodel, the results of forecasting rice prices for all qualities show that there\nwas a decline for some time (between September 1, 2023 and September 6, 2023)\nand then remained constant (between September 6, 2023 and December 31, 2023).", "published": "2024-11-21 13:44:57", "link": "http://arxiv.org/abs/2411.15228v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Calculating Profits and Losses for Algorithmic Trading Strategies: A Short Guide", "abstract": "We present a series of equations that track the total realized and unrealized\nprofits and losses at any time, incorporating the spread. The resulting\nformalism is ideally suited to evaluate the performance of trading model\nalgorithms.", "published": "2024-11-21 12:31:14", "link": "http://arxiv.org/abs/2411.14068v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Market Making without Regret", "abstract": "We consider a sequential decision-making setting where, at every round $t$, a\nmarket maker posts a bid price $B_t$ and an ask price $A_t$ to an incoming\ntrader (the taker) with a private valuation for one unit of some asset. If the\ntrader's valuation is lower than the bid price, or higher than the ask price,\nthen a trade (sell or buy) occurs. If a trade happens at round $t$, then\nletting $M_t$ be the market price (observed only at the end of round $t$), the\nmaker's utility is $M_t - B_t$ if the maker bought the asset, and $A_t - M_t$\nif they sold it. We characterize the maker's regret with respect to the best\nfixed choice of bid and ask pairs under a variety of assumptions (adversarial,\ni.i.d., and their variants) on the sequence of market prices and valuations.\nOur upper bound analysis unveils an intriguing connection relating market\nmaking to first-price auctions and dynamic pricing. Our main technical\ncontribution is a lower bound for the i.i.d. case with Lipschitz distributions\nand independence between prices and valuations. The difficulty in the analysis\nstems from the unique structure of the reward and feedback functions, allowing\nan algorithm to acquire information by graduating the \"cost of exploration\" in\nan arbitrary way.", "published": "2024-11-21 10:13:55", "link": "http://arxiv.org/abs/2411.13993v1", "categories": ["cs.GT", "cs.LG", "q-fin.TR"], "primary_category": "cs.GT"}
{"title": "Does the square-root price impact law belong to the strict universal scalings?: quantitative support by a complete survey of the Tokyo stock exchange market", "abstract": "Universal power laws have been scrutinised in physics and beyond, and a\nlong-standing debate exists in econophysics regarding the strict universality\nof the nonlinear price impact, commonly referred to as the square-root law\n(SRL). The SRL posits that the average price impact $I$ follows a power law\nwith respect to transaction volume $Q$, such that $I(Q) \\propto Q^{\\delta}$\nwith $\\delta \\approx 1/2$. Some researchers argue that the exponent $\\delta$\nshould be system-specific, without universality. Conversely, others contend\nthat $\\delta$ should be exactly $1/2$ for all stocks across all countries,\nimplying universality. However, resolving this debate requires high-precision\nmeasurements of $\\delta$ with errors of around $0.1$ across hundreds of stocks,\nwhich has been extremely challenging due to the scarcity of large microscopic\ndatasets -- those that enable tracking the trading behaviour of all individual\naccounts. Here we conclusively support the universality hypothesis of the SRL\nby a complete survey of all trading accounts for all liquid stocks on the Tokyo\nStock Exchange (TSE) over eight years. Using this comprehensive microscopic\ndataset, we show that the exponent $\\delta$ is equal to $1/2$ within\nstatistical errors at both the individual stock level and the individual trader\nlevel. Additionally, we rejected two prominent models supporting the\nnonuniversality hypothesis: the Gabaix-Gopikrishnan-Plerou-Stanley and the\nFarmer-Gerig-Lillo-Waelbroeck models. Our work provides exceptionally\nhigh-precision evidence for the universality hypothesis in social science and\ncould prove useful in evaluating the price impact by large investors -- an\nimportant topic even among practitioners.", "published": "2024-11-21 09:28:26", "link": "http://arxiv.org/abs/2411.13965v1", "categories": ["q-fin.TR", "cond-mat.stat-mech", "econ.GN", "q-fin.EC", "q-fin.PM", "q-fin.RM"], "primary_category": "q-fin.TR"}
{"title": "Explaining GPT-4's Schema of Depression Using Machine Behavior Analysis", "abstract": "Use of large language models such as ChatGPT (GPT-4) for mental health\nsupport has grown rapidly, emerging as a promising route to assess and help\npeople with mood disorders, like depression. However, we have a limited\nunderstanding of GPT-4's schema of mental disorders, that is, how it internally\nassociates and interprets symptoms. In this work, we leveraged contemporary\nmeasurement theory to decode how GPT-4 interrelates depressive symptoms to\ninform both clinical utility and theoretical understanding. We found GPT-4's\nassessment of depression: (a) had high overall convergent validity (r = .71\nwith self-report on 955 samples, and r = .81 with experts judgments on 209\nsamples); (b) had moderately high internal consistency (symptom\ninter-correlates r = .23 to .78 ) that largely aligned with literature and\nself-report; except that GPT-4 (c) underemphasized suicidality's -- and\noveremphasized psychomotor's -- relationship with other symptoms, and (d) had\nsymptom inference patterns that suggest nuanced hypotheses (e.g. sleep and\nfatigue are influenced by most other symptoms while feelings of\nworthlessness/guilt is mostly influenced by depressed mood).", "published": "2024-11-21 02:58:23", "link": "http://arxiv.org/abs/2411.13800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemiKong: Curating, Training, and Evaluating A Semiconductor\n  Industry-Specific Large Language Model", "abstract": "Large Language Models (LLMs) have demonstrated the potential to address some\nissues within the semiconductor industry. However, they are often\ngeneral-purpose models that lack the specialized knowledge needed to tackle the\nunique challenges of this sector, such as the intricate physics and chemistry\nof semiconductor devices and processes. SemiKong, the first industry-specific\nLLM for the semiconductor domain, provides a foundation that can be used to\ndevelop tailored proprietary models. With SemiKong 1.0, we aim to develop a\nfoundational model capable of understanding etching problems at an expert\nlevel. Our key contributions include (a) curating a comprehensive corpus of\nsemiconductor-related texts, (b) creating a foundational model with in-depth\nsemiconductor knowledge, and (c) introducing a framework for integrating expert\nknowledge, thereby advancing the evaluation process of domain-specific AI\nmodels. Through fine-tuning a pre-trained LLM using our curated dataset, we\nhave shown that SemiKong outperforms larger, general-purpose LLMs in various\nsemiconductor manufacturing and design tasks. Our extensive experiments\nunderscore the importance of developing domain-specific LLMs as a foundation\nfor company- or tool-specific proprietary models, paving the way for further\nresearch and applications in the semiconductor domain. Code and dataset will be\navailable at https://github.com/aitomatic/semikong", "published": "2024-11-21 03:05:38", "link": "http://arxiv.org/abs/2411.13802v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel\n  Planning", "abstract": "How are LLM-based agents used in the future? While many of the existing work\non agents has focused on improving the performance of a specific family of\nobjective and challenging tasks, in this work, we take a different perspective\nby thinking about full delegation: agents take over humans' routine\ndecision-making processes and are trusted by humans to find solutions that fit\npeople's personalized needs and are adaptive to ever-changing context. In order\nto achieve such a goal, the behavior of the agents, i.e., agentic behaviors,\nshould be evaluated not only on their achievements (i.e., outcome evaluation),\nbut also how they achieved that (i.e., procedure evaluation). For this, we\npropose APEC Agent Constitution, a list of criteria that an agent should follow\nfor good agentic behaviors, including Accuracy, Proactivity, Efficiency and\nCredibility. To verify whether APEC aligns with human preferences, we develop\nAPEC-Travel, a travel planning agent that proactively extracts hidden\npersonalized needs via multi-round dialog with travelers. APEC-Travel is\nconstructed purely from synthetic data generated by Llama3.1-405B-Instruct with\na diverse set of travelers' persona to simulate rich distribution of dialogs.\nIteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses\nbaselines by 20.7% on rule-based metrics and 9.1% on LLM-as-a-Judge scores\nacross the constitution axes.", "published": "2024-11-21 07:30:02", "link": "http://arxiv.org/abs/2411.13904v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRPruning: Efficient Large Language Model Pruning through\n  Distributionally Robust Optimization", "abstract": "Large language models (LLMs) deliver impressive results but face challenges\nfrom increasing model sizes and computational costs. Structured pruning reduces\nmodel size and speeds up inference but often causes uneven degradation across\ndomains, leading to biased performance. To address this, we propose DRPruning,\nwhich incorporates distributionally robust optimization to restore balanced\nperformance across domains, along with further improvements to enhance\nrobustness. Experiments in monolingual and multilingual settings show that our\nmethod surpasses similarly sized models in pruning and continued pretraining\nover perplexity, downstream tasks, and instruction tuning. We further provide\nanalysis demonstrating the robustness of our method towards various domains and\ndistribution shifts. Furthermore, our method automatically determines optimal\nreference losses and data ratios, suggesting potential for broader\napplications. Our code is available at https://github.com/hexuandeng/DRPruning.", "published": "2024-11-21 12:02:39", "link": "http://arxiv.org/abs/2411.14055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Inference: Rediscovering the Role of Natural Language Inference\n  for Large Language Models", "abstract": "In the recent past, a popular way of evaluating natural language\nunderstanding (NLU), was to consider a model's ability to perform natural\nlanguage inference (NLI) tasks. In this paper, we investigate if NLI tasks,\nthat are rarely used for LLM evaluation, can still be informative for\nevaluating LLMs. Focusing on five different NLI benchmarks across six models of\ndifferent scales, we investigate if they are able to discriminate models of\ndifferent size and quality and how their accuracies develop during training.\nFurthermore, we investigate the extent to which the softmax distributions of\nmodels align with human distributions in cases where statements are ambiguous\nor vague. Overall, our results paint a positive picture for the NLI tasks: we\nfind that they are able to discriminate well between models at various stages\nof training, yet are not (all) saturated. Furthermore, we find that while the\nsimilarity of model distributions with human label distributions increases with\nscale, it is still much higher than the similarity between two populations of\nhumans, making it a potentially interesting statistic to consider.", "published": "2024-11-21 13:09:36", "link": "http://arxiv.org/abs/2411.14103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from \"Silly\" Questions Improves Large Language Models, But Only\n  Slightly", "abstract": "Constructing high-quality Supervised Fine-Tuning (SFT) datasets is critical\nfor the training of large language models (LLMs). Recent studies have shown\nthat using data from a specific source, Ruozhiba, a Chinese website where users\nask \"silly\" questions to better understand certain topics, can lead to better\nfine-tuning performance. This paper aims to explore some hidden factors: the\npotential interpretations of its success and a large-scale evaluation of the\nperformance. First, we leverage GPT-4 to analyze the successful cases of\nRuozhiba questions from the perspective of education, psychology, and cognitive\nscience, deriving a set of explanatory rules. Then, we construct fine-tuning\ndatasets by applying these rules to the MMLU training set. Surprisingly, our\nresults indicate that rules can significantly improve model performance in\ncertain tasks, while potentially diminishing performance on others. For\nexample, SFT data generated following the \"Counterintuitive Thinking\" rule can\nachieve approximately a 5% improvement on the \"Global Facts\" task, whereas the\n\"Blurring the Conceptual Boundaries\" rule leads to a performance drop of 6.14%\non the \"Econometrics\" task. In addition, for specific tasks, different rules\ntend to have a consistent impact on model performance. This suggests that the\ndifferences between the extracted rules are not as significant, and the\neffectiveness of the rules is relatively consistent across tasks. Our research\nhighlights the importance of considering task diversity and rule applicability\nwhen constructing SFT datasets to achieve more comprehensive performance\nimprovements.", "published": "2024-11-21 13:45:40", "link": "http://arxiv.org/abs/2411.14121v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why do language models perform worse for morphologically complex\n  languages?", "abstract": "Language models perform differently across languages. It has been previously\nsuggested that morphological typology may explain some of this variability\n(Cotterell et al., 2018). We replicate previous analyses and find additional\nnew evidence for a performance gap between agglutinative and fusional\nlanguages, where fusional languages, such as English, tend to have better\nlanguage modeling performance than morphologically more complex languages like\nTurkish. We then propose and test three possible causes for this performance\ngap: morphological alignment of tokenizers, tokenization quality, and\ndisparities in dataset sizes and measurement. To test the morphological\nalignment hypothesis, we present MorphScore, a tokenizer evaluation metric, and\nsupporting datasets for 22 languages. We find some evidence that tokenization\nquality explains the performance gap, but none for the role of morphological\nalignment. Instead we find that the performance gap is most reduced when\ntraining datasets are of equivalent size across language types, but only when\nscaled according to the so-called \"byte-premium\" -- the different encoding\nefficiencies of different languages and orthographies. These results suggest\nthat no language is harder or easier for a language model to learn on the basis\nof its morphological typology. Differences in performance can be attributed to\ndisparities in dataset size. These results bear on ongoing efforts to improve\nperformance for low-performing and under-resourced languages.", "published": "2024-11-21 15:06:51", "link": "http://arxiv.org/abs/2411.14198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Aspect-Based Summarization of Climate Change Reports with\n  Small Language Models", "abstract": "The use of Natural Language Processing (NLP) for helping decision-makers with\nClimate Change action has recently been highlighted as a use case aligning with\na broader drive towards NLP technologies for social good. In this context,\nAspect-Based Summarization (ABS) systems that extract and summarize relevant\ninformation are particularly useful as they provide stakeholders with a\nconvenient way of finding relevant information in expert-curated reports. In\nthis work, we release a new dataset for ABS of Climate Change reports and we\nemploy different Large Language Models (LLMs) and so-called Small Language\nModels (SLMs) to tackle this problem in an unsupervised way. Considering the\nproblem at hand, we also show how SLMs are not significantly worse for the\nproblem while leading to reduced carbon footprint; we do so by applying for the\nfirst time an existing framework considering both energy efficiency and task\nperformance to the evaluation of zero-shot generative models for ABS. Overall,\nour results show that modern language models, both big and small, can\neffectively tackle ABS for Climate Change reports but more research is needed\nwhen we frame the problem as a Retrieval Augmented Generation (RAG) problem and\nour work and dataset will help foster efforts in this direction.", "published": "2024-11-21 16:28:32", "link": "http://arxiv.org/abs/2411.14272v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for\n  Continual Pre-training", "abstract": "It is well-known that a diverse corpus is critical for training large\nlanguage models, which are typically constructed from a mixture of various\ndomains. In general, previous efforts resort to sampling training data from\ndifferent domains with static proportions, as well as adjusting data\nproportions during training. However, few methods have addressed the\ncomplexities of domain-adaptive continual pre-training. To fill this gap, we\npropose Velocitune, a novel framework dynamically assesses learning velocity\nand adjusts data proportions accordingly, favoring slower-learning domains\nwhile shunning faster-learning ones, which is guided by a scaling law to\nindicate the desired learning goal for each domain with less associated cost.\nTo evaluate the effectiveness of Velocitune, we conduct experiments in a\nreasoning-focused dataset with CodeLlama, as well as in a corpus specialised\nfor system command generation with Llama3 and Mistral. Velocitune achieves\nperformance gains in both math and code reasoning tasks and command-line\ngeneration benchmarks. Further analysis reveals that key factors driving\nVelocitune's effectiveness include target loss prediction and data ordering.", "published": "2024-11-21 17:10:02", "link": "http://arxiv.org/abs/2411.14318v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "POS-tagging to highlight the skeletal structure of sentences", "abstract": "This study presents the development of a part-of-speech (POS) tagging model\nto extract the skeletal structure of sentences using transfer learning with the\nBERT architecture for token classification. The model, fine-tuned on Russian\ntext, demonstrating its effectiveness. The approach offers potential\napplications in enhancing natural language processing tasks, such as improving\nmachine translation.\n  Keywords: part of speech tagging, morphological analysis, natural language\nprocessing, BERT.", "published": "2024-11-21 18:25:19", "link": "http://arxiv.org/abs/2411.14393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings", "abstract": "With the recent proliferation of large language models (LLMs), enterprises\nhave been able to rapidly develop proof-of-concepts and prototypes. As a\nresult, there is a growing need to implement robust guardrails that monitor,\nquantize and control an LLM's behavior, ensuring that the use is reliable,\nsafe, accurate and also aligned with the users' expectations. Previous\napproaches for filtering out inappropriate user prompts or system outputs, such\nas LlamaGuard and OpenAI's MOD API, have achieved significant success by\nfine-tuning existing LLMs. However, using fine-tuned LLMs as guardrails\nintroduces increased latency and higher maintenance costs, which may not be\npractical or scalable for cost-efficient deployments. We take a different\napproach, focusing on fine-tuning a lightweight architecture: Sentence-BERT.\nThis method reduces the model size from LlamaGuard's 7 billion parameters to\napproximately 67 million, while maintaining comparable performance on the AEGIS\nsafety benchmark.", "published": "2024-11-21 18:27:25", "link": "http://arxiv.org/abs/2411.14398v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions", "abstract": "Currently OpenAI o1 sparks a surge of interest in the study of large\nreasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on\ndisciplines with standard answers, such as mathematics, physics, and coding --\nwhich are well-suited for reinforcement learning (RL) -- but also places\ngreater emphasis on open-ended resolutions. We aim to address the question:\n''Can the o1 model effectively generalize to broader domains where clear\nstandards are absent and rewards are challenging to quantify?'' Marco-o1 is\npowered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS),\nreflection mechanisms, and innovative reasoning strategies -- optimized for\ncomplex real-world problem-solving tasks.", "published": "2024-11-21 18:37:33", "link": "http://arxiv.org/abs/2411.14405v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation\n  Across Languages, Domains, and Expertise Levels", "abstract": "This study presents a comprehensive evaluation of GPT-4's translation\ncapabilities compared to human translators of varying expertise levels. Through\nsystematic human evaluation using the MQM schema, we assess translations across\nthree language pairs (Chinese$\\longleftrightarrow$English,\nRussian$\\longleftrightarrow$English, and Chinese$\\longleftrightarrow$Hindi) and\nthree domains (News, Technology, and Biomedical). Our findings reveal that\nGPT-4 achieves performance comparable to junior-level translators in terms of\ntotal errors, while still lagging behind senior translators. Unlike traditional\nNeural Machine Translation systems, which show significant performance\ndegradation in resource-poor language directions, GPT-4 maintains consistent\ntranslation quality across all evaluated language pairs. Through qualitative\nanalysis, we identify distinctive patterns in translation approaches: GPT-4\ntends toward overly literal translations and exhibits lexical inconsistency,\nwhile human translators sometimes over-interpret context and introduce\nhallucinations. This study represents the first systematic comparison between\nLLM and human translators across different proficiency levels, providing\nvaluable insights into the current capabilities and limitations of LLM-based\ntranslation systems.", "published": "2024-11-21 01:12:46", "link": "http://arxiv.org/abs/2411.13775v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptable Embeddings Network (AEN)", "abstract": "Modern day Language Models see extensive use in text classification, yet this\ncomes at significant computational cost. Compute-effective classification\nmodels are needed for low-resource environments, most notably on edge devices.\nWe introduce Adaptable Embeddings Networks (AEN), a novel dual-encoder\narchitecture using Kernel Density Estimation (KDE). This architecture allows\nfor runtime adaptation of classification criteria without retraining and is\nnon-autoregressive. Through thorough synthetic data experimentation, we\ndemonstrate our model outputs comparable and in certain cases superior results\nto that of autoregressive models an order of magnitude larger than AEN's size.\nThe architecture's ability to preprocess and cache condition embeddings makes\nit ideal for edge computing applications and real-time monitoring systems.", "published": "2024-11-21 02:15:52", "link": "http://arxiv.org/abs/2411.13786v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "InstCache: A Predictive Cache for LLM Serving", "abstract": "Large language models are revolutionizing every aspect of human life.\nHowever, the unprecedented power comes at the cost of significant computing\nintensity, suggesting long latency and large energy footprint. Key-Value Cache\nand Semantic Cache have been proposed as a solution to the above problem, but\nboth suffer from limited scalability due to significant memory cost for each\ntoken or instruction embeddings. Motivated by the observations that most\ninstructions are short, repetitive and predictable by LLMs, we propose to\npredict user-instructions by an instruction-aligned LLM and store them in a\npredictive cache, so-called InstCache. We introduce an instruction\npre-population algorithm based on the negative log likelihood of instructions,\ndetermining the cache size with regard to the hit rate. The proposed InstCache\nis efficiently implemented as a hash table with minimal lookup latency for\ndeployment. Experimental results show that InstCache can achieve up to 51.34%\nhit rate on LMSys dataset, which corresponds to a 2x speedup, at a memory cost\nof only 4.5GB.", "published": "2024-11-21 03:52:41", "link": "http://arxiv.org/abs/2411.13820v1", "categories": ["cs.CL", "cs.DC"], "primary_category": "cs.CL"}
{"title": "Interactive and Expressive Code-Augmented Planning with Large Language\n  Models", "abstract": "Large Language Models (LLMs) demonstrate strong abilities in common-sense\nreasoning and interactive decision-making, but often struggle with complex,\nlong-horizon planning tasks. Recent techniques have sought to structure LLM\noutputs using control flow and other code-adjacent techniques to improve\nplanning performance. These techniques include using variables (to track\nimportant information) and functions (to divide complex tasks into smaller\nre-usable sub-tasks). However, purely code-based approaches can be error-prone\nand insufficient for handling ambiguous or unstructured data. To address these\nchallenges, we propose REPL-Plan, an LLM planning approach that is fully\ncode-expressive (it can utilize all the benefits of code) while also being\ndynamic (it can flexibly adapt from errors and use the LLM for fuzzy\nsituations). In REPL-Plan, an LLM solves tasks by interacting with a\nRead-Eval-Print Loop (REPL), which iteratively executes and evaluates code,\nsimilar to language shells or interactive code notebooks, allowing the model to\nflexibly correct errors and handle tasks dynamically. We demonstrate that\nREPL-Plan achieves strong results across various planning domains compared to\nprevious methods.", "published": "2024-11-21 04:23:17", "link": "http://arxiv.org/abs/2411.13826v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PIORS: Personalized Intelligent Outpatient Reception based on Large\n  Language Model with Multi-Agents Medical Scenario Simulation", "abstract": "In China, receptionist nurses face overwhelming workloads in outpatient\nsettings, limiting their time and attention for each patient and ultimately\nreducing service quality. In this paper, we present the Personalized\nIntelligent Outpatient Reception System (PIORS). This system integrates an\nLLM-based reception nurse and a collaboration between LLM and hospital\ninformation system (HIS) into real outpatient reception setting, aiming to\ndeliver personalized, high-quality, and efficient reception services.\nAdditionally, to enhance the performance of LLMs in real-world healthcare\nscenarios, we propose a medical conversational data generation framework named\nService Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM\nto the real-world environments and PIORS settings. We evaluate the\neffectiveness of PIORS and SFMSS through automatic and human assessments\ninvolving 15 users and 15 clinical experts. The results demonstrate that\nPIORS-Nurse outperforms all baselines, including the current state-of-the-art\nmodel GPT-4o, and aligns with human preferences and clinical needs. Further\ndetails and demo can be found at https://github.com/FudanDISC/PIORS", "published": "2024-11-21 07:28:07", "link": "http://arxiv.org/abs/2411.13902v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Logic Augmented Generation", "abstract": "Semantic Knowledge Graphs (SKG) face challenges with scalability,\nflexibility, contextual understanding, and handling unstructured or ambiguous\ninformation. However, they offer formal and structured knowledge enabling\nhighly interpretable and reliable results by means of reasoning and querying.\nLarge Language Models (LLMs) overcome those limitations making them suitable in\nopen-ended tasks and unstructured environments. Nevertheless, LLMs are neither\ninterpretable nor reliable. To solve the dichotomy between LLMs and SKGs we\nenvision Logic Augmented Generation (LAG) that combines the benefits of the two\nworlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate\npotentially infinite relations and tacit knowledge on-demand. SKGs are key for\ninjecting a discrete heuristic dimension with clear logical and factual\nboundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,\nmedical diagnostics and climate projections. Understanding the properties and\nlimitations of LAG, which are still mostly unknown, is of utmost importance for\nenabling a variety of tasks involving tacit knowledge in order to provide\ninterpretable and effective results.", "published": "2024-11-21 10:54:35", "link": "http://arxiv.org/abs/2411.14012v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Forecasting Future International Events: A Reliable Dataset for\n  Text-Based Event Modeling", "abstract": "Predicting future international events from textual information, such as news\narticles, has tremendous potential for applications in global policy, strategic\ndecision-making, and geopolitics. However, existing datasets available for this\ntask are often limited in quality, hindering the progress of related research.\nIn this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction),\na novel dataset designed to address these limitations by leveraging the\nadvanced reasoning capabilities of large-language models (LLMs). Our dataset\nfeatures high-quality scoring labels generated through advanced prompt modeling\nand rigorously validated by domain experts in political science. We showcase\nthe quality and utility of WORLDREP for real-world event prediction tasks,\ndemonstrating its effectiveness through extensive experiments and analysis.\nFurthermore, we publicly release our dataset along with the full automation\nsource code for data collection, labeling, and benchmarking, aiming to support\nand advance research in text-based event prediction.", "published": "2024-11-21 11:44:23", "link": "http://arxiv.org/abs/2411.14042v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FunctionChat-Bench: Comprehensive Evaluation of Language Models'\n  Generative Capabilities in Korean Tool-use Dialogs", "abstract": "This study investigates language models' generative capabilities in tool-use\ndialogs. We categorize the models' outputs in tool-use dialogs into four\ndistinct types: Tool Call, Answer Completion, Slot Question, and Relevance\nDetection, which serve as aspects for evaluation. We introduce\nFunctionChat-Bench, comprising 700 evaluation items and automated assessment\nprograms. Using this benchmark, we evaluate several language models that\nsupport function calling. Our findings indicate that while language models may\nexhibit high accuracy in single-turn Tool Call scenarios, this does not\nnecessarily translate to superior generative performance in multi-turn\nenvironments. We argue that the capabilities required for function calling\nextend beyond generating tool call messages; they must also effectively\ngenerate conversational messages that engage the user.", "published": "2024-11-21 11:59:13", "link": "http://arxiv.org/abs/2411.14054v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Master-Slave Encoder Model for Improving Patent Text Summarization:\n  A New Approach to Combining Specifications and Claims", "abstract": "In order to solve the problem of insufficient generation quality caused by\ntraditional patent text abstract generation models only originating from patent\nspecifications, the problem of new terminology OOV caused by rapid patent\nupdates, and the problem of information redundancy caused by insufficient\nconsideration of the high professionalism, accuracy, and uniqueness of patent\ntexts, we proposes a patent text abstract generation model (MSEA) based on a\nmaster-slave encoder architecture; Firstly, the MSEA model designs a\nmaster-slave encoder, which combines the instructions in the patent text with\nthe claims as input, and fully explores the characteristics and details between\nthe two through the master-slave encoder; Then, the model enhances the\nconsideration of new technical terms in the input sequence based on the pointer\nnetwork, and further enhances the correlation with the input text by re\nweighing the \"remembered\" and \"for-gotten\" parts of the input sequence from the\nencoder; Finally, an enhanced repetition suppression mechanism for patent text\nwas introduced to ensure accurate and non redundant abstracts generated. On a\npublicly available patent text dataset, compared to the state-of-the-art model,\nImproved Multi-Head Attention Mechanism (IMHAM), the MSEA model achieves an\nimprovement of 0.006, 0.005, and 0.005 in Rouge-1, Rouge-2, and Rouge-L scores,\nrespectively. MSEA leverages the characteristics of patent texts to effectively\nenhance the quality of patent text generation, demonstrating its advancement\nand effectiveness in the experiments.", "published": "2024-11-21 12:36:19", "link": "http://arxiv.org/abs/2411.14072v1", "categories": ["cs.CL", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Meaning at the Planck scale? Contextualized word embeddings for doing\n  history, philosophy, and sociology of science", "abstract": "This paper explores the potential of contextualized word embeddings (CWEs) as\na new tool in the history, philosophy, and sociology of science (HPSS) for\nstudying contextual and evolving meanings of scientific concepts. Using the\nterm \"Planck\" as a test case, I evaluate five BERT-based models with varying\ndegrees of domain-specific pretraining, including my custom model\nAstro-HEP-BERT, trained on the Astro-HEP Corpus, a dataset containing 21.84\nmillion paragraphs from 600,000 articles in astrophysics and high-energy\nphysics. For this analysis, I compiled two labeled datasets: (1) the\nAstro-HEP-Planck Corpus, consisting of 2,900 labeled occurrences of \"Planck\"\nsampled from 1,500 paragraphs in the Astro-HEP Corpus, and (2) a\nphysics-related Wikipedia dataset comprising 1,186 labeled occurrences of\n\"Planck\" across 885 paragraphs. Results demonstrate that the domain-adapted\nmodels outperform the general-purpose ones in disambiguating the target term,\npredicting its known meanings, and generating high-quality sense clusters, as\nmeasured by a novel purity indicator I developed. Additionally, this approach\nreveals semantic shifts in the target term over three decades in the unlabeled\nAstro-HEP Corpus, highlighting the emergence of the Planck space mission as a\ndominant sense. The study underscores the importance of domain-specific\npretraining for analyzing scientific language and demonstrates the\ncost-effectiveness of adapting pretrained models for HPSS research. By offering\na scalable and transferable method for modeling the meanings of scientific\nconcepts, CWEs open up new avenues for investigating the socio-historical\ndynamics of scientific discourses.", "published": "2024-11-21 12:38:23", "link": "http://arxiv.org/abs/2411.14073v1", "categories": ["cs.CL", "physics.hist-ph", "I.2.6; I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "VAGUE: Visual Contexts Clarify Ambiguous Expressions", "abstract": "Human communication often relies on visual cues to resolve ambiguity. While\nhumans can intuitively integrate these cues, AI systems often find it\nchallenging to engage in sophisticated multimodal reasoning. We introduce\nVAGUE, a benchmark evaluating multimodal AI systems' ability to integrate\nvisual context for intent disambiguation. VAGUE consists of 1.6K ambiguous\ntextual expressions, each paired with an image and multiple-choice\ninterpretations, where the correct answer is only apparent with visual context.\nThe dataset spans both staged, complex (Visual Commonsense Reasoning) and\nnatural, personal (Ego4D) scenes, ensuring diversity. Our experiments reveal\nthat existing multimodal AI models struggle to infer the speaker's true intent.\nWhile performance consistently improves from the introduction of more visual\ncues, the overall accuracy remains far below human performance, highlighting a\ncritical gap in multimodal reasoning. Analysis of failure cases demonstrates\nthat current models fail to distinguish true intent from superficial\ncorrelations in the visual scene, indicating that they perceive images but do\nnot effectively reason with them. We release our code and data at\nhttps://github.com/Hazel-Heejeong-Nam/VAGUE.git.", "published": "2024-11-21 14:01:42", "link": "http://arxiv.org/abs/2411.14137v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for\n  Multi-Turn Intent Classification", "abstract": "Generating large-scale, domain-specific, multilingual multi-turn dialogue\ndatasets remains a significant hurdle for training effective Multi-Turn Intent\nClassification models in chatbot systems. In this paper, we introduce\nChain-of-Intent, a novel mechanism that combines Hidden Markov Models with\nLarge Language Models (LLMs) to generate contextually aware, intent-driven\nconversations through self-play. By extracting domain-specific knowledge from\ne-commerce chat logs, we estimate conversation turns and intent transitions,\nwhich guide the generation of coherent dialogues. Leveraging LLMs to enhance\nemission probabilities, our approach produces natural and contextually\nconsistent questions and answers. We also propose MINT-CL, a framework for\nmulti-turn intent classification using multi-task contrastive learning,\nimproving classification accuracy without the need for extensive annotated\ndata. Evaluations show that our methods outperform baselines in dialogue\nquality and intent classification accuracy, especially in multilingual\nsettings, while significantly reducing data generation efforts. Furthermore, we\nrelease MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue\ncorpus to support future research in this area.", "published": "2024-11-21 15:59:29", "link": "http://arxiv.org/abs/2411.14252v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Graphs, Large Language Models, and Hallucinations: An NLP\n  Perspective", "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP) based applications including automated text generation, question\nanswering, chatbots, and others. However, they face a significant challenge:\nhallucinations, where models produce plausible-sounding but factually incorrect\nresponses. This undermines trust and limits the applicability of LLMs in\ndifferent domains. Knowledge Graphs (KGs), on the other hand, provide a\nstructured collection of interconnected facts represented as entities (nodes)\nand their relationships (edges). In recent research, KGs have been leveraged to\nprovide context that can fill gaps in an LLM understanding of certain topics\noffering a promising approach to mitigate hallucinations in LLMs, enhancing\ntheir reliability and accuracy while benefiting from their wide applicability.\nNonetheless, it is still a very active area of research with various unresolved\nopen problems. In this paper, we discuss these open challenges covering\nstate-of-the-art datasets and benchmarks as well as methods for knowledge\nintegration and evaluating hallucinations. In our discussion, we consider the\ncurrent use of KGs in LLM systems and identify future directions within each of\nthese challenges.", "published": "2024-11-21 16:09:05", "link": "http://arxiv.org/abs/2411.14258v1", "categories": ["cs.CL", "cs.AI", "68-02", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Looking Beyond Text: Reducing Language bias in Large Vision-Language\n  Models via Multimodal Dual-Attention and Soft-Image Guidance", "abstract": "Large vision-language models (LVLMs) have achieved impressive results in\nvarious vision-language tasks. However, despite showing promising performance,\nLVLMs suffer from hallucinations caused by language bias, leading to diminished\nfocus on images and ineffective visual comprehension. We identify two primary\nreasons for this bias: 1. Different scales of training data between the\npretraining stage of LLM and multimodal alignment stage. 2. The learned\ninference bias due to short-term dependency of text data. Therefore, we propose\nLACING, a systemic framework designed to address the language bias of LVLMs\nwith muLtimodal duAl-attention meChanIsm (MDA) aNd soft-image Guidance (IFG).\nSpecifically, MDA introduces a parallel dual-attention mechanism that enhances\nthe integration of visual inputs across the model. IFG introduces a learnable\nsoft visual prompt during training and inference to replace visual inputs,\ndesigned to compel LVLMs to prioritize text inputs. Then, IFG further proposes\na novel decoding strategy using the soft visual prompt to mitigate the model's\nover-reliance on adjacent text inputs. Comprehensive experiments demonstrate\nthat our method effectively debiases LVLMs from their language bias, enhancing\nvisual comprehension and reducing hallucinations without requiring additional\ntraining resources or data. The code and model are available at\n[lacing-lvlm.github.io](https://lacing-lvlm.github.io).", "published": "2024-11-21 16:33:30", "link": "http://arxiv.org/abs/2411.14279v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs\n  on Low-Resource Languages", "abstract": "Large language models (LLMs) under-perform on low-resource languages due to\nlimited training data. We present a method to efficiently collect text data for\nlow-resource languages from the entire Common Crawl corpus. Our approach,\nUnifiedCrawl, filters and extracts common crawl using minimal compute\nresources, yielding mono-lingual datasets much larger than previously available\nsources. We demonstrate that leveraging this data to fine-tuning multilingual\nLLMs via efficient adapter methods (QLoRA) significantly boosts performance on\nthe low-resource language, while minimizing VRAM usage. Our experiments show\nlarge improvements in language modeling perplexity and an increase in few-shot\nprompting scores. Our work and released source code provide an affordable\napproach to improve LLMs for low-resource languages using consumer hardware.\nOur source code is available here at\nhttps://github.com/bethelmelesse/unifiedcrawl.", "published": "2024-11-21 17:41:08", "link": "http://arxiv.org/abs/2411.14343v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction\n  Tuning", "abstract": "The efficacy of large language models (LLMs) on downstream tasks usually\nhinges on instruction tuning, which relies critically on the quality of\ntraining data. Unfortunately, collecting high-quality and diverse data is both\nexpensive and time-consuming. To mitigate this issue, we propose a novel\nStar-Agents framework, which automates the enhancement of data quality across\ndatasets through multi-agent collaboration and assessment. The framework adopts\na three-pronged strategy. It initially generates diverse instruction data with\nmultiple LLM agents through a bespoke sampling method. Subsequently, the\ngenerated data undergo a rigorous evaluation using a dual-model method that\nassesses both difficulty and quality. Finaly, the above process evolves in a\ndynamic refinement phase, where more effective LLMs are prioritized, enhancing\nthe overall data quality. Our empirical studies, including instruction tuning\nexperiments with models such as Pythia and LLaMA, demonstrate the effectiveness\nof the proposed framework. Optimized datasets have achieved substantial\nimprovements, with an average increase of 12% and notable gains in specific\nmetrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like\nMT-bench, Vicuna bench, and WizardLM testset.", "published": "2024-11-21 02:30:53", "link": "http://arxiv.org/abs/2411.14497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards a Middleware for Large Language Models", "abstract": "Large language models have gained widespread popularity for their ability to\nprocess natural language inputs and generate insights derived from their\ntraining data, nearing the qualities of true artificial intelligence. This\nadvancement has prompted enterprises worldwide to integrate LLMs into their\nservices. So far, this effort is dominated by commercial cloud-based solutions\nlike OpenAI's ChatGPT and Microsoft Azure. As the technology matures, however,\nthere is a strong incentive for independence from major cloud providers through\nself-hosting \"LLM as a Service\", driven by privacy, cost, and customization\nneeds. In practice, hosting LLMs independently presents significant challenges\ndue to their complexity and integration issues with existing systems. In this\npaper, we discuss our vision for a forward-looking middleware system\narchitecture that facilitates the deployment and adoption of LLMs in\nenterprises, even for advanced use cases in which we foresee LLMs to serve as\ngateways to a complete application ecosystem and, to some degree, absorb\nfunctionality traditionally attributed to the middleware.", "published": "2024-11-21 13:55:24", "link": "http://arxiv.org/abs/2411.14513v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Towards Knowledge Checking in Retrieval-augmented Generation: A\n  Representation Perspective", "abstract": "Retrieval-Augmented Generation (RAG) systems have shown promise in enhancing\nthe performance of Large Language Models (LLMs). However, these systems face\nchallenges in effectively integrating external knowledge with the LLM's\ninternal knowledge, often leading to issues with misleading or unhelpful\ninformation. This work aims to provide a systematic study on knowledge checking\nin RAG systems. We conduct a comprehensive analysis of LLM representation\nbehaviors and demonstrate the significance of using representations in\nknowledge checking. Motivated by the findings, we further develop\nrepresentation-based classifiers for knowledge filtering. We show substantial\nimprovements in RAG performance, even when dealing with noisy knowledge\ndatabases. Our study provides new insights into leveraging LLM representations\nfor enhancing the reliability and effectiveness of RAG systems.", "published": "2024-11-21 20:39:13", "link": "http://arxiv.org/abs/2411.14572v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models", "abstract": "Recent advancements in vision-language models (VLMs), such as CLIP, have\ndemonstrated substantial success in self-supervised representation learning for\nvision tasks. However, effectively adapting VLMs to downstream applications\nremains challenging, as their accuracy often depends on time-intensive and\nexpertise-demanding prompt engineering, while full model fine-tuning is costly.\nThis is particularly true for biomedical images, which, unlike natural images,\ntypically suffer from limited annotated datasets, unintuitive image contrasts,\nand nuanced visual features. Recent prompt learning techniques, such as Context\nOptimization (CoOp) intend to tackle these issues, but still fall short in\ngeneralizability. Meanwhile, explorations in prompt learning for biomedical\nimage analysis are still highly limited. In this work, we propose BiomedCoOp, a\nnovel prompt learning framework that enables efficient adaptation of BiomedCLIP\nfor accurate and highly generalizable few-shot biomedical image classification.\nOur approach achieves effective prompt context learning by leveraging semantic\nconsistency with average prompt ensembles from Large Language Models (LLMs) and\nknowledge distillation with a statistics-based prompt selection strategy. We\nconducted comprehensive validation of our proposed framework on 11 medical\ndatasets across 9 modalities and 10 organs against existing state-of-the-art\nmethods, demonstrating significant improvements in both accuracy and\ngeneralizability. The code is publicly available at\nhttps://github.com/HealthX-Lab/BiomedCoOp.", "published": "2024-11-21 19:13:04", "link": "http://arxiv.org/abs/2411.15232v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Framework for Evaluating LLMs Under Task Indeterminacy", "abstract": "Large language model (LLM) evaluations often assume there is a single correct\nresponse -- a gold label -- for each item in the evaluation corpus. However,\nsome tasks can be ambiguous -- i.e., they provide insufficient information to\nidentify a unique interpretation -- or vague -- i.e., they do not clearly\nindicate where to draw the line when making a determination. Both ambiguity and\nvagueness can cause task indeterminacy -- the condition where some items in the\nevaluation corpus have more than one correct response. In this paper, we\ndevelop a framework for evaluating LLMs under task indeterminacy. Our framework\ndisentangles the relationships between task specification, human ratings, and\nLLM responses in the LLM evaluation pipeline. Using our framework, we conduct a\nsynthetic experiment showing that evaluations that use the \"gold label\"\nassumption underestimate the true performance. We also provide a method for\nestimating an error-adjusted performance interval given partial knowledge about\nindeterminate items in the evaluation corpus. We conclude by outlining\nimplications of our work for the research community.", "published": "2024-11-21 00:15:44", "link": "http://arxiv.org/abs/2411.13760v1", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap\n  via Informational Interviews", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ngenerating coherent text but often struggle with grounding language and\nstrategic dialogue. To address this gap, we focus on journalistic interviews, a\ndomain rich in grounding communication and abundant in data. We curate a\ndataset of 40,000 two-person informational interviews from NPR and CNN, and\nreveal that LLMs are significantly less likely than human interviewers to use\nacknowledgements and to pivot to higher-level questions. Realizing that a\nfundamental deficit exists in multi-turn planning and strategic thinking, we\ndevelop a realistic simulated environment, incorporating source personas and\npersuasive elements, in order to facilitate the development of agents with\nlonger-horizon rewards. Our experiments show that while source LLMs mimic human\nbehavior in information sharing, interviewer LLMs struggle with recognizing\nwhen questions are answered and engaging persuasively, leading to suboptimal\ninformation extraction across model size and capability. These findings\nunderscore the need for enhancing LLMs' strategic dialogue capabilities.", "published": "2024-11-21 01:37:38", "link": "http://arxiv.org/abs/2411.13779v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for\n  Exploration and Exploitation in Recommender Systems", "abstract": "Modern recommender systems often create information cocoons, restricting\nusers' exposure to diverse content. A key challenge lies in balancing content\nexploration and exploitation while allowing users to adjust their\nrecommendation preferences. Intuitively, this balance can be modeled as a\ntree-structured representation, where depth search facilitates exploitation and\nbreadth search enables exploration. However, existing approaches face two\nfundamental limitations: Euclidean methods struggle to capture hierarchical\nstructures, while hyperbolic methods, despite their superior hierarchical\nmodeling, lack semantic understanding of user and item profiles and fail to\nprovide a principled mechanism for balancing exploration and exploitation. To\naddress these challenges, we propose HERec, a hyperbolic graph-LLM framework\nthat effectively balances exploration and exploitation in recommender systems.\nOur framework introduces two key innovations: (1) a hierarchical-aware\ngraph-LLM mechanism that jointly aligns textual descriptions with user-item\ncollaborative information in hyperbolic space, and (2) a hierarchical\nrepresentation structure that enables user-adjustable exploration-exploitation\ntrade-offs. Extensive experiments demonstrate that HERec consistently\noutperforms both Euclidean and hyperbolic baselines, achieving up to 5.49%\nimprovement in utility metrics and 11.39% increase in diversity metrics,\neffectively mitigating information cocoons. We open-source our model\nimplementation at https://github.com/Martin-qyma/HERec.", "published": "2024-11-21 06:01:47", "link": "http://arxiv.org/abs/2411.13865v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Sentiment Analysis of Economic Text: A Lexicon-Based Approach", "abstract": "We propose an Economic Lexicon (EL) specifically designed for textual\napplications in economics. We construct the dictionary with two important\ncharacteristics: 1) to have a wide coverage of terms used in documents\ndiscussing economic concepts, and 2) to provide a human-annotated sentiment\nscore in the range [-1,1]. We illustrate the use of the EL in the context of a\nsimple sentiment measure and consider several applications in economics. The\ncomparison to other lexicons shows that the EL is superior due to its wider\ncoverage of domain relevant terms and its more accurate categorization of the\nword sentiment.", "published": "2024-11-21 09:13:12", "link": "http://arxiv.org/abs/2411.13958v1", "categories": ["cs.CE", "cs.CL", "cs.CY", "91B62, 91B84, 91B86", "H.4; J.2"], "primary_category": "cs.CE"}
{"title": "MMGenBench: Fully Automatically Evaluating LMMs from the Text-to-Image\n  Generation Perspective", "abstract": "Large Multimodal Models (LMMs) demonstrate impressive capabilities. However,\ncurrent benchmarks predominantly focus on image comprehension in specific\ndomains, and these benchmarks are labor-intensive to construct. Moreover, their\nanswers tend to be brief, making it difficult to assess the ability of LMMs to\ngenerate detailed descriptions of images. To address these limitations, we\npropose the MMGenBench-Pipeline, a straightforward and fully automated\nevaluation pipeline. This involves generating textual descriptions from input\nimages, using these descriptions to create auxiliary images via text-to-image\ngenerative models, and then comparing the original and generated images.\nFurthermore, to ensure the effectiveness of MMGenBench-Pipeline, we design\nMMGenBench-Test, evaluating LMMs across 13 distinct image patterns, and\nMMGenBench-Domain, focusing on generative image performance. A thorough\nevaluation involving over 50 popular LMMs demonstrates the effectiveness and\nreliability of both the pipeline and benchmark. Our observations indicate that\nnumerous LMMs excelling in existing benchmarks fail to adequately complete the\nbasic tasks related to image understanding and description. This finding\nhighlights the substantial potential for performance improvement in current\nLMMs and suggests avenues for future model optimization. Concurrently,\nMMGenBench-Pipeline can efficiently assess the performance of LMMs across\ndiverse domains using only image inputs.", "published": "2024-11-21 12:16:16", "link": "http://arxiv.org/abs/2411.14062v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken\n  Term Detection", "abstract": "Spoken term detection (STD) is often hindered by reliance on frame-level\nfeatures and the computationally intensive DTW-based template matching,\nlimiting its practicality. To address these challenges, we propose a novel\napproach that encodes speech into discrete, speaker-agnostic semantic tokens.\nThis facilitates fast retrieval using text-based search algorithms and\neffectively handles out-of-vocabulary terms. Our approach focuses on generating\nconsistent token sequences across varying utterances of the same term. We also\npropose a bidirectional state space modeling within the Mamba encoder, trained\nin a self-supervised learning framework, to learn contextual frame-level\nfeatures that are further encoded into discrete tokens. Our analysis shows that\nour speech tokens exhibit greater speaker invariance than those from existing\ntokenizers, making them more suitable for STD tasks. Empirical evaluation on\nLibriSpeech and TIMIT databases indicates that our method outperforms existing\nSTD baselines while being more efficient.", "published": "2024-11-21 13:05:18", "link": "http://arxiv.org/abs/2411.14100v2", "categories": ["eess.AS", "cs.CL", "cs.IR"], "primary_category": "eess.AS"}
{"title": "Evaluating the Robustness of Analogical Reasoning in Large Language\n  Models", "abstract": "LLMs have performed well on several reasoning benchmarks, including ones that\ntest analogical reasoning abilities. However, there is debate on the extent to\nwhich they are performing general abstract reasoning versus employing\nnon-robust processes, e.g., that overly rely on similarity to pre-training\ndata. Here we investigate the robustness of analogy-making abilities previously\nclaimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu\n(2023): letter-string analogies, digit matrices, and story analogies. For each\ndomain we test humans and GPT models on robustness to variants of the original\nanalogy problems that test the same abstract reasoning abilities but are likely\ndissimilar from tasks in the pre-training data. The performance of a system\nthat uses robust abstract reasoning should not decline substantially on these\nvariants.\n  On simple letter-string analogies, we find that while the performance of\nhumans remains high for two types of variants we tested, the GPT models'\nperformance declines sharply. This pattern is less pronounced as the complexity\nof these problems is increased, as both humans and GPT models perform poorly on\nboth the original and variant problems requiring more complex analogies. On\ndigit-matrix problems, we find a similar pattern but only on one out of the two\ntypes of variants we tested. On story-based analogy problems, we find that,\nunlike humans, the performance of GPT models are susceptible to answer-order\neffects, and that GPT models also may be more sensitive than humans to\nparaphrasing.\n  This work provides evidence that LLMs often lack the robustness of zero-shot\nhuman analogy-making, exhibiting brittleness on most of the variations we\ntested. More generally, this work points to the importance of carefully\nevaluating AI systems not only for accuracy but also robustness when testing\ntheir cognitive capabilities.", "published": "2024-11-21 15:25:08", "link": "http://arxiv.org/abs/2411.14215v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Language Reinforcement Learning", "abstract": "Reinforcement Learning (RL) mathematically formulates decision-making with\nMarkov Decision Process (MDP). With MDPs, researchers have achieved remarkable\nbreakthroughs across various domains, including games, robotics, and language\nmodels. This paper seeks a new possibility, Natural Language Reinforcement\nLearning (NLRL), by extending traditional MDP to natural language-based\nrepresentation space. Specifically, NLRL innovatively redefines RL principles,\nincluding task objectives, policy, value function, Bellman equation, and policy\niteration, into their language counterparts. With recent advancements in large\nlanguage models (LLMs), NLRL can be practically implemented to achieve RL-like\npolicy and value improvement by either pure prompting or gradient-based\ntraining. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games\ndemonstrate the effectiveness, efficiency, and interpretability of the NLRL\nframework among diverse use cases. Our code will be released at\nhttps://github.com/waterhorse1/Natural-language-RL.", "published": "2024-11-21 15:57:02", "link": "http://arxiv.org/abs/2411.14251v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in\n  Language Models", "abstract": "Hallucinations in large language models are a widespread problem, yet the\nmechanisms behind whether models will hallucinate are poorly understood,\nlimiting our ability to solve this problem. Using sparse autoencoders as an\ninterpretability tool, we discover that a key part of these mechanisms is\nentity recognition, where the model detects if an entity is one it can recall\nfacts about. Sparse autoencoders uncover meaningful directions in the\nrepresentation space, these detect whether the model recognizes an entity, e.g.\ndetecting it doesn't know about an athlete or a movie. This suggests that\nmodels can have self-knowledge: internal representations about their own\ncapabilities. These directions are causally relevant: capable of steering the\nmodel to refuse to answer questions about known entities, or to hallucinate\nattributes of unknown entities when it would otherwise refuse. We demonstrate\nthat despite the sparse autoencoders being trained on the base model, these\ndirections have a causal effect on the chat model's refusal behavior,\nsuggesting that chat finetuning has repurposed this existing mechanism.\nFurthermore, we provide an initial exploration into the mechanistic role of\nthese directions in the model, finding that they disrupt the attention of\ndownstream heads that typically move entity attributes to the final token.", "published": "2024-11-21 16:05:58", "link": "http://arxiv.org/abs/2411.14257v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding World or Predicting Future? A Comprehensive Survey of\n  World Models", "abstract": "The concept of world models has garnered significant attention due to\nadvancements in multimodal large language models such as GPT-4 and video\ngeneration models such as Sora, which are central to the pursuit of artificial\ngeneral intelligence. This survey offers a comprehensive review of the\nliterature on world models. Generally, world models are regarded as tools for\neither understanding the present state of the world or predicting its future\ndynamics. This review presents a systematic categorization of world models,\nemphasizing two primary functions: (1) constructing internal representations to\nunderstand the mechanisms of the world, and (2) predicting future states to\nsimulate and guide decision-making. Initially, we examine the current progress\nin these two categories. We then explore the application of world models in key\ndomains, including autonomous driving, robotics, and social simulacra, with a\nfocus on how each domain utilizes these aspects. Finally, we outline key\nchallenges and provide insights into potential future research directions.", "published": "2024-11-21 03:58:50", "link": "http://arxiv.org/abs/2411.14499v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Accuracy-Fairness Trade-off in Large Language Models", "abstract": "Large Language Models (LLMs) have made significant strides in the field of\nartificial intelligence, showcasing their ability to interact with humans and\ninfluence human cognition through information dissemination. However, recent\nstudies have brought to light instances of bias inherent within these LLMs,\npresenting a critical issue that demands attention. In our research, we delve\ndeeper into the intricate challenge of harmonising accuracy and fairness in the\nenhancement of LLMs. While improving accuracy can indeed enhance overall LLM\nperformance, it often occurs at the expense of fairness. Overemphasising\noptimisation of one metric invariably leads to a significant degradation of the\nother. This underscores the necessity of taking into account multiple\nconsiderations during the design and optimisation phases of LLMs. Therefore, we\nadvocate for reformulating the LLM training process as a multi-objective\nlearning task. Our investigation reveals that multi-objective evolutionary\nlearning (MOEL) methodologies offer promising avenues for tackling this\nchallenge. Our MOEL framework enables the simultaneous optimisation of both\naccuracy and fairness metrics, resulting in a Pareto-optimal set of LLMs. In\nsummary, our study sheds valuable lights on the delicate equilibrium between\naccuracy and fairness within LLMs, which is increasingly significant for their\nreal-world applications. By harnessing MOEL, we present a promising pathway\ntowards fairer and more efficacious AI technologies.", "published": "2024-11-21 04:40:35", "link": "http://arxiv.org/abs/2411.14500v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers", "abstract": "Generative Pre-trained Transformers (GPTs) have demonstrated remarkable\nperformance across diverse domains through the extensive scaling of model\nparameters. Recent works observe the redundancy across the transformer blocks\nand develop compression methods by structured pruning of the unimportant\nblocks. However, such straightforward elimination will always provide\nirreversible performance degradation. In this paper, we propose FuseGPT, a\nnovel methodology to recycle the pruned transformer blocks to further recover\nthe model performance. Firstly we introduce a new importance detection metric,\nMacro Influence (MI), to detect the long-term influence of each transformer\nblock by calculating their loss of information after removal. Then we propose\ngroup-level layers fusion, which adopts the parameters in layers of the\nunimportant blocks and injects them into the corresponding layers inside the\nneighboring blocks. The fusion is not one-off but through iterative parameter\nupdates by lightweight group-level fine-tuning. Specifically, these injected\nparameters are frozen but weighted with learnable rank decomposition matrices\nto reduce the overhead during fine-tuning. Our approach not only works well on\nlarge language models but also on large multimodal models. The experiments have\nshown that, by using modest amounts of data, FuseGPT can outperform previous\nworks in both perplexity and zero-shot task performance.", "published": "2024-11-21 09:49:28", "link": "http://arxiv.org/abs/2411.14507v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Experimental Study on Data Augmentation Techniques for Named Entity\n  Recognition on Low-Resource Domains", "abstract": "Named Entity Recognition (NER) is a machine learning task that traditionally\nrelies on supervised learning and annotated data. Acquiring such data is often\na challenge, particularly in specialized fields like medical, legal, and\nfinancial sectors. Those are commonly referred to as low-resource domains,\nwhich comprise long-tail entities, due to the scarcity of available data. To\naddress this, data augmentation techniques are increasingly being employed to\ngenerate additional training instances from the original dataset. In this\nstudy, we evaluate the effectiveness of two prominent text augmentation\ntechniques, Mention Replacement and Contextual Word Replacement, on two\nwidely-used NER models, Bi-LSTM+CRF and BERT. We conduct experiments on four\ndatasets from low-resource domains, and we explore the impact of various\ncombinations of training subset sizes and number of augmented examples. We not\nonly confirm that data augmentation is particularly beneficial for smaller\ndatasets, but we also demonstrate that there is no universally optimal number\nof augmented examples, i.e., NER practitioners must experiment with different\nquantities in order to fine-tune their projects.", "published": "2024-11-21 19:45:48", "link": "http://arxiv.org/abs/2411.14551v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reducibility among NP-Hard graph problems and boundary classes", "abstract": "Many NP-hard graph problems become easy for some classes of graphs, such as\ncoloring is easy for bipartite graphs, but NP-hard in general. So we can ask\nquestion like when does a hard problem become easy? What is the minimum\nsubstructure for which the problem remains hard? We use the notion of boundary\nclasses to study such questions. In this paper, we introduce a method for\ntransforming the boundary class of one NP-hard graph problem into a boundary\nclass for another problem. If $\\Pi$ and $\\Gamma$ are two NP-hard graph problems\nwhere $\\Pi$ is reducible to $\\Gamma$, we transform a boundary class of $\\Pi$\ninto a boundary class of $\\Gamma$. More formally if $\\Pi$ is reducible to\n$\\Gamma$, where the reduction is bijective and it maps hereditary classes of\ngraphs to hereditary classes of graphs, then $X$ is a boundary class of $\\Pi$\nif and only if the image of $X$ under the reduction is a boundary class of\n$\\Gamma$. This gives us a relationship between boundary classes and\nreducibility among several NP-hard problems. To show the strength of our main\nresult, we apply our theorem to obtain some previously unknown boundary classes\nfor a few graph problems namely; vertex-cover, clique, traveling-salesperson,\nbounded-degree-spanning-tree, subgraph-isomorphism and clique-cover.", "published": "2024-11-21 19:49:33", "link": "http://arxiv.org/abs/2411.14553v1", "categories": ["cs.CC", "cs.CL", "cs.DM"], "primary_category": "cs.CC"}
{"title": "Assessment of LLM Responses to End-user Security Questions", "abstract": "Answering end user security questions is challenging. While large language\nmodels (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have\nshown promise in answering a variety of questions outside of security. We\nstudied LLM performance in the area of end user security by qualitatively\nevaluating 3 popular LLMs on 900 systematically collected end user security\nquestions.\n  While LLMs demonstrate broad generalist ``knowledge'' of end user security\ninformation, there are patterns of errors and limitations across LLMs\nconsisting of stale and inaccurate answers, and indirect or unresponsive\ncommunication styles, all of which impacts the quality of information received.\nBased on these patterns, we suggest directions for model improvement and\nrecommend user strategies for interacting with LLMs when seeking assistance\nwith security.", "published": "2024-11-21 20:36:36", "link": "http://arxiv.org/abs/2411.14571v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CR"}
{"title": "Voice Communication Analysis in Esports", "abstract": "In most team-based esports, voice communications are prominent in the team\nefficiency and synergy. In fact it has been observed that not only the skill\naspect of the team but also the team effective voice communication comes into\nplay when trying to have good performance in official matches. With the recent\nemergence of LLM (Large Language Models) tools regarding NLP (Natural Language\nProcessing) (Vaswani et. al.), we decided to try applying them in order to have\na better understanding on how to improve the effectiveness of the voice\ncommunications. In this paper the study has been made through the prism of\nLeague of Legends esport. However the main concepts and ideas can be easily\napplicable in any other team related esports.", "published": "2024-11-21 12:21:11", "link": "http://arxiv.org/abs/2411.19793v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "StackEval: Benchmarking LLMs in Coding Assistance", "abstract": "We present two comprehensive benchmarks to evaluate the performance of\nlanguage models in coding assistance tasks, covering code writing, debugging,\ncode review, and conceptual understanding. Our main contribution includes two\ncurated datasets: StackEval, a large-scale benchmark derived from Stack\nOverflow questions, and StackUnseen, a dynamic benchmark featuring the most\nrecent Stack Overflow content. These benchmarks offer novel insights into the\ncapabilities and limitations of LLMs, particularly in handling new and emerging\ncontent. Additionally, we assess LLMs' proficiency as judges for coding tasks\nusing a curated, human-annotated dataset, exploring their evaluation\ncapabilities and potential biases, including whether they favor their own\ngenerated solutions. Our findings underscore the potential of these benchmarks\nto advance LLM development and application in coding assistance. To ensure\nreproducibility, we publicly share our datasets and evaluation code at\nhttps://github.com/ProsusAI/stack-eval .", "published": "2024-11-21 11:20:48", "link": "http://arxiv.org/abs/2412.05288v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "NewsHomepages: Homepage Layouts Capture Information Prioritization\n  Decisions", "abstract": "Information prioritization plays an important role in how humans perceive and\nunderstand the world. Homepage layouts serve as a tangible proxy for this\nprioritization. In this work, we present NewsHomepages, a large dataset of over\n3,000 new website homepages (including local, national and topic-specific\noutlets) captured twice daily over a three-year period. We develop models to\nperform pairwise comparisons between news items to infer their relative\nsignificance. To illustrate that modeling organizational hierarchies has\nbroader implications, we applied our models to rank-order a collection of local\ncity council policies passed over a ten-year period in San Francisco, assessing\ntheir \"newsworthiness\". Our findings lay the groundwork for leveraging implicit\norganizational cues to deepen our understanding of information prioritization.", "published": "2024-11-21 00:46:42", "link": "http://arxiv.org/abs/2501.00004v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented\n  LMs", "abstract": "Scientific progress depends on researchers' ability to synthesize the growing\nbody of literature. Can large language models (LMs) assist scientists in this\ntask? We introduce OpenScholar, a specialized retrieval-augmented LM that\nanswers scientific queries by identifying relevant passages from 45 million\nopen-access papers and synthesizing citation-backed responses. To evaluate\nOpenScholar, we develop ScholarQABench, the first large-scale multi-domain\nbenchmark for literature search, comprising 2,967 expert-written queries and\n208 long-form answers across computer science, physics, neuroscience, and\nbiomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and\nPaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\nhallucinates citations 78 to 90% of the time, OpenScholar achieves citation\naccuracy on par with human experts. OpenScholar's datastore, retriever, and\nself-feedback inference loop also improves off-the-shelf LMs: for instance,\nOpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,\nexperts preferred OpenScholar-8B and OpenScholar-GPT4o responses over\nexpert-written ones 51% and 70% of the time, respectively, compared to GPT4o's\n32%. We open-source all of our code, models, datastore, data and a public demo.", "published": "2024-11-21 15:07:42", "link": "http://arxiv.org/abs/2411.14199v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing LLMs for Power System Simulations: A Feedback-driven\n  Multi-agent Framework", "abstract": "The integration of experimental technologies with large language models\n(LLMs) is transforming scientific research, positioning AI as a versatile\nresearch assistant rather than a mere problem-solving tool. In the field of\npower systems, however, managing simulations -- one of the essential\nexperimental technologies -- remains a challenge for LLMs due to their limited\ndomain-specific knowledge, restricted reasoning capabilities, and imprecise\nhandling of simulation parameters. To address these limitations, we propose a\nfeedback-driven, multi-agent framework that incorporates three proposed\nmodules: an enhanced retrieval-augmented generation (RAG) module, an improved\nreasoning module, and a dynamic environmental acting module with an\nerror-feedback mechanism. Validated on 69 diverse tasks from Daline and\nMATPOWER, this framework achieves success rates of 93.13% and 96.85%,\nrespectively, significantly outperforming the latest LLMs (ChatGPT 4o and\no1-preview), which achieved a 27.77% success rate on standard simulation tasks\nand 0% on complex tasks. Additionally, our framework also supports rapid,\ncost-effective task execution, completing each simulation in approximately 30\nseconds at an average cost of 0.014 USD for tokens. Overall, this adaptable\nframework lays a foundation for developing intelligent LLM-based assistants for\nhuman researchers, facilitating power system research and beyond.", "published": "2024-11-21 19:01:07", "link": "http://arxiv.org/abs/2411.16707v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.CL"}
{"title": "Robust Detection of Watermarks for Large Language Models Under Human\n  Edits", "abstract": "Watermarking has offered an effective approach to distinguishing text\ngenerated by large language models (LLMs) from human-written text. However, the\npervasive presence of human edits on LLM-generated text dilutes watermark\nsignals, thereby significantly degrading detection performance of existing\nmethods. In this paper, by modeling human edits through mixture model\ndetection, we introduce a new method in the form of a truncated goodness-of-fit\ntest for detecting watermarked text under human edits, which we refer to as\nTr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection\nof the Gumbel-max watermark in a certain asymptotic regime of substantial text\nmodifications and vanishing watermark signals. Importantly, Tr-GoF achieves\nthis optimality \\textit{adaptively} as it does not require precise knowledge of\nhuman edit levels or probabilistic specifications of the LLMs, in contrast to\nthe optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover,\nwe establish that the Tr-GoF test attains the highest detection efficiency rate\nin a certain regime of moderate text modifications. In stark contrast, we show\nthat sum-based detection rules, as employed by existing methods, fail to\nachieve optimal robustness in both regimes because the additive nature of their\nstatistics is less resilient to edit-induced noise. Finally, we demonstrate the\ncompetitive and sometimes superior empirical performance of the Tr-GoF test on\nboth synthetic data and open-source LLMs in the OPT and LLaMA families.", "published": "2024-11-21 06:06:04", "link": "http://arxiv.org/abs/2411.13868v1", "categories": ["stat.ME", "cs.CL", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Sequence-to-Sequence Neural Diarization with Automatic Speaker Detection\n  and Representation", "abstract": "This paper proposes a novel Sequence-to-Sequence Neural Diarization (SSND)\nframework to perform online and offline speaker diarization. It is developed\nfrom the sequence-to-sequence architecture of our previous target-speaker voice\nactivity detection system and then evolves into a new diarization paradigm by\naddressing two critical problems. 1) Speaker Detection: The proposed approach\ncan utilize incompletely given speaker embeddings to discover the unknown\nspeaker and predict the target voice activities in the audio signal. It does\nnot require a prior diarization system for speaker enrollment in advance. 2)\nSpeaker Representation: The proposed approach can adopt the predicted voice\nactivities as reference information to extract speaker embeddings from the\naudio signal simultaneously. The representation space of speaker embedding is\njointly learned within the whole diarization network without using an extra\nspeaker embedding model. During inference, the SSND framework can process long\naudio recordings blockwise. The detection module utilizes the previously\nobtained speaker-embedding buffer to predict both enrolled and unknown\nspeakers' voice activities for each coming audio block. Next, the\nspeaker-embedding buffer is updated according to the predictions of the\nrepresentation module. Assuming that up to one new speaker may appear in a\nsmall block shift, our model iteratively predicts the results of each block and\nextracts target embeddings for the subsequent blocks until the signal ends.\nFinally, the last speaker-embedding buffer can re-score the entire audio,\nachieving highly accurate diarization performance as an offline system.\n(......)", "published": "2024-11-21 05:15:46", "link": "http://arxiv.org/abs/2411.13849v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "MVANet: Multi-Stage Video Attention Network for Sound Event Localization\n  and Detection with Source Distance Estimation", "abstract": "Sound event localization and detection with source distance estimation (3D\nSELD) involves not only identifying the sound category and its\ndirection-of-arrival (DOA) but also predicting the source's distance, aiming to\nprovide full information about the sound position. This paper proposes a\nmulti-stage video attention network (MVANet) for audio-visual (AV) 3D SELD.\nMulti-stage audio features are used to adaptively capture the spatial\ninformation of sound sources in videos. We propose a novel output\nrepresentation that combines the DOA with distance of sound sources by\ncalculating the real Cartesian coordinates to address the newly introduced\nsource distance estimation (SDE) task in the Detection and Classification of\nAcoustic Scenes and Events (DCASE) 2024 Challenge. We also employ a variety of\neffective data augmentation and pre-training methods. Experimental results on\nthe STARSS23 dataset have proven the effectiveness of our proposed MVANet. By\nintegrating the aforementioned techniques, our system outperforms the\ntop-ranked method we used in the AV 3D SELD task of the DCASE 2024 Challenge\nwithout model ensemble. The code will be made publicly available in the future.", "published": "2024-11-21 14:18:10", "link": "http://arxiv.org/abs/2411.14153v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Tiny-Align: Bridging Automatic Speech Recognition and Large Language\n  Model on the Edge", "abstract": "The combination of Large Language Models (LLM) and Automatic Speech\nRecognition (ASR), when deployed on edge devices (called edge ASR-LLM), can\nserve as a powerful personalized assistant to enable audio-based interaction\nfor users. Compared to text-based interaction, edge ASR-LLM allows accessible\nand natural audio interactions. Unfortunately, existing ASR-LLM models are\nmainly trained in high-performance computing environments and produce\nsubstantial model weights, making them difficult to deploy on edge devices.\nMore importantly, to better serve users' personalized needs, the ASR-LLM must\nbe able to learn from each distinct user, given that audio input often contains\nhighly personalized characteristics that necessitate personalized on-device\ntraining. Since individually fine-tuning the ASR or LLM often leads to\nsuboptimal results due to modality-specific limitations, end-to-end training\nensures seamless integration of audio features and language understanding\n(cross-modal alignment), ultimately enabling a more personalized and efficient\nadaptation on edge devices. However, due to the complex training requirements\nand substantial computational demands of existing approaches, cross-modal\nalignment between ASR audio and LLM can be challenging on edge devices. In this\nwork, we propose a resource-efficient cross-modal alignment framework that\nbridges ASR and LLMs on edge devices to handle personalized audio input. Our\nframework enables efficient ASR-LLM alignment on resource-constrained devices\nlike NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while\nimproving the alignment quality by more than 50\\%. To the best of our\nknowledge, this is the first work to study efficient ASR-LLM alignment on\nresource-constrained edge devices.", "published": "2024-11-21 00:29:58", "link": "http://arxiv.org/abs/2411.13766v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "X-CrossNet: A complex spectral mapping approach to target speaker\n  extraction with cross attention speaker embedding fusion", "abstract": "Target speaker extraction (TSE) is a technique for isolating a target\nspeaker's voice from mixed speech using auxiliary features associated with the\ntarget speaker. It is another attempt at addressing the cocktail party problem\nand is generally considered to have more practical application prospects than\ntraditional speech separation methods. Although academic research in this area\nhas achieved high performance and evaluation scores on public datasets, most\nmodels exhibit significantly reduced performance in real-world noisy or\nreverberant conditions. To address this limitation, we propose a novel TSE\nmodel, X-CrossNet, which leverages CrossNet as its backbone. CrossNet is a\nspeech separation network specifically optimized for challenging noisy and\nreverberant environments, achieving state-of-the-art performance in tasks such\nas speaker separation under these conditions. Additionally, to enhance the\nnetwork's ability to capture and utilize auxiliary features of the target\nspeaker, we integrate a Cross-Attention mechanism into the global multi-head\nself-attention (GMHSA) module within each CrossNet block. This facilitates more\neffective integration of target speaker features with mixed speech features.\nExperimental results show that our method performs superior separation on the\nWSJ0-2mix and WHAMR! datasets, demonstrating strong robustness and stability.", "published": "2024-11-21 03:21:42", "link": "http://arxiv.org/abs/2411.13811v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Single-Model Attribution for Spoofed Speech via Vocoder Fingerprints in\n  an Open-World Setting", "abstract": "As speech generation technology advances, so do the potential threats of\nmisusing spoofed speech signals. One way to address these threats is by\nattributing the signals to their source generative model. In this work, we are\nthe first to tackle the single-model attribution task in an open-world setting,\nthat is, we aim at identifying whether spoofed speech signals from unknown\nsources originate from a specific vocoder. We show that the standardized\naverage residual between audio signals and their low-pass filtered or EnCodec\nfiltered versions can serve as powerful vocoder fingerprints. The approach only\nrequires data from the target vocoder and allows for simple but highly accurate\ndistance-based model attribution. We demonstrate its effectiveness on LJSpeech\nand JSUT, achieving an average AUROC of over 99% in most settings. The\naccompanying robustness study shows that it is also resilient to noise levels\nup to a certain degree.", "published": "2024-11-21 10:55:49", "link": "http://arxiv.org/abs/2411.14013v1", "categories": ["eess.AS", "cs.CR", "cs.LG"], "primary_category": "eess.AS"}
{"title": "HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset", "abstract": "This contribution introduces a dataset of 7th-order Ambisonic Room Impulse\nResponses (HOA-RIRs), created using the Image Source Method. By employing\nhigher-order Ambisonics, our dataset enables precise spatial audio\nreproduction, a critical requirement for realistic immersive audio\napplications. Leveraging the virtual simulation, we present a unique microphone\nconfiguration, based on the superposition principle, designed to optimize sound\nfield coverage while addressing the limitations of traditional microphone\narrays. The presented 64-microphone configuration allows us to capture RIRs\ndirectly in the Spherical Harmonics domain. The dataset features a wide range\nof room configurations, encompassing variations in room geometry, acoustic\nabsorption materials, and source-receiver distances. A detailed description of\nthe simulation setup is provided alongside for an accurate reproduction. The\ndataset serves as a vital resource for researchers working on spatial audio,\nparticularly in applications involving machine learning to improve room\nacoustics modeling and sound field synthesis. It further provides a very high\nlevel of spatial resolution and realism crucial for tasks such as source\nlocalization, reverberation prediction, and immersive sound reproduction.", "published": "2024-11-21 15:16:48", "link": "http://arxiv.org/abs/2411.14207v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Listening for Expert Identified Linguistic Features: Assessment of Audio\n  Deepfake Discernment among Undergraduate Students", "abstract": "This paper evaluates the impact of training undergraduate students to improve\ntheir audio deepfake discernment ability by listening for expert-defined\nlinguistic features. Such features have been shown to improve performance of AI\nalgorithms; here, we ascertain whether this improvement in AI algorithms also\ntranslates to improvement of the perceptual awareness and discernment ability\nof listeners. With humans as the weakest link in any cybersecurity solution, we\npropose that listener discernment is a key factor for improving trustworthiness\nof audio content. In this study we determine whether training that familiarizes\nlisteners with English language variation can improve their abilities to\ndiscern audio deepfakes. We focus on undergraduate students, as this\ndemographic group is constantly exposed to social media and the potential for\ndeception and misinformation online. To the best of our knowledge, our work is\nthe first study to uniquely address English audio deepfake discernment through\nsuch techniques. Our research goes beyond informational training by introducing\ntargeted linguistic cues to listeners as a deepfake discernment mechanism, via\na training module. In a pre-/post- experimental design, we evaluated the impact\nof the training across 264 students as a representative cross section of all\nstudents at the University of Maryland, Baltimore County, and across\nexperimental and control sections. Findings show that the experimental group\nshowed a statistically significant decrease in their unsurety when evaluating\naudio clips and an improvement in their ability to correctly identify clips\nthey were initially unsure about. While results are promising, future research\nwill explore more robust and comprehensive trainings for greater impact.", "published": "2024-11-21 20:52:02", "link": "http://arxiv.org/abs/2411.14586v1", "categories": ["cs.SD", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generative AI for Music and Audio", "abstract": "Generative AI has been transforming the way we interact with technology and\nconsume content. In the next decade, AI technology will reshape how we create\naudio content in various media, including music, theater, films, games,\npodcasts, and short videos. In this dissertation, I introduce the three main\ndirections of my research centered around generative AI for music and audio: 1)\nmultitrack music generation, 2) assistive music creation tools, and 3)\nmultimodal learning for audio and music. Through my research, I aim to answer\nthe following two fundamental questions: 1) How can AI help professionals or\namateurs create music and audio content? 2) Can AI learn to create music in a\nway similar to how humans learn music? My long-term goal is to lower the\nbarrier of entry for music composition and democratize audio content creation", "published": "2024-11-21 23:02:12", "link": "http://arxiv.org/abs/2411.14627v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
