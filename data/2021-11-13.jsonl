{"title": "Extracting and filtering paraphrases by bridging natural language\n  inference and paraphrasing", "abstract": "Paraphrasing is a useful natural language processing task that can contribute\nto more diverse generated or translated texts. Natural language inference (NLI)\nand paraphrasing share some similarities and can benefit from a joint approach.\nWe propose a novel methodology for the extraction of paraphrasing datasets from\nNLI datasets and cleaning existing paraphrasing datasets. Our approach is based\non bidirectional entailment; namely, if two sentences can be mutually entailed,\nthey are paraphrases. We evaluate our approach using several large pretrained\ntransformer language models in the monolingual and cross-lingual setting. The\nresults show high quality of extracted paraphrasing datasets and surprisingly\nhigh noise levels in two existing paraphrasing datasets.", "published": "2021-11-13 14:06:37", "link": "http://arxiv.org/abs/2111.07119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prediction of Listener Perception of Argumentative Speech in a\n  Crowdsourced Dataset Using (Psycho-)Linguistic and Fluency Features", "abstract": "One of the key communicative competencies is the ability to maintain fluency\nin monologic speech and the ability to produce sophisticated language to argue\na position convincingly. In this paper we aim to predict TED talk-style\naffective ratings in a crowdsourced dataset of argumentative speech consisting\nof 7 hours of speech from 110 individuals. The speech samples were elicited\nthrough task prompts relating to three debating topics. The samples received a\ntotal of 2211 ratings from 737 human raters pertaining to 14 affective\ncategories. We present an effective approach to the classification task of\npredicting these categories through fine-tuning a model pre-trained on a large\ndataset of TED talks public speeches. We use a combination of fluency features\nderived from a state-of-the-art automatic speech recognition system and a large\nset of human-interpretable linguistic features obtained from an automatic text\nanalysis system. Classification accuracy was greater than 60% for all 14 rating\ncategories, with a peak performance of 72% for the rating category\n'informative'. In a secondary experiment, we determined the relative importance\nof features from different groups using SP-LIME.", "published": "2021-11-13 15:07:13", "link": "http://arxiv.org/abs/2111.07130v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A feast for trolls -- Engagement analysis of counternarratives against\n  online toxicity", "abstract": "This report provides an engagement analysis of counternarratives against\nonline toxicity. Between February 2020 and July 2021, we observed over 15\nmillion toxic messages on social media identified by our fine-grained,\nmultilingual detection AI. Over 1,000 dashboard users responded to toxic\nmessages with combinations of visual memes, text, or AI-generated text, or they\nreported content. This leads to new, real-life insights on self-regulatory\napproaches for the mitigation of online hate.", "published": "2021-11-13 20:38:31", "link": "http://arxiv.org/abs/2111.07188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Deep Reinforcement Learning for Extractive Legal Summarization", "abstract": "Automatic summarization of legal texts is an important and still a\nchallenging task since legal documents are often long and complicated with\nunusual structures and styles. Recent advances of deep models trained\nend-to-end with differentiable losses can well-summarize natural text, yet when\napplied to legal domain, they show limited results. In this paper, we propose\nto use reinforcement learning to train current deep summarization models to\nimprove their performance on the legal domain. To this end, we adopt proximal\npolicy optimization methods and introduce novel reward functions that encourage\nthe generation of candidate summaries satisfying both lexical and semantic\ncriteria. We apply our method to training different summarization backbones and\nobserve a consistent and significant performance gain across 3 public legal\ndatasets.", "published": "2021-11-13 17:27:49", "link": "http://arxiv.org/abs/2111.07158v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explainable Semantic Space by Grounding Language to Vision with\n  Cross-Modal Contrastive Learning", "abstract": "In natural language processing, most models try to learn semantic\nrepresentations merely from texts. The learned representations encode the\ndistributional semantics but fail to connect to any knowledge about the\nphysical world. In contrast, humans learn language by grounding concepts in\nperception and action and the brain encodes grounded semantics for cognition.\nInspired by this notion and recent work in vision-language learning, we design\na two-stream model for grounding language learning in vision. The model\nincludes a VGG-based visual stream and a Bert-based language stream. The two\nstreams merge into a joint representational space. Through cross-modal\ncontrastive learning, the model first learns to align visual and language\nrepresentations with the MS COCO dataset. The model further learns to retrieve\nvisual objects with language queries through a cross-modal attention module and\nto infer the visual relations between the retrieved objects through a bilinear\noperator with the Visual Genome dataset. After training, the language stream of\nthis model is a stand-alone language model capable of embedding concepts in a\nvisually grounded semantic space. This semantic space manifests principal\ndimensions explainable with human intuition and neurobiological knowledge. Word\nembeddings in this semantic space are predictive of human-defined norms of\nsemantic features and are segregated into perceptually distinctive clusters.\nFurthermore, the visually grounded language model also enables compositional\nlanguage understanding based on visual knowledge and multimodal image search\nwith queries based on images, texts, or their combinations.", "published": "2021-11-13 19:54:15", "link": "http://arxiv.org/abs/2111.07180v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Deep Learning to Identify Patients with Cognitive Impairment in\n  Electronic Health Records", "abstract": "Dementia is a neurodegenerative disorder that causes cognitive decline and\naffects more than 50 million people worldwide. Dementia is under-diagnosed by\nhealthcare professionals - only one in four people who suffer from dementia are\ndiagnosed. Even when a diagnosis is made, it may not be entered as a structured\nInternational Classification of Diseases (ICD) diagnosis code in a patient's\ncharts. Information relevant to cognitive impairment (CI) is often found within\nelectronic health records (EHR), but manual review of clinician notes by\nexperts is both time consuming and often prone to errors. Automated mining of\nthese notes presents an opportunity to label patients with cognitive impairment\nin EHR data. We developed natural language processing (NLP) tools to identify\npatients with cognitive impairment and demonstrate that linguistic context\nenhances performance for the cognitive impairment classification task. We\nfine-tuned our attention based deep learning model, which can learn from\ncomplex language structures, and substantially improved accuracy (0.93)\nrelative to a baseline NLP model (0.84). Further, we show that deep learning\nNLP can successfully identify dementia patients without dementia-related ICD\ncodes or medications.", "published": "2021-11-13 01:44:10", "link": "http://arxiv.org/abs/2111.09115v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym\n  Prediction", "abstract": "In the expansion of biomedical dataset, the same category may be labeled with\ndifferent terms, thus being tedious and onerous to curate these terms.\nTherefore, automatically mapping synonymous terms onto the ontologies is\ndesirable, which we name as biomedical synonym prediction task. Unlike\nbiomedical concept normalization (BCN), no clues from context can be used to\nenhance synonym prediction, making it essential to extract graph features from\nontology. We introduce an expert-curated dataset OBO-syn encompassing 70\ndifferent types of concepts and 2 million curated concept-term pairs for\nevaluating synonym prediction methods. We find BCN methods perform weakly on\nthis task for not making full use of graph information. Therefore, we propose\nGraphPrompt, a prompt-based learning approach that creates prompt templates\naccording to the graphs. GraphPrompt obtained 37.2\\% and 28.5\\% improvement on\nzero-shot and few-shot settings respectively, indicating the effectiveness of\nthese graph-based prompt templates. We envision that our method GraphPrompt and\nOBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as\nthe basis for analyzing diverse and accumulating biomedical data. All the data\nand codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt", "published": "2021-11-13 06:59:27", "link": "http://arxiv.org/abs/2112.03002v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Class and Automated Tweet Categorization", "abstract": "Twitter is among the most prevalent social media platform being used by\nmillions of people all over the world. It is used to express ideas and opinions\nabout political, social, business, sports, health, religion, and various other\ncategories. The study reported here aims to detect the tweet category from its\ntext. It becomes quite challenging when text consists of 140 characters only,\nwith full of noise. The tweet is categorized under 12 specified categories\nusing Text Mining or Natural Language Processing (NLP), and Machine Learning\n(ML) techniques. It is observed that a huge number of trending topics are\nprovided by Twitter but it is really challenging to find out that what these\ntrending topics are all about. Therefore, it is extremely crucial to\nautomatically categorize the tweets into general categories for plenty of\ninformation extraction tasks. A large dataset is constructed by combining two\ndifferent nature of datasets having varying levels of category identification\ncomplexities. It is annotated by experts under proper guidelines for increased\nquality and high agreement values. It makes the proposed model quite robust.\nVarious types of ML algorithms were used to train and evaluate the proposed\nmodel. These models have explored over three datasets separately. It is\nexplored that the nature of the dataset is highly non-linear therefore complex\nor non-linear models perform better. The best ensemble model named, Gradient\nBoosting achieved an AUC score of 85\\%. That is much better than the other\nrelated studies conducted.", "published": "2021-11-13 14:28:47", "link": "http://arxiv.org/abs/2112.03005v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Memotion Analysis through the Lens of Joint Embedding", "abstract": "Joint embedding (JE) is a way to encode multi-modal data into a vector space\nwhere text remains as the grounding key and other modalities like image are to\nbe anchored with such keys. Meme is typically an image with embedded text onto\nit. Although, memes are commonly used for fun, they could also be used to\nspread hate and fake information. That along with its growing ubiquity over\nseveral social platforms has caused automatic analysis of memes to become a\nwidespread topic of research. In this paper, we report our initial experiments\non Memotion Analysis problem through joint embeddings. Results are marginally\nyielding SOTA.", "published": "2021-11-13 09:22:39", "link": "http://arxiv.org/abs/2111.07074v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SocialBERT -- Transformers for Online SocialNetwork Language Modelling", "abstract": "The ubiquity of the contemporary language understanding tasks gives relevance\nto the development of generalized, yet highly efficient models that utilize all\nknowledge, provided by the data source. In this work, we present SocialBERT -\nthe first model that uses knowledge about the author's position in the network\nduring text analysis. We investigate possible models for learning social\nnetwork information and successfully inject it into the baseline BERT model.\nThe evaluation shows that embedding this information maintains a good\ngeneralization, with an increase in the quality of the probabilistic model for\nthe given author up to 7.5%. The proposed model has been trained on the\nmajority of groups for the chosen social network, and still able to work with\npreviously unknown groups. The obtained model, as well as the code of our\nexperiments, is available for download and use in applied tasks.", "published": "2021-11-13 16:37:15", "link": "http://arxiv.org/abs/2111.07148v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Keyphrase Extraction Using Neighborhood Knowledge Based on Word\n  Embeddings", "abstract": "Keyphrase extraction is the task of finding several interesting phrases in a\ntext document, which provide a list of the main topics within the document.\nMost existing graph-based models use co-occurrence links as cohesion indicators\nto model the relationship of syntactic elements. However, a word may have\ndifferent forms of expression within the document, and may have several\nsynonyms as well. Simply using co-occurrence information cannot capture this\ninformation. In this paper, we enhance the graph-based ranking model by\nleveraging word embeddings as background knowledge to add semantic information\nto the inter-word graph. Our approach is evaluated on established benchmark\ndatasets and empirical results show that the word embedding neighborhood\ninformation improves the model performance.", "published": "2021-11-13 21:48:18", "link": "http://arxiv.org/abs/2111.07198v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Direct Noisy Speech Modeling for Noisy-to-Noisy Voice Conversion", "abstract": "Beyond the conventional voice conversion (VC) where the speaker information\nis converted without altering the linguistic content, the background sounds are\ninformative and need to be retained in some real-world scenarios, such as VC in\nmovie/video and VC in music where the voice is entangled with background\nsounds. As a new VC framework, we have developed a noisy-to-noisy (N2N) VC\nframework to convert the speaker's identity while preserving the background\nsounds. Although our framework consisting of a denoising module and a VC module\nwell handles the background sounds, the VC module is sensitive to the\ndistortion caused by the denoising module. To address this distortion issue, in\nthis paper we propose the improved VC module to directly model the noisy speech\nwaveform while controlling the background sounds. The experimental results have\ndemonstrated that our improved framework significantly outperforms the previous\none and achieves an acceptable score in terms of naturalness, while reaching\ncomparable similarity performance to the upper bound of our framework.", "published": "2021-11-13 13:47:37", "link": "http://arxiv.org/abs/2111.07116v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Emotion Recognition Using Deep Sparse Auto-Encoder Extreme\n  Learning Machine with a New Weighting Scheme and Spectro-Temporal Features\n  Along with Classical Feature Selection and A New Quantum-Inspired Dimension\n  Reduction Method", "abstract": "Affective computing is very important in the relationship between man and\nmachine. In this paper, a system for speech emotion recognition (SER) based on\nspeech signal is proposed, which uses new techniques in different stages of\nprocessing. The system consists of three stages: feature extraction, feature\nselection, and finally feature classification. In the first stage, a complex\nset of long-term statistics features is extracted from both the speech signal\nand the glottal-waveform signal using a combination of new and diverse features\nsuch as prosodic, spectral, and spectro-temporal features. One of the\nchallenges of the SER systems is to distinguish correlated emotions. These\nfeatures are good discriminators for speech emotions and increase the SER's\nability to recognize similar and different emotions. This feature vector with a\nlarge number of dimensions naturally has redundancy. In the second stage, using\nclassical feature selection techniques as well as a new quantum-inspired\ntechnique to reduce the feature vector dimensionality, the number of feature\nvector dimensions is reduced. In the third stage, the optimized feature vector\nis classified by a weighted deep sparse extreme learning machine (ELM)\nclassifier. The classifier performs classification in three steps: sparse\nrandom feature learning, orthogonal random projection using the singular value\ndecomposition (SVD) technique, and discriminative classification in the last\nstep using the generalized Tikhonov regularization technique. Also, many\nexisting emotional datasets suffer from the problem of data imbalanced\ndistribution, which in turn increases the classification error and decreases\nsystem performance. In this paper, a new weighting method has also been\nproposed to deal with class imbalance, which is more efficient than existing\nweighting methods. The proposed method is evaluated on three standard emotional\ndatabases.", "published": "2021-11-13 11:09:38", "link": "http://arxiv.org/abs/2111.07094v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
