{"title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers", "abstract": "Pretrained automatic speech recognition (ASR) models such as Whisper perform\nwell but still need domain adaptation to handle unseen vocabulary and parlance.\nIn many real-world settings, collecting speech data is impractical,\nnecessitating text-only adaptation. We propose WhisTLE, a deeply supervised,\ntext-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE\ntrains a variational autoencoder (VAE) to model encoder outputs from text and\nfine-tunes the decoder using the learned text-to-latent encoder, optionally\ncombined with text-to-speech (TTS) adaptation. At inference, the original\nencoder is restored, incurring no extra runtime cost. Across four out-of-domain\ndatasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by\n12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines\nin 27 of 32 scenarios.", "published": "2025-09-12 17:59:09", "link": "http://arxiv.org/abs/2509.10452v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "abstract": "Augmenting large language models (LLMs) with browsing tools substantially\nimproves their potential as deep search agents to solve complex, real-world\ntasks. Yet, open LLMs still perform poorly in such settings due to limited\nlong-horizon reasoning capacity with browsing tools and the lack of\nsufficiently difficult supervised data. To address these challenges, we present\nDeepDive to advance deep search agents. First, we propose a strategy to\nautomatically synthesize complex, difficult, and hard-to-find questions from\nopen knowledge graphs. Second, we apply end-to-end multi-turn reinforcement\nlearning (RL) to enhance LLMs' long-horizon reasoning with deep search.\nExperiments show that DeepDive-32B achieves a new open-source competitive\nresult on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and\nSearch-o1. We demonstrate that multi-turn RL training improves deep search\nability and significantly contributes to the performance improvements across\nmultiple benchmarks. We observe that DeepDive enables test-time scaling of tool\ncalls and parallel sampling. All datasets, models, and code are publicly\navailable at https://github.com/THUDM/DeepDive.", "published": "2025-09-12 17:52:35", "link": "http://arxiv.org/abs/2509.10446v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment", "abstract": "To optimize the reasoning and problem-solving capabilities of Large Language\nModels (LLMs), we propose a novel cloud-edge collaborative architecture that\nenables a structured, multi-agent prompting framework. This framework comprises\nthree specialized components: GuideLLM, a lightweight model deployed at the\nedge to provide methodological guidance; SolverLLM, a more powerful model\nhosted in the cloud responsible for generating code solutions; and JudgeLLM, an\nautomated evaluator for assessing solution correctness and quality. To evaluate\nand demonstrate the effectiveness of this architecture in realistic settings,\nwe introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate\nand enhance the performance of Large Language Models (LLMs) across multi-domain\ncoding tasks. Motivated by the limitations of existing benchmarks,\nRefactorCoderQA systematically covers various technical domains, including\nSoftware Engineering, Data Science, Machine Learning, and Natural Language\nProcessing, using authentic coding challenges from Stack Overflow. Extensive\nexperiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves\nstate-of-the-art performance, significantly outperforming leading open-source\nand commercial baselines with an overall accuracy of 76.84%. Human evaluations\nfurther validate the interpretability, accuracy, and practical relevance of the\ngenerated solutions. In addition, we evaluate system-level metrics, such as\nthroughput and latency, to gain deeper insights into the performance\ncharacteristics and trade-offs of the proposed architecture.", "published": "2025-09-12 17:44:22", "link": "http://arxiv.org/abs/2509.10436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long Context Automated Essay Scoring with Language Models", "abstract": "Transformer-based language models are architecturally constrained to process\ntext of a fixed maximum length. Essays written by higher-grade students\nfrequently exceed the maximum allowed length for many popular open-source\nmodels. A common approach to addressing this issue when using these models for\nAutomated Essay Scoring is to truncate the input text. This raises serious\nvalidity concerns as it undermines the model's ability to fully capture and\nevaluate organizational elements of the scoring rubric, which requires long\ncontexts to assess. In this study, we evaluate several models that incorporate\narchitectural modifications of the standard transformer architecture to\novercome these length limitations using the Kaggle ASAP 2.0 dataset. The models\nconsidered in this study include fine-tuned versions of XLNet, Longformer,\nModernBERT, Mamba, and Llama models.", "published": "2025-09-12 17:13:47", "link": "http://arxiv.org/abs/2509.10417v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is In-Context Learning Learning?", "abstract": "In-context learning (ICL) allows some autoregressive models to solve tasks\nvia next-token prediction and without needing further training. This has led to\nclaims about these model's ability to solve (learn) unseen tasks with only a\nfew shots (exemplars) in the prompt. However, deduction does not always imply\nlearning, as ICL does not explicitly encode a given observation. Instead, the\nmodels rely on their prior knowledge and the exemplars given, if any. We argue\nthat, mathematically, ICL does constitute learning, but its full\ncharacterisation requires empirical work. We then carry out a large-scale\nanalysis of ICL ablating out or accounting for memorisation, pretraining,\ndistributional shifts, and prompting style and phrasing. We find that ICL is an\neffective learning paradigm, but limited in its ability to learn and generalise\nto unseen tasks. We note that, in the limit where exemplars become more\nnumerous, accuracy is insensitive to exemplar distribution, model, prompt\nstyle, and the input's linguistic features. Instead, it deduces patterns from\nregularities in the prompt, which leads to distributional sensitivity,\nespecially in prompting styles such as chain-of-thought. Given the varied\naccuracies on formally similar tasks, we conclude that autoregression's ad-hoc\nencoding is not a robust mechanism, and suggests limited all-purpose\ngeneralisability.", "published": "2025-09-12 17:12:04", "link": "http://arxiv.org/abs/2509.10414v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "abstract": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "published": "2025-09-12 16:51:15", "link": "http://arxiv.org/abs/2509.10401v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs", "abstract": "Sparse Mixture-of-Experts (SMoE) architectures are widely used in large\nlanguage models (LLMs) due to their computational efficiency. However, though\nonly a few experts are activated for each token, SMoE still requires loading\nall expert parameters, leading to high memory usage and challenges in\ndeployment. Previous work has tried to reduce the overhead by pruning and\nmerging experts, but primarily focused on expert-level operations, leaving\nneuron-level structure underexplored. We propose DERN (Dropping Experts,\nRecombining Neurons), a task-agnostic and retraining-free framework for expert\npruning and reconstruction. We observe that experts are often misaligned and\ncontain semantic conflicts at the neuron level, which poses challenges for\ndirect merging. To solve this, DERN works in three steps: it first prunes\nredundant experts using router statistics; then it decomposes them into\nneuron-level expert segments, assigning each segment to its most compatible\nretained expert; and finally, it merges segments within each retained expert to\nbuild a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE\nmodels show that DERN improves performance by more than 5% on commonsense\nreasoning and MMLU benchmarks under 50% expert sparsity, without extra\ntraining. It also greatly reduces the number of experts and memory usage,\nmaking SMoE LLMs easier to deploy in practice.", "published": "2025-09-12 16:09:39", "link": "http://arxiv.org/abs/2509.10377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning", "abstract": "Large Language Models often generate unfaithful responses in knowledge\nintensive tasks due to knowledge conflict,that is,a preference for relying on\ninternal parametric knowledge rather than the provided context.To address this\nissue,we propose a novel self improving framework,Self Improving Faithfulness\nAware Contrastive Tuning.The framework uses a self instruct mechanism that\nallows the base LLM to automatically generate high quality,structured\ncontrastive learning data,including anchor samples,semantically equivalent\npositive samples,and negative samples simulating unfaithful scenarios.This\napproach significantly reduces the cost of manual\nannotation.Subsequently,contrastive learning is applied to train the\nmodel,enabling it to pull faithful responses closer and push unfaithful\nresponses farther apart in the representation space.Experiments on knowledge\nconflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT\nmodel based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%\nover the best baseline method,while significantly reducing dependence on\ninternal memory.The results indicate that SI FACT provides strong effectiveness\nand high data efficiency in enhancing the contextual faithfulness of\nLLMs,offering a practical pathway toward building more proactive and\ntrustworthy language models.", "published": "2025-09-12 12:56:14", "link": "http://arxiv.org/abs/2509.10208v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Token Limits: Assessing Language Model Performance on Long Text Classification", "abstract": "The most widely used large language models in the social sciences (such as\nBERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text\nlength that they can process to produce predictions. This is a particularly\npressing issue for some classification tasks, where the aim is to handle long\ninput texts. One such area deals with laws and draft laws (bills), which can\nhave a length of multiple hundred pages and, therefore, are not particularly\namenable for processing with models that can only handle e.g. 512 tokens. In\nthis paper, we show results from experiments covering 5 languages with\nXLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass\nclassification task of the Comparative Agendas Project, which has a codebook of\n21 policy topic labels from education to health care. Results show no\nparticular advantage for the Longformer model, pre-trained specifically for the\npurposes of handling long inputs. The comparison between the GPT variants and\nthe best-performing open model yielded an edge for the latter. An analysis of\nclass-level factors points to the importance of support and substance overlaps\nbetween specific categories when it comes to performance on long text inputs.", "published": "2025-09-12 12:47:28", "link": "http://arxiv.org/abs/2509.10199v1", "categories": ["cs.CL", "I.7; I.2; J.4"], "primary_category": "cs.CL"}
{"title": "Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations", "abstract": "In emotionally supportive conversations, well-intended positivity can\nsometimes misfire, leading to responses that feel dismissive, minimizing, or\nunrealistically optimistic. We examine this phenomenon of incongruent\npositivity as miscalibrated expressions of positive support in both human and\nLLM generated responses. To this end, we collected real user-assistant\ndialogues from Reddit across a range of emotional intensities and generated\nadditional responses using large language models for the same context. We\ncategorize these conversations by intensity into two levels: Mild, which covers\nrelationship tension and general advice, and Severe, which covers grief and\nanxiety conversations. This level of categorization enables a comparative\nanalysis of how supportive responses vary across lower and higher stakes\ncontexts. Our analysis reveals that LLMs are more prone to unrealistic\npositivity through dismissive and minimizing tone, particularly in high-stakes\ncontexts. To further study the underlying dimensions of this phenomenon, we\nfinetune LLMs on datasets with strong and weak emotional reactions. Moreover,\nwe developed a weakly supervised multilabel classifier ensemble (DeBERTa and\nMentalBERT) that shows improved detection of incongruent positivity types\nacross two sorts of concerns (Mild and Severe). Our findings shed light on the\nneed to move beyond merely generating generic positive responses and instead\nstudy the congruent support measures to balance positive affect with emotional\nacknowledgment. This approach offers insights into aligning large language\nmodels with affective expectations in the online supportive dialogue, paving\nthe way toward context-aware and trust preserving online conversation systems.", "published": "2025-09-12 12:25:02", "link": "http://arxiv.org/abs/2509.10184v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmark of stylistic variation in LLM-generated texts", "abstract": "This study investigates the register variation in texts written by humans and\ncomparable texts produced by large language models (LLMs). Biber's\nmultidimensional analysis (MDA) is applied to a sample of human-written texts\nand AI-created texts generated to be their counterparts to find the dimensions\nof variation in which LLMs differ most significantly and most systematically\nfrom humans. As textual material, a new LLM-generated corpus AI-Brown is used,\nwhich is comparable to BE-21 (a Brown family corpus representing contemporary\nBritish English). Since all languages except English are underrepresented in\nthe training data of frontier LLMs, similar analysis is replicated on Czech\nusing AI-Koditex corpus and Czech multidimensional model. Examined were 16\nfrontier models in various settings and prompts, with emphasis placed on the\ndifference between base models and instruction-tuned models. Based on this, a\nbenchmark is created through which models can be compared with each other and\nranked in interpretable dimensions.", "published": "2025-09-12 12:12:20", "link": "http://arxiv.org/abs/2509.10179v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Error Analysis in a Modular Meeting Transcription System", "abstract": "Meeting transcription is a field of high relevance and remarkable progress in\nrecent years. Still, challenges remain that limit its performance. In this\nwork, we extend a previously proposed framework for analyzing leakage in speech\nseparation with proper sensitivity to temporal locality. We show that there is\nsignificant leakage to the cross channel in areas where only the primary\nspeaker is active. At the same time, the results demonstrate that this does not\naffect the final performance much as these leaked parts are largely ignored by\nthe voice activity detection (VAD). Furthermore, different segmentations are\ncompared showing that advanced diarization approaches are able to reduce the\ngap to oracle segmentation by a third compared to a simple energy-based VAD. We\nadditionally reveal what factors contribute to the remaining difference. The\nresults represent state-of-the-art performance on LibriCSS among systems that\ntrain the recognition module on LibriSpeech data only.", "published": "2025-09-12 11:10:38", "link": "http://arxiv.org/abs/2509.10143v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Reliable and Interpretable Document Question Answering via VLMs", "abstract": "Vision-Language Models (VLMs) have shown strong capabilities in document\nunderstanding, particularly in identifying and extracting textual information\nfrom complex documents. Despite this, accurately localizing answers within\ndocuments remains a major challenge, limiting both interpretability and\nreal-world applicability. To address this, we introduce\n\\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that\ndecouples answer generation from spatial localization. This design makes it\napplicable to existing VLMs, including proprietary systems where fine-tuning is\nnot feasible. Through systematic evaluation, we provide quantitative insights\ninto the gap between textual accuracy and spatial grounding, showing that\ncorrect answers often lack reliable localization. Our standardized framework\nhighlights these shortcomings and establishes a benchmark for future research\ntoward more interpretable and robust document information extraction VLMs.", "published": "2025-09-12 10:44:24", "link": "http://arxiv.org/abs/2509.10129v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "abstract": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.", "published": "2025-09-12 10:43:47", "link": "http://arxiv.org/abs/2509.10127v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prominence-aware automatic speech recognition for conversational speech", "abstract": "This paper investigates prominence-aware automatic speech recognition (ASR)\nby combining prominence detection and speech recognition for conversational\nAustrian German. First, prominence detectors were developed by fine-tuning\nwav2vec2 models to classify word-level prominence. The detector was then used\nto automatically annotate prosodic prominence in a large corpus. Based on those\nannotations, we trained novel prominence-aware ASR systems that simultaneously\ntranscribe words and their prominence levels. The integration of prominence\ninformation did not change performance compared to our baseline ASR system,\nwhile reaching a prominence detection accuracy of 85.53% for utterances where\nthe recognized word sequence was correct. This paper shows that\ntransformer-based models can effectively encode prosodic information and\nrepresents a novel contribution to prosody-enhanced ASR, with potential\napplications for linguistic research and prosody-informed dialogue systems.", "published": "2025-09-12 10:18:38", "link": "http://arxiv.org/abs/2509.10116v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records", "abstract": "The development of medical chatbots in Arabic is significantly constrained by\nthe scarcity of large-scale, high-quality annotated datasets. While prior\nefforts compiled a dataset of 20,000 Arabic patient-doctor interactions from\nsocial media to fine-tune large language models (LLMs), model scalability and\ngeneralization remained limited. In this study, we propose a scalable synthetic\ndata augmentation strategy to expand the training corpus to 100,000 records.\nUsing advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated\n80,000 contextually relevant and medically coherent synthetic question-answer\npairs grounded in the structure of the original dataset. These synthetic\nsamples were semantically filtered, manually validated, and integrated into the\ntraining pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,\nand evaluated their performance using BERTScore metrics and expert-driven\nqualitative assessments. To further analyze the effectiveness of synthetic\nsources, we conducted an ablation study comparing ChatGPT-4o and\nGemini-generated data independently. The results showed that ChatGPT-4o data\nconsistently led to higher F1-scores and fewer hallucinations across all\nmodels. Overall, our findings demonstrate the viability of synthetic\naugmentation as a practical solution for enhancing domain-specific language\nmodels in-low resource medical NLP, paving the way for more inclusive,\nscalable, and accurate Arabic healthcare chatbot systems.", "published": "2025-09-12 09:58:11", "link": "http://arxiv.org/abs/2509.10108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VARCO-VISION-2.0 Technical Report", "abstract": "We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model\n(VLM) for Korean and English with improved capabilities compared to the\nprevious model VARCO-VISION-14B. The model supports multi-image understanding\nfor complex inputs such as documents, charts, and tables, and delivers\nlayoutaware OCR by predicting both textual content and its spatial location.\nTrained with a four-stage curriculum with memory-efficient techniques, the\nmodel achieves enhanced multimodal alignment, while preserving core language\nabilities and improving safety via preference optimization. Extensive benchmark\nevaluations demonstrate strong spatial grounding and competitive results for\nboth languages, with the 14B model achieving 8th place on the OpenCompass VLM\nleaderboard among models of comparable scale. Alongside the 14B-scale model, we\nrelease a 1.7B version optimized for on-device deployment. We believe these\nmodels advance the development of bilingual VLMs and their practical\napplications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a\nfull-scale 14B model and a lightweight 1.7B model.", "published": "2025-09-12 09:55:56", "link": "http://arxiv.org/abs/2509.10105v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Arabic Large Language Models for Medical Text Generation", "abstract": "Efficient hospital management systems (HMS) are critical worldwide to address\nchallenges such as overcrowding, limited resources, and poor availability of\nurgent health care. Existing methods often lack the ability to provide\naccurate, real-time medical advice, particularly for irregular inputs and\nunderrepresented languages. To overcome these limitations, this study proposes\nan approach that fine-tunes large language models (LLMs) for Arabic medical\ntext generation. The system is designed to assist patients by providing\naccurate medical advice, diagnoses, drug recommendations, and treatment plans\nbased on user input. The research methodology required the collection of a\nunique dataset from social media platforms, capturing real-world medical\nconversations between patients and doctors. The dataset, which includes patient\ncomplaints together with medical advice, was properly cleaned and preprocessed\nto account for multiple Arabic dialects. Fine-tuning state-of-the-art\ngenerative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2\nMedium, optimized the system's ability to generate reliable medical text.\nResults from evaluations indicate that the fine-tuned Mistral-7B model\noutperformed the other models, achieving average BERT (Bidirectional Encoder\nRepresentations from Transformers) Score values in precision, recall, and\nF1-scores of 68.5\\%, 69.08\\%, and 68.5\\%, respectively. Comparative\nbenchmarking and qualitative assessments validate the system's ability to\nproduce coherent and relevant medical replies to informal input. This study\nhighlights the potential of generative artificial intelligence (AI) in\nadvancing HMS, offering a scalable and adaptable solution for global healthcare\nchallenges, especially in linguistically and culturally diverse environments.", "published": "2025-09-12 09:37:26", "link": "http://arxiv.org/abs/2509.10095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery", "abstract": "The growing complexity and volume of climate science literature make it\nincreasingly difficult for researchers to find relevant information across\nmodels, datasets, regions, and variables. This paper introduces a\ndomain-specific Knowledge Graph (KG) built from climate publications and\nbroader scientific texts, aimed at improving how climate knowledge is accessed\nand used. Unlike keyword based search, our KG supports structured, semantic\nqueries that help researchers discover precise connections such as which models\nhave been validated in specific regions or which datasets are commonly used\nwith certain teleconnection patterns. We demonstrate how the KG answers such\nquestions using Cypher queries, and outline its integration with large language\nmodels in RAG systems to improve transparency and reliability in\nclimate-related question answering. This work moves beyond KG construction to\nshow its real world value for climate researchers, model developers, and others\nwho rely on accurate, contextual scientific information.", "published": "2025-09-12 09:28:29", "link": "http://arxiv.org/abs/2509.10087v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models", "abstract": "Researchers have applied established psychometric questionnaires (e.g., BFI,\nPVQ) to measure the personality traits and values reflected in the responses of\nLarge Language Models (LLMs). However, concerns have been raised about applying\nthese human-designed questionnaires to LLMs. One such concern is their lack of\necological validity--the extent to which survey questions adequately reflect\nand resemble real-world contexts in which LLMs generate texts in response to\nuser queries. However, it remains unclear how established questionnaires and\necologically valid questionnaires differ in their outcomes, and what insights\nthese differences may provide. In this paper, we conduct a comprehensive\ncomparative analysis of the two types of questionnaires. Our analysis reveals\nthat established questionnaires (1) yield substantially different profiles of\nLLMs from ecologically valid ones, deviating from the psychological\ncharacteristics expressed in the context of user queries, (2) suffer from\ninsufficient items for stable measurement, (3) create misleading impressions\nthat LLMs possess stable constructs, and (4) yield exaggerated profiles for\npersona-prompted LLMs. Overall, our work cautions against the use of\nestablished psychological questionnaires for LLMs. Our code will be released\nupon publication.", "published": "2025-09-12 09:14:42", "link": "http://arxiv.org/abs/2509.10078v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment", "abstract": "We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained\nArabic readability assessment, achieving first place in six of six tracks. Our\napproach is a confidence-weighted ensemble of four complementary transformer\nmodels (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with\ndistinct loss functions to capture diverse readability signals. To tackle\nsevere class imbalance and data scarcity, we applied weighted training,\nadvanced preprocessing, SAMER corpus relabeling with our strongest model, and\nsynthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level\nsamples. A targeted post-processing step corrected prediction distribution\nskew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system\nreached 87.5 percent QWK at the sentence level and 87.4 percent at the document\nlevel, demonstrating the power of model and loss diversity, confidence-informed\nfusion, and intelligent augmentation for robust Arabic readability prediction.", "published": "2025-09-12 08:08:45", "link": "http://arxiv.org/abs/2509.10040v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic trajectories of bipolar disorder on social media", "abstract": "Language provides valuable markers of affective disorders such as bipolar\ndisorder (BD), yet clinical assessments remain limited in scale. In response,\nanalyses of social media (SM) language have gained prominence due to their high\ntemporal resolution and longitudinal scope. Here, we introduce a method to\ndetermine the timing of users' diagnoses and apply it to study language\ntrajectories from 3 years before to 21 years after BD diagnosis - contrasted\nwith uses reporting unipolar depression (UD) and non-affected users (HC). We\nshow that BD diagnosis is accompanied by pervasive linguistic alterations\nreflecting mood disturbance, psychiatric comorbidity, substance abuse,\nhospitalization, medical comorbidities, unusual thought content, and\ndisorganized thought. We further observe recurring mood-related language\nchanges across two decades after the diagnosis, with a pronounced 12-month\nperiodicity suggestive of seasonal mood episodes. Finally, trend-level evidence\nsuggests an increased periodicity in users estimated to be female. In sum, our\nfindings provide evidence for language alterations in the acute and chronic\nphase of BD. This validates and extends recent efforts leveraging SM for\nscalable monitoring of mental health.", "published": "2025-09-12 08:02:38", "link": "http://arxiv.org/abs/2509.10035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Learnable 2D Convolutional Feature Extraction for ASR", "abstract": "Neural front-ends represent a promising approach to feature extraction for\nautomatic speech recognition (ASR) systems as they enable to learn specifically\ntailored features for different tasks. Yet, many of the existing techniques\nremain heavily influenced by classical methods. While this inductive bias may\nease the system design, our work aims to develop a more generic front-end for\nfeature extraction. Furthermore, we seek to unify the front-end architecture\ncontrasting with existing approaches that apply a composition of several layer\ntopologies originating from different sources. The experiments systematically\nshow how to reduce the influence of existing techniques to achieve a generic\nfront-end. The resulting 2D convolutional front-end is parameter-efficient and\nsuitable for a scenario with limited computational resources unlike large\nmodels pre-trained on unlabeled audio. The results demonstrate that this\ngeneric unified approach is not only feasible but also matches the performance\nof existing supervised learnable feature extractors.", "published": "2025-09-12 07:52:51", "link": "http://arxiv.org/abs/2509.10031v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs", "abstract": "In this paper, we provide an extensive analysis of multi-label intent\nclassification using Large Language Models (LLMs) that are open-source,\npublicly available, and can be run in consumer hardware. We use the MultiWOZ\n2.1 dataset, a benchmark in the dialogue system domain, to investigate the\nefficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,\nMistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot\nsetup, giving 20 examples in the prompt with some instructions. Our approach\nfocuses on the differences in performance of these models across several\nperformance metrics by methodically assessing these models on multi-label\nintent classification tasks. Additionally, we compare the performance of the\ninstruction-based fine-tuning approach with supervised learning using the\nsmaller transformer model BertForSequenceClassification as a baseline. To\nevaluate the performance of the models, we use evaluation metrics like\naccuracy, precision, and recall as well as micro, macro, and weighted F1 score.\nWe also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1\noutperforms two other generative models on 11 intent classes out of 14 in terms\nof F-Score, with a weighted average of 0.50. It also has relatively lower\nHumming Loss and higher Jaccard Similarity, making it the winning model in the\nfew-shot setting. We find BERT based supervised classifier having superior\nperformance compared to the best performing few-shot generative LLM. The study\nprovides a framework for small open-source LLMs in detecting complex\nmulti-intent dialogues, enhancing the Natural Language Understanding aspect of\ntask-oriented chatbots.", "published": "2025-09-12 07:10:55", "link": "http://arxiv.org/abs/2509.10010v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Unsupervised Hallucination Detection by Inspecting Reasoning Processes", "abstract": "Unsupervised hallucination detection aims to identify hallucinated content\ngenerated by large language models (LLMs) without relying on labeled data.\nWhile unsupervised methods have gained popularity by eliminating\nlabor-intensive human annotations, they frequently rely on proxy signals\nunrelated to factual correctness. This misalignment biases detection probes\ntoward superficial or non-truth-related aspects, limiting generalizability\nacross datasets and scenarios. To overcome these limitations, we propose IRIS,\nan unsupervised hallucination detection framework, leveraging internal\nrepresentations intrinsic to factual correctness. IRIS prompts the LLM to\ncarefully verify the truthfulness of a given statement, and obtain its\ncontextualized embedding as informative features for training. Meanwhile, the\nuncertainty of each response is considered a soft pseudolabel for truthfulness.\nExperimental results demonstrate that IRIS consistently outperforms existing\nunsupervised methods. Our approach is fully unsupervised, computationally low\ncost, and works well even with few training data, making it suitable for\nreal-time detection.", "published": "2025-09-12 06:58:17", "link": "http://arxiv.org/abs/2509.10004v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China", "abstract": "Minority languages in China, such as Tibetan, Uyghur, and Traditional\nMongolian, face significant challenges due to their unique writing systems,\nwhich differ from international standards. This discrepancy has led to a severe\nlack of relevant corpora, particularly for supervised tasks like headline\ngeneration. To address this gap, we introduce a novel dataset, Chinese Minority\nHeadline Generation (CMHG), which includes 100,000 entries for Tibetan, and\n50,000 entries each for Uyghur and Mongolian, specifically curated for headline\ngeneration tasks. Additionally, we propose a high-quality test set annotated by\nnative speakers, designed to serve as a benchmark for future research in this\ndomain. We hope this dataset will become a valuable resource for advancing\nheadline generation in Chinese minority languages and contribute to the\ndevelopment of related benchmarks.", "published": "2025-09-12 06:18:44", "link": "http://arxiv.org/abs/2509.09990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Whisper Has an Internal Word Aligner", "abstract": "There is an increasing interest in obtaining accurate word-level timestamps\nfrom strong automatic speech recognizers, in particular Whisper. Existing\napproaches either require additional training or are simply not competitive.\nThe evaluation in prior work is also relatively loose, typically using a\ntolerance of more than 200 ms. In this work, we discover attention heads in\nWhisper that capture accurate word alignments and are distinctively different\nfrom those that do not. Moreover, we find that using characters produces finer\nand more accurate alignments than using wordpieces. Based on these findings, we\npropose an unsupervised approach to extracting word alignments by filtering\nattention heads while teacher forcing Whisper with characters. Our approach not\nonly does not require training but also produces word alignments that are more\naccurate than prior work under a stricter tolerance between 20 ms and 100 ms.", "published": "2025-09-12 06:03:24", "link": "http://arxiv.org/abs/2509.09987v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Large Language Models Meet Legal Artificial Intelligence: A Survey", "abstract": "Large Language Models (LLMs) have significantly advanced the development of\nLegal Artificial Intelligence (Legal AI) in recent years, enhancing the\nefficiency and accuracy of legal tasks. To advance research and applications of\nLLM-based approaches in legal domain, this paper provides a comprehensive\nreview of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and\nalso gather 15 benchmarks and 29 datasets to evaluate different legal\ncapabilities. Additionally, we analyse the challenges and discuss future\ndirections for LLM-based approaches in the legal domain. We hope this paper\nprovides a systematic introduction for beginners and encourages future research\nin this field. Resources are available at\nhttps://github.com/ZhitianHou/LLMs4LegalAI.", "published": "2025-09-12 05:08:11", "link": "http://arxiv.org/abs/2509.09969v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Standards in the Preparation of Biomedical Research Metadata: A Bridge2AI Perspective", "abstract": "AI-readiness describes the degree to which data may be optimally and\nethically used for subsequent AI and Machine Learning (AI/ML) methods, where\nthose methods may involve some combination of model training, data\nclassification, and ethical, explainable prediction. The Bridge2AI consortium\nhas defined the particular criteria a biomedical dataset may possess to render\nit AI-ready: in brief, a dataset's readiness is related to its FAIRness,\nprovenance, degree of characterization, explainability, sustainability, and\ncomputability, in addition to its accompaniment with documentation about\nethical data practices.\n  To ensure AI-readiness and to clarify data structure and relationships within\nBridge2AI's Grand Challenges (GCs), particular types of metadata are necessary.\nThe GCs within the Bridge2AI initiative include four data-generating projects\nfocusing on generating AI/ML-ready datasets to tackle complex biomedical and\nbehavioral research problems. These projects develop standardized, multimodal\ndata, tools, and training resources to support AI integration, while addressing\nethical data practices. Examples include using voice as a biomarker, building\ninterpretable genomic tools, modeling disease trajectories with diverse\nmultimodal data, and mapping cellular and molecular health indicators across\nthe human body.\n  This report assesses the state of metadata creation and standardization in\nthe Bridge2AI GCs, provides guidelines where required, and identifies gaps and\nareas for improvement across the program. New projects, including those outside\nthe Bridge2AI consortium, would benefit from what we have learned about\ncreating metadata as part of efforts to promote AI readiness.", "published": "2025-09-12 17:38:46", "link": "http://arxiv.org/abs/2509.10432v1", "categories": ["q-bio.OT", "cs.AI"], "primary_category": "q-bio.OT"}
{"title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "abstract": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "published": "2025-09-12 17:24:20", "link": "http://arxiv.org/abs/2509.10423v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Multimodal SAM-adapter for Semantic Segmentation", "abstract": "Semantic segmentation, a key task in computer vision with broad applications\nin autonomous driving, medical imaging, and robotics, has advanced\nsubstantially with deep learning. Nevertheless, current approaches remain\nvulnerable to challenging conditions such as poor lighting, occlusions, and\nadverse weather. To address these limitations, multimodal methods that\nintegrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,\nproviding complementary information that enhances robustness. In this work, we\npresent MM SAM-adapter, a novel framework that extends the capabilities of the\nSegment Anything Model (SAM) for multimodal semantic segmentation. The proposed\nmethod employs an adapter network that injects fused multimodal features into\nSAM's rich RGB features. This design enables the model to retain the strong\ngeneralization ability of RGB features while selectively incorporating\nauxiliary modalities only when they contribute additional cues. As a result, MM\nSAM-adapter achieves a balanced and efficient use of multimodal information. We\nevaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,\nwhere MM SAM-adapter delivers state-of-the-art performance. To further analyze\nmodality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard\nsubsets. Results consistently demonstrate that our framework outperforms\ncompeting methods in both favorable and adverse conditions, highlighting the\neffectiveness of multimodal adaptation for robust scene understanding. The code\nis available at the following link:\nhttps://github.com/iacopo97/Multimodal-SAM-Adapter.", "published": "2025-09-12 16:58:51", "link": "http://arxiv.org/abs/2509.10408v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Diversified recommendations of cultural activities with personalized determinantal point processes", "abstract": "While optimizing recommendation systems for user engagement is a\nwell-established practice, effectively diversifying recommendations without\nnegatively impacting core business metrics remains a significant industry\nchallenge. In line with our initiative to broaden our audience's cultural\npractices, this study investigates using personalized Determinantal Point\nProcesses (DPPs) to sample diverse and relevant recommendations. We rely on a\nwell-known quality-diversity decomposition of the similarity kernel to give\nmore weight to user preferences. In this paper, we present our implementations\nof the personalized DPP sampling, evaluate the trade-offs between relevance and\ndiversity through both offline and online metrics, and give insights for\npractitioners on their use in a production environment. For the sake of\nreproducibility, we release the full code for our platform and experiments on\nGitHub.", "published": "2025-09-12 16:34:07", "link": "http://arxiv.org/abs/2509.10392v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Improving Audio Event Recognition with Consistency Regularization", "abstract": "Consistency regularization (CR), which enforces agreement between model\npredictions on augmented views, has found recent benefits in automatic speech\nrecognition [1]. In this paper, we propose the use of consistency\nregularization for audio event recognition, and demonstrate its effectiveness\non AudioSet. With extensive ablation studies for both small ($\\sim$20k) and\nlarge ($\\sim$1.8M) supervised training sets, we show that CR brings consistent\nimprovement over supervised baselines which already heavily utilize data\naugmentation, and CR using stronger augmentation and multiple augmentations\nleads to additional gain for the small training set. Furthermore, we extend the\nuse of CR into the semi-supervised setup with 20K labeled samples and 1.8M\nunlabeled samples, and obtain performance improvement over our best model\ntrained on the small set.", "published": "2025-09-12 16:31:20", "link": "http://arxiv.org/abs/2509.10391v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms", "abstract": "Contrastive learning is a widely adopted self-supervised pretraining\nstrategy, yet its dependence on cohort composition remains underexplored. We\npresent Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation\nmodel and pretrain on four cohorts (n = 5,203,352), from diverse populations\nacross three continents (North America, South America, Asia). We systematically\nassess how cohort demographics, health status, and population diversity\ninfluence the downstream performance for prediction tasks also including two\nadditional cohorts from another continent (Europe). We find that downstream\nperformance depends on the distributional properties of the pretraining cohort,\nincluding demographics and health status. Moreover, while pretraining with a\nmulti-centre, demographically diverse cohort improves in-distribution accuracy,\nit reduces out-of-distribution (OOD) generalisation of our contrastive approach\nby encoding cohort-specific artifacts. To address this, we propose the\nIn-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency\nduring pretraining and enhances OOD robustness. This work provides important\ninsights for developing clinically fair and generalisable foundation models.", "published": "2025-09-12 16:01:18", "link": "http://arxiv.org/abs/2509.10369v1", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.TO"], "primary_category": "cs.LG"}
{"title": "Towards Understanding Visual Grounding in Visual Language Models", "abstract": "Visual grounding refers to the ability of a model to identify a region within\nsome visual input that matches a textual description. Consequently, a model\nequipped with visual grounding capabilities can target a wide range of\napplications in various domains, including referring expression comprehension,\nanswering questions pertinent to fine-grained details in images or videos,\ncaption visual context by explicitly referring to entities, as well as low and\nhigh-level control in simulated and real environments. In this survey paper, we\nreview representative works across the key areas of research on modern\ngeneral-purpose vision language models (VLMs). We first outline the importance\nof grounding in VLMs, then delineate the core components of the contemporary\nparadigm for developing grounded models, and examine their practical\napplications, including benchmarks and evaluation metrics for grounded\nmultimodal generation. We also discuss the multifaceted interrelations among\nvisual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,\nwe analyse the challenges inherent to visual grounding and suggest promising\ndirections for future research.", "published": "2025-09-12 15:33:49", "link": "http://arxiv.org/abs/2509.10345v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography", "abstract": "Mammography screening is an essential tool for early detection of breast\ncancer. The speed and accuracy of mammography interpretation have the potential\nto be improved with deep learning methods. However, the development of a\nfoundation visual language model (VLM) is hindered by limited data and domain\ndifferences between natural and medical images. Existing mammography VLMs,\nadapted from natural images, often ignore domain-specific characteristics, such\nas multi-view relationships in mammography. Unlike radiologists who analyze\nboth views together to process ipsilateral correspondence, current methods\ntreat them as independent images or do not properly model the multi-view\ncorrespondence learning, losing critical geometric context and resulting in\nsuboptimal prediction. We propose GLAM: Global and Local Alignment for\nMulti-view mammography for VLM pretraining using geometry guidance. By\nleveraging the prior knowledge about the multi-view imaging process of\nmammograms, our model learns local cross-view alignments and fine-grained local\nfeatures through joint global and local, visual-visual, and visual-language\ncontrastive learning. Pretrained on EMBED [14], one of the largest open\nmammography datasets, our model outperforms baselines across multiple datasets\nunder different settings.", "published": "2025-09-12 15:33:18", "link": "http://arxiv.org/abs/2509.10344v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation", "abstract": "Vision Transformers (ViTs) have recently achieved strong results in semantic\nsegmentation, yet their deployment on resource-constrained devices remains\nlimited due to their high memory footprint and computational cost. Quantization\noffers an effective strategy to improve efficiency, but ViT-based segmentation\nmodels are notoriously fragile under low precision, as quantization errors\naccumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the\nfirst fully integer-only ViT segmentation framework. Building on the Segmenter\narchitecture, I-Segmenter systematically replaces floating-point operations\nwith integer-only counterparts. To further stabilize both training and\ninference, we propose $\\lambda$-ShiftGELU, a novel activation function that\nmitigates the limitations of uniform quantization in handling long-tailed\nactivation distributions. In addition, we remove the L2 normalization layer and\nreplace bilinear interpolation in the decoder with nearest neighbor upsampling,\nensuring integer-only execution throughout the computational graph. Extensive\nexperiments show that I-Segmenter achieves accuracy within a reasonable margin\nof its FP32 baseline (5.1 % on average), while reducing model size by up to\n3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,\neven in one-shot PTQ with a single calibration image, I-Segmenter delivers\ncompetitive accuracy, underscoring its practicality for real-world deployment.", "published": "2025-09-12 15:14:19", "link": "http://arxiv.org/abs/2509.10334v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "State Algebra for Propositional Logic", "abstract": "This paper presents State Algebra, a novel framework designed to represent\nand manipulate propositional logic using algebraic methods. The framework is\nstructured as a hierarchy of three representations: Set, Coordinate, and Row\nDecomposition. These representations anchor the system in well-known semantics\nwhile facilitating the computation using a powerful algebraic engine. A key\naspect of State Algebra is its flexibility in representation. We show that\nalthough the default reduction of a state vector is not canonical, a unique\ncanonical form can be obtained by applying a fixed variable order during the\nreduction process. This highlights a trade-off: by foregoing guaranteed\ncanonicity, the framework gains increased flexibility, potentially leading to\nmore compact representations of certain classes of problems. We explore how\nthis framework provides tools to articulate both search-based and knowledge\ncompilation algorithms and discuss its natural extension to probabilistic logic\nand Weighted Model Counting.", "published": "2025-09-12 15:05:52", "link": "http://arxiv.org/abs/2509.10326v1", "categories": ["cs.AI", "cs.LO", "03G27 (Primary) 68W30, 68T27 (Secondary)"], "primary_category": "cs.AI"}
{"title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "abstract": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "published": "2025-09-12 14:45:39", "link": "http://arxiv.org/abs/2509.10303v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis", "abstract": "Artificial intelligence (AI) is advancing at a pace that raises urgent\nquestions about how to align machine decision-making with human moral values.\nThis working paper investigates how leading AI systems prioritize moral\noutcomes and what this reveals about the prospects for human-AI symbiosis. We\naddress two central questions: (1) What moral values do state-of-the-art large\nlanguage models (LLMs) implicitly favour when confronted with dilemmas? (2) How\ndo differences in model architecture, cultural origin, and explainability\naffect these moral preferences? To explore these questions, we conduct a\nquantitative experiment with six LLMs, ranking and scoring outcomes across 18\ndilemmas representing five moral frameworks. Our findings uncover strikingly\nconsistent value biases. Across all models, Care and Virtue values outcomes\nwere rated most moral, while libertarian choices were consistently penalized.\nReasoning-enabled models exhibited greater sensitivity to context and provided\nricher explanations, whereas non-reasoning models produced more uniform but\nopaque judgments. This research makes three contributions: (i) Empirically, it\ndelivers a large-scale comparison of moral reasoning across culturally distinct\nLLMs; (ii) Theoretically, it links probabilistic model behaviour with\nunderlying value encodings; (iii) Practically, it highlights the need for\nexplainability and cultural awareness as critical design principles to guide AI\ntoward a transparent, aligned, and symbiotic future.", "published": "2025-09-12 14:37:57", "link": "http://arxiv.org/abs/2509.10297v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "We Need a New Ethics for a World of AI Agents", "abstract": "The deployment of capable AI agents raises fresh questions about safety,\nhuman-machine relationships and social coordination. We argue for greater\nengagement by scientists, scholars, engineers and policymakers with the\nimplications of a world increasingly populated by AI agents. We explore key\nchallenges that must be addressed to ensure that interactions between humans\nand agents, and among agents themselves, remain broadly beneficial.", "published": "2025-09-12 14:29:14", "link": "http://arxiv.org/abs/2509.10289v1", "categories": ["cs.CY", "cs.AI", "I.2.0; K.4.1"], "primary_category": "cs.CY"}
{"title": "SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion", "abstract": "Sign language translation (SLT) aims to translate natural language from sign\nlanguage videos, serving as a vital bridge for inclusive communication. While\nrecent advances leverage powerful visual backbones and large language models,\nmost approaches mainly focus on manual signals (hand gestures) and tend to\noverlook non-manual cues like mouthing. In fact, mouthing conveys essential\nlinguistic information in sign languages and plays a crucial role in\ndisambiguating visually similar signs. In this paper, we propose SignClip, a\nnovel framework to improve the accuracy of sign language translation. It fuses\nmanual and non-manual cues, specifically spatial gesture and lip movement\nfeatures. Besides, SignClip introduces a hierarchical contrastive learning\nframework with multi-level alignment objectives, ensuring semantic consistency\nacross sign-lip and visual-text modalities. Extensive experiments on two\nbenchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our\napproach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip\nsurpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from\n24.32 to 24.71, and ROUGE from 46.57 to 48.38.", "published": "2025-09-12 14:08:06", "link": "http://arxiv.org/abs/2509.10266v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering", "abstract": "Recent advances in Language Models (LMs) have failed to mask their\nshortcomings particularly in the domain of reasoning. This limitation impacts\nseveral tasks, most notably those involving ontology engineering. As part of a\nPhD research, we investigate the consequences of incorporating formal methods\non the performance of Small Language Models (SLMs) on reasoning tasks.\nSpecifically, we aim to orient our work toward using SLMs to bootstrap ontology\nconstruction and set up a series of preliminary experiments to determine the\nimpact of expressing logical problems with different grammars on the\nperformance of SLMs on a predefined reasoning task. Our findings show that it\nis possible to substitute Natural Language (NL) with a more compact logical\nlanguage while maintaining a strong performance on reasoning tasks and hope to\nuse these results to further refine the role of SLMs in ontology engineering.", "published": "2025-09-12 13:46:43", "link": "http://arxiv.org/abs/2509.10249v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Compartmentalised Agentic Reasoning for Clinical NLI", "abstract": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "published": "2025-09-12 13:14:47", "link": "http://arxiv.org/abs/2509.10222v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Openness in AI and downstream governance: A global value chain approach", "abstract": "The rise of AI has been rapid, becoming a leading sector for investment and\npromising disruptive impacts across the economy. Within the critical analysis\nof the economic impacts, AI has been aligned to the critical literature on data\npower and platform capitalism - further concentrating power and value capture\namongst a small number of \"big tech\" leaders.\n  The equally rapid rise of openness in AI (here taken to be claims made by AI\nfirms about openness, \"open source\" and free provision) signals an interesting\ndevelopment. It highlights an emerging ecosystem of open AI models, datasets\nand toolchains, involving massive capital investment. It poses questions as to\nwhether open resources can support technological transfer and the ability for\ncatch-up, even in the face of AI industry power.\n  This work seeks to add conceptual clarity to these debates by conceptualising\nopenness in AI as a unique type of interfirm relation and therefore amenable to\nvalue chain analysis. This approach then allows consideration of the capitalist\ndynamics of \"outsourcing\" of foundational firms in value chains, and\nconsequently the types of governance and control that might emerge downstream\nas AI is adopted. This work, therefore, extends previous mapping of AI value\nchains to build a framework which links foundational AI with downstream value\nchains.\n  Overall, this work extends our understanding of AI as a productive sector.\nWhile the work remains critical of the power of leading AI firms, openness in\nAI may lead to potential spillovers stemming from the intense competition for\nglobal technological leadership in AI.", "published": "2025-09-12 13:12:09", "link": "http://arxiv.org/abs/2509.10220v1", "categories": ["cs.CY", "cs.AI", "K.4.1; K.4.3"], "primary_category": "cs.CY"}
{"title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "abstract": "Automated characterization of porous materials has the potential to\naccelerate materials discovery, but it remains limited by the complexity of\nsimulation setup and force field selection. We propose a multi-agent framework\nin which LLM-based agents can autonomously understand a characterization task,\nplan appropriate simulations, assemble relevant force fields, execute them and\ninterpret their results to guide subsequent steps. As a first step toward this\nvision, we present a multi-agent system for literature-informed force field\nextraction and automated RASPA simulation setup. Initial evaluations\ndemonstrate high correctness and reproducibility, highlighting this approach's\npotential to enable fully autonomous, scalable materials characterization.", "published": "2025-09-12 12:56:47", "link": "http://arxiv.org/abs/2509.10210v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "abstract": "Online planning in Markov Decision Processes (MDPs) enables agents to make\nsequential decisions by simulating future trajectories from the current state,\nmaking it well-suited for large-scale or dynamic environments. Sample-based\nmethods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely\nadopted for their ability to approximate optimal actions using a generative\nmodel. However, in practical settings, the generative model is often learned\nfrom limited data, introducing approximation errors that can degrade\nperformance or lead to unsafe behaviors. To address these challenges, Robust\nMDPs (RMDPs) offer a principled framework for planning under model uncertainty,\nyet existing approaches are typically computationally intensive and not suited\nfor real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the\nfirst online planning algorithm for RMDPs with finite-sample theoretical\nperformance guarantees. Unlike Sparse Sampling, which estimates the nominal\nvalue function, RSS computes a robust value function by leveraging the\nefficiency and theoretical properties of Sample Average Approximation (SAA),\nenabling tractable robust policy computation in online settings. RSS is\napplicable to infinite or continuous state spaces, and its sample and\ncomputational complexities are independent of the state space size. We provide\ntheoretical performance guarantees and empirically show that RSS outperforms\nstandard Sparse Sampling in environments with uncertain dynamics.", "published": "2025-09-12 11:41:23", "link": "http://arxiv.org/abs/2509.10162v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BenchECG and xECG: a benchmark and baseline for ECG foundation models", "abstract": "Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to\ndeep learning. Recently, interest has grown in developing foundation models for\nECGs - models that generalise across diverse downstream tasks. However,\nconsistent evaluation has been lacking: prior work often uses narrow task\nselections and inconsistent datasets, hindering fair comparison. Here, we\nintroduce BenchECG, a standardised benchmark comprising a comprehensive suite\nof publicly available ECG datasets and versatile tasks. We also propose xECG,\nan xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,\nwhich achieves the best BenchECG score compared to publicly available\nstate-of-the-art models. In particular, xECG is the only publicly available\nmodel to perform strongly on all datasets and tasks. By standardising\nevaluation, BenchECG enables rigorous comparison and aims to accelerate\nprogress in ECG representation learning. xECG achieves superior performance\nover earlier approaches, defining a new baseline for future ECG foundation\nmodels.", "published": "2025-09-12 11:27:17", "link": "http://arxiv.org/abs/2509.10151v1", "categories": ["cs.LG", "cs.AI", "I.2.1"], "primary_category": "cs.LG"}
{"title": "Virtual Agent Economies", "abstract": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "published": "2025-09-12 11:20:11", "link": "http://arxiv.org/abs/2509.10147v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Efficient Learning-Based Control of a Legged Robot in Lunar Gravity", "abstract": "Legged robots are promising candidates for exploring challenging areas on\nlow-gravity bodies such as the Moon, Mars, or asteroids, thanks to their\nadvanced mobility on unstructured terrain. However, as planetary robots' power\nand thermal budgets are highly restricted, these robots need energy-efficient\ncontrol approaches that easily transfer to multiple gravity environments. In\nthis work, we introduce a reinforcement learning-based control approach for\nlegged robots with gravity-scaled power-optimized reward functions. We use our\napproach to develop and validate a locomotion controller and a base pose\ncontroller in gravity environments from lunar gravity (1.62 m/s2) to a\nhypothetical super-Earth (19.62 m/s2). Our approach successfully scales across\nthese gravity levels for locomotion and base pose control with the\ngravity-scaled reward functions. The power-optimized locomotion controller\nreached a power consumption for locomotion of 23.4 W in Earth gravity on a\n15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.\nAdditionally, we designed a constant-force spring offload system that allowed\nus to conduct real-world experiments on legged locomotion in lunar gravity. In\nlunar gravity, the power-optimized control policy reached 12.2 W, 36 % less\nthan a baseline controller which is not optimized for power efficiency. Our\nmethod provides a scalable approach to developing power-efficient locomotion\ncontrollers for legged robots across multiple gravity levels.", "published": "2025-09-12 10:43:58", "link": "http://arxiv.org/abs/2509.10128v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution", "abstract": "Pre-trained diffusion models have shown great potential in real-world image\nsuper-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.\nWhile one-step diffusion (OSD) methods significantly improve efficiency\ncompared to traditional multi-step approaches, they still have limitations in\nbalancing fidelity and realism across diverse scenarios. Since the OSDs for SR\nare usually trained or distilled by a single timestep, they lack flexible\ncontrol mechanisms to adaptively prioritize these competing objectives, which\nare inherently manageable in multi-step methods through adjusting sampling\nsteps. To address this challenge, we propose a Realism Controlled One-step\nDiffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping\nstrategy that enables explicit control over fidelity-realism trade-offs during\nthe noise prediction phase with minimal training paradigm modifications and\noriginal training data. A degradation-aware sampling strategy is also\nintroduced to align distillation regularization with the grouping strategy and\nenhance the controlling of trade-offs. Moreover, a visual prompt injection\nmodule is used to replace conventional text prompts with degradation-aware\nvisual tokens, enhancing both restoration accuracy and semantic consistency.\nOur method achieves superior fidelity and perceptual quality while maintaining\ncomputational efficiency. Extensive experiments demonstrate that RCOD\noutperforms state-of-the-art OSD methods in both quantitative metrics and\nvisual qualities, with flexible realism control capabilities in the inference\nstage. The code will be released.", "published": "2025-09-12 10:32:04", "link": "http://arxiv.org/abs/2509.10122v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework", "abstract": "The absolute dominance of Artificial Intelligence (AI) introduces\nunprecedented societal harms and risks. Existing AI risk assessment models\nfocus on internal compliance, often neglecting diverse stakeholder perspectives\nand real-world consequences. We propose a paradigm shift to a human-centric,\nharm-severity adaptive approach grounded in empirical incident data. We present\nAI Harmonics, which includes a novel AI harm assessment metric (AIH) that\nleverages ordinal severity data to capture relative impact without requiring\nprecise numerical estimates. AI Harmonics combines a robust, generalized\nmethodology with a data-driven, stakeholder-aware framework for exploring and\nprioritizing AI harms. Experiments on annotated incident data confirm that\npolitical and physical harms exhibit the highest concentration and thus warrant\nurgent mitigation: political harms erode public trust, while physical harms\npose serious, even life-threatening risks, underscoring the real-world\nrelevance of our approach. Finally, we demonstrate that AI Harmonics\nconsistently identifies uneven harm distributions, enabling policymakers and\norganizations to target their mitigation efforts effectively.", "published": "2025-09-12 09:52:45", "link": "http://arxiv.org/abs/2509.10104v1", "categories": ["cs.AI", "stat.ME"], "primary_category": "cs.AI"}
{"title": "Generating Energy-Efficient Code via Large-Language Models -- Where are we now?", "abstract": "Context. The rise of Large Language Models (LLMs) has led to their widespread\nadoption in development pipelines. Goal. We empirically assess the energy\nefficiency of Python code generated by LLMs against human-written code and code\ndeveloped by a Green software expert. Method. We test 363 solutions to 9 coding\nproblems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting\ntechniques, and comparing them to human-developed solutions. Energy consumption\nis measured on three different hardware platforms: a server, a PC, and a\nRaspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%\nmore energy-efficient on the server and 3% on the Raspberry Pi, while LLMs\noutperform human developers by 25% on the PC. Prompting does not consistently\nlead to energy savings, where the most energy-efficient prompts vary by\nhardware platform. The code developed by a Green software expert is\nconsistently more energy-efficient by at least 17% to 30% against all LLMs on\nall hardware platforms. Conclusions. Even though LLMs exhibit relatively good\ncode generation capabilities, no LLM-generated code was more energy-efficient\nthan that of an experienced Green software developer, suggesting that as of\ntoday there is still a great need of human expertise for developing\nenergy-efficient Python code.", "published": "2025-09-12 09:49:46", "link": "http://arxiv.org/abs/2509.10099v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks", "abstract": "Efficient planning and sequence selection are central to intelligence, yet\ncurrent approaches remain largely incompatible with biological computation.\nClassical graph algorithms like Dijkstra's or A* require global state and\nbiologically implausible operations such as backtracing, while reinforcement\nlearning methods rely on slow gradient-based policy updates that appear\ninconsistent with rapid behavioral adaptation observed in natural systems.\n  We propose a biologically plausible algorithm for shortest-path computation\nthat operates through local spike-based message-passing with realistic\nprocessing delays. The algorithm exploits spike-timing coincidences to identify\nnodes on optimal paths: Neurons that receive inhibitory-excitatory message\npairs earlier than predicted reduce their response delays, creating a temporal\ncompression that propagates backwards from target to source. Through analytical\nproof and simulations on random spatial networks, we demonstrate that the\nalgorithm converges and discovers all shortest paths using purely timing-based\nmechanisms. By showing how short-term timing dynamics alone can compute\nshortest paths, this work provides new insights into how biological networks\nmight solve complex computational problems through purely local computation and\nrelative spike-time prediction. These findings open new directions for\nunderstanding distributed computation in biological and artificial systems,\nwith possible implications for computational neuroscience, AI, reinforcement\nlearning, and neuromorphic systems.", "published": "2025-09-12 09:13:47", "link": "http://arxiv.org/abs/2509.10077v1", "categories": ["cs.NE", "cs.AI", "cs.DS", "cs.LG"], "primary_category": "cs.NE"}
{"title": "TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model", "abstract": "Robot skill acquisition processes driven by reinforcement learning often rely\non simulations to efficiently generate large-scale interaction data. However,\nthe absence of simulation models for tactile sensors has hindered the use of\ntactile sensing in such skill learning processes, limiting the development of\neffective policies driven by tactile perception. To bridge this gap, we present\nTwinTac, a system that combines the design of a physical tactile sensor with\nits digital twin model. Our hardware sensor is designed for high sensitivity\nand a wide measurement range, enabling high quality sensing data essential for\nobject interaction tasks. Building upon the hardware sensor, we develop the\ndigital twin model using a real-to-sim approach. This involves collecting\nsynchronized cross-domain data, including finite element method results and the\nphysical sensor's outputs, and then training neural networks to map simulated\ndata to real sensor responses. Through experimental evaluation, we\ncharacterized the sensitivity of the physical sensor and demonstrated the\nconsistency of the digital twin in replicating the physical sensor's output.\nFurthermore, by conducting an object classification task, we showed that\nsimulation data generated by our digital twin sensor can effectively augment\nreal-world data, leading to improved accuracy. These results highlight\nTwinTac's potential to bridge the gap in cross-domain learning tasks.", "published": "2025-09-12 08:51:28", "link": "http://arxiv.org/abs/2509.10063v1", "categories": ["cs.RO", "cs.AI", "I.2.9"], "primary_category": "cs.RO"}
{"title": "Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration", "abstract": "Mathematical reasoning is critical for tasks such as precise distance and\narea computations, trajectory estimations, and spatial analysis in unmanned\naerial vehicle (UAV) based remote sensing, yet current vision-language models\n(VLMs) have not been adequately tested in this domain. To address this gap, we\nintroduce AVI-Math, the first benchmark to rigorously evaluate multimodal\nmathematical reasoning in aerial vehicle imagery, moving beyond simple counting\ntasks to include domain-specific knowledge in areas such as geometry, logic,\nand algebra. The dataset comprises 3,773 high-quality vehicle-related questions\ncaptured from UAV views, covering 6 mathematical subjects and 20 topics. The\ndata, collected at varying altitudes and from multiple UAV angles, reflects\nreal-world UAV scenarios, ensuring the diversity and complexity of the\nconstructed mathematical problems. In this paper, we benchmark 14 prominent\nVLMs through a comprehensive evaluation and demonstrate that, despite their\nsuccess on previous multimodal benchmarks, these models struggle with the\nreasoning tasks in AVI-Math. Our detailed analysis highlights significant\nlimitations in the mathematical reasoning capabilities of current VLMs and\nsuggests avenues for future research. Furthermore, we explore the use of\nChain-of-Thought prompting and fine-tuning techniques, which show promise in\naddressing the reasoning challenges in AVI-Math. Our findings not only expose\nthe limitations of VLMs in mathematical reasoning but also offer valuable\ninsights for advancing UAV-based trustworthy VLMs in real-world applications.\nThe code, and datasets will be released at\nhttps://github.com/VisionXLab/avi-math", "published": "2025-09-12 08:46:49", "link": "http://arxiv.org/abs/2509.10059v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reinforcement learning for spin torque oscillator tasks", "abstract": "We address the problem of automatic synchronisation of the spintronic\noscillator (STO) by means of reinforcement learning (RL). A numerical solution\nof the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to\nsimulate the STO and we train the two types of RL agents to synchronise with a\ntarget frequency within a fixed number of steps. We explore modifications to\nthis base task and show an improvement in both convergence and energy\nefficiency of the synchronisation that can be easily achieved in the simulated\nenvironment.", "published": "2025-09-12 08:41:39", "link": "http://arxiv.org/abs/2509.10057v1", "categories": ["physics.app-ph", "cs.AI", "cs.LG"], "primary_category": "physics.app-ph"}
{"title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "published": "2025-09-12 08:40:58", "link": "http://arxiv.org/abs/2509.10054v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts", "abstract": "Understanding the internal organization of neural networks remains a\nfundamental challenge in deep learning interpretability. We address this\nchallenge by exploring a novel Sparse Mixture of Experts Variational\nAutoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw\ndataset, comparing unsupervised expert routing against a supervised baseline\nguided by ground-truth labels. Surprisingly, we find that unsupervised routing\nconsistently achieves superior reconstruction performance. The experts learn to\nidentify meaningful sub-categorical structures that often transcend\nhuman-defined class boundaries. Through t-SNE visualizations and reconstruction\nanalysis, we investigate how MoE models uncover fundamental data structures\nthat are more aligned with the model's objective than predefined labels.\nFurthermore, our study on the impact of dataset size provides insights into the\ntrade-offs between data quantity and expert specialization, offering guidance\nfor designing efficient MoE architectures.", "published": "2025-09-12 07:45:10", "link": "http://arxiv.org/abs/2509.10025v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "abstract": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "published": "2025-09-12 07:22:49", "link": "http://arxiv.org/abs/2509.10018v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "abstract": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "published": "2025-09-12 07:11:05", "link": "http://arxiv.org/abs/2509.10011v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae", "abstract": "Evaluating explainable AI (XAI) approaches is a challenging task in general,\ndue to the subjectivity of explanations. In this paper, we focus on tabular\ndata and the specific use case of AI models predicting the values of Boolean\nfunctions. We extend the previous work in this domain by proposing a formal and\nprecise measure of importance of variables based on actual causality, and we\nevaluate state-of-the-art XAI tools against this measure. We also present a\nnovel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it\nis superior to other black-box XAI tools on a large-scale benchmark.\nSpecifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\\pm$ 0.012\non random 10-valued Boolean formulae", "published": "2025-09-12 05:52:47", "link": "http://arxiv.org/abs/2509.09982v1", "categories": ["cs.AI", "I.2.4"], "primary_category": "cs.AI"}
{"title": "Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms", "abstract": "This study addresses the escalating threat of branched broomrape (Phelipanche\nramosa) to California's tomato industry, which supplies over 90 percent of U.S.\nprocessing tomatoes. The parasite's largely underground life cycle makes early\ndetection difficult, while conventional chemical controls are costly,\nenvironmentally harmful, and often ineffective. To address this, we combined\ndrone-based multispectral imagery with Long Short-Term Memory (LSTM) deep\nlearning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)\nto handle class imbalance. Research was conducted on a known broomrape-infested\ntomato farm in Woodland, Yolo County, CA, across five key growth stages\ndetermined by growing degree days (GDD). Multispectral images were processed to\nisolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with\n79.09 percent overall accuracy and 70.36 percent recall without integrating\nlater stages. Incorporating sequential growth stages with LSTM improved\ndetection substantially. The best-performing scenario, which integrated all\ngrowth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy\nand 95.37 percent recall. These results demonstrate the strong potential of\ntemporal multispectral analysis and LSTM networks for early broomrape\ndetection. While further real-world data collection is needed for practical\ndeployment, this study shows that UAV-based multispectral sensing coupled with\ndeep learning could provide a powerful precision agriculture tool to reduce\nlosses and improve sustainability in tomato production.", "published": "2025-09-12 05:16:56", "link": "http://arxiv.org/abs/2509.09972v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching", "abstract": "Large Language Models (LLMs) show promise in generating firmware for embedded\nsystems, but often introduce security flaws and fail to meet real-time\nperformance constraints. This paper proposes a three-phase methodology that\ncombines LLM-based firmware generation with automated security validation and\niterative refinement in a virtualized environment. Using structured prompts,\nmodels like GPT-4 generate firmware for networking and control tasks, deployed\non FreeRTOS via QEMU. These implementations are tested using fuzzing, static\nanalysis, and runtime monitoring to detect vulnerabilities such as buffer\noverflows (CWE-120), race conditions (CWE-362), and denial-of-service threats\n(CWE-400). Specialized AI agents for Threat Detection, Performance\nOptimization, and Compliance Verification collaborate to improve detection and\nremediation. Identified issues are categorized using CWE, then used to prompt\ntargeted LLM-generated patches in an iterative loop. Experiments show a 92.4\\%\nVulnerability Remediation Rate (37.3\\% improvement), 95.8\\% Threat Model\nCompliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms\nworst-case execution time and 195{\\mu}s jitter. This process enhances firmware\nsecurity and performance while contributing an open-source dataset for future\nresearch.", "published": "2025-09-12 05:15:35", "link": "http://arxiv.org/abs/2509.09970v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes", "abstract": "Synthetic tabular data generation is increasingly essential in data\nmanagement, supporting downstream applications when real-world and high-quality\ntabular data is insufficient. Existing tabular generation approaches, such as\ngenerative adversarial networks (GANs), diffusion models, and fine-tuned Large\nLanguage Models (LLMs), typically require sufficient reference data, limiting\ntheir effectiveness in domain-specific databases with scarce records. While\nprompt-based LLMs offer flexibility without parameter tuning, they often fail\nto capture dataset-specific feature-label dependencies and generate redundant\ndata, leading to degradation in downstream task performance. To overcome these\nissues, we propose ReFine, a framework that (i) derives symbolic \"if-then\"\nrules from interpretable models and embeds them into prompts to explicitly\nguide generation toward domain-specific feature distribution, and (ii) applies\na dual-granularity filtering strategy that suppresses over-sampling patterns\nand selectively refines rare but informative samples to reduce distributional\nimbalance. Extensive experiments on various regression and classification\nbenchmarks demonstrate that ReFine consistently outperforms state-of-the-art\nmethods, achieving up to 0.44 absolute improvement in R-squared for regression\nand 10.0 percent relative improvement in F1 score for classification tasks.", "published": "2025-09-12 04:34:46", "link": "http://arxiv.org/abs/2509.09960v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification", "abstract": "Referring Expression Comprehension (REC) is usually addressed with\ntask-trained grounding models. We show that a zero-shot workflow, without any\nREC-specific training, can achieve competitive or superior performance. Our\napproach reformulates REC as box-wise visual-language verification: given\nproposals from a COCO-clean generic detector (YOLO-World), a general-purpose\nVLM independently answers True/False queries for each region. This simple\nprocedure reduces cross-box interference, supports abstention and multiple\nmatches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our\nmethod not only surpasses a zero-shot GroundingDINO baseline but also exceeds\nreported results for GroundingDINO trained on REC and GroundingDINO+CRG.\nControlled studies with identical proposals confirm that verification\nsignificantly outperforms selection-based prompting, and results hold with open\nVLMs. Overall, we show that workflow design, rather than task-specific\npretraining, drives strong zero-shot REC performance.", "published": "2025-09-12 04:32:52", "link": "http://arxiv.org/abs/2509.09958v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge", "abstract": "Large-scale transformers are central to modern semantic communication, yet\ntheir high computational and communication costs hinder deployment on\nresource-constrained edge devices. This paper introduces a training-free\nframework for adaptive token merging, a novel mechanism that compresses\ntransformer representations at runtime by selectively merging semantically\nredundant tokens under per-layer similarity thresholds. Unlike prior\nfixed-ratio reduction, our approach couples merging directly to input\nredundancy, enabling data-dependent adaptation that balances efficiency and\ntask relevance without retraining. We cast the discovery of merging strategies\nas a multi-objective optimization problem and leverage Bayesian optimization to\nobtain Pareto-optimal trade-offs between accuracy, inference cost, and\ncommunication cost. On ImageNet classification, we match the accuracy of the\nunmodified transformer with 30\\% fewer floating-point operations per second and\nunder 20\\% of the original communication cost, while for visual question\nanswering our method achieves performance competitive with the full LLaVA model\nat less than one-third of the compute and one-tenth of the bandwidth. Finally,\nwe show that our adaptive merging is robust across varying channel conditions\nand provides inherent privacy benefits, substantially degrading the efficacy of\nmodel inversion attacks. Our framework provides a practical and versatile\nsolution for deploying powerful transformer models in resource-limited edge\nintelligence scenarios.", "published": "2025-09-12 04:11:59", "link": "http://arxiv.org/abs/2509.09955v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "primary_category": "cs.LG"}
{"title": "SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization", "abstract": "Smart contracts automate the management of high-value assets, where\nvulnerabilities can lead to catastrophic financial losses. This challenge is\namplified in Large Language Models (LLMs) by two interconnected failures: they\noperate as unauditable \"black boxes\" lacking a transparent reasoning process,\nand consequently, generate code riddled with critical security vulnerabilities.\nTo address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a\nnovel framework for secure and explainable smart contract generation. It begins\nwith Continual Pre-training (CPT) to specialize the model. We then apply Long\nChain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated\nreasoning-and-code samples to train the model to emulate human security\nanalysis. Finally, to directly mitigate vulnerabilities, we employ\nSecurity-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement\nlearning phase that refines the generation policy by optimizing a weighted\nreward signal for compilation success, security compliance, and format\ncorrectness. Evaluated against 17 baselines on a benchmark of 756 real-world\nfunctions, SmartCoder-R1 establishes a new state of the art, achieving top\nperformance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a\nSafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This\nFullRate marks a 45.79% relative improvement over the strongest baseline,\nDeepSeek-R1. Crucially, its generated reasoning also excels in human\nevaluations, achieving high-quality ratings for Functionality (82.7%), Security\n(85.3%), and Clarity (90.7%).", "published": "2025-09-12 03:14:50", "link": "http://arxiv.org/abs/2509.09942v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments", "abstract": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.", "published": "2025-09-12 01:51:01", "link": "http://arxiv.org/abs/2509.09919v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "WALL: A Web Application for Automated Quality Assurance using Large Language Models", "abstract": "As software projects become increasingly complex, the volume and variety of\nissues in code files have grown substantially. Addressing this challenge\nrequires efficient issue detection, resolution, and evaluation tools. This\npaper presents WALL, a web application that integrates SonarQube and large\nlanguage models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these\ntasks. WALL comprises three modules: an issue extraction tool, code issues\nreviser, and code comparison tool. Together, they enable a seamless pipeline\nfor detecting software issues, generating automated code revisions, and\nevaluating the accuracy of revisions. Our experiments, conducted on 563 files\nwith over 7,599 issues, demonstrate WALL's effectiveness in reducing human\neffort while maintaining high-quality revisions. Results show that employing a\nhybrid approach of cost-effective and advanced LLMs can significantly lower\ncosts and improve revision rates. Future work aims to enhance WALL's\ncapabilities by integrating open-source LLMs and eliminating human\nintervention, paving the way for fully automated code quality management.", "published": "2025-09-12 01:43:26", "link": "http://arxiv.org/abs/2509.09918v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "abstract": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "published": "2025-09-12 01:14:34", "link": "http://arxiv.org/abs/2509.09915v1", "categories": ["cs.AI", "cs.DC"], "primary_category": "cs.AI"}
{"title": "An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars", "abstract": "The practical adoption of deep learning in high-stakes forensic applications,\nsuch as dental age estimation, is often limited by the 'black box' nature of\nthe models. This study introduces a framework designed to enhance both\nperformance and transparency in this context. We use a notable performance\ndisparity in the automated staging of mandibular second (tooth 37) and third\n(tooth 38) molars as a case study. The proposed framework, which combines a\nconvolutional autoencoder (AE) with a Vision Transformer (ViT), improves\nclassification accuracy for both teeth over a baseline ViT, increasing from\n0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond\nimproving performance, the framework provides multi-faceted diagnostic\ninsights. Analysis of the AE's latent space metrics and image reconstructions\nindicates that the remaining performance gap is data-centric, suggesting high\nintra-class morphological variability in the tooth 38 dataset is a primary\nlimiting factor. This work highlights the insufficiency of relying on a single\nmode of interpretability, such as attention maps, which can appear anatomically\nplausible yet fail to identify underlying data issues. By offering a\nmethodology that both enhances accuracy and provides evidence for why a model\nmay be uncertain, this framework serves as a more robust tool to support expert\ndecision-making in forensic age estimation.", "published": "2025-09-12 00:54:07", "link": "http://arxiv.org/abs/2509.09911v1", "categories": ["cs.CV", "cs.AI", "68T07 (Primary)"], "primary_category": "cs.CV"}
{"title": "Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building", "abstract": "Key global challenges of our times are characterized by complex\ninterdependencies and can only be effectively addressed through an integrated,\nparticipatory effort. Conventional risk analysis frameworks often reduce\ncomplexity to ensure manageability, creating silos that hinder comprehensive\nsolutions. A fundamental shift towards holistic strategies is essential to\nenable effective negotiations between different sectors and to balance the\ncompeting interests of stakeholders. However, achieving this balance is often\nhindered by limited time, vast amounts of information, and the complexity of\nintegrating diverse perspectives. This study presents an AI-assisted\nnegotiation framework that incorporates large language models (LLMs) and\nAI-based autonomous agents into a negotiation-centered risk analysis workflow.\nThe framework enables stakeholders to simulate negotiations, systematically\nmodel dynamics, anticipate compromises, and evaluate solution impacts. By\nleveraging LLMs' semantic analysis capabilities we could mitigate information\noverload and augment decision-making process under time constraints.\nProof-of-concept implementations were conducted in two real-world scenarios:\n(i) prudent use of a biopesticide, and (ii) targeted wild animal population\ncontrol. Our work demonstrates the potential of AI-assisted negotiation to\naddress the current lack of tools for cross-sectoral engagement. Importantly,\nthe solution's open source, web based design, suits for application by a\nbroader audience with limited resources and enables users to tailor and develop\nit for their own needs.", "published": "2025-09-12 00:25:20", "link": "http://arxiv.org/abs/2509.09906v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation", "abstract": "In this paper, we propose a training-free framework for vision-and-language\nnavigation (VLN). Existing zero-shot VLN methods are mainly designed for\ndiscrete environments or involve unsupervised training in continuous simulator\nenvironments, which makes it challenging to generalize and deploy them in\nreal-world scenarios. To achieve a training-free framework in continuous\nenvironments, our framework formulates navigation guidance as graph constraint\noptimization by decomposing instructions into explicit spatial constraints. The\nconstraint-driven paradigm decodes spatial semantics through constraint\nsolving, enabling zero-shot adaptation to unseen environments. Specifically, we\nconstruct a spatial constraint library covering all types of spatial\nrelationship mentioned in VLN instructions. The human instruction is decomposed\ninto a directed acyclic graph, with waypoint nodes, object nodes and edges,\nwhich are used as queries to retrieve the library to build the graph\nconstraints. The graph constraint optimization is solved by the constraint\nsolver to determine the positions of waypoints, obtaining the robot's\nnavigation path and final goal. To handle cases of no solution or multiple\nsolutions, we construct a navigation tree and the backtracking mechanism.\nExtensive experiments on standard benchmarks demonstrate significant\nimprovements in success rate and navigation efficiency compared to\nstate-of-the-art zero-shot VLN methods. We further conduct real-world\nexperiments to show that our framework can effectively generalize to new\nenvironments and instruction sets, paving the way for a more robust and\nautonomous navigation framework.", "published": "2025-09-12 17:59:58", "link": "http://arxiv.org/abs/2509.10454v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets", "abstract": "Alzheimer's disease is a progressive, neurodegenerative disorder that causes\nmemory loss and cognitive decline. While there has been extensive research in\napplying deep learning models to Alzheimer's prediction tasks, these models\nremain limited by lack of available labeled data, poor generalization across\ndatasets, and inflexibility to varying numbers of input scans and time\nintervals between scans. In this study, we adapt three state-of-the-art\ntemporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,\nand add novel extensions designed to handle variable-length inputs and learn\nrobust spatial features. We aggregate four publicly available datasets\ncomprising 3,161 patients for pre-training, and show the performance of our\nmodel across multiple Alzheimer's prediction tasks including diagnosis\nclassification, conversion detection, and future conversion prediction.\nImportantly, our SSL model implemented with temporal order prediction and\ncontrastive learning outperforms supervised learning on six out of seven\ndownstream tasks. It demonstrates adaptability and generalizability across\ntasks and number of input images with varying time intervals, highlighting its\ncapacity for robust performance across clinical applications. We release our\ncode and model publicly at https://github.com/emilykaczmarek/SSL-AD.", "published": "2025-09-12 17:59:32", "link": "http://arxiv.org/abs/2509.10453v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis", "abstract": "Arbitrary resolution image generation provides a consistent visual experience\nacross devices, having extensive applications for producers and consumers.\nCurrent diffusion models increase computational demand quadratically with\nresolution, causing 4K image generation delays over 100 seconds. To solve this,\nwe explore the second generation upon the latent diffusion models, where the\nfixed latent generated by diffusion models is regarded as the content\nrepresentation and we propose to decode arbitrary resolution images with a\ncompact generated latent using a one-step generator. Thus, we present the\n\\textbf{InfGen}, replacing the VAE decoder with the new generator, for\ngenerating images at any resolution from a fixed-size latent without retraining\nthe diffusion models, which simplifies the process, reducing computational\ncomplexity and can be applied to any model using the same latent space.\nExperiments show InfGen is capable of improving many models into the arbitrary\nhigh-resolution era while cutting 4K image generation time to under 10 seconds.", "published": "2025-09-12 17:48:57", "link": "http://arxiv.org/abs/2509.10441v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards", "abstract": "Compressed video quality enhancement (CVQE) is crucial for improving user\nexperience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.\nWhile deep learning based CVQE has driven significant progress, existing\nsurveys still suffer from limitations: lack of systematic classification\nlinking methods to specific standards and artifacts, insufficient comparative\nanalysis of architectural paradigms across coding types, and underdeveloped\nbenchmarking practices. To address these gaps, this paper presents three key\ncontributions. First, it introduces a novel taxonomy classifying CVQE methods\nacross architectural paradigms, coding standards, and compressed-domain feature\nutilization. Second, it proposes a unified benchmarking framework integrating\nmodern compression protocols and standard test sequences for fair\nmulti-criteria evaluation. Third, it provides a systematic analysis of the\ncritical trade-offs between reconstruction performance and computational\ncomplexity observed in state-of-the-art methods and highlighting promising\ndirections for future research. This comprehensive review aims to establish a\nfoundation for consistent assessment and informed model selection in CVQE\nresearch and deployment.", "published": "2025-09-12 16:58:20", "link": "http://arxiv.org/abs/2509.10407v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition", "abstract": "Decomposing an image into its intrinsic photometric factors--shading and\nreflectance--is a long-standing challenge due to the lack of extensive\nground-truth data for real-world scenes. Recent methods rely on synthetic data\nor sparse annotations for limited indoor and even fewer outdoor scenes. We\nintroduce a novel training-free approach for intrinsic image decomposition\nusing only a pair of visible and thermal images. We leverage the principle that\nlight not reflected from an opaque surface is absorbed and detected as heat by\na thermal camera. This allows us to relate the ordinalities between visible and\nthermal image intensities to the ordinalities of shading and reflectance, which\ncan densely self-supervise an optimizing neural network to recover shading and\nreflectance. We perform quantitative evaluations with known reflectance and\nshading under natural and artificial lighting, and qualitative experiments\nacross diverse outdoor scenes. The results demonstrate superior performance\nover recent learning-based models and point toward a scalable path to curating\nreal-world ordinal supervision, previously infeasible via manual labeling.", "published": "2025-09-12 16:29:02", "link": "http://arxiv.org/abs/2509.10388v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Learned Image Compression Through Knowledge Distillation", "abstract": "Learned image compression sits at the intersection of machine learning and\nimage processing. With advances in deep learning, neural network-based\ncompression methods have emerged. In this process, an encoder maps the image to\na low-dimensional latent space, which is then quantized, entropy-coded into a\nbinary bitstream, and transmitted to the receiver. At the receiver end, the\nbitstream is entropy-decoded, and a decoder reconstructs an approximation of\nthe original image. Recent research suggests that these models consistently\noutperform conventional codecs. However, they require significant processing\npower, making them unsuitable for real-time use on resource-constrained\nplatforms, which hinders their deployment in mainstream applications. This\nstudy aims to reduce the resource requirements of neural networks used for\nimage compression by leveraging knowledge distillation, a training paradigm\nwhere smaller neural networks, partially trained on the outputs of larger, more\ncomplex models, can achieve better performance than when trained independently.\nOur work demonstrates that knowledge distillation can be effectively applied to\nimage compression tasks: i) across various architecture sizes, ii) to achieve\ndifferent image quality/bit rate tradeoffs, and iii) to save processing and\nenergy resources. This approach introduces new settings and hyperparameters,\nand future research could explore the impact of different teacher models, as\nwell as alternative loss functions. Knowledge distillation could also be\nextended to transformer-based models. The code is publicly available at:\nhttps://github.com/FABallemand/PRIM .", "published": "2025-09-12 15:59:55", "link": "http://arxiv.org/abs/2509.10366v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Immunizing Images from Text to Image Editing via Adversarial Cross-Attention", "abstract": "Recent advances in text-based image editing have enabled fine-grained\nmanipulation of visual content guided by natural language. However, such\nmethods are susceptible to adversarial attacks. In this work, we propose a\nnovel attack that targets the visual component of editing methods. We introduce\nAttention Attack, which disrupts the cross-attention between a textual prompt\nand the visual representation of the image by using an automatically generated\ncaption of the source image as a proxy for the edit prompt. This breaks the\nalignment between the contents of the image and their textual description,\nwithout requiring knowledge of the editing method or the editing prompt.\nReflecting on the reliability of existing metrics for immunization success, we\npropose two novel evaluation strategies: Caption Similarity, which quantifies\nsemantic consistency between original and adversarial edits, and semantic\nIntersection over Union (IoU), which measures spatial layout disruption via\nsegmentation masks. Experiments conducted on the TEDBench++ benchmark\ndemonstrate that our attack significantly degrades editing performance while\nremaining imperceptible.", "published": "2025-09-12 15:47:50", "link": "http://arxiv.org/abs/2509.10359v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-pathology Chest X-ray Classification with Rejection Mechanisms", "abstract": "Overconfidence in deep learning models poses a significant risk in\nhigh-stakes medical imaging tasks, particularly in multi-label classification\nof chest X-rays, where multiple co-occurring pathologies must be detected\nsimultaneously. This study introduces an uncertainty-aware framework for chest\nX-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective\nprediction mechanisms: entropy-based rejection and confidence interval-based\nrejection. Both methods enable the model to abstain from uncertain predictions,\nimproving reliability by deferring ambiguous cases to clinical experts. A\nquantile-based calibration procedure is employed to tune rejection thresholds\nusing either global or class-specific strategies. Experiments conducted on\nthree large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)\ndemonstrate that selective rejection improves the trade-off between diagnostic\naccuracy and coverage, with entropy-based rejection yielding the highest\naverage AUC across all pathologies. These results support the integration of\nselective prediction into AI-assisted diagnostic workflows, providing a\npractical step toward safer, uncertainty-aware deployment of deep learning in\nclinical settings.", "published": "2025-09-12 15:36:26", "link": "http://arxiv.org/abs/2509.10348v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT", "abstract": "Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing\nand monitoring retinal diseases. However, OCT images are inherently degraded by\nspeckle noise, which obscures fine details and hinders accurate interpretation.\nWhile numerous denoising methods exist, many struggle to balance noise\nreduction with the preservation of crucial anatomical structures. This paper\nintroduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel\ndeep learning approach for OCT image despeckling that leverages the strengths\nof diffusion probabilistic models. Unlike conventional diffusion models that\nassume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more\naccurately reflect the statistical properties of speckle. Furthermore, we\nintroduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,\nless-noisy image to guide the denoising process. This crucial addition prevents\nthe reintroduction of high-frequency noise. We accelerate the inference process\nby adapting the Denoising Diffusion Implicit Model framework to our Gamma-based\nmodel. Experiments on a dataset with paired noisy and less-noisy OCT B-scans\ndemonstrate that GARD significantly outperforms traditional denoising methods\nand state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.\nQualitative results confirm that GARD produces sharper edges and better\npreserves fine anatomical details.", "published": "2025-09-12 15:24:41", "link": "http://arxiv.org/abs/2509.10341v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching", "abstract": "Diffusion transformers have gained significant attention in recent years for\ntheir ability to generate high-quality images and videos, yet still suffer from\na huge computational cost due to their iterative denoising process. Recently,\nfeature caching has been introduced to accelerate diffusion transformers by\ncaching the feature computation in previous timesteps and reusing it in the\nfollowing timesteps, which leverage the temporal similarity of diffusion models\nwhile ignoring the similarity in the spatial dimension. In this paper, we\nintroduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and\ncomplementary perspective for previous feature caching. Specifically, ClusCa\nperforms spatial clustering on tokens in each timestep, computes only one token\nin each cluster and propagates their information to all the other tokens, which\nis able to reduce the number of tokens by over 90%. Extensive experiments on\nDiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image\nand text-to-video generation. Besides, it can be directly applied to any\ndiffusion transformer without requirements for training. For instance, ClusCa\nachieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing\nthe original model by 0.51%. The code is available at\nhttps://github.com/Shenyi-Z/Cache4Diffusion.", "published": "2025-09-12 14:53:45", "link": "http://arxiv.org/abs/2509.10312v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments", "abstract": "In this paper we address the problem of precise geolocation of street\nfurniture in complex urban environments, which is a critical task for effective\nmonitoring and maintenance of public infrastructure by local authorities and\nprivate stakeholders. To this end, we propose a probabilistic framework based\non energy maps that encode the spatial likelihood of object locations.\nRepresenting the energy in a map-based geopositioned format allows the\noptimisation process to seamlessly integrate external geospatial information,\nsuch as GIS layers, road maps, or placement constraints, which improves\ncontextual awareness and localisation accuracy. A stochastic birth-and-death\noptimisation algorithm is introduced to infer the most probable configuration\nof assets. We evaluate our approach using a realistic simulation informed by a\ngeolocated dataset of street lighting infrastructure in Dublin city centre,\ndemonstrating its potential for scalable and accurate urban asset mapping. The\nimplementation of the algorithm will be made available in the GitHub repository\nhttps://github.com/EMurphy0108/SBD_Street_Furniture.", "published": "2025-09-12 14:52:42", "link": "http://arxiv.org/abs/2509.10310v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks", "abstract": "Deep neural networks and Vision Transformers achieve state-of-the-art\nperformance in computer vision but are highly vulnerable to adversarial\nperturbations. Standard defenses often incur high computational cost or lack\nformal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)\nmethod, where drop probabilities increase with depth to control the effective\nLipschitz constant of the network. This approach regularizes deeper layers,\nimproving robustness while preserving clean accuracy and reducing computation.\nExperiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent\nschedule maintains near-baseline clean accuracy, enhances robustness under\nFGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to\nbaseline and linear DropPath schedules.", "published": "2025-09-12 14:38:18", "link": "http://arxiv.org/abs/2509.10298v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection", "abstract": "Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects\nwithout relying on labeled training data, making it especially valuable in\nscenarios constrained by data scarcity, privacy, or high annotation cost.\nHowever, most existing methods focus exclusively on point clouds, neglecting\nthe rich semantic cues available from complementary modalities such as RGB\nimages and texts priors. This paper introduces MCL-AD, a novel framework that\nleverages multimodal collaboration learning across point clouds, RGB images,\nand texts semantics to achieve superior zero-shot 3D anomaly detection.\nSpecifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that\nenhances the intra-modal representation capability and inter-modal\ncollaborative learning by introducing an object-agnostic decoupled text prompt\nand a multimodal contrastive loss. In addition, a collaborative modulation\nmechanism (CMM) is proposed to fully leverage the complementary representations\nof point clouds and RGB images by jointly modulating the RGB image-guided and\npoint cloud-guided branches. Extensive experiments demonstrate that the\nproposed MCL-AD framework achieves state-of-the-art performance in ZS-3D\nanomaly detection.", "published": "2025-09-12 14:21:54", "link": "http://arxiv.org/abs/2509.10282v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Detecting Text Manipulation in Images using Vision Language Models", "abstract": "Recent works have shown the effectiveness of Large Vision Language Models\n(VLMs or LVLMs) in image manipulation detection. However, text manipulation\ndetection is largely missing in these studies. We bridge this knowledge gap by\nanalyzing closed- and open-source VLMs on different text manipulation datasets.\nOur results suggest that open-source models are getting closer, but still\nbehind closed-source ones like GPT- 4o. Additionally, we benchmark image\nmanipulation detection-specific VLMs for text manipulation detection and show\nthat they suffer from the generalization problem. We benchmark VLMs for\nmanipulations done on in-the-wild scene texts and on fantasy ID cards, where\nthe latter mimic a challenging real-world misuse.", "published": "2025-09-12 14:20:29", "link": "http://arxiv.org/abs/2509.10278v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation", "abstract": "Text-to-image (T2I) generation has achieved remarkable progress in\ninstruction following and aesthetics. However, a persistent challenge is the\nprevalence of physical artifacts, such as anatomical and structural flaws,\nwhich severely degrade perceptual quality and limit application. Given the\ndiversity and complexity of these artifacts, a systematic and fine-grained\nevaluation framework is required, which is lacking in current benchmarks. To\nfill this gap, we introduce MagicMirror, a comprehensive framework for\nartifacts assessment. We first establish a detailed taxonomy of generated image\nartifacts. Guided by this taxonomy, we manually annotate MagicData340K, the\nfirst human-annotated large-scale dataset of 340K generated images with\nfine-grained artifact labels. Building on this dataset, we train MagicAssessor,\na Vision-Language Model (VLM) that provides detailed assessments and\ncorresponding labels. To overcome challenges like class imbalance and reward\nhacking, we design a novel data sampling strategy and a multi-level reward\nsystem for Group Relative Policy Optimization (GRPO). Finally, we leverage\nMagicAssessor to construct MagicBench, an automated benchmark for evaluating\nthe image artifacts of current T2I models. Our evaluation with MagicBench\nreveals that despite their widespread adoption, even top-tier models like\nGPT-image-1 are consistently plagued by significant artifacts, highlighting\nartifact reduction as a critical frontier for future T2I development. Project\npage: https://wj-inf.github.io/MagicMirror-page/.", "published": "2025-09-12 14:03:00", "link": "http://arxiv.org/abs/2509.10260v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mask Consistency Regularization in Object Removal", "abstract": "Object removal, a challenging task within image inpainting, involves\nseamlessly filling the removed region with content that matches the surrounding\ncontext. Despite advancements in diffusion models, current methods still face\ntwo critical challenges. The first is mask hallucination, where the model\ngenerates irrelevant or spurious content inside the masked region, and the\nsecond is mask-shape bias, where the model fills the masked area with an object\nthat mimics the mask's shape rather than surrounding content. To address these\nissues, we propose Mask Consistency Regularization (MCR), a novel training\nstrategy designed specifically for object removal tasks. During training, our\napproach introduces two mask perturbations: dilation and reshape, enforcing\nconsistency between the outputs of these perturbed branches and the original\nmask. The dilated masks help align the model's output with the surrounding\ncontent, while reshaped masks encourage the model to break the mask-shape bias.\nThis combination of strategies enables MCR to produce more robust and\ncontextually coherent inpainting results. Our experiments demonstrate that MCR\nsignificantly reduces hallucinations and mask-shape bias, leading to improved\nperformance in object removal.", "published": "2025-09-12 14:02:52", "link": "http://arxiv.org/abs/2509.10259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI", "abstract": "Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce\nmotion artifacts caused by fetal movement. However, these stacks are typically\nlow resolution, may suffer from motion corruption, and do not adequately\ncapture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to\naddress these limitations by combining slice-to-volume registration and\nsuper-resolution techniques to generate high-resolution (HR) 3D volumes. While\nseveral SRR methods have been proposed, their comparative performance -\nparticularly in pathological cases - and their influence on downstream\nvolumetric analysis and diagnostic tasks remain underexplored. In this study,\nwe applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to\n140 fetal brain MRI scans, including both healthy controls (HC) and\npathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was\nsegmented using the BoUNTi algorithm to extract volumes of nine principal brain\nstructures. We evaluated visual quality, SRR success rates, volumetric\nmeasurement agreement, and diagnostic classification performance. NeSVoR\ndemonstrated the highest and most consistent reconstruction success rate (>90%)\nacross both HC and PC groups. Although significant differences in volumetric\nestimates were observed between SRR methods, classification performance for VM\nwas not affected by the choice of SRR method. These findings highlight NeSVoR's\nrobustness and the resilience of diagnostic performance despite SRR-induced\nvolumetric variability.", "published": "2025-09-12 13:59:23", "link": "http://arxiv.org/abs/2509.10257v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection", "abstract": "With generative models becoming increasingly sophisticated and diverse,\ndetecting AI-generated images has become increasingly challenging. While\nexisting AI-genereted Image detectors achieve promising performance on\nin-distribution generated images, their generalization to unseen generative\nmodels remains limited. This limitation is largely attributed to their reliance\non generation-specific artifacts, such as stylistic priors and compression\npatterns. To address these limitations, we propose GAMMA, a novel training\nframework designed to reduce domain bias and enhance semantic alignment. GAMMA\nintroduces diverse manipulation strategies, such as inpainting-based\nmanipulation and semantics-preserving perturbations, to ensure consistency\nbetween manipulated and authentic content. We employ multi-task supervision\nwith dual segmentation heads and a classification head, enabling pixel-level\nsource attribution across diverse generative domains. In addition, a reverse\ncross-attention mechanism is introduced to allow the segmentation heads to\nguide and correct biased representations in the classification branch. Our\nmethod achieves state-of-the-art generalization performance on the GenImage\nbenchmark, imporving accuracy by 5.8%, but also maintains strong robustness on\nnewly released generative model such as GPT-4o.", "published": "2025-09-12 13:46:54", "link": "http://arxiv.org/abs/2509.10250v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints", "abstract": "We present the first systematic comparison of implicit and explicit Novel\nView Synthesis methods for space-based 3D object reconstruction, evaluating the\nrole of appearance embeddings. While embeddings improve photometric fidelity by\nmodeling lighting variation, we show they do not translate into meaningful\ngains in geometric accuracy - a critical requirement for space robotics\napplications. Using the SPEED+ dataset, we compare K-Planes, Gaussian\nSplatting, and Convex Splatting, and demonstrate that embeddings primarily\nreduce the number of primitives needed for explicit methods rather than\nenhancing geometric fidelity. Moreover, convex splatting achieves more compact\nand clutter-free representations than Gaussian splatting, offering advantages\nfor safety-critical applications such as interaction and collision avoidance.\nOur findings clarify the limits of appearance embeddings for geometry-centric\ntasks and highlight trade-offs between reconstruction quality and\nrepresentation efficiency in space scenarios.", "published": "2025-09-12 13:37:18", "link": "http://arxiv.org/abs/2509.10241v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LayerLock: Non-collapsing Representation Learning with Progressive Freezing", "abstract": "We introduce LayerLock, a simple yet effective approach for self-supervised\nvisual representation learning, that gradually transitions from pixel to latent\nprediction through progressive layer freezing. First, we make the observation\nthat during training of video masked-autoencoding (MAE) models, ViT layers\nconverge in the order of their depth: shallower layers converge early, deeper\nlayers converge late. We then show that this observation can be exploited to\naccelerate standard MAE by progressively freezing the model according to an\nexplicit schedule, throughout training. Furthermore, this same schedule can be\nused in a simple and scalable approach to latent prediction that does not\nsuffer from \"representation collapse\". We apply our proposed approach,\nLayerLock, to large models of up to 4B parameters with results surpassing those\nof non-latent masked prediction on the 4DS perception suite.", "published": "2025-09-12 11:32:51", "link": "http://arxiv.org/abs/2509.10156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization", "abstract": "Vector quantization (VQ) is a key component in discrete tokenizers for image\ngeneration, but its training is often unstable due to straight-through\nestimation bias, one-step-behind updates, and sparse codebook gradients, which\nlead to suboptimal reconstruction performance and low codebook usage. In this\nwork, we analyze these fundamental challenges and provide a simple yet\neffective solution. To maintain high codebook usage in VQ networks (VQN) during\nlearning annealing and codebook size expansion, we propose VQBridge, a robust,\nscalable, and efficient projector based on the map function method. VQBridge\noptimizes code vectors through a compress-process-recover pipeline, enabling\nstable and effective codebook training. By combining VQBridge with learning\nannealing, our VQN achieves full (100%) codebook usage across diverse codebook\nconfigurations, which we refer to as FVQ (FullVQ). Through extensive\nexperiments, we demonstrate that FVQ is effective, scalable, and generalizable:\nit attains 100% codebook usage even with a 262k-codebook, achieves\nstate-of-the-art reconstruction performance, consistently improves with larger\ncodebooks, higher vector channels, or longer training, and remains effective\nacross different VQ variants. Moreover, when integrated with LlamaGen, FVQ\nsignificantly enhances image generation performance, surpassing visual\nautoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,\nhighlighting the importance of high-quality tokenizers for strong\nautoregressive image generation.", "published": "2025-09-12 11:08:21", "link": "http://arxiv.org/abs/2509.10140v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment", "abstract": "Accurate segmentation of the optic disc and cup is critical for the early\ndiagnosis and management of ocular diseases such as glaucoma. However,\nsegmentation models trained on one dataset often suffer significant performance\ndegradation when applied to target data acquired under different imaging\nprotocols or conditions. To address this challenge, we propose\n\\textbf{Grad-CL}, a novel source-free domain adaptation framework that\nleverages a pre-trained source model and unlabeled target data to robustly\nadapt segmentation performance without requiring access to the original source\ndata. Grad-CL combines a gradient-guided pseudolabel refinement module with a\ncosine similarity-based contrastive learning strategy. In the first stage,\nsalient class-specific features are extracted via a gradient-based mechanism,\nenabling more accurate uncertainty quantification and robust prototype\nestimation for refining noisy pseudolabels. In the second stage, a contrastive\nloss based on cosine similarity is employed to explicitly enforce inter-class\nseparability between the gradient-informed features of the optic cup and disc.\nExtensive experiments on challenging cross-domain fundus imaging datasets\ndemonstrate that Grad-CL outperforms state-of-the-art unsupervised and\nsource-free domain adaptation methods, achieving superior segmentation accuracy\nand improved boundary delineation. Project and code are available at\nhttps://visdomlab.github.io/GCL/.", "published": "2025-09-12 10:51:46", "link": "http://arxiv.org/abs/2509.10134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss", "abstract": "Face image quality assessment (FIQA) plays a critical role in face\nrecognition and verification systems, especially in uncontrolled, real-world\nenvironments. Although several methods have been proposed, general-purpose\nno-reference image quality assessment techniques often fail to capture\nface-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be\ncomputationally intensive, limiting their practical applicability. We propose a\nlightweight and efficient method for FIQA, designed for the perceptual\nevaluation of face images in the wild. Our approach integrates an ensemble of\ntwo compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,\nwith prediction-level fusion via simple averaging. To enhance alignment with\nhuman perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),\ncombining mean squared error (MSE) with a Pearson correlation regularizer. Our\nmethod achieves a strong balance between accuracy and computational cost,\nmaking it suitable for real-world deployment. Experiments on the VQualA FIQA\nbenchmark demonstrate that our model achieves a Spearman rank correlation\ncoefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient\n(PLCC) of 0.9894, remaining within competition efficiency constraints.", "published": "2025-09-12 10:13:38", "link": "http://arxiv.org/abs/2509.10114v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Polarization Denoising and Demosaicking: Dataset and Baseline Method", "abstract": "A division-of-focal-plane (DoFP) polarimeter enables us to acquire images\nwith multiple polarization orientations in one shot and thus it is valuable for\nmany applications using polarimetric information. The image processing pipeline\nfor a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.\nWhile polarization demosaicking for a noise-free case has increasingly been\nstudied, the research for the joint task of polarization denoising and\ndemosaicking is scarce due to the lack of a suitable evaluation dataset and a\nsolid baseline method. In this paper, we propose a novel dataset and method for\npolarization denoising and demosaicking. Our dataset contains 40 real-world\nscenes and three noise-level conditions, consisting of pairs of noisy mosaic\ninputs and noise-free full images. Our method takes a\ndenoising-then-demosaicking approach based on well-accepted signal processing\ncomponents to offer a reproducible method. Experimental results demonstrate\nthat our method exhibits higher image reconstruction performance than other\nalternative methods, offering a solid baseline.", "published": "2025-09-12 09:40:42", "link": "http://arxiv.org/abs/2509.10098v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario", "abstract": "The increasing labor shortage and aging population underline the need for\nassistive robots to support human care recipients. To enable safe and\nresponsive assistance, robots require accurate human motion prediction in\nphysical interaction scenarios. However, this remains a challenging task due to\nthe variability of assistive settings and the complexity of coupled dynamics in\nphysical interactions. In this work, we address these challenges through two\nkey contributions: (1) HHI-Assist, a dataset comprising motion capture clips of\nhuman-human interactions in assistive tasks; and (2) a conditional\nTransformer-based denoising diffusion model for predicting the poses of\ninteracting agents. Our model effectively captures the coupled dynamics between\ncaregivers and care receivers, demonstrating improvements over baselines and\nstrong generalization to unseen scenarios. By advancing interaction-aware\nmotion prediction and introducing a new dataset, our work has the potential to\nsignificantly enhance robotic assistance policies. The dataset and code are\navailable at: https://sites.google.com/view/hhi-assist/home", "published": "2025-09-12 09:38:17", "link": "http://arxiv.org/abs/2509.10096v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing", "abstract": "Multi-human parsing is the task of segmenting human body parts while\nassociating each part to the person it belongs to, combining instance-level and\npart-level information for fine-grained human understanding. In this work, we\ndemonstrate that, while state-of-the-art approaches achieved notable results on\npublic datasets, they struggle considerably in segmenting people with\noverlapping bodies. From the intuition that overlapping people may appear\nseparated from a different point of view, we propose a novel training framework\nexploiting multi-view information to improve multi-human parsing models under\nocclusions. Our method integrates such knowledge during the training process,\nintroducing a novel approach based on weak supervision on human instances and a\nmulti-view consistency loss. Given the lack of suitable datasets in the\nliterature, we propose a semi-automatic annotation strategy to generate human\ninstance segmentation masks from multi-view RGB+D data and 3D human skeletons.\nThe experiments demonstrate that the approach can achieve up to a 4.20\\%\nrelative improvement on human parsing over the baseline model in occlusion\nscenarios.", "published": "2025-09-12 09:36:23", "link": "http://arxiv.org/abs/2509.10093v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals", "abstract": "In autonomous driving, trajectory prediction is essential for ensuring safe\nand efficient navigation. To improve prediction accuracy, recent approaches\noften rely on pre-built high-definition (HD) maps or real-time local map\nconstruction modules to incorporate static environmental information. However,\npre-built HD maps are limited to specific regions and cannot adapt to transient\nchanges. In addition, local map construction modules, which recognize only\npredefined elements, may fail to capture critical scene details or introduce\nerrors that degrade prediction performance. To overcome these limitations, we\npropose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory\nprediction framework that operates directly in the bird's-eye view (BEV) space\nutilizing real-time sensor data without relying on any pre-built maps. The\nBEVTraj leverages deformable attention to efficiently extract relevant context\nfrom dense BEV features. Furthermore, we introduce a Sparse Goal Candidate\nProposal (SGCP) module, which enables full end-to-end prediction without\nrequiring any post-processing steps. Extensive experiments demonstrate that the\nBEVTraj achieves performance comparable to state-of-the-art HD map-based models\nwhile offering greater flexibility by eliminating the dependency on pre-built\nmaps. The source code is available at https://github.com/Kongminsang/bevtraj.", "published": "2025-09-12 09:17:54", "link": "http://arxiv.org/abs/2509.10080v1", "categories": ["cs.CV", "I.2.9; I.4.8"], "primary_category": "cs.CV"}
{"title": "Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation", "abstract": "Accurate color alignment in text-to-image (T2I) generation is critical for\napplications such as fashion, product visualization, and interior design, yet\ncurrent diffusion models struggle with nuanced and compound color terms (e.g.,\nTiffany blue, lime green, hot pink), often producing images that are misaligned\nwith human intent. Existing approaches rely on cross-attention manipulation,\nreference images, or fine-tuning but fail to systematically resolve ambiguous\ncolor descriptions. To precisely render colors under prompt ambiguity, we\npropose a training-free framework that enhances color fidelity by leveraging a\nlarge language model (LLM) to disambiguate color-related prompts and guiding\ncolor blending operations directly in the text embedding space. Our method\nfirst employs a large language model (LLM) to resolve ambiguous color terms in\nthe text prompt, and then refines the text embeddings based on the spatial\nrelationships of the resulting color terms in the CIELAB color space. Unlike\nprior methods, our approach improves color accuracy without requiring\nadditional training or external reference images. Experimental results\ndemonstrate that our framework improves color alignment without compromising\nimage quality, bridging the gap between text semantics and visual generation.", "published": "2025-09-12 08:44:22", "link": "http://arxiv.org/abs/2509.10058v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA", "abstract": "As large vision language models (VLMs) advance, their capabilities in\nmultilingual visual question answering (mVQA) have significantly improved.\nChain-of-thought (CoT) reasoning has been proven to enhance interpretability\nand complex reasoning. However, most existing approaches rely primarily on\ntextual CoT and provide limited support for multilingual multimodal reasoning,\nconstraining their deployment in real-world applications. To address this gap,\nwe introduce \\textbf{LaV-CoT}, the first Language-aware Visual CoT framework\nwith Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable\nmulti-stage reasoning pipeline consisting of Text Summary with Bounding Box\n(BBox), Language Identification, Spatial Object-level Captioning, and\nStep-by-step Logical Reasoning. Following this reasoning pipeline, we design an\nautomated data curation method that generates multilingual CoT annotations\nthrough iterative generation, correction, and refinement, enabling scalable and\nhigh-quality training data. To improve reasoning and generalization, LaV-CoT\nadopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)\nwith Language-aware Group Relative Policy Optimization (GRPO), guided by\nverifiable multi-aspect rewards including language consistency, structural\naccuracy, and semantic alignment. Extensive evaluations on public datasets\nincluding MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up\nto \\(\\sim\\)9.5\\% accuracy improvements over open-source baselines of similar\nsize and even surpasses models with 2$\\times$ larger scales by \\(\\sim\\)2.6\\%.\nMoreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513\nand Gemini-2.5-flash. We further conducted an online A/B test to validate our\nmethod on real-world data, highlighting its effectiveness for industrial\ndeployment. Our code is available at this link:\n\\href{https://github.com/HJNVR/LaV-CoT}", "published": "2025-09-12 07:45:44", "link": "http://arxiv.org/abs/2509.10026v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images", "abstract": "Recovering 3D face models from 2D in-the-wild images has gained considerable\nattention in the computer vision community due to its wide range of potential\napplications. However, the lack of ground-truth labeled datasets and the\ncomplexity of real-world environments remain significant challenges. In this\nchapter, we propose a convolutional neural network-based approach, the\nHierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face\nmodels from single in-the-wild images. Our model predicts detailed facial\ngeometry, texture, pose, and illumination parameters from a single image.\nSpecifically, we employ a pre-trained hierarchical backbone network and\nintroduce multi-level attention mechanisms at different stages of 2D face image\nfeature extraction. A semi-supervised training strategy is employed,\nincorporating 3D Morphable Model (3DMM) parameters from publicly available\ndatasets along with a differentiable renderer, enabling an end-to-end training\nprocess. Extensive experiments, including both comparative and ablation\nstudies, were conducted on two benchmark datasets, AFLW2000-3D and MICC\nFlorence, focusing on 3D face reconstruction and 3D face alignment tasks. The\neffectiveness of the proposed method was evaluated both quantitatively and\nqualitatively.", "published": "2025-09-12 07:42:27", "link": "http://arxiv.org/abs/2509.10024v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient and Accurate Downfacing Visual Inertial Odometry", "abstract": "Visual Inertial Odometry (VIO) is a widely used computer vision method that\ndetermines an agent's movement through a camera and an IMU sensor. This paper\npresents an efficient and accurate VIO pipeline optimized for applications on\nmicro- and nano-UAVs. The proposed design incorporates state-of-the-art feature\ndetection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and\nquantized for emerging RISC-V-based ultra-low-power parallel systems on chips\n(SoCs). Furthermore, by employing a rigid body motion model, the pipeline\nreduces estimation errors and achieves improved accuracy in planar motion\nscenarios. The pipeline's suitability for real-time VIO is assessed on an\nultra-low-power SoC in terms of compute requirements and tracking accuracy\nafter quantization. The pipeline, including the three feature tracking methods,\nwas implemented on the SoC for real-world validation. This design bridges the\ngap between high-accuracy VIO pipelines that are traditionally run on\ncomputationally powerful systems and lightweight implementations suitable for\nmicrocontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates\nan average reduction in RMSE of up to a factor of 3.65x over the baseline\npipeline when using the ORB feature tracker. The analysis of the computational\ncomplexity of the feature trackers further shows that PX4FLOW achieves on-par\ntracking accuracy with ORB at a lower runtime for movement speeds below 24\npixels/frame.", "published": "2025-09-12 07:30:24", "link": "http://arxiv.org/abs/2509.10021v1", "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Few-Part-Shot Font Generation", "abstract": "This paper proposes a novel model of few-part-shot font generation, which\ndesigns an entire font based on a set of partial design elements, i.e., partial\nshapes. Unlike conventional few-shot font generation, which requires entire\ncharacter shapes for a couple of character classes, our approach only needs\npartial shapes as input. The proposed model not only improves the efficiency of\nfont creation but also provides insights into how partial design details\ninfluence the entire structure of the individual characters.", "published": "2025-09-12 07:04:25", "link": "http://arxiv.org/abs/2509.10006v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion", "abstract": "RGB-thermal (RGB-T) semantic segmentation improves the environmental\nperception of autonomous platforms in challenging conditions. Prevailing models\nemploy encoders pre-trained on RGB images to extract features from both RGB and\ninfrared inputs, and design additional modules to achieve cross-modal feature\nfusion. This results in limited thermal feature extraction and suboptimal\ncross-modal fusion, while the redundant encoders further compromises the\nmodel's real-time efficiency. To address the above issues, we propose TUNI,\nwith an RGB-T encoder consisting of multiple stacked blocks that simultaneously\nperform multi-modal feature extraction and cross-modal fusion. By leveraging\nlarge-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder\nlearns to integrate feature extraction and fusion in a unified manner. By\nslimming down the thermal branch, the encoder achieves a more compact\narchitecture. Moreover, we introduce an RGB-T local module to strengthen the\nencoder's capacity for cross-modal local feature fusion. The RGB-T local module\nemploys adaptive cosine similarity to selectively emphasize salient consistent\nand distinct local features across RGB-T modalities. Experimental results show\nthat TUNI achieves competitive performance with state-of-the-art models on FMB,\nPST900 and CART, with fewer parameters and lower computational cost. Meanwhile,\nit achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its\nreal-time capability in deployment. Codes are available at\nhttps://github.com/xiaodonguo/TUNI.", "published": "2025-09-12 07:02:45", "link": "http://arxiv.org/abs/2509.10005v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction", "abstract": "Accurate and reliable solar flare predictions are essential to mitigate\npotential impacts on critical infrastructure. However, the current performance\nof solar flare forecasting is insufficient. In this study, we address the task\nof predicting the class of the largest solar flare expected to occur within the\nnext 72 hours. Existing methods often fail to adequately address the severe\nclass imbalance across flare classes. To address this issue, we propose a solar\nflare prediction model based on multiple deep state space models. In addition,\nwe introduce the frequency & local-boundary-aware reliability loss (FLARE loss)\nto improve predictive performance and reliability under class imbalance.\nExperiments were conducted on a multi-wavelength solar image dataset covering a\nfull 11-year solar activity cycle. As a result, our method outperformed\nbaseline approaches in terms of both the Gandin-Murphy-Gerrity score and the\ntrue skill statistic, which are standard metrics in terms of the performance\nand reliability.", "published": "2025-09-12 06:09:09", "link": "http://arxiv.org/abs/2509.09988v1", "categories": ["cs.CV", "astro-ph.SR"], "primary_category": "cs.CV"}
{"title": "ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking", "abstract": "RGB-Event tracking has become a promising trend in visual object tracking to\nleverage the complementary strengths of both RGB images and dynamic spike\nevents for improved performance. However, existing artificial neural networks\n(ANNs) struggle to fully exploit the sparse and asynchronous nature of event\nstreams. Recent efforts toward hybrid architectures combining ANNs and spiking\nneural networks (SNNs) have emerged as a promising solution in RGB-Event\nperception, yet effectively fusing features across heterogeneous paradigms\nremains a challenge. In this work, we propose ISTASTrack, the first\ntransformer-based \\textbf{A}NN-\\textbf{S}NN hybrid \\textbf{Track}er equipped\nwith \\textbf{ISTA} adapters for RGB-Event tracking. The two-branch model\nemploys a vision transformer to extract spatial context from RGB inputs and a\nspiking transformer to capture spatio-temporal dynamics from event streams. To\nbridge the modality and paradigm gap between ANN and SNN features, we\nsystematically design a model-based ISTA adapter for bidirectional feature\ninteraction between the two branches, derived from sparse representation theory\nby unfolding the iterative shrinkage thresholding algorithm. Additionally, we\nincorporate a temporal downsampling attention module within the adapter to\nalign multi-step SNN features with single-step ANN features in the latent\nspace, improving temporal fusion. Experimental results on RGB-Event tracking\nbenchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that\nISTASTrack achieves state-of-the-art performance while maintaining high energy\nefficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN\ndesigns for robust visual tracking. The code is publicly available at\nhttps://github.com/lsying009/ISTASTrack.git.", "published": "2025-09-12 05:37:17", "link": "http://arxiv.org/abs/2509.09977v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey", "abstract": "Event camera sensors are bio-inspired sensors which asynchronously capture\nper-pixel brightness changes and output a stream of events encoding the\npolarity, location and time of these changes. These systems are witnessing\nrapid advancements as an emerging field, driven by their low latency, reduced\npower consumption, and ultra-high capture rates. This survey explores the\nevolution of fusing event-stream captured with traditional frame-based capture,\nhighlighting how this synergy significantly benefits various video restoration\nand 3D reconstruction tasks. The paper systematically reviews major deep\nlearning contributions to image/video enhancement and restoration, focusing on\ntwo dimensions: temporal enhancement (such as frame interpolation and motion\ndeblurring) and spatial enhancement (including super-resolution, low-light and\nHDR enhancement, and artifact reduction). This paper also explores how the 3D\nreconstruction domain evolves with the advancement of event driven fusion.\nDiverse topics are covered, with in-depth discussions on recent works for\nimproving visual quality under challenging conditions. Additionally, the survey\ncompiles a comprehensive list of openly available datasets, enabling\nreproducible research and benchmarking. By consolidating recent progress and\ninsights, this survey aims to inspire further research into leveraging event\ncamera systems, especially in combination with deep learning, for advanced\nvisual media restoration and enhancement.", "published": "2025-09-12 05:16:54", "link": "http://arxiv.org/abs/2509.09971v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock", "abstract": "The need for long-term multi-object tracking (MOT) is growing due to the\ndemand for analyzing individual behaviors in videos that span several minutes.\nUnfortunately, due to identity switches between objects, the tracking\nperformance of existing MOT approaches decreases over time, making them\ndifficult to apply for long-term tracking. However, in many real-world\napplications, such as in the livestock sector, it is possible to obtain\nsporadic identifications for some of the animals from sources like feeders. To\naddress the challenges of long-term MOT, we propose a new framework that\ncombines both uncertain identities and tracking using a Hidden Markov Model\n(HMM) formulation. In addition to providing real-world identities to animals,\nour HMM framework improves the F1 score of ByteTrack, a leading MOT approach\neven with re-identification, on a 10 minute pig tracking dataset with 21\nidentifications at the pen's feeding station. We also show that our approach is\nrobust to the uncertainty of identifications, with performance increasing as\nidentities are provided more frequently. The improved performance of our HMM\nframework was also validated on the MOT17 and MOT20 benchmark datasets using\nboth ByteTrack and FairMOT. The code for this new HMM framework and the new\n10-minute pig tracking video dataset are available at:\nhttps://github.com/ngobibibnbe/uncertain-identity-aware-tracking", "published": "2025-09-12 04:39:38", "link": "http://arxiv.org/abs/2509.09962v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation", "abstract": "Accurate segmentation of foliar diseases and insect damage in wheat is\ncrucial for effective crop management and disease control. However, the insect\ndamage typically occupies only a tiny fraction of annotated pixels. This\nextreme pixel-level imbalance poses a significant challenge to the segmentation\nperformance, which can result in overfitting to common classes and insufficient\nlearning of rare classes, thereby impairing overall performance. In this paper,\nwe propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to\naddress the pixel imbalance problem. Specifically, we extract rare\ninsect-damage patches from annotated training images and apply random geometric\ntransformations to simulate variations. The transformed patches are then pasted\nin appropriate regions while avoiding overlaps with lesions or existing damaged\nregions. In addition, we apply a random projection filter to the pasted\nregions, refining local features and ensuring a natural blend with the new\nbackground. Experiments show that our method substantially improves\nsegmentation performance on the insect damage class, while maintaining or even\nslightly enhancing accuracy on other categories. Our results highlight the\neffectiveness of targeted augmentation in mitigating extreme pixel imbalance,\noffering a straightforward yet effective solution for agricultural segmentation\nproblems.", "published": "2025-09-12 04:38:32", "link": "http://arxiv.org/abs/2509.09961v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images", "abstract": "Material creation and reconstruction are crucial for appearance modeling but\ntraditionally require significant time and expertise from artists. While recent\nmethods leverage visual foundation models to synthesize PBR materials from\nuser-provided inputs, they often fall short in quality, flexibility, and user\ncontrol. We propose a novel two-stage generate-and-estimate framework for PBR\nmaterial generation. In the generation stage, a fine-tuned diffusion model\nsynthesizes shaded, tileable texture images aligned with user input. In the\nestimation stage, we introduce a chained decomposition scheme that sequentially\npredicts SVBRDF channels by passing previously extracted representation as\ninput into a single-step image-conditional diffusion model. Our method is\nefficient, high quality, and enables flexible user control. We evaluate our\napproach against existing material generation and estimation methods,\ndemonstrating superior performance. Our material estimation method shows strong\nrobustness on both generated textures and in-the-wild photographs. Furthermore,\nwe highlight the flexibility of our framework across diverse applications,\nincluding text-to-material, image-to-material, structure-guided generation, and\nmaterial editing.", "published": "2025-09-12 04:03:07", "link": "http://arxiv.org/abs/2509.09952v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation", "abstract": "Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision\ntask for automating large-scale surveillance. With camera calibration and depth\ninformation, the targets in the scene can be projected into 3D space, offering\nunparalleled levels of automatic perception of a 3D environment. However,\ntracking in the 3D space requires replacing all 2D tracking components from the\nground up, which may be infeasible for existing MTMC systems. In this paper, we\npresent an approach for extending any online 2D multi-camera tracking system\ninto 3D space by utilizing depth information to reconstruct a target in\npoint-cloud space, and recovering its 3D box through clustering and yaw\nrefinement following tracking. We also introduced an enhanced online data\nassociation mechanism that leverages the target's local ID consistency to\nassign global IDs across frames. The proposed framework is evaluated on the\n2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the\nleaderboard.", "published": "2025-09-12 03:28:35", "link": "http://arxiv.org/abs/2509.09946v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segment Anything for Cell Tracking", "abstract": "Tracking cells and detecting mitotic events in time-lapse microscopy image\nsequences is a crucial task in biomedical research. However, it remains highly\nchallenging due to dividing objects, low signal-tonoise ratios, indistinct\nboundaries, dense clusters, and the visually similar appearance of individual\ncells. Existing deep learning-based methods rely on manually labeled datasets\nfor training, which is both costly and time-consuming. Moreover, their\ngeneralizability to unseen datasets remains limited due to the vast diversity\nof microscopy data. To overcome these limitations, we propose a zero-shot cell\ntracking framework by integrating Segment Anything 2 (SAM2), a large foundation\nmodel designed for general image and video segmentation, into the tracking\npipeline. As a fully-unsupervised approach, our method does not depend on or\ninherit biases from any specific training dataset, allowing it to generalize\nacross diverse microscopy datasets without finetuning. Our approach achieves\ncompetitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos\nwhile eliminating the need for dataset-specific adaptation.", "published": "2025-09-12 03:19:35", "link": "http://arxiv.org/abs/2509.09943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SCoDA: Self-supervised Continual Domain Adaptation", "abstract": "Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a\nmodel to a target domain without access to the data of the source domain.\nPrevailing methods typically start with a source model pre-trained with full\nsupervision and distill the knowledge by aligning instance-level features.\nHowever, these approaches, relying on cosine similarity over L2-normalized\nfeature vectors, inadvertently discard crucial geometric information about the\nlatent manifold of the source model. We introduce Self-supervised Continual\nDomain Adaptation (SCoDA) to address these limitations. We make two key\ndepartures from standard practice: first, we avoid the reliance on supervised\npre-training by initializing the proposed framework with a teacher model\npre-trained entirely via self-supervision (SSL). Second, we adapt the principle\nof geometric manifold alignment to the SFDA setting. The student is trained\nwith a composite objective combining instance-level feature matching with a\nSpace Similarity Loss. To combat catastrophic forgetting, the teacher's\nparameters are updated via an Exponential Moving Average (EMA) of the student's\nparameters. Extensive experiments on benchmark datasets demonstrate that SCoDA\nsignificantly outperforms state-of-the-art SFDA methods.", "published": "2025-09-12 02:53:03", "link": "http://arxiv.org/abs/2509.09935v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios", "abstract": "Long-tailed learning has garnered increasing attention due to its wide\napplicability in real-world scenarios. Among existing approaches, Long-Tailed\nSemi-Supervised Learning (LTSSL) has emerged as an effective solution by\nincorporating a large amount of unlabeled data into the imbalanced labeled\ndataset. However, most prior LTSSL methods are designed to train models from\nscratch, which often leads to issues such as overconfidence and low-quality\npseudo-labels. To address these challenges, we extend LTSSL into the foundation\nmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed\nsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate\nthat fine-tuned foundation models can generate more reliable pseudolabels,\nthereby benefiting imbalanced learning. Furthermore, we explore a more\npractical setting by investigating semi-supervised learning under open-world\nconditions, where the unlabeled data may include out-of-distribution (OOD)\nsamples. To handle this problem, we propose LoFT-OW (LoFT under Open-World\nscenarios) to improve the discriminative ability. Experimental results on\nmultiple benchmarks demonstrate that our method achieves superior performance\ncompared to previous approaches, even when utilizing only 1\\% of the unlabeled\ndata compared with previous works.", "published": "2025-09-12 02:28:32", "link": "http://arxiv.org/abs/2509.09926v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On arc-density of pushably $3$-critical oriented graphs", "abstract": "An oriented graph $\\overrightarrow{G}$ is pushably $k$-critical if it is not\npushably $k$-colorable, but every proper subgraph of $\\overrightarrow{G}$ is.\nThe main result of this article is that every pushably $3$-critical oriented\ngraph on $n$ vertices, but for four exceptions, has at least $\\frac{15n+2}{13}$\narcs, and that this bound is tight. As an application of this result, we show\nthat the class of oriented graphs with maximum average degree strictly less\nthan $\\frac{30}{13}$ and girth at least $5$, which includes all oriented planar\nand projective planar graphs with girth at least $15$, have pushable chromatic\nnumber at most $3$. Moreover, we provide an exhaustive list of pushably\n$3$-critical graphs with maximum average degree equal to $\\frac{30}{13}$ and a\npushably $3$-critical orientation of a $4$-cycle to prove the tightness of our\nbound with respect to both maximum average degree and girth. We also show that\nthese classes of oriented graphs admit a homomorphism to an oriented planar\ngraph on six vertices (an orientation of $K_{2,2,2}$) which (tightly) improves\na result due to Borodin \\textit{et al.} [Discrete Mathematics 1998].\nFurthermore, for these classes of oriented graphs, we prove that the $2$-dipath\n$L(p,q)$ and the oriented $L(p,q)$ spans are upper bounded by $2p+3q$ for all\n$q \\leq p$. All these implications improve previously known results.", "published": "2025-09-12 12:15:37", "link": "http://arxiv.org/abs/2509.10182v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Toward Minimum Graphic Parity Networks", "abstract": "Quantum circuits composed of CNOT and $R_z$ are fundamental building blocks\nof many quantum algorithms, so optimizing the synthesis of such quantum\ncircuits is crucial. We address this problem from a theoretical perspective by\nstudying the graphic parity network synthesis problem. A graphic parity network\nfor a graph $G$ is a quantum circuit composed solely of CNOT gates where each\nedge of $G$ is represented in the circuit, and the final state of the wires\nmatches the original input. We aim to synthesize graphic parity networks with\nthe minimum number of gates, specifically for quantum algorithms addressing\ncombinatorial optimization problems with Ising formulations. We demonstrate\nthat a graphic parity network for a connected graph with $n$ vertices and $m$\nedges requires at least $m+n-1$ gates. This lower bound can be improved to\n$m+\\Omega(m) = m+\\Omega(n^{1.5})$ when the shortest cycle in the graph has a\nlength of at least five. We complement this result with a simple randomized\nalgorithm that synthesizes a graphic parity network with expected $m +\nO(n^{1.5}\\sqrt{\\log n})$ gates. Additionally, we begin exploring connected\ngraphs that allow for graphic parity networks with exactly $m+n-1$ gates. We\nconjecture that all such graphs belong to a newly defined graph class.\nFurthermore, we present a linear-time algorithm for synthesizing minimum\ngraphic parity networks for graphs within this class. However, this graph class\nis not closed under taking induced subgraphs, and we show that recognizing it\nis $\\textsf{NP}$-complete, which is complemented with a fixed-parameter\ntractable algorithm parameterized by the treewidth.", "published": "2025-09-12 09:00:38", "link": "http://arxiv.org/abs/2509.10070v1", "categories": ["quant-ph", "cs.DM", "cs.DS", "math.CO"], "primary_category": "quant-ph"}
{"title": "A Note on Constructive Canonical Splitter Strategies in Nowhere Dense Graph Classes", "abstract": "The radius-$r$ splitter game is played on a graph $G$ between two players:\nSplitter and Connector. In each round, Connector selects a vertex $v$, and the\ncurrent game arena is restricted to the radius-$r$ neighborhood of $v$. Then\nSplitter removes a vertex from this restricted subgraph. The game ends, and\nSplitter wins, when the arena becomes empty. Splitter aims to end the game as\nquickly as possible, while Connector tries to prolong it for as long as\npossible. The splitter game was introduced by Grohe, Kreutzer and Siebertz to\ncharacterize nowhere dense graph classes. They showed that a class\n$\\mathscr{C}$ of graphs is nowhere dense if and only if for every radius $r$\nthere exists a number $\\ell$ such that Splitter has a strategy on every $G\\in\n\\mathscr{C}$ to win the radius-$r$ splitter game in at most $\\ell$ rounds. It\nwas recently proved by Ohlmann et al. that there are only a bounded number of\npossible Splitter moves that are progressing, that is, moves that lead to an\narena where Splitter can win in one less round. The proof of Ohlmann et al. is\nbased on the compactness theorem and does not give a constructive bound on the\nnumber of progressing moves. In this work, we give a simple constructive proof,\nshowing that if Splitter can force a win in the radius-$r$ game in $k$ rounds,\nthen there are at most $(2r+1)^{\\,2^{k-1}-1}$ progressing moves.", "published": "2025-09-12 08:48:53", "link": "http://arxiv.org/abs/2509.10062v1", "categories": ["cs.LO", "cs.DM", "math.LO"], "primary_category": "cs.LO"}
{"title": "MatSKRAFT: A framework for large-scale materials knowledge extraction from scientific tables", "abstract": "Scientific progress increasingly depends on synthesizing knowledge across\nvast literature, yet most experimental data remains trapped in semi-structured\nformats that resist systematic extraction and analysis. Here, we present\nMatSKRAFT, a computational framework that automatically extracts and integrates\nmaterials science knowledge from tabular data at unprecedented scale. Our\napproach transforms tables into graph-based representations processed by\nconstraint-driven GNNs that encode scientific principles directly into model\narchitecture. MatSKRAFT significantly outperforms state-of-the-art large\nlanguage models, achieving F1 scores of 88.68 for property extraction and 71.35\nfor composition extraction, while processing data $19$-$496\\times$ faster than\nthem (compared to the slowest and the fastest models, respectively) with modest\nhardware requirements. Applied to nearly 69,000 tables from more than 47,000\nresearch publications, we construct a comprehensive database containing over\n535,000 entries, including 104,000 compositions that expand coverage beyond\nmajor existing databases, pending manual validation. This systematic approach\nreveals previously overlooked materials with distinct property combinations and\nenables data-driven discovery of composition-property relationships forming the\ncornerstone of materials and scientific discovery.", "published": "2025-09-12 17:55:11", "link": "http://arxiv.org/abs/2509.10448v1", "categories": ["cs.IR", "cond-mat.mtrl-sci"], "primary_category": "cs.IR"}
{"title": "RecoWorld: Building Simulated Environments for Agentic Recommender Systems", "abstract": "We present RecoWorld, a blueprint for building simulated environments\ntailored to agentic recommender systems. Such environments give agents a proper\ntraining space where they can learn from errors without impacting real users.\nRecoWorld distinguishes itself with a dual-view architecture: a simulated user\nand an agentic recommender engage in multi-turn interactions aimed at\nmaximizing user retention. The user simulator reviews recommended items,\nupdates its mindset, and when sensing potential user disengagement, generates\nreflective instructions. The agentic recommender adapts its recommendations by\nincorporating these user instructions and reasoning traces, creating a dynamic\nfeedback loop that actively engages users. This process leverages the\nexceptional reasoning capabilities of modern LLMs. We explore diverse content\nrepresentations within the simulator, including text-based, multimodal, and\nsemantic ID modeling, and discuss how multi-turn RL enables the recommender to\nrefine its strategies through iterative interactions. RecoWorld also supports\nmulti-agent simulations, allowing creators to simulate the responses of\ntargeted user populations. It marks an important first step toward recommender\nsystems where users and agents collaboratively shape personalized information\nstreams. We envision new interaction paradigms where \"user instructs,\nrecommender responds,\" jointly optimizing user retention and engagement.", "published": "2025-09-12 16:44:34", "link": "http://arxiv.org/abs/2509.10397v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Model-agnostic post-hoc explainability for recommender systems", "abstract": "Recommender systems often benefit from complex feature embeddings and deep\nlearning algorithms, which deliver sophisticated recommendations that enhance\nuser experience, engagement, and revenue. However, these methods frequently\nreduce the interpretability and transparency of the system. In this research,\nwe develop a systematic application, adaptation, and evaluation of deletion\ndiagnostics in the recommender setting. The method compares the performance of\na model to that of a similar model trained without a specific user or item,\nallowing us to quantify how that observation influences the recommender, either\npositively or negatively. To demonstrate its model-agnostic nature, the\nproposal is applied to both Neural Collaborative Filtering (NCF), a widely used\ndeep learning-based recommender, and Singular Value Decomposition (SVD), a\nclassical collaborative filtering technique. Experiments on the MovieLens and\nAmazon Reviews datasets provide insights into model behavior and highlight the\ngenerality of the approach across different recommendation paradigms.", "published": "2025-09-12 13:43:16", "link": "http://arxiv.org/abs/2509.10245v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Research Vision for Web Search on Emerging Topics", "abstract": "We regularly encounter information on novel, emerging topics for which the\nbody of knowledge is still evolving, which can be linked, for instance, to\ncurrent events. A primary way to learn more about such topics is through web\nsearch. However, information on emerging topics is sparse and evolves\ndynamically as knowledge grows, making it uncertain and variable in quality and\ntrustworthiness and prone to deliberate or accidental manipulation,\nmisinformation, and bias. In this paper, we outline a research vision towards\nsearch systems and interfaces that support effective knowledge acquisition,\nawareness of the dynamic nature of topics, and responsible opinion formation\namong people searching the web for information on emerging topics. To realize\nthis vision, we propose three overarching research questions, aimed at\nunderstanding the status quo, determining requirements of systems aligned with\nour vision, and building these systems. For each of the three questions, we\nhighlight relevant literature, including pointers on how they could be\naddressed. Lastly, we discuss the challenges that will potentially arise in\npursuing the proposed vision.", "published": "2025-09-12 13:00:06", "link": "http://arxiv.org/abs/2509.10212v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Vendi Information Gain for Active Learning and its Application to Ecology", "abstract": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG\nachieves impressive predictive accuracy close to full supervision using less\nthan 10% of the labels. It consistently outperforms standard baselines across\nmetrics and batch sizes, collecting more diverse data in the feature space. VIG\nhas broad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "published": "2025-09-12 16:31:16", "link": "http://arxiv.org/abs/2509.10390v1", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "primary_category": "cs.LG"}
{"title": "Near-Optimal Recovery Performance of PhaseLift for Phase Retrieval from Coded Diffraction Patterns", "abstract": "The PhaseLift algorithm is an effective convex method for solving the phase\nretrieval problem from Fourier measurements with coded diffraction patterns\n(CDP). While exact reconstruction guarantees are well-established in the\nnoiseless case, the stability of recovery under noise remains less well\nunderstood. In particular, when the measurements are corrupted by an additive\nnoise vector $\\mathbf{w} \\in \\mathbb{R}^m$, existing recovery bounds scale on\nthe order of $\\|\\mathbf{w}\\|_2$, which is conjectured to be suboptimal. More\nrecently, Soltanolkotabi conjectured that the optimal PhaseLift recovery bound\nshould scale with the average noise magnitude, that is, on the order of\n$\\|\\mathbf{w}\\|_2/\\sqrt m$. However, establishing this theoretically is\nconsiderably more challenging and has remained an open problem. In this paper,\nwe focus on this conjecture and provide a nearly optimal recovery bound for it.\nWe prove that under adversarial noise, the recovery error of PhaseLift is\nbounded by $O(\\log n \\cdot \\|\\mathbf{w}\\|_2/\\sqrt m)$, and further show that\nthere exists a noise vector for which the error lower bound exceeds\n$O\\bigl(\\frac{1}{\\sqrt{\\log n}} \\cdot \\frac{\\|\\mathbf{w}\\|_2}{\\sqrt m}\\bigr)$.\nHere, $n$ is the dimension of the signals we aim to recover. Moreover, for\nmean-zero sub-Gaussian noise vector $\\mathbf{w} \\in \\mathbb R^m$ with\nsub-Gaussian norm $\\sigma$, we establish a bound of order $O\\bigl(\\sigma\n\\sqrt{\\frac{n \\log^4 n}{m}}\\bigr)$, and also provide a corresponding minimax\nlower bound. Our results affirm Soltanolkotabi's conjecture up to logarithmic\nfactors, providing a new insight into the stability of PhaseLift under noisy\nCDP measurements.", "published": "2025-09-12 14:39:38", "link": "http://arxiv.org/abs/2509.10300v1", "categories": ["math.NA", "cs.IT", "cs.NA", "math.IT"], "primary_category": "math.NA"}
{"title": "Energy Efficiency for Massive MIMO Integrated Sensing and Communication Systems", "abstract": "This paper explores the energy efficiency (EE) of integrated sensing and\ncommunication (ISAC) systems employing massive multiple-input multiple-output\n(mMIMO) techniques to leverage spatial beamforming gains for both communication\nand sensing. We focus on an mMIMO-ISAC system operating in an orthogonal\nfrequency-division multiplexing setting with a uniform planar array,\nzero-forcing downlink transmission, and mono-static radar sensing to exploit\nmulti-carrier channel diversity. By deriving closed-form expressions for the\nachievable communication rate and Cram\\'er-Rao bounds (CRBs), we are able to\ndetermine the overall EE in closed-form. A power allocation problem is then\nformulated to maximize the system's EE by balancing communication and sensing\nefficiency while satisfying communication rate requirements and CRB\nconstraints. Through a detailed analysis of CRB properties, we reformulate the\nproblem into a more manageable form and leverage Dinkelbach's and successive\nconvex approximation (SCA) techniques to develop an efficient iterative\nalgorithm. A novel initialization strategy is also proposed to ensure\nhigh-quality feasible starting points for the iterative optimization process.\nExtensive simulations demonstrate the significant performance improvement of\nthe proposed approach over baseline approaches. Results further reveal that as\ncommunication spectral efficiency rises, the influence of sensing EE on the\noverall system EE becomes more pronounced, even in sensing-dominated scenarios.\nSpecifically, in the high $\\omega$ regime of $2 \\times 10^{-3}$, we observe a\n16.7\\% reduction in overall EE when spectral efficiency increases from $4$ to\n$8$ bps/Hz, despite the system being sensing-dominated.", "published": "2025-09-12 14:30:03", "link": "http://arxiv.org/abs/2509.10290v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Large-scale Aerial Reconfigurable Intelligent Surface-aided Robust Anti-jamming Transmission", "abstract": "Aerial reconfigurable intelligent surfaces (ARIS), deployed on unmanned\naerial vehicles (UAVs), could enhance anti-jamming communication performance by\ndynamically configuring channel conditions and establishing reliable air-ground\nlinks. However, large-scale ARIS faces critical deployment challenges due to\nthe prohibitive computational complexity of conventional discrete optimization\nmethods and sophisticated jamming threats. In this paper, we introduce a mean\nfield modeling approach to design the spatial configuration of ARIS by a\ncontinuous density function, thus bypassing high-dimensional combinatorial\noptimization. We consider an adaptive jammer which adjusts its position and\nbeamforming to minimize the sum-rate. A key finding reveals that the jammer's\noptimal strategy is governed by a proximity-directivity trade-off between\nreducing path loss and enhancing spatial focusing. To combat the jamming, we\npropose a robust anti-jamming transmission framework that jointly optimizes the\nBS beamforming, the ARIS reflection, and the ARIS spatial distribution to\nmaximize the worst-case sum-rate. By leveraging variational optimization and\nRiemannian manifold methods, we efficiently solve the functional optimization\nproblems. Our analysis further unveils that the optimal ARIS deployment follows\na spatial water-filling principle, concentrating resources in high-gain regions\nwhile avoiding interference-prone areas. Simulation results demonstrate that\nthe proposed framework remarkably improves the sum-rate. Furthermore, the\ncomputational complexity of the proposed algorithm is independent of the number\nof UAVs, validating its effectiveness for scalable ARIS-assisted anti-jamming\ncommunications.", "published": "2025-09-12 14:20:55", "link": "http://arxiv.org/abs/2509.10280v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cooperative Base Station Assignment and Resource Allocation for 6G ISAC Network", "abstract": "In the upcoming 6G networks, integrated sensing and communications (ISAC)\nwill be able to provide a performance boost in both perception and wireless\nconnectivity. This paper considers a multiple base station (BS) architecture to\nsupport the comprehensive services of data transmission and multi-target\nsensing. In this context, a cooperative BS assignment and resource allocation\n(CBARA) strategy is proposed in this paper, aiming at jointly optimizing the\ncommunication and sensing (C&S) performance. The posterior Cramer-Rao lower\nbound and the achievable rate with respect to transmit power and bandwidth are\nderived and utilized as optimization criteria for the CBARA scheme. We develop\na heuristic alternating optimization algorithm to obtain an effective\nsub-optimal solution for the non-convex optimization problem caused by multiple\ncoupled variables. Numerical results show the effectiveness of the proposed\nsolution, which achieves a performance improvement of 117% in communication\nrate and 40% in sensing accuracy, compared to the classic scheme.", "published": "2025-09-12 13:34:01", "link": "http://arxiv.org/abs/2509.10240v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Symplectic Lattices and GKP Codes -- Simple Randomized Constructions from Cryptographic Lattices", "abstract": "We construct good GKP (Gottesman-Kitaev-Preskill) codes (in the sense of\nConrad, Eisert and Seifert proposed) from standard short integer solution\nlattices (SIS) as well as from ring SIS and module SIS lattices, R-SIS and\nM-SIS lattices, respectively. These lattice are crucial for lattice-based\ncryptography. Our construction yields GKP codes with distance $\\sqrt{n/\\pi e}$.\nThis compares favorably with the NTRU-based construction by Conrad et al. that\nachieves distance $\\Omega(\\sqrt{n/q}),$ with $n\\le q^2/0.28$. Unlike their\ncodes, our codes do not have secret keys that can be used to speed-up the\ndecoding. However, we present a simple decoding algorithm that, for many\nparameter choices, experimentally yields decoding results similar to the ones\nfor NTRU-based codes. Using the R-SIS and M-SIS construction, our simple\ndecoding algorithm runs in nearly linear time. Following Conrad, Eisert and\nSeifert's work, our construction of GKP codes follows directly from an\nexplicit, randomized construction of symplectic lattices with (up to constants\n$\\approx 1$) minimal distance $(1/\\sigma_{2n})^{1/2n}\\approx \\sqrt{\\frac{n}{\\pi\ne}}$, where $\\sigma_{2n}$ is the volume of the 2n-dimensional unit ball. Before\nthis result, Buser and Sarnak gave a non-constructive proof for the existence\nof such symplectic lattices.", "published": "2025-09-12 12:17:04", "link": "http://arxiv.org/abs/2509.10183v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "abstract": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "published": "2025-09-12 11:41:40", "link": "http://arxiv.org/abs/2509.10163v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Analog Over-the-Air Federated Learning with Interference-Based Energy Harvesting", "abstract": "We consider analog over-the-air federated learning, where devices harvest\nenergy from in-band and out-band radio frequency signals, with the former also\ncausing co-channel interference (CCI). To mitigate the aggregation error, we\npropose an effective denoising policy that does not require channel state\ninformation (CSI). We also propose an adaptive scheduling algorithm that\ndynamically adjusts the number of local training epochs based on available\nenergy, enhancing device participation and learning performance while reducing\nenergy consumption. Simulation results and convergence analysis confirm the\nrobust performance of the algorithm compared to conventional methods. It is\nshown that the performance of the proposed denoising method is comparable to\nthat of conventional CSI-based methods. It is observed that high-power CCI\nseverely degrades the learning performance, which can be mitigated by\nincreasing the number of active devices, achievable via the adaptive algorithm.", "published": "2025-09-12 10:35:15", "link": "http://arxiv.org/abs/2509.10123v1", "categories": ["cs.IT", "cs.ET", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantic Rate-Distortion Theory with Applications", "abstract": "Artificial intelligence (AI) is ushering in a new era for communication. As a\nresult, the establishment of a semantic communication framework is putting on\nthe agenda. Based on a realistic semantic communication model, this paper\ndevelops a rate-distortion framework for semantic compression. Different from\nthe existing works primarily focusing on decoder-side estimation of intrinsic\nmeaning and ignoring its inherent issues, such as ambiguity and polysemy, we\nexploit a constraint of conditional semantic probability distortion to\neffectively capture the essential features of practical semantic exchanges in\nan AI-assisted communication system. With the help of the methods in\nrate-distortion-perception theory, we establish a theorem specifying the\nminimum achievable rate under this semantic constraint and a traditional\nsymbolic constraint and obtain its closed-form limit for a particular semantic\nscenario. From the experiments in this paper, bounding conditional semantic\nprobability distortion can effectively improve both semantic transmission\naccuracy and bit-rate efficiency. Our framework bridges information theory and\nAI, enabling potential applications in bandwidth-efficient semantic-aware\nnetworks, enhanced transceiver understanding, and optimized semantic\ntransmission for AI-driven systems.", "published": "2025-09-12 08:48:47", "link": "http://arxiv.org/abs/2509.10061v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Several new classes of optimal p-ary cyclic codes", "abstract": "Cyclic codes, as a crucial subclass of linear codes, exhibit broad\napplications in communication systems, data storage systems, and consumer\nelectronics, primarily attributed to their well-structured algebraic\nproperties. Let $p$ denote an odd prime with $p\\geq5$, and let $m$ be a\npositive integer. The primary objective of this paper is to construct three\nnovel classes of optimal $p$-ary cyclic codes, denoted as\n${\\mathcal{C}_p}(0,s,t)$, which possess the parameters $[{p^m} - 1,{p^m} - 2m -\n2,4]$. Here, $s$ is defined as $s = \\frac{{{p^m}+1}}{{2}}$, and $t$ satisfies\nthe condition $2 \\le t \\le {p^m} - 2$. Notably, one of the constructed classes\nincludes certain known optimal quinary cyclic codes as special cases.\nFurthermore, for the specific case when $p=5$, this paper additionally presents\nfour new classes of optimal cyclic codes ${\\mathcal{C}_5}(0,s,t)$.", "published": "2025-09-12 04:01:24", "link": "http://arxiv.org/abs/2509.09951v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration", "abstract": "Modern machine learning often requires training with large batch size,\ndistributed data, and massively parallel compute hardware (like mobile and\nother edge devices or distributed data centers). Communication becomes a major\nbottleneck in such settings but methods like Local Stochastic Gradient Descent\n(Local SGD) show great promise in reducing this additional communication\noverhead. Local SGD consists of three parts: a local optimization process, an\naggregation mechanism, and an outer optimizer that uses the aggregated updates\nfrom the nodes to produce a new model. While there exists an extensive\nliterature on understanding the impact of hyperparameters in the local\noptimization process, the choice of outer optimizer and its hyperparameters is\nless clear. We study the role of the outer optimizer in Local SGD, and prove\nnew convergence guarantees for the algorithm. In particular, we show that\ntuning the outer learning rate allows us to (a) trade off between optimization\nerror and stochastic gradient noise variance, and (b) make up for ill-tuning of\nthe inner learning rate. Our theory suggests that the outer learning rate\nshould sometimes be set to values greater than $1$. We extend our results to\nsettings where we use momentum in the outer optimizer, and we show a similar\nrole for the momentum-adjusted outer learning rate. We also study acceleration\nin the outer optimizer and show that it improves the convergence rate as a\nfunction of the number of communication rounds, improving upon the convergence\nrate of prior algorithms that apply acceleration locally. Finally, we also\nintroduce a novel data-dependent analysis of Local SGD that yields further\ninsights on outer learning rate tuning. We conduct comprehensive experiments\nwith standard language models and various outer optimizers to validate our\ntheory.", "published": "2025-09-12 17:47:58", "link": "http://arxiv.org/abs/2509.10439v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining", "abstract": "Ensuring the resilience of computer-based railways is increasingly crucial to\naccount for uncertainties and changes due to the growing complexity and\ncriticality of those systems. Although their software relies on strict\nverification and validation processes following well-established best-practices\nand certification standards, anomalies can still occur at run-time due to\nresidual faults, system and environmental modifications that were unknown at\ndesign-time, or other emergent cyber-threat scenarios. This paper explores\nrun-time control-flow anomaly detection using process mining to enhance the\nresilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European\nTrain Control System Level 2). Process mining allows learning the actual\ncontrol flow of the system from its execution traces, thus enabling run-time\nmonitoring through online conformance checking. In addition, anomaly\nlocalization is performed through unsupervised machine learning to link\nrelevant deviations to critical system components. We test our approach on a\nreference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its\ncapability to detect and localize anomalies with high accuracy, efficiency, and\nexplainability.", "published": "2025-09-12 17:17:35", "link": "http://arxiv.org/abs/2509.10419v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "abstract": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "published": "2025-09-12 16:58:17", "link": "http://arxiv.org/abs/2509.10406v1", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "abstract": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "published": "2025-09-12 16:44:31", "link": "http://arxiv.org/abs/2509.10396v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Differentially Private Decentralized Dataset Synthesis Through Randomized Mixing with Correlated Noise", "abstract": "In this work, we explore differentially private synthetic data generation in\na decentralized-data setting by building on the recently proposed\nDifferentially Private Class-Centric Data Aggregation (DP-CDA). DP-CDA\nsynthesizes data in a centralized setting by mixing multiple randomly-selected\nsamples from the same class and injecting carefully calibrated Gaussian noise,\nensuring ({\\epsilon}, {\\delta})-differential privacy. When deployed in a\ndecentralized or federated setting, where each client holds only a small\npartition of the data, DP-CDA faces new challenges. The limited sample size per\nclient increases the sensitivity of local computations, requiring higher noise\ninjection to maintain the differential privacy guarantee. This, in turn, leads\nto a noticeable degradation in the utility compared to the centralized setting.\nTo mitigate this issue, we integrate the Correlation-Assisted Private\nEstimation (CAPE) protocol into the federated DP-CDA framework and propose CAPE\nAssisted Federated DP-CDA algorithm. CAPE enables limited collaboration among\nthe clients by allowing them to generate jointly distributed (anti-correlated)\nnoise that cancels out in aggregate, while preserving privacy at the individual\nlevel. This technique significantly improves the privacy-utility trade-off in\nthe federated setting. Extensive experiments on MNIST and FashionMNIST datasets\ndemonstrate that the proposed CAPE Assisted Federated DP-CDA approach can\nachieve utility comparable to its centralized counterpart under some parameter\nregime, while maintaining rigorous differential privacy guarantees.", "published": "2025-09-12 16:18:35", "link": "http://arxiv.org/abs/2509.10385v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Flow Straight and Fast in Hilbert Space: Functional Rectified Flow", "abstract": "Many generative models originally developed in finite-dimensional Euclidean\nspace have functional generalizations in infinite-dimensional settings.\nHowever, the extension of rectified flow to infinite-dimensional spaces remains\nunexplored. In this work, we establish a rigorous functional formulation of\nrectified flow in an infinite-dimensional Hilbert space. Our approach builds\nupon the superposition principle for continuity equations in an\ninfinite-dimensional space. We further show that this framework extends\nnaturally to functional flow matching and functional probability flow ODEs,\ninterpreting them as nonlinear generalizations of rectified flow. Notably, our\nextension to functional flow matching removes the restrictive measure-theoretic\nassumptions in the existing theory of \\citet{kerrigan2024functional}.\nFurthermore, we demonstrate experimentally that our method achieves superior\nperformance compared to existing functional generative models.", "published": "2025-09-12 16:18:16", "link": "http://arxiv.org/abs/2509.10384v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Matrix-free Neural Preconditioner for the Dirac Operator in Lattice Gauge Theory", "abstract": "Linear systems arise in generating samples and in calculating observables in\nlattice quantum chromodynamics~(QCD). Solving the Hermitian positive definite\nsystems, which are sparse but ill-conditioned, involves using iterative\nmethods, such as Conjugate Gradient (CG), which are time-consuming and\ncomputationally expensive. Preconditioners can effectively accelerate this\nprocess, with the state-of-the-art being multigrid preconditioners. However,\nconstructing useful preconditioners can be challenging, adding additional\ncomputational overhead, especially in large linear systems. We propose a\nframework, leveraging operator learning techniques, to construct linear maps as\neffective preconditioners. The method in this work does not rely on explicit\nmatrices from either the original linear systems or the produced\npreconditioners, allowing efficient model training and application in the CG\nsolver. In the context of the Schwinger model U(1) gauge theory in 1+1\nspacetime dimensions with two degenerate-mass fermions), this preconditioning\nscheme effectively decreases the condition number of the linear systems and\napproximately halves the number of iterations required for convergence in\nrelevant parameter ranges. We further demonstrate the framework learns a\ngeneral mapping dependent on the lattice structure which leads to zero-shot\nlearning ability for the Dirac operators constructed from gauge field\nconfigurations of different sizes.", "published": "2025-09-12 16:10:18", "link": "http://arxiv.org/abs/2509.10378v1", "categories": ["hep-lat", "cs.LG"], "primary_category": "hep-lat"}
{"title": "Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective", "abstract": "The rapid scaling of Large Language Models (LLMs) has pushed training\nworkloads far beyond the limits of single-node analysis, demanding a deeper\nunderstanding of how these models behave across large-scale, multi-GPU systems.\nIn this paper, we present a comprehensive characterization of LLM training\nacross diverse real-world workloads and hardware platforms, including NVIDIA\nH100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various\nparallelism strategies -- tensor, pipeline, data, and expert -- and evaluate\ntheir effects on hardware utilization, power consumption, and thermal behavior.\nWe further evaluate the effectiveness of optimizations such as activation\nrecomputation and compute-communication overlap. Our findings show that\nperformance is not determined solely by scaling hardware capacity. Scale-up\nsystems with fewer, higher-memory GPUs can outperform scale-out systems in\ncommunication-bound regimes, but only under carefully tuned configurations; in\nother cases, scale-out deployments achieve superior throughput. We also show\nthat certain parallelism combinations, such as tensor with pipeline, lead to\nbandwidth underutilization due to inefficient data chunking, while increasing\nmicrobatch sizes beyond a certain point induces bursty execution and peak power\nexcursions that worsen thermal throttling. These insights reveal how training\nperformance is shaped by complex interactions between hardware, system\ntopology, and model execution. We conclude by offering recommendations for\nsystem and hardware design to improve the scalability and reliability of future\nLLM systems and workloads. The source code of this project is available at\nhttps://github.com/sitar-lab/CharLLM-PPT.", "published": "2025-09-12 16:05:07", "link": "http://arxiv.org/abs/2509.10371v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "A Discrepancy-Based Perspective on Dataset Condensation", "abstract": "Given a dataset of finitely many elements $\\mathcal{T} = \\{\\mathbf{x}_i\\}_{i\n= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic\ndataset $\\mathcal{S} = \\{\\tilde{\\mathbf{x}}_j\\}_{j = 1}^M$ which is\nsignificantly smaller ($M \\ll N$) such that a model trained from scratch on\n$\\mathcal{S}$ achieves comparable or even superior generalization performance\nto a model trained on $\\mathcal{T}$. Recent advances in DC reveal a close\nconnection to the problem of approximating the data distribution represented by\n$\\mathcal{T}$ with a reduced set of points. In this work, we present a unified\nframework that encompasses existing DC methods and extend the task-specific\nnotion of DC to a more general and formal definition using notions of\ndiscrepancy, which quantify the distance between probability distribution in\ndifferent regimes. Our framework broadens the objective of DC beyond\ngeneralization, accommodating additional objectives such as robustness,\nprivacy, and other desirable properties.", "published": "2025-09-12 16:00:49", "link": "http://arxiv.org/abs/2509.10367v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-informed sensor coverage through structure preserving machine learning", "abstract": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.", "published": "2025-09-12 15:54:13", "link": "http://arxiv.org/abs/2509.10363v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Why does your graph neural network fail on some graphs? Insights from exact generalisation error", "abstract": "Graph Neural Networks (GNNs) are widely used in learning on graph-structured\ndata, yet a principled understanding of why they succeed or fail remains\nelusive. While prior works have examined architectural limitations such as\nover-smoothing and over-squashing, these do not explain what enables GNNs to\nextract meaningful representations or why performance varies drastically\nbetween similar architectures. These questions are related to the role of\ngeneralisation: the ability of a model to make accurate predictions on\nunlabelled data. Although several works have derived generalisation error\nbounds for GNNs, these are typically loose, restricted to a single\narchitecture, and offer limited insight into what governs generalisation in\npractice. In this work, we take a different approach by deriving the exact\ngeneralisation error for GNNs in a transductive fixed-design setting through\nthe lens of signal processing. From this viewpoint, GNNs can be interpreted as\ngraph filter operators that act on node features via the graph structure. By\nfocusing on linear GNNs while allowing non-linearity in the graph filters, we\nderive the first exact generalisation error for a broad range of GNNs,\nincluding convolutional, PageRank-based, and attention-based models. The exact\ncharacterisation of the generalisation error reveals that only the aligned\ninformation between node features and graph structure contributes to\ngeneralisation. Furthermore, we quantify the effect of homophily on\ngeneralisation. Our work provides a framework that explains when and why GNNs\ncan effectively leverage structural and feature information, offering practical\nguidance for model selection.", "published": "2025-09-12 15:18:36", "link": "http://arxiv.org/abs/2509.10337v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting", "abstract": "This paper proposes a simple yet effective convolutional module for long-term\ntime series forecasting. The proposed block, inspired by the Auto-Regressive\nIntegrated Moving Average (ARIMA) model, consists of two convolutional\ncomponents: one for capturing the trend (autoregression) and the other for\nrefining local variations (moving average). Unlike conventional ARIMA, which\nrequires iterative multi-step forecasting, the block directly performs\nmulti-step forecasting, making it easily extendable to multivariate settings.\nExperiments on nine widely used benchmark datasets demonstrate that our method\nARMA achieves competitive accuracy, particularly on datasets exhibiting strong\ntrend variations, while maintaining architectural simplicity. Furthermore,\nanalysis shows that the block inherently encodes absolute positional\ninformation, suggesting its potential as a lightweight replacement for\npositional embeddings in sequential models.", "published": "2025-09-12 15:03:49", "link": "http://arxiv.org/abs/2509.10324v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robot guide with multi-agent control and automatic scenario generation with LLM", "abstract": "The work describes the development of a hybrid control architecture for an\nanthropomorphic tour guide robot, combining a multi-agent resource management\nsystem with automatic behavior scenario generation based on large language\nmodels. The proposed approach aims to overcome the limitations of traditional\nsystems, which rely on manual tuning of behavior scenarios. These limitations\ninclude manual configuration, low flexibility, and lack of naturalness in robot\nbehavior. The process of preparing tour scenarios is implemented through a\ntwo-stage generation: first, a stylized narrative is created, then non-verbal\naction tags are integrated into the text. The multi-agent system ensures\ncoordination and conflict resolution during the execution of parallel actions,\nas well as maintaining default behavior after the completion of main\noperations, contributing to more natural robot behavior. The results obtained\nfrom the trial demonstrate the potential of the proposed approach for\nautomating and scaling social robot control systems.", "published": "2025-09-12 14:59:04", "link": "http://arxiv.org/abs/2509.10317v1", "categories": ["cs.RO", "cs.LG", "93C85", "I.2.9; I.2.7; I.2.11"], "primary_category": "cs.RO"}
{"title": "GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction", "abstract": "In the aftermath of disasters, many institutions worldwide face challenges in\ncontinually monitoring changes in disaster risk, limiting the ability of key\ndecision-makers to assess progress towards the UN Sendai Framework for Disaster\nRisk Reduction 2015-2030. While numerous efforts have substantially advanced\nthe large-scale modeling of hazard and exposure through Earth observation and\ndata-driven methods, progress remains limited in modeling another equally\nimportant yet challenging element of the risk equation: physical vulnerability.\nTo address this gap, we introduce Graph Categorical Structured Variational\nAutoencoder (GraphCSVAE), a novel probabilistic data-driven framework for\nmodeling physical vulnerability by integrating deep learning, graph\nrepresentation, and categorical probabilistic inference, using time-series\nsatellite-derived datasets and prior expert belief systems. We introduce a\nweakly supervised first-order transition matrix that reflects the changes in\nthe spatiotemporal distribution of physical vulnerability in two\ndisaster-stricken and socioeconomically disadvantaged areas: (1) the\ncyclone-impacted coastal Khurushkul community in Bangladesh and (2) the\nmudslide-affected city of Freetown in Sierra Leone. Our work reveals\npost-disaster regional dynamics in physical vulnerability, offering valuable\ninsights into localized spatiotemporal auditing and sustainable strategies for\npost-disaster risk reduction.", "published": "2025-09-12 14:50:56", "link": "http://arxiv.org/abs/2509.10308v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case", "abstract": "In disaster scenarios where conventional energy infrastructure is\ncompromised, secure and traceable energy trading between solar-powered\nhouseholds and mobile charging units becomes a necessity. To ensure the\nintegrity of such transactions over a blockchain network, robust and\nunpredictable nonce generation is vital. This study proposes an SDN-enabled\narchitecture where machine learning regressors are leveraged not for their\naccuracy, but for their potential to generate randomized values suitable as\nnonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN\nallows flexible control over data flows and energy routing policies even in\nfragmented or degraded networks, ensuring adaptive response during emergencies.\nUsing a 9000-sample dataset, we evaluate five AutoML-selected regression models\n- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest\nNeighbors - not by their prediction accuracy, but by their ability to produce\ndiverse and non-deterministic outputs across shuffled data inputs. Randomness\nanalysis reveals that Random Forest and Extra Trees regressors exhibit complete\ndependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and\nLightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and\n99.9%, respectively). These findings highlight that certain machine learning\nmodels, particularly tree-based ensembles, may serve as effective and\nlightweight nonce generators within blockchain-secured, SDN-based energy\ntrading infrastructures resilient to disaster conditions.", "published": "2025-09-12 14:30:18", "link": "http://arxiv.org/abs/2509.10291v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Targeted Test Selection Approach in Continuous Integration", "abstract": "In modern software development change-based testing plays a crucial role.\nHowever, as codebases expand and test suites grow, efficiently managing the\ntesting process becomes increasingly challenging, especially given the high\nfrequency of daily code commits. We propose Targeted Test Selection (T-TS), a\nmachine learning approach for industrial test selection. Our key innovation is\na data representation that represent commits as Bags-of-Words of changed files,\nincorporates cross-file and additional predictive features, and notably avoids\nthe use of coverage maps. Deployed in production, T-TS was comprehensively\nevaluated against industry standards and recent methods using both internal and\npublic datasets, measuring time efficiency and fault detection. On live\nindustrial data, T-TS selects only 15% of tests, reduces execution time by\n$5.9\\times$, accelerates the pipeline by $5.6\\times$, and detects over 95% of\ntest failures. The implementation is publicly available to support further\nresearch and practical adoption.", "published": "2025-09-12 14:20:51", "link": "http://arxiv.org/abs/2509.10279v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning", "abstract": "Ionic liquids (ILs) have emerged as versatile replacements for traditional\nsolvents because their physicochemical properties can be precisely tailored to\nvarious applications. However, accurately predicting key thermophysical\nproperties remains challenging due to the vast chemical design space and the\nlimited availability of experimental data. In this study, we present a\ndata-driven transfer learning framework that leverages a neural recommender\nsystem (NRS) to enable reliable property prediction for ILs using sparse\nexperimental datasets. The approach involves a two-stage process: first,\npre-training NRS models on COSMO-RS-based simulated data at fixed temperature\nand pressure to learn property-specific structural embeddings for cations and\nanions; and second, fine-tuning simple feedforward neural networks using these\nembeddings with experimental data at varying temperatures and pressures. In\nthis work, five essential IL properties are considered: density, viscosity,\nsurface tension, heat capacity, and melting point. The framework supports both\nwithin-property and cross-property knowledge transfer. Notably, pre-trained\nmodels for density, viscosity, and heat capacity are used to fine-tune models\nfor all five target properties, achieving improved performance by a substantial\nmargin for four of them. The model exhibits robust extrapolation to previously\nunseen ILs. Moreover, the final trained models enable property prediction for\nover 700,000 IL combinations, offering a scalable solution for IL screening in\nprocess design. This work highlights the effectiveness of combining simulated\ndata and transfer learning to overcome sparsity in the experimental data.", "published": "2025-09-12 14:13:31", "link": "http://arxiv.org/abs/2509.10273v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "abstract": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "published": "2025-09-12 13:45:24", "link": "http://arxiv.org/abs/2509.10248v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "abstract": "Fatigue life prediction is essential in both the design and operational\nphases of any aircraft, and in this sense safety in the aerospace industry\nrequires early detection of fatigue cracks to prevent in-flight failures.\nRobust and precise fatigue life predictors are thus essential to ensure safety.\nTraditional engineering methods, while reliable, are time consuming and involve\ncomplex workflows, including steps such as conducting several Finite Element\nMethod (FEM) simulations, deriving the expected loading spectrum, and applying\ncycle counting techniques like peak-valley or rainflow counting. These steps\noften require collaboration between multiple teams and tools, added to the\ncomputational time and effort required to achieve fatigue life predictions.\nMachine learning (ML) offers a promising complement to traditional fatigue life\nestimation methods, enabling faster iterations and generalization, providing\nquick estimates that guide decisions alongside conventional simulations.\n  In this paper, we present a ML-based pipeline that aims to estimate the\nfatigue life of different aircraft wing locations given the flight parameters\nof the different missions that the aircraft will be operating throughout its\noperational life. We validate the pipeline in a realistic use case of fatigue\nlife estimation, yielding accurate predictions alongside a thorough statistical\nvalidation and uncertainty quantification. Our pipeline constitutes a\ncomplement to traditional methodologies by reducing the amount of costly\nsimulations and, thereby, lowering the required computational and human\nresources.", "published": "2025-09-12 13:18:19", "link": "http://arxiv.org/abs/2509.10227v1", "categories": ["cs.LG", "physics.app-ph"], "primary_category": "cs.LG"}
{"title": "RFSeek and Ye Shall Find", "abstract": "Requests for Comments (RFCs) are extensive specification documents for\nnetwork protocols, but their prose-based format and their considerable length\noften impede precise operational understanding. We present RFSeek, an\ninteractive tool that automatically extracts visual summaries of protocol logic\nfrom RFCs. RFSeek leverages large language models (LLMs) to generate\nprovenance-linked, explorable diagrams, surfacing both official state machines\nand additional logic found only in the RFC text. Compared to existing RFC\nvisualizations, RFSeek's visual summaries are more transparent and easier to\naudit against their textual source. We showcase the tool's potential through a\nseries of use cases, including guided knowledge extraction and semantic\ndiffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.\n  In practice, RFSeek not only reconstructs the RFC diagrams included in some\nspecifications, but, more interestingly, also uncovers important logic such as\nnodes or edges described in the text but missing from those diagrams. RFSeek\nfurther derives new visualization diagrams for complex RFCs, with QUIC as a\nrepresentative case. Our approach, which we term \\emph{Summary Visualization},\nhighlights a promising direction: combining LLMs with formal, user-customized\nvisualizations to enhance protocol comprehension and support robust\nimplementations.", "published": "2025-09-12 13:08:50", "link": "http://arxiv.org/abs/2509.10216v1", "categories": ["cs.NI", "cs.HC", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Investigating Feature Attribution for 5G Network Intrusion Detection", "abstract": "With the rise of fifth-generation (5G) networks in critical applications, it\nis urgent to move from detection of malicious activity to systems capable of\nproviding a reliable verdict suitable for mitigation. In this regard,\nunderstanding and interpreting machine learning (ML) models' security alerts is\ncrucial for enabling actionable incident response orchestration. Explainable\nArtificial Intelligence (XAI) techniques are expected to enhance trust by\nproviding insights into why alerts are raised. A dominant approach\nstatistically associates feature sets that can be correlated to a given alert.\nThis paper starts by questioning whether such attribution is relevant for\nfuture generation communication systems, and investigates its merits in\ncomparison with an approach based on logical explanations. We extensively study\ntwo methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts\ngenerated by an XGBoost model in three different use cases with several 5G\ncommunication attacks. We identify three metrics for assessing explanations:\nsparsity, how concise they are; stability, how consistent they are across\nsamples from the same attack type; and efficiency, how fast an explanation is\ngenerated. As an example, in a 5G network with 92 features, 6 were deemed\nimportant by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while\nSHAP identified over 20. More importantly, we found a significant divergence\nbetween features selected by SHAP and VoTE-XAI. However, none of the top-ranked\nfeatures selected by SHAP were missed by VoTE-XAI. When it comes to efficiency\nof providing interpretations, we found that VoTE-XAI is significantly more\nresponsive, e.g. it provides a single explanation in under 0.002 seconds, in a\nhigh-dimensional setting (478 features).", "published": "2025-09-12 12:55:48", "link": "http://arxiv.org/abs/2509.10206v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Hadamard-Riemannian Optimization for Margin-Variance Ensemble", "abstract": "Ensemble learning has been widely recognized as a pivotal technique for\nboosting predictive performance by combining multiple base models.\nNevertheless, conventional margin-based ensemble methods predominantly focus on\nmaximizing the expected margin while neglecting the critical role of margin\nvariance, which inherently restricts the generalization capability of the model\nand heightens its vulnerability to overfitting, particularly in noisy or\nimbalanced datasets. Additionally, the conventional approach of optimizing\nensemble weights within the probability simplex often introduces computational\ninefficiency and scalability challenges, complicating its application to\nlarge-scale problems. To tackle these limitations, this paper introduces a\nnovel ensemble learning framework that explicitly incorporates margin variance\ninto the loss function. Our method jointly optimizes the negative expected\nmargin and its variance, leading to enhanced robustness and improved\ngeneralization performance. Moreover, by reparameterizing the ensemble weights\nonto the unit sphere, we substantially simplify the optimization process and\nimprove computational efficiency. Extensive experiments conducted on multiple\nbenchmark datasets demonstrate that the proposed approach consistently\noutperforms traditional margin-based ensemble techniques, underscoring its\neffectiveness and practical utility.", "published": "2025-09-12 12:28:39", "link": "http://arxiv.org/abs/2509.10189v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "abstract": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.", "published": "2025-09-12 12:26:06", "link": "http://arxiv.org/abs/2509.10186v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams", "abstract": "We study the gradient-based training of large-depth residual networks\n(ResNets) from standard random initializations. We show that with a diverging\ndepth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,\nthe training dynamics converges to a Neural Mean ODE training dynamics.\nRemarkably, the limit is independent of the scaling of $M$, covering practical\ncases of, say, Transformers, where $M$ (the number of hidden units or attention\nheads per layer) is typically of the order of $D$. For a residual scale\n$\\Theta_D\\big(\\frac{\\alpha}{LM}\\big)$, we obtain the error bound\n$O_D\\big(\\frac{1}{L}+ \\frac{\\alpha}{\\sqrt{LM}}\\big)$ between the model's output\nand its limit after a fixed number gradient of steps, and we verify empirically\nthat this rate is tight. When $\\alpha=\\Theta(1)$, the limit exhibits complete\nfeature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In\ncontrast, we show that $\\alpha \\to \\infty$ yields a \\lazy ODE regime where the\nMean ODE is linearly parameterized. We then focus on the particular case of\nResNets with two-layer perceptron blocks, for which we study how these scalings\ndepend on the embedding dimension $D$. We show that for this model, the only\nresidual scale that leads to complete feature learning is\n$\\Theta\\big(\\frac{\\sqrt{D}}{LM}\\big)$. In this regime, we prove the error bound\n$O\\big(\\frac{1}{L}+ \\frac{\\sqrt{D}}{\\sqrt{LM}}\\big)$ between the ResNet and its\nlimit after a fixed number of gradient steps, which is also empirically tight.\nOur convergence results rely on a novel mathematical perspective on ResNets :\n(i) due to the randomness of the initialization, the forward and backward pass\nthrough the ResNet behave as the stochastic approximation of certain mean ODEs,\nand (ii) by propagation of chaos (that is, asymptotic independence of the\nunits) this behavior is preserved through the training dynamics.", "published": "2025-09-12 11:51:44", "link": "http://arxiv.org/abs/2509.10167v1", "categories": ["cs.LG", "68T07, 60H30, 34F05"], "primary_category": "cs.LG"}
{"title": "Repulsive Monte Carlo on the sphere for the sliced Wasserstein distance", "abstract": "In this paper, we consider the problem of computing the integral of a\nfunction on the unit sphere, in any dimension, using Monte Carlo methods.\nAlthough the methods we present are general, our guiding thread is the sliced\nWasserstein distance between two measures on $\\mathbb{R}^d$, which is precisely\nan integral on the $d$-dimensional sphere. The sliced Wasserstein distance (SW)\nhas gained momentum in machine learning either as a proxy to the less\ncomputationally tractable Wasserstein distance, or as a distance in its own\nright, due in particular to its built-in alleviation of the curse of\ndimensionality. There has been recent numerical benchmarks of quadratures for\nthe sliced Wasserstein, and our viewpoint differs in that we concentrate on\nquadratures where the nodes are repulsive, i.e. negatively dependent. Indeed,\nnegative dependence can bring variance reduction when the quadrature is adapted\nto the integration task. Our first contribution is to extract and motivate\nquadratures from the recent literature on determinantal point processes (DPPs)\nand repelled point processes, as well as repulsive quadratures from the\nliterature specific to the sliced Wasserstein distance. We then numerically\nbenchmark these quadratures. Moreover, we analyze the variance of the UnifOrtho\nestimator, an orthogonal Monte Carlo estimator. Our analysis sheds light on\nUnifOrtho's success for the estimation of the sliced Wasserstein in large\ndimensions, as well as counterexamples from the literature. Our final\nrecommendation for the computation of the sliced Wasserstein distance is to use\nrandomized quasi-Monte Carlo in low dimensions and \\emph{UnifOrtho} in large\ndimensions. DPP-based quadratures only shine when quasi-Monte Carlo also does,\nwhile repelled quadratures show moderate variance reduction in general, but\nmore theoretical effort is needed to make them robust.", "published": "2025-09-12 11:48:11", "link": "http://arxiv.org/abs/2509.10166v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Symmetry-Integrated Approach to Surface Code Decoding", "abstract": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "published": "2025-09-12 11:41:49", "link": "http://arxiv.org/abs/2509.10164v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "abstract": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "published": "2025-09-12 11:41:06", "link": "http://arxiv.org/abs/2509.10161v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning", "abstract": "Bayesian Federated Learning (BFL) combines uncertainty modeling with\ndecentralized training, enabling the development of personalized and reliable\nmodels under data heterogeneity and privacy constraints. Existing approaches\ntypically rely on Markov Chain Monte Carlo (MCMC) sampling or variational\ninference, often incorporating personalization mechanisms to better adapt to\nlocal data distributions. In this work, we propose an information-geometric\nprojection framework for personalization in parametric BFL. By projecting the\nglobal model onto a neighborhood of the user's local model, our method enables\na tunable trade-off between global generalization and local specialization.\nUnder mild assumptions, we show that this projection step is equivalent to\ncomputing a barycenter on the statistical manifold, allowing us to derive\nclosed-form solutions and achieve cost-free personalization. We apply the\nproposed approach to a variational learning setup using the Improved\nVariational Online Newton (IVON) optimizer and extend its application to\ngeneral aggregation schemes in BFL. Empirical evaluations under heterogeneous\ndata distributions confirm that our method effectively balances global and\nlocal performance with minimal computational overhead.", "published": "2025-09-12 10:46:21", "link": "http://arxiv.org/abs/2509.10132v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework", "abstract": "We introduce a novel symbolic regression framework, namely KAN-SR, built on\nKolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.\nSymbolic regression searches for mathematical equations that best fit a given\ndataset and is commonly solved with genetic programming approaches. We show\nthat by using deep learning techniques, more specific KANs, and combining them\nwith simplification strategies such as translational symmetries and\nseparabilities, we are able to recover ground-truth equations of the Feynman\nSymbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we\nshow that by combining the proposed framework with neural controlled\ndifferential equations, we are able to model the dynamics of an in-silico\nbioprocess system precisely, opening the door for the dynamic modeling of other\nengineering systems.", "published": "2025-09-12 09:31:34", "link": "http://arxiv.org/abs/2509.10089v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification", "abstract": "Introduction: This study presents FetalSleepNet, the first published deep\nlearning approach to classifying sleep states from the ovine\nelectroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and\nlaborious to interpret consistently. However, accurate sleep stage\nclassification may aid in the early detection of abnormal brain maturation\nassociated with pregnancy complications (e.g. hypoxia or intrauterine growth\nrestriction).\n  Methods: EEG electrodes were secured onto the ovine dura over the parietal\ncortices of 24 late gestation fetal sheep. A lightweight deep neural network\noriginally developed for adult EEG sleep staging was trained on the ovine EEG\nusing transfer learning from adult EEG. A spectral equalisation-based domain\nadaptation strategy was used to reduce cross-domain mismatch.\n  Results: We demonstrated that while direct transfer performed poorly, full\nfine tuning combined with spectral equalisation achieved the best overall\nperformance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming\nbaseline models.\n  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep\nlearning framework specifically developed for automated sleep staging from the\nfetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier\nfunctions as a label engine, enabling large scale weak/semi supervised labeling\nand distillation to facilitate training on less invasive signals that can be\nacquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.\nFetalSleepNet's lightweight design makes it well suited for deployment in low\npower, real time, and wearable fetal monitoring systems.", "published": "2025-09-12 09:19:04", "link": "http://arxiv.org/abs/2509.10082v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Prototypical Contrastive Learning For Improved Few-Shot Audio Classification", "abstract": "Few-shot learning has emerged as a powerful paradigm for training models with\nlimited labeled data, addressing challenges in scenarios where large-scale\nannotation is impractical. While extensive research has been conducted in the\nimage domain, few-shot learning in audio classification remains relatively\nunderexplored. In this work, we investigate the effect of integrating\nsupervised contrastive loss into prototypical few shot training for audio\nclassification. In detail, we demonstrate that angular loss further improves\nthe performance compared to the standard contrastive loss. Our method leverages\nSpecAugment followed by a self-attention mechanism to encapsulate diverse\ninformation of augmented input versions into one unified embedding. We evaluate\nour approach on MetaAudio, a benchmark including five datasets with predefined\nsplits, standardized preprocessing, and a comprehensive set of few-shot\nlearning models for comparison. The proposed approach achieves state-of-the-art\nperformance in a 5-way, 5-shot setting.", "published": "2025-09-12 09:10:55", "link": "http://arxiv.org/abs/2509.10074v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data", "abstract": "Predictive models are being increasingly used across a wide range of domains,\nincluding safety-critical applications such as medical diagnosis and criminal\njustice. Reliable uncertainty estimation is a crucial task in such settings.\nTabular Prior-data Fitted Network (TabPFN) is a recently proposed machine\nlearning foundation model for tabular dataset, which uses a generative\ntransformer architecture. Variational Bayesian Last Layers (VBLL) is a\nstate-of-the-art lightweight variational formulation that effectively improves\nuncertainty estimation with minimal computational overhead. In this work we aim\nto evaluate the performance of VBLL integrated with the recently proposed\nTabPFN in uncertainty calibration. Our experiments, conducted on three\nbenchmark medical tabular datasets, compare the performance of the original\nTabPFN and the VBLL-integrated version. Contrary to expectations, we observed\nthat original TabPFN consistently outperforms VBLL integrated TabPFN in\nuncertainty calibration across all datasets.", "published": "2025-09-12 08:24:19", "link": "http://arxiv.org/abs/2509.10048v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection", "abstract": "Federated learning (FL) offers an innovative paradigm for collaborative model\ntraining across decentralized devices, such as smartphones, balancing enhanced\npredictive performance with the protection of user privacy in sensitive areas\nlike Internet of Things (IoT) and medical data analysis. Despite its\nadvantages, FL encounters significant challenges related to user privacy\nprotection against potential attacks and the management of communication costs.\nThis paper introduces a novel federated learning algorithm called FedRP, which\nintegrates random projection techniques with the Alternating Direction Method\nof Multipliers (ADMM) optimization framework. This approach enhances privacy by\nemploying random projection to reduce the dimensionality of model parameters\nprior to their transmission to a central server, reducing the communication\ncost. The proposed algorithm offers a strong $(\\epsilon, \\delta)$-differential\nprivacy guarantee, demonstrating resilience against data reconstruction\nattacks. Experimental results reveal that FedRP not only maintains high model\naccuracy but also outperforms existing methods, including conventional\ndifferential privacy approaches and FedADMM, in terms of both privacy\npreservation and communication efficiency.", "published": "2025-09-12 08:08:48", "link": "http://arxiv.org/abs/2509.10041v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability", "abstract": "We present a formal and constructive theory showing that probabilistic finite\nautomata (PFAs) can be exactly simulated using symbolic feedforward neural\nnetworks. Our architecture represents state distributions as vectors and\ntransitions as stochastic matrices, enabling probabilistic state propagation\nvia matrix-vector products. This yields a parallel, interpretable, and\ndifferentiable simulation of PFA dynamics using soft updates-without\nrecurrence. We formally characterize probabilistic subset construction,\n$\\varepsilon$-closure, and exact simulation via layered symbolic computation,\nand prove equivalence between PFAs and specific classes of neural networks. We\nfurther show that these symbolic simulators are not only expressive but\nlearnable: trained with standard gradient descent-based optimization on labeled\nsequence data, they recover the exact behavior of ground-truth PFAs. This\nlearnability, formalized in Proposition 5.1, is the crux of this work. Our\nresults unify probabilistic automata theory with neural architectures under a\nrigorous algebraic framework, bridging the gap between symbolic computation and\ndeep learning.", "published": "2025-09-12 07:57:01", "link": "http://arxiv.org/abs/2509.10034v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sparse Coding Representation of 2-way Data", "abstract": "Sparse dictionary coding represents signals as linear combinations of a few\ndictionary atoms. It has been applied to images, time series, graph signals and\nmulti-way spatio-temporal data by jointly employing temporal and spatial\ndictionaries. Data-agnostic analytical dictionaries, such as the discrete\nFourier transform, wavelets and graph Fourier, have seen wide adoption due to\nefficient implementations and good practical performance. On the other hand,\ndictionaries learned from data offer sparser and more accurate solutions but\nrequire learning of both the dictionaries and the coding coefficients. This\nbecomes especially challenging for multi-dictionary scenarios since encoding\ncoefficients correspond to all atom combinations from the dictionaries. To\naddress this challenge, we propose a low-rank coding model for 2-dictionary\nscenarios and study its data complexity. Namely, we establish a bound on the\nnumber of samples needed to learn dictionaries that generalize to unseen\nsamples from the same distribution. We propose a convex relaxation solution,\ncalled AODL, whose exact solution we show also solves the original problem. We\nthen solve this relaxation via alternating optimization between the sparse\ncoding matrices and the learned dictionaries, which we prove to be convergent.\nWe demonstrate its quality for data reconstruction and missing value imputation\nin both synthetic and real-world datasets. For a fixed reconstruction quality,\nAODL learns up to 90\\% sparser solutions compared to non-low-rank and\nanalytical (fixed) dictionary baselines. In addition, the learned dictionaries\nreveal interpretable insights into patterns present within the samples used for\ntraining.", "published": "2025-09-12 07:53:33", "link": "http://arxiv.org/abs/2509.10033v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neural Scaling Laws for Deep Regression", "abstract": "Neural scaling laws--power-law relationships between generalization errors\nand characteristics of deep learning models--are vital tools for developing\nreliable models while managing limited resources. Although the success of large\nlanguage models highlights the importance of these laws, their application to\ndeep regression models remains largely unexplored. Here, we empirically\ninvestigate neural scaling laws in deep regression using a parameter estimation\nmodel for twisted van der Waals magnets. We observe power-law relationships\nbetween the loss and both training dataset size and model capacity across a\nwide range of values, employing various architectures--including fully\nconnected networks, residual networks, and vision transformers. Furthermore,\nthe scaling exponents governing these relationships range from 1 to 2, with\nspecific values depending on the regressed parameters and model details. The\nconsistent scaling behaviors and their large scaling exponents suggest that the\nperformance of deep regression models can improve substantially with increasing\ndata size.", "published": "2025-09-12 06:49:19", "link": "http://arxiv.org/abs/2509.10000v1", "categories": ["cs.LG", "cond-mat.other"], "primary_category": "cs.LG"}
{"title": "Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning", "abstract": "This paper presents a machine learning-based approach to estimate the energy\nconsumption of virtual servers without access to physical power measurement\ninterfaces. Using resource utilization metrics collected from guest virtual\nmachines, we train a Gradient Boosting Regressor to predict energy consumption\nmeasured via RAPL on the host. We demonstrate, for the first time, guest-only\nresource-based energy estimation without privileged host access with\nexperiments across diverse workloads, achieving high predictive accuracy and\nvariance explained ($0.90 \\leq R^2 \\leq 0.97$), indicating the feasibility of\nguest-side energy estimation. This approach can enable energy-aware scheduling,\ncost optimization and physical host independent energy estimates in virtualized\nenvironments. Our approach addresses a critical gap in virtualized environments\n(e.g. cloud) where direct energy measurement is infeasible.", "published": "2025-09-12 06:22:01", "link": "http://arxiv.org/abs/2509.09991v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition", "abstract": "Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential for intent-irrelevant and conflicting information across modalities\nmay hinder performance from being further improved. Most current models attempt\nto fuse modalities by applying mechanisms like multi-head attention to unimodal\nfeature sequences and then adding the result back to the original\nrepresentation. This process risks corrupting the primary linguistic features\nwith noisy or irrelevant non-verbal signals, as it often fails to capture the\nfine-grained, token-level influence where non-verbal cues should modulate, not\njust augment, textual meaning. To address this, we introduce DyKen-Hyena, which\nreframes the problem from feature fusion to processing modulation. Our model\ntranslates audio-visual cues into dynamic, per-token convolutional kernels that\ndirectly modulate textual feature extraction. This fine-grained approach\nachieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.\nNotably, it yields a +10.46% F1-score improvement in out-of-scope detection,\nvalidating that our method creates a fundamentally more robust intent\nrepresentation.", "published": "2025-09-12 03:12:39", "link": "http://arxiv.org/abs/2509.09940v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SciML Agents: Write the Solver, Not the Solution", "abstract": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "published": "2025-09-12 02:53:57", "link": "http://arxiv.org/abs/2509.09936v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Multi-Play Combinatorial Semi-Bandit Problem", "abstract": "In the combinatorial semi-bandit (CSB) problem, a player selects an action\nfrom a combinatorial action set and observes feedback from the base arms\nincluded in the action. While CSB is widely applicable to combinatorial\noptimization problems, its restriction to binary decision spaces excludes\nimportant cases involving non-negative integer flows or allocations, such as\nthe optimal transport and knapsack problems.To overcome this limitation, we\npropose the multi-play combinatorial semi-bandit (MP-CSB), where a player can\nselect a non-negative integer action and observe multiple feedbacks from a\nsingle arm in each round. We propose two algorithms for the MP-CSB. One is a\nThompson-sampling-based algorithm that is computationally feasible even when\nthe action space is exponentially large with respect to the number of arms, and\nattains $O(\\log T)$ distribution-dependent regret in the stochastic regime,\nwhere $T$ is the time horizon. The other is a best-of-both-worlds algorithm,\nwhich achieves $O(\\log T)$ variance-dependent regret in the stochastic regime\nand the worst-case $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ regret in the\nadversarial regime. Moreover, its regret in adversarial one is data-dependent,\nadapting to the cumulative loss of the optimal action, the total quadratic\nvariation, and the path-length of the loss sequence. Finally, we numerically\nshow that the proposed algorithms outperform existing methods in the CSB\nliterature.", "published": "2025-09-12 02:46:59", "link": "http://arxiv.org/abs/2509.09933v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Engineering Spatial and Molecular Features from Cellular Niches to Inform Predictions of Inflammatory Bowel Disease", "abstract": "Differentiating between the two main subtypes of Inflammatory Bowel Disease\n(IBD): Crohns disease (CD) and ulcerative colitis (UC) is a persistent clinical\nchallenge due to overlapping presentations. This study introduces a novel\ncomputational framework that employs spatial transcriptomics (ST) to create an\nexplainable machine learning model for IBD classification. We analyzed ST data\nfrom the colonic mucosa of healthy controls (HC), UC, and CD patients. Using\nNon-negative Matrix Factorization (NMF), we first identified four recurring\ncellular niches, representing distinct functional microenvironments within the\ntissue. From these niches, we systematically engineered 44 features capturing\nthree key aspects of tissue pathology: niche composition, neighborhood\nenrichment, and niche-gene signals. A multilayer perceptron (MLP) classifier\ntrained on these features achieved an accuracy of 0.774 +/- 0.161 for the more\nchallenging three-class problem (HC, UC, and CD) and 0.916 +/- 0.118 in the\ntwo-class problem of distinguishing IBD from healthy tissue. Crucially, model\nexplainability analysis revealed that disruptions in the spatial organization\nof niches were the strongest predictors of general inflammation, while the\nclassification between UC and CD relied on specific niche-gene expression\nsignatures. This work provides a robust, proof-of-concept pipeline that\ntransforms descriptive spatial data into an accurate and explainable predictive\ntool, offering not only a potential new diagnostic paradigm but also deeper\ninsights into the distinct biological mechanisms that drive IBD subtypes.", "published": "2025-09-12 02:10:41", "link": "http://arxiv.org/abs/2509.09923v1", "categories": ["q-bio.GN", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training", "abstract": "Trajectory prediction is a critical component of autonomous driving,\nessential for ensuring both safety and efficiency on the road. However,\ntraditional approaches often struggle with the scarcity of labeled data and\nexhibit suboptimal performance in multi-agent prediction scenarios. To address\nthese challenges, we introduce a disentangled context-aware pre-training\nframework for multi-agent motion prediction, named DECAMP. Unlike existing\nmethods that entangle representation learning with pretext tasks, our framework\ndecouples behavior pattern learning from latent feature reconstruction,\nprioritizing interpretable dynamics and thereby enhancing scene representation\nfor downstream prediction. Additionally, our framework incorporates\ncontext-aware representation learning alongside collaborative spatial-motion\npretext tasks, which enables joint optimization of structural and intentional\nreasoning while capturing the underlying dynamic intentions. Our experiments on\nthe Argoverse 2 benchmark showcase the superior performance of our method, and\nthe results attained underscore its effectiveness in multi-agent motion\nforecasting. To the best of our knowledge, this is the first context\nautoencoder framework for multi-agent motion forecasting in autonomous driving.\nThe code and models will be made publicly available.", "published": "2025-09-12 17:29:02", "link": "http://arxiv.org/abs/2509.10426v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "A Holistic Architecture for Monitoring and Optimization of Robust Multi-Agent Path Finding Plan Execution", "abstract": "The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a\nfleet of agents moving in a shared environment such that the agents reach their\ngoals without colliding with each other. In practice, some of the robots\nexecuting the plan may get delayed, which can introduce collision risk.\nAlthough robust execution methods are used to ensure safety even in the\npresence of delays, the delays may still have a significant impact on the\nduration of the execution. At some point, the accumulated delays may become\nsignificant enough that instead of continuing with the execution of the\noriginal plan, even if it was optimal, there may now exist an alternate plan\nwhich will lead to a shorter execution. However, the problem is how to decide\nwhen to search for the alternate plan, since it is a costly procedure. In this\npaper, we propose a holistic architecture for robust execution of MAPF plans,\nits monitoring and optimization. We exploit a robust execution method called\nAction Dependency Graph to maintain an estimate of the expected execution\nduration during the plan's execution. This estimate is used to predict the\npotential that finding an alternate plan would lead to shorter execution. We\nempirically evaluate the architecture in experiments in a real-time simulator\nwhich we designed to mimic our real-life demonstrator of an autonomous\nwarehouse robotic fleet.", "published": "2025-09-12 14:23:02", "link": "http://arxiv.org/abs/2509.10284v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Multiscaling in Wasserstein Spaces", "abstract": "We present a novel multiscale framework for analyzing sequences of\nprobability measures in Wasserstein spaces over Euclidean domains. Exploiting\nthe intrinsic geometry of optimal transport, we construct a multiscale\ntransform applicable to both absolutely continuous and discrete measures.\nCentral to our approach is a refinement operator based on McCann's\ninterpolants, which preserves the geodesic structure of measure flows and\nserves as an upsampling mechanism. Building on this, we introduce the\noptimality number, a scalar that quantifies deviations of a sequence from\nWasserstein geodesicity across scales, enabling the detection of irregular\ndynamics and anomalies. We establish key theoretical guarantees, including\nstability of the transform and geometric decay of coefficients, ensuring\nrobustness and interpretability of the multiscale representation. Finally, we\ndemonstrate the versatility of our methodology through numerical experiments:\ndenoising and anomaly detection in Gaussian flows, analysis of point cloud\ndynamics under vector fields, and the multiscale characterization of neural\nnetwork learning trajectories.", "published": "2025-09-12 17:12:06", "link": "http://arxiv.org/abs/2509.10415v1", "categories": ["math.NA", "cs.NA", "28A33, 43A32, 65C20, 65D17"], "primary_category": "math.NA"}
{"title": "Mathematical and numerical study of symmetry and positivity of the tensor-valued spring constant defined from P1-FEM for two- and three-dimensional linear elasticity", "abstract": "In this study, we consider a spring-block system that approximates a\n$d$-dimensional linear elastic body, where $d=2$ or $d=3$. We derive a $d\\times\nd$ matrix as the spring constant using the P1 finite element method with a\ntriangular mesh for the linear elasticity equations. We mathematically analyze\nthe symmetry and positive-definiteness of the spring constant. Even if we\nassume full symmetry of the elasticity tensor, the symmetry of the matrix\nobtained as the spring constant is not trivial. However, we have succeeded in\nproving this in a unified manner for both 2D and 3D cases. This is an\nalternative proof for the 2D case in Notsu-Kimura (2014) and is a new result\nfor the 3D case. We provide a necessary and sufficient condition for the spring\nconstant to be positive-definite in the case of an isotropic elasticity tensor,\nalong with a sufficient condition in terms of mesh regularity and the Poisson\nratio. These theoretical results are supported by several numerical\nexperiments. The positive-definiteness of the spring constant derived from the\nfinite element method plays a vital role in fracture simulations of elastic\nbodies using the spring-block system.", "published": "2025-09-12 15:16:04", "link": "http://arxiv.org/abs/2509.10335v1", "categories": ["math.NA", "cs.NA", "35Q74, 65N30, 74B05, 74R10"], "primary_category": "math.NA"}
{"title": "Numerical analysis of the large deviation regime of a kinetic equation with a nonlocal Hamilton-Jacobi limit", "abstract": "We develop and study an asymptotic-preserving (AP) numerical scheme for a\nlinear kinetic equation in a large deviation regime. After applying a Hopf-Cole\ntransform to the distribution function, the system exhibits the behavior of\nrare events, which in the limit is governed by a non-standard, nonlocal\nHamilton-Jacobi equation, as identified in [E. Bouin et al., J. Lond. Math.\nSoc., II. Ser., 2023].\n  The proposed scheme efficiently handles the stiffness introduced by scaling,\nwith a computational cost that remains uniform with respect to the small\nparameter. It takes advantage of the conservation properties of the original\nkinetic model to overcome the numerical challenges posed by stiffness. The\nscheme satisfies a discrete maximum principle, preserves equilibrium states,\nand correctly captures the asymptotic limit, recovering the viscosity solution\nof the limit nonlocal Hamilton-Jacobi equation.\n  As the limit problem is non-standard, convergence results from the literature\nare not directly applicable. We introduce new analytical tools based on a\ndiscrete representation formula that links the numerical scheme with the\ncontinuous setting. This allows us to prove the convergence and establish key\nstructural properties of the method. Numerical tests support the analysis and\nillustrate the robustness of the scheme and the original behavior of the limit\nsystem.", "published": "2025-09-12 15:03:35", "link": "http://arxiv.org/abs/2509.10323v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Structure-Preserving High-Order Methods for the Compressible Euler Equations in Potential Temperature Formulation for Atmospheric Flows", "abstract": "We develop structure-preserving numerical methods for the compressible Euler\nequations, employing potential temperature as a prognostic variable.We\nconstruct three numerical fluxes designed to ensure the conservation of entropy\nand total energy within the discontinuous Galerkin framework on general\ncurvilinear meshes.Furthermore, we introduce a generalization for the kinetic\nenergy preservation property and total energy conservation in the presence of a\ngravitational potential term. To this end, we adopt a flux-differencing\napproach for the discretization of the source term, treated as non-conservative\nproduct. We present well-balanced schemes for different constant background\nstates for both formulations (total energy and potential temperature) on\ncurvilinear meshes. Finally, we validate the methods by comparing the potential\ntemperature formulation with the traditional Euler equations formulation across\na range of classical atmospheric scenarios.", "published": "2025-09-12 14:53:20", "link": "http://arxiv.org/abs/2509.10311v1", "categories": ["math.NA", "cs.NA", "physics.ao-ph", "physics.comp-ph", "65M12, 65M20, 65M70, 65M60, 65M06, 76U60"], "primary_category": "math.NA"}
{"title": "Matrix-Free Evaluation Strategies for Continuous and Discontinuous Galerkin Discretizations on Unstructured Tetrahedral Grids", "abstract": "This study presents novel strategies for improving the node-level performance\nof matrix-free evaluation of continuous and discontinuous Galerkin spatial\ndiscretizations on unstructured tetrahedral grids. In our approach the\nunderlying integrals of a generic finite-element operator are computed\ncell-by-cell through numerical quadrature using tabulated dense local matrices\nof shape functions, achieving high throughput for low to moderate-order\npolynomial degrees. By employing dense matrix-matrix products instead of\nmatrix-vector products for the cell-wise interpolation, the method reaches over\n$60\\%$ of peak performance. The optimization strategies exploit explicit data\nparallelism to enhance computational efficiency, complemented by a hierarchical\nmesh reordering algorithm that improves data locality. The matrix-free\nimplementation achieves up to a $6\\times$ speedup compared to a global sparse\nmatrix-based approach at a polynomial degree of three. The effectiveness of the\nmethod is demonstrated through numerical experiments on the Poisson and\nNavier--Stokes equations. The Poisson operator is preconditioned by a hybrid\nmultigrid scheme that combines auxiliary continuous finite-element spaces,\npolynomial and geometric coarsening where possible while employing algebraic\nmultigrid on the coarse mesh. Within the preconditioner, the implementation\ntransitions between the matrix-free and matrix-based strategies for optimal\nefficiency. Finally, we analyze the strong scaling behavior of the Poisson and\nHelmholtz operators, demonstrating the method's potential to solve large\nreal-world problems.", "published": "2025-09-12 13:18:12", "link": "http://arxiv.org/abs/2509.10226v1", "categories": ["math.NA", "cs.MS", "cs.NA", "cs.PF", "65M60, 68W10, 76M10"], "primary_category": "math.NA"}
{"title": "Convergence to equilibrium for fully discretizations of nonlocal Cahn-Hilliard equation", "abstract": "The study of long-term dynamics for numerical solutions of nonlinear\nevolution equations, particularly phase field models, has consistently garnered\nconsiderable attention. The Cahn-Hilliard (CH) equation is one of the most\nimportant phase field models and is widely applied in materials science. In\norder to more accurately describe the practical phenomena in material\nmicrostructural phase transitions, the Nonlocal Cahn-Hilliard (N-CH) equation\nincorporates a finite range of spatial nonlocal interactions is introduced,\nwhich is a generalization of the classic CH equation. However, compared to its\nclassic counterpart, it is very challenging to investigate the long-term\nasymptotic behavior of solution to the N-CH equation due to the complexity of\nthe nonlocal integral term and the lack of high-order diffusion term. In this\npaper, we consider first-order and second-order temporal discretization methods\nfor the N-CH equation, respectively, while utilizing a second-order finite\ndifference method for spatial approximation to construct the energy stable\nfully discrete numerical schemes. Based on energy stability and the\n{\\L}ojasiewicz inequality, we rigorously prove that the numerical solutions of\nthese fully discrete numerical schemes converge to equilibrium as time goes to\ninfinity.", "published": "2025-09-12 12:13:59", "link": "http://arxiv.org/abs/2509.10180v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The unified gas kinetic wave-particle method for the neutron transport equation", "abstract": "The unified gas-kinetic wave-particle (UGKWP) method is proposed for the\nneutron transport equation, addressing the inherent multiscale nature of\nneutron propagation in both optically thin and thick regimes. UGKWP couples\nmacroscopic diffusion and microscopic transport processes within a unified\ntime-dependent framework, allowing a smooth transition between the free\ntransport and diffusion regimes. This method is readily extended to multi-group\nneutron transport models and is applicable to both steady-state and eigenvalue\nproblems. Several numerical examples, including the 1D and 3D single-group and\n3D multi-group problems, are studied, indicating UGKWP a promising framework\nfor scalable and accurate simulation of multigroup neutron transport in complex\ngeometries.", "published": "2025-09-12 12:10:00", "link": "http://arxiv.org/abs/2509.10178v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The low-rank tensor-train finite difference method for three-dimensional parabolic equations", "abstract": "This paper presents a numerical framework for the low-rank approximation of\nthe solution to three-dimensional parabolic problems. The key contribution of\nthis work is the tensorization process based on a tensor-train reformulation of\nthe second-order accurate finite difference method. We advance the solution in\ntime by combining the finite difference method with an explicit and implicit\nEuler method and with the Crank-Nicolson method. We solve the linear system\narising at each time step from the implicit and semi-implicit time-marching\nschemes through a matrix-free preconditioned conjugate gradient (PCG) method,\nappositely designed to exploit the separation of variables induced by the\ntensor-train format. We assess the performance of our method through extensive\nnumerical experimentation, demonstrating that the tensor-train design offers a\nrobust and highly efficient alternative to the traditional approach. Indeed,\nthe usage of this type of representation leads to massive time and memory\nsavings while guaranteeing almost identical accuracy with respect to the\ntraditional one. These features make the method particularly suitable to tackle\nchallenging high-dimensional problems.", "published": "2025-09-12 11:10:23", "link": "http://arxiv.org/abs/2509.10142v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Neural network-based singularity detection and applications", "abstract": "We present a method for constructing a special type of shallow neural network\nthat learns univariate meromorphic functions with pole-type singularities. Our\nmethod is based on using a finite set of Laurent coefficients as input\ninformation, which we compute by FFT, employing values of the investigated\nfunction on some contour $\\Gamma$ in the complex plane. The primary components\nof our methodology are the following: (1) the adaptive construction of rational\npolynomial activation functions, (2) a novel backpropagation-free method for\ndetermining the weights and biases of the hidden layer, and (3) the computation\nof the weights and biases of the output layer through least-squares fitting.\nBreaking with the idea of \"safe\" rational activation functions, we introduce a\nrational activation function as a meromorphic function with a single pole\nsituated within the domain of investigation. Employing the weights and biases\nof the hidden layer, we then scale and shift the pole of the activation\nfunction to find the estimated locations of the singularities; this implies\nthat the number of neurons in the hidden layer is determined by the number of\nsingularities of the function that is being approximated. While the weights and\nbiases of the hidden layer are tuned so as to capture the singularities, the\nleast-squares fitting for the computation of weights and biases of the output\nlayer ensures approximation of the function in the rest of the domain. Through\nthe use of Laurent-Pad\\'e rational approximation concepts, we prove locally\nuniform convergence of our method. We illustrate the effectiveness of our\nmethod through numerical experiments, including the construction of extensions\nof the time-dependent solutions of nonlinear autonomous PDEs into the complex\nplane, and study the dynamics of their singularities.", "published": "2025-09-12 10:05:16", "link": "http://arxiv.org/abs/2509.10110v1", "categories": ["math.NA", "cs.NA", "30D30, 30E10, 41A20, 65D15"], "primary_category": "math.NA"}
{"title": "A Spectral Localization Method for Time-Fractional Integro-Differential Equations with Nonsmooth Data", "abstract": "In this work, we develop a localized numerical scheme with low regularity\nrequirements for solving time-fractional integro-differential equations. First,\na fully discrete numerical scheme is constructed. Specifically, for temporal\ndiscretization, we employ the contour integral method (CIM) with parameterized\nhyperbolic contours to approximate the nonlocal operators. For spatial\ndiscretization, the standard piecewise linear Galerkin finite element method\n(FEM) is used. We then provide a rigorous error analysis, demonstrating that\nthe proposed scheme achieves high accuracy even for problems with\nnonsmooth/vanishing initial values or low-regularity solutions, featuring\nspectral accuracy in time and second-order convergence in space. Finally, a\nseries of numerical experiments in both 1-D and 2-D validate the theoretical\nfindings and confirm that the algorithm combines the advantages of spectral\naccuracy, low computational cost, and efficient memory usage.", "published": "2025-09-12 09:33:48", "link": "http://arxiv.org/abs/2509.10091v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Perfectly transparent boundary conditions and wave propagation in lattice Boltzmann schemes", "abstract": "Systems of N = 1, 2, . . . first-order hyperbolic conservation laws feature N\nundamped waves propagating at finite speeds. On their own hand, multi-step\nFinite Difference and lattice Boltzmann schemes with q = N + 1, N + 2, . . .\nunknowns involve N ''physical'' waves, which are aimed at being as\nclosely-looking as possible to the ones of the PDEs, and q-N\n''numerical-spurious-parasitic'' waves, which are subject to their own speed of\npropagation, and either damped or undamped. The whole picture is even more\ncomplicated in the discrete setting-as numerical schemes act as dispersive\nmedia, thus propagate different harmonics at different phase (and group)\nvelocities. For compelling practical reasons, simulations must always be\nconducted on bounded domains, even when the target problem is unbounded in\nspace. The importance of transparent boundary conditions, preventing artificial\nboundaries from acting as mirrors producing polluting ricochets, naturally\nfollows. This work presents, building on Besse, Coulombel, and Noble [ESAIM:\nM2AN, 55 (2021)], a systematic way of developing perfectly transparent boundary\nconditions for lattice Boltzmann schemes tackling linear problems in one and\ntwo space dimensions. Our boundary conditions are ''perfectly'' transparent, at\nleast for 1D problems, as they absorb both physical and spurious waves\nregardless of their frequency. After presenting, in a simple framework, several\napproaches to handle the fact that q > N , we elect the so-called ''scalar''\napproach (which despite its name, also works when N > 1) as method of choice\nfor more involved problems. This method solely relies on computing the\ncoefficients of the Laurent series at infinity of the roots of the dispersion\nrelation of the bulk scheme. We insist on asymptotics for these coefficients in\nthe spirit of analytic combinatorics. The reason is two-fold: asymptotics guide\ntruncation of boundary conditions to make them depending on a fixed number of\npast time-steps, and make it clearduring the process of computing\ncoefficients-whether intermediate quantities can be safely stored using\nfloating-point arithmetic or not. Numerous numerical investigations in 1D and\n2D with N = 1 and 2 are carried out, and show the effectiveness of the proposed\nboundary conditions.", "published": "2025-09-12 08:57:11", "link": "http://arxiv.org/abs/2509.10066v1", "categories": ["math.NA", "cs.NA", "math.CA"], "primary_category": "math.NA"}
{"title": "A streamline upwind/Petrov-Galerkin method for the magnetic advection-diffusion problem", "abstract": "This paper presents the development and analysis of a streamline\nupwind/Petrov-Galerkin (SUPG) method for the magnetic advection-diffusion\nproblem. A key feature of the method is an SUPG-type stabilization term based\non the residuals and weighted advection terms of the test function. By\nintroducing a lifting operator to characterize the jumps of finite element\nfunctions across element interfaces, we define a discrete magnetic advection\noperator, which subsequently enables the formulation of the desired SUPG\nmethod. Under mild assumptions, we establish the stability of the scheme and\nderive optimal error estimates. Furthermore, by introducing a stabilization\nterm that depends on the residual, we propose a nonlinear extension aimed at\nmore effectively reducing numerical oscillations in sharp layers. Numerical\nexamples in both two and three dimensions are provided to demonstrate the\ntheoretical convergence and stabilization properties of the proposed method.", "published": "2025-09-12 01:07:11", "link": "http://arxiv.org/abs/2509.09913v1", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 65N15"], "primary_category": "math.NA"}
{"title": "The Interplay between Utility and Risk in Portfolio Selection", "abstract": "We revisit the problem of portfolio selection, where an investor maximizes\nutility subject to a risk constraint. Our framework is very general and\naccommodates a wide range of utility and risk functionals, including\nnon-concave utilities such as S-shaped utilities from prospect theory and\nnon-convex risk measures such as Value at Risk. Our main contribution is a\nnovel and complete characterization of well-posedness for utility-risk\nportfolio selection in one period that takes the interplay between the utility\nand the risk objectives fully into account. We show that under mild regularity\nconditions the minimal necessary and sufficient condition for well-posedness is\ngiven by a very simple either-or criterion: either the utility functional or\nthe risk functional need to satisfy the axiom of sensitivity to large losses.\nThis allows to easily describe well-posedness or ill-posedness for many\nutility-risk pairs, which we illustrate by a large number of examples. In the\nspecial case of expected utility maximization without a risk constraint (but\nincluding non-concave utilities), we show that well-posedness is fully\ncharacterised by the asymptotic loss-gain ratio, a simple and interpretable\nquantity that describes the investor's asymptotic relative weighting of large\nlosses versus large gains.", "published": "2025-09-12 15:39:56", "link": "http://arxiv.org/abs/2509.10351v1", "categories": ["q-fin.MF", "q-fin.PM", "q-fin.RM"], "primary_category": "q-fin.MF"}
{"title": "Ultrafast Extreme Events: Empirical Analysis of Mechanisms and Recovery in a Historical Perspective", "abstract": "To understand the emergence of Ultrafast Extreme Events (UEEs), the influence\nof algorithmic trading or high-frequency traders is of major interest as they\nmake it extremely difficult to intervene and to stabilize financial markets. In\nan empirical analysis, we compare various characteristics of UEEs over\ndifferent years for the US stock market to assess the possible non-stationarity\nof the effects. We show that liquidity plays a dominant role in the emergence\nof UEEs and find a general pattern in their dynamics. We also empirically\ninvestigate the after-effects in view of the recovery rate. We find common\npatterns for different years. We explain changes in the recovery rate by\nvarying market sentiments for the different years.", "published": "2025-09-12 16:08:31", "link": "http://arxiv.org/abs/2509.10376v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Competition and Incentives in a Shared Order Book", "abstract": "Recent regulation on intraday electricity markets has led to the development\nof shared order books with the intention to foster competition and increase\nmarket liquidity. In this paper, we address the question of the efficiency of\nsuch regulations by analysing the situation of two exchanges sharing a single\nlimit order book, i.e. a quote by a market maker can be hit by a trade arriving\non the other exchange. We develop a Principal-Agent model where each exchange\nacts as the Principal of her own market maker acting as her Agent. Exchanges\nand market makers have all CARA utility functions with potentially different\nrisk-aversion parameters. In terms of mathematical result, we show existence\nand uniqueness of the resulting Nash equilibrium between exchanges, give the\noptimal incentive contracts and provide numerical solution to the PDE satisfied\nby the certainty equivalent of the exchanges. From an economic standpoint, our\nmodel demonstrates that incentive provision constitutes a public good. More\nprecisely, it highlights the presence of a competitiveness spillover effect:\nwhen one exchange optimally incentivizes its market maker, the competing\nexchange also reaps indirect benefits. This interdependence gives rise to a\nfree-rider problem. Given that providing incentives entails a cost, the\nstrategic interaction between exchanges may lead to an equilibrium in which\nneither platform offers incentives -- ultimately resulting in diminished\noverall competition.", "published": "2025-09-12 09:36:45", "link": "http://arxiv.org/abs/2509.10094v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "A Computable Measure of Suboptimality for Entropy-Regularised Variational Objectives", "abstract": "Several emerging post-Bayesian methods target a probability distribution for\nwhich an entropy-regularised variational objective is minimised. This increased\nflexibility introduces a computational challenge, as one loses access to an\nexplicit unnormalised density for the target. To mitigate this difficulty, we\nintroduce a novel measure of suboptimality called 'gradient discrepancy', and\nin particular a 'kernel gradient discrepancy' (KGD) that can be explicitly\ncomputed. In the standard Bayesian context, KGD coincides with the kernel Stein\ndiscrepancy (KSD), and we obtain a novel charasterisation of KSD as measuring\nthe size of a variational gradient. Outside this familiar setting, KGD enables\nnovel sampling algorithms to be developed and compared, even when unnormalised\ndensities cannot be obtained. To illustrate this point several novel algorithms\nare proposed, including a natural generalisation of Stein variational gradient\ndescent, with applications to mean-field neural networks and prediction-centric\nuncertainty quantification presented. On the theoretical side, our principal\ncontribution is to establish sufficient conditions for desirable properties of\nKGD, such as continuity and convergence control.", "published": "2025-09-12 16:38:41", "link": "http://arxiv.org/abs/2509.10393v1", "categories": ["stat.CO", "stat.ML"], "primary_category": "stat.CO"}
{"title": "A Smooth Computational Transition in Tensor PCA", "abstract": "We propose an efficient algorithm for tensor PCA based on counting a specific\nfamily of weighted hypergraphs. For the order-$p$ tensor PCA problem where $p\n\\geq 3$ is a fixed integer, we show that when the signal-to-noise ratio is\n$\\lambda n^{-\\frac{p}{4}}$ where $\\lambda=\\Omega(1)$, our algorithm succeeds\nand runs in time $n^{C+o(1)}$ where $C=C(\\lambda)$ is a constant depending on\n$\\lambda$. This algorithm improves a poly-logarithmic factor compared to\nprevious algorithms based on the Sum-of-Squares hierarchy \\cite{HSS15} or based\non the Kikuchi hierarchy in statistical physics \\cite{WEM19}. Furthermore, our\nresult shows a smooth tradeoff between the signal-to-noise ratio and the\ncomputational cost in this problem, thereby confirming a conjecture posed in\n\\cite{KWB22}.", "published": "2025-09-12 00:21:20", "link": "http://arxiv.org/abs/2509.09904v1", "categories": ["math.ST", "cs.DS", "math.PR", "stat.ML", "stat.TH", "68Q87, 90C35"], "primary_category": "math.ST"}
{"title": "Low-latency Assistive Audio Enhancement for Neurodivergent People", "abstract": "Neurodivergent people frequently experience decreased sound tolerance, with\nestimates suggesting it affects 50-70% of this population. This heightened\nsensitivity can provoke reactions ranging from mild discomfort to severe\ndistress, highlighting the critical need for assistive audio enhancement\ntechnologies In this paper, we propose several assistive audio enhancement\nalgorithms designed to selectively filter distressing sounds. To address this,\nwe curated a list of potential trigger sounds by analyzing\nneurodivergent-focused communities on platforms such as Reddit. Using this\nlist, a dataset of trigger sound samples was compiled from publicly available\nsources, including FSD50K and ESC50. These samples were then used to train and\nevaluate various Digital Signal Processing (DSP) and Machine Learning (ML)\naudio enhancement algorithms. Among the approaches explored, Dynamic Range\nCompression (DRC) proved the most effective, successfully attenuating trigger\nsounds and reducing auditory distress for neurodivergent listeners.", "published": "2025-09-12 12:51:22", "link": "http://arxiv.org/abs/2509.10202v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Towards Data Drift Monitoring for Speech Deepfake Detection in the context of MLOps", "abstract": "When being delivered in applications or services on the cloud, static speech\ndeepfake detectors that are not updated will become vulnerable to newly created\nspeech deepfake attacks. From the perspective of machine learning operations\n(MLOps), this paper tries to answer whether we can monitor new and unseen\nspeech deepfake data that drifts away from a seen reference data set. We\nfurther ask, if drift is detected, whether we can fine-tune the detector using\nsimilarly drifted data, reduce the drift, and improve the detection\nperformance. On a toy dataset and the large-scale MLAAD dataset, we show that\nthe drift caused by new text-to-speech (TTS) attacks can be monitored using\ndistances between the distributions of the new data and reference data.\nFurthermore, we demonstrate that fine-tuning the detector using data generated\nby the new TTS deepfakes can reduce the drift and the detection error rates.", "published": "2025-09-12 09:26:56", "link": "http://arxiv.org/abs/2509.10086v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Effective Modeling of Critical Contextual Information for TDNN-based Speaker Verification", "abstract": "Today, Time Delay Neural Network (TDNN) has become the mainstream\narchitecture for speaker verification task, in which the ECAPA-TDNN is one of\nthe state-of-the-art models. The current works that focus on improving TDNN\nprimarily address the limitations of TDNN in modeling global information and\nbridge the gap between TDNN and 2-Dimensional convolutions. However, the\nhierarchical convolutional structure in the SE-Res2Block proposed by ECAPA-TDNN\ncannot make full use of the contextual information, resulting in the weak\nability of ECAPA-TDNN to model effective context dependencies. To this end,\nthree improved architectures based on ECAPA-TDNN are proposed to fully and\neffectively extract multi-scale features with context dependence and then\naggregate these features. The experimental results on VoxCeleb and CN-Celeb\nverify the effectiveness of the three proposed architectures. One of these\narchitectures achieves nearly a 23% lower Equal Error Rate compared to that of\nECAPA-TDNN on VoxCeleb1-O dataset, demonstrating the competitive performance\nachievable among the current TDNN architectures under the comparable parameter\ncount.", "published": "2025-09-12 02:34:25", "link": "http://arxiv.org/abs/2509.09932v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Acoustic Scene Classification Using CNN-GRU Model Without Knowledge Distillation", "abstract": "In this technical report, we present the SNTL-NTU team's Task 1 submission\nfor the Low-Complexity Acoustic Scenes and Events (DCASE) 2025 challenge. This\nsubmission departs from the typical application of knowledge distillation from\na teacher to a student model, aiming to achieve high performance with limited\ncomplexity. The proposed model is based on a CNN-GRU model and is trained\nsolely using the TAU Urban Acoustic Scene 2022 Mobile development dataset,\nwithout utilizing any external datasets, except for MicIRP, which is used for\ndevice impulse response (DIR) augmentation. The proposed model has a memory\nusage of 114.2KB and requires 10.9M muliply-and-accumulate (MAC) operations.\nUsing the development dataset, the proposed model achieved an accuracy of\n60.25%.", "published": "2025-09-12 02:33:01", "link": "http://arxiv.org/abs/2509.09931v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Robust Localization in Modern Cellular Networks using Global Map Features", "abstract": "Radio frequency (RF) signal-based localization using modern cellular networks\nhas emerged as a promising solution to accurately locate objects in challenging\nenvironments. One of the most promising solutions for situations involving\nobstructed-line-of-sight (OLoS) and multipath propagation is multipathbased\nsimultaneous localization and mapping (MP-SLAM) that employs map features\n(MFs), such as virtual anchors. This paper presents an extended MP-SLAM method\nthat is augmented with a global map feature (GMF) repository. This repository\nstores consistent MFs of high quality that are collected during prior\ntraversals. We integrate these GMFs back into the MP-SLAM framework via a\nprobability hypothesis density (PHD) filter, which propagates GMF intensity\nfunctions over time. Extensive simulations, together with a challenging\nreal-world experiment using LTE RF signals in a dense urban scenario with\nsevere multipath propagation and inter-cell interference, demonstrate that our\nframework achieves robust and accurate localization, thereby showcasing its\neffectiveness in realistic modern cellular networks such as 5G or future 6G\nnetworks. It outperforms conventional proprioceptive sensor-based localization\nand conventional MP-SLAM methods, and achieves reliable localization even under\nadverse signal conditions.", "published": "2025-09-12 17:40:31", "link": "http://arxiv.org/abs/2509.10433v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Realistic UE Antennas for 6G in the 3GPP Channel Model", "abstract": "The transition to 6G has driven significant updates to the 3GPP channel\nmodel, particularly in modeling UE antennas and user-induced blockage for\nhandheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more\nrealistic framework that captures directive antenna patterns, practical antenna\nplacements, polarization effects, and element-specific blockage. These updates\nare based on high-fidelity simulations and measurements of a reference\nsmartphone across multiple frequency ranges. By aligning link- and system-level\nsimulations with real-world device behavior, the new model enables more\naccurate evaluation of 6G technologies and supports consistent performance\nassessment across industry and research.", "published": "2025-09-12 15:45:32", "link": "http://arxiv.org/abs/2509.10357v1", "categories": ["eess.SP", "cs.NI", "94A05, 78M31", "C.2.1; I.6.5"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Null-Space-Based Simultaneous Wireless Information and Power Transfer Scheme", "abstract": "Simultaneous wireless information and power transfer (SWIPT) has attracted\nsustained interest. We propose a null-space-based transmission scheme for\nmultiuser SWIPT serving both energy users (EUs) and information users (IUs).\nUnder a practical nonlinear energy-harvesting (EH) model and multiple waveform\noptions, we revisit the role of dedicated energy beams (EBs). We show that, in\ngeneral, dedicated EBs are unnecessary because information beams (IBs) with\nGaussian signaling can simultaneously support wireless energy transfer (WET)\nand wireless information transfer (WIT), unless special energy-centric\nwaveforms (e.g., deterministic sinusoidal waveforms) are employed and provide\nsufficient gains. Guided by these insights, we formulate an optimization\nproblem for EB design to enable dedicated waveform transmission for WET, and we\ndevelop a low-complexity algorithm that reduces computation by ignoring the WET\ncontribution of IBs during optimization. Numerical results corroborate that\ndeterministic sinusoidal waveforms outperform Gaussian signaling when the\nreceived RF power lies in the EH high-efficiency region, making dedicated EBs\nbeneficial. The proposed scheme achieves computational complexity reductions of\n91.43\\% and 98.54\\% for the cases $M=8,,K^I=K^E=2$ and $M=16,,K^I=K^E=4$,\nrespectively, with negligible performance loss, thereby validating the\nefficiency of the low-complexity algorithm.", "published": "2025-09-12 14:37:04", "link": "http://arxiv.org/abs/2509.10296v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Real-time identification and control of influential pandemic regions using graph signal variation", "abstract": "The global spread of pandemics is facilitated by the mobility of populations,\ntransforming localized infections into widespread phenomena. To contain it,\ntimely identification of influential regions that accelerate this process is\nnecessary. In this work, we model infection as a temporally evolving graph\nsignal and propose graph signal variation-based metrics to capture\nspatio-temporal changes. Both graph domain and time domain locality are\nmodeled. Based on this metric, we propose an online algorithm to identify\ninfluential regions. Simulations demonstrate that the proposed method\neffectively identifies geographical regions with a higher capacity to spread\nthe infection. Isolating these regions leads to a significant reduction in\ncumulative infection. Simulations, along with analyses of hybrid H1N1 data and\nreal-world Indian COVID-19 data, underscore the utility of proposed metric in\nenhancing our understanding and control of infection spread", "published": "2025-09-12 14:21:49", "link": "http://arxiv.org/abs/2509.10281v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration", "abstract": "The growing demand for high-speed, ultra-reliable, and low-latency\ncommunications in 5G and beyond networks has significantly driven up power\nconsumption, particularly within the Radio Access Network (RAN). This surge in\nenergy demand poses critical operational and sustainability challenges for\nmobile network operators, necessitating innovative solutions that enhance\nenergy efficiency without compromising Quality of Service (QoS). Open Radio\nAccess Network (O-RAN), spearheaded by the O-RAN Alliance, offers\ndisaggregated, programmable, and intelligent architectures, promoting\nflexibility, interoperability, and cost-effectiveness. However, this\ndisaggregated approach adds complexity, particularly in managing power\nconsumption across diverse network components such as Open Radio Units (RUs).\nIn this paper, we propose a hybrid xApp leveraging heuristic methods and\nunsupervised machine learning, integrated with digital twin technology through\nthe TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically\nmanages RU sleep modes to effectively reduce energy consumption. Our\nexperimental evaluation in a realistic, large-scale emulated Open RAN scenario\ndemonstrates that the hybrid xApp achieves approximately 13% energy savings,\nhighlighting its practicality and significant potential for real-world\ndeployments without compromising user QoS.", "published": "2025-09-12 09:39:15", "link": "http://arxiv.org/abs/2509.10097v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Resilient Vital Sign Monitoring Using RIS-Assisted Radar", "abstract": "Vital sign monitoring plays a critical role in healthcare and well-being, as\nparameters such as respiration and heart rate offer valuable insights into an\nindividual's physiological state. While wearable devices allow for continuous\nmeasurement, their use in settings like in-home elderly care is often hindered\nby discomfort or user noncompliance. As a result, contactless solutions based\non radar sensing have garnered increasing attention. This is due to their\nunobtrusive design and preservation of privacy advantages compared to\ncamera-based systems. However, a single radar perspective can fail to capture\nbreathing-induced chest movements reliably, particularly when the subject's\norientation is unfavorable. To address this limitation, we integrate a\nreconfigurable intelligent surface (RIS) that provides an additional sensing\npath, thereby enhancing the robustness of respiratory monitoring. We present a\nnovel model for multi-path vital sign sensing that leverages both the direct\nradar path and an RIS-reflected path. We further discuss the potential benefits\nand improved performance our approach offers in continuous, privacy-preserving\nvital sign monitoring.", "published": "2025-09-12 09:29:31", "link": "http://arxiv.org/abs/2509.10088v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uplink RSMA for Pinching-Antenna Systems", "abstract": "One of the key goals of next-generation wireless networks is to adapt to\nchanging conditions and meet the growing demand for reliable, high-capacity\ncommunications from emerging applications. Overcoming the limitations of\nconventional technologies, such as fixed antenna positions, is essential to\nachieving this objective because it mitigates the impact of path loss on the\nreceived signal and creates strong line-of-sight links, enhancing system\nperformance. With this in mind, the newly proposed pinching antenna systems\n(PASs) are a promising solution for indoor applications because they can\nactivate antennas across a waveguide deployed in a room, thus reducing the\ndistance between the transmitter and receiver. In this paper, we investigate a\ntwo-user, two-pinching-antenna uplink PAS, in which the transmitters use rate\nsplitting to create a more resilient framework than non-orthogonal multiple\naccess (NOMA). For this network, we derive novel closed-form expressions for\nthe outage probability. Numerical results validate these expressions, proving\nthat the proposed rate-splitting multiple access (RSMA) scheme outperforms NOMA\nPAS.", "published": "2025-09-12 09:12:18", "link": "http://arxiv.org/abs/2509.10076v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A General Nonlinear Model for Arbitrary Modulation Formats in the Presence of Inter-Channel Simulated Raman Scattering", "abstract": "The four-dimensional nonlinear model is extended to include the inter-channel\nstimulated Raman scattering, enabling accurate prediction of dual-polarization\nfour-dimensional modulation formats and probabilistically shaped constellations\nin high-dispersion regimes. The proposed model is validated via comparisons\nwith the split-step Fourier method and enhanced Gaussian noise model.", "published": "2025-09-12 07:09:12", "link": "http://arxiv.org/abs/2509.10009v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Is In-Context Learning Learning?", "abstract": "In-context learning (ICL) allows some autoregressive models to solve tasks\nvia next-token prediction and without needing further training. This has led to\nclaims about these model's ability to solve (learn) unseen tasks with only a\nfew shots (exemplars) in the prompt. However, deduction does not always imply\nlearning, as ICL does not explicitly encode a given observation. Instead, the\nmodels rely on their prior knowledge and the exemplars given, if any. We argue\nthat, mathematically, ICL does constitute learning, but its full\ncharacterisation requires empirical work. We then carry out a large-scale\nanalysis of ICL ablating out or accounting for memorisation, pretraining,\ndistributional shifts, and prompting style and phrasing. We find that ICL is an\neffective learning paradigm, but limited in its ability to learn and generalise\nto unseen tasks. We note that, in the limit where exemplars become more\nnumerous, accuracy is insensitive to exemplar distribution, model, prompt\nstyle, and the input's linguistic features. Instead, it deduces patterns from\nregularities in the prompt, which leads to distributional sensitivity,\nespecially in prompting styles such as chain-of-thought. Given the varied\naccuracies on formally similar tasks, we conclude that autoregression's ad-hoc\nencoding is not a robust mechanism, and suggests limited all-purpose\ngeneralisability.", "published": "2025-09-12 17:12:04", "link": "http://arxiv.org/abs/2509.10414v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Reliable and Interpretable Document Question Answering via VLMs", "abstract": "Vision-Language Models (VLMs) have shown strong capabilities in document\nunderstanding, particularly in identifying and extracting textual information\nfrom complex documents. Despite this, accurately localizing answers within\ndocuments remains a major challenge, limiting both interpretability and\nreal-world applicability. To address this, we introduce DocExplainerV0, a\nplug-and-play bounding-box prediction module that decouples answer generation\nfrom spatial localization. This design makes it applicable to existing VLMs,\nincluding proprietary systems where fine-tuning is not feasible. Through\nsystematic evaluation, we provide quantitative insights into the gap between\ntextual accuracy and spatial grounding, showing that correct answers often lack\nreliable localization. Our standardized framework highlights these shortcomings\nand establishes a benchmark for future research toward more interpretable and\nrobust document information extraction VLMs.", "published": "2025-09-12 10:44:24", "link": "http://arxiv.org/abs/2509.10129v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Vendi Information Gain for Active Learning and its Application to Ecology", "abstract": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. We applied VIG to the Snapshot Serengeti dataset\nand compared it against common active learning methods. VIG needs only 3% of\nthe available data to reach 75\\% accuracy, a level that baselines require more\nthan 10% of the data to achieve. With 10% of the data, VIG attains 88\\%\npredictive accuracy, 12% higher than the best of the baselines. This\nimprovement in performance is consistent across metrics and batch sizes, and we\nshow that VIG also collects more diverse data in the feature space. VIG has\nbroad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "published": "2025-09-12 16:31:16", "link": "http://arxiv.org/abs/2509.10390v2", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "primary_category": "cs.LG"}
{"title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "abstract": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "published": "2025-09-12 16:58:17", "link": "http://arxiv.org/abs/2509.10406v2", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "abstract": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "published": "2025-09-12 13:45:24", "link": "http://arxiv.org/abs/2509.10248v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "abstract": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "published": "2025-09-12 07:11:05", "link": "http://arxiv.org/abs/2509.10011v2", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Structure-Preserving High-Order Methods for the Compressible Euler Equations in Potential Temperature Formulation for Atmospheric Flows", "abstract": "We develop structure-preserving numerical methods for the compressible Euler\nequations, employing potential temperature as a prognostic variable. We\nconstruct three numerical fluxes designed to ensure the conservation of entropy\nand total energy within the discontinuous Galerkin framework on general\ncurvilinear meshes. Furthermore, we introduce a generalization for the kinetic\nenergy preservation property and total energy conservation in the presence of a\ngravitational potential term. To this end, we adopt a flux-differencing\napproach for the discretization of the source term, treated as non-conservative\nproduct. We present well-balanced schemes for different constant background\nstates for both formulations (total energy and potential temperature) on\ncurvilinear meshes. Finally, we validate the methods by comparing the potential\ntemperature formulation with the traditional Euler equations formulation across\na range of classical atmospheric scenarios.", "published": "2025-09-12 14:53:20", "link": "http://arxiv.org/abs/2509.10311v2", "categories": ["math.NA", "cs.NA", "physics.ao-ph", "physics.comp-ph", "65M12, 65M20, 65M70, 65M60, 65M06, 76U60"], "primary_category": "math.NA"}
{"title": "Realistic UE Antennas for 6G in the 3GPP Channel Model", "abstract": "The transition to 6G has driven significant updates to the 3GPP channel\nmodel, particularly in modeling UE antennas and user-induced blockage for\nhandheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more\nrealistic framework that captures directive antenna patterns, practical antenna\nplacements, polarization effects, and element-specific blockage. These updates\nare based on high-fidelity simulations and measurements of a reference\nsmartphone across multiple frequency ranges. By aligning link- and system-level\nsimulations with real-world device behavior, the new model enables more\naccurate evaluation of 6G technologies and supports consistent performance\nassessment across industry and research.", "published": "2025-09-12 15:45:32", "link": "http://arxiv.org/abs/2509.10357v2", "categories": ["eess.SP", "cs.NI", "94A05, 78M31", "C.2.1; I.6.5"], "primary_category": "eess.SP"}
{"title": "On Closure Properties of Read-Once Oblivious Algebraic Branching Programs", "abstract": "We investigate the closure properties of read-once oblivious Algebraic\nBranching Programs (roABPs) under various natural algebraic operations and\nprove the following.\n  - Non-closure under factoring: There is a sequence of explicit polynomials\n$(f_n(x_1,\\ldots, x_n))_n$ that have $\\mathsf{poly}(n)$-sized roABPs such that\nsome irreducible factor of $f_n$ does not have roABPs of superpolynomial size\nin any order.\n  - Non-closure under powering: There is a sequence of polynomials\n$(f_n(x_1,\\ldots, x_n))_n$ with $\\mathsf{poly}(n)$-sized roABPs such that any\nsuper-constant power of $f_n$ does not have roABPs of polynomial size in any\norder (and $f_n^n$ requires exponential size in any order).\n  - Non-closure under symmetric compositions: There are symmetric polynomials\n$(f_n(e_1,\\ldots, e_n))_n$ that have roABPs of polynomial size such that\n$f_n(x_1,\\ldots, x_n)$ do not have roABPs of subexponential size. (Here,\n$e_1,\\ldots, e_n$ denote the elementary symmetric polynomials in $n$\nvariables.)\n  These results should be viewed in light of known results on models such as\nalgebraic circuits, (general) algebraic branching programs, formulas and\nconstant-depth circuits, all of which are known to be closed under these\noperations.\n  To prove non-closure under factoring, we construct hard polynomials based on\nexpander graphs using gadgets that lift their hardness from sparse polynomials\nto roABPs. For symmetric compositions, we show that the circulant polynomial\nrequires roABPs of exponential size in every variable order.", "published": "2025-09-12 22:30:24", "link": "http://arxiv.org/abs/2509.10725v1", "categories": ["cs.CC", "cs.DM"], "primary_category": "cs.CC"}
{"title": "MAGNET-KG: Maximum-Entropy Geometric Networks for Temporal Knowledge Graphs: Theoretical Foundations and Mathematical Framework", "abstract": "We present a unified theoretical framework for temporal knowledge graphs\ngrounded in maximum-entropy principles, differential geometry, and information\ntheory. We prove a unique characterization of scoring functions via the\nmaximum-entropy principle and establish necessity theorems for specific\ngeometric choices. We further provide rigorous derivations of generalization\nbounds with explicit constants and outline conditions under which consistency\nguarantees hold under temporal dependence. The framework establishes principled\nfoundations for temporal knowledge graph modeling with formal connections to\ndifferential geometric methods.", "published": "2025-09-12 07:25:57", "link": "http://arxiv.org/abs/2509.10587v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Asynchronous Gathering of Opaque Robots with Mobility Faults", "abstract": "We consider the fundamental benchmarking problem of gathering in an\n$(N,f)$-fault system consisting of $N$ robots, of which at most $f$ might fail\nat any execution, under asynchrony. Two seminal results established\nimpossibility of a solution in the oblivious robot (OBLOT) model in a\n$(2,0)$-fault system under semi-synchrony and in a $(3,1)$-Byzantine fault\nsystem under asynchrony. Recently, a breakthrough result circumvented the first\nimpossibility result by giving a deterministic algorithm in a $(2,0)$-fault\nsystem under asynchrony in the luminous robot (LUMI) model using 2-colored\nlights. However, a breakthrough result established impossibility of gathering\nin a $(2,1)$-crash system in the LUMI model under semi-synchrony. In this\npaper, we consider a {\\em mobility fault} model in which a robot crash only\nimpacts it mobility but not the operation of the light.\n  We establish four results under asynchrony in LUMI with the mobility fault\nmodel. We show that it is impossible to solve gathering in a $(2,1)$-mobility\nfault system using 2-colored lights, and then give a solution using 3-colored\nlights, which is optimal w.r.t. the number of colors. We then consider an\n$(N,f)$-mobility fault system, $f<N$, both $N,f$ not known, and give two\ndeterministic algorithms that exhibit a nice time-color trade-off: The first\nwith time $O(N)$ using 7-colored lights and the second with time\n$O(\\max\\{\\ell,f\\})$ using 26-colored lights, where $\\ell< N$ is the number of\ndistinct convex layers of robot positions in the initial configuration.\nInterestingly, for $l, f = O(1)$, our result is optimal. Our algorithms for an\n$(N,f)$-mobility fault system are the first to be analysed time complexity, can\nwithstand obstructed visibility (opaque robot model) and asynchronous\nscheduling.", "published": "2025-09-12 22:05:10", "link": "http://arxiv.org/abs/2509.10711v1", "categories": ["cs.DC", "cs.MA", "cs.RO"], "primary_category": "cs.DC"}
{"title": "ZapGPT: Free-form Language Prompting for Simulated Cellular Control", "abstract": "Human language is one of the most expressive tools for conveying intent, yet\nmost artificial or biological systems lack mechanisms to interpret or respond\nmeaningfully to it. Bridging this gap could enable more natural forms of\ncontrol over complex, decentralized systems. In AI and artificial life, recent\nwork explores how language can specify high-level goals, but most systems still\ndepend on engineered rewards, task-specific supervision, or rigid command sets,\nlimiting generalization to novel instructions. Similar constraints apply in\nsynthetic biology and bioengineering, where the locus of control is often\ngenomic rather than environmental perturbation.\n  A key open question is whether artificial or biological collectives can be\nguided by free-form natural language alone, without task-specific tuning or\ncarefully designed evaluation metrics. We provide one possible answer here by\nshowing, for the first time, that simple agents' collective behavior can be\nguided by free-form language prompts: one AI model transforms an imperative\nprompt into an intervention that is applied to simulated cells; a second AI\nmodel scores how well the prompt describes the resulting cellular dynamics; and\nthe former AI model is evolved to improve the scores generated by the latter.\n  Unlike previous work, our method does not require engineered fitness\nfunctions or domain-specific prompt design. We show that the evolved system\ngeneralizes to unseen prompts without retraining. By treating natural language\nas a control layer, the system suggests a future in which spoken or written\nprompts could direct computational, robotic, or biological systems to desired\nbehaviors. This work provides a concrete step toward this vision of AI-biology\npartnerships, in which language replaces mathematical objective functions,\nfixed rules, and domain-specific programming.", "published": "2025-09-12 19:38:46", "link": "http://arxiv.org/abs/2509.10660v1", "categories": ["cs.AI", "cs.MA", "q-bio.CB"], "primary_category": "cs.AI"}
{"title": "Combined perturbation bounds for eigenstructure of Hermitian matrices and singular structure of general matrices", "abstract": "Combined perturbation bounds are presented for eigenvalues and eigenspaces of\nHermitian matrices or singular values and singular subspaces of general\nmatrices. The bounds are derived based on the smooth decompositions and\nelementary calculus techniques.", "published": "2025-09-12 20:44:56", "link": "http://arxiv.org/abs/2509.10688v1", "categories": ["math.NA", "cs.NA", "65F15, 65F99"], "primary_category": "math.NA"}
{"title": "Invariant subspace perturbations related to defective eigenvalues of $\u0394$-Hermitian and Hamiltonian matrices", "abstract": "Structured perturbation results for invariant subspaces of $\\Delta$-Hermitian\nand Hamiltonian matrices are provided. The invariant subspaces under\nconsideration are associated with the eigenvalues perturbed from a single\ndefective eigenvalue. The results show how the original eigenvectors and\ngeneralized eigenvectors are involved in composing such perturbed invariant\nsubspaces and eigenvectors.", "published": "2025-09-12 19:09:57", "link": "http://arxiv.org/abs/2509.10643v1", "categories": ["math.NA", "cs.NA", "15A18, 47A55, 65F15"], "primary_category": "math.NA"}
{"title": "Learning Concave Bid Shading Strategies in Online Auctions via Measure-valued Proximal Optimization", "abstract": "This work proposes a bid shading strategy for first-price auctions as a\nmeasure-valued optimization problem. We consider a standard parametric form for\nbid shading and formulate the problem as convex optimization over the joint\ndistribution of shading parameters. After each auction, the shading parameter\ndistribution is adapted via a regularized Wasserstein-proximal update with a\ndata-driven energy functional. This energy functional is conditional on the\ncontext, i.e., on publisher/user attributes such as domain, ad slot type,\ndevice, or location. The proposed algorithm encourages the bid distribution to\nplace more weight on values with higher expected surplus, i.e., where the win\nprobability and the value gap are both large. We show that the resulting\nmeasure-valued convex optimization problem admits a closed form solution. A\nnumerical example illustrates the proposed method.", "published": "2025-09-12 21:11:06", "link": "http://arxiv.org/abs/2509.10693v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Interpretable neural network system identification method for two families of second-order systems based on characteristic curves", "abstract": "Nonlinear system identification often involves a fundamental trade-off\nbetween interpretability and flexibility, often requiring the incorporation of\nphysical constraints. We propose a unified data-driven framework that combines\nthe mathematical structure of the governing differential equations with the\nflexibility of neural networks (NNs). At the core of our approach is the\nconcept of characteristic curves (CCs), which represent individual nonlinear\nfunctions (e.g., friction and restoring components) of the system. Each CC is\nmodeled by a dedicated NN, enabling a modular and interpretable representation\nof the system equation. To demonstrate the versatility of the CC-based\nformalism, we introduce three identification strategies: (1) SINDy-CC, which\nextends the sparse regression approach of SINDy by incorporating the\nmathematical structure of the governing equations as constraints; (2) Poly-CC,\nwhich represents each CC using high-degree polynomials; and (3) NN-CC, which\nuses NNs without requiring prior assumptions about basis functions. Our results\nshow that all three approaches are well-suited for systems with simple\npolynomial nonlinearities, such as the van der Pol oscillator. In contrast,\nNN-CC demonstrates superior performance in modeling systems with complex\nnonlinearities and discontinuities, such as those observed in stick-slip\nsystems. The key contribution of this work is to demonstrate that the CC-based\nframework, particularly the NN-CC approach, can capture complex nonlinearities\nwhile maintaining interpretability through the explicit representation of the\nCCs. This balance makes it well-suited for modeling systems with\ndiscontinuities and complex nonlinearities that are challenging to assess using\ntraditional polynomial or sparse regression methods, providing a powerful tool\nfor nonlinear system identification.", "published": "2025-09-12 18:32:02", "link": "http://arxiv.org/abs/2509.10632v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Optimal Multimarginal Schr\u00f6dinger Bridge: Minimum Spanning Tree over Measure-valued Vertices", "abstract": "The Multimarginal Schr\\\"odinger Bridge (MSB) finds the optimal coupling among\na collection of random vectors with known statistics and a known correlation\nstructure. In the MSB formulation, this correlation structure is specified\n\\emph{a priori} as an undirected connected graph with measure-valued vertices.\nIn this work, we formulate and solve the problem of finding the optimal MSB in\nthe sense we seek the optimal coupling over all possible graph structures. We\nfind that computing the optimal MSB amounts to solving the minimum spanning\ntree problem over measure-valued vertices. We show that the resulting problem\ncan be solved in two steps. The first step constructs a complete graph with\nedge weight equal to a sum of the optimal value of the corresponding bimarginal\nSB and the entropies of the endpoints. The second step solves a standard\nminimum spanning tree problem over that complete weighted graph. Numerical\nexperiments illustrate the proposed solution.", "published": "2025-09-12 18:15:42", "link": "http://arxiv.org/abs/2509.10626v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "pySigLib -- Fast Signature-Based Computations on CPU and GPU", "abstract": "Signature-based methods have recently gained significant traction in machine\nlearning for sequential data. In particular, signature kernels have emerged as\npowerful discriminators and training losses for generative models on\ntime-series, notably in quantitative finance. However, existing implementations\ndo not scale to the dataset sizes and sequence lengths encountered in practice.\nWe present pySigLib, a high-performance Python library offering optimised\nimplementations of signatures and signature kernels on CPU and GPU, fully\ncompatible with PyTorch's automatic differentiation. Beyond an efficient\nsoftware stack for large-scale signature-based computation, we introduce a\nnovel differentiation scheme for signature kernels that delivers accurate\ngradients at a fraction of the runtime of existing libraries.", "published": "2025-09-12 18:00:14", "link": "http://arxiv.org/abs/2509.10613v1", "categories": ["cs.LG", "cs.MS", "stat.ML", "60L10, 65Y05, 68T99"], "primary_category": "cs.LG"}
{"title": "Sound Matching an Analogue Levelling Amplifier Using the Newton-Raphson Method", "abstract": "Automatic differentiation through digital signal processing algorithms for\nvirtual analogue modelling has recently gained popularity. These algorithms are\ntypically more computationally efficient than black-box neural networks that\nrely on dense matrix multiplications. Due to their differentiable nature, they\ncan be integrated with neural networks and jointly trained using gradient\ndescent algorithms, resulting in more efficient systems. Furthermore, signal\nprocessing algorithms have significantly fewer parameters than neural networks,\nallowing the application of the Newton-Raphson method. This method offers\nfaster and more robust convergence than gradient descent at the cost of\nquadratic storage. This paper presents a method to emulate analogue levelling\namplifiers using a feed-forward digital compressor with parameters optimised\nvia the Newton-Raphson method. We demonstrate that a digital compressor can\nsuccessfully approximate the behaviour of our target unit, the Teletronix\nLA-2A. Different strategies for computing the Hessian matrix are benchmarked.\nWe leverage parallel algorithms for recursive filters to achieve efficient\ntraining on modern GPUs. The resulting model is made into a VST plugin and is\nopen-sourced at https://github.com/aim-qmul/4a2a.", "published": "2025-09-12 21:48:30", "link": "http://arxiv.org/abs/2509.10706v1", "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SY"], "primary_category": "eess.AS"}
{"title": "Quasi-Deterministic Modeling of Sub-THz Band Access Channels in Street Canyon Environments", "abstract": "Sub-terahertz (sub-THz) frequencies (100--300 GHz) are expected to play a key\nrole in beyond-5G and 6G mobile networks. However, their quasi-optical\npropagation characteristics require new channel models beyond sub-100 GHz\nextrapolations. This paper presents an extensive double-directional (D-D)\nchannel measurement campaign conducted in an outdoor street-canyon environment\nat 154 GHz and 300 GHz under both line-of-sight (LoS) and non-line-of-sight\n(NLoS) conditions using an in-house-developed channel sounder. Based on these\nmeasurements, clustering with merged datasets across the two frequencies\nenables comparative analyses that identify both common and distinct multipath\nclusters, as well as the frequency dependence of cluster-level characteristics.\nA quasi-deterministic (QD) channel model is then proposed, combining\ndeterministic components, such as LoS and single-bounce reflections from side\nwalls, with random components. Large-scale parameters (path loss, delay spread,\nangular spread, and Rician K-factor) are also evaluated. These results provide\nvaluable insights into sub-THz propagation in urban street canyons and\ncontribute toward the development of accurate, channel models for future 6G\nsystems.", "published": "2025-09-12 23:44:10", "link": "http://arxiv.org/abs/2509.10752v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uplink and Downlink Communications in Segmented Waveguide-Enabled Pinching-Antenna Systems (SWANs)", "abstract": "A segmented waveguide-enabled pinching-antenna system (SWAN) is proposed, in\nwhich a segmented waveguide composed of multiple short dielectric waveguide\nsegments is employed to radiate or receive signals through the pinching\nantennas (PAs) deployed on each segment. Based on this architecture, three\npractical operating protocols are proposed: segment selection (SS), segment\naggregation (SA), and segment multiplexing (SM). For uplink SWAN\ncommunications, where one PA is activated per segment, the segmented structure\neliminates the inter-antenna radiation effect, i.e., signals captured by one PA\nmay re-radiate through other PAs along the same waveguide. This yields a\ntractable and physically consistent uplink signal model for a multi-PA\npinching-antenna system (PASS), which has not been established for conventional\nPASS using a single long waveguide. Building on this model, PA placement\nalgorithms are proposed to maximize the uplink signal-to-noise ratio (SNR).\nClosed-form expressions for the received SNR under the three protocols are\nderived, and the corresponding scaling laws with respect to the number of\nsegments are analyzed. It is proven that the segmented architecture reduces\nboth the average PA-to-user distance and the PA-to-feed distance, thereby\nmitigating both large-scale path loss and in-waveguide propagation loss. These\nresults are extended to downlink SWAN communications, where multiple PAs are\nactivated per segment, and PA placement methods are proposed to maximize the\ndownlink received SNR under the three protocols. Numerical results demonstrate\nthat: \\romannumeral1) among the three protocols, SM achieves the best\nperformance, followed by SA and then SS; and \\romannumeral2) for all protocols,\nthe proposed SWAN achieves a higher SNR than conventional PASS with a single\nlong waveguide in both uplink and downlink scenarios.", "published": "2025-09-12 19:45:29", "link": "http://arxiv.org/abs/2509.10666v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Vendi Information Gain for Active Learning and its Application to Ecology", "abstract": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. We applied VIG to the Snapshot Serengeti dataset\nand compared it against common active learning methods. VIG needs only 3% of\nthe available data to reach 75% accuracy, a level that baselines require more\nthan 10% of the data to achieve. With 10% of the data, VIG attains 88%\npredictive accuracy, 12% higher than the best of the baselines. This\nimprovement in performance is consistent across metrics and batch sizes, and we\nshow that VIG also collects more diverse data in the feature space. VIG has\nbroad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "published": "2025-09-12 16:31:16", "link": "http://arxiv.org/abs/2509.10390v3", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "primary_category": "cs.LG"}
{"title": "An Adaptive CMSA for Solving the Longest Filled Common Subsequence Problem with an Application in Audio Querying", "abstract": "This paper addresses the Longest Filled Common Subsequence (LFCS) problem, a\nchallenging NP-hard problem with applications in bioinformatics, including gene\nmutation prediction and genomic data reconstruction. Existing approaches,\nincluding exact, metaheuristic, and approximation algorithms, have primarily\nbeen evaluated on small-sized instances, which offer limited insights into\ntheir scalability. In this work, we introduce a new benchmark dataset with\nsignificantly larger instances and demonstrate that existing datasets lack the\ndiscriminative power needed to meaningfully assess algorithm performance at\nscale. To solve large instances efficiently, we utilize an adaptive Construct,\nMerge, Solve, Adapt (CMSA) framework that iteratively generates promising\nsubproblems via component-based construction and refines them using feedback\nfrom prior iterations. Subproblems are solved using an external black-box\nsolver. Extensive experiments on both standard and newly introduced benchmarks\nshow that the proposed adaptive CMSA achieves state-of-the-art performance,\noutperforming five leading methods. Notably, on 1,510 problem instances with\nknown optimal solutions, our approach solves 1,486 of them -- achieving over\n99.9% optimal solution quality and demonstrating exceptional scalability. We\nadditionally propose a novel application of LFCS for song identification from\ndegraded audio excerpts as an engineering contribution, using real-world\nenergy-profile instances from popular music. Finally, we conducted an empirical\nexplainability analysis to identify critical feature combinations influencing\nalgorithm performance, i.e., the key problem features contributing to success\nor failure of the approaches across different instance types are revealed.", "published": "2025-09-12 19:17:09", "link": "http://arxiv.org/abs/2509.12261v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training", "abstract": "Trajectory prediction is a critical component of autonomous driving,\nessential for ensuring both safety and efficiency on the road. However,\ntraditional approaches often struggle with the scarcity of labeled data and\nexhibit suboptimal performance in multi-agent prediction scenarios. To address\nthese challenges, we introduce a disentangled context-aware pre-training\nframework for multi-agent motion prediction, named DECAMP. Unlike existing\nmethods that entangle representation learning with pretext tasks, our framework\ndecouples behavior pattern learning from latent feature reconstruction,\nprioritizing interpretable dynamics and thereby enhancing scene representation\nfor downstream prediction. Additionally, our framework incorporates\ncontext-aware representation learning alongside collaborative spatial-motion\npretext tasks, which enables joint optimization of structural and intentional\nreasoning while capturing the underlying dynamic intentions. Our experiments on\nthe Argoverse 2 benchmark showcase the superior performance of our method, and\nthe results attained underscore its effectiveness in multi-agent motion\nforecasting. To the best of our knowledge, this is the first context\nautoencoder framework for multi-agent motion forecasting in autonomous driving.\nThe code and models will be made publicly available.", "published": "2025-09-12 17:29:02", "link": "http://arxiv.org/abs/2509.10426v2", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "All Models Are Wrong, But Can They Be Useful? Lessons from COVID-19 Agent-Based Models: A Systematic Review", "abstract": "The COVID-19 pandemic prompted a surge in computational models to simulate\ndisease dynamics and guide interventions. Agent-based models (ABMs) are\nwell-suited to capture population and environmental heterogeneity, but their\nrapid deployment raised questions about utility for health policy. We\nsystematically reviewed 536 COVID-19 ABM studies published from January 2020 to\nDecember 2023, retrieved from Web of Science, PubMed, and Wiley on January 30,\n2024. Studies were included if they used ABMs to simulate COVID-19\ntransmission, where reviews were excluded. Studies were assessed against nine\ncriteria of model usefulness, including transparency and re-use,\ninterdisciplinary collaboration and stakeholder engagement, and evaluation\npractices. Publications peaked in late 2021 and were concentrated in a few\ncountries. Most models explored behavioral or policy interventions (n = 294,\n54.85%) rather than real-time forecasting (n = 9, 1.68%). While most described\nmodel assumptions (n = 491, 91.60%), fewer disclosed limitations (n = 349,\n65.11%), shared code (n = 219, 40.86%), or built on existing models (n = 195,\n36.38%). Standardized reporting protocols (n = 36, 6.72%) and stakeholder\nengagement were rare (13.62%, n = 73). Only 2.24% (n = 12) described a\ncomprehensive validation framework, though uncertainty was often quantified (n\n= 407, 75.93%). Limitations of this review include underrepresentation of\nnon-English studies, subjective data extraction, variability in study quality,\nand limited generalizability. Overall, COVID-19 ABMs advanced quickly, but\nlacked transparency, accessibility, and participatory engagement. Stronger\nstandards are needed for ABMs to serve as reliable decision-support tools in\nfuture public health crises.", "published": "2025-09-12 21:16:50", "link": "http://arxiv.org/abs/2509.13346v1", "categories": ["cs.MA", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Optimized Operation of Standalone Battery Energy Storage Systems in the Cross-Market Energy Arbitrage Business", "abstract": "The provision of renewable electricity is the foundation for a sustainable\nfuture. To achieve the goal of sustainable renewable energy, Battery Energy\nStorage Systems (BESS) could play a key role to counteract the intermittency of\nsolar and wind generation power. In order to aid the system, the BESS can\nsimply charge at low wholesale prices and discharge during high prices, which\nis also called energy arbitrage. However, the real-time execution of energy\narbitrage is not straightforward for many companies due to the fundamentally\ndifferent behavior of storages compared to conventional power plants. In this\nwork, the optimized operation of standalone BESS in the cross-market energy\narbitrage business is addressed by describing a generic framework for trading\nintegrated BESS operation, the development of a suitable backtest engine and a\nspecific optimization-based strategy formulation for cross-market optimized\nBESS operation. In addition, this strategy is tested in a case study with a\nsensitivity analysis to investigate the influence of forecast uncertainty. The\nresults show that the proposed strategy allows an increment in revenues by\ntaking advantage of the increasing market volatility. Furthermore, the\nsensitivity analysis shows the robustness of the proposed strategy, as only a\nmoderate portion of revenues will be lost if real forecasts are adopted.", "published": "2025-09-12 11:35:12", "link": "http://arxiv.org/abs/2509.21337v1", "categories": ["q-fin.TR", "cs.SY", "eess.SY"], "primary_category": "q-fin.TR"}
