{"title": "How to Do Things with Deep Learning Code", "abstract": "The premise of this article is that a basic understanding of the composition\nand functioning of large language models is critically urgent. To that end, we\nextract a representational map of OpenAI's GPT-2 with what we articulate as two\nclasses of deep learning code, that which pertains to the model and that which\nunderwrites applications built around the model. We then verify this map\nthrough case studies of two popular GPT-2 applications: the text adventure\ngame, AI Dungeon, and the language art project, This Word Does Not Exist. Such\nan exercise allows us to test the potential of Critical Code Studies when the\nobject of study is deep learning code and to demonstrate the validity of code\nas an analytical focus for researchers in the subfields of Critical Artificial\nIntelligence and Critical Machine Learning Studies. More broadly, however, our\nwork draws attention to the means by which ordinary users might interact with,\nand even direct, the behavior of deep learning systems, and by extension works\ntoward demystifying some of the auratic mystery of \"AI.\" What is at stake is\nthe possibility of achieving an informed sociotechnical consensus about the\nresponsible applications of large language models, as well as a more expansive\nsense of their creative capabilities-indeed, understanding how and where\nengagement occurs allows all of us to become more active participants in the\ndevelopment of machine learning systems.", "published": "2023-04-19 03:46:12", "link": "http://arxiv.org/abs/2304.09406v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models Enable Simple Systems for Generating Structured Views of\n  Heterogeneous Data Lakes", "abstract": "A long standing goal of the data management community is to develop general,\nautomated systems that ingest semi-structured documents and output queryable\ntables without human effort or domain specific customization. Given the sheer\nvariety of potential documents, state-of-the art systems make simplifying\nassumptions and use domain specific training. In this work, we ask whether we\ncan maintain generality by using large language models (LLMs). LLMs, which are\npretrained on broad data, can perform diverse downstream tasks simply\nconditioned on natural language task descriptions.\n  We propose and evaluate EVAPORATE, a simple, prototype system powered by\nLLMs. We identify two fundamentally different strategies for implementing this\nsystem: prompt the LLM to directly extract values from documents or prompt the\nLLM to synthesize code that performs the extraction. Our evaluations show a\ncost-quality tradeoff between these two approaches. Code synthesis is cheap,\nbut far less accurate than directly processing each document with the LLM. To\nimprove quality while maintaining low cost, we propose an extended code\nsynthesis implementation, EVAPORATE-CODE+, which achieves better quality than\ndirect extraction. Our key insight is to generate many candidate functions and\nensemble their extractions using weak supervision. EVAPORATE-CODE+ not only\noutperforms the state-of-the art systems, but does so using a sublinear pass\nover the documents with the LLM. This equates to a 110x reduction in the number\nof tokens the LLM needs to process, averaged across 16 real-world evaluation\nsettings of 10k documents each.", "published": "2023-04-19 06:00:26", "link": "http://arxiv.org/abs/2304.09433v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling keywords and their positions in text generation", "abstract": "One of the challenges in text generation is to control text generation as\nintended by the user. Previous studies proposed specifying the keywords that\nshould be included in the generated text. However, this approach is\ninsufficient to generate text that reflect the user's intent. For example,\nplacing an important keyword at the beginning of the text would help attract\nthe reader's attention; however, existing methods do not enable such flexible\ncontrol. In this paper, we tackle a novel task of controlling not only keywords\nbut also the position of each keyword in the text generation. To this end, we\npropose a task-independent method that uses special tokens to control the\nrelative position of keywords. Experimental results on summarization and story\ngeneration tasks show that the proposed method can control keywords and their\npositions. The experimental results also demonstrate that controlling the\nkeyword positions can generate summary texts that are closer to the user's\nintent than baseline.", "published": "2023-04-19 09:11:45", "link": "http://arxiv.org/abs/2304.09516v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model,\n  Data, and Training", "abstract": "Aspect-based sentiment analysis (ABSA) aims at automatically inferring the\nspecific sentiment polarities toward certain aspects of products or services\nbehind the social media texts or reviews, which has been a fundamental\napplication to the real-world society. Since the early 2010s, ABSA has achieved\nextraordinarily high accuracy with various deep neural models. However,\nexisting ABSA models with strong in-house performances may fail to generalize\nto some challenging cases where the contexts are variable, i.e., low robustness\nto real-world environments. In this study, we propose to enhance the ABSA\nrobustness by systematically rethinking the bottlenecks from all possible\nangles, including model, data, and training. First, we strengthen the current\nbest-robust syntax-aware models by further incorporating the rich external\nsyntactic dependencies and the labels with aspect simultaneously with a\nuniversal-syntax graph convolutional network. In the corpus perspective, we\npropose to automatically induce high-quality synthetic training data with\nvarious types, allowing models to learn sufficient inductive bias for better\nrobustness. Last, we based on the rich pseudo data perform adversarial training\nto enhance the resistance to the context perturbation and meanwhile employ\ncontrastive learning to reinforce the representations of instances with\ncontrastive sentiments. Extensive robustness evaluations are conducted. The\nresults demonstrate that our enhanced syntax-aware model achieves better\nrobustness performances than all the state-of-the-art baselines. By\nadditionally incorporating our synthetic corpus, the robust testing results are\npushed with around 10% accuracy, which are then further improved by installing\nthe advanced training strategies. In-depth analyses are presented for revealing\nthe factors influencing the ABSA robustness.", "published": "2023-04-19 11:07:43", "link": "http://arxiv.org/abs/2304.09563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT Equipped with Emotional Dialogue Capabilities?", "abstract": "This report presents a study on the emotional dialogue capability of ChatGPT,\nan advanced language model developed by OpenAI. The study evaluates the\nperformance of ChatGPT on emotional dialogue understanding and generation\nthrough a series of experiments on several downstream tasks. Our findings\nindicate that while ChatGPT's performance on emotional dialogue understanding\nmay still lag behind that of supervised models, it exhibits promising results\nin generating emotional responses. Furthermore, the study suggests potential\navenues for future research directions.", "published": "2023-04-19 11:42:40", "link": "http://arxiv.org/abs/2304.09582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Natural Language Processing and Psycholinguistics:\n  computationally grounded semantic similarity datasets for Basque and Spanish", "abstract": "We present a computationally-grounded word similarity dataset based on two\nwell-known Natural Language Processing resources; text corpora and knowledge\nbases. This dataset aims to fulfil a gap in psycholinguistic research by\nproviding a variety of quantifications of semantic similarity in an extensive\nset of noun pairs controlled by variables that play a significant role in\nlexical processing. The dataset creation has consisted in three steps, 1)\ncomputing four key psycholinguistic features for each noun; concreteness,\nfrequency, semantic and phonological neighbourhood density; 2) pairing nouns\nacross these four variables; 3) for each noun pair, assigning three types of\nword similarity measurements, computed out of text, Wordnet and hybrid\nembeddings. The present dataset includes noun pairs' information in Basque and\nEuropean Spanish, but further work intends to extend it to more languages.", "published": "2023-04-19 12:47:51", "link": "http://arxiv.org/abs/2304.09616v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BRENT: Bidirectional Retrieval Enhanced Norwegian Transformer", "abstract": "Retrieval-based language models are increasingly employed in\nquestion-answering tasks. These models search in a corpus of documents for\nrelevant information instead of having all factual knowledge stored in its\nparameters, thereby enhancing efficiency, transparency, and adaptability. We\ndevelop the first Norwegian retrieval-based model by adapting the REALM\nframework and evaluating it on various tasks. After training, we also separate\nthe language model, which we call the reader, from the retriever components,\nand show that this can be fine-tuned on a range of downstream tasks. Results\nshow that retrieval augmented language modeling improves the reader's\nperformance on extractive question-answering, suggesting that this type of\ntraining improves language models' general ability to use context and that this\ndoes not happen at the expense of other abilities such as part-of-speech\ntagging, dependency parsing, named entity recognition, and lemmatization. Code,\ntrained models, and data are made publicly available.", "published": "2023-04-19 13:40:47", "link": "http://arxiv.org/abs/2304.09649v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MPMQA: Multimodal Question Answering on Product Manuals", "abstract": "Visual contents, such as illustrations and images, play a big role in product\nmanual understanding. Existing Product Manual Question Answering (PMQA)\ndatasets tend to ignore visual contents and only retain textual parts. In this\nwork, to emphasize the importance of multimodal contents, we propose a\nMultimodal Product Manual Question Answering (MPMQA) task. For each question,\nMPMQA requires the model not only to process multimodal contents but also to\nprovide multimodal answers. To support MPMQA, a large-scale dataset PM209 is\nconstructed with human annotations, which contains 209 product manuals from 27\nwell-known consumer electronic brands. Human annotations include 6 types of\nsemantic regions for manual contents and 22,021 pairs of question and answer.\nEspecially, each answer consists of a textual sentence and related visual\nregions from manuals. Taking into account the length of product manuals and the\nfact that a question is always related to a small number of pages, MPMQA can be\nnaturally split into two subtasks: retrieving most related pages and then\ngenerating multimodal answers. We further propose a unified model that can\nperform these two subtasks all together and achieve comparable performance with\nmultiple task-specific models. The PM209 dataset is available at\nhttps://github.com/AIM3-RUC/MPMQA.", "published": "2023-04-19 13:48:14", "link": "http://arxiv.org/abs/2304.09660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Corpora for Germanic Low-Resource Languages and Dialects", "abstract": "Despite much progress in recent years, the vast majority of work in natural\nlanguage processing (NLP) is on standard languages with many speakers. In this\nwork, we instead focus on low-resource languages and in particular\nnon-standardized low-resource languages. Even within branches of major language\nfamilies, often considered well-researched, little is known about the extent\nand type of available resources and what the major NLP challenges are for these\nlanguage varieties. The first step to address this situation is a systematic\nsurvey of available corpora (most importantly, annotated corpora, which are\nparticularly valuable for NLP research). Focusing on Germanic low-resource\nlanguage varieties, we provide such a survey in this paper. Except for\ngeolocation (origin of speaker or document), we find that manually annotated\nlinguistic resources are sparse and, if they exist, mostly cover morphosyntax.\nDespite this lack of resources, we observe that interest in this area is\nincreasing: there is active development and a growing research community. To\nfacilitate research, we make our overview of over 80 corpora publicly\navailable. We share a companion website of this overview at\nhttps://github.com/mainlp/germanic-lrl-corpora .", "published": "2023-04-19 16:45:16", "link": "http://arxiv.org/abs/2304.09805v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low-resource Bilingual Dialect Lexicon Induction with Large Language\n  Models", "abstract": "Bilingual word lexicons are crucial tools for multilingual natural language\nunderstanding and machine translation tasks, as they facilitate the mapping of\nwords in one language to their synonyms in another language. To achieve this,\nnumerous papers have explored bilingual lexicon induction (BLI) in\nhigh-resource scenarios, using a typical pipeline consisting of two\nunsupervised steps: bitext mining and word alignment, both of which rely on\npre-trained large language models~(LLMs).\n  In this paper, we present an analysis of the BLI pipeline for German and two\nof its dialects, Bavarian and Alemannic. This setup poses several unique\nchallenges, including the scarcity of resources, the relatedness of the\nlanguages, and the lack of standardization in the orthography of dialects. To\nevaluate the BLI outputs, we analyze them with respect to word frequency and\npairwise edit distance. Additionally, we release two evaluation datasets\ncomprising 1,500 bilingual sentence pairs and 1,000 bilingual word pairs. They\nwere manually judged for their semantic similarity for each Bavarian-German and\nAlemannic-German language pair.", "published": "2023-04-19 20:20:41", "link": "http://arxiv.org/abs/2304.09957v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MasakhaNEWS: News Topic Classification for African languages", "abstract": "African languages are severely under-represented in NLP research due to lack\nof datasets covering several NLP tasks. While there are individual language\nspecific datasets that are being expanded to different tasks, only a handful of\nNLP tasks (e.g. named entity recognition and machine translation) have\nstandardized benchmark datasets covering several geographical and\ntypologically-diverse African languages. In this paper, we develop MasakhaNEWS\n-- a new benchmark dataset for news topic classification covering 16 languages\nwidely spoken in Africa. We provide an evaluation of baseline models by\ntraining classical machine learning models and fine-tuning several language\nmodels. Furthermore, we explore several alternatives to full fine-tuning of\nlanguage models that are better suited for zero-shot and few-shot learning such\nas cross-lingual parameter-efficient fine-tuning (like MAD-X), pattern\nexploiting training (PET), prompting language models (like ChatGPT), and\nprompt-free sentence transformer fine-tuning (SetFit and Cohere Embedding API).\nOur evaluation in zero-shot setting shows the potential of prompting ChatGPT\nfor news topic classification in low-resource African languages, achieving an\naverage performance of 70 F1 points without leveraging additional supervision\nlike MAD-X. In few-shot setting, we show that with as little as 10 examples per\nlabel, we achieved more than 90\\% (i.e. 86.0 F1 points) of the performance of\nfull supervised training (92.6 F1 points) leveraging the PET approach.", "published": "2023-04-19 21:12:23", "link": "http://arxiv.org/abs/2304.09972v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Radar de Parit\u00e9: An NLP system to measure gender representation in\n  French news stories", "abstract": "We present the Radar de Parit\\'e, an automated Natural Language Processing\n(NLP) system that measures the proportion of women and men quoted daily in six\nCanadian French-language media outlets. We outline the system's architecture\nand detail the challenges we overcame to address French-specific issues, in\nparticular regarding coreference resolution, a new contribution to the NLP\nliterature on French. We also showcase statistics covering over one year's\nworth of data (282,512 news articles). Our results highlight the\nunderrepresentation of women in news stories, while also illustrating the\napplication of modern NLP methods to measure gender representation and address\nsocietal issues.", "published": "2023-04-19 21:33:59", "link": "http://arxiv.org/abs/2304.09982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shuffle & Divide: Contrastive Learning for Long Text", "abstract": "We propose a self-supervised learning method for long text documents based on\ncontrastive learning. A key to our method is Shuffle and Divide (SaD), a simple\ntext augmentation algorithm that sets up a pretext task required for\ncontrastive updates to BERT-based document embedding. SaD splits a document\ninto two sub-documents containing randomly shuffled words in the entire\ndocuments. The sub-documents are considered positive examples, leaving all\nother documents in the corpus as negatives. After SaD, we repeat the\ncontrastive update and clustering phases until convergence. It is naturally a\ntime-consuming, cumbersome task to label text documents, and our method can\nhelp alleviate human efforts, which are most expensive resources in AI. We have\nempirically evaluated our method by performing unsupervised text classification\non the 20 Newsgroups, Reuters-21578, BBC, and BBCSport datasets. In particular,\nour method pushes the current state-of-the-art, SS-SB-MT, on 20 Newsgroups by\n20.94% in accuracy. We also achieve the state-of-the-art performance on\nReuters-21578 and exceptionally-high accuracy performances (over 95%) for\nunsupervised classification on the BBC and BBCSport datasets.", "published": "2023-04-19 02:02:29", "link": "http://arxiv.org/abs/2304.09374v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Leveraging Knowledge Distillation for Compressing\n  Multilingual Neural Machine Translation Models", "abstract": "Knowledge distillation (KD) is a well-known method for compressing neural\nmodels. However, works focusing on distilling knowledge from large multilingual\nneural machine translation (MNMT) models into smaller ones are practically\nnonexistent, despite the popularity and superiority of MNMT. This paper bridges\nthis gap by presenting an empirical investigation of knowledge distillation for\ncompressing MNMT models. We take Indic to English translation as a case study\nand demonstrate that commonly used language-agnostic and language-aware KD\napproaches yield models that are 4-5x smaller but also suffer from performance\ndrops of up to 3.5 BLEU. To mitigate this, we then experiment with design\nconsiderations such as shallower versus deeper models, heavy parameter sharing,\nmulti-stage training, and adapters. We observe that deeper compact models tend\nto be as good as shallower non-compact ones, and that fine-tuning a distilled\nmodel on a High-Quality subset slightly boosts translation quality. Overall, we\nconclude that compressing MNMT models via KD is challenging, indicating immense\nscope for further research.", "published": "2023-04-19 02:57:55", "link": "http://arxiv.org/abs/2304.09388v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MixPro: Simple yet Effective Data Augmentation for Prompt-based Learning", "abstract": "Prompt-based learning has shown considerable promise in reformulating various\ndownstream tasks as cloze problems by combining original input with a\npredetermined template. This approach demonstrates its effectiveness,\nespecially in few-shot learning scenarios, where the model is trained on a\nscarce amount of data. Despite its successes, the limited templates and text in\nfew-shot prompt-based learning scenarios leave significant room for performance\nimprovement. Moreover, existing methods sometimes resort to model ensembles,\nwhich, while effective, could potentially hamper model efficiency due to\nincreased computational demands. To address these issues, we introduce MixPro,\nan augmentation method designed to augment both the vanilla input text and the\ntemplates. We implement this through the token-level, the sentence-level, and\nthe template-level Mixup strategies. The experimental results on five few-shot\ndatasets show that MixPro outperforms other augmentation baselines, improving\nmodel performance by an average of 5.08% compared to before augmentation.", "published": "2023-04-19 03:38:25", "link": "http://arxiv.org/abs/2304.09402v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emotion fusion for mental illness detection from social media: A survey", "abstract": "Mental illnesses are one of the most prevalent public health problems\nworldwide, which negatively influence people's lives and society's health. With\nthe increasing popularity of social media, there has been a growing research\ninterest in the early detection of mental illness by analysing user-generated\nposts on social media. According to the correlation between emotions and mental\nillness, leveraging and fusing emotion information has developed into a\nvaluable research topic. In this article, we provide a comprehensive survey of\napproaches to mental illness detection in social media that incorporate emotion\nfusion. We begin by reviewing different fusion strategies, along with their\nadvantages and disadvantages. Subsequently, we discuss the major challenges\nfaced by researchers working in this area, including issues surrounding the\navailability and quality of datasets, the performance of algorithms and\ninterpretability. We additionally suggest some potential directions for future\nresearch.", "published": "2023-04-19 08:28:34", "link": "http://arxiv.org/abs/2304.09493v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT Good at Search? Investigating Large Language Models as\n  Re-Ranking Agents", "abstract": "Large Language Models (LLMs) have demonstrated remarkable zero-shot\ngeneralization across various language-related tasks, including search engines.\nHowever, existing work utilizes the generative ability of LLMs for Information\nRetrieval (IR) rather than direct passage ranking. The discrepancy between the\npre-training objectives of LLMs and the ranking objective poses another\nchallenge. In this paper, we first investigate generative LLMs such as ChatGPT\nand GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal\nthat properly instructed LLMs can deliver competitive, even superior results to\nstate-of-the-art supervised methods on popular IR benchmarks. Furthermore, to\naddress concerns about data contamination of LLMs, we collect a new test set\ncalled NovelEval, based on the latest knowledge and aiming to verify the\nmodel's ability to rank unknown knowledge. Finally, to improve efficiency in\nreal-world applications, we delve into the potential for distilling the ranking\ncapabilities of ChatGPT into small specialized models using a permutation\ndistillation scheme. Our evaluation results turn out that a distilled 440M\nmodel outperforms a 3B supervised model on the BEIR benchmark. The code to\nreproduce our results is available at www.github.com/sunnweiwei/RankGPT.", "published": "2023-04-19 10:16:03", "link": "http://arxiv.org/abs/2304.09542v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Progressive-Hint Prompting Improves Reasoning in Large Language Models", "abstract": "The performance of Large Language Models (LLMs) in reasoning tasks depends\nheavily on prompt design, with Chain-of-Thought (CoT) and self-consistency\nbeing critical methods that enhance this ability. However, these methods do not\nfully exploit the answers generated by the LLM to guide subsequent responses.\nThis paper proposes a new prompting method, named Progressive-Hint Prompting\n(PHP), that enables automatic multiple interactions between users and LLMs by\nusing previously generated answers as hints to progressively guide toward the\ncorrect answers. PHP is orthogonal to CoT and self-consistency, making it easy\nto combine with state-of-the-art techniques to further improve performance. We\nconducted extensive and comprehensive experiments on seven benchmarks. The\nresults show that PHP significantly improves accuracy while remaining highly\nefficient. For instance, with text-davinci-003, we observed a 4.2% improvement\non GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction\nin sample paths with self-consistency. With GPT-4 and PHP, we achieve\nstate-of-the-art performances on SVAMP (89.1% -> 91.9%), GSM8K (92% -> 95.5%),\nAQuA (76.4% -> 79.9%) and MATH (50.3% -> 53.9%).", "published": "2023-04-19 16:29:48", "link": "http://arxiv.org/abs/2304.09797v6", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Verifiability in Generative Search Engines", "abstract": "Generative search engines directly generate responses to user queries, along\nwith in-line citations. A prerequisite trait of a trustworthy generative search\nengine is verifiability, i.e., systems should cite comprehensively (high\ncitation recall; all statements are fully supported by citations) and\naccurately (high citation precision; every cite supports its associated\nstatement). We conduct human evaluation to audit four popular generative search\nengines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse\nset of queries from a variety of sources (e.g., historical Google user queries,\ndynamically-collected open-ended questions on Reddit, etc.). We find that\nresponses from existing generative search engines are fluent and appear\ninformative, but frequently contain unsupported statements and inaccurate\ncitations: on average, a mere 51.5% of generated sentences are fully supported\nby citations and only 74.5% of citations support their associated sentence. We\nbelieve that these results are concerningly low for systems that may serve as a\nprimary tool for information-seeking users, especially given their facade of\ntrustworthiness. We hope that our results further motivate the development of\ntrustworthy generative search engines and help researchers and users better\nunderstand the shortcomings of existing commercial systems.", "published": "2023-04-19 17:56:12", "link": "http://arxiv.org/abs/2304.09848v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The eBible Corpus: Data and Model Benchmarks for Bible Translation for\n  Low-Resource Languages", "abstract": "Efficiently and accurately translating a corpus into a low-resource language\nremains a challenge, regardless of the strategies employed, whether manual,\nautomated, or a combination of the two. Many Christian organizations are\ndedicated to the task of translating the Holy Bible into languages that lack a\nmodern translation. Bible translation (BT) work is currently underway for over\n3000 extremely low resource languages. We introduce the eBible corpus: a\ndataset containing 1009 translations of portions of the Bible with data in 833\ndifferent languages across 75 language families. In addition to a BT\nbenchmarking dataset, we introduce model performance benchmarks built on the No\nLanguage Left Behind (NLLB) neural machine translation (NMT) models. Finally,\nwe describe several problems specific to the domain of BT and consider how the\nestablished data and model benchmarks might be used for future translation\nefforts. For a BT task trained with NLLB, Austronesian and Trans-New Guinea\nlanguage families achieve 35.1 and 31.6 BLEU scores respectively, which spurs\nfuture innovations for NMT for low-resource languages in Papua New Guinea.", "published": "2023-04-19 18:52:49", "link": "http://arxiv.org/abs/2304.09919v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large\n  Language Models Using Generative Pre-Trained Transformers", "abstract": "The proliferation of fake reviews of doctors has potentially detrimental\nconsequences for patient well-being and has prompted concern among consumer\nprotection groups and regulatory bodies. Yet despite significant advancements\nin the fields of machine learning and natural language processing, there\nremains limited comprehension of the characteristics differentiating fraudulent\nfrom authentic reviews. This study utilizes a novel pre-labeled dataset of\n38048 physician reviews to establish the effectiveness of large language models\nin classifying reviews. Specifically, we compare the performance of traditional\nML models, such as logistic regression and support vector machines, to\ngenerative pre-trained transformer models. Furthermore, we use GPT4, the newest\nmodel in the GPT family, to uncover the key dimensions along which fake and\ngenuine physician reviews differ. Our findings reveal significantly superior\nperformance of GPT-3 over traditional ML models in this context. Additionally,\nour analysis suggests that GPT3 requires a smaller training sample than\ntraditional models, suggesting its appropriateness for tasks with scarce\ntraining data. Moreover, the superiority of GPT3 performance increases in the\ncold start context i.e., when there are no prior reviews of a doctor. Finally,\nwe employ GPT4 to reveal the crucial dimensions that distinguish fake physician\nreviews. In sharp contrast to previous findings in the literature that were\nobtained using simulated data, our findings from a real-world dataset show that\nfake reviews are generally more clinically detailed, more reserved in\nsentiment, and have better structure and grammar than authentic ones.", "published": "2023-04-19 19:59:26", "link": "http://arxiv.org/abs/2304.09948v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conversational Process Modeling: Can Generative AI Empower Domain\n  Experts in Creating and Redesigning Process Models?", "abstract": "AI-driven chatbots such as ChatGPT have caused a tremendous hype lately. For\nBPM applications, several applications for AI-driven chatbots have been\nidentified to be promising to generate business value, including explanation of\nprocess mining outcomes and preparation of input data. However, a systematic\nanalysis of chatbots for their support of conversational process modeling as a\nprocess-oriented capability is missing. This work aims at closing this gap by\nproviding a systematic analysis of existing chatbots. Application scenarios are\nidentified along the process life cycle. Then a systematic literature review on\nconversational process modeling is performed, resulting in a taxonomy of\napplication scenarios for conversational process modeling, including\nparaphrasing and improvement of process descriptions. In addition, this work\nsuggests and applies an evaluation method for the output of AI-driven chatbots\nwith respect to completeness and correctness of the process models. This method\nconsists of a set of KPIs on a test set, a set of prompts for task and control\nflow extraction, as well as a survey with users. Based on the literature and\nthe evaluation, recommendations for the usage (practical implications) and\nfurther development (research directions) of conversational process modeling\nare derived.", "published": "2023-04-19 06:54:14", "link": "http://arxiv.org/abs/2304.11065v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fundamental Limitations of Alignment in Large Language Models", "abstract": "An important aspect in developing language models that interact with humans\nis aligning their behavior to be useful and unharmful for their human users.\nThis is usually achieved by tuning the model in a way that enhances desired\nbehaviors and inhibits undesired ones, a process referred to as alignment. In\nthis paper, we propose a theoretical approach called Behavior Expectation\nBounds (BEB) which allows us to formally investigate several inherent\ncharacteristics and limitations of alignment in large language models.\nImportantly, we prove that within the limits of this framework, for any\nbehavior that has a finite probability of being exhibited by the model, there\nexist prompts that can trigger the model into outputting this behavior, with\nprobability that increases with the length of the prompt. This implies that any\nalignment process that attenuates an undesired behavior but does not remove it\naltogether, is not safe against adversarial prompting attacks. Furthermore, our\nframework hints at the mechanism by which leading alignment approaches such as\nreinforcement learning from human feedback make the LLM prone to being prompted\ninto the undesired behaviors. This theoretical result is being experimentally\ndemonstrated in large scale by the so called contemporary \"chatGPT jailbreaks\",\nwhere adversarial users trick the LLM into breaking its alignment guardrails by\ntriggering it into acting as a malicious persona. Our results expose\nfundamental limitations in alignment of LLMs and bring to the forefront the\nneed to devise reliable mechanisms for ensuring AI safety.", "published": "2023-04-19 17:50:09", "link": "http://arxiv.org/abs/2304.11082v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ESimCSE Unsupervised Contrastive Learning Jointly with UDA\n  Semi-Supervised Learning for Large Label System Text Classification Mode", "abstract": "The challenges faced by text classification with large tag systems in natural\nlanguage processing tasks include multiple tag systems, uneven data\ndistribution, and high noise. To address these problems, the ESimCSE\nunsupervised comparative learning and UDA semi-supervised comparative learning\nmodels are combined through the use of joint training techniques in the\nmodels.The ESimCSE model efficiently learns text vector representations using\nunlabeled data to achieve better classification results, while UDA is trained\nusing unlabeled data through semi-supervised learning methods to improve the\nprediction performance of the models and stability, and further improve the\ngeneralization ability of the model. In addition, adversarial training\ntechniques FGM and PGD are used in the model training process to improve the\nrobustness and reliability of the model. The experimental results show that\nthere is an 8% and 10% accuracy improvement relative to Baseline on the public\ndataset Ruesters as well as on the operational dataset, respectively, and a 15%\nimprovement in manual validation accuracy can be achieved on the operational\ndataset, indicating that the method is effective.", "published": "2023-04-19 03:44:23", "link": "http://arxiv.org/abs/2304.13140v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM as A Robotic Brain: Unifying Egocentric Memory and Control", "abstract": "Embodied AI focuses on the study and development of intelligent systems that\npossess a physical or virtual embodiment (i.e. robots) and are able to\ndynamically interact with their environment. Memory and control are the two\nessential parts of an embodied system and usually require separate frameworks\nto model each of them. In this paper, we propose a novel and generalizable\nframework called LLM-Brain: using Large-scale Language Model as a robotic brain\nto unify egocentric memory and control. The LLM-Brain framework integrates\nmultiple multimodal language models for robotic tasks, utilizing a zero-shot\nlearning approach. All components within LLM-Brain communicate using natural\nlanguage in closed-loop multi-round dialogues that encompass perception,\nplanning, control, and memory. The core of the system is an embodied LLM to\nmaintain egocentric memory and control the robot. We demonstrate LLM-Brain by\nexamining two downstream tasks: active exploration and embodied question\nanswering. The active exploration tasks require the robot to extensively\nexplore an unknown environment within a limited number of actions. Meanwhile,\nthe embodied question answering tasks necessitate that the robot answers\nquestions based on observations acquired during prior explorations.", "published": "2023-04-19 00:08:48", "link": "http://arxiv.org/abs/2304.09349v4", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "TieFake: Title-Text Similarity and Emotion-Aware Fake News Detection", "abstract": "Fake news detection aims to detect fake news widely spreading on social media\nplatforms, which can negatively influence the public and the government. Many\napproaches have been developed to exploit relevant information from news\nimages, text, or videos. However, these methods may suffer from the following\nlimitations: (1) ignore the inherent emotional information of the news, which\ncould be beneficial since it contains the subjective intentions of the authors;\n(2) pay little attention to the relation (similarity) between the title and\ntextual information in news articles, which often use irrelevant title to\nattract reader' attention. To this end, we propose a novel Title-Text\nsimilarity and emotion-aware Fake news detection (TieFake) method by jointly\nmodeling the multi-modal context information and the author sentiment in a\nunified framework. Specifically, we respectively employ BERT and ResNeSt to\nlearn the representations for text and images, and utilize publisher emotion\nextractor to capture the author's subjective emotion in the news content. We\nalso propose a scale-dot product attention mechanism to capture the similarity\nbetween title features and textual features. Experiments are conducted on two\npublicly available multi-modal datasets, and the results demonstrate that our\nproposed method can significantly improve the performance of fake news\ndetection. Our code is available at https://github.com/UESTC-GQJ/TieFake.", "published": "2023-04-19 04:47:36", "link": "http://arxiv.org/abs/2304.09421v1", "categories": ["cs.CL", "cs.CV", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "EC^2: Emergent Communication for Embodied Control", "abstract": "Embodied control requires agents to leverage multi-modal pre-training to\nquickly learn how to act in new environments, where video demonstrations\ncontain visual and motion details needed for low-level perception and control,\nand language instructions support generalization with abstract, symbolic\nstructures. While recent approaches apply contrastive learning to force\nalignment between the two modalities, we hypothesize better modeling their\ncomplementary differences can lead to more holistic representations for\ndownstream adaption. To this end, we propose Emergent Communication for\nEmbodied Control (EC^2), a novel scheme to pre-train video-language\nrepresentations for few-shot embodied control. The key idea is to learn an\nunsupervised \"language\" of videos via emergent communication, which bridges the\nsemantics of video details and structures of natural language. We learn\nembodied representations of video trajectories, emergent language, and natural\nlanguage using a language model, which is then used to finetune a lightweight\npolicy network for downstream control. Through extensive experiments in\nMetaworld and Franka Kitchen embodied benchmarks, EC^2 is shown to consistently\noutperform previous contrastive learning methods for both videos and texts as\ntask inputs. Further ablations confirm the importance of the emergent language,\nwhich is beneficial for both video and language learning, and significantly\nsuperior to using pre-trained video captions. We also present a quantitative\nand qualitative analysis of the emergent language and discuss future directions\ntoward better understanding and leveraging emergent communication in embodied\ntasks.", "published": "2023-04-19 06:36:02", "link": "http://arxiv.org/abs/2304.09448v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SemEval 2023 Task 6: LegalEval - Understanding Legal Texts", "abstract": "In populous countries, pending legal cases have been growing exponentially.\nThere is a need for developing NLP-based techniques for processing and\nautomatically understanding legal documents. To promote research in the area of\nLegal NLP we organized the shared task LegalEval - Understanding Legal Texts at\nSemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles\nLabeling) is about automatically structuring legal documents into semantically\ncoherent units, Task-B (Legal Named Entity Recognition) deals with identifying\nrelevant entities in a legal document and Task-C (Court Judgement Prediction\nwith Explanation) explores the possibility of automatically predicting the\noutcome of a legal case along with providing an explanation for the prediction.\nIn total 26 teams (approx. 100 participants spread across the world) submitted\nsystems paper. In each of the sub-tasks, the proposed systems outperformed the\nbaselines; however, there is a lot of scope for improvement. This paper\ndescribes the tasks, and analyzes techniques proposed by various teams.", "published": "2023-04-19 10:28:32", "link": "http://arxiv.org/abs/2304.09548v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CB-Conformer: Contextual biasing Conformer for biased word recognition", "abstract": "Due to the mismatch between the source and target domains, how to better\nutilize the biased word information to improve the performance of the automatic\nspeech recognition model in the target domain becomes a hot research topic.\nPrevious approaches either decode with a fixed external language model or\nintroduce a sizeable biasing module, which leads to poor adaptability and slow\ninference. In this work, we propose CB-Conformer to improve biased word\nrecognition by introducing the Contextual Biasing Module and the Self-Adaptive\nLanguage Model to vanilla Conformer. The Contextual Biasing Module combines\naudio fragments and contextual information, with only 0.2% model parameters of\nthe original Conformer. The Self-Adaptive Language Model modifies the internal\nweights of biased words based on their recall and precision, resulting in a\ngreater focus on biased words and more successful integration with the\nautomatic speech recognition model than the standard fixed language model. In\naddition, we construct and release an open-source Mandarin biased-word dataset\nbased on WenetSpeech. Experiments indicate that our proposed method brings a\n15.34% character error rate reduction, a 14.13% biased word recall increase,\nand a 6.80% biased word F1-score increase compared with the base Conformer.", "published": "2023-04-19 12:26:04", "link": "http://arxiv.org/abs/2304.09607v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GeneGPT: Augmenting Large Language Models with Domain Tools for Improved\n  Access to Biomedical Information", "abstract": "While large language models (LLMs) have been successfully applied to various\ntasks, they still face challenges with hallucinations. Augmenting LLMs with\ndomain-specific tools such as database utilities can facilitate easier and more\nprecise access to specialized knowledge. In this paper, we present GeneGPT, a\nnovel method for teaching LLMs to use the Web APIs of the National Center for\nBiotechnology Information (NCBI) for answering genomics questions.\nSpecifically, we prompt Codex to solve the GeneTuring tests with NCBI Web APIs\nby in-context learning and an augmented decoding algorithm that can detect and\nexecute API calls. Experimental results show that GeneGPT achieves\nstate-of-the-art performance on eight tasks in the GeneTuring benchmark with an\naverage score of 0.83, largely surpassing retrieval-augmented LLMs such as the\nnew Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as\nwell as GPT-3 (0.16) and ChatGPT (0.12). Our further analyses suggest that: (1)\nAPI demonstrations have good cross-task generalizability and are more useful\nthan documentations for in-context learning; (2) GeneGPT can generalize to\nlonger chains of API calls and answer multi-hop questions in GeneHop, a novel\ndataset introduced in this work; (3) Different types of errors are enriched in\ndifferent tasks, providing valuable insights for future improvements.", "published": "2023-04-19 13:53:19", "link": "http://arxiv.org/abs/2304.09667v3", "categories": ["cs.CL", "cs.AI", "q-bio.GN"], "primary_category": "cs.CL"}
{"title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language\n  Models", "abstract": "Large language models (LLMs) have achieved remarkable progress in solving\nvarious natural language processing tasks due to emergent reasoning abilities.\nHowever, LLMs have inherent limitations as they are incapable of accessing\nup-to-date information (stored on the Web or in task-specific knowledge bases),\nusing external tools, and performing precise mathematical and logical\nreasoning. In this paper, we present Chameleon, an AI system that mitigates\nthese limitations by augmenting LLMs with plug-and-play modules for\ncompositional reasoning. Chameleon synthesizes programs by composing various\ntools (e.g., LLMs, off-the-shelf vision models, web search engines, Python\nfunctions, and heuristic-based modules) for accomplishing complex reasoning\ntasks. At the heart of Chameleon is an LLM-based planner that assembles a\nsequence of tools to execute to generate the final response. We showcase the\neffectiveness of Chameleon on two multi-modal knowledge-intensive reasoning\ntasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%\noverall accuracy on ScienceQA, improving the best published few-shot result by\n11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,\nlifting the state of the art to 98.78%. Our analysis also shows that the\nGPT-4-powered planner exhibits more consistent and rational tool selection via\ninferring potential constraints from instructions, compared to a\nChatGPT-powered planner. The project is available at\nhttps://chameleon-llm.github.io.", "published": "2023-04-19 17:47:47", "link": "http://arxiv.org/abs/2304.09842v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Latent Space Theory for Emergent Abilities in Large Language Models", "abstract": "Languages are not created randomly but rather to communicate information.\nThere is a strong association between languages and their underlying meanings,\nresulting in a sparse joint distribution that is heavily peaked according to\ntheir correlations. Moreover, these peak values happen to match with the\nmarginal distribution of languages due to the sparsity. With the advent of LLMs\ntrained on big data and large models, we can now precisely assess the marginal\ndistribution of languages, providing a convenient means of exploring the sparse\nstructures in the joint distribution for effective inferences. In this paper,\nwe categorize languages as either unambiguous or {\\epsilon}-ambiguous and\npresent quantitative results to demonstrate that the emergent abilities of\nLLMs, such as language understanding, in-context learning, chain-of-thought\nprompting, and effective instruction fine-tuning, can all be attributed to\nBayesian inference on the sparse joint distribution of languages.", "published": "2023-04-19 20:45:01", "link": "http://arxiv.org/abs/2304.09960v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Supporting Human-AI Collaboration in Auditing LLMs with LLMs", "abstract": "Large language models are becoming increasingly pervasive and ubiquitous in\nsociety via deployment in sociotechnical systems. Yet these language models, be\nit for classification or generation, have been shown to be biased and behave\nirresponsibly, causing harm to people at scale. It is crucial to audit these\nlanguage models rigorously. Existing auditing tools leverage either or both\nhumans and AI to find failures. In this work, we draw upon literature in\nhuman-AI collaboration and sensemaking, and conduct interviews with research\nexperts in safe and fair AI, to build upon the auditing tool: AdaTest (Ribeiro\nand Lundberg, 2022), which is powered by a generative large language model\n(LLM). Through the design process we highlight the importance of sensemaking\nand human-AI communication to leverage complementary strengths of humans and\ngenerative models in collaborative auditing. To evaluate the effectiveness of\nthe augmented tool, AdaTest++, we conduct user studies with participants\nauditing two commercial language models: OpenAI's GPT-3 and Azure's sentiment\nanalysis model. Qualitative analysis shows that AdaTest++ effectively leverages\nhuman strengths such as schematization, hypothesis formation and testing.\nFurther, with our tool, participants identified a variety of failures modes,\ncovering 26 different topics over 2 tasks, that have been shown before in\nformal audits and also those previously under-reported.", "published": "2023-04-19 21:59:04", "link": "http://arxiv.org/abs/2304.09991v3", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Comparison of Semi-Supervised Learning Techniques for Streaming ASR at\n  Scale", "abstract": "Unpaired text and audio injection have emerged as dominant methods for\nimproving ASR performance in the absence of a large labeled corpus. However,\nlittle guidance exists on deploying these methods to improve production ASR\nsystems that are trained on very large supervised corpora and with realistic\nrequirements like a constrained model size and CPU budget, streaming\ncapability, and a rich lattice for rescoring and for downstream NLU tasks. In\nthis work, we compare three state-of-the-art semi-supervised methods\nencompassing both unpaired text and audio as well as several of their\ncombinations in a controlled setting using joint training. We find that in our\nsetting these methods offer many improvements beyond raw WER, including\nsubstantial gains in tail-word WER, decoder computation during inference, and\nlattice density.", "published": "2023-04-19 18:09:27", "link": "http://arxiv.org/abs/2304.11053v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scaling Transformer to 1M tokens and beyond with RMT", "abstract": "A major limitation for the broader scope of problems solvable by transformers\nis the quadratic scaling of computational complexity with input size. In this\nstudy, we investigate the recurrent memory augmentation of pre-trained\ntransformer models to extend input context length while linearly scaling\ncompute. Our approach demonstrates the capability to store information in\nmemory for sequences of up to an unprecedented two million tokens while\nmaintaining high retrieval accuracy. Experiments with language modeling tasks\nshow perplexity improvement as the number of processed input segments\nincreases. These results underscore the effectiveness of our method, which has\nsignificant potential to enhance long-term dependency handling in natural\nlanguage understanding and generation tasks, as well as enable large-scale\ncontext processing for memory-intensive applications.", "published": "2023-04-19 16:18:54", "link": "http://arxiv.org/abs/2304.11062v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Affective social anthropomorphic intelligent system", "abstract": "Human conversational styles are measured by the sense of humor, personality,\nand tone of voice. These characteristics have become essential for\nconversational intelligent virtual assistants. However, most of the\nstate-of-the-art intelligent virtual assistants (IVAs) are failed to interpret\nthe affective semantics of human voices. This research proposes an\nanthropomorphic intelligent system that can hold a proper human-like\nconversation with emotion and personality. A voice style transfer method is\nalso proposed to map the attributes of a specific emotion. Initially, the\nfrequency domain data (Mel-Spectrogram) is created by converting the temporal\naudio wave data, which comprises discrete patterns for audio features such as\nnotes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used\nto predict seven different affective states from voice. The voice is also fed\nparallelly to the deep-speech, an RNN model that generates the text\ntranscription from the spectrogram. Then the transcripted text is transferred\nto the multi-domain conversation agent using blended skill talk,\ntransformer-based retrieve-and-generate generation strategy, and beam-search\ndecoding, and an appropriate textual response is generated. The system learns\nan invertible mapping of data to a latent space that can be manipulated and\ngenerates a Mel-spectrogram frame based on previous Mel-spectrogram frames to\nvoice synthesize and style transfer. Finally, the waveform is generated using\nWaveGlow from the spectrogram. The outcomes of the studies we conducted on\nindividual models were auspicious. Furthermore, users who interacted with the\nsystem provided positive feedback, demonstrating the system's effectiveness.", "published": "2023-04-19 18:24:57", "link": "http://arxiv.org/abs/2304.11046v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Multilingual Query-by-Example Keyword Spotting with Metric Learning and\n  Phoneme-to-Embedding Mapping", "abstract": "In this paper, we propose a multilingual query-by-example keyword spotting\n(KWS) system based on a residual neural network. The model is trained as a\nclassifier on a multilingual keyword dataset extracted from Common Voice\nsentences and fine-tuned using circle loss. We demonstrate the generalization\nability of the model to new languages and report a mean reduction in EER of\n59.2 % for previously seen and 47.9 % for unseen languages compared to a\ncompetitive baseline. We show that the word embeddings learned by the KWS model\ncan be accurately predicted from the phoneme sequences using a simple LSTM\nmodel. Our system achieves a promising accuracy for streaming keyword spotting\nand keyword search on Common Voice audio using just 5 examples per keyword.\nExperiments on the Hey-Snips dataset show a good performance with a false\nnegative rate of 5.4 % at only 0.1 false alarms per hour.", "published": "2023-04-19 11:47:08", "link": "http://arxiv.org/abs/2304.09585v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Security and Privacy Problems in Voice Assistant Applications: A Survey", "abstract": "Voice assistant applications have become omniscient nowadays. Two models that\nprovide the two most important functions for real-life applications (i.e.,\nGoogle Home, Amazon Alexa, Siri, etc.) are Automatic Speech Recognition (ASR)\nmodels and Speaker Identification (SI) models. According to recent studies,\nsecurity and privacy threats have also emerged with the rapid development of\nthe Internet of Things (IoT). The security issues researched include attack\ntechniques toward machine learning models and other hardware components widely\nused in voice assistant applications. The privacy issues include technical-wise\ninformation stealing and policy-wise privacy breaches. The voice assistant\napplication takes a steadily growing market share every year, but their privacy\nand security issues never stopped causing huge economic losses and endangering\nusers' personal sensitive information. Thus, it is important to have a\ncomprehensive survey to outline the categorization of the current research\nregarding the security and privacy problems of voice assistant applications.\nThis paper concludes and assesses five kinds of security attacks and three\ntypes of privacy threats in the papers published in the top-tier conferences of\ncyber security and voice domain.", "published": "2023-04-19 08:17:01", "link": "http://arxiv.org/abs/2304.09486v1", "categories": ["cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
