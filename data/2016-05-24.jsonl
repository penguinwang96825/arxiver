{"title": "Combining Recurrent and Convolutional Neural Networks for Relation\n  Classification", "abstract": "This paper investigates two different neural architectures for the task of\nrelation classification: convolutional neural networks and recurrent neural\nnetworks. For both models, we demonstrate the effect of different architectural\nchoices. We present a new context representation for convolutional neural\nnetworks for relation classification (extended middle context). Furthermore, we\npropose connectionist bi-directional recurrent neural networks and introduce\nranking loss for their optimization. Finally, we show that combining\nconvolutional and recurrent neural networks using a simple voting scheme is\naccurate enough to improve results. Our neural models achieve state-of-the-art\nresults on the SemEval 2010 relation classification task.", "published": "2016-05-24 08:20:12", "link": "http://arxiv.org/abs/1605.07333v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Level Analysis and Annotation of Arabic Corpora for Text-to-Sign\n  Language MT", "abstract": "In this paper, we present an ongoing effort in lexical semantic analysis and\nannotation of Modern Standard Arabic (MSA) text, a semi automatic annotation\ntool concerned with the morphologic, syntactic, and semantic levels of\ndescription.", "published": "2016-05-24 09:19:05", "link": "http://arxiv.org/abs/1605.07346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experiments in Linear Template Combination using Genetic Algorithms", "abstract": "Natural Language Generation systems typically have two parts - strategic\n('what to say') and tactical ('how to say'). We present our experiments in\nbuilding an unsupervised corpus-driven template based tactical NLG system. We\nconsider templates as a sequence of words containing gaps. Our idea is based on\nthe observation that templates are grammatical locally (within their textual\nspan). We posit the construction of a sentence as a highly restricted sequence\nof such templates. This work is an attempt to explore the resulting search\nspace using Genetic Algorithms to arrive at acceptable solutions. We present a\nbaseline implementation of this approach which outputs gapped text.", "published": "2016-05-24 10:28:43", "link": "http://arxiv.org/abs/1605.07366v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Neural Semantic Role Labeling with Dependency Path Embeddings", "abstract": "This paper introduces a novel model for semantic role labeling that makes use\nof neural sequence modeling techniques. Our approach is motivated by the\nobservation that complex syntactic structures and related phenomena, such as\nnested subordinations and nominal predicates, are not handled well by existing\nmodels. Our model treats such instances as sub-sequences of lexicalized\ndependency paths and learns suitable embedding representations. We\nexperimentally demonstrate that such embeddings can improve results over\nprevious state-of-the-art semantic role labelers, and showcase qualitative\nimprovements obtained by our method.", "published": "2016-05-24 15:54:48", "link": "http://arxiv.org/abs/1605.07515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning End-to-End Goal-Oriented Dialog", "abstract": "Traditional dialog systems used in goal-oriented applications require a lot\nof domain-specific handcrafting, which hinders scaling up to new domains.\nEnd-to-end dialog systems, in which all components are trained from the dialogs\nthemselves, escape this limitation. But the encouraging success recently\nobtained in chit-chat dialog may not carry over to goal-oriented settings. This\npaper proposes a testbed to break down the strengths and shortcomings of\nend-to-end dialog systems in goal-oriented applications. Set in the context of\nrestaurant reservation, our tasks require manipulating sentences and symbols,\nso as to properly conduct conversations, issue API calls and use the outputs of\nsuch calls. We show that an end-to-end dialog system based on Memory Networks\ncan reach promising, yet imperfect, performance and learn to perform\nnon-trivial operations. We confirm those results by comparing our system to a\nhand-crafted slot-filling baseline on data from the second Dialog State\nTracking Challenge (Henderson et al., 2014a). We show similar result patterns\non data extracted from an online concierge service.", "published": "2016-05-24 23:09:58", "link": "http://arxiv.org/abs/1605.07683v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Classifying discourse in a CSCL platform to evaluate correlations with\n  Teacher Participation and Progress", "abstract": "In Computer-Supported learning, monitoring and engaging a group of learners\nis a complex task for teachers, especially when learners are working\ncollaboratively: Are my students motivated? What kind of progress are they\nmaking? Should I intervene? Is my communication and the didactic design adapted\nto my students? Our hypothesis is that the analysis of natural language\ninteractions between students, and between students and teachers, provide very\nvaluable information and could be used to produce qualitative indicators to\nhelp teachers' decisions. We develop an automatic approach in three steps (1)\nto explore the discursive functions of messages in a CSCL platform, (2) to\nclassify the messages automatically and (3) to evaluate correlations between\ndiscursive attitudes and other variables linked to the learning activity.\nResults tend to show that some types of discourse are correlated with a notion\nof Progress on the learning activities and the importance of emotive\nparticipation from the Teacher.", "published": "2016-05-24 02:39:26", "link": "http://arxiv.org/abs/1605.07268v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "On-line Active Reward Learning for Policy Optimisation in Spoken\n  Dialogue Systems", "abstract": "The ability to compute an accurate reward function is essential for\noptimising a dialogue policy via reinforcement learning. In real-world\napplications, using explicit user feedback as the reward signal is often\nunreliable and costly to collect. This problem can be mitigated if the user's\nintent is known in advance or data is available to pre-train a task success\npredictor off-line. In practice neither of these apply for most real world\napplications. Here we propose an on-line learning framework whereby the\ndialogue policy is jointly trained alongside the reward model via active\nlearning with a Gaussian process model. This Gaussian process operates on a\ncontinuous space dialogue representation generated in an unsupervised fashion\nusing a recurrent neural network encoder-decoder. The experimental results\ndemonstrate that the proposed framework is able to significantly reduce data\nannotation costs and mitigate noisy user feedback in dialogue policy learning.", "published": "2016-05-24 21:56:08", "link": "http://arxiv.org/abs/1605.07669v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Memory Networks", "abstract": "Memory networks are neural networks with an explicit memory component that\ncan be both read and written to by the network. The memory is often addressed\nin a soft way using a softmax function, making end-to-end training with\nbackpropagation possible. However, this is not computationally scalable for\napplications which require the network to read from extremely large memories.\nOn the other hand, it is well known that hard attention mechanisms based on\nreinforcement learning are challenging to train successfully. In this paper, we\nexplore a form of hierarchical memory network, which can be considered as a\nhybrid between hard and soft attention memory networks. The memory is organized\nin a hierarchical structure such that reading from it is done with less\ncomputation than soft attention over a flat memory, while also being easier to\ntrain than hard attention over a flat memory. Specifically, we propose to\nincorporate Maximum Inner Product Search (MIPS) in the training and inference\nprocedures for our hierarchical memory network. We explore the use of various\nstate-of-the art approximate MIPS techniques and report results on\nSimpleQuestions, a challenging large scale factoid question answering task.", "published": "2016-05-24 12:48:19", "link": "http://arxiv.org/abs/1605.07427v1", "categories": ["stat.ML", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "stat.ML"}
