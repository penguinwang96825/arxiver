{"title": "Investigating the Working of Text Classifiers", "abstract": "Text classification is one of the most widely studied tasks in natural\nlanguage processing. Motivated by the principle of compositionality, large\nmultilayer neural network models have been employed for this task in an attempt\nto effectively utilize the constituent expressions. Almost all of the reported\nwork train large networks using discriminative approaches, which come with a\ncaveat of no proper capacity control, as they tend to latch on to any signal\nthat may not generalize. Using various recent state-of-the-art approaches for\ntext classification, we explore whether these models actually learn to compose\nthe meaning of the sentences or still just focus on some keywords or lexicons\nfor classifying the document. To test our hypothesis, we carefully construct\ndatasets where the training and test splits have no direct overlap of such\nlexicons, but overall language structure would be similar. We study various\ntext classifiers and observe that there is a big performance drop on these\ndatasets. Finally, we show that even simple models with our proposed\nregularization techniques, which disincentivize focusing on key lexicons, can\nsubstantially improve classification accuracy.", "published": "2018-01-19 00:29:55", "link": "http://arxiv.org/abs/1801.06261v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Size vs. Structure in Training Corpora for Word Embedding Models:\n  Araneum Russicum Maximum and Russian National Corpus", "abstract": "In this paper, we present a distributional word embedding model trained on\none of the largest available Russian corpora: Araneum Russicum Maximum (over 10\nbillion words crawled from the web). We compare this model to the model trained\non the Russian National Corpus (RNC). The two corpora are much different in\ntheir size and compilation procedures. We test these differences by evaluating\nthe trained models against the Russian part of the Multilingual SimLex999\nsemantic similarity dataset. We detect and describe numerous issues in this\ndataset and publish a new corrected version. Aside from the already known fact\nthat the RNC is generally a better training corpus than web corpora, we\nenumerate and explain fine differences in how the models process semantic\nsimilarity task, what parts of the evaluation set are difficult for particular\nmodels and why. Additionally, the learning curves for both models are\ndescribed, showing that the RNC is generally more robust as training material\nfor this task.", "published": "2018-01-19 14:11:16", "link": "http://arxiv.org/abs/1801.06407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating neural network explanation methods using hybrid documents and\n  morphological agreement", "abstract": "The behavior of deep neural networks (DNNs) is hard to understand. This makes\nit necessary to explore post hoc explanation methods. We conduct the first\ncomprehensive evaluation of explanation methods for NLP. To this end, we design\ntwo novel evaluation paradigms that cover two important classes of NLP\nproblems: small context and large context problems. Both paradigms require no\nmanual annotation and are therefore broadly applicable. We also introduce\nLIMSSE, an explanation method inspired by LIME that is designed for NLP. We\nshow empirically that LIMSSE, LRP and DeepLIFT are the most effective\nexplanation methods and recommend them for explaining DNNs in NLP.", "published": "2018-01-19 14:41:45", "link": "http://arxiv.org/abs/1801.06422v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Resource-Light Method for Cross-Lingual Semantic Textual Similarity", "abstract": "Recognizing semantically similar sentences or paragraphs across languages is\nbeneficial for many tasks, ranging from cross-lingual information retrieval and\nplagiarism detection to machine translation. Recently proposed methods for\npredicting cross-lingual semantic similarity of short texts, however, make use\nof tools and resources (e.g., machine translation systems, syntactic parsers or\nnamed entity recognition) that for many languages (or language pairs) do not\nexist. In contrast, we propose an unsupervised and a very resource-light\napproach for measuring semantic similarity between texts in different\nlanguages. To operate in the bilingual (or multilingual) space, we project\ncontinuous word vectors (i.e., word embeddings) from one language to the vector\nspace of the other language via the linear translation model. We then align\nwords according to the similarity of their vectors in the bilingual embedding\nspace and investigate different unsupervised measures of semantic similarity\nexploiting bilingual embeddings and word alignments. Requiring only a\nlimited-size set of word translation pairs between the languages, the proposed\napproach is applicable to virtually any pair of languages for which there\nexists a sufficiently large corpus, required to learn monolingual word\nembeddings. Experimental results on three different datasets for measuring\nsemantic textual similarity show that our simple resource-light approach\nreaches performance close to that of supervised and resource intensive methods,\ndisplaying stability across different language pairs. Furthermore, we evaluate\nthe proposed method on two extrinsic tasks, namely extraction of parallel\nsentences from comparable corpora and cross lingual plagiarism detection, and\nshow that it yields performance comparable to those of complex\nresource-intensive state-of-the-art models for the respective tasks.", "published": "2018-01-19 15:00:33", "link": "http://arxiv.org/abs/1801.06436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Practitioners' Guide to Transfer Learning for Text Classification\n  using Convolutional Neural Networks", "abstract": "Transfer Learning (TL) plays a crucial role when a given dataset has\ninsufficient labeled examples to train an accurate model. In such scenarios,\nthe knowledge accumulated within a model pre-trained on a source dataset can be\ntransferred to a target dataset, resulting in the improvement of the target\nmodel. Though TL is found to be successful in the realm of image-based\napplications, its impact and practical use in Natural Language Processing (NLP)\napplications is still a subject of research. Due to their hierarchical\narchitecture, Deep Neural Networks (DNN) provide flexibility and customization\nin adjusting their parameters and depth of layers, thereby forming an apt area\nfor exploiting the use of TL. In this paper, we report the results and\nconclusions obtained from extensive empirical experiments using a Convolutional\nNeural Network (CNN) and try to uncover thumb rules to ensure a successful\npositive transfer. In addition, we also highlight the flawed means that could\nlead to a negative transfer. We explore the transferability of various layers\nand describe the effect of varying hyper-parameters on the transfer\nperformance. Also, we present a comparison of accuracy value and model size\nagainst state-of-the-art methods. Finally, we derive inferences from the\nempirical results and provide best practices to achieve a successful positive\ntransfer.", "published": "2018-01-19 16:24:47", "link": "http://arxiv.org/abs/1801.06480v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transfer Learning for Improving Speech Emotion Classification Accuracy", "abstract": "The majority of existing speech emotion recognition research focuses on\nautomatic emotion detection using training and testing data from same corpus\ncollected under the same conditions. The performance of such systems has been\nshown to drop significantly in cross-corpus and cross-language scenarios. To\naddress the problem, this paper exploits a transfer learning technique to\nimprove the performance of speech emotion recognition systems that is novel in\ncross-language and cross-corpus scenarios. Evaluations on five different\ncorpora in three different languages show that Deep Belief Networks (DBNs)\noffer better accuracy than previous approaches on cross-corpus emotion\nrecognition, relative to a Sparse Autoencoder and SVM baseline system. Results\nalso suggest that using a large number of languages for training and using a\nsmall fraction of the target data in training can significantly boost accuracy\ncompared with baseline also for the corpus with limited training examples.", "published": "2018-01-19 10:16:11", "link": "http://arxiv.org/abs/1801.06353v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "What Does a TextCNN Learn?", "abstract": "TextCNN, the convolutional neural network for text, is a useful deep learning\nalgorithm for sentence classification tasks such as sentiment analysis and\nquestion classification. However, neural networks have long been known as black\nboxes because interpreting them is a challenging task. Researchers have\ndeveloped several tools to understand a CNN for image classification by deep\nvisualization, but research about deep TextCNNs is still insufficient. In this\npaper, we are trying to understand what a TextCNN learns on two classical NLP\ndatasets. Our work focuses on functions of different convolutional kernels and\ncorrelations between convolutional kernels.", "published": "2018-01-19 04:02:04", "link": "http://arxiv.org/abs/1801.06287v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Multi-Task Pharmacovigilance Mining from Social Media Posts", "abstract": "Social media has grown to be a crucial information source for\npharmacovigilance studies where an increasing number of people post adverse\nreactions to medical drugs that are previously unreported. Aiming to\neffectively monitor various aspects of Adverse Drug Reactions (ADRs) from\ndiversely expressed social medical posts, we propose a multi-task neural\nnetwork framework that learns several tasks associated with ADR monitoring with\ndifferent levels of supervisions collectively. Besides being able to correctly\nclassify ADR posts and accurately extract ADR mentions from online posts, the\nproposed framework is also able to further understand reasons for which the\ndrug is being taken, known as 'indication', from the given social media post. A\ncoverage-based attention mechanism is adopted in our framework to help the\nmodel properly identify 'phrasal' ADRs and Indications that are attentive to\nmultiple words in a post. Our framework is applicable in situations where\nlimited parallel data for different pharmacovigilance tasks are available.We\nevaluate the proposed framework on real-world Twitter datasets, where the\nproposed model outperforms the state-of-the-art alternatives of each individual\ntask consistently.", "published": "2018-01-19 05:04:21", "link": "http://arxiv.org/abs/1801.06294v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deep Learning for Detecting Cyberbullying Across Multiple Social Media\n  Platforms", "abstract": "Harassment by cyberbullies is a significant phenomenon on the social media.\nExisting works for cyberbullying detection have at least one of the following\nthree bottlenecks. First, they target only one particular social media platform\n(SMP). Second, they address just one topic of cyberbullying. Third, they rely\non carefully handcrafted features of the data. We show that deep learning based\nmodels can overcome all three bottlenecks. Knowledge learned by these models on\none dataset can be transferred to other datasets. We performed extensive\nexperiments using three real-world datasets: Formspring (12k posts), Twitter\n(16k posts), and Wikipedia(100k posts). Our experiments provide several useful\ninsights about cyberbullying detection. To the best of our knowledge, this is\nthe first work that systematically analyzes cyberbullying detection on various\ntopics across multiple SMPs using deep learning based models and transfer\nlearning.", "published": "2018-01-19 16:27:36", "link": "http://arxiv.org/abs/1801.06482v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Epoch-Synchronous Overlap-Add (ESOLA) for Time- and Pitch-Scale\n  Modification of Speech Signals", "abstract": "Time- and pitch-scale modifications of speech signals find important\napplications in speech synthesis, playback systems, voice conversion,\nlearning/hearing aids, etc.. There is a requirement for computationally\nefficient and real-time implementable algorithms. In this paper, we propose a\nhigh quality and computationally efficient time- and pitch-scaling methodology\nbased on the glottal closure instants (GCIs) or epochs in speech signals. The\nproposed algorithm, termed as epoch-synchronous overlap-add time/pitch-scaling\n(ESOLA-TS/PS), segments speech signals into overlapping short-time frames and\nthen the adjacent frames are aligned with respect to the epochs and the frames\nare overlap-added to synthesize time-scale modified speech. Pitch scaling is\nachieved by resampling the time-scaled speech by a desired sampling factor. We\nalso propose a concept of epoch embedding into speech signals, which\nfacilitates the identification and time-stamping of samples corresponding to\nepochs and using them for time/pitch-scaling to multiple scaling factors\nwhenever desired, thereby contributing to faster and efficient implementation.\nThe results of perceptual evaluation tests reported in this paper indicate the\nsuperiority of ESOLA over state-of-the-art techniques. ESOLA significantly\noutperforms the conventional pitch synchronous overlap-add (PSOLA) techniques\nin terms of perceptual quality and intelligibility of the modified speech.\nUnlike the waveform similarity overlap-add (WSOLA) or synchronous overlap-add\n(SOLA) techniques, the ESOLA technique has the capability to do exact\ntime-scaling of speech with high quality to any desired modification factor\nwithin a range of 0.5 to 2. Compared to synchronous overlap-add with fixed\nsynthesis (SOLAFS), the ESOLA is computationally advantageous and at least\nthree times faster.", "published": "2018-01-19 17:05:59", "link": "http://arxiv.org/abs/1801.06492v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
