{"title": "A Comprehensive Comparison of Pre-training Language Models", "abstract": "Recently, the development of pre-trained language models has brought natural\nlanguage processing (NLP) tasks to the new state-of-the-art. In this paper we\nexplore the efficiency of various pre-trained language models. We pre-train a\nlist of transformer-based models with the same amount of text and the same\ntraining steps. The experimental results shows that the most improvement upon\nthe origin BERT is adding the RNN-layer to capture more contextual information\nfor short text understanding. But the conclusion is: There are no remarkable\nimprovement for short text understanding for similar BERT structures.\nData-centric method[12] can achieve better performance.", "published": "2021-06-22 02:12:29", "link": "http://arxiv.org/abs/2106.11483v9", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BARTScore: Evaluating Generated Text as Text Generation", "abstract": "A wide variety of NLP applications, such as machine translation,\nsummarization, and dialog, involve text generation. One major challenge for\nthese applications is how to evaluate whether such generated texts are actually\nfluent, accurate, or effective. In this work, we conceptualize the evaluation\nof generated text as a text generation problem, modeled using pre-trained\nsequence-to-sequence models. The general idea is that models trained to convert\nthe generated text to/from a reference output or the source text will achieve\nhigher scores when the generated text is better. We operationalize this idea\nusing BART, an encoder-decoder based pre-trained model, and propose a metric\nBARTScore with a number of variants that can be flexibly applied in an\nunsupervised fashion to evaluation of text from different perspectives (e.g.\ninformativeness, fluency, or factuality). BARTScore is conceptually simple and\nempirically effective. It can outperform existing top-scoring metrics in 16 of\n22 test settings, covering evaluation of 16 datasets (e.g., machine\ntranslation, text summarization) and 7 different perspectives (e.g.,\ninformativeness, factuality). Code to calculate BARTScore is available at\nhttps://github.com/neulab/BARTScore, and we have released an interactive\nleaderboard for meta-evaluation at\nhttp://explainaboard.nlpedia.ai/leaderboard/task-meval/ on the ExplainaBoard\nplatform, which allows us to interactively understand the strengths,\nweaknesses, and complementarity of each metric.", "published": "2021-06-22 03:20:53", "link": "http://arxiv.org/abs/2106.11520v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SENT: Sentence-level Distant Relation Extraction via Negative Training", "abstract": "Distant supervision for relation extraction provides uniform bag labels for\neach sentence inside the bag, while accurate sentence labels are important for\ndownstream applications that need the exact relation type. Directly using bag\nlabels for sentence-level training will introduce much noise, thus severely\ndegrading performance. In this work, we propose the use of negative training\n(NT), in which a model is trained using complementary labels regarding that\n``the instance does not belong to these complementary labels\". Since the\nprobability of selecting a true label as a complementary label is low, NT\nprovides less noisy information. Furthermore, the model trained with NT is able\nto separate the noisy data from the training data. Based on NT, we propose a\nsentence-level framework, SENT, for distant relation extraction. SENT not only\nfilters the noisy data to construct a cleaner dataset, but also performs a\nre-labeling process to transform the noisy data into useful training data, thus\nfurther benefiting the model's performance. Experimental results show the\nsignificant improvement of the proposed method over previous methods on\nsentence-level evaluation and de-noise effect.", "published": "2021-06-22 06:49:05", "link": "http://arxiv.org/abs/2106.11566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Error-Aware Interactive Semantic Parsing of OpenStreetMap", "abstract": "In semantic parsing of geographical queries against real-world databases such\nas OpenStreetMap (OSM), unique correct answers do not necessarily exist.\nInstead, the truth might be lying in the eye of the user, who needs to enter an\ninteractive setup where ambiguities can be resolved and parsing mistakes can be\ncorrected. Our work presents an approach to interactive semantic parsing where\nan explicit error detection is performed, and a clarification question is\ngenerated that pinpoints the suspected source of ambiguity or error and\ncommunicates it to the human user. Our experimental results show that a\ncombination of entropy-based uncertainty detection and beam search, together\nwith multi-source training on clarification question, initial parse, and user\nanswer, results in improvements of 1.2% F1 score on a parser that already\nperforms at 90.26% on the NLMaps dataset for OSM semantic parsing.", "published": "2021-06-22 13:18:42", "link": "http://arxiv.org/abs/2106.11739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Task-Oriented Dialog Modeling with Semi-Structured Knowledge\n  Management", "abstract": "Current task-oriented dialog (TOD) systems mostly manage structured knowledge\n(e.g. databases and tables) to guide the goal-oriented conversations. However,\nthey fall short of handling dialogs which also involve unstructured knowledge\n(e.g. reviews and documents). In this paper, we formulate a task of modeling\nTOD grounded on a fusion of structured and unstructured knowledge. To address\nthis task, we propose a TOD system with semi-structured knowledge management,\nSeKnow, which extends the belief state to manage knowledge with both structured\nand unstructured contents. Furthermore, we introduce two implementations of\nSeKnow based on a non-pretrained sequence-to-sequence model and a pretrained\nlanguage model, respectively. Both implementations use the end-to-end manner to\njointly optimize dialog modeling grounded on structured and unstructured\nknowledge. We conduct experiments on a modified version of MultiWOZ 2.1\ndataset, Mod-MultiWOZ 2.1, where dialogs are processed to involve\nsemi-structured knowledge. Experimental results show that SeKnow has strong\nperformances in both end-to-end dialog and intermediate knowledge management,\ncompared to existing TOD systems and their extensions with pipeline knowledge\nmanagement schemes.", "published": "2021-06-22 14:07:22", "link": "http://arxiv.org/abs/2106.11796v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Evaluation of Machine Translation for Terminology Consistency", "abstract": "As neural machine translation (NMT) systems become an important part of\nprofessional translator pipelines, a growing body of work focuses on combining\nNMT with terminologies. In many scenarios and particularly in cases of domain\nadaptation, one expects the MT output to adhere to the constraints provided by\na terminology. In this work, we propose metrics to measure the consistency of\nMT output with regards to a domain terminology. We perform studies on the\nCOVID-19 domain over 5 languages, also performing terminology-targeted human\nevaluation. We open-source the code for computing all proposed metrics:\nhttps://github.com/mahfuzibnalam/terminology_evaluation", "published": "2021-06-22 15:59:32", "link": "http://arxiv.org/abs/2106.11891v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple and Practical Approach to Improve Misspellings in OCR Text", "abstract": "The focus of our paper is the identification and correction of non-word\nerrors in OCR text. Such errors may be the result of incorrect insertion,\ndeletion, or substitution of a character, or the transposition of two adjacent\ncharacters within a single word. Or, it can be the result of word boundary\nproblems that lead to run-on errors and incorrect-split errors. The traditional\nN-gram correction methods can handle single-word errors effectively. However,\nthey show limitations when dealing with split and merge errors. In this paper,\nwe develop an unsupervised method that can handle both errors. The method we\ndevelop leads to a sizable improvement in the correction rates. This tutorial\npaper addresses very difficult word correction problems - namely incorrect\nrun-on and split errors - and illustrates what needs to be considered when\naddressing such problems. We outline a possible approach and assess its success\non a limited study.", "published": "2021-06-22 19:38:17", "link": "http://arxiv.org/abs/2106.12030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Language Models Perform Generalizable Commonsense Inference?", "abstract": "Inspired by evidence that pretrained language models (LMs) encode commonsense\nknowledge, recent work has applied LMs to automatically populate commonsense\nknowledge graphs (CKGs). However, there is a lack of understanding on their\ngeneralization to multiple CKGs, unseen relations, and novel entities. This\npaper analyzes the ability of LMs to perform generalizable commonsense\ninference, in terms of knowledge capacity, transferability, and induction. Our\nexperiments with these three aspects show that: (1) LMs can adapt to different\nschemas defined by multiple CKGs but fail to reuse the knowledge to generalize\nto new relations. (2) Adapted LMs generalize well to unseen subjects, but less\nso on novel objects. Future work should investigate how to improve the\ntransferability and induction of commonsense mining from LMs.", "published": "2021-06-22 04:17:19", "link": "http://arxiv.org/abs/2106.11533v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learn to Resolve Conversational Dependency: A Consistency Training\n  Framework for Conversational Question Answering", "abstract": "One of the main challenges in conversational question answering (CQA) is to\nresolve the conversational dependency, such as anaphora and ellipsis. However,\nexisting approaches do not explicitly train QA models on how to resolve the\ndependency, and thus these models are limited in understanding human dialogues.\nIn this paper, we propose a novel framework, ExCorD (Explicit guidance on how\nto resolve Conversational Dependency) to enhance the abilities of QA models in\ncomprehending conversational context. ExCorD first generates self-contained\nquestions that can be understood without the conversation history, then trains\na QA model with the pairs of original and self-contained questions using a\nconsistency-based regularizer. In our experiments, we demonstrate that ExCorD\nsignificantly improves the QA models' performance by up to 1.2 F1 on QuAC, and\n5.2 F1 on CANARD, while addressing the limitations of the existing approaches.", "published": "2021-06-22 07:16:45", "link": "http://arxiv.org/abs/2106.11575v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Knowledge-Grounded Counter Narrative Generation for Hate Speech", "abstract": "Tackling online hatred using informed textual responses - called counter\nnarratives - has been brought under the spotlight recently. Accordingly, a\nresearch line has emerged to automatically generate counter narratives in order\nto facilitate the direct intervention in the hate discussion and to prevent\nhate content from further spreading. Still, current neural approaches tend to\nproduce generic/repetitive responses and lack grounded and up-to-date evidence\nsuch as facts, statistics, or examples. Moreover, these models can create\nplausible but not necessarily true arguments. In this paper we present the\nfirst complete knowledge-bound counter narrative generation pipeline, grounded\nin an external knowledge repository that can provide more informative content\nto fight online hatred. Together with our approach, we present a series of\nexperiments that show its feasibility to produce suitable and informative\ncounter narratives in in-domain and cross-domain settings.", "published": "2021-06-22 13:48:49", "link": "http://arxiv.org/abs/2106.11783v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Exemplars-guided Empathetic Response Generation Controlled by the\n  Elements of Human Communication", "abstract": "The majority of existing methods for empathetic response generation rely on\nthe emotion of the context to generate empathetic responses. However, empathy\nis much more than generating responses with an appropriate emotion. It also\noften entails subtle expressions of understanding and personal resonance with\nthe situation of the other interlocutor. Unfortunately, such qualities are\ndifficult to quantify and the datasets lack the relevant annotations. To\naddress this issue, in this paper we propose an approach that relies on\nexemplars to cue the generative model on fine stylistic properties that signal\nempathy to the interlocutor. To this end, we employ dense passage retrieval to\nextract relevant exemplary responses from the training set. Three elements of\nhuman communication -- emotional presence, interpretation, and exploration, and\nsentiment are additionally introduced using synthetic labels to guide the\ngeneration towards empathy. The human evaluation is also extended by these\nelements of human communication. We empirically show that these approaches\nyield significant improvements in empathetic response quality in terms of both\nautomated and human-evaluated metrics. The implementation is available at\nhttps://github.com/declare-lab/exemplary-empathy.", "published": "2021-06-22 14:02:33", "link": "http://arxiv.org/abs/2106.11791v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "It's All in the Heads: Using Attention Heads as a Baseline for\n  Cross-Lingual Transfer in Commonsense Reasoning", "abstract": "Commonsense reasoning is one of the key problems in natural language\nprocessing, but the relative scarcity of labeled data holds back the progress\nfor languages other than English. Pretrained cross-lingual models are a source\nof powerful language-agnostic representations, yet their inherent reasoning\ncapabilities are still actively studied. In this work, we design a simple\napproach to commonsense reasoning which trains a linear classifier with weights\nof multi-head attention as features. To evaluate this approach, we create a\nmultilingual Winograd Schema corpus by processing several datasets from prior\nwork within a standardized pipeline and measure cross-lingual generalization\nability in terms of out-of-sample performance. The method performs\ncompetitively with recent supervised and unsupervised approaches for\ncommonsense reasoning, even when applied to other languages in a zero-shot\nmanner. Also, we demonstrate that most of the performance is given by the same\nsmall subset of attention heads for all studied languages, which provides\nevidence of universal reasoning capabilities in multilingual encoders.", "published": "2021-06-22 21:25:43", "link": "http://arxiv.org/abs/2106.12066v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks", "abstract": "Fake news travels at unprecedented speeds, reaches global audiences and puts\nusers and communities at great risk via social media platforms. Deep learning\nbased models show good performance when trained on large amounts of labeled\ndata on events of interest, whereas the performance of models tends to degrade\non other events due to domain shift. Therefore, significant challenges are\nposed for existing detection approaches to detect fake news on emergent events,\nwhere large-scale labeled datasets are difficult to obtain. Moreover, adding\nthe knowledge from newly emergent events requires to build a new model from\nscratch or continue to fine-tune the model, which can be challenging,\nexpensive, and unrealistic for real-world settings. In order to address those\nchallenges, we propose an end-to-end fake news detection framework named\nMetaFEND, which is able to learn quickly to detect fake news on emergent events\nwith a few verified posts. Specifically, the proposed model integrates\nmeta-learning and neural process methods together to enjoy the benefits of\nthese approaches. In particular, a label embedding module and a hard attention\nmechanism are proposed to enhance the effectiveness by handling categorical\ninformation and trimming irrelevant posts. Extensive experiments are conducted\non multimedia datasets collected from Twitter and Weibo. The experimental\nresults show our proposed MetaFEND model can detect fake news on never-seen\nevents effectively and outperform the state-of-the-art methods.", "published": "2021-06-22 21:21:29", "link": "http://arxiv.org/abs/2106.13711v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Statistical Analysis of Perspective Scores on Hate Speech Detection", "abstract": "Hate speech detection has become a hot topic in recent years due to the\nexponential growth of offensive language in social media. It has proven that,\nstate-of-the-art hate speech classifiers are efficient only when tested on the\ndata with the same feature distribution as training data. As a consequence,\nmodel architecture plays the second role to improve the current results. In\nsuch a diverse data distribution relying on low level features is the main\ncause of deficiency due to natural bias in data. That's why we need to use high\nlevel features to avoid a biased judgement. In this paper, we statistically\nanalyze the Perspective Scores and their impact on hate speech detection. We\nshow that, different hate speech datasets are very similar when it comes to\nextract their Perspective Scores. Eventually, we prove that, over-sampling the\nPerspective Scores of a hate speech dataset can significantly improve the\ngeneralization performance when it comes to be tested on other hate speech\ndatasets.", "published": "2021-06-22 17:17:35", "link": "http://arxiv.org/abs/2107.02024v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers", "abstract": "The goal of database question answering is to enable natural language\nquerying of real-life relational databases in diverse application domains.\nRecently, large-scale datasets such as Spider and WikiSQL facilitated novel\nmodeling techniques for text-to-SQL parsing, improving zero-shot generalization\nto unseen databases. In this work, we examine the challenges that still prevent\nthese techniques from practical deployment. First, we present KaggleDBQA, a new\ncross-domain evaluation dataset of real Web databases, with domain-specific\ndata types, original formatting, and unrestricted questions. Second, we\nre-examine the choice of evaluation tasks for text-to-SQL parsers as applied in\nreal-life settings. Finally, we augment our in-domain evaluation task with\ndatabase documentation, a naturally occurring source of implicit domain\nknowledge. We show that KaggleDBQA presents a challenge to state-of-the-art\nzero-shot parsers but a more realistic evaluation setting and creative use of\nassociated database documentation boosts their accuracy by over 13.2%, doubling\ntheir performance.", "published": "2021-06-22 00:08:03", "link": "http://arxiv.org/abs/2106.11455v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Fine-tune the Entire RAG Architecture (including DPR retriever) for\n  Question-Answering", "abstract": "In this paper, we illustrate how to fine-tune the entire Retrieval Augment\nGeneration (RAG) architecture in an end-to-end manner. We highlighted the main\nengineering challenges that needed to be addressed to achieve this objective.\nWe also compare how end-to-end RAG architecture outperforms the original RAG\narchitecture for the task of question answering. We have open-sourced our\nimplementation in the HuggingFace Transformers library.", "published": "2021-06-22 03:17:59", "link": "http://arxiv.org/abs/2106.11517v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Graph Routing between Capsules", "abstract": "Routing methods in capsule networks often learn a hierarchical relationship\nfor capsules in successive layers, but the intra-relation between capsules in\nthe same layer is less studied, while this intra-relation is a key factor for\nthe semantic understanding in text data. Therefore, in this paper, we introduce\na new capsule network with graph routing to learn both relationships, where\ncapsules in each layer are treated as the nodes of a graph. We investigate\nstrategies to yield adjacency and degree matrix with three different distances\nfrom a layer of capsules, and propose the graph routing mechanism between those\ncapsules. We validate our approach on five text classification datasets, and\nour findings suggest that the approach combining bottom-up routing and top-down\nattention performs the best. Such an approach demonstrates generalization\ncapability across datasets. Compared to the state-of-the-art routing methods,\nthe improvements in accuracy in the five datasets we used were 0.82, 0.39,\n0.07, 1.01, and 0.02, respectively.", "published": "2021-06-22 04:00:57", "link": "http://arxiv.org/abs/2106.11531v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LV-BERT: Exploiting Layer Variety for BERT", "abstract": "Modern pre-trained language models are mostly built upon backbones stacking\nself-attention and feed-forward layers in an interleaved order. In this paper,\nbeyond this stereotyped layer pattern, we aim to improve pre-trained models by\nexploiting layer variety from two aspects: the layer type set and the layer\norder. Specifically, besides the original self-attention and feed-forward\nlayers, we introduce convolution into the layer type set, which is\nexperimentally found beneficial to pre-trained models. Furthermore, beyond the\noriginal interleaved order, we explore more layer orders to discover more\npowerful architectures. However, the introduced layer variety leads to a large\narchitecture space of more than billions of candidates, while training a single\ncandidate model from scratch already requires huge computation cost, making it\nnot affordable to search such a space by directly training large amounts of\ncandidate models. To solve this problem, we first pre-train a supernet from\nwhich the weights of all candidate models can be inherited, and then adopt an\nevolutionary algorithm guided by pre-training accuracy to find the optimal\narchitecture. Extensive experiments show that LV-BERT model obtained by our\nmethod outperforms BERT and its variants on various downstream tasks. For\nexample, LV-BERT-small achieves 79.8 on the GLUE testing set, 1.8 higher than\nthe strong baseline ELECTRA-small.", "published": "2021-06-22 13:20:14", "link": "http://arxiv.org/abs/2106.11740v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Diversity and Limits of Human Explanations", "abstract": "A growing effort in NLP aims to build datasets of human explanations.\nHowever, the term explanation encompasses a broad range of notions, each with\ndifferent properties and ramifications. Our goal is to provide an overview of\ndiverse types of explanations and human limitations, and discuss implications\nfor collecting and using explanations in NLP. Inspired by prior work in\npsychology and cognitive sciences, we group existing human explanations in NLP\ninto three categories: proximal mechanism, evidence, and procedure. These three\ntypes differ in nature and have implications for the resultant explanations.\nFor instance, procedure is not considered explanations in psychology and\nconnects with a rich body of work on learning from instructions. The diversity\nof explanations is further evidenced by proxy questions that are needed for\nannotators to interpret and answer open-ended why questions. Finally,\nexplanations may require different, often deeper, understandings than\npredictions, which casts doubt on whether humans can provide useful\nexplanations in some tasks.", "published": "2021-06-22 18:00:07", "link": "http://arxiv.org/abs/2106.11988v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "ABCD: A Graph Framework to Convert Complex Sentences to a Covering Set\n  of Simple Sentences", "abstract": "Atomic clauses are fundamental text units for understanding complex\nsentences. Identifying the atomic sentences within complex sentences is\nimportant for applications such as summarization, argument mining, discourse\nanalysis, discourse parsing, and question answering. Previous work mainly\nrelies on rule-based methods dependent on parsing. We propose a new task to\ndecompose each complex sentence into simple sentences derived from the tensed\nclauses in the source, and a novel problem formulation as a graph edit task.\nOur neural model learns to Accept, Break, Copy or Drop elements of a graph that\ncombines word adjacency and grammatical dependencies. The full processing\npipeline includes modules for graph construction, graph editing, and sentence\ngeneration from the output graph. We introduce DeSSE, a new dataset designed to\ntrain and evaluate complex sentence decomposition, and MinWiki, a subset of\nMinWikiSplit. ABCD achieves comparable performance as two parsing baselines on\nMinWiki. On DeSSE, which has a more even balance of complex sentence types, our\nmodel achieves higher accuracy on the number of atomic sentences than an\nencoder-decoder baseline. Results include a detailed error analysis.", "published": "2021-06-22 19:31:28", "link": "http://arxiv.org/abs/2106.12027v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Positivity Bias in Negative Reviews", "abstract": "Prior work has revealed that positive words occur more frequently than\nnegative words in human expressions, which is typically attributed to\npositivity bias, a tendency for people to report positive views of reality. But\nwhat about the language used in negative reviews? Consistent with prior work,\nwe show that English negative reviews tend to contain more positive words than\nnegative words, using a variety of datasets. We reconcile this observation with\nprior findings on the pragmatics of negation, and show that negations are\ncommonly associated with positive words in negative reviews. Furthermore, in\nnegative reviews, the majority of sentences with positive words express\nnegative opinions based on sentiment classifiers, indicating some form of\nnegation.", "published": "2021-06-22 21:04:25", "link": "http://arxiv.org/abs/2106.12056v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Structured in Space, Randomized in Time: Leveraging Dropout in RNNs for\n  Efficient Training", "abstract": "Recurrent Neural Networks (RNNs), more specifically their Long Short-Term\nMemory (LSTM) variants, have been widely used as a deep learning tool for\ntackling sequence-based learning tasks in text and speech. Training of such\nLSTM applications is computationally intensive due to the recurrent nature of\nhidden state computation that repeats for each time step. While sparsity in\nDeep Neural Nets has been widely seen as an opportunity for reducing\ncomputation time in both training and inference phases, the usage of non-ReLU\nactivation in LSTM RNNs renders the opportunities for such dynamic sparsity\nassociated with neuron activation and gradient values to be limited or\nnon-existent. In this work, we identify dropout induced sparsity for LSTMs as a\nsuitable mode of computation reduction. Dropout is a widely used regularization\nmechanism, which randomly drops computed neuron values during each iteration of\ntraining. We propose to structure dropout patterns, by dropping out the same\nset of physical neurons within a batch, resulting in column (row) level hidden\nstate sparsity, which are well amenable to computation reduction at run-time in\ngeneral-purpose SIMD hardware as well as systolic arrays. We conduct our\nexperiments for three representative NLP tasks: language modelling on the PTB\ndataset, OpenNMT based machine translation using the IWSLT De-En and En-Vi\ndatasets, and named entity recognition sequence labelling using the CoNLL-2003\nshared task. We demonstrate that our proposed approach can be used to translate\ndropout-based computation reduction into reduced training time, with\nimprovement ranging from 1.23x to 1.64x, without sacrificing the target metric.", "published": "2021-06-22 22:44:32", "link": "http://arxiv.org/abs/2106.12089v1", "categories": ["cs.LG", "cs.CL", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Key-Sparse Transformer for Multimodal Speech Emotion Recognition", "abstract": "Speech emotion recognition is a challenging research topic that plays a\ncritical role in human-computer interaction. Multimodal inputs further improve\nthe performance as more emotional information is used. However, existing\nstudies learn all the information in the sample while only a small portion of\nit is about emotion. The redundant information will become noises and limit the\nsystem performance. In this paper, a key-sparse Transformer is proposed for\nefficient emotion recognition by focusing more on emotion related information.\nThe proposed method is evaluated on the IEMOCAP and LSSED. Experimental results\nshow that the proposed method achieves better performance than the\nstate-of-the-art approaches.", "published": "2021-06-22 04:02:58", "link": "http://arxiv.org/abs/2106.11532v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-accent Speech Separation with One Shot Learning", "abstract": "Speech separation is a problem in the field of speech processing that has\nbeen studied in full swing recently. However, there has not been much work\nstudying a multi-accent speech separation scenario. Unseen speakers with new\naccents and noise aroused the domain mismatch problem which cannot be easily\nsolved by conventional joint training methods. Thus, we applied MAML and FOMAML\nto tackle this problem and obtained higher average Si-SNRi values than joint\ntraining on almost all the unseen accents. This proved that these two methods\ndo have the ability to generate well-trained parameters for adapting to speech\nmixtures of new speakers and accents. Furthermore, we found out that FOMAML\nobtains similar performance compared to MAML while saving a lot of time.", "published": "2021-06-22 12:30:36", "link": "http://arxiv.org/abs/2106.11713v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning to Inference with Early Exit in the Progressive Speech\n  Enhancement", "abstract": "In real scenarios, it is often necessary and significant to control the\ninference speed of speech enhancement systems under different conditions. To\nthis end, we propose a stage-wise adaptive inference approach with early exit\nmechanism for progressive speech enhancement. Specifically, in each stage, once\nthe spectral distance between adjacent stages lowers the empirically preset\nthreshold, the inference will terminate and output the estimation, which can\neffectively accelerate the inference speed. To further improve the performance\nof existing speech enhancement systems, PL-CRN++ is proposed, which is an\nimproved version over our preliminary work PL-CRN and combines stage recurrent\nmechanism and complex spectral mapping. Extensive experiments are conducted on\nthe TIMIT corpus, the results demonstrate the superiority of our system over\nstate-of-the-art baselines in terms of PESQ, ESTOI and DNSMOS. Moreover, by\nadjusting the threshold, we can easily control the inference efficiency while\nsustaining the system performance.", "published": "2021-06-22 13:07:06", "link": "http://arxiv.org/abs/2106.11730v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Glance and Gaze: A Collaborative Learning Framework for Single-channel\n  Speech Enhancement", "abstract": "The capability of the human to pay attention to both coarse and fine-grained\nregions has been applied to computer vision tasks. Motivated by that, we\npropose a collaborative learning framework in the complex domain for monaural\nnoise suppression. The proposed system consists of two principal modules,\nnamely spectral feature extraction module (FEM) and stacked glance-gaze modules\n(GGMs). In FEM, the UNet-block is introduced after each convolution layer,\nenabling the feature recalibration from multiple scales. In each GGM, we\ndecompose the multi-target optimization in the complex spectrum into two\nsub-tasks. Specifically, the glance path aims to suppress the noise in the\nmagnitude domain to obtain a coarse estimation, and meanwhile, the gaze path\nattempts to compensate for the lost spectral detail in the complex domain. The\ntwo paths work collaboratively and facilitate spectral estimation from\ncomplementary perspectives. Besides, by repeatedly unfolding the GGMs, the\nintermediate result can be iteratively refined across stages and lead to the\nultimate estimation of the spectrum. The experiments are conducted on the\nWSJ0-SI84, DNS-Challenge dataset, and Voicebank+Demand dataset. Results show\nthat the proposed approach achieves state-of-the-art performance over previous\nadvanced systems on the WSJ0-SI84 and DNS-Challenge dataset, and meanwhile,\ncompetitive performance is achieved on the Voicebank+Demand corpus.", "published": "2021-06-22 13:58:08", "link": "http://arxiv.org/abs/2106.11789v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep neural network Based Low-latency Speech Separation with Asymmetric\n  analysis-Synthesis Window Pair", "abstract": "Time-frequency masking or spectrum prediction computed via short symmetric\nwindows are commonly used in low-latency deep neural network (DNN) based source\nseparation. In this paper, we propose the usage of an asymmetric\nanalysis-synthesis window pair which allows for training with targets with\nbetter frequency resolution, while retaining the low-latency during inference\nsuitable for real-time speech enhancement or assisted hearing applications. In\norder to assess our approach across various model types and datasets, we\nevaluate it with both speaker-independent deep clustering (DC) model and a\nspeaker-dependent mask inference (MI) model. We report an improvement in\nseparation performance of up to 1.5 dB in terms of source-to-distortion ratio\n(SDR) while maintaining an algorithmic latency of 8 ms.", "published": "2021-06-22 14:05:54", "link": "http://arxiv.org/abs/2106.11794v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Information Retrieval for ZeroSpeech 2021: The Submission by University\n  of Wroclaw", "abstract": "We present a number of low-resource approaches to the tasks of the Zero\nResource Speech Challenge 2021. We build on the unsupervised representations of\nspeech proposed by the organizers as a baseline, derived from CPC and clustered\nwith the k-means algorithm. We demonstrate that simple methods of refining\nthose representations can narrow the gap, or even improve upon the solutions\nwhich use a high computational budget. The results lead to the conclusion that\nthe CPC-derived representations are still too noisy for training language\nmodels, but stable enough for simpler forms of pattern matching and retrieval.", "published": "2021-06-22 08:30:41", "link": "http://arxiv.org/abs/2106.11603v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
